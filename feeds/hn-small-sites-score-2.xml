<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 07 Oct 2020 01:06:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 07 Oct 2020 01:06:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Fast, consistent, durable and scalable streaming data with Pravega]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24685835">thread link</a>) | @fpj
<br/>
October 5, 2020 | https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/ | <a href="https://web.archive.org/web/*/https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <!-- Share buttons by mashshare.net - Version: 3.7.7--><p><em><a href="https://es.linkedin.com/in/raulgraciatinedo">Raul Gracia</a> and <a href="https://www.linkedin.com/in/flavio-junqueira-bab134/">Flavio Junqueira</a></em></p>
<h2>Introduction</h2>
<p>Streaming systems continuously ingest and process data from a variety of data sources. They build on append-only data structures to enable efficient write and read access, targeting low-latency end-to-end. As more of the data sources in applications are machines, the expected volume of continuously generated data has been growing and is expected to grow further [1][2]. Such growth puts pressure on streaming systems to handle machine-generated workloads not only with low latency, but also with high throughput to accommodate high volumes of data.</p>
<p><a href="https://pravega.io/" target="_blank" rel="noopener">Pravega</a>&nbsp;(“good speed” in Sanskrit) is an open-source storage system for streams that we have built from the ground up to ingest data from continuous data sources and meet the <a href="https://pravega.io/docs/latest/" target="_blank" rel="noopener">stringent requirements</a> of such streaming workloads. It provides the ability to store an unbounded amount of data per stream using&nbsp;<a href="https://pravega.io/docs/latest/pravega-concepts/#a-note-on-tiered-storage" target="_blank" rel="noopener">tiered storage</a>&nbsp;while being <a href="https://pravega.io/docs/latest/pravega-concepts/#elastic-streams-auto-scaling" target="_blank" rel="noopener">elastic</a>, <a href="https://pravega.io/docs/latest/pravega-concepts/#architecture">durable</a> and <a href="https://pravega.io/docs/latest/pravega-concepts/#ordering-guarantees" target="_blank" rel="noopener">consistent</a>. Both the write and read paths of Pravega have been designed to provide low latency along with high throughput for event streams in addition to features such as long-term retention and stream scaling. This post is a performance evaluation of Pravega focusing on the ability of reading and writing.</p>
<p>To contrast with different design choices, we additionally show results from other systems: <a href="https://kafka.apache.org/">Apache Kafka</a> and <a href="https://pulsar.apache.org/">Apache Pulsar</a>. Initially qualified as messaging systems, both Pulsar and Kafka make a conscious effort to become more like a storage system; they have recently added features like tiered storage. These systems have made fundamentally different design choices, however, leading to different behavior and performance characteristics that we explore in this post.</p>
<p>The main aspects covered in this post and the highlights of our results are the following:</p>
<ul>
<li><em><a href="#pravega-ingestion">Overall ingestion performance</a>.</em>&nbsp;A Pravega writer produces over <strong>1 million events</strong>&nbsp;<strong>per second</strong>&nbsp;<strong>for small events</strong> (100 bytes) and <strong>sustains 350MB/s throughput for large events</strong> (10,000 bytes), both with <strong>single-digit millisecond latency</strong>&nbsp;(at the 95th percentile).</li>
<li><a href="#durability"><em>Durability</em></a>. <strong>Pravega always makes the data durable on acknowledgment</strong>. The write throughput of Kafka is at least 40% less compared to Pravega for a single-segment stream, independent of flushing on every message or not. For a 16-segment stream, the Pravega writer provides comparable throughput to the Kafka writer flushing on every message, but Pravega write latency is lower (<em>i.e.</em>, single-digit millisecond vs. 1+ seconds for Kafka).</li>
<li><em><a href="#dynamic-batching">Dynamically adjusting batches</a>.</em>&nbsp;Pravega <strong>does not</strong>&nbsp;<strong>require a complex configuration for client batching</strong>. The Pulsar client can achieve either low latency or high throughput, but not both. For Kafka, configuring large batches is detrimental for throughput when the application uses routing keys (throughput is 80% lower for a 16-segment stream). In both cases, forcing the user to statically configure batching is undesirable.</li>
<li><em><a href="#high-throughput">Behavior in the presence of large events for throughput-oriented workloads</a>. </em><strong>Pravega obtains up to 350MB/s for a 16-segment stream with 10kB events.&nbsp;</strong>The throughput&nbsp;is 40% higher than the one of Pulsar and comparable to the throughput of Kafka (about 6% difference). However, the latency in the case of Kafka is over 800ms while the one of Pravega is in single-digit milliseconds.</li>
<li><em><a href="#end-to-end-latency">End-to-end latency</a></em>. When tailing a stream, the Pravega reader also provides <strong>single-digit millisecond latency</strong>&nbsp;<strong>end-to-end&nbsp;</strong>while serving data at high throughput. It provides a higher throughput (roughly 80% more) for a single-segment stream when compared to Kafka. For Pulsar, adding partitions and readers leads to lower performance (single-partition case achieves 3.6x the throughput of the 16-segment case).</li>
<li><em><a href="#routing-keys">Use of routing keys</a></em>. <strong>Pravega does not present any significant performance difference when using or omitting routing keys.</strong>&nbsp;For moderate/high throughput rates, Kafka and Pulsar show over 2x end-to-end latency when using routing keys and, specifically for Kafka, a maximum read throughput that is over 37% lower.</li>
<li><em><a href="#historical-catchup">Tiered storage for catch-up and historical reads</a>.</em>&nbsp;Pravega can&nbsp;<strong>catch up with 100GB of historical data dynamically</strong>&nbsp;<strong>while ingesting 100MB per second of new data</strong>. Pulsar with tiering enabled was not able to catch up for the same scenario, inducing a backlog that grows without bounds.</li>
<li><em><a href="#auto-scaling">Performance with auto-scaling</a>. </em><strong>Auto-s</strong><strong>caling is a unique feature of Pravega</strong>. Scaling up a stream provides higher ingestion performance. We show that scaling up a stream using a constant ingestion rate of 100MB/s causes&nbsp;<strong>write latency to drop.</strong></li>
</ul>
<p>Except when we show time series, we plot latency along with throughput. It is a problem we commonly find across blog posts; they plot either latency or throughput, whereas both are jointly relevant for streaming workloads. For example, the maximum throughput for a given configuration might look very good while the latency is of the order of hundreds of milliseconds to a few seconds. We plot latency-throughput graphs to avoid misleading conclusions. We additionally provide tables with the data points used to complement the plots. The tables give more data than the plots (<em>e.g.</em>, different percentile ranks) for completeness.</p>
<h2>Background</h2>
<p>Pravega is a complex system, and we encourage the reader to investigate further our documentation, including <a href="https://blog.pravega.io/" target="_blank" rel="noopener">previous blog posts</a>. Here, we provide a very brief summary of the write and read paths, along with some key points of Kafka and Pulsar.</p>
<h3>The Pravega write path</h3>
<p>Pravega has different APIs for adding data to a stream. In this section, we primarily focus on the <a href="https://pravega.io/docs/latest/javadoc/clients/index.html"><em>event stream API</em></a>.</p>
<p>The <em>event stream writer&nbsp;</em>writes events to a stream. A stream can have parallel segments that can change dynamically according to an auto-scaling policy. When an application provides routing keys, the client uses them to map events to segments.&nbsp; If the routing key is omitted when writing an event, then the client selects a segment randomly.</p>
<p>The client opportunistically batches event data, and writes such batches to a segment. The client controls when to open new batches and close them, but the data for a batch accumulates on the server. The component in Pravega managing segments is called the <em><a href="https://blog.pravega.io/2019/04/22/events-big-or-small-bring-them-on/" target="_blank" rel="noopener">segment store</a></em>. The segment store receives such requests to write to a segment, and both add the data to a cache and appends it to a <em>durable log</em>, currently implemented with <a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener">Apache BookKeeper</a>. When appending to the durable log, the segment store performs a second round of batching. We have this second level of aggregation to sustain high throughput for use cases in which the message size is small and possibly infrequent.</p>
<p>The log guarantees durability: Pravega acknowledges events once they are made durable to the log, and uses such logs only for recovery. As the segment store keeps a copy of the written data to its cache, it flushes data out of the cache to tiered storage, called <em>long-term storage </em>(LTS), asynchronously.</p>
<p>BookKeeper splits its storage among journal, entry logger, and index. The journal is an append-only data structure, and it is the only data structure critical for the write path. Entry loggers and indexes are used in the read path of BookKeeper. In Pravega, the BookKeeper read path is only exercised during the recovery of segment stores. Consequently, the capacity of the write path depends primarily on the journal and not the other data structures, setting aside any occasional interference they can induce.</p>
<h3>The Pravega read path</h3>
<p>An application reads events individually using instances of the <em>event stream reader</em>. Event stream readers form part of a reader group and internally coordinate the assignment of stream segments. Stream readers read from the assigned segments, and they pull segment data from the segment store. Each time a reader fetches segment data, it fetches as much as it is available, up to a maximum of 1MB.</p>
<p>The segment store always serves data from the cache. If it is a cache hit, then serving the read does not require an additional IO. Otherwise, the segment store fetches the data from LTS in blocks of 1MB, populates the cache, and responds to the client. The segment store does not serve reads reading data from the durable log.</p>
<h3>Pulsar and Kafka</h3>
<p>Both Pulsar and Kafka define themselves as streaming platforms. Pulsar implements a broker that builds on Apache BookKeeper. The broker builds on the abstraction of a managed ledger, which is an unbounded log comprising BookKeeper ledgers that are sequentially organized. BookKeeper is the primary data store of Pulsar, although it optionally enables as part of a recent feature to <a href="https://pulsar.apache.org/docs/en/concepts-tiered-storage/" target="_blank" rel="noopener">tier data to long-term storage</a>.</p>
<p>Pulsar exposes the topic abstraction, and enables topics to be partitioned. Pulsar producers produce messages to topics.&nbsp; It provides different options for receiving and consuming messages, such as different subscription modes and reading manually from topics.</p>
<p>Kafka also implements a broker and exposes partitioned topics. Kafka does not use an external storage dependency like Pravega and Pulsar; it relies on local broker storage as the primary storage of the system. There is a proposal for <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" target="_blank" rel="noopener">adding tiered storage to Kafka in open-source</a>, but to our knowledge, it is only available as a <a href="https://www.confluent.io/blog/infinite-kafka-storage-in-confluent-platform/" target="_blank" rel="noopener">preview feature in the Confluent platform</a>. Consequently, we only compare tiered storage with Pulsar.</p>
<p>Both Pulsar and Kafka implement client batching, and enable the configuration of such batching. For both, two main parameters control client-side batching:</p>
<ul>
<li><strong>Maximum batch size</strong>: this is the maximum amount of data that the client is willing to accumulate for a single batch.</li>
<li><strong>Maximum wait time or linger</strong>: this is the maximum amount of time that the client is willing to wait to close a batch and submit it.</li>
</ul>
<p>There is an inherent trade-off between maximum batch size and waiting time: larger batches favor throughput in detriment of latency, whereas shorter waiting times have the opposite effect. If batches can be accumulated fast enough, then it is possible to obtain both high throughput and low …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/">https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/</a></em></p>]]>
            </description>
            <link>https://blog.pravega.io/2020/10/01/when-speeding-makes-sense-fast-consistent-durable-and-scalable-streaming-data-with-pravega/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685835</guid>
            <pubDate>Mon, 05 Oct 2020 08:55:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying “make invalid states unrepresentable”]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24685772">thread link</a>) | @fanf2
<br/>
October 5, 2020 | https://kevinmahoney.co.uk/articles/applying-misu/ | <a href="https://web.archive.org/web/*/https://kevinmahoney.co.uk/articles/applying-misu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="applying-make-invalid-states-unrepresentable">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">02 October 2020</time></p>

<p>Here are some real life cases of applying one of my
<a href="https://kevinmahoney.co.uk/articles/my-principles-for-building-software/">favourite principles</a>.</p>

<p>I’ll try to update this as I come across good examples.</p>

<h2 id="case-1-contiguous-time-periods">Case 1: Contiguous Time Periods</h2>

<p>A straightforward way to represent a period of time is by its start
and end dates (<code>(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c1.png"></p>

<p>If we need to represent a timeline split in to contiguous periods, it
may be tempting to represent this as a sequence of periods (e.g. <code>List
(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c2.png"></p>

<p>However, with this representation there can be both gaps in the
timeline and overlapping periods:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c3.png"></p>

<h3 id="improved-representation">Improved Representation</h3>

<p>We can improve this representation so that the contiguous and
non-overlapping constraints always hold, and we can do this in a way
that may remind you of database normalisation - by removing
redundancy.</p>

<p>In a well formed contiguous timeline, the joint start/end
of the adjacent periods are redundant. Contiguous, non-overlapping
splits can simply be represented by a set of dates (<code>Set Date</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c4.png"></p>

<p>You can begin to see how this representation simplifies the system
when you consider how to make a further split in the timeline. In the
list representation, splitting a period requires carefully modifying
the data-structure and ensuring constraints aren’t violated. In the
‘set of dates’ representation you simply add a date to the set.</p>

<p>It is sometimes still useful to represent the periods as a sequence of
start and end dates. It is trivial to project the set of dates in to
this form. As long as the canonical representation is the set, the
constraints will still hold.</p>

<h2 id="case-2-default-contracts">Case 2: Default Contracts</h2>

<p>In this system, a customer pays us a recurring rent based upon a contract.
Contracts last for a fixed amount of time, and when they expire we fall back to
a ‘default contract’. The customer can have many fixed contracts, and can
sign new contracts at any time.</p>

<p>This was represented as:</p>
<ul>
  <li>A ‘customers’ table storing
    <ul>
      <li>The customer start date.</li>
      <li>An optional end date, should the customer leave.</li>
    </ul>
  </li>
  <li>A ‘contracts’ table storing
    <ul>
      <li>The contract start date.</li>
      <li>An optional end date, for default contracts that don’t end.</li>
      <li>If it was a ‘fixed’ or ‘default’ contract.</li>
    </ul>
  </li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f1.png"></p>
<p>Customer and contract timelines</p>

<p>This representation allows for some undesirable states that are trivial to prevent:</p>
<ul>
  <li>The customer may have gaps in their contracts.</li>
  <li>A fixed contract may not have an end date.</li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f2.png"></p>
<p>Contract gaps</p>

<p>To make matters worse, the API for these contracts allowed you to
modify each individual contract, fixed or default, without guarding against
these states. This shows how a poor choice of
representation propagates itself through the design of a system.</p>

<p>This poor choice was not just a theoretical problem -
gaps in contracts were found on more than one occasion, requiring
hours of engineering effort to hunt down and fix.</p>

<h3 id="improved-representation-1">Improved Representation</h3>

<p>This is easily improved by removing the ‘default’ contracts from the
contract table. If the customer doesn’t have a fixed contract, it is
assumed they are on a default contract:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f3.png"></p>
<p>Inferred default contracts</p>

<p>Now there can no longer be any gaps, and 
the end date of a contract no longer needs to be optional as it only represents fixed contracts.</p>

<p>It’s worth reiterating that this representation can be projected in to the previous
representation using a database view if that form is more convenient. What is
important is that the underlying representation enforces these constraints, it
is not important how you view the data.</p>

<p>As with the first case, a better representation makes the manipulation
of the data structure simpler. In this case, adding a new fixed contract is
greatly simplified. There is no need to create or modify default contracts, or ensure
that the contracts are contiguous.</p>

<h3 id="the-influence-of-object-oriented-thinking">The Influence of Object-Oriented Thinking</h3>

<p>If this improvement seems obvious to you, you may wonder how the
original design happened in the first place.</p>

<p>I think this happens because of atomistic, object-oriented thinking.</p>

<p>In this mindset, the fixed contracts are <em>objects</em>, the default contracts are
<em>objects</em>, and each of these concepts must be reified as a row in a table and
never inferred.
There is a distrust of using any features the database
offers beyond storing or retrieving <em>objects</em>.</p>

<p>This approach is antithetical to quality relational design and
the principle of making invalid states unrepresentable.</p>

<p>It may feel “simpler” on some level, as you don’t really need
to think about your design.
However, as we see here, this lack of forethought inevitably
leads to complexity.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://kevinmahoney.co.uk/articles/applying-misu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685772</guid>
            <pubDate>Mon, 05 Oct 2020 08:43:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The End of Google?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24685505">thread link</a>) | @copypirate
<br/>
October 5, 2020 | https://seobutler.com/end-of-google/ | <a href="https://web.archive.org/web/*/https://seobutler.com/end-of-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				        	
<figure><img loading="lazy" width="1024" height="576" src="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-300x169.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-768x432.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1536x864.png 1536w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-600x338.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-300x169.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-768x432.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1536x864.png 1536w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image-600x338.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Header-Image.png 1920w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Header-Image-1024x576.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Google, Facebook, Apple, Amazon…</p>



<p>Combined, the “Big 4” tech giants are <a target="_blank" href="https://www.businessinsider.com/most-valuable-tech-companies-total-worth-trillions-alphabet-stock-record-2020-1">worth over $5 trillion dollars.</a></p>



<p>Humans have a <a target="_blank" href="https://www.wsj.com/articles/grasping-giant-numbers-is-far-from-second-nature-1490952621">problem grasping giant numbers</a>, so to put that figure in perspective, it’s equal to the <a target="_blank" href="https://www.investopedia.com/insights/worlds-top-economies/">2019 GDP of Japan</a> — and almost a quarter that of the United States.</p>



<p>Despite being <a target="_blank" href="https://www.forbes.com/the-worlds-most-valuable-brands/#dd07f06119c0">the world’s second-most valuable company,</a> Google’s had a tough month.</p>



<p>The fact that <a target="_blank" href="https://www.nytimes.com/2020/09/24/technology/google-service-outage.html?">a brief service outage in the US</a> made <a target="_blank" href="https://www.the-sun.com/news/1530213/google-gmail-youtube-hangout-crashed-down/">front-page news worldwide</a> goes to show how dependent people have become on Google and its products…</p>



<p>But far more distressing to the C-Suite must be the news that US Attorney General William Barr is hellbent on bringing an <a target="_blank" href="https://www.nytimes.com/2020/09/22/technology/justice-dept-case-google-search-dominance.html">antitrust lawsuit against Google</a> before the election in November — and maybe as early as the beginning of October.</p>



<p>Barr’s Justice Department has set its sights square on Google’s dominance in search.</p>



<p>At the risk of biting the hand that feeds us, I’m going to take a look at what brought Google to this point — and some possible outcomes of the threats to Google’s monopoly on both search and digital advertising.</p>



<h2><strong>Antitrust and Technology</strong></h2>



<p>In the US, antitrust laws <a target="_blank" href="https://www.investopedia.com/terms/a/antitrust.asp">date back to the Sherman Act,</a> passed in the 1890s.</p>



<p>Antitrust regulations are designed to protect consumers from the adverse impact of one or less than a handful of companies having a monopoly on an essential product or service.</p>



<p>Monopolies represent a barrier to competition — and <a target="_blank" href="https://www.consumer.ftc.gov/sites/default/files/games/off-site/youarehere/pages/pdf/FTC-Competition_How-Comp-Works.pdf">competition is essential</a> in a free-market economy.</p>



<figure><img loading="lazy" width="945" height="630" src="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png 945w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-300x200.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-768x512.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-600x400.png 600w" sizes="(max-width: 945px) 100vw, 945px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png 945w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-300x200.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-768x512.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic-600x400.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Monopoly-Graphic.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: </em><a target="_blank" href="https://www.thebalance.com/monopoly-4-reasons-it-s-bad-and-its-history-3305945"><em>The Balance</em></a><em>)</em></figcaption></figure>



<p>Some of the <a target="_blank" href="https://www.thebalance.com/monopoly-4-reasons-it-s-bad-and-its-history-3305945">commonly cited adverse effects</a> of a monopoly include price-fixing, inferior products and services, and the stifling of innovation.</p>



<p>The first antitrust lawsuits were brought against <a target="_blank" href="https://www.law.cornell.edu/supremecourt/text/274/693">International Harvester</a> and <a target="_blank" href="https://en.wikipedia.org/wiki/United_States_v._American_Tobacco_Co.">American Tobacco…</a></p>



<p>Apparently, both farm machinery and cigarettes were both viewed as essential at the turn of the twentieth century.</p>



<p>Antitrust laws are often used to prevent mergers between large companies that might harm consumers.</p>



<p>When oil giants Exxon and Mobil merged in the late 1990s, they were forced to sell 2,431 gas stations before the <a target="_blank" href="https://www.dividend.com/how-to-invest/5-major-antitrust-mergers/">$80.3 billion deal</a> was allowed to proceed.</p>



<p>Despite this divestiture, Exxon-Mobil was the world’s most valuable company until <a target="_blank" href="https://money.cnn.com/2012/01/25/markets/apple_stock/index.htm">Apple surpassed it in 2012.</a></p>



<p>Digital technology companies have had their fair share of skirmishes over monopoly and antitrust issues with the government, both in the US and around the world.</p>



<p>IBM faced <a target="_blank" href="https://en.wikipedia.org/wiki/History_of_IBM#Twentieth-century_market_power_and_antitrust">over 20 government and private antitrust actions</a> in the 20th century.</p>



<p>On the cusp of the 2000s, <a target="_blank" href="https://www.investopedia.com/ask/answers/08/microsoft-antitrust.asp">Microsoft was sued by the Department of Justice (DoJ)</a> and others to “determine whether the company’s bundling of additional programs into its operating system constituted monopolistic actions.”</p>



<p>These actions were partly a result of the <a target="_blank" href="https://thehistoryoftheweb.com/browser-wars/">“Browser Wars”</a> between Microsoft’s Internet Explorer and their now long-defunct competitor, Netscape.&nbsp;</p>



<p>Microsoft was accused of intentionally making it difficult for consumers to install software from competitors on Windows machines — and delete Microsoft’s bundled programs.</p>



<p>Microsoft <a target="_blank" href="https://www.theringer.com/tech/2018/5/18/17362452/microsoft-antitrust-lawsuit-netscape-internet-explorer-20-years">lost the case,</a> and the judge called for the company to split into two separate entities called <a target="_blank" href="https://www.investopedia.com/terms/b/babybills.asp">Baby Bills</a>, a reference to the “Baby Bells” created when the government broke up AT&amp;T in the 1980s.&nbsp;</p>



<p>The Windows OS side of Microsoft’s business was to become a separate corporate entity from the software side.</p>



<p>Ultimately, <a target="_blank" href="https://www.seattletimes.com/business/microsoft/long-antitrust-saga-ends-for-microsoft/">Microsoft settled with the US government</a>, and escaped being split up but it was forced to make <a target="_blank" href="https://www.justice.gov/atr/usdoj-antitrust-division-us-v-microsoft-corporation-information-settlement">significant concessions</a> that limited its anticompetitive tactics.</p>



<p>Many observers speculate that the antitrust lawsuits against Microsoft led to Bill Gates stepping down as CEO.</p>



<p>The lawsuits and settlement also fostered a more competitive environment that allowed fledgling startups like Google, Facebook, and Amazon to survive and thrive.&nbsp;</p>



<figure><img loading="lazy" src="https://seobutler.com/wp-content/uploads/2020/09/Sundar-Pichai-Congress.png" alt="" width="860" height="586" data-src="https://seobutler.com/wp-content/uploads/2020/09/Sundar-Pichai-Congress.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>8<strong>Google CEO Sundar Pichai Testifies Remotely to Congress, July 2020</strong><em> (Source: <a target="_blank" href="https://www.cnet.com/news/congress-zeroes-in-on-google-during-historic-tech-antitrust-hearing/">Cnet</a>)</em></figcaption></figure>



<h2><strong>Threats to Google’s Monopoly on Search and Digital Advertising</strong></h2>



<h3><strong>Antitrust in the US</strong></h3>



<p>Federal government concerns about Google’s dominance in both search and online advertising really began to pick up steam in summer 2019 when the Justice Department and Federal Trade Commission (FTC) <a target="_blank" href="https://www.nytimes.com/2020/09/22/technology/justice-dept-case-google-search-dominance.html?searchResultPosition=1">opened antitrust investigations</a> into all of the “Big Four” tech giants.</p>



<p>Additionally, <a target="_blank" href="https://www.theverge.com/2019/9/9/20857440/google-antitrust-investigation-attorneys-general-advertising-search">Google finds itself targeted for investigation by 50 state attorneys general</a> for its anticompetitive practices, particularly its dominant share of the digital advertising market.&nbsp;</p>



<p>Only California and Arizona declined to join the probe.</p>



<figure><img loading="lazy" src="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png" alt="" width="720" height="537" srcset="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png 560w, https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search-300x224.png 300w" sizes="(max-width: 720px) 100vw, 720px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png 560w, https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search-300x224.png 300w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Top-5-Companies-Search.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>(<em>Source: <a target="_blank" href="https://www.geekwire.com/2019/amazon-gaining-google-search-advertising-market-share/">Geekwire</a></em>)</figcaption></figure>



<p>In 2019, Google accounted for a 31.6% market share of overall digital ad spending and a 73.1% share of search advertising.</p>



<p>Google’s dominance in search is even more staggering…</p>



<figure><img loading="lazy" width="1000" height="743" src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-600x446.png 600w" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020-600x446.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id216573_global-market-share-of-search-engines-2010-2020.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><strong>Global Market Share of Search Engines</strong><em> (Source: <a target="_blank" href="https://www.statista.com/statistics/216573/worldwide-market-share-of-search-engines/">Statista</a>)</em></figcaption></figure>



<p>As of July 2020, Google held an 87% market share in desktop search — its nearest competitor, Bing, accounted for just over 6%.</p>



<p>This disparity has led critics of both major political parties, as well as President Donald Trump, to argue that Google needs to be more strictly regulated — or even split up into smaller entities.</p>



<p>There is precedent for breaking up monopolies in the United States.&nbsp;</p>



<p>In 1904, John D. Rockefeller’s Standard Oil controlled <a target="_blank" href="https://www.cnbc.com/2020/05/15/doj-and-state-ags-likely-to-file-antitrust-lawsuit-against-google-wsj.html">91% of oil production and 85% of oil sales in the US.</a></p>



<p>The Supreme Court ruled in 1911 that Standard Oil was in violation of federal antitrust laws and split the company up into 34 separate entities, including companies that became <a target="_blank" href="https://en.wikipedia.org/wiki/John_D._Rockefeller">ExxonMobil and Chevron.</a></p>



<p>In more recent history, <a target="_blank" href="https://www.investopedia.com/ask/answers/09/att-breakup-spinoff.asp">antitrust lawsuits filed in the early 1970s against AT&amp;T</a> — which operated a legal monopoly on local and long-distance telecommunications for almost a century — broke the company up into seven smaller entities known as <a target="_blank" href="https://www.investopedia.com/terms/b/babybells.asp">“Baby Bells.”</a></p>



<p>In addition to the DoJ and State’s attorney investigations into Google, all of the Big 4’s CEOs were recently summoned to appear remotely before Congress’s <a target="_blank" href="https://judiciary.house.gov/subcommittees/antitrust-commercial-and-administrative-law-116th-congress/">House Judiciary subcommittee on Antitrust.</a>&nbsp;</p>



<figure><img loading="lazy" src="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png" alt="" width="720" height="410" srcset="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png 782w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-300x171.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-768x438.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-600x342.png 600w" sizes="(max-width: 720px) 100vw, 720px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png 782w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-300x171.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-768x438.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs-600x342.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Big-4-CEOs.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><strong>Mark Zuckerburg, Jeff Bezos, Tim Cook, Sundar Pichai testify before Congress, July 2020</strong> <em>(Source: <a target="_blank" href="https://www.exchange4media.com/digital-news/us-congress-accuse-zuckerberg-bezos-cook-pichai-of-crippling-competitors-with-monopoly-106495.html">Exchange4Media</a>)</em></figcaption></figure>



<p>The subcommittee held the hearing after investigating the Big 4 for over a year.</p>



<p>In the current American political environment, where it often seems like Republicans and Democrats agree on practically nothing, the hearing was surprisingly bipartisan.</p>



<p>By many pundit’s accounts, <a target="_blank" href="https://www.cnet.com/news/congress-zeroes-in-on-google-during-historic-tech-antitrust-hearing/">Google’s Sundar Pichai faced the most intense scrutiny</a> by lawmakers during the <a target="_blank" href="https://youtu.be/T0gJYFX8WVc">almost 6-hour session.</a></p>



<p>Here are the elements of Google’s vast empire that are thought to be most vulnerable to punitive antitrust actions.</p>



<figure><img loading="lazy" width="1000" height="743" src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png" alt="Google Ad revenue" srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-600x446.png 600w" sizes="(max-width: 1000px) 100vw, 1000px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png 1000w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-300x223.png 300w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-768x571.png 768w, https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019-600x446.png 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/statistic_id266249_google_-annual-advertising-revenue-2001-2019.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: <a target="_blank" href="https://www.statista.com/statistics/266249/advertising-revenue-of-google/">Statista</a>)</em></figcaption></figure>



<h4>Advertising&nbsp;</h4>



<p>Not only does Google command a lopsided market share in both search advertising and digital advertising as a whole, but it also faces investigation because Google effectively owns and controls every aspect of the online marketplace for selling and purchasing advertising.</p>



<p>Google has achieved its advertising hegemony primarily through acquiring competitors, such as it’s <a target="_blank" href="https://www.wired.com/2008/03/google-seals-do/">2008 buyout of ad-tech firm DoubleClick.</a></p>



<p>Over <a target="_blank" href="https://www.statista.com/statistics/266249/advertising-revenue-of-google/">70% of Google’s revenue comes from advertising</a> — over $160 billion in 2019.</p>



<p>Any threat to this income stream could have devastating effects on the value of the company.</p>



<p>Investigators and competitors charge that allowing Google to have such complete control over digital advertising is harmful to competition and gives Google an unfair advantage.</p>



<h4>Content</h4>



<p>Content creators and publishers big and small were likely thrilled when Rep. David Cicilline, chairman of the antitrust subcommittee <a target="_blank" href="https://news.yahoo.com/why-does-google-steal-content-201052393.html">straight up asked Pichai,</a> “Why does Google steal content?”</p>



<p>Unsurprisingly, Pichai disagreed with the characterization, but Cicilline rejected his response.&nbsp;</p>



<p>Congress, he said, has “heard throughout this investigation that Google has stolen content to build your own business. These are consistent reports, and so your testimony that it doesn’t happen is really inconsistent with what we’ve learned during the course of the investigation.”</p>



<p>As Google continually finds new ways to answer search queries using third party content on its own platform, often without attribution or a link to the source, it seems likely that this strategy will come under growing scrutiny.</p>



<figure><img loading="lazy" width="1024" height="598" src="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png" alt="Google Search Antitrust" srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-300x175.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-768x448.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-600x350.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust.png 1252w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-300x175.png 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-768x448.png 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-600x350.png 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust.png 1252w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Google-Search-Antitrust-1024x598.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h4>Search</h4>



<p>Google’s near-total dominance of search has led to numerous allegations of anticompetition practices — including favoring its own products above competitors in search results.</p>



<p>Founder’s tales of businesses being decimated by Google’s search manipulation and favoritism towards its own offerings abound online — such as <a target="_blank" href="https://www.usatoday.com/story/opinion/2020/02/14/googles-anti-competitive-practices-decimates-online-shopping-antitrust-column/4718626002/">this one</a> from the founder of comparison shopping site Kelkoo or this <a target="_blank" href="https://www.latimes.com/business/la-fi-google-search-favoritism-20150630-story.html">Harvard and Columbia study funded by Yelp.</a></p>



<p><a target="_blank" href="https://www.nytimes.com/2020/09/22/technology/justice-dept-case-google-search-dominance.html?">According to The New York Times</a>, the DoJ has narrowed its focus to search and may leave action on Google’s advertising practices to the state attorneys, <a target="_blank" href="https://www.reuters.com/article/us-google-doj-idUSKBN22R37I">led by Texas Attorney General, Ken Paxton.</a></p>



<p>Paxton says he has not ruled out any possible punishment, including breaking up the company.</p>



<p>By narrowing the focus to search, the DOJ hopes to have a stronger lawsuit that it can file in a more timely fashion.</p>



<p>The federal case is expected to largely drill down on Google’s agreements with Apple and other companies to have Google set as the default search engine on iPhones and other devices.&nbsp;</p>



<p>The DoJ will likely argue this an anti-competitive practice that puts other search engines at a significant disadvantage.</p>



<figure><img loading="lazy" width="1024" height="683" src="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-300x200.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-768x512.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1536x1025.jpg 1536w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-2048x1367.jpg 2048w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-600x400.jpg 600w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-300x200.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-768x512.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1536x1025.jpg 1536w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-2048x1367.jpg 2048w, https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-600x400.jpg 600w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Android-Antitrust1482061-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: <a target="_blank" href="https://www.pexels.com/photo/black-google-smartphone-on-box-1482061/">Pexels</a>)</em></figcaption></figure>



<h4>Android</h4>



<p>One other possible vulnerability regulators might exploit is the ubiquity of Google’s Android mobile operating system.</p>



<p>Android is by far the most popular mobile OS globally, with a <a target="_blank" href="https://www.statista.com/statistics/272698/global-market-share-held-by-mobile-operating-systems-since-2009/">74.6% market share.</a></p>



<p><a target="_blank" href="https://www.reuters.com/article/us-tech-antitrust-google-idUSKBN1XO2UQ">Reports say that the state attorneys</a> are also investigating Android for antitrust violations.&nbsp;</p>



<p>The EU has already fined Google €4.34 billion for using Android “as a vehicle to cement the dominance of its search engine.”</p>



<figure><img loading="lazy" width="1024" height="535" src="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg" alt="" srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-300x157.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-768x402.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-600x314.jpg 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe.jpg 1050w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg 1024w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-300x157.jpg 300w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-768x402.jpg 768w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-600x314.jpg 600w, https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe.jpg 1050w" data-src="https://seobutler.com/wp-content/uploads/2020/09/Google-Antitrust-Europe-1024x535.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption><em>(Source: </em><a target="_blank" href="https://www.nytimes.com/2015/04/16/business/international/european-union-google-antitrust-case.html"><em>NY Times</em></a><em>)</em></figcaption></figure>



<h2><strong>Taxation and Privacy Regulation in Europe</strong></h2>



<p>AG Barr’s antitrust campaign is far …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seobutler.com/end-of-google/">https://seobutler.com/end-of-google/</a></em></p>]]>
            </description>
            <link>https://seobutler.com/end-of-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685505</guid>
            <pubDate>Mon, 05 Oct 2020 07:49:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Underestimated Value of Open-Source]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24685502">thread link</a>) | @mstruebing
<br/>
October 5, 2020 | https://farbenmeer.de/de/blog/the-underestimated-value-of-open-source | <a href="https://web.archive.org/web/*/https://farbenmeer.de/de/blog/the-underestimated-value-of-open-source">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>What is open source</h3><p>Open-source software means that the source code of a software is publicly available. Everyone can read, copy or change the source code which makes the software more trustworthy and long-living than closed source software. Famous and big examples of open-source software projects are the <a href="https://github.com/torvalds/linux" target="_blank" rel="noopener">Linux kernel</a>, <a href="https://hg.mozilla.org/mozilla-central" target="_blank" rel="noopener">Firefox</a>, <a href="https://git.libreoffice.org/core" target="_blank" rel="noopener">LibreOffice</a> or <a href="https://android.googlesource.com/?format=HTML" target="_blank" rel="noopener">Android</a> but there are also many many small open-source software projects out there.</p><h3>Benefits</h3><p>If you can read code, you are actually able to understand and evaluate what is happening when you execute that software. Not only what the software pretends to do but rather what it really does.</p><p>This feature also allows everyone to scan the source code for security vulnerabilities or other weaknesses of any kind, which adds to the trustworthiness mentioned above.</p><p>Another main advantage is that you are able to request help from basically every user/contributor of that software which is mostly faster and provides more creative solutions than most commercial support.</p><p>Also, the software is not only dependent on the original author and can be maintained and extended by the community. There can be even different versions of the same software with different features. If the community thinks it would not be a good idea to add a specific feature, someone can copy the source code and release their own version of it.</p><p>You can learn a lot, and I mean really a lot! </p><p>Reading and understanding the source code of other programs may not be easy, especially if the software is relative complex, but you will learn a lot in the progress as you are confronted with ideas and solutions from many other people which spend sometimes hours, days or even longer with a specific problem and came up with a solution.</p><p>If you are also willing to contribute and not only to use the software you gain another few advantages.</p><p>You will be forced to think way more about your problem than with closed source. As the software will be used by many other people, it is not only your specific use case which is relevant. This forces you to gain a deeper understanding of the concrete problem and you are also forced to think of reasonable abstractions and edge cases as well as configurability.</p><p>Another important step, which is often not really recognized is that it is not only important to fix the problem or build that feature, it is also very important to write readable and maintainable code, otherwise no one will be able to touch it and as the software evolves it may be removed eventually because no one understands.</p><p>As everyone knows, good documentation is key, you actually need to write documentation, otherwise, no one will be able to use your cool new feature</p><p>and the community of that project will not be happy and may not even merge your cool new feature. This all may sound difficult, but I think you will learn key skills which are important or beneficial for your whole career as a software engineer.</p><p>It is especially beneficial for job applications because others can really see what you are doing rather than just talking about it or even worse, test your skills on a whiteboard.</p><p>Another major advantage is the joy you feel when others actually use the software you have written, especially if it will be used in ways you don't even consider.</p><h3>Disadvantages</h3><p>What may be viewed as a disadvantage is the monetization of your product. As this is true at the first glance, there are also ways of making money with open-source software.</p><p>If your software is a service you could provide a hosted solution where users would have to pay money to use it, but if they really want and have the resources they could also host it themselves.</p><p>On the other hand, you are an expert in using, customizing and developing the software, so if others need support they could hire you to help them.</p><p>Some individuals or companies are also sponsoring open source software maintainer through <a href="https://github.com/sponsors" target="_blank" rel="noopener">GitHub Sponsors</a> or <a href="https://www.patreon.com/" target="_blank" rel="noopener">Patreon</a> for example.</p><p>If your software grows and more and more people are contributing to it you will have no other choice than to set up some processes, like: "When is someone allowed to merge a PR?", "Who decides if something will be added or not?", "Who has the last word in case a conflict arises?", "What documentation is mandatory?", "Do we raise money?"(In case of a non-profit open-source project), "What kind of merchandising are producing?" and there are many many more, that are all questions that came to my mind in less than 5 minutes. To set up such rules and processes will feel cumbersome at the beginning, but you will not be able to grow your project without. There is no silver bullet, you will need to think of processes and rules on your own, what is applicable to your project, but sure you can grab inspiration from other open-source software projects.</p><h3>Summary</h3><p>Open-source software is very popular because of the trust this gives its users. Contributing to it also has a bunch of advantages for the contributing</p><p>individuals although it is way harder than working on individual and closed source software as you need to pay attention to more and greater details and you can even earn some money with it. </p></div></div>]]>
            </description>
            <link>https://farbenmeer.de/de/blog/the-underestimated-value-of-open-source</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685502</guid>
            <pubDate>Mon, 05 Oct 2020 07:49:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What you could steal from the Kakoune code editor, and get away with]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24685267">thread link</a>) | @todsacerdoti
<br/>
October 5, 2020 | https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
      <h2>What you could steal from the Kakoune code editor right now, and get away with it</h2>

<p><a href="https://kakoune.org/">Kakoune</a> is a (fairly) young modal code editor
that has matured for as long and as well as a good red wine. It places
multiple-selections, operability and interactivity at the heart of its
distinctive characteristics. It provides users with an efficient and
comfortable text editing experience — but that’s not what this article
is about.</p>

<p>Now 8 years old at the time of writing, Kakoune has gone through several
iterations that removed a dependency here, optimised a core feature there,
even factorised entire parts of its codebase! And as any long-term user
will tell you, it’s easy to take all that good stuff for granted.</p>

<p>So here it is. I’m stopping time for a couple minutes, and listing in
this article a few things that the Kakoune project does well in several
dimensions. Some are technical, but the rest should hopefully be easily
adaptable to other projects (whether they are code editors or not), and
generic enough to be adopted seamlessly.</p>

<p>Now why does the title of this piece mention stealing? Read on, that’s item
number one.</p>

<h2 id="from-its-licensing-model">From its licensing model</h2>

<p>If something doesn’t belong to anybody, is it stealing if you take it for
yourself? What if it belongs equally to everybody?</p>

<p>Fortunately we don’t need to solve that problem: Kakoune is a public domain
project. Which means that anyone is free to do anything they want with the
source code of the editor, no questions asked.</p>

<p>This has several advantages:</p>

<ul>
  <li>the tool can be shipped with any distribution or suite, regardless of
licensing</li>
  <li>users can modify the code (to fix bugs, add new features or tweak already
existing ones etc.) and publish it (or compiled binaries) without worrying
about attribution</li>
  <li>it lifts some weight of responsibility of the maintainer for the whole
project, which anyone can re-brand or heavily modify to their liking</li>
</ul>

<p>Users don’t like paying for tools, and when they are free and open-source,
I’d argue that they turn out to be more useful (with several iterations,
over time) in the end if they place no limits on what users are allowed to
do with the code.</p>

<p>I’m not in favour of abolishing licenses, I think it would be more
productive for everyone if specialised tools were in the public
domain. In fact, the Kakoune project <em>is</em> licensed, under the
<a href="https://choosealicense.com/licenses/unlicense/">terms</a> of the
<a href="https://unlicense.org/">UNLICENSE</a>, in order to avoid conflicts with
jurisdictions that don’t recognise the <em>public domain</em> model.</p>

<p>As for the small riddle above, that’s a tough one, bordering on the
philosophical, but since we’re talking about replicating data, we can easily
break out of that paradox: copying is not stealing.</p>

<h2 id="from-its-code">From its code</h2>

<p>New comers like to praise Kakoune for having a clean codebase, easy to
navigate and modify. And for good reason! Written in C++, the code uses the
smallest amount of bells and whistles possible to keep the code elegant,
compilable with (reasonably) old compiler versions, but more importantly
convenient.</p>

<p>And when it comes to convenience, Kakoune has some interesting assets your
project could benefit from:</p>

<ul>
  <li>a header-only implementation of a diffing algorithm
(<a href="https://github.com/mawww/kakoune/blob/master/src/diff.hh">diff.hh</a>)</li>
  <li>a regex engine mostly following the ECMA syntax — this implementation
allowed the project to drop
<a href="https://www.boost.org/doc/libs/1_74_0/libs/regex/doc/html/index.html">boost::regex</a>
as a dependency
(<a href="https://github.com/mawww/kakoune/blob/master/src/regex.hh">regex.hh</a>)</li>
  <li>a minimal JSON (un)marshaller
(<a href="https://github.com/mawww/kakoune/blob/master/src/json.hh">json.hh</a>)</li>
  <li>a custom hash map implementation
(<a href="https://github.com/mawww/kakoune/blob/master/src/hash_map.hh">hash_map.hh</a>)</li>
  <li>wrappers for string types (e.g. string view) and associated utilities:
join, wrap, split, quote, pad etc.
(<a href="https://github.com/mawww/kakoune/blob/master/src/string.hh">string.hh</a>
· <a href="https://github.com/mawww/kakoune/blob/master/src/string_utils.hh">string_utils.hh</a>)</li>
  <li>various functional range filters: filter, transform, gather, map etc.
(<a href="https://github.com/mawww/kakoune/blob/master/src/ranges.hh">ranges.hh</a>)</li>
  <li>an implementation of Go’s defer statement that runs code once the execution
flow leaves the current scope
(<a href="https://golang.org/ref/spec#Defer_statements">Go specification</a>
· <a href="https://github.com/mawww/kakoune/blob/master/src/utils.hh#L53">utils.hh</a>)</li>
</ul>

<p>The above snippets are not exactly drop-in, as they are still coupled to
custom types defined for the editor, but should nonetheless be adaptable
without much difficulty to other C++ projects.</p>

<h2 id="from-its-user-interface">From its user interface</h2>

<p>Originally an easter-egg that savvy users found out about by reading the
code that handles the terminal client’s user interface, the Clippy character
has become a mascot that is now enabled out of the box. However, although
it’s undeniable that nostalgia for Microsoft Office’s assistant has fuelled
prolonged interest in Clippy itself, the easter egg’s notoriety has cast a
shadow on the larger feature it’s a prisoner of: the auto-info pop up window.</p>

<p>The auto-info window is a big contributor to the general level of
interactivity the editor provide, as it pops up any time the user hits a
key in normal mode or has typed a function name in the command prompt. Its
purpose is to provide instant feedback to the user, communicate usage
information or possible options that are available to the user. Every time
I’m using a terminal program that lets me type commands but never hints
at what parameters they take, I sorely wished more people would steal that
from Kakoune!</p>

<p>Another command prompt related improvement that the editor proposes is
fuzzy matching: the user doesn’t need to type out letters that make up
the name of the command they need in order, which makes for much faster
completion selection, and increased discoverability.</p>

<p>All command names in Kakoune are WORDS that start with the name of the
functionality group they belong to. The examples below follow:</p>

<ul>
  <li>to figure out what commands interact with the buffer, typing <code>:buff</code>
would return candidates like <code>buffer-next</code>, <code>lint-buffer</code>,
<code>format-buffer</code>…</li>
  <li>to call the <code>lint-buffer</code> command, typing <code>:lb&lt;tab&gt;</code> would insert the
entire command name in the prompt</li>
</ul>

<p>Use Kakoune once, and you’ll wish your browser enabled fuzzy
matching in your history/bookmarks for the rest of your days. But
you might wonder: there are individual tools that handles
fuzzy-matching, like <a href="https://github.com/junegunn/fzf">fzf</a>,
<a href="https://github.com/kien/ctrlp.vim">ctrlp</a> or
<a href="https://github.com/jhawthorn/fzy">fzy</a>, what if the user would rather
use them to handle opening, for example, files? Great question! Read on,
that’s the next dimension I want you to steal from.</p>

<h2 id="from-its-philosophy">From its philosophy</h2>

<p>The UNIX philosophy states that tools should focus on doing one thing,
and do it well. The implications are that tools that implement too many
unrelated features end up providing users with an underwhelming experience
because they only allow so much granularity over their behaviour, and that
their maintainers are spread too thin to improve/fix them.</p>

<p>If we re-frame this into the context of text editing, editors should only
worry about exactly that — text editing. And Kakoune does its job as
a UNIX citizen brilliantly, but it also goes one step further: it allows
other tools to interact with it, via shell scripting.</p>

<p>Remember the case of spawning a third-party fuzzy matching program,
above? Without getting into details, in Kakoune you’d implement that by
spawning a new terminal (or pane/tab), which would run the program, and
its output would be interpreted by the editor. Users are free to run any
program they want, any terminal or multiplexer they prefer.</p>

<p>And the concept isn’t bound to terminal programs either, although they are
probably the type of tools that Kakoune users would intuitively want to
interact with, on account of the editor being one itself. For example, do
you want to edit a file using a graphical interface? Try the following:</p>

<div><div><pre><code>:edit %sh{zenity --file-selection}
</code></pre></div></div>

<p>If that doesn’t sound anything special, it means that it makes
sense. Unfortunately, the field of text editors on UNIX systems has over
the years turned into an archipelago, in which every editor aims at being an
island. Job management, shell, terminal emulation,&nbsp;window multiplexing…
Text editors have turned into closed ecosystems (or Integrated Development
Environments) that provide many (sometimes cardboard-looking) features
unrelated to editing, which new comers have to buy into, or be left out in
the cold.</p>

<p>So here’s an idea everybody should not feel guilty about stealing, if
applicable to their projects: don’t re-invent the wheel, we have enough
bad imitations already<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> — instead, work on ways to make your tools
interface with others more easily!</p>

<p>If you have comments or questions, feel free to drop by the official IRC
channel: #kakoune @ FreeNode.</p>




<p>
    — written by

    

    <a href="https://github.com/lenormf">

    

        Frank Lenormand
    </a>

    · <time datetime="2020-10-01T00:00:00+00:00">
        <i>1st October 2020</i>
    </time>

    · license <strong>CC BY-SA 4.0</strong>
</p>


      
    </div></div>]]>
            </description>
            <link>https://kakoune-editor.github.io/community-articles/2020/10/01/what_steal_get_away_kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24685267</guid>
            <pubDate>Mon, 05 Oct 2020 07:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Principles of Data Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24684638">thread link</a>) | @viebel
<br/>
October 4, 2020 | https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show | <a href="https://web.archive.org/web/*/https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  <div itemprop="articleBody">
    <div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
<p>This chapter is an attempt to illustrate what are the core principles of Data Oriented Programming as I understand them.
It is highly influenced by my programming experience in Clojure, but I believe that those principles are language agnostic.</p>
<p>One could adhere to them in an Object Oriented (OO) language like Java or C# and one could break them
in a Functional Programming (FP) language like Ocaml, Haskell, JavaScript (or even in Clojure).</p>
<p>In fact, in this chapter, I am going to illustrate how those principles could be applied or broken
in JavaScript, a programming language that supports both FP and OOP.</p>
<p>The principles of Data Oriented (DO) Programming are:</p>

<p>Each principle is explored in a separate article.</p>

<p>Enjoy!</p>
<div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
  </div>

</article><p>
  If you enjoy this kind of interactive articles would you consider a (small) donation💸  on <a href="https://www.patreon.com/bePatron?u=18227864">Patreon</a> or at least giving a star⭐ for the Klispe repo on <a href="https://github.com/viebel/klipse/stargazers"> Github</a>?
</p></div>]]>
            </description>
            <link>https://blog.klipse.tech/databook/2020/09/29/do-principles.html?show</link>
            <guid isPermaLink="false">hacker-news-small-sites-24684638</guid>
            <pubDate>Mon, 05 Oct 2020 04:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It’s 255:19AM. Do you know what your validation criteria are?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24683995">thread link</a>) | @SAPikachu
<br/>
October 4, 2020 | https://hdevalence.ca/blog/2020-10-04-its-25519am | <a href="https://web.archive.org/web/*/https://hdevalence.ca/blog/2020-10-04-its-25519am">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
  
  <p>A basic property of a <a href="https://en.wikipedia.org/wiki/Digital_signature">digital signature scheme</a> is that it should specify which signatures are valid and which signatures are invalid, so that all implementations can accept only valid signatures and reject only invalid signatures. <em>Unfortunately, Ed25519 signatures don’t provide this property, making their use in distributed systems fragile and risky.</em></p>
<p>Although the scheme was standardized in <a href="https://tools.ietf.org/html/rfc8032">RFC8032</a>, the RFC does not specify validation criteria, and does not require conformant implementations to agree on whether a particular signature is valid. In addition, because the specification changed validation criteria years after deployment, it is incompatible with almost all existing implementations. Worse still, some implementations added extra ad-hoc criteria, making them further incompatible.</p>
<p>The result is an extremely wide variation in validation criteria across implemententations. The diagram below plots verification results of a \(14 \times 14\) grid of edge cases, with light squares representing accepted signatures, and dark squares representing rejected ones. As the diagram illustrates, verification results are generally inconsistent not just between implementations, but also between different versions and different modes. <img src="https://hdevalence.ca/images/ed25519-comparison.png"></p>
<p>Some protocols may tolerate this variation, but it is unacceptable for any protocol that requires participants to reach consensus on signature validity. A malicious participant can submit signatures that are accepted by some implementations but rejected by others, causing a network partitition or a consensus fork. Having only a single implementation makes this problem less obvious, but it doesn’t go away, since behavior can vary across versions of the ‘same’ implementation. This occurred in practice with the widely used <code>libsodium</code> library, which made breaking changes to validation criteria in a point release.</p>
<p>Finally, although all of these problems occur when verifying signatures individually, they also prevent the use of batch verification, which can provide a significant performance benefit.</p>
<p>This post describes:</p>
<ol type="1">
<li><p>The structure of Ed25519 signatures and the scope of potential divergence in validation criteria <a href="#points-of-potential-divergence">(jump)</a>;</p></li>
<li><p>The results of a survey of Ed25519 validation behavior <a href="#a-survey-of-implementation-behaviors">(jump)</a>, which revealed:</p>
<ul>
<li><p>that almost no implementations conform to RFC8032;</p></li>
<li><p>that there is a wide variation in behavior not just between implementations, but also across different versions of the same implementation;</p></li>
<li><p>a platform-specific bug in Go’s <code>crypto/ed25519</code> that gave different validation results on the IBM z/Architecture;</p></li>
<li><p>a crash denial-of-service bug in Tor triggered by validating attacker-controlled signatures (though this bug was coincidentally not exploitable because of the way the function is currently used).</p></li>
</ul></li>
<li><p>The ZIP215 rules <a href="#fixing-the-problem">(jump)</a>, a set of precisely defined validation criteria for consensus-critical Ed25519 signatures which resolve this problem. These rules are implemented in <a href="https://docs.rs/ed25519-zebra"><code>ed25519-zebra</code></a> in Rust and and <a href="https://github.com/hdevalence/ed25519consensus"><code>ed25519consensus</code></a> in Go, are backwards-compatible with existing signatures, and will be deployed in Zcash as part of the <em>Canopy</em> network upgrade.</p></li>
</ol>
<h2 id="the-scope-of-potential-divergence">The scope of potential divergence</h2>
<h3 id="the-ed25519-signing-process">The Ed25519 signing process</h3>
<p>Before explaining the validation criteria, it’s useful to briefly review the signing process. An honest signer generates their signing key, a random scalar \(a\), through a complicated procedure not relevant here. Then, they multiply their signing key by the Curve25519 basepoint \(B\) to obtain their verification key, a curve point \(A = [a]B\). The <em>signing</em> and <em>verification</em> keys are more commonly referred to as the <em>private</em> and <em>public</em> keys, but (following Daira Hopwood), I prefer to use the capability-based terminology, since it more precisely captures the role of the key material.</p>
<p>To sign a message <code>M</code>, a signer first generates a secret random nonce \(r\), through a procedure that is also not relevant here, and then form a public commitment to this randomness by computing \(R = [r]B\). Next, they use a hash function \(H\) to compute a challenge scalar as \( k \gets H(R, A, M) \). Finally, they compute a response scalar as \( s \gets r + ka \).</p>
<h3 id="divergence-in-ed25519-signature-validation-criteria">Divergence in Ed25519 signature validation criteria</h3>
<p>To understand the scope of potential divergence in validation criteria, let’s walk through the steps to verify a signature <code>sig</code> with verification key \(A\) on the message <code>M</code>, noting each step with a possibly divergent behavior choice. Then, in subsequent sections, we’ll look at the scope and implications of each divergence.</p>
<p>Ed25519 signatures are 64 bytes long, structured as two 32-byte components: <code>sig = R_bytes || s_bytes</code>. The first 32 bytes store an encoding of \(R\), and the second 32 bytes store an encoding of \(s\). Ed25519 verification keys are 32 bytes long, storing an encoding of \(A\).</p>
<p>Next, the verifier parses <code>s_bytes</code> as \(s\). It’s always possible to interpret a byte string as a little-endian encoded integer, so parsing \(s\) can’t fail. However, \(s\) is supposed to represent an integer \(\mod q\), where \(q\) is the order of the prime-order subgroup of Curve25519. Honestly-generated signatures will have \(0 \leq s &lt; q\), and implementations can choose to reject \(s \ge q\). Call this check <em>canonical \(s\)</em>.</p>
<p>Next, the verifier attempts to parse <code>A_bytes</code> as \(A\). Not all byte strings are valid point encodings, so parsing \(A\) can fail, causing the signature to be rejected. Points can be encoded non-canonically, although in contrast to the encoding of \(s\), the mechanism is somewhat more complicated and subtle, as will be described <a href="#canonical-a-r">below</a>. Implementations can choose to reject non-canonically encoded curve points. Call this check <em>canonical \(A\)</em>.</p>
<p>The verifier then uses <code>A_bytes</code>, <code>R_bytes</code>, and the message <code>M</code> to recompute the challenge value \(k \gets H(R, A, M)\). (Note that since \(H\) is a hash function, it actually operates on the encodings <code>A_bytes</code> and <code>R_bytes</code>, not their decoded internal representations).</p>
<p>Implementations then make a <em>choice of verification equation</em>, choosing which of two verification equations to check. They can use either the <em>batched equation</em> \[ [8]R = [8]([s]B - [k]A), \] or the <em>unbatched equation</em> \[ R = [s]B - [k]A. \] The naming of <em>batched equation</em> versus <em>unbatched equation</em> suggests that the difference is related to batched versus individual verification, but in fact these give different behavior even in the case of individual verification, as will be explained <a href="#choice-of-verification-equation">below</a>.</p>
<p>Finally, to actually check whichever equation is used, an implementation must choose an <em>equality check</em>. Recall that we didn’t actually decode <code>R_bytes</code> to \(R\) yet. When using the batched equation, an implementation must operate on \(R\), so it must decode <code>R_bytes</code> to \(R\), and check equality of curve points. This also means it must make a choice of whether to require <em>canonical \(R\)</em>.</p>
<p>When using the unbatched equation, however, an implementation can choose to either check equality of curve points, or to compute \(R’ \gets [s]B - [k]A\), encode \(R’\) to <code>Rprime_bytes</code>, and check equality of byte strings. When \(R\) is canonically encoded, these equality checks produce the same result. But because the encoding procedure produces canonical encodings, if <code>R_bytes</code> contains a non-canonical encoding of \(R\), then even if \(R’ = R\) (as curve points), <code>Rprime_bytes</code> may differ from <code>R_bytes</code> (as byte strings).</p>
<h3 id="points-of-potential-divergence">Points of potential divergence</h3>
<p>In summary, there are a number of points of potential divergence between implementations:</p>
<ol type="1">
<li>Whether to require <em>canonical \(s\)</em> or to allow non-canonical encodings.</li>
<li>Whether to require <em>canonical \(A\)</em> or to allow non-canonical encodings.</li>
<li>The <em>choice of verification equation</em>, either <em>batched</em> or <em>unbatched</em>.</li>
<li>The <em>choice of equality check</em>, and the related choice of <em>canonical \(R\)</em>.</li>
<li>Any other <em>ad-hoc checks</em> added by a particular implementation.</li>
</ol>
<p>Before comparing the choices made by RFC8032 and actually existing implementations, let’s examine the exact mechanism and implications of each of these points of potential divergence.</p>
<h3 id="canonical-s">Canonical \(s\)</h3>
<p>The values <code>A_bytes</code>, <code>R_bytes</code>, and <code>M</code> are all fed into the hash function, so they cannot be modified without changing the challenge value. However, a third party could replace \(s\) with \(s’ = s + nq\). Because \(s’ \equiv s \pmod q\), the modified signature \((R, s’)\) would still pass verification. Requiring that <code>s_bytes</code> encodes \(s &lt; q\) prevents this.</p>
<p>This check is simple, low-cost, prevents malleability, is required by RFC8032, and is performed by most implementations. The only notable exception is the original reference implementation of Ed25519, which chose to write a paragraph arguing that signature malleability is never a problem instead of performing the check.</p>
<p>Because this check is fairly common, well-known, and unobjectionable, I didn’t focus on it, and didn’t comprehensively test implementation behavior.</p>
<h3 id="canonical-a-r">Canonical \(A\), \(R\)</h3>
<p>While the mechanism for constructing non-canonically encoded scalar values is fairly simple, the mechanism for constructing non-canonically encoded point values is somewhat more complicated, as mentioned <a href="#divergence-in-ed25519-signature-validation-criteria">above</a>. To explain it, we need to describe the “compressed Edwards \(y\)” encoding used by Ed25519.</p>
<p>Curve25519 is defined over the finite field of order \(p = 2^{255} - 19\), so the coördinates of curve points \((x,y)\) are integers \(\mod p\). The curve equation in (twisted) Edwards form is \[ - x^2 + y^2 = 1 + d x^2 y^2, \] where \(d\) is a curve parameter. This means that \[ x^2 = \frac { y^2 - 1} {d y^2 + 1}. \] If the fraction on the right-hand side is nonsquare, then there is no \(x\) so that the right-hand side equals \(x^2\), and the \(y\) value is not the \(y\)-coördinate of a curve point. If it is square, then there is a square root \(x\), and the value of \(y\) is sufficient to recover \(x\) up to a choice of sign.</p>
<p>Because \(p &lt; 2^{255}\), the encodings of field elements fit in 255 bits. The compressed Edwards \(y\) format uses the first 255 bits to store the \(y\) coördinate, and the 256th bit to indicate the sign of the \(x\) …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hdevalence.ca/blog/2020-10-04-its-25519am">https://hdevalence.ca/blog/2020-10-04-its-25519am</a></em></p>]]>
            </description>
            <link>https://hdevalence.ca/blog/2020-10-04-its-25519am</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683995</guid>
            <pubDate>Mon, 05 Oct 2020 02:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benchmarking static website hosting providers]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24683403">thread link</a>) | @rencire
<br/>
October 4, 2020 | https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/ | <a href="https://web.archive.org/web/*/https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Static websites are still a hot topic. They are fast, and they’re incredibly secure because there isn’t a CMS to hack. Once you build a static website, however, the question becomes: Where do I host?</p>

<p>In other words: what is the fastest static website hosting provider in 2020? Well, let’s find out!</p>

<!--more-->

<p>I did <a href="https://www.savjee.be/2017/10/Static-website-hosting-who-is-fastest/">a similar test in 2017</a>, so it will be curious to see if the hosting providers have been improving.</p>

<h2 id="test-setup">Test setup</h2>
<p>Just like in 2017, I created a simple webpage that I could host on many services. I opted to use my own homepage, including all the images, CSS, and JS files. I then uploaded these files to the following hosting providers:</p>

<ul>
  <li>
<strong>Pay-as-you-go</strong>
    <ul>
      <li>
<a href="https://aws.amazon.com/s3/" target="_blank" data-no-instant="data-no-instant">AWS S3</a> (Region: <code>eu-west-1</code>, Ireland)</li>
      <li><a href="https://aws.amazon.com/cloudfront/" target="_blank" data-no-instant="data-no-instant">AWS CloudFront</a></li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (regional bucket, <code>europe-west1</code>, Belgium)</li>
      <li>
<a href="https://cloud.google.com/storage" target="_blank" data-no-instant="data-no-instant">Google Cloud Storage</a> (multi-region bucket)</li>
      <li>
<a href="https://workers.cloudflare.com/sites" target="_blank" data-no-instant="data-no-instant">Cloudflare Workers Sites</a> ($5/month)</li>
    </ul>
  </li>
  <li>
<strong>Freemium (some parts free)</strong>
    <ul>
      <li><a href="https://firebase.google.com/docs/hosting" target="_blank" data-no-instant="data-no-instant">Firebase Hosting</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Cloudflare CDN</a></li>
      <li><a href="https://www.cloudflare.com/cdn/" target="_blank" data-no-instant="data-no-instant">Netlify</a></li>
    </ul>
  </li>
  <li>
<strong>Free</strong>
    <ul>
      <li><a href="https://pages.github.com/" target="_blank" data-no-instant="data-no-instant">GitHub Pages</a></li>
    </ul>
  </li>
</ul>

<p><em>Quick note</em>: I did not test Microsoft Azure, because I couldn’t sign up for it with my <a href="https://revolut.com/referral/xavierh5x" target="_blank" data-no-instant="data-no-instant">Revolut Visa card</a>. Thanks, Microsoft!</p>

<p>To check the performance, I used Pingdom and <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>. Pingdom measures uptime and response times from <a href="https://my.pingdom.com/probes/feed" target="_blank" data-no-instant="data-no-instant">their worldwide network of probe servers</a> while Oh Dear is located in a single location.</p>

<p>Some other things to keep in mind:</p>

<ul>
  <li>I tested the HTTPS endpoints for all services</li>
  <li>I added <code>index.html</code> to all URL’s, meaning no time wasted resolving the index document</li>
  <li>The services were probed <strong>once every minute</strong> for <strong>10 days</strong>
</li>
  <li>Oh Dear did not only track response times, but also DNS lookup time,  TCP connection time, content download time, and more. Pretty cool! All of the raw data is available at the end of this post.</li>
</ul>

<p><strong>Note:</strong> Pingdom or Oh Dear did NOT sponsor this blog post in any way! <a href="https://ohdear.app/" target="_blank" data-no-instant="data-no-instant">Oh Dear</a>, however, gave me a free trial with enough slots for all the test sites. Thanks a lot!</p>

<h2 id="expectations">Expectations</h2>
<p>My expectations are pretty much aligned to when I did this last time around:</p>

<ul>
  <li>I expect paid services to do better than free servers. There must be a reason for the prices they charge, right?</li>
  <li>Firebase and Google Cloud belong to the same company, so I expect them to perform similarly.</li>
  <li>I use CloudFront for my website, so hopefully they don’t come out as a bad option. Otherwise, there’s some additional homework for me ;)</li>
  <li>Netlify performed quite inconsistently last time around. With a few years passing, I hope they were able to address those issues.</li>
  <li>Last time, I didn’t have Cloudflare in the benchmark. I expect them to be a strong contender, given how popular they are and how many edge locations they have.</li>
</ul>

<h2 id="results">Results</h2>
<p>Here’s a screenshot from the Pingdom dashboard after 10 days of testing:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-overview.png" alt="Overview of the Pingdom dashboard">
<em>Overview of the Pingdom dashboard</em></p>

<p>At first glance, it seems that all services perform very consistently, with CloudFront, GitHub Pages, and Google Cloud, leading the pack. But let’s not jump to conclusions.</p>

<h3 id="uptime">Uptime</h3>
<p>Let’s start with uptime. All of these services had 100% uptime, except for Firebase. Pingdom detected 1 minute of downtime. One check returned, “Network is unreachable,” and the other returned “Invalid certificate.”</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/pingdom-error-log.png" alt="Firebase downtime as reported by Pingdom">
<em>Firebase downtime as reported by Pingdom</em></p>

<p>This was not detected by Oh Dear, so I’m willing to give Firebase the benefit of the doubt and say that this was an issue on Pingdom’s side.</p>

<h3 id="response-times">Response times</h3>
<p>Let’s start with some basic statistics: the median, and average response time of each service (including standard deviation):</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times.png" alt="Median response times, measured by Pingdom">
<em>Median response times as reported by Pingdom</em></p>

<p>A few things might catch your attention:</p>

<ul>
  <li>CloudFront &amp; GitHub Pages are speedy and consistent. They have the lowest median, average, and deviation. Interesting because one is a paid service, while the other is completely free.</li>
  <li>AWS S3 is the slowest of them all (but performs consistently). It is kind of expected from a hosting provider that is located only in a single region (in this case Ireland, <code>eu-west-1</code>)</li>
  <li>Google Cloud’s regional and multi-regional buckets perform fairly alike. Interestingly, both are much faster than S3, which is a comparable service. Is Google doing some caching behind the scenes?</li>
  <li>I expected Cloudflare to be much more competitive with the top rankings, but somehow both their CDN and Workers aren’t the top performers. Their Workers product does, however, perform slightly better than their CDN.</li>
</ul>

<p>Since I used both Pingdom and Oh Dear, let’s check the difference in median response times:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-pingdom-oh-dear.png" alt="Pingdom vs Oh Dear (median response times)">
<em>Pingdom vs Oh Dear (median response times)</em></p>

<p>Interestingly, Oh Dear is reporting much faster response times compared to Pingdom. This is probably related to the fact that they only test from a single (apparently very well connected) location.</p>

<p>Pingdom is testing from various locations around the world, some of which aren’t as well connected, which increases the response times.</p>

<p>Some additional findings:</p>

<ul>
  <li>Somehow, AWS S3 is the fastest performer, even though the content is only hosted in a single location. It also outperformed Amazon’s CDN! Wherever Oh Dear is hosted, it must be somewhere in the EU with good connections to the Ireland region of AWS.</li>
  <li>The difference between CloudFront, S3, Firebase, GitHub Pages, and Google Cloud Storage is minimal. Once more, showing that free and paid services compete quite closely with one another.</li>
</ul>

<h3 id="time-to-first-byte">Time to first byte</h3>
<p>Oh Dear also kept track of other metrics like how long it took for the first bytes to start being transferred. This can give us an indication of how responsive the webserver is (how long does it need to think before being able to fulfill a request).</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-time-to-first-byte.png" alt="Time to first byte: measures responsiveness of web servers">
<em>Time to first byte: measures responsiveness of web servers</em></p>

<ul>
  <li>The “simple” storage services like S3 and Google Cloud Storage are doing very well.</li>
  <li>Once again, GitHub Pages, Firebase, and CloudFront are great performers, delivering the first byte in under 40ms.</li>
  <li>Surprisingly, Cloudflare is taking quite a while to start delivering the first bytes. Maybe this is due to all of their protection services?</li>
</ul>

<h3 id="compared-to-2017">Compared to 2017</h3>
<p>Comparing this new data with the one from 2017 reveals that not much has changed. Note that here I’m comparing the data from Pingdom:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-response-times-2017-vs-2020.png" alt="Benchmark from 2017 vs 2020: median response times">
<em>Benchmark from 2017 vs 2020: median response times</em></p>

<p>All providers (except GitHub Pages) have become slightly slower. Most noticeably AWS S3 (+13%) and Firebase (+31%). The others are so close to their 2017 performance that I would consider these differences to be in the margin of error.</p>

<p>Netlify has a slower median response time in 2020 compared to 2017. But it did improve massively on its consistency. Last time around, they had weird spikes in performance but not anymore. Nice!</p>

<p>This could be explained by Pingdom having added additional test servers located in areas that are further away from these providers.</p>

<h3 id="trying-to-find-edge-cases">Trying to find edge cases</h3>
<p>A scatter plot reveals that there aren’t many outliers, and no service is suffering from regular spikes in performance. There are some outliers here and there, but I wouldn’t look into them too much:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-scatter-response-times.png" alt="Scatter plot of all response times">
<em>Scatter plot of all response times</em></p>

<p>If we visualize the response times with a box plot, we see something interesting:</p>

<p><img src="https://www.savjee.be/uploads/2020-05-28-benchmaring-static-website-hosting-providers/chart-boxplot-response-times.png" alt="Box plot of response times, showing some high spikes">
<em>Box plot of response times, showing some high spikes</em></p>

<p>All services, except for AWS, GitHub Pages, and Firebase, have weird spikes. Last time around, this was only limited to Netlify. Not sure what to make of these, but I’m guessing it’s more related to Pingdom’s tests than to the services themselves.</p>

<h2 id="conclusions">Conclusions</h2>
<p>Time to draw some conclusions:</p>

<p>The best all-around performer is <strong>AWS CloudFront</strong>, followed closely by <strong>GitHub Pages</strong>. Not only do they have the fastest response times (median), they’re also the most consistent.</p>

<p>They are, however, closely followed by Google Cloud Storage. Interestingly, there is very little difference between a regional and multi-regional bucket. The only reason to pick a multi-regional bucket would be the additional uptime guarantee.</p>

<p><strong>Cloudflare</strong> didn’t perform as well I would’ve expected. It’s certainly faster than a standard S3 bucket but falls away when compared to other CDN’s like CloudFront. Their Workers product is slightly faster than their CDN, but it’s hard to recommend it when it costs $5 a month, and free products like GitHub Pages perform better.</p>

<p>Netlify has improved big time; the spikes in performance are gone and performs in line with Google Cloud and Firebase hosting.</p>

<h2 id="which-should-you-choose">Which should you choose?</h2>
<p>If you want a fast website without breaking the bank, go for GitHub Pages. It’s completely free and super fast. It does, however, require you to open source your site.</p>

<p>If that’s not doable, CloudFront is a good alternative, but its price depends on how much bandwidth you push around. For most personal sites, CloudFront won’t cost more than a couple of dollars per month. The same thing goes for Google Cloud Storage.</p>

<p>Netlify and Firebase Hosting are pretty solid choices as well. While they don’t perform as well as CloudFront or GitHub Pages, they make up for it with excellent development tools. Everything works out-of-the-box with no configuration required on your end. Just push your website live with their easy to use CLI tools.</p>

<h2 id="download-the-data">Download the data</h2>
<p>The raw CSV data <a href="https://github.com/Savjee/static-website-hosting-benchmark" target="_blank" data-no-instant="data-no-instant">is available on GitHub</a>. Both of 2017 and 2020. Feel free to do your analysis and let me know if you find other interesting things in the dataset. Definitely check out the detailed statistics from Oh Dear!</p>

    </div></div>]]>
            </description>
            <link>https://www.savjee.be/2020/05/benchmarking-static-website-hosting-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683403</guid>
            <pubDate>Mon, 05 Oct 2020 00:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whitworth 3 plates method: How to make flat surfaces from scratch]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24683158">thread link</a>) | @ethanwillis
<br/>
October 4, 2020 | https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method | <a href="https://web.archive.org/web/*/https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper" role="main">
        <!-- CATEGORY NAV -->
        
      <section id="page">

      <div data-content-field="main-content">
        <article id="article-597e8ac1bf629a06939204a8" data-item-id="597e8ac1bf629a06939204a8">

  <!--SPECIAL CONTENT-->

  
     
  

  
  <!--POST HEADER-->
    
  <header>
    
    
  </header>
  
  
  <!--POST BODY-->

  <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1501467179009" id="item-597e8ac1bf629a06939204a8"><div><div><div data-block-type="2" id="block-fbbf397e596a02c81f90"><div><p>A key contribution to precision machine tools was the understanding of the importance of flatness, and the development of processes that are used to make surfaces very flat.&nbsp;Henry Maudslay invented the first machine that could cut standard screw threads and contributed to the invention of the now-common surface plate, which serves an important role in metrology today. A classic book called Foundations of Mechanical Accuracy described this and other concepts in detail. It’s available as a PDF <a href="http://frank.villaro-dixon.eu/public_upload/Foundations%20of%20Mechanical%20Accuracy%20by%20Wayne%20R%20Moore%20-%201970.pdf">here</a> and in print <a href="https://www.amazon.com/gp/product/B0006CAKT8/ref=as_li_tl?camp=1789&amp;creative=9325&amp;creativeASIN=B0006CAKT8&amp;ie=UTF8&amp;linkCode=as2&amp;linkId=9a3b69c12fefcdb4c52fac9cb6d7d37d&amp;tag=eweinhoffer-20">here</a>.</p><p>Typically made of granite, surface plates act as a datum, or the basis upon which precise measurements and movements can be made. They can be finished to a variety of grades of flatness, based on their intended use, and can even be used to <a href="https://youtu.be/sFrVdoOhu1Q?t=378" target="_blank">build up precise structures</a>&nbsp;(that whole video is a must-watch, btw). When dealing with such flat surfaces, tiny imperfections or gradual wear can have drastic effects: using a gauge over the same spot on a surface plate, or leaving it in a space where the temperature varies by more than a few degrees, can negatively affect their flatness. Due to this, calibrating and conditioning your plate is important. The process is really neat, partially because it requires an autocollimator and an incredibly precise repeat-o-meter. Watch a great video from Tom Lipton about the process <a href="https://www.youtube.com/watch?v=EWqThb9Z1jk">here</a>.</p><p>The neat thing about surface plates is that they do not require precision tools to create. By using the “three plate method”, developed by Joseph Whitworth, flat surfaces can be created by using gravity and a simple hand-scraping tool, or by lapping the plates against each other. By starting with three plates of relative flatness, rubbing the plates against each other in alternating pairs to remove the high spots can yield fantastic results.&nbsp;</p><p>The process can be completed in six steps, and then repeated until the desired level of flatness is achieved. In this visual explanation, the surface finishes of the three plates are exaggerated. Before beginning this process, the three plates (Red, Green and Blue) should be machined or ground to as flat a surface as possible, to remove all unnecessary lapping work. In addition, a fine abrasive compound is often used between plates to assist in material removal. Tom also has <a href="https://youtu.be/rHmsQEAx16o" target="_blank">a great video series</a> about this, which includes some compound and technique recommendations.</p><h3><strong>STEP 1</strong></h3><p>To begin, the Red and Green plates are lapped against each other in an alternating manner. That is, one plate remains stationary while the other is lapped against it, and then the opposite is performed:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_27886"><div><p>At the completion of this step, the Red and Green plates “agree with” each other, but that is all.</p><h3><strong>STEP 2</strong></h3><p>Next, the Red plate acts as the control (it remains stationary) while the Blue plate is lapped against it:</p></div></div><div data-aspect-ratio="61" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_70590"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466847775-58UA12B6IE1GFQINDMGP/ke17ZwdGBToddI8pDm48kKjydk0csocbYJxIVcMQ1bZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzqU3cEBtqRRwYjAYGyosNgQsOKq0UmUo64vi4mlvYfjdsZzedh78aVv83vtx0Hbu8/Step2.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466847775-58UA12B6IE1GFQINDMGP/ke17ZwdGBToddI8pDm48kKjydk0csocbYJxIVcMQ1bZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzqU3cEBtqRRwYjAYGyosNgQsOKq0UmUo64vi4mlvYfjdsZzedh78aVv83vtx0Hbu8/Step2.PNG" data-image-dimensions="641x461" data-image-focal-point="0.5,0.5" alt="Step2.PNG" data-load="false" data-image-id="597e90dfe6f2e130978984d8" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_70867"><div><p>At the end of this step, both the Green and Blue plates have picked up the error from the Red plate. They do not agree with each other, however.</p><h3><strong>STEP 3</strong></h3><p>Next, the Green and Blue plates are lapped against each other in an alternating manner:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_77200"><p>Since both of these plates picked up the error of the Red plate from the first two steps, lapping them together removes some of the error from the Red plate, bringing them closer to flat. At this point, the Green and Blue plates are more flat than the Red plate:</p></div><div data-aspect-ratio="33.111111111111114" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_88664"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png" data-image-dimensions="669x316" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="597e913f1e5b6c655dc59803" data-type="image" src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501466943104-U6107Q1CDQLYSNUVL7NI/ke17ZwdGBToddI8pDm48kGe8TXgcQVDUmo5vQmbEDsBZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzA9naiwluJQ_kK0sg_II7w35zaPBpmJCrN4Kwo-6BMNT3WRFB5Tugrf3qegyz1T9U/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_92197"><div><h3><strong>STEP 4</strong></h3><p>Next, the Green plate acts as the control and the Red plate is lapped against it:</p></div></div><div data-aspect-ratio="46.33333333333333" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_94647"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png" data-image-dimensions="659x381" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="597e91bd893fc0db647a42a7" data-type="image" src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501467070027-3LL80AR2TC5II8BUVVKD/ke17ZwdGBToddI8pDm48kGk_3Ncv1fH5DdGK18dF0qVZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxtfymh001AcOarnr2uGi1kW-U-N61NdqukMDCso82xr52Tam0GtZjT7vwr_FwkpBA/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_94925"><p>At the completion of this step, all three plates are of roughly equal flatness, but one (Green) is convex and the other two are concave:</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_121764"><div><h3><strong>STEP 5</strong></h3><p>Next, move back to an alternating pattern and lap the two concave plates against each other:</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_152855"><p>This results in two fairly flat plates. At this point, only the Green plates needs to be brought to the same level of flatness as the other two.</p></div><div data-aspect-ratio="31.88888888888889" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_165836"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475603295-OFW3C82RD552KQ49A7RV/ke17ZwdGBToddI8pDm48kNWCFiWWhfaNS5VLrcZyQutZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyy9Fy2RaNboFpBomQTPg1txkql11BZnuEVTVDPZ9u31D5I1QL-tcg8zvJ8M0lhae8/Step5_result.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475603295-OFW3C82RD552KQ49A7RV/ke17ZwdGBToddI8pDm48kNWCFiWWhfaNS5VLrcZyQutZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpyy9Fy2RaNboFpBomQTPg1txkql11BZnuEVTVDPZ9u31D5I1QL-tcg8zvJ8M0lhae8/Step5_result.PNG" data-image-dimensions="658x331" data-image-focal-point="0.5,0.5" alt="Step5_result.PNG" data-load="false" data-image-id="597eb313be6594cef6b0bcbd" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_166114"><div><h3><strong>STEP 6</strong></h3><p>Finally, the single convex plate is lapped against the Blue control plate:</p></div></div><div data-aspect-ratio="38.88888888888889" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_192139"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475861656-22C2B4NEM6ZAZQ0P4K4F/ke17ZwdGBToddI8pDm48kI9eWsscw_kS1_uRgVsEHexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwGSioTyTafrclwm5SZpGyT2rpSgTdNg3Xh5CnqFcW2oD55xYIdUfkjC4EKb91nUpg/Step6.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475861656-22C2B4NEM6ZAZQ0P4K4F/ke17ZwdGBToddI8pDm48kI9eWsscw_kS1_uRgVsEHexZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpwGSioTyTafrclwm5SZpGyT2rpSgTdNg3Xh5CnqFcW2oD55xYIdUfkjC4EKb91nUpg/Step6.PNG" data-image-dimensions="670x342" data-image-focal-point="0.5,0.5" alt="Step6.PNG" data-load="false" data-image-id="597eb4151b631b24fd8c15c9" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_192416"><p>And the result is three plates that are in agreement with each other!</p></div><div data-aspect-ratio="46.666666666666664" data-block-type="5" id="block-yui_3_17_2_1_1501464915476_200838"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475898272-437GDLHUTW5BMSQZQDCN/ke17ZwdGBToddI8pDm48kNvUiQrA4HGuW7moH_5i-xpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzrkbryVTHu8zEnqOVmzRanTXYKAn9EoQRz2Y-iL-5Xp9ba_nGnlK6x3VCG914hy60/Step6_result.PNG" data-image="https://images.squarespace-cdn.com/content/v1/543c7393e4b00144c882951a/1501475898272-437GDLHUTW5BMSQZQDCN/ke17ZwdGBToddI8pDm48kNvUiQrA4HGuW7moH_5i-xpZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpzrkbryVTHu8zEnqOVmzRanTXYKAn9EoQRz2Y-iL-5Xp9ba_nGnlK6x3VCG914hy60/Step6_result.PNG" data-image-dimensions="667x386" data-image-focal-point="0.5,0.5" alt="Step6_result.PNG" data-load="false" data-image-id="597eb43ae58c621d0696f9cf" data-type="image">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1501464915476_201115"><div><p>It’s also worth noting that, although this yields great precision “from nothing”, Joseph Whitworth later improved upon the technique by utilizing engineer’s blue and hand scraping, as mentioned previously. Engineer’s blue alone would be an instrumental improvement over using no indicator - with the blue, it’s easy to see which areas have, and haven’t been, scraped.</p><p>Let me know if you’ve tried this yourself or have any comments about how I can improve the instruction. Most of what I know about the original Three Plates Method came from <a href="https://etshare.pbworks.com/f/Chapter%2014%20Reference%20Planes.pdf" target="_blank">this PDF</a>.</p></div></div><div data-block-type="44" id="block-yui_3_17_2_1_1571515799694_114027"><p><span data-preserve-html-node="true" size="2"><span data-preserve-html-node="true"><span data-preserve-html-node="true" color="#d6d6d6">Note: ericweinhoffer.com is a participant in the Amazon Services LLC Associates Program, an affiliate advertising program designed to provide a means for sites to earn advertising fees by advertising and linking to amazon.com.</span></span></span></p></div></div></div></div></div>
      
  <!--POST FOOTER-->
    
  
  

</article>




<!--PAGINATION-->
  

  




<!-- COMMENTS -->


      </div>

      
        
      

      </section>
      </div></div>]]>
            </description>
            <link>https://ericweinhoffer.com/blog/2017/7/30/the-whitworth-three-plates-method</link>
            <guid isPermaLink="false">hacker-news-small-sites-24683158</guid>
            <pubDate>Sun, 04 Oct 2020 23:43:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting Lemire's nearly divisionless random number generator]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24682483">thread link</a>) | @fanf2
<br/>
October 4, 2020 | https://veryseriousblog.com/posts/dissecting-lemire | <a href="https://web.archive.org/web/*/https://veryseriousblog.com/posts/dissecting-lemire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-74174200445ef6e30546"><div><p>This blog post is very late. It’s well over a year since<a href="https://twitter.com/colmmacc/status/1153727018896244736"> I posted a coding challenge on twitter</a>. The idea was simple, I’ve always felt that code readability is undervalued so I figured I’d put cold hard cash up. I announced a $1,000 pot, divided into $500, $300, and $200 prizes for the most readable implementations of <a href="https://lemire.me/blog/2019/06/06/nearly-divisionless-random-integer-generation-on-various-systems/">Daniel Lemire’s nearly divisionless algorithm for selecting a random number from an interval.</a> I now have winners to announce and congratulate, and they’re in this blog post, but there’s more to this story.</p><p>I didn’t know it at the time but I’d end up reviewing the entries with colleagues to see if they could follow what was happening (spoiler: they couldn’t). When people got stuck, we’d whiteboard&nbsp;our way through so that we could better understand why and where people were getting stuck. Oh, to be able to whiteboard in person again!  </p><p>I learned a lot about how people think through problems, and that process led to me writing a seperate implementation of Lemire’s Algorithm, with a twenty-to-one comment to code ratio (that’s a lot of comments), and finding a sort-of security issue with the algorithm in the process. I say “sort of” because you really have a ridiculously enormous struggle to find a case where it’s going to be practical to exploit. But it still surprised me, and you probably can’t use Lemire’s algorithm in Vegas.</p><h4>Why Lemire’s Algorithm?</h4><p>I chose Lemire’s algorithm because it is brilliant. When I read Lemire’s code I get that kind of brain-tingling and gawk at the sheer “How on earth did someone think of this” of it all. Lemire has a mastery of code and how code is executed, and then pairs that with transcendent creativity and concision.  Lemire also writes well, and the papers that accompany his code and algorithms are easily some of the most cogent and approachable you’ll find in academia. They are short and clear and avoid the jargon and obtuseness that plagues the field, while containing just enough formalism to be rigorous.</p><p>Lemire’s algorithm is a solution to the problem “Give me a random number between 0 and N, not including N itself”. For simulating a dice, N would be 6 and you’d get back either 0, 1, 2, 3, 4, or 5 with equal probability. Computers like to start at zero. We can always add one to the result to get the familiar results you’d get on a real dice. I’ve worked on random number generators and written quite a few. In 20 years of doing that, I’d never come across a solution as cool as Lemire’s.</p><p>Before Lemire, the best-known solutions to this problem required one or two divisions per number generated. You probably learned long division when you were quite young. You may remember that it can be get pretty tedious and cumbersome. It’s the same for computers. Division is actually one of the slowest things we can ask a computer to do. Lemire avoids division by translating numbers into a much larger number “space” and using binary-friendly powers-of-two operations instead. His technique almost always avoids needing a division.</p><p>The second reason I chose Lemire’s algorithm is that it is impenetrable upon first reading. There are lucky few people who are so practiced and conversant in number manipulation that they can see inside of algorithms like Neo in the matrix, but I don’t mean them. To the average reader, myself included, it’s not clear what’s going on and why.</p><p>Lemire’s reference code is fourteen lines long, like a sonnet. Twelve of the lines are simple, and any proficient programmer could tell <em>what</em> they are doing. Two specific lines of the code are pretty hard to decipher.. But the real difficulty is how hard it is to understand <em>why</em> all 14 lines are doing what they are doing, and <em>why</em> it results in a fair and correct algorithm for choosing a random number.</p><div><p>As a case in point, if you read the comments to Lemire’s blog, you’ll find several misunderstandings of the code. That’s within an audience of primed Lemire fans and critics who are familiar with the field. <a href="https://arxiv.org/abs/1805.10941">Lemire’s accompanying paper</a> is great and very readable, but it still takes effort and concentration to follow everything. I work on cryptography and write cryptographic code for a living and I’m not ashamed to tell you it took me about 3 readings to really get it. The algorithm is based on an interaction between two modular spaces, one of which is sized 2 to power of 64, and the other is “N” sized, and if I just totally lost you there, I beg forgiveness and if you bear with me I promise there’s a link to my detailed dissection of how and why everything works. </p><p>All of this makes Lemire’s algorithm a really good challenge for creating a more readable version. Ideally something that an average coder can read in one pass, understand, and agree that it’s correct. </p></div><h4>Why does readability matter?</h4><p>Code readability is the most important pillar of code correctness and maintainability. When code is unreadable, it is harder to spot errors. That’s true when you’re doing a code review and it’s even more true when you’re adding more code to an existing code base. Great testing can compensate for some of the correctness challenges, but it doesn’t do as much for maintainability. </p><p>In s2n, one of our <a href="https://github.com/awslabs/s2n/blob/main/docs/DEVELOPMENT-GUIDE.md">development principles</a> is to write clear readable code with a light cognitive load. We’re serious about it, and I wasn’t going to try and use Lemire’s algorithm in s2n without a very readable implementation.</p><p>Working in software development I’ve heard the opinion more than once about how programmers and coders should be more familiar with the fundamental mathematics of logic and number theory that underpin their field, and that academic style papers and explanations should be sufficient. I happen to work with teams that are made up of both expert coders and expert mathematicians, and even there I don’t think this is a good idea.</p><p>Software engineering is engineering, which means translating science into solutions that work in the real world.  To wildly generalize, there are better dividends to be found in focusing on deepening ones understanding of the “real world” part of that, the users, the customers, the business models, usability, ergonomics, and so on, than on the “science” part of that. Some science is needed, but there’s a shallow limit. Just as a civil engineer doesn’t need too detailed an understanding of the chemistry of concrete. PHs and setting times, but not quantum numbers.</p><p>Code should be self-documenting. The average programmer, including someone straight out of college, should be able to understand and work on a well put-together codebase. This greatly improves the odds of finding problems, and that’s what matters. </p><h4>The contest</h4><p>One of the reasons I’ve been so tardy about this blog post is that the contest didn’t go as I’d expected. </p><p>Let’s start with the great thing that happened. I got several submissions, more than enough to pick winners from. Many of these submissions are good and do improve upon Lemire’s code. The most common improvement was to use more descriptive names for the variables. Lemire uses variable names such as “s”, “t”, “l” which seemingly don’t correspond to much. In such a short piece of code, this actually isn’t too big an offense. I kept these terms in my own implementation, because I want to be consistent with the paper, but it’s absolutely a valid improvement. Another great improvement is to write and include tests, which is really an essential part of software development. </p><p>The first place <a href="https://github.com/ziglang/zig/blob/98183e47436699f6e5eab200061c46eec342806e/std/rand.zig#L74-L118">winner</a> did both of these, and also cleared up some of the confusing lines of code by making an implicit truncation explicit. According to GitHub the winner had 5 contributors, but twitter user <a href="https://twitter.com/komu_wairagu/status/1161643573223317504">komu_wairagu</a> submitted it, so that’s who I’ll be contacting to Venmo $500.</p><p>The second place <a href="https://github.com/nimia/Lemire_RNG">winner</a> comes from <a href="https://twitter.com/NimrodAviram">Nimrod Aviram</a>, who I know professionally as the discoverer of the DROWN vulnerability and fun person to hang out with at RealWorldCrypto. Nimrod’s implementation includes some great testing too.</p><p>The third place winner wants to stay anonymous, and cheated their way to some bonus points by writing a great implementation in LISP. How can you not love that? If they change their minds about anonymity I’ll update this post with a link. The sha256 checksum of their implementation is ae008644b2f0b10eddbbce3a0508b103b19925e4e0c9354c569ff0816acb760c. </p><p>Now on to the not as great, and one of the reasons I’ve taken this long to write. It doesn’t feel right to criticize any of these efforts, made in spare time and as part of a fun challenge I put out there, but none of them actually explained Lemire’s algorithm or broke down how and why it worked. I asked several colleagues to look through these implementations and tell me if they understood what was going on, and the response was a uniform zero. Noone could fully understand even one of the implementations, or Lemire’s original.  When I asked people to also read the paper, things got a bit better, but everyone still seemed to trip on some issues.  These are smart people who absolutely know what they are doing. I’m sure given more time they could fully understand everything, but that wasn’t the goal. The goal was to have understanding after one or two, or at most just a few, readings.</p><h4>What did people find hard to follow?</h4><p>Talking through things with people I found some common problems. Some directly in the code, and others in the paper. The first line of code that threw people was:</p><pre><code>uint64_t l = ( uint64_t ) m;</code></pre><p>This line of code does an unusual operation called truncation. It takes a 128-bit value “m” and truncates that to its least significant 64-bits. All of this is implicit in the code, rather than explicit. Reading the code, you have to recall that m is 128-bits. Then there’s also the question of why are we doing this truncation? I’ll leave that for a minute. </p><p>The next problematic line of code was:</p><pre><code>uint64_t t = -s % s;</code></pre><p>This line of code is using an unusual combination of unary negation, on an unsigned int, and the modulus operator.  Nobody remembers what unary negation does to an unsigned int - and why should they …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://veryseriousblog.com/posts/dissecting-lemire">https://veryseriousblog.com/posts/dissecting-lemire</a></em></p>]]>
            </description>
            <link>https://veryseriousblog.com/posts/dissecting-lemire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24682483</guid>
            <pubDate>Sun, 04 Oct 2020 21:43:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Serverless API in Seconds on Vercel with Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24682393">thread link</a>) | @lucasleray
<br/>
October 4, 2020 | https://lucas-le-ray.com/blog/build-serverless-api-vercel-nodejs | <a href="https://web.archive.org/web/*/https://lucas-le-ray.com/blog/build-serverless-api-vercel-nodejs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Having a personal server can have a lot of advantages, but also a lot of weakness:</p>
<ul>
<li>You are running a server <strong>all the time</strong>, even when no one is using your product.</li>
<li>You have to pay, <a href="https://www.webhostingsecretrevealed.net/website-hosting-cost/#5">sometimes a lot</a>.</li>
<li>You have to configure everything yourself and do some <em>sysadmin</em> work.</li>
<li>Resources allocated to your server are limited, and if you have a spike in usage, it may crash.</li>
</ul>
<p>For these reasons, building a WEB API can be unnecessarily long and expensive.  </p>
<p>The truth is that you may not need any server at all.<br>
What if I told you that it’s possible to code and deploy a performant WEB API  in seconds, without any cost?</p>

<p>To show you how, we are going to build a Serverless API and deploy it on Vercel.</p>
<p><strong>But what’s Serverless?</strong><br>
<a href="https://serverless-stack.com/">Serverless Stack</a> describes Serverless as “<em>an execution model where the cloud provider is responsible for executing a piece of code by dynamically allocating the resources</em>”. In other words, <em>Cloud Providers</em> such as <a href="https://vercel.com/">Vercel</a> take care of everything, from resource management to deployment.</p>
<p>In this article, you’ll learn how to build a simple WEB API which send random lyrics from <em>Pop Smoke</em> (R.I.P 🕊).
We’ll code it in <a href="https://nodejs.org/">Node.Js</a> and use the <a href="https://genius-lyrics.zyrouge.gq/">genius-lyrics API</a>.
Again, all this in seconds, without paying anything.</p>
<hr>
<h2>Building the API 🛠</h2>
<p>Enter this command to setup the project:</p>
<pre><code>yarn init
</code></pre>
<p>Then install  <code>genius-lyrics</code> :</p>
<pre><code>yarn add genius-lyrics
</code></pre>
<p>Now, write this code in <code>api/index.js</code>:</p>
<div id="gist105680230">
    <div>
      <div>
        <div>
  <div id="file-popsmokerandom-js">
    

  <div itemprop="text">
      
<table data-tab-size="8" data-paste-markdown-skip="">
      <tbody><tr>
        <td id="file-popsmokerandom-js-L1" data-line-number="1"></td>
        <td id="file-popsmokerandom-js-LC1"><span>const</span> <span>Genius</span> <span>=</span> <span>require</span><span>(</span><span>"genius-lyrics"</span><span>)</span> <span>// import the library</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L2" data-line-number="2"></td>
        <td id="file-popsmokerandom-js-LC2"><span>const</span> <span>Client</span> <span>=</span> <span>new</span> <span>Genius</span><span>.</span><span>Client</span><span>(</span><span>)</span> <span>// setup the Genius Lyrics API</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L3" data-line-number="3"></td>
        <td id="file-popsmokerandom-js-LC3">
</td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L4" data-line-number="4"></td>
        <td id="file-popsmokerandom-js-LC4"><span>async</span> <span>function</span> <span>retrieveLyrics</span><span>(</span><span>)</span> <span>{</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L5" data-line-number="5"></td>
        <td id="file-popsmokerandom-js-LC5">  <span>const</span> <span>songs</span> <span>=</span> <span>await</span> <span>Client</span><span>.</span><span>songs</span><span>.</span><span>search</span><span>(</span><span>"Pop Smoke"</span><span>)</span> <span>// Get songs from Pop Smoke</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L6" data-line-number="6"></td>
        <td id="file-popsmokerandom-js-LC6">
</td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L7" data-line-number="7"></td>
        <td id="file-popsmokerandom-js-LC7">  <span>const</span> <span>indexSongs</span> <span>=</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> * <span>Math</span><span>.</span><span>floor</span><span>(</span><span>songs</span><span>.</span><span>length</span><span>)</span><span>)</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L8" data-line-number="8"></td>
        <td id="file-popsmokerandom-js-LC8">  <span>const</span> <span>lyrics</span> <span>=</span> <span>await</span> <span>songs</span><span>[</span><span>indexSongs</span><span>]</span><span>.</span><span>lyrics</span><span>(</span><span>)</span> <span>// Get random song</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L9" data-line-number="9"></td>
        <td id="file-popsmokerandom-js-LC9">
</td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L10" data-line-number="10"></td>
        <td id="file-popsmokerandom-js-LC10">  <span>const</span> <span>arrLyrics</span> <span>=</span> <span>lyrics</span><span>.</span><span>split</span><span>(</span><span>"\n"</span><span>)</span><span>.</span><span>filter</span><span>(</span><span>l</span> <span>=&gt;</span> <span>l</span><span>.</span><span>length</span> <span>&amp;&amp;</span> <span>l</span><span>[</span><span>0</span><span>]</span> !== <span>'['</span><span>)</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L11" data-line-number="11"></td>
        <td id="file-popsmokerandom-js-LC11">  <span>const</span> <span>indexLyrics</span> <span>=</span> <span>Math</span><span>.</span><span>floor</span><span>(</span><span>Math</span><span>.</span><span>random</span><span>(</span><span>)</span> * <span>Math</span><span>.</span><span>floor</span><span>(</span><span>arrLyrics</span><span>.</span><span>length</span><span>)</span><span>)</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L12" data-line-number="12"></td>
        <td id="file-popsmokerandom-js-LC12">  <span>return</span> <span>arrLyrics</span><span>[</span><span>indexLyrics</span><span>]</span> <span>// Return random lyrics</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L13" data-line-number="13"></td>
        <td id="file-popsmokerandom-js-LC13"><span>}</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L14" data-line-number="14"></td>
        <td id="file-popsmokerandom-js-LC14">
</td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L15" data-line-number="15"></td>
        <td id="file-popsmokerandom-js-LC15"><span>module</span><span>.</span><span>exports</span> <span>=</span> <span>async</span> <span>(</span><span>req</span><span>,</span> <span>res</span><span>)</span> <span>=&gt;</span> <span>{</span> <span>// this function will be launched when the API is called.</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L16" data-line-number="16"></td>
        <td id="file-popsmokerandom-js-LC16">  <span>try</span> <span>{</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L17" data-line-number="17"></td>
        <td id="file-popsmokerandom-js-LC17">    <span>res</span><span>.</span><span>send</span><span>(</span><span>await</span> <span>retrieveLyrics</span><span>(</span><span>)</span><span>)</span> <span>// send the lyrics</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L18" data-line-number="18"></td>
        <td id="file-popsmokerandom-js-LC18">  <span>}</span> <span>catch</span> <span>(</span><span>err</span><span>)</span> <span>{</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L19" data-line-number="19"></td>
        <td id="file-popsmokerandom-js-LC19">    <span>res</span><span>.</span><span>send</span><span>(</span><span>err</span><span>)</span> <span>// send the thrown error</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L20" data-line-number="20"></td>
        <td id="file-popsmokerandom-js-LC20">  <span>}</span></td>
      </tr>
      <tr>
        <td id="file-popsmokerandom-js-L21" data-line-number="21"></td>
        <td id="file-popsmokerandom-js-LC21"><span>}</span></td>
      </tr>
</tbody></table>


  </div>

  </div>
</div>

      </div>
      
    </div>
</div>
<p>As you can see, no need to add an API key to make <a href="https://genius-lyrics.zyrouge.gq/">genius-lyrics</a> work. But adding a Genius API key will unlock some cool features! You can see a more complete code <a href="https://github.com/LucasLeRay/serverless-vercel">here</a>.</p>
<hr>
<h2>Deployment 🍾</h2>
<p>The most interesting part, and yet the easiest one.  </p>
<p>To deploy on Vercel, install <a href="https://vercel.com/docs/cli">Vercel CLI</a> first:</p>
<pre><code>yarn global vercel
</code></pre>
<p>Then, deploy with the following command in the root of your project:</p>
<pre><code>vercel --prod
</code></pre>
<p>If it’s the first time you use the CLI, you’ll need to login to Vercel.<br>
You’ll be then prompted to add some infos to your project (default options are fine).</p>
<p>Here's the response you should have:</p>
<pre><code>Vercel CLI 20.1.1
🔍  Inspect: DETAILS-URL [3s]
✅  Production: https://YOUR-PRODUCTION-URL [copied to clipboard] [14s]
</code></pre>
<p>And voilà !<br>
Go to <code>https://YOUR-PRODUCTION-URL/api</code> to see it live!<br>
You can take a look at my live version <a href="https://serverless-vercel-eta.vercel.app/api">here</a>.</p>
<pre><code>{
  "status": 200,
  "lyrics": "Oh, oh, oh, oh"
}
</code></pre>
<h6>So deep lyrics 👀</h6>
<p>Here are some advantages of our fresh new Serverless API:</p>
<ul>
<li>It only runs when called.</li>
<li>It’s free, forever. <a href="https://vercel.com/pricing">Vercel’s paid plans</a> are for team projects.</li>
<li>Vercel scales the allocated resources according to your needs. So you don't have to worry if your API will resist x100 usage.</li>
<li>Vercel offers a lot of configuration. For example, you can deploy your API from a GitHub repository. Take a look at your new dashboard on <a href="https://vercel.com/dashboard">Vercel</a>.</li>
</ul>
<hr>
<h2>Serverless Drawbacks 🤔</h2>
<p>As we saw, Serverless is awesome, but it’s not perfect, though. Here’s some common critics about it:</p>
<ul>
<li><strong><a href="https://dashbird.io/blog/can-we-solve-serverless-cold-starts/">Cold Start</a></strong>: Your API may be a bit slower than a regular server. It's because your Serverless function needs to warm up when it’s called, whereas your server is always up.</li>
<li><strong><a href="https://www.oreilly.com/library/view/what-is-serverless/9781491984178/ch04.html#idm140542862552224">Loss of Control</a></strong>: The <em>Cloud Provider</em> operates your API and not you. So, you depend on them for the reliability of your API.</li>
<li><strong><a href="https://www.serverless.com/blog/serverless-monitoring-the-good-the-bad-and-the-ugly">Difficult Monitoring</a></strong>: In general, Serverless apps are harder to test and monitor. It can be a problem when you need to have critical insight about your functions.</li>
</ul>
<p>The great thing is that Serverless community is working to make it even better! Weaknesses are becoming less common and Serverless can be used on a growing number of problems.</p>
<hr>
<h2>Conclusion 🎉</h2>
<p>For most of your backend needs, Serverless may be a great opportunity. Coupled with a <a href="https://www.staticgen.com/">SSG (Static Site Generator)</a> such as <a href="https://nextjs.org/">Next.Js</a> you can build complete applications without server or financial costs.</p>
<p>The sky is the limit, and we only saw a very minimal use of what is possible to do with Serverless or Vercel.</p>
<p>Did you use Serverless In your projects? <a href="http://twitter.com/intent/tweet?text=Hey%20@Lucas_Le_Ray%20,%20">Tell me on Twitter</a> and show me the results!</p></div></div>]]>
            </description>
            <link>https://lucas-le-ray.com/blog/build-serverless-api-vercel-nodejs</link>
            <guid isPermaLink="false">hacker-news-small-sites-24682393</guid>
            <pubDate>Sun, 04 Oct 2020 21:28:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles of Data Oriented Programming]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24682380">thread link</a>) | @viebel
<br/>
October 4, 2020 | https://blog.klipse.tech/databook/2020/09/29/do-principles.html | <a href="https://web.archive.org/web/*/https://blog.klipse.tech/databook/2020/09/29/do-principles.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  <div itemprop="articleBody">
    <div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
<p>This chapter is an attempt to illustrate what are the core principles of Data Oriented Programming as I understand them.
It is highly influenced by my programming experience in Clojure, but I believe that those principles are language agnostic.</p>
<p>One could adhere to them in an Object Oriented (OO) language like Java or C# and one could break them
in a Functional Programming (FP) language like Ocaml, Haskell, JavaScript (or even in Clojure).</p>
<p>In fact, in this chapter, I am going to illustrate how those principles could be applied or broken
in JavaScript, a programming language that supports both FP and OOP.</p>
<p>The principles of Data Oriented (DO) Programming are:</p>

<p>Each principle is explored in a separate article.</p>

<p>Enjoy!</p>
<div>
  <p>
    This article is an excerpt from my upcoming book about Data Oriented Programming. The book will be published by Manning, once it is completed (hopefully in 2021).
  </p>

  <p>
    More excerpts are available on my <a href="https://blog.klipse.tech/data-oriented-programming-book.html">blog</a>.
  </p>

  <p>
    Enter your email address below to get notified when the book is published.
  </p>

  
  <br>
</div>
  </div>

</article><p>
  If you enjoy this kind of interactive articles would you consider a (small) donation💸  on <a href="https://www.patreon.com/bePatron?u=18227864">Patreon</a> or at least giving a star⭐ for the Klispe repo on <a href="https://github.com/viebel/klipse/stargazers"> Github</a>?
</p></div>]]>
            </description>
            <link>https://blog.klipse.tech/databook/2020/09/29/do-principles.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24682380</guid>
            <pubDate>Sun, 04 Oct 2020 21:27:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Death to the Shell]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24681940">thread link</a>) | @pmoriarty
<br/>
October 4, 2020 | http://howardism.org/Technical/Emacs/piper-presentation-transcript.html | <a href="https://web.archive.org/web/*/http://howardism.org/Technical/Emacs/piper-presentation-transcript.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org418e909">
<p>
Remember how I mention that we use shell in two distinct ways, interactively and programmatically.
I’ve shown my idea for the first, let’s chat about the second.
</p>

<p>
While I’ve been thinking about this for many years, not long ago, I came across a Reddit Question:
</p>


<figure>
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/piper-presentation-a.png" alt="Lisp people: What's your go-to language for when you want to write a quick script.  Python seems to be the default for me, but I do genuinely find Lisp joyful to write in." width="1000">

</figure>

<p>
To which I responded that as a Lisp, Emacs Lisp is great as integrating any good idea that comes along, and stealing good ideas has made this system from the twentieth century still useful and almost modern.
</p>


<figure>
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/piper-presentation-b.png" alt="After many years of shell and Perl scripts that grew in complexity, I switch to writing scripts where it is easiest to call, Emacs Lisp.  With modern libraries and completing libraries like Helm and Ivy, I just found a nice go to language." width="1000">

</figure>


<figure id="orgd91c85c">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-12.png" alt="I skipped showing a couple of slides that I just described.  This slide is titled, Emacs as a Go To Scripting Language" width="1000">

</figure>

<p>
The old adage that Emacs is an operating system is pretty true, it is just an operating system of functions, and as such, it really good for the hacker.  You want to either overwrite or just advice every function.  Global variables, normally a bad thing when you are sharing code with others, turns out to be really easy to prototype ideas when it is just you.
</p>

<p>
But think about all the really great libraries and support that we have that are new.  I didn’t have these in the 1980s:
</p>

<ul>
<li>Common Lisp library</li>
<li><a href="https://github.com/magnars/dash.el">Dash library</a></li>
<li><a href="https://github.com/magnars/s.el">S library</a> for strings</li>
<li><a href="https://github.com/rejeep/f.el">F Library</a> for files</li>
<li>Web-focused Libraries for JSON, Yaml, XML</li>
</ul>

<p>
But I think the most compelling argument for using Emacs functions instead of shell scripts is the improved user interface.  I’m serious.  Think about all those command line options to each command you use, and how no amount of tab completion helps.  In emacs, we can easily bind functions to keys, use two great completing systems (<a href="https://github.com/abo-abo/swiper">Ivy</a> or <a href="https://github.com/emacs-helm/helm">Helm</a>) that can give you history of the arguments, just not the command.
</p>

<p>
Finally, think of using Hydra and Magit’s interface, <a href="https://github.com/magit/transient">Transient</a>, to really have a flexible approach to running commands.
</p>


<figure id="org5b922cc">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-13.png" alt="Shell scripts are both good and bad" width="1000">

</figure>

<p>
Shell scripts, especially small ones can be really readable, and they are good as running commands and connecting them with streams, however, any script that grows to any size seems to become completely unreadable.  The other issue is that since everything is a string, we can have conversion issues into numbers or needing to escape white space.  Sure, modern versions of the shell have arrays, but they’re pretty kludgy at best.
</p>

<p>
So, can we take the best of both Lisp and Shell scripts?
If we could, this could be a win for us using Emacs, as calling a <i>function</i> is better than a <i>script</i>.
</p>


<figure id="org55b36c0">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-14.png" alt="Maybe we could bring the good parts of shell scripts into Emacs." width="1000">

</figure>

<p>
What should we <i>bring over</i> from shells?  The <code>format</code> function is fairly good, but the shell, along with most modern languages, have variable substitution within strings.  This seems more readable.  Also, since the shell has embedded itself in my DNA, I am comfortable with <code>mkdir</code> and <code>cp</code>.  Besides, since Emacs doesn’t have namespaces, our functions tend to be pretty lengthy, which often makes our code is little more difficult to read.
</p>

<p>
But when we do, we can get a slew of Lispy goodness, like data structures, better iterations, logical variable scoping, and more functions than you can shake a stick.
</p>


<figure id="org08050f7">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-15.png" alt="Desired Features" width="1000">

</figure>

<p>
The magic starts with a couple of macros that will convert the <i>forms within</i> to be more script-like.  I have five specific goals for how this macro should behave.  Let me explain each of these in details.
</p>


<figure id="orgfb3be37">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-16.png" alt="Shell Executables should just Work" width="1000">

</figure>

<p>
Should be easy to call a shell command, using the <code>shell</code> form:
</p>
<div>
<pre><span>(</span><span>piper-script</span>
 <span>(</span>shell <span>"ls /tmp"</span><span>))</span>
</pre>
</div>

<p>
This should also work well with files that have spaces:
</p>
<div>
<pre><span>(</span><span>piper-script</span>
 <span>(</span>shell <span>"ls"</span> <span>"~/Google Drive File Stream/My Drive/"</span><span>))</span>
</pre>
</div>

<p>
Give the <code>shell</code> form function multiple strings, and it will assume that all strings are parameters, and not do any parsing, but this function will split single strings on spaces.
</p>

<p>
How about making an alias for the <code>shell</code> function name?
</p>
<div>
<pre><span>(</span><span>piper-script</span>
 <span>(</span>$ <span>"ls /tmp"</span><span>))</span>
</pre>
</div>

<p>
Looks like a prompt character.
</p>


<figure id="orgef93771">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-17.png" alt="Pipes and Data Transformations" width="1000">

</figure>

<p>
I use the same technique described earlier of using a temporary buffer, and running shell commands such that the contents of the buffer become <i>standard in</i> to a shell command, and the results of the command replace the contents of the buffer for the next command.  This allows an obvious pipe-like approach:
</p>

<div>
<pre><span>(</span><span>piper-script</span>
 <span>(</span>$ <span>"ls"</span> <span>"-1"</span> <span>"/tmp"</span><span>)</span>
 <span>(</span>| <span>"grep Temp"</span><span>)</span>
 <span>(</span>| <span>"tr [a-z] [A-Z]"</span><span>))</span>
</pre>
</div>

<p>
Keep in mind you can use any Emacs function that works with buffers.
</p>



<figure id="org1476641">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-18.png" alt="Wildcard Expansion" width="1000">

</figure>

<p>
File expansion should work as expected:
</p>

<div>
<pre><span>(</span><span>piper-script</span>
 <span>(</span>$ <span>"ls"</span> <span>"~/.emacs.d/*.el"</span><span>))</span>
</pre>
</div>

<p>
Keep in mind that the <code>piper-script</code> looks at <i>every string</i>, so to make this work, if an expansion fails to find matching files, I just return the original string.
</p>


<figure id="org0331f2e">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-19.png" alt="Embedded Strings" width="1000">

</figure>

<p>
While <code>format</code> is fine, <i>string-variable substitution</i> is more readable, plus I want to be able to insert both Emacs variables as well as environment variables:
</p>

<div>
<pre><span>(</span><span>let</span> <span>((</span>some-var <span>"fooey"</span><span>))</span>
  <span>(</span><span>piper-script</span>
   <span>(</span><span>let</span> <span>((</span>nudder-var <span>"chop"</span><span>))</span>
     <span>(</span>echo <span>"$HOME/projects/${nudder-var}/${some-var}"</span><span>))))</span>
</pre>
</div>

<p>
Should return:
</p>
<pre>"/home/howard/projects/chop/fooey"
</pre>


<figure id="orga006232">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-20.png" alt="Shell-Like Commands?" width="1000">

</figure>

<p>
I’m not convinced, but perhaps when converted shell script should have shorter, more shell-like function names.  In others words, I could use the function <code>grep</code> instead of <code>keep-lines</code>.  In this case, if <code>grep</code> were in quotes and passed to the <code>shell</code> function it would call out to the executable, and if not, to the Emacs function, so maybe this would be more confusing.
</p>

<p>
However, I do need to write <i>some functions</i>, like <code>sudo</code> is a <code>let</code> wrapper around a modification to convert the <code>default-directory</code> variable to reference Tramp.
</p>


<p>
Let me run through a couple of examples, and for each, I want to show my original shell script, and how I converted it.
</p>


<figure id="org4d28751">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-21.png" alt="First Example" width="1000">

</figure>

<p>
First, let’s see if I can get the resident memory size of two running browsers.
</p>



<figure id="org28b9eda">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-22.png" alt="First example's Original Script" width="1000">

</figure>

<p>
While the <code>ps</code> has a lot of command line options, I’m going to use grep to look for the top-level process, that is, the ones where the parent process is <code>1</code>, and I want to ignore all the extra service frameworks that Chrome starts:
</p>

<div>
<pre>ps -u $<span>USER</span> -o ppid,rss,command | egrep <span>'Chrome|Firefox'</span> | grep <span>'^ *1'</span> | grep -v Frameworks
</pre>
</div>



<figure id="orgea00a67">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-23.png" alt="New Piper Script for First example" width="1000">

</figure>

<p>
The most prominent advantage is the use of Emacs’ <code>rx</code> macro for the regular expression (which I pass to the <code>keep-lines</code> alias):
</p>

<div>
<pre><span>(</span><span>let</span> <span>((</span>browsers      <span>(</span><span>rx</span> <span>(</span><span>or</span> <span>"Chrome"</span> <span>"Firefox"</span><span>)))</span>
      <span>(</span>session-leads <span>(</span><span>rx</span> line-start <span>(</span>one-or-more blank<span>)</span> <span>"1"</span><span>)))</span>

  <span>(</span><span>piper-script</span>
   <span>(</span>$ <span>"ps"</span> <span>"-u $USER"</span> <span>"-o ppid,rss,command"</span><span>)</span>
   <span>(</span>grep browsers<span>)</span>
   <span>(</span>grep session-leads<span>)</span>
   <span>(</span>grep-v <span>"Frameworks"</span><span>))))</span>
</pre>
</div>



<figure id="org49dfd21">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-24.png" alt="Second Example" width="1000">

</figure>

<p>
I’ve installed Ubuntu on an old Macbook laptop, and I noticed that after closing the lid, the computer would repeated turn itself on and off.  The reason is that some devices are set to wake up the system, and magic process entry can be used to both read the state of all these devices, but if you write the name of the device back to this process entry, it will turn it off.
</p>

<p>
Why yes, this does seem like a job for a script, eh?
</p>


<figure id="org517f76f">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-25.png" alt="Second example's original script" width="1000">

</figure>

<p>
My original script uses <code>cat</code> to expose all the entries, which text I can massage with a little pipe sequence.
Eventually storing each enabled device in a variable, and writing the value of that variable back into the process entry.
</p>



<figure id="orgee9db29">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-26.png" alt="New Piper Script for Second example" width="1000">

</figure>

<p>
The <code>piper-script</code> version starts by looking a lot like the original, but I use a Lisp-looking looping macro I call <code>for</code> and a function that converts all the lines in this temporary buffer into a list of strings for it to consume:
</p>

<div>
<pre><span>(</span><span>piper-script</span>
 <span>(</span>sudo
  <span>(</span>cat <span>"/proc/acpi/wakeup"</span><span>)</span>
  <span>(</span>grep <span>"enabled"</span><span>)</span>
  <span>(</span>replace-regexp <span>" .*"</span> <span>""</span><span>)</span>
  <span>(</span>for <span>(</span>device <span>(</span>read-all-lines<span>))</span>
    <span>(</span>write-into device <span>"/proc/acpi/wakeup"</span><span>))))</span>
</pre>
</div>



<figure id="org7fd16be">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-27.png" alt="Show us the Magic" width="1000">

</figure>

<p>
The magic is obviously a nifty macro.  I simply use a function from the dash library to analyze and possibly change every element I find in the forms given to it, without changing the structure of those forms:
</p>

<div>
<pre><span>(</span><span>defmacro</span> <span>piper-script</span> <span>(</span><span>&amp;rest</span> forms<span>)</span>
  <span>"Runs the FORMS in a shell-like DSL."</span>
  <span>(</span>cons 'with-temp-buffer
        <span>(</span>-tree-map #'piper--script-transform forms<span>)))</span>
</pre>
</div>

<p>
Since all command works with a buffer, we create one, run through the converted forms, and not shown here, but we return the contents of the buffer as a string.
</p>



<figure id="org55639ce">
<img src="http://howardism.org/Technical/Emacs/piper-presentation-slides/slide-28.png" alt="Piper Script Transform" width="1000">

</figure>

<p>
The followup magic happens with a function that returns a potentially changed version of the form.  It is just a lengthy <code>cond</code> statement, but you can see that at first, I change strings, so that I can expand any wildcards or variable substitution.  Then I just swap out various function names for their alias.  The way it is currently written, I can’t use any variables with matching names as I don’t currently distinguish their position.  Did I mention that this was a proof of concept?
</p>

<div>
<pre><span>(</span><span>defun</span> <span>piper--script-transform</span> <span>(</span>element<span>)</span>
  <span>"Helper for `</span><span>piper-script</span><span>' to convert forms and strings. "</span>
  <span>(</span><span>cond</span>
   <span>((</span>stringp element<span>)</span> `<span>(</span>piper-script-get-files ,element<span>))</span>

   <span>((</span>eq element '$<span>)</span> 'piper-script-shell<span>)</span>
   <span>((</span>eq element '|<span>)</span> 'piper-script-shell<span>)</span>

   <span>((</span>eq element 'echo<span>)</span> 'piper-script-echo<span>)</span>
   <span>((</span>eq element 'ifsh<span>)</span> 'piper-script-shell-if<span>)</span>
   <span>((</span>eq element 'for<span>)</span> 'piper-script-loop<span>)</span>

   <span>((</span>eq element 'cat<span>)</span> 'insert-file-contents<span>)</span>
   <span>((</span>eq element 'touch<span>)</span> 'f-touch<span>)</span>
   <span>((</span>eq element 'ln-s<span>)</span> 'f-symlink<span>)</span>   <span>; </span><span>Perhaps make-symbolic-link</span>
   <span>((</span>eq element 'mkdir<span>)</span> 'f-mkdir<span>)</span>    <span>; </span><span>...</span>

   <span>((</span>eq element 'write-into<span>)</span> 'piper-script-write-into<span>)</span>
   <span>((</span>eq element 'to-clipboard<span>)</span> 'piper-script-to-clipboard<span>)</span>
   <span>((</span>eq element 'read-all-lines<span>)</span> 'piper-script-read-all-lines<span>)</span>
   <span>;; </span><span>...</span>
   <span>(</span>t element<span>)))</span>
</pre>
</div>
</div></div>]]>
            </description>
            <link>http://howardism.org/Technical/Emacs/piper-presentation-transcript.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24681940</guid>
            <pubDate>Sun, 04 Oct 2020 20:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ApproxiPong: An informal review of reinforcement learning algorithms]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24681340">thread link</a>) | @guiambros
<br/>
October 4, 2020 | https://jonathanfiat.github.io/ApproxiPong/ | <a href="https://web.archive.org/web/*/https://jonathanfiat.github.io/ApproxiPong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Reinforcement Learning (RL) is all the rage nowadays. It doesn’t matter if you want to play <a href="https://deepmind.com/research/dqn/">Atari 2600 games</a>, to master <a href="https://deepmind.com/research/alphago/">go</a> (<a href="https://deepmind.com/blog/alphago-zero-learning-scratch/">twice</a>) or even <a href="https://arxiv.org/abs/1712.01815">chess</a>, you should probably use RL. Almost two years ago <a href="http://karpathy.github.io/">Andrej Karpathy</a> wrote an excellent post <a href="http://karpathy.github.io/2016/05/31/rl/">“Pong from Pixels”</a>. He did a wonderful job at explaining the RL problem and a specific RL algorithm (Policy Gradient) by the example of learning to play Pong. Here we extend his work, and compare multiple approaches to learn Pong. In contrast to the work of Kaparthy or DeepMind, we do not solve Pong “from pixels”, but from the actual internal state of the game. It’s easier, and allows us to focus on the RL part of the problem rather than the image processing part.</p>

<p>We rely on deep learning as a building block within classical RL algorithms. Solving Pong is not a very challenging task. The focus of this project is on understanding the merits and pitfalls of RL algorithms when combined with deep learning.</p>

<p>The structure of this website is as follows:</p>

<ul>
  <li>
    <p>In the <a href="https://jonathanfiat.github.io/ApproxiPong/introduction">Introduction</a> we give a very short introduction to RL, to make sure we’re all on the same page, and expand on what are we trying to do here.</p>
  </li>
  <li>
    <p>Perhaps the simplest approach to solve RL problems is by imitating an expert. In <a href="https://jonathanfiat.github.io/ApproxiPong/chapter1">Chapter 1</a> we describe this approach and underscore its limitations.</p>
  </li>
  <li>
    <p>In <a href="https://jonathanfiat.github.io/ApproxiPong/chapter2">Chapter 2: When You Know the Model</a> we present the most common mathematical formulation of the problem (MDP), and some classic solutions. We also show how they actually work when applied to Pong.</p>
  </li>
  <li>
    <p>In <a href="https://jonathanfiat.github.io/ApproxiPong/chapter3">Chapter 3: AlphaZero</a> we present DeepMind’s breakthrough algorithm AlphaGo Zero, and our own implementation, AlphaPong Zero.</p>
  </li>
  <li>
    <p>In <a href="https://jonathanfiat.github.io/ApproxiPong/chapter4">Chapter 4: Learning While Playing Part 1</a> we move on to learn how to play Pong without knowing the rules in advance, and present the Policy Gradient algorithm. We also give a variant of this algorithm with improved peformance.</p>
  </li>
  <li>
    <p>In <a href="https://jonathanfiat.github.io/ApproxiPong/chapter5">Chapter 5: Learning While Playing Part 2</a> we present DeepMind’s Deep-Q-Learning algorithm, and some previously published variants and some of our own making.</p>
  </li>
  <li>
    <p>In <a href="https://jonathanfiat.github.io/ApproxiPong/chapter6">Chapter 6: Learning While Playing Part 3</a> we present Actor-Critic methods: methods that attempt to combine the other algorithms we described. This combination does indeed obtain the best results in our experiments.</p>
  </li>
  <li>
    <p>Finally, there are some <a href="https://jonathanfiat.github.io/ApproxiPong/references">References</a>.</p>
  </li>
</ul>

<p>Should you read this article? If you’re interested in RL, but can’t find your feet in all the mess of concepts and algorithms, you should certainly read this. If you’re an RL expert, you probably already know most of it, but you might find some of the empirical results interesting. If you’re not at all interested in RL, then you should most certainly not read this article. Here, play some Pong instead:</p>

<figure>
  <canvas id="pong-canvas" tabindex="1"></canvas>
  <figcaption>Play Pong. Use the arrows to move the right paddle.</figcaption>
</figure>

<p>Anyway, we hope you’ll enjoy reading through. And if you don’t know yet where to begin, simply start at the <a href="https://jonathanfiat.github.io/ApproxiPong/introduction">Introduction</a>.</p>


  </div>

  
    

  
  
  


  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jonathanfiat.github.io/ApproxiPong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24681340</guid>
            <pubDate>Sun, 04 Oct 2020 18:49:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turing Machine Notation and Normal Form]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24681272">thread link</a>) | @nickdrozd
<br/>
October 4, 2020 | https://nickdrozd.github.io/2020/10/04/turing-machine-notation-and-normal-form.html | <a href="https://web.archive.org/web/*/https://nickdrozd.github.io/2020/10/04/turing-machine-notation-and-normal-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>A <strong>Turing machine</strong> (TM) can be defined formally as the collection of the following objects:</p>

<ul>
  <li>a finite, non-empty set 𝑸 of <em>active states</em>;</li>
  <li>a distinguished state 𝒒<sub>0</sub> ∈ 𝑸, the <em>initial state</em>;</li>
  <li>an object 𝒒<sub>H</sub> ∉ 𝑸, the <em>halt state</em>;</li>
  <li>a finite set with quantity &gt; 1 𝜞 of <em>symbols</em>;</li>
  <li>a distinguished symbol 𝜸<sub>0</sub> ∈ 𝜞, the <em>blank symbol</em>;</li>
  <li>a 2-element set 𝑫, the <em>shifts</em>; and</li>
  <li>a <strong>total</strong> function 𝜹 : 𝑸 × 𝜞 → 𝜞 × 𝑫 × 𝑸 ∪ { 𝒒<sub>H</sub> }, the <em>transition function</em>.</li>
</ul>

<p>A few remarks about this definition:</p>

<ol>
  <li>Some presentations of TMs allow the transition function to be <strong>partial</strong>, but this difference is inessential; a partial function can be made total by adding a catch-all default case.</li>
  <li>Although the halt state is stipulated to be distinct from the “active states”, it is occasionally convenient to group together the <strong>set of all states</strong>, 𝑸 ∪ { 𝒒<sub>H</sub> } (for instance, in the range of the transition function). The expression “active states” is used in cases where the halt state is not under consideration</li>
  <li>An element of 𝑸 ∪ { 𝒒<sub>H</sub> } × 𝜞 × 𝑫 is known as an <strong><em>action</em></strong>.</li>
  <li><strong>Alternative “architectures”</strong> can be obtained by modifying this definition. The architecture described here is the <em>quintuple variation</em>, so called because its transition function can be represented as a set of 5-tuples. Another common architecture is the <em>quadruple variation</em>, with the transition function of the form 𝑸 × 𝜞 → 𝑸 ∪ { 𝒒<sub>H</sub> } × 𝜞 ∪ 𝑫. Whereas the quintuple variation prints and moves at each step, the quadruple variation does one or the other but not both. (In other words, the transition function prescribes different kinds of actions.)</li>
  <li>TMs are typically <strong>grouped by number of active states and symbols</strong>. An <em>n-state, m-symbol</em> TM has <em>n</em> active states and <em>m</em> symbols.</li>
  <li>It has become customary to represent states with capital Roman letters starting with <code>A</code>, with the halt state as <code>H</code> (or something else if it’s needed for the active states), <em>m</em> symbols with the numbers <em>0 … m-1</em> (with <em>0</em> as the blank symbol), and the shifts with <code>L</code> and <code>R</code> (or something else, if these letter are needed for the active states). In the old days, numbers were used for states, symbols, and shifts, and TM programs were much, much harder to read.</li>
</ol>

<p>Individual TMs are typically <strong>identified</strong> with their transition functions, or with <strong>representations thereof</strong>. These represenations may also be referred to simply as <strong><em>programs</em></strong><sup><a id="fnr.1" href="#fn.1">1</a></sup>. Transition functions are often represented as tables, with actions indexed by state and symbol:</p>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>A</th>
      <th>B</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>1RB</td>
      <td>1RC</td>
      <td>1RD</td>
      <td>1LA</td>
      <td>1RH</td>
    </tr>
    <tr>
      <td>1</td>
      <td>1LC</td>
      <td>1RB</td>
      <td>0LE</td>
      <td>1LD</td>
      <td>0LA</td>
    </tr>
  </tbody>
</table>

<p>What this says is: if the machine is in state <code>A</code> and scanning a <code>0</code> on the tape, it will print <code>1</code>, shift to the right, and transition to state <code>B</code>, and so on. Less transparently but more compactly, TMs can also be represented as <strong>simple strings</strong>. The actions are laid out, delimited by spaces, in such a way that actions from earlier states go earlier than later ones, and actions from the same state are ordered by the symbol they come from. Thus the table above comes out as <code>1RB 1LC 1RC 1RB 1RD 0LE 1LA 1LD 1RH 0LA</code>.</p>

<p>Table notation is easier to read than string notation, but since it’s not possible in general to tell what a TM does just by looking at it, this is of little benefit. On the other hand, string notation is excellent for <strong>ease of communication</strong>; a string TM description can easily be dropped into an email or a blog comment. String notation is also amenable to the use of <strong>standard text manipulation tools</strong>. For instance, a file of line-separated TMs in string form can be editted with <code>sed</code> and searched with <code>grep</code>.</p>

<p>Given two distinct TM strings, it might be asked if they represent <strong>meaningfully different</strong> programs or if they are only <strong>superficially different</strong>. This question can be answered by defining a canonical representation. A TM string is in <strong><em>lexical normal form</em></strong> iff the following conditions obtain:</p>

<ol>
  <li>The first shift is <code>R</code>.</li>
  <li>The non-initial active states (𝑸 ∖ 𝒒<sub>0</sub>) first occur in ascending order.</li>
  <li>The non-blank symbols (𝜞 ∖ 𝜸<sub>0</sub>) first occur in ascending order.</li>
</ol>

<p>The first condition rules out the possibility of two TMs being identical except for <strong>“mirror images”</strong> of each other. The second and third conditions rule out TMs that are the same except for <strong>permutations of states and symbols</strong>. Note that the second condition is trivially true for 1- and 2-state TMs, and the third condition is trivially true for 2-symbol TMs.</p>

<p>It’s <strong>easy</strong> determine whether or not a given TM is in normal form, and reasonably short TMs can be judged as normal or not by <strong>eyeball</strong>. It’s also straightforward, though a little more difficult, to <strong>generate</strong> the corresponding normal form for an arbitrary non-normal TM (doing so requires permuting graphs, which can be tricky).</p>

<p>There is another “normal form” that has been in use since the 60s. A TM string is in <strong><em>tree normal form</em></strong> iff the following conditions obtain:</p>

<ol>
  <li>The first shift is <code>R</code>.</li>
  <li>When run on a blank tape, the TM enters its non-initial active states in order.</li>
  <li>When run on a blank tape, the TM prints its non-blank symbols in order.</li>
</ol>

<p>Tree normal form is so-named because it is what results from the <strong>tree generation procedure</strong>. In that procedure, a partially-specified TM is partially run and its transition function “holes” are filled in as needed in a “tree” fashion. New states and symbols are added in order, yielding some kind of canonical form.</p>

<p>Notice that the definition of lexical normal form considers only to the TM string itself, and therefore belongs to <strong>static analysis</strong>. In contrast, the definition of tree normal form makes reference to the actual <strong>runtime behavior</strong> of the program represented by the TM string. Unfortunately, this means that it is <strong>not generally decideable</strong> whether a particular TM string is in tree normal form or not, or whether two distinct TM strings have the same tree normal form or not. Without impugning the tree generation procedure, which has been successfully used by researchers for decades, it’s safe to say that “tree normal form” is a <strong>misnomer</strong>.</p>

<p>For the reasons above, I propose that <strong>lexical normal form should be considered the canonical representation of TMs, and TM should be communicated and published in lexical normal form</strong>.</p>



<ol>
  <li>Which of the following are in lexical normal form? Which are in tree normal form?
    <ul>
      <li><code>1LB 0RB 1RA 0LC 1RC 1RA</code></li>
      <li><code>1RB 0LB 1LA 0RC 1LC 1LA</code></li>
      <li><code>1LC 0RC 1RB 1RA 1RA 0LB</code></li>
      <li><code>1RC 0LC 1LB 1LA 1LA 0RB</code></li>
    </ul>
  </li>
  <li>Can a program be in both lexical and tree normal forms at once? If so, give an example. If not, why not?</li>
  <li>Write a program to determine whether or not an arbitrary TM string is in lexical / tree normal form.</li>
  <li>Write a program to convert an arbitrary TM string to lexical / tree normal form.</li>
  <li>There are <em>(2m(n+1))<sup>mn</sup></em> <em>n</em>-state <em>m</em>-symbol TMs. How many are there in lexical normal form? How many are there in tree normal form?</li>
</ol>

<p>The following questions have to do with Pascal Michel’s <strong><a href="http://www.logique.jussieu.fr/~michel/ha.html">historical survey of Busy Beaver candidate machines</a></strong>.</p>

<ol>
  <li>Determine <em>by eyeball</em> which programs in the list are in lexical or tree normal forms.</li>
  <li>Use your program from exercise 2 above to determine which programs in the list are in lexical or tree normal form.</li>
  <li>(Extra credit) Go through the list and convert every program to lexical normal form, then email Pascal Michel and politely ask him to update the list to be lexical-normal.</li>
</ol>



<p><sup><a id="fn.1" href="#fnr.1">1</a></sup> In some philosophical quarters a sharp distinction is drawn between <strong>“use” and “mention”</strong>. However, it’s both practical and instructive to let one’s eyes go out of focus when looking at the difference between a “Turing machine” and its “representation”. See <strong><a href="https://nickdrozd.github.io/2020/09/14/programmable-turing-machine.html">“Are Turing Machines Programmable?”</a></strong></p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nickdrozd.github.io/2020/10/04/turing-machine-notation-and-normal-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24681272</guid>
            <pubDate>Sun, 04 Oct 2020 18:43:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Read your Twitter timeline in the terminal, using Nitter RSS feeds]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24681111">thread link</a>) | @christian_fei
<br/>
October 4, 2020 | https://decent.social/cli/ | <a href="https://web.archive.org/web/*/https://decent.social/cli/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><code>npm i -g decent-social-cli</code></p><p>or, for one-off runs <code>npx decent-social-cli --help</code></p></div><div><div><p>initialize your timeline with your current Twitter username if you like.<br>this will fetch you current followers (currently max 100) and add them to <code>~/.decent/usernames</code></p><p><code>decent init &lt;username&gt;</code></p></div></div><div><p><code>decent init christian_fei</code></p><p><code>~/.decent/usernames</code> looks like this</p><pre><code>
elonmusk
lexfridman
mkbhd
...
        </code></pre></div><div><p>Read your Twitter timeline with <b>less</b></p><p><code>decent --max 100 | less</code></p></div><div><p>for more information, see <code>decent --help</code><br></p><pre><code>
# Initialize ~/.decent/usernames
decent init<br>
# List your timeline based on ~/.decent/usernames
decent list<br>
# List the timeline of the user "lexfridman"
decent list lexfridman<br>
# Show max 100 tweets
decent list --max 100<br>
# Show max 100 tweets without retweets
decent list --no-retweets --max 100<br>
# Show max 100 tweets without replies
decent list --no-replies --max 100<br>
# Show max 100 tweets without replies without retweets
decent list --no-replies --no-retweets --max 100<br>
# Filter tweets containing term "erlang"
decent filter erlang<br>
# Follow user "lexfridman"
decent follow lexfridman<br>
# unfollow user "lexfridman"
decent unfollow lexfridman<br>
# Followers of user "lexfridman"
decent followers lexfridman
          </code></pre></div><p><code>npm i -g decent-social-cli</code></p></div></div>]]>
            </description>
            <link>https://decent.social/cli/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24681111</guid>
            <pubDate>Sun, 04 Oct 2020 18:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Concepts in Unity for Software Engineers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24680934">thread link</a>) | @Eyas
<br/>
October 4, 2020 | https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you’re trying to get into game development as a Software Engineer, finding
learning materials with the right level of context can be challenging. You’ll
likely face a choice between following materials introducing you to basic C# and
OOP concepts while also describing Unity concepts, or starting with advanced
tutorials and be left to figure out the core concepts deductively.</p><p>To fill that gap, I’m writing a series called
<strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>. This is
the first piece, and I’ll be releasing additional installments over the next few
weeks, so <a href="http://eepurl.com/gVgusL">make sure to subscribe</a> for updates. The
series is intended for folks already comfortable with programming and software
architecture, especially those who learn best as I do: starting with first
principles and working your way upwards.</p><hr><p>I started my programming journey around 17 years ago by picking up
<a href="https://www.yoyogames.com/gamemaker">Game Maker</a>. Countless hours spent coding
little games and tools led me to a bigger passion for programming. Eventually, I
was at a point where I focused mainly on Software Engineering. From my peers, I
know this is quite a common path that many of us took to find programming.</p><p>Yet the game development scene has changed significantly from those days. When I
went to pick up Unity after a long absence from game development, I was mostly
interested in understanding the basic concepts: what are the fundamental
building blocks of a game? What do I need to know about how these building
blocks are represented in memory or on disk? How is idiomatic code organized?
What patterns are preferred?</p><p>In the first article in the series, we’ll focus on those first two questions.</p><h2 id="scene">Scenes</h2><p>A <strong>Scene</strong> is the largest unit of organizing your objects in-memory. Scenes
contain the objects making up your game.</p><p>In basic use, one scene represents a <strong>single level</strong> in your game, where one
scene is loaded at any given point. In more “advanced” use, you can have two or
more active scenes at a time. Scenes can be loaded additively and unloaded <sup id="fnref-1"><a href="#fn-1">1</a></sup>.
Having multiple scenes loaded during gameplay comes especially handy when
building a massive world; keeping far-away areas on-disk rather than in-memory
will help you stay within your performance budget.</p><div><figure><p><span>
      <a href="https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/20a35/empty-scene.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/28a80/empty-scene.webp 400w,https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/8d2ea/empty-scene.webp 800w,https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/e1ffd/empty-scene.webp 1016w" sizes="(max-width: 1016px) 100vw, 1016px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/a3397/empty-scene.png 400w,https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/a331c/empty-scene.png 800w,https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/20a35/empty-scene.png 1016w" sizes="(max-width: 1016px) 100vw, 1016px" type="image/png">
        <img src="https://blog.eyas.sh/static/8a63c592f9c8efe7c6fe5027f8075845/20a35/empty-scene.png" alt="A scene editor showing an empty scene in 3D Mode." title="A scene editor showing an empty scene in 3D Mode." loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>Unity Scene editor opening a default empty scene in 3D mode. Empty Scenes in
Unity3D will by default include <em>Main Camera</em> and <em>Directional light</em> objects.</p></figcaption></figure><figure><p><span>
      <a href="https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/02ee0/scene-with-objects.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/28a80/scene-with-objects.webp 400w,https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/8d2ea/scene-with-objects.webp 800w,https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/97a89/scene-with-objects.webp 1014w" sizes="(max-width: 1014px) 100vw, 1014px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/a3397/scene-with-objects.png 400w,https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/a331c/scene-with-objects.png 800w,https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/02ee0/scene-with-objects.png 1014w" sizes="(max-width: 1014px) 100vw, 1014px" type="image/png">
        <img src="https://blog.eyas.sh/static/3663ec5a133582da273a56e10f2811b6/02ee0/scene-with-objects.png" alt="A scene editor showing a heavily populated scene in 3DM mode." title="A scene editor showing a heavily populated scene in 3DM mode." loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>Unity Scene editor showing an example scene, with a few objects selected. You
can use the scene view to edit levels in your game.</p></figcaption></figure></div><p>Every <a href="#gameobject"><em>game object</em></a> in Unity needs to be <em>in</em> a scene.</p><h2 id="gameobject">Game Objects</h2><p>A <strong>Game Object</strong> (in code, <code>GameObject</code>) is one of the basic building blocks of
a game.</p><p>Game Objects can represent both <em>physical</em> things you see in the game (e.g., a
player, the ground, a tree, a terrain, lights, a weapon, a bullet, an explosion)
<em>as well as</em> <em>metaphysical</em> things (e.g., an inventory manager, a multiplayer
controller, etc.) in your game.</p><p>Every Game Object has a position and rotation. For metaphysical objects, this
doesn’t matter.</p><p>Game Objects can nest under each other. Each object’s position and rotation is
relative to its parent object. An object directly in the scene is relative to
“world space” coordinates.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/d1176/nested-objects-organizational.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/28a80/nested-objects-organizational.webp 400w,https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/8d2ea/nested-objects-organizational.webp 800w,https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/43d96/nested-objects-organizational.webp 1600w,https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/b5638/nested-objects-organizational.webp 2045w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/a3397/nested-objects-organizational.png 400w,https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/a331c/nested-objects-organizational.png 800w,https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/1a152/nested-objects-organizational.png 1600w,https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/d1176/nested-objects-organizational.png 2045w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/png">
        <img src="https://blog.eyas.sh/static/1fa53e027dc03e25490512c1ad1b4e93/1a152/nested-objects-organizational.png" alt="Screenshot showing nested objects for organizational purposes" title="Screenshot showing nested objects for organizational purposes" loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>A group of objects nested together in a scene under an empty “Interior_Props”
object, for organizational purposes.</p></figcaption></figure><p>You might choose to nest your objects for many reasons. For example, you might
decide it organizationally makes sense to put all your “environment” (e.g.,
individual pieces that make up a city or village) objects under an empty parent
object. This way, it can be collapsed in the scene view and easily moved
together when building your game.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/171d2/nested-objects-functional.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/28a80/nested-objects-functional.webp 400w,https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/8d2ea/nested-objects-functional.webp 800w,https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/71c32/nested-objects-functional.webp 1106w" sizes="(max-width: 1106px) 100vw, 1106px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/a3397/nested-objects-functional.png 400w,https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/a331c/nested-objects-functional.png 800w,https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/171d2/nested-objects-functional.png 1106w" sizes="(max-width: 1106px) 100vw, 1106px" type="image/png">
        <img src="https://blog.eyas.sh/static/c5e377de23f2c41444e43b1dee3b86a7/171d2/nested-objects-functional.png" alt="Screenshot showing nested objects for functional purposes" title="Screenshot showing nested objects for functional purposes" loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>A group of objects nested under the player. These include the player’s weapon,
avatar, and various UI elements rendered around the player.</p></figcaption></figure><p>Game Object nesting can also have <em>functional significance</em>. For example, a
“Car” can be an object, with code that controls the car’s speed and rotation as
a whole. But individual child objects might represent the four wheels (these
would spin independently), the car body, windows, etc. Moving the parent car
object would move all the child objects, keeping their relative orientation to
the parent (and each other). We might want the player to interact with a door
separately from the rest of the car, for instance.</p><h2 id="component">Components (&amp; MonoBehaviors)</h2><figure><p><span>
      <a href="https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/faa4f/inspector-with-components.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/28a80/inspector-with-components.webp 400w,https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/8d2ea/inspector-with-components.webp 800w,https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/e432d/inspector-with-components.webp 878w" sizes="(max-width: 878px) 100vw, 878px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/a3397/inspector-with-components.png 400w,https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/a331c/inspector-with-components.png 800w,https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/faa4f/inspector-with-components.png 878w" sizes="(max-width: 878px) 100vw, 878px" type="image/png">
        <img src="https://blog.eyas.sh/static/6c13139bed0d3e0340ef8308a17e47fd/faa4f/inspector-with-components.png" alt="Screenshot showing the inspector window on an object." title="Screenshot showing the inspector window on an object." loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>The Warrior object from the previous screenshot is shown above in Unity’s
“Inspector” window. Each illustrated section (e.g., Animator, Rigidbody,
Collider) are <em>Components</em> making up this object.</p></figcaption></figure><p>Every Game Object is comprised of <strong>Components</strong>.</p><p>A Component implements a well-defined set of behaviors for a GameObject to
execute. Everything that makes an object what it is would come from the
components that make it up:</p><ul><li>A single “visible” piece of a car will have a <em>Renderer</em> component that
paints it, and likely a <em>Collider</em> component that sets up its collision
bounds.</li><li>If a car represents the player, the car object itself might have a <em>Player
Input Controller</em> that takes key input events and translates these to code
moving the car around.</li></ul><p>While you can write large and complex Components that correspond 1:1 to an
object (e.g., a player component codes the entire player, while an enemy
component codes the enemy as a whole), it’s typically common to factor out your
logic into streamlined pieces corresponding to individual <em>traits</em>. For example:</p><ul><li>All objects with <em>health</em>, whether a Player or an Enemy, might have a
<code>LivingObject</code> component that sets an initial health value, takes damage,
and triggers a death event once it dies.</li><li>A player might additionally have an input component controlling its
movement, while the enemy might have an AI component that controls its
movement instead.</li></ul><p>Components receive various callbacks throughout their lifetime, known in Unity
as <em>Messages</em>. Examples of Messages include <code>OnEnable</code>/<code>OnDisable</code>, <code>Start</code>,
<code>OnDestroy</code>, <code>Update</code>, and others. If an object implements an <code>Update()</code> method,
this method will automagically be called by Unity in every frame of the game
loop while the object is active, and the given component is enabled. These
methods can be marked <code>private</code>; the Unity engine will still call them.</p><p>Components can also expose public methods as you’d expect. Other components can
take a reference to a component and call these public methods.</p><h2 id="asset">Assets</h2><p><strong>Assets</strong> are the on-disk resources that make up your game project. These
include meshes (models), textures, sprites, sounds, and other resources.</p><p>When serialized to the disk, your scenes are represented as assets made up of
the Game Objects inside of them. We’ll also discuss in the next section how you
can make Game Objects that are reused often into an asset known as a
<a href="#prefab">Prefab</a>.<sup id="fnref-2"><a href="#fn-2">2</a></sup></p><figure><p><span>
      <a href="https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/3c2e3/assets-in-project-view.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/28a80/assets-in-project-view.webp 400w,https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/8d2ea/assets-in-project-view.webp 800w,https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/cedc5/assets-in-project-view.webp 1291w" sizes="(max-width: 1291px) 100vw, 1291px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/a3397/assets-in-project-view.png 400w,https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/a331c/assets-in-project-view.png 800w,https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/3c2e3/assets-in-project-view.png 1291w" sizes="(max-width: 1291px) 100vw, 1291px" type="image/png">
        <img src="https://blog.eyas.sh/static/65a370888c3e5f061718bfab6daec6eb/3c2e3/assets-in-project-view.png" alt="Unity Asset view showing visual assets in a game project" title="Unity Asset view showing visual assets in a game project" loading="lazy">
      </picture>
  </a>
    </span></p></figure><p>Assets can also represent less tangible things, such as Input Control Maps,
Graphics Settings, i18n string databases, and more. You can also create your own
custom asset types
<a href="https://unity.com/how-to/architect-game-code-scriptable-objects">using ScriptableObjects</a>.
I wrote about how these are saved
<a href="https://blog.eyas.sh/2020/09/where-scriptableobjects-live/">here</a>.</p><p>For your in-development project, assets form the key representation of your
project’s codebase, alongside your code.</p><p>Your built-and-bundled game will include <em>most</em><sup id="fnref-3"><a href="#fn-3">3</a></sup> of your assets. These assets
will be saved on disk on the device where the game is installed.</p><h2 id="prefab">Prefabs</h2><figure><p><span>
      <a href="https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/af8d6/container-homes.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/28a80/container-homes.webp 400w,https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/8d2ea/container-homes.webp 800w,https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/43d96/container-homes.webp 1600w,https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/f3ff0/container-homes.webp 1920w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/4cda9/container-homes.jpg 400w,https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/c60e9/container-homes.jpg 800w,https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/56dca/container-homes.jpg 1600w,https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/af8d6/container-homes.jpg 1920w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
        <img src="https://blog.eyas.sh/static/c795152ffc6beb8afcfe8b85fbb6886a/56dca/container-homes.jpg" alt="Photo of rows of container homes" title="Photo of rows of container homes" loading="lazy">
      </picture>
  </a>
    </span></p></figure><p>Game Objects, their Components, and their input parameters exist as individual
<em>instances</em> in a scene. But what if a particular class of objects is commonly
repeated? Such objects can be made into a <strong>Prefab</strong>, which is effectively the
object in asset form.</p><p>Instances of a prefab in a scene can have local modifications that distinguish
it (e.g., if a <em>tree</em> object is a prefab, you can have tree instances of
different heights). Instances of a prefab all inherit and override data from
their prefab.</p><h3>Nested Prefabs</h3><p>Starting with Unity 2018.3, Prefabs can be nested just as you expect:</p><ol><li>A parent object with prefab child objects can be a prefab itself. In the
parent prefab, the child prefab instance can have its own modifications. In
the scene, the entire prefab hierarchy is instantiated, and scene-specific
modifications can layer on top.</li><li>A prefab instance in a scene with its own local modifications can be saved as
its own “Prefab Variant” asset. A variant is a prefab asset that inherits
from another prefab, applying additional modifications on top.</li></ol><p>These concepts compose; a prefab variant of a nested prefab, or a prefab variant
of a prefab variant, for instance.</p><h2 id="serialization">Serialization &amp; Deserialization</h2><p>Your project’s assets, scenes, and objects are all persisted on-disk. When
editing your game, these objects are loaded in memory and saved back to disk
using
<a href="https://blogs.unity3d.com/2014/06/24/serialization-in-unity/">Unity’s serialization system</a>.
When playtesting your game, the objects and scenes in-memory are loaded through
the same serialization system. This system also maps between assets in your
compiled bundle and the loaded/unloaded scene objects in-memory.</p><p>The Unity Engine’s Serialization/Deserialization flow loads on-disk assets into
memory (in your project: for editing/playtesting; in-game, when loading a scene)
and is responsible for saving the state of your edited objects &amp; components back
into their scenes and prefabs.</p><p>Therefore, the serialization system is also at the core of the Unity Editor
experience itself. For a <code>MonoBehavior</code> to take an input on construction when
instantiated in a scene, those fields must be <em>serialized</em>.</p><p>Most core Unity types such as <code>GameObject</code>s, <code>MonoBehavior</code>s, and asset
resources are
<a href="https://docs.microsoft.com/en-us/dotnet/api/system.serializableattribute">Serializable</a>
and can receive initial values on creation from within the Unity Editor. Public
fields on your <code>MonoBehavior</code> are serialized by default (if they’re of a
serializable type), and private fields need to be marked with Unity’s
<a href="https://docs.unity3d.com/ScriptReference/SerializeField.html"><code>[SerializeField]</code></a>
attribute to be serialized as well.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/d0cfe39b333b7b70ede27e286ad3be48/7d442/chaos-reborn-screenshot.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
   …</picture></a></span></p></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/">https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/</a></em></p>]]>
            </description>
            <link>https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680934</guid>
            <pubDate>Sun, 04 Oct 2020 18:02:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple sues Canadian recycling firm for reselling 100k devices, not destroying]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 124 (<a href="https://news.ycombinator.com/item?id=24680870">thread link</a>) | @geuis
<br/>
October 4, 2020 | https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/ | <a href="https://web.archive.org/web/*/https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<!-- .entry-social-links -->
<div>
	
	
	
		
		
	
<!-- .entry-social-links -->	
		
		
	<div>
	<p><a href="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png"><img src="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png" alt="" width="696" height="488" srcset="https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11.png 696w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-350x245.png 350w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-640x449.png 640w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-660x463.png 660w, https://cdn.iphoneincanada.ca/wp-content/uploads/2020/09/apple-website-iphone-11-560x393.png 560w" sizes="(max-width: 696px) 100vw, 696px"></a></p>
<p>According to <a href="https://thelogic.co/news/exclusive/apple-sues-ontario-electronics-recycling-firm-claiming-it-stole-nearly-100000-products-for-resale/"><em>The Logic</em></a>, an Ontario electronics recycling firm is being sued by Apple, alleging the company stole and resold iOS and watchOS devices instead of destroying them.</p>	
	
	
	
<p>GEEP Canada is being accused of reselling 100,000 iPhones, iPads and Apple Watches, according to Apple’s lawsuit.</p>
<p>Apple says Barrie-based GEEP and members of its senior management team were aware of its activity. GEEP denies all wrongdoing and says when it discovered the reselling ring, it shut it down immediately.</p>
<p>As for damages, Apple is seeking $31 million from GEEP, plus proceeds made from selling iPhones, iPads and Apple Watches.</p>
<p>GEEP was hired by Apple back in the fall of November 2014 to assist in recycling old products instead of being discarded into landfills.</p>
<p>Apple says it sent 531,966 iPhones, 25,673 iPads and 19,277 Apple Watches to GEEP to be recycled from the start of 2015 to the end of 2017, according to lawsuit, seen by <em>The Logic</em>.</p>
<p>“At least 11,766 pounds of Apple devices left GEEP’s premises without being destroyed – a fact that GEEP itself confirmed. These misappropriated devices were then subsequently sold at a significantly higher price than other recycled materials to downstream vendors who refurbished and resold the devices to consumers,” explains Apple’s suit, filed in January.</p>
<p>Apple discovered GEEP was moving devices into areas not under camera surveillance after auditing the Ontario company’s warehouse. The iPhone maker found 18% of devices shipped to GEEP were active on wireless carrier networks.</p>
<p>While some devices like Wi-Fi iPads won’t show up on carrier networks, which Apple says makes the total number of stolen products higher.</p>
<p>GEEP says the reselling ring was due to three “rogue” employees, Roger Micks, Edward Cooper and Steven White, who sold the devices to Fu Yuan Yang at Whitby Recycling. Yang then sold these Apple devices to people in China.</p>
<p>GEEP’s third-party claim from July says it wants these employees, Yang and Whitby Recycling to pay damages if Apple wins, plus cover its legal fees.</p>
<p>The Ontario recycler says it has suffered “extensive business losses” due to the incident and its reputation, to go with Apple cancelling its contract.</p>

	</div>

</div><!-- .entry-inner -->
</article></div>]]>
            </description>
            <link>https://www.iphoneincanada.ca/news/apple-sues-canadian-recycling-firm-for-reselling-100000-devices-instead-of-destroying-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680870</guid>
            <pubDate>Sun, 04 Oct 2020 17:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sonos is spying on me (and you)]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24680614">thread link</a>) | @gingerlime
<br/>
October 4, 2020 | https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/ | <a href="https://web.archive.org/web/*/https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2630">
		<!-- .entry-header -->

	
	<div>
		
<p>I recently decided to get a wireless speaker for our Kitchen. Sonos seems like an obvious choice these days. The sound quality and aesthetics were very appealing. So I ordered a Sonos One SL speaker.</p>



<p>In terms of sound quality and looks, I was very pleased. I’m not an audiophile but the sound quality seemed superb and the speaker just looks fantastic. A very clean and unassuming look.</p>



<div><figure><img loading="lazy" width="768" height="1024" src="https://blog.gingerlime.com/assets/IMG_6571-1-768x1024.jpg" alt="" srcset="https://blog.gingerlime.com/assets/IMG_6571-1-768x1024.jpg 768w, https://blog.gingerlime.com/assets/IMG_6571-1-225x300.jpg 225w, https://blog.gingerlime.com/assets/IMG_6571-1.jpg 1024w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"><figcaption>what’s hiding underneath ?</figcaption></figure></div>



<p><strong>As I later discovered, a dirty beast hides under the cool exterior.</strong></p>



<p>My concerns started to grow almost immediately as I was setting up the new speaker. I downloaded the app, and started the setup process, soon to realize that I need to register with my email just to set up the device on my network… And of course, I had to accept the terms and conditions …. hmmm… ok, I guess.</p>



<div><figure><img loading="lazy" src="https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-576x1024.jpeg" alt="" width="236" height="420" srcset="https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-576x1024.jpeg 576w, https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1-169x300.jpeg 169w, https://blog.gingerlime.com/assets/IMG_92F6A34207E1-1.jpeg 750w" sizes="(max-width: 236px) 100vw, 236px"></figure></div>



<div><figure><img loading="lazy" src="https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1.png" alt="" width="203" height="361" srcset="https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1.png 375w, https://blog.gingerlime.com/assets/IMG_31E9A893CD62-1-169x300.png 169w" sizes="(max-width: 203px) 100vw, 203px"></figure></div>



<p>I was then asked to allow sharing my location as well, which raised another alarm bell. <strong>Why does my speaker need my location?</strong> I’m not 100% sure, but if I recall, I had to allow it to access my location, or else I couldn’t continue.</p>



<p>Once the device was finally set up, I went through the settings, to explore and see what else is there. I was rather disappointed to find that <strong>“Additional usage data” was turned on by default</strong>. I live in Europe, and I thought that the EU regulations should prevent this kind of behaviour. They should explicitly ask my permission to track my usage, especially if it isn’t necessary for the device to function.</p>



<p>I could opt-out of it luckily, but it didn’t feel right to me.</p>



<h2>What data is Sonos collecting, and why?</h2>



<p>Digging into the <a href="https://www.sonos.com/en/legal/privacy" target="_blank" rel="noreferrer noopener nofollow">Sonos privacy policy</a> made my hair stand… </p>



<div><div>
<h5>Functional Data:</h5>



<div><p>This data is absolutely necessary for your Sonos Product or Service, including Sonos Radio, to perform its basic functions in a secure way and <strong>you will not be able to opt out from this data collection, sharing, and/or processing</strong> if you want to continue to use your Sonos Products.</p><p><strong>We collect:</strong></p></div>



<p><strong>Registration data.</strong> This data includes your email address, location, language preference, Product serial number, IP address, and Sonos account login information (as described above).<br><strong>System data.</strong> This data includes things like Product type, controller device type, controller operating system, software version, content source (audio line in), signal input (e.g. whether your TV outputs a specific audio signal such as Dolby to your Sonos system), information about WiFi antennas, system settings (such as equalisation or stereo pair), Product orientation, names of the music service(s) you added/enabled on your Sonos product, the names you have given your Sonos Product in different rooms, whether your Product has been tuned using Sonos Trueplay technology, system performance metrics (e.g. the temperature of your Product or WiFi signal strength) and error information.</p>
</div></div>



<p>(emphasis not mine)</p>



<p>So this is <em>just</em> the data that you <strong><em>cannot</em></strong> opt-out of. The data <strong>absolutely necessary to perform basic functions.</strong>  And in case you wonder why they track this data, here’s what the privacy policy says</p>



<div><p><strong>Why we collect Functional Data:</strong> We collect this information to help ensure that your Products are working properly, to provide you with customer support, to honour your audio preferences, and to guide product improvement and customer support decisions. We also collect this information to guide product improvement and customer support decisions which is <strong>our legitimate interest</strong>.</p></div>



<p>emphasis mine… we’ll go back to what <em><strong>legitimate interest</strong></em><strong> </strong>actually means later on.</p>



<p>I’m not sure what basic functions for a speaker might be, that they require to share so much data with Sonos. And if this not enough, there’s also the (optional) Usage data that Sonos happily collects, by default, without asking for permission</p>



<div><div>
<div><div>
<h5>Additional Usage Data:</h5>



<p>In order to improve your experience with Sonos Products and to offer better, personalised Sonos Products and Services, including Sonos Radio, that meet the needs and expectations of our customers, we collect the following Additional Usage Data. The processing of this information is in our legitimate interest as further set out below (under Why). You can opt out of sharing this data by following the steps listed <a href="https://www.sonos.com/en/legal/privacy#data-opt-out" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p>



<p><strong>We collect:</strong></p>



<ul><li><strong>Performance Information.</strong> This includes things like the temperature of your Product, WiFi information like signal strength, how often you use music services you have connected to your Sonos system (including, for some services, your login username, but not password), information about how often you use the Sonos app versus other control mechanisms, flow of interactions within the Sonos app, how often you use the physical controls on the unit, the flow of interactions within the Sonos app, duration of Sonos Product use, and, as required for certain Services, location-based data using GPS (or similar technology, where available) and crowdsourced WiFi access points and cell tower locations collected from your third party device when the Sonos app is in use.</li><li><strong>Activity Information.</strong> This includes duration of music service use, Product or room grouping information, command information (such as play, pause, change volume, or skip tracks), information about playlist or station container data including listening history (‘Recently Played’), and Sonos playlist or Sonos favourites information; each correlated to individual Sonos Products and your interactions with them. If you enable voice control or use Sonos Radio, we will additionally collect information about track data when using those features.</li></ul>



<blockquote><p><strong>Why:</strong> We collect this information so that we can help ensure Sonos Products are functioning properly, provide a personalised experience for our customers, determine what types of Product or feature improvements would please our customers most, and to help predict potential problems with Sonos Products. Additionally, to provide Sonos Radio, we collect location-based information for licensing and reporting purposes. <strong>Collecting this data is our legitimate interest</strong> to support a user-friendly experience that meets your needs and help you with issues you may experience. It is your choice if you want us to collect this information, and therefore you can opt out of sharing this data by following the steps listed <a href="https://www.sonos.com/en/legal/privacy#rights-choices" target="_blank" rel="noreferrer noopener nofollow">here</a>.</p><p><strong>Note:</strong> personalisation services (e.g. Recently Played), Sonos Radio, Voice Control, and Direct Control functionality require Additional Usage Data to function. If you decide to use any of these features and/or Services, the <a href="https://www.sonos.com/en/legal/privacy#additional-data" target="_blank" rel="noreferrer noopener nofollow">Additional Usage Data</a> becomes functional. You can always clear all Recently Played by following the instructions in the Sonos app.</p></blockquote>
</div></div>
</div></div>



<p>Again, the legitimate interest emphasis is mine…</p>



<p>If you read their privacy policy further, you could spot the real incentives and potential uses of the data, but I won’t dive into it here. I do recommend reading it though.</p>



<h2>(il)legitimate interest</h2>



<p>So what is this all about? Well, if you’re familiar with the General Data Protection Regulation (GDPR), you might guess the answer. I’m not a lawyer, so without going into too much detail, here’s my brief understanding of it.</p>



<p>First off, the GDPR is the regulation that aims to protect the privacy of all EU citizens. It’s meant to reduce privacy invasive practices, force companies to protect private data, and encourage companies to treat private data with care and respect.</p>



<p>But what’s “legitimate interest”, and why is it important?</p>



<p>Essentially, companies aren’t simply allowed to store any customer data they want. They need a “good reason” to do so. Or in other words, they need to have a legitimate interest in storing such data. Otherwise, they’re simply not allowed to store it at all.</p>



<p>So now, can I just ask someone who accesses my website “What’s your home address”? and store it, if they give it to me. I need to have a real reason to ask for this address. It can be my legitimate interest to ask it if, for example, I’m going to send you a free gift. I obviously can’t send you a gift without knowing your address.</p>



<p>As you can imagine, “legitimate interest” can be interpreted in many different ways. Is it legitimate interest to ask for an email address in order to send marketing emails? well, actually it might be. There’s no black and white answer here.</p>



<h2>Putting it to the test</h2>



<p>There are <a href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/legitimate-interests/what-is-the-legitimate-interests-basis/#balancing_test" target="_blank" rel="noreferrer noopener">3 tests for “legitimate interest”</a>:</p>



<div><div>
<div><div>
<ul><li><strong>Purpose test</strong> – is there a legitimate interest behind the processing?</li><li><strong>Necessity test</strong> – is the processing necessary for that purpose?</li><li><strong>Balancing test</strong> – is the legitimate interest overridden by the individual’s interests, rights or freedoms?</li></ul>
</div></div>



<p>Whilst Sonos tries very hard to meet those first two tests with their policies (but in my opinion, have a very weak position there), I think it clearly fails the balancing test. Sonos blatantly violates its customer privacy by excessively tracking, analysing and making use of very detailed information about them. They capture their listening preferences, their location, neighbouring Wifi access points and lots more. And worse of all, they do it without asking for explicit consent. It’s all hidden in the privacy policy, and set to expose all this data by default.</p>



<p>What’s the <strong>purpose</strong> of collecting all this data? Sonos claims that their purpose is “[To] help ensure Sonos Products are functioning properly, provide a personalised experience for our customers, determine what types of Product or feature improvements would please our customers most, and to help predict potential problems with Sonos Products”. This seems fairly clear as a purpose. Still rather widespread and invasive, but there’s a purpose.</p>



<p>But is collecting all this data <strong>necessary</strong> to meet this purpose? I don’t think so. I think they collect far too detailed information, and they could meet the same purpose with far less data, or by using non-private / anonymised data. </p>



<p>For example: how does the IP address of the customer help with any of those stated purposes? Or why do they need to map neighbouring Wifi access …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/">https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/</a></em></p>]]>
            </description>
            <link>https://blog.gingerlime.com/2020/sonos-is-spying-on-me-and-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680614</guid>
            <pubDate>Sun, 04 Oct 2020 17:18:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Symbiotic Prototyping: Minimizing value risk in B2B settings]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24680396">thread link</a>) | @martingordon
<br/>
October 4, 2020 | https://joycegordon.me/2020/09/29/symbiotic-prototyping-minimizing-value-risk/ | <a href="https://web.archive.org/web/*/https://joycegordon.me/2020/09/29/symbiotic-prototyping-minimizing-value-risk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>If we asked a room full of product managers what was keeping them up at night, the most common answer would be a version of “building product that doesn’t get used,” more concisely known as “Value Risk.”&nbsp;</p>



<p>In <a href="https://svpg.com/four-big-risks/" target="_blank" rel="noreferrer noopener">The Four Big Risks</a>, Marty Cagan calls out the major risk categories products face:</p>



<blockquote><ol>
<li>value risk (whether customers will buy it or users will chose it)</li>
<li>usability risk (whether users can figure out how to use it)</li>
<li>feasibility risk (whether our engineers can build out what we need with the time, skills, and technology we have)</li>
<li>business viability risk (whether this solution also works for the various aspects of our business)</li></ol></blockquote>



<p>Of the four risks, “value risk” is the most fundamental: does this product effectively solve a meaningful pain point for users?&nbsp; Usability, feasibility, and business viability risks are only relevant if we’re confident in the product’s value.</p>



<div><figure><img data-attachment-id="130" data-permalink="https://joycegordon.me/screen-shot-2020-09-28-at-8-53-39-pm-2/" data-orig-file="https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png" data-orig-size="1584,1086" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="risk-hierarchy" data-image-description="" data-medium-file="https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=300" data-large-file="https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=1024" src="https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=1024" alt="" width="600" srcset="https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=1024 1024w, https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=150 150w, https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=300 300w, https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png?w=768 768w, https://joycegordonme.files.wordpress.com/2020/09/screen-shot-2020-09-28-at-8.53.39-pm-2.png 1584w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>With value risk looming largest, identifying strategies to quickly assess and mitigate value risk is one of the most important jobs of product teams.</p>



<h2>B2C Painted Door Tests</h2>



<p>B2C brands often use <a href="https://medium.com/@crstanier/a-product-managers-guide-to-painted-door-tests-a1a5de33b473" target="_blank" rel="noreferrer noopener">Painted Door Tests</a> to evaluate interest in a new capability.&nbsp; Painted Door Tests are designed to measure a user’s appetite for a feature without requiring that the feature be built.</p>



<p>For example, let’s imagine that a social network is considering adding a feature that shows which of your friends are discussing a topic a user recently posted about.&nbsp; The social network might add a “See Who’s Talking About This” button and measure the number of clicks the button receives.&nbsp; By adding a placeholder version of the button, the team can begin to assess whether there’s enough interest or value (proxied by clicks) to consider building the new feature without actually having to build out the functionality.&nbsp;&nbsp;</p>



<p>Once a feature passes the initial Painted Door Test, there’s still more work to do in evaluating the feature’s impact. For example, we would probably want to measure whether sessions including the “See Who’s Talking About This” button lead to long-term engagement.&nbsp; Still, the Painted Door Test provides a quick read on user interest.</p>



<div><figure><img loading="lazy" data-attachment-id="137" data-permalink="https://joycegordon.me/see-whos-talking-tchaikovsky/" data-orig-file="https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png" data-orig-size="780,1126" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="see-whos-talking-tchaikovsky" data-image-description="" data-medium-file="https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=208" data-large-file="https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=709" src="https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=709" alt="" width="355" height="512" srcset="https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=355 355w, https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=710 710w, https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=104 104w, https://joycegordonme.files.wordpress.com/2020/09/see-whos-talking-tchaikovsky.png?w=208 208w" sizes="(max-width: 355px) 100vw, 355px"></figure></div>



<h2>Challenges of B2B Painted Door Tests</h2>



<p>For B2B companies, Painted Door Tests are tricky to execute for a couple of reasons:</p>



<ul><li><strong>Smaller user base:</strong> while it’s not uncommon for B2C products to have thousands or millions of active users, B2B brands typically have fewer users.&nbsp; The smaller user base can make it hard to see clear directional results from Painted Door Tests.</li><li><strong>Disruptive to users:</strong> users often depend on B2B software to do their jobs and might be annoyed if they click on an exciting new feature that turns out to be a mirage.</li><li><strong>Draws attention to functionality gaps in the product:</strong> Painted Door Tests in B2B products can draw attention to missing functionality in a product that a user might be paying a high price tag for.&nbsp; This can be especially problematic if the feature offered by a Painted Door Test is not ultimately integrated into the product.</li><li><strong>Greater complexity in measuring business critical outcomes:</strong> In a B2C setting, clicking on a Painted Door feature is a signal that a feature is desired, but it still might not translate into a business critical result, like increased time in an app.&nbsp; The gap between expressing interest and desired long-term behavior is often larger and more complex for B2B products.&nbsp; For example, desired B2B outcomes might include behaviors like setting up a tracking event on a website, increasing ad spend, or setting up a new data feed.&nbsp; Because many of these B2B outcomes are preceded by a series of events that occur within the four walls of the client (budgeting changes, internal approvals, etc), the link between a Painted Door Test and its desired result can be challenging to measure.</li></ul>



<p>With a little creativity, we can take the spirit of rapid validation from Painted Door Tests and apply it to a B2B setting.&nbsp; We’ll quickly create a prototype to get direct customer feedback and measure whether there’s interest in the feature and whether that interest translates to a business critical action.&nbsp;&nbsp;</p>



<h2>Symbiotic Prototyping</h2>



<p>Since Painted Door Tests can draw attention to functionality gaps, potentially create friction for B2B users, and suffer from small sample sizes, any attempt to run these tests in a B2B context must mitigate these obstacles.&nbsp;</p>



<p>Enter <strong>symbiotic prototyping</strong>, a validation technique designed for insights-focused B2B products.</p>



<p>All good relationships need an element of symbiosis, and the relationship between product managers and users is no different.&nbsp; Symbiotic prototyping creates value for the user in the form of business insight and creates value for the product manager by enabling the direct observation of product usage in a complex B2B setting.</p>



<p>During symbiotic prototyping, we take a new product idea, and prototype that idea with client data, resulting in an insight about the client’s business.&nbsp; We share that insight with a user in the course of normal business communication and work with them as they take the insight and turn it into an action.&nbsp;</p>



<p>During this process we’ll receive implicit and explicit feedback from the user.&nbsp; Since the feedback isn’t tied to an existing product feature, and instead is framed as a helpful insight shared in an email, responses are likely to be more candid and the product manager has the opportunity to change directions based on the feedback.</p>



<p>After working through the symbiotic prototyping process, we’ll have a read on whether the insights our potential product surfaces, provide value and drive impact for users.</p>



<p>Here are the steps to get a symbiotic prototype up and running:</p>



<ol><li><strong>Define the target outcome:</strong> what specific metric or action is the potential new product intended to drive?&nbsp;</li><li><strong>Prototype:</strong> the “prototype” is a few sentences sharing the key insight on the client’s business and maybe a graph or two for illustrative purposes.&nbsp; The idea is to move quickly and clearly communicate information to the user, not to think about interactions in the product or to perfect the design. The design will become critical only if the potential product passes the value test.</li><li><strong>Test:</strong> share the prototype with the user, keeping an ear to the ground for questions and feedback, and observe whether the user drives to the target outcome.</li><li><strong>Iterate:</strong> based on both explicit and implicit feedback from the customer, iterate on the prototype and share with a few more users.</li></ol>



<p>Let’s walk through a case study illustrating how we’d apply these four steps in a real world setting.</p>



<h3>The Scenario</h3>



<p>Let’s imagine that our product is an on-site analytics tool.&nbsp; We’re considering adding a feature that highlights the demographics of users contributing to the growth or decline of key actions on the website.&nbsp; We are prototyping the feature for a robo-advisor client.</p>



<h4>Target Outcome</h4>



<p>We’ve observed that the number of A/B tests set up on our on-site analytics platform is a strong indicator of client retention.&nbsp; The key outcome we’re optimizing for is whether the client sets up an A/B test based on the information we provide.</p>



<h4>Prototype</h4>



<p>Looking at the client’s account, we see that the “Increase Deposit” action on the website is an event that they are consistently analyzing and that the event was triggered 15% less frequently this week relative to last week.&nbsp; Furthermore, we notice that 75% of the decline resulted from users aged 25-35.&nbsp;</p>



<h4>Test<em>&nbsp;</em></h4>



<div><figure><img data-attachment-id="147" data-permalink="https://joycegordon.me/painted-door-email-1-3/" data-orig-file="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png" data-orig-size="2130,1728" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="painted-door-email-1-3" data-image-description="" data-medium-file="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=300" data-large-file="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=1024" src="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=1024" alt="" srcset="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=1024 1024w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=2048 2048w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=150 150w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=300 300w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-1-3.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<figure><img data-attachment-id="149" data-permalink="https://joycegordon.me/painted-door-email-2-2/" data-orig-file="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png" data-orig-size="1780,844" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="painted-door-email-2-2" data-image-description="" data-medium-file="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=300" data-large-file="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=1024" src="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=1024" alt="" srcset="https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=1024 1024w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=150 150w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=300 300w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png?w=768 768w, https://joycegordonme.files.wordpress.com/2020/09/painted-door-email-2-2.png 1780w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h4>Iterate</h4>



<p>During the exchange with Carlos, it’s clear that we’ve hit on a meaningful customer pain point (he too is concerned that the “Increase Deposit” event is down) and our product hypothesis of highlighting which customer segments are responsible for the decline in events seems promising. However, Carlos alluded to a couple of potential product improvements:</p>



<ul><li>Highlighting whether the engagement decline from 25-35 year olds was due to fewer users in that age range coming to the website or whether they visited the website but were not engaging with the “Increase Deposit” action.&nbsp;&nbsp;</li><li>Identifying website changes that coincided with the decline in the key event.</li></ul>



<p>Based on Carlos’s feedback, we would reply with the data on session decline for the 25-35 age range and information on other changes that Carlos’ team had recently made to the website.&nbsp;&nbsp;</p>



<p>Most importantly, we would partner closely with Carlos as he root causes and addresses the decline in the “Increase Deposit” event by observing and asking questions to inform our product direction.&nbsp; Here are a couple areas we should pay special attention to:</p>



<ul><li>Does Carlos launch the A/B test?&nbsp; Why or why not?&nbsp; How could we have accelerated Carlos’ ability to launch the test?</li><li>What information is Carlos hoping to understand after launching the A/B test?</li><li>How does Carlos share information on the decline of the “Increase Deposit” event with his colleagues at work?&nbsp; How might we make sharing that information easier?</li><li>What questions does Carlos ask us along the way?</li></ul>



<p>After walking through the symbiotic prototyping process with Carlos, we would take our new and improved prototype based on Carlos’s feedback and repeat this same exercise with a few more customers, integrating their feedback with each cycle.&nbsp;&nbsp;</p>



<p>Once we’ve reached a place where clients consistently launch A/B tests based on the insights we’ve provided, we would move into the product specification and design process.&nbsp; During this phase, we’d determine how to surface the key customer segments driving changes in event frequency within our product, and go through another validation process focused on product usability.</p>



<p>If we aren’t ultimately able to consistently drive towards the A/B outcome, that’s also a success.&nbsp; The ability to quickly toss out product ideas that don’t provide value to the user is the mark of a great product manager.</p>



<hr>



<p>Taking a step back, there are several benefits to the symbiotic prototyping process:</p>



<ul><li><strong>Unbiased feedback:</strong> During the symbiotic prototyping process, …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://joycegordon.me/2020/09/29/symbiotic-prototyping-minimizing-value-risk/">https://joycegordon.me/2020/09/29/symbiotic-prototyping-minimizing-value-risk/</a></em></p>]]>
            </description>
            <link>https://joycegordon.me/2020/09/29/symbiotic-prototyping-minimizing-value-risk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680396</guid>
            <pubDate>Sun, 04 Oct 2020 16:50:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust meets the web – a clash of programming paradigms]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24680215">thread link</a>) | @yannikyeo
<br/>
October 4, 2020 | https://www.jakobmeier.ch/blogging/Rust_on_the_Web.html | <a href="https://web.archive.org/web/*/https://www.jakobmeier.ch/blogging/Rust_on_the_Web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      


<p><span>
  Written on
  
    03/10/2020




  
    Jakob Meier
  
</span>


  <img src="https://www.jakobmeier.ch/assets/img/20/sky.jpg" title="The sky as seen from a immigrant. I took it when I moved to the UK."></p><!-- TODO: Lighter tone or more concise or preferably both -->
<!-- TODO: More fore-shadowing / string it all together with a rotem faden -->



<p>Most code running on the web is event-based, garbage-collected, and dynamically typed.
In stark contrast, Rust is a compiled language with static type- and memory-safety without a garbage-collector.
What are the implications for a project that compiles Rust to WebAssembly?
I try to answer this question with a fictive story and hands-on code examples.
<!-- and I introduce a Rust library which helps to overcome some of the worst obstacles. --></p>

<!-- [Paddlers](https://github.com/jakmeier/paddlers-browser-game) -->

<h2 id="table-of-contents">Table of contents</h2>
<ul id="markdown-toc">
  <li><a href="#overview" id="markdown-toc-overview">Overview</a></li>
  <li><a href="#the-land-of-javascript" id="markdown-toc-the-land-of-javascript">The land of JavaScript</a>    <ul>
      <li><a href="#how-the-browser-was-intended-to-be-used" id="markdown-toc-how-the-browser-was-intended-to-be-used">How the Browser was Intended to be Used</a></li>
      <li><a href="#the-javascript-core-features" id="markdown-toc-the-javascript-core-features">The JavaScript Core Features</a></li>
      <li><a href="#the-javascript-event-loop" id="markdown-toc-the-javascript-event-loop">The JavaScript Event Loop</a></li>
      <li><a href="#race-conditions-not-with-javascript" id="markdown-toc-race-conditions-not-with-javascript">Race conditions? Not with JavaScript!</a></li>
      <li><a href="#clicker-game-example-in-javascript" id="markdown-toc-clicker-game-example-in-javascript">Clicker Game Example in JavaScript</a></li>
    </ul>
  </li>
  <li><a href="#the-land-of-rust" id="markdown-toc-the-land-of-rust">The land of Rust</a>    <ul>
      <li><a href="#lifetimes-and-mrsw" id="markdown-toc-lifetimes-and-mrsw">Lifetimes and MRSW</a></li>
    </ul>
  </li>
  <li><a href="#rust-on-the-web" id="markdown-toc-rust-on-the-web">Rust on the Web</a>    <ul>
      <li><a href="#integer-micro-benchmarks" id="markdown-toc-integer-micro-benchmarks">Integer Micro Benchmarks</a></li>
      <li><a href="#clicker-game-example-in-wasm" id="markdown-toc-clicker-game-example-in-wasm">Clicker Game Example in WASM</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
  <li><a href="#epilogue" id="markdown-toc-epilogue">Epilogue</a></li>
</ul>

<h2 id="overview">Overview</h2>

<p>Today, I tell a tale of a cultural clash.
Programming culture, that is.
The JavaScript culture on one end, and the Rust culture on the other.
<!-- But it is a culture nevertheless. -->
<!-- What do I mean by *programming culture", I hear you ask. -->
<!-- For me, this is a set of programming paradigms that are often used together. -->
<!-- As an example, take object-oriented programming -->
<!-- Some programmers are very attached to their programming language of choice. -->
<!-- Usually, because that language turned out to be very suitable for  --></p>

<p>To lay down the necessary foundation, I start by talking about what makes the two ecosystems unique and different from each other.
This leads to the suggestion that it might be difficult to write idiomatic Rust code that runs in the browser.
I want to find out how viable it is and when it makes sense to use Rust in the browser.</p>

<!-- I sketch a possible solution to the proposed dilemma with some Rust code. -->
<!-- Using these idea, I will alVery briefly, I will introduce a new publish-subscribe library called *Nuts*, which I have been working on in the last months. -->
<!-- A full coverage of the library will follow in the next blog post. -->

<h2 id="the-land-of-javascript">The land of JavaScript</h2>
<h3 id="how-the-browser-was-intended-to-be-used">How the Browser was Intended to be Used</h3>
<!-- I am definitely not an expert on the history of browsers, I was too young to program when browsers first saw the light of day.  -->
<!-- light of day? -->
<!-- But to make a point about the fundamentally different approach of JavaScript compared to Rust, I have to write a little bit about the fundamental design elements of JavaScript as the main programming language for browsers. -->

<p>When browsers have first been created, people were very excited.
Text and images could be placed and styled with dozens of possibilities.
It is a second Gutenberg Revolution, everyone gets access to an infinite amount of information that was previously unreachable. What a great achievement!</p>

<p>Then, those elements became interactive with the addition of a scripting language that can run directly in the browser and modify what is displayed.
Suddenly, the browser looks less like a book on a screen and more like newspapers from Harry Potter.</p>

<!-- Code running in the browser was added as an additional nice-to-have feature. -->
<p>Fast-forward to 2020, browsers are the doorstep to so much more than just animated books.
Everyone uses them for everything.
Be it watching videos of cute cats or managing stock portfolios. It all happens in the browser nowadays.
JavaScript evolved to support all these different use cases.</p>

<!-- To make the transition from 1995 to now, JavaScript had to address several major points.
Back then, programming complex code JavaScript was *cumbersome* and the results in the browser *slow* and *insecure*.
We are blessed that this topic received so much attention by browser developers that, by and large, the issues have been resolved. -->

<h3 id="the-javascript-core-features">The JavaScript Core Features</h3>
<p>The inhabitants of JavaScript land, let us call them <em>JavaScriptler</em> from now on, are very open people.
It is one of their greatest strengths that they cooperate with many other JavaScriptlers.
Communication between them has to be easy and without any road blockers.
This idea is at the heart of JavaScript’s culture.</p>

<p>The downside is that they naively run anyone’s code.
To avoid major damage being inflicted by an adversary JavaScriptler, a code running in JavaScript land had to be limited in what it can do.
We also say it executes in a sandbox within the browser.
While other languages like C or Python communicate directly with the host operating system (OS), JavaScript can only communicate with the browser.</p>

<!-- As a result, modern websites are full of code and there are highly dynamic interactions between DOM elements. -->

<!-- To address the speed problems that come with such a sandbox, just-in-time (JIT) compilers [BOOKMARK TODO] put traditional compilers to shame with their crazy-efficient compilation times and remarkable optimizations at runtime. -->

<p>A huge number of libraries and frameworks in JavaScript land have tried to make programming more accessible and simple.
Their combined power is really what defined modern life in JavaScript land.
Arguably, the sheer number of frameworks made it more complex than it has simplified thing.
But there is always just the basic JavaScript without frameworks as the baseline.
For today, I want to talk only about that fundament of JavaScript and its interactions with the browser.</p>

<p>Memory management is a big differentiator of programming languages.
Any language has to provide means to allocate and release memory but the approach can vary.
In JavaScript, it is all done silently in the background.
And sharing memory between functions and closures could not be simpler, it just works.
This fits very well in the general philosophy of JavaScript land, enabling easy communication.</p>

<p>Simple memory management is enabled by the garbage-collectors, which are a bunch of very busy inhabitants of the land.
They clean up all the leftover memory by fast-paced communication of busy programs that cannot be bothered to tidy up behind themselves.
<!-- Running in an execution environment provided by the browser allows to make design choices like using a garbage-collector. -->
<!-- Natively compiled languages, like Rust, basically have to cope with what ever the hardware and operating system provides them. -->
<!-- The designers of JavaScript have had a bit more freedom here. -->
<!-- Another important choice has been made when the JavaScript event loop has been defined. -->
<!-- -T-O-D-O-: Example of JS with easy data sharing, that will not go well with Rust. --></p>

<p>This should give you an idea of how a JavaScriptler thinks.
But there is one more very important topic to cover, the <em>event loop</em>.
Let me explain what the event loop is in the next section, it will be important in the comparison to Rust.</p>

<h3 id="the-javascript-event-loop">The JavaScript Event Loop</h3>
<!-- and how it Prevents Race Conditions -->
<p>The land of JavaScript is ruled by a thing called <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/EventLoop"><em>the event loop</em></a>, which schedules different tasks (threads) to run orderly.
It defines several rules that all code living in the browser has to obey.
For simple JavaScript programming, it is usually okay not to worry about them.
But then there are also quite basic cases in which it matters a lot.</p>

<p>Below is a JavaScript example with a promise, a timeout of 0 seconds, and some console logging.
If you can tell me with confidence in what order the output appears, you have studied the event loop laws well.</p>

<p><a href="https://jsfiddle.net/2oL4s7km/6/">JS Fiddle</a></p>
<div><div><pre><code><span>// Create promise which resolves after a timeout of 0ms.</span>
<span>// This forces the promise to be enqueue as a new thread in </span>
<span>// the event loop instead of executing immediately in this thread.</span>
<span>// The function within the timeout acts very much like</span>
<span>// a thread in other programming models.</span>
<span>let</span> <span>promise</span> <span>=</span> <span>new</span> <span>Promise</span><span>((</span><span>resolve</span><span>,</span> <span>reject</span><span>)</span> <span>=&gt;</span>
  <span>setTimeout</span><span>(</span>
    <span>()</span> <span>=&gt;</span> <span>{</span>
      <span>console</span><span>.</span><span>log</span><span>(</span><span>"</span><span>[A] Inside Promise</span><span>"</span><span>);</span>
      <span>resolve</span><span>(</span><span>"</span><span>DONE</span><span>"</span><span>);</span>
    <span>}),</span>
  <span>0</span>
<span>);</span>

<span>// Add another message after promise has been resolved.</span>
<span>promise</span><span>.</span><span>then</span><span>(</span>
  <span>result</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>"</span><span>[B] Promise returned: </span><span>"</span><span>,</span> <span>result</span><span>),</span>
  <span>error</span> <span>=&gt;</span> <span>console</span><span>.</span><span>log</span><span>(</span><span>"</span><span>[C] Promise failed: </span><span>"</span><span>,</span> <span>error</span><span>)</span>
<span>);</span>

<span>// Write to the console when this code block finshes executing.</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>"</span><span>[D] End of code</span><span>"</span><span>);</span>

<span>// SOLUTION</span>
<span>// Output order: D, A, B</span>

</code></pre></div></div>

<p>If the output comes as a surprise to you, you should learn about rule number one of the event loop.</p>

<ol>
  <li>Once a thread is running, it runs to completion without interruptions of other threads.</li>
</ol>

<p>In the example above, this means that even though the timeout has been set to be resolved immediately, it has to wait in the queue until the currently running thread is done.
If you have understood this one rule, you know enough about the JavaScript to follow the rest of the article.</p>

<p>But why does this rule exist?
Would it not be more efficient to start executing the second thread of the example immediately?
Especially, considering that virtually all modern consumer devices have multiple cores which could work on the two threads in parallel.
I am glad you asked.</p>

<h3 id="race-conditions-not-with-javascript">Race conditions? Not with JavaScript!</h3>
<p>When the result of some code depends on the order in which the threads access the same data, we call that a <em>race condition</em>.
Sometimes, this is intended and perfectly fine.
But in other cases, the programmer does not even know that there is a race condition, hence not all possible outcomes will be accounted for. In that case, race conditions are bad.</p>

<!-- Complicated bugs may occur only in very specific timing conditions. -->
<!-- This is the kind of bug ticket your typical lazy programmer would just close as *not-reproducible*. -->
<!-- Until it happens when someone important watches, when it suddenly becomes the focus of the entire team for days if not weeks. -->

<p>There are different solutions to avoid the risk of race conditions.
The founders of JavaScript thought about this carefully. 
They came to a drastic conclusion and decided that no concurrency between threads is allowed, for the safety of everybody.</p>

<p>This resolves the race conditions by removing the possibility that multiple threads ever run at the same time.
However, the existence of multiple threads should still be allowed, or otherwise, it would be very annoying to write code.
So they came up with the event loop, which sequentially runs one thread after another without interleaving them.</p>

<h3 id="clicker-game-example-in-javascript">Clicker Game Example in JavaScript</h3>

<p>Here is some example code in JavaScript for a simple clicker game where a player collects apples.</p>



<p>The variables <code>apples</code> and <code>trees</code> in this example are allocated automatically and they are easily accessible from other functions and threads, just like JavaScriptlers are used to.
There is also no race condition here, thanks to the event loop.
Without it, (A) <code>apples -= 1;</code> within the <code>buy()</code> function would have a race condition with (B) <code>apples += trees;</code> in the closure given to <code>setInterval()</code>.</p>

<p>How is it a race condition?
Assume <code>apples</code> is 10 and <code>trees</code> is 5;
In the normally intended timing, after both statements execute, the result should be 14 apples and 6 trees.
But with one possible timing of a multi-core processor, A reads 10 and B reads 10,too before A has a chance to write.
Then A writes 9, which is immediately overwritten by B writing 15, so we end up with 15 apples and 6 trees. (Buying the tree was for free.)
This is possible because <code>+=</code> is not an atomic operation in hardware, it will be compiled into a read, add, and write operation executed sequentially.</p>

<p>Times have changed but the traditions of our ancestors have remained unchallenged within the browser. Most people in JavaScript have probably forgotten about the problem with race conditions because the problem has long been solved for them.
But there are other regions, outside the browser, which have found different solutions to race condition problem.</p>

<!-- ### Asynchronous and Parallel Code in JavaScript
The demonstrated behavior in the previous example is a direct consequence of the concurrency model used in JavaScript.
It has proven itself to be very useful for event-based programming.
For example, when registering two event-listeners on HTML UI elements, the registering code will not be interrupted by the first event being fired. This avoids a lot of tricky cases which are easily forgotten by programmers.

```js
TODO: Example with jQuery initilization
button A: set text to AAA and remove listener on B
button B: set text to BBB and remove listener on A
```

The problem of the model is that multi-core machine (desktops, laptops, phones, ...) cannot easily use all their cores to parallelize the workload because all asynchronous tasks are executed in sequence.
It is of course possible to do parallel programming in JavaScript, but it is a bit more involved.

I think it is fair to say that JavaScript has not initially been designed with parallel programming in mind.
There was simply no reason for it just to manipulate a few hundred DOM nodes.
But the world has moved on from the 90s. Browsers are used for more than just displaying text and static images. Devices use many cores. 
Thus, it is time to enable easier parallel programming. -->

<!-- 
 - JS
    - Portable (Not compiled)
    - JIT for performance (JS magic)
    - Single-threaded with run-to-completion scheduling on the event loop(?)
 - DOM
    - Code mostly just manipulates DOM
 - Events
    - Closures everywhere
    - Many cross references for shared data
 - Garbage collection -->

<h2 id="the-land-of-rust">The land of Rust</h2>
<!-- ### What Rust was Designed for -->
<!-- 
 - Compiled to CPU native assembly
 - Lots of type information to support compile-time optimizations (Rust magic)
 - Memory safety without garbage collection
    - Compiler needs to know a lot about memory usage
    - Data sharing avoided as much as possible
    - single root of execution tree
 - Multi-threading built into the language/std -->
<!-- Ah, where should I even start with Rust. -->
<!-- I am definitely a bit of a fanboy for the language but I will try to stay factual. -->

<p><img src="https://www.jakobmeier.ch/assets/img/20/private_drive.jpg" alt="Image: A private road with a friendly sign."></p>

<p>A Rust citizen, also known as Rustacean, is very picky about its program code, as opposed to the openness found in JavaScriptlers.
All programs have to be scanned by the compiler and nothing is executed before all checks are done.</p>

<p>And rules to get in Rust land are very strict indeed.
Trying to smuggle through an ordinary <code>7</code> as an <code>f32</code>?
Nope, the <code>7</code> only qualifies for integers, you would have to use <code>7.0</code> instead.
That type of narrow thinking is very typical in Rust land.
<!-- Everything has to be compiled completely into native instructions.
compiles it code to native instructions  with a strong type system.
Zero cost abstractions allow for high-level concepts to be compiled into native binary code that requires no dedicated runtime environment. --></p>

<p>Many of the early Rustaceans are refugees from C++, which is one of the countries impacted the hardest by race conditions.
It is therefore deeply engraved into Rustaceans that they want to prevent any future race condition disasters.
But they are used to build very performance-oriented stuff for a living.
Operating systems, numerical libraries, and world simulations are daily business for a Rustacean.</p>

<p>Naturally, they depend a lot on the benefits of multi-processors. They cannot do without.
The single-threaded approach as seen in JavaScript is not an option in Rust land.</p>

<h3 id="lifetimes-and-mrsw">Lifetimes and MRSW</h3>
<p>The founders …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jakobmeier.ch/blogging/Rust_on_the_Web.html">https://www.jakobmeier.ch/blogging/Rust_on_the_Web.html</a></em></p>]]>
            </description>
            <link>https://www.jakobmeier.ch/blogging/Rust_on_the_Web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680215</guid>
            <pubDate>Sun, 04 Oct 2020 16:30:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I left my tenured academic job]]>
            </title>
            <description>
<![CDATA[
Score 345 | Comments 192 (<a href="https://news.ycombinator.com/item?id=24680154">thread link</a>) | @adamnemecek
<br/>
October 4, 2020 | https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/ | <a href="https://web.archive.org/web/*/https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time datetime="2020-10-03T09:00:00+0200">Sat, Oct 3, 2020</time></p>

    <p>RSS: </p> <p><a href="https://reyammer.io/blog/index.xml"><img src="https://reyammer.io/rss.png" width="23px"></a></p>

  <p>The <a href="https://twitter.com/reyammer/status/1311338230139232258" target="_blank">news is out</a>: I left France, I'm no longer a professor at EURECOM, I joined the Malware Research Team at CISCO Talos, and I moved to beautiful Vienna. Big change :-)</p>
<p>I have been a professor for a bit more than three years, but I have had contrasting feelings about the "prof job" for a long time (even before finishing my PhD), it took me a couple of years to realize that I would eventually have needed to move on, and it took even more (mental) effort to actually make the call and leave. Despite being <em>very</em> excited for what's next, oh boy, this was tough :-) But independently of the concrete next step, it was time to move on. Even if Talos realizes the mistake and kicks me out next week, I'm still confident that moving on was the right call.</p>
<p>Especially when it comes to take big decisions, I tend to obsess about trying to stay rational, and I spent years collecting notes on the various pros/cons. Many of these thoughts often started surfacing as "feeling something is not right", without consciously understanding what was going on. But by keep thinking and writing notes down, patterns of thoughts started to emerge and I was eventually able to pinpoint some more defined thoughts on what kept me on the current job and what pushed me to change. Once these reasons were clear, it was much easier to take the decision.</p>
<p>This is a very long blog post, and I don't expect more than a very few people to actually read it. I wrote it mostly for selfish reasons: before changing to a new life, I wanted to wrap up all these notes in something more structured. I can't be certain I took a good decision, but systematizing these thoughts allowed me to move on with enough confidence to know I'm likely making a step forward.</p>
<p>With that being said, I know that someone may be actually interested in hearing these thoughts and my experience. When I was a PhD student and I needed to take the notorious academia vs. industry decision, I would have paid big bucks to read more thoughts on the various pros/cons. One of the stupidest things you can do is to take big decisions based on what other people do and think, but reading about other people's thought process has helped me a lot. It is time I do my part.</p>
<p>The target audience for this post is, other than myself, PhD students / postdocs that are about to decide what to do next and junior profs that somehow feel that "something is wrong". I also expect some senior academics and industry people to read this post, but I guess they will find themselves skipping directly to the academic rant part and mostly agree with much I have to say :-) Anyways, I tried to stay away from the "very known things" (e.g., 👀-level BS when writing proposals, generally "more limited" immediate impact of your work, different compensation level, etc.), and I tried to focus on thoughts I have not seen much discussed around (at least not in this depth).</p>
<p>So, if you feel clueless and you want to hear more from an equivalently clueless random dude on the Internet, here we are :-) If you think this is <em>the</em> blog post that will make everything clear, I have a bad news for you: it's all about tradeoffs and in my opinion there is no clear-cut winner. And, unfortunately, the problem with tradeoffs and balancing many aspects is that figuring out which one to weigh more is yet another very personal decision in its own way. So, you will not find any answer in this post and you will eventually need to figure this thing out on your own, but I hope this will help you forming your own opinion.</p>
<p>This post is organized in three parts:</p>
<ul>
<li><a href="#part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good — What pushed me to keep the job</a></li>
<li><a href="#part-2-the-bad-mdash-what-pushed-me-to-leave-the-job">Part 2: The Bad — What pushed me to leave the job</a></li>
<li><a href="#part-3-the-bye-bye-mdash-the-decision-to-leave">Part 3: The Bye Bye — The decision to leave</a></li>
</ul>
<p>Enjoy!</p>
<p><em>Mandatory disclaimer: I have no idea what I'm talking about, and these are personal takes/opinions anyways. Unless you are a bad person, please don't take anything personal. Please feel free to reach out, ping me on twitter, or shoot me an email: I'm of course happy to share more thoughts if you have any question. And if you disagree with something, bring it on! I love to argue, especially with people with strong and different opinions :-)</em></p>
<br>
<h2 id="part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good — What pushed me to keep the job</h2>
<p>Before I discuss why I left, I want to touch on what pushed me to keep the job. I want to make sure it's a balanced post despite the upcoming mega rant, so that my overall opinion is more closely reflected. And I really don't want to discourage anyone to take this path, I still think it is a great one.</p>
<p>Note that some of my "reasons to stay" are good, but some are bad. Also note that many of these refer to my personal situation at EURECOM, working in the field of systems security, and not all these points can be generalized to all universities. As they say, your mileage may vary.</p>
<h3 id="its-a-very-good-job">It's a very good job</h3>
<p>The first pros is... 🥁: "it's a very good job". At first, I was shocked to find out that it's an actual job. When I joined this prof thingy I thought that this would be a "job" (note the double quotes). But, while it's true that you don't have a direct boss that tells you what to do, at the end of the day you need to deliver, and you actually work very hard: If your PhD students are in trouble or you teaching sucks, you will run into problems. This doesn't necessarily mean "they kick out", but if you value being a professional (and I do), failing at your core tasks will make you feel bad, even without additional pressure from your superior, and even if you have tenure.</p>
<p>And now that we got this "it's an actual job" out of the way, I can tell you: it's a very good one. There is <em>a lot</em> of freedom in what you do and how you structure your time. Research-wise I felt very free (but you eventually work on what your students like to work on — as it should be), and the department values the right things (I've heard some BS in other schools where, in the context of systems security research, they pressure you to "publish more journal papers..." 🤦‍♂️). I really like teaching and mentoring, and there were many opportunities to do so. They let me create and teach my own class on mobile security, <a href="https://mobisec.reyammer.io/" target="_blank">MOBISEC</a>, and the teaching load is overall very low (1 or 1.5 classes per year). I love playing CTFs and I was even <em>encouraged</em> to spend time and push for NOPS, the EURECOM CTF team (after winning <a href="https://ctftime.org/event/647" target="_blank">HXP CTF 2018</a> and after being referred to as "<a href="https://youtu.be/j0taw78tCYs?t=968" target="_blank">probably a top team</a>" we are mostly enjoying our eternal and well-deserved glory).</p>
<p>The environment is extremely relaxed, informal, and friendly. You are surrounded by top-skilled colleagues and humans, from MS students to profs. I felt in a family from day 1. Last very good point: since in France positions come with tenure, there were not even problems in terms of pre-tenure stress, a real luxury. And on this aspect, EURECOM delivered: I never felt any sort of pressure (but: I did work my ass off... so if you stop doing anything, bad things may happen :-)).</p>
<p>[BTW, EURECOM is frantically trying to replace me, you should apply :-)]</p>
<h3 id="you-are-surrounded-by-students">You are surrounded by students</h3>
<p>When I took my decision to remain in academia, my top reason was for teaching and mentorship. Probably the best perk of the job is that you are surrounded by people eager to learn, from MS to PhD students to postdocs. It is extremely fulfilling and rewarding. Working with my students has been the highlight of my time at EURECOM, from traditional teaching, to suffering through the various rejections, to celebrating defeats of Reviewer #2, to cluelessly getting CTF-close in many stego CTF challenges. I feel very lucky that during these years we found enough interesting ideas that we enjoyed working on together, and that my next job will allow me to keep advising them until they graduate. As a prof, I believe the net output of my work is to see students becoming independent researchers, not the actual papers — I can't wait to see the bright careers I'm sure they will have :-)</p>
<h3 id="i-have-deep-respect-for-the-role-of-profs-in-society-and-it-felt-great-to-be-one">I have deep respect for the role of "profs" in society, and it felt great to be one</h3>
<p>I somehow have a profound admiration for the role that professors have in society and that had in my life. For their hard work, knowledge, passion, patience, and ultimately their service to the community. I'm referring to all teachers and mentors (from elementary schools to universities), who spend their life helping others, while at the same time often being asked to do many useless things and being massively underpaid. I admire and deeply respect these efforts: my most sincere thank you to all past, present, and future profs!</p>
<p>And, to be frank, it felt great to be one. I have been in love with the idea of being a prof for many years. In part, I think it is because some of the people who impacted me the most are professors, and I wanted to do my part in helping others. And after all the uncertainties that one has during a PhD, I think I was even more in love with the idea of having finally found my place in society. [Narrator: LOL, this clueless dude did not find his place. [Answer to narrator: But I've surely found it <em>now</em>!!1!]]</p>
<p>Overcoming all these positive emotions and feelings attached to this job was likely the biggest challenge I faced in coming to terms with the several problems and cons I did have during these three years. As mentioned, I have no intention to give up on this teaching/mentoring thing (taking the time for this long blog post is part of this!), but it will surely not be the same thing. I'm very grateful I had a chance to try this job out. Thanks to all who made it possible, from family to advisors, colleagues, and students ❤️. I owe you big time.</p>
<p>[Of course, being a prof does not necessarily make you a smart or great person. Some profs I know are some of the dumbest people I have ever met (by far) and they would not survive one day in the real world. And some profs I know are the most asshole, selfish, egomaniac, and delusional humans I have ever heard of (Are you pushing your students to stay in the lab …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</a></em></p>]]>
            </description>
            <link>https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680154</guid>
            <pubDate>Sun, 04 Oct 2020 16:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running a Unix-like OS on a home-built CPU with a home-built C compiler]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24680109">thread link</a>) | @abc_tkys
<br/>
October 4, 2020 | https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/ | <a href="https://web.archive.org/web/*/https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <p>It’s been two years since I started working as a software engineer.
I sometimes tell my colleagues about a student project I did in my junior year of university,
and it’s so well-received that I’m writing this post.
<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Now, let me ask you a question. Have you ever designed your own ISA, built a processor of that ISA on FPGA, and built a compiler for it?
Furthermore, have you run an operating system on that processor?
Actually, we have.</p>
<p>In this post, I’m going to talk about my undergraduate days in 2015,
our four months of building a home-built CPU of a home-built RISC ISA,
building a home-built C toolchain, and porting Xv6, a Unix-like OS, to that CPU.</p>
<h2 id="cpu-experiment-at-the-university-of-tokyo">CPU Experiment at the University of Tokyo</h2>
<p>It was all done as a student experiment project called CPU Experiment.
So, let’s start with what is CPU experiment.</p>
<p>CPU experiment is a little famous exercise held in the winter of the junior year in my department,
the Department of Information Science at the University of Tokyo.
In the experiment, students are divided into groups of four or five students.
Each group designs an own CPU architecture, implements it on an FPGA,
builds an OCaml subset compiler for that CPU, and then runs a given ray-tracing program on the CPU.
Typically, one or two people are responsible for each of the CPU, FPU, CPU simulator and compiler.
I was in charge of the CPU in my group, Group 6.</p>
<p>This exercise is well known for the high expectation of self learning.
The instructor only asks the students to “take this ray-tracing program written in OCaml and run it on your CPU implemented on an FPGA”, and the class ends.
He/she doesn’t tell much about the concrete steps of how to write CPU and compilers.
The students learn for themselves how to embody the general knowledge of CPUs and compilers learned in previous lectures to the level of real circuits and code.
Well, this is a very tough exercise, but very exciting and educational.</p>
<h2 id="lets-run-operating-system-on-our-own-cpu">Let’s run Operating System on our own CPU.</h2>
<p>As some of you may have noticed, I didn’t talk about operating system at all.
I’ll add a little explanation.</p>
<p>Typically, the experiment proceeds as follows.
First, you make a CPU that works reliably, no matter how slow it is.
If you can make a working CPU and successfully run the ray-tracing program, you can earn the credit of the experiment.
After that, your team has a free time.
The traditional way to spend this free time is to further speed up their CPU.
In past experiments, students have made out-of-order CPU, VLIEW CPU, multi-core CPU, or even superscalar CPU, which is amazing.</p>
<p>However, some teams put more energy into doing fun such as running games or playing music by connecting a speaker with their CPU.
Group 6, to which I belonged, was a group of such people who loved entertainment,
and we decided to run an OS as our team goal.</p>
<p>As a result of other groups showing interest in this idea, a joint group of about 8 people, Group X,
was formed, and their goal was “Let’s run an OS on our own CPU!”</p>
<p>Although I was in charge of creating a CPU in Group 6,
this time I chose to be the leader of the OS team in the Group X.
So this post is written primarily from the perspective of the OS team,
but of course I also introduce the overall group’s results.</p>
<h2 id="xv6">Xv6</h2>
<p>As the OS to be ported, we chose Xv6, a simple Unix v6-inspired OS created by MIT for educational purposes.
Xv6 is written in ANSI C, unlike Unix v6, and it runs on x86.
Xv6 is an educational OS, so its features are a bit poor, but it has sufficient features as a simple Unix-like OS.
You can find more information of Xv6 on <a href="https://en.wikipedia.org/wiki/Xv6" target="_blank">Wikipedia</a>

 or <a href="https://github.com/mit-pdos/xv6-public" target="_blank">the GitHub repository</a>

.</p>
<h2 id="challenges">Challenges</h2>
<p>In porting xv6, there are a lot of challenges on the software side alone because we were trying to create everything from scratch.</p>
<p><strong>1. C Compiler and tool chain for Xv6</strong></p>
<p>In the CPU experiment, we usually create an ML compiler. Naturally, you can’t compile C codes of Xv6.</p>
<p><strong>2. What kind of CPU features required for operating system?</strong></p>
<p>Privilege protections? Virtual address? Interrupt?
Yes, we had overall understanding of what operating system does by lectures,
but we didn’t have solid enough understanding to explain what specific CPU features could make that happen at that time.</p>
<p><strong>3. What about the simulator?</strong></p>
<p>We had a simulator made in the core part of CPU experiment,
but it was a simple one that executes one instruction by instruction,
and there was no interruption or no virtual address conversion.</p>
<p><strong>4. Low portability of xv6</strong></p>
<p>Xv6 was not very portable.
For example, it assumes the <code>char</code> is 1 byte and <code>int</code> is 4 bytes, and manipulates the stack heavily.
Well, the name “Xv6” I guess comes from x86 and Unix “v6”, so it’s kind of natural.</p>
<p>We had a lot of concerns, but started the Group X’s OS porting project in December.<br>
From here I’m going to write about what we did in roughly chronological order.
It’s a little bit long, so if you want to look at our final products quickly, <a href="#march---xv6-runs">please jump to March</a>

.</p>
<h2 id="late-november---starting-the-compiler">Late November - Starting the compiler</h2>
<p>The first problem that we saw the answer to was the compiler and tool chain.
To be surprise, our decision was to build the C89 compiler from scratch.
To be honest, I hadn’t imagined that we would choose this way.
I remember I talked with Yuichi, who became in charge of CPU of Group X, about doing a gcc or llvm port at first.</p>
<p>However, one of the team members, Keiichi, suddenly said he had written a C compiler and showed us a prototype of a compiler with a simple parser and emitter.
It seemed more fun to write the toolchain from scratch, so we decided to write a compiler by ourselves.</p>
<p>Yuichi and Wataru from Group 3, who had already finished the core part of the experiment that year, joined Keiichi, and the Group X compiler team was born.
We later named our compiler Ucc.</p>
<h2 id="mid-december---the-os-team-is-up">Mid-December - The OS team is up!</h2>
<p>At the beginning of December, I completed my CPU, and Group 6 completed the core part of the CPU experiment.
So, we moved on to the fun part, Group X’s OS porting task.
At this time, myself and Shohei from Group 6 started working in Group X and became the OS team. Masayoshi joined it at the same time.</p>
<h3 id="core-part-of-the-experiment-writing-a-cpu">Core part of the experiment: Writing a CPU</h3>
<p>By the way, I guess not so many software engineers have ever written a CPU, so let me talk a little bit about making a CPU as well.</p>
<p>Nowadays, making a CPU doesn’t mean wiring every single jump wire on a breadboard; you write the circuitry in Hardware Description Language.
Then you synthesize that HDL into a real circuit using Vivado or Quartus.
This process is called logic synthesis, not compilation.</p>
<p>HDL and programming language are similar but different.
Think of it like writing a function that maps the signal state of registers to another signal state, triggered by a clock or input signal.
If you want to experience real reactive programming, I suggest you try writing an HDL.
Please also remember to write HDLs, always worrying about whether the signal propagation of the HDLs you write really ends up in one clock.
Otherwise, the behavior of your circuits would be incomprehensible to humans.</p>
<!-- You'd write a CPU state machine that decodes the machine instructions each time the clock rises, and then performs ALUs and branches accordingly, and updating the state of the exposed registers as an interface to the assembly. -->
<p>The hardest part of the actual development was that this logic synthesis took a ridiculous amount of time.
It was not uncommon for us to have to wait up to 30 minutes after starting the synthesis,
so once I started the synthesis,
I was often playing Smash Bros. Melee with the other CPU guys who were also waiting for the synthesis to finish.
FYI, my character was Sheik.</p>
<h2 id="late-december-to-mid-january---learn-by-porting-xv6-to-mips">Late December to mid-January - Learn by porting Xv6 to MIPS</h2>
<p>We began to find the answer to “What kind of CPU features required for operating system?”</p>
<p>After the OS team was born, we started weekly rounds of Xv6 source code reading.</p>
<p>At the same time, I started porting Xv6 to MIPS.
This was partly to learn how an OS works at the implementation level, and partly because there appeared to be no Xv6 port to MIPS.
I completed the port until the process scheduler started in about a week.
I did a lot of research on MIPS during this porting process,
and on x86 to understand how xv6 works.
Thanks to that, I understood mechanisms around interrupts and MMU at the implementation level.
At this stage I got a solid understanding of the CPU functionality required for Xv6.</p>
<p>Also, in mid-January, we worked hard to compile the entire Xv6 code by commenting out the various parts.
As a result, Xv6 on the simulator of our homebrew architecture showed the first message of the boot sequence,</p>
<pre><code>xv6...
cpu0: starting...
</code></pre><p>At the same time, this meant that by this time Ucc had already grown enough to compile most of xv6, which was awesome.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<h2 id="february---our-cpu-gaia-was-born">February - our CPU, GAIA was born!</h2>
<p>In the MIPS port, I completed the initialization of the PIC, which was a real pain,
and also completed the implementation of the interrupt handler.
As a result, the porting of Xv6 to MIPS was completed until just before the first user program started.</p>
<p>Based on this experience, I made the draft specifications of the interrupt and virtual address translation for our homebrew CPU.
In order to keep it simple, we decided to omit hardware privilege mechanisms like Ring protection.
For virtual address translation, we decided to use a hardware page-walking method, just like x86.
It may seem difficult to implement in hardware, but we thought it was cheaper if we sacrificed the speed and omit TLB implementation.
After all, Yuichi made an excellent CPU core later, and it installed TLB from the beginning though.</p>
<p>Yuichi completed the overall design of the ISA of our CPU.
He named our CPU GAIA.
In typical CPU experiment projects, we don’t implement interrupt nor MMU.
However, Yuichi started to implement them for Xv6, based on the refactored version of the CPU of Group 3.</p>
<p>I’ll note the weekly records as the rapid progress begins from then on!</p>
<h2 id="1st-week">1st Week</h2>
<p>Instead of just commenting boot sequences out, Masayoshi started implementing actual initialization of our CPU,
and Shohei rewrote the x86 assembly of Xv6 into our homebrew architecture’s.
I added interrupt simulation capability to our simulator which Wataru had made …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/">https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/</a></em></p>]]>
            </description>
            <link>https://fuel.edby.coffee/posts/how-we-ported-xv6-os-to-a-home-built-cpu-with-a-home-built-c-compiler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680109</guid>
            <pubDate>Sun, 04 Oct 2020 16:17:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Restoring Democracy – A Thought Experiment]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24680059">thread link</a>) | @reimbar
<br/>
October 4, 2020 | https://lashoun.com/learning/restoring-democracy-a-thought-experiment/ | <a href="https://web.archive.org/web/*/https://lashoun.com/learning/restoring-democracy-a-thought-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article lang="en">
  

  
  

  <div>
  
<p>In recent years, democratic governments have had their fair share of troubles. The US presidential election of 2016 was probably one of the most shameful and toxic political events to date, with both Democrats and Republicans verbally abusing each other on social media. In France, the 2017 presidential election saw the fall of the major parties (LR and PS) and the rise of the nationalist party led by Marine Le Pen and a newly-born unaffiliated movement created by Emmanuel Macron: La République en Marche, and, in late 2018, the Yellow Vests protests broke out and outlasted even the protest of May 1968. Many more examples could be cited, such as Brexit, Viktor Orban’s erosion of the rule of law in Hungaria, Jair Bolsonaro’s election in Brazil, the Hong Kong protests, and many more. Worldwide, democracies seem to be crumbling: how can we restore and reassert their legitimacy? We will not be so bold as to declare we have found a silver bullet to the rise of authoritarian regimes, but we will nevertheless try and suggest promising ideas.</p>

<p>First of all, if we are to overhaul the building blocks of our democracies, we must gain fundamental understanding of how politics work. Why do some countries take the authoritarian road while other ones become hosts to governments with free elections?</p>
<h2 id="the-rules-for-rulers">The Rules for Rulers</h2>
<p>The power of a king is not to act but to <strong>get others to act for him</strong>, often through the help of money. In dictatorships, three rules prevail: dictators must get the key supporters - that is, the people who have financial or military power - on their side, and they must control the treasure and buy the key supporters’ loyalty. Then, they have to minimize the number of key supporters, since key supporters needed to gain power are not the same as the ones needed to maintain it.</p>
<p>In democracies, <strong>power is fractured and earned with words</strong>, not violence. Citizens are divided into blocks which politicians can reward as groups. For instance, farming subsidies have no correlation with how much food a country needs, but instead with how much influence farmers have on elections. That’s why populists sometimes manage to garner substantial support despite being disliked by a large part of the population: they cater to a specific subset of the voters which is receptive to their shenanigans. For instance, Donald Trump’s target is mainly the rural, white and low-educated American population.</p>
<p>The main difference between both cases is that <strong>dictators have no need to please the crowds</strong>, especially when the nation’s wealth comes from natural resources (minerals, oil…). On the contrary, <strong>elected representatives need productivity</strong> to increase treasury and therefore to increase the money they can give to their keys, hence they create hospitals, universities… Representatives generally last longer than dictators because their goals are generally more aligned with those of the population. When a dictator is replaced by the people, it is because their keys let the people do so. The people never replace the ruler: the court does. That’s why the following ruler is generally even worse, because they need to keep the keys’ loyalty. In stable democracies, aspiring dictators struggle to gain support because the potential key supporters, more educated, have to weigh the probabilities of making it through the revolt. The more the wealth of a nation comes from the productivity of the citizens, the more the rulers have to redistribute that wealth to the citizens. Democracies typically fall when the treasure becomes empty or when natural resources which dwarf citizen’s productivity are discovered.</p>
<p>Therefore, we will reduce the scope of our reasoning to states which are already democratic, that is most of the Western world. It would be a pipe dream to imagine being able to turn China or Saudi Arabia into a democracy as of today. However, we may reasonably gather ideas which would improve existing democratic systems.</p>
<h2 id="de-mesquitas-principle">De Mesquita’s Principle</h2>
<p>Bruce Bruno de Mesquita offers a very insightful take on politics. According to him, all politicians follow a very basic desire which consists in only two things: to <strong>get hold of power</strong> and to <strong>keep it</strong>. A politician is not “good” or “evil” per se: they will make different choices based on the incentives provided by their environment. From this fundamental principle, many other principles can be deduced:</p>
<ul>
<li>Corollary 1: what a politician really thinks is irrelevant. What matters to them are the other politicians, lobbies and voters they owe.</li>
<li>Corollary 2: merit and responsibility are bad predictors of politics.</li>
<li>Corollary 3: politicians are not stupid. Otherwise, they wouldn’t have won at the game of politics.</li>
<li>Corollary 4: to be “right” is irrelevant in politics. What matters is to get the support of the population.</li>
<li>Corollary 5: it is extremely difficult to introduce new ideas in politics because voters and other politicians will most likely not heed them.</li>
<li>Corollary 6: voters should not vote for ideals or individuals; they should take into account the incentives that will be provided to the different political parties and vote for the political party that will receive the incentives most aligned with their own values.</li>
</ul>
<p>A very natural question follows from those rules: how do politicians attain power? Through <strong>elections</strong>. Let us then examine the current ballot systems of Western democracies.</p>

<h2 id="the-current-distribution-of-voting-systems">The Current Distribution of Voting Systems</h2>
<p>Voting systems can be divided in three main categories:</p>
<ul>
<li><strong>Plurality systems</strong> are systems in which the candidate(s) with the highest number of votes wins, with no requirement to get a majority of votes, such as the US first-past-the-post ballot.</li>
<li><strong>Majoritarian systems</strong> are systems in which candidates have to receive a majority of the votes to be elected, although in some cases only a plurality is required in the last round of counting if no candidate can achieve a majority, such as instant-runoff voting (Australia) or two-round systems (France).</li>
<li><strong>Proportional systems</strong> are systems in which divisions in an electorate are reflected proportionately in the elected body. Party-list proportional representation is the single most common electoral system for national legislatures, being used by 80 countries, and involves voters voting for a list of candidates proposed by a party.</li>
</ul>
<p>The most common system used for presidential elections around the world is the <strong>two-round system</strong>, being used in 88 countries.</p>
<figure>
    
        <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Electoral_systems_for_heads_of_state_map.svg/1280px-Electoral_systems_for_heads_of_state_map.svg.png">
    
    
</figure>

<p><span data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">&nbsp;&nbsp;&nbsp;</span>&nbsp;<a href="https://en.wikipedia.org/wiki/First-past-the-post_voting">First past the post</a> (FPTP)<br>
<span data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">&nbsp;&nbsp;&nbsp;</span>&nbsp;<a href="https://en.wikipedia.org/wiki/Two-round_system">Two-round system</a> (TRS)<br>
<span data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">&nbsp;&nbsp;&nbsp;</span>&nbsp;<a href="https://en.wikipedia.org/wiki/Instant-runoff_voting">Instant-runoff voting</a> (IRV)<br>
<span data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">&nbsp;&nbsp;&nbsp;</span>&nbsp;Election by legislature<br>
<span data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">&nbsp;&nbsp;&nbsp;</span>&nbsp;Election by electoral college or local legislatures<br>
<span data-darkreader-inline-bgcolor="" data-darkreader-inline-color="">&nbsp;&nbsp;&nbsp;</span>&nbsp;No direct election</p>
<h2 id="ballot-properties-and-theorems">Ballot Properties and Theorems</h2>
<p>Unbeknownst to most voters, the single most important factor in election results is, in fact, the choice of the ballot. However, it so happens that two of the most used voting systems - the first-past-the-post and two-round systems - are arguably flawed ballots, at least more so than others. Indeed, they are <strong>dependent on irrelevant alternatives</strong>, which is an intuitively bad mathematical property, as opposed to independence from irrelevant alternatives which is defined as such: if one candidate (X) would win an election, and if a new candidate (Y) were added to the ballot, then either X or Y would win the election. Independence from irrelevant alternatives is an intuitively reasonable assumption, but both systems do not have that property. A good example of dependence on irrelevant alternatives is illustrated by this example:</p>
<blockquote>
<p>After finishing dinner, Sidney Morgenbesser decides to order dessert. The waitress tells him he has two choices: apple pie and blueberry pie. Sidney orders the apple pie. After a few minutes the waitress returns and says that they also have cherry pie at which point Morgenbesser says “In that case I’ll have the blueberry pie.”</p>
</blockquote>
<p>They are also exposed to the <strong>tactical voting dilemma</strong>: voters support another candidate more strongly than their sincere preference in order to prevent an undesirable outcome. This is partly what happened in the 2017 French presidential election: many voters chose either Mr. Macron or Ms. Le Pen during the first round rather than another candidate which had fewer chances to win.</p>
<p>Mathematicians have in fact devised theorems which put strict boundaries on what we can expect from a ballot:</p>
<ul>
<li><strong>Arrow’s impossibility theorem</strong>: no rank-order electoral system can be designed that always satisfies these three “fairness” criteria:
<ul>
<li>If every voter prefers alternative X over alternative Y, then the group prefers X over Y.</li>
<li>If every voter’s preference between X and Y remains unchanged, then the group’s preference between X and Y will also remain unchanged (even if voters' preferences between other pairs like X and Z, Y and Z, or Z and W change).</li>
<li>There is no “dictator”: no single voter possesses the power to always determine the group’s preference.</li>
</ul>
</li>
</ul>
<p>In summary, Arrow’s theorem states that when voters have three or more distinct alternatives (options), <strong>no ranked voting electoral system can convert the ranked preferences of individuals into a community-wide (complete and transitive) ranking</strong>.</p>
<ul>
<li>
<p><strong>Gibbard-Satterthwaite theorem</strong>: for every voting rule, one of the following three things must hold:</p>
<ul>
<li>The rule is dictatorial, i.e. there exists a distinguished voter who can choose the winner; or</li>
<li>The rule limits the possible outcomes to two alternatives only; or</li>
<li>The rule is <strong>susceptible to tactical voting</strong>: in certain conditions some voter’s sincere ballot may not defend their opinion best.</li>
</ul>
</li>
<li>
<p><strong>Gibbard’s 1977 theorem</strong> is an extension of the previous theorem when including random strategies. The only voting scheme which satisfies anonymity, unanimity and is strategy-proof is a random dictatorship.</p>
</li>
</ul>
<h2 id="the-randomized-condorcet-method">The Randomized Condorcet Method</h2>
<p>Although the aforementioned theorems guarantee that a perfect ballot doesn’t exist, it is possible to build a ballot which exhibits better properties than the first-past-the-post and two-round systems. We will here advocate for the <strong>random…</strong></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lashoun.com/learning/restoring-democracy-a-thought-experiment/">https://lashoun.com/learning/restoring-democracy-a-thought-experiment/</a></em></p>]]>
            </description>
            <link>https://lashoun.com/learning/restoring-democracy-a-thought-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24680059</guid>
            <pubDate>Sun, 04 Oct 2020 16:11:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Ek- The Observer Effect]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24679924">thread link</a>) | @ankitkumar98
<br/>
October 4, 2020 | https://www.theobservereffect.org/daniel.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/daniel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the second interview on 'The Observer Effect'. We are lucky to have one
									of the most influential founders/CEOs in technology and media - Daniel Ek, Founder
									and CEO of Spotify. This interview was published on 4th October, 2020.

							</em></p><p><em>Daniel does things very differently from other business leaders and was generous to go
								deep with us on his leadership style, time management, decision making, Spotify's impact
								on the world and much, much more. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let’s start with the basics. Walk me through a typical day in the life of
										Daniel Ek.</strong></em>
							</p><p><strong>Daniel Ek</strong><br>
								So, this will sound incredibly lazy compared to some leaders. I wake up at around 6:30
								in the morning and spend some time with my kids and wife. At 7:30, I go work out. At
								8:30, I go for a walk – even in the winter. I’ve found this is often where I do my best
								thinking. At 9:30, I read for thirty minutes to an hour. Sometimes I read the news, but
								you’ll also find an ever-rotating stack of books in my office, next to my bed, on tables
								around the house. Books on history, leadership, biographies. It’s a pretty eclectic mix
								– much like my taste in music. Finally, my “work” day really starts at 10:30.
							</p><p>
								Many people make big decisions early on in the day, I make them later in the day--at
								least later in the day here in Europe. Ironically, it's not actually because I'm more
								productive then, rather because we have so many of our staff in the US, and as a result,
								I've kind of primed myself to work that way.
							</p><p>
								So the earlier part of my day is focused on coaching, one-on-ones, and planning. Then, I
								typically tackle one topic a day which takes a lot of my time. That's my big thing for
								the day. Before we go into a live team discussion on that particular topic, I invest
								time to prepare beforehand – reading and talking to members of the team who are either
								part of the decision-making process or who have insights and context. I sometimes even
								get external perspectives.
							</p><p>
								I also think about what my role is at that meeting. Sometimes I'm the approver. Other
								times, I'm supposed to come with a thoughtful perspective on whether an initiative makes
								sense or not.
							</p><p>
								I’ve found that creating this clarity of role for myself is critical. It’s something I
								challenge my direct reports to think about as they engage with their own teams. I remind
								them that all meetings are not the same. Even when we are meeting to discuss really,
								really complicated topics I always ask myself: “What am I going to do in this meeting?
								What does my involvement really need to be?”
							</p><p>
								The truth is: it's entirely contextual. I find it crucial to be upfront about everyone’s
								role in different meetings, I think this is super, super important. Often that's my
								number one thing: to make sure I know what role I'm playing.</p><p>
								<b><i>Wow, okay, there are multiple things in there ranging from how you choose to spend
										your time to how you handle meetings. To work backwards, what makes a good
										meeting in your mind?
									</i></b></p><p>A great meeting has three key elements: the desired outcome of the meeting is clear ahead
								of time; the various options are clear, ideally ahead of time; and the roles of the
								participants are clear at the time.
							</p><p>
								I often find that meetings lack one of those elements. Sometimes they lack all those,
								which is when you have to say, “This is a horrible meeting, let's end it and regroup so
								it can be more effective for everyone.”
							</p><p>
								To clarify outcomes, options, and roles ahead of time, we sometimes rely upon a preread.
								Prereads are a great way to share context so that attendees can quickly get into the
								meat of the issue and not waste time getting everyone up to speed. What I find is when
								you use a tool like a Google Doc, you can take in a great deal of information by reading
								comments, assessing options, and understanding how opinions have evolved over time. With
								this uniform background and context, attendees can focus on discussing the matter at
								hand versus getting on the same page. When the latter happens, the meeting becomes an
								incredible waste of time.
							</p><p>
								I think that's the single largest source of optimization for a company: the makeup of
								their meetings. To be clear, it's not about fewer meetings because meetings serve a
								purpose. Rather, it’s key to improve the meetings, themselves. A lot of my efforts focus
								on teaching people this framework. Ironically, I find that most people are just
								challenged by that stuff.
							</p><p>
								Candidly, that’s my role as leader: to coach others on how best to make use of their
								limited time. Not only is time the most precious resource the company has, it’s also the
								most precious resource they have! It’s crucial that they approach the use of their time
								with a holistic perspective. By way of example, I had a recent call with one of my
								directors who had not taken a vacation in six months. Our conversation delved into why
								this person thought that they could not be away for two weeks, and me arguing for why
								the person had to take two weeks to recharge!
							</p><p>
								There is never enough time – for work, for family and friends – and it takes work to
								make the best use of it. It's all about fostering a holistic perspective in life.

							</p><p>
								<b><i>
										That’s fascinating. Let’s turn to your team.

										Your direct reports are highly accomplished people; what are the common mistakes
										you see executives at that level make when it comes to personal time management?
									</i>
							</b></p><div>
							<div><p>
								I don’t think most executives dedicate enough time to thinking. They spend too much time
								in meetings. By the way, I will say as a caveat, I do know people who are incredibly
								organized and succeed with a lot of “do time.” Shishir Mehrotra [Co-founder and CEO of
								Coda] is a great example. If you've seen the docs on how he organizes his time...
								</p><p>

								<b><i>Oh yeah, he has a lot of very well-organized docs! [laughs]</i></b></p></div><p>
								He is a source of inspiration. For a while, I tried to mimic his style because I was so
								impressed with his thinking behind it. But in the end, it just wasn’t for me. It
								actually drove me nuts. <i>[Sriram laughs]</i>
								But I respect him. I would say he's a highly effective executive. His system works for
								him. It's not one size fits all. Some of my direct reports thrive on lots of meetings.
								But, in general, I would say the largest mistake is that they conflate meetings with
								productivity. Often fewer meetings and better decisions drive the business forward.

							</p>
							<h2 id="opencalendar"><b>On Creating an Open Calendar</b></h2>
							<p>


								<b><i>This dovetails nicely with something that fascinates many of your colleagues: how
										do you have so much open time on your calendar?

										This drastically differs from your typical “successful CEO” who is booked from
										8:30am to 6pm. Walk us through your calendar and how you manage to create this
										open space.
									</i></b>

							</p>

							<p>

								My friends know me well! I do keep a lot of open time. I understand this comes from a
								place of privilege and I’m very lucky to have this flexibility.
							</p>
							<p>

								I feel like synchronous time is very costly; asynchronous time is better. I know there
								are some leaders who prefer to have all executive decisions travel through them. But
								then, you have to wait until the leader has availability to review things. Sometimes you
								run into delays in that process.
							</p>
							<p>
								I typically don't have more than really three or four meetings per day. There are
								exceptions; when I travel, I book in a lot more and I don't keep to my normal schedule.
								That said, most of the time it's three or four meetings a day.

							</p>
							<p>
								My way is to plan long term and do so ahead of time so that people better understand the
								direction in which they're going. You have to be incredibly crisp and clear when doing
								that. For instance, right now we're finalizing our five year plans and long range
								planning. These are actual, real targets fueled by real insights. They are made up of
								lots of super-detailed quarterly and annual goals. I don’t spend much time on the
								quarterly goals and instead focus on our so-called “big rocks.”
							</p>


							<h2 id="bets"><b>On Company Bets</b></h2>
							<p>
								At Spotify, we have something called “Company Bets.” These are large-scale initiatives
								that we believe will have a significant impact on the business within a relatively short
								period of time. I find that these bets are a much better use of my time. Our Company
								Bets typically update every six months, so I'm not needed that much in between. This
								way, I can constantly be thinking: “Where are we headed in the next six months?” Right
								now, I am thinking more about H2 2021. From a timeline perspective, that's the earliest
								place where I focus most of my time.
							</p>
							<p>
								It’s also my role to think far beyond that. For instance, I’m immersing myself in our
								2025 plans. I trust my team to manage the day-to-day, shorter-term initiatives and
								iterate as needed based on data and insights. They’re the best at that and I appreciate
								that this then frees me up to think about the long term.
							</p>

							<h2 id="decisionmaking"><b>On Delegated Decision Making<br></b></h2>
							<p>
								<b><i>
										Your system reminds me of Jack [Dorsey] at Twitter a …</i></b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/daniel.html">https://www.theobservereffect.org/daniel.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/daniel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679924</guid>
            <pubDate>Sun, 04 Oct 2020 15:56:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Summarizing 12 months of reading papers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24679890">thread link</a>) | @matt_d
<br/>
October 4, 2020 | https://alastairreid.github.io/a-year-of-papers/ | <a href="https://web.archive.org/web/*/https://alastairreid.github.io/a-year-of-papers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>This is an overview of <a href="https://alastairreid.github.io/RelatedWork/papers">the papers that I have read over the last 12 months</a>
since I <a href="https://alastairreid.github.io/joining-google/">joined Google Research</a>.
Over the last year, I have read 122 papers and I have added 364 to my paper
backlog.
You can read <a href="https://alastairreid.github.io/RelatedWork">my summaries of all the papers</a>,
read <a href="https://alastairreid.github.io/RelatedWork/notes">notes on common themes in the papers</a>,
and download <a href="https://alastairreid.github.io/RelatedWork/RelatedWork.bib">BibTeX</a> for all the papers.
As the number of papers grew, I reorganized several times and
<a href="https://alastairreid.github.io/RelatedWork">the site</a> became a bit like a <a href="https://zettelkasten.de/posts/zettelkasten-improves-thinking-writing">Zettelkasten</a>.</p>

<h2 id="how-i-organize-my-notes-about-papers">How I organize my notes about papers</h2>

<p>I started the year by trying to define a few topics that the papers I read
would fit into and trying to maintain overviews of each topic that linked to
each paper.  This is how I used to organize papers in filing boxes, filing
cabinets, stacks on my desk, etc. but it doesn’t work very well.  The most
obvious reason that it doesn’t work is that some papers span multiple research
topics so, whichever topic I assign them to, it will be wrong.
More seriously though, I am often reading because I don’t understand the field so
how can I possibly know how to organize papers when I first start
reading.
I also found that I was not updating the overviews because each time I read
a paper, I would need to restructure the overview to accomodate what I had just
learned.</p>

<p>After a few months, the original system was starting to fail, and I learned
about the <a href="https://zettelkasten.de/posts/zettelkasten-improves-thinking-writing">ZettelKasten</a> method of making
notes about papers and concepts. I have not fully adopted this method
but I have adopted some of the ideas:</p>

<ul>
  <li>
    <p>If a paper introduces an important looking concept, I create a new
page in my <a href="https://alastairreid.github.io/RelatedWork/notes">notes</a> and link the paper to the note.
This avoids duplication of the information and, by adding links to
all the referring pages, it makes it easy to find all the papers
related to the concept.</p>
  </li>
  <li>
    <p>I vigorously add links between papers and notes: going back to previously
read papers and adding links when I add a new concept.</p>
  </li>
  <li>
    <p>I rely on the links to define the structure of the site.
That is, I allow topics to emerge and evolve organically as I read
papers instead of trying to impose structure on a topic before
I even understand it.</p>
  </li>
</ul>

<p>The main way that my approach differs from <a href="https://zettelkasten.de/posts/zettelkasten-improves-thinking-writing">ZettelKasten</a> is that
a true ZettelKasten would create notes for every concept whereas
I tend to create notes only if I think multiple papers will link
to the concept.
I should probably follow the ZettelKasten approach more closely
and move a lot of the information I currently put in paper summaries
into notes about concepts.</p>

<h2 id="what-i-read">What I read</h2>

<p>Over the last year, I have mostly been reading about software verification
and security including
<a href="https://alastairreid.github.io/RelatedWork/notes/information-flow/">Information flow control</a>,
<a href="https://alastairreid.github.io/RelatedWork/topics/os/">Operating Systems</a>,
<a href="https://alastairreid.github.io/RelatedWork/topics/tools/">Verification tools</a>,
<a href="https://alastairreid.github.io/RelatedWork/notes/separation-logic/">Separation logic</a> (and, more generally, <a href="https://alastairreid.github.io/RelatedWork/notes/permission-logic/">permission logic</a>),
<a href="https://alastairreid.github.io/RelatedWork/notes/rust-language/">The Rust language</a>,
<a href="https://alastairreid.github.io/RelatedWork/notes/fuzz-testing/">Fuzz testing</a>,
the <a href="https://www.cs.umd.edu/~pugh/BugWorkshop05/">2005 Bugs workshop</a>,
<a href="https://alastairreid.github.io/RelatedWork/notes/property-based-testing/">Property-based testing</a>,
<a href="https://alastairreid.github.io/RelatedWork/notes/test-generation/">Test generation</a>,
and
<a href="https://alastairreid.github.io/RelatedWork/notes/google/">Google</a>
(in, more or less, chronological order).</p>

<p>Each paper links to my summary of the paper.
A few caveats about my summaries:</p>

<ul>
  <li>
    <p>Paper summaries are written fairly quickly, in a single pass, with little/no revision.</p>
  </li>
  <li>
    <p>Notes about concepts are always in a state of flux and often contain ‘todo’ comments
about how they should be restructured when I find the time.</p>
  </li>
  <li>
    <p>Especially when I am reading about a new topic, the summaries will contain errors
because I don’t understand that topic well enough to write a good summary.</p>
  </li>
  <li>
    <p>Since the summaries are mostly intended to help my understanding they may skip explaining
concepts that I already understand well.
Reading other papers in the same topic may help, or it may not.</p>
  </li>
  <li>
    <p>The summaries are not a substitute for reading the paper yourself and forming your own
understanding and opinion.
I encourage you to write your own paper summaries and maybe only use my list as one
source of ideas of what to read.</p>
  </li>
</ul>

<h3 id="information-flow-control"><a href="https://alastairreid.github.io/RelatedWork/notes/information-flow/">Information flow control</a></h3>

<p>Tracking and controlling how information moves through a program – usually for security reasons</p>

<ul>
  <li>Secure information flow by self composition [<a href="https://alastairreid.github.io/RelatedWork/papers/barthe:csfw:2004/">barthe:csfw:2004</a>]</li>
  <li>SecChisel: Language and tool for practical and scalable security verification of security-aware hardware architectures [<a href="https://alastairreid.github.io/RelatedWork/papers/deng:hasp:2019/">deng:hasp:2019</a>]</li>
  <li>Noninterference, transitivity, and channel-control security policies [<a href="https://alastairreid.github.io/RelatedWork/papers/rushby:sri:1992/">rushby:sri:1992</a>]</li>
  <li>A hardware design language for timing-sensitive information flow security [<a href="https://alastairreid.github.io/RelatedWork/papers/zhang:asplos:2015/">zhang:asplos:2015</a>]</li>
  <li>Complete information flow tracking from the gates up [<a href="https://alastairreid.github.io/RelatedWork/papers/tiwari:asplos:2009/">tiwari:asplos:2009</a>]</li>
  <li>Theoretical analysis of gate level information flow tracking [<a href="https://alastairreid.github.io/RelatedWork/papers/oberg:dac:2010/">oberg:dac:2010</a>]</li>
  <li>On the foundations of quantitative information flow [<a href="https://alastairreid.github.io/RelatedWork/papers/smith:fossacs:2009/">smith:fossacs:2009</a>]</li>
  <li>Secure autonomous cyber-physical systems through verifiable information flow control [<a href="https://alastairreid.github.io/RelatedWork/papers/liu:cpsspc:2018/">liu:cpsspc:2018</a>]</li>
  <li>Verifying constant-time implementations [<a href="https://alastairreid.github.io/RelatedWork/papers/almeida:security:2016/">almeida:security:2016</a>]</li>
</ul>

<h3 id="operating-systems"><a href="https://alastairreid.github.io/RelatedWork/topics/os/">Operating Systems</a></h3>

<p>Mostly concerned with verification of OSes and information flow control.</p>

<ul>
  <li>seL4: from general purpose to a proof of information flow enforcement [<a href="https://alastairreid.github.io/RelatedWork/papers/murray:secpriv:2013/">murray:secpriv:2013</a>]</li>
  <li>Scaling symbolic evaluation for automated verification of systems code with Serval [<a href="https://alastairreid.github.io/RelatedWork/papers/nelson:sosp:2019/">nelson:sosp:2019</a>]</li>
  <li>Combining mechanized proofs and model-based testing in the formal analysis of a hypervisor [<a href="https://alastairreid.github.io/RelatedWork/papers/becker:fm:2016/">becker:fm:2016</a>]</li>
  <li>überSpark: Enforcing verifiable object abstractions for automated compositional security analysis of a hypervisor [<a href="https://alastairreid.github.io/RelatedWork/papers/vasudevan:usenix:2016/">vasudevan:usenix:2016</a>]</li>
  <li>Komodo: Using verification to disentangle secure-enclave hardware from software [<a href="https://alastairreid.github.io/RelatedWork/papers/ferraiuolo:sosp:2017/">ferraiuolo:sosp:2017</a>]</li>
  <li>CertiKOS: An extensible architecture for building certified concurrent OS Kernels [<a href="https://alastairreid.github.io/RelatedWork/papers/gu:osdi:2016/">gu:osdi:2016</a>]</li>
  <li>End-to-end verification of information flow security for C and assembly programs [<a href="https://alastairreid.github.io/RelatedWork/papers/costanzo:pldi:2016/">costanzo:pldi:2016</a>]</li>
  <li>Attacking, repairing, and verifying SecVisor: A retrospective on the security of a hypervisor [<a href="https://alastairreid.github.io/RelatedWork/papers/franklin:cmu:2008/">franklin:cmu:2008</a>]</li>
  <li>SecVisor: A tiny hypervisor to provide lifetime kernel code integrity for commodity OSes [<a href="https://alastairreid.github.io/RelatedWork/papers/seshadri:sosp:2007/">seshadri:sosp:2007</a>]</li>
  <li>Verifying security invariants in ExpressOS [<a href="https://alastairreid.github.io/RelatedWork/papers/mai:asplos:2013/">mai:asplos:2013</a>]</li>
  <li>Scalable translation validation of unverified legacy OS code [<a href="https://alastairreid.github.io/RelatedWork/papers/tahat:fmcad:2019/">tahat:fmcad:2019</a>]</li>
  <li>Verifying the Microsoft Hyper-V hypervisor with VCC [<a href="https://alastairreid.github.io/RelatedWork/papers/leinenbach:fm:2009/">leinenbach:fm:2009</a>]</li>
  <li>Sound formal verification of Linux’s USB BP keyboard driver [<a href="https://alastairreid.github.io/RelatedWork/papers/penninckx:nfm:2012/">penninckx:nfm:2012</a>]</li>
  <li>Local verification of global invariants in concurrent programs [<a href="https://alastairreid.github.io/RelatedWork/papers/cohen:cav:2010/">cohen:cav:2010</a>]</li>
  <li>The Flask security architecture: System support for diverse security policies [<a href="https://alastairreid.github.io/RelatedWork/papers/spencer:security:1999/">spencer:security:1999</a>]</li>
</ul>

<h3 id="verification-tools"><a href="https://alastairreid.github.io/RelatedWork/topics/tools/">Verification tools</a></h3>

<p>With a focus on verification tools.</p>

<ul>
  <li>
    <p><a href="https://alastairreid.github.io/RelatedWork/notes/bounded-model-checking/">Bounded model checking</a> and <a href="https://alastairreid.github.io/RelatedWork/notes/model-checking/">Model checking</a></p>

    <ul>
      <li>Software model checking [<a href="https://alastairreid.github.io/RelatedWork/papers/jhala:compsurv:2009/">jhala:compsurv:2009</a>]</li>
      <li>Model checking: Algorithmic verification and debugging [<a href="https://alastairreid.github.io/RelatedWork/papers/clarke:cacm:2009/">clarke:cacm:2009</a>]</li>
      <li>Code-level model checking in the software development workflow [<a href="https://alastairreid.github.io/RelatedWork/papers/chong:icse:2020/">chong:icse:2020</a>]</li>
      <li>Software verification: Testing vs. model checking [<a href="https://alastairreid.github.io/RelatedWork/papers/beyer:hvc:2017/">beyer:hvc:2017</a>]</li>
      <li>Model checking [<a href="https://alastairreid.github.io/RelatedWork/papers/mcmillan:ecs:2003/">mcmillan:ecs:2003</a>]</li>
      <li>A lightweight symbolic virtual machine for solver-aided host languages [<a href="https://alastairreid.github.io/RelatedWork/papers/torlak:pldi:2014/">torlak:pldi:2014</a>]</li>
    </ul>
  </li>
  <li>
    <p><a href="https://alastairreid.github.io/RelatedWork/notes/symbolic-execution/">Symbolic execution</a></p>

    <ul>
      <li>Symbolic execution for software testing: Three decades later [<a href="https://alastairreid.github.io/RelatedWork/papers/cadar:cacm:2013/">cadar:cacm:2013</a>]</li>
      <li>The art, science, and engineering of fuzzing: A survey [<a href="https://alastairreid.github.io/RelatedWork/papers/manes:ieeetse:2019/">manes:ieeetse:2019</a>]</li>
      <li>A survey of symbolic execution techniques [<a href="https://alastairreid.github.io/RelatedWork/papers/baldoni:compsurv:2018/">baldoni:compsurv:2018</a>]</li>
      <li>Enhancing symbolic execution with veritesting [<a href="https://alastairreid.github.io/RelatedWork/papers/avgerinos:icse:2014/">avgerinos:icse:2014</a>]</li>
      <li>Selective symbolic execution [<a href="https://alastairreid.github.io/RelatedWork/papers/chipounov:hotdep:2009/">chipounov:hotdep:2009</a>]</li>
      <li>-Overify: Optimizing programs for fast verification [<a href="https://alastairreid.github.io/RelatedWork/papers/wagner:hotos:2013/">wagner:hotos:2013</a>]</li>
      <li>COASTAL: Combining concolic and fuzzing for Java (competition contribution) [<a href="https://alastairreid.github.io/RelatedWork/papers/visser:tacas:2020/">visser:tacas:2020</a>]</li>
    </ul>
  </li>
  <li>
    <p><a href="https://alastairreid.github.io/RelatedWork/notes/auto-active-verification/">Auto active verification</a> – requires input from user but all interaction is in terms of the original program.</p>

    <ul>
      <li>Extended static checking: A ten-year perspective [<a href="https://alastairreid.github.io/RelatedWork/papers/leino:informatics:2001/">leino:informatics:2001</a>]</li>
      <li>Dafny: An automatic program verifier for functional correctness [<a href="https://alastairreid.github.io/RelatedWork/papers/leino:lpair:2010/">leino:lpair:2010</a>]</li>
      <li>Developing verified programs with Dafny [<a href="https://alastairreid.github.io/RelatedWork/papers/leino:icse:2013/">leino:icse:2013</a>]</li>
    </ul>
  </li>
  <li>
    <p><a href="https://alastairreid.github.io/RelatedWork/notes/sat-solver/">SAT</a> and <a href="https://alastairreid.github.io/RelatedWork/notes/smt-solver/">SMT</a></p>

    <ul>
      <li>Boolean satisfiability from theoretical hardness to practical success [<a href="https://alastairreid.github.io/RelatedWork/papers/malik:cacm:2009/">malik:cacm:2009</a>]</li>
      <li>Satisfiability modulo theories: Introduction and applications [<a href="https://alastairreid.github.io/RelatedWork/papers/demoura:cacm:2011/">demoura:cacm:2011</a>]</li>
      <li>Benchmarking solvers, SAT-style [<a href="https://alastairreid.github.io/RelatedWork/papers/nyxbrain:sc2:2017/">nyxbrain:sc2:2017</a>]</li>
    </ul>
  </li>
  <li>SMACK: Decoupling source language details from verifier implementations [<a href="https://alastairreid.github.io/RelatedWork/papers/rakamaric:cav:2014/">rakamaric:cav:2014</a>]</li>
  <li>The Boogie verification debugger [<a href="https://alastairreid.github.io/RelatedWork/papers/legoues:sefm:2011/">legoues:sefm:2011</a>]</li>
  <li>Boogie: A modular reusable verifier for object-oriented programs [<a href="https://alastairreid.github.io/RelatedWork/papers/barnett:fmco:2005/">barnett:fmco:2005</a>]</li>
  <li>Specification and verification: The Spec# experience [<a href="https://alastairreid.github.io/RelatedWork/papers/barnett:cacm:2011/">barnett:cacm:2011</a>]</li>
  <li>VeriFast: Imperative programs as proofs [<a href="https://alastairreid.github.io/RelatedWork/papers/jacobs:vstte:2010/">jacobs:vstte:2010</a>]</li>
  <li>Software verification with VeriFast: Industrial case studies [<a href="https://alastairreid.github.io/RelatedWork/papers/philippaerts:scp:2014/">philippaerts:scp:2014</a>]</li>
  <li>VeriFast: A powerful, sound, predictable, fast verifier for C and Java [<a href="https://alastairreid.github.io/RelatedWork/papers/jacobs:nfm:2011/">jacobs:nfm:2011</a>]</li>
  <li>A solver for reachability modulo theories [<a href="https://alastairreid.github.io/RelatedWork/papers/lal:cav:2012/">lal:cav:2012</a>]</li>
  <li>A precise yet efficient memory model for C [<a href="https://alastairreid.github.io/RelatedWork/papers/cohen:entcs:2009/">cohen:entcs:2009</a>]</li>
  <li>Frama-C: A software analysis perspective [<a href="https://alastairreid.github.io/RelatedWork/papers/cuoq:sefm:2012/">cuoq:sefm:2012</a>]</li>
  <li>Multi-prover verification of C programs [<a href="https://alastairreid.github.io/RelatedWork/papers/filliatre:fem:2004/">filliatre:fem:2004</a>]</li>
  <li>Formal verification of a memory allocation module of Contiki with Frama-C: a case study [<a href="https://alastairreid.github.io/RelatedWork/papers/mangano:crisis:2016/">mangano:crisis:2016</a>]</li>
  <li>SpaceSearch: A library for building and verifying solver-aided tools [<a href="https://alastairreid.github.io/RelatedWork/papers/weitz:icfp:2017/">weitz:icfp:2017</a>]</li>
</ul>

<h3 id="separation-logic-and-more-generally-permission-logic"><a href="https://alastairreid.github.io/RelatedWork/notes/separation-logic/">Separation logic</a> (and, more generally, <a href="https://alastairreid.github.io/RelatedWork/notes/permission-logic/">permission logic</a>)</h3>

<p>For reasoning about heap data structures and aliasing.</p>

<ul>
  <li>Separation logic [<a href="https://alastairreid.github.io/RelatedWork/papers/ohearn:cacm:2019/">ohearn:cacm:2019</a>]</li>
  <li>VeriFast: Imperative programs as proofs [<a href="https://alastairreid.github.io/RelatedWork/papers/jacobs:vstte:2010/">jacobs:vstte:2010</a>]</li>
  <li>Software verification with VeriFast: Industrial case studies [<a href="https://alastairreid.github.io/RelatedWork/papers/philippaerts:scp:2014/">philippaerts:scp:2014</a>]</li>
  <li>VeriFast: A powerful, sound, predictable, fast verifier for C and Java [<a href="https://alastairreid.github.io/RelatedWork/papers/jacobs:nfm:2011/">jacobs:nfm:2011</a>]</li>
  <li>Viper: A verification infrastructure for permission-based reasoning [<a href="https://alastairreid.github.io/RelatedWork/papers/muller:vmcai:2016/">muller:vmcai:2016</a>]</li>
  <li>Lightweight support for magic wands in an automatic verifier [<a href="https://alastairreid.github.io/RelatedWork/papers/schwerhoff:ecoop:2015/">schwerhoff:ecoop:2015</a>]</li>
  <li>Specified blocks [<a href="https://alastairreid.github.io/RelatedWork/papers/hehner:vstte:2008/">hehner:vstte:2008</a>]</li>
  <li>Local reasoning about while-loops [<a href="https://alastairreid.github.io/RelatedWork/papers/tuerk:vstte:2010/">tuerk:vstte:2010</a>]</li>
  <li>Alias types [<a href="https://alastairreid.github.io/RelatedWork/papers/smith:esop:2000/">smith:esop:2000</a>]</li>
  <li>TALx86: A realistic typed assembly language [<a href="https://alastairreid.github.io/RelatedWork/papers/morrisett:wcsss:1999/">morrisett:wcsss:1999</a>]</li>
  <li>Fractional permissions without the fractions [<a href="https://alastairreid.github.io/RelatedWork/papers/heule:ftfjp:2011/">heule:ftfjp:2011</a>]</li>
  <li>The ramifications of sharing in data structures [<a href="https://alastairreid.github.io/RelatedWork/papers/hobor:popl:2013/">hobor:popl:2013</a>]</li>
  <li>Verifying event-driven programs using ramified frame properties [<a href="https://alastairreid.github.io/RelatedWork/papers/krishnaswami:tldi:2010/">krishnaswami:tldi:2010</a>]</li>
  <li>Separation logic and abstraction [<a href="https://alastairreid.github.io/RelatedWork/papers/parkinson:popl:2005/">parkinson:popl:2005</a>]</li>
  <li>Verification of concurrent programs with Chalice [<a href="https://alastairreid.github.io/RelatedWork/papers/leino:fosad:2007/">leino:fosad:2007</a>]</li>
  <li>Compositional shape analysis by means of bi-abduction [<a href="https://alastairreid.github.io/RelatedWork/papers/calcagno:popl:2009/">calcagno:popl:2009</a>]</li>
  <li>Smallfoot: Modular automatic assertion checking with separation logic [<a href="https://alastairreid.github.io/RelatedWork/papers/berdine:fmco:2005/">berdine:fmco:200…</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alastairreid.github.io/a-year-of-papers/">https://alastairreid.github.io/a-year-of-papers/</a></em></p>]]>
            </description>
            <link>https://alastairreid.github.io/a-year-of-papers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679890</guid>
            <pubDate>Sun, 04 Oct 2020 15:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fibers, Oh My]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24679740">thread link</a>) | @zdw
<br/>
October 4, 2020 | https://graphitemaster.github.io/fibers/ | <a href="https://web.archive.org/web/*/https://graphitemaster.github.io/fibers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>Written by Dale Weiler, last updated Oct 5th, 2020</p>
<ul>
<li>
  <a href="https://twitter.com/actualGraphite">Twitter</a></li>
<li>
  <a href="https://github.com/graphitemaster">GitHub</a></li>
</ul>
<p>It’s been brought to the attention of many people in the game development industry that you can use fibers to parallelize your engines and games. This one presentation in particular:
  <a href="http://twvideo01.ubm-us.net/o1/vault/gdc2015/presentations/Gyrling_Christian_Parallelizing_The_Naughty.pdf">Parallelizing the Naughty Dog engine using fibers</a> has been a talking point since it came out in 2015. However, it doesn’t quite go into the details enough to really explain why fibers are a good fit or how to actually implement them. In my pursuit to educate myself and take a stab at implementing them, I’ve concluded that there’s a distinctive lack of good information online. In response to the lack of literature on this topic, I’ve decided to explain it from multiple angles, and provide less known information on the subject. This document serves as a
  <a href="https://en.wikipedia.org/wiki/Sourcebook">Sourcebook</a> for those who really want to determine if it’s a right fit for them and how to go about actually doing it.</p>
<h2 id="disambiguation-of-terms">
  Disambiguation of terms.
  <a href="#disambiguation-of-terms">#</a>
</h2>
<p>Before we get started I want to define three distinctive terms.</p>
<ul>
<li>OS-thread (the thread given to us by the OS)</li>
<li>Hardware-thread (the actual physical thread on a CPU)</li>
<li>Fiber-thread (the thread of execution that is our fiber)</li>
</ul>
<h2 id="what-are-fibers">
  What are fibers?
  <a href="#what-are-fibers">#</a>
</h2>
<p>Fibers are a lightweight thread of execution similar to OS threads. However, unlike OS threads, they’re cooperatively scheduled as opposed to preemptively scheduled. What this means in plain English is that fibers <em>yield</em> themselves to allow another fiber to run. You may have used something similar to this in your programming language of choice where it’s typically called a <em>coroutine</em>, there’s no real distinction between coroutines and fibers other than that coroutines are usually a language-level construct, while fibers tend to be a systems-level concept.</p>
<p>Other names for fibers you may have heard before include:</p>
<ul>
<li>green threads</li>
<li>user-space threads</li>
<li>coroutines</li>
<li>tasklets</li>
<li>microthreads</li>
</ul>
<p>There are very few and minor differences between fibers and the above list. For the purposes of this document, we should consider them equivalent as the distinctions don’t quite matter.</p>
<h2 id="scheduling">
  Scheduling
  <a href="#scheduling">#</a>
</h2>
<p>At any given moment the OS is running multiple processes all with their own OS threads. All of those OS threads need to be making forward progress. There’s two classes of thought when it comes to how you solve this problem.</p>
<ul>
<li>
  <a href="https://en.wikipedia.org/wiki/Cooperative_multitasking">Cooperative scheduling</a></li>
<li>
  <a href="https://en.wikipedia.org/wiki/Preemption_%28computing%29">Preemptive scheduling</a></li>
</ul>
<p>It’s important to note that while you may observe that all processes and OS threads are running in parallel, scheduling is really providing the <em>illusion</em> of that. Not all threads are running in parallel, the scheduler is just switching between them quickly enough that it appears everything is running in parallel. That is they’re <em>concurrent</em>. Threads start, run, and complete in an <em>interleaved</em> fashion.</p>
<blockquote>
<p>It is possible for multiple OS threads to be running in parallel with
  <a href="https://en.wikipedia.org/wiki/Symmetric_multiprocessing">symmetric multiprocessing</a> (SMP) where they’re mapped to multiple hardware threads, but only as many hardware threads as the CPU physically has.</p>
</blockquote>
<h3 id="premptive-scheduling">
  Premptive scheduling
  <a href="#premptive-scheduling">#</a>
</h3>
<p>Most people familiar with threads know that you don’t have to <strong>yield</strong> to other threads to allow them to run. This is because most operating systems (OS) schedule threads <strong>preemptively</strong>.</p>
<p>The points at which the OS may decide to preempt a thread include:</p>
<ul>
<li>IO</li>
<li>sleeps</li>
<li>waits (seen in locking primitives)</li>
<li>interrupts (hardware events mostly)</li>
</ul>
<p>The first three in particular are often expressed by an application as a
  <a href="https://en.wikipedia.org/wiki/System_call">system call</a>. These system calls cause the CPU to cease executing the current code and execute the OS’s code registered for that system call. This allows the OS to service the request then resume execution of your application’s calling thread, or another thread entierly.</p>
<p>This is possible because the OS will decide at one of the points listed above to save all the relevant state of that thread then resume some other thread, the idea being that when this thread can run again, the OS can reinstate that thread and continue executing it like nothing ever happened. These transition points where the OS switches a thread are called
  <a href="https://en.wikipedia.org/wiki/Context_switch">context switches</a>.</p>
<p>There’s a cost associated with this context switching and all modern operating systems have made great deals of effort to reduce this cost as much as possible. Unfortunately, that overhead begins to show itself when you have <em>a lot</em> of threads. In addition, recent cache
  <a href="https://en.wikipedia.org/wiki/Side-channel_attack">side channel attacks</a> like:
  <a href="https://en.wikipedia.org/wiki/Spectre_%28security_vulnerability%29">Spectre</a>,
  <a href="https://en.wikipedia.org/wiki/Meltdown_%28security_vulnerability%29">Meltdown</a>,
  <a href="https://en.wikipedia.org/wiki/Spoiler_%28security_vulnerability%29">Spoiler</a>,
  <a href="https://en.wikipedia.org/wiki/Foreshadow_%28security_vulnerability%29">Foreshadow</a>, and
  <a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a> on modern processors has led to a series of both user-space and kernel-space mitigation strategies, some of which increased the overhead of context switches significantly.</p>
<blockquote>
<p>You can read more about context switching overhead in
  <a href="https://www.usenix.org/legacy/events/expcs07/papers/2-li.pdf">this paper</a>.</p>
</blockquote>
<h3 id="cooperative-scheduling">
  Cooperative scheduling
  <a href="#cooperative-scheduling">#</a>
</h3>
<p>This idea of fibers yielding to each other is what is known as cooperative scheduling. Fibers effectively move the idea of context switching from kernel-space to user-space and then make those switches a fundamental part of computation, that is, they’re a deliberate and explicitly done thing, by the fibers themselves. The benefit of this is that a lot of the previously mentioned overhead can be entierly eliminated while still permitting an excess count of threads of execution, just in the form of these fibers now.</p>
<h2 id="the-problem-with-multi-threading">
  The problem with multi-threading
  <a href="#the-problem-with-multi-threading">#</a>
</h2>
<p>There’s many problems related to multi-threading, most obviously that it’s difficult to get right. Most proponents of fibers make false claims about how this problem goes away when you use fibers because you don’t have parallel threads of execution. Instead, you have these cooperatively scheduled fibers which yield to each other. This means it’s not possible to
  <a href="https://en.wikipedia.org/wiki/Race_condition">race data</a>,
  <a href="https://en.wikipedia.org/wiki/Deadlock">dead lock</a>,
  <a href="https://en.wikipedia.org/wiki/Deadlock#Livelock">live lock</a>, etc. While this statement is true when you look at fibers as a N:1 proposition, the story is entierly different when you introduce M:N.</p>
<h3 id="n1-and-what-it-means">
  N:1 and what it means
  <a href="#n1-and-what-it-means">#</a>
</h3>
<p>Most documentation, libraries, and tutorials on fibers are almost exclusively based around using a single thread given to you by the OS, then sharing it among multiple fibers that cooperatively yield and run all your asynchronous code. This is called N:1 (“N to one”). <code>N</code> fibers to <code>1</code> thread, and it’s the most prevalent form of fibers. This is how Lua coroutines work, how Javascript’s and Python’s async/await work, and it’s <strong>not what you’re interested in</strong> doing if you actually want to take advantage of hardware threads. What you’re interested in is M:N, (“M to N”) <code>M</code> fibers to <code>N</code> threads.</p>
<h3 id="mn-and-what-it-means">
  M:N and what it means
  <a href="#mn-and-what-it-means">#</a>
</h3>
<p>The idea behind M:N is to take the model given to us by N:1 and map it to multiple actual OS threads. Just like we’re familiar to the concept of thread pools where we execute tasks, here we have a pool of threads where we execute fibers and those fibers get to yield more of themselves on that thread.</p>
<blockquote>
<p>I should stress that M:N fibers have all the usual problems of multi-threading. You still need to syncronize access to resources shared between multiple fibers because there’s still multiple threads.</p>
</blockquote>
<h2 id="the-problem-with-thread-pools">
  The problem with thread pools
  <a href="#the-problem-with-thread-pools">#</a>
</h2>
<p>A lot of you may be wondering how this is different from traditional task based parallelism choices seen in many game engines and applications. The model where you have a fixed-size pool of threads you queue tasks on to be executed at some point in the future by one of those threads.</p>
<h3 id="locality-of-reference">
  Locality of reference
  <a href="#locality-of-reference">#</a>
</h3>
<p>The first problem is <em>locality of reference</em>. The data-oriented / cache-aware programmers reading this will have to mind my overloading of that phrase because what I’m really talking about is the resources that a job needs access to are usually local. The job isn’t going to be executed immediately, but rather when the thread pool has a chance to. Any resource that job needs access to, needs to be available for the job at some point in the future. This means local values need their lifetime’s extended for an undefined amount of time.</p>
<p>There’s many ways to solve this lifetime problem, except they all have overhead. Consider this trivial example where I want to asynchronously upload a local file to a webserver</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>upload_file</span>(<span>const</span> String<span>&amp;</span> filename) {
  thread_pool<span>-&gt;</span>add_job([<span>&amp;</span>] {
    <span>auto</span> file <span>=</span> open_file(filename);
    <span>auto</span> data <span>=</span> read_file(file);
    post_binary_data(data);
  });
}
</code></pre></div><p>Do you see the bug?</p>
<p>The issue is that the string passed to <code>upload_file</code>, i.e the local <code>filename</code>, only has a lifetime of the body of the function. When this function returns, <code>filename</code> no longer is a valid string. However, at some point this lambda function will be executed and try to access <code>filename</code> in it’s local context and it’ll be a dangling reference by then.</p>
<p>This can be surprsing to those more familiar with dynamic languages, since they support this functionality with something called a closure. The closure will actually extend the lifetime of <code>filename</code>. In native languages like C or C++ though, this isn’t the case and all lifetime extension needs to be done explicitly with obvious runtime which introduces overhead.</p>
<p>What you could do is <strong>copy</strong> the string. The copy will then have the lifetime of the lambda. However, if we had a much larger resource to share with this job that couldn’t be as cheaply copied, we would have to use something like a <strong>reference count</strong> instead. As you can see, the solutions to the resource problem involve a great deal of overhead in many cases and requires you to really think and reason about lifetimes here when you didn’t have to, nor should you have to.</p>
<p>We’re experiencing a lot of friction here already and it’s only a few lines of code. My personal rule of thumb is if you find yourself experiencing friction like this, it’s usually indicative of bad design and the problem needs to be rethought.</p>
<h3 id="nested-induced-deadlocks">
  Nested induced deadlocks
  <a href="#nested-induced-deadlocks">#</a>
</h3>
<p>The other significant problem with thread pools is what I call <em>nested induced deadlocks</em>. No matter how you slice and dice it, jobs are going to want to schedule other jobs and need the result before they themselves can continue.</p>
<p>Let me set up a real world example because it’s easier to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphitemaster.github.io/fibers/">https://graphitemaster.github.io/fibers/</a></em></p>]]>
            </description>
            <link>https://graphitemaster.github.io/fibers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679740</guid>
            <pubDate>Sun, 04 Oct 2020 15:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LibrePCB 0.1.5 Released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24679678">thread link</a>) | @dbrgn
<br/>
October 4, 2020 | https://librepcb.org/blog/2020-10-04_release_0.1.5/ | <a href="https://web.archive.org/web/*/https://librepcb.org/blog/2020-10-04_release_0.1.5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    <div id="intro">
      <div>
        <div>
          <div>
            
            <p>We are happy to announce LibrePCB 0.1.5 with several long awaited new features
in the library-, schematic- and board editors!</p>
<h3 id="highlights">Highlights</h3>
<h4 id="copypaste-in-schematic--and-board-editors">Copy&amp;Paste in Schematic- and Board Editors</h4>
<p>Finally the clipboard functionality cut, copy and paste are available in the
schematic- and board editors
(<a href="https://github.com/LibrePCB/LibrePCB/pull/724">#724</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/754">#754</a>)! Just use the keyboard
shortcuts Ctrl+X to cut, Ctrl+C to copy and Ctrl+V to paste schematic- or board
items. In the board editor, it’s even possible to paste polygons copied from a
footprint in the library editor.</p>
<h4 id="usability-improvements-in-all-editors">Usability Improvements In All Editors</h4>
<p>This release contains a lot of usability improvements, which makes creating
library elements, schematics and boards much easier. Especially drawing traces
and placing vias was one of the weaknesses of LibrePCB – until now! The tools
to draw traces and place vias have been heavily improved, for example:</p>
<ul>
<li>Traces snap to pads and vias even if they are off the grid</li>
<li>The layer can be switched while drawing a trace, vias are inserted
automatically</li>
<li>Vias automatically take the closest net while placing</li>
<li>Inserted vias are automatically connected to the traces underneath</li>
<li>Trace and via properties can be changed with keyboard shortcuts while drawing
a trace</li>
</ul>
<p><a href="https://librepcb.org/img/board_editor_draw_trace.gif"><img src="https://librepcb.org/img/board_editor_draw_trace.gif" alt="Draw Trace"></a></p>
<p>Another inconvenience was that the outline of planes and polygons could only
be modified by specifying the exact vertex coordinates. Now this is much easier
since vertices can be moved, inserted and removed graphically right in the
editors.</p>
<h3 id="changelog">Changelog</h3>
<h4 id="library-manager">Library Manager:</h4>
<ul>
<li>Fix error when downloading a library after an aborted download
(<a href="https://github.com/LibrePCB/LibrePCB/pull/775">#775</a>)</li>
</ul>
<h4 id="library-editor">Library Editor:</h4>
<ul>
<li>Implement “Select All” (Ctrl+A)
(<a href="https://github.com/LibrePCB/LibrePCB/pull/723">#723</a>)</li>
<li>Support cycling selection through items under cursor by pressing Shift
(<a href="https://github.com/LibrePCB/LibrePCB/pull/757">#757</a>)</li>
<li>Support rotate/mirror/flip while moving items
(<a href="https://github.com/LibrePCB/LibrePCB/pull/769">#769</a>)</li>
<li>Support modifying polygons graphically
(<a href="https://github.com/LibrePCB/LibrePCB/pull/773">#773</a>)</li>
<li>Copy all categories when duplicating a library element
(<a href="https://github.com/LibrePCB/LibrePCB/pull/765">#765</a>)</li>
<li>Fix “Could not move X to Y” error when moving library element
(<a href="https://github.com/LibrePCB/LibrePCB/pull/715">#715</a>)</li>
<li>Fix crash when going back in “New Component” wizard
(<a href="https://github.com/LibrePCB/LibrePCB/pull/719">#719</a>)</li>
</ul>
<h4 id="schematic-editor">Schematic Editor:</h4>
<ul>
<li>Implement clipboard cut/copy/paste
(<a href="https://github.com/LibrePCB/LibrePCB/pull/724">#724</a>)</li>
<li>Implement “Select All” (Ctrl+A)
(<a href="https://github.com/LibrePCB/LibrePCB/pull/723">#723</a>)</li>
<li>Support cycling selection through items under cursor by pressing Shift
(<a href="https://github.com/LibrePCB/LibrePCB/pull/757">#757</a>)</li>
<li>Support cycling through results of the search toolbar
(<a href="https://github.com/LibrePCB/LibrePCB/pull/756">#756</a>)</li>
<li>Make component toolbar norm-aware by using preferred symbol variant
(<a href="https://github.com/LibrePCB/LibrePCB/pull/768">#768</a>)</li>
<li>Fix leaving tool with when pressing right mouse click while moving
(<a href="https://github.com/LibrePCB/LibrePCB/pull/761">#761</a>)</li>
</ul>
<h4 id="board-editor">Board Editor:</h4>
<ul>
<li>Implement clipboard cut/copy/paste
(<a href="https://github.com/LibrePCB/LibrePCB/pull/754">#754</a>)</li>
<li>Implement “Select All” (Ctrl+A)
(<a href="https://github.com/LibrePCB/LibrePCB/pull/723">#723</a>)</li>
<li>Heavily improve the “Draw Trace” tool
(<a href="https://github.com/LibrePCB/LibrePCB/pull/733">#733</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/751">#751</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/753">#753</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/749">#749</a>)</li>
<li>Heavily improve the “Add Via” tool
(<a href="https://github.com/LibrePCB/LibrePCB/pull/736">#736</a>)</li>
<li>Support cycling selection through items under cursor by pressing Shift
(<a href="https://github.com/LibrePCB/LibrePCB/pull/748">#748</a>)</li>
<li>Support cycling through results of the search toolbar
(<a href="https://github.com/LibrePCB/LibrePCB/pull/756">#756</a>)</li>
<li>Support modifying polygons graphically
(<a href="https://github.com/LibrePCB/LibrePCB/pull/773">#773</a>)</li>
<li>Support modifying plane outlines graphically
(<a href="https://github.com/LibrePCB/LibrePCB/pull/774">#774</a>)</li>
<li>Don’t remove complete trace when changing a device
(<a href="https://github.com/LibrePCB/LibrePCB/pull/746">#746</a>)</li>
<li>Fix possibly outdated displayed texts of devices
(<a href="https://github.com/LibrePCB/LibrePCB/pull/770">#770</a>)</li>
<li>Fix possibly outdated displayed net names
(<a href="https://github.com/LibrePCB/LibrePCB/pull/771">#771</a>)</li>
</ul>
<h4 id="erc">ERC:</h4>
<ul>
<li>Disregard schematic-only components in net pin count
(<a href="https://github.com/LibrePCB/LibrePCB/pull/745">#745</a>)</li>
</ul>
<h4 id="miscellaneous">Miscellaneous:</h4>
<ul>
<li>Add support for Solaris based systems
(<a href="https://github.com/LibrePCB/LibrePCB/pull/713">#713</a>)</li>
<li>Allow unbundling of some vendored libraries
(<a href="https://github.com/LibrePCB/LibrePCB/pull/698">#698</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/742">#742</a>)</li>
<li>Fix too restrictive format version check of FontoBene files
(<a href="https://github.com/fontobene/fontobene-qt5/pull/4">fontobene-qt5#673</a>)</li>
<li>Various internal code refactorings &amp; improvements
(<a href="https://github.com/LibrePCB/LibrePCB/pull/720">#720</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/760">#760</a>,
<a href="https://github.com/LibrePCB/LibrePCB/pull/767">#767</a>, …)</li>
</ul>
<h3 id="download">Download</h3>
<p>The release can be downloaded for all major operating systems from our download
page:</p>
<h4 id="httpslibrepcborgdownload"><a href="https://librepcb.org/download/">https://librepcb.org/download/</a></h4>
<p>Thanks to all contributors for making this awesome release possible!</p>

              <p><i>2020-10-04</i></p>
          </div>
        </div>
      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://librepcb.org/blog/2020-10-04_release_0.1.5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679678</guid>
            <pubDate>Sun, 04 Oct 2020 15:23:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Can we call this democracy? Amnesty's M.Mahmoudi on Why Privacy Matters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24679661">thread link</a>) | @rakeye
<br/>
October 4, 2020 | https://theprivacycollective.eu/en/privacy-matters/an-interview-with-matt-mahmoudi/ | <a href="https://web.archive.org/web/*/https://theprivacycollective.eu/en/privacy-matters/an-interview-with-matt-mahmoudi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="420" data-elementor-settings="[]">
		<div>
					<section data-id="1495100f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
							<div>
					<div data-id="3b0d4b5d" data-element_type="column">
			<div>
							<div>
						<div data-id="4295b310" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div>
    <p><span onclick="openNav()">☰</span></p><p><a href="https://theprivacycollective.eu/"><img src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/TPC-logo-colour.svg"></a> </p>
    
    <p><img src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/TPC-logotype-white.svg"></p>
</div>		</div>
				</div>
				<div data-id="5f5d9533" data-element_type="widget" data-widget_type="html.default">
				<div>
			<div id="mySidenav">
  <p>×</p>
    <div>
     <p>info@privacycollective.eu</p> 

<p><a href="https://www.facebook.com/theprivacycollective/"> <img src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/Facebook.svg"></a> 
   <a href="https://www.linkedin.com/company/the-privacy-collective/"> <img src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/LinkedIn.svg"></a>
   <a href="https://twitter.com/theprivacycoll1"> <img src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/Twitter.svg"></a>
</p>


  </div>
  
  </div>		</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="69a6598a" data-element_type="section">
						
		</section>
				<section data-id="676fa6f" data-element_type="section">
						<div>
							<div>
					<div data-id="c2057e3" data-element_type="column">
			<div>
							<div>
						<div data-id="1325124" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="871" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="6d84e049" data-element_type="section">
						
		</section>
				<section data-id="2dea3697" data-element_type="section">
						<div>
							<div>
					<div data-id="7a6eacef" data-element_type="column">
			<div>
							<div>
						
				<div data-id="2f79ea2e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><i><span>As part of an international campaign to lift the lid on data privacy violations, The Privacy Collective is asking some of the UK’s leading experts why online privacy matters.&nbsp;</span></i></p><p><span>Matt Mahmoudi is a researcher and adviser at Amnesty International on artificial intelligence and human rights, and Jo Cox PhD Scholar at the University of Cambridge. He co-founded and presents Declarations, the human rights podcast. Here, he discusses the need to reclassify privacy from being an individual issue to a community problem, the danger of becoming desensitised to surveillance technologies, and the risks of decision making by algorithms. </span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="226b2e96" data-element_type="column">
			<div>
							<div>
						
				<div data-id="ac4aff6" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/elementor/thumbs/MattMahmoudi-owa07ms9tzxisjqs5t75d1kcmlobjqkwbojjkot9rs.jpeg" title="MattMahmoudi" alt="MattMahmoudi">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="6d224d5e" data-element_type="section">
						<div>
							<div>
					<div data-id="6b9b46a2" data-element_type="column">
			<div>
							<div>
						<div data-id="2c559b1e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h4>Why does online privacy matter?</h4><p><span>Privacy is a means of protecting yourself from exploitation by actors who are using your data in ways that are often not disclosed to you. And this isn’t just at the individual level – we need to think about privacy and its impact on our communities, neighbourhoods and countries.&nbsp;</span></p><p><span>One of the things that should matter to us is thinking about what kind of behaviours does data collection at this scale encourage, what kind of societies does this create? What information is being served to us that shapes how we conceive of the world around us? How have we been living under the guise of democracy since so much power has been amassed under Facebook and Google, for example? Can we really call that democracy? Or is this a techno-authoritarian state-of-being that we’re living through?</span></p><h4><b>What do you think are the biggest risks to online data privacy at the moment?&nbsp;</b></h4><p><span>I think our understanding of data privacy at a general level is quite one dimensional. I don’t think that we necessarily have the right tools or education to fully understand. We’re not just talking about what is convenient, we’re talking about people’s ability to access information, about economic rights, about questions around life and death for especially vulnerable populations, many of whom rely on anonymous identities. That’s one of the major risks.&nbsp;</span></p><p><span>Another risk is the concentration of the means to classify individuals, which is done by a handful of tech giants and data brokers. That’s a determining factor of how you’re treated and what information you’re served. And then thirdly, is the fact that our behaviour and data make up lucrative business models.</span></p><p><span>I don’t think this is just about awareness. Even though The Social Dilemma [a new documentary on Netflix that Amnesty International was involved with] does a great job at creating awareness, it’s not like we weren’t aware that this could happen. Cambridge Analytica happened not too long ago. The Snowden revelations also happened not too long ago. But are you someone who believes that you are fundamentally affected by how your data is surveilled? Does this have a consequence in your everyday life? Those are the questions that will impact how we think about data and tech.&nbsp;</span></p><h4><b>You’ve also spoken about the dangers of surveillance technology – particularly facial recognition software. How do you think the Covid-19 pandemic has shifted the public view on tracking technologies?&nbsp;</b></h4><p><span>Global emergencies are conditions under which states of exception become possible. During the pandemic, we’ve seen a rollout of contact tracing, we’ve seen a rollout of not just facial recognition, but also in some contexts emotion recognition, and really quite diverse forms of biometric identification that we haven’t really seen used at the scale before. Covid-19 has almost created an innovation race for surveillance technologies. However, that crisis element also intersects with our nature to adapt and move on and try to make normal what we can in exceptional circumstances. Before we know it, the invasive measures that were put into place during the pandemic could outlive it. I think the contact tracing debate has opened a lot more discourse around this issue, but it’s not at the same level as the response to the Cambridge Analytica scandal or the Snowden revelations.&nbsp;</span></p><p><span>We had those great debates. Those debates were never settled. They made us worried, but at some point, we just accepted that some surveillance is ongoing. Things like contact tracing risks significantly stifling our ability to freely move. There are so many things that can go wrong when you’re dealing with a centralised means of controlling people’s movement. The ways in which these technologies can be used are not kept in check. And I think that is one of my biggest grievances around contract tracing and around facial recognition. But we won’t have the kinds of regulatory frameworks that we need as long as there isn’t outrage at the scale that we saw before.</span></p></div>
				</div>
				</div>
				<section data-id="b0c0f8f" data-element_type="section">
						<div>
							<div>
					<div data-id="1eef306d" data-element_type="column">
			<div>
							<div>
						<div data-id="3011a3b5" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="580" height="580" src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/quotemrk.svg" alt="" loading="lazy" srcset="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads//2020/08/quotemrk.svg 150w, https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads//2020/08/quotemrk.svg 300w, https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads//2020/08/quotemrk.svg 1024w" sizes="(max-width: 580px) 100vw, 580px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="1cc9ce25" data-element_type="column">
			<div>
							<div>
						<div data-id="3841818e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>Privacy is a means of protecting yourself from exploitation by actors who are using your data in ways that are often not disclosed to you. And this isn’t just at the individual level – we need to think about privacy and its impact on our communities, neighbourhoods and countries. </span></p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<div data-id="75fe8d8" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><h4>Talking about outrage, it was interesting to see the uproar over the A Level results fiasco recently – where else are algorithms being used that we might not be aware of?&nbsp;</h4><p><span>There are many other contexts to think about. The A Levels moment gave some hope to the cynical minds of people like myself who are waiting for people to challenge this notion of deferring human judgment to a machine. Algorithms are often used to quantify unquantifiable things, and where there should really be a more extensive consultative process of figuring out what the truth is and how to best respond.&nbsp;</span></p><p><span>There was another example recently in the Netherlands, where a particular algorithm was used to try and predict who was more likely to commit tax fraud and used dual citizenship as a variable. That largely resulted in it finding that people with dual nationality, often ethnic minorities, were committing tax fraud even though there was no evidence to say so. Other examples are predictive policing, which tends to double down on existing prejudice, and welfare assessments, which often come down to indicators designed to encourage reductive decision-making, rather than augmenting the expertise of a caseworker or social worker.&nbsp;</span></p><h4>You recently co-authored a book called <a href="https://global.oup.com/academic/product/digital-witness-9780198836070?cc=gb&amp;lang=en&amp;">Digital Witness</a> about using open source information for human rights investigation and accountability. I wondered what your thoughts are around whether technology leaves people more open to human rights abuses when it comes to the use of their data?&nbsp;</h4><p><span>I don’t think that we can make an unequivocal assertion that technology leaves people open to greater human rights abuses. They do. Of course they do. But they also lead to greater ways for people to contest oppressive power relations and systems that are authoritarian. Contexts in which we’ve used technology to accomplish that includes Amnesty’s reporting on war crimes, human rights atrocities and crimes against humanity. Some of the same technologies that allow for heavy surveillance and the abuse of human rights, also enable the effective pursuit and fight for human rights.&nbsp;</span></p><p><span>So I do think it’s double edged. I think the way that we shift that dial is by challenging the circumstances under which these technologies exist. Technology should not be operating according to a surveillance business model, which privileges the abuses of human rights over the fight for them.&nbsp; Does the tech industry have to be based on generating an income from our online behaviour and the data that we share, in ways that we don’t always understand? Are we willing to accept that society should be commodified in this way? In lots of ways, this is an exercise in imagining a different world. One we should not shy away from.</span></p><h4>Do big technology companies have a responsibility to be more ethical when it comes to handling our data?&nbsp;</h4><p><span>I think social media platforms tend to rely on the language of ethics to justify their model. Ethics can do a lot to steer the conversation in the right direction and there are incredible digital ethicists, scholars and activists out there doing fantastic work on this. However, my fear is that it can also be a normalising discourse when deployed from within the corporate responsibility side of things, where there is very little accountability.</span></p><p><span>It’s taken for granted, for example, that these asymmetric relations of power are birthed by tech and merely need a tech fix in order to be corrected, which is simply not enough from my perspective. Not only do we need social media platforms to do better when it comes to ethical practice, but at the same time we need stronger and stricter regulation that acknowledges the structural inequities within which the technology industry is embedded.&nbsp;</span></p><p><em>Your data should not be for sale. We’re taking Oracle and Salesforce to court for illegally selling millions of peoples data and we need your help! If you believe that tech giants should be held accountable for their use of people’s data please <span><strong>support our claim by “liking” our support button. </strong></span></em></p><p><em>We’re fighting for change, because your privacy matters.&nbsp;</em></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="7a38ac9f" data-element_type="section">
						
		</section>
				<section data-id="4f033297" data-element_type="section">
						<div>
							<div>
					<div data-id="44e9ccdb" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							<div>
						
				<section data-id="70d95eaa" data-element_type="section">
						<div>
							<div>
					<div data-id="2760f5ff" data-element_type="column">
			<div>
							<div>
						<div data-id="3043db83" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="199" height="199" src="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/TPC-logo-white0footer.png" alt="" loading="lazy" srcset="https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/TPC-logo-white0footer.png 199w, https://theprivacycollective.eu/en/privacy-matters/wp-content/uploads/2020/08/TPC-logo-white0footer-150x150.png 150w" sizes="(max-width: 199px) 100vw, 199px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
				
				…</div></div></section></div></div></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theprivacycollective.eu/en/privacy-matters/an-interview-with-matt-mahmoudi/">https://theprivacycollective.eu/en/privacy-matters/an-interview-with-matt-mahmoudi/</a></em></p>]]>
            </description>
            <link>https://theprivacycollective.eu/en/privacy-matters/an-interview-with-matt-mahmoudi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679661</guid>
            <pubDate>Sun, 04 Oct 2020 15:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Put a Raspberry Pi in a Rocket]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24679435">thread link</a>) | @johnjones4
<br/>
October 4, 2020 | https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/ | <a href="https://web.archive.org/web/*/https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://news.ycombinator.com/item?id=24679435">Q&amp;A on Hacker News about this project</a></p>
<p>As we're driving out to our launch site in Leesburg, VA, my wife turns to me and asks, "did you intentionally wear a yellow and blue striped rugby shirt to match your yellow and blue striped rocket?" I look down, and realize that, yes I had indeed accidentally dressed exactly like my rocket. I wonder if that ever happens to Elon?</p>
<h2>Launches</h2>
<p><img src="https://johnjonesfour.com/images/rocket/launch.jpg" alt="Launch images"></p>
<p>Very special thank you to my exceptionally patient wife who tagged along, captured these great pictures, and ended up actually having a lot of fun with her very nerdy husband.</p>
<p>Ida Lee Park in Leesburg, VA allows rocket launches up to 400 feet with a permit, so I applied earlier in September for an October 3rd launch and received fast approval. With the day upon us, my wife and I made the 40 minute drive to Leesburg (apparently in uniform?), set up in our designated part of the park, and got to work.</p>
<h3>Launch 1</h3>
<p><img src="https://johnjonesfour.com/images/rocket/telemetry.gif" alt="Telemetry"></p>
<p><img src="https://johnjonesfour.com/images/rocket/launch1.png" alt="Launch 1"></p>
<p>The first launch was a huge success. The rocket reached 110.3 meters (~362 feet), which beat my simulation's prediction of 90 meters, and it reached a peak velocity of 41.69 meters per second (~93 mph) at 1.44 seconds into the flight. We can see the rocket started to descend very quickly after apogee, and the chute deployed successfully 7.5 seconds into the flight. From there, the chute allowed for a linear rate of descent to a gentle field landing.</p>
<h3>Launch 2</h3>
<p><img src="https://johnjonesfour.com/images/rocket/launch2.png" alt="Launch 2"></p>
<p>Launch 2 was less of a success. While the ascent went smoothly, telemetry was lost 4.57 seconds into flight and the ejection charge ripped the shock cord causing the two rocket components to separate with no parachute to slow their descent. This incident also knocked out the battery cable causing inboard video and data capture to also fail. Unfortunately no video data could be recovered.</p>
<h2>Next Steps</h2>
<p><img src="https://johnjonesfour.com/images/rocket/recovery.jpg" alt="Rocket after launch"></p>
<p>The second launch revealed three major issues that need to be resolved: </p>
<ol>
<li>The shock cord is not strong enough to absorb the force caused by separation, likely because of how heavy the payload is. In a future upgrade I will need to double-up the cords OR use two parachutes for each component to let them descend separately.</li>
<li>When the payload section hit the ground, it drove the coupler way into the body tube. Upon impact, the battery bracket absorbed the force and shattered. However all of the electronics survived. Part of the coupler also broke off when I attempted to pull the it out of the payload section, so this will all need to be redesigned to better absorb hard landings.</li>
<li>There must be a buffer that holds a certain amount of camera footage before saving it to disk. Because the battery disconnected in-flight, no flight video saved. I'd like to figure out how to write video data more frequently in case the battery issue happens again.</li>
</ol>
<p>In addition to those major issues, I'd also like to make the following improvements:</p>
<ol>
<li>The software performed well, but I'd still like to increase the data capture rate. There are Adafruit libraries for the components I'm using in C++, so I'm considering rewriting <code>air.py</code> in C++, but I'd really love it if someone talked me out of that.</li>
<li>Between launches I manually rebooted the ground computer so that it would clear the visualizations and start logging to a new file. To make this easier, I plan to add the option to the dashboard to start new "capture sessions" without needing to restart the system.</li>
</ol></div></div>]]>
            </description>
            <link>https://johnjonesfour.com/2020/10/04/model-rocket-telemetry-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24679435</guid>
            <pubDate>Sun, 04 Oct 2020 14:48:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physical distancing, mask-wearing could be in place for 2-3 years with vaccine]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24678863">thread link</a>) | @just-juan-post
<br/>
October 4, 2020 | https://www.cbc.ca/news/politics/covid-19-vaccine-tam-1.5673729 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/covid-19-vaccine-tam-1.5673729">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canadians shouldn't expect a COVID-19 vaccine to be a&nbsp;"silver bullet" that will bring a swift end to the coronavirus&nbsp;pandemic and a return to normal, according to the&nbsp;country's chief public health officer.</p><div><p><span><span><div><div role="button" tabindex="0" title="Dr. Tam cautions COVID-19 vaccines not a 'silver bullet'"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/345/911/ftr%20TAM%20vaccine_frame_66.jpg" alt=""></p></div></div></div><span>Canada's chief public health officer Dr. Theresa Tam responds to reporter questions about the search for a vaccine for COVID-19.<!-- --> <!-- -->2:08</span></span></span></p><p><span><p>Canadians shouldn't expect a COVID-19 vaccine to be a&nbsp;"silver bullet" that will bring a swift end to the coronavirus&nbsp;pandemic and a return to normal, according to the&nbsp;country's chief public health officer.</p>  <p>Dr. Theresa Tam used her briefing on Tuesday in Ottawa to temper expectations about the speed and effectiveness of a vaccine. She reiterated the importance of physical distancing, proper hand hygiene and mask-wearing, and attempted to&nbsp;dispel any&nbsp;notion&nbsp;that a vaccine will make life go back to the way it was in a couple of months.</p>  <p>"We can't at this stage just put all of our focus [on a vaccine] in the hopes that this is the silver bullet solution," said Tam.</p>  <p>"We're going to have to manage this pandemic certainly over the next year, but certainly [we are]&nbsp;planning for the longer term of the next two to three years during which the vaccine may play a role but we don't know yet."</p>  <p>Tam said it's unclear at this stage how effective a vaccine will be. She said key questions remain about the degree and duration of immunity a vaccine will provide, the dosage that will be needed&nbsp;and whether it will prevent people from getting infected altogether or simply prevent severe illness requiring hospitalization.</p>  <h2>More than 150&nbsp;under development</h2>  <p>There are <a href="https://newsinteractives.cbc.ca/coronavirusvaccinetracker/">more than 166 vaccines</a> at various stages of <a href="https://www.cbc.ca/news/health/vaccine-clinical-trials-1.5580436">preclinical and clinical (human) testing</a>&nbsp;across the globe right now, the World Health Organization says. <a href="https://www.cbc.ca/news/world/us-azar-vaccine-global-supply-1.5571264">U.S.</a> and <a href="https://www.cbc.ca/news/world/coronavirus-vaccine-1.5569165">European</a> experts say under an optimistic scenario, the first of those vaccines could complete testing and get approval for distribution next year.&nbsp;</p>  <p>Tam warned that even once a vaccine is tested and deemed to be both safe and effective, there will be challenges with distributing it widely to those who need it.</p>  <p>"It's likely that there won't be enough vaccines for the population," said Tam. "So there'll be prioritization and we're looking at that."</p>  <p>Tam said she agreed with Dr. Anthony Fauci, the&nbsp;top infectious disease specialist in the U.S., who told Congress last week that he was "cautiously optimistic" that a safe and effective vaccine will be available by the end of the year.</p>  <p>Despite that, she said&nbsp;public health officials are planning for a scenario in which measures that have been put in place thus far, including physical distancing to limiting crowd sizes,&nbsp;could be required even after a vaccine is found.</p>  <p>"[A vaccine] is one important layer of protection," said Tam. "It is a very important solution if we get a safe and effective vaccine,&nbsp;but I would say that the public health measures that we have in place&nbsp;— the sort of personal, daily measures that we take — is going to have to continue."</p>  <p><em><strong>WATCH: Tam on&nbsp;how Canadians should psychologically prepare for the future:</strong></em></p>  <p><span><span><div><div role="button" tabindex="0" title="Tam questioned about how Canadians should psychologically prepare for the future"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/385/450/ftr%20TAM%20looking%20forward_frame_167.jpg" alt=""></p></div></div></div><span>Canada's chief public health officer Dr. Theresa Tam spoke with reporters, including the CBC's Tom Parry on Parliament Hill Tuesday.<!-- --> <!-- -->2:19</span></span></span></p>  <h2>Recommends masks for children over 10</h2>  <p>Tam said one of the busiest areas of planning for officials&nbsp;is the reopening of schools in September, for which,&nbsp;she said, the Public Health Agency of Canada will be publishing detailed guidelines later this week.</p>  <p>The guidelines will include a recommendation that children over the age of 10 be required to wear masks, said Tam, in French. Extra consideration should be given for children under the age of 10, she said.</p>  <p>"The recommendations will undergo evolution as the evidence changes and we'll also have to see what happens as we understand transmission in different age groups&nbsp;and what happens in schools." said Tam. "We may have to adapt this recommendation as we go along."</p>    <p>Tam also addressed criticism of another layer of protection the federal government rolled out last week&nbsp;— the COVID Alert exposure notification app&nbsp;— which is meant to tell users if their phones have recently been close to a phone registered to someone who volunteers that they've tested positive for the coronavirus.</p>  <p>The app&nbsp;works only on phones released in the last five years or so because it needs a relatively recent operating system.</p>  <p><a href="https://www.cbc.ca/news/politics/covid-alert-app-accessibility-1.5672881">Critics say that will leave out poorer and older Canadians</a>, who are more likely to use older devices and suffer worse effects from the virus.</p>  <p>Tam said&nbsp;the app is&nbsp;one of many tools available to fight the pandemic, and that people should use them even if they aren't perfect.</p>  <p>"Despite these gaps, we need to have a go at using it," said Tam. "As many people who can download it and use it as possible will make the app more successful."</p>  <p>The government said Monday that more than 1.1 million people had downloaded the app.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/covid-19-vaccine-tam-1.5673729</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678863</guid>
            <pubDate>Sun, 04 Oct 2020 13:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[French bar owners arrested for offering free WiFi but not keeping logs]]>
            </title>
            <description>
<![CDATA[
Score 659 | Comments 310 (<a href="https://news.ycombinator.com/item?id=24678702">thread link</a>) | @seigando
<br/>
October 4, 2020 | https://www.cozyit.com/french-bar-owners-arrested-for-offering-free-wifi-but-not-keeping-logs/ | <a href="https://web.archive.org/web/*/https://www.cozyit.com/french-bar-owners-arrested-for-offering-free-wifi-but-not-keeping-logs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1007">
														
							
														
							
														
							<div>
															<div>
									<p>At least five bar owners in Grenoble, France have been arrested for providing WiFi at their businesses without keeping logs. The bar owners were arrested under a 2006 law that technically classifies WiFi hotspot providing establishments as ISPs, and requires them to store one year’s worth of logs or connection records for anti-terrorism purposes. This requirement is in place even if the WiFi network is password protected.</p>
<p>The law No. 2006-64&nbsp;<a href="https://www.bfmtv.com/economie/des-patrons-de-bars-en-garde-a-vue-a-cause-du-wi-fi-offert-a-leurs-clients_AN-202009290142.html" target="_blank" rel="noopener noreferrer">extends</a>&nbsp;the traditional ISP logging requirements “to all persons who, in respect of an activity primary or secondary professional, offer the public a connection allowing on-line communication via network access, including free of charge.” Violating this crime means that the owner of a small cafe that offers WiFi to patrons could face up to one year in prison and up to a 75,000 euro fine.</p>
<h2>All businesses in France providing WiFi to the public are required to log</h2>
<p>That all public WiFi hotspots in France are required by law to be logging shouldn’t be too surprising.&nbsp;<a href="https://www.bfmtv.com/economie/des-patrons-de-bars-en-garde-a-vue-a-cause-du-wi-fi-offert-a-leurs-clients_AN-202009290142.html" target="_blank" rel="noopener noreferrer">BFM Business</a>&nbsp;noted that most large providers of free WiFi like hotels, conference centers, airports, and such do so with business packages that include this logging. However, it seems that most people aren’t aware that even small businesses like bars, cafes, nightclubs, and restaurants that offer WiFi to their patrons are faced with these logging requirements. One of the arrested bar owners noted that the relevant organization, Umih, never noted this requirement when renewing his license:</p>
<blockquote><p>“Nobody, not even the professionals of Umih who provide compulsory training as part of a license IV resumption, to me never said I should keep this history.”</p></blockquote>
<p>In response to questions by BFM Business, Umih admitted that the training doesn’t mention WiFi logging but noted that Umih members should have known about this important requirement because it was mentioned in a newsletter.</p>
<p>If anything, this piece of dystopian news highlights the state of surveillance in France and the desperate need for online privacy there, as well. Small business owners in France need to make sure that they are in compliance with the laws; similarly, public WiFi users in France need to make sure they never connect without a VPN.</p>
																	</div>
														</div>
														

																				</article></div>]]>
            </description>
            <link>https://www.cozyit.com/french-bar-owners-arrested-for-offering-free-wifi-but-not-keeping-logs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678702</guid>
            <pubDate>Sun, 04 Oct 2020 12:59:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music Production Masterclass: Kilian Bohn]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24678374">thread link</a>) | @tosh
<br/>
October 4, 2020 | https://www.artlapinsch.com/kilian/ | <a href="https://web.archive.org/web/*/https://www.artlapinsch.com/kilian/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>During the covid lockdown in 2020 I picked up <a href="https://www.artlapinsch.com/logic-pro-x/">music production</a>. </p><p>After a few remix projects a <a href="https://www.artlapinsch.com/liam/">friend</a> and I decided to collaborate on a documentary <em>(subject: being stuck in Guatemala during the global lockdown)</em>. </p><ul><li><strong>My Goal:</strong> Deliver a 4-track EP <em>(movie soundtrack)</em> before the end of the year</li><li><strong>Accountability:</strong> Be accountable to my collaborators <em>(director + mastering engineer)</em></li><li><strong>Learning:</strong> Learn the entire process of album production <em>(composition; instrumentation; arrangement; mixing; mastering; distribution)</em></li></ul><p>This post is a summary of the collaboration and learning experience with Kilian - my mastering engineer.</p><hr><h2 id="kilian-working-with-a-full-stack-music-producer">Kilian: Working with a Full-Stack Music Producer</h2><p>Kilian Bohn is a multiple award-winning sound engineer, music producer and lecturer. </p><p>Most importantly, he's a good friend. </p><figure><img src="https://www.artlapinsch.com/content/images/2020/10/kilian-1.jpg" alt="" srcset="https://www.artlapinsch.com/content/images/2020/10/kilian-1.jpg 600w"><figcaption>Kilian Bohn: Music Production Brain [source: <a href="https://xpsr.de/markenmanufaktur/about/">https://xpsr.de/markenmanufaktur/about/</a>]</figcaption></figure><ul><li><strong>Taste:</strong> <a href="https://open.spotify.com/playlist/2da4IuA8KMYL7eZKk5Nv7U?si=e-on-FehRRWiKkJR1HzZ4g">10 hand-selected tracks by Kilian</a></li><li><strong>Expertise:</strong> Music Production; Engineering; Mixing; Mastering</li></ul><hr><h3 id="the-collaboration-how-to-work-with-a-mixing-mastering-engineer">The Collaboration: How to Work With a Mixing/Mastering Engineer</h3><p>There's no one-size-fits all solution to music production and collaboration since different teams split the workloads differently <em>(composition; instrumentation; arrangement; mixing; mastering)</em>. </p><figure><img src="https://www.artlapinsch.com/content/images/2020/10/template-10.png" alt="" srcset="https://www.artlapinsch.com/content/images/size/w600/2020/10/template-10.png 600w, https://www.artlapinsch.com/content/images/size/w1000/2020/10/template-10.png 1000w, https://www.artlapinsch.com/content/images/size/w1600/2020/10/template-10.png 1600w, https://www.artlapinsch.com/content/images/2020/10/template-10.png 2388w" sizes="(min-width: 1200px) 1200px"><figcaption><strong>Stages of Music Production:</strong> A visualization of the steps involved</figcaption></figure><p>Our workflow looked like this:</p><ol><li><strong>Kick-off Call:</strong> Artist and engineer discuss the scope <em>(4 tracks) and</em> idea <em>(soundtrack with a cohesive story arc)</em> of the project</li><li><strong>Track Draft:</strong> Artist sends track draft once they are at a first-presentable-draft stage <em>(= arrangement is set; first version of mix complete)</em></li><li><strong>Feedback &amp; Discussion:</strong> Engineer provides feedback and indicates if major fixes <em>(e.g. instrumentation; arrangement; mix/levels; technical [file; etc.])</em> are needed before the master draft. Artists makes adjustments if needed.</li><li><strong>Master Draft:</strong> Engineer sends master draft</li><li><strong>Feedback &amp; Discussion:</strong> Artist provides feedback and indicates if master is not fully aligned with artistic vision <em>(e.g. general sound [too loud/silent; dynamic range]; sound at certain points; etc.)</em></li><li><strong>Rinse &amp; Repeat:</strong> Artist and engineer work through track draft and master draft loops until both are happy</li></ol><figure><div><div><p><img src="https://www.artlapinsch.com/content/images/2020/10/Screenshot-2020-07-29-at-18.19.33--2-.png" width="2560" height="1440" alt="" srcset="https://www.artlapinsch.com/content/images/size/w600/2020/10/Screenshot-2020-07-29-at-18.19.33--2-.png 600w, https://www.artlapinsch.com/content/images/size/w1000/2020/10/Screenshot-2020-07-29-at-18.19.33--2-.png 1000w, https://www.artlapinsch.com/content/images/size/w1600/2020/10/Screenshot-2020-07-29-at-18.19.33--2-.png 1600w, https://www.artlapinsch.com/content/images/size/w2400/2020/10/Screenshot-2020-07-29-at-18.19.33--2-.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.artlapinsch.com/content/images/2020/10/Screenshot-2020-08-17-at-12.16.32.png" width="3584" height="2240" alt="" srcset="https://www.artlapinsch.com/content/images/size/w600/2020/10/Screenshot-2020-08-17-at-12.16.32.png 600w, https://www.artlapinsch.com/content/images/size/w1000/2020/10/Screenshot-2020-08-17-at-12.16.32.png 1000w, https://www.artlapinsch.com/content/images/size/w1600/2020/10/Screenshot-2020-08-17-at-12.16.32.png 1600w, https://www.artlapinsch.com/content/images/size/w2400/2020/10/Screenshot-2020-08-17-at-12.16.32.png 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://www.artlapinsch.com/content/images/2020/10/Screenshot-2020-08-11-at-10.28.39.png" width="1675" height="1411" alt="" srcset="https://www.artlapinsch.com/content/images/size/w600/2020/10/Screenshot-2020-08-11-at-10.28.39.png 600w, https://www.artlapinsch.com/content/images/size/w1000/2020/10/Screenshot-2020-08-11-at-10.28.39.png 1000w, https://www.artlapinsch.com/content/images/size/w1600/2020/10/Screenshot-2020-08-11-at-10.28.39.png 1600w, https://www.artlapinsch.com/content/images/2020/10/Screenshot-2020-08-11-at-10.28.39.png 1675w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.artlapinsch.com/content/images/2020/10/Screenshot-2020-08-11-at-14.57.42.png" width="2560" height="1440" alt="" srcset="https://www.artlapinsch.com/content/images/size/w600/2020/10/Screenshot-2020-08-11-at-14.57.42.png 600w, https://www.artlapinsch.com/content/images/size/w1000/2020/10/Screenshot-2020-08-11-at-14.57.42.png 1000w, https://www.artlapinsch.com/content/images/size/w1600/2020/10/Screenshot-2020-08-11-at-14.57.42.png 1600w, https://www.artlapinsch.com/content/images/size/w2400/2020/10/Screenshot-2020-08-11-at-14.57.42.png 2400w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption><strong>Show and Tell:</strong> It's easier to send screenshots and/or do quick video calls to explain what's going on <em>(clockwise: hi-hat setting + frequency spectrum; mug shot; arrangement discussion; automation view)</em></figcaption></figure><h3 id="tools-rules-making-our-lives-easier">Tools &amp; Rules: Making our Lives Easier</h3><p>We mainly used the following tools: </p><ul><li><strong><a href="https://www.artlapinsch.com/logic-pro-x/">Logic Pro X:</a></strong> My DAW of choice</li><li><strong>Ableton Live:</strong> Kilian's workbench for mastering workflows</li><li><strong>Phone/Zoom:</strong> Quick discussion about drafts + next steps</li><li><strong>Email/Text:</strong> Written feedback on tracks</li><li><strong><a href="https://wetransfer.com/">WeTransfer</a>/<a href="https://nextcloud.com/">NextCloud</a>:</strong> File sharing <em>(wav audio files) </em></li></ul><p>To keep our work efficient we followed a few simple rules: </p><ul><li><strong>Files:</strong> Bounce/export tracks as wav files with 96kHz sample rate</li><li><strong>Naming:</strong> Each new update to the track gets a version number <em>(e.g. [TRACK]_<strong>v001</strong>)</em> and each bounce/export gets an additional collaboration number <em>(e.g. [TRACK]_vo14 - <strong>bounce v001</strong>)</em>. This makes it easier to reference versions</li></ul><hr><h2 id="principles-kilian-s-guidelines-for-successful-music-production">Principles: Kilian's Guidelines for Successful Music Production</h2><blockquote>Applications are easy if you understand the principles.</blockquote><h3 id="-1-identify-the-main-elements-of-a-track">#1 Identify the Main Elements of a Track</h3><p>Our brains can process ~4 inputs/items at once. Not more. </p><p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864034/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2864034/</a></p><blockquote><strong>Working memory storage capacity</strong> is important because cognitive tasks can be completed only with sufficient ability to hold information as it is processed. The ability to repeat information depends on task demands but can be distinguished from a more constant, underlying mechanism: <strong>a central memory store limited to 3 to 5 meaningful items in young adults.</strong> </blockquote><p>For music production this means that you should have at max 4 main elements. </p><p>A typical combination could look like this: </p><ol><li><strong>Rhythm:</strong> Kick + Percussion</li><li><strong>Lead:</strong> Vox/Synth/etc.</li><li><strong>Melody:</strong> Bass/Pads/etc.</li></ol><p>Many times a track will have more elements, but the idea is to understand which sounds are the most important ones.</p><p>It's a good rule of thumb to think about relative importance of elements. Focus most of your time on them.</p><p><strong>Important:</strong> This helps to avoid too many elements competing in similar frequency bands <em>(example: vox; guitar; piano; synth in the same Hz range)</em>.</p><hr><h3 id="-2-a-little-goes-a-long-way">#2 "A Little Goes a Long Way"</h3><p>Listen and trust your ears. </p><p>When making changes in the arrangement, mix, or master it is usually enough to make a small change.</p><blockquote>One of the biggest mistakes people make is that they change too much and it tilts the balance of the entire track. Then you have to rework again. That's why 'a little goes a long way'.</blockquote><hr><h3 id="-3-an-instrument-is-a-combination-of-many-sounds">#3 An Instrument Is a Combination of Many Sounds</h3><blockquote>Many people think that an instrument is only composed of a single sound, but <strong>that's an illusion</strong>. Think of a guitar, it is a combination of the following sounds: the pick hitting the string, the hand grabbing the frets, the vibration of the string, the vibration of the guitar's body, and so much more.</blockquote><p>Once you understand the various frequency ranges at which each instrument works you can start to play with those to create the desired sound.</p><p>A great primer for this concept is the video below:</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/Wx_kugSemfY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><hr><h3 id="-4-something-for-the-hip-and-something-for-the-head">#4 "Something for the Hip and Something for the Head"</h3><p>You can think about music in two basic layers: </p><ol><li><strong>[</strong>Foundation<strong>] Something for the Hip:</strong> A groove and rhythm that makes you want to dance and shake your booty. Usually it is the kick drum, the percussive elements and the bass sounds. </li><li><strong>[</strong>Embellishment<strong>] Something for the Head:</strong> Melodic elements that make your head pay attention. Usually it is the vocals/vox, keys, string instruments, synthesizers, etc.</li></ol><hr><h3 id="-5-tension-release">#5 Tension &amp; Release</h3><p>Tension and release is my favorite principle, since it has many applications beyond music:</p><ul><li><a href="https://twitter.com/george__mack/status/1292206039576780806?s=20">Professional/physical performance</a></li><li>Physical exercise</li><li>Negotiation</li><li><a href="https://www.duarte.com/presentation-skills-resources/move-presentation-audience-with-story-techniques-in-presentations/">Story telling</a></li><li><em>... the list goes on</em></li></ul><p>For music you can think about tension and release in the following terms: </p><ul><li><strong>Composition:</strong> Harmonic sequences that form a story <em>(watch the video below for a good introduction👇)</em></li><li><strong>Instrumentation:</strong> Soft vs. harsh instrument; deep vs. high pitch; left vs. right <em>(= panning)</em></li><li><strong>Arrangement:</strong> Verse/Chorus vs. Intro/Outro/Bridge/Breaks</li><li><strong>Mixing:</strong> Compression of sounds <em>(release)</em> based on trigger inputs <em>(tension)</em></li></ul><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/eRkgK4jfi6M?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><hr><h2 id="techniques-practical-insights-for-music-production">Techniques: Practical Insights for Music Production</h2><p>A <a href="https://www.youtube.com/watch?v=pdUXHZU8dSs">basic understanding</a> of mixing is required to understand the content below.</p><h3 id="-1-mixing-sequence-and-focus">#1 Mixing Sequence and Focus</h3><p>Similar to the first principle <em>(<strong>#1 Identify the Main Elements of the Track</strong>)</em> you should focus most of your time mixing the main elements.</p><p>You would do that like so: </p><ol><li>Identify main elements</li><li>Group similar elements <em>(e.g. Kick + off-Kick)</em> into Sub-/Mixing-Groups</li><li>Start mixing <em>(levels; compression; FX; etc.)</em> those main elements and mute all other tracks</li><li>Once main elements are mixed you unmute and mix the rest</li></ol><p><strong>Pro Tip:</strong> <a href="https://www.musicianonamission.com/mixing-mono/">Start Mixing in Mono</a></p><hr><h3 id="-2-pulling-the-listener-into-the-mix">#2 Pulling the Listener Into the Mix</h3><p>Great tracks pull the listener into the music. </p><p>This is done via presentation of a noticeable element <em>(example: lead synth)</em> and a gradual reduction of volume of that element relative to the rest of the instruments. It's almost like pulling the listener's attention by its hand and '<em>dragging them into the mix'</em>.</p><p>A great example of that technique is the following statement by producer Maya Jane Coles from her <a href="https://www.residentadvisor.net/features/3558">Resident Advisor interview</a>: </p><blockquote>I often layer multiple different sounds that cover four frequency ranges, especially with bass. There'll be a very filtered low, low sub below 100 Hz that sounds very muted, then the more solid, mono mid-range sound. If I'm creating a wobble bassline, then I'll make the cutoff frequency of the filter vary to create some movement. On top of that I'll have a more high-frequency, low-cut bass sound, and I'll filter that in and out throughout the whole track. <strong>I'll record the automation from start to finish so that there's never a static part and it's always changing a little bit.</strong><p>That's especially important when the track revolves around a bassline, as with a lot of Nocturnal Sunshine stuff. I'll try and make sure that there's never eight bars where the bass is all flat and the movement is the same. Say automation is controlling the filter of one of the layered parts of the bass. <strong>Even if all the other three layered parts stay the same, it creates movement within that sound.</strong> A listener wouldn't necessarily know that that sound's created with three or four layers. It just gives it a slightly fuller sound with the movement.</p></blockquote><hr><h3 id="-3-mixing-depends-on-context">#3 Mixing Depends on Context</h3><p>The world is changing, and so are the expectations to what music should sound like. </p><p><em>(This is an entire rabbit hole in itself and I can recommend "<strong>How Music Works</strong>" by David Byrne [<a href="https://amzn.to/2GkJAkU">affiliate link</a>] where he discusses this at length)</em></p><p>One of the first feedbacks I received from Kilian was the following:</p><blockquote>Your tracks are very beautiful and nicely arranged. The one thing that I noticed was that the mix was very symphonic - meaning it had a very large dynamic range. <p>Usually this happens when people listen to a lot of organically produced music - like classic - and when they mix on headphones.</p></blockquote><p>Both was true.</p><blockquote>If the context of the music would be to have these tracks only as silent background for a movie it would work, but if you want the tracks to work in a club setting then we need to make some adjustments. <p><strong>Modern music has an unnatural amount of <a href="https://www.artlapinsch.com/hearing-protection/">sound pressure</a></strong> - particularly in the lower frequencies. </p><p>On top, there is a loudness war, every producer wants her tracks to be as loud as the references from beatport. </p><p>The reference tracks on beatport are compressed to death and therefore are consistently loud - on headphones and most importantly in the club.</p></blockquote><p>Since my goal was to have tracks that could be played in a club/festival setting we needed to do some extra work.</p><hr><h3 id="-4-sequential-sidechain-compression">#4 Sequential Sidechain Compression</h3><p><a href="https://blog.liveschool.net/breakdown-kaytranada-crafts-beats/">Many producers use sidechain compression</a> to give more space for their kick drum. </p><p><u>Example:</u> Kick drum hits and triggers a sidechained compression of another element <em>(in most cases a sub-bass or a synth)</em>.</p><p>But... it gets interesting once you start using sidechain compressions on multiple mix groups in similar frequency bands.</p><p>Let's assume you have vox, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.artlapinsch.com/kilian/">https://www.artlapinsch.com/kilian/</a></em></p>]]>
            </description>
            <link>https://www.artlapinsch.com/kilian/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678374</guid>
            <pubDate>Sun, 04 Oct 2020 12:05:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic Rules of Reason (1933)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24678313">thread link</a>) | @hkhn
<br/>
October 4, 2020 | https://www.simplish.org/readings/basic-rules-reason/ | <a href="https://web.archive.org/web/*/https://www.simplish.org/readings/basic-rules-reason/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
<h2>Division of sections </h2>
<ol type="I">
	<li><a href="#to-the-reader">To the reader</a></li>
	<li><a href="#language-machine">Language Machine</a></li>
	<li><a href="#theory-of-knowledge">Theory of Knowledge</a></li>
	<li><a href="#theory-of-connections">Theory of Connections</a></li>
	<li><a href="#theory-of-instruments">Theory of Instruments</a></li>
	<li><a href="#list-of-chief-senses">List of the Chief Senses of some Key Words in Discussion</a></li>
</ol>
<h2 id="to-the-reader">To the reader</h2>

<p>
	   This little book is in Basic English. It is a first attempt to put some  chief parts of the science which has rightly been named ' the key to knowledge  ' into the new language which is becoming month by month the international  language of the Earth. For those who have no knowledge of Basic, a list of  books about it has been printed on the last page. The rules for working the 850  words here used (all of which are printed at the front, on one side of a bit of  business notepaper) are given in <i>Basic English</i> and in the <i>ABC</i> ;  and the different forms and uses of the words themselves are made clear in <i>The  Basic Words.</i> </p>
<p><br>
    As to my experience in using this language ; I am not conscious  that at any point I have said anything which is in any way different from what  I had in mind to say, or that I have been forced to say it in a way which is  less clear, or less in harmony with my purpose than the other ways which would,  with a longer Word List, have been open to me. In fact, very frequently the  opposite has been true ; the simple language has been better for this sort of  work than a more complex language. About half of the book is an account of  views with which everyone who has any experience with these questions will be  in agreement. The other half is only a statement of my opinions about points on  which agreement is unhappily not possible in the present conditions of  knowledge. But when what is said is wrong, the error is to my thought, not in  the language, and may be put right without the use of more or different words. </p>
<p><br>
   For suggestions on points of detail in the writing I am in debt to  Miss Lockhart of the Orthological Institute. <br>
  I. A. R. <br></p>
 <p> <i>Magdalene</i><i> College, Cambridge</i></p>


<h2 id="language-machine">Langage Machine</h2>
<div><p><i> An idea in the mind is to a Natural Law as the power of seeing is to  light.</i>  S. T. Coleridge, on  Shakespeare's use of language.</p><p>
     
    The purpose of this book is to give a clear account of how we may  best put our thought in order, of if we are not able quite to do this, how we  may best make a serious attempt in this direction. To put our thoughts in order  is to make them come into agreement with things, to make them give us a truer  picture, a representative map or instrument for guiding our acts, so that men  may give effect to as great a number of their desires as possible. The name of  the general theory of how to do this is ' Logic '. As Bentham said, ' Logic is  the art which has for its end (or purpose) the giving, in the best way,  direction to the mind '. This direction is chiefly a power of keeping the divisions  between our thoughts in the right places, and the right places are only the  places in which, for the purpose in view, we have a need to put them, and the  places in which other for their purposes have put them. </p></div>
<div><p>
    Another very great authority -- Charles Saunders Pierce -- gave  as his account of Logic : that it is the theory of good behaviour in thought,  in the sense in which good behaviour is the use of self-control for the purpose  of making our desires come about. (His words were, "Logic is the ethics of  thinking, in the sense in which ethics is the bringing to bear of self control  for the purpose of realizing our desires.") Because we are only able to  put and keep our thoughts in control by the help of language, and because of  control of language, for this purpose, is the control of the senses of our  words, a great part of Logic, as Bentham and Pierce saw it, becomes the theory  and right use of the senses of our chief words -- those upon which the ordering  of the senses of our other words is dependent. The senses of these chief words  -- and their ways of working with or against one another -- are the rules of  reason There are not (1) the sense and (2) rules for putting them together ;  but the senses themselves give us, in their ways of acting, the rules of  reason. </p><p>
    
    p. 10 . . . . . . (more) . . . for 11 pages . . . </p><p>
    
    After these first pages about the purpose and need of a better  apparatus for controlling the senses of our words, we may go on freely to the  necessary work.</p></div>

<h2 id="theory-of-knowledge">Theory of Knowledge</h2>
<p>   Let us take the most important word, in the theory of the comparison of  senses and in the work of taking statements to bits for the purpose of  comparison, and make lists of their chief senses. We will give numbers to these  senses, so that we may put a finger on them, without trouble, when in the  process of discussion it becomes necessary to give them separate attention. We  will be able to see -- together and on one page -- the chief senses which may  be coming into use at this point in the discussion. We will then see not only  which tricks and twists we will have to keep in mind, but -- and this is more  important -- the other possible theories. </p>
<p>
    The first reaction of most readers to number (12-112, 3-24 and so  on) in pages put before them is normally fear mixed with disgust. It is hoped,  however, that here the great help which such numbering gives in keeping  different things separate will make you more kind to them. Without them I would  be forced to make the discussion at least three times longer, and to say the  same thing even more frequently than I do. A numbered list at the end of the  book in which lists of all the senses of the key-words are printed together in  their numbered order will make the necessary looking forward and back as little  trouble as possible. These numbers are only names for the sense, names which  make their positions in relation to one another clear to the eye. A number like  5-12 makes us see that the sense it is a name of is a division of sense 5-1 ;  9-211 and 9-212 are different divisions or special forms of 9-21 and so on.</p>
<p> <br>
    I give in my account only some of the reasons for making the  divisions where I do. The apparatus is a machine for separating the senses of  other words when it is necessary to do so. The test of the value of our  divisions is the amount of help they give us. It is important to keep in view  this fact that we are not here putting on paper something which is given to us,  so much as making a machine -- a machine for controlling thought which will let  us do some things and keep us from doing other things. It is a good machine if  it is of use to us ; any changes which will make it of more use to us will make  it better. They are not able to be tested in any other way than this. If the  reader is troubled by this word <i>use</i> here, a look at <i>necessary,</i> sense 17-12, in the list at the end of the book, may make the point clearer. </p>
<p>
    On the other hand, if it is to be of use, it is necessary to keep  some of the divisions in the places in which our minds normally put them. The  attempt to make a machine like this is, in fact, a way (and the best way) to  the discovery of how our minds do their work. But, as we will see, our minds do  their work in a number of different ways. They put the chief divisions, upon  which all the other are dependent, in a number of different places for  different purposes. </p>
<p>So a number of different machines are possible and  necessary. Very little of the theory of the connections between these possible  machines has been worked out. The history of thought is still waiting for such  a theory. The experts have had enough to do putting their machines together or  attacking the machines of other experts. They have not made the right sort of  comparisons, and their machines have not been put together for this purpose.  This sad condition of our theories will seem very strange in the future,  because the work is important. The histories of different nations make their  ways of thought different ; and the fact that they are different will, in the  end, be of value to us all. But there is no need for them to be out of all  relation to one another ; as they are now. The machine which is put together in  these pages is for the connection of different systems of thought -- of  different men, nations, governments, sciences, religions, societies -- with one  another. To get things into clear relations to one another we have first to  take them to bits. But the purpose is new knowledge and new buildings, not  destruction. This machine is only one of a number of possible machines ; it  will be tested by the work which it lets us do. </p>
<p>
    The most important words in this machine are :  </p>
<table>
	<thead>
		<tr><th>Theory of Knowledge</th>
		<th>Theory of Connections</th>
		<th>Theory of Instruments</th>
	</tr></thead>
  	<tbody>
  		<tr>
  			<td>Through 1</td>
  			<td>Cause 9</td>
  			<td>Property 12</td>
  		</tr>
		<tr>
		    <td>Thing 2</td>
		    <td>Effect</td>
		    <td>Is 13</td>
		</tr>
		<tr>
		    <td>Fiction 3</td>
		    <td>Force</td>
		    <td>General 14</td>
		</tr>
		<tr>
		    <td>Fact 4</td>
		    <td>Event</td>
		    <td>Special</td>
		</tr>
		<tr>
		    <td>Knowledge 5</td>
		    <td>Law 10</td>
		    <td>Quality 15</td>
		  </tr>
		  <tr>
		    <td>Belief 6</td>
		    <td>Part 11</td>
		    <td>Relation 16</td>
		  </tr>
		  <tr>
		    <td>True 7</td>
		    <td>System</td>
		    <td>Necessary 17</td>
		  </tr>
		  <tr>
		    <td>Sense 8</td>
		    <td>Change</td>
		    <td>Possible 18</td>
		  </tr>
		  <tr>
		    <td></td>
		    <td>Same</td>
		    <td>Probable 18</td>
		  </tr>
		  <tr>
		    <td></td>
		    <td></td>
		    <td>Sort</td>
		  </tr>
		  <tr>
		    <td></td>
		    <td></td>
		    <td>Degree </td>
		  </tr>
		  <tr>
		    <td></td>
		    <td></td>
		    <td>Agreement</td>
		  </tr>
	</tbody>
</table>
<p>
    I take them in these three groups because the sort of discussion  I give them is changed from one group to another. The senses of the words int  he last group, for example, have not quite the wide and free ways of being  different from one another which those in the first group have. A group is a  unit, but senses from all three of them have at times to be kept in view  together. </p>
<p>
    With accounts of the chief senses of these key-words before us on  paper in clear lists, the worst troubles of all discussion will in a short time  be seen to give the best chances for new discoveries. they will no longer be,  as they are now causes of unfertile doubt and complex errors. The lists in this  book will at first not be complete and clear enough to give us every sense  which is needed. But even list which are not complete will let us see much  which we do not now naturally see without them. Even a bad attempt will be much  better than no attempt at all. </p>
<p>
    In giving lists of the senses of those words which I take first I  have to make use, in special senses, of those which come later. The numbers put  with these …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simplish.org/readings/basic-rules-reason/">https://www.simplish.org/readings/basic-rules-reason/</a></em></p>]]>
            </description>
            <link>https://www.simplish.org/readings/basic-rules-reason/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678313</guid>
            <pubDate>Sun, 04 Oct 2020 11:56:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Ways of DevOps]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24678055">thread link</a>) | @kiyanwang
<br/>
October 4, 2020 | https://ermetic.com/whats-new/blog/the-three-ways-of-devops/ | <a href="https://web.archive.org/web/*/https://ermetic.com/whats-new/blog/the-three-ways-of-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>			
				<article>
			<header>
				<img src="https://ermetic.com/wp-content/uploads/2020/09/DevOps-header_933x300.jpg" alt="">				
				
				<p>By Tanya Janca, CEO and Founder of WeHackPurple, September 30, 2020</p>
				<p>
	share:
	<a target="blank" href="http://twitter.com/home/?status=The%20Three%20Ways%20of%20DevOps%20-%20https://ermetic.com/?p=1310%20via%20@kenmata" title="Tweet this!"><span></span></a>
	<a target="blank" href="http://www.facebook.com/sharer.php?u=https://ermetic.com/whats-new/blog/the-three-ways-of-devops/%20-%20https://ermetic.com/?p=1310" title="Share on Facebook!"><span></span></a>
		<a target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://ermetic.com/whats-new/blog/the-three-ways-of-devops/%20-%20%20https://ermetic.com/?p=1310;source=LinkedIn" title="Share on LinkedIn!"><span></span></a>
</p>			</header>
			<section><p>In this article we will explore applying the security concept of least privilege to your cloud instances, within a DevOps environment, without adding bulk and delays to your pipeline.</p>
<p>DevOps is not a tool that you buy, or the act of using pipeline software to release your code, it is so much more. Let’s define DevOps, then the three ways, then letâ€™s apply least privilege.</p>
<p><em>Although there are many different definitions of exactly what DevOps is, the most popular definition is from the Phoenix project and the DevOps Handbook. We will follow this definition in this article.</em></p>
<p>DevOps is a way of developing software, as well as a culture within a software development shop, and a mixture of processes and tooling that helps you get there.</p>
<h3>In Order to do DevOps, You Must Follow the Three Ways of DevOps</h3>
<p><em>The first way of DevOps</em> is to emphasize the speed and efficiency of the entire system, instead of just your part. Sometimes this means that you have to help another team do their work, rather than your own, because that will make the entire system so much better. Sometimes this means, asking for help from other teams. Often, automation helps with this, which is why we use a DevOps pipeline software, in order to release and deploy our code quickly and efficiently. Automation generally results in fewer errors, and it almost always results in much faster results. This is the first way of DevOps.</p>
<p><em>The second way of DevOps</em> is fast feedback. This means getting feedback to the correct person or people, in a timely manner. It also means the feedback needs to be accurate, because feedback that is inaccurate is not only unhelpful, it is potentially harmful. We add security testing, and all sorts of other quality tests, to our pipeline software in order to ensure the code that we are creating is high quality, and so that we get very fast feedback. That said, a pipeline is not the only way that you can get feedback, we will talk about this when we apply least privilege.</p>
<p><em>The third way of DevOps</em> is continuous learning. This means setting time aside on a regular basis to improve your daily work. Sometimes this means training. Sometimes this means tuning your tools or doing a proof of concept of several new tools that you are considering ensuring that the one you choose is the absolute best for your specific business needs. Sometimes this means introducing artificial intelligence and machine learning into your systems or tooling, to ensure that it is continuously learning. The point being that you want to be in a constant state of striving for improvement.</p>
<p>Quite often when people think of DevOps, they assume that every single tool or test must go into the pipeline. This is not true. We need to abide by the three ways of DevOps, and that definitely means using pipeline software and putting security tests inside of it, but our work is not done with just that. We cannot possibly complete all of our security requirements within a pipeline.</p>
<h3>Least Privilege and the Three Ways</h3>
<p>Let’s look at how we can implement the concept of <em>least privilege</em> to our cloud processes within a DevOps environment, and how it relates to each of the three ways.</p>
<p>Now we could attempt to put some tests for least privilege in our DevOps pipeline, however, what would we test for? If a permission is included in the pipeline, it’s likely because the software developer assumed that they would need it. What test could we put in a pipeline that would clarify whether or not a permission was actually required? To see if it is in use, or not? This means, it is unlikely we can test for this in our pipeline.</p>
<p>Instead of putting a test in the pipeline, we could set up monitoring in our systems of new processes, to watch which permissions are actually being used and which are not. Whichever permissions are not being used, could be removed, in order to implement<em> least privilege</em>. Now, let’s look at how we can apply this to <em>the three ways</em> of DevOps.</p>
<p>The first of the three ways, to repeat, is speed and efficiency of the entire system. By not putting a tool like this in the pipeline, this would not slow the pipeline down, and that would increase the speed of the system. Instead, we could create automation outside the pipeline, to ensure that this work was done quickly and efficiently, that would obey the first rule for instance, if we had a monitoring tool that did this for us. Letâ€™s take this imaginary monitoring system with us to the next way.</p>
<p>The second way is fast, accurate and timely feedback. Letâ€™s say our automated monitoring system that is watching all of our processes to see which permissions are being used, it gives feedback quickly and to the right people [the security team], that would be a very handy tool. If it could automate removing unused permissions, tell us if someone tries to use a removed permission, and shows us reports of both, that would certainly fit well into the second way. Having it also automate sending alerts and creating tickets would be a cherry on top of all of this; feedback going directly to who needs it.</p>
<p>The third way involves continuous learning. If our automated monitoring system, itself, can learn continuously from the traffic, access, and behavior of our cloud activity and users, then that respects the third way. A system that can train itself, learn when to remove permissions, when to replace permissions, and when to block access, not only respects the third way, it makes for a fantastic least privilege security tool. With enough learning (monitoring), a tool can even start to recommend which access policies would be the best option, given specific situations and previous decisions.</p>
<p>Although many people seem to think that DevOps tools need to go in a pipeline, this article makes it clear that you can still respect the three ways of DevOps and work within DevOps processes, without having your tool in the pipeline. And gain fantastic security results to boot!</p>
<p><a href="https://l.ermetic.com/get-a-demo" target="_blank" rel="noopener noreferrer">Find out how Ermetic can help you continually enforce least privilege access in your cloud environment.</a></p>
<p><strong>About the Guest Author</strong></p>
<p>Tanya Janca, also known as <a href="https://shehackspurple.ca/" target="_blank" rel="noopener noreferrer">SheHacksPurple</a>, is the author of â€˜Alice and Bob Learn Application Securityâ€™. She is also the founder of <a href="https://wehackpurple.com/" target="_blank" rel="noopener noreferrer">We Hack Purple</a>, an online learning academy, community and weekly podcast that revolves around teaching everyone to create secure software. Tanya has been coding and working in IT for over twenty years, won numerous awards, and has been everywhere from startups to public service to tech giants (Microsoft, Adobe, &amp; Nokia). She has worn many hats; startup founder, pentester, CISO, AppSec Engineer, and software developer. She is an award-winning public speaker, active blogger &amp; streamer and has delivered hundreds of talks and trainings on 6 continents. She values diversity, inclusion and kindness, which shines through in her countless initiatives.</p>
<p>Founder: We Hack Purple (Academy, Community and Podcast), WoSEC International (Women of Security), OWASP DevSlop, OWASP Victoria, #CyberMentoringMonday</p>
</section>
			
		</article>
				</div></div>]]>
            </description>
            <link>https://ermetic.com/whats-new/blog/the-three-ways-of-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678055</guid>
            <pubDate>Sun, 04 Oct 2020 11:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knolling]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24678050">thread link</a>) | @any1
<br/>
October 4, 2020 | https://andri.yngvason.is/knolling.html | <a href="https://web.archive.org/web/*/https://andri.yngvason.is/knolling.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Software development is a craft. We tend to call it “engineering”, but most of
the time, it feels more like plumbing or carpentry. Most of the time, completing
a task does not require any inventiveness. Sometimes we fool ourselves
into thinking that we are more than a craftsmen, engineers even, and in order to
verify our bias, we try to be clever where no inventiveness is required. This
only complicates things, both in the moment and the future.</p>

<p>Because software development is a craft, it is perhaps fair to deduce that
principles which apply to crafts also apply to computer programming. An efficient
workshop is, invariably, a tidy workshop, where every tool has its place.
Consistency is the key to completing tasks at a constant pace. When nothing is
amiss and there are no surprises, it is easy to make plans and execute them. To
keep a tidy workshop, you must <a href="https://www.youtube.com/watch?v=s-CTkbHnpNQ">always be knolling</a>.</p>

<p>An efficient team is, invariably, a team that keeps the code tidy and all
external aspects of it up to date. <em>Always be knolling</em>. This does not directly
contribute to the solution or success of the current task, but the current task
is not your entire job responsibility. In the long run, your job is to complete
tasks consistently and in accordance to specifications. If you’re held up by
ancillary tasks such as upgrading dependencies or unwinding an abstraction that
was meant to solve duplication that turned out to be incidental, then you have
failed to keep a tidy system.</p>

<p>Keeping a tidy system is not only useful to you as a programmer, it is also
useful for team leaders because it helps them to accurately report progress and
estimates to management. Another important aspect is the psychological well-being
of the team. A tidy system is a joy to work on. You do not dread a task because
you know that you are going to have to work on poorly maintained part of the
system or because you’ll have to edit code that offends your sensibilities.
Instead, what you get is the dopamine boost that comes with closing the task in
the issue tracker after you’ve completed it and verified that it works.</p>

<p>A software project is never complete. It can always be extended and changed to
take on new roles and fulfill new design criteria. This is perhaps also true
of physical items such a furniture, but software has more possibilities.
Notably, this is where software development differs from other crafts: it is
more dynamic. This is a an extremely powerful attribute of software. Just
imagine having the possibility of morphing a regular kitchen chair into a
wheelchair or a rocking-chair just by carving an incantation into its seat.</p>

<p>In order to exploit this powerful aspect of software that sets it apart from all
other things, it must be possible to actually make changes to the software. An
untidy system resists change and stands in the way of progress. By constantly
clearing away detritus, we can take advantage of software’s full potential.</p>

<p>Consistency enables change.</p>


  </div>

  
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://andri.yngvason.is/knolling.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24678050</guid>
            <pubDate>Sun, 04 Oct 2020 11:12:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lambda Calculus Diagrams (2015)]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24677614">thread link</a>) | @fanf2
<br/>
October 4, 2020 | https://tromp.github.io/cl/diagrams.html | <a href="https://web.archive.org/web/*/https://tromp.github.io/cl/diagrams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


Lambda Diagrams are a graphical notation for closed lambda terms,
in which abstractions (lambdas) are represented by horizontal lines,
variables by vertical lines emanating down from their binding lambda,
and applications by horizontal links connecting the leftmost variables.
In the alternative style, applications link the nearest deepest variables,
for a more stylistic, if less uniform, look.
<p>

The following table shows diagrams of identity, the booleans, some standard combinators,
some Church numerals, the predecessor function on Church numerals, and Omega.

<table>
<tbody><tr> <td>term</td><td>definition</td> <td>diagram</td> <td>alternative</td> </tr>
<tr> <td>I/1</td> <td> λx.x</td>
  <td><img src="https://tromp.github.io/img/cl/I.gif"></td><td> </td></tr>
<tr> <td>K/true</td> <td> λx.λy.x</td>
  <td><img src="https://tromp.github.io/img/cl/K.gif"></td><td> </td></tr>
<tr> <td>false/0</td> <td> λx.λy.y</td>
  <td><img src="https://tromp.github.io/img/cl/false.gif"></td><td> </td></tr>
<tr> <td>S</td> <td> λx.λy.λz.(x z)(y z)</td>
  <td><img src="https://tromp.github.io/img/cl/S.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/S.alt.gif"></td> </tr>
<tr> <td>Y</td> <td> λf.(λx.x x)(λx.f(x x))</td>
  <td><img src="https://tromp.github.io/img/cl/Y.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/Y.alt.gif"></td> </tr>
<tr> <td>2</td> <td> λf.λx.f(f x)</td>
  <td><img src="https://tromp.github.io/img/cl/2.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/2.alt.gif"></td> </tr>
<tr> <td>3</td> <td> λf.λx.f(f(f x))</td>
  <td><img src="https://tromp.github.io/img/cl/3.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/3.alt.gif"></td> </tr>
<tr> <td>4</td> <td> λf.λx.f(f(f(f x)))</td>
  <td><img src="https://tromp.github.io/img/cl/4.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/4.alt.gif"></td> </tr>
<tr> <td>pred</td> <td> λn.λf.λx.n(λg.λh.h(g f))(λu.x)(λu.u)</td>
  <td><img src="https://tromp.github.io/img/cl/pred.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/pred.alt.gif"></td> </tr>
<tr> <td>fac</td> <td> λn.λf.n(λf.λn.n(f(λf.λx.n f(f x))))(λx.f)(λx.x)</td>
  <td><img src="https://tromp.github.io/img/cl/fac.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/fac.alt.gif"></td> </tr>
<tr> <td>fib</td> <td> λn.λf.n(λc.λa.λb.c b(λx.a (b x)))(λx.λy.x)(λx.x)f</td>
  <td><img src="https://tromp.github.io/img/cl/fib.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/fib.alt.gif"></td> </tr>
<tr> <td>Ω</td> <td> (λx.x x)(λx.x x)</td>
  <td><img src="https://tromp.github.io/img/cl/Omega.gif"></td>
  <td><img src="https://tromp.github.io/img/cl/Omega.alt.gif"></td> </tr>
</tbody></table>
Curiously, the alternative Omega diagram somewhat resembles an (upside-down) Omega.
</p><p>
And here, on a larger scale, is a prime number sieve (alternative style): </p><p>
<img src="https://tromp.github.io/img/cl/primes.alt.gif">
</p><p>
which reduces to an infinite list of booleans that starts out as
</p><p>
<img src="https://tromp.github.io/img/cl/primebits.gif">

</p><h2>Dimensions and complexity</h2>

In terms of pixels, a diagram's width is one less than 4 times the number of variables
(vertical lines),
and its height is one more than twice the maximum number of nested abstractions and applications
(one less for alternaitve diagrams with multiple variables).
<p>
The size of the binary encoding of a term is closely related to
the graphical complexity: it is exactly twice the number of lines
plus the number of (4-way) intersections.

</p><h2>Reduction</h2>

Beta-reduction on lambda diagrams can be shown in several steps, as demonstrated in this reduction
from Y=λf.(λx.x x)(λx.f(x x)) to λf.(λx.f(x x))(λx.f(x x))

<table>
<tbody><tr><td>initial term</td><td><img src="https://tromp.github.io/img/cl/Y.gif"></td></tr>
<tr><td>show application of abstraction</td><td><img src="https://tromp.github.io/img/cl/Y0.gif"></td></tr>
<tr><td>show bound variables and argument</td><td><img src="https://tromp.github.io/img/cl/Y1.gif"></td></tr>
<tr><td>expand function body</td><td><img src="https://tromp.github.io/img/cl/Y2.gif"></td></tr>
<tr><td>to make room for substitution</td><td><img src="https://tromp.github.io/img/cl/Y3.gif"></td></tr>
<tr><td>substitute argument for variables</td><td><img src="https://tromp.github.io/img/cl/Y4.gif"></td></tr>
<tr><td>final term</td><td><img src="https://tromp.github.io/img/cl/Y5.gif"></td></tr>
</tbody></table>

In the third frame, we show only the part of bound variables below abstractions, e.g. when
applying <img src="https://tromp.github.io/img/cl/applied.gif">, the function body x(λy.x) shows as <img src="https://tromp.github.io/img/cl/bound.gif">.

<h2>Diagrams In Motion</h2>

Paul Brauner has produced some awesome <a href="https://www.youtube.com/playlist?list=PLi8_XqluS5xc7GL-bgVrxpA2Uww6nK0gV">videos</a> of beta reductions, produced with this <a href="https://github.com/polux/lambda-diagrams">software</a>.
 
<h2> Related work</h2>
<a href="http://dkeenan.com/">Dave Keenan</a> has a comprehensive online paper
<a href="http://dkeenan.com/Lambda/">To Dissect a Mockingbird:
A Graphical Notation for the Lambda Calculus with Animated Reduction</a>,
which partly inspired this page.
<p>
In his <a href="http://bntr.planet.ee/lambda/work/visual_lambda.pdf">Master thesis</a>, Viktor Massalõgin discusses 4 existing graphical notations before introducing his own "bubble" notation. Figure 3 on page 10 shows 4 depictions of the fixpoint combinator (which differs from Y above in one beta reduction), while the bubble form is in Figure 5 on page 13.

</p><h3>Note</h3>

The diagram in the title, produced by the postscript code below, is a slightly deformed alternative Y diagram made to look like a Y.
<pre>%!PS-Adobe-2.0 EPSF-2.0
%%BoundingBox:0 0 118 110
/m{moveto}def/l{lineto}def/c{concat 6 m 0 6 l 7 8 m 0 8 l l l 3 6 l 2 6 m 7 6 l
3 4 m 6 4 l 6 6 l stroke}def 3 0 0 0 1[-8 4 0 8 60 9]c 3 2 0 2 2[-1 1 0 1 0 0]c
</pre>

<hr>
Back to my <a href="http://tromp.github.io/cl/cl.html">Binary Lambda Calculus page</a>. <br>


</div>]]>
            </description>
            <link>https://tromp.github.io/cl/diagrams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677614</guid>
            <pubDate>Sun, 04 Oct 2020 09:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dual licensing GPL for fame and profit]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24677481">thread link</a>) | @george3d6
<br/>
October 4, 2020 | https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-10-04</p>
        
<p>Dual licensing with GPL is the idea that if I own a certain piece of GPL code, I can also relicense it as a proprietary library. This is how Oracle licenses Java and how QT licenses QT.</p>
<h2>I - All rights for me but not for thee</h2>
<p>But my general feeling is that there is some stigma associated with this practice, to quote <a href="https://www.gnu.org/licenses/gpl-faq.en.html#ReleaseUnderGPLAndNF">gnu.org</a>:</p>
<blockquote>
<p>To release a nonfree program is always ethically tainted, but legally there is no obstacle to your doing this. If you are the copyright holder for the code, you can release it under various different non-exclusive licenses at various times.</p>
</blockquote>
<p>The "ethically tainted" doesn't resonate with me, I think this licensing model should be encouraged.</p>
<p>I will admit I am kind of biased on this because I work on a for-profit GPL-license project. But it strikes me as silly that this business model is shunned by the open-source community in favor of licensing under MIT/BSD.</p>
<p>Dual licensing is a way in which the "owner" of the code ends up in an advantageous position compared to other users.</p>
<p>That is to say, a user must abide by the strict rules of the GPL license:</p>
<ul>
<li>Release all modifications.</li>
<li>Potentially (depending on the specifics of the GPL license) have to release other projects that are used "in relation" to the library.</li>
<li>Not ship the code under a different license.</li>
</ul>
<p>The "owner" of the code abides by none of these and can thus benefit in ways that the users can't.</p>
<p>In the open-source utopia, where resources are aplenty for everyone, everything is open source and nothing is for sale, so dual-licensing doesn't fit that particular utopia. But we live in the real world, where money makes things a bit more complicated, and in the long term, dual-licensing might be better than equal-rights open licenses.</p>
<p>Well, developers have to eat.</p>
<p>Even worst, good software is made by good developers, developers which can get six-figure salaries designing skinner boxes. On the contingency that those developers aren't ideal altruists, they have to get way-above-subsistence salaries to work on useful open source projects instead of skinner boxes.</p>
<p>So if dual-licensing provides a middle ground for that which is better than the current situation where a lot of good software is proprietary, what's the harm?</p>
<p>Some would say it's a middle ground that will hamper the development of truly free software. But who release said truly free software anyway?</p>
<h2>II - Who release fully-free projects</h2>
<p>When it comes to license like MIT and BSD, that impose no restrictions upon usage, where the "owner" doesn't exist, it's interesting to look at who release projects under those licenses:</p>
<p>a) Students or hobbyists, people creating software for fun, notoriety, and experience.</p>
<p>b) Very large companies (Facebook, Google, Amazon, Uber) or government &amp; donation founded organizations (Universities, Public Research centers, software foundations such as GNU, Apache, and LSF)</p>
<p>The first group is one I don't wish to dismiss, I think a lot of important programs stem from here. But their end goal is not to work for free for their whole life. Usually, they moonlight for their open-source projects and work a paid gig to earn money. A small minority can be funded by donations, but it's a small minority.</p>
<p>The project I use for allowing comments on this website (<a href="https://github.com/umputun/remark42">remark42</a>), has 2.3k stars on GitHub and <a href="https://www.patreon.com/remark42/posts">earns 9$/month from donations</a>. The <a href="https://github.com/mindsdb/mindsdb">project I work on</a> has 2.9k stars on Github and an operating budget of <a href="https://venturebeat.com/2020/04/16/mindsdb-raises-3-million-for-open-source-automated-machine-learning/">a few million</a> dollars.</p>
<p>You can certainly get to a point where you are funded by donations, but the reality is that it's not a good enough incentive. Doubly so since the developers working on these projects are usually the "creme de la creme", releasing and maintaining truly useful software usually requires expertise only a small fraction of engineers have.</p>
<p>The second group, the corporation and government-funded teams can only exist because of the scale.</p>
<p>Why can Facebook develop PyTorch?</p>
<ul>
<li>Because Facebook hires so many ML engineers that in the cost-benefit analysis it's cheaper to have your internal framework be popular enough such that you can get already-trained people from day 1. The &lt; 100 people working full time on PyTorch save months of training for every single one of the thousands of ML people facebook hires, since it can hire people that already know PyTorch.</li>
<li>Because Facebook doesn't dominate by having better ML models, it dominates by having thousands of times more data than anyone else. It's in facebook's interest to keep research open since it's objective is not to get ahead, but just to stay even, or at least not fall significantly behind.</li>
</ul>
<p>Why can Nvidia assign engineers to dozens of open source ML and game-engine projects?</p>
<ul>
<li>Because Nvidia makes hundreds of billions each year selling GPUs. The little work they put into those libraries to make sure it works ideally with their GPUs is insignificant to the revenue they get from those markets.</li>
</ul>
<p>Why can Google develop TensorFlow?</p>
<ul>
<li>For about the same reasons as Facebook.</li>
<li>Because they can make a lot more money from selling/renting TensorFlow optimized hardware.</li>
</ul>
<p>And that's on the happier side of the spectrum. On the "shadier" end of the scale, one could argue projects like Flutter and Angular might be worth their investment because they make spyware-free browsers like Firefox send-class citizens in the war for the web, not to mention easier integration into internet-monopolizing schemas like AMP.</p>
<p>You've also got, I will admit, projects that seem to be open source purely for flexing. To my knowledge, Yandex might have well never released Clickhouse and the column-store database landscape would have been set back 10+ years for it. Why did they do it? Maybe just because few dozens of people working on it wanted to showcase how good they are.</p>
<p>But at the end of the day, this is not a reliable model</p>
<h2>III - Profit motives</h2>
<p>So would it not be nice for open source if one can bring profit motives into the whole thing?</p>
<p>Even better, profit from the people that don't support or contribute to open source, but not from those that do.</p>
<p>It seems to me like double-licensing with GPL achieves just that. One can release a project and charge large companies for using it, at the risk of breaking the license if they don't pay. Even if a lot of them will use the software illegally, as is the case now, the threat of lawsuits will end up deterring some or most heavy-users from doing so.</p>
<p>On the other hand, people using the project in an open-source project of their own have nothing to worry about.</p>
<p>The only problem that remains here is the fact that you can't chain GPL projects. That is to say, one can't use GPL code in their own double-licensed GPL code, but there are workarounds for that (e.g. isolating the GPL dependency and open-sourcing the changes to that alone). Still, this seems like the kind of problem that could be fixed by an off-shoot of the GPL meant for just this use-case.</p>
<p>This model keeps all the advantages of GPL, in that it incentives your users to open-source their product. It doesn't force them to do so, like a purely-GPL licensed software might, but it's not like GPL is working as intended, outside of a few cases where enough money was at stake to sue (e.g. TiVo), violations of the GPL go unpunished.</p>
<p>Currently, a company that wants to include GPL into their project has two options:</p>
<ul>
<li>Use the code in such a way that GPL won't force you to open source the rest of your code.</li>
<li>Use the code and break the license.</li>
</ul>
<p>Since the wording of GPL is not that clear, it could often be argued that companies go for alternative nr 2. After all, who will ever know?</p>
<p>But what if the "pay the maintainer a small sum" option was available. Wouldn't the liability afraid giants look towards this much more favorably than either of the other 2 options? Wouldn't this, in the long run, give an edge to open source projects which don't have to worry about these fees ?</p>
<hr>
<p>Thus I think I come in squarely on the side of open-source companies dual-licensing GPL on their product[s]. A model that already exists and often enough has great success (see MariaDB and Aerospike).</p>
<p>It's a nice compromise for moving towards a more open world, without having to live in Stallman's utopia. It's an amazingly pragmatic solution and anyone who reads this blog knows I'm a fan of those.</p>

      </div></div>]]>
            </description>
            <link>https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677481</guid>
            <pubDate>Sun, 04 Oct 2020 09:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A modular, extensible DIY NAS]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24677407">thread link</a>) | @ggeorgovassilis
<br/>
October 4, 2020 | https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/ | <a href="https://web.archive.org/web/*/https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This post was extensively <a href="https://news.ycombinator.com/item?id=24677407">discussed on Hacker News</a>.</p>



<p>I’ve been running for a decade a self-built NAS at home, so I thought I’d write down my experience so that others might gloat over my many failures and gasp in awe at my few triumphs.</p>



<figure><img data-attachment-id="1780" data-permalink="https://blog.georgovassilis.com/img_20200929_210932458_hdr/" data-orig-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg" data-orig-size="1728,2304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;moto x4&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1601413773&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.519&quot;,&quot;iso&quot;:&quot;763&quot;,&quot;shutter_speed&quot;:&quot;0.071428571428571&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20200929_210932458_hdr" data-image-description="" data-medium-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=225" data-large-file="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768" src="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768" alt="" srcset="https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=768 768w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=1536 1536w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=113 113w, https://georgovassilis.files.wordpress.com/2020/09/img_20200929_210932458_hdr.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>The HP Proliant microsever gen8 is affordable, compact and runs on Ubuntu</figcaption></figure>



<p>The NAS is <strong>perfect</strong> because it is simple, safe, modular and extensible and it is <strong>cheap </strong>because it is built of second hand, commodity parts.</p>



<p>The NAS mostly stores files (documents and media) on a software RAID 6 and serves them over Windows shares to the local network. I’m staying away from proprietary NAS solutions because a hardware failure would make data recovery hard to impossible without the exact same hardware replacement. Every piece of hardware,  from the hard disks to the case and motherboard have been switched out for something else in this decade, sometimes more than once, so the focus on modularity paid for itself. Since long-term data integrity and robustness is a concern, the NAS should run some sort of redundant RAID level.</p>



<h2>Goals</h2>



<figure><table><tbody><tr><td><strong>Goal</strong></td><td><strong>Description</strong></td><td><strong>Solution</strong></td></tr><tr><td>Function</td><td>The NAS serves as a <strong>network attached file system</strong> for home use; the NAS operates a few hours a day and is either off or in standby most of the time </td><td>Commodity hardware, open source software, modularity, keep it simple</td></tr><tr><td>Interoperability</td><td>Commonly used computer platforms should be able to access files on the NAS. Commodity hardware should be able to connect to the NAS.</td><td>Samba (aka Windows shares) on Ubuntu, USB, SATA. Connect LAN to Wifi router, does name resolution and time server. Access and manage with SSH.</td></tr><tr><td>Modularity</td><td>Hardware and software components should be <strong>interchangeable </strong>without redesigning the entire system  </td><td>x86 PC platform, Linux, Docker</td></tr><tr><td>Control</td><td>I want to control <strong>which software is installed</strong> on the NAS and what it does </td><td>Ubuntu 18.04 LTS</td></tr><tr><td>Data integrity</td><td>Files of arbitrary <strong>size </strong>(within reason) and content should be stored on the NAS and not <strong>corrode or lose integrity</strong> over time </td><td>RAID 6 with 4 hard drives, ext4fs with checksumming, scrubbing, manually assembled RAID, ECC RAM. Sign archives with par2.</td></tr><tr><td>Noise</td><td>Noise should be low and tolerable </td><td>HDDs in standby, SSD as primary OS disk, write-mostly, lots of RAM, passive cooling</td></tr><tr><td>Cost</td><td>Use commodity hardware and free, open source software </td><td>2nd-hand commodity hardware, hard disks instead of SSDs</td></tr><tr><td>Low maintenance</td><td>Avoid time critical maintenance</td><td>ufw firewall accepting connections only from internal network, no auto-updates, limited software, Docker, not accessible from the Internet.</td></tr><tr><td>Data safety</td><td>In case of hardware loss or theft unauthorised parties shouldn’t be able to access the data</td><td>dmcrypt with key on external device</td></tr><tr><td>Low power consumption</td><td>Power consumption should be in line with the server’s function</td><td>Components in stand-by most of the time, SSD, RAID in write-mostly</td></tr><tr><td>Compact</td><td>Physical NAS dimensions should be small; no space wasted</td><td>2nd hand HP proliant microsever gen8 </td></tr></tbody></table></figure>



<h2>Non-goals</h2>



<ul><li>Typical media-server tasks: streaming, encoding, transcoding etc</li><li>Bitcoin mining</li><li>Torrenting</li><li>Everything else 🙂</li></ul>



<h2>Getting the Hardware</h2>



<p>Getting the right hardware is the hard-(pun)-est part as it is the platform for modularity, price, energy consumption, size and many other goals I’m interested in. There are many second-hand, cheap proprietary NAS servers around, but I don’t like the idea of closed hardware and software systems. Eg, if a hardware RAID controller stores data in a proprietary format on the hard drives I would need the exact same replacement controller to recover that data in case of a controller failure.</p>



<p>Space is also an issue, so the server should be compact while allowing running Linux on it; that is quite hard to find as most compact NAS’ out there are proprietary systems and don’t allow installing your own OS. There are plenty of used x86 PCs and servers, but they are mostly too big or don’t have enough drive bays or SATA ports. Connecting drives over USB is also not an option because of the low speed, higher power consumption and space requirements. The first couple of my NAS revisions around 2010 used a compact barebone and later a mini tower case around which had 3 or 4 hard disk bays, but I find those box formats harder to come by these days. Lucky you if you get one at an affordable price!</p>



<p>I came across a used <a href="https://support.hpe.com/hpsc/doc/public/display?docId=emr_na-c03793258">HP proliant microserver</a> gen8 and haven’t regretted it ever since. The base model came with 2GB ECC RAM, a Celeron 2-core CPU and no hard drives for about 100€. There’s an excellent review of that server on <a href="https://louwrentius.com/zfs-performance-on-hp-proliant-microserver-gen8-g1610t.html">Louwrentius</a>. The server is extremely compact (about 26cm each dimension), reasonably low noise (although not silent) in standby, has a passively cooled CPU, two GBit ethernet ports, four 3,5″ hard drive bays and a somewhat hidden proprietary format slot for a fifth low-profile 2,5″ disk which I use for an SSD. The drive bays can directly receive SATA disks while the 5th slot requires a 4 pin FDD male-to-SATA adapter and a SATA cable to connect a 2.5″ SSD to the motherboard, which requires an FDD 4 pin (male)-to-SATA connector. As an added bonus, the server features <a href="https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out">ILO</a> which allows remote access to the server with a web browser – so no need for a keyboard or screen!</p>



<p>I admit that the server isn’t 100% commodity parts; eg. a motherboard or CPU failure would require ordering the exact same spare parts (which is probably going to be expensive) or building a completely new server on a different platform. However RAM, network and storage are fairly standard, I run Ubuntu on it and the benefits outlined earlier weigh enough to take that risk. About 6 years later the server still runs without any issues; barring <a href="https://en.wikipedia.org/wiki/Survivorship_bias">survivor bias</a>, I think that approach worked well.</p>



<p>The server I purchased had firmware from 2014 and HP thankfully started publishing updates for free recently, the last one from late 2019 which I flashed the microserver with for a slick HTML5 management UI.</p>



<p>The server underwent various upgrades over the years; from a RAID5 array of three 2TB hard disks to the current setup of 3x6TB + 1x8TB + 1x 512MB SSD and a CPU upgrade to a Xeon model and a RAM upgrade to 16GB ECC. I almost exclusively repurpose external USB hard drives (after opening , extracting the HDD and kissing the warranty goodbye) which are cheaper than internal ones… at first that is surprising considering the extra hardware (case, USB-to-SATA adapter, cables, power supply) they come with; however the warranty and technical specs are significantly inferior to those of internal drives which explains the price difference. Since the server runs a RAID 6 (the entire point of which is to survive disk failures) I think that is an ok risk to take.</p>



<p>The server is connected over an Ethernet cable to the home Wifi router; network speeds are close to 100mb/s which is ok, the USB3 ports can do around 40mb/s.</p>



<h2>Installation</h2>



<p><a href="https://en.wikipedia.org/wiki/HP_Integrated_Lights-Out">ILO </a>makes setting up the server easy even without a physical keyboard and screen. I started with Ubuntu server LTS 14.04, switched over to 16.04 and am currently running 18.04. The upgrades never worked in place, in each case a fresh installation was required. </p>



<p>I recommend installing a VM (like VirtualBox) on your workstation, booting Ubuntu Server 18.04 from a live image and installing Ubuntu on a USB harddisk. I couldn’t get the Proliant microserver to boot with UEFI, so a traditional grub BIOS installation is required. </p>



<p>The four hard disks are partitioned according to the schema below: a 1MB partition at the beginning for the GRUB boot loader, a 50GB partition for Ubuntu and a 5.5TB partition for the RAID.</p>



<p>I used the Ubuntu Server 18.04 alternative installer to set up the Ubuntu partitions as a RAID 1 which mirrors that partition over all hard disks. The installer is able to install Ubuntu into that RAID 1 and GRUB is able to boot from it. In case of a hard disk failure, just removing that hard disk will allow the server to boot again.</p>



<pre><code>+-------------------+
| 1MB bios_grub     |
|                   |
+-------------------+
| 50GB Ubuntu ext4  |
| RAID 1            |
+-------------------+
| 5.5TB Data        |
| RAID 6            |
+-------------------+</code></pre>



<p>For the installer to work, there need to be at least two disks in the RAID. More disks can be <a href="https://raid.wiki.kernel.org/index.php/Growing">added later</a>. Just make sure to install the GRUB bootloader on all disks with:</p>



<pre><code>grub-install /dev/sdX</code></pre>



<p>In my first experiments Ubuntu was able to boot fine, but wouldn’t activate the ethernet cards. This requires some fiddling with netplan.</p>



<p> <strong>/etc/netplan/01-netcfg.yaml</strong> </p>


<pre title="">network:
  version: 2
  ethernets:
    eno1:
      dhcp4: true
      dhcp6: true
      optional: true
    eno2:
      dhcp4: true
      dhcp6: true
      optional: true
</pre>


<h2>Boot RAID considerations</h2>



<p>As discussed in “installation”, Ubuntu boots from a RAID 1. md mirrors changes to all boot partitions, which is awesome. The boot RAID is mapped under /dev/md0 – I didn’t find a way to assign a name to it, but I found the device name to be stable. Unfortunately Ubuntu will constantly access the boot drive during normal operation, which in my case means that four drives are always spinning. I tried various things like remapping log directories to a ram disk and pre-loading files, but the resulting jungle of scripts is impossible to maintain. The solution turned out to be quite simple and elegant, after a hack: I installed an SSD in the 5th hard disk bay and added it to the boot RAID 1. While mirroring worked, the Proliant (gen8) BIOS won’t boot from the 5th bay if it finds hard disks somewhere else. The solution is a script which runs after boot and fails all mechanical hard disks in the RAID:</p>



<pre><code>mdadm --manage /dev/md0 --fail /dev/sda2 /dev/sdb2 /dev/sdc2 /dev/sdd2</code></pre>



<p>The script is a bit more complex than that as device names are not stable and various error conditions need to be taken into account (eg. the RAID shouldn’t be touched if a harddisk is failing) – but that is a topic for a different post. MD will forget that the disks have been marked as failed after a reboot, which …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/">https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/</a></em></p>]]>
            </description>
            <link>https://blog.georgovassilis.com/2020/04/01/building-the-perfect-cheap-diy-nas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677407</guid>
            <pubDate>Sun, 04 Oct 2020 09:04:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Left My Tenured Academic Job]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24677171">thread link</a>) | @DyslexicAtheist
<br/>
October 4, 2020 | https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/ | <a href="https://web.archive.org/web/*/https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><time datetime="2020-10-03T09:00:00+0200">Sat, Oct 3, 2020</time></p>

    <p>RSS: </p> <p><a href="https://reyammer.io/blog/index.xml"><img src="https://reyammer.io/rss.png" width="23px"></a></p>

  <p>The <a href="https://twitter.com/reyammer/status/1311338230139232258" target="_blank">news is out</a>: I left France, I'm no longer a professor at EURECOM, I joined the Malware Research Team at CISCO Talos, and I moved to beautiful Vienna. Big change :-)</p>
<p>I have been a professor for a bit more than three years, but I have had contrasting feelings about the "prof job" for a long time (even before finishing my PhD), it took me a couple of years to realize that I would eventually have needed to move on, and it took even more (mental) effort to actually make the call and leave. Despite being <em>very</em> excited for what's next, oh boy, this was tough :-) But independently of the concrete next step, it was time to move on. Even if Talos realizes the mistake and kicks me out next week, I'm still confident that moving on was the right call.</p>
<p>Especially when it comes to take big decisions, I tend to obsess about trying to stay rational, and I spent years collecting notes on the various pros/cons. Many of these thoughts often started surfacing as "feeling something is not right", without consciously understanding what was going on. But by keep thinking and writing notes down, patterns of thoughts started to emerge and I was eventually able to pinpoint some more defined thoughts on what kept me on the current job and what pushed me to change. Once these reasons were clear, it was much easier to take the decision.</p>
<p>This is a very long blog post, and I don't expect more than a very few people to actually read it. I wrote it mostly for selfish reasons: before changing to a new life, I wanted to wrap up all these notes in something more structured. I can't be certain I took a good decision, but systematizing these thoughts allowed me to move on with enough confidence to know I'm likely making a step forward.</p>
<p>With that being said, I know that someone may be actually interested in hearing these thoughts and my experience. When I was a PhD student and I needed to take the notorious academia vs. industry decision, I would have paid big bucks to read more thoughts on the various pros/cons. One of the stupidest things you can do is to take big decisions based on what other people do and think, but reading about other people's thought process has helped me a lot. It is time I do my part.</p>
<p>The target audience for this post is, other than myself, PhD students / postdocs that are about to decide what to do next and junior profs that somehow feel that "something is wrong". I also expect some senior academics and industry people to read this post, but I guess they will find themselves skipping directly to the academic rant part and mostly agree with much I have to say :-) Anyways, I tried to stay away from the "very known things" (e.g., 👀-level BS when writing proposals, generally "more limited" immediate impact of your work, different compensation level, etc.), and I tried to focus on thoughts I have not seen much discussed around (at least not in this depth).</p>
<p>So, if you feel clueless and you want to hear more from an equivalently clueless random dude on the Internet, here we are :-) If you think this is <em>the</em> blog post that will make everything clear, I have a bad news for you: it's all about tradeoffs and in my opinion there is no clear-cut winner. And, unfortunately, the problem with tradeoffs and balancing many aspects is that figuring out which one to weigh more is yet another very personal decision in its own way. So, you will not find any answer in this post and you will eventually need to figure this thing out on your own, but I hope this will help you forming your own opinion.</p>
<p>This post is organized in three parts:</p>
<ul>
<li><a href="#part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good — What pushed me to keep the job</a></li>
<li><a href="#part-2-the-bad-mdash-what-pushed-me-to-leave-the-job">Part 2: The Bad — What pushed me to leave the job</a></li>
<li><a href="#part-3-the-bye-bye-mdash-the-decision-to-leave">Part 3: The Bye Bye — The decision to leave</a></li>
</ul>
<p>Enjoy!</p>
<p><em>Mandatory disclaimer: I have no idea what I'm talking about, and these are personal takes/opinions anyways. Unless you are a bad person, please don't take anything personal. Please feel free to reach out, ping me on twitter, or shoot me an email: I'm of course happy to share more thoughts if you have any question. And if you disagree with something, bring it on! I love to argue, especially with people with strong and different opinions :-)</em></p>
<br>
<h2 id="part-1-the-good-mdash-what-pushed-me-to-keep-the-job">Part 1: The Good — What pushed me to keep the job</h2>
<p>Before I discuss why I left, I want to touch on what pushed me to keep the job. I want to make sure it's a balanced post despite the upcoming mega rant, so that my overall opinion is more closely reflected. And I really don't want to discourage anyone to take this path, I still think it is a great one.</p>
<p>Note that some of my "reasons to stay" are good, but some are bad. Also note that many of these refer to my personal situation at EURECOM, working in the field of systems security, and not all these points can be generalized to all universities. As they say, your mileage may vary.</p>
<h3 id="its-a-very-good-job">It's a very good job</h3>
<p>The first pros is... 🥁: "it's a very good job". At first, I was shocked to find out that it's an actual job. When I joined this prof thingy I thought that this would be a "job" (note the double quotes). But, while it's true that you don't have a direct boss that tells you what to do, at the end of the day you need to deliver, and you actually work very hard: If your PhD students are in trouble or you teaching sucks, you will run into problems. This doesn't necessarily mean "they kick out", but if you value being a professional (and I do), failing at your core tasks will make you feel bad, even without additional pressure from your superior, and even if you have tenure.</p>
<p>And now that we got this "it's an actual job" out of the way, I can tell you: it's a very good one. There is <em>a lot</em> of freedom in what you do and how you structure your time. Research-wise I felt very free (but you eventually work on what your students like to work on — as it should be), and the department values the right things (I've heard some BS in other schools where, in the context of systems security research, they pressure you to "publish more journal papers..." 🤦‍♂️). I really like teaching and mentoring, and there were many opportunities to do so. They let me create and teach my own class on mobile security, <a href="https://mobisec.reyammer.io/" target="_blank">MOBISEC</a>, and the teaching load is overall very low (1 or 1.5 classes per year). I love playing CTFs and I was even <em>encouraged</em> to spend time and push for NOPS, the EURECOM CTF team (after winning <a href="https://ctftime.org/event/647" target="_blank">HXP CTF 2018</a> and after being referred to as "<a href="https://youtu.be/j0taw78tCYs?t=968" target="_blank">probably a top team</a>" we are mostly enjoying our eternal and well-deserved glory).</p>
<p>The environment is extremely relaxed, informal, and friendly. You are surrounded by top-skilled colleagues and humans, from MS students to profs. I felt in a family from day 1. Last very good point: since in France positions come with tenure, there were not even problems in terms of pre-tenure stress, a real luxury. And on this aspect, EURECOM delivered: I never felt any sort of pressure (but: I did work my ass off... so if you stop doing anything, bad things may happen :-)).</p>
<p>[BTW, EURECOM is frantically trying to replace me, you should apply :-)]</p>
<h3 id="you-are-surrounded-by-students">You are surrounded by students</h3>
<p>When I took my decision to remain in academia, my top reason was for teaching and mentorship. Probably the best perk of the job is that you are surrounded by people eager to learn, from MS to PhD students to postdocs. It is extremely fulfilling and rewarding. Working with my students has been the highlight of my time at EURECOM, from traditional teaching, to suffering through the various rejections, to celebrating defeats of Reviewer #2, to cluelessly getting CTF-close in many stego CTF challenges. I feel very lucky that during these years we found enough interesting ideas that we enjoyed working on together, and that my next job will allow me to keep advising them until they graduate. As a prof, I believe the net output of my work is to see students becoming independent researchers, not the actual papers — I can't wait to see the bright careers I'm sure they will have :-)</p>
<h3 id="i-have-deep-respect-for-the-role-of-profs-in-society-and-it-felt-great-to-be-one">I have deep respect for the role of "profs" in society, and it felt great to be one</h3>
<p>I somehow have a profound admiration for the role that professors have in society and that had in my life. For their hard work, knowledge, passion, patience, and ultimately their service to the community. I'm referring to all teachers and mentors (from elementary schools to universities), who spend their life helping others, while at the same time often being asked to do many useless things and being massively underpaid. I admire and deeply respect these efforts: my most sincere thank you to all past, present, and future profs!</p>
<p>And, to be frank, it felt great to be one. I have been in love with the idea of being a prof for many years. In part, I think it is because some of the people who impacted me the most are professors, and I wanted to do my part in helping others. And after all the uncertainties that one has during a PhD, I think I was even more in love with the idea of having finally found my place in society. [Narrator: LOL, this clueless dude did not find his place. [Answer to narrator: But I've surely found it <em>now</em>!!1!]]</p>
<p>Overcoming all these positive emotions and feelings attached to this job was likely the biggest challenge I faced in coming to terms with the several problems and cons I did have during these three years. As mentioned, I have no intention to give up on this teaching/mentoring thing (taking the time for this long blog post is part of this!), but it will surely not be the same thing. I'm very grateful I had a chance to try this job out. Thanks to all who made it possible, from family to advisors, colleagues, and students ❤️. I owe you big time.</p>
<p>[Of course, being a prof does not necessarily make you a smart or great person. Some profs I know are some of the dumbest people I have ever met (by far) and they would not survive one day in the real world. And some profs I know are the most asshole, selfish, egomaniac, and delusional humans I have ever heard of (Are you pushing your students to stay in the lab …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/">https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</a></em></p>]]>
            </description>
            <link>https://reyammer.io/blog/2020/10/03/the-good-the-bad-and-the-bye-bye-why-i-left-my-tenured-academic-job/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677171</guid>
            <pubDate>Sun, 04 Oct 2020 07:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SEO vs. Social Media Marketing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24676920">thread link</a>) | @grwthckrmstr
<br/>
October 3, 2020 | https://www.preetamnath.com/blog/seo-vs-social-media-marketing | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/seo-vs-social-media-marketing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>One of the little things I don’t like about Twitter, or social media in general, is how it demands you to constantly create new content to keep people’s attention.</p><p>I understand the value of creating new tweets or instagram posts, sharing ephemeral updates that entertain and engage for a short while and keep your presence fresh in the minds of your audience. That’s how discovery-based social media works.</p><p>But I’ll be the first to admit that I’m a fan of things that you can do once, but reap the benefits of again and again, preferably growing over time.</p><p>And hence I prefer intent-driven search, because if I can show up for a relevant search and satisfy the searcher’s query well enough with my content, I can reap the benefits of that content today, tomorrow, and into the future.&nbsp;</p><p>I’ve read in theory about SEO for long enough, without ever having practiced it strategically in the long term. One of the growth pillars for DelightChat is based on SEO, so I might as well move on from theory and get started with real world learnings.</p><p>My personal blog <a href="https://www.preetamnath.com/blog" target="_blank">Preetamnath.com</a> is the first such long-term experiment.&nbsp;</p><p>I started publishing regularly on June 4, exact 4 months ago. Back then, my blog was to get 50 impressions/day on search results. Today, the average is at 1000/day. That’s a solid 20x jump.</p><figure id="w-node-8f3ea7c3f7d8-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f79561d425f076bba77e965_search%20traffic%20on%20preetamnath%20console.png" loading="lazy" alt=""></p></figure><p>Clicks have gone up from 3/day to 30/day, which is a 10x jump. Looks like clicks didn’t grow as well as impressions, perhaps there’s a layer of optimisation that I could look into over there.<br></p><p>I first noticed that my blog was showing up for “micro saas”, “shopify app ideas” and related long term keywords. Back then I hadn’t thought too deeply about it. But I did end up making a page called <a href="https://www.preetamnath.com/habit-tracker-app" target="_blank">Habit Tracker App</a> as an experiment, which I published on August 2 (little over 2 months ago).</p><p>Since then, my habit tracker landing page has garnered 4,700+ impressions and 239 clicks directly from Google Search. This is completely on autopilot, I’ve never updated the page since I first posted.</p><figure id="w-node-d230c6cb7bbb-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f79567f6493631e80a0a6e1_habit%20tracker%20search%20organic%20traffic.png" loading="lazy" alt=""></p><figcaption><em>June 4-Oct 3 data. Habit tracker was published on August 2.</em></figcaption></figure><p>But the #1 keyword for which my website draws search traffic is “micro saas”. It shouldn’t have taken me this long, but today I’m doubling down on that keyword by creating a dedicated page called Micro SaaS.&nbsp;<br></p><p>For my page, I did basic research around</p><ul role="list"><li>Which search terms related to “Micro SaaS” is my blog already ranking.</li><li>What are the suggested keywords and questions that I see when I type “Micro SaaS” on Google.</li><li>What are the related search phrase suggestions I see from Keywords Everywhere. This tool also helps find search traffic for a search phrase.</li></ul><figure id="w-node-ffbd1113d572-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f7956c49f41dba556373e16_micro%20saas%20ideas%20search%20traffic.png" loading="lazy" alt=""></p></figure><p>Based on this research, I’ve released the first version of <a href="https://www.preetamnath.com/micro-saas" target="_blank">Micro SaaS</a> landing page today.</p><p>It’s incomplete as there’s several sub-topics to cover, of which I’ve only covered 2 as of today. Over the next week or two, I’ll fill the page with more content, as well as curate links to existing resources wherever I find a relevant high-quality one.</p><figure id="w-node-a56e744a481d-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f79692b952b4acb01bc7e6b_micro%20saas%20keywords%20research.png" loading="lazy" alt=""></p></figure><p>I’ll report back on results in a month.<br></p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/seo-vs-social-media-marketing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676920</guid>
            <pubDate>Sun, 04 Oct 2020 06:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Imposter syndrome: Is it a bug or a feature?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24676834">thread link</a>) | @root993
<br/>
October 3, 2020 | https://www.sankalpjonna.com/posts/imposter-syndrome-is-it-a-bug-or-a-feature | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/imposter-syndrome-is-it-a-bug-or-a-feature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Imposter syndrome is something that I have been battling with my entire life. Often times I get the feeling that whatever success &nbsp;I have acquired over the years might have just been luck or maybe things worked out because I partnered with the right people who did all the work while I reaped the fruits. </p><p>This feeling started all the way back in school when I scored the highest marks in an exam which everybody else struggled with. </p><p>At the time I was convinced that the only reason this happened was because I was lucky enough to have studied that one question in the syllabus which nobody thought would appear in the exam but ended up appearing. </p><p>But here’s the thing, because I felt like a fraud I ended up studying harder for the next exam with the fear of being exposed as someone who just got lucky in the last one. So is this feeling really a bad thing?</p><h3>‍<br>‍<strong>Why does imposter syndrome occur?</strong><br></h3><p>From my personal experience, I can say that imposter syndrome mainly occurs in people who have self taught themselves the skill that they are currently using to make a living. </p><p>In my case it is software development. I was not particularly good at it in college even though I was studying computer science. I was just an average student if not below average.</p><p>After I left college I started working in early stage startups where there is no structure or someone to teach you stuff. The only option is to do your own research and learn things yourself. Google and Stack overflow were my only true friends.</p><p>Because I never really went through a “standard program” I always have this self doubt and I never know if the way I am doing things is the right way or not and the fact that there is no defined right way of doing things in software does not make this any easier.<br></p><h3><strong>How do you use this as a strength</strong><br></h3><p>My co-founder and I built a business that <a href="https://www.preetamnath.com/blog/grow-shopify-micro-saas-to-25k-mrr-in-14-months" target="_blank">we grew to $25k MRR</a>. Because of my imposter syndrome I have convinced myself that most of it was luck. We were in the right place at the right time. <br></p><p>The fact that we did 2 months of research on the market and product, spent a lot of time figuring out where we would get distribution from even before writing a single line of code seemed to have conveniently slipped my mind. The reason we even did all of this in the first place was our fear of not being good enough.<br></p><p>We have now started a <a href="https://www.delightchat.io/" target="_blank">new venture</a> and hired a team. Now because of the fact that we had a successful venture in the past, I am now under immense pressure to make this new one a success otherwise I might get exposed as a “fraud” or someone who “just got lucky”. <br></p><p>Because I have no other option but to make this a success I am going to work hard once again just like I did in my last venture. I would like to think that this imposter syndrome has turned into a strength. It is a feature and not a bug.<br></p><h3><strong>Closing notes</strong><br></h3><p>Some amount of self doubt is healthy and it keeps you on your toes. It also prevents you from letting your previous success go to your head and always be open for new learnings.<br></p><p>It enables you to be open to the suggestions given by your teammates which you might otherwise ignore just because they are less experienced than you if you had no self doubt at all. <br></p><p>Having said that, it is also not right to doubt yourself to an extent where it starts impacting you in a negative way. For instance, what if your teammates catch wind of your immense self doubt and they start losing faith in you? This is also not something you can afford.<br></p><p>One must have a healthy balance of self doubt and faith in yourself that you are moving in the right direction.</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/imposter-syndrome-is-it-a-bug-or-a-feature</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676834</guid>
            <pubDate>Sun, 04 Oct 2020 06:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Gzip Format (2011)]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24676831">thread link</a>) | @WoodenChair
<br/>
October 3, 2020 | http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001 | <a href="https://web.archive.org/web/*/http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><tbody><tr><td><div id="main">
<p>
In this article I describe the DEFLATE algorithm that GZIP implements and depends on. The DEFLATE algorithm uses a combination of LZ77, Huffman codes and run-length-encoding; this article describes each in detail by walking through an example and developing source code to implement the algorithm. My aim is to implement readable rather than efficient or extensible code. I'll focus here on unzipping, rather than zipping, but by the end of the article, the zipping process should be clear.
</p>
<p>
Material intended for human consumption tends to be highly redundant, from an information processing perspective. Because of the mysterious human mind, we need to have the same thing repeated to us in different ways in order for it to be processed correctly. Natural language, for example, is inefficient - the English language phrase "I am going to the store" could easily be abbreviated "I go store". If the subject of conversation has already been established as "me", it could be further abbreviated unambiguously as "go store". This is how children communicate until they are taught proper grammar - but as we mature, we like/want/need the redundancy.
</p>
<p>
Computers are no better when it comes to demanding redundancy. Computer programs repeat the same instructions over and over again, and program source code is verbose, even when the programmer isn't concerned about using readable variable names (you know who you are). Computer storage, on the other hand, is a scarce resource. It becomes less and less scarce every day, but every time capacity increases, we seem to find a way to run out of it. I'm sure that someday, my children will be complaining that their thumbnail computer devices can "only store four holodeck simulations!"
</p>
<p>
Computer scientists have been studying ways to use computer storage more efficiently since the 1960s. In 1977, Abraham Lempel and Jacob Ziv published "A Universal Algorithm for Sequential Data Compression " [1] which described what is now referred to as the "LZ77" compression algorithm. Conceptually, LZ77 is pretty straightforward - read the source document, and, for each sequence of bytes encountered, search backward through the document to see if the same sequence occurs previously. If so, rather than outputting the sequence, output a back pointer to the first occurrence of the sequence.
</p>
<p>
To get a sense of just how redundant English text is, take a look at figure 1 and figure 2. Figure 1 contains the first few verses of the Bible's book of Genesis and figure 2 shows all of the places where text from a prior point in the document is repeated. LZ77 does a very good job of exploiting that redundancy and making efficient use of available storage.
</p>
<p>
<img src="http://www.infinitepartitions.com/genesis.gif">
</p><p>Figure 1: Uncompressed ASCII text</p>

<p>
<img src="http://www.infinitepartitions.com/genesis_compressed.gif">
</p><p>Figure 2: LZW compression</p>

<p>
The first 17 verses, with LZ77 compression applied, is shown below. The &lt;#,#&gt; brackets indicate backpointers in the form &lt;distance, length&gt;. So, the first backpointer &lt;25,5&gt; indicates that, to uncompress the document, search backward 25 characters, and reproduce the five characters you find there. As you can see, the first sentence is mostly uncompressed, but by the middle of the text, there's almost no uncompressed text.
</p>
<p>
001:001 In the beginning God created&lt;25, 5&gt;heaven an&lt;14, 6&gt;earth.
0&lt;63, 5&gt;2 A&lt;23, 12&gt; was without form,&lt;55, 5&gt;void;&lt;9, 5&gt;darkness&lt;40, 4&gt;
&lt;0, 7&gt;upo&lt;132, 6&gt;face of&lt;11, 5&gt;deep.&lt;93, 9&gt;Spirit&lt;27, 4&gt;&lt;158, 4&gt;mov&lt;156, 3&gt;&lt;54, 4&gt;&lt;67, 9&gt;&lt;62, 16&gt;w&lt;191, 3&gt;rs&lt;167, 9&gt;3&lt;73, 5&gt;&lt;59, 4&gt;said, Let&lt;38, 4&gt;r&lt;248, 4&gt; light:&lt;225, 8&gt;re&lt;197, 5&gt;&lt;20, 5&gt;&lt;63, 9&gt;4&lt;63, 11&gt;w&lt;96, 5&gt;&lt;31, 5&gt;,&lt;10, 3&gt;at &lt;153, 3&gt;&lt;50, 4&gt;good&lt;70, 6&gt;&lt;40, 4&gt;divid&lt;323, 6&gt;&lt;165, 9&gt;&lt;52, 5&gt; from&lt;227, 6&gt;&lt;269, 7&gt;&lt;102, 9&gt;5&lt;102, 9&gt;call&lt;384, 7&gt;&lt;52, 6&gt;Day,&lt;388, 9&gt;&lt;326, 9&gt;&lt;11, 3&gt;&lt;41, 6&gt;&lt;98, 9&gt;N&lt;183, 5&gt;&lt;406, 10&gt;&lt;443, 3&gt;&lt;469, 4&gt;&lt;57, 8&gt;mor&lt;15, 5&gt;w&lt;231, 4&gt;&lt;308, 5&gt;irst&lt;80, 3&gt;y&lt;132, 9&gt;6&lt;299, 28&gt;a&lt;48, 4&gt;mamen&lt;246, 3&gt;&lt;437, 6&gt;midst&lt;375, 7&gt;&lt;134, 9&gt;&lt;383, 6&gt;&lt;177, 6&gt;le&lt;290, 5&gt;&lt;272, 6&gt;&lt;413, 11&gt;&lt;264, 10&gt;&lt;429, 15&gt;7&lt;129, 9&gt;mad&lt;166, 9&gt;&lt;117, 6&gt;&lt;82, 6&gt;&lt;348, 11&gt;&lt;76, 8&gt;which&lt;215, 5&gt;&lt;600, 10&gt;nder&lt;62, 14&gt;&lt;115, 16&gt;&lt;54, 11&gt; ab&lt;599, 3&gt;&lt;197, 13&gt;&lt;54, 9&gt;&lt;470, 6&gt;&lt;487, 7&gt;so&lt;169, 9&gt;8&lt;432, 20&gt;&lt;108, 10&gt;H&lt;827, 5&gt;&lt;397, 25&gt;&lt;103, 9&gt;&lt;405, 17&gt;seco&lt;814, 5&gt;&lt;406, 10&gt;9&lt;406, 22&gt;&lt;199, 8&gt;&lt;235, 10&gt;&lt;944, 7&gt;&lt;428, 3&gt;ga&lt;439, 5&gt;&lt;540, 10&gt;toge&lt;18, 4&gt;&lt;45, 3&gt;to one pl&lt;820, 3&gt;&lt;422, 10&gt;&lt;604, 5&gt;ry l&lt;16, 4&gt;app&lt;981, 3&gt;&lt;250, 8&gt;&lt;474, 11&gt;&lt;258, 12&gt;10&lt;258, 20&gt;&lt;67, 9&gt;E&lt;1046, 4&gt;;&lt;638, 9&gt;&lt;145, 6&gt;&lt;234, 4&gt;&lt;138, 8&gt;&lt;86, 9&gt;&lt;952, 13&gt;&lt;75, 8&gt;&lt;1018, 4&gt;eas&lt;853, 10&gt;&lt;894, 6&gt;&lt;883, 14&gt;&lt;138, 9&gt;1&lt;290, 23&gt;&lt;1179, 6&gt;b&lt;119, 5&gt;&lt;1173, 3&gt;&lt;11, 3&gt;grass,&lt;302, 7&gt;rb&lt;132, 9&gt;yield&lt;38, 4&gt;seed&lt;879, 10&gt;fru&lt;111, 3&gt;tree&lt;33, 10&gt;&lt;19, 6&gt;af&lt;174, 3&gt; hi&lt;1229, 10&gt;kin&lt;57, 3&gt;whose&lt;69, 5&gt; is&lt;809, 4&gt;itself,&lt;1260, 10&gt;&lt;148, 5&gt;&lt;599, 23&gt;1&lt;1367, 16&gt;brou&lt;1082, 5&gt;&lt;189, 12&gt;&lt;58, 4&gt;&lt;189, 4&gt;&lt;181, 14&gt;&lt;136, 9&gt;&lt;154, 9&gt;&lt;146, 7&gt;&lt;204, 8&gt;&lt;198, 19&gt;&lt;175, 13&gt;&lt;138, 4&gt;i&lt;1369, 10&gt;&lt;184, 8&gt;&lt;78, 14&gt;&lt;401, 39&gt;3&lt;1160, 42&gt;thir&lt;753, 13&gt;14&lt;1460, 33&gt;s&lt;1155, 8&gt;&lt;882, 10&gt;&lt;1159, 15&gt;&lt;780, 7&gt;&lt;749, 3&gt;&lt;1150, 11&gt;&lt;100, 3&gt;&lt;1031, 10&gt;n&lt;72, 4&gt;;&lt;769, 12&gt;m&lt;95, 4&gt;&lt;361, 3&gt;&lt;68, 9&gt;sign&lt;367, 7&gt;&lt;22, 3&gt;&lt;293, 3&gt;aso&lt;16, 12&gt;&lt;79, 3&gt;&lt;13, 7&gt;y&lt;430, 3&gt;s:&lt;192, 8&gt;&lt;1486, 6&gt;&lt;85, 15&gt;&lt;185, 31&gt;&lt;177, 10&gt;&lt;126, 9&gt;giv&lt;1541, 8&gt;&lt;573, 38&gt;6&lt;1343, 15&gt;wo&lt;562, 3&gt;&lt;2001, 3&gt;&lt;122, 7&gt;;&lt;906, 6&gt;&lt;2019, 5&gt;&lt;142, 7&gt;&lt;288, 4&gt;rul&lt;1277, 14&gt;d&lt;1650, 12&gt;l&lt;1646, 3&gt;&lt;45, 20&gt;&lt;319, 6&gt;:&lt;937, 4&gt;&lt;1452, 9&gt;st&lt;261, 3&gt;&lt;647, 10&gt;l&lt;154, 11&gt;&lt;1498, 10&gt;s&lt;278, 8&gt;&lt;264, 33&gt;&lt;256, 11&gt;&lt;2099, 18&gt;&lt;264, 5&gt;,
</p>
<p>
Example 1: LZ77 compressed representation of the first 17 verses of Genesis
</p>
<p>
This relatively short document is compressed at just over 3:1 - and the compression ratio generally improves as documents get longer.
</p>
<p>
Of course, when discussing computer formats, it's not enough to talk about concepts - a concrete representation must be agreed upon. The decoder/decompressor must have a way to distinguish which input bytes are literals, and which input bytes are backpointers. One simple, naive representation might be to introduce an "escape code" - say, 0x255, to distinguish backpointers from literals. Of course, a literal escape code would need to be similarly escaped.
</p>
<p>
Unfortunately, all of these escape codes end up defeating the purpose of compressing in the first place. As it turns out, there's a better way to encode these backpointers and still allow them to be correctly distinguished from literals: variable length codes. In ordinary byte-oriented data, each code is a fixed length (typically 8 bits). Variable length codes remove this restriction. Some codes can be shorter and some can be longer. Once there's no need to restrict yourself to eight-bit bytes, you can define an arbitrarily-sized "alphabet", which is exactly what GZIP does. The first 255 characters in this alphabet are the literal codes - the 8-bit bytes that were read from the input stream. The 256th character is a "stop code" that tells the decode when to stop decoding. The 257-285th codes indicate the length of the matched range (followed immediately by a distance code).
</p>
<p>
Now, if there are only 285-257=28 length codes, that doesn't give the LZ77 compressor much room to reuse previous input. Instead, the deflate format uses the 28 pointer codes as an indication to the decompressor as to how many extra bits follow which indicate the actual length of the match. This logic is complex but important for compatibility; I'll cover it in more detail below.
</p>
<p>
In a fixed-length world, this 285-symbol alphabet would require 9 bits per symbol, but would use only a little more than half of the available 512 bytes that 9 bits can encode. This alphabet can be encoded much more efficiently by assigning the symbols variable-length codes. However, the problem with variable length codes is that the decoder needs to know where one code ends and the other begins. This isn't a problem with fixed-length codes such as ASCII - the decoder reads 8 bits, decodes them, and then reads another 8 bits. To ensure that the encoder can unambiguously interpret the variable length codes, you have to be careful how you assign these codes. Imagine that you were dealing with a four-character "alphabet" with four variable-length codes:
</p>
<pre>1. A: 1
2. B: 0
3. C: 10
4. D: 11
</pre>
<p>
Example 2: Invalid variable-length code assignment
</p>
<p>
The problem with this assignment is that the codes are ambiguous. The decoder can't tell if the input sequence "10" is an A followed by a B, or a C by itself.
</p>
<p>
The solution is to assign prefix codes. With prefix codes, once you use a prefix to delineate a range of codes, it can't be used by itself as a code. So if the character "A" is assigned the 1-bit code "1", no other code can start with "1". If "B" is assigned the code "01", no other code can start with "01". A valid Huffman coding of the four-character alphabet above, then, is:
</p>
<pre>1. A: 1
2. B: 01
3. C: 001
4. D: 000
</pre>
<p>
Example 3: Valid prefix-coding variable-length code assignment
</p>
<p>
This means that there can only be one 1-bit code, one two-bit code, two three-bit codes, four four-bit codes, etc. You may deal with prefix codes on a regular basis - the country calling codes that allow you to make international phone calls are assigned using prefix code rules. Prefix codes are usually referred to as Huffman codes [2] after the inventor of a provably optimal algorithm for generating them when symbol probabilities are known. These Huffman codes are often represented as trees, where each leaf is a symbol, and each branch is a bit value.
</p>
<p>
<img src="http://www.infinitepartitions.com/huffman_tree_1.gif">
</p><p>Figure 3: a prefix code tree</p>

<p>
Once such a tree structure has been constructed, decoding is simple - start at the top of the tree and read in a bit of data. If the bit is a 0, follow the left-branch of the tree; if 1, follow the right-branch. When a leaf node is hit, stop; a symbol has been completely read. Output the symbol and return to the top of the tree.
</p>
<p>
Listing 1 illustrates a tree structure for representing Huffman codes in memory:
</p>
<pre>typedef struct huffman_node_t
{
  int code; // -1 for non-leaf nodes
  struct huffman_node_t *zero;
  struct huffman_node_t *one;
}
huffman_node;
</pre>
<p>Listing 1: Huffman tree structure</p>
<p>
Once constructed, reading …</p></div></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001">http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001</a></em></p>]]>
            </description>
            <link>http://www.infinitepartitions.com/cgi-bin/showarticle.cgi?article=art001</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676831</guid>
            <pubDate>Sun, 04 Oct 2020 06:02:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quick Chatbot Demo]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24676515">thread link</a>) | @cheeseblubber
<br/>
October 3, 2020 | https://www.papercupsbot.io/bot/demo | <a href="https://web.archive.org/web/*/https://www.papercupsbot.io/bot/demo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.papercupsbot.io/bot/demo</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676515</guid>
            <pubDate>Sun, 04 Oct 2020 04:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Formal Models for Ethics]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24676411">thread link</a>) | @queueue
<br/>
October 3, 2020 | https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/ | <a href="https://web.archive.org/web/*/https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<main>
  
<section id="post-the-ethical-question-mk-ii"> 
   
    <div>
      <a href="https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">
        <h2>The Ethical Question, Mk. II</h2>
      </a> 
      <h3>
        <span>September 28, 2020</span>
        <span>26 minutes</span>
      </h3>
      
    </div>
  
    
  <div>
    
<p>As the reading time estimate crept over 30 minutes, without any end in sight, I was starting to feel like a bit of a blowhard.</p>



<p>The draft I’d originally intended to inaugurate this blog is still sitting there. Maybe I will condense and finish it (eventually), but I think it makes more sense to write <s>briefly</s> less long-windedly about what I mean. Instead of trying to exhaust the subject matter, I’m going to offer a perspective, and present a more intuitive argument for it.</p>



<p>So, more briefly, I’d like to ask you to think, for a moment, about what makes humans <em>ethically</em> important. There are two parts to this question, hidden just under the surface. The first asks you to consider why humans are ethical <em>agents</em>. What makes it possible for them to do, want, or experience things that could fall under the umbrella of ethics? The second (no particular order) asks you to consider why humans are ethical <em>patients</em>. How is it that what happens to them, what is wanted of them, or what is experienced about them might also be part of an ethical problem? (This agent/patient distinction I inherit from Coeckelbergh, whose book, <em>Growing Moral Relations</em>, is worth your time.)</p>



<p>I will add before you start: ethics has been defined in a few different ways, over the millennia. I consider a few definitions interesting. </p>



<p>Charles Taylor, for instance, describes ethics as pertaining not just to moral choices and obligations between people, but questions like “what is the good life?” and “what is good?”. His more expansive account, following Aristotle, moves closer to the Greek root, which refers to one’s <em>character</em>, and can be read to have a slant towards something resembling <em>virtue ethics</em>. Using Taylor, we could ask questions like “what is it good to love?” and not just “what is the right way to act?” </p>



<p>Conversely, followers of Nietzsche contrast <em>ethics</em> with <em>morality</em>, arguing that morality is about passing judgment on what people (or living beings) are and do, whereas ethics can be about <em>affirming</em> life as intrinsically self-justifying. From a (post-) Nietzschean point of view, life’s capacity to want, struggle, and change, <em>is, from the very beginning, what is good</em> (maybe not in those words). Living well means trying to overcome the need to judge, and instead to explore and express what it is to be alive, for all its intensities and tragedies. Nietzsche is often read to be asking his readers to abandon compassion, or to think only of themselves and never of the common good, but I don’t think that is exactly the case. Nietzsche is asking us to live in pursuit of what is good, but not to define it as the enemy of the bad, rather, to live <em>for its own sake, come what may</em>, and to do what is good, <em>defined in itself</em>, rather than as a reaction.</p>



<p>I don’t know Coeckelbergh’s position on ethics broadly, but he considers morality to be embedded in social relationships themselves. Rather than what is right or wrong to do to a <em>patient</em> being about its properties (whether it has consciousness, for instance) and defined in absolute terms, morality is about what relationships exist between an agent and a patient, and what kinds of relationships are good to have, knowing what the agent and patient already are to each other. Do I already mostly act like it’s a person? I should probably treat it like one. Coeckelbergh is interesting in that he tries to legitimate ideas that have, until recently, not had much hearing in the community of western philosophers, although citing him as a source for them over others might, fairly, be challenged. For instance, he would consider our dependence on our ecology grounds to entertain an obligation towards it. I haven’t finished his book yet, so I’m not aware of the extent of the advice he gives for considering problems in these relationships, but it seems fair to say that he doesn’t believe there’s a system of absolute rules out there, or that we should try to find final answers to ethical problems. Relationships are particular, and they evolve. We shouldn’t seek to use the fact that we don’t get hard answers for our convenience; instead, we should consider relationships, for their lumpiness, their particularity, their uncertainty, and live them as best we can.</p>



<p>All of these viewpoints are very different from our ordinary patterns of ethical thought. We are used to thinking that <em>individuals</em>, or sometimes <em>social groups</em> (such as nations) have <em>rights</em> that must be guaranteed to them, but everything else goes. Sometimes, referencing Isaiah Berlin, we might say we believe that this obligation is <em>negative</em> (there are some things that people are fundamentally allowed to do, and our only obligation is to stop people who try to mess with that), or it is <em>positive</em> (there are some things that people should fundamentally be allowed to do, and we need to do our best to make that possible for them). Maybe, for whatever definition of the good, we are utilitarians, who think that we should do the most good for the most people, whatever means that could entail. Perhaps we take the <em>view from afar</em>, and ask “if I had the choice of all reasonably possible societies, which would I like to be born into, knowing that I might be anyone?” Perhaps we see ethics as different versions of the trolley problem, and find reasons, based on our moral intuitions, about what choices we should make when push comes to shove. Some of us, unfashionably, believe in immortal souls and divine law, against which we must not sin, or that her majesty inherits the right to judge from God, and that the highest good is obedience to an Earthly law. A scientist, being familiar with Hume, might read his argument that we cannot derive statements about what <em>ought to be</em> from statements about what <em>is</em>, and see cause to be an anti-realist. Maybe <em>ought</em> statements only express our personal preferences, derived from what we’ve been either (or both) biologically or socially conditioned to think is pleasing. Scientists might say this implies some sort of <em>relativism</em>, or that it’s best to follow whatever is the <em>conventional</em> way to think about ethics (although, if we’re not in the business of assuming the world is already a pretty just place to be in, that last one may not be safe). </p>



<p>So, knowing what you know about what humans are made of, and how they relate to one another, to society, or to other beings, what makes them ethical agents, and what does it mean that they are? What about patients? I think it’s probably a bad idea to try to find an answer too quickly. It might be better to think through what kinds of approaches are better, and what facts could be relevant to the question. For instance, maybe the way people want things matters, as it is defined in terms of elaborations on what’s generated by the default mode network. Maybe there can’t be exactly one right answer, or maybe there must be, or maybe it’s impossible to know. How would you argue that?</p>



<h2>Why it Matters </h2>



<p>I don’t fully agree with Taylor, but, in <em>Sources of the Self</em>, he makes a good case for why we shouldn’t be self-serving, and why we already care about ethics. He says ethics are about what we <em>want to be</em>, how we identify ourselves. This is always done in terms of social groups we identify <em>with</em>. “I am a professional, so I should…” Identity gives us community, people who share something about us (a way of life, perhaps), or maybe it contrasts us against a community (we can identify ourselves as rebels). We rarely, if ever, identify with just one thing, and it’s no use to try to come up with a completely original identity, if it’s possible to do it meaningfully at all, because it doesn’t tell us much about what we’re trying to be, given we’re the only one who would know or care that we’re being it. Identity is critically important to us in interpreting our place in the world, and what we are trying to do with it. So, says he, without identity, we would struggle to come to grips with life. It is a good thing, then, that you and I already have some ideas about <em>who we are</em>, or if we’re struggling to figure that out, generally already acknowledge that it <em>is</em> an important thing to get down. Taylor says that, since it’s all about coming to grips with life, we escape Hume’s is/ought problem, because we don’t have to set up an ethics from scratch. Ethics are already there from the beginning, and have some known properties, so we can argue about them by contrasting them. “Given these two frameworks, which one of them provides the richer set of tools for figuring out how to live a good life?” To Taylor, ethics are certainly <em>real</em>, but not in the sense that they’re an object embedded in a reality perfectly detached from us, rather, they come <em>from</em> the fact that we are social creatures, and relate <em>to</em> how we are trying to live in society. They aren’t just individual, or perfectly culturally relative (as there are no perfectly incommensurable cultures, which share none of the same moral ideas and cannot communicate with each other), but they aren’t exactly objective and final either.</p>



<p>I like Taylor, for how he grounds consciousness of <em>ethics</em> in <em>social consciousness</em>, and I like how good he is at striking down the (usually unanswerable) “why should I care about ethics?” question. I share Coeckelbergh’s complaint that he considers only one kind of relation (between the individual and the community), and I would also gripe that his ethics are unusually centred on the <em>self</em>, for a subject that tends to ask us to think beyond ourselves. But then, that is why the argument against selfishness works so well. It’s difficult to get through to somebody who only thinks of themself unless that’s the place you’re starting from. </p>



<p>Taylor’s other issues, which I will not go too in-depth on here, are first, that he frames the source of ethics as appearing in the fact that one is an <em>ind…</em></p></div></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/</a></em></p>]]>
            </description>
            <link>https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676411</guid>
            <pubDate>Sun, 04 Oct 2020 03:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open-source self-hosted comments systems for static websites]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24676152">thread link</a>) | @nuker
<br/>
October 3, 2020 | https://lisakov.com/projects/open-source-comments/ | <a href="https://web.archive.org/web/*/https://lisakov.com/projects/open-source-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This comparison table is inspired by
<a href="http://staticsitegenerators.net/">staticsitegenerators.net</a>. Contribute at
<a href="https://github.com/pozitron57/open-source-comments">github</a> —
add the missing data. Github-related data (stars, open issues + PR, etc.)
are updated daily automatically. Want different columns? Noted a bug? Submit
an <a href="https://github.com/pozitron57/open-source-comments/issues/new">issue</a>.</p>
<h2>What’s wrong with Disqus</h2>
<p>Disqus loads absurd amount of tracking services, which exposes your visitors’
personal data and significantly increases loading time. See, e.g., 
<a href="http://donw.io/post/github-comments/#what-s-wrong-with-disqus">this post</a>.</p>
<h2>What’s not covered here</h2>
<p>For a static website, one usually wants a lightweight commenting server with
as little dependencies as possible. Few commenting engines listed on the page
are provided by heavy applications (e.g.,
<a href="https://github.com/discourse/discourse">discourse</a>,
<a href="https://github.com/debiki/talkyard">talkyard</a>), but the majority are
relatively lightweight applications designed specifically to provide 
comments for the static pages.</p>
<p>This page prioritizes information on self-hosted comments. However, there
are other open-source solutions, including implementations of third-party
services (e.g., Github issues, such as
<a href="https://github.com/imsun/gitment">[1]</a>,
<a href="https://github.com/gitalk/gitalk">[2]</a>,
<a href="https://github.com/Blankj/awesome-comment">[3]</a>,
<a href="https://github.com/utterance/utterances">[4]</a>).</p>
<h2>Stars vs. time</h2>
<p>The figure below shows some of the top competitors except for Discourse (as it's not
just a light commenting server like others). The figure is useful to
indirectly estimate how active the project is.</p>
<p><a href="https://lisakov.com/projects/open-source-comments/stars-v-date.png">
<img src="https://lisakov.com/projects/open-source-comments/stars-v-date.png" alt="Plot stars vs. time" width="800px">
</a></p>
<h2>Choose columns to show</h2>
</div></div>]]>
            </description>
            <link>https://lisakov.com/projects/open-source-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676152</guid>
            <pubDate>Sun, 04 Oct 2020 02:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interacting with JavaScript from Go/WASM: objects, promises, HTTP requests]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24675460">thread link</a>) | @ItalyPaleAle
<br/>
October 3, 2020 | https://withblue.ink/2020/10/03/go-webassembly-http-requests-and-promises.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/10/03/go-webassembly-http-requests-and-promises.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><a href="https://webassembly.org/">WebAssembly</a>, or Wasm, is an open standard that allows developers to build apps that run inside a web browser using compiled programming languages. With WebAssembly, it’s possible to write components of web apps in languages such as C/C++, Rust, C#, and Go, among others, which run within the same sandbox as JavaScript. This allows things like porting existing libraries, leveraging capabilities not available in JavaScript, and running code faster because WebAssembly is compiled into a binary format.</p><p>Recently, I’ve been experimenting with WebAssembly to be able to run some Go code in the browser. Specifically, I’ve been trying to port certain parts of <a href="https://github.com/italypaleale/prvt">prvt</a>, an open source project for storing end-to-end encrypted documents, to run within a web browser directly. The reason for the WebAssembly experiment was two-fold: first, prvt makes extensive uses of cryptography and streams, both things which are not yet great in JavaScript; second, prvt itself is written in Go, so being able to re-use code in the browser would significantly simplify development.</p><blockquote><p>For an <strong>introduction to using WebAssembly with Go</strong>, I recommend <a href="https://golangbot.com/webassembly-using-go/">this article on Golang Bot</a>.<br>Additionally, more information can be found in the Go project’s <a href="https://github.com/golang/go/wiki/WebAssembly">GitHub wiki</a> and in the documentation for the <a href="https://golang.org/pkg/syscall/js/">syscall/js</a> package.<br>Note that as of writing, <strong>WebAssembly support in Go is still experimental</strong>. Because of that, the APIs might change too. This article was tested against Go 1.15.</p></blockquote><p>This article contains four different yet connected things that I’ve learnt while working on the WebAssembly port, and which I thought useful to share.</p><ol><li>Working with and creating JavaScript objects from Go code</li><li>Creating Promises in Go for passing async results</li><li>Making HTTP requests from Go code</li><li>Streaming from Go code</li></ol><h2 id="javascript-objects-in-webassembly-and-go">JavaScript objects in WebAssembly and Go</h2><p>The WebAssembly runtime for Go automatically converts the most common Go types to their JavaScript equivalent. The documentation for the <a href="https://golang.org/pkg/syscall/js/#ValueOf">js.ValueOf</a> method contains a nice summary table of how Go and JavaScript types are matched:</p><div><pre><code data-lang="text">| Go                     | JavaScript             |
| ---------------------- | ---------------------- |
| js.Value               | [its value]            |
| js.Func                | function               |
| nil                    | null                   |
| bool                   | boolean                |
| integers and floats    | number                 |
| string                 | string                 |
| []interface{}          | new array              |
| map[string]interface{} | new object             |
</code></pre></div><p>From here, you can see that the most common types, such as numbers, booleans, and strings, are converted automatically. The last row is particularly interesting as it explains how to pass “Plain Old JavaScript Objects” (POJO’s), which are the simplest kinds of objects (also called dictionaries).</p><p>For example, the following Go code defines a function called <code>MyGoFunc</code> that can be called from JavaScript code, which returns a dictionary with a string and a number (as you can see, types can be heterogeneous).</p><blockquote><p>For instructions of how to compile Go code into WebAssembly, check out the <a href="https://github.com/golang/go/wiki/WebAssembly#getting-started">Getting Started section</a> of the Wiki.</p></blockquote><p>After having compiled the code into WebAssembly and having imported it in the JavaScript code, you can call <code>MyGoFunc()</code> from JavaScript to see the result. For example:</p><div><pre><code data-lang="js"><span>console</span><span>.</span><span>log</span><span>(</span><span>MyGoFunc</span><span>())</span>
<span>// Prints: {hello: "world", answer: 42}
</span></code></pre></div><p>However, what the documentation is less explicit about is that we can also <strong>use any JavaScript object</strong> inside the Go code, <strong>even built-ins</strong>! And this is where things can start getting more interesting.</p><p>For example, let’s try to pass a date as a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date"><code>Date</code></a> object. To do that, we first need to grab the <code>Date</code> constructor, loading its <code>js.Value</code> from the global scope of JS:</p><div><pre><code data-lang="go"><span>dateConstructor</span> <span>:=</span> <span>js</span><span>.</span><span>Global</span><span>().</span><span>Get</span><span>(</span><span>"Date"</span><span>)</span>
</code></pre></div><p>Then, we can create a new object off this constructor with the <code>dateConstructor.New</code> method, passing any argument to it as you’d pass to the <code>new Date()</code> constructor in JavaScript. The result of the invocation is a <code>js.Value</code> that can be returned to JavaScript:</p><div><pre><code data-lang="go"><span>dateConstructor</span><span>.</span><span>New</span><span>(</span><span>"2020-10-01"</span><span>)</span>
</code></pre></div><p>So, we can modify our <code>MyGoFunc</code> to return the current date as computed in Go:</p><p>Invoking <code>MyGoFunc()</code> in the JavaScript code will now return a <code>Date</code> object:</p><div><pre><code data-lang="js"><span>let</span> <span>d</span> <span>=</span> <span>MyGoFunc</span><span>()</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>typeof</span> <span>d</span><span>)</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>d</span> <span>instanceof</span> <span>Date</span><span>)</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>d</span><span>.</span><span>toString</span><span>())</span>

<span>/*
</span><span>Prints:
</span><span>
</span><span>object
</span><span>true
</span><span>Sat Oct 03 2020 10:58:27 GMT-0700 (Pacific Daylight Time)
</span><span>*/</span>
</code></pre></div><h2 id="async-js-with-promises-from-go">Async JS with Promises from Go</h2><p>In JavaScript, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise"><code>Promise</code>'s</a> are the foundation of async/await. If you need a refresher on Promises, <a href="https://javascript.info/promise-basics">this is a good article</a>.</p><p>For example, consider this code, which creates a Promise that resolves with a message (<a href="https://www.mamalisa.com/?t=es&amp;p=5534">an Italian tongue-twister</a>) after 3 seconds:</p><div><pre><code data-lang="js"><span>const</span> <span>p</span> <span>=</span> <span>new</span> <span>Promise</span><span>((</span><span>resolve</span><span>,</span> <span>reject</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(()</span> <span>=&gt;</span> <span>{</span>
        <span>resolve</span><span>(</span><span>"sopra la panca la capra campa, sotto la panca la capra crepa"</span><span>)</span>
    <span>},</span> <span>3000</span><span>)</span>
<span>})</span>
</code></pre></div><p>In an <code>async</code> function, you can then <code>await</code> on the Promise above, so after 3 seconds you receive the message:</p><div><pre><code data-lang="js"><span>// This is an async function, which can contain "await" statements inside
</span><span></span><span>async</span> <span>function</span> <span>MyFunc</span><span>()</span> <span>{</span>
    <span>// Create the Promise
</span><span></span>    <span>const</span> <span>p</span> <span>=</span> <span>new</span> <span>Promise</span><span>((</span><span>resolve</span><span>,</span> <span>reject</span><span>)</span> <span>=&gt;</span> <span>{</span>
        <span>// After a 3 second timeout, this calls "resolve" with the message we're passing
</span><span></span>        <span>setTimeout</span><span>(()</span> <span>=&gt;</span> <span>{</span>
            <span>resolve</span><span>(</span><span>"sopra la panca la capra campa, sotto la panca la capra crepa"</span><span>)</span>
        <span>},</span> <span>3000</span><span>)</span>
    <span>})</span>
    <span>// Await for the Promise - this resolves after 3 seconds
</span><span></span>    <span>const</span> <span>message</span> <span>=</span> <span>await</span> <span>p</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>message</span><span>)</span>
<span>}</span>
</code></pre></div><p>Invoking <code>MyFunc()</code> will show <code>sopra la panca la capra campa, sotto la panca la capra crepa</code> in the console.</p><p>When working with Wasm in Go, Promises are particularly important.</p><p>In fact, as per the documentation, you cannot make blocking calls in Go inside a function that is invoked by JavaScript directly—if you do that, you’ll get an immediate deadlock and your app will crash. Instead, the documentation recommends that all blocking calls be inside a goroutine, which raises the problem of then returning the value to the JavaScript code. Quoting from the <a href="https://golang.org/pkg/syscall/js/#FuncOf">docs</a>:</p><blockquote><p>Invoking the wrapped Go function from JavaScript will pause the event loop and spawn a new goroutine. Other wrapped functions which are triggered during a call from Go to JavaScript get executed on the same goroutine.<br>As a consequence, if one wrapped function blocks, JavaScript’s event loop is blocked until that function returns. Hence, calling any async JavaScript API, which requires the event loop, like fetch (http.Client), will cause an immediate deadlock. Therefore a blocking function should explicitly start a new goroutine.</p></blockquote><p>Using a Promise is perhaps the best way to solve this problem: avoiding deadlocks while allowing programming with idiomatic JavaScript.</p><p>We saw in the previous section that we can create custom JavaScript objects from Go, and this applies to Promises too! We just need to create the <code>Promise</code> object by passing a function to the constructor. Just like in the pure-JS code above, this function receives two arguments, which are functions themselves: <code>resolve</code> should be invoked with the final result when the Promise’s work is done, and <code>reject</code> can be called when there’s an error to make the Promise fail.</p><p>Here’s an updated <code>MyGoFunc</code> that resolves with a message (<a href="https://www.bbc.co.uk/languages/yoursay/tongue_twisters/italian/trotting_trentonians.shtml">another Italian tongue twister!</a>) after 3 seconds:</p><p>To invoke this from JavaScript:</p><div><pre><code data-lang="js"><span>async</span> <span>function</span> <span>MyFunc</span><span>()</span> <span>{</span>
    <span>// Get the Promise from Go
</span><span></span>    <span>const</span> <span>p</span> <span>=</span> <span>MyGoFunc</span><span>()</span>
    <span>// Show the current UNIX timestamps (in seconds)
</span><span></span>    <span>console</span><span>.</span><span>log</span><span>(</span><span>Math</span><span>.</span><span>floor</span><span>(</span><span>Date</span><span>.</span><span>now</span><span>()</span> <span>/</span> <span>1000</span><span>))</span>
    <span>// Await for the Promise to resolve
</span><span></span>    <span>const</span> <span>message</span> <span>=</span> <span>await</span> <span>p</span>
    <span>// Show the current timestamp in seconds, then the result of the Promise
</span><span></span>    <span>console</span><span>.</span><span>log</span><span>(</span><span>Math</span><span>.</span><span>floor</span><span>(</span><span>Date</span><span>.</span><span>now</span><span>()</span> <span>/</span> <span>1000</span><span>),</span> <span>message</span><span>)</span>
<span>}</span>

<span>/*
</span><span>Result:
</span><span>  1601746916
</span><span>  1601746919 "Trentatré Trentini entrarono a Trento, tutti e trentatré trotterellando"
</span><span>*/</span>
</code></pre></div><p>If your Go code errors, you can throw exceptions to JavaScript by using the <code>reject</code> function instead. For example:</p><p>When you invoke this from JavaScript, you will see the returned object about half of the times, and you’ll get an exception the other half. Note that we’re invoking the <code>reject</code> function with an actual JavaScript <code>Error</code> object, as best practice in JavaScript!</p><div><pre><code data-lang="js"><span>async</span> <span>function</span> <span>MyFunc</span><span>()</span> <span>{</span>
    <span>try</span> <span>{</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>await</span> <span>MyGoFunc</span><span>())</span>
    <span>}</span> <span>catch</span> <span>(</span><span>err</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>error</span><span>(</span><span>'Caught exception'</span><span>,</span> <span>err</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>/*
</span><span>Result is either:
</span><span>  {error: null, message: "Hooray, it worked!"}
</span><span>Or a caught exception (followed by the stack trace):
</span><span>  Caught exception Error: Nope, it failed
</span><span>*/</span>
</code></pre></div><h2 id="making-http-requests-from-go-code">Making HTTP requests from Go code</h2><p>Finally, let’s look at how we can use Go and WebAssembly to make HTTP requests, a very common task. For example, you can do this inside a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers">Service Worker</a> to <a href="https://developer.mozilla.org/en-US/docs/Web/API/FetchEvent">intercept network requests</a> and have Go process them instead (that’s what I’m doing with prvt, so the Go code can decrypt the files).</p><p>There are two important things to keep in mind:</p><ol><li>Network calls from Go are blocking, so they must be executed in a separate Goroutine. Because of that, we should return a Promise from Go to JavaScript that eventually resolves with the result of the network request.</li><li>If your goal is to intercept network requests, then your Go code should return the response wrapped in a JavaScript <a href="https://developer.mozilla.org/en-US/docs/Web/API/Response"><code>Response</code></a> object.</li></ol><p>Here’s an example:</p><p>We can then use it in our JavaScript code to invoke any REST API and get the result as if it were a <code>fetch</code> request. For example, in the code below we’re making a call to the <a href="https://taylor.rest/">taylor.rest</a> API, which returns a random quote from Taylor Swift:</p><div><pre><code data-lang="js"><span>async</span> <span>function</span> <span>MyFunc</span><span>()</span> <span>{</span>
    <span>try</span> <span>{</span>
        <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>MyGoFunc</span><span>(</span><span>'https://api.taylor.rest/'</span><span>)</span>
        <span>const</span> <span>message</span> <span>=</span> <span>await</span> <span>response</span><span>.</span><span>json</span><span>()</span>
        <span>console</span><span>.</span><span>log</span><span>(</span><span>message</span><span>)</span>
    <span>}</span> <span>catch</span> <span>(</span><span>err</span><span>)</span> <span>{</span>
        <span>console</span><span>.</span><span>error</span><span>(</span><span>'Caught exception'</span><span>,</span> <span>err</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>/*
</span><span>Result is a quote from Taylor Swift, as a JSON object. For example:
</span><span>  {"quote":"The only one who's got enough of me to break my heart."}
</span><span>*/</span>
</code></pre></div><blockquote><p>Note that when making a HTTP request from Go, the WebAssembly runtime internally converts the calls to fetch requests in the browser. So, even when …</p></blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/10/03/go-webassembly-http-requests-and-promises.html">https://withblue.ink/2020/10/03/go-webassembly-http-requests-and-promises.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/10/03/go-webassembly-http-requests-and-promises.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24675460</guid>
            <pubDate>Sat, 03 Oct 2020 23:31:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Radix Sort Revisited (2000)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24675370">thread link</a>) | @Radim
<br/>
October 3, 2020 | http://www.codercorner.com/RadixSortRevisited.htm | <a href="https://web.archive.org/web/*/http://www.codercorner.com/RadixSortRevisited.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span lang="FR">Radix Sort Revisited<o:p></o:p></span></p>





<p><span lang="EN-GB">Pierre <span>Terdiman</span><o:p></o:p></span></p>

<p><span lang="EN-GB">Last revision: 04.01.2000<o:p></o:p></span></p>





<p><span lang="FR">In every decent
programmer’s toolbox lies a strange weapon called a Radix Sort. Where does it
come from&nbsp;? Who invented it&nbsp;? I don’t know. As far as I can remember
it was there, fast, easy, effective. <i>Really</i> effective. So unbelievably
useful I’ve never really understood why people would want to use something
else. The reasons&nbsp;? Most of the time, they tell me about floats, negative
values, and why their new quick-sort code rocks.<o:p></o:p></span></p>



<p><span lang="FR">Enough, I’m tired.
Although the standard Radix Sort doesn’t work very well with floating point
values, this is something actually very easy to fix. In this little article I
will review the standard Radix Sort algorithm, and enhance it so that&nbsp;:<o:p></o:p></span></p>



<p><!--[if !supportLists]--><span lang="FR"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="FR">it sorts
negative floats as well<o:p></o:p></span></p>

<p><!--[if !supportLists]--><span lang="FR"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="FR">it has
reduced complexity for bytes and words<o:p></o:p></span></p>

<p><!--[if !supportLists]--><span lang="FR"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="FR">it uses
temporal coherence<o:p></o:p></span></p>

<p><!--[if !supportLists]--><span lang="FR"><span>-<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span></span></span><!--[endif]--><span lang="FR">it
supports sorting on multiple keys<o:p></o:p></span></p>











<p><span lang="FR">Is it worth writing
anything in 2000 about a sort routine&nbsp;? Doesn’t everyone already have
one&nbsp;? Aren’t those things already well known&nbsp;? Everyone knows how to
sort negative floats with a Radix, don’t you think&nbsp;?<o:p></o:p></span></p>



<p><span lang="FR">Well, that’s what I
would’ve said some weeks ago. But I recently wandered on Ming C. Lin’s homepage
[2], and began to read her courses. Here’s what I found&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR">«&nbsp;Counting sort
and radix sort are good for integers. For floating point numbers, try bucket
sort or other comparison-based methods&nbsp;» (21 sept. 1999) [3]<o:p></o:p></span></p>



<p><span lang="FR">As you see this is
not very old…I read more of the courses, read some older papers about collision
detection, and it appeared my own way of dealing with a specific part of this
problem was (at least from a theoretical point of view) faster than the
official one. Hence, I think this article will be useful for beginners as well
as for experienced programmers.<o:p></o:p></span></p>











<p><span lang="FR">A Radix Sort is an
apparently bizarre sort routine which manages to sort values without actually
performing any comparisons on input data. That’s why this sort routine breaks
the theoretical lower bound of the O(N*logN) complexity, which only applies for
comparison-based sorts. Radix is O(k*N), with k = 4 most of the time, and
although this is not an in-place sort (i.e. it uses extra storage) it is so
much faster than any other sorting methods it has become a very popular way of sorting
data.<o:p></o:p></span></p>





<p><span lang="FR">The algorithm<o:p></o:p></span></p>



<p><span lang="FR">What is a <i>radix</i>, anyway&nbsp;?<o:p></o:p></span></p>



<p><span lang="FR">Roughly we can say a radix is a position in a number. In the decimal
system, a radix is just a digit in a decimal number. For example the number
«&nbsp;42&nbsp;» has two digits, or two radices, which are 4 and 2. In
hexadecimal the radix is 8 bits wide. For example the hexadecimal number 0xAB
has two radices, A and B. The Radix Sort gets its name from those radices,
because the method first sorts the input values according to their first radix,
then according to the second one, and so on. The Radix Sort is then a multipass
sort, and the number of passes equals the number of radices in the input
values. For example you’ll need 4 passes to sort standard 32 bits integers,
since in hexadecimal the radix is a byte. By the way that’s why the Radix Sort
is often called <i>Byte Sort</i>.<o:p></o:p></span></p>



<p><span lang="FR">How does it work&nbsp;? Say you want to sort some bytes, for
example&nbsp;those ones:<o:p></o:p></span></p>



<p><span lang="FR">54,
18, 2, 128, 3<o:p></o:p></span></p>



<p><span lang="FR">The idea behind the Radix Sort is to read input values and immediately
store them at the right place.<o:p></o:p></span></p>



<p><span lang="FR">Have a look at that sample code&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR"><span>&nbsp;&nbsp;
</span>unsigned char InputValues[] = { 54, 18, 2, 128, 3 };<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>int SortedBuffer[256];<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp;
</span>memset(SortedBuffer, -1, 256*sizeof(int));<span>&nbsp;&nbsp; </span>// Fill with –1<o:p></o:p></span></p>



<pre><span lang="FR"><span>&nbsp;&nbsp; </span>for(int i=0&nbsp;;i&lt;5&nbsp;;i++){<o:p></o:p></span></pre>

<p><span lang="FR"><span>&nbsp;&nbsp;&nbsp;&nbsp;
</span>unsigned char c = InputValues[i];<o:p></o:p></span></p>

<pre><span lang="FR"><span>&nbsp; </span><span>&nbsp;&nbsp;&nbsp;</span>SortedBuffer[c] = c;<o:p></o:p></span></pre>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>}<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>// Now you can read SortedBuffer and get
values back in sorted order<o:p></o:p></span></p>





<p><span lang="FR">You may think this example is stupid – it <i>is</i>&nbsp;! – but it
nicely introduces the ideas we’ll have to deal with. What do we need to change
in that code, in order for it to become useful&nbsp;? First we need to get rid
of the empty destination locations, so that the destination buffer (called
SortedBuffer in our example) has the same size as the input buffer (i.e. enough
for 5 values, no more). We also need a way to handle collisions – collisions in
the hash-table sense of the word, i.e. we must be able to deal with two equal
input values and know how to store both of them in the final buffer. Luckily
enough, both problems are solved by the same solution&nbsp;: an <i>offset table</i>.<o:p></o:p></span></p>



<p><span lang="FR">The offset table is a 256-entries table telling us, for each possible
input byte, where we should store the result. It is usually built in two
passes, one to compute the distribution of bytes in the input flow (i.e.
histograms, or <i>counters</i>), another one to create the offset table
according to this distribution.<o:p></o:p></span></p>



<p><span lang="FR">This sample code&nbsp;creates the counters:<o:p></o:p></span></p>



<p><span lang="FR"><span>&nbsp;&nbsp; </span>int
Counters[256];<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp;
</span>memset(Counters, 0, 256*sizeof(int));<span>&nbsp; </span>//
Set all counters to 0<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>for(
i =0&nbsp;; i &lt; NbItems&nbsp;; i++){<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>//
Loop over the input array<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span>unsigned char c = InputValues[i];<span> </span>//
Get current byte…<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
</span>Counters[c]++;<span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>//
…and update counter<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>}<o:p></o:p></span></p>



<p><span lang="FR">We can now create the offset table&nbsp;:<o:p></o:p></span></p>



<pre><span lang="FR"><span>&nbsp;&nbsp; </span>int OffsetTable[256];<o:p></o:p></span></pre><pre><span lang="FR"><span>&nbsp;&nbsp; </span>OffsetTable[0] = 0;<o:p></o:p></span></pre>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>for(i=1;i&lt;256;i++){<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>OffsetTable[i] = OffsetTable[i-1] +
Counters[i-1];<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp; </span>}<o:p></o:p></span></p>



<p><span lang="FR">Now, for each input byte, we can
get the right offset back thanks to this table, put the input byte at the right
place in the destination buffer, increase the offset, and repeat the sequence
for the next byte.<o:p></o:p></span></p>



<p><span lang="FR">For example&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR"><span>&nbsp;&nbsp; </span>unsigned char c =
InputValues[i];<o:p></o:p></span></p>

<p><span lang="FR"><span>&nbsp;&nbsp;
</span>DestinationBuffer[OffsetTable[c]++] = c;<o:p></o:p></span></p>



<p><span lang="FR">The destination buffer won’t have
any empty locations&nbsp;: we have enough room in it for the same number of
values as in the input buffer, no more. Thanks to the offsets we know exactly
where we must store them, and whenever an empty location would have existed in
our first example, here it doesn’t appear because no offset actually maps that
empty location.<o:p></o:p></span></p>



<p><span lang="FR">Collisions are not a problem
either because offsets are increased each time we use one of them. If we have
two identical bytes in input, the first one will be put in
DestinationBuffer[Offset], Offset will be increased, and the next one will then
fall in DestinationBuffer[Offset+1]. Radix sort is <i>stable</i> by the way,
which means two same values in input will be in the same order in output.<o:p></o:p></span></p>



<p><span lang="FR">This last point is very important
to understand the next step&nbsp;: how can we extend the process in order to
sort not only bytes but also words, dwords, or event character strings&nbsp;?
This is actually very simple&nbsp;: we just have to sort again according to the
next radix. Recall a radix actually is a byte in the values to sort. The first
radix is the LSB (Least Significant Byte). The last one must be the MSB (Most
Significant Byte). Between those two, we perform all necessary passes. The
second pass doesn’t destroy what has been done in the first one because the
sorting method is stable.<o:p></o:p></span></p>



<p><span lang="FR">Example&nbsp;: say we want to sort
those hexadecimal values&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR">0xBC, 0xAB, 0xBA, 0xAC, 0xBB, 0xAA<o:p></o:p></span></p>



<p><span lang="FR">The first pass leads to&nbsp;:<o:p></o:p></span></p>

<p><span lang="FR">0xBA<o:p></o:p></span></p>

<p><span lang="FR">0xAA<o:p></o:p></span></p>

<p><span lang="FR">0xAB<o:p></o:p></span></p>

<p><span lang="FR">0xBB<o:p></o:p></span></p>

<p><span lang="FR">0xBC<o:p></o:p></span></p>

<p><span lang="FR">0xAC<o:p></o:p></span></p>



<p><span lang="FR">Note that the list is sorted
according to the last column (ie the LSB which is the first radix). The second
pass will sort this list according to the first column (ie the MSB, our second
radix) and since the sorting method is stable, the 3 numbers 0xAA, 0xAB and
0xAC which share the same MSB will be found in output in the same order as in
input. And since the input order has been determined by the first sorting pass,
eh, it’s already sorted according to the LSB, and here we are with the final
sorted list&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR">0xAA<o:p></o:p></span></p>

<p><span lang="FR">0xAB<o:p></o:p></span></p>

<p><span lang="FR">0xAC<o:p></o:p></span></p>

<p><span lang="FR">0xBA<o:p></o:p></span></p>

<p><span lang="FR">0xBB<o:p></o:p></span></p>

<p><span lang="FR">0xBC<o:p></o:p></span></p>



<p><span lang="FR">Radix selection is
performed by shifting and ANDing the input value according to the pass
number&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR">unsigned
char Radix = (InputValues[i]&gt;&gt;(Pass&lt;&lt;3)) &amp; 0xFF;<o:p></o:p></span></p>



<p><span lang="FR">…where pass begins
to 0 and gets increased for each new pass.<o:p></o:p></span></p>







<p><b><span lang="FR">Sorting floating point values<o:p></o:p></span></b></p>



<p><span lang="FR">Ok, that was the
standard Radix Sort, as most of us knew it on old 16 bits computers. What
happened then, was the following&nbsp;: one day, we all switched to 80486 (or
Pentium) and suddenly we had floats. At first sight, a Radix Sort can’t deal
with floats&nbsp;: the inner structure of a float isn’t obvious, you don’t
really see how to shift them or AND a value with them (the algorithm involves
such an operation, as seen just above), you don’t even know how to do it.<o:p></o:p></span></p>



<p><span lang="FR">The first step is to
learn how a floating-point value is actually built. This is well known
nowadays&nbsp;: the first bit is the sign bit, the next 8 bits are the biased
exponent, and the 23 last ones are the mantissa. The exponent is always
positive thanks to the bias. Chris Hecker once wrote a good introduction paper
to the numerous floating-points tricks you can afford on Intel processors [1].
Let’s quote him&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR">«&nbsp;Because the
exponent are always positive (and are in more significant bits than the
mantissa), large numbers compare greater than small numbers even when the
floating-point values are compared as normal integer bits. The sign bit throws
a monkey wrench in this, but it works great for single-signed values.&nbsp;»<o:p></o:p></span></p>



<p><span lang="FR">I couldn’t have said
that better. And from this point, it is easy to see why it works with positive
floats. Let’s define a function IR(x) as the integer representation of any
floating-point value x. For example the floating-point value 42.0 has a binary
representation of 0x42280000. In other words&nbsp;:<o:p></o:p></span></p>



<p><span lang="FR">IR(42.0)
= 0x42280000<o:p></o:p></span></p>



<p><span lang="FR">The Radix Sort works
with positive floats because for any floating-point values x and y,<o:p></o:p></span></p>



<p><span lang="FR">x
&gt; y &gt;0 =&gt; IR(x) &gt; IR(y)<o:p></o:p></span></p>



<p><span lang="FR">Hence x and y will
be treated by the sorting code as IR(x) and IR(y), and the final order will be
correct. This is easy to check&nbsp;: just cast your float pointer into integer
pointer and ask your code to sort your array of positive floats&nbsp;! It
works. Well, it doesn’t work on DEC Alpha because the float format is
different, but that’s another story&nbsp;: it works provided you use IEEE
floats, which means it works on PC, on Dreamcast, and so on.<o:p></o:p></span></p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.codercorner.com/RadixSortRevisited.htm">http://www.codercorner.com/RadixSortRevisited.htm</a></em></p>]]>
            </description>
            <link>http://www.codercorner.com/RadixSortRevisited.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24675370</guid>
            <pubDate>Sat, 03 Oct 2020 23:12:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You have no idea where the time has gone and have nothing to showcase your work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24674879">thread link</a>) | @sanmak
<br/>
October 3, 2020 | https://www.boxpiper.com/posts/the-pomodoro-technique-why-what-how-productivity-worksheet/ | <a href="https://web.archive.org/web/*/https://www.boxpiper.com/posts/the-pomodoro-technique-why-what-how-productivity-worksheet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
  <a href="https://www.boxpiper.com/static/48405c694b4f1832e9d9ec0c3b940eca/eea4a/pomodoro-1.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="pomodoro 1" title="" src="https://www.boxpiper.com/static/48405c694b4f1832e9d9ec0c3b940eca/6a068/pomodoro-1.jpg" srcset="https://www.boxpiper.com/static/48405c694b4f1832e9d9ec0c3b940eca/09b79/pomodoro-1.jpg 240w,
https://www.boxpiper.com/static/48405c694b4f1832e9d9ec0c3b940eca/7cc5e/pomodoro-1.jpg 480w,
https://www.boxpiper.com/static/48405c694b4f1832e9d9ec0c3b940eca/6a068/pomodoro-1.jpg 960w,
https://www.boxpiper.com/static/48405c694b4f1832e9d9ec0c3b940eca/eea4a/pomodoro-1.jpg 1280w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    </p>
<h2><u>Problem Statement</u></h2>
<ul>
<li>You know you are wasting time, and feel disappointed, because you have lost your day by scrolling social media feeds, emails, YouTube.</li>
<li>You have no idea where the time has gone and you have nothing to showcase your work.</li>
<li>You are a procrastinator.</li>
<li>You did a lot of work and felt accomplished but you didn’t complete exactly what is required from that day.</li>
<li>You are working but not able to give 100%.</li>
</ul>
<p>To solve the problems mentioned above, The Pomodoro technique was born and used by <strong>Successful People</strong> like Steven Sande, Natalie Sisson, Hayden Miyamoto, Tim Ferriss and many more.</p>
<h2><u>The Pomodoro Technique</u></h2>
<p>
  <a href="https://www.boxpiper.com/static/bbe98a5e2bf757a5df1653808cef841d/8c557/pomodoro-4.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="pomodoro-4" title="" src="https://www.boxpiper.com/static/bbe98a5e2bf757a5df1653808cef841d/8c557/pomodoro-4.png" srcset="https://www.boxpiper.com/static/bbe98a5e2bf757a5df1653808cef841d/8ff5a/pomodoro-4.png 240w,
https://www.boxpiper.com/static/bbe98a5e2bf757a5df1653808cef841d/e85cb/pomodoro-4.png 480w,
https://www.boxpiper.com/static/bbe98a5e2bf757a5df1653808cef841d/8c557/pomodoro-4.png 700w" sizes="(max-width: 700px) 100vw, 700px">
    </span>
  </span>
  
  </a>
    </p>
<h2><u>Basic Explanation</u> <p> <iframe src="https://player.vimeo.com/video/157970785" frameborder="0" allow="fullscreen" allowfullscreen=""></iframe> </p></h2>
<p>The Pomodoro Technique is a framework which is designed to provide time management recipes and hence improving your focus and productivity.</p>
<h2><u>Process</u></h2>
<p>Firstly, Find and list down tasks to be done. The follow steps given below.</p>
<ul>
<li>Choose a task from list.</li>
<li>Focus for next 25 mins. Work closely with little or zero distractions and no pause. Pomodoro teaches to manage distractions. List down if any distractions identified in this step.</li>
<li>Take a 5 min break. Once 25 minutes ended, relax, clear your mind and come back after 5 mins.</li>
<li>Repeat it for 4 times.</li>
<li>Total time spent is 2 hours. 1 hours 40 mins for work and 20 mins break. Note progress that you have made.</li>
<li>After 4th iteration, take a long break of 15 - 25 mins and come back to restart from point 1.</li>
<li>Long break can be used for lunch in between.</li>
</ul>
<p>
  <a href="https://www.boxpiper.com/static/904c2560cca21686eb8161fb06f75248/d7542/pomodoro-2.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="pomodoro 2" title="" src="https://www.boxpiper.com/static/904c2560cca21686eb8161fb06f75248/d7542/pomodoro-2.png" srcset="https://www.boxpiper.com/static/904c2560cca21686eb8161fb06f75248/8ff5a/pomodoro-2.png 240w,
https://www.boxpiper.com/static/904c2560cca21686eb8161fb06f75248/e85cb/pomodoro-2.png 480w,
https://www.boxpiper.com/static/904c2560cca21686eb8161fb06f75248/d7542/pomodoro-2.png 810w" sizes="(max-width: 810px) 100vw, 810px">
    </span>
  </span>
  
  </a>
    </p>
<p>25-minute blocks are called <strong>Pomodoro sessions</strong> and it’s the core of this Technique. Work is divided / breakdown into smaller sprints. Due to shorter sprints cycle, any tasks (small or big) becomes much more manageable and the brain is getting trained to focus and eventually it helps to make progress.</p>
<p>Generally, an 8-hour workday technically leaves room for sixteen Pomodoro sessions, but do keep some Pomodoro sessions in the buffer as a factor of safety. In case a task required more than available Pomodoro sessions, then tasks need a further breakdown. Tasks which takes less than one Pomodoro sessions can be combined with other tasks.</p>
<p>Pomodoro sessions are strictly delegated for work, learning, reading, improving skills. If a task is completed and have few minutes in hand during a session, utilise it carefully.</p>
<h2><u>Result</u></h2>
<p>With all the time available in a day, With the Pomodoro technique, you have a clear measurement of your time and efforts. It leads to reflect and plan your days more accurately and efficiently.</p>
<p>With time, a more accurate assessment of Pomodoro sessions will be developed and hence building consistent work habits.</p>
<h2><u>Pomodoro Timer App for Pomodoro Timer</u></h2>
<p><a href="https://pomofocus.io/">https://pomofocus.io/</a>. This tool helps you to focus and manager your tasks.</p>
<h2><u>Pomodoro Technique Playlist</u></h2>
<p>A playlist to utilise the Pomodoro technique. 4 cycles of 25 minutes of focus LoFi music followed by 5 minutes of vocal tracks for a break. Make sure shuffle is turned off. At the end of the playlist, take a 30-minute break.</p>

<h2><u>Looking to master Pomodoro Technique ?</u></h2>
<p><iframe width="100%" height="315" src="https://www.youtube-nocookie.com/embed/VFW3Ld7JO0w?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<h2><u>Ending Note</u></h2>
<p>Pomodoro Technique breaks down tasks into smaller chunks and helps to do more with less. It simplifies your life and unclutters your mind. The technique will become a part of your routine if followed religiously. Since it’s free you can tweak it as per your schedule.</p></div></div>]]>
            </description>
            <link>https://www.boxpiper.com/posts/the-pomodoro-technique-why-what-how-productivity-worksheet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24674879</guid>
            <pubDate>Sat, 03 Oct 2020 21:43:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Push vs. Pull-Based Urgency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24674584">thread link</a>) | @Ozzie_osman
<br/>
October 3, 2020 | https://somehowmanage.com/2020/10/03/push-vs-pull-based-motivation/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/10/03/push-vs-pull-based-motivation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-119">

	

	
	<div>
		
<p>I was talking to my friend Josh a couple weeks ago about the speed at which teams move and how best managers can create a sense of urgency. We pretty quickly agreed that there are two types of urgency for a team: push-based and pull-based.</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>Is your urgency push-based or pull-based?</p><p>It's a thought-provoking management question.</p><p>Ex: Arbitrary deadline=push, Excitement=pull</p><p>Does this division make sense? What other kinds of urgency are there?</p></div>— Joshua Levy (@ojoshe) <a href="https://twitter.com/ojoshe/status/1309279621448310786?ref_src=twsrc%5Etfw">September 24, 2020</a></blockquote></div>
</div></figure>



<p>I felt like this is an important delineation, and wanted to summarize our conversation a little, just by giving some examples.</p>



<ul><li><strong>Team:</strong><ul><li><strong>Push-based: </strong>You hire people who will what is asked of them, and nothing more.</li><li><strong>Pull-based: </strong>You hire people who are conscientious and self-motivated, and if they aren’t being pushed, they will push themselves and everyone around them.</li></ul></li><li><strong>Goals:</strong><ul><li><strong>Push-based: </strong>The team has “soul-less” goals like “get X done by Y” or “increase metric Y by Z”.</li><li><strong>Pull-based: </strong>The team clearly understands the value of what they are building and are excited about making it real.</li></ul></li><li><strong>Road-blocks:</strong><ul><li><strong>Push-based:</strong> Team members constantly lose momentum because they run into obstacles that are beyond their control.</li><li><strong>Pull-based: </strong>The “path is paved”, so-to-speak. Team members might face obstacles, but they are either empowered to clear those obstacles or have access to executives that can clear the obstacles for them.</li></ul></li><li><strong>Deadlines:</strong><ul><li><strong>Push-based:</strong> Arbitrary deadlines like “our exec wants this done by Friday”.</li><li><strong>Pull-based:</strong> Self-imposed deadlines like “this should take 2 weeks, and we will hold ourselves accountable to that”.</li></ul></li></ul>



<p>We actually discussed deadlines a little bit, and as Josh always does he broke out a few dimensions:</p>



<ul><li>Deadlines can be artificial or real. An artificial deadline is one in which there will be no repercussions if the deadline is missed, and a real one has repercussions.</li><li>Deadlines can be superimposed or self-imposed. A team can decide a deadline for itself, or someone (typically more senior) can decide a deadline for them.</li><li>Deadlines can be evident or arbitrary. An evident deadline might be “if we don’t build our product by November, we’ll miss out on the holiday season orders.”</li></ul>



<p>So a deadline that is real, superimposed, and arbitrary, could be something like “If you don’t accomplish this by end-of-month, you will be fired.”</p>



<p>Someone once told me that managers push and leaders pull. Plenty of people, companies, and teams have gotten results with very “push-based” urgencies, but if you ask someone which type of urgency they prefer on their team, they’ll likely say “pull-based”. Which is an interesting point to ponder.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://somehowmanage.com/2020/10/03/push-vs-pull-based-motivation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24674584</guid>
            <pubDate>Sat, 03 Oct 2020 20:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make your Ubuntu Server VPS more secure against unauthorized access]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24674317">thread link</a>) | @phiilu
<br/>
October 3, 2020 | https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access | <a href="https://web.archive.org/web/*/https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When creating a new VPS you need to make sure that you secure your server from the scary internet. The only one that should be able to administrate the server should be you and <strong>only</strong> you!</p><p>There are few (simple) steps involved in how you can secure your server and have a good sleep at night, without fearing someone might hack your server.</p><h2 id="Prerequisites">Prerequisites<a aria-label="Prerequisites permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Prerequisites"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h2><p>You should have an existing or freshly installed server running Ubuntu 20.08 VPS available and able to log in. </p><p>If you don't know how you can create your own server, check out my blog post <a href="https://phiilu.com/create-your-first-vps-on-vultr">Create your first VPS on Vultr</a> to deploy your very first VPS using <a href="https://www.vultr.com/?ref=8356779" target="_blank" rel="noopener noreferrer">Vultr*</a>. </p><p>Vultr is just my choice for hosting servers on the internet, but you can use other providers such as <a href="https://www.linode.com/" target="_blank" rel="noopener noreferrer">Linode</a> or <a href="https://m.do.co/c/c9b5a3aebb78" target="_blank" rel="noopener noreferrer">DigitalOcean*</a> too. You can't be wrong choosing any of the mentioned providers.</p><blockquote><p>Disclaimer: links containing a * at the end are affiliate links, which means if you signup using that link I would get a small commission and it helps me out!</p></blockquote><h2 id="Creating-a-new-user-to-administrate-the-server">Creating a new user to administrate the server<a aria-label="Creating a new user to administrate the server permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Creating-a-new-user-to-administrate-the-server"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h2><p>When you create a new VPS you usually get access to the <code>root</code> user with a password. For security reasons, we create a new user that will be used to administrate the server. It is good practice to only work with the least amount of privileges you need and use <code>sudo</code> when you need more permissions. </p><p>We will disable the possibility to log in as the <code>root</code> user using a password, but we will allow it to log in using public-key authentication.</p><hr><p>To add a new user you can use the <code>adduser</code> command.</p><p>You will be asked a few questions including what password you want to use. Make sure the password is secure and in the best case random generated and stored in a password manager like <a href="https://1password.com/" target="_blank" rel="noopener noreferrer">1Password</a> or <a href="https://www.lastpass.com/" target="_blank" rel="noopener noreferrer">Lastpass</a>.</p><div><pre><code><p><span>Adding user `phiilu' ...</span></p><p><span>Adding new group `phiilu' (1000) ...</span></p><p><span>Adding new user `phiilu' (1000) with group `phiilu' ...</span></p><p><span>Creating home directory `/home/phiilu' ...</span></p><p><span>Copying files from `/etc/skel' ...</span></p><p><span>New password:</span></p><p><span>Retype new password:</span></p><p><span>passwd: password updated successfully</span></p><p><span>Changing the user information for phiilu</span></p><p><span>Enter the new value, or press ENTER for the default</span></p><p><span>    Full Name []: Florian</span></p><p><span>    Room Number []:</span></p><p><span>    Work Phone []:</span></p><p><span>    Home Phone []:</span></p><p><span>    Other []:</span></p><p><span>Is the information correct? [Y/n]</span></p></code></pre></div><p>Now we have a new user that we can use to log in. If you are the <code>root</code> user you can just type</p><p>and you will be logged in as the user without prompted a password. You can also use log in with the <code>login</code> command.</p><hr><p>Next, we want to give the user permission to administrate the server. Right now we have a new user, but the user does not have any permission to make any changes as a superuser. </p><p>You can confirm this when trying to update the packages:</p><div><pre><code><p><span>[sudo] password for phiilu:</span></p><p><span>phiilu is not in the sudoers file.  This incident will be reported.</span></p></code></pre></div><p>As you can see, we need to add the new user to the sudoers file to be able to execute commands as the superuser.</p><p>We need to exit our current session with <code>exit</code>. You should now be logged in as the <code>root</code> user.</p><p>If you are <code>root</code>, you can type <code>visudo</code> to check the current sudoers file.</p><div><pre><code><p><span>#</span></p><p><span># This file MUST be edited with the 'visudo' command as root.</span></p><p><span>#</span></p><p><span># Please consider adding local content in /etc/sudoers.d/ instead of</span></p><p><span># directly modifying this file.</span></p><p><span>#</span></p><p><span># See the man page for details on how to write a sudoers file.</span></p><p><span>#</span></p><p><span>Defaults        env_reset</span></p><p><span>Defaults        mail_badpass</span></p><p><span>Defaults        secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"</span></p><p><span># Host alias specification</span></p><p><span># User alias specification</span></p><p><span># Cmnd alias specification</span></p><p><span># User privilege specification</span></p><p><span>root    ALL=(ALL:ALL) ALL</span></p><p><span># Members of the admin group may gain root privileges</span></p><p><span>%admin ALL=(ALL) ALL</span></p><p><span># Allow members of group sudo to execute any command</span></p><p><span>%sudo   ALL=(ALL:ALL) ALL</span></p><p><span># See sudoers(5) for more information on "#include" directives:</span></p><p><span>#includedir /etc/sudoers.d</span></p></code></pre></div><p>You can see that if a user is in the <code>sudo</code> group, he should be able to execute commands as <code>root</code>. There is also the <code>admin</code> group in my <code>sudoers</code> file which will allow the user in that group to execute some commands as <code>root</code>. We want to be able to do the same things the root user can do so we will choose the <code>sudo</code> group.</p><p>To add a user to a group you can use the <code>usermod</code> command using the options <code>-a</code> for add and <code>-G</code> for alternative groups followed by the group's name and the user you want to modify.</p><div><pre><code><p><span>usermod -a -G sudo phiilu</span></p></code></pre></div><p>With <code>id</code> you can check the groups (and ids) of a user and can confirm that the user is now part of the <code>sudo</code> group.</p><div><pre><code><p><span>id phiilu</span></p><p><span>uid=1000(phiilu) gid=1000(phiilu) groups=1000(phiilu),27(sudo)</span></p></code></pre></div><p>Now that our user is in the <code>sudo</code> group, you can log in as that user and try to update the packages again and this time it should work!</p><h2 id="Securing-SSH">Securing SSH<a aria-label="Securing SSH permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Securing-SSH"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h2><p>Now that we have a new user that can execute commands as <code>root</code>, we can go forward and harden our server even more by changing some settings for <code>ssh</code>. </p><p>Before doing that we want to set up public-key authentication for both our users <code>root</code> and the one we created before.</p><h3 id="Using-public-key-authentication">Using public key authentication<a aria-label="Using public key authentication permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Using-public-key-authentication"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h3><blockquote><p>This is a recap of the "Skip passwords with public key authentication" section of my <a title="Use Visual Studio Code Remote to edit files on servers" href="https://phiilu.com/use-visual-studio-code-remote-to-edit-files-on-servers/">Use Visual Studio Code Remote to edit files on servers</a> post.</p></blockquote><p><a href="https://en.wikipedia.org/wiki/Public-key_cryptography" target="_blank" rel="noopener noreferrer">Public key authentication</a> is a secure way to connect to a server with SSH using a set of key pairs. The public key is saved on the server and the private key should be kept on your local machine. This is the key to unlock the server and <strong>must never</strong> be leaked or shared with someone else.</p><p>If you are using Windows you must have <a href="https://gitforwindows.org/" target="_blank" rel="noopener noreferrer">Git for Windows</a> installed and use the following commands inside the <strong>Git Bash</strong>.</p><p>The following commands should be the same for Windows and macOS except you might have to end the commands on Windows with <code>.exe</code>.</p><h4 id="Generating-SSH-Key">Generating SSH Key<a aria-label="Generating SSH Key permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Generating-SSH-Key"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h4><p>If you already have an SSH key that you might already use with <code>git</code> you can skip this step.</p><p>Which results in the following output.</p><div><pre><code><p><span>Generating public/private rsa key pair.</span></p><p><span>Enter file in which to save the key (/c/Users/flori/.ssh/id_rsa):</span></p><p><span>Enter passphrase (empty for no passphrase):</span></p><p><span>Enter same passphrase again:</span></p><p><span>Your identification has been saved in /c/Users/flori/.ssh/id_rsa.</span></p><p><span>Your public key has been saved in /c/Users/flori/.ssh/id_rsa.pub.</span></p><p><span>The key fingerprint is:</span></p><p><span>SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx flori@Windows</span></p></code></pre></div><p>You can set a passphrase for the key if you want, but then you have to enter a password for the log in which we want to avoid.</p><h4 id="Copy-the-public-key-to-the-server">Copy the public key to the server<a aria-label="Copy the public key to the server permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Copy-the-public-key-to-the-server"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h4><p>You can either manually paste the key to the server or you can use a program called <code>ssh-copy-id</code> which I prefer.</p><p>On macOS you have to install <code>ssh-copy-id</code> using <code>brew</code> on Windows it should be already present in the Git Bash. </p><p>To copy the key to the server you just have to log in to the server using the <code>ssh-copy-id</code> utility. Do this step twice for both users.</p><blockquote><p>replace VPS_IP with the real IP of your VPS</p></blockquote><div><pre><code><p><span>/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/Users/florian/.ssh/id_rsa.pub"</span></p><p><span>/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span></p><p><span>/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span></p><p><span>root@VPS_IP's password:</span></p><p><span>Number of key(s) added:        1</span></p><p><span>Now try logging into the machine, with:   "ssh 'root@VPS_IP'"</span></p><p><span>and check to make sure that only the key(s) you wanted were added.</span></p></code></pre></div><h4 id="Verifying-the-public-key-authentication">Verifying the public key authentication<a aria-label="Verifying the public key authentication permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Verifying-the-public-key-authentication"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h4><p>Now if you try to log in with <code>ssh</code> you should not be asked for a password.</p><p>If you are still asked for a password check if the permissions on the <code>authorized_keys</code> file on the server are correct:</p><div><pre><code><p><span>drwx------ 2 root root 4096 Sep 18 17:23 .</span></p><p><span>drwx------ 7 root root 4096 Sep 21 14:48 ..</span></p><p><span>-rw------- 1 root root  416 Sep 18 17:23 authorized_keys</span></p></code></pre></div><p>If your permissions are different you might have to change them:</p><div><pre><code><p><span>chmod 700 ~/.ssh</span></p><p><span>chmod 600 ~/.ssh/authorized_keys</span></p></code></pre></div><h3 id="A-more-secure-ssh-config">A more secure ssh config<a aria-label="A more secure ssh config permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#A-more-secure-ssh-config"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h3><p>To change the configuration for <code>ssh</code> open the <code>/etc/ssh/sshd_config</code> file with your favorite text editor or you can check out my blog post <strong><a title="Use Visual Studio Code Remote to edit files on servers" href="https://phiilu.com/use-visual-studio-code-remote-to-edit-files-on-servers/">Use Visual Studio Code Remote to edit files on servers</a></strong> to use a GUI editor to modify your server files.</p><p>First of all, I want to change that the <code>root</code> user is not able to log in with a password, but should be able to use public-key authentication to sign in.</p><p>Find the line that says <code>PermitRootLogin yes</code> and change it to <code>PermitRootLogin without-password</code>. </p><hr><p>If you want to only allow public-key authentication find the following configuration keys and change them:</p><div><pre><code><p><span>PubkeyAuthentication yes</span></p><p><span>PasswordAuthentication no</span></p></code></pre></div><hr><p>Last but not least only allow users that you explicitly defined to log in to your server. Go to the end of the file and add the following line:</p><div><pre><code><p><span>AllowUsers phiilu root dokku</span></p></code></pre></div><p>Here you should add the usernames separated with space. In my case, I am allowing the users <code>phiilu</code> <code>root</code> and <code>dokku</code> to log in into my server using ssh.</p><hr><p>After changing the configuration you must restart the <code>sshd</code> server.</p><div><pre><code><p><span>sudo service sshd restart</span></p></code></pre></div><h2 id="Banning-bad-people-with-fail2ban">Banning bad people with fail2ban<a aria-label="Banning bad people with fail2ban permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Banning-bad-people-with-fail2ban"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h2><p><a href="https://twitter.com/phiilu/status/1068652093098086400?s=20" target="_blank" rel="noopener noreferrer">The Internet is a scary place</a> and you need to be aware that everyone out there wants to take over your server. It is very important to make sure bad people or in this case, bad IP addresses get sent to jail and never will bother our server again. </p><p>This is why we will install <code>fail2ban</code>. Fail2ban is a small service that will run on your server and will read your log files and makes sure to ban IP addresses that are trying to log in to your server. </p><p>In this post, I will only show you how you configure <code>fail2ban</code> to only check the logs of the <code>ssh</code> service, but <code>fail2ban</code> can also be used to check other log files like <code>nginx</code> or <code>mail</code>.</p><h3 id="Installation-and-configuration">Installation and configuration<a aria-label="Installation and configuration permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Installation-and-configuration"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h3><p>Installation is very easy and only one command away.</p><div><pre><code><p><span>sudo apt install fail2ban</span></p></code></pre></div><p>That is it, we don't need to make any additional configuration, fail2ban is now working and will make sure it bans bad log in attempts. </p><p>If you want to make changes to the config file, you must copy the original <code>/etc/fail2ban/jail.conf</code> file and create a <code>/etc/fail2ban/jail.local</code> file</p><div><pre><code><p><span>cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local</span></p></code></pre></div><p>Now you could make changes in <code>jail.local</code> and adjust ban time or retries, but I think the default is already pretty good. </p><h3 id="Unban-an-IP-address">Unban an IP address<a aria-label="Unban an IP address permalink" href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access/#Unban-an-IP-address"><svg fill="currentColor" viewBox="0 0 20 20"><path fill-rule="evenodd" d="M9.243 3.03a1 1 0 01.727 1.213L9.53 6h2.94l.56-2.243a1 1 0 111.94.486L14.53 6H17a1 1 0 110 2h-2.97l-1 4H15a1 1 0 110 2h-2.47l-.56 2.242a1 1 0 11-1.94-.485L10.47 14H7.53l-.56 2.242a1 1 0 11-1.94-.485L5.47 14H3a1 1 0 110-2h2.97l1-4H5a1 1 0 110-2h2.47l.56-2.243a1 1 0 011.213-.727zM9.03 8l-1 4h2.938l1-4H9.031z" clip-rule="evenodd"></path></svg></a></h3><p>Sometimes you may want to unban …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access">https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access</a></em></p>]]>
            </description>
            <link>https://phiilu.com/make-your-ubuntu-server-vps-more-secure-against-unauthorized-access</link>
            <guid isPermaLink="false">hacker-news-small-sites-24674317</guid>
            <pubDate>Sat, 03 Oct 2020 20:02:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parkinson's disease is not one but two diseases]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24674201">thread link</a>) | @JPLeRouzic
<br/>
October 3, 2020 | https://padiracinnovation.org/News/2020/10/parkinsons-disease-is-not-one-but-two-diseases | <a href="https://web.archive.org/web/*/https://padiracinnovation.org/News/2020/10/parkinsons-disease-is-not-one-but-two-diseases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    						
					                    <p>
                        <span itemprop="datePublished">03 October 2020</span> - Posted in 
                        <span itemprop="articleSection"><a href="https://padiracinnovation.org/News/category/english">English</a></span> by 
                        
                    </p>
                </div><div itemprop="articleBody">                                   
                    <p><a href="https://dx.doi.org/10.1093/brain/awaa238">A study which has just been published in the leading neurology journal Brain</a>,  indicates that Parkinson's disease is not one but two diseases, starting either in the brain or in the intestines.</p>

<p>These two groups of patients displayed strikingly different profiles on multimodal imaging battery.</p>

<p>These profiles support the existence of a brain-first and body-first subtype of Parkinson’s disease, and furthermore, that premotor rapid eye movement sleep (REM) sleep behaviour disorder is a highly predictive marker of the body-first subtype.
<img src="https://scx1.b-cdn.net/csz/news/800/2019/wheredoespar.jpg" alt="enter image description here"></p>

<p>Neuropathological autopsy studies of patients with Parkinson’s disease, dementia with Lewy bodies, or incidental Lewy body disease have shown discrepant results.</p>

<p>Heiko Braak’s staging system was derived from a cohort of patients, who were selected based on the presence of Lewy pathology in the dorsal motor nucleus of the vagus, and all these patients conformed to a brainstem predominant type.</p>

<p>Other studies reported that some post-mortem cases do not harbour Lewy pathology in the dorsal motor nucleus of the vagus, and a minority of patients do not follow the Braak staging scheme.</p>

<p>A pathological hallmark of Parkinson’s disease is the presence of intraneuronal a-synuclein inclusions termed Lewy pathology. However, it remains unknown from where the initial a-synuclein aggregates originate.</p>

<p>It has been hypothesized that a-synuclein inclusions initially form in nerve terminals of the enteric nervous system, and then subsequently spread via autonomic connections to the dorsal motor nucleus of the vagus and intermediolateral cell columns of the sympathetic system (Braak et al., 2003).</p>

<p>In addition, Lewy pathology has been detected in gastrointestinal nerve fibres years prior to Parkinson’s disease diagnosis.
There is also epidemiological evidence that complete but not partial vagotomy may protect against later Parkinson’s disease.</p>

<p>Autopsy studies have shown that a minority of cases with Lewy pathology do not have pathological inclusions in the dorsal motor nucleus of the vagus, and that a fraction of cases display a limbic-predominant distribution of a-synuclein inclusions with less pathology in the brainstem.</p>

<p>The scientists hypothesized that the appearance of isolated REM sleep behaviour disorder well before parkinsonism is a strong marker of the body-first subtype. The presence of REM sleep behaviour disorder in the premotor phase is a marker of the body-first type, probably a reflection of ascending a-synuclein pathology reaching the pons before the substantia nigra. 
<img src="https://upload.wikimedia.org/wikipedia/commons/6/6f/Substantia_nigra.gif" alt="enter image description here">
<em>The substantia nigra in the brain.
Source Wikipedia</em></p>

<p>To test this hypothesis, they recruited de novo patients with Parkinson’s disease and performed video-polysomnography to divide patients into de novo Parkinson’s disease without REM sleep behaviour disorder and de novo Parkinson’s disease with pre-motor REM sleep behaviour disorder. The study was conducted between August 2018 and January 2020.</p>

<p>The scientists have shown that prodromal and de novo patients with Parkinson’s disease can be categorized by means of multimodal imaging into distinct clusters, which are compatible with a brain-first and body-first Parkinson’s disease subtype.</p>

<p>Their conclusion is that the Parkinson’s disease comprises two subtypes: 
(i) a body-first (bottom-up) subtype, where the pathology originates in the enteric or peripheral autonomic nervous system, and then ascends via the vagus nerve and sympathetic connectome to the CNS;</p>

<p>(ii) a brain-first (top-down) subtype, in which the a-synuclein pathology initially arises in the brain itself or sometimes enters via the ol- factory bulb, and subsequently descends to the peripheral autonomic nervous system.</p>

<p><strong>Body-first (bottom-up) subtype:</strong>
The initial a-synuclein pathology appears in the enteric or peripheral autonomic nervous system. It then propagates via the sympathetic connectome to the heart, and via the vagus nerve to the dorsal motor nucleus of the vagus.
<img src="https://upload.wikimedia.org/wikipedia/commons/0/05/Pons.gif" alt="enter image description here">
<em>The pons area in the brain.
Source Wikipedia</em></p>

<p>Ascending pathology affects pontine structures giving rise to REM sleep behaviour disorder before the substantia nigra shows substantial involvement.
When parkinsonism appears, signifying a loss of 450% of nigrostriatal dopamine terminals, all lower Braak stage structures show marked damage on relevant imaging markers.</p>

<p><strong>Brain-first (top-down) subtype:</strong>
 In the brain-first type, the initial a-synuclein pathology appears in the CNS.
The most likely site of origin seems to be the amygdala or connected structures, or the pathology may in some cases enter via the olfactory bulb.
Rarely, the pathology arises in the upper brainstem (substantia nigra or locus coeruleus).
The pathology spreads from the site of origin to the brainstem and cortex.
When parkinsonism appears, the brainstem shows a rostro-caudal gradient of pathology with marked involvement of the substantia nigra, moderate involvement of the neighbouring pons, but little involvement of the medulla and autonomic nervous system.</p>

<p>Citation:
<em>Jacob Horsager et al, Brain-first versus body-first Parkinson's disease: a multimodal imaging case-control study, Brain (2020). DOI: 10.1093/brain/awaa238</em></p>
                </div></div>]]>
            </description>
            <link>https://padiracinnovation.org/News/2020/10/parkinsons-disease-is-not-one-but-two-diseases</link>
            <guid isPermaLink="false">hacker-news-small-sites-24674201</guid>
            <pubDate>Sat, 03 Oct 2020 19:42:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Burnout: 35 years of research and practice [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24674072">thread link</a>) | @rustoo
<br/>
October 3, 2020 | https://www.wilmarschaufeli.nl/publications/Schaufeli/311.pdf | <a href="https://web.archive.org/web/*/https://www.wilmarschaufeli.nl/publications/Schaufeli/311.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.wilmarschaufeli.nl/publications/Schaufeli/311.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24674072</guid>
            <pubDate>Sat, 03 Oct 2020 19:17:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git Good at Git]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24674058">thread link</a>) | @davidenunes
<br/>
October 3, 2020 | https://davidenunes.com/git-good/ | <a href="https://web.archive.org/web/*/https://davidenunes.com/git-good/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
          
        
        <p>Git is a free and open source distributed Version Control System (VCS). Git can
be hard, especially for people discovering it for the first time, but there are
a lot of things that make this an exceptional VCS worth learning. This post is
not meant to be a git tutorial, but rather a compilation of things and tips I
find interesting. I also wanted to give a perspective of git independent of
services like GitHub. Hopefully you can find something useful and “<em>git better
at it</em>” 🙃.</p>

<p>If you’re looking to learn how to use git, take a look at the <a href="https://git-scm.com/book/en/v2/">Pro Git
book</a>, it’s free and it is a great resource!</p>

<h2 id="git-is-not-github-">Git is not GitHub 😮</h2>

<p>Services like <a href="https://github.com/">GitHub</a> made git particularly popular, but
the convenience of something like Github has its downsides for new users: it
causes confusion about the differences between <a href="https://github.com/">GitHub</a> or
<a href="https://gitlab.com/">GitLab</a>, and the actual version control system, <em>git</em>.
While the former are great to host git repositories and make them publicly
available (among other things), git is a piece of software designed to allow for
distributed version control and collaboration. This means that you can use it
offline, without GitHub, you can collaborate with people via chat, email, and
anything that allows you to send text to someone else. Yes, GitHub makes it
convenient to host your project and make it discoverable; it provides an
incentive for collaboration, but, at the end of the day, GitHub is not git, just
as Gmail is not e-mail.</p>

<h2 id="git-is-distributed-">Git is distributed 🖧</h2>

<p>For those used to GitHub, collaborating with git over e-mail might seem
anachronistic, but, consider the scale of projects and what git was designed to
do. Being able to send contributions as plain text allied with the threaded
nature of e-mail, means that you can have multiple discussions around certain
aspects of a contribution, which is a big plus. Linux kernel development, for
example, doesn’t happen on GitHub or GitLab. From the linux kernel GitHub Pull
requests (GitHub’s system for submitting contributions):</p>

<blockquote>
  <p>Thanks for your contribution to the Linux kernel!</p>

  <p>Linux kernel development happens on mailing lists, rather than on GitHub -
this GitHub repository is a read-only mirror that isn’t used for accepting
contributions. So that your change can become part of Linux, please email it
to us as a patch.</p>

  <p>Sending patches isn’t quite as simple as sending a pull request, but
fortunately it is a well documented process.</p>

  <p>Here’s what to do:</p>

  <ul>
    <li>Format your contribution according to kernel requirements</li>
    <li>Decide who to send your contribution to</li>
    <li>Set up your system to send your contribution as an email</li>
    <li>Send your contribution and wait for feedback</li>
  </ul>
</blockquote>

<p>The development happens on various mailing lists for multiple subsystems. It’s
distributed development to an unprecedented scale. This scale has a price,
discipline in your contributions, something that GitHub doesn’t really help
reinforce –which seems to be the whole
<a href="https://github.com/torvalds/linux/pull/17#issuecomment-5654674">issue</a> that the
creator of git Linus Torvalds has with it.</p>

<h3 id="git-daemon-">Git daemon 🌐</h3>

<p>Focusing the development on a centralised service like GitHub can feel like
you’re using an improved version of Subversion client/server approach, but
remember, git is truly a decentralized system and we can do better. Suppose you
don’t want to use GitHub, but want to make your repository available for other
people to clone, pull from, etc. Git supports Peer-to-Peer setup out of the box
with <a href="https://git-scm.com/book/en/v2/Git-on-the-Server-Git-Daemon"><code>git
daemon</code></a>.
Collaboration then happens on each peer local copy of the source tree and some
form of communication channel (e.g. e-mail, chat, etc).</p>

<p>From your git folder you can execute the following command</p>

<div><div><pre><code>git daemon <span>--export-all</span> <span>--base-path</span><span>=</span><span>.</span> <span>--reuseaddr</span>
</code></pre></div></div>

<ul>
  <li><code>--enable=upload-pack</code>: (enabled by default) allows for <code>git fetch</code>, <code>git pull</code>, and <code>git clone</code>.</li>
  <li><code>--export-all</code>: means that you don’t have to create a file named git-daemon-export-ok in each exported repository.</li>
  <li><code>--base-path</code>: allows people to clone projects without specifying the entire
path. Example: if you start the daemon with <code>--base-path=/srv/git</code> and try to
pull from <code>git://example.com/hello.git</code>, git daemon will interpret the path as
<code>/srv/git/hello.git</code>.</li>
  <li><code>--reuseaddr</code>: allows the server to restart without waiting for old connections to time out.</li>
</ul>

<p>Congratulations, your machine is now running a git server and anyone can do:</p>

<div><div><pre><code>git clone git://192.168.1.42/  <span>#Your IP</span>
<span># or</span>
git remote add Foo git://192.168.1.42/
git fetch Foo
git checkout develop
git push Foo develop
</code></pre></div></div>

<h3 id="git-patches-">Git patches 📝</h3>

<p>As we have discussed, git is a decentralized system, you can send contributions
to anyone without the need of a centralized git repository. This is not only the
default way of collaborating with git, it is particularly useful when a server
is down, or if you don’t have permissions to write to a remote repository
—but would still like to propose changes.</p>

<p>You can create a patch from your current changes without committing the code on
your source tree:</p>

<div><div><pre><code><span># changes in the working tree not yet staged for commit</span>
git diff <span>&gt;</span> big-improvements.patch
<span># or changes between the index and your last commit;</span>
<span># what you would be committing if you run "git commit"</span>
<span># without "-a" option.</span>
git diff <span>--cached</span> <span>&gt;</span> big-improvements.patch
</code></pre></div></div>

<p>As an example suppose the change is the addition of a README file, the diff
would look like this:</p>

<div><div><pre><code><span>diff --git a/README b/README
</span><span>new file mode 100644
</span><span>index 0000000..e69de29
</span></code></pre></div></div>

<p>More often, what we would like to do is to propose a change we have made in your
local source tree. To do this, we can use the <a href="https://git-scm.com/docs/git-format-patch"><code>git
format-patch</code></a> command:</p>



<p>if we have commits ahead of the master branch, a diff file will be generated. We can also reference other commits in the same branch.
Suppose we made changes in the current branch and want to reference the changes in relation to the last commit. We can do:</p>



<p>the patch file will contain something like:</p>

<div><div><pre><code><span>From daf1010eb425a67ca6b0ba60f7cbec15bcff31f1 Mon Sep 17 00:00:00 2001
From: John Doe &lt;heresjohnny@bestmail.com&gt;
Date: Tue, 09 Sep 2020 15:42:00 +0100
Subject: [PATCH] Update README
</span>
---
 README | 1 +
 1 file changed, 1 insertion(+)

diff --git a/README b/README
<span>index e69de29..d0fc019 100644
</span><span>--- a/README
</span><span>+++ b/README
</span><span>@@ -0,0 +1 @@</span>
<span>+This is a README file, that is all.
</span><span>--
</span><span>2.28.0
</span></code></pre></div></div>

<p>to apply the patch we do:</p>

<div><div><pre><code><span># patch as unstaged changes in your branch</span>
git apply 0001-Update-README.patch

<span># patch as commits</span>
git am 0001-Update-README.patch
</code></pre></div></div>

<p>For more information, check the documentation for <a href="https://git-scm.com/docs/git-diff"><code>git
diff</code></a>, <a href="https://git-scm.com/docs/git-format-patch"><code>git
format-patch</code></a>, <a href="https://git-scm.com/docs/git-apply"><code>git
apply</code></a>, and <a href="https://git-scm.com/docs/git-am"><code>git
am</code></a>.</p>

<!-- 
### git request-pull ✉️

Git comes with its own [pull request
module](https://www.git-scm.com/docs/git-request-pull).

This feature has nothing to do with [GitHubs pull
request](https://docs.github.com/en/desktop/contributing-and-collaborating-using-github-desktop/creating-an-issue-or-pull-request).
It's mean to facilitate the creation of summary messages to be sent through
e-mail for example. If you want to use GitHubs pull request feature without the
web interface, check out the [hub](https://hub.github.com/) command line interface tool.
{: .notice--danger}

Imagine that you built your work on your master branch on top of the v1.0
release, and want it to be integrated to the project. First you push that change
to your public repository for others to see. If this is a remote repository you might do it like this:

```bash
git push https://bestgitserver.com/project master
```

Then we run the following command:

```bash
git request-pull v1.0 https://bestgitserver.com/project master
```

This will produce a request message with information about:

 1. where to pull from (your downstream repository address)
 2. the upstream repository
 3. a summary of the changes between v1.0 release and your master.

You can then send this request by e-mail for instance, making the pull request
completely distributed and independent from GitHub proprietary system.
-->

<h2 id="git-tips-">Git tips 🔥</h2>

<p>We are all bound to get stuck sometimes when things go wrong. A good starting
point is this <a href="https://ohshitgit.com/">compilation</a>. These are solutions to
problems I often have to solve.</p>

<h3 id="premature-commit-">Premature commit 🔧</h3>

<p>You pulled the trigger too fast on that commit and wish you could include
additional changes? Make your changes, call <code>git commit --amend</code> and done. (Also
useful to change the commit message.)</p>

<h3 id="go-back-">Go back ⌛</h3>

<p>We messed up, go back to a previous commit.</p>

<div><div><pre><code><span># go back n commits n=1 in this case,</span>
<span># --soft: optionally don't discard changes</span>
<span># and put them on the staging area instead</span>
git reset HEAD~1 <span>--soft</span>
</code></pre></div></div>

<h3 id="put-changes-on-hold-">Put changes on hold 🚧</h3>

<p>So you want to get back to the state before you started making changes, but
don’t want to throw these changes away:</p>

<div><div><pre><code><span># stash the changes</span>
git stash
<span># get the changes back when needed</span>
git stash pop
</code></pre></div></div>

<h3 id="where-it-went-wrong-">Where it went wrong 🔍</h3>

<p>You have a problem and don’t know which commit introduced it, enter <a href="https://git-scm.com/docs/git-bisect"><code>git bisect</code></a>:</p>

<div><div><pre><code>git bisect start          <span># start a bisect section</span>
git bisect bad            <span># Current version is bad</span>
git bisect good v2.2.1    <span># v2.2.1 is known to be good</span>
</code></pre></div></div>

<p>bisect will now choose commits in the middle of the history and you can mark
them as good or bad with the same commands. When no more revisions are available
you’ll have a description of the commit that caused the problem. You can then reset
the bisect state with <code>git bisect reset</code>.</p>

<h3 id="rebasing-commits-">Rebasing commits 💥</h3>

<p>Sometimes we make two commits when in reality, we could have included all the
changes in a single commit, and our history would be clearer. This is what is
known as <em>squashing</em>. We can use <code>git rebase</code> to meld commits with previous
commits. It can also be used instead of merging branches. Git’s rebase command
temporarily rewinds the commits on your current branch, pulls in the commits
from the other reference and reapplies the re-winded commits back on top.</p>

<p>Most people will advise you to always squash the commits and rebase them onto
the parent branch (like master or develop) before you submit a pull request or
send out a patch. Whether rebasing is preferred to merging really depends on the
context.</p>

<p>If you want to read more about <code>rebase</code> vs <code>merge</code>, check out <a href="https://medium.com/hackernoon/mastering-git-why-rebase-is-amazing-a954485b128a">this
post</a></p>

<p>Whatever you do <strong>DO NOT</strong> rebase commits in a upstream repository people can
pull from. It will mess everyone’s history and lead to conflicts that all
downstream peers will need to fix.
Also, it’s <strong>never</strong> a good idea to <strong>rebase somebody else’s work</strong>, see <a href="https://yarchive.net/comp/linux/git_rebase.html">this
discussion</a>.</p>

<div><div><pre><code><span># rebase last 2 commits</span>
git rebase <span>-i</span> HEAD~2
</code></pre></div></div>

<p>The interactive system will open an editor where you can choose each commit in a
list that are about to be changed. In this case, it will list 2 lines with the
last 2 commits. This list reflects exactly how your branch will look like after
the rebase:</p>

<div><div><pre><code>pick c8175df added line
pick dc58443 added final line

<span># Rebase 65e38e0..dc58443 onto 65e38e0 (2 commands)</span>
<span>#</span>
<span># Commands:</span>
<span># p, pick &lt;commit&gt; = use commit</span>
<span># r, reword &lt;commit&gt; = use commit, but edit the commit message</span>
<span># r, reword &lt;commit&gt; = use commit, but edit the commit message</span>
<span># s, squash &lt;commit&gt; = meld into previous commit</span>
<span># f, fixup &lt;commit&gt; = like "squash", but discard log message</span>
<span># ...</span>
</code></pre></div></div>

<p>You can pick, reorder or squash any commits you want to make for a more readable
history.</p>

<p>As we discussed, you can also rebase the current branch onto another</p>

<div><div><pre><code>git checkout feature
git rebase <span>-i</span> master
</code></pre></div></div>

<p>For more information about rebase see the <a href="https://git-scm.com/docs/git-rebase">documentation</a></p>

<h3 id="good-commit-messages-">Good commit messages 🧐</h3>

<p>Commit messages should be consistent across a project in terms of <strong>style</strong>,
<strong>content</strong>, and <strong>metadata</strong>. But some good rules are as follows:</p>

<ol>
  <li>the minimum is a single short …</li></ol></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://davidenunes.com/git-good/">https://davidenunes.com/git-good/</a></em></p>]]>
            </description>
            <link>https://davidenunes.com/git-good/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24674058</guid>
            <pubDate>Sat, 03 Oct 2020 19:15:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A web of trust for NPM]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24673917">thread link</a>) | @tao_oat
<br/>
October 3, 2020 | https://www.btao.org/2020/10/02/npm-trust.html | <a href="https://web.archive.org/web/*/https://www.btao.org/2020/10/02/npm-trust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In 1984 the co-inventor of Unix, Ken Thompson, delivered a seminal speech in which he highlighted that <em>you can’t trust code that you did not totally create yourself</em> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. For a while, this lesson was largely ignored as open-source package registries like RubyGems, PyPI and npm grew rapidly. However, as we’re seeing <a href="https://blog.reversinglabs.com/blog/mining-for-malicious-ruby-gems" target="_blank" rel="noopener noreferrer">more</a> <a href="https://blog.npmjs.org/post/185397814280/plot-to-steal-cryptocurrency-foiled-by-the-npm" target="_blank" rel="noopener noreferrer">and</a> <a href="https://snyk.io/blog/a-post-mortem-of-the-malicious-event-stream-backdoor/" target="_blank" rel="noopener noreferrer">more</a> supply-chain attacks through software dependencies, the risks of using unvetted dependencies are becoming clearer.</p>

<p>The risks are particularly great for JavaScript applications. Veracode found that the average JavaScript project relies on 377 dependencies – compared with just 16 for Python projects, or 43 in the Java ecosystem<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. Whenever a developer pulls in a new dependency, they are implicitly trusting the maintainers of that dependency. Often, this trust is awarded on the basis of popularity – we assume that a popular library will be more carefully vetted, or that since many others trust the maintainers, we can too. Other times, this trust relationship and the risks involved are not considered at all.</p>

<p><a href="https://sambleckley.com/writing/npm.html" target="_blank" rel="noopener noreferrer">Some have argued</a> that the ill health of the npm registry is a social, rather than a technical problem, and suggest a human-compiled set of packages in order to separate the wheat of maintained, healthy packages from the chaff of abandoned toy projects with no documentation. <a href="https://medium.com/@dpc_96143/cargo-crev-and-rust-2019-fearless-code-reuse-b75d58398cb8" target="_blank" rel="noopener noreferrer">Another suggestion from the Rust world</a> involves creating a manual web of trust from maintainers cryptographically signing each other’s projects. Either way, there are challenges: webs of trust have rarely taken off (outside of Debian), and compiling a vetted set of packages from scratch is a massive undertaking. I propose something in the middle: bootstrapping a web of trust using existing npm dependency relationships, and building from that foundation.</p>

<h2 id="existing-trust-relationships-in-npm">Existing trust relationships in npm</h2>

<p>Creating a web of trust from existing npm dependencies is, admittedly, somewhat problematic. As stated earlier, choosing to use a particular dependency is not always a well-considered decision based on researching its code and maintainers, and the trust relationship is merely implied. Similarly, there is no cryptographic verification of this weak trust, nor does npm currently have the infrastructure for such tools<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. What I am suggesting is an imperfect starting point to demonstrate the need for, and potential of, stronger trust measures in open source.</p>

<p>To construct this initial web, we can model npm’s maintainerships as a graph. If we let each node be a maintainer, then the edges between them are the trust relationship arising from using a dependency. In other words, if Alice maintains a package A, and A depends on package B maintained by Bob, then there is a directed edge from Alice to Bob. We can even weigh these edges by the number of Alice’s packages in which she implies trust of Bob.</p>

<h2 id="exploring-the-graph">Exploring the graph</h2>

<p>This simple model exhibits a power-law-like pattern in terms of trust: the vast majority of users are trusted by few or no others, and a very small number of users are highly trusted. This type of pattern is common in social networks: you see a similar thing emerge when plotting follower counts on Twitter. Such power laws often lead to a rich-get-richer feedback process in which the inequality (in terms of trust, in this case) gets more pronounced over time<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/efe1a929e64ebeeb021e79f341b35faa4baf1397/c0643/static/img/maintainer-wot-in-degrees.png" alt="Scatter plot of in-degree vs. number of users. Shows a roughly power-law relationship."></p>

<p>Who are these highly-trusted users? They’re who you’d expect: bots for large projects (e.g. <code>types</code>), corporate accounts (e.g. <code>fb</code>), and the maintainers of extremely popular open-source libraries (e.g. <code>sindresorhus</code>, who maintains e.g. <code>string-length</code>).</p>

<p>Perhaps more interestingly, this web of trust exhibits some useful structures. A number of <a href="https://en.wikipedia.org/wiki/Strongly_connected_component" target="_blank" rel="noopener noreferrer">strongly connected components</a> emerge – groups of users that, roughly speaking, all trust each other according to the web of trust principles (i.e. if I trust Alice, and Alice trusts Bob, then I trust Bob, too). All of these connected components are small, with the exception of a single one that’s home to over 11,000 users<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>. This core component – we’ll call it the <strong>strong set</strong> – could provide a starting point for a measure of trust in the npm ecosystem.</p>



<p>We can quantify trust in a slightly more nuanced way than simply looking at the in-degree of each npm user. The PageRank algorithm provides such a measure that takes into account the trustworthiness of the people who trust me. For example, I may only be trusted by one user, but if that user is <code>isaacs</code> (the creator of npm) then that trust relationship counts for a lot! After running PageRank, the 10 “most-trusted” users are:</p>

<ol>
  <li><code>types</code></li>
  <li><code>sindresorhus</code></li>
  <li><code>angular</code></li>
  <li><code>m1tk4</code></li>
  <li><code>tjholowaychuk</code></li>
  <li><code>google-wombot</code></li>
  <li><code>fb</code></li>
  <li><code>isaacs</code></li>
  <li><code>gaearon</code></li>
  <li><code>yyx990803</code></li>
</ol>

<p>Many of these are unsurprising. However, <code>m1tk4</code> stands out: they only maintain two rarely-downloaded libraries. Because one of these libraries is used by the BBC, <code>m1tk4</code> is implicitly trusted by a large number of relatively trustworthy BBC employees who maintain other, more popular projects. This demonstrates how PageRank diffuses trust across the social network of npm maintainers. In fact, <code>m1tk4</code> is not a member of the strong set mentioned earlier – but many of the users who trust them <em>are</em>. <code>m1tk4</code> just doesn’t trust those users back!</p>

<p>While PageRank gives a fun measure of trust, it’s a very rough model for the reasons mentioned earlier: it’s based on a pretty weak indication of real trust. However, it might be useful in detecting suspicious behaviours in npm, which is something we – or registry maintainers – need to do proactively if we want to stop supply-chain attacks. For example, it might be a red flag if a highly-trusted user suddenly starts using a library by someone with a PageRank-based-trust of close to 0. And regardless, the strong set comes merely from observing which dependencies people choose to use without applying any complex calculations.</p>

<p>How might we want to use the strong set to create a stricter trust (or reputation) system? I think that formalizing such a system is unlikely if it requires large-scale buy-in from npm users. Instead, we might create a simple wrapper for npm that checks if you’re about to install something from a developer outside of the strong set, similar to Liran Tal’s excellent <a href="https://github.com/lirantal/npq" target="_blank" rel="noopener noreferrer">npq</a>. Or perhaps security researchers could use the npm web of trust as an additional data point when deciding whether a suspicious package warrants further investigation. Either way, the state of trust within the npm ecosystem is not great. This model gives us a starting point.</p>

<p><em>Do you think I’ve got it all wrong? Or do you have further suggestions on how we can improve the state of trust in open source? <a href="https://www.btao.org/contact">Get in touch</a>.</em></p>

<p><em>A final note: this analysis is based on data from June 2020, which I collected for my Master’s thesis. I believe you’d reach similar numbers if you ran the analysis on data from today.</em></p>

<h3 id="footnotes">Footnotes</h3>



</div></div>]]>
            </description>
            <link>https://www.btao.org/2020/10/02/npm-trust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24673917</guid>
            <pubDate>Sat, 03 Oct 2020 18:51:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Replacing Zoom with OBS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24673429">thread link</a>) | @HaoZeke
<br/>
October 3, 2020 | https://rgoswami.me/posts/rep-zoom-obs/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/rep-zoom-obs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>A post on local recordings</p></blockquote><h2 id="background">Background</h2><p>Since the advent of the COVID-19 situation, there has been an increase in the demand for recorded materials. Standard approaches involve Zoom, which is not only proprietary, but also quite a bit of a privacy nightmare. The last straw was the random placement of my speaker bauble head.</p><figure><img src="https://rgoswami.me/ox-hugo/2020-10-03_16-51-07_screenshot.png" alt="Figure 1: Zoom webcam placement"><figcaption><p>Figure 1: Zoom webcam placement</p></figcaption></figure><p>At this point, given that I was to set up a pre-recorded video for <a href="https://rgoswami.me/posts/pycon-in-2020-meta/">PyCon India 2020</a>, I decided to look into alternatives.</p><h2 id="alternatives">Alternatives</h2><p>The search for alternative screen recording systems isn’t really a very new one. For group work (like <a href="https://wc3m.github.io/">W3cm</a>&nbsp;<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>), I tend to prefer Skype, since it handles speaker galleries very well. Unfortunately, Skype has no capacity for recording single person calls, at least as yet. This is not the place for an extended debate on the pros and cons of Skype, or Google Meet (only records corporate accounts), or the rest. Instead, lets sum up all these issue with the simple understanding that, if <strong>one person</strong> wants to record a webcam connected to their local computer, along with the screen, it is insane to imagine that the only way to get this is by:</p><ul><li>Making an account somewhere (Zoom, Meet, Skype, anything)</li><li>Giving a cloud service permission to record our screens</li></ul><p>At the same time, a lot of standard tools for screen recording do not play nice with webcam recorders (like <a href="https://www.maartenbaert.be/simplescreenrecorder/">Simple Screen Recorder</a> and <a href="https://help.gnome.org/users/cheese/stable/">Cheese</a>).</p><h2 id="open-broadcaster-software">Open Broadcaster Software</h2><p>The <a href="https://duckduckgo.com/?q=obs+studio&amp;ia=web">OBS studio project</a> is a godsend. It allows for simultaneously managing multiple streams, of both audio and video. Furthermore, since these are implemented as overlays, it is possible to fine-tune the positioning of each of these, which is something Zoom and friends lack.</p><figure><img src="https://rgoswami.me/ox-hugo/2020-10-03_16-53-51_screenshot.png" alt="Figure 2: Into the matrix"><figcaption><p>Figure 2: Into the matrix</p></figcaption></figure><p>The ability to resize the webcam is best shown in the figure below.</p><figure><img src="https://rgoswami.me/ox-hugo/2020-10-03_16-58-26_screenshot.png" alt="Figure 3: Almost Zoom, only better"><figcaption><p>Figure 3: Almost Zoom, only better</p></figcaption></figure><p>OBS also generates beautifully small videos and supports live-streaming.</p><h3 id="common-caveats">Common Caveats</h3><ul><li>The standard setting is set to work with hardware acceleration, which may not be present for many users<ul><li>Use the settings to change this back to the software setting</li></ul></li></ul><h2 id="conclusions">Conclusions</h2><p>I cannot imagine going back to Zoom to record anything local. It is an added bonus that OBS is both cross-platform and FOSS. It is only incredible more people do not use it.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Water, Chemicals and more with Computers for Chemistry, a computational chemistry course aimed at middle school students taught with my sister <a href="https://scholar.google.com/citations?user=mviv92EAAAAJ&amp;hl=en">Amrita Goswami</a> <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]>
            </description>
            <link>https://rgoswami.me/posts/rep-zoom-obs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24673429</guid>
            <pubDate>Sat, 03 Oct 2020 17:25:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Save your wrists and your time: lose the mouse]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24673074">thread link</a>) | @kchow
<br/>
October 3, 2020 | https://www.kchow.org/post/keyboard-warrior/ | <a href="https://web.archive.org/web/*/https://www.kchow.org/post/keyboard-warrior/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Note: This post is aimed at macOS users, with some cross-OS tools. Most are free and open-source.</strong></p><p>Hi, I’m Kevin and I don’t use a mouse.</p><p>As a knowledge worker or <em>keyboard warrior</em>, most of my life exists between the four corners of a screen. Even if you’re young, longevity is something to think about if the keyboard is your sword 12 hours a day.</p><p>Its important to note that this post is <strong>secondary</strong> to good ergonomics
<a href="https://www.ccohs.ca/oshanswers/ergonomics/office/" target="_blank" rel="noopener">[1]</a>
<a href="http://www.rsi.deas.harvard.edu/preventing.html" target="_blank" rel="noopener">[2]</a>. However, some believe that the mouse is <em>particularly</em>
<a href="https://www.ccohs.ca/oshanswers/ergonomics/office/mouse/mouse_problems.html" target="_blank" rel="noopener">hazardous</a> because of its poor design and need for precision. In desperation, I’ve tried all kinds of things like switching mouse hands and buying supposedly ergonomic mice. What makes sense to me is to <em>offload</em> the work of a mouse to the keyboard
<a href="https://techhq.com/2020/05/carpal-tunnel-rsi-repetitive-strain-injury-mouse-computer-alternatives-to-best-2020/" target="_blank" rel="noopener">[1]</a>
<a href="https://gist.github.com/lornajane/3892c39098cf70baa9c7a1874cddf233" target="_blank" rel="noopener">[2]</a>.</p><p>Sometimes, you can have your cake and eat it too. In my experience, eliminating mouse and trackpad use has <em>not only</em> decreased strain on my wrists, shoulders, and elbows, but made me more productive.</p><p>The goal of this guide is to introduce tools that can <strong>1) expose powerful new keyboard shortcuts</strong>, and <strong>2) completely replace the mouse with your keyboard .</strong></p><h2 id="a-index-the-ui-for-the-keyboard">A) Index the UI for the keyboard</h2><ol><li><a href="#vimium">Vimium “Master of chrome” (All OS, chrome and safari)</a><br>1b.
<a href="#icmd">iCMD “Vimium for macOS”</a></li><li><a href="#sc">Shortcat “Search the button” (macOS)</a></li></ol><h2 id="b-replace-mouse-functions-with-the-keyboard">B) Replace mouse functions with the keyboard</h2><ol start="3"><li><a href="#karabiner">Karabiner &amp; Mouse keys “Mouse killer” (macOS)</a><br>3b.
<a href="#mk">Mouse keys (Ubuntu and macOS)</a></li></ol><h2 id="c-bonus-and-miscellaneous">C) Bonus and miscellaneous</h2><ol start="4"><li><a href="#alfred">Alfred “Juiced up Spotlight” (macOS)</a></li><li><a href="#spectacle">Spectacle “Resize and manipulate windows” (macOS)</a></li><li><a href="#mac">Native shortcuts (macOS)</a></li></ol><h2 id="1-vimium-master-of-chrome-all-os-chrome-and-safarihttpsvimiumgithubio"><a name="vimium"></a><a href="https://vimium.github.io/" target="_blank" rel="noopener">1. Vimium “Master of chrome” (All OS, chrome and safari)</a></h2><p>If you ignored everything else, <strong>this is the tool I’d recommend.</strong> Because most of us habitate inside our web browsers (this tool works on Google Chrome or Safari), Vimium is <em>essential</em>. It’s easy to use, and <strong>I’ve never gone back to using my mouse in my browser again.</strong>
<img src="" alt=""></p><figure id="figure-mouse-free-web-browsing"><a data-fancybox="" href="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252499475_Vimium.gif" data-caption="Mouse-free web browsing"><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252499475_Vimium.gif" alt=""></a><figcaption>Mouse-free web browsing</figcaption></figure><p>As you can see above, it can take care of just about <strong>all</strong> your needs. If you’re a fan of vim, you’ve got a headstart with shortcuts. The shortcuts I use are:</p><table><thead><tr><th>Key</th><th>Action</th><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>f</td><td>index all links to open in current tab</td><td>gg</td><td>top of page</td></tr><tr><td>F</td><td>index all links to open in new tab</td><td>G</td><td>bottom of page</td></tr><tr><td>j</td><td>scroll down</td><td>/</td><td>find, press n to iterate</td></tr><tr><td>k</td><td>scroll up</td><td>t</td><td>new tab</td></tr><tr><td>d</td><td>half a page down</td><td>x</td><td>close current tab</td></tr><tr><td>u</td><td>half a page up</td><td>J</td><td>move one tab left</td></tr><tr><td>h</td><td>scroll left</td><td>K</td><td>move one tab tigh</td></tr><tr><td>l</td><td>scroll right</td><td>H</td><td>back one page</td></tr><tr><td></td><td></td><td>L</td><td>forward one page</td></tr></tbody></table><h2 id="b-icmd-vimium-for-macos-macos-19httpswwwicmdappgclidcjwkcajwkoz7brbpeiwaekw3q0nc8cmwhp4flnc9fpuzw3ovppmxh_bwjkpilfv_fgfhmumny3bq2hocgbgqavd_bwe"><a href="https://www.icmd.app/?gclid=CjwKCAjwkoz7BRBPEiwAeKw3q0nC8CmwHp4FLnc9fPUzW3oVpPmxh_bWJKpILfV_FgFHmuMNY3bq2hoCGbgQAvD_BwE" target="_blank" rel="noopener">b. iCMD “Vimium for macOS” (macOS) $19</a></h2><p><strong>Update 9/23/20:</strong> This functionality finally exists on MacOS, but at a price.</p><figure id="figure-vimium-like-ui-indexing-across-all-apps"><a data-fancybox="" href="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1600989973816_iCMD2.gif" data-caption="Vimium-like UI indexing across all apps!"><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1600989973816_iCMD2.gif" alt=""></a><figcaption>Vimium-like UI indexing across all apps!</figcaption></figure><p>I’ve been waiting for someone to make this indexing functionality for MacOS overall, and
<a href="https://www.icmd.app/?gclid=CjwKCAjwkoz7BRBPEiwAeKw3q0nC8CmwHp4FLnc9fPUzW3oVpPmxh_bWJKpILfV_FgFHmuMNY3bq2hoCGbgQAvD_BwE" target="_blank" rel="noopener">iCMD</a> has finally done it. The functionality of Vimium’s UI indexing now universal on macOS and also being able to search the menu bar (
<a href="#menusearch">something macOS has</a>).</p><h2 id="2-shortcat-search-the-button-httpsshortcatappcommacoshttpsshortcatappcom"><a name="sc">2.
</a><a href="https://shortcatapp.com/" target="_blank" rel="noopener">Shortcat “Search the button” (</a>macOS
<a href="https://shortcatapp.com/" target="_blank" rel="noopener">)</a></h2><p><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252654859_sc.gif" alt=""></p><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>⇧ (Shift) ⌘ (Command) Space</td><td>Activate</td></tr><tr><td>⌃ (Ctrl) + index</td><td>Select candidate button indexed with letters</td></tr><tr><td>Tab</td><td>Iterate through candidate buttons</td></tr></tbody></table><p>Shortcat is pretty useful for answering dialog boxes or clicking things with a kind of search index of the buttons on your entire screen. It can be slower since you have to search the text, and doesn’t work in all circumstances. But when it works, it does save quite a few clicks, especially because you can select the button with ⌃ (Ctrl) + index, similar to Vimium’s indexing of links.
<strong>Note: The beta is free, but the paid version costs $18. The beta works quite well for me.</strong></p><h2 id="3-karabinerhttpskarabiner-elementspqrsorg--mouse-keyshttpssupportapplecomguidemac-helpcontrol-the-pointer-using-mouse-keys-mh27469mac-mouse-killer-ubuntu-and-macos"><a name="karabiner">3.
</a><a href="https://karabiner-elements.pqrs.org/" target="_blank" rel="noopener">Karabiner</a> &amp;
<a href="https://support.apple.com/guide/mac-help/control-the-pointer-using-mouse-keys-mh27469/mac" target="_blank" rel="noopener">Mouse keys</a> “Mouse killer” (Ubuntu and macOS)</h2><figure id="figure-completely-controlled-by-my-keyboard"><a data-fancybox="" href="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1600288643787_karabiner2.gif" data-caption="Completely controlled by my keyboard!"><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1600288643787_karabiner2.gif" alt=""></a><figcaption>Completely controlled by my keyboard!</figcaption></figure><p>Karabiner is a <strong>true replacement to mouse input</strong>, and since picking it up I’ve retired my mouse. I would list Karabiner as my first tool, but the process to set up and break in is a tad more involved. Karabiner works by mapping mouse actions (mouse up, down, left, right, click, etc) onto the keyboard. In my personal setup that lets me use either hand/side of the keyboard, I’ve mapped <em>⌃ (Ctrl) + wasd OR ijkl</em> to my mouse movements. I’ve also mapped actions such as scroll, click, and right click, and have a precise and fast mouse navigation setting.</p><p>There are some details to getting it set up, and tweaking it to your preferences, which will be explained in detail in a follow up blog post very shortly.</p><h2 id="b-mouse-keys-nativehttpssupportapplecomguidemac-helpcontrol-the-pointer-using-mouse-keys-mh27469mac-macoshttpssupportapplecomguidemac-helpcontrol-the-pointer-using-mouse-keys-mh27469mac"><a name="mk"></a><a href="https://support.apple.com/guide/mac-help/control-the-pointer-using-mouse-keys-mh27469/mac" target="_blank" rel="noopener">b. Mouse keys (native</a> macOS
<a href="https://support.apple.com/guide/mac-help/control-the-pointer-using-mouse-keys-mh27469/mac" target="_blank" rel="noopener">)</a></h2><figure id="figure-apples-inferior-take-on-a-keyboard-mouse"><a data-fancybox="" href="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252573431_mk.gif" data-caption="Apple’s inferior take on a keyboard-mouse"><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252573431_mk.gif" alt=""></a><figcaption>Apple’s inferior take on a keyboard-mouse</figcaption></figure><p>If Karabiner is too low-level for you, macOS’s
<a href="https://support.apple.com/guide/mac-help/control-the-pointer-using-mouse-keys-mh27469/mac" target="_blank" rel="noopener">native mouse keys</a> is an alternative, with some caveats. I find it rather tacky and slow for my tastes (even cranked up to the max speed). Left click and right click exist, but there is no mouse-wheel scroll function. Having an external numpad is also essential, or you’re stuck using your main keys and toggling mouse keys to alternate keyboard and mouse function.</p><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>⌥ (Option) 5 times</td><td>Activate or deactivate mouse keys</td></tr><tr><td>Numpad 5</td><td>Click</td></tr><tr><td>⌃ (Ctrl) Numpad 5</td><td>Right click</td></tr><tr><td>Numpad 8 2 6 4</td><td>Up Down Right Left respectively</td></tr><tr><td>Numpad 7 9 1 3</td><td>NW NE SW SE respectively</td></tr></tbody></table><p>This also exists on Ubuntu and is more usable (mainly due to mouse speed) but needs some tuning to get used to.</p><h2 id="4-alfred-juiced-up-spotlight-httpswwwalfredappcommacoshttpswwwalfredappcom"><a name="alfred">4.
</a><a href="https://www.alfredapp.com/" target="_blank" rel="noopener">Alfred “Juiced up Spotlight” (</a>macOS
<a href="https://www.alfredapp.com/" target="_blank" rel="noopener">)</a></h2><p><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252714722_alfred.gif" alt="">
<strong>Update 10/1/20: I previously had not covered the premium version, and now have, updating Alfred’s position on my list from 5 to 4.</strong></p><p>Some swear by Alfred’s as a force multiplier, and there is a rich community of support. I didn’t understand it until I tried it myself. I’ve since retired Spotlight for Alfred. The free version offers a taste of it’s power, with lots of tedious actions exposed as keywords. But the real power comes from the custom workflows you can build or get from open-source: any action you could want to automate now at your fingertips you can use in Alfred. For example, by making bash to keywords in alfred, a basic task like toggling bluetooth or connecting to a device is now an option in alfred, thanks to someone who built this
<a href="https://github.com/tilmanginzel/alfred-bluetooth-workflow" target="_blank" rel="noopener">plugin</a>.</p><p><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1601689628728_Screen+Shot+2020-10-02+at+9.46.50+PM.png" alt=""></p><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>⌥ Space</td><td>Activation</td></tr></tbody></table><p><strong>Features in free version</strong></p><ul><li>Fast index of search results command + num</li><li>Better more customized search</li><li>Keyword for more specific task such as Google, wiki, Open for file search, Define, = fast calculator</li><li>Other chained actions you can now execute like logout, lock, quit, forcequit, shutdown, restart, or empty trash.</li></ul><h2 id="5-spectacle-resize-and-manipulate-windows-httpswwwspectacleappcommacoshttpswwwspectacleappcom"><a name="spectacle">5.
</a><a href="https://www.spectacleapp.com/" target="_blank" rel="noopener">Spectacle “Resize and manipulate windows” (</a>macOS
<a href="https://www.spectacleapp.com/" target="_blank" rel="noopener">)</a></h2><p>If you multi-task on a single screen or with many screens, this is the tool for you. With lots of shortcuts, you can resize and reposition any programs into whatever order you want quickly.</p><p><img src="https://paper-attachments.dropbox.com/s_6F54B5726E1B796E5B1C8B3A9530E099F78F3BC3CC65782B5317AA7529B9B82F_1599252788238_spectacle.gif" alt=""></p><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>⌘⌥C</td><td>Center</td></tr><tr><td>⌘⌥F</td><td>Full screen</td></tr><tr><td>⌥⌃←</td><td>Left half</td></tr><tr><td>⌥⌃→</td><td>Right half</td></tr><tr><td>⌥⌃↑</td><td>Top half</td></tr><tr><td>⌥⌃↓</td><td>Make smaller</td></tr><tr><td>⌥⌃⇧→</td><td>Make larger</td></tr><tr><td>⌘⌃←</td><td>Top left quadrant</td></tr><tr><td>⌘⌃⇧←</td><td>Bottom left quadrant</td></tr><tr><td>⌘⌃→</td><td>Top right quadrant</td></tr><tr><td>⌘⌃⇧→</td><td>Bottom right quadrant</td></tr></tbody></table><p>(Note that the settings can be changed on install, these are my settings I’ve changed to not conflict with the native copy and find shortcuts)</p><p>If you use dual monitors there’s also the option to zap a window into the next or previous screen.</p><p>That’s it for now from third party tools. Some of these tools work well in isolation, and others work better together in combination with each other and with native app shortcuts or OS shortcuts. For example, in Chrome, I limit my tabs to 9 with a chrome extension so I can navigate with command + tab number 1-9 (native chrome shortcut), use Vimium for clicking and indexing links, Karabiner for scrolling, and Alfred to quickly google or wikipedia in a new tab.</p><p>For that reason, I’d highly recommend spending even ten minutes getting intimate with all the shortcuts of your OS and the applications you use frequently. For me, knowing OneNote and Sublime Text shortcuts is essential.</p><p>In my opinion, shortcutting is much better than moving a cursor, even if controlled by a keyboard.</p><a name="mac"><h2 id="6-general-mac-shortcuts">6. General Mac shortcuts</h2><p>My favorites:</p><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody><tr><td>⌘Tab</td><td>Switch to last program. Hold ⌘ to navigate through open programs.</td></tr><tr><td>⌘w</td><td>Close current front window or tab</td></tr><tr><td>⌘`</td><td>Switch to last window of current program.</td></tr><tr><td>⌘h</td><td>Hide the current window</td></tr><tr><td>⌘m</td><td>Minimize the current window to the dock</td></tr><tr><td>⇧⌘/</td><td><a name="menusearch">Activate menu search for fast access</a></td></tr></tbody></table><h2 id="the-future">The future</h2><p>Eye-tracking or head-tracking mouse. This is a popular idea I’ve been researching recently. There is some existing software I want to try out. I’ll report more on this in the future. Head tracking is also now a part of macOS Catalina, which I’ll also give a go and maybe write about.</p><p>Brain computer interfaces (BCIs). Let’s hold out for our godfather Elon Musk to make Neuralink a reality. The next step is when the computer I/O is no longer limited by dexterous digits.</p><p>I hope you find this post useful. Please feel free to give me feedback, and comments on tools I may have neglected.</p><p><strong>Disclaimer: I’m not giving any medical advice here. If you have problems, please go see someone for your wrists, and prioritize ergonomics.</strong></p><h2 id="references">References</h2></a><ul><a name="mac"></a><li><a name="mac">Vimium</a><ul><a name="mac"></a><li><a name="mac"></a><a href="https://vimium.github.io/" target="_blank" rel="noopener">https://vimium.github.io</a></li></ul></li><li>iCMD (like vimium for MacOS)<ul><li><a href="https://www.icmd.app/?gclid=CjwKCAjwkoz7BRBPEiwAeKw3q0nC8CmwHp4FLnc9fPUzW3oVpPmxh_bWJKpILfV_FgFHmuMNY3bq2hoCGbgQAvD_BwE" target="_blank" rel="noopener">iCMD</a></li></ul></li><li>Karabiner<ul><li><a href="https://karabiner-elements.pqrs.org/" target="_blank" rel="noopener">https://karabiner-elements.pqrs.org/</a></li></ul></li><li>Mouse Keys tutorial<ul><li><a href="https://support.apple.com/guide/mac-help/control-the-pointer-using-mouse-keys-mh27469/mac" target="_blank" rel="noopener">https://support.apple.com/guide/mac-help/control-the-pointer-using-mouse-keys-mh27469/mac</a></li></ul></li><li>Shortcat App<ul><li><a href="https://shortcatapp.com/" target="_blank" rel="noopener">https://shortcatapp.com</a></li></ul></li><li>Alfred<ul><li><a href="https://www.alfredapp.com/" target="_blank" rel="noopener">https://www.alfredapp.com</a></li></ul></li><li>Spectacle<ul><li><a href="https://www.spectacleapp.com/" target="_blank" rel="noopener">https://www.spectacleapp.com/</a></li></ul></li><li>Keyboard-only Mac Cheatheet (Original inspiration for this post)<ul><li><a href="https://gist.github.com/lornajane/3892c39098cf70baa9c7a1874cddf233" target="_blank" rel="noopener">https://gist.github.com/lornajane/3892c39098cf70baa9c7a1874cddf233</a></li></ul></li><li>Vimium cheatsheet<ul><li><a href="https://cheatography.com/l1qu1d/cheat-sheets/vimium/" target="_blank" rel="noopener">https://cheatography.com/l1qu1d/cheat-sheets/vimium/</a></li></ul></li><li>Alfred cheatsheet<ul><li><a href="https://www.alfredapp.com/help/getting-started/cheatsheet/" target="_blank" rel="noopener">https://www.alfredapp.com/help/getting-started/cheatsheet/</a></li></ul></li><li>More general mac setups (More inspiration)<ul><li><a href="https://github.com/nikitavoloboev/my-mac-os" target="_blank" rel="noopener">https://github.com/nikitavoloboev/my-mac-os</a></li></ul></li><li>OneNote shortcuts<ul><li><a href="https://support.microsoft.com/en-us/office/keyboard-shortcuts-in-onenote-44b8b3f4-c274-4bcc-a089-e80fdcc87950#PickTab=macOS" target="_blank" rel="noopener">https://support.microsoft.com/en-us/office/keyboard-shortcuts-in-onenote-44b8b3f4-c274-4bcc-a089-e80fdcc87950#PickTab=</a></li></ul></li><li><a href="https://www.rsiprevention.com/reluctant_mouser.php" target="_blank" rel="noopener">The reluctant mouse</a> another guide for windows shortcuts</li><li><a href="http://matt.might.net/articles/preventing-and-managing-rsi/" target="_blank" rel="noopener">Some good advice on the right setup from Matt Might’s blog</a><ul><li>Notably recommends the Kinesis Advantage keyboard, shoulder support, and Aeron ergonomic chair</li></ul></li><li><a href="https://web.eecs.umich.edu/~cscott/rsi.html" target="_blank" rel="noopener">More unsolicited advice</a></li></ul></div></div></div>]]>
            </description>
            <link>https://www.kchow.org/post/keyboard-warrior/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24673074</guid>
            <pubDate>Sat, 03 Oct 2020 16:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Privacy Tools in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24672948">thread link</a>) | @pavanyara
<br/>
October 3, 2020 | https://zaiste.net/posts/my-favorite-privacy-tools-2020/ | <a href="https://web.archive.org/web/*/https://zaiste.net/posts/my-favorite-privacy-tools-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <div>
        <p>This is a list of tools I use to increase my privacy on the Internet. I'm not a security expert. My goal is to have a good enough protection. Feel free to suggest any additions and improvements.</p>
<h2 id="firefox">Firefox</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343120-ed616080-e00d-11ea-9451-f2c69ada5246.jpg" alt="firefox"></p>
<p><a href="https://www.mozilla.org/en-US/exp/firefox/">Firefox</a> probably doesn't need an introduction. It is an open-source project. It's run by Mozilla - a non-profit organization. Anyone can go to the <a href="https://hg.mozilla.org/">Firefox repository</a> to take a look at the code and see how it works.</p>
<p>Firefox doesn't gather your personal data to serve you ads as Chrome. While Google seems careful and to an extend trustworthy with handling people's personal data, you don't seem to have much control how your profile is built and used.</p>
<p>The browser is constantly being improved. It seems slightly heavier than Chrome or Safari on my computer, but that's a minor issue compared to all the advantages. I use the <a href="https://www.mozilla.org/en-US/firefox/developer/">Developer Edition</a>.</p>
<h2 id="little-snitch">Little Snitch</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343121-edf9f700-e00d-11ea-91d7-a2a876111ca1.jpg" alt="Little Snitch"></p>
<p><a href="https://www.obdev.at/products/littlesnitch/">Little Snitch</a> is a MacOS application that  monitors connections and lets you control inbound and outbound traffic from your computer. It visualizes these connections and shows where applications connect. This way you have information about both familiar and unfamiliar network actions that applications are trying to perform.</p>
<h2 id="pihole-adguard">PiHole &amp; AdGuard</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343124-ef2b2400-e00d-11ea-8f26-f4dcbdf189d6.jpg" alt="Pi Hole">
<img src="https://user-images.githubusercontent.com/200613/90343113-e9cdd980-e00d-11ea-8d17-642c01565237.jpg" alt="AdGuard"></p>
<p><a href="https://pi-hole.net/">PiHole</a> &amp; <a href="https://adguard.com/">AdGuard</a> are ad blockers. PiHole is open-source while AdGuard is a paid offering. I use one at home and the other one at the office. AdGuard is slightly easier to setup and use. Both work network-wide, but AdGuard also provides standalone applications and browser plugins to protect from ads when being outside of private networks.</p>
<h2 id="nibspace">Nibspace</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343122-ee928d80-e00d-11ea-950f-3514adfca5fa.jpg" alt="Nibspace"></p>
<p><a href="https://nibspace.com/">Nibspace</a> is an alternative to Google Analytics. It provides basic information about the visitors of my websites. It doesn't use cookies and it has a small footprint (~ 1kb) while being affordable ($1/mo per domain). It's not open-source. There are few other, notable competitors such as <a href="https://usefathom.com/">Fathom</a>, <a href="https://simpleanalytics.com/">Simple Analytics</a> and <a href="https://plausible.io/">Plausible</a>.</p>
<h2 id="bitwarden">Bitwarden</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343117-ec303380-e00d-11ea-828d-c0bf960154a2.png" alt="Bitwarden"></p>
<p><a href="https://bitwarden.com/">Bitwarden</a> is an open-source password manager. I used to use 1Password, but I wanted something more affordable yet with similar features and Bitwarden fits the bill perfectly.</p>
<h2 id="nordvpn">NordVPN</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343123-ef2b2400-e00d-11ea-8026-de472ec96bc6.jpg" alt="Nord VPN"></p>
<p><a href="https://nordvpn.com/">NordVPN</a> is a personal virtual private network service provider. Their marketing seems aggressive, so I was a bit skeptical at the beginning, but then I decided to give it a try. Overall, NordVPN is one of the most polished and reliable VPNs I've used so far.</p>
<p>I also like that they show some innovation efforts, namely their NordLynx technology that is built around WireGuard - this relatively new VPN tunneling protocol</p>
<p>Last year <a href="https://news.ycombinator.com/item?id=21312609">NordVPN was hacked</a>, but they handled the whole situation pretty well in my view.</p>
<h2 id="fastmail">Fastmail</h2>
<p><img src="https://user-images.githubusercontent.com/200613/90343118-ecc8ca00-e00d-11ea-938b-7e9f884e8a6d.jpg" alt="Fastmail"></p>
<p><a href="https://www.fastmail.com/">Fastmail</a> is a paid e-mail service that focuses on privacy and doesn't display ads. It is a simple service to manage e-mails, calendars and contacts. It costs $5/mo. It is also fast. This is partly related to their work on a more reliable, faster IMAP alternative, called <a href="https://jmap.io/">JMAP</a> - so it goes beyond just a snappy UI.</p>
<hr>
<p>Have I missed an interesting tool? Let me know <a href="https://twitter.com/zaiste">on Twitter</a>.</p>

      </div>

      
        
      
    </div></div>]]>
            </description>
            <link>https://zaiste.net/posts/my-favorite-privacy-tools-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24672948</guid>
            <pubDate>Sat, 03 Oct 2020 16:13:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiment with Lifetime Subscription and made $20k in two days]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24672653">thread link</a>) | @mddanishyusuf
<br/>
October 3, 2020 | https://mohddanish.me/experiment-with-lifetime-subscription-and-made-usd20k-in-48-hours-18 | <a href="https://web.archive.org/web/*/https://mohddanish.me/experiment-with-lifetime-subscription-and-made-usd20k-in-48-hours-18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>👋 Hi, My name is Mohd Danish from INDIA &amp; I started my Indiehacker journey in January 2019. </p><p>You can find me on twitter <a href="https://twitter.com/mddanishyusuf" target="_blank" rel="noopener noreferrer">https://twitter.com/mddanishyusuf</a> &amp; watch me how I failed &amp; success with my projects.</p><p>I really love to read good stories &amp; write true stories based on true life events. So, today I’m sharing my life experience about how I made good money with my product in less than 48 hours.</p><p>I solved 10 problems I faced with MVP &amp; launch on ProductHunt.</p><p>After all those, I build my first SAAS product that related to API called NoCodeAPI.com</p><p>NoCodeAPI - The easiest way to connect your Google Sheet, Airtable, Google Analytics, Twitter, Telegram, Open Graph API, MailChimp, 50+ application APIs without any backend.</p><p><img width="1440" alt="Screenshot 2020-10-03 at 6 37 53 PM" src="https://user-images.githubusercontent.com/9165019/94992426-9ad10900-05a7-11eb-91d9-5fff09b4f1a6.png"></p><p>I Build NoCodeAPI MVP in 20 days. Finally, launch on ProductHunt on 12th January 2020 &amp; tweeted also. Everyone was loving it &amp; this was #1 product of the day. <a href="https://www.producthunt.com/posts/nocodeapi" target="_blank" rel="noopener noreferrer">https://www.producthunt.com/posts/nocodeapi</a></p><p>My tweet got 100k+ impression &amp; 17k media views.</p><p><a href="https://twitter.com/mddanishyusuf/status/1215947112187228161" target="_blank" rel="noopener noreferrer">https://twitter.com/mddanishyusuf/status/1215947112187228161</a></p><p>On the launch day, I got my first 3 paid customers &amp; more than 1200 signups. The launch was really successful but I learn one thing after 6 months that it’s easy to keep running a business &amp; get money from the customer pocket.</p><p>I made $2960 profit until 31-July-2020 but the growth was not good that I was expecting. But, One thing I realized that people need this product and I have to work more on market the product than develop new features.</p><p>One of my mentors told me that if you can get validate the idea &amp; people are paying for your service. Don’t give up just keep working on it and keep iterate according to what the user needs. So, I also get more confidence that Yes, this will be going to good.</p><p>Couple of things I did after that in Marketing:</p><ol start="1"><li>Made YouTube channels &amp; record videos for all the APIs. -&gt; Got Good traffic</li><li>Weekly email newsletter about new updates, integration, &amp; pricing update in the bottom -&gt; Got good conversion to paid users</li><li>Auto-mated email when free users cross API usage by 50%, 75%, &amp; 100% to upgrade plan.</li><li>Write content about the use-cases for the APIs.</li><li>Video call with the free &amp; paid customers if they need any help.</li><li>Improve the documentation part more easy &amp; simple for users.</li><li>I also keep adding one integration every week.</li></ol><p>After all these things I was able to get $850 MRR until and this was pretty great.</p><p>I see people were launching Lifetime deals and made more than 10k in 2 days.</p><p>I was working on NoCodeAPI 2.0 with a new dashboard &amp; I decide to launch a new version with 100 Lifetime deals launch offer. I was calculating that if I made this then I could be a millionaire in my country in 2 days and if I got failed then this will be a great lesson for my journey.</p><p>You guys can’t believe that I was getting mad and my heart was pumping. I was getting stripe notion on every 10 minutes. Someone bought Business Plan Lifetime subscription for $249. I was getting so excited &amp; feeling a high responsibility for the users.</p><p>And finally, the experiment was really successful &amp; I made $20,228 in less than 48 hours. I become the first solo millionaire in my country within 2 days.</p><p>It’s not about I never made that much money in my life, I sold the first product I build in Jan’2019 for $23k. The point is this money from my first SAAS product. </p><p>This all my experience with this experiment &amp; I’m seeing a huge potential with the product. I’m still working hard to make the product more mature &amp; profitable.</p><p>That's all.</p><p>I'll keep writing about my real-life experience. You can follow on twitter for the next story. <a href="https://twitter.com/mddanishyusuf" target="_blank" rel="noopener noreferrer">https://twitter.com/mddanishyusuf</a></p><p>Peace.</p></div></div></div></div></div>]]>
            </description>
            <link>https://mohddanish.me/experiment-with-lifetime-subscription-and-made-usd20k-in-48-hours-18</link>
            <guid isPermaLink="false">hacker-news-small-sites-24672653</guid>
            <pubDate>Sat, 03 Oct 2020 15:29:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sound Blaster 1.0 Principles of Operation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24672496">thread link</a>) | @pwg
<br/>
October 3, 2020 | http://tubetime.us/index.php/2019/01/19/sound-blaster-1-0-principles-of-operation/ | <a href="https://web.archive.org/web/*/http://tubetime.us/index.php/2019/01/19/sound-blaster-1-0-principles-of-operation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-508">
		
		<p><span title="Date">January 19, 2019</span>
		<span title="Time">6:14 pm</span>
		
		<span title="Category"><a href="http://tubetime.us/index.php/category/cleverness/" rel="category tag">Cleverness</a></span>
		<span></span>
		<span><p>The Sound Blaster 1.0 was not the first PC sound card, but it was the first to support digital sound, two different types of sound synthesis, MIDI, and a joystick all in one card. Let’s lift the hood and examine how the card does its magic.<br>
You can follow along by <a href="https://github.com/schlae/snark-barker/blob/master/SnarkBarker.pdf">looking at the schematic here</a>.</p>
<p><strong>Sound Playback</strong><br>
There are three methods a Sound Blaster card uses to play back digital audio.</p>
<p><strong>Direct DAC</strong><br>
The first is called Direct DAC and it means that the PC software has to feed the sound card each sample at just the right time. It works a lot like the parallel-port DACs that people used to build in the 80s and 90s, or like the Disney Sound Source. When you send a data byte to the sound card, it immediately changes the analog signal going into the speaker amplifier.</p>
<p>Software using this method typically sets up a periodic timer interrupt. In the interrupt handler, the new sample is calculated and then fed to the sound card for playback.</p>
<p>Although it’s a simple method, it produces extra noisy playback to due the timing jitter of the interrupt handler. Because PC interrupts are non-deterministic, the samples don’t occur at precisely the sampling rate. This timing difference means that the waveform being reproduced doesn’t match the source material, and the difference in voltage sounds like noise or hiss.</p>
<p><strong>DMA DAC</strong><br>
The other method uses the DMA (Direct Memory Access) controller on the PC motherboard to automatically send samples to the sound card. It does require a little bit more work to set up the operation.</p>
<ol>
<li>The software configures the PC’s DMA controller (historically an Intel 8237) with the source address and length. The DMA controller is set to perform a single transfer per DMA request (DREQ).</li>
<li>The Sound Blaster is configured for a particular sampling rate. It programs an internal timer to generate a DREQ signal at the sampling rate.</li>
<li>The software sends the playback command to the Sound Blaster.</li>
</ol>
<p>The next operations happen in a loop until all the samples have been played back. Notice that the software is not involved at all—just the DMA controller, the Sound Blaster, and main memory.</p>
<ol>
<li>The Sound Blaster asserts DREQ.</li>
<li>The DMA controller responds by asserting DACK (DMA Acknowledge) at the same time it places the memory address and memory chip select onto the bus. The data byte gets transferred directly from main memory into the Sound Blaster input register!</li>
<li>The Sound Blaster takes this data and sends it to the audio DAC.</li>
</ol>
<p>Finally, the Sound Blaster ends playback then triggers an interrupt to let the software know that it is done with playback.</p>
<p><strong>Auto-Initialize DMA DAC</strong><br>
The final method, introduced with the Sound Blaster 2.0, is very similar to the previous method, except the ending. The Sound Blaster triggers an interrupt as before, but then it reloads the sample counter to the original value and continues requesting samples from the DMA controller!</p>
<p>The usual way software uses this feature is to create a seamless digital audio stream using a double buffer. The DMA controller gets a buffer that is twice as big as the number of samples that the Sound Blaster is programmed to play back. Because of that, the interrupt gets triggered halfway through buffer playback. In the interrupt handler, the software then loads a new set of samples into the buffer half that has already been played. When playback hits the end of the DMA buffer, the interrupt triggers again, only this time the software refills the last half of the DMA buffer. The DMA controller then wraps around to the beginning of the buffer and playback continues unbroken.</p>
<p>One of the side effects of this approach is that if the software crashes, the DMA controller and sound card continue to play back the sample buffer in a loop. You may have heard this when playing old DOS games back in the day.</p>
<p><strong>Sound Recording</strong><br>
This works in very much the same way as playback including the Direct mode, DMA mode, and Auto-Init DMA modes, except data gets transferred in the opposite direction, from the sound card into main memory.</p>
<p>One interesting wrinkle is that the Sound Blaster doesn’t actually have a proper ADC (analog-to-digital converter)! Instead it uses a clever circuit and an algorithm to accomplish the same thing:</p>
<ol>
<li>An input filter processes the incoming sound to smooth out any high frequency transients. This is common practice, even with an ADC, to help prevent sampling-induced aliasing, but it it’s helpful for making the trick work.</li>
<li>A comparator looks at the difference between the audio DAC and the incoming signal. The output of the comparator is only one bit; it can only tell if the incoming signal is greater than or less than the setting of the audio DAC.</li>
<li>The DSP starts the audio DAC at the halfway point, then looks at the comparator output. The comparator output gets recorded as the most significant bit of the audio sample.</li>
<li>Depending on the bit, the DSP sets the audio DAC up or down half again—either 25% or 75%.</li>
<li>The DSP repeats steps 3 and 4, going halfway again and again until it’s obtained the 8 bits of a complete sample.</li>
</ol>
<p>This technique is known as successive approximation, and it’s a technique used in many ADC chips. The code looks something like this:<br>
<code><br>
mov	p1,#80h		; Start DAC at the halfway point, 1000 0000<br>
mov	c,t1			; 1 Put comparator output into carry bit<br>
mov	p1.7,c			; 2 If greater, then leave MSB as is. If less, clear MSB<br>
setb	p1.6			; 1 Set DAC to upper or lower halfway point<br>
mov	c,t1			; 1 Check comparator output again<br>
mov	p1.6,c			; 2 Rinse and repeat<br>
setb	p1.5<br>
mov	c,t1<br>
mov	p1.5,c<br>
setb	p1.4<br>
mov	c,t1<br>
mov	p1.4,c<br>
setb	p1.3<br>
mov	c,t1<br>
mov	p1.3,c<br>
setb	p1.2<br>
mov	c,t1<br>
mov	p1.2,c<br>
setb	p1.1<br>
mov	c,t1<br>
mov	p1.1,c<br>
setb	p1.0<br>
mov	c,t1<br>
mov	p1.0,c<br>
mov	a,p1			; We are done, copy DAC code into accumulator.</code></p>
<p><strong>The Hardware, Section By Section</strong></p>
<p><strong>Address Decoder</strong><br>
The address decoder takes the I/O port address off the ISA bus and looks for accesses at 210h, 220h, 230h, 240h, 250h, or 260h depending on the jumper setting. It also looks for 388h and 389h so that it can make the Yamaha OPL2 chip appear there for Adlib compatibility. It also decodes 0x200-207h as the joystick port (each address is actually the same).</p>
<p><a href="http://tubetime.us/wp-content/uploads/2019/01/address-decoder.png"><img src="http://tubetime.us/wp-content/uploads/2019/01/address-decoder.png" alt="" width="490" height="177"></a></p>
<p>A jumper, JP1, can be pulled to shut off the PC joystick port. The MIDI function still works, however. Many combo-IO boards came with a built-in joystick port so the one on the Sound Blaster may not always be needed.</p>
<p><strong>Reset Circuit</strong><br>
It’s important to make sure the card powers up in a good state without generating spurious noises, so the SB uses the ISA RESET signal to clear the OPL2, the CMS chips, the joystick one-shot, and basically all of the other internal state latches.</p>
<p><a href="http://tubetime.us/wp-content/uploads/2019/01/reset.png"><img src="http://tubetime.us/wp-content/uploads/2019/01/reset.png" alt="" width="496" height="159"></a></p>
<p>There is also an IO port that, if you write a 1 to it, resets the DSP and its associated bus interface. (You also have to write a 0 to it afterwards to allow the DSP to start operating.) Later versions of the DSP require this to exit high speed auto-init DMA mode, since in this mode, the DSP devotes 100% CPU to servicing DMA requests.</p>
<p><strong>DSP</strong><br>
The core of the digital sound capabilities of the Sound Blaster is the Digital Sound Processor, or DSP for short. It’s not actually a Digital Signal Processor in the traditional sense—it’s just an 8051 microcontroller with custom firmware.</p>
<p>The DSP also handles MIDI transmit and receive using the 8051’s built-in UART.</p>
<p><strong>DSP Bus Interface</strong><br>
The bus interface allows the host PC to talk to the DSP. It uses two unidirectional 8-bit registers as a “mailbox,” temporary holding areas for a single data byte. One is for PC-to-DSP communications, and the other is for DSP-to-PC communications. There are also two data flip flops that are used to signal when data is available in one of the registers.</p>
<p><a href="http://tubetime.us/wp-content/uploads/2019/01/mailbox.png"><img src="http://tubetime.us/wp-content/uploads/2019/01/mailbox.png" alt="" width="349" height="362"></a></p>
<p>When the PC sends data to the DSP (I/O port 2XCh), the data gets stored in an 8-bit register and the flip-flop is automatically set high (DAV_DSP).</p>
<p>When the DSP reads the register, the flip-flop gets cleared automatically.</p>
<p>When the DSP sends data to the PC, the data goes into the other 8-bit register and the other flip-flop automatically gets set (DAV_PC). The PC can check this bit by reading from I/O port 2XEh. When it reads from I/O port 2XAh, it receives the byte of data and the flip-flop automatically gets cleared. The DSP can see that the PC has read the byte by checking the DAV_PC input. The DSP often checks this pin to make sure the PC has read a data byte before writing a new data byte to the register, otherwise the byte in the register will be lost before the PC has a chance to read it.</p>
<p><a href="http://tubetime.us/wp-content/uploads/2019/01/data-flags.png"><img src="http://tubetime.us/wp-content/uploads/2019/01/data-flags.png" alt="" width="441" height="355"></a></p>
<p><strong>Interrupts</strong><br>
When the DSP is done with a particular (often lengthy) task, it can signal the host PC by asserting the interrupt line. It does this by pulsing IREQUEST which triggers a flip-flop that asserts the IRQ line on the PC bus. On the host PC, the interrupt handler is supposed to clear the interrupt by reading from I/O port 2XEh. This simply clears the flip-flop which then deasserts the IRQ line.</p>
<p><a href="http://tubetime.us/wp-content/uploads/2019/01/interrupt-flag.png"><img src="http://tubetime.us/wp-content/uploads/2019/01/interrupt-flag.png" alt="" width="426" height="281"></a></p>
<p><strong>DMA</strong><br>
When the DSP needs a new sample from the PC (or needs to transfer a new sample to the PC during record mode), it pulses the DREQUEST line. Note that the DSP also needs to enable DMA by asserting its DMA_EN# line. When DREQUEST pulses, it causes the DMA request flip-flop to output a 1 on the DRQ1 line. The PC’s DMA controller responds by asserting DACK1#, which clears the flip-flop. DACK1# also bypasses the address decode logic of the Sound Blaster and forces it to either accept data from or place data on the ISA bus lines. This data transfer happens between the ISA bus and the mailbox registers.</p>
<p><a href="http://tubetime.us/wp-content/uploads/2019/01/dma-flag.png"><img src="http://tubetime.us/wp-content/uploads/2019/01/dma-flag.png" alt="" width="527" height="170"></a></p>
<p><strong>Digital Audio Output</strong><br>
An 8-bit DAC connected to the 8051 generates an analog current corresponding with the digital code on its inputs. A current-to-voltage converter (U5C) changes the current into a voltage that is used by the rest of the circuit. This voltage goes through an antialiasing filter which removes distinctive- and ugly-sounding artifacts from the audio signal. U5A implements this filter using a Sallen-Key design. The filter cutoff frequency is about 4KHz, …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tubetime.us/index.php/2019/01/19/sound-blaster-1-0-principles-of-operation/">http://tubetime.us/index.php/2019/01/19/sound-blaster-1-0-principles-of-operation/</a></em></p>]]>
            </description>
            <link>http://tubetime.us/index.php/2019/01/19/sound-blaster-1-0-principles-of-operation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24672496</guid>
            <pubDate>Sat, 03 Oct 2020 15:07:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Freedom needs friction: lessons in choice from French history]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24671977">thread link</a>) | @canada_random1
<br/>
October 3, 2020 | https://psyche.co/ideas/freedom-needs-friction-lessons-in-choice-from-french-history | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/freedom-needs-friction-lessons-in-choice-from-french-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>The French language</strong> offers two ways of speaking about freedom: <em>libre arbitre</em> means â€˜free will;â€™ <em>volontÃ©</em> means â€˜the willâ€™ or, better, â€˜volitionâ€™. Each carries with it distinct conceptual baggage. On the one hand, we exercise free will when making a choice. For volition, on the other hand, our freedom amounts to an exertion of effort. One is intellectual; the other laborious. Although you could get away with using either in everyday conversation, the choice of one term rather than the other is consequential. Indeed, the history of this semantic rift spills beyond the French language. It reveals a fissure at the core of what it means to author oneâ€™s own life story.</p>
<p>Two hundred years ago, disputes over the nature of freedom were all-consuming in France. Thatâ€™s not only because political upheavals rocked the 19th century. In the wake of the 1789 French Revolution, men and women experienced radical democracies, military dictatorships, resurgent monarchies and constitutional republics â€“ a living exercise in political science during which questions of <em>libertÃ©</em> (another term for â€˜freedomâ€™) preoccupied national debates.</p>
<p>A scientific revolution also ignited beyond the Palace of Versailles, setting the fates of free will and volition on a collision course. The rise of psychology and neurology threw into disarray the terms with which people made sense of their selfhood. By the beginning of the 20th century, the young sciences showed how freedom involves our entire bodies; indeed, it penetrates far deeper into our being than mere choice.</p>
<p>The philosopher and psychologist Maine de Biran (1766-1824) led the vanguard. During a long political career, from the court of Louis XVI to the lower house of parliament â€“ an institution created after the brothers of the executed king took over the throne in 1815 â€“ Biran used his influence to gather the foremost French scientists. They studied the mind as part of the body. At a time when the nervous systemâ€™s workings were only beginning to be understood, the gatherings were, for some, an occasion to dispel freedom as an illusion. Emblematic was the physiologist Pierre-Jean-George Cabanis (1757-1808) who claimed that â€˜The brain secretes thought like the liver secretes bile.â€™ Material enquiry, and not the abstract notion of free will, was to explain our agency.</p>
<p>Biran saw the fledgling brain sciences otherwise. In his work <em>The Influence of Habit on the Faculty of Thinking</em> (1802), Biran showed how our freedom hinges on volition, which canâ€™t be easily confined to the space between our ears. Materialist scientists tilted at windmills, so Biran charged. The idea of free will is a fiction because our freedom needs friction.</p>
<p>Biranâ€™s insight was that our nervous system is not a cause of volition but its constraint. In putting our body to use, we exert effort and encounter resistance. The play between the two â€“ their modulation over time â€“ gives rise to habits. According to Biran, habit follows a double law: â€˜the less we feel, the more we perceiveâ€™. Before I studied the French language, the silent consonants and serous liaisons struck my ears like an indistinguishable mÃ©lange. By focusing on individual words, contorting my tongue and taking risks to speak, I eventually came to inhabit the language. Thanks to my sustained volition, a cacophony of foreign sounds eventually gave way to meaningful speech. For Biran, the paradigmatic habit is self-education.</p>
<p>His book overthrew the longstanding view that habit is blind repetition. RenÃ© Descartes and Immanuel Kant had condemned habits as mechanical routines. They cloud clear judgment. For Biran, however, the discrete decisions of our free will matter less than the direction of our volition over time. And as habits take over, new resistance mounts. My patterns of thought and verbal crutches take the place of intentional speech. When I find myself lost in conversation at a cocktail party, <em>voilÃ&nbsp;</em> rolls off my tongue instinctively whenever I feel itâ€™s time to wrap up. Habits open an opportunity to renew our efforts and overcome the resistance that takes over within us.</p>
<p><strong>In the 19th century</strong>, psychology and politics revolved in the same orbit. Uprisings sought to replace old monarchical habits with new democratic ones. Biran, however, was no democrat. He applauded NapolÃ©onâ€™s brief return from exile in 1815. The French deserved an emperor who would strengthen peopleâ€™s volition, which had been weakened by the unruly sentiments of popular sovereignty. Biranâ€™s vision of selfhood was as consistent as his politics was lamentable, tethered as it was to an enduring aristocratic disposition.</p>
<p>Bergson adapted Biranâ€™s insight for a modern world ruled by numbers: choices touch only the shallows of our selfhood</p>
<p>In the eyes of European liberals, the new social orderâ€™s success hinged on a different form of freedom â€“ free will. Universal male suffrage and market economies, both established with yet another French revolution in 1848, introduced novel decision-making capacities. The prolific polymath Charles Renouvier (1815-1903) argued that citizensâ€™ <em>libre arbitre</em> usurped the reign of God and monarch. We occupy the role of judge (following the Latin, <em>arbitrium</em>) who renders a decision, as it were, in the court of the mind. To act with a free will, we â€˜place the government of our innermost spirit in the hands of a single ideaâ€™. Renouvier spent the decade of 1854-64 writing his <em>Essays of General Critique</em>, a project to translate the individual will into the driving force of national regeneration. Government would thereby find its legitimacy in the voluntary consent of citizens.</p>
<p>National regeneration was the chief <a href="https://quod.lib.umich.edu/w/wsfh/0642292.0042.015/--brain-in-the-third-republic-science-pedagogy-and-national?rgn=main;view=fulltext" rel="nofollow noreferrer noopener">goal</a> of the Third Republic, which reinvigorated disputes between free will and volition. It was the longest democratic regime in the countryâ€™s history, lasting from 1870 to the Nazi occupation in 1940. Following its inception, investment in science was a national priority. Fidelity to the <em>patrie</em> was to be not only free but also rational.</p>
<p>When the first experimental psychology laboratories broke ground in the 1880s, their focus was psychometrics. Reaction time experiments allowed researchers to track the time of thinking, feeling and willing. They ranged between .1 and .3 seconds (the time from the reception of stimuli in the brain to the movement of a limb). The mathematical revolution in the study of mind also set in motion projects to scale intellectual aptitude â€“ Alfred Binet (1857-1911) released the first IQ measure in 1905 â€“ and to rationalise colonial conquests of â€˜uncivilisedâ€™ people in West Africa and Indochina. A trenchant materialism characterised the <em>fin de siÃ¨cle</em>, a period during which faith in numbers drove projects to hierarchise human freedom.</p>
<p>Critics returned to Biranâ€™s ideas. For Alfred FouillÃ©e (1838-1912), quantitative psychology demonstrated that thoughts constitute powerful motor actions â€“ what he called <em>idea-forces.</em> Their duration fluctuates with the obstacles we confront. In documenting the time taken to make decisions, experimental research didnâ€™t make freedom predictable so much as it laid to rest the idea of unencumbered free will. Such was the case in liberal politics as well: our choices (left or right, buy or sell) reflect the surface of our freedom. Deeper, FouillÃ©e believed, was a fleshly understanding of volition entangled with the bodyâ€™s sensory-motor coordination.</p>
<p>The philosopher Henri Bergson (1859-1941) went a step further. In an <em>oeuvre</em> that was awarded the 1927 Nobel Prize in Literature, Bergson showed how we experience the world as a <em>lived duration</em>. As he saw it, psychometrics recorded the trace left by our volition, much like a marathonâ€™s final standings indicate when runners pass the finish line. Within the flow of time, however, our freedom fluctuates between exertions of energy and effortless passivity. When I reflect inward on the life I live, I notice discrete decisions: the choice of college majors, career paths and romantic partners. When I probe deeper, the volition shaping my self comes into view â€“ that is, the kind of person I continuously strive to become â€“ and with it the constraints that have lent traction to my creativity. Bergson adapted Biranâ€™s insight for a modern world ruled by numbers: choices touch only the shallows of our selfhood.</p>
<p>Today, choice-making is central to economic forecasting, political analysis and psychological testing. Market data and survey metrics aggregate our collective decisions. Although our world is distant from that of France a century ago, the countryâ€™s thinkers offer an enduring reminder that our aspirations for freedom do not amount to one thing. Do we seek more choices? Or do we strive to resist the sediments of time â€“ that is, to make our selfhood anew?</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/freedom-needs-friction-lessons-in-choice-from-french-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671977</guid>
            <pubDate>Sat, 03 Oct 2020 13:32:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vets Who Code: What, Where, and How to Help]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24671488">thread link</a>) | @mooreds
<br/>
October 3, 2020 | https://vetswhocode.io/blog/vets-who-code-what-where-and-how-to-help | <a href="https://web.archive.org/web/*/https://vetswhocode.io/blog/vets-who-code-what-where-and-how-to-help">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="blog-page"><div><div><div><article><div><div><h2>Vets Who Code: What, Where, And How to Help</h2></div><p>When I started this journey&nbsp;<span>SIX</span>&nbsp;years ago, I just wanted to create an affordable solution for veterans to transition into the workforce as fast as they can without the hurdles of civilian life of trying to find a code school that accepts the GI Bill. I didn’t want my fellow troops in transition to fall through the cracks, like I did.</p><p>That’s why I went into the nonprofit sector in the first place. I wanted to help my brothers and sisters. What I found was a system designed, not to help them, but, to get as much money out of donors, sponsors and government agencies as possible by telling the story of how the nation fails our servicemen and women; all the while creating extremely high requirements, yet, having extremely low benchmarks for success. Did you know that unless you are actually sleeping on the streets in some states you aren’t considered homeless? Meaning, if you are living out of your car, living out of a hotel room, or couch-surfing, you don’t qualify for certain support services.</p><p>I should know — I’ve had the great displeasure of doing all three. Despite the adversity, perseverance enabled me to climb out of the darkness, with a deep desire to keep other veterans from falling into the abyss. Thinking back, that was the hardest six months of my life! It was development and design that helped me get through those tough times, not the current nonprofit sector filled with relics that have cozy relationships all the while doing the minimum.</p><p>I spent every waking moment learning skills that other people were either too stubborn or just too fearful to learn, and it added value to me — value the civilian sector could understand. Then, when a fallen soldier’s family needed help, my newly minted value empowered me to answer the call to bury a brother. Afterwards, I was like “what do I do next?” — leading to the stupid idea of turning something old (a freaking castle!) into something new, repurposing it to retrain veterans in real and digital skillsets. Unfortunately that didn’t work. But, out of it came true inspiration, something revamped, brilliant, and functional — something I hope would even make David Heinemeier Hansson (my hero) proud.</p><p><span>What is Vets Who Code?</span></p><p>Vets Who Code is a veteran founded, lead and operated 501(c)(3) distributed charitable non-profit, dedicated to filling the wide chasm between technical expertise needed and available with transitioning veterans and active duty military spouses through software development training and education. We utilize our distributed model for the capability to train veterans anywhere, but we are so much more. We are a team of people with hybrid tech skills and a lean mentality, focused on helping veterans not only learn how to program, but get jobs in the field and to do it without the unnecessary bloat that other nonprofits take on. From UX and DevOPs engineers to little old me, who got thrown into this because I simply wanted to help my fellow veterans, which is the most important part of this nonprofit. Currently 80% of the team is veterans, and we provide what you need to surpass our successes and learn from our mistakes. ’Cause if we are to celebrate this thing called life, we need to be there together.</p><p><span>Why Code?</span></p><p>Great question. Right now our country has a problem: we have programming jobs, but not enough programmers. Not only that, we don’t have enough GOOD programmers. On top of that, while it’s definitely better, veterans are still the highest unemployed demographic in America. So we had this crazy idea. What if we created a vetted curriculum designed around modern technologies? Not just any veterans, those who this skill could really impact. Not only that, let’s work tirelessly to mentor them in professional standards of code, business, and design. Can you imagine how much better you get at design thinking when the guy speaking has been thinking about it every day for the last 15 years? We then thought, what if we added tools to continue learning after you’ve dealt with us for 15 weeks? Our partners like Frontend Masters and Google Cloud give us amazing tools to gift the veterans so that they can learn and prep for up to a year. Not only that — we make introductions, and train them in the interview process to help them get jobs in the industry. You know what? It works. Our troops have been getting highly paid positions, and we couldn’t be happier. Here we empower amazing people to have the lifestyle they have earned, and we do it all online; a feat that wasn’t even possible 10 years ago.</p><p><span>How Can You Help?</span></p><p>That’s actually a question we get quite often. Our veterans spend 15 weeks with our team focusing on the language JavaScript and and all it encompasses, and understanding software architecture and computer science fundamentals. We focus on having workflows, interview questions, computer science, and UX research.</p><p>The most important thing you can do to support our mission is&nbsp;<a href="https://donorbox.org/vetswhocode-donation" target="_blank" rel="noopener noreferrer"><span>donate</span></a>. As a 501(c)(3) we are tax-deductible, and as a distributed non-profit, we don't have any wasteful operating cost. All proceeds go directly to resources and cool things for the troops.</p><p>If you’re a software engineer with at least two years experience working with ES6 and Javascript, sign up as a mentor. If you are a designer who can code, we are always looking for someone to help us with our user experience. If you are in HR, drop us a line in our contact form, so that we can get our troops into your pipeline for javascript jobs.</p></div></article></div></div></div></section></div>]]>
            </description>
            <link>https://vetswhocode.io/blog/vets-who-code-what-where-and-how-to-help</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671488</guid>
            <pubDate>Sat, 03 Oct 2020 12:19:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doctoberfest: Rewarding Open Source Documentation Contributions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24671446">thread link</a>) | @barlo
<br/>
October 3, 2020 | https://wagon.dev/doctoberfest | <a href="https://web.archive.org/web/*/https://wagon.dev/doctoberfest">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lp-pom-text-10"><p><span><span><a data-fr-linked="true" href="https://wagon.dev/clkn/https/wagon.dev/"></a></span></span><span><span>The open source world needs more documentation.&nbsp;</span></span></p><p><span><span>For the month of October, we will will be offering a beanie to developers and technical writers that make &nbsp;documentation improvements to open source projects that support IPv6, privacy, and advancements in networking technology.</span></span></p></div><div id="lp-pom-text-333"><p><span><span>Participants</span></span><span><span>&nbsp;must make three (3) substantial documentation improvements.&nbsp;</span></span></p><p><span><span>Improvements can be to a single project or more than one. The offer is limited to the first one hundred participants.&nbsp;</span></span></p></div><div id="lp-pom-text-336"><p><span>After verifying your pull requests, we will email you a link to submit your address for shipping.</span></p><p><a data-action="url" data-params="false" href="mailto://doctoberfest@wagon.dev" target="_self"><span>doctoberfest@wagon.dev</span></a></p></div></div>]]>
            </description>
            <link>https://wagon.dev/doctoberfest</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671446</guid>
            <pubDate>Sat, 03 Oct 2020 12:12:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Starter Kit 2020]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24671403">thread link</a>) | @psxuaw
<br/>
October 3, 2020 | https://wiki.alopex.li/RustStarterKit2020 | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/RustStarterKit2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>People were arguing about Rust’s std lib recently, so I went through the <code>Cargo.toml</code> of all the Rust projects I’ve written since 2015 and picked out the choice tools that get used over and over again. Up to date as of October 2020.</p>
<p>Also see <a href="https://wiki.alopex.li/RustCrates" title="Go to wiki page">RustCrates</a>, though that’s old. There’s also <a href="https://christine.website/blog/rust-crates-go-stdlib-2020-09-27">this</a>, which is narrower but deeper, and <a href="https://github.com/rust-unofficial/awesome-rust">awesome-rust</a>, which is shallower and broader, and the various <a href="https://www.arewewebyet.org/">more</a> <a href="https://arewegameyet.rs/">specific</a> <a href="https://areweasyncyet.rs/">websites</a> <a href="https://www.areweguiyet.com/">for various</a> <a href="https://areweideyet.com/">topics</a>.</p>

<p>I need to set up a new Rust dev environment, what do I install?</p>
<h2 id="linting-clippy">Linting – <code>clippy</code></h2>
<p>The one, the only, the great Rust style and correctness linter. Want to learn how to write “idiomatic” Rust, or just learn more about handy little corners of the language and library? Run <code>clippy</code> regularly. It’s distributed with the compiler via <code>rustup</code> now, so you have no excuse not to.</p>
<h2 id="build-cache-sccache">Build cache – <code>sccache</code></h2>
<p>Or, “how to make a full rebuild 70% faster”. <code>sccache</code> is a build artifact cache similar to <code>icecream</code> or <code>ccache</code>, except it’s actually trivial to just use. <code>cargo install sccache</code>, add a single line in a home dir config file, and you’re ready to go. Pretty much handles most crate and compiler versioning issues for you, so it Just Works if you update crates or install a new version of <code>rustc</code> or something. I think I’ve had to force-clear the cache due to some build weirdness a grand total of once. Looks like it has enough features to use in a professional context as well, at least on a small-to-medium scale.</p>
<h2 id="dependency-viewer-cargo-tree">Dependency viewer – <code>cargo-tree</code></h2>
<p>The best way to view what dependencies you are using, and what dependencies they are using, and so on. Best way to start cracking down on flabby dependencies.</p>
<h2 id="benchmarking-criterion">Benchmarking – <code>criterion</code></h2>
<p>Basically the best benchmark system out there. Incredibly simple to use, informative, and statistically sound. Doesn’t really do profiling, but it’s a good start for understanding your program’s performance, and better for proving that your implementation of X is faster than someone else’s.</p>
<h2 id="other-things">Other things</h2>
<p>Stuff that is less general purpose but occasionally very useful for the meta-programming process of choosing libraries, evaluating them, etc.</p>
<ul>
<li><code>cargo-geiger</code> – Measures how much unsafe code is in a codebase, and its dependencies</li>
<li><code>cargo-crev</code> – A <a href="https://wiki.alopex.li/ActuallyUsingCrev">very neat tool</a> for authoring and verifying distributed code reviews.</li>
<li>Various tools maintained by <a href="https://github.com/EmbarkStudios/rust-ecosystem">Embark Studios</a>, useful for production/company purposes like checking licenses, pinning specific versions of crates, etc.</li>
</ul>

<p>The cool stuff Real Computer Scientists write about.</p>
<h2 id="hashing">Hashing</h2>
<p>No specific crates here. There’s no single crate that provides All The Hash Algorithms, just lots of little ones that generally provide a single algorithm each. Just type the name of the algorithm you want into <code>crates.io</code> and you’ll get at least a couple options, choose the one with 8 million downloads or whatever. <code>sha2</code>, <code>md5</code>, <code>crc</code>, etc. Lots of them are written by the Rust core team.</p>
<h2 id="compression">Compression</h2>
<p>Same as the hashing category. Type <code>zip</code> or <code>bzip2</code> or whatever into crates.io and you’ll get what you need. <code>flate2</code> might be the one crate that’s not quite trivial to find. Again, many of them are written by the Rust core team.</p>
<h2 id="encryption">Encryption</h2>
<p>I have little actual experience or authority on this topic, so I’m going to punt on this one.</p>
<h2 id="pseudorandom-number-generator">Pseudorandom number generator</h2>
<p>Use <code>oorandom</code>. (Disclaimer, I wrote <code>oorandom</code>, but people besides me seem to like it.) More usually you’ll see the <code>rand</code> crate in use. If you’re doing Real Science and need to generate <a href="https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html">fancy probabilities</a>, then <code>rand</code> is the right tool, but most people aren’t doing that. Otherwise <code>rand</code> is complicated and has lots of features, while <code>oorandom</code> is very simple and has about two features, and I expect 80% of code to use at least one of them. <code>rand</code> has had several major breaking changes in its history that the rest of the ecosystem still hasn’t caught up with, while I intend <code>oorandom</code>’s API to change maybe twice in my lifetime. (Its version number, while obeying semver, is mostly a joke.)</p>
<p>There’s other lightweight PRNG crates that are just fine; see <code>oorandom</code>’s readme for a list of some others and choose one you like. Whatever you choose, use the <code>getrandom</code> crate to produce Real Random Seeds for it.</p>

<p>“I just need to solve this ooooooone common problem, but it needs to be solved WELL…”</p>
<h2 id="logging-log">Logging – <code>log</code></h2>
<p>Need to output log messages in your code? Why, use the <code>log</code> crate. Where do the log messages go? <code>log</code> provides only an interface, and that interface compiles to nothing if it isn’t used. You can write your own system for it to actually output the logs to, which is pretty easy, or use one of the small plethora of crates for it. My preferred one is <code>pretty_env_logger</code>, but <code>fern</code>, <code>slog</code> and others are all good too.</p>
<h2 id="parallel-data-crunching-rayon">Parallel data crunching – <code>rayon</code></h2>
<p>Ever have some computation where you have a big list of STUFF and want to process it in parallel, farming out jobs to as many threads as you have CPU’s? That’s what <code>rayon</code> does, and it does it really, really well. You still <a href="https://aspenuwu.me/posts/rust-optimization.html">have to know what you’re doing</a>, but changing a single <code>.iter()</code> into <code>.par_iter()</code> and watching your CPU-bound data-crunching run 8x faster is pretty magical. Now your CPU can help keep you warm this winter!</p>
<p>Please never use it in a library. It’s rude to spawn threads in library code, unless that’s specifically what the library is for.</p>
<h2 id="regexes-regex">Regexes – <code>regex</code></h2>
<p>To quote the inestimable <a href="https://www.jwz.org/blog/">jwz</a>:</p>
<blockquote>
<p>Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.</p>
</blockquote>
<p>On the other hand, <a href="https://xkcd.com/208/">somebody’s gotta save the day</a>. So, use the <code>regex</code> crate. Also use <a href="https://crates.io/crates/ripgrep">anything else</a> <a href="https://crates.io/crates/xsv">written by BurntSushi</a>. BurntSushi is a paragon of Rust program design, and also just a great <del>human being</del> charred cuisine in general.</p>
<h2 id="threadsafe-globals-lazy_static">Threadsafe globals – <code>lazy_static</code></h2>
<p>“I know globals are evil,” you say, “but I just need one. I’ll only use it for good, I promise.” <code>lazy_static</code> has your back.</p>
<p>May eventually be superseded by <code>once_cell</code>, which looks like its <a href="https://github.com/rust-lang/rfcs/pull/2788">headed for inclusion into <code>std</code></a>.</p>
<h2 id="serializationdeserialization-serde">Serialization/deserialization – <code>serde</code></h2>
<p>Ever have a struct and just wanted to turn it into JSON, CBOR, XML, or some other engine of woe and devastation designed to be written to an I/O stream? Or had a blob of random JSON and wanted to just stuff it into a struct matching it? Sure you have. <code>serde</code> lets you do this with a single <code>#[derive]</code>. <code>serde</code> is without a doubt one of Rust’s killer libraries. It is better than any other serialization system I have ever used.</p>
<p>What data formats does it support? Anything; the actual reading and writing is done via plugin library. There’s a <a href="https://serde.rs/#data-formats">wide selection of them</a>, of varying quality, and writing your own is a little tedious but not terribly difficult.</p>
<h2 id="error-handling">Error handling</h2>
<p>This spot deliberately left blank.</p>
<p>Rust’s <code>Result&lt;T,E&gt;</code> type is one of the best setups for lightweight, transparent error handling I’ve seen, but it doesn’t do everything. How do you easily write your own error type without a bunch of boilerplate? What if you have multiple different error types from different libraries you want to coalesce together? How do you collect a backtrace of every function an <code>Err</code> is returned through, so you can find the root cause of where it came from? Can we do all this without allocating anything unnecessarily? And so on.</p>
<p>There have been various crates to try to solve these problems. First in 2015 there was <code>error_chain</code>, which was complicated and not very convenient. Then in 2017 there was <code>failure</code>, which was simpler but not very flexible, and which took an irritatingly long time to compile. Then in 2019 there was <code>anyhow</code>, which was about the time I stopped paying attention. Now apparently the new kid on the block is <code>eyre</code>, and I’m sure that in another year or two there will be something else.</p>
<p>So, I just write the boilerplate and make my errors descriptive enough I don’t need a backtrace. When I want to get fancy I implement the built-in <a href="https://doc.rust-lang.org/std/error/trait.Error.html"><code>Error</code></a> trait, which used to be kinda useless but is now more helpful. And in another five years it’ll still work just fine.</p>
<h2 id="byte-mucking-bytemuck">Byte mucking – <code>bytemuck</code></h2>
<p>For the rare occasions you need to turn a structure into arbitrary <code>&amp;[u8]</code> or back. Doing this using unsafe pointers is quite easy, and also makes it very easy to screw up horribly with Undefined Behavior galore. (Did you know that changing the value of padding bytes in a struct in UB? You do now.) <code>bytemuck</code> lets you muck around with bytes a little more responsibly.</p>
<h2 id="human-dates-and-times-chrono">Human dates and times – <code>chrono</code></h2>
<p>Rust’s <code>std::time</code> doesn’t really handle calendar or wall-clock times, just arbitrary, monotonic <code>Instant</code>’s and measurable <code>Duration</code>’s between them. Nice, pure, computationally-robust time measurement. For all the nasty human calendar and timezone stuff, you use <code>chrono</code>. (And maybe <code>humantime</code>, but I personally reach for <code>chrono</code> first, just out of habit.)</p>
<h2 id="bit-flags-bitflags">Bit flags – <code>bitflags</code></h2>
<p>Defining type-safe bit-masks in a reasonably convenient way. Not always worth the trouble, but sometimes pretty convenient.</p>

<p>“I have to create or read a…”</p>
<h2 id="pngjpeggifetc-image">PNG/JPEG/GIF/etc – <code>image</code></h2>
<p>General-purpose loading and saving and images, which can handle a lot of formats. Can do some amount of image manipulation as well, such as cropping, smoothing, etc. but that will hopefully be pulled out into its own library at some point soon.</p>
<h2 id="small-data-things-uuid-base64-csv-semver">Small data THINGS – <code>uuid</code>, <code>base64</code>, <code>csv</code>, <code>semver</code>…</h2>
<p>Exactly what it says on the tin.</p>

<p>Not aware of any great encoders, but there’s plenty of <em>decoders</em> for common audio formats. <code>lewton</code> for Ogg Vorbis, <code>hound</code> for .wav, <code>minimp3</code> for MP3, <code>claxon</code> for FLAC. Video, I haven’t used enough to have an opinion on.</p>
<h2 id="config-files-toml">Config files – <code>toml</code></h2>
<p>For all your config file format needs. Works with <code>serde</code>, naturally.</p>
<h2 id="markdown-pulldown-cmark">Markdown – <code>pulldown-cmark</code></h2>
<p>There’s several good Markdown readers and writers, <code>pulldown-cmark</code> is my favorite. It supports CommonMark, it’s simple to use, and it’s pure Rust.</p>
<h2 id="templating-askama">Templating – <code>askama</code></h2>
<p>There’s several quite good text templating engines, but <code>askama</code> IMO rises above them all by compiling your templates into Rust code and type-checking your templates at compile time. Sometimes this isn’t what you want, but it is a great feature surprisingly often. This also makes it super fast, for when you really need to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/RustStarterKit2020">https://wiki.alopex.li/RustStarterKit2020</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/RustStarterKit2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671403</guid>
            <pubDate>Sat, 03 Oct 2020 12:04:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where is my electric bike for the mind?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24671237">thread link</a>) | @adam_fallon_
<br/>
October 3, 2020 | https://adamfallon.com/2020/08/25/where-is-my-electric-bike-for-the-mind/ | <a href="https://web.archive.org/web/*/https://adamfallon.com/2020/08/25/where-is-my-electric-bike-for-the-mind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://adamfallon.com/2020/08/25/where-is-my-electric-bike-for-the-mind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671237</guid>
            <pubDate>Sat, 03 Oct 2020 11:19:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from studying Shaolin Kung Fu in China]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24671229">thread link</a>) | @flreln
<br/>
October 3, 2020 | https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><em>The last piece of hair fell on the floor.</em></p><p><em>My head was shining like a moon.</em></p><p><em>“Tomorrow, I’ll be in China.”</em></p><hr><p><strong><strong>In the first week of June, I was stuck.</strong></strong></p><p>We desperately needed to come up with a startup idea. Our company was in free fall, and I had to do something about it.</p><p>But I couldn’t.</p><p>I spent weeks trying to figure it all out in my head. Every day, we would sit for hours in the office. Trying to understand what we really want to work on. Brainstorming ideas. Nothing worked.</p><p>I had the idea to take some time off for a while. But I never really explored it. I’ve always believed the only way to solve a problem is to start working on it. A mere thought of lying on a beach all day long and doing nothing caused physical pain in my head.</p><p>After a few weeks of struggle, I accepted that we’re not moving anywhere.</p><p><strong><strong>I needed a change.</strong></strong></p><p>I used to do martial arts as a kid. I remember when I first read about Shaolin. I was amazed. It seemed like something sacred, unreal to me. Very distant, but also very close in some way.</p><p>I remember begging parents to allow me to go there and train with monks.</p><p><em>“You’re out of your damn mind!”</em></p><p>I’m not blaming them; I’d probably tell my kids the same.</p><p>But now I had no excuse.</p><p>I decided to fly to China and study Kung Fu at The Shaolin Temple.</p><figure><img src="https://lh3.googleusercontent.com/Q3pS6-bIyhrxVRndWfaux_yN_-PJBPebn2jwQJHImjIMygREWwyR3Wc8w0kILJgijhjt0r-d4BIdoeT3qsZO7VEfvQpbh5pVHakdASf1Q03R6s4clJWAUA0EjgxqNDkCdRKFH1ek" alt=""></figure><p>The Shaolin Monastery is like Mecca for Buddhists.</p><p>It’s a mysterious place where monks live, train, and meditate.</p><p><em>Some of them never leave the temple.</em></p><p>And while you can visit the temple as a tourist, there’s no way for a stranger to get into the private part of the monastery, where real monks train. There’s no website where you can apply. No email address.</p><p>But I had a plan.</p><p>I decided to find a martial arts school in Dengfeng, which is a small town 12 km from the temple. My idea was to get to Dengfeng, and then try to meet some younger monks from the temple and beg them to death to let me in.</p><p>After a few days of research, I found a school that seemed reasonable and applied.</p><figure><img src="https://lh6.googleusercontent.com/YDuca6U-Xj9WUbeyshjgYpN2oWYZXvEXofbvILQW7t-j-FljoSA9TjA_S3LTvOHsMWiiltMTuraj13qtDORfzWvbY_nxeqM6fI6xt_5bRC4wVUUuIYjFu-gBo6lLeZZFXbXzfbRz" alt=""><figcaption>Shifu and students. And his kid.</figcaption></figure><p><em>“Unfortunately, we’ll not be able to enroll you. We’re shutting down.”</em></p><p>That’s what I heard from the school 24 hours before the flight.</p><p>I frowned.</p><p>Finding this school was tough. There are hundreds of fake “Shaolin Kung Fu” schools in Dengfeng. They’re making money off the Shaolin brand, but there’s no real, authentic, hard training involved.</p><p>Getting another good one to accept me over night seemed impossible. But I kept looking.</p><p>I was looking for something original and challenging. And all Kung Fu schools I’d seen before were like holiday camps.</p><p>A few hours later, serendipity kicked into play.</p><p>I found a YouTube video from a former Xing Long student. I loved it. I went on their website and smiled.</p><p>The website said:</p><p><strong><strong>“Our school is not a holiday retreat.”</strong></strong></p><p>On a warm night of June 14th, I landed in Beijing.</p><figure><img src="https://lh3.googleusercontent.com/Ku0IQGnR2GgIWEcrPMlgo-wFYzrsanZT3agAhjOq95QJNZmS9Axi2I1MxXmN6KBHi_bmHD50q7RsO96dWnjovN83jDGHhEIxKdsCf1X3sgntgTe16-EmsHXw3DmGMWNzPWdNWwrn" alt=""><figcaption>4:30 a.m. Meeting the dawn at a Beijing Railway Station.</figcaption></figure><p>When I arrived in Beijing, I still hadn’t heard from Xing Long.</p><p>But I had no choice. I was in China, and coming back was not an option. So I bought a train ticket and embarked on 600 km journey to northern China.</p><p>After six hours of slumber in the high-speed train, I was in Siping.</p><p>At the exit of the train station, three students of Xing Long waited for me with a welcoming sign, “Vasili Shynkarenka.” They drove me to school.</p><p>That’s when I met the Master for the first time.</p><figure><img src="https://lh3.googleusercontent.com/TDkN2V3FfpErJtZ5GeLWTX__0T2KMX_dKy1xq40UENQN6OiQUEgQ3JW4jE-mfU5ECQwI4TDTflt5wuf2lz6IlbswXzhZ2bdmKpH09BsWQYqPA8nGsR9vPe6v70TcWczFbhI4DO-M" alt=""></figure><p>Shifu is 5”2, fast as a jaguar, has a bone-crushing handshake and dark brown eyes that look right into your soul.</p><p>He once tore off someone’s shoulder with bare hands.</p><p>At 12, he already trained in Shaolin.</p><p>Shifu turned pro after seven years. He started competing professionally, won the famous “Kungfu King” tournament, and achieved the rank of a 7th-degree master at 19.</p><p>And then he broke his back. It was a full-contact sparring match, and he cracked his fourth vertebrae.</p><p>Doctors said he wouldn’t be able to walk ever again. Shifu made a full recovery in six months.</p><p>He couldn’t return to professional fighting, but life without Kung Fu was not an option to him.</p><p>He began teaching.</p><p>His vision was simple:</p><p><strong><strong>“To spread classic Shaolin skills throughout the world.”</strong></strong></p><p>To achieve that goal, Shifu had to learn English. He worked hard for 18 years, and he speaks almost fluently now.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/image.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/image.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/image.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/image.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/image.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Me and Shifu Wang.</figcaption></figure><p>Shifu believes that Shaolin Kung Fu is not just a martial art from Jackie Chan movies.</p><p>In its origin, Kung Fu refers to any discipline achieved through hard work. Anything that requires patience, energy, and time to complete. And once you learn it in martial arts, you can transfer this knowledge to other domains.</p><p>He is also a great thinker. I saw him reading Meditations from Marcus Aurelius once. That’s the kind of teacher I needed.</p><p>The Shaolin Temple has become fancy.</p><p>More tourists. More noise.<em> Less signal.</em></p><p>Three years after opening his first school near the temple, Shifu moved to the northern province of Jilin.</p><figure><img src="https://lh4.googleusercontent.com/58E2EatlNlHjmGt-l9A8bY4nSm_Q7xixee-35sXFc3LmT6oeERgxi9cerT_jz152153YHAHvHryr1r6j2JVma4dZ-ZiMqHFTrPpqk-AInBJONHGqlm_xQQR2U41raPCAjhp1mDMf" alt=""><figcaption>Hills near the school in winter.</figcaption></figure><p>Xing Long school is located on a small farm in the countryside.</p><p>There's one large training hall, full of equipment and dried sweat.</p><p>Second training hall in the back. It's used during the winter when the temperature drops to -15. During the summer, training takes place outside for much of the time.</p><figure><img src="https://lh3.googleusercontent.com/AG-Mtzr8srM4SnborSx51QdOWh_pqXEQz_KhXKezlcjDahDwrUQq8o3d4OyhsVo2vZWK0mDRn2Mi2e4rp1d-Z1EP6nZePJSBU8jMZpCXEyfw-hv_XUFRkafctSEcVy9B9rURRqjj" alt=""></figure><p>When I arrived, there were 12 students at the school.</p><p>During the year, this number varies from 5 to 15. Having a small group helps Shifu to dedicate enough time to each student, but also make sure there’s a lot of practice for everyone.</p><p>People all over the globe came to China to study Kung Fu. Explorers; seeking for something deeper than living in the Matrix.</p><p>Some of them, like Matt, had been at the school for six years already.</p><figure><img src="https://lh5.googleusercontent.com/_MkifjL76syDHa6wuUXWJXHu2EkaEh9vXg6a-aAPWoZvveQmQemDcwyjDH6cnBEZWXcMsN1LcyGL-u3tML98ZCwW4H145ubkG7JQaPeMYuuIgiu0r2s_MOrePSaBbHYo9FvWzVp1" alt=""></figure><p>I was surprised by how diverse, open, and curious students were.</p><p>We had a scientist who worked on quantum computing, a famous reporter from Hollywood, and a primary school teacher.</p><p>We spent hours at the dinner table talking about everything from farming to teaching to space.</p><p><strong><strong>It felt like a brotherhood.</strong></strong></p><h2 id="training">Training</h2><p><em>It was the final lap of 45 degrees uphill mountain running.</em></p><p><em>My legs were destroyed. I barely strolled. The sole purpose of my existence came down to two words:</em></p><p><strong><strong><em>“Don’t. Stop.”</em></strong></strong></p><p><em>I questioned myself a thousand times.</em></p><p><em>“Why are you doing this to yourself? What’s the purpose? Why don’t you just walk the rest of the run?”</em></p><p><em>And then it hit me:</em></p><p><em>“Because that’s who I am.”</em></p><p><em>I kept running.</em></p><hr><p><strong><strong>Every day we had six to eight hours of Shaolin training.</strong></strong></p><p>We woke up at 5:30. At 5:50, we lined up.</p><p><em>“Go, running!”</em></p><p>We ran for about three miles uphill and then stretched for twenty minutes.</p><p>After the warmup was done, we had Tai Chi.</p><p>Tai Chi is like action movies in slow motion. It’s a very steady motion, supported by breath control.</p><p><em>“If you want to go fast, you need to go slow first.”</em></p><figure><img src="https://lh5.googleusercontent.com/0-mClkSOHm5SmigJFL4YlvMSlici0u11ghqBVSPZas9SVRcif6z3O07H_3jq7DGTmoZp5crsLOpgORG42BApwhJ1XIHUiah69_vozhQBUzLchxNWc45lhTRH3MO5zZFY2iy-1_TB" alt=""></figure><p>Soft movements helped us to recover our energy faster, heal sore muscles, and release body tension that accumulated throughout the previous day. After eight hours of hard training every day, Tai Chi was saving my life.</p><p>Here’s a little video I made of Johny and Emilian doing 42 Tai Chi Steps:</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/Rjyy-ocBgPw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>After an hour of Tai Chi, we had breakfast and an hour of rest.</p><p>At 8:30, the morning training started.</p><figure><img src="https://lh5.googleusercontent.com/fryF8-kmO3Ex0tAuFiY1KEAK5iEgjujjxZc4F1qbOi3lJO4_LKeY5ySm6twt_5rUxRrAD4jPOSCgnqtupbjKQQ6qCqHbsRhRUkvNUu1c9HxxMaecVkP7PL10SkbD9snpD39eEYmw" alt=""><figcaption>Shifu is always watching.</figcaption></figure><p>Every morning we practiced forms.</p><p>Forms are like shadow boxing.</p><p>It’s a very ancient set of techniques arranged in patterns. Each form is a sequence of sets, and each set is a sequence of movements. You go from small moves, like striking with a left fist, to a five-minute-long combination of strikes, turns, and jumps.</p><p>Shaolin monks designed forms by contemplating animal behavior for hundreds of years. Some forms are even called this way: The Monkey, The Dragon, or The Snake.</p><figure><img src="https://lh5.googleusercontent.com/JxoTjcgR4mGCvXH3tAjhVJChFnNQsz5N8soW-1KCXdzTO3dsNsAoR5onqolr8TVnqSLjmTjHcZ8h7RA9BJdJ5rlkMEknrOooKwkHYY2lWokTvMnfBKQNhJmItLy63Im6FpFxN61M" alt=""><figcaption>Shifu and Matt are doing forms. Weather is for puppies.</figcaption></figure><p>Forms help to develop strong footwork and learn striking.</p><p>When you practice long enough, you unconsciously start using individual movements, sets, and sequences in a real fight.</p><p>The morning training finished at about 12, and then we had lunch and an hour of rest.</p><p>At 2:30, the afternoon training began.</p><hr><p>After one week of basic training, I started doing Sanda.</p><p>It’s a form of kickboxing, which allows you to learn all basic punches, kicks, and combinations.</p><p>Sanda is how you actually use your Kung Fu in practice.</p><figure><img src="https://lh6.googleusercontent.com/IHJDa_jIjoyU1_lO7HJHEYK0myxQxDlC3aefu0hqeoUUI-s4meG0oTVTFskOR2eGY_B0rKNXUAJEZRNThqafevN1X8NvGsqC0iUs3lRBBKrP9aJ5922f8o2JHppGgIyWGwxGgr5-" alt=""></figure><p>Three times a week, we had power training, like doing burpees for two miles.</p><p>Or “lizard moves,” when you literally crawl uphill for half a mile.</p><p>It sucked.</p><p>But that’s where the spirit was sprouting.</p><figure><img src="https://lh3.googleusercontent.com/m3CeUeqcgH5xhIHnCqaEP03POcCrWiE3b2-K2y3pUWjw1c27O_Ri8r3E6q3cNjSjEEJJuDAwy7LsR_BXoaUHZsdjLB9CMI8eJvCQGNBvNVh0K-YHise92tVEQOwokKp95UFBoTrG" alt=""></figure><p>After dinner, we had Qigong.</p><p>Qigong is a standing meditation. You freeze in a stance and focus on breath control. No movements for ten minutes. Then you change the position.</p><p>I thought I was fit. I wasn’t for Qigong.</p><p>I couldn’t stand still for more than two minutes in a horse stance. My sore legs were in agony.</p><p>But after a week it began to work. Minutes began adding up. I’m still not sure how exactly Qigong heals sore legs, but in two weeks I was able to stand in the horse stance for 10 minutes. Soreness was gone.</p><figure><img src="https://lh4.googleusercontent.com/2k2dWL0iLqSWl-wt3PJ-cyVc20GzEdon4Utf_KEBUiu2KgMG-mRf7BrrCUC7VMFBj_Ogpcj8okPESE1bKP7WMkT6D-IqvJvJlVrxkGTE3woVp77xjMg8mp9eFV3oCznnvMy1tsG9" alt=""></figure><p>Every Friday, we had power stretching.</p><p>It was torturous.</p><p>We ran five miles uphill first. Then we stretched for about twenty minutes. And then power stretching began.</p><p>Shifu was assisted by one student. I laid on the floor, and the guy sits on my knee, so I couldn’t move. Shifu took my leg and started moving it up to my head, in short, swaying movements.</p><p>He didn’t stop.</p><p>That’s when I learned what the pain really is.</p><p>When you scream. When you cry. When you’re short of breath and can’t scream anymore.</p><figure><img src="https://lh6.googleusercontent.com/RtCJUFKTbQ9g2J9GfTsI7Q3d2BakfDFs13jGok3XrptKQyMs-bRRVLBWDdMAJQM3oW4YjKZozVaIQnbL5j9DJFu3T6GiInGPhWM-SuZiiD87dgNzSSr9csWTfWASS2mnktrtqBVL" alt=""><figcaption>Shifu helping a student to go beyond his limits.</figcaption></figure><p>Don’t get me wrong; Shifu knows his stuff. But knowing that he won’t tear your legs apart is not making the process more enjoyable.</p><p>Over time, I learned to accept the pain. To breathe. To let go.</p><p>And that’s when I felt the power of it. In two weeks, I came closer to transverse twine than in two years of doing my own stretching.</p><h2 id="lessons">Lessons</h2><figure><img src="https://lh4.googleusercontent.com/ceI7ZAs0TekQcVP0mhN_wLS5CRf_xQnuhznYV2flXbqAeHtWVENNoHmKGZJNjB9F6yoRcYSni94uJDxmA0LQ308vg2ZmRZ4QYC8i3zRegHznhB_oKM7W_UZKvo6WYh5URIX9NcUE" alt=""></figure><p><em>Lunch was over.</em></p><p><em>I went to my room and fell on the bed. I was exhausted.</em></p><p><em>Suddenly, the thoughts started pouring in my head.</em></p><p><em>The mental fog was gone. I knew what I needed to do.</em></p><p><em>I saw the forest for the trees.</em></p><hr><p>Three weeks in, I figured out that I want to work on longevity.</p><p><strong><strong>Not just figure …</strong></strong></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/">https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671229</guid>
            <pubDate>Sat, 03 Oct 2020 11:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The truth about ferrites]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24671225">thread link</a>) | @lightlyused
<br/>
October 3, 2020 | https://qrm.guru/the-truth-about-ferrites/ | <a href="https://web.archive.org/web/*/https://qrm.guru/the-truth-about-ferrites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1430">
          
         <!-- .entry-header -->
         
       <!-- /.entry-header -->
       
       
       <div>
        <p><em><strong>These tests and experiments were performed by Ian Jackson VK3BUF in the QRM Guru test lab.</strong></em></p>
<div class="page" title="Page 1">
<div>
<p>Much has been said about the importance of applying ferrite clamps, rings and beads to radios and other domestic products to fight QRM.</p>
</div>
</div>
<p>Articles on the correct placement of ferrite noise suppressors are common, but little has been written about the different options and where to buy them. &nbsp;In Australia, there are only a limited number of suppliers that carry stock.&nbsp; Ferrite size, shape and cost varies significantly.&nbsp; The information provided can be minimal or non-existent.&nbsp; Part numbers for ferrites listed in international catalogues are not generally available in Australia and buying these can entail long lead times and high freight costs.</p>
<p>Often we don’t really know what we’re getting and how effective they will work for us when they finally arrive.&nbsp; From this perspective, buying and using ferrite filters seems to have more in common with black magic than the application of radio science.</p>
<ul>
<li>How do I know if the ferrites I purchased are good, bad or totally ineffective?</li>
<li>Do I get what I pay for? &nbsp;Are expensive ferrites much better than cheap ones?</li>
<li>How can I tell if one ferrite is enough?&nbsp; Are 2 or 3 together really worthwhile?</li>
<li>What are the advantages of clamps over beads and rings?</li>
<li>Are big and heavy ferrites better than lightweight and small ones?</li>
<li>How far up the radio spectrum are these things going to work for me?</li>
</ul>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-3.jpg" alt="" width="243" height="218" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-3.jpg 832w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-300x270.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-768x690.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-60x54.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-3-150x135.jpg 150w" sizes="(max-width: 243px) 100vw, 243px">Ferrites are a type of ceramic made from iron and other oxides and come moulded into different shapes.&nbsp; The material combination &nbsp;is called a ‘mix’.</p>
<p>The characteristics of these mixes determine where and how they should be used.&nbsp;&nbsp; When a wire passes through or near ferrite materials, it effectively adds resistance to that wire at radio frequencies, but this resistance effect varies with the frequency applied to the wire.</p>
<p>Every ferrite has its own characteristic impedance curve allowing it to absorb unwanted RF currents before reaching your receiver or appliance.</p>
<p>Unfortunately, you can’t tell what that working curve is going to be just by looking at it.</p>
<p>For this experiment, we purchased sample ferrites from the Australian retailers Jaycar and Altronics.&nbsp; We compared these with samples of similar size from the QRM Guru ferrite kits, then further compared all of these with some cheap ‘no-name’ ferrites purchased from eBay.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-4.jpg" alt="" width="800" height="460" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-4.jpg 800w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-300x173.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-768x442.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-60x35.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-4-150x86.jpg 150w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>Testing methodology is important.&nbsp; We used a spectrum analyser with a tracking generator.&nbsp; The spectrum analyser shows gain or loss of radio frequencies between any two points on the radio spectrum.&nbsp; Our unit has capability to scan the radio spectrum from 10KHz to 1.5 GHz, but in this trial, we profiled these ferrite devices between 100KHz and 450MHz.</p>
<p>The tracking generator creates a small signal that regularly sweeps between two frequencies we are monitoring at a very controlled level.&nbsp; We are then able to couple from the tracking generator to the spectrum analyser via a small brass rod, which will become our test wire.&nbsp; First we&nbsp; ‘<strong>normalise’</strong> to compensate for any stray capacitance and inductance around our test area.&nbsp; A flat yellow line represents zero dB.&nbsp; This line becomes our reference point before filtering is added.&nbsp; When any unknown ferrite is added to the test conductor, we measure a clear plot showing the unique characteristics of that item.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-5.jpg" alt="" width="985" height="509" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-5.jpg 985w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-300x155.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-768x397.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-60x31.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-5-150x78.jpg 150w" sizes="(max-width: 985px) 100vw, 985px"></p>
<p>With this arrangement we examined a graphic plot of each sample, then recorded five unique values which identify its effectiveness.&nbsp; We looked at :</p>
<ul>
<li>(<strong>A</strong>) The <strong>lowest</strong> frequency where the item drops below the -3dB (half-signal) point.</li>
<li>(<strong>B</strong>) The <strong>highest</strong> frequency where the curve crosses the -3dB point</li>
<li>(<strong>C</strong>) The frequency (<strong>MHz</strong>) where the greatest attenuation takes place</li>
<li>(<strong>D</strong>) The maximum degree of <strong>attenuation</strong> (peak –dB) that takes place.</li>
<li>(<strong>E</strong>)&nbsp; The <strong>weight</strong> of each ferrite item.&nbsp; (in grams)</li>
</ul>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-7.jpg" alt="" width="932" height="360" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-7.jpg 932w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-300x116.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-768x297.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-60x23.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-7-150x58.jpg 150w" sizes="(max-width: 932px) 100vw, 932px"></p>
<p><strong>Not all characteristics are being tested here</strong></p>
<p>It should be noted that this article is focused on using ferrites for noise reduction only.&nbsp; In this role the energy being absorbed is not great.&nbsp; Where ferrites are used in high-current environments, such as in a transmitter balun, there will be an RF power threshold where they can no longer effectively absorb energy and their characteristics will begin to distort.</p>
<p>The overheating and saturation effects of high current applications are not a part of this study.</p>
<h2><strong>Study Results</strong></h2>
<p>The table below contains the raw results of our assessment, grouped in order of supplier, then size. &nbsp;The figures can be difficult to digest in this form, but we can take away some very important findings from this test data.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-8.jpg" alt="" width="900" height="459" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-8.jpg 900w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-300x153.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-768x392.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-60x31.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-8-150x77.jpg 150w" sizes="(max-width: 900px) 100vw, 900px"></p>
<h2><strong>Branding vs Price</strong></h2>
<p>The first significant observation is that they all worked.&nbsp; Regardless of the source, none of the samples tested were fake or defective.&nbsp; They were all capable of suppressing radio frequencies to a greater or lesser degree. &nbsp;This is reassuring, as you can never prove authenticity just by looking at a ferrite.</p>
<p>From these samples, we can surmise that regardless of their source, all of these clamp-on ferrites will provide at least some degree of effectiveness in the shack.</p>
<h2><strong>Ferrite Mixture Type</strong></h2>
<p>The next observation (with the exception of the Altronics Iron Core ring) is that all of these materials are composed from a similar mix of ferrite material.&nbsp; The absorption curves were all a reasonable match to <strong>Mix 43</strong>.&nbsp; This indicates that their application is appropriate for HF and low VHF frequencies.&nbsp;&nbsp; (The Altronics ring L4534A was purchased with the rest of the ferrites, but it does not qualify as a ferrite device.&nbsp; It is a powdered iron object with different characteristics.&nbsp; We left it in the test for contrast and will provide separate comment on these devices.)</p>
<h2><strong>Size vs weight correlation of ferrite clamps</strong></h2>
<p>Clamp-on ferrite devices come in a variety of different physical sizes and shapes.&nbsp; It is reasonable to think that bigger ferrites work better than smaller ones, but is this actually the case?&nbsp; We sorted our samples by weight and plotted this chart to see how closely the degree of absorption of RF energy followed the physical weight of each sample.</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-9.jpg" alt="" width="874" height="242" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-9.jpg 874w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-300x83.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-768x213.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-60x17.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-9-150x42.jpg 150w" sizes="(max-width: 874px) 100vw, 874px"></p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-10.jpg" alt="" width="326" height="267" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-10.jpg 481w, https://qrm.guru/wp-content/uploads/2020/02/Image-10-300x246.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-10-60x49.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-10-150x123.jpg 150w" sizes="(max-width: 326px) 100vw, 326px">The answer appears to be”partially yes”.&nbsp; Generally, heavier ferrites will out-perform lighter versions, but there were a couple of exceptions that did very well.</p>
<p>The <strong>Altronics</strong> solid ring <strong>L4534A (A3) </strong>outperformed clamps of similar weight, as did the <strong>Jaycar</strong> <strong>LF1294 (J2)</strong>.&nbsp; Both are circled in red in the chart above.</p>
<p>There is a correlation between ferrite effectiveness and wall thickness.&nbsp; Both circled examples had a relatively small internal wire opening, which made for a thicker clamp wall.&nbsp; This equates to a higher density of ferrite material around the single conductor, giving superior performance.</p>

<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-11.jpg" alt="" width="321" height="203" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-11.jpg 425w, https://qrm.guru/wp-content/uploads/2020/02/Image-11-300x190.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-11-60x38.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-11-150x95.jpg 150w" sizes="(max-width: 321px) 100vw, 321px">Conversely, sample <strong>E1</strong> from eBay was a physically large clamp, but it catered for a thick 12mm cable.&nbsp; This thinner wall thickness reduced effectiveness, as seen by the data point circled in yellow on the chart above.</p>
<p>This effect is not as bad as it first seems, so don’t necessarily shop only for thick-walled clamps.&nbsp; Examine some of the following sections in this article which explore the most effective ways to use ferrite clamps.</p>
<p>The final comment on the size of clamps was the observation that the very small clamp-on ferrites don’t have sufficient mass for good performance.&nbsp; The smallest of the eBay clamps (<strong>E5</strong>) didn’t even reach -3dB.&nbsp; Unless a friend gives you a lot of them for nothing, there is a lot to be said for aiming straight for medium and large clamps, or the results could be disappointing.</p>
<h2><strong>Are solid ferrite rings better than split rings?</strong></h2>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-12.jpg" alt="" width="335" height="209" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-12.jpg 552w, https://qrm.guru/wp-content/uploads/2020/02/Image-12-300x188.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-12-60x38.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-12-150x94.jpg 150w" sizes="(max-width: 335px) 100vw, 335px">This turned out to be an easy question to answer.&nbsp; Two rings of similar weight, hole-size and ferrite mix were compared.&nbsp; One was solid and the other was split.</p>
<p>The results were almost identical when tested.&nbsp; This tells us that shopping for solid cores have no real advantage over split cores.&nbsp; However, the split ferrites can be applied to cables without having to remove connector plugs and this makes them a more practical purchase.</p>
<h2><strong>What’s the best way to use ferrites?</strong></h2>
<p>An important question to answer is “<em>what is the optimum configuration for the application of ferrite clamps</em>“.&nbsp; It’s easy to imagine that two clamps are better than one, but how much better?</p>
<p>For this exercise we focused our attention on the QRM Guru clamps (<strong>Q2</strong>) designed for 8mm wire.</p>
<p>Compare the following screen captures and images of one and two clamps:</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-13.jpg" alt="" width="1173" height="435" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-13.jpg 1173w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-300x111.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-1024x380.jpg 1024w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-768x285.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-60x22.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-13-150x56.jpg 150w" sizes="(max-width: 1173px) 100vw, 1173px"></p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-14.jpg" alt="" width="1164" height="429" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-14.jpg 1164w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-300x111.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-1024x377.jpg 1024w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-768x283.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-60x22.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-14-150x55.jpg 150w" sizes="(max-width: 1164px) 100vw, 1164px"></p>
<p>Unsurprisingly, doubling up on the clamps gives an additional 3dB of RF absorption.&nbsp; At <strong>55 MHz</strong> the peak absorption jumped from <strong>-4.40 dB</strong> to <strong>-7.54 dB</strong>.&nbsp;&nbsp; This tells us that if one clamp on its own does not quite do the job, then add another for improved performance.&nbsp; Be aware that to achieve a further 3dB, you must double again from two to four units.</p>
<p>Next, we explore the effectiveness of looping a wire through a clamp more than once.&nbsp; This can only work where there is sufficient slack in the cable, and where the hole in the core is large enough to accept additional turns.</p>
<p>Here is what happens:</p>
<p><img loading="lazy" src="https://qrm.guru/wp-content/uploads/2020/02/Image-15.jpg" alt="" width="1151" height="458" srcset="https://qrm.guru/wp-content/uploads/2020/02/Image-15.jpg 1151w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-300x119.jpg 300w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-1024x407.jpg 1024w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-768x306.jpg 768w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-60x24.jpg 60w, https://qrm.guru/wp-content/uploads/2020/02/Image-15-150x60.jpg 150w" sizes="(max-width: 1151px) 100vw, 1151px"></p>
<p>This is a very interesting result showing that the single extra turn through the core increases absorption from -4.4dB to a huge -12.41 dB.&nbsp;&nbsp; This 8 dB increase makes a single clamp provide the same effectiveness of around six such clamps on the same wire.</p>
<p>Want to see some case studies covering off the use of ferrites?&nbsp; Click on the links below</p>
<h2><strong>Why adding turns makes ferrites much more effective</strong></h2>
<p>This effect is not really a mystery when we break down what’s happening.&nbsp; When we add ferrite to a wire, we are effectively adding series resistance to that wire, but this resistance effect varies with frequency.&nbsp; At steady DC, the ferrites have no effect, but as an AC signal is applied a resistance is developed within the wire surrounded by the ferrite material.&nbsp; The higher the frequency, the greater the increased resistance.&nbsp; This resistance is also affected by the type of ferrite material, its volume, and its distance from the wire concerned.</p>
<p>When we …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qrm.guru/the-truth-about-ferrites/">https://qrm.guru/the-truth-about-ferrites/</a></em></p>]]>
            </description>
            <link>https://qrm.guru/the-truth-about-ferrites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671225</guid>
            <pubDate>Sat, 03 Oct 2020 11:16:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Last Meeting – Bill Atkinson and HyperCard (1987)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24671101">thread link</a>) | @amichlin
<br/>
October 3, 2020 | https://blog.ceos.io/2020/10/03/last-meeting-bill-atkinson-and-hypercard/ | <a href="https://web.archive.org/web/*/https://blog.ceos.io/2020/10/03/last-meeting-bill-atkinson-and-hypercard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-111">

	

	
	<div>
		
<figure><img loading="lazy" data-attachment-id="120" data-permalink="https://blog.ceos.io/hypercard/" data-orig-file="https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 8&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1601706870&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;40&quot;,&quot;shutter_speed&quot;:&quot;0.0083333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="hypercard" data-image-description="" data-medium-file="https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=300" data-large-file="https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=750" src="https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=1024" alt="" width="211" height="158" srcset="https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=211 211w, https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=422 422w, https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=150 150w, https://blogceosio.files.wordpress.com/2020/10/hypercard.jpg?w=300 300w" sizes="(max-width: 211px) 100vw, 211px"></figure>



<p><em>Guest blog post by <a href="https://lanebc.com/about/">Jay Michlin</a>, circa 1987 (used with permission). A recounting of a presentation by <a href="https://en.wikipedia.org/wiki/Bill_Atkinson">Bill Atkinson</a> at the <a href="https://www.pa-smug.org/">Stanford Macintosh User Group (SMUG)</a> </em></p>



<p>HyperCard. Bill Atkinson. The auditorium was packed and everyone stayed until the end.<br>What more need be said?</p>



<p>I considered stopping this month’s report right here, because the first paragraph already<br>tells volumes. But I never learned to quit while ahead, so here’s more. Specifically, I’m going to try to explain what HyperCard is, both as Bill described it and as I see it. As you’ll see, my perspective is somewhat different.</p>



<p>Bill said that HyperCard tries to make more of the power of a personal computer available to nonprogrammers. There’s plenty of goodness in using a computer for word processing, spreadsheets and other applications. But to unlock the real power, you have to program, and that’s very hard. HyperCard delivers a lot of the power of programming, but with minimal burden.</p>



<p>Or, you can look at the matter another way. Before HyperCard, the Mac had documents and applications. Documents contain information, but by themselves offer no opportunity for interaction with you. Applications offer interaction, but do not contain information. HyperCard stacks are in between, with a combination of both information and interaction inherent in them.</p>



<p>Or, you can think of HyperCard as a software erector set. It comes with a kit of tools, a set of instructions and lots of parts. Like an erector set, it has one more thing — examples. When you first get the set, you build copies of the ex amples. Then you change a few small details. Eventually you become comfortable with the tools and the parts and start using it fluidly to express your own, original ideas. In the same way, HyperCard comes with dozens of sample stacks. They’re not an afterthought. They’re an integral part of the product, intended to help you use it immediately and learn it quickly.</p>



<p>Here’s what I think. HyperCard is the latest in a long list of “languages” that seek to make<br>computers easy to program. The need is not new, the idea is not new and the solution is not new. What’s special about HyperCard is that it’s brilliantly executed. Biil obviously spent a lot of time thinking and learning about his task before, during and after sitting down to code.</p>



<p>Let me explain. For the early computers there were no such things as “canned” applications like word processors and spreadsheets. Everyone was a programmer. There was no choice. Then, in the 1960’s, timesharing was invented. The primary external feature that made timesharing different was that it supported users interacting with the computer at terminals.</p>



<p>But the users still had to program if they were to get the machine to do anything, As terminal access to timesharing became more widespread, especially on college campuses, everyone understood that programming was a barrier. So they invented BASIC.</p>



<p>Perhaps you thought that BASIC always was as it is today on personal computers. It wasn’t. It was expressly designed to help college students get over the programming barrier on early timesharing systems. It did that in a number of ways:</p>



<ul><li>It was interpretive. Users could type a command and get instant results printed on the terminal. It’s an elementary fact of life that we learn better if we have quick, useful feedback. </li><li>It made simple things simple. To print something on the terminal, you said, “PRINT.” There was no need to tell the computer how to find the terminal or what the printing format was to be. </li><li>It was small in that it had very few statements and options defined. Of course, that was partly because the computers and translators of the time would have struggled to give quick response on a complicated language. But even when more features were added, they remained in the background, invisible to novice users who don’t need them. </li><li>It came with clear, obvious examples, either as part of a college course or in a manual. You learned to write BASIC by trying the examples. BASIC worked. It helped a generation of college students learn to use computers. Later, it was the primary offering on commercial timesharing systems from Tymshare and General Electric. And most recently, it helped launch the personal computer revolution. It wasn’t so long ago that to use a personal computer at all, you had to program.</li></ul>



<p>Personal computers and their application software have grown sophisticated so fast that we easily forget that computers and programming go together. It’s tempting to say that to- day, in the modern era, programming is no longer needed. We all just go to Computer Ware and buy whatever package we need to make our machines do anything.</p>



<p>For many, perhaps that is true. But Bill Atkinson, and Apple are saying that you still need the opportunity to program to tap the underlying power of your computer. HyperCard will be the BASIC of the modern era, with possibly as profound an effect on the future as BASIC has had up to now.</p>



<p>Those are my words, not Bill’s. But I wouldn’t be surprised if he agreed.</p>



<p> * * * *</p>



<p>In case you missed the meeting, here are some details. Bill wasn’t there alone. Dan Winkler, who created HyperTalk, HyperCard’s internal scripting language, was also present. So was Danny Goodman, who wrote the book. Also Kristee Kreitman, who did the artwork (of which there is lots), Robin Shank, who helped do the testing, and Mike Holm, the Product Manager.</p>



<p>As an aside, this is an interesting illustration of the difference between a modern business enterprise and one from the last generation. A modern corporation values the natural benefits to all concerned when employees from all parts of the organization go out and meet customers. A more traditional corporation sends out only carefully prepared marketing teams.</p>



<p>Anyway, Bill demonstrated HyperCard and talked about the philosophy behind it. Then Dan told us about HyperTalk. He showed it to be a powerful, yet well-behaved language. Despite the fact that it underlies much of what goes on in HyperCerd, HyperTalk remains invisible be- hind the scenes if you don’t need or want to know about it.</p>



<p>Then Danny told us about two stacks he designed and is now selling commercially. The first, Business Class, presents a map of the world. Click anywhere and you can learn about language, currency, time zones, air travel and other important conditions. The second, Focal Point, is a very generalized and very interactive desk calendar and diary. Both are implemented as HyperCard stacks.</p>



<p>Incidentally, when you buy a HyperCard stack, you can copy and modify it the same way you can manipulate the example stacks that come with HyperCard itself. Apple’s whole approach is to make HyperCard a common tool, and stacks a common medium that people exchange and build on.</p>



<p>Finally, here are a few miscellancous points our guests made in response to questions.</p>



<p>HyperCard is roughly 360K of code, nearly ten times the sum of Bill’s original MacPaint and QuickDraw combined. HyperCard requires at least 1 MB or memory and the 128K ROMs. The team tried for 512K, but couldn’t make it.</p>



<p>The program contains some pioneering work Bill has done to compress bit maps. The com- pression feature brings two advantages. First, it minimizes disk space to store stacks. And second, it speeds response because the program has fewer bytes to move to and from disk. The feature typically achieves 10-to-1 compressions, with up to 30-to-1 not unusual.</p>



<p>Bill claims to be about two-thirds done with HyperCard. The product is now at a point “where you can build stacks and count on them still working five years from now…” The next features to be added are international features beginning in a month or two (Kanji will take longer) and CD-ROM support a bit later. Color is on the to-do list, but not at high priority.</p>



<p>The product’s current limits are 16 million cards and 500 MB total storage for a stack. And according to Bill, “If you run into those limits, we can change them together.”</p>



<p>Exit, to thunderous applause.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://blog.ceos.io/2020/10/03/last-meeting-bill-atkinson-and-hypercard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671101</guid>
            <pubDate>Sat, 03 Oct 2020 10:44:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The case for building a SETI observatory on the moon]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 76 (<a href="https://news.ycombinator.com/item?id=24670960">thread link</a>) | @pseudolus
<br/>
October 3, 2020 | https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>On Monday, a group of researchers sponsored by Breakthrough Listen, the world’s largest SETI program, </span><a href="http://seti.berkeley.edu/lunarseti/" rel="noopener noreferrer" target="_blank">submitted a paper</a><span> to National Academy of Sciences’ Planetary Science and Astrobiology Decadal Survey that makes the case for establishing a SETI radio observatory on the farside of the moon. The decadal survey establishes scientific priorities for the next ten years and the new paper addresses one of the biggest problems facing the search for extraterrestrial intelligence today: The overwhelming amount of radio interference.&nbsp;</span></p></div><div><p><span>Our planet has become so “loud” in the part of the radio spectrum observed by SETI that it threatens to drown out any signal sent from an intelligent civilization. Not only would a lunar radio telescope not have to deal with terrestrial radio interference, it could also significantly increase our chances of hearing from ET by opening up parts of the radio spectrum that are blocked by Earth's atmosphere. While the idea of using the moon for radio astronomy is decades old, the researchers make the case that technological advancements have finally made a lunar SETI observatory truly feasible.</span></p></div><div><div><p><span>
says Eric Michaud, an intern at the SETI Berkeley Research Center and the first author of the paper. “Maybe not today, but I think it’s going to get more and more feasible as time goes on.”&nbsp;</span></p></div></div><div><p><span>Radio interference has been a problem for SETI from the very beginning. In the spring of 1960, the planetary scientist Frank Drake trained the massive radio telescope at Green Bank Observatory in West Virginia on Tau Ceti and Epsilon Eridani, two stars a mere 12 light years from Earth. That summer, Drake spent his days studying the signals picked up by Green Bank’s giant mechanical ear in the hopes of receiving a message broadcast by an alien civilization orbiting those stars. Known as Project Ozma, Drake’s experiment marked the beginning of SETI, the scientific search for extraterrestrial intelligence.&nbsp;</span></p></div><div><p><span>Shortly after Drake started his observations, he was surprised to find what appeared to be a signal of intelligent origin. After days of watching a needle drift lazily over a spool of paper recording the random undulations of cosmic static, Drake and his colleagues were jolted awake when the machine started recording the frantic pulses of a strong radio signal picked up by the telescope. The timing and magnitude of the pulses clearly marked them as artificial; there was nothing in the natural world that could produce such a frenetic radio profile. It would have been an astounding stroke of luck to pick up an alien message after only a few hours of observation, but it was hard to argue with the data.&nbsp;</span></p></div><div><p><span>“None of us had ever seen anything like it,” Drake recalled in </span><em>Is Anyone Out There?</em><span>, his autobiographical book about the early days of SETI. “We looked at each other wide-eyed. Could discovery be this easy?”</span></p></div><div><div><p><span>

It was a letdown, but the false detection turned out to be a portent for the future of SETI. In the 60 years since Drake’s pioneering experiment, researchers have conducted dozens of SETI searches across thousands of stars and turned up empty-handed. At the same time, the sources of radio interference on Earth—military radars, TV towers, cell phones, and satellites—have exponentially increased, which greatly increases the chances that an extraterrestrial signal will be lost among the noise.&nbsp;</span></p></div></div><div><p><span>Earth was never a particularly great place to do any kind of radio astronomy due to our thick atmosphere blocking a large portion of the radio spectrum. The proliferation of radio communication technologies has only made things harder. The moon, by comparison, has no atmosphere and its nights last for weeks on end, which limits radio noise from the sun. And as&nbsp;NASA discovered through a spate of lunar orbiter missions in the late 1960s, the moon also acts as a natural shield that blocks radio signals emanating from Earth. As the planetary astronomer Phillipe Zarka has put it, “the farside of the moon during the lunar night is the most radio-quiet place in our local universe.” It’s exactly the sort of peace and quiet you want if you’re searching for faint radio signals from solar systems that might be hundreds of light years away.&nbsp;</span></p></div><div><p><span>The new Breakthrough Listen paper proposed two main approaches to a lunar SETI observatory: an orbiter and a telescope on the surface. The basic idea behind a SETI lunar orbiter would be to scan for signals as it passed over the lunar farside and relay data back to Earth as it passed over the near side. One of the main advantages of an orbiter is cost. The proliferation of small satellites that are capable of accurate tracking combined with low-cost small launch providers like Rocket Lab means that a SETI orbiter could conceivably be sent to the moon </span><a href="https://www.nasa.gov/press-release/nasa-awards-contract-to-launch-cubesat-to-moon-from-virginia/#:~:text=The%20firm%2Dfixed%2Dprice%20launch,Tyvak%20Nano%2DSatellite%20Systems%20Inc." rel="noopener noreferrer" target="_blank">for less than $20 million</a><span>. This would be a valuable pathfinder mission that could pave the way for a more ambitious observatory on the surface, but without the risk and cost.&nbsp; As the </span><a href="https://www.supercluster.com/editorial/the-supercluster-podcast-water-bears-might-now-occupy-the-moon" rel="noopener noreferrer" target="_blank">ill-fated Israeli Beresheet lander mission</a><span> reminded us, landing on the moon is extremely challenging even when the mission is backed by $100 million.&nbsp;</span></p></div><div><p><span>But a SETI lunar orbiter would also come with a lot of compromises. It would only be able to conduct observations during the brief stretches when it was on the lunar farside, which would make a sustained observation campaign more challenging. The upshot is that an orbiter would have access to the full sky, whereas a telescope on the surface would be constrained by the moon’s rotation. The biggest downside of an orbiter is that it might lose a lot of the shielding benefits of the moon and be more vulnerable to radio interference from Earth since it would be orbiting high above the lunar surface.&nbsp;</span></p></div><div><p><span>“The first SETI observations that are done from the lunar farside will be done from orbit, there’s no question about that,” says Andrew Siemion, the director of the Berkeley SETI Research Center and the second author on the paper. “I think eventually we absolutely want to do something on the surface because we want to build a very large aperture telescope, but even when we’re at that point I don’t think that would negate the utility of doing things from orbit as well.”&nbsp;</span></p></div><div><p><span>So what would a SETI observatory on the moon look like? One idea is to use the naturally parabolic lunar crater as a radio dish, much like the Arecibo telescope in Puerto Rico and </span><a href="https://www.supercluster.com/editorial/chinas-massive-telescope-is-the-next-great-seti-hope" rel="noopener noreferrer" target="_blank">the FAST telescope in China</a><span>, which are built into natural depressions in the land. This idea was </span><a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/RS012i005p00845" rel="noopener noreferrer" target="_blank">first considered</a><span> back in the late 1970s by a group of scientists at the radio physics lab at the Stanford Research Institute. Their idea was to recreate Arecibo on the moon by suspending an antenna from the lip of a crater and using the basin as a reflector. The reduced gravity on the moon would allow for a radio telescope far larger than any on Earth, which could significantly enhance the sensitivity of SETI searches. Ultimately the researchers concluded that a lunar radio observatory was too expensive compared to SETI telescopes that could be built on Earth.&nbsp;</span></p></div><div><p><span>But 40 years later, Michaud says that building a radio dish in a lunar crater may finally be cheap enough to pull off. One of the main drivers of this cost reduction is the advent of commercial launch providers like SpaceX and Rocket Lab, which have </span><a href="https://www.supercluster.com/editorial/cheaper-rockets-growing-the-human-family-in-space" rel="noopener noreferrer" target="_blank">dramatically lowered the cost of space access</a><span>. Another driver is NASA’s push to establish a permanent human presence on the moon, which has subsidized the development of a fleet of commercial lunar exploration vehicles. “There’s so much interest in going back to the moon,” says Michaud, who cited Blue Origin’s lunar lander and Rocket Lab’s Photon Lunar satellite as examples of technologies enabled by </span><a href="https://www.supercluster.com/editorial/nasas-first-puerto-rican-born-director-aims-for-a-moonshot" rel="noopener noreferrer" target="_blank">NASA’s Artemis program</a><span>.&nbsp;</span></p></div><div><p><span>A crux of the original vision for lunar SETI observatories was that it would require a human settlement on the moon to build and operate the radio dish. But robotic systems have improved enough that it may be possible to take humans out of the equation. This was clearly demonstrated in 2019 when China’s Chang’e 4 rover landed autonomously on the farside of the moon. These advancements in autonomous navigation have laid the foundation for a lunar radio observatory that is built entirely by robots.&nbsp;</span></p></div><div><p><span>It sounds like science fiction, but earlier this year NASA’s Advanced Innovative Concepts program </span><a href="https://www.nasa.gov/directorates/spacetech/niac/2020_Phase_I_Phase_II/lunar_crater_radio_telescope/" rel="noopener noreferrer" target="_blank">awarded one of it’s prestigious grants to Saptarshi Bandyopadhyay, a researcher at the Jet Propulsion Laboratory, to figure out a way to make it happen</a><span>. His idea is to use rovers to deploy wire mesh in a crater on the lunar farside and suspend a receiver over the dish. NIAC is all about funding high risk, high reward missions, and there’s no guarantee that Bandyopadhyay’s proposal will ever come to fruition. Still, addressing the technical problems associated with building a radio receiver on the farside of the moon is an important first step.</span></p></div><div><p><span>And Bandyopadhyay isn’t the only NASA-backed researcher contemplating a lunar radio observatory. Jack Burns, a radio astronomer at the University of Colorado, has also received a grant to study a mission concept for a radio telescope array called </span><a href="https://www.colorado.edu/project/lunar-farside/dr-jack-burns" rel="noopener noreferrer" target="_blank">FARSIDE</a><span>. Instead of using a crater as a dish, FARSIDE would deploy several smaller antennas across the lunar surface that would collectively form a large radio telescope. Both NASA studies are focused on radio astronomy rather than SETI, but Siemion sees the two disciplines as natural allies in the quest to establish an observatory on the lunar farside. SETI has piggybacked on other radio astronomy projects in the past—SERENDIP, for instance, opportunistically searched for ET signals during radio observation campaigns at a variety of telescopes—and it seems plausible that a similar arrangement could be made with an observatory on the moon.&nbsp;</span></p></div><div><p><span>Siemion acknowledged that there were certain technical challenges that would arise in a collaboration on a lunar radio observatory. The biggest issue, he says, is that a lot of radio astronomy is done at frequencies that don’t really require an observatory on the moon. “Radio …</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670960</guid>
            <pubDate>Sat, 03 Oct 2020 10:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering a North Korean Sim City Game]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24670827">thread link</a>) | @pcr910303
<br/>
October 3, 2020 | https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/ | <a href="https://web.archive.org/web/*/https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-371">
	<!-- .entry-header -->

	<div>
		<p><em>Reverse engineering the North Korean version of a popular Sim City-like game using Ghidra and ndSpy to understand video game monetization strategies in the DPRK and the marketization of the country’s economy. </em></p><p><em>Key takeaways:</em></p><p><em>
<li>Android devices and applications are increasingly common in North Korea. Physical “app stores” can be found on every street corner in Pyongyang.</li>
<li>The game considered in this post is based on a Chinese version of a popular Android game developed in the Netherlands</li>
<li>The game’s monetization strategy was adapted to the country’s infrastructure (low internet/intranet availability, physical app stores)</li>
<li>The North Korean version eschews the original freemium + online microtransaction model for a one-time licence purchase + offline microtransaction model</li>
<li>File integrity checks added by North Korean developers shows that piracy is a concern and suggests the existence a warez/cracking scene in the DPRK</li>
<li>The cryptographic algorithms used for the licence are MD5, SHA1, RSA and AES. The library used by the game included the domestically developed private key algorithms Pilsung and Jipsam, but they were not used as part of the licencing system</li></em></p><p><a href="#intro">0. Introduction</a><br>
<a href="#licence">1. Licensing system</a><br>
<a href="#check">2. File integrity checks</a><br>
<a href="#money">3. In-game monetization strategy and key generation</a><br>
<a href="#end">4. Conclusion</a></p>
<h4 id="intro">0. Introduction </h4><p>During a recent trip to North Korea, I noticed the recent and ubiquitous presence of <em>Information Technology Exchange Rooms</em> (정보기술교류실), physical stores where one can purchase a variety of electronic devices – from laptops and tablets to USB sticks and chargers – as well as software and video games for PC, mobile and tablets (for an in-depth look at what goes on inside those stores as well as what the app selection looks like, <a href="https://www.nknews.org/2019/02/what-to-buy-inside-a-north-korean-app-store/">this article</a> by Alek Sigley provides a an excellent description. There are also a few <a href="https://www.youtube.com/watch?v=1ujblnigJmM">videos</a> on YouTube). After looking through the catalogue of available games at different stores, I eventually decided to try and buy a Sim City-like game called <em>City Management</em> (도시경경).</p>
<figure id="attachment_426"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png" alt="" width="845" height="760"></a><figcaption>Billboards for various app stores in Pyongyang</figcaption></figure><p>The game only cost 5000 wons (less than 1 USD) which I paid to have the app installed on the phone I had, a Samsung Galaxy A5 running Android 8. The vendor connected the phone to his PC, transferred the APK and tried to install it, but to no avail. After multiple attempts, he eventually informed me that North Korean apps most likely could not run on phones from other countries. </p>
<figure id="attachment_428"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png" alt="" width="551" height="827"></a><figcaption>Advertisement for a car racing game inside a North Korean app store</figcaption></figure><p>Fortunately, I was later able to purchase one of the different tablets sold in North Korea. I got the <em>Morning</em> (아침) brand, which is geared towards students and quite affordable. The tablet ran Android 4 (Kit Kat) on an ARM cpu and came loaded with a few educational apps: language learning courses, dictionaries and several e-book libraries containing the complete works of Kim Il Sung, school textbooks and a collection of literary works. No games, but that could now be fixed quite easily.</p>
<figure id="attachment_431"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png" alt="" width="800" height="490"></a><figcaption>A North Korean Ach’im (Morning) tablet</figcaption></figure><p>I retrieved the <em>City Management</em> APK from my phone and installed it on the tablet, where it ran perfectly. Unfortunately, after the game’s initial splash screen, I landed on this:</p>
<figure id="attachment_434"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png" alt="" width="1024" height="600"></a><figcaption>Licence key needed</figcaption></figure><p>The screen tells us that there is no “key file” (열쇠화일) and that we should purchase one at a store. There is a “request number” (요청번호) likely used to generate the licence key and make sure it can’t be shared with other devices. Unfortunately, since the APK never installed, the vendor did not put a licence file on my phone when I bought the app. My stay in North Korea was coming to an end too and I did not have time to go back to an app store to buy a new key. So I figured I would take a look inside the app and see if I could get it running nonetheless. </p>
<hr id="licence">
<h4>1. Licensing system </h4><p>To start looking into the APK’s code, I’ll use the standard suite of tools to decompress, decompile and rebuild android apps: <a href="https://sourceforge.net/projects/dex2jar/">dex2jar</a>, <a href="http://java-decompiler.github.io/">jd-gui</a>, <a href="https://ibotpeaches.github.io/Apktool/install/">apktool</a> and <a href="https://github.com/appium/sign">apksign</a>. I’ll also use <a href="https://developer.android.com/studio">Android Studio</a> to run and debug the app. The fact that I couldn’t run the app on my phone may have just come from an Android version compatibility issue: I had no problem running it on an emulated Android 4.4 device with Android Studio. The decompilation of the <code>classes.dex</code> file gives us some interesting information right away:</p>
<figure id="attachment_438"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png" alt="" width="211" height="326"></a><figcaption>Packages and classes from the decompiled <code>classes.dex</code> file</figcaption></figure><p>The name of the <code>com.bz.cityisland2</code> package actually refers to the original game that <em>City Management</em> is based on: <a href="https://www.sparklingsociety.net/sparkling-games/city-building-games/city-island-2/">City Island 2</a> by the Dutch game studio Sparkling Society. The name of the package <code>com.smartions.appprotected</code> refers to <a href="https://www.crunchbase.com/organization/smartions-ag#section-overview">Smartions</a>, a company that offers solutions to “monetize your mobile game or app in China” and are apparently also City Island’s <a href="https://en.wikipedia.org/wiki/Sparkling_Society">distributor in China</a>. There are no mentions of those companies in the game itself however. The game’s loading splash screen only tells us that the game was made by the Ryusong (meteor) Technology Exchange Center (류성기술교류소) and that it is protected by the law for the protection of software (<a href="https://www.kisdi.re.kr/kisdi/common/premium?file=1%7C10360">콤퓨터쏘프트웨어보호법</a>). The law has been in place since 2003 to regulate the sales and distribution of software in the country and guarantees software developers the private ownership of their creation.</p>
<figure id="attachment_502"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png" alt="" width="1000" height="640"></a><figcaption>Loading screen for the game</figcaption></figure><p>It’s hard to tell whether the North Korean version is based on the source code of the original game or if it’s entirely reverse engineered. In any case, the North Korean version does not use Smartions’s monetization system nor Sparkling Society’s but relies on a different system, which is the main difference from the original game. Save for the translation and some minor renames, the game is otherwise similar to the original (from a cursory examination) in its design, gameplay, features… to the original. </p>
<figure id="attachment_442"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png" alt="" width="339" height="221"></a><figcaption>Structure a Unity APK. From Shim et al., <a href="https://www.hindawi.com/journals/scn/2018/6280768/"><em>Static and Dynamic Analysis of Android Malware and Goodware Written with Unity Framework</em></a> (2018).<br></figcaption></figure><p>There’s not much more we can glean from the Java code for now since, as the classes in <code>unity3dplayer</code> and <code>AndroidManifest.xml</code> file make clear, it is used to run code that was written with <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a>, a popular cross-plaform video game framework which uses C# as its main programming language. The Unity code is stored in various library with the developer’s C# code being compiled to <code>Assembly-CSharp.dll</code>. C# compiled code is easily decompilable using tools such as <a href="https://github.com/0xd4d/dnSpy">dnSpy</a>. Once the dll is decompiled, we can look for the message we got earlier “열쇠화일이 존재하지 않습니다” (“The key file does not exist”) to find the bits of code we are interested in. The string search takes us to the <code>CIGLoadingScreen</code> class where we find the string among other variables:</p>
<pre title="">
	// Token: 0x0400056A RID: 1386
	private string userKey;

	// Token: 0x0400056B RID: 1387
	private string tapjoyCurrencyIdentifier;

	// Token: 0x0400056C RID: 1388
	private bool bannerVisible;

	// Token: 0x0400056D RID: 1389
	private int _loadingScreenShownCount;

	// Token: 0x0400056E RID: 1390
	private Dictionary&lt;int, bool&gt; m_gameObjectStatus = new Dictionary&lt;int, bool&gt;();

	// Token: 0x0400056F RID: 1391
	private bool m_isVerify;

	// Token: 0x04000570 RID: 1392
	private Font kfont;

	// Token: 0x04000571 RID: 1393
	private string reqMsg = "열쇠화일이 존재하지 않습니다.\r\n열쇠화일을 판매소에서 구입하십시오.";

	// Token: 0x04000572 RID: 1394
	private string reqNumLabel = "요청번호 : ";

	// Token: 0x04000573 RID: 1395
	private string reqNum;

	// Token: 0x04000574 RID: 1396
	private string finishLabel = "끝내기";
</pre><p>Looking for the name of the string variable <code>reqMsg</code> takes us here:</p>
<pre title="">	// Token: 0x06000928 RID: 2344 RVA: 0x00026E60 File Offset: 0x00025060
	private void OnGUI()
	{
		if (!this.m_isVerify &amp;&amp; this.loadingDone)
		{
			GUI.skin.font = this.kfont;
			GUI.DrawTexture(new Rect(0f, 0f, (float)Screen.width, (float)Screen.height), this.blackBg, ScaleMode.StretchToFill);
			GUI.Label(this.GetTextLabelRect(this.reqMsg, 0.5f, 0.3f), this.reqMsg);
			GUI.Label(this.GetTextLabelRect(this.reqNumLabel, 0.3f, 0.5f), this.reqNumLabel);
			GUI.Label(this.GetTextLabelRect(this.reqNum, 0.6f, 0.5f), this.reqNum);
			RectOffset padding = GUI.skin.button.padding;
			GUI.skin.button.padding = new RectOffset(20, 20, 10, 10);
			if (GUI.Button(this.GetButtonRect(this.finishLabel, 0.5f, 0.8f), this.finishLabel))
			{
				Application.Quit();
			}
		}
	}
</pre><p>This is the code used to display the splashscreen we encountered earlier. If the boolean property <code>this.m_isVerify</code>, presumably the result of a call to a function checking the existence and validity of a licence key, is <code>False</code> then, the screen is displayed with the message we saw earlier and the “request number”. The verification function and the generation of the request number are handled in another class <code>GameCus</code>:</p>
<pre title="">using System;
using System.IO;
using System.Runtime.InteropServices;

// Token: 0x02000147 RID: 327
public class GameCus
{
	// Token: 0x06000AA7 RID: 2727
	[DllImport("Game")]
	private static extern int vProcess(byte[] key, int keyLen, byte[] certData, int certDataLen);

	// Token: 0x06000AA9 RID: 2729 RVA: 0x0002E910 File Offset: 0x0002CB10
	public string GetReqNumber()
	{
		string deviceIdString = this.GetDeviceIdString();
		return string.Format("{0:d4} {1:d4} {2:d4} {3:d4}", new object[]
		{
			deviceIdString.Substring(0, 4),
			deviceIdString.Substring(4, 4),
			deviceIdString.Substring(8, 4),
			deviceIdString.Substring(12, 4)
		});
	}

	// Token: 0x06000AAA RID: 2730 RVA: 0x0002E968 File Offset: 0x0002CB68
	public string GetDeviceIdString()
	{
		string text = Utils.GetDeviceModel();
		text = string.Format("{0:d10}", (uint)text.GetHashCode());
		string str = text.Substring(2, 8);
		string text2 = Utils.GetDeviceUid();
		text2 = string.Format("{0:d10}", (uint)text2.GetHashCode());
		string str2 = text2.Substring(2, 8);
		return str + str2;
	}

	// Token: 0x06000AAB RID: 2731 RVA: 0x0002E9CC File Offset: 0x0002CBCC
	public bool checkCertData(byte[] certData)
	{
		if (certData == null || certData.Length == 0)
		{
			return false;
		}
		string text = this.GetDeviceIdString() + …</pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</a></em></p>]]>
            </description>
            <link>https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670827</guid>
            <pubDate>Sat, 03 Oct 2020 09:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying “Make Invalid States Unrepresentable”]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24670763">thread link</a>) | @todsacerdoti
<br/>
October 3, 2020 | https://kevinmahoney.co.uk/articles/applying-misu/ | <a href="https://web.archive.org/web/*/https://kevinmahoney.co.uk/articles/applying-misu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting" id="applying-make-invalid-states-unrepresentable">
  <div itemprop="articleBody">
    <p><time itemprop="datePublished">02 October 2020</time></p>

<p>Here are some real life cases of applying one of my
<a href="https://kevinmahoney.co.uk/articles/my-principles-for-building-software/">favourite principles</a>.</p>

<p>I’ll try to update this as I come across good examples.</p>

<h2 id="case-1-contiguous-time-periods">Case 1: Contiguous Time Periods</h2>

<p>A straightforward way to represent a period of time is by its start
and end dates (<code>(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c1.png"></p>

<p>If we need to represent a timeline split in to contiguous periods, it
may be tempting to represent this as a sequence of periods (e.g. <code>List
(Date, Date)</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c2.png"></p>

<p>However, with this representation there can be both gaps in the
timeline and overlapping periods:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c3.png"></p>

<h3 id="improved-representation">Improved Representation</h3>

<p>We can improve this representation so that the contiguous and
non-overlapping constraints always hold, and we can do this in a way
that may remind you of database normalisation - by removing
redundancy.</p>

<p>In a well formed contiguous timeline, the joint start/end
of the adjacent periods are redundant. Contiguous, non-overlapping
splits can simply be represented by a set of dates (<code>Set Date</code>):</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/c4.png"></p>

<p>You can begin to see how this representation simplifies the system
when you consider how to make a further split in the timeline. In the
list representation, splitting a period requires carefully modifying
the data-structure and ensuring constraints aren’t violated. In the
‘set of dates’ representation you simply add a date to the set.</p>

<p>It is sometimes still useful to represent the periods as a sequence of
start and end dates. It is trivial to project the set of dates in to
this form. As long as the canonical representation is the set, the
constraints will still hold.</p>

<h2 id="case-2-default-contracts">Case 2: Default Contracts</h2>

<p>In this system, a customer pays us a recurring rent based upon a contract.
Contracts last for a fixed amount of time, and when they expire we fall back to
a ‘default contract’. The customer can have many fixed contracts, and can
sign new contracts at any time.</p>

<p>This was represented as:</p>
<ul>
  <li>A ‘customers’ table storing
    <ul>
      <li>The customer start date.</li>
      <li>An optional end date, should the customer leave.</li>
    </ul>
  </li>
  <li>A ‘contracts’ table storing
    <ul>
      <li>The contract start date.</li>
      <li>An optional end date, for default contracts that don’t end.</li>
      <li>If it was a ‘fixed’ or ‘default’ contract.</li>
    </ul>
  </li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f1.png"></p>
<p>Customer and contract timelines</p>

<p>This representation allows for some undesirable states that are trivial to prevent:</p>
<ul>
  <li>The customer may have gaps in their contracts.</li>
  <li>A fixed contract may not have an end date.</li>
</ul>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f2.png"></p>
<p>Contract gaps</p>

<p>To make matters worse, the API for these contracts allowed you to
modify each individual contract, fixed or default, without guarding against
these states. This shows how a poor choice of
representation propagates itself through the design of a system.</p>

<p>This poor choice was not just a theoretical problem -
gaps in contracts were found on more than one occasion, requiring
hours of engineering effort to hunt down and fix.</p>

<h3 id="improved-representation-1">Improved Representation</h3>

<p>This is easily improved by removing the ‘default’ contracts from the
contract table. If the customer doesn’t have a fixed contract, it is
assumed they are on a default contract:</p>

<p><img src="https://kevinmahoney.co.uk/img/articles/misu/f3.png"></p>
<p>Inferred default contracts</p>

<p>Now there can no longer be any gaps, and 
the end date of a contract no longer needs to be optional as it only represents fixed contracts.</p>

<p>It’s worth reiterating that this representation can be projected in to the previous
representation using a database view if that form is more convenient. What is
important is that the underlying representation enforces these constraints, it
is not important how you view the data.</p>

<p>As with the first case, a better representation makes the manipulation
of the data structure simpler. In this case, adding a new fixed contract is
greatly simplified. There is no need to create or modify default contracts, or ensure
that the contracts are contiguous.</p>

<h3 id="the-influence-of-object-oriented-thinking">The Influence of Object-Oriented Thinking</h3>

<p>If this improvement seems obvious to you, you may wonder how the
original design happened in the first place.</p>

<p>I think this happens because of atomistic, object-oriented thinking.</p>

<p>In this mindset, the fixed contracts are <em>objects</em>, the default contracts are
<em>objects</em>, and each of these concepts must be reified as a row in a table and
never inferred.
There is a distrust of using any features the database
offers beyond storing or retrieving <em>objects</em>.</p>

<p>This approach is antithetical to quality relational design and
the principle of making invalid states unrepresentable.</p>

<p>It may feel “simpler” on some level, as you don’t really need
to think about your design.
However, as we see here, this lack of forethought inevitably
leads to complexity.</p>

  </div>
</article></div>]]>
            </description>
            <link>https://kevinmahoney.co.uk/articles/applying-misu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670763</guid>
            <pubDate>Sat, 03 Oct 2020 09:27:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is the market share of Firefox in Germany so much higher?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24670605">thread link</a>) | @jlelse
<br/>
October 3, 2020 | https://jlelse.blog/posts/firefox-market-share/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/posts/firefox-market-share/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently took a closer look at Cloudflare’s new project <a href="https://radar.cloudflare.com/" target="_blank" rel="noopener">Radar</a>. Besides statistics about internet usage, attacks and popular domains, the site also shows statistics about the market shares of browsers.</p><p>Here is an overview of the global statistics:</p><p><a href="https://media.jlelse.blog/eb2cc6b3a4f116777f08594989bc16b4376a10b159e2c9d9ccc93080fb077631.png"><img src="https://media.jlelse.blog/eb2cc6b3a4f116777f08594989bc16b4376a10b159e2c9d9ccc93080fb077631.png" loading="lazy" alt="Global top browsers" title="Global top browsers"></a></p><p>Here the distribution in the USA:</p><p><a href="https://media.jlelse.blog/172293b33c412050c263e9a5eff0062158c509b58e40c3da31447199e304a871.png"><img src="https://media.jlelse.blog/172293b33c412050c263e9a5eff0062158c509b58e40c3da31447199e304a871.png" loading="lazy" alt="Top browsers in the USA" title="Top browsers in the USA"></a></p><p>And here in Germany:</p><p><a href="https://media.jlelse.blog/fb2e26d1aafda14d14b0affe91b35c6e531669632b3aa7cad1de3276130dd795.png"><img src="https://media.jlelse.blog/fb2e26d1aafda14d14b0affe91b35c6e531669632b3aa7cad1de3276130dd795.png" loading="lazy" alt="Top browsers in Germany" title="Top browsers in Germany"></a></p><p>When comparing the statistics, I notice a few interesting things:</p><ul><li>In the USA as well as in Germany the usage of Firefox is higher than the world average. In Germany, however, it is much higher, instead of only about 7%, the share of Firefox in Germany is almost 21%.</li><li>The use of Safari (iOS and desktop) in the USA is significantly higher than the world average and in Germany.</li><li>However, Chrome (mobile) and Samsung Internet have higher shares in Germany than in the USA. But Chrome (mobile) in Germany still has less than worldwide.</li></ul><p>The higher share of Safari in the USA can probably be explained relatively by the higher market share of Apple in the USA. While many people in Germany tend to rely more on Android smartphones (and Windows PCs), the iPhone (and Mac) share is significantly higher in the USA. Here are <a href="https://www.statista.com/statistics/461900/android-vs-ios-market-share-in-smartphone-sales-germany/" target="_blank" rel="noopener">some</a> <a href="https://www.statista.com/statistics/1150677/us-market-share-held-by-leading-smartphone-vendors/" target="_blank" rel="noopener">statistics</a> on this.</p><p>This different distribution naturally also affects the other mobile browsers. In Germany many people seem to use Samsung smartphones and the pre-installed browser Samsung Internet.</p><p>What I can’t quite explain is the high percentage of Firefox in Germany. Are people in Germany more critical of Google? I somehow don’t believe that…</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/posts/firefox-market-share/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670605</guid>
            <pubDate>Sat, 03 Oct 2020 08:53:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an Assembler]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24670583">thread link</a>) | @todsacerdoti
<br/>
October 3, 2020 | https://blog.steve.fi/writing_an_assembler_.html | <a href="https://web.archive.org/web/*/https://blog.steve.fi/writing_an_assembler_.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
          <div>
  <h2><a href="https://blog.steve.fi/writing_an_assembler_.html">Writing an assembler.</a></h2>
  <p>3 October 2020 13:00</p>
  <div><p>Recently I've been writing a couple of simple compilers, which take input in a particular format and generate assembly language output.  This output can then be piped through <code>gcc</code> to generate a native executable.</p>

<p>Public examples include this trivial <a href="https://github.com/skx/math-compiler" rel="nofollow">math compiler</a> and my <a href="https://github.com/skx/bfcc" rel="nofollow">brainfuck compiler</a>.</p>

<p>Of course there's always the nagging thought that relying upon <code>gcc</code> (or <code>nasm</code>) is a bit of a cheat.  So I wondered how hard is it to write an assembler?  Something that would take assembly-language program and generate a native (ELF) binary?</p>

<p>And the answer is "It isn't hard, it is just tedious".</p>

<p>I found <a href="https://github.com/vishen/go-x64-executable/" rel="nofollow">some code</a> to generate an ELF binary, and after that assembling simple instructions was pretty simple.  I remember from my assembly-language days that the encoding of instructions can be pretty much handled by tables, but I've not yet gone into that.</p>

<p>(Specifically there are instructions like "<code>add rax, rcx</code>", and the encoding specifies the source/destination registers - with different forms for various sized immediates.)</p>

<p>Anyway I hacked up a simple assembler, it can compile <code>a.out</code> from this input:</p>

<pre><code>.hello   DB "Hello, world\n"
.goodbye DB "Goodbye, world\n"

        mov rdx, 13        ;; write this many characters
        mov rcx, hello     ;; starting at the string
        mov rbx, 1         ;; output is STDOUT
        mov rax, 4         ;; sys_write
        int 0x80           ;; syscall

        mov rdx, 15        ;; write this many characters
        mov rcx, goodbye   ;; starting at the string
        mov rax, 4         ;; sys_write
        mov rbx, 1         ;; output is STDOUT
        int 0x80           ;; syscall


        xor rbx, rbx       ;; exit-code is 0
        xor rax, rax       ;; syscall will be 1 - so set to xero, then increase
        inc rax            ;;
        int 0x80           ;; syscall
</code></pre>

<p>The obvious omission is support for "JMP", "JMP_NZ", etc.  That's painful because jumps are encoded with relative offsets.  For the moment if you want to jump:</p>

<pre><code>        push foo     ; "jmp foo" - indirectly.
        ret

:bar
        nop          ; Nothing happens
        mov rbx,33   ; first syscall argument: exit code
        mov rax,1    ; system call number (sys_exit)
        int 0x80     ; call kernel

:foo
        push bar     ; "jmp bar" - indirectly.
        ret
</code></pre>

<p>I'll update to add some more instructions, and see if I can use it to handle the output I generate from a couple of other tools.  If so that's a win, if not then it was a fun learning experience:</p>

<ul>
<li><a href="https://github.com/skx/assembler/" rel="nofollow">https://github.com/skx/assembler/</a></li>
</ul>

   <p>
    <span>
      
       Tags: <a href="https://blog.steve.fi/tags/asm">asm</a>, <a href="https://blog.steve.fi/tags/assembly">assembly</a>, <a href="https://blog.steve.fi/tags/github">github</a>, <a href="https://blog.steve.fi/tags/go">go</a>, <a href="https://blog.steve.fi/tags/golang">golang</a>
     
    </span>
    <span>|</span>
    
   </p>
  </div>
</div>


           






          
<h2>Add your comment</h2>

<p>Your submission will be ignored if any of the fields are left blank, but your email address will <b>never</b> be displayed.</p>


        </div></div>]]>
            </description>
            <link>https://blog.steve.fi/writing_an_assembler_.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670583</guid>
            <pubDate>Sat, 03 Oct 2020 08:47:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding Worry Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24670483">thread link</a>) | @gfysfm
<br/>
October 3, 2020 | https://www.seangoedecke.com/worry-driven-development/ | <a href="https://web.archive.org/web/*/https://www.seangoedecke.com/worry-driven-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header></header><section><p>Sofware dysfunction is more often motivated by anxiety, fear, worry and embarassment than it is by a lack of technical skill. Engineers avoid work that needs doing because they’re afraid of becoming entangled with a nightmarish task, or because they’re afraid of looking stupid, or harming their career by spending time on grungy work. The task itself is rarely that difficult; it just seems so, which is enough of a barrier to discourage anyone from picking it up. One of the highest-leverage things you can do as an engineer is to recognize this emotional reaction in yourself and work to counter it. If you’re working on a single task, doing this can make your implementation significantly cleaner. If you’re a senior engineer with responsibility for a whole system, this can help you address high-impact architectural or operational issues.</p>
<p>You can see this in the common advice to sleep on a problem and come back to it in the morning. A bug that seems impossible when you’re tired and frustrated is far more approachable when you’re well-rested and caffeinated. Tedious investigative tasks (like scanning the logs for a bug or tracing all the possible code paths in a function) are still tedious in the morning, but infinitely more doable. You can knock it out in half an hour while drinking your morning coffee, rather than spending hours the night before avoiding the tedious work and hoping for a flash of inspiration.</p>
<p>Necessary work avoided becomes a haunted forest in the codebase. One engineer’s avoidant emotions turn into dangerous team habits as engineers teach each other to avoid touching certain files, or to pass odd-looking production bugs to the operations team. “This network behaviour is dark magic, let them handle it!” What began as a single engineer’s worry is now a team’s dysfunction, and can eventually metastasize into actively blocking engineers from working on the original technical problems: if you’re avoiding working on a worrying problem, it can feel threatening when someone else comes along and tries to solve it. What if they succeed, or worse still succeed easily? That would reveal that you weren’t good enough to solve the problem.</p>
<p>Just because you’re touching a scary part of the system doesn’t mean you’re facing scary work calmly and rationally. Engineers often approach thorny work like they’re going through a haunted house: either trudging through with eyes half-closed, or rushing through at full speed trying to get out as quickly as possible. Both tactics aim to take in as little of the frightening environment as possible, and neither tactic is a good way of solving real problems in technical systems. If you’ve ever just tweaked setings or frantically moved code around until it worked, you’ve done this.</p>
<p>From the inside, this doesn’t feel like emotionally-driven avoidance. It feels like working on legacy code, sharing friendly complaints about it with other engineers on your team. This is in part because a fear of hard technical problems can be a rational fear. Untangling messy parts of the codebase, identifying and removing dead code, cleaning up build, deploy and monitoring systems - these tasks often feel overwhelming because they can overwhelm you, sucking up days for no real gain. It can harm your career to spend time on this work in an org that mainly values shipping features. (I haven’t seen the other common worry - looking stupid - really be an issue in practice myself.) The trouble comes when you don’t recognise that part of your response is emotional, and therefore overrate the actual difficulty or risk.</p>
<p>How can you distinguish a rational response to a too-difficult task from a learned emotional reaction to a task that is merely worrying? This is a hard problem. I think it is the hardest problem that almost all engineers will regularly face. One approach is to avoid trying to tell the difference at all, and allot a certain amount of time to looking at randomly-chosen neglected parts of the system. Things that reduce stress in general are also good ways to reduce stress and worry about work. Good sleep, eating well, exercise, therapy, and working in an emotionally safe team all have a significant positive effect on the quality of engineering work. Once you start doing this, the difference is usually obvious in hindsight: if the task that worried you for six months took an hour or two of work when you finally mustered up the effort to look at it, you know your worry was unfounded. Dealing with worry is a virtuous cycle. Each difficult task you do makes you less scared of the next one.</p>
<p>Tackling a series of worrying tasks is one of the quickest ways I know to have massive impact in your engineering org. This is because once you understand a thorny piece of code, or a neglected system, you will usually see how to make obvious improvements. In any other part of the system these improvements would have been made already, but since you are the first person to really wrap your head around it in a long time, you get to make them here! Occasionally, you will see the opportunity to completely remove the worrying part of the system, which for me is one of the most satisfying things you can do as a software engineer. Removing things that cause your team stress has compounding benefits to your team, to the systems you work on, and to your engineering org in general.</p></section><hr></article></div>]]>
            </description>
            <link>https://www.seangoedecke.com/worry-driven-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670483</guid>
            <pubDate>Sat, 03 Oct 2020 08:23:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Honest Review of Gatsby]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24670252">thread link</a>) | @ehfeng
<br/>
October 3, 2020 | https://cra.mr/an-honest-review-of-gatsby/ | <a href="https://web.archive.org/web/*/https://cra.mr/an-honest-review-of-gatsby/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We decided to adopt Gatsby for <a href="https://docs.sentry.io/">Sentry’s customer-facing documentation</a> - well, I should say that <em>I</em> decided. We were already using it successfully for a variety of static marketing content, and I knew it had a lot of hype, so after a brief proof-of-concept it seemed like a safe choice.</p>
<p>To help contextualize everything I’m about to say, it’s important to understand the scope of our usage. Sentry’s documentation is not as straightforward as you might think - in fact, there are over 3,000 pages as of writing. We have a large amount of templated content designed to render language-specific examples, as well as a variety of different types of documentation (user guides, help desk-y articles, code-rich technical docs). Originally we had extended Jekyll to support a lot of this, but Ruby isn’t widely used at Sentry (approximately 0% of the engineering team knows Ruby), and it had become a big mess of spaghetti code with slow build times.</p>
<p>I also want to note that while this blog post is primarily focusing on the flaws of Gatsby as a framework, I’m not here to tell you that it’s not good for your use case. That said, I was not able to discover many of these short comings easily when evaluating Gatsby, and many things you read on the internet don’t stem out of real-world usage. My hope here is that Gatsby continues to improve over time, and that, as a user, you can be more informed about if it’s the right choice for you.</p>
<h2>Adopting Gatsby</h2>
<p>So, enter Gatsby. It seemed fast, was built on React (we’re experts on that here, with our gigabyte-sized Sentry frontend app), and had a huge adoption (assumed future existence and stability). While we didn’t have the desire to use MDX, it also seemed like a positive outcome given we could more easily deal with some of the rich aspects of our docs site, without having to resort to 2010-era JavaScript. We assumed a bunch of the other features of Gatsby had value-add, but we didn’t have an immediate need. These were things like dynamic source data - thus the need for a GraphQL engine at all - as well as the large plug-in ecosystem.</p>
<p>We started by iteratively converting sections of the Jekyll site into Gatsby - running them side by side for a time. At one point we eventually bulk converted pages, and ripped off the band aid. At this point though it was becoming clear build times were a problem. You’d spend at least 5 minutes on image optimization alone, with no way to even disable that. Slowly but surely we were depleting the ozone later on re-optimizing images which had already been pre-optimized. Oh yeah, and we were crippling our iteration speed as well, since the build cache would invalidate under a variety of situations in early development.</p>
<p>Making this worse was how we deployed Gatsby. We started off leveraging what we had already done: deploying Jekyll with Docker onto our own infrastructure - effectively just proxied via a CDN. We continued that for a period of time, but deploy times were far too long - upwards of 30-40 minutes for everything to build. Eventually we moved over to <a href="https://vercel.com/">Vercel</a> which dropped it down closer to 10 minutes, but ultimately it can’t fix what it doesn’t control.</p>
<p>The build and deploy times were the first of many woes, and they represent what would become a continued frustration: a problem without a clear solution.</p>
<h2>Enter MDX</h2>
<p>Rewind time a little bit - this actually wasn’t our first project converting documentation to Gatsby. The proof-of-concept I mentioned earlier was actually our <a href="https://develop.sentry.dev/">developer documentation</a>, which I had migrated out of Notion to make public. While doing that we had gotten our hands dirty with some initial MDX usability and extensions - like our code samples which support toggling between different languages. This was one of the many things we needed to solve for, but MDX made it look like it’d be seemingly easy. No more jQuery DOM manipulation, just clean, encapsulated React components. Or so we thought.</p>
<p>Almost immediately we hit rough spots with MDX. We were coming from Jekyll - which was Liquid-rendered (a template engine) markdown - to MDX - a strange offspring of Markdown and JSX, attempting all of the benefits of both, but missing by a fairly large margin. Let’s illustrate the crux of the issue with what has got to be one of the most common needs in a documentation system: an alert (or callout) component:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>info<span>"</span></span><span>&gt;</span></span>You should know something important about this!<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>At face value this looks great. <code>Alert</code> is just a React component, and JSX is close enough to HTML that non-technical folks are able to pick it up fairly easily. Now the problem comes into play when you actually want to do something in the real world. Here’s an example from our API docs:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span>
    <span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.
<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>How would you expect this to render? Both as an engineer and a non-engineer, I would expect - given this is markdown - that the “PUT/DELETE” text would be bold. It’s not. Because the MDX interpreter decides that once you enter a component block, it’s no longer markdown. So instead, we’re forced with this monstrosity <em>everywhere</em> in our documentation:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;</span>markdown</span><span>&gt;</span></span>

<span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.

<span><span><span>&lt;/</span>markdown</span><span>&gt;</span></span><span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>There’s two things you should note here: 1) we have to use this <code>&lt;markdown&gt;</code> tag, 2) we have to put empty new-lines to ensure paragraph tags render.</p>
<p>“But David”, you might say, “why don’t you just tell the <code>Alert</code> component to render the text as markdown?“. If only you could, or at least, if only I could have possibly found a way to achieve that as a user with minimal Gatsby or MDX internals knowledge.</p>
<p>To Gatsby, or at least to the MDX team’s credit, they recognize some of these problems and <a href="https://github.com/mdx-js/mdx/issues/1041">there is work underway</a> on a 2.0 of the MDX dialect. While I’m confident they will improve things, I’m not confident MDX can ultimately succeed. It’s likely going to tradeoff one problem for another due to what it’s trying to achieve in the first place. It may get to a good place, but frankly, we need to step back and look at what we’re trying to solve, instead of creating a solution to a problem we don’t have. I don’t need JSX syntax in my markdown, I need a way to include JSX components. That might sound similar, but its quite a different thing.</p>
<p>As an example, there’s no reason I couldn’t simply use markdown syntax, and provide a way to achieve something akin to:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>a-valid-html-tag-because-markdown-allows-that</span> <span>a-valid-property</span><span><span>=</span><span>"</span>a-value<span>"</span></span><span>&gt;</span></span></code></pre></div>
<p>This wouldn’t force us to work around quirks in a new language (or interpreter even), and could be solved in a much more sustainable way. There are other alternatives as well. A generic way to render extensions in markdown could simply call into a React component, and avoid even trying to hijack HTML in the first place. While I don’t know what this might look like in Markdown, in <a href="https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html">Sphinx’s use of reStructuredText</a> this was solved early on with Directives:</p>
<div data-language="text"><pre><code>.. my-directive:: some data
   :property-name: property-value</code></pre></div>
<p>I will hold out for MDX 2.0 and hope that finds a nice minimal-compromise place, but if not, we’ll be looking for a way to extend native markdown.</p>
<h2>A Broken DOM</h2>
<p>While we were able to work around the kinks of MDX, there’s been some things not yet solved. One of those is the layer which Gatsby uses to apply diffs to the DOM. I’m going to caveat this section with <em>I don’t know what the technical implementation is</em>, but I can make some assumptions given what I know of the domain. The system itself is intended to apply deltas to the DOM. This is naively also how React works, and I imagine under the hood it’s relying on React at least for part of it. We’ve had issues with this identified in two places already:</p>
<ul>
<li>progressive image loading</li>
<li>dynamic JSX components</li>
</ul>
<p>While they might not be linked to the same issue, they smell like they are, so we’re going to roll with it. The problem exhibits itself when you have a bunch of DOM that to a naive robot might look the same:</p>
<div data-language="text"><pre><code>&lt;div&gt;foo&lt;/div&gt;
&lt;div&gt;bar&lt;/div&gt;
&lt;div&gt;baz&lt;/div&gt;
&lt;div&gt;foobizbar&lt;/div&gt;</code></pre></div>
<p>In React it uses the graph to identify which node is which - effectively creating a unique entity ID based on its location. In cases where that’s difficult, React will warn you to explicitly bind a <code>key</code> attribute on each element to ensure it can more accurately deal with updates. While I would assume Gatsby is at least partially using React’s DOM engine, what we see in production effectively takes the above example, and replaces some of the content with other subsets of content - meaning it’s unable to accurately identify which nodes need updated.</p>
<p>We’ve seen this where a progressive image is replaced with an entirely different image that’s present near it on the page. We’ve also seen this happen for a dynamically loaded section of content (our language-selector include tags). While we’ve yet to identify a fix for the image tags, our other issue was resolved by literally changing a <code>div</code> tag to a different tag, one which is less commonly used (in our case, <code>section</code>).</p>
<p>All of the cases happen after Gatsby’s initial static render and exist only when applying some form of delta.</p>
<h2>Let’s Talk GraphQL</h2>
<p>It’s a static website generator. It literally does not need GraphQL all over the place. While there are few instances in the real world where that is valuable, it shouldn’t require a GraphQL API to read objects that are already in memory.</p>
<p>I don’t want to spend the energy to hammer this in, but take a look at Jared Palmer’s <a href="https://jaredpalmer.com/gatsby-vs-nextjs">Gatsby vs. Next.js</a> as it echoes my thoughts.</p>
<p>So, let’s actually not talk about GraphQL, but all its done is create complexity for us.</p>
<h2>Minor Gripes</h2>
<p>There’s a number of other things we’ve found fairly frustrating at this point, but this post is already getting long, so I’m choosing to summarize them.</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cra.mr/an-honest-review-of-gatsby/">https://cra.mr/an-honest-review-of-gatsby/</a></em></p>]]>
            </description>
            <link>https://cra.mr/an-honest-review-of-gatsby/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670252</guid>
            <pubDate>Sat, 03 Oct 2020 07:18:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get promoted (A guide for engineering managers)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24669805">thread link</a>) | @daniel-tlt21
<br/>
October 2, 2020 | https://www.tlt21.com/how-to-get-promoted/ | <a href="https://web.archive.org/web/*/https://www.tlt21.com/how-to-get-promoted/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

<article>
  

    <section>
      <p>When the engineering managers I coach struggle to find ambitious goals, I sometimes leverage their ambitions to help them identify areas where they can improve. But, to my surprise, not so many EMs have ambitions beyond their current role.</p><p>When I had a “real job”, I was always driven by the next thing. I didn’t care about the title, but I always wanted more impact and responsibilities (in six years and two companies, I had seven different positions 😅). While I don’t recommend being as “opportunistic” as I was (but hey, I ended up being an entrepreneur), I do believe that thinking about the next position gives you <strong>perspective and makes you more in control of your career</strong>. But the difference between thinking about your next promotion and getting it is enormous. </p><p>Many engineers believe that if you do great work at your job, people will recognise that work and automatically give you an adequate promotion or raise. It is unfortunately far from reality, as <strong>those who get promoted, are not the best employees, but the more visible</strong>.</p><figure><img src="https://www.tlt21.com/content/images/2020/10/image.png" alt="" srcset="https://www.tlt21.com/content/images/size/w600/2020/10/image.png 600w, https://www.tlt21.com/content/images/2020/10/image.png 900w" sizes="(min-width: 720px) 720px"><figcaption>Dilbert.com</figcaption></figure><h3 id="visibility-matters"><strong>Visibility matters</strong></h3><p>Think about your CTO’s typical day (or the VP Engineering, the one who will eventually decide on your promotion). They might have eight to ten meetings to attend, tens of emails (or Slack messages) to answer and they always have to switch their mind to a different project or a new problem that needs to be solved. So, unless you’re involved in the problem du jour, the number of seconds the CTO is thinking about you in a day is about zero. Pretty normal right? The CTO is a busy gal and can’t think about every single team member. But if you’re serious about this promotion, <strong>she should hear about you often</strong>. </p><p>In an <a href="https://staffeng.com/stories/katie-sylor-miller">interview with StaffEng</a>, Katie Sylor-Miller, a Frontend Architect at Etsy, says that “<em>a big part of being promoted [...] is making sure that your work is visible, that people know your name and you have a good reputation.</em>” I’m sure you’re thinking right now about OKRs, performance reviews, one-on-one(s) with your boss and all the other mechanisms in place at your company to make your work visible. Unfortunately, as rightly pointed out by <a href="https://defmacro.substack.com/p/how-to-get-promoted">Slava Akhmechet</a>, a product manager at Stripe, they’re too often <strong>“social fiction”</strong>:</p><blockquote><em>Following the overt mechanisms of advancement is neither sufficient nor necessary. It may even be actively harmful - almost everyone who does great work and takes performance reviews seriously toils in relative obscurity. Look at the people who occupy positions of considerable authority in your organisation. Did any of them get there by following some middle manager's feedback?</em></blockquote><p>Instead of social fiction, I think the word “game” is more appropriate for the advancement system in most companies (and any human interactions by the way). Since I’m pretty sure you’ve spent countless hours like me playing video games (or still do 🎮), how do you win at video games? <strong>You game the system</strong>.</p><h3 id="understand-the-promotion-process-at-your-company"><strong>Understand the promotion process at your company</strong></h3><p>If you’re currently an engineering manager, any promotion from now on will make you part of your company’s leadership team. And, as pointed out by <a href="https://lethain.com/being-visible/">Will Larson</a>, “<em>existing members of that team want to be comfortable that they’re expanding their ranks with folks they believe in, and they can’t believe in you if they don’t know you.</em>”</p><figure><img src="https://www.tlt21.com/content/images/2020/10/image-1.png" alt="" srcset="https://www.tlt21.com/content/images/size/w600/2020/10/image-1.png 600w, https://www.tlt21.com/content/images/size/w1000/2020/10/image-1.png 1000w, https://www.tlt21.com/content/images/2020/10/image-1.png 1240w" sizes="(min-width: 720px) 720px"><figcaption>FangXianUo/iStock</figcaption></figure><p>As an engineering manager, you’re not contributing anymore to the codebase. You’re<strong> contributing to the company’s success</strong>. Managing your team is the means to get there, not the goal. More specifically, an engineering manager contributes to the company’s success by:</p><p><strong>1/ Attracting and retaining the very best engineers</strong>: like <a href="https://www.joelonsoftware.com/2005/07/25/hitting-the-high-notes/">Joel Spolsky</a>, I firmly believe that an organisation “<em>where the best software developers in the world would want to work [leads] to profits as naturally as chocolate leads to chubbiness.</em>” So even if there is a process in place to attract engineers, everyone in the company will thank you if you managed to score a high-profile recruit (while saving thousands in headhunter’s fees). Some tips for doing so:</p><ul><li><strong>Be recognised externally as an expert</strong> and someone great engineers would want to work with (blogging, speaking…)</li><li><strong>Continuously look for talent</strong>, especially visible ones (the ones who blog, speak, live code, contribute to open source…) and invite them for informal interviews</li><li><strong>Mentor external engineers</strong> pro-bono, even if they don’t end working for you, they sometimes have friends who might</li></ul><p><strong>2/ Shipping revenue-generating projects</strong>: for any company out there, technology is just the means to make more money. So which projects in your company right now have the highest revenue-generating potential? There are usually three or four such projects per year, so you need to make sure your team is involved in these projects, even if it means <strong>being proactive about it and not waiting for your manager to assign it to you</strong>. When I was an employee, I used to regularly crash meetings (or discussions at the coffee counter) and see if I could be useful to a project.</p><p><strong>3/ Proactively solving problems:</strong> I’m sure you’re the kind of person who always presents problems with a solution. What’s even better is for you to <strong>start solving the problem before your boss is even aware of it</strong>. CTOs have to make countless decisions every day, and they need to know they can count on leaders in their team to be proactive and make the right decisions for them. Obviously, this action shouldn't say hidden and you would have sent a message to the leadership with information about the problem, what your team is doing to solve it and a deadline.</p><h3 id="building-your-promotion-playbook">Building your promotion playbook</h3><p>When I was advising startups on fundraising, most of the work we were doing was building up a great story that would unroll during the roadshow (3 to 6 months). Getting promoted is not the same as fundraising, but the mechanism is similar:</p><p><strong>1/ Make your intentions known</strong>: promotion is a two-way street, and your management should be aware of your objectives, as well as you should be aware of what they’re expecting from someone who does your targeted job. Ideally, they should state clearly what you should be demonstrating to get the job so that you can show you’ve done it when the time is right.</p><p><strong>2/ Keep a log of your achievements and impact:</strong> start a <a href="https://jvns.ca/blog/brag-documents/">brag document</a> or a <a href="https://staffeng.com/guides/promo-packets">promotion packet</a> that will be the base for any communication about your team’s accomplishments (especially the ones on high-impact projects).</p><p><strong>3/ Make it impossible for them to say no</strong>: when it’s promotion or review time, build a short presentation that shows factually how you achieved what the management expected of you and your team’s successes.</p><p>Keep in mind that <strong>the higher you go on the management ladder, the fewer positions are available</strong>. Sometimes you might want to make a lateral move at a smaller company to build up more responsibilities (like becoming CTO or VPE at a startup) before going back to a more mature company.</p><p>Last but not least, it’s essential to understand that while thinking about your next promotion should not be your main focus, <strong>it is part of your job</strong>. There are still way too many opportunistic leaders in technology organisations and not enough people like you. So please do me a favour, keep doing a great job AND get that promotion instead of all the opportunistic contenders 😉</p><hr><h3 id="news"><strong>News</strong></h3><p><em>This section is only available to email subscribers. <a href="https://www.tlt21.com/signup/">Sign up</a>, it's free!</em></p><hr><h3 id="summary"><strong>Summary</strong></h3><ul><li>Thinking about getting promoted gives you perspective and makes you more in control of your career</li><li>Those who get promoted are not the best employees, but the more visible</li><li>To be more visible: attract high-level engineers, ship revenue-generating projects, proactively solve problems</li><li>Getting promoted is a 6-month process that resembles a fundraising roadshow</li></ul><h3 id="reading-list"><strong>Reading List</strong></h3><p>[RESOURCE] <a href="https://progression.monzo.com/techops"><strong>Progression at Monzo</strong></a> - Monzo</p><p>[ESSAY] <strong><a href="https://defmacro.substack.com/p/how-to-get-promoted">How to get promoted</a> </strong>- Slava Akhmechet</p><p>[ESSAY] <a href="https://blog.pragmaticengineer.com/software-engineering-promotions/"><strong>Software Developer Promotions: Advice to Get to That Next Level</strong></a> - Gergely Orosz</p><p>[ESSAY] <a href="https://lethain.com/being-visible/"><strong>Being visible</strong></a> - Will Larson</p>
    </section>

      <section>
        <a href="https://www.tlt21.com/tag/personal/">Personal Development</a>
      </section>

          <section>
            <h3>TLT21 Newsletter</h3>
            <p>Join the newsletter to receive the latest updates in your inbox.</p>
            <form data-members-form="subscribe">
  <p><label for="subscribe-email-post">Your email address</label>
    
    
  </p>

  <p>Please check your inbox and click the link to confirm your subscription.</p>
  <p>Please enter a valid email address!</p>
  <p>An error occurred, please try again later.</p>
</form>          </section>

  <hr>
</article>




<!--
  Get related posts based on tags
 -->

    

        </div></div>]]>
            </description>
            <link>https://www.tlt21.com/how-to-get-promoted/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24669805</guid>
            <pubDate>Sat, 03 Oct 2020 05:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Starter Kit 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24669220">thread link</a>) | @todsacerdoti
<br/>
October 2, 2020 | https://wiki.alopex.li/RustStarterKit2020 | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/RustStarterKit2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>People were arguing about Rust’s std lib recently, so I went through the <code>Cargo.toml</code> of all the Rust projects I’ve written since 2015 and picked out the choice tools that get used over and over again. Up to date as of October 2020.</p>
<p>Also see <a href="https://wiki.alopex.li/RustCrates" title="Go to wiki page">RustCrates</a>, though that’s old. There’s also <a href="https://christine.website/blog/rust-crates-go-stdlib-2020-09-27">this</a>, which is narrower but deeper, and <a href="https://github.com/rust-unofficial/awesome-rust">awesome-rust</a>, which is shallower and broader, and the various <a href="https://www.arewewebyet.org/">more</a> <a href="https://arewegameyet.rs/">specific</a> <a href="https://areweasyncyet.rs/">websites</a> <a href="https://www.areweguiyet.com/">for various</a> <a href="https://areweideyet.com/">topics</a>.</p>

<p>I need to set up a new Rust dev environment, what do I install?</p>
<h2 id="linting-clippy">Linting – <code>clippy</code></h2>
<p>The one, the only, the great Rust style and correctness linter. Want to learn how to write “idiomatic” Rust, or just learn more about handy little corners of the language and library? Run <code>clippy</code> regularly. It’s distributed with the compiler via <code>rustup</code> now, so you have no excuse not to.</p>
<h2 id="build-cache-sccache">Build cache – <code>sccache</code></h2>
<p>Or, “how to make a full rebuild 70% faster”. <code>sccache</code> is a build artifact cache similar to <code>icecream</code> or <code>ccache</code>, except it’s actually trivial to just use. <code>cargo install sccache</code>, add a single line in a home dir config file, and you’re ready to go. Pretty much handles most crate and compiler versioning issues for you, so it Just Works if you update crates or install a new version of <code>rustc</code> or something. I think I’ve had to force-clear the cache due to some build weirdness a grand total of once. Looks like it has enough features to use in a professional context as well, at least on a small-to-medium scale.</p>
<h2 id="dependency-viewer-cargo-tree">Dependency viewer – <code>cargo-tree</code></h2>
<p>The best way to view what dependencies you are using, and what dependencies they are using, and so on. Best way to start cracking down on flabby dependencies.</p>
<h2 id="benchmarking-criterion">Benchmarking – <code>criterion</code></h2>
<p>Basically the best benchmark system out there. Incredibly simple to use, informative, and statistically sound. Doesn’t really do profiling, but it’s a good start for understanding your program’s performance, and better for proving that your implementation of X is faster than someone else’s.</p>
<h2 id="other-things">Other things</h2>
<p>Stuff that is less general purpose but occasionally very useful for the meta-programming process of choosing libraries, evaluating them, etc.</p>
<ul>
<li><code>cargo-geiger</code> – Measures how much unsafe code is in a codebase, and its dependencies</li>
<li><code>cargo-crev</code> – A <a href="https://wiki.alopex.li/ActuallyUsingCrev">very neat tool</a> for authoring and verifying distributed code reviews.</li>
<li>Various tools maintained by <a href="https://github.com/EmbarkStudios/rust-ecosystem">Embark Studios</a>, useful for production/company purposes like checking licenses, pinning specific versions of crates, etc.</li>
</ul>

<p>The cool stuff Real Computer Scientists write about.</p>
<h2 id="hashing">Hashing</h2>
<p>No specific crates here. There’s no single crate that provides All The Hash Algorithms, just lots of little ones that generally provide a single algorithm each. Just type the name of the algorithm you want into <code>crates.io</code> and you’ll get at least a couple options, choose the one with 8 million downloads or whatever. <code>sha2</code>, <code>md5</code>, <code>crc</code>, etc. Lots of them are written by the Rust core team.</p>
<h2 id="compression">Compression</h2>
<p>Same as the hashing category. Type <code>zip</code> or <code>bzip2</code> or whatever into crates.io and you’ll get what you need. <code>flate2</code> might be the one crate that’s not quite trivial to find. Again, many of them are written by the Rust core team.</p>
<h2 id="encryption">Encryption</h2>
<p>I have little actual experience or authority on this topic, so I’m going to punt on this one.</p>
<h2 id="pseudorandom-number-generator">Pseudorandom number generator</h2>
<p>Use <code>oorandom</code>. (Disclaimer, I wrote <code>oorandom</code>, but people besides me seem to like it.) More usually you’ll see the <code>rand</code> crate in use. If you’re doing Real Science and need to generate <a href="https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html">fancy probabilities</a>, then <code>rand</code> is the right tool, but most people aren’t doing that. Otherwise <code>rand</code> is complicated and has lots of features, while <code>oorandom</code> is very simple and has about two features, and I expect 80% of code to use at least one of them. <code>rand</code> has had several major breaking changes in its history that the rest of the ecosystem still hasn’t caught up with, while I intend <code>oorandom</code>’s API to change maybe twice in my lifetime. (Its version number, while obeying semver, is mostly a joke.)</p>
<p>There’s other lightweight PRNG crates that are just fine; see <code>oorandom</code>’s readme for a list of some others and choose one you like. Whatever you choose, use the <code>getrandom</code> crate to produce Real Random Seeds for it.</p>

<p>“I just need to solve this ooooooone common problem, but it needs to be solved WELL…”</p>
<h2 id="logging-log">Logging – <code>log</code></h2>
<p>Need to output log messages in your code? Why, use the <code>log</code> crate. Where do the log messages go? <code>log</code> provides only an interface, and that interface compiles to nothing if it isn’t used. You can write your own system for it to actually output the logs to, which is pretty easy, or use one of the small plethora of crates for it. My preferred one is <code>pretty_env_logger</code>, but <code>fern</code>, <code>slog</code> and others are all good too.</p>
<h2 id="parallel-data-crunching-rayon">Parallel data crunching – <code>rayon</code></h2>
<p>Ever have some computation where you have a big list of STUFF and want to process it in parallel, farming out jobs to as many threads as you have CPU’s? That’s what <code>rayon</code> does, and it does it really, really well. You still <a href="https://aspenuwu.me/posts/rust-optimization.html">have to know what you’re doing</a>, but changing a single <code>.iter()</code> into <code>.par_iter()</code> and watching your CPU-bound data-crunching run 8x faster is pretty magical. Now your CPU can help keep you warm this winter!</p>
<p>Please never use it in a library. It’s rude to spawn threads in library code, unless that’s specifically what the library is for.</p>
<h2 id="regexes-regex">Regexes – <code>regex</code></h2>
<p>To quote the inestimable <a href="https://www.jwz.org/blog/">jwz</a>:</p>
<blockquote>
<p>Some people, when confronted with a problem, think “I know, I’ll use regular expressions.” Now they have two problems.</p>
</blockquote>
<p>On the other hand, <a href="https://xkcd.com/208/">somebody’s gotta save the day</a>. So, use the <code>regex</code> crate. Also use <a href="https://crates.io/crates/ripgrep">anything else</a> <a href="https://crates.io/crates/xsv">written by BurntSushi</a>. BurntSushi is a paragon of Rust program design, and also just a great <del>human being</del> charred cuisine in general.</p>
<h2 id="threadsafe-globals-lazy_static">Threadsafe globals – <code>lazy_static</code></h2>
<p>“I know globals are evil,” you say, “but I just need one. I’ll only use it for good, I promise.” <code>lazy_static</code> has your back.</p>
<p>May eventually be superseded by <code>once_cell</code>, which looks like its <a href="https://github.com/rust-lang/rfcs/pull/2788">headed for inclusion into <code>std</code></a>.</p>
<h2 id="serializationdeserialization-serde">Serialization/deserialization – <code>serde</code></h2>
<p>Ever have a struct and just wanted to turn it into JSON, CBOR, XML, or some other engine of woe and devastation designed to be written to an I/O stream? Or had a blob of random JSON and wanted to just stuff it into a struct matching it? Sure you have. <code>serde</code> lets you do this with a single <code>#[derive]</code>. <code>serde</code> is without a doubt one of Rust’s killer libraries. It is better than any other serialization system I have ever used.</p>
<p>What data formats does it support? Anything; the actual reading and writing is done via plugin library. There’s a <a href="https://serde.rs/#data-formats">wide selection of them</a>, of varying quality, and writing your own is a little tedious but not terribly difficult.</p>
<h2 id="error-handling">Error handling</h2>
<p>This spot deliberately left blank.</p>
<p>Rust’s <code>Result&lt;T,E&gt;</code> type is one of the best setups for lightweight, transparent error handling I’ve seen, but it doesn’t do everything. How do you easily write your own error type without a bunch of boilerplate? What if you have multiple different error types from different libraries you want to coalesce together? How do you collect a backtrace of every function an <code>Err</code> is returned through, so you can find the root cause of where it came from? Can we do all this without allocating anything unnecessarily? And so on.</p>
<p>There have been various crates to try to solve these problems. First in 2015 there was <code>error_chain</code>, which was complicated and not very convenient. Then in 2017 there was <code>failure</code>, which was simpler but not very flexible, and which took an irritatingly long time to compile. Then in 2019 there was <code>anyhow</code>, which was about the time I stopped paying attention. Now apparently the new kid on the block is <code>eyre</code>, and I’m sure that in another year or two there will be something else.</p>
<p>So, I just write the boilerplate and make my errors descriptive enough I don’t need a backtrace. When I want to get fancy I implement the built-in <a href="https://doc.rust-lang.org/std/error/trait.Error.html"><code>Error</code></a> trait, which used to be kinda useless but is now more helpful. And in another five years it’ll still work just fine.</p>
<h2 id="byte-mucking-bytemuck">Byte mucking – <code>bytemuck</code></h2>
<p>For the rare occasions you need to turn a structure into arbitrary <code>&amp;[u8]</code> or back. Doing this using unsafe pointers is quite easy, and also makes it very easy to screw up horribly with Undefined Behavior galore. (Did you know that changing the value of padding bytes in a struct in UB? You do now.) <code>bytemuck</code> lets you muck around with bytes a little more responsibly.</p>
<h2 id="human-dates-and-times-chrono">Human dates and times – <code>chrono</code></h2>
<p>Rust’s <code>std::time</code> doesn’t really handle calendar or wall-clock times, just arbitrary, monotonic <code>Instant</code>’s and measurable <code>Duration</code>’s between them. Nice, pure, computationally-robust time measurement. For all the nasty human calendar and timezone stuff, you use <code>chrono</code>. (And maybe <code>humantime</code>, but I personally reach for <code>chrono</code> first, just out of habit.)</p>
<h2 id="bit-flags-bitflags">Bit flags – <code>bitflags</code></h2>
<p>Defining type-safe bit-masks in a reasonably convenient way. Not always worth the trouble, but sometimes pretty convenient.</p>

<p>“I have to create or read a…”</p>
<h2 id="pngjpeggifetc-image">PNG/JPEG/GIF/etc – <code>image</code></h2>
<p>General-purpose loading and saving and images, which can handle a lot of formats. Can do some amount of image manipulation as well, such as cropping, smoothing, etc. but that will hopefully be pulled out into its own library at some point soon.</p>
<h2 id="small-data-things-uuid-base64-csv-semver">Small data THINGS – <code>uuid</code>, <code>base64</code>, <code>csv</code>, <code>semver</code>…</h2>
<p>Exactly what it says on the tin.</p>

<p>Not aware of any great encoders, but there’s plenty of <em>decoders</em> for common audio formats. <code>lewton</code> for Ogg Vorbis, <code>hound</code> for .wav, <code>minimp3</code> for MP3, <code>claxon</code> for FLAC. Video, I haven’t used enough to have an opinion on.</p>
<h2 id="config-files-toml">Config files – <code>toml</code></h2>
<p>For all your config file format needs. Works with <code>serde</code>, naturally.</p>
<h2 id="markdown-pulldown-cmark">Markdown – <code>pulldown-cmark</code></h2>
<p>There’s several good Markdown readers and writers, <code>pulldown-cmark</code> is my favorite. It supports CommonMark, it’s simple to use, and it’s pure Rust.</p>
<h2 id="templating-askama">Templating – <code>askama</code></h2>
<p>There’s several quite good text templating engines, but <code>askama</code> IMO rises above them all by compiling your templates into Rust code and type-checking your templates at compile time. Sometimes this isn’t what you want, but it is a great feature surprisingly often. This also makes it super fast, for when you really need to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/RustStarterKit2020">https://wiki.alopex.li/RustStarterKit2020</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/RustStarterKit2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24669220</guid>
            <pubDate>Sat, 03 Oct 2020 03:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking Physics from the Back of a Napkin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24668522">thread link</a>) | @c1ccccc1
<br/>
October 2, 2020 | https://hapax.github.io/physics/teaching/hacks/napkin-hacks/ | <a href="https://web.archive.org/web/*/https://hapax.github.io/physics/teaching/hacks/napkin-hacks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>February 24, 2020.</strong> <em>The computational power of a humble napkin is
  awesome. I discuss three napkin algorithms — dimensional
  analysis, Fermi estimates, and random walks — and use them to
  figure out why rain falls, the length of the E. coli genome, and the
  mass of a proton, among other things. These examples suggest a
  napkin-based approach to teaching physics.</em></p>

<h3 id="contents">Contents</h3>

<ol>
  <li><a href="#sec-1">Hacking physics</a></li>
  <li><a href="#sec-2">Dimensional analysis</a>
    <ol>
      <li><a href="#sec-2-1">Pendulous pumpkins</a></li>
      <li><a href="#sec-2-2">Drag and drop</a></li>
      <li><a href="#sec-2-3">Usage notes</a></li>
    </ol>
  </li>
  <li><a href="#sec-3">Fermi estimates</a>
    <ol>
      <li><a href="#sec-3-1">Geometric means</a></li>
      <li><a href="#sec-3-2">Subestimates</a></li>
      <li><a href="#sec-3-3">KISS</a></li>
      <li><a href="#sec-3-4">Usage notes</a></li>
    </ol>
  </li>
  <li><a href="#sec-4">Random walks</a>
    <ol>
      <li><a href="#sec-4-1">Polymers</a></li>
      <li><a href="#sec-4-2">Bumping into things</a></li>
      <li><a href="#sec-4-3">Rainy day dilemma</a></li>
      <li><a href="#sec-4-4">Brownian motion</a></li>
    </ol>
  </li>
  <li><a href="#sec-5">Conclusion</a></li>
</ol>

<h2 id="1-hacking-physics-">1. Hacking physics <a id="sec-1" name="sec-1"></a></h2>

<p><em>Hacker spirit.</em> Nowadays, the word “hacker” conjures up visions of
Russian trolls, Julian Assange, and Angelina Jolie’s 90s pixie cut.
But a nobler usage predates this.
Hacker culture, in the original sense, grew out of places like MIT
in the 60s, with its tradition of highbrow silliness and elaborate technical pranks.
Although associated with programming, hacker spirit can be viewed as
a broader ethos about play, understanding and creativity.
In the words of open-source gnuru Richard Stallman,</p>

<p><span>
What [hackers] had in common was a love of excellence and
programming. They wanted to make the programs that they used be as
good as they could. They also wanted to make them do neat things. They
wanted to be able to do something in a more exciting way than anyone
believed possible and show ‘Look how wonderful this is. I bet you
didn’t believe this could be done.’
</span></p>

<p>Using techniques in a clever or unexpected way is a <em>hack</em>, with <em>hack
value</em> quantifying the degree of ingenuity. (“Hack” is actually a
back-formation of “hack value”.)
Hackers do not look for the most powerful, or obvious, or easy tool
for the job.
They delight in the unexpected, in using humble means to achieve
extraordinary ends.
In a way, they realise David Deutsch’s
<a href="https://en.wikipedia.org/wiki/The_Beginning_of_Infinity">definition</a>
of knowledge as
<em>information with causal power</em>.
Knowing a technique well enough to hack it means you can act on the world in new ways.</p>

<p>I think physics needs more hacker spirit: more people willing to fool
around and explore what our marvellous toolset can do, to creatively
defy expectations and push the Deutschian envelope.
Physics is not withouts its hackers but unlike computer
science, the hackers are colourful exceptions, tending towards
goofy irreverence and self-mythology
(<a href="https://en.wikipedia.org/wiki/Richard_feynman">Richard Feynman</a>
springs to mind).
I think hacking should go mainstream.</p>

<figure>
    <div><p><img src="https://hapax.github.io/images/posts/hacker1.png" width="45%"></p><figcaption><i>Physics needs more hacker spirit.</i></figcaption>
	</div>
	</figure>

<p><em>Napkin hacks.</em> My goal in this post is to outline a few simple hacks
for the back of a napkin.
I think of these as algorithms for a napkin computer, and with some
practice, they really
can be implemented using high school algebra on a small piece of
paper, without calculus or calculators (though the latter save
time).
While there is whimsy and irreverence aplenty, our focus will be
<em>real physics</em>.
Our goal will be a beautiful proof of the existence of atoms, due to
none other than Albert Einstein, the greatest physics hacker of all.
Another running theme is rain, a tribute to my rainy city of residence,
Vancouver.</p>

<figure>
    <div><p><img src="https://hapax.github.io/images/posts/einstein.jpg" width="45%"></p><figcaption><i>The greatest physics hacker of all.</i></figcaption>
	</div>
	</figure>

<p>Hackery is not just about excellence and creativity for their own
sake, but has clear pedagogical implications.
Most people have to wait until grad school to compute viscous drag, estimate
urban power usage, or determine the size of the E. coli genome.
But imagine a world where high school students are so empowered that,
given a few hints, a pencil, and a napkin, they could discover it all
themselves.
This world is very close to ours: all we need is a little more hacker
spirit in the enjoyment and instruction of physics.</p>

<p><em>Notes.</em> This post really consists of three distinct tutorials.
The <a href="#sec-2">dimensional analysis tutorial</a> and <a href="#sec-3">section on Fermi estimates</a> can be
read independently. The <a href="#sec-4">last tutorial</a> on random
walks assumes you have read the dimensional analysis section.
The exercises are just as important as the text, but only the results
of <a href="#sec-2-3">Exercise 3</a>
and <a href="#sec-4-2">Exercise 14</a> are used subsequently.
Solutions, and various other technicalities, are collected
<a href="https://hapax.github.io/assets/napkin-hacks-appendix">here</a>.</p>

<h2 id="2-dimensional-analysis-">2. Dimensional analysis <a id="sec-2" name="sec-2"></a></h2>

<p>We will start with one of the most powerful but underappreciated tools in
physics: <em>dimensional analysis</em>.
Physics is ultimately about experimental measurements.
Take some object, maybe an old pumpkin, and poke or prod it with a
measuring device.
The device returns a number, but that’s now what interests us;
instead, we want to know the <em>physical property</em> probed by that
device.
This is what we mean by <em>dimension</em>.
For instance, if we compare the width of the pumpkin to a ruler, the
dimension is the length, if we put it on some scales it’s the mass,
and if we time how long it takes to rot, the dimension is time.</p>

<p>We denote the dimension of length by $L$, time by $T$ and mass by
$M$.
We use brackets $[\cdot]$ to refer to the dimension of a measurement.
It’s easy when the measurement is given in some units, since we can
throw away the numbers and just ask: what aspect does the unit measure?
For instance,</p><p>

\[[20 \text{ cm}] = [\text{cm}]  = L, \quad [5 \text{ lb}]
=[\text{lb}] = M, \quad \quad [2 \text{ days}] =[\text{days}] = T.\]

</p><p>Centimetres measure length,
hours measure time, and pounds measure mass.
More complicated dimensions follow from the basic ones according to
simple rules which are easier to show than tell.
Area, for example, has dimensions $L^2$:</p><p>

\[[1 \text{ cm}^2] = [\text{cm}^2] = [\text{cm}]^2.\]

</p><p>An alternative to units is using general formulas, e.g. for the area of a rectangle:</p><p>

\[[\text{area}] = [\text{width}\times \text{height}] = [\text{width}]
\times [\text{height}] = L^2.\]

</p><p>Dimensions can be divided as well as multiplied:</p><p>

\[[\text{velocity}] = \left[\frac{\text{distance}}{\text{time}}\right] =
\frac{[\text{distance}]}{[\text{time}]} = \frac{L}{T}.\]

</p><p>Be careful: only measurements with the same dimensions can
be added and subtracted.
For instance, it makes no sense to ask what “$1$ cm + $4$ hours” is,
though it <em>is</em> sensible to compute “$1$ cm + $4$ feet”.</p>

<p>Physical laws tell us how measurements depend
on each other.
For example, Newton’s second law $F = ma$ tells us how measurements of
force, mass and acceleration are related.
If the two sides of $F = ma$ are equal, the dimensions must agree,
with</p><p>

\[[F] = [m a] = [m]\times \left[\frac{v}{t}\right] = \frac{ML}{T^2}.\]

</p><p>The point of dimensional analysis is that you can sometimes <em>reverse</em>
this process, and determine the physical laws from dimensions!
Let’s see how.</p>

<h3 id="21-pendulous-pumpkins-">2.1. Pendulous pumpkins <a id="sec-2-1" name="sec-2-1"></a></h3>

<p>Suppose we attach an old pumpkin to a length of string and give it a
kick.
Gravity will pull on the pumpkin, causing it to oscillate back and
forth with some period of oscillation $t$.
If we know how the period of oscillation depends on other properties
of the system, we can utilise this knowledge to make a pumpkin clock!
Let’s start by listing some relevant quantities:</p>
<ul>
  <li>the mass of the pumpkin $m$, with dimension $[m] = M$;</li>
  <li>the length of the string $\ell$, dimension $[\ell] = L$;</li>
  <li>gravitational acceleration $g = 9.8 \text{ m/s}^2$, dimension $[g] =
LT^{-2}$ (from the units);</li>
  <li>the initial displacement of the pumpkin $x$, dimension $[x] = L$.</li>
</ul>

<figure>
    <div><p><img src="https://hapax.github.io/images/posts/hacker3.png" width="30%"></p><figcaption><i>Physical features of the pendulous pumpkin.</i></figcaption>
	</div>
	</figure>

<p>Not all of these quantities will turn out to be relevant.
Galileo discovered that as long as the initial kick is
small, it has no affect on the period: pendulums are “isochronic”.
Grab a pumpkin, stopwatch and string, and check for yourself!
Galileo realised he could exploit this property to make a reliable
timepiece, and invented the pendulum clock.
(There is actually a deep physical reason pendulums are isochronic for
small kicks, but we will have to leave that for another time!)</p>

<p>In terms of relevant features, this leaves the pumpkin mass $m$, string length $\ell$, and gravity $g$.
You can also eliminate the pumpkin mass empirically, but as we’ll see,
we can leave it in and let dimensional analysis <em>tell us</em> it’s irrelevant.
At this point, I’m going to do something a bit sneaky.
Instead of period $t$, we will deal with the <em>angular velocity</em></p><p>

\[\omega = \frac{2\pi}{t}.\]

</p><p>(We will explain another way to get factors of $2\pi$ in Exercise 4.)
Dimensional analysis is nothing fancier than guessing that $\omega$ is related to $m$,
$\ell$ and $g$ by a relation of the form</p><p>

\[\omega = m^a \ell^b g^c,\]

</p><p>for some numbers $a$, $b$, and $c$.
Our goal is to figure out what these numbers are.
We can find the powers by matching dimensions on each side:</p><p>

\[\begin{align*}
\frac{1}{T} = [\omega] = [m^a \ell^c g^c] = \frac{M^aL^{b+c}}{T^{2c}}.
\end{align*}\]

</p><p>Requiring the leftmost and rightmost expressions to be equal, we can immediately read off the powers:</p><p>

\[a = 0, \quad 2c = 1, \quad b + c = 0 \quad \Longrightarrow \quad a =
0, \quad c = -b = \frac{1}{2}.\]

</p><p>As promised, dimensional analysis kindly informs us that the mass
is irrelevant!
My earlier piece of sneakiness (replacing period with angular
velocity) actually gives the exact answer for small kicks:</p><p>

\[\omega = m^a \ell^b g^c =  \sqrt{\frac{g}{\ell}}.\]

</p><p>We didn’t need to solve a differential equation, analyse forces, or even deal with numbers.
Dimensional analysis let us skip straight to the answer!</p>

<p>Suppose we want to make a pumpkin clock with the conventional
grandfather-clock period of $t = 2 \text{
s}$, so that each half swing takes
one second.
Then we should suspend the old pumpkin from a string of length</p><p>

\[\ell = \frac{g}{\omega^2} = \frac{g t^2}{(2\pi)^2} = \frac{9.8 \text{
m}}{\pi^2} \approx 1
\text{ m}.\]

</p><p>Incidentally, this explains why grandfather clocks are so large.
They will house a large (typically non-curcurbitar) pendulum with
$\ell \approx 1$ m.</p>

<p>In order to make the clock, we need a ruler to measure out the length
of string.
But for maximal whimsy, we can switch things up, and turn a stopwatch,
pumpkin and spool into a ruler!
Measure with the string and snip off the corresponding length, attach
the pumpkin and gently wobble.
By …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hapax.github.io/physics/teaching/hacks/napkin-hacks/">https://hapax.github.io/physics/teaching/hacks/napkin-hacks/</a></em></p>]]>
            </description>
            <link>https://hapax.github.io/physics/teaching/hacks/napkin-hacks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668522</guid>
            <pubDate>Sat, 03 Oct 2020 00:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C++ Guidelines]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24668455">thread link</a>) | @zerofrancisco
<br/>
October 2, 2020 | https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors | <a href="https://web.archive.org/web/*/https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>August 3, 2020</p>

<p>Editors:</p>

<ul>
  <li><a href="http://www.stroustrup.com/">Bjarne Stroustrup</a></li>
  <li><a href="http://herbsutter.com/">Herb Sutter</a></li>
</ul>

<p>This is a living document under continuous improvement.
Had it been an open-source (code) project, this would have been release 0.8.
Copying, use, modification, and creation of derivative works from this project is licensed under an MIT-style license.
Contributing to this project requires agreeing to a Contributor License. See the accompanying <a href="https://isocpp.github.io/CppCoreGuidelines/LICENSE">LICENSE</a> file for details.
We make this project available to “friendly users” to use, copy, modify, and derive from, hoping for constructive input.</p>

<p>Comments and suggestions for improvements are most welcome.
We plan to modify and extend this document as our understanding improves and the language and the set of available libraries improve.
When commenting, please note <a href="#S-introduction">the introduction</a> that outlines our aims and general approach.
The list of contributors is <a href="#SS-ack">here</a>.</p>

<p>Problems:</p>

<ul>
  <li>The sets of rules have not been completely checked for completeness, consistency, or enforceability.</li>
  <li>Triple question marks (???) mark known missing information</li>
  <li>Update reference sections; many pre-C++11 sources are too old.</li>
  <li>For a more-or-less up-to-date to-do list see: <a href="#S-unclassified">To-do: Unclassified proto-rules</a></li>
</ul>

<p>You can <a href="#S-abstract">read an explanation of the scope and structure of this Guide</a> or just jump straight in:</p>

<ul>
  <li><a href="#S-introduction">In: Introduction</a></li>
  <li><a href="#S-philosophy">P: Philosophy</a></li>
  <li><a href="#S-interfaces">I: Interfaces</a></li>
  <li><a href="#S-functions">F: Functions</a></li>
  <li><a href="#S-class">C: Classes and class hierarchies</a></li>
  <li><a href="#S-enum">Enum: Enumerations</a></li>
  <li><a href="#S-resource">R: Resource management</a></li>
  <li><a href="#S-expr">ES: Expressions and statements</a></li>
  <li><a href="#S-performance">Per: Performance</a></li>
  <li><a href="#S-concurrency">CP: Concurrency and parallelism</a></li>
  <li><a href="#S-errors">E: Error handling</a></li>
  <li><a href="#S-const">Con: Constants and immutability</a></li>
  <li><a href="#S-templates">T: Templates and generic programming</a></li>
  <li><a href="#S-cpl">CPL: C-style programming</a></li>
  <li><a href="#S-source">SF: Source files</a></li>
  <li><a href="#S-stdlib">SL: The Standard Library</a></li>
</ul>

<p>Supporting sections:</p>

<ul>
  <li><a href="#S-A">A: Architectural ideas</a></li>
  <li><a href="#S-not">NR: Non-Rules and myths</a></li>
  <li><a href="#S-references">RF: References</a></li>
  <li><a href="#S-profile">Pro: Profiles</a></li>
  <li><a href="#S-gsl">GSL: Guidelines support library</a></li>
  <li><a href="#S-naming">NL: Naming and layout rules</a></li>
  <li><a href="#S-faq">FAQ: Answers to frequently asked questions</a></li>
  <li><a href="#S-libraries">Appendix A: Libraries</a></li>
  <li><a href="#S-modernizing">Appendix B: Modernizing code</a></li>
  <li><a href="#S-discussion">Appendix C: Discussion</a></li>
  <li><a href="#S-tools">Appendix D: Supporting tools</a></li>
  <li><a href="#S-glossary">Glossary</a></li>
  <li><a href="#S-unclassified">To-do: Unclassified proto-rules</a></li>
</ul>

<p>You can sample rules for specific language features:</p>

<ul>
  <li>assignment:
<a href="#Rc-regular">regular types</a> –
<a href="#Rc-initialize">prefer initialization</a> –
<a href="#Rc-copy-semantic">copy</a> –
<a href="#Rc-move-semantic">move</a> –
<a href="#Rc-matched">other operations</a> –
<a href="#Rc-eqdefault">default</a></li>
  <li><code>class</code>:
<a href="#Rc-org">data</a> –
<a href="#Rc-struct">invariant</a> –
<a href="#Rc-member">members</a> –
<a href="#Rc-helper">helpers</a> –
<a href="#SS-concrete">concrete types</a> –
<a href="#S-ctor">ctors, =, and dtors</a> –
<a href="#SS-hier">hierarchy</a> –
<a href="#SS-overload">operators</a></li>
  <li><code>concept</code>:
<a href="#SS-concepts">rules</a> –
<a href="#Rt-raise">in generic programming</a> –
<a href="#Rt-concepts">template arguments</a> –
<a href="#Rt-low">semantics</a></li>
  <li>constructor:
<a href="#Rc-struct">invariant</a> –
<a href="#Rc-ctor">establish invariant</a> –
<a href="#Rc-throw"><code>throw</code></a> –
<a href="#Rc-default0">default</a> –
<a href="#Rc-default">not needed</a> –
<a href="#Rc-explicit"><code>explicit</code></a> –
<a href="#Rc-delegating">delegating</a> –
<a href="#Rc-ctor-virtual"><code>virtual</code></a></li>
  <li>derived <code>class</code>:
<a href="#Rh-domain">when to use</a> –
<a href="#Rh-abstract">as interface</a> –
<a href="#Rh-dtor">destructors</a> –
<a href="#Rh-copy">copy</a> –
<a href="#Rh-get">getters and setters</a> –
<a href="#Rh-mi-interface">multiple inheritance</a> –
<a href="#Rh-using">overloading</a> –
<a href="#Rc-copy-virtual">slicing</a> –
<a href="#Rh-dynamic_cast"><code>dynamic_cast</code></a></li>
  <li>destructor:
<a href="#Rc-matched">and constructors</a> –
<a href="#Rc-dtor">when needed?</a> –
<a href="#Rc-dtor-fail">may not fail</a></li>
  <li>exception:
<a href="#S-errors">errors</a> –
<a href="#Re-throw"><code>throw</code></a> –
<a href="#Re-errors">for errors only</a> –
<a href="#Re-noexcept"><code>noexcept</code></a> –
<a href="#Re-catch">minimize <code>try</code></a> –
<a href="#Re-no-throw-codes">what if no exceptions?</a></li>
  <li><code>for</code>:
<a href="#Res-for-range">range-for and for</a> –
<a href="#Res-for-while">for and while</a> –
<a href="#Res-for-init">for-initializer</a> –
<a href="#Res-empty">empty body</a> –
<a href="#Res-loop-counter">loop variable</a> –
<a href="#Res-???">loop variable type ???</a></li>
  <li>function:
<a href="#Rf-package">naming</a> –
<a href="#Rf-logical">single operation</a> –
<a href="#Rf-noexcept">no throw</a> –
<a href="#Rf-smart">arguments</a> –
<a href="#Rf-conventional">argument passing</a> –
<a href="#Rf-out-multi">multiple return values</a> –
<a href="#Rf-return-ptr">pointers</a> –
<a href="#Rf-capture-vs-overload">lambdas</a></li>
  <li><code>inline</code>:
<a href="#Rf-inline">small functions</a> –
<a href="#Rs-inline">in headers</a></li>
  <li>initialization:
<a href="#Res-always">always</a> –
<a href="#Res-list">prefer <code>{}</code></a> –
<a href="#Res-lambda-init">lambdas</a> –
<a href="#Rc-in-class-initializer">in-class initializers</a> –
<a href="#Rc-initialize">class members</a> –
<a href="#Rc-factory">factory functions</a></li>
  <li>lambda expression:
<a href="#SS-lambdas">when to use</a></li>
  <li>operator:
<a href="#Ro-conventional">conventional</a> –
<a href="#Ro-conversion">avoid conversion operators</a> –
<a href="#Ro-lambda">and lambdas</a></li>
  <li><code>public</code>, <code>private</code>, and <code>protected</code>:
<a href="#Rc-private">information hiding</a> –
<a href="#Rh-public">consistency</a> –
<a href="#Rh-protected"><code>protected</code></a></li>
  <li><code>static_assert</code>:
<a href="#Rp-compile-time">compile-time checking</a> –
<a href="#Rt-check-class">and concepts</a></li>
  <li><code>struct</code>:
<a href="#Rc-org">for organizing data</a> –
<a href="#Rc-struct">use if no invariant</a> –
<a href="#Rc-class">no private members</a></li>
  <li><code>template</code>:
<a href="#Rt-raise">abstraction</a> –
<a href="#Rt-cont">containers</a> –
<a href="#Rt-concepts">concepts</a></li>
  <li><code>unsigned</code>:
<a href="#Res-mix">and signed</a> –
<a href="#Res-unsigned">bit manipulation</a></li>
  <li><code>virtual</code>:
<a href="#Ri-abstract">interfaces</a> –
<a href="#Rc-concrete">not <code>virtual</code></a> –
<a href="#Rc-dtor-virtual">destructor</a> –
<a href="#Rc-dtor-fail">never fail</a></li>
</ul>

<p>You can look at design concepts used to express the rules:</p>

<ul>
  <li>assertion: ???</li>
  <li>error: ???</li>
  <li>exception: exception guarantee (???)</li>
  <li>failure: ???</li>
  <li>invariant: ???</li>
  <li>leak: ???</li>
  <li>library: ???</li>
  <li>precondition: ???</li>
  <li>postcondition: ???</li>
  <li>resource: ???</li>
</ul>



<p>This document is a set of guidelines for using C++ well.
The aim of this document is to help people to use modern C++ effectively.
By “modern C++” we mean effective use of the ISO C++ standard (currently C++17, but almost all of our recommendations also apply to C++14 and C++11).
In other words, what would you like your code to look like in 5 years’ time, given that you can start now? In 10 years’ time?</p>

<p>The guidelines are focused on relatively high-level issues, such as interfaces, resource management, memory management, and concurrency.
Such rules affect application architecture and library design.
Following the rules will lead to code that is statically type safe, has no resource leaks, and catches many more programming logic errors than is common in code today.
And it will run fast – you can afford to do things right.</p>

<p>We are less concerned with low-level issues, such as naming conventions and indentation style.
However, no topic that can help a programmer is out of bounds.</p>

<p>Our initial set of rules emphasizes safety (of various forms) and simplicity.
They may very well be too strict.
We expect to have to introduce more exceptions to better accommodate real-world needs.
We also need more rules.</p>

<p>You will find some of the rules contrary to your expectations or even contrary to your experience.
If we haven’t suggested you change your coding style in any way, we have failed!
Please try to verify or disprove rules!
In particular, we’d really like to have some of our rules backed up with measurements or better examples.</p>

<p>You will find some of the rules obvious or even trivial.
Please remember that one purpose of a guideline is to help someone who is less experienced or coming from a different background or language to get up to speed.</p>

<p>Many of the rules are designed to be supported by an analysis tool.
Violations of rules will be flagged with references (or links) to the relevant rule.
We do not expect you to memorize all the rules before trying to write code.
One way of thinking about these guidelines is as a specification for tools that happens to be readable by humans.</p>

<p>The rules are meant for gradual introduction into a code base.
We plan to build tools for that and hope others will too.</p>

<p>Comments and suggestions for improvements are most welcome.
We plan to modify and extend this document as our understanding improves and the language and the set of available libraries improve.</p>



<p>This is a set of core guidelines for modern C++ (currently C++17) taking likely future enhancements and ISO Technical Specifications (TSs) into account.
The aim is to help C++ programmers to write simpler, more efficient, more maintainable code.</p>

<p>Introduction summary:</p>

<ul>
  <li><a href="#SS-readers">In.target: Target readership</a></li>
  <li><a href="#SS-aims">In.aims: Aims</a></li>
  <li><a href="#SS-non">In.not: Non-aims</a></li>
  <li><a href="#SS-force">In.force: Enforcement</a></li>
  <li><a href="#SS-struct">In.struct: The structure of this document</a></li>
  <li><a href="#SS-sec">In.sec: Major sections</a></li>
</ul>

<h2 id="intarget-target-readership"><a name="SS-readers"></a>In.target: Target readership</h2>

<p>All C++ programmers. This includes <a href="#S-cpl">programmers who might consider C</a>.</p>

<h2 id="inaims-aims"><a name="SS-aims"></a>In.aims: Aims</h2>

<p>The purpose of this document is to help developers to adopt modern C++ (currently C++17) and to achieve a more uniform style across code bases.</p>

<p>We do not suffer the delusion that every one of these rules can be effectively applied to every code base. Upgrading old systems is hard. However, we do believe that a program that uses a rule is less error-prone and more maintainable than one that does not. Often, rules also lead to faster/easier initial development.
As far as we can tell, these rules lead to code that performs as well or better than older, more conventional techniques; they are meant to follow the zero-overhead principle (“what you don’t use, you don’t pay for” or “when you use an abstraction mechanism appropriately, you get at least as good performance as if you had handcoded using lower-level language constructs”).
Consider these rules ideals for new code, opportunities to exploit when working on older code, and try to approximate these ideals as closely as feasible.
Remember:</p>

<h3 id="in0-dont-panic"><a name="R0"></a>In.0: Don’t panic!</h3>

<p>Take the time to understand the implications of a guideline rule on your program.</p>

<p>These guidelines are designed according to the “subset of superset” principle (<a href="#Stroustrup05">Stroustrup05</a>).
They do not simply define a subset of C++ to be used (for reliability, safety, performance, or whatever).
Instead, they strongly recommend the use of a few simple “extensions” (<a href="#S-gsl">library components</a>)
that make the use of the most error-prone features of C++ redundant, so that they can be banned (in our set of rules).</p>

<p>The rules emphasize static type safety and resource safety.
For that reason, they emphasize possibilities for range checking, for avoiding dereferencing <code>nullptr</code>, for avoiding dangling pointers, and the systematic use of exceptions (via RAII).
Partly to achieve that and partly to minimize obscure code as a source of errors, the rules also emphasize simplicity and the hiding of necessary complexity behind well-specified interfaces.</p>

<p>Many of the rules are prescriptive.
We are uncomfortable with rules that simply state “don’t do that!” without offering an alternative.
One consequence of that is that some rules can be supported only by heuristics, rather than precise and mechanically verifiable checks.
Other rules articulate general principles. For these more general rules, more detailed and specific rules provide partial checking.</p>

<p>These guidelines address the core of C++ and its use.
We expect that most large organizations, specific application areas, and even large projects will need further rules, possibly further restrictions, and further library support.
For example, hard-real-time programmers typically can’t use free store (dynamic memory) freely and will be restricted in their choice of libraries.
We encourage the development of such more specific rules as addenda to these core guidelines.
Build your ideal small foundation library and use that, rather than lowering your level of programming to glorified assembly code.</p>

<p>The rules are designed to allow <a href="#S-modernizing">gradual adoption</a>.</p>

<p>Some rules aim to increase various forms of safety while others aim to reduce the likelihood of accidents, many do both.
The guidelines aimed at preventing accidents often ban perfectly legal C++.
However, when there are two ways of expressing an idea and one has shown itself a common source …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors">https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors</a></em></p>]]>
            </description>
            <link>https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#S-errors</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668455</guid>
            <pubDate>Sat, 03 Oct 2020 00:36:40 GMT</pubDate>
        </item>
    </channel>
</rss>
