<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 03 Mar 2021 17:02:09 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 03 Mar 2021 17:02:09 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Proposal for an Internet Service: The Eternal Home Page (1996)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26313569">thread link</a>) | @jstrieb
<br/>
March 2, 2021 | http://neilsloane.com/doc/eternal.html | <a href="https://web.archive.org/web/*/http://neilsloane.com/doc/eternal.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center><h2>Proposal for an Internet Service: The Eternal Home Page</h2></center><center>
<a href="http://neilsloane.com/index.html"> N. J. A. Sloane</a>
</center>
<center>
Information Sciences Research Center,
</center>
<center>
AT&amp;T Labs - Research, Florham Park, New Jersey 07932, U.S.A.
</center>
<center>
Email address: njasloane@gmail.com.
</center>
<center>
December 13, 1996. Revised November 11, 1997.
</center>
<center>
<h2><strong>Abstract</strong></h2>
</center>
<p>
This paper describes a possible Internet service that
some major organization such as
Harvard University, AT&amp;T,
the Institute of Electrical and Electronic Engineers,
the American Mathematical Society, the American Medical Association,
or even the Vatican, might offer: a home page "in perpetuity".
Such a "perpetual page" or "eternity page" or
"e-memorial page" would be a home page that the organization would
help the customer set up, with a guarantee that it would
last for (say) 500 years, or until the organization no
longer exists.
It would list all the things that the customer would like to
be remembered for (accomplishments, family, etc.).
As the population of the U.S. ages,
such a service should prove very popular.
After all, almost everyone wants to be remembered by posterity.
</p><center><h2> Details </h2></center>
<ul>
<li>
The name for this service needs to be chosen with care, and
of course registered. "Eternity service",
"Perpetual page", "Eternity page", "E-memorial page",
"Everlasting page"
are a few possibilities. I will use "Perpetual page"
in this paper.

</li>
<li>
The first version of this paper was written in
December 1996, although the idea for the "Perpetual home page"
first occurred to me in January 1996.
Not surprisingly,
it turns out that other people have had similar ideas, and there may be some
commercial services that provide electronic gravestones available even now.
But my vision is that
this service would be offered by a major organization or institute,
that has already existed for a long time and
has some chance of existing 500 years from now.
And I'm not thinking of tombstones, but home-pages.

</li>
<li>
The "Perpetual page" could include such things as:
<ul>
<li>
photographs of houses, boats, paintings, other precious possessions
</li>
<li>
lists of awards, accomplishments
</li>
<li>
writings, drawings, songs, even unpublished novels
(disk space is cheap)
</li>
<li>
links to perpetual pages of one's family (including ancestors!) and friends
</li>
</ul>

</li>
<li>
This is the customer's chance to write their own
<em>New York Times</em> obituary page, or "time capsule".
(Many people do not realize that except for a handful of major obituaries,
every obituary item in the <em>New York Times</em> has to be
purchased at about $40 per line -- this can be a humiliating
experience for the next-of-kin.
Setting up a "Perpetual page" in advance for the sick
and elderly could be both therapeutic and comforting for the family.)

</li>
<li>
There should be a generous amount of disk
space available for each page - a minimum of ten megabytes,
to allow a number of photographs to be included. (Most Internet
providers at present do not allow nearly enough disk space.)
As my colleague 
Andrew Odlyzko has pointed out in his
<a href="http://www.research.att.com/~amo/doc/tragic.loss.txt">
discussion of the future of scholarly journals</a>,
the cost of disk space is dropping so rapidly that it is likely that 
the cost of providing a service
in perpetuity will be not much more than that of providing it for
one year.

</li>
<li>
The organization would help the customer set up the initial page, and would
provide instructions on how to maintain it.
A "help desk" would be part of the service.

</li>
<li>
One way to structure the offer might be to tell customers:
For a one-time fee of $X, we will provide you with Y MB of
storage, and as long as you pay a small monthly fee,
you can keep modifying it.  Once you stop paying the monthly fee
(say because you die, or switch to a different
provider) we will keep the latest version <em>forever</em>.

</li>
<li>
Part of the offer would be a guarantee that when the Internet is replaced
by some other service in a few years, all the "Perpetual pages"
would be automatically converted to the new medium.

</li>
<li>
It is important that the organization offering the servce
should have been in existence for a long time, and have a good chance of
still existing 500 hundred years from now.
The organizations mentioned in the Abstract certainly
satisfy these conditions, and it is easy to think of others. 
Such a service would not carry much conviction
if offered by some tiny local Internet service provider.

</li>
<li>
This is the first time in history that such a thing is possible.

</li>
<li>
Incidentally,
the <em>New York Times</em>} for Saturday Dec. 7 1996 describes (on page D2)
a patent, US 5,517,791, for a new tombstone design that can
incorporate a person's life story - including photographs.
So ideas like the one I am proposing are "in the air".

</li>
<li>
As one may verify by visiting cemeteries in New Jersey, tombstones are rarely
legible after a hundred years have passed.  One of the advertisements for the
proposed service could show a family searching through a
cemetery full of grave stones that have been worn smooth,
looking for the lost grave of an ancestor.  Furthermore,
as the world population continues to explode,
cemeteries will become increasingly irrelevant.

</li>
<li>
The "perpetual page" service would especially appeal to mature customers.
There are several ways in which advertisements could point out the futility
of earlier attempts to be remembered, even by world leaders.
For example, one advertisement could show a replica of the original
Mausoleum at Halicarnassus,
after which all later mausoleums are named.
(See <em>The Oxford History of the Classical World</em>,
ed. J. Boardman et al., Oxford, 1993, p. 150.)
<center> <img src="http://neilsloane.com/doc/maus1.jpg"> </center>
<p>
One of the Seven Wonders of the World, it was
built in the year 353 for King Mausolus of Caria by his wife.
It no longer exists.
"But if King Mausolus had had a perpetual page, we could still read
about his victories today ...".

</p></li>
<li>
An alternative way in which the "perpetual page" could be used is
by family and friends after the death of a loved one, by setting up a
permanent memorial for the deceased.  The Page would need to have an
authorized keeper, to screen out inappropriate material.
A certain amount of permanent space would be purchased, to which
interested parties could contribute in any way they wished.


</li>
<li>
Another advertisement could have a voice reading P. B. Shelley's
poem <strong>Ozymandias</strong>,
while the picture shows dust blowing around an appropriate ruin:

<pre>     I met a traveller from an antique land 
     Who said: Two vast and trunkless legs of stone 
     Stand in the desert ... Near them, on the sand,
     Half sunk, a shattered visage lies, whose frown,
     And wrinkled lip, and sneer of cold command,
     Tell that its sculptor well those passions read
     Which yet survive, stamped on these lifeless things,
     The hand that mocked them, and the heart that fed:
     And on the pedestal these words appear: 
     `My name is Ozymandias, king of kings: 
     Look on my works, ye Mighty, and despair!' 
     Nothing beside remains. Round the decay 
     Of that colossal wreck, boundless and bare
     The lone and level sands stretch far away.
</pre>
<center><img src="http://neilsloane.com/doc/ozy4.jpg"> </center>
</li>
<li>
It will also give all the unpublished poets and writers,
the unrecognized painters and musicians, the scientists
whose theories are rejected, the opportunity to have their
work immortalized.

</li>
<li>
Yet another advertisement could have Jessye Norman singing the moving
and unforgettable aria "Remember Me"
from Henry Purcell's "Dido and Aeneas".
(The formal title
is "Thy hand Belinda - when I am laid in Earth"
[Philips CD 434 161-2].)

</li>
</ul>
<p>
<strong>Acknowledgements</strong>:  I am grateful to Colin Mallows, Andrew Odlyzko,
Susanna Cuyler Sloane and Nambi Seshadri for a number of helpful comments.

</p><center>
<img src="http://neilsloane.com/banners/bline.gif" alt=" ">
</center>
<p><strong>See also:</strong> <a href="http://neilsloane.com/index.html"> <strong>My home page</strong></a> | 
<a href="http://neilsloane.com/doc/links.html#ET"><strong>Related links</strong></a>





</p></div>]]>
            </description>
            <link>http://neilsloane.com/doc/eternal.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313569</guid>
            <pubDate>Tue, 02 Mar 2021 09:49:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A network of weather stations to help prevent pesticide spray drift]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26313216">thread link</a>) | @Damon_Mesonet
<br/>
March 2, 2021 | https://cotl.com.au/launch.html | <a href="https://web.archive.org/web/*/https://cotl.com.au/launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <a name="intro"></a>


              <figure>
                <a href="https://riverlandmalleemesonet.com.au/"><img alt="Screenshot of the Riverland Mesonet during the beginning of an inversion" src="https://cotl.com.au/assets/app-screenshot-riverland-inversion-e97e8509021dc60e59f9013061552f9c5589719e56dbf50e5420a2d2ffc36e1a.png"></a>
                <figcaption>Screenshot of the Riverland Mesonet during the beginning of an inversion</figcaption>
              </figure>


              <p>Hi from the team who built the "mesonet" weather station networks in the state of South Australia!</p>
              <p>A <a href="https://en.wikipedia.org/wiki/Mesonet">mesonet</a> is a term for a network of automated weather stations designed to monitor meteorological phenomena at high geographic density and updated frequently.</p>
              <p>We built these networks to help prevent pesticide <a href="#spraydrift">spray drift</a> - the phenomenon in which pesticide spray that is applied to a crop ends up drifting to other crops, sometimes many kilometres away.</p>
              <p>Spray drift can be a huge problem, as it can lead to damage or even destruction of highly valuable crops, and can also cause pollution to waterways and harm to native ecosystems.</p>
              <p>The biggest factor in spray drift the presence of a <a href="#thermalinversions">thermal inversion</a>, a state in which temperature increases with increasing altitude, which usually happens in the evening and overnight when the earth is cooling, but can happen at other times. However other meteorological phenomena also affect the likelihood of spray drift, and different types of spray respond differently.</p>
              <p>So we designed a <a href="#ourweatherstations">weather station</a> to measure all the relevant meteorological phenomena, and in particular to detect thermal inversions, and a custom <a href="#webapp">web app</a> to display the data in format that is very fast and simple to access and understand.</p>
              <p>We've now deployed 70 of these stations across two of the major agricultural regions of South Australia, and so far it seems to be making a difference: no damage due to spray drift has been reported in these regions since the networks were rolled out.</p>


              

              <a name="background"><h2>Background</h2></a>

              <p>A group of stakeholders in the <a href="https://en.wikipedia.org/wiki/Mid_North">Mid North region of South Australia</a> had identified spray drift as a major issue.</p>
              <p>The region, to the north of <a href="https://en.wikipedia.org/wiki/South_Australia">South Australia</a>'s capital of <a href="https://en.wikipedia.org/wiki/Adelaide">Adelaide</a>, has a thriving agricultural sector, producing wheat, barley, wine grapes, pulses, livestock and other produce.</p>
              <p>The total annual output from the region is valued at nearly AUD $2 billion. It has been estimated that the potential loss in production from spray drift could be as high as $178M/year, and potential harm to waterways and native ecosystems is significant.</p>
              <p>The local stakeholders worked with meteorologists and researchers to develop a solution, then sought funding from the South Australia state government to fund the project.</p>
              <p>In 2018, a $1.4M grant was provided, and a pilot rollout of 40 weather stations was undertaken.  It was named the Mid North Mesonet.</p>
              <p>The pilot was deemed successful, and in 2019, another grant was provided by the state government for a network in the <a href="https://en.wikipedia.org/wiki/Riverland">Riverland</a> and <a href="https://en.wikipedia.org/wiki/Murray_Mallee">Mallee</a> region to the north-east of Adelaide.</p>

              <p>In the two years since the Mid North Mesonet was rolled out, there have been no reported instances of crop damage due spray drift.</p>

              <a name="spraydrift"><h2>The Problem of Spray Drift</h2></a>
              <p>Farmers spray pesticides on their crops to manage pests. It is an important feature of modern farming. Herbicide may be applied to target broad-leaf plants, other times to target summer weeds.</p>
              <p>Spray drift occurs when pesticide spray 'drifts' across into non-target areas.</p>
              <p>Spray drift is a problem because:</p>
              <div>
                <ul>
                    <li>The affected non-target area may be particularly susceptible to pesticides (i.e. broad-leaf crops such as grapevines are especially vulnerable)</li>
                    <li>Some markets are highly sensitive to the amount of pesticide residues detectable in the end products (i.e. wine exports to China; organic farms; etc)</li>
                    <li>The affected non-target area might be a sensitive natural ecosystem (i.e. local waterways)</li>
                    <li>The affected non-target area might include rain water tanks used for drinking water</li>
                    <li>It is a waste of pesticide product and labour time costs</li>
                </ul>
              </div>

              <a name="causesofspraydrift"><h2>Causes of Spray Drift</h2></a>
              <p>A combination of conditions can lead to spray drift.</p>
              <h3>Wind Speed</h3>
              <p>Wind speed that is very low or very high.</p>
              <h3>Temperature</h3>
              <p>A temperature over about 28°C (83°F).</p>
              <h3>Humidity</h3>
              <p>The effect of humidity varies depending on the type of spray. The spray manufacturer's instructions should provide guidance.</p>
              <h3>Atmospheric Stability</h3>
              <p><i>Unstable</i> or <i>stable</i> conditions can lead to spray drift. Conditions should be <i>neutral.</i></p>
              <h3>Thermal Inversions</h3>
              <p>A thermal inversion, in which temperature increases with increasing altitude, is a major risk factor for spray drift.</p>
              <p>Inversions generally happen in the evening and overnight as the earth cools, but they can happen at other times.</p>

              <a name="thermalinversions"><h2>Thermal Inversions</h2></a>
              <p>For current farming practices, long-distance spray drift generally occurs during very stable weather conditions (i.e. little to no air turbulence).</p>
              <p>A thermal inversion occurs when a warm layer of air sits above a cooler layer of air near the ground.</p>
              <p>This reduces air turbulence and can act as a ‘lid’ for an airborne pollutant source. The lack of air turbulence means the smaller spray droplets float without settling on the target crops.</p>
              <p>A very slight breeze can then carry these floating droplets large distances before they eventually descend into a non-target area.</p>
              <p>It is illegal to spray during a thermal inversion.</p>

              <p><strong>The problem: it is very difficult for farmers to tell if a thermal inversion is underway.</strong></p>

              <figure>
                <img alt="Diagram of an inversion" src="https://cotl.com.au/assets/inversion-diagram-4620f5e78853d307f3eda98282034a2f31990112210498b118a7f7209d362393.png">
                <figcaption>Diagram of an inversion</figcaption>
              </figure>

              <figure>
                <img alt="Photograph of an inversion with smoke" src="https://cotl.com.au/assets/inversion-smoke-photograph-37a8df015d3d946abce8f157b9088b23458cf7be098822bc24c5ccc5c98ac6ac.png">
                <figcaption>Photograph of an inversion with smoke</figcaption>
              </figure>

              <a name="ourweatherstations"><h2>Our Weather Stations</h2></a>

              <p>Our weather stations were designed to:</p>
              <div>
                <ul>
                    <li>Measure temperature at 1.2m and 10m, in order to detect inversions</li>
                    <li>Measure all weather metrics that are relevant in determining whether it is safe to spray</li>
                    <li>Update data every 10 minutes, so farmers have access to the most recent readings</li>
                </ul>
              </div>

              <p>They consist of:</p>
              <div>
                <ul>
                    <li>Temperature sensors at 1.2m</li>
                    <li>Temperature difference between 10m and 1.2m</li>
                    <li>Wind speed and direction sensors at 2m and 10m</li>
                    <li>Tipping bucket rain-gauge</li>
                    <li>Solar radiation sensor</li>
                    <li>Pressure sensor</li>
                    <li>Relative Humidity sensor</li>
                    <li>Antenna</li>
                    <li>DataLogger which takes readings every 10 minutes, does some calculations locally, and uploads over cellular data (3G/4G) to the web server for processing and display</li>
                </ul>
              </div>
              <p>Each tower is self-powered by a solar panel and battery.</p>

              <figure>
                <img alt="Weather Station at Walker Flat, SA" src="https://cotl.com.au/assets/aws-walkerflat-700x400px-4c79a337af8e7993aa961117c4d7ce0714a59cf0d23192272858e23c0c7e8a6f.jpg">
                <figcaption>Weather Station at Walker Flat, SA</figcaption>
              </figure>

              <figure>
                <img alt="Weather Station at Pinkerton Plains, SA" src="https://cotl.com.au/assets/aws_pinkerton_550px-e67cf8f7ec5c635d25d6fd2855bd4144e8209d78f17d71c9443a3b5e924419ce.jpg">
                <figcaption>Weather Station at Pinkerton Plains, SA</figcaption>
              </figure>


              <a name="webapp"><h2>The Web Application</h2></a>

              <p>We initially used an off-the-shelf web application for displaying meteorological data, but soon realised we needed something tailored to our needs. We found a company that was already in the business of building web-applications to display environmental data for farmers, and they were willing to build a customised version for us.</p>

              <p>The key requirements for the application were:</p>
              <div>
                <ul>
                    <li>Each of the monitored metrics displayed on a map, with fast/simple switching between each metric</li>
                    <li>A dashboard of all the current key metrics and recent historical graphs</li>
                    <li>Long-term graphs of all the key metrics also available, and as well as the past 48 hours of data in tabular format</li>
                    <li>The site must display well and be easy to use on a mobile device, and be fast to use even in areas with low cellular signal strength, given that much of the usage will be by farmers out in the field in remote areas.</li>
                </ul>
              </div>

              <p>The key technologies are:</p>
              <div>
                <ul>
                    <li>Ruby on Rails</li>
                    <li>PostgreSQL</li>
                    <li>Redis</li>
                    <li>Sidekiq for queue processing</li>
                    <li>React</li>
                </ul>
              </div>

              <p>Data is uploaded from the data logger via FTP (which may seem primitive, but the world of meteorological data still relies heavily on FTP).</p>

              <p>On detection of new data, the application first takes the most recent readings, and updates the data structures for the map and dashboard views.</p>

              <p>The historical data is then placed in a queue, for updating of historical graphs.</p>

              <p>All the data for the map view, dashboards and historical graphs are formatted into a JSON hash then serialized and stored in the Redis cache. That way, when the React web interface makes a request, the pre-formatted data can be retrieved and sent very quickly, as no querying, processing or formatting of data is required at request time.</p>

              <figure>
                <a href="https://midnorthmesonet.com.au/"><img alt="Screenshot of the Mid North Mesonet Map View with wind speeds shown" src="https://cotl.com.au/assets/app-screenshot-mid-north-mesonet-e2dc04bb613cc2a2607527fb6973e8fd78f938152818a84f184d0f8aeba497d5.png"></a>
                <figcaption>Screenshot of the Mid North Mesonet Map View with wind speeds shown</figcaption>
              </figure>

              <figure>
                <a href="https://riverlandmalleemesonet.com.au/"><img alt="Screenshot of the Riverland Mallee Mesonet Map View with temperatures shown" src="https://cotl.com.au/assets/app-screenshot-riverland-mallee-mesonet-61fdac0ba62e4974f33b61ae5b121162a7078d7320f4be951f2eb55052a59ce2.png"></a>
                <figcaption>Screenshot of the Riverland Mallee Mesonet Map View with temperatures shown</figcaption>
              </figure>

              <a name="results"><h2>Results so far</h2></a>

              <p>In the two years since the Mid North Mesonet was deployed, there have been no reported cases of crop damage due to spray drift.</p>

              <p>Damage and loss had been reported in most of the previous years - though not all. So it is too early to tell if the problem has been completely solved, but indications are promising.</p>

              <p>Other government bodies and NGOs are expressing interest in establishing their own mesonets.</p>


              <a name="contacts"><h2>Contacts</h2></a>
              <p>
                Damon Grace<br>
                Project Engineer<br>
                damon.grace@cotl.com.au<br>
              </p>
              <p>
                Warwick Grace<br>
                Meteorologist<br>
                warwick@graceresearch.com<br>
              </p>
              <p>
                Tom Howard<br>
  …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cotl.com.au/launch.html">https://cotl.com.au/launch.html</a></em></p>]]>
            </description>
            <link>https://cotl.com.au/launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313216</guid>
            <pubDate>Tue, 02 Mar 2021 08:42:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PDP-1 Spotting – The Amherst Mystery]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26313124">thread link</a>) | @masswerk
<br/>
March 2, 2021 | https://www.masswerk.at/nowgobang/2021/pdp1-spotting | <a href="https://web.archive.org/web/*/https://www.masswerk.at/nowgobang/2021/pdp1-spotting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
		<article role="article">
		
		<time datetime="2021-03-01">March 1, 2021</time>
		<p>Yet another PDP-1 riddle, extended mode.</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/pdp1-spotting.jpg" alt="Spotting PDP-1s (and trains)" width="761" height="490">
		</figure>

		<p><span>Y</span>esterday, we solved the mystery of <a href="https://www.masswerk.at/nowgobang/2021/train-spotting-1">two well-known images</a>, formerly known as “The PDP-1 at the Tech Model Railroad Club”, with the help of the Hacker News community. — A triumph of shared knowledge.</p>
		<p>In 1971, the German artist Daniel Chodowiecki (1726 – 1801) commented his etching “Enlightenment” <em lang="de">(Aufklärung)</em> by the words, “However, if the sun only rises, mists do no harm.” <em lang="de">(Indessen wenn die Sonne nur aufgeht, so schaden Nebel nichts.)</em> In real life, mists rise only to reveal another bank of fog. Which is the very process of research. — And this is certainly no exception. So this is a post about annother bank of fog, in the amazing form factor of a fully transitorized electronic contraption apt to manipulate 18-bit words in realtime according to a stored program and human interaction.</p>

		<figure>
			<img src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-chodowiecki.jpg" alt="Daniel Chodowiecki, Aufklärung" width="512" height="876">
			<figcaption>Daniel Chodowiecki, <span lang="de">“Aufklärung”</span> (Enlightenment).<br>
			Image source: <a href="https://st.museum-digital.de/index.php?t=objekt&amp;oges=65771" target="_blank" rel="noopener" lang="de">Gleimaus Museum der deutschen Aufklärung</a>.
			<p lang="de" aria-label="Artits's comment (German language)">“Dieses höchste Werk der Vernunft … hat bis jetzt noch kein allgemeines verständliches allegorisches Zeichen (vielleicht weil die Sache selbst noch neu ist), als die aufgehende Sonne. Es wird auch wohl noch lange das schicklichste bleiben, wegen der Nebel, die immer aus Sümpfen, Rauchfässern und von neuen Brandopfern und Götzenaltären aufsteigen werden, die sie leicht verdecken können. Indessen wenn die Sonne nur aufgeht, so schaden Nebel nichts.”</p></figcaption>
		</figure>

		

		<h2>Another PDP-1B Prototype?</h2>
		<p><span>Y</span>esterday’s sunrise, <em>um,</em> success was the indentification of the scene of a series of images showing a somewhat rudimentary front part of a DEC PDP-1 and a Type 30 Visual CRT display next to a model railway layout. And we proceeded to conclude that this was a PDP-1 at the University of Massachusetts Amherst, operated by the Program Head of the CS program, J.A.N. Lee (probably around 1970).</p>

		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/dec.pdp-1.train_set.102631219.lg.jpg" alt="DEC PDP-1 at Amherst besides a model railroad layout, Computer History Museum, Catalog No. 102631219" width="496" height="500">
			<figcaption>Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102631219" target="_blank" rel="noopener">102631219</a>, Lot No. X2675.2004.</figcaption>
		</figure>

		<p>However, this also posed a new riddle, as at least two sources referred to this machine as a PDP-1B. Namely, the history page of the UMass Amherst CS program’ website,</p>
		<blockquote>
		The PDP-lB of those early days was soon replaced by three PDP-11s and a PDP-l5 with a graphics system.
		<cite>(<a href="https://www.cics.umass.edu/about/history-school-computer-science" target="_blank" rel="noopener">www.cics.umass.edu/about/history-school-computer-science</a>)</cite>
		</blockquote>
		<p>and the title of another photo of the same series (or lot) in the collection of the Computer History Museum (CHM), which isn’t available as a digitized image,</p>

		<blockquote>
			<dl>
			<dt>Title</dt>
			<dd>PDP-1/B and miniature model railroad at University of Massachusetts</dd>
			<dt>Catalog Number</dt>
			<dd>102757910</dd>
			<dt>Lot Number</dt>
			<dd>X2675.2004</dd>
			<dt>Type</dt>
			<dd>Still image</dd>
			<dt>Format</dt>
			<dd>Negative</dd>
			</dl>
			<cite>(CHM, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102757910" target="_blank" rel="noopener">102757910</a>, excerpt.)</cite>
		</blockquote>

		<p>Following established knowledge, there was a single PDP-1A prototype, followed by two PDP-1B pre-production prototypes (one going to Lawrence Livermore National Laboratory, LLNL, the other to BBN) and the production models PDP-1C and PDP-1D, the latter being the enhanced time-sharing model. Further, the two pre-production prototypes had a 4-cabinets main unit, which was repackaged for a more cost effective and reliable 3-cabinets design for the production models. This history leaves no apparent room for a PDP-1B at Amherst. So is this an error in these attributions, maybe referring to a common source as a single point of failure, or is there more to this?</p>

		<h2>PDP-1 Lineage</h2>
		<h3>All-White PDP-1s</h3>
		<p>The first prototype, PDP-1A, was an all white machine, featuring an integrated control desk with built-in CRT and operator’s console, a three-cabinet packaging of the main unit, and a Friden Flexowriter as a console typewriter. This machine was presented at the Eastern Joint Computer Conference in Boston in December 1959.</p>

		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-pdp1a.jpg" alt="PDP-1A prototype" width="500" height="353">
			<figcaption>PDP-1A prototype (Computer History Museum, Catalog No. <a href="https://www.computerhistory.org/collections/catalog/102618912" target="_blank" rel="noopener">102618912</a>).</figcaption>
		</figure>

		<p>The same machine (and the same image) also appeared in the initial announcement in Datamation, November/December issue 1959:</p>

		<figure>
			<a href="https://www.masswerk.at/nowgobang/images/pdp1-spotting-datamation.png" target="_blank" title="click to enlarge"><img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-datamation.png" alt="PDP-1 announcement, Datamation Nov/Dec 1959" width="900" height="1267"></a>
			<figcaption>PDP-1 announced in Datamation, November/December 1959 issue.<br>(Image source: <a href="http://bitsavers.org/pdf/dec/pdp1/JPEGs/pdp1_Datamation.jpg,%20http://bitsavers.org/pdf/dec/pdp1/JPEGs/pdp1_Datamation.jpg" target="_blank" rel="noopener">bitsavers.org</a>.)</figcaption>
		</figure>

		<p>Then, there is a white 4-cabinets machine seen in early DEC materials, here from a brochure from March 1961. This all-white machine features a 4-cabinets main unit, a detached control console with black print and the early DEC logo (more on this later), a CRT display in similar hexagonal housing as later Type 30 CRTs, but mounted on a narrower, single-unit stand, and a Soroban console typewriter (a modified IBM Model A):</p>
		<figure>
			<a href="https://www.masswerk.at/nowgobang/images/pdp1-spotting-pdp1-white-4-cabinets.jpg" target="_blank" title="click to enlarge"><img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-pdp1-white-4-cabinets.jpg" alt="Early PDP-1, white, 4 cabinets" width="900" height="581"></a>
			<figcaption>Early, white 4-cabinets PDP-1, featuring the early DEC logo on a detached console.<br>(Image source: DEC brochure F-11, March 1961, <a href="http://bitsavers.org/pdf/dec/pdp1/JPEGs/" target="_blank" rel="noopener">bitsavers.org</a>; post-processed.)</figcaption>
		</figure>
		<p>Apparently, we see this machine again at Bolt Beranek and Newman (BBN), in an image in <a href="http://www.walden-family.com/bbn/bbn-print2.pdf" target="_blank" rel="noopener">“A Culture of Innovation – Insider Accounts of Computing and Life at BBN”</a> by David Walden and Raymond Nickerson (ed.), 2010; page 51:</p>
		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-bbn-p51.jpg" alt="Early PDP-1 at BBN, white, 4 cabinets" width="900" height="813">
			<figcaption>Early, white PDP-1 with detached console at BBN. Mind the narrow CRT stand, similar to the above image.<br>(Image source: <a href="http://www.walden-family.com/bbn/bbn-print2.pdf" target="_blank" rel="noopener">“A Culture of Innovation”</a>, p.51, fig. 3.2.)</figcaption>
		</figure>
		<p>The following, rather blurry image from <a href="https://archive.computerhistory.org/resources/access/text/2018/08/102740407-05-01-acc.pdf" target="_blank" rel="noopener">“Digital Equipment Corporation – Nineteen Fifty-Seven to the Present”</a> (Digital Equipment Corporation, Maynard, MA, 1972; p.3) seems to show the same machine (all white, 4 cabinets, detached console), but with a different CRT with the standard double-unit display stand. Notably, the paper-tape devices on the left and the chairs look much like the one the BBN image, hinting at the photo showing the same installation.</p>
		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-1959-present-p3.png" alt="Early PDP-1 (at BBN?), white, 4 cabinets" width="600" height="295">
			<figcaption>Early, white PDP-1 with detached console. Mind the double-unit CRT stand, similar to production models.<br>(Image source: <a href="https://archive.computerhistory.org/resources/access/text/2018/08/102740407-05-01-acc.pdf" target="_blank" rel="noopener">“Digital Equipment Corporation – Nineteen Fifty-Seven to the Present”</a>, p.3.)</figcaption>
		</figure>
		<p>The same configuration appears in yet another photo (from the “DIGITAL Computing Timeline”), here, explicitely tagged as <em>“The PDP-1 operating system, the world's first timesharing system, is written by engineers at MIT and BBN for the PDP-1. (…) Shown here is the PDP-1 installation at BBN.”:</em></p>
		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-bbn-tmsh2.png" alt="BBN PDP-1 time sharing prototype" width="400" height="270">
			<figcaption>PDP-1B time-sharing prototype at BBN.<br>(Image source: <a href="https://www.vt100.net/timeline/1962.html" target="_blank" rel="noopener">vt100.net</a>; post-processed.)</figcaption>
		</figure>

		<p>At this point it may be fair to assume that the images of the white PDP-1B, found in early DEC brochures, are actually depicting the BBN PDP-1B.</p>

		<p>The last image (to my humble knowledge) in this lineage of all-white PDP-1s featuring a detached console seems to be an early production PDP-1 in 3-cabinets packaging at Itek (allegedly the second production machine):</p>
		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-itek2.jpg" alt="Early PDP-1 at Itek" width="612" height="478">
			<figcaption>Early, white prodcution PDP-1 with detached console at Itek.<br>(Image source: <a href="http://cadhistory.net/06%20First%20Commercial%20CAD%20System.pdf" target="_blank" rel="noopener">“The First Commercial CAD System”</a>, by David E. Weisberg, 2006 p.6-3, fig. 6.1.)</figcaption>
		</figure>

		<p>Something, all these all-white machines with a detached console have in common, is that they are lacking an integrated paper-tape unit. In these images, we see a separate generic paper-tape unit associated to the machine, usually to the left of the control console. DEC even envisioned the tape unit as a detached desk appliance, much like the control console:</p>
		<figure>
			<img loading="lazy" src="https://www.masswerk.at/nowgobang/images/pdp1-spotting-brochMar61_p6.jpg" alt="PDP-1 paper-tape unit as a desk appliance" width="700" height="443">
			<figcaption>Desk-appliance paper-tape unit, DEC brochure F-11, March 1961.<br>(Image source: <a href="http://bitsavers.org/pdf/dec/pdp1/JPEGs/" target="_blank" rel="noopener">bitsavers.org</a>; post-processed.)</figcaption>
		</figure>

		<p>Here’s a short history of this strand of PDP-1s, as comprehensively told in <a href="http://www.walden-family.com/bbn/bbn-print2.pdf" target="_blank" rel="noopener">“A Culture of Innovation – Insider Accounts of Computing and Life at BBN”</a> (ibidem, pp. 53–55):</p>
		<blockquote>
		<p>The Eastern Joint Computer Conference was in Boston in December 1959, and there Fredkin saw the PDP-1 and “realized it was fantastic.”
		The project to design and build the PDP-1 had started just four months prior to that. Ben Gurley was the designer, and he also built the computer with the help of one engineering assistant.</p>
		<p>“So,” says Fredkin, “I convinced BBN to become Digital’s first customer for the PDP-1. We arranged to borrow the prototype PDP-1 while Digital built the first ‘production’ version.” The prototype machine (a PDP model 1a) was delivered to BBN in early 1960.
		At the time, according to Fredkin, Digital had the idea that a computer manufacturer shouldn’t do software. Thus, Fredkin wrote the assembler for the machine, wrote utility routines (like a rudimentary operating system), and so forth. In that era programs were typically written on ruled sheets with columns for the various fixed-length instruction fields. Ed’s assembler for the PDP-1 was called FRAP, which stood for “free of rules assembly program” and which allowed variable-length instructions. At some point Fredkin also wrote light pen software for the machine.</p>
		<p>Eventually the first production model PDP-1, a PDP model 1b system (serial number 2), arrived at BBN. That was Digital’s first PDP-1 sale. Fredkin says,</p>
		<p>When the PDP-1b arrived, BBN had a ceremony with a lot of hoopla. I wrote a little program so that the PDP-1b could cut its own ribbon at a ribbon-cutting ceremony (appropriate since one of the ideas was for the PDP-1 to interact with the real world). Digital founder Ken Olsen was present.</p>
		<p>Bill Fletcher also was working with Fredkin on the PDP-1b. (…)</p>
		<p><strong>PDP-1b Time-Sharing: the Research Computer System</strong></p>
		<p>Fredkin says that he had the idea of hiring John McCarthy and Marvin Minsky. This soon led to plans to develop a time-sharing system for the PDP-1. McCarthy had the idea of time-sharing, and Fredkin saw the potential for time-sharing on the PDP-1. (…) Fredkin says,</p>
		<p>John’s invention of time-sharing and his telling me about his ideas all occurred before the PDP-1 existed. When I first saw the PDP-1 at the Eastern Joint Computer Conference, I realized that it was the perfect low-cost vehicle for implementing John’s ideas. That is why I specified that several of the modifications for time sharing be part of the PDP-1b.</p>
		<p>Fredkin knew Ben Gurley <em>[designer of the PDP-1; N.L.]</em> (from Lincoln Laboratory), who was the machine designer at Digital; thus, Fredkin also suggested or designed improvements for the hardware with time-sharing in mind. For instance, Fredkin designed the input/output system to be the first to have a modern …</p></blockquote></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masswerk.at/nowgobang/2021/pdp1-spotting">https://www.masswerk.at/nowgobang/2021/pdp1-spotting</a></em></p>]]>
            </description>
            <link>https://www.masswerk.at/nowgobang/2021/pdp1-spotting</link>
            <guid isPermaLink="false">hacker-news-small-sites-26313124</guid>
            <pubDate>Tue, 02 Mar 2021 08:27:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quality Means Teamwork]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26312993">thread link</a>) | @omoser
<br/>
March 2, 2021 | https://blog.codecentric.de/en/2021/03/quality-means-teamwork/ | <a href="https://web.archive.org/web/*/https://blog.codecentric.de/en/2021/03/quality-means-teamwork/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We are usually involved in projects demanding a high level of software quality, whether they be large legacy applications, where the customer is already beset with problems and is trying to shut the stable door after the horse has bolted, or newer pilot projects, which need to be built on stable foundations. As experienced technical experts we can of course help to get things on the right track. Having said that, we frequently find that our customers initially do not understand how quality is about a lot more than just good technology.</p><p>Even technically excellent teams can slip into quality problems if the working conditions or the project goal are unclear. In this article we explain why this is the case and what we can do about it.</p><h2>Is it a bug or a feature?</h2><p>Poor software quality often only comes to management’s attention when the number of errors reaches an unacceptable level. Yet what is actually a bug and what is just a (missing) feature? This question often leads to discussions between the product and development teams and cannot, strictly speaking, be answered without a clear written specification of the software’s requirements.</p><p>How do we decide during development what can be removed and what needs to remain? Most developers have experienced the situation where a bug fix leads to a string of new ones, due to something “not working like it used to” in the new version. For fear of breaking something, we often see developers steer clear of improving bad software design, which in turn leads to a continuing deterioration of the software’s maintainability.</p><p>To escape from this dilemma we need a shared understanding of what the software actually is: that is to say, what can it do and what not? Each user story should include clear acceptance criteria and, where applicable, define what is out of scope. For effective software development the team also needs to understand the broader context, i.e. not just <em>what</em> it is developing, but also <em>why</em> it is required and what concrete use cases are envisaged. Experienced teams avoid bugs through this type of communication, before they even begin with the implementation in code.</p><p>The development team still of course needs the right technical skills and experience in order to ensure that the software functions properly and is adequately protected through automated tests. Best practices such as pair programming, code reviews and test driven development (TDD) can help achieve this.</p><h2>Tests</h2><p>We frequently encounter projects with inadequate test coverage. Our approach is not to write new code or fix a bug without corresponding automated tests to verify the expected behaviour. This, however, presupposes that it is clear what the software is supposed to do.</p><p>Acceptance criteria in a user story serve as a basis for understanding this. Acceptance test driven development (ATDD) even goes so far as to translate the written specification into executable tests. Similarly, in the case of bugs, the way in which the functionality deviates from expected behaviour and how the error can be reproduced need to be clearly defined. This information can then be mapped into appropriate automated test cases so as to ensure functional correctness and avoid regression.</p><p>It is critical for the business to understand high test automation as an integral part of high-quality software <a href="https://blog.codecentric.de/2020/09/wie-qualitaet-uns-schneller-macht/">which actually makes development faster</a>: development speed should always be measured based on <em>working</em> features. Unfortunately, the deployment of technical experts is in many cases not enough to communicate this message, rather, the business often requires significant cultural and organisational upheaval, which reaches as far as management level, to achieve this. Development teams cannot bring about such a change on their own.</p><p>Additionally, efficient test automation can only be achieved when developers and testers work together cross-functionally. If testing is only carried out after the development stage (for example by a dedicated QA department) many of the advantages of test automation, such as fast feedback loops, are lost. Consequently organisational aspects such as team structure and process often go hand in hand with technical matters.</p><p>It is, on the other hand, not enough just to deliver good requirement documents and to expect a new culture to appear. Teams need to be capable of mapping these requirements onto an efficient test pyramid and ensuring the software still works in ensuing months and years. Even good teamwork is a skill that cross-functional teams need to learn through practice.</p><p>Furthermore, code testability is very much dependent on good software design. Technical methods, for example test driven development and refactorings, can help to improve this, and such methods can be more readily established when experienced developers or coaches are on hand.</p><h2>Refactorings</h2><p>Legacy applications often suffer from old code being difficult to understand and maintain. This leads to new features being very expensive and to an ever-increasing bug rate.</p><p>Experienced teams refactor their application code continuously and ideally avoid these pitfalls. They are capable of recognising how the software design can be improved as they go along in order to implement the current feature and regularly switch between the “two hats” (new functionality and refactoring) to achieve the goal in hand. They also keep an eye on upcoming requirements to ensure the technical foundations are optimised to deal with them. In order to achieve this they keep open a continuous dialogue with product team representatives and understand the current business goals.</p><p>But what happens when larger refactorings are required? Teams with only a technical focus might prefer to leave no stone unturned in order to achieve their interpretation of technical perfection and might even push for a complete rewrite of the application. This is, however, rarely the most efficient use of limited resources.</p><p>Refactorings should always be geared towards making the job in hand and future requirements easier and quicker to implement. Yet in order to achieve this, it is important to understand where the application is heading. A clear product vision and strategic focus on defined goals is critical so that refactorings with the most value (i.e. which improve future development speed) can be prioritised.</p><p>Whether larger refactorings should be undertaken is always a judgement call, which cannot be made solely based on technical reasons. A clear product strategy, which defines the key parameters for anticipated functional requirements, is incredibly helpful to estimate the relative effort of the refactorings and to answer important questions such as:</p><ul><li>How and to what extent will this component be extended in the coming development cycles?</li><li>Does the current software design satisfy the requirements on the product roadmap?</li><li>Do we (in the worst-case scenario) need to throw this component away and start from scratch?</li></ul><p>Nonetheless, even the best product vision cannot be fulfilled if teams do not have the technical skills to dig themselves out of the hole they find themselves in. Once it is clear where the journey is heading, developers still need the right technical skills and training to understand how to refactor a legacy application and keep the project on the right track.</p><h2>Architecture</h2><p>Software architecture is not an end in itself, but should seek to provide an optimal technical foundation for the product’s business requirements. There is no such thing as “the best architecture”, rather, it is always a question of making trade-offs. A software product will always have multiple architecture goals which conflict with and need to be weighed up against each other. Again, the product’s goal and its functional requirements will also play an important role here in making the appropriate architectural decisions.</p><p>During development, even the best teams will keep coming up against conflicts between current and future requirements. On the one hand, software architecture should be evolutionary and be improved incrementally, as it is impossible to predict users’ feedback and the exact nature of future priorities. Yet, on the other hand, certain architectural decisions do need to be made early enough in the development process so that the right foundation is in place to facilitate productive development. Only a well-functioning team, which not only brings together the relevant technical and business knowledge but also assumes responsibility for the software’s architecture, will be in a position to make the right decisions and react to changes in requirements in the best possible way.</p><p>Only through such teamwork is it possible to identify the right context boundaries in the application and to define the business domains and their objects. It is also critical to establish a universal language for these domains, so that business objects and the software’s use cases are clearly understood by the entire team.</p><p>Successful teams discuss the software’s architecture as part of their daily business and are able to experiment with various possible solutions. This is not possible in organisations where small predefined tasks are imposed on development teams from above or where teams are constantly under pressure from external deadlines. Agile practices in self-organised teams are therefore an important precondition for good architecture decisions.</p><p>It is, on the other hand, not enough simply to introduce agile frameworks and hope that this leads to teams being immediately capable of good software architecture. This will usually not be the case without support and coaching from experienced developers, especially if the previous working conditions were very different and the developers do not have prior experience of working in self-organised teams.</p><h2>Code quality and the “four eyes principle”</h2><p>Methods such as clean code, pair programming and code reviews help to achieve a high level of software quality. As technical coaches we can help out in these areas, but this …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codecentric.de/en/2021/03/quality-means-teamwork/">https://blog.codecentric.de/en/2021/03/quality-means-teamwork/</a></em></p>]]>
            </description>
            <link>https://blog.codecentric.de/en/2021/03/quality-means-teamwork/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312993</guid>
            <pubDate>Tue, 02 Mar 2021 08:05:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Problem with Perpetual Licensing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26312725">thread link</a>) | @filipacro
<br/>
March 1, 2021 | https://pacurar.dev/the-problem-with-perpetual-licensing/ | <a href="https://web.archive.org/web/*/https://pacurar.dev/the-problem-with-perpetual-licensing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<p>Unless you’ve been living under a rock, you know should know by now the perpetual licensing pattern: you buy a license to certain software, you receive updates for a year or two, depending on the license, then you stop receiving updates for the app and you can use that version forever.</p>



<p>The main problem with this type of license, from a user’s perspective, is consistency. <a href="https://pacurar.dev/uses/">I use</a> quite a few software with this type of license BUT the main difference is that some are updated daily/weekly or at least monthly and some are less frequently updated.</p>



<p>Most applications receive tons of updates after the initial release and then they magically stop receiving updates or new features for a while. My question is: why buy another year of your software if in the past 5-6 months I received only a minor update? What will I miss if you do not update it? Well, for most applications, you won’t miss anything… except some euros in your pocket.</p>



<p>On the other hand, there’s software like TablePlus that is fully worth paying for it year by year because it is updated a lot and you would miss a lot of features if you are stuck on an old version.</p>



<p>Nevertheless, I have a problem with all subscriptions lately. You pay a subscription for everything, and now you are required to pay monthly for software too. It all piles up, and sure, developers make more money and they can afford 5$ here and 5$ there, but again, it all piles up and at the end of the month you end up giving a lot of money on licenses.</p>



<p>So… maybe a perpetual license is ok though and it all depends on the developer itself if clients would renew their license: keeping an updated app and adding new features would make a higher percentage of the clients renew their license for another year.</p>



<p>What do you say, what is the best license for you and your needs? How many perpetual licenses do you pay yearly?</p>
<br>
            </div></div>]]>
            </description>
            <link>https://pacurar.dev/the-problem-with-perpetual-licensing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312725</guid>
            <pubDate>Tue, 02 Mar 2021 07:23:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DDD Is Overrated]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 70 (<a href="https://news.ycombinator.com/item?id=26312652">thread link</a>) | @mcp_
<br/>
March 1, 2021 | https://tilkov.com/post/2021/03/01/ddd-is-overrated/ | <a href="https://web.archive.org/web/*/https://tilkov.com/post/2021/03/01/ddd-is-overrated/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Update: There’s a <a href="https://www.innoq.com/en/blog/is-domain-driven-design-overrated/">slightly extended version of this post</a> over at the INNOQ company blog.</em></p>
<p>There, I said it. Now that I have your attention: Domain Driven Design (DDD) has recently gained additional popularity, as evidenced by new books, conference talks (and even complete conferences dedicated to it), and lots of trainings – including some by our very own colleagues at <a href="https://www.innoq.com/">INNOQ</a>. And in contrast to my click-bait headline, I’m actually a fan. <a href="https://www.dddcommunity.org/book/evans_2003/">Eric Evans’s book</a>, the additional work writing and evangelizing it done by <a href="https://vaughnvernon.com/">Vaughn Vernon</a> (e.g. in <a href="https://www.case-podcast.org/15-domain-driven-design-with-vaughn-vernon">this very good podcast</a> with my colleague Joy) and many others, are all very good additions to our industry’s body of knowledge. In the best sense of pattern languages, DDD gives clear names to things that many developers and designers know how to do, but cannot reliably and compatibly communicate about.</p>
<p>But I’m annoyed by the fact that recently, it seems that any time somebody talks about how to architect system or service boundaries, or even just mentions non-technical design, everybody feels compelled to bring in the DDD experts – as if they were the only superheroes who could possibly design anything at all. This is just as bad as any other situation where you blindly apply the solution that’s currently en vogue, just because it is the thing everyone talks about, and not because it is the right solution for the job. DDD is great, but it’s just one of many tools and techniques you should be aware of.</p>
<p>I think there is a more important aspect that people miss, especially when they get into DDD as their introduction to design in general. DDD emphasizes the importance of naming, and it suggests you should strive for a common, ubiquitous language, in the context you’re designing for. But it also uses its own language – concepts like bounded context, aggregates, entities, value objects, etc. – for our domain, the domain of designing systems. And while these are all well and good, they’re only one possible language. There’s value in calling a value object a value object, if this is a term many people understand, to facilitate communication. But the existing, common DDD concepts are not the only concepts you should consider – they are just examples of a very common trait of designing and architecting systems: Coming up with and recognizing patterns, giving them good names, and using them to give the system structure and integrity. If in your architecture, there’s a common pattern that you use a Filter to route requests to a Handler, or a concept of a Document that is handled by an Agent, then these things may occur again and again, on the same level as Services or Repositories, and end up being way more important to you. This is fine! This concept, that we can and should invent our own languages, is to me way more important than many naïve DDD practitioners think. I like to believe that DDD experts know this very well, and view any DDD material as a starting point, not an end result – but if all you’re doing is applying the by-the-book definition of existing DDD terms, and trying to shoe-horn any problem into this existing structure, yours is a very sad designer’s life.</p>
<p>There is a life beyond DDD. Not every good design needs to be Domain-Driven (though I can accept it should always be driven by the domain, just not necessarily in the DDD sense). You can design good systems even if you’re not a DDD expert.</p>

</div></div>]]>
            </description>
            <link>https://tilkov.com/post/2021/03/01/ddd-is-overrated/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312652</guid>
            <pubDate>Tue, 02 Mar 2021 07:08:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speed Is the Killer Feature]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26312516">thread link</a>) | @bdickason
<br/>
March 1, 2021 | https://bdickason.com/posts/speed-is-the-killer-feature/ | <a href="https://web.archive.org/web/*/https://bdickason.com/posts/speed-is-the-killer-feature/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		        
<p>Do you remember your first time using a modern smartphone? A vibrant screen that responded instantly when you tapped replaced cramped keyboards. You could sign your name, drag and drop apps around the screen, and even spin the giant Price is Right wheel to set your alarm. In 2007, this felt like a the future. There's a reason it was called 'the Jesus phone.'</p>
<p>At that same time, The Motorola Razr (<a href="https://www.youtube.com/watch?v=4_IK295sfxQ">video</a>) was the top phone on the market. It was a flip phone with the ability to take photos, play videos, browse the web, and play music. Sound familiar?</p>
<p>Phones in 2007 had the same features as the iPhone. The Palm Treo (<a href="https://www.youtube.com/watch?v=nK7FvGz4Jkc">video</a>) even had a touch screen.</p>
<img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/smartphones-2007.png">
<p>The difference was <em>speed</em>.</p>
<p>When you touched a Razr or a Palm phone, there was a delay. It felt sluggish and slow. Apple removed the delay between your finger tapping the screen and something happening. Your finger could finally manipulate the UI in realtime, just like in the real world. It felt magical. If there was even a slight delay, the whole experience fell apart.</p>
<p><strong>Speed is a killer feature. Speed is a differentiator.</strong></p>
<p>Yet teams consistently overlook speed. Instead, they add more features (which ironically make things slower). Products bloat over time and performance goes downhill.</p>
<p>New features might help your users accomplish something extra in your product.
<strong>Latency stops your users from doing the job they already hire your product for.</strong></p>
<p>Slow ui acts like tiny papercuts. Every time we have to wait, we get impatient, frustrated, and lose our flow.</p>
<h2>Honestly assess your speed</h2>
<p>I want you to take a moment and approach your product with a fresh set of eyes: Eyes for speed  👀</p>
<p>Go through your onboarding flow and try your core product features. Take mental note of how long each step takes to appear on the page then to be interactive.</p>
<p>How slow is it?
Be honest.
It’s ok, I’ve been there too.</p>
<p>Does your checkout page take 10+ seconds to load? Did you have to wait for a loading indicator multiple times along the way? Did things look interactive but weren’t loaded yet?</p>
<p>Every one of these is an opportunity. The great thing about speed (also called ‘performance’) is that you can stack rank it and burn it down.</p>
<p>Imagine what your product would feel like if everything happened in real time.</p>
<p><img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/speed-keanu-sandra.png"></p><p>Be like Keanu and fix every slowdown in your product. Your users will thank you.</p>
<h2>Places where speed matters</h2>
<ul>
<li>Speed during Checkout - Every second of page load time kills conversion rates. A 1 second delay <a href="https://neilpatel.com/blog/loading-time/">reduces conversion rate by 7%</a>.</li>
<li>Framerate in Virtual Reality - The early days of Virtual Reality caused intense nausea akin to motion sickness <a href="https://link.medium.com/QyheLe9rbeb">when framerates dropped below 60fps</a>.</li>
<li>Design Tools - Users are consistently frustrated when Sketch or Figma are slow. <a href="https://quizlet.com/blog/everything-i-know-about-design">Designers have high APM</a> (actions per minute) and a small slowdown can occur 5-10 times per minute.</li>
<li>The core interaction of your product - Your product exists to save people time or help them solve a problem. Introducing friction or delay during the most important flow of your product will drive people crazy. Notion has developed a reputation for being a sluggish product:</li>
</ul>
<img src="https://bdickason.com/static/posts/speed-is-the-killer-feature/reddit-notion.png">
<h2>Perception vs. Reality</h2>
<p>If you can’t speed up a specific action, you can often fake it. Perceived speed is just as important as actual speed. Even if you can’t be fast, you should appear to be fast.</p>
<p><strong>Large content</strong> - Render the screen while content loads so the user knows what’s coming.
<strong>Long load times</strong> - Make the screen interactive, even if everything hasn’t loaded.
<strong>Waiting for an action</strong> - Allow the user to take the action and keep moving but post the action in the background.
<strong>Very long actions</strong> - If you have an action that will take 30s or more, offer to notify the user (e.g. via email) when the action is available.</p>
<p>Here are some examples of products that fake being fast:</p>
<ul>
<li>Facebook’s app pioneered loading images that look like actual content. The structure and UI of the page loads but the content does not. As a result, you can still use the product and prepare to take actions, even if the content hasn’t loaded.</li>
<li>Games have a rule to never block the input thread. You can slow down the visuals but the controls should always feel responsive so the user feels in control.</li>
<li>Robinhood has you swipe up to trade, but runs your transaction in the background and notifies you via email when your trade is complete.</li>
</ul>
<h2>When is it ok to be slow?</h2>
<ul>
<li>When there is a physical constraint that causes things to take a while (e.g. dispensing money from an ATM)</li>
<li>When you want to give people a chance to correct a mistake (e.g. Gmail's "undo" feature)</li>
<li>When a human has to keep up with a machine (e.g. we slow down video game framerates, otherwise the game would run at 60x speed and overwhelm you).</li>
</ul>
<h2>Bonus Fun: What would it be like to live with lag?</h2>
<p>Imagine making breakfast with a 1 second latency added to every action you take. Even something as simple as moving your hands so that an egg rests over a bowl becomes incredibly challenging.</p>
<p><strong>Here's a real life experiment where 0.5-3s of latency was added to everyone's action via a VR headset:</strong></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/_fNp37zFn9Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>This is what we're forcing on people when we ship laggy software. We're making them spend their time waiting for us.</p>
<p><strong>Do you struggle to prioritize speed for your product? I'd love to hear more: <a href="http://twitter.com/bdickason">@bdickason</a></strong></p>
<p><strong>Get my newsletter.</strong>  It features simple improvements you can make to improve your day-to-day PM life. From Product Vision/Strategy to Goals and Metrics to Roadmaps and everything in between.</p>


<center></center>


<p>Soundtrack: <a href="https://www.youtube.com/watch?v=MviNwNKYLN4">Mega Ran &amp; Futurecop! - Slow Down</a></p>

<p> <a href="https://open.spotify.com/playlist/1sjamnHIeKEKqkYVwFtXo9?si=NAShg2i5TzetT69GKQ9Irw">See all songs featured on my site.</a></p>
<p>Post last updated: Feb 25, 2021
</p><h2 id="posts">Posts</h2>
<div>
<ul>
<li>
<p><a href="https://bdickason.com/posts/speed-is-the-killer-feature/">Speed is the killer feature</a> <span>Feb 25, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/manage-your-manager/">How to manage your manager</a> <span>Feb 19, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/social-thinkers-solo-thinkers/">Social thinkers vs. Solo thinkers</a> <span>Feb 11, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/pm-lead-massive-projects-writer-editor/">How top silicon valley PM's lead massive projects</a> <span>Feb 4, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/hardware-release-software-release/">How great hardware and software teams ship</a> <span>Jan 21, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/most-pms-dont-use-their-product/">Most PM's don't use their own product</a> <span>Jan 15, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/the-best-product-management-books-articles/">The Best Product Management books, articles, and videos</a> <span>Jan 8, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/gather-great-feedback-from-power-users/">How to gather great feedback from your power users</a> <span>Jan 4, 2021</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/biggest-pm-learning-2020-set-an-intention/">Set an intention for the year (and tell everyone)</a> <span>Dec 27, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/strategy-write-great-prereads/">Write great pre-reads and land your strategy</a> <span>Dec 21, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/write-things-down/">Write Things Down</a> <span>Dec 2, 2020</span></p>
</li>
<li>
<p><a href="https://bdickason.com/posts/strategy-101-unpack-your-assumptions/">Strategy 101: Unpack your assumptions</a> <span>Nov 19, 2020</span></p>
</li>
</ul>
</div>

		


	  </div></div>]]>
            </description>
            <link>https://bdickason.com/posts/speed-is-the-killer-feature/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312516</guid>
            <pubDate>Tue, 02 Mar 2021 06:40:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers: Before you turn 40, get a plan B]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26312500">thread link</a>) | @generichuman
<br/>
March 1, 2021 | https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/ | <a href="https://web.archive.org/web/*/https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					<br><h2>Welcome to geezer town, junior.</h2>
<p>While researching my recent article, “<a title="Article on Age Discrimination by yours truly" href="https://improvingsoftware.com/2009/04/20/age-discrimination-and-programming-jobs/" target="_self">Age discrimination and Programming Jobs</a>”&nbsp;, I discovered a <a title="NYT Article: &quot;Now Hiring, if you're young.&quot;" href="http://www.nytimes.com/1998/01/26/opinion/now-hiring-if-you-re-young.html" target="_blank">1998 Op-Ed piece from The New York Times</a>&nbsp;that cited some startling statistics from the NSF and Census bureau about the longevity of a software engineering career.</p>
<blockquote><p>[S]ix years after finishing college, 57 percent of computer science graduates are working as programmers; at 15 years the figure drops to 34 percent, and at 20 years — when most are still only in their early 40’s — it is down to 19 percent. In contrast, the figures for civil engineering are 61 percent, 52 percent and 52 percent.</p></blockquote>
<p><img data-attachment-id="677" data-permalink="https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/retiredprogrammer/" data-orig-file="https://softwareplusplus.files.wordpress.com/2009/05/retiredprogrammer.jpg" data-orig-size="210,210" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="RetiredProgrammerButton" data-image-description="<p>Retired programmer button</p>
" data-medium-file="https://softwareplusplus.files.wordpress.com/2009/05/retiredprogrammer.jpg?w=210" data-large-file="https://softwareplusplus.files.wordpress.com/2009/05/retiredprogrammer.jpg?w=210" title="RetiredProgrammerButton" src="https://softwareplusplus.files.wordpress.com/2009/05/retiredprogrammer.jpg?w=468" alt="RetiredProgrammerButton" srcset="https://softwareplusplus.files.wordpress.com/2009/05/retiredprogrammer.jpg 210w, https://softwareplusplus.files.wordpress.com/2009/05/retiredprogrammer.jpg?w=150 150w" sizes="(max-width: 210px) 100vw, 210px">I find the defensive tone of the article and the use of dubious sampling of only computer science graduates to support its conclusion undermines its credibility. In a lot of ways, the Government has been very slow to grok the software engineering trade. In this study it completely ignores the significant number of working programmers who either earned their degree in another discipline or never finished college.</p>

<p>&nbsp;Still, smart money seems to concur that the software engineer depreciates only slightly more slowly than the machine he or she toils behind as exemplified in this 1996 comment from <a title="Craig Barrett Bio" href="http://en.wikipedia.org/wiki/Craig_Barrett_(businessman)" target="_blank">Craig Barrett</a>, then President and Co-founder of Intel.</p>
<blockquote><p>The half-life of an engineer, software or hardware, is only a few years.</p></blockquote>
<p>Sure, the guy’s a suit, but more importantly he was (at the time) a 57 year old former engineer publicly reinforcing the discriminatory notion of expiration dates on other engineers. It’s scary as hell to think that such an influential industry insider thinks that a programming career is roughly the same as a professional basketball player’s.</p>

<h2>My take on the issue</h2>
<p>Considerable accusatory ink has been dedicated to the age discrimination problem in technology, but I suspect it may be an inevitable consequence of the rapid pace of change that defines this field.</p>
<p>Consider the following:</p>
<ul>
<li>The market value of an employee is primarily determined by experience in technologies relevant to the employer.</li>
<li>Software engineering reliably undergoes a major technology shift at least every 10 years.</li>
<li>While a technology shift doesn’t completely negate the skills of veterans, it certainly levels the playing field for recent grads.</li>
</ul>
<p>Now put yourself in the shoes of a prospective hiring manager using a newer technology like Ruby on Rails for which nobody other than <a title="Creator of Rails" href="http://www.loudthinking.com/about.html" target="_blank">David Heinemeier</a>has more than about 5 years of experience. &nbsp;Sure, that extra 10 years of C++ experience is a positive differentiator for the veteran over the upstart with the same 3 years of Rails experience.&nbsp; All things equal you’d naturally hire the guy with more total experience.</p>
<p>However, all things are NOT equal. Those 10 years of C++ experience made the veteran candidate progressively more expensive as they leveraged the value of that experience in jobs requiring C++. The problem is that the marginal utility of that extra experience must exceed the marginal cost of hiring the veteran to justify paying the premium.</p>
<p>Herein is the source of the problem. The more irrelevant experience a candidate has, the more lopsided the utility/value equation becomes, and this presumes that the manager even has the luxury of paying extra to get that experience.</p>
<p>Even if the veteran prices himself competitively with a younger candidate, the hiring manager has to consider the implications of bringing in someone taking a big pay cut. Will they have morale issues from day one? Are they going to change their mind after a month that they really do need that extra cash and leave? It’s a sticky situation.</p>
<p>The unfortunate truth is that unlike other forms of discrimination that are more arbitrary and capricious, age discrimination can often be a result of objective and sound business justifications. I’m not trying to justify it as an acceptable practice, but just trying to describe the pickle it puts the manager in trying to make a sound business decision without compromising the ethical and legal obligations of the company.</p>
<h2>So what’s your plan B?</h2>
<p>Assuming you aren’t fabulously wealthy, accepted to clown college, or the fatal victim of a Red-bull induced heart attack by 40 a mitigation strategy is in order. Here are some viable options.</p>
<p><img data-attachment-id="678" data-permalink="https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/chooseadventure/" data-orig-file="https://softwareplusplus.files.wordpress.com/2009/05/chooseadventure.jpg" data-orig-size="190,310" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="chooseadventure" data-image-description="<p>Choose Your Adventure Book Cover- The Cave of Time</p>
" data-medium-file="https://softwareplusplus.files.wordpress.com/2009/05/chooseadventure.jpg?w=184" data-large-file="https://softwareplusplus.files.wordpress.com/2009/05/chooseadventure.jpg?w=190" title="chooseadventure" src="https://softwareplusplus.files.wordpress.com/2009/05/chooseadventure.jpg?w=468" alt="chooseadventure" srcset="https://softwareplusplus.files.wordpress.com/2009/05/chooseadventure.jpg 190w, https://softwareplusplus.files.wordpress.com/2009/05/chooseadventure.jpg?w=92 92w" sizes="(max-width: 190px) 100vw, 190px"></p>
<h3>Work for the one person who would never discriminate against you.</h3>
<p>No. Not your mother. You! If you aren’t the entrepreneurial type, consider a consultancy. For some reason that I don’t completely get, a little gray hair and a smattering of experience in different technologies can create a beneficial bias for companies when they are renting brains instead of buying them outright. It may have something to do with the tendency for consultants to be vetted from higher up in the management chain where the silver foxes live.</p>



<h3>Give in to the dark side and go into management.</h3>
<p>I’d argue that a career in programming does precious little to prepare someone for management, but clearly management thinks that everyone including technologists harbors a deep longing to “graduate” into their ranks. I think it a fallacy that no one would continue to design and build software for 20 years unless they had no ambition or growth potential. However, people like me that respect such dedication to the craft are in the minority. Maybe it is best to just stop fighting it, but consider the following before taking the plunge:</p>
<ul>
<li>Mid-level managers often make very little more, if not the same as high level engineers.</li>
<li>It gets progressively harder to keep up with new technology because you don’t work directly with it.</li>
<li>Meetings, politics and dealing with unrealistic requests will pretty much become your life.</li>
<li>You may try to avoid it, but management-speak will creep into your vocabulary (did you notice my “paradigm” comment earlier?)</li>
<li>Even when it isn’t your fault, it’s your fault.</li>
<li>Even when you make it succeed, your team should get the credit.</li>
<li>Being the wunderkind as a technologist is much easier to do in technology than management, you’ll have to check your ego at the door.</li>
<li>You will be forced to make decisions that affect people’s personal life (pay, bonus, firing, etc.) and this is hard to stomach sometimes.</li>
<li>It is very empowering, enjoyable to be able to set the agenda and sometimes say, “No. We ain’t doing that shit.”</li>
<li>Computers are predictable, people are complicated. You will eventually fantasize about robot employees.</li>
<li>Mentoring can be very rewarding, but also very challenging.</li>
</ul>
<blockquote><p>The most difficult thing in the world is to know how to do a thing and to watch someone else do it wrong without comment.<br>
-Theodore H. White.</p></blockquote>
<h3>You’ve got a cash cow, milk that sucker!</h3>
<p>I know you love programming because you like technology, so this may go against your very nature, but no one says you’ve got to jump every time some snot-nosed kid invents a new way to run byte-code. You have invested a lot of time and energy mastering the technology you use, and your experience differentiates you. Money follows scarcity, and snow-birding on an older technology, if you can stomach it, may just be the way to protect your earning potential. The industry turns on a dime, but is slow to retire proven technology. It is highly likely that you will still be able to earn some decent coin in the technology you know and love even after a few decades.</p>
			
			
								
					<p>
						Filed under: <a href="https://improvingsoftware.com/category/careers-in-software-development/" rel="category tag">Careers in Software Development</a> | Tagged: <a href="https://improvingsoftware.com/tag/age-discrimination/" rel="tag">age discrimination</a>, <a href="https://improvingsoftware.com/tag/career/" rel="tag">career</a>, <a href="https://improvingsoftware.com/tag/programmers/" rel="tag">programmers</a> |					</p>

				</div></div>]]>
            </description>
            <link>https://improvingsoftware.com/2009/05/19/programmers-before-you-turn-40-get-a-plan-b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26312500</guid>
            <pubDate>Tue, 02 Mar 2021 06:38:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Element Matrix Services Announces Element Home]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26311801">thread link</a>) | @decrypt
<br/>
March 1, 2021 | https://element.io/blog/element-home/ | <a href="https://web.archive.org/web/*/https://element.io/blog/element-home/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      <div><p>We’ve launched a brand new version of Element, called <a href="https://element.io/element-home">Element Home</a>!<br></p><p>It’s the Element app, but faster, personalised and under your control - all packaged up so you don’t have to worry about how it works! You can just enjoy the fact you know you chose someone you trust (us!) with your data.<br></p><p>So that you know, here’s what’s going on behind the scenes with Element Home; in practice you’re getting your own fully managed, dedicated server alongside your Element app. It means you have a notably faster service than when using a typical free public server - you’re saved the hassle of self-hosting and it’s guaranteed to be kept updated with the very latest and greatest Matrix hosting best practices.<br></p><div><p>On top of faster messaging, Element Home comes with five user accounts. It’s the ideal way for a family, or groups of friends, to get a super-quick professionally hosted version of Element.</p><p><strong>A new type of messenger</strong></p></div><p>As you know, Element is completely different to most messaging apps. <br></p><p>Because Element is <strong>decentralised</strong>, the app itself (what you see) is separate from the Matrix hosting service behind it (what you don’t see; the movement of messages and where they are stored).<br></p><p>That’s important because it lets users decide where their messages and data are kept. In owning that choice, you also get to own your data and messages rather than having them sucked up into the likes of Facebook Messenger, Signal, Telegram or WhatsApp.<br></p><p>Some people choose to host themselves, and that’s great. As it requires some technical knowledge, many others choose to use a free public hosting service such as Matrix.org to get up and running.<br></p><p>Element Home is a third option; the ability to pay for a fully managed, dedicated server (aka a ‘homeserver’). Being a dedicated server, it devotes itself to just a handful of users; and that’s why it’s so much quicker than a typical free public server that constantly juggles thousands of users.</p><p><strong>There are many messaging apps, but surprisingly little choice.</strong></p><figure><img src="https://element.io/blog/content/images/2021/02/Comparison-table-8--1-.png" alt="" srcset="https://element.io/blog/content/images/size/w600/2021/02/Comparison-table-8--1-.png 600w, https://element.io/blog/content/images/size/w1000/2021/02/Comparison-table-8--1-.png 1000w, https://element.io/blog/content/images/size/w1600/2021/02/Comparison-table-8--1-.png 1600w, https://element.io/blog/content/images/2021/02/Comparison-table-8--1-.png 2108w" sizes="(min-width: 720px) 720px"><figcaption>Element compared with centralised messaging apps.</figcaption></figure><p><br><strong>Free vs $10 per month</strong><br></p><p>As you know, Element and Matrix is all about giving you choice. If you want to use the free version, that’s completely fine by us!<br></p><p>But here’s the extra you get in return for a few bucks a month:<br></p><ol><li>Element Home means you’re <strong>hosted by Element Matrix Services</strong> - our Matrix-based hosting platform used by big companies and public sector organisations. You have a <strong>dedicated server</strong> (so you’re sharing minimal infrastructure with anyone else), fully managed and maintained by the most Matrix-savvy team in the world.<br></li><li>Professional-hosting means the service is <strong>notably faster</strong> than when hosted by a typical free public server, and <strong>always fully updated</strong> and maintained.<br></li><li>An Element domain that you can name, so you can make <strong>memorable Matrix IDs</strong> such as @yourfirstname:yoursurname.ems.host. Use your surname as the domain, and it’s perfect for family sharing!<br></li><li><strong>Five Element accounts</strong> - so after using one yourself, you’ll have four more for family or friends - so that’s <strong>just $2 per user per month</strong> for a super-quick data sovereign messaging service (you can add more users if you wish).</li></ol><figure><img src="https://element.io/blog/content/images/2021/02/Element-Home-custom-IDs.png" alt="" srcset="https://element.io/blog/content/images/size/w600/2021/02/Element-Home-custom-IDs.png 600w, https://element.io/blog/content/images/2021/02/Element-Home-custom-IDs.png 848w" sizes="(min-width: 720px) 720px"><figcaption>Matching IDs for all the family!</figcaption></figure><p><strong>Wishing you could turn back time?!</strong></p><p>If you’re an Element user and you’re self-hosting, or using a typical free public server (such as Matrix.org), you can simply copy your existing account over to Element Home. Currently, you can only do this in the Element web app (we’re working on an equally simple upgrade from within Android and iOS). Once you’ve upgraded your ‘old’ account will still be live, so feel free to keep it or delete it as you see fit.<br></p><p>For those not already up and running on Element, just <a href="https://element.io/element-home">sign up for Element Home</a> from here.</p></div>
      
    </div>
  </div></div>]]>
            </description>
            <link>https://element.io/blog/element-home/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311801</guid>
            <pubDate>Tue, 02 Mar 2021 04:05:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much knowledge can human brain hold]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26311789">thread link</a>) | @breck
<br/>
March 1, 2021 | https://supermemo.guru/wiki/How_much_knowledge_can_human_brain_hold | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/How_much_knowledge_can_human_brain_hold">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This article by Dr <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> is part of <a href="https://supermemo.guru/wiki/SuperMemo_Guru" title="SuperMemo Guru">SuperMemo Guru</a> series on memory, learning, creativity, and problem solving.</small>
</p>


<h2><span id="Estimating_total_knowledge_in_the_brain">Estimating total knowledge in the brain</span></h2>
<p>I am finally closer to being able to say how much knowledge a human brain can hold. Scientists have counted the number of synapses in the human brain (above 100 trillion), and came up with staggering numbers on brain capacity. However, in real life, we see the brain as an unreliable and forgetful device. For an average student, to learn 100 new French words for an exam is an effort. To memorize 45,000 words of English in the <a href="https://supermemo.guru/wiki/Advanced_English" title="Advanced English">Advanced English</a> collection is a feat very few achieved for the cost in time. In other words, trillions of synapses seem to contradict our struggles with mere thousands of questions we need to know to function effectively on a daily basis.
</p>
<h2><span id="SuperMemo_estimates">SuperMemo estimates</span></h2>
<p>30 years ago, using simulations of the learning process in <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>, I predicted that I will not see a human memorize a million <a href="https://supermemo.guru/wiki/Item" title="Item">items</a>. Today, even a million seems like a super-optimistically high number.
</p><p><a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> makes estimates easy. We can count individual questions and answers, and worry less how many bits of information get stored in the brain. The estimates are pretty inaccurate to evaluate the totality of knowledge. For example, I once computed that I am able to recognize around 30,000 human faces without even trying. Some knowledge flows in effortlessly. <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> measures harder knowledge that we want to preserve due to its high value.
</p><p>For 32 years now, I have been using SuperMemo to control what knowledge I remember with high recall. In those three decades, there were a couple of breakthroughs where I could sense a significant acceleration or an increase to the quality of learning. In particular, the arrival of <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a> in 1999 and the employment of the <a href="https://supermemo.guru/wiki/Priority_queue" title="Priority queue">priority queue</a> in 2006 were such booster events. However, the total number of <a href="https://supermemo.guru/wiki/Item" title="Item">items</a> in the <a href="https://supermemo.guru/wiki/Collection" title="Collection">collection</a> is not a true reflection of knowledge. In <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a>, the tolerance for knowledge overload increases, and the <a href="https://supermemo.guru/wiki/Priority_queue" title="Priority queue">priority queue</a> makes it possible to focus on top priority <a href="https://supermemo.guru/wiki/Item" title="Item">items</a>, while neglecting lesser knowledge. In other words, we can perfectly know a smaller set of items, and know a huge set of items more superficially. The only good reflection of knowledge would be to consider the probability of recall for all individual items.
</p>
<h2><span id="Adding_up_memory_retrievability">Adding up memory retrievability</span></h2>
<p>With the new <a href="https://supermemo.guru/wiki/Spaced_repetition" title="Spaced repetition">spaced repetition</a> algorithm, <a href="https://supermemo.guru/wiki/Algorithm_SM-17" title="Algorithm SM-17">Algorithm SM-17</a> (2015), we can finally take a <a href="https://supermemo.guru/wiki/Repetition_history" title="Repetition history">repetition history</a> of each <a href="https://supermemo.guru/wiki/Item" title="Item">item</a> and estimate the chance of <a href="https://supermemo.guru/wiki/Recall" title="Recall">recall</a> at any point in time with pretty good accuracy. The last tool missing in the box was a chance to take any point in time (a date), and run the estimate for all items in the entire <a href="https://supermemo.guru/wiki/Collection" title="Collection">collection</a> (e.g. <i>"How much did I know on Jan 1, 2000?"</i>). The only problem with such estimates is that they are computationally expensive. Finally, in 2020, <a href="https://supermemo.guru/wiki/SuperMemo_18" title="SuperMemo 18">SuperMemo 18</a> makes it possible to chose a selected number of time points in the lifetime of any <a href="https://supermemo.guru/wiki/Collection" title="Collection">collection</a>, and run total knowledge estimates. For any date, the total knowledge estimate is the sum of <a href="https://supermemo.guru/wiki/Memory_retrievability" title="Memory retrievability">memory retrievability</a> estimates for that given point in time.
</p>
<p>Total knowledge can be estimated by adding up <a href="https://supermemo.guru/wiki/Memory_retrievability" title="Memory retrievability">memory retrievability</a> for all individual items</p>
<h2><span id="Longitudinally_largest_data_set">Longitudinally largest data set</span></h2>
<p>I safely hold the record for the longest continuous use of <a href="https://supermemo.guru/wiki/Spaced_repetition" title="Spaced repetition">spaced repetition</a> (over 32 years at the moment of writing). I will keep the title as long as I keep learning. I was simply the first to start (see: <a href="https://supermemo.guru/wiki/Birth_of_SuperMemo" title="Birth of SuperMemo">Birth of SuperMemo</a>). I hope to keep going as long as health permits. This is why my own collection is the best source of data today to make lifelong learning estimates (Jan 1, 2020). 
</p><p>There was a minor problem on the way however. Full record of <a href="https://supermemo.guru/wiki/Repetition_history" title="Repetition history">repetition history</a> was kept only as of 1996 (due to costs and limitations on the available storage in the late 1980s). Seemingly, this might make the first 9 year of data unreliable. However, SuperMemo can provide a reasonable simulation of repetition histories for items with a known number of <a href="https://supermemo.guru/wiki/Lapse" title="Lapse">lapses</a>, <a href="https://supermemo.guru/wiki/Repetition" title="Repetition">repetitions</a>, and the last <a href="https://supermemo.guru/wiki/Interval" title="Interval">interval</a>. Those simulations cut the 9 years to roughly 6-7 years, and are accurate enough to make an imperceptible difference to the final outcome unless a major incongruity hides in that early period. I bet my right hand this is not the case. I was easily able to learn at 10,000 items per year in the early years, but total <a href="https://supermemo.guru/wiki/Retrievability" title="Retrievability">retrievability</a> estimates cut this number substantially.
</p><p>I split my 32 years of learning into 60 equal intervals and let the computational procedure run overnight. In the morning, I had a beautiful graph that I want to share for the new year 2020. The staggering conclusion is that all my perceptions about acceleration, slow downs, improved learning, or neglect were largely illusory. For 32 years, I kept building up knowledge at a remarkably steady rate. In the early years, the effort seemed a bit harder, I needed more self-discipline, there were outstanding items, long days of repetitions, etc. In the times of <a href="https://supermemo.guru/wiki/Incremental_reading" title="Incremental reading">incremental reading</a> it all turn out to be fun, learning with pleasure, and learning on demand, i.e. learning mostly for a specific purpose when I needed new knowledge. My departure into unrelated areas of learning proceeded at leisurely pace. With all those seeming upheavals and changes, hardly any kink shows up in the graph. Many people misread that observation as a disappointment with <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>. Metaphorically speaking, I am only surprised with the smooth ride of the rocket. The speed is no less fantastic.
</p>
<h2><span id="Conceptualization_process">Conceptualization process</span></h2>
<p>To make a good estimate of maximum human knowledge, we need to have data that would span a 100 years period. This is how long an average human might live given a perfect lifestyle, good health, and a couple of other conditions. My 32 years of learning fall into the most uneventful period that is characterized by steady linear progress. In theory, the <a href="https://supermemo.guru/wiki/Conceptualization" title="Conceptualization">conceptualization</a> process in the <a href="https://supermemo.guru/wiki/Concept_network" title="Concept network">concept network</a> of the brain should begin slowly. It might possibly saturate when the ceiling of the brain size is reached. Those early and late changes in the speed of conceptualization will be reflected in the underlying speed of learning. This is illustrated in the figure with the light blue line marked as computational <b>Capacity</b>:
</p>
<div><p><a href="https://supermemo.guru/wiki/File:Crystallization_of_knowledge_in_the_human_brain.png"><img alt="Crystallization of knowledge in the human brain.png" src="https://supermemo.guru/images/thumb/0/0e/Crystallization_of_knowledge_in_the_human_brain.png/350px-Crystallization_of_knowledge_in_the_human_brain.png" width="350" height="254" srcset="https://supermemo.guru/images/thumb/0/0e/Crystallization_of_knowledge_in_the_human_brain.png/525px-Crystallization_of_knowledge_in_the_human_brain.png 1.5x, https://supermemo.guru/images/thumb/0/0e/Crystallization_of_knowledge_in_the_human_brain.png/700px-Crystallization_of_knowledge_in_the_human_brain.png 2x"></a></p></div>
<blockquote><i><b>Figure:</b> Hypothetical course of learning and <a href="https://supermemo.guru/wiki/Conceptualization" title="Conceptualization">conceptualization</a> in a fixed-size <a href="https://supermemo.guru/wiki/Concept_network" title="Concept network">concept network</a>. The naïve network begins the learning process at <a href="https://supermemo.guru/wiki/Dendritic_spine_stabilization_corresponds_with_long-term_memories" title="Dendritic spine stabilization corresponds with long-term memories">high plasticity</a> (in red). As individual <a href="https://supermemo.guru/wiki/Concept" title="Concept">concepts</a> form, they are consolidated and <a href="https://supermemo.guru/wiki/Stabilization" title="Stabilization">stabilized</a>. The overall <a href="https://supermemo.guru/wiki/Stability" title="Stability">stability</a> of the network keeps increasing (dark blue). The speed of <a href="https://supermemo.guru/wiki/Conceptualization" title="Conceptualization">conceptualization</a> (in orange) is a resultant of plasticity and <a href="https://supermemo.guru/wiki/Stability" title="Stability">stability</a>. It reaches its theoretical maximum somewhere on the way from the random graph stage to a sparse representation stage. This is the time of a large supply of <a href="https://supermemo.guru/wiki/Concept" title="Concept">concepts</a> that may be subject to <a href="https://supermemo.guru/wiki/Generalization" title="Generalization">generalization</a>, and a good balance between <a href="https://supermemo.guru/wiki/Stabilization" title="Stabilization">stabilization</a> and <a href="https://supermemo.guru/wiki/Forgetting" title="Forgetting">forgetting</a>. The overall problem solving capacity of the network (light blue) is negligible at first, and tends to saturate with network stabilization. Large number of well-stabilized concepts makes it harder to find new plastic network nodes for further conceptualization. The maximum capacity of the network depends on its size. Speed of learning in <a href="https://supermemo.guru/wiki/Spaced_repetition" title="Spaced repetition">spaced repetition</a> at older ages seems to indicate that the size of the <a href="https://supermemo.guru/wiki/Concept_network" title="Concept network">concept network</a> of the human brain is high enough to provide for lifelong learning without noticeable saturation. See: <a href="https://supermemo.guru/wiki/Conceptualization_theory_of_childhood_amnesia" title="Conceptualization theory of childhood amnesia">Conceptualization theory of childhood amnesia</a> and <strong>How much knowledge can human brain hold</strong></i></blockquote>
<h2><span id="Combining_data_from_many_users">Combining data from many users</span></h2>
<p>To make a good estimate I would need data from many users. In particular, the first 10 years of life, and the data past the age of 80 are most precious. We have surprisingly many users in those age categories, but all users learn at different speeds, use different strategies, learn different things, etc. This is why we need collections that span a decade or more. Short periods cannot be collated from many collections because they are largely uninformative. Regrettably, I have hundreds of collections submitted in various circumstances, and they mostly come from young or middle aged users. They also predominantly come from novices. To this day, I do not have any data from users above the age of 80.
</p><p>I was hoping that my own data might hint if the fifth decade of life brings some slowdown to the learning process. However, my data has been polluted with a great deal of self-experimentation. To account for artifacts of experimental learning, I needed extra correction procedures. In the end, depending on the method, I received a different verdict. My learning might have slowed down a bit, or it might have actually accelerated (my unreliable perception leans towards the latter).
</p><p>By combining data from collections of users at different ages I arrived at a hypothetical course of learning in a lifetime. Unfortunately, the projected slowdown after 70 is just a hypothesis. I tried to imagine myself in a wheelchair at 100, and the mere loss of mobility, I imagine, would undermine my ability to progress with learning at the present rate. I have no data to prove the slowdown. It is just a common sense speculation and my best guess based on four decades of analysis and deliberations on the nature of learning.
</p>
<div><p><a href="https://supermemo.guru/wiki/File:Lifelong_learning_with_spaced_repetition_(projection).png"><img alt="Lifelong learning with spaced repetition (projection).png" src="https://supermemo.guru/images/thumb/6/6c/Lifelong_learning_with_spaced_repetition_%28projection%29.png/500px-Lifelong_learning_with_spaced_repetition_%28projection%29.png" width="500" height="363" srcset="https://supermemo.guru/images/thumb/6/6c/Lifelong_learning_with_spaced_repetition_%28projection%29.png/750px-Lifelong_learning_with_spaced_repetition_%28projection%29.png 1.5x, https://supermemo.guru/images/6/6c/Lifelong_learning_with_spaced_repetition_%28projection%29.png 2x"></a></p></div>
<blockquote><i><b>Figure:</b> Projected course of lifelong knowledge acquisition in <a href="https://supermemo.guru/wiki/Spaced_repetition" title="Spaced repetition">spaced repetition</a>. The curve was compiled with the use of data from users of different ages. The only consistent change in the speed of learning seems to occur at earlier ages (<a href="https://supermemo.guru/wiki/Conceptualization" title="Conceptualization">conceptualization stage</a>). The projected slowdown at older ages is hypothetical and may be associated with inevitable aging rather than with the limit on the size of the <a href="https://supermemo.guru/wiki/Concept_network" title="Concept network">concept network</a>. Moreover, the impact of aging may not necessarily be associated with cognitive aging</i></blockquote>
<h2><span id="Matching_the_projection_with_my_own_data">Matching the projection with my own data</span></h2>
<p>A perfect match between my data and the projection is deceptive. The projection itself was largely rooted in my own data. It is the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/How_much_knowledge_can_human_brain_hold">https://supermemo.guru/wiki/How_much_knowledge_can_human_brain_hold</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/How_much_knowledge_can_human_brain_hold</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311789</guid>
            <pubDate>Tue, 02 Mar 2021 04:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Read Assembly Language]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26311722">thread link</a>) | @sidcool
<br/>
March 1, 2021 | https://wolchok.org/posts/how-to-read-assembly-language/ | <a href="https://web.archive.org/web/*/https://wolchok.org/posts/how-to-read-assembly-language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Why, in 2021, does anyone need to learn about assembly language?
First, reading assembly language is the way to know <em>exactly</em> what
your program is doing. Why, <em>exactly</em>, is that C++ program 1 MiB (say)
instead of 100 KiB? Is it possible to squeeze some more performance
out of that function that gets called all the time?</p><p>For C++ in particular, it is easy to forget or just not notice some
operation (e.g., an implicit conversion or a call to a copy
constructor or destructor) that is implied by the source code and
language semantics, but not spelled out explicitly. Looking at the
assembly generated by the compiler puts everything in plain sight.</p><p>Second, the more practical reason: so far, posts on this blog haven’t
required an understanding of assembly language, despite constant
links to <a href="https://godbolt.org/">Compiler Explorer</a>. By <a href="https://twitter.com/ScottWolchok/status/1361022423399755776">popular
demand</a>,
however, our next topic will be parameter passing, and for that, we
will need a basic understanding of assembly language. We will focus
only on <em>reading</em> assembly language, not writing it.</p><p>The basic unit of assembly language is the <strong>instruction</strong>. Each
machine instruction is a small operation, like adding two numbers,
loading some data from memory, jumping to another memory location
(like the dreaded <a href="https://en.wikipedia.org/wiki/Goto">goto</a>
statement), or calling or returning from a function. (The x86
architecture has <a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">lots of not-so-small
instructions</a>
as well. Some of these are <a href="https://stackoverflow.com/questions/5959890/enter-vs-push-ebp-mov-ebp-esp-sub-esp-imm-and-leave-vs-mov-esp-ebp">legacy
cruft</a>
built up over the 40-odd years of the architecture’s existence, and
others are <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">newfangled
additions</a>. )</p><p>Our first toy example will get us acquainted with simple
instructions. It just calculates the square of the
<a href="https://en.wikipedia.org/wiki/Norm_(mathematics)#Euclidean_norm">norm</a>
of a 2D vector:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and here is the resulting x86_64 assembly from clang 11, <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tQVvQAZPLUwA5YwCNMxEADZSAB1QLC62nsMTQS8fNTorG3sjJxd3JRUw2gYCZmICAONTTkVlTFU/ZNSCCLtHZzdFFLSMoOyFKuLrUujy1wBKRVQDYmQOAHIpAGZrZEMsAGpxQZ1kevx6KexxAAYAQRXV%2BuIDVXGANTzJSYB2WTXxi/HrAlduAH0CcYAPKbPVy6v6W4fxgE9XjbiY4AEQBaw212%2Bj1oJCMDAAjgZUph0BADsgjgA3NonN4fYiYAjdWjjTEAOie4wAVKSKZMZLTftTGWD1iC%2Bh1WCA%2BgBWPqkUx9Zb81DcnRyOTjBRdHqYemDTj8gjc4VtDoAaxAg0GZO1ev1BvcXL63H5guFpFFfX5ChAy1IyqFHNIcFgSDQRg8eHYZAoEA9Xp9KGEok4nGW2So3oIzltEAcKv5DmsqV%2B3MVpA9Ri0BAA8rRWGmnaQsEYRMB2ImS3gCflMZhbcXME88gYY%2Bn%2BddlB2hHgHMRU3osD2CMQ8EYOx0aPQmGwODx%2BIIQ2IJTJew5bZAOqgPIlGwBaXODcb7uZTYESGRySQW%2BJ5RKabQ1LKkcwlKIxYLeXx0Z9f0J%2BO%2BZQuHUuT5HQhTVPomSCHe4FJA0QEtCBlRFH%2BdSIU0H7lJwHTSt0vRcJy3J8gKVZWk8AAcrj7rc4yjOW4xhmSyxkpw4wQLghAkPK2TjHonres4vE4uKV4yEqiZqqQmrarqBoKdqRrcqaZHFlaNp2g6UkujAiAoKggk%2BuQlABkJLgMaG4aRtGsaUAmxbJrQqY9lmOb5oWValuWlbFvgtZqPWjYWs2rbtn0GZdsaFqsH2A7EL8Q79Bao7jpOpDTowLCVguAiSEI5YoKu8ixRu8DbrufgHkeJ5noMF7FTeNpgQ%2BEDmOhr7aEhn7ZCEP7%2BNBtSeN%2BiTdThOQJAUDQdXBiSQY0kTAbB02DS%2B9RFGNIF4TKhG4UIJFmuR3JUTRdGWcATGcCxbEcVxRDELxpD8YZgbCUMkiicVklOtJsk6opin7Sah3qdymn2o6qrEX0kggxaGnaT9HT1sQPgaNwQA%3D%3D">via Compiler Explorer</a>:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><div><pre><code data-lang="asm">        <span>imulq</span>   %rdi, %rdi
        <span>imulq</span>   %rsi, %rsi
        <span>leaq</span>    (%rsi,%rdi), %rax
        <span>retq</span>
</code></pre></div><p>Let’s talk about that first instruction: <code>imulq %rdi, %rdi</code>. This
instruction <a href="https://www.felixcloutier.com/x86/imul">performs signed integer
multiplication</a>. The <code>q</code>
suffix tells us that it is operating on 64-bit quantities. (In
contrast, <code>l</code>, <code>w</code>, and <code>b</code> would denote 32-bit, 16-bit, and 8-bit,
respectively.) It multiplies the value in the first given register
(<code>rdi</code>; register names are prefixed with a <code>%</code> sign) by the value in
the second register and stores the result in that second
register. This is squaring <code>v.x</code> in our example C++ code.</p><p>The second instruction does the same with the value in <code>%rsi</code>, which
squares <code>v.y</code>.</p><p>Next, we have an odd instruction: <code>leaq (%rsi,%rdi), %rax</code>. <code>lea</code>
stands for “load effective address”, and it stores the address of the
first operand into the second operand. <code>(%rsi, %rdi)</code> means “the
memory location pointed to by <code>%rsi + %rdi</code>”, so this is just adding
<code>%rsi</code> and <code>%rdi</code> and storing the result in <code>%rax</code>. <code>lea</code> is a quirky
x86-specific instruction; on a more
<a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a>-y
architecture like ARM64, we would expect to see a plain old <code>add</code>
instruction.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>Finally, <code>retq</code> returns from the <code>normSquared</code> function.</p><p>Let’s take a brief detour to explain what the registers we saw in our
example are. Registers are the “variables” of assembly
langauge. Unlike your favorite programming language (probably), there
are a finite number of them, they have standardized names, and the
ones we’ll be talking about are at most 64 bits in size. Some of them
have specific uses that we’ll see later. I wouldn’t be able to rattle
this off from memory, but <a href="https://en.wikipedia.org/wiki/X86-64#Architectural_features">per
Wikipedia</a>,
the full list<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> of 16 registers on x86_64 is <code>rax</code>, <code>rcx</code>, <code>rdx</code>, <code>rbx</code>,
<code>rsp</code>, <code>rbp</code>, <code>rsi</code>, <code>rdi</code>, <code>r8</code>, <code>r9</code>, <code>r10</code>, <code>r11</code>, <code>r12</code>, <code>r13</code>,
<code>r14</code>, and <code>r15</code>.</p><p>Now, let’s extend our example to debug print the <code>Vec2</code> in <code>normSquared</code>:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdint&gt;</span><span>
</span><span></span>
<span>struct</span> <span>Vec2</span> {
    <span>int64_t</span> x;
    <span>int64_t</span> y;
<span>    <span>void</span> <span>debugPrint</span>() <span>const</span>;
</span>};

<span>int64_t</span> <span>normSquared</span>(Vec2 v) {
<span>    v.debugPrint();
</span>    <span>return</span> v.x <span>*</span> v.x <span>+</span> v.y <span>*</span> v.y;
}
</code></pre></div><p>and, again, let’s see <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEJICcpLegAyeWpgByxgEaZiIAGykADqgWE6rR6hiaCfgFqdHYOzkZuHt5KKlG0DATMxAQhxqYWisqYqkHpmQQxTq7uXooZWTlhnLVlFXEJXgCUiqgGxMgcAORSAMz2yIZYANTiwzrICgT49DPY4gAMAILrGwvEBqqTAGpFktMA7LKbk9eT9gSe3AD6BJMAHjOXGze39A/PkwBPD7bb4AN1QeHQkywLgMwAACsQ7hAOpM0LQFsDNuIzgARLFbTZ3P4vWgkIwMACOBkymHQEGOyFOoNROM%2BYIAdDC4YjkR0Cd9iJgCL1aJNQRzXpMAFTiyXTGRygEypUEnG4gZdVggAYAVgGpFMAzWBtQOp0cjkkwUPT6mAVw04BoIOpNHS6AGsQMNhhyff6A4HvNqBtwDUaTaQzQMDQoQGtSC7jZrSHBYEg0EYfHh2GQKBBM9ncyhhKJOJw1k0qDmCO44xAXK6DS57JkATqnaRM0YtAQAPK0Vjt5OkLBGETAdhN0d4IXFUGYOMjzCvIoGWsdg13ZSboR4FzENt6LC7ghIoybro0ehMNgcHj8QSlsSWmR7lxxyBdVA%2BVJLgC0fbDJM/4LOgMy4hIMhyJIkbJEUqSaNoDSmE01itFUHhNBEgR0Ch4T%2BLhtAYfE1RNPBxR0KU9T6LkggUak1HlPYlSkVhzQ0aEqEccxsSYVwXQ2r0/QCUIOr6oa07Rq8AAcnj/g8aLPpM5YcmsHKcJMEC4IQJAOk0kx6FmObuPpqIWtBMjOk27qkF6Pp%2BoGTk%2BsGOphpJI7RrG8aJjZqYwIgKCoMZubkJQhYmR44wTuWlakNWrC1sQ9aNiOLa0G2u7dr2A5DtOY4TlOI74HOagLkukYrmuG4DJ224hpGrD7oexAAsegyRmeeAXrVKbXowLBTg%2BAiSEIE4oK%2B8hNR%2B8Dfr%2BQQAUBIFgRBUGyDIsGxoUlGmBA1j4Zwo3oSxbRkcMviEakB2jThqQke0nDnQxJR1NktGNKNz1Ua991nTx108b9WHDIJtoiZwWrieGUk6rJ8mKdFogqZwakaVpOlEMQ%2BmkIZwVFqZIySOZk3Wcmtn2b6znOWJobQ55OreQmSZupDAySHTkZeb5ZNdAuyVBCA3BAA">the generated assembly</a>:</p><div><pre><code data-lang="asm">        <span>subq</span>    <span>$24</span>, %rsp
        <span>movq</span>    %rdi, <span>8</span>(%rsp)
        <span>movq</span>    %rsi, <span>16</span>(%rsp)
        <span>leaq</span>    <span>8</span>(%rsp), %rdi
        <span>callq</span>   <span>Vec2</span>::<span>debugPrint</span>() <span>const</span>
        <span>movq</span>    <span>8</span>(%rsp), %rcx
        <span>movq</span>    <span>16</span>(%rsp), %rax
        <span>imulq</span>   %rcx, %rcx
        <span>imulq</span>   %rax, %rax
        <span>addq</span>    %rcx, %rax
        <span>addq</span>    <span>$24</span>, %rsp
        <span>retq</span>
</code></pre></div><p>In addition to the obvious call to <code>Vec2::debugPrint() const</code>, we have
some other new instructions and registers! <code>%rsp</code> is special: it is
the “stack pointer”, used to maintain the <a href="https://en.wikipedia.org/wiki/Call_stack">function call
stack</a>. It points to the
bottom of the stack, which grows “down” (toward lower addresses) on
x86. So, our <code>subq $24, %rsp</code> instruction is making space for three
64-bit integers on the stack. (In general, setting up the stack and
registers at the start of your function is called the <a href="https://en.wikipedia.org/wiki/Function_prologue">function
prologue</a>.) Then, the
following two <code>mov</code> instructions store the first and second arguments
to <code>normSquared</code>, which are <code>v.x</code> and <code>v.y</code> (more about how parameter
passing words in the next blog post!) to the stack, effectively
creating a copy of <code>v</code> in memory at the address <code>%rsp + 8</code>. Next, we
load the address of our copy of <code>v</code> into <code>%rdi</code> with <code>leaq 8(%rsp), %rdi</code> and then call <code>Vec2::debugPrint() const</code>.</p><p>After <code>debugPrint</code> has returned, we load <code>v.x</code> and <code>v.y</code> back into
<code>%rcx</code> and <code>%rax</code>. We have the same <code>imulq</code> and <code>addq</code> instructions as
before. Finally, we <code>addq $24, %rsp</code> to clean up the 24
bytes<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> of stack space we allocated at the start of
our function (called the <a href="https://en.wikipedia.org/wiki/Function_prologue#Epilogue">function
epilogue</a>),
and then return to our caller with <code>retq</code>.</p><p>Now, let’s look at a different example. Suppose that we want to print
an uppercased C string and we’d like to avoid heap allocations for
smallish strings.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> We might write something like
the following:</p><div><pre><code data-lang="c++"><span>#include</span> <span>&lt;cstdio&gt;</span><span>
</span><span>#include</span> <span>&lt;cstring&gt;</span><span>
</span><span>#include</span> <span>&lt;memory&gt;</span><span>
</span><span></span>
<span>void</span> <span>copyUppercase</span>(<span>char</span> <span>*</span>dest, <span>const</span> <span>char</span> <span>*</span>src);

<span>constexpr</span> size_t MAX_STACK_ARRAY_SIZE <span>=</span> <span>1024</span>;

<span>void</span> <span>printUpperCase</span>(<span>const</span> <span>char</span> <span>*</span>s) {
    <span>auto</span> sSize <span>=</span> strlen(s);
    <span>if</span> (sSize <span>&lt;=</span> MAX_STACK_ARRAY_SIZE) {
        <span>char</span> temp[sSize <span>+</span> <span>1</span>];
        copyUppercase(temp, s);
        puts(temp);
    } <span>else</span> {
        <span>// std::make_unique_for_overwrite is missing on Godbolt.
</span><span></span>        std<span>::</span>unique_ptr<span>&lt;</span><span>char</span>[]<span>&gt;</span> temp(<span>new</span> <span>char</span>[sSize <span>+</span> <span>1</span>]);
        copyUppercase(temp.get(), s);
        puts(temp.get());
    }
}
</code></pre></div><p>Here is <a href="https://godbolt.org/#z:OYLghAFBqd5QCxAYwPYBMCmBRdBLAF1QCcAaPECAM1QDsCBlZAQwBtMQBGAFlICsupVs1qhkAUgBMAISnTSAZ0ztkBPHUqZa6AMKpWAVwC2tEAHZeW9ABk8tTADljAI0zEuANlIAHVAsLqtHqGJua8vv5qdLb2Tkau7pxeSipRtAwEzMQEwcamForKmKqBGVkEMY4ubp6Kmdm5oQUK9RV2VfE1SQCUiqgGxMgcAORSAMx2yIZYANTiYzrILfio89jiAAwAguOT05hzC0sExHbAa5s7khO0Uwaz8zpGmEYkAJ4X25cAbqh46DM0N43gBVbzeNwsJQQZAILIzABUWBapEBdBagLhxERCkG3Xmsi%2B2zQtBamAAHt5sf4AF6YAD6BBmAFktgANekMAAqWx0AGl6VsAEpCrYATU5AEkAFrYQ4AERmnA2km4BMuPz%2BAKpdgIYIhxB0zGhJIxsPhCIU3TmZkJWxmDpmzAMRBmCgYeDpCrdJ3YtAgVvV20dMzwVBmAY9Xse80VrI53N5AuFoolDBl2Gt4ltlxDIfN2IIL284gArNJ3Z6DnIlWX5UH7XmHUDQeDIcbMBAi0ZvKjA2M7U2Hd4XQou8X8QPc47s4rlEobYOhwB6Zc%2B9AgEBGZgAawZBloeAAjgYGTRiPTUN83AB3U5F0MKGZGPAKfyiGZ0GZ6Ht4djY7BKVYEg3AAOmnJtlk3A9j1PelvBOR4CzLWRS3rMY5W7bwIHsG9MSyFDK2jGRazQyclybFt9XbaEsNA4BMAICBejdciILzEcCDHOiGKY7o2ODGczHrL5hOGXpWBAYZS2GUhTGGDZZNQKSdDkGsFH6QZq2uThZIIKTFP40gdxAbgxlAsZlTGABOMxS1LMZSySAAOSQhCk7hZPkxTSGU4ZZIUEANlIfSFPE0g4FgJA0F/f9yEoGLvD/GophEYBOGVThSCoP8i2IQKIGcAzZOcOwsjeKTdNIGLnnoAB5WhWAqsLSCwbdRHYYrWrwYhijUa9ApailihdEYqt1ZRKtk1g8GcYhyr0LAppC04jCm3oaHoJg2A4Hh%2BEEYRRBQNSZCEWbAsgXpUAQwJBoAWjqsYZju5ZYwkGQ5EkDZnqoWhUDu69VBIKsfr%2Bu6D2IfRWDu4DrqfO7fv%2Bikhhu9EAqKEoNAgKxGlMLKrEqOIEkECIAjoXGSb8MnaEJ6pEkKVJSlaCmspSPqmfKWnOnplpyhZupOfaImul6DSBiGLgJKkmS5K6vzyWcjw7o8bhAUO4AlU4UCNlAzgI1wQgSDmHTUR/JL/2NyzrVUj6ZD04qjJMsZzMkUszNLMxrI2MxnIc653OGTzZZavyAqCkKHYimBEBQVBYrceKYTj82UvVjKNiynLWDygqipa0raHK5aaq0AgGqarq2rSzqWvwXqSgGrrhuQUblomySWpmuaFowEYfJOPA1uGXSNroRgWE6vaBDc9Xjtt%2BQu4u5jfNR0kpIep6XoIdA3pO6QvtB/7AaIU4vQRsGIahmHUDhw%2B7uRzBV4UdHGaxnH9DyQQCaFunKciQJ%2BakzSFzYmrMMZpDKA0D%2BoQwGv3SK0EBXQBZQJCHjZBbRYi/04KLTSEtsEBxlt5JSUkFZKxVmrNKmtta631vgE%2BlssrfmTslbE4xJDWz3vbMKjsQDXFAu7VU3AHKK0kNZaypYZ4eS8nLKSYdgqhUMlLYYkhpEh1kRHbhvRrz5UCKZIAA%3D">the generated assembly</a>:<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><div><pre><code data-lang="asm"><span>printUpperCase</span>(<span>char</span> <span>const</span>*):                  <span># @printUpperCase(char const*)
</span><span></span>        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
        <span>callq</span>   <span>strlen</span>
        <span>leaq</span>    <span>1</span>(%rax), %rdi
        <span>cmpq</span>    <span>$1024</span>, %rax                     <span># imm = 0x400
</span><span></span>        <span>ja</span>      <span>.LBB0_2</span>
        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
.LBB0_2:
        <span>callq</span>   <span>operator</span> <span>new</span>[](<span>unsigned</span> <span>long</span>)
        <span>movq</span>    %rax, %rbx
        <span>movq</span>    %rax, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
        <span>movq</span>    %rbx, %rdi
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>jmp</span>     <span>operator</span> <span>delete</span>[](<span>void</span>*)                          <span># TAILCALL
</span></code></pre></div><p>Our function prologue has gotten a lot longer, and we have some new
control flow instructions as well. Let’s take a closer look at the
prologue:</p><div><pre><code data-lang="asm">        <span>pushq</span>   %rbp
        <span>movq</span>    %rsp, %rbp
        <span>pushq</span>   %r15
        <span>pushq</span>   %r14
        <span>pushq</span>   %rbx
        <span>pushq</span>   %rax
        <span>movq</span>    %rdi, %r14
</code></pre></div><p>The <code>pushq %rbp; movq %rsp, %rbp</code> sequence is very common: it pushes
the <a href="https://en.wikipedia.org/wiki/Call_stack#FRAME-POINTER">frame
pointer</a>
stored in <code>%rbp</code> to the stack and saves the old stack pointer
(which is the new frame pointer) in <code>%rbp</code>. The following four
<code>pushq</code> instructions store registers that <a href="https://en.wikipedia.org/wiki/X86_calling_conventions#System_V_AMD64_ABI">we need to save before
using</a>.<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>
Finally, we save our first argument (<code>%rdi</code>) in <code>%r14</code>.</p><p>On to the function body. We call <code>strlen(s)</code> with <code>callq strlen</code> and
store <code>sSize + 1</code> in <code>%rdi</code> with <code>lea 1(%rax), %rdi</code>.</p><p>Next, we finally see our first <code>if</code> statement! <code>cmpq $1024, %rax</code> sets
the <a href="https://en.wikipedia.org/wiki/FLAGS_register">flags register</a>
according to the result of <code>%rax - $1024</code>, and then <code>ja .LBB0_2</code>
(“jump if above”) transfers control to the location labeled <code>.LBB0_2</code>
if the flags indicate that <code>%rax &gt; 1024</code>. In general, higher-level
control-flow primitives like <code>if</code>/<code>else</code> statements and loops are
implemented in assembly using conditional jump instructions.</p><p>Let’s first look at the path where <code>%rax &lt;= 1024</code> and thus the branch
to <code>.LBB0_2</code> was not taken. We have a blob of instructions to create
<code>char temp[sSize + 1]</code> on the stack:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rsp, %r15
        <span>movq</span>    %rsp, %rbx
        <span>addq</span>    <span>$15</span>, %rdi
        <span>andq</span>    <span>$-16</span>, %rdi
        <span>subq</span>    %rdi, %rbx
        <span>movq</span>    %rbx, %rsp
</code></pre></div><p>We save <code>%rsp</code> to <code>%r15</code> and <code>%rbx</code> for later
use.<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> Then, we add 15 to <code>%rdi</code> (which,
remember, contains the size of our array), mask off the lower 4 bits
with <code>andq $-16, %rdi</code>, and subtract the result from <code>%rbx</code>, which we
then put back into <code>%rsp</code>. In short, this rounds the array size up to
the next multiple of 16 bytes and makes space for it on the stack.</p><p>The following block simply calls <code>copyUppercase</code> and <code>puts</code> as written in the code:</p><div><pre><code data-lang="asm">        <span>movq</span>    %rbx, %rdi
        <span>movq</span>    %r14, %rsi
        <span>callq</span>   <span>copyUppercase</span>(<span>char</span>*, <span>char</span> <span>const</span>*)
        <span>movq</span>    %rbx, %rdi
        <span>callq</span>   <span>puts</span>
</code></pre></div><p>Finally, we have our function epilogue:</p><div><pre><code data-lang="asm">        <span>movq</span>    %r15, %rsp
        <span>leaq</span>    -<span>24</span>(%rbp), %rsp
        <span>popq</span>    %rbx
        <span>popq</span>    %r14
        <span>popq</span>    %r15
        <span>popq</span>    %rbp
        <span>retq</span>
</code></pre></div><p>We restore the stack pointer to deallocate our variable-length array
using <code>leaq</code>. Then, we <code>popq</code> the registers we saved during the
function prologue and return control to our caller, and we are done.</p><p>Next, let’s look at the path when <code>%rax &gt; 1024</code> and we branch to
<code>.LBB0_2</code>. This path is more …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolchok.org/posts/how-to-read-assembly-language/">https://wolchok.org/posts/how-to-read-assembly-language/</a></em></p>]]>
            </description>
            <link>https://wolchok.org/posts/how-to-read-assembly-language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311722</guid>
            <pubDate>Tue, 02 Mar 2021 03:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National Security Commission on Artificial Intelligence's Final Report]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 43 (<a href="https://news.ycombinator.com/item?id=26311616">thread link</a>) | @AndrewKemendo
<br/>
March 1, 2021 | https://www.nscai.gov/2021-final-report/ | <a href="https://web.archive.org/web/*/https://www.nscai.gov/2021-final-report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><div data-elementor-type="wp-page" data-elementor-id="419" data-elementor-settings="[]"><div><div><section data-id="234355d" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="d8c7098" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><section data-id="deac5bd" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="8ba7a06" data-element_type="column"><div><div><div data-id="d57a85d" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg" data-elementor-open-lightbox="yes" data-elementor-lightbox-title="final-repor__screenshot-1"> <img width="732" height="412" src="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg" alt="" loading="lazy" srcset="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1.jpg 732w, https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-1-300x169.jpg 300w" sizes="(max-width: 732px) 100vw, 732px"> </a></p></div></div><div data-id="cd4d96d" data-element_type="widget" data-widget_type="image.default"><div><p><a href="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg" data-elementor-open-lightbox="yes" data-elementor-lightbox-title="final-repor__screenshot-3"> <img width="732" height="412" src="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg" alt="" loading="lazy" srcset="https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3.jpg 732w, https://www.nscai.gov/wp-content/uploads/2021/03/final-repor__screenshot-3-300x169.jpg 300w" sizes="(max-width: 732px) 100vw, 732px"> </a></p></div></div></div></div></div><div data-id="4cf2c23" data-element_type="column"><div><div><div data-id="0d42a7d" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>The mandate of the National Security Commission on Artificial Intelligence’s (NSCAI) is to make recommendations to the President and Congress to “advance the development of artificial intelligence, machine learning, and associated technologies to comprehensively address the national security and defense needs of the United States.”</p><p>This Final Report presents the NSCAI’s strategy for winning the artificial intelligence era. The 16 chapters in the Main Report provide topline conclusions and recommendations. The accompanying Blueprints for Action outline more detailed steps that the U.S. Government should take to implement the recommendations.</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="06674a1" data-element_type="section" data-settings="{&quot;ekit_has_onepagescroll_dot&quot;:&quot;yes&quot;}"><div><div><div data-id="5e2210f" data-element_type="column"><div><div><div data-id="dc57494" data-element_type="widget" data-widget_type="text-editor.default"><div><p>From quick bites to in depth interviews, hear from leading artificial intelligence and United States defense experts, including insights on how to move recommendations to crucial actions. New podcasts from our latest series, Highlights from 2020 Quarterly Recommendations, will be shared weekly.</p></div></div></div></div></div><div data-id="848e99b" data-element_type="column"><div><div><div data-id="222fe7f" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p>Read our COVID white paper series, including:</p><ul><li><span>The Role of AI Technology in Pandemic Response and Preparedness: Recommended Investments and Initiatives</span></li><li><span>Mitigating Economic Impacts of the COVID-19 Pandemic and Preserving U.S. Strategic Competitiveness in AI</span></li><li><p><span>Privacy and Ethics Recommendations for Computing Applications Developed to Mitigate COVID-19</span></p></li></ul></div></div></div></div></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.nscai.gov/2021-final-report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311616</guid>
            <pubDate>Tue, 02 Mar 2021 03:33:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables from PDF/Images]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26311562">thread link</a>) | @nishparadox
<br/>
March 1, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>“We are using Docsumo’s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.”</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say “Ask anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>We’d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311562</guid>
            <pubDate>Tue, 02 Mar 2021 03:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TMB Chose C++ in '21]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26311204">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | http://dominickm.com/why-tmb-chose-c-in-21/ | <a href="https://web.archive.org/web/*/http://dominickm.com/why-tmb-chose-c-in-21/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-1138">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					
<p>I don’t normally enjoy writing controversial posts about why new technologies are bad; I LOVE it! So here we go! We’re starting a new large-scale first-party project over at <a href="https://themadbotter.com/">The Mad Botter</a> (sorry no details today) that requires a significant level of low-level engineering work on Linux.  Initially, we considered using some sort of solution like CYthon to compile Python to native code, but we ultimately decided against it. That led us to look at compiled languages.  Spoiler alert! We went with C++.  Before you flip your lid, here’s why. </p>



<p><strong>Multiple Platforms / Native Code</strong>:  Sure, I’ve spent a lot of energy trying to find cross-platform solutions that work well and the solution I came to is that are always compromises that aren’t the ones that I care to make; with that said, there’s a lot of good reasons to go with more traditionally write once run everywhere solutions. C++ allows us to have shared code (with some platform specific modifications to be sure)  compiled  for each of our desired platforms while also having specific modules to take advantage platform specific features.  A key point here is that by platforms we are not just talking about operating systems but also processor architectures; I’m looking at you Apple Silicon</p>



<p><strong>Modern C++:</strong> Over the last few releases C++ has seen some changes that aim to sand down some of the rougher edges of the language. Collections and memory management have been getting a lot of good attention in the last few releases. In particular, we found smart pointers to be particularly attractive; dare I say they are downright familiar at least on their face to this Objective-C die-hard fan; yes, I am still pining for my square brackets!</p>



<p><strong>Team Familiarity: </strong>OK, so this is a bit of a weak one in terms of technical reasons, but it’s actually pretty important. Compared to the competing low-level languages (Go and Rust), all of the team has at least some experience in C++ with some of us having quite a bit of experience in the language. While it shouldn’t drive all technical decisions, experience is a factor. </p>



<p>Before landing on C++ we ended up with three languages in the running at the end of the process: C++, C# (.Net) and Rust. C# was eliminated first for a few reasons including some extra hoops to work in it on Linux and macOS; having said that, .Net is much easier to develop in on Linux and macOS now than it ever was before. Rust almost took the cup and <a href="https://coder.show/">Coder Radio</a> listeners will know I am a Rust fan, but ultimately the existing C++ experience on the team carried the day and like a vinyl record collection at a hipster swap-meet, it’s golden.  Let me know what you think on <a href="https://twitter.com/dominucco">Twitter</a> and if you’re in need of Python, IOT or mobile development, reach out! A</p>




					</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>http://dominickm.com/why-tmb-chose-c-in-21/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311204</guid>
            <pubDate>Tue, 02 Mar 2021 02:21:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Meta-Creator Ceiling]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26311129">thread link</a>) | @forrestbrazeal
<br/>
March 1, 2021 | https://www.swyx.io/meta-creator-ceiling/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/meta-creator-ceiling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em><a href="https://share.transistor.fm/s/05ccbc28">Listen to narrated version</a></em></p>
<p><strong>How many should be teaching people how to succeed instead of just succeeding in their own way?</strong></p>
<p>As independent creators carve out a new career path for themselves, I suspect that some are unintentionally picking a path that limits their growth and robs the world of their true potential.</p>
<p>This theory was triggered by this Hunter Walk tweet:</p>
<p>
  <img src="https://dev-to-uploads.s3.amazonaws.com/i/s1btlni3fe2mzxhghkm6.png" alt="Hunter Walk: the emerging newsletter playbook seems to be &quot;B-Players Writing About A-Players While Being Subscribed to by C-Players&quot;">
</p>
<p>The message is clear: By doing B player things, you are at least doing better than C players. <strong>But you will <em>never</em> be an A player using the B player playbook.</strong></p>
<p>Is that a tradeoff you are consciously making?</p>
<p>Of course it is too reductive to reduce pluripotent people to "A players" and "B players". You can be both in different domains, or transition from one to the other. And of course this is nowhere near as bad as the real-life "<a href="https://en.wikipedia.org/wiki/Glass_ceiling">glass ceiling</a>" or a "<a href="https://en.wikipedia.org/wiki/Bamboo_ceiling">bamboo ceiling</a>" in normal careers, where a certain set of the workforce is unable to progress by sheer fact of <em>who they are</em>. That is obviously despicable and is a far more important societal issue.</p>
<p>But the meta-creator ceiling is interesting to me because it is a path that new creators <strong>follow by choice,</strong> yet <em>without being aware of it's limitations</em> because nobody is incentivized to warn them. Perhaps because it is an easier game than others, or perhaps because of hype and marketing.</p>
<p>No judgment — I of all people know that there are many ways to avoid asking what it is I really want to do with my life.</p>
<p>Perhaps some definitions are in order: <strong>A "Meta-Creator" is someone who creates content about creating, instead of just creating.</strong></p>
<p>The temptation toward being a Meta-Creator is extremely high. There are three paths:</p>
<ul>
  <li><strong>The A-B-C Loop</strong>: People want success porn. They are oblivious to the <a href="https://medium.com/@coffeeandjunk/cognitive-bias-narrative-fallacy-9cff93a597b2">narrative fallacy</a> and ignore luck and complicating details. Your success creating success porn gains you access to more successful people who are only too happy to let you write their hagiography. You can spend an entire career mythologizing successful people, living a life of a bard rather than a hero. Always the vibesmaid, never the vibe.</li>
  <li><strong>The Creator Strange Loop:</strong> To <a href="https://twitter.com/philip_kiely/status/1349361401316446211?s=20">quote the always-brilliant Philip Kiely</a>: "First you do X, then you make content about doing X, then you make content about that content... One day you realize you haven't done X for six months. And there is only so much room for content at the highest levels of abstraction." Every single step makes logical sense because you have credibility from having just done the thing. After a while every step you take you wind back up at the same spot because you're in the generic Creator <a href="https://en.wikipedia.org/wiki/Strange_loop">strange loop</a> everyone has pigeonholed you in.</li>
  <li><strong>The Audience-Building Loop:</strong> The natural end game of the current <strong>Audience-First</strong> and <strong>Build in Public</strong> memes is that you naturally attract an audience of wannabe builders. There are only so many topics they want to buy, and so many things to incestuously sell to each other. The successful cohorts will be supported by the far bigger unsuccessful ones in a self-organizing pyramid scheme.</li>
</ul>
<p>To be extremely clear: You can be enormously successful and happy being a Meta-Creator, and bring success and happiness to millions, and that is no small feat. I enjoy Tim Ferris' podcasts and Tren Griffin's blogposts. No judgment if that's your thing. The economics make sense too — in a gold rush, go mine a bit of gold, then sell copies of the shovel you used because it is now proven to work. Just don't spend too long thinking about <a href="https://twitter.com/swyx/status/1284597930398105600?s=20">who arranged those economics in the first place</a>.</p>
<p>But, one, you may have a lower chance of success pursuing this path than others, because it is both available to everyone and zero-sum.</p>
<p>But I write for reason two: the sneaking suspicion that <em>even if you win</em> and are top of the heap at the Meta-Creator game, you are still limiting yourself from what you could be doing with your life. What the people you <em>actually</em> look up to are doing with theirs. What the world could be benefiting from if the greatest minds of our generation just applied themselves to other problems than "How to Crush it on Twitter" or "Get a Million YouTube Subscribers" or the 3923rd "How Warren Buffett and Charlie Munger Think" blogpost.</p>
<p>Smart, capable people like you and I can often approach life with more ambition than direction. We want success more than we want to solve problems. I think the way to approach the question of "what do I do to be successful", may be to flip it on its head:</p>
<p>Assume you will be successful at whatever game you play. <strong>Are you playing a game you want to win?</strong></p>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/meta-creator-ceiling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311129</guid>
            <pubDate>Tue, 02 Mar 2021 02:11:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Literate: A Flexible Literate Programming System]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26311089">thread link</a>) | @cableclasper
<br/>
March 1, 2021 | https://zyedidia.github.io/literate/index.html | <a href="https://web.archive.org/web/*/https://zyedidia.github.io/literate/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- This adds the top navigation bar -->
            


            <!-- Jumbotron -->
            <div>
                
                <p>A Flexible Literate Programming System</p>
            </div>

            <!-- What is Literate Programming -->
            <p>View the literate <a href="https://zyedidia.github.io/literate/literate-source">source code</a> for Literate!
            </p><p>View the literate <a href="https://zyedidia.github.io/literate/website-source">source code</a> for this website!
            </p><p>See the <a href="https://github.com/zyedidia/Literate">Github page</a>.</p>
            
            <h2>What is Literate Programming?</h2>
            <p>Literate programming is a style of programming invented by Donald Knuth, where the main idea is
            that a program's source code is made primarily to be read and understood by other people, and
            secondarily to be executed by the computer.</p>
            
            <p>This frees the programmer from the structure of a program imposed by the computer and means that
            the programmer can develop programs in the order of the flow of their thoughts.</p>
            
            <p>A Literate program consists of explanation of the code in a natural language such as English, interspersed
            with snippets of code to be executed. This means that Literate programs are very easy to understand and share,
            as all the code is well explained.</p>
            
            <p>Literate, a tool for literate programming, will allow you to take a literate source file (<code>*.lit</code>) and
            either <em>tangle</em> the source file which will create a file with executable code, or <em>weave</em> the
            source file, which will generate an HTML document to be read as formatted documentation.</p>

            <!-- What are the features of lit -->
            <h2>Features of this tool</h2><p>
            Literate works with any programming language, generates HTML as output (<a href="https://wkhtmltopdf.org/">which can be converted to pdf</a>),
            and generates readable code. The code that is generated is indented properly and is automatically commented using the titles you have written
            for the code blocks.</p><p>
            Here is the full list of features:</p><ul>
                <li>Supports any language including syntax highlighting and pretty printing in HTML</li>
                <li>Generates HTML as output</li>
                <li>Generates readable code and commented in the target language</li>
                <li>Reports syntax errors back from the compiler to the right line in the literate source</li>
                <li>Runs fast -- wc.lit compiled for me in 7ms for both code and html output</li>
                <li>Markdown based -- very easy to read and write Literate source.</li>
                <li>Automatically generates hyperlinks between code sections</li>
                <li>Formatted output similar to CWEB</li>
                <li>Creates an index with identifiers used (you need to have exuberant or universal ctags installed to use this feature)</li>
                <li>Supports TeX equations with <code>$</code> notation</li>
                <li>Compatible with Vim (<a href="https://github.com/zyedidia/literate.vim" target="_blank">literate.vim</a>)</li>
                <li>Highly customizable</li>
            </ul><p>
            
            You can get started by taking a look at the <a href="https://zyedidia.github.io/literate/manual.html">manual</a>.
            In addition, this website is made with Literate, and the source can be viewed
            <a href="https://github.com/zyedidia/literate-website">here</a>.

        </p></div></div>]]>
            </description>
            <link>https://zyedidia.github.io/literate/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26311089</guid>
            <pubDate>Tue, 02 Mar 2021 02:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Switch to, contribute to, and use open source software]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310772">thread link</a>) | @isabellavieira
<br/>
March 1, 2021 | https://tarscloud.org/feeds/5060442204302876 | <a href="https://web.archive.org/web/*/https://tarscloud.org/feeds/5060442204302876">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<p>I got a chance to deeply learn about OSS (Open Source Software) while I was doing my Master's degree in 2016. I've been researching open source development since then, and I fell in love with its collaborative nature and the way of writing and using software. Since then, I've been advocating for open source projects, and supporting the OSS community in many different ways. What strikes me the most about open source development is that its collaborative nature allows innovation at a fast pace and I believe that it can result in many future discoveries.</p>
<p>Although open source is very popular now, it has been defined as an actual term in the late 70's and early 80's. For those who are not familiar with the term, open source is a technology development and distribution model, where everything is done in public - from setting a roadmap to develop new features, fix bugs, code review to source code, to name a few. Normally, there is a governing board, usually formed by hobbyists, a company, or a foundation, that publicly manages the project.</p>
<p>Open source is everywhere! From the smallest embedded systems to the computers, cellphones, and infrastructure of the companies we engage with every day.  When you stream Netflix on your home, for example, you fire up Amazon web services, most of which run on Linux, one of the biggest open source projects. If you have an Android cellphone, then you use Linux in your everyday life. Despite that, many applications in the next generation of technology are open source. For example, Google open sourced its artificial intelligence engine called TensorFlow in 2015.</p>
<p>Surprisingly, open source is now embraced by big tech companies. For example, IBM plans to pay $34 billion for the open source company Red Hat, and Microsoft paid $7.5 billion to acquire the code hosting and collaboration platform GitHub. Finally, Walmart has just released its own open source software [1].</p>
<p><strong>So, at this point, you might be asking yourself why would a company open source their projects?</strong></p>
<p>For a lot of reasons. Let's take the aforementioned Tensorflow as an example. When Google open sourced Tensorflow, it not only enabled companies, researchers, and hobbyists to build applications using the technology the tech giant uses to do translation tasks, for example, but also to have outside developers to make their software better and adapt it to each person's needs. Currently, more than 1,300 developers outside Google have worked on TensorFlow.</p>
<p>And in this case, what is the advantage of open sourcing Tensorflow? It's pretty simple! By open sourcing the tool, Google helped TensorFlow to become one of the standard frameworks for developing AI applications, which can boost other tech fields that depend on AI. Additionally, open source serves as valuable marketing. After Google has open sourced Tensorflow, Dropbox and Airbnb have used TensorFlow to recognize text in documents and photographs.</p>
<p>Another example is the Chinese tech giant Tencent that has open sourced its microservices framework TARS. TARS now is an open source foundation and it is helping to build a strong community of microservice open source software. After TARS has become open source, not only has TARS grown in terms of the number of functionalities developed by developers all over the world, but it has also helped the project to attract and retain technical talent.</p>
<p>I hope that at this stage I have convinced you the many advantages when open sourcing a software project. So, let's take a look at the main reasons why you should either open source your project, use open source software or contribute to open source development.</p>
<p><strong>Vendor neutrality</strong><br>
Open source software enables vendor neutrality. That means that no matter if you are a user, a company, or a country, you are not locked in to another company's technical stack, road map or licensing agreements [2]. Soon in the future, chip designers won't be locked into Intel or ARM with RISC-V. Thanks to the OpenRAN project, 5G network builders won't be forced to buy from Huawei, Nokia, or Ericsson, for example [2].</p>
<p><strong>Security</strong><br>
You might be thinking that by open sourcing a project, it becomes more vulnerable to attacks. The fact is that when exposing the codebase publicly, security experts have easy access to test it and improve the technology security. The operating system Linux and the cloud container orchestration system Kubernetes are good examples for security in open source.</p>
<p><strong>Collaboration &amp; Sharing Leads to Innovation</strong><br>
Community is the core of open source development. Contributing in a diverse and innovative environment helps to create an innovative organization for three reasons. First, developers will need to work with other people, explain how things work as well as ask for help (especially if you are a newcomer in the community :-) ). The acts of learning and teaching can bring a lot to everyone involved [3]. Second, open source communities have people with different skills, experiences, nationalities, and gender. By valuing an inclusive environment and having a lot of diversity, teams may become more innovative. Finally, open source has practices around transparency, reduction in hierarchy, and open communication, which encourage motivation and an innovative mindset.</p>
<p>To conclude, open source development depends on a passionate community of developers. To succeed in open source, I believe that there must be a continued collaboration between users, developers, and companies. Although open source development might have its issues (as every thing in life), the pros are more than the cons. Diverse team builds better projects, and better software is what open source is about.</p>
<p><strong data-tomark-pass="">About the author: </strong><br>
<em>Isabella Ferreira is ambassador at TARS Foundation, a cloud-native open-source microservice foundation under the Linux Foundation.</em></p>
<p><strong>References:</strong><br>
[1] https://www.wired.com/story/wired-guide-open-source-software/<br>
[2] https://www.wired.com/story/opinon-the-future-of-american-industry-depends-on-open-source-tech/<br>
[3] https://opensource.guide/how-to-contribute/</p>
        </div></div>]]>
            </description>
            <link>https://tarscloud.org/feeds/5060442204302876</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310772</guid>
            <pubDate>Tue, 02 Mar 2021 01:19:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Database Normalization in plain language for the working dev (with examples)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310646">thread link</a>) | @aegatlin
<br/>
March 1, 2021 | https://www.gatlin.io/guides/database-normalization | <a href="https://web.archive.org/web/*/https://www.gatlin.io/guides/database-normalization">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<h2 id="table-of-contents">Table of Contents</h2>
<ul>
<li>
<p><a href="#introduction">Introduction</a></p>
</li>
<li>
<p><a href="#basic-columns-and-special-columns">Basic columns and special columns</a></p>
<ul>
<li><a href="#ignoring-the-serial-id-column">Ignoring the serial <code>id</code> column</a></li>
</ul>
</li>
<li>
<p><a href="#first-normal-form-1nf">First Normal Form, 1NF</a></p>
</li>
<li>
<p><a href="#second-normal-form-2nf">Second Normal Form, 2NF</a></p>
</li>
<li>
<p><a href="#third-normal-form-3nf">Third Normal Form, 3NF</a></p>
<ul>
<li><a href="#a-note-about-boyce-codd-normal-form-bcnf-35nf">A note about Boyce-Codd Normal Form, BCNF, 3.5NF</a></li>
</ul>
</li>
<li>
<p><a href="#fourth-normal-form-4nf">Fourth Normal Form, 4NF</a></p>
</li>
<li>
<p><a href="#fifth-normal-form-and-beyond">Fifth Normal Form and beyond</a></p>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
<li>
<p><a href="#appendices">Appendices</a></p>
<ul>
<li><a href="#appendix-a-sql-script-converting-unnormalized-data-to-1nf">Appendix A: SQL script converting unnormalized data to 1NF</a></li>
<li><a href="#appendix-b-sql-script-converting-1nf-to-2nf">Appendix B: SQL script converting 1NF to 2NF</a></li>
<li><a href="#appendix-c-sql-script-converting-2nf-to-3nf">Appendix C: SQL script converting 2NF to 3NF</a></li>
</ul>
</li>
</ul>
<h2 id="introduction">Introduction</h2>
<p><a href="https://en.wikipedia.org/wiki/Database_normalization">Database Normalization</a> can be complicated. The definitions of the various "normal forms" are academic and not very practical. All this can leave one feeling lost. Hopefully, this guide can help. <strong>This guide aims to be a practical, succinct guide to database normalization for the working software engineer.</strong> In what follows we will look at the first few normal forms and their properties in simple language. (If you just want a table of normal forms and their properties, check out <a href="https://en.wikipedia.org/wiki/Database_normalization#Normal_forms">this table</a>.)</p>
<h2 id="basic-columns-and-special-columns">Basic columns and special columns</h2>
<p>In what follows I will refer to table columns as either "basic columns" or "special columns". When I say "basic", I really just mean "not special", which raises the core question of: <strong>What is meant by "special column"? Simply put, a special column is a column you could use to uniqely identify rows within a table.</strong><sup id="fnref-1"><a href="#fn-1">1</a></sup> It is of critical important in database normalization to identify all the special columns of a table. This might naively seem easy to do, but determining the special columns of a table can quickly become a subtle and debatable business.</p>
<p>That said, there is one special column that is always straightforward, and will show up in essentially every production database table you will ever interact with: the serial <code>id</code> column. It's basically the <em>most</em> special column of all because it exists for the sole purpose of uniquely identifying rows in a table. It's so special in fact, that, really, it's too special, and so we will completely ignore it when discussing database normalization. I discuss this oddity in more detail in the next section.</p>
<h3 id="ignoring-the-serial-id-column">Ignoring the serial <code>id</code> column</h3>
<p>The reason we ignore the serial <code>id</code> column is because what we are really looking for is the <em>naturally</em> special columns. We are looking for the fundamental attributes, or properties, of the entities in question. We want to normalize the "real" data, the data you <em>need</em> in order to appropriately describe the entities. The serial <code>id</code> column isn't "real" data, it's not a property of the entity, it's just tacked on to a row to guarantee unique identification. Only by normalizing against the "real" data will you actually gain the benefits of normalization, which are, among other things, less duplication and less redundancy.</p>
<p>So, while I will include the <code>id</code> column in examples, because that's the most practical way to interact with tables, please keep in mind that (1) we will be ignoring it, and (2) why we are choosing to do so (which, as a reminder, is because we are only concerned with "real" data).</p>
<h2 id="first-normal-form-1nf">First Normal Form, 1NF</h2>
<p><a href="https://en.wikipedia.org/wiki/First_normal_form">First Normal Form</a>, simply put, means <strong>don't put lists in table cells</strong>.<sup id="fnref-2"><a href="#fn-2">2</a></sup></p>
<p>Putting a list in a cell is strongly discouraged unless you have a very good reason to do so. There are multiple datatypes that will allow you to do this, for example the <code>ARRAY</code> keyword in SQL, but just because you can doesn't mean you should.</p>
<p>Before I discuss the most common way I see this violation occur, I want to briefly discuss JSON and JSONB data in table cells. JSON(B) is a valid data type, and has many justifiable use cases, including NoSQL-like data storage, but it should still be avoided unless you have a good reason to use it. <a href="https://www.postgresql.org/docs/13/datatype-json.html#JSON-DOC-DESIGN">Section 8.14.2</a> of the PostgreSQL docs states the following on this topic:</p>
<blockquote>
<p>Ideally, JSON documents should each represent an atomic datum that business rules dictate cannot reasonably be further subdivided into smaller datums that could be modified independently.</p>
</blockquote>
<p>Now, probably the most common way you'll see 1NF being violated is with cells containing comma-separated values as follows:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>books</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Austin</td>
<td>East of Eden,Green Eggs and Ham</td>
</tr>
<tr>
<td>2</td>
<td>Bertha</td>
<td>Grapes of Wrath,The Cat in the Hat</td>
</tr>
</tbody>
</table>
<p>The solution to the problem is to create a row per book instead:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>book</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Austin</td>
<td>East of Eden</td>
</tr>
<tr>
<td>2</td>
<td>Austin</td>
<td>Green Eggs and Ham</td>
</tr>
<tr>
<td>3</td>
<td>Bertha</td>
<td>Grapes of Wrath</td>
</tr>
<tr>
<td>4</td>
<td>Bertha</td>
<td>The Cat in the Hat</td>
</tr>
</tbody>
</table>
<p>See Appendix A for a SQL<sup id="fnref-3"><a href="#fn-3">3</a></sup> script that transforms the unnormalized example data into the 1NF data as shown above. It is in a format that's easy to copy and paste and experiment with yourself, which I encourage you to do.</p>
<h2 id="second-normal-form-2nf">Second Normal Form, 2NF</h2>
<p><a href="https://en.wikipedia.org/wiki/Second_normal_form">Second Normal Form</a>, simply put, means that, in addition to being in 1NF, <strong>every basic column is determined by <em>all</em> the special columns</strong>. <sup id="fnref-4"><a href="#fn-4">4</a></sup> <sup id="fnref-5"><a href="#fn-5">5</a></sup></p>
<p>An example 1NF table that violates 2NF is as follows:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>book</th>
<th>price</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Austin</td>
<td>East of Eden</td>
<td>25</td>
</tr>
<tr>
<td>2</td>
<td>Austin</td>
<td>Green Eggs and Ham</td>
<td>10</td>
</tr>
<tr>
<td>3</td>
<td>Bertha</td>
<td>East of Eden</td>
<td>25</td>
</tr>
<tr>
<td>4</td>
<td>Bertha</td>
<td>Grapes of Wrath</td>
<td>20</td>
</tr>
</tbody>
</table>
<p>The <code>price</code> column is determined completely by the <code>book</code> column, and nothing else. But, the special columns are both <code>book</code> <em>and</em> name. This partial determination of <code>price</code> by just <code>book</code>, and not also <code>name</code>, is a violation of 2NF. The logic here is that if a special column has no impact on a basic column, then the basic column probably shouldn't be in the table at all.</p>
<p>The solution is separating out the book details into a second table:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>title</th>
<th>price</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>East of Eden</td>
<td>25</td>
</tr>
<tr>
<td>2</td>
<td>Grapes of Wrath</td>
<td>20</td>
</tr>
<tr>
<td>3</td>
<td>Green Eggs and Ham</td>
<td>10</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>book_id</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Austin</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>Austin</td>
<td>5</td>
</tr>
<tr>
<td>3</td>
<td>Bertha</td>
<td>3</td>
</tr>
<tr>
<td>4</td>
<td>Bertha</td>
<td>4</td>
</tr>
</tbody>
</table>
<p>This is sufficient to satisfy 2nd Normal Form.<sup id="fnref-6"><a href="#fn-6">6</a></sup></p>
<p>See Appendix B for a SQL script that transforms the 1NF table into 2NF tables as shown above. It is in a format that's easy to copy and paste and experiment with yourself, which I encourage you to do.</p>
<h2 id="third-normal-form-3nf">Third Normal Form, 3NF</h2>
<p><a href="https://en.wikipedia.org/wiki/Third_normal_form">Third Normal Form</a>, simply put, means that, in addition to being in 2NF, <strong>every basic column is <em>directly</em> determined by the special columns</strong>.<sup id="fnref-7"><a href="#fn-7">7</a></sup> <sup id="fnref-8"><a href="#fn-8">8</a></sup> This might sound confusingly similar to 2NF, but the key difference is <em>direct</em> determination. 2NF still allows for <strong>in</strong>direct determination, otherwise known as transitively dependent determination.</p>
<p>An example 2NF table that is violating 3NF is as follows:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>loan_date</th>
<th>loanee</th>
<th>loanee_dob</th>
<th>book_id</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2021-03-03</td>
<td>Bertha</td>
<td>1902-02-02</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>2021-03-03</td>
<td>Bertha</td>
<td>1902-02-02</td>
<td>7</td>
</tr>
<tr>
<td>3</td>
<td>2021-02-02</td>
<td>Austin</td>
<td>1900-01-01</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>The problem is that <code>loanee_dob</code> is determined by <code>loanee</code>, but <code>loanee</code> is <em>not</em> one of the special columns, which are <code>book_id</code> and <code>loan_date</code>. It <em>is</em> true that, if you give me the special columns of <code>book_id</code> and <code>loan_date</code> I <em>will</em> find the <code>loanee_dob</code> unique to that row, but the "truth" of <code>loanee_dob</code> is <em>dependent</em> on the <code>loanee</code>. This indicates that the <code>loanee_dob</code> is <em>indirectly (i.e., transitively) dependent</em> on the special columns <em>through</em> the <code>loanee</code> column. This is the kind of indirectness we are trying to avoid.</p>
<p>The solution is extracting the transitively dependent columns into their own table. For example:</p>
<table>
<thead>
<tr>
<th>id</th>
<th>name</th>
<th>dob</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Bertha</td>
<td>1902-02-02</td>
</tr>
<tr>
<td>2</td>
<td>Austin</td>
<td>1900-01-01</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>id</th>
<th>loan_date</th>
<th>loanee_id</th>
<th>book_id</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2021-03-03</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>2</td>
<td>2021-03-03</td>
<td>1</td>
<td>7</td>
</tr>
<tr>
<td>3</td>
<td>2021-02-02</td>
<td>1</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>See Appendix C for a SQL script that transforms the 2NF table into 3NF tables as shown above. It is in a format that's easy to copy and paste and experiment with yourself, which I encourage you to do.</p>
<h3 id="a-note-about-boyce-codd-normal-form-bcnf-35nf">A note about Boyce-Codd Normal Form, BCNF, 3.5NF</h3>
<p>There are edge cases in the technical definition of 3NF that <a href="https://en.wikipedia.org/wiki/Boyce%E2%80%93Codd_normal_form">BCNF</a> attempts to address. (<a href="https://en.wikipedia.org/wiki/Third_normal_form#Definition_of_third_normal_form">This</a> is the best articulation of the difference between 3NF and BCNF/3.5NF that I've read, which occurs near the end of the section.) To the best of my knowledge, the simple takeaway is essentially the same it was for 3NF, i.e., <strong>every basic column is <em>directly</em> determined by the special columns</strong>.</p>
<h2 id="fourth-normal-form-4nf">Fourth Normal Form, 4NF</h2>
<p><a href="https://en.wikipedia.org/wiki/Fourth_normal_form">Fourth Normal Form</a>, in a sense, <em>cannot be put simply</em>. If I had to try, I'd say that 4NF, "simply put", means that, in addition to being in 3NF, <strong>if a group of cells across one or more columns can determine a group of cells in one or more <em>other</em> columns, then the original group of cells in the original column(s) must at least be in the special columns</strong>. Since that "simple" sentence barely makes sense, I'll just include the technical version, instead of hiding it in a footnote. The technical version is: Every non-trivial, <em>multivalued</em> functional dependency is derived from a superkey, minimal or otherwise.</p>
<p>I have not found a dataset that, in my opinion, is unequivocally both in 3NF and violating 4NF, so at the moment I do not have an example nor script to transform the relation. The wikipedia pages for <a href="https://en.wikipedia.org/wiki/Third_normal_form">3NF</a>, <a href="https://en.wikipedia.org/wiki/Boyce%E2%80%93Codd_normal_form">BCNF</a>, and <a href="https://en.wikipedia.org/wiki/Fourth_normal_form">4NF</a> are good starting points for learning more about 4NF. When I find a good example, I will include it here.</p>
<h2 id="fifth-normal-form-and-beyond">Fifth Normal Form and beyond</h2>
<p>Things get quite academic and arguably non-practical after 4NF, and maybe actually after 3NF, although it does seems that <a href="https://en.wikipedia.org/wiki/Fourth_normal_form#4NF_in_practice">4NF violations do actually occur in practice</a>.</p>
<p>I will chose not to cover <a href="https://en.wikipedia.org/wiki/Fifth_normal_form">5NF</a> and other higher-order properties that can be found in <a href="https://en.wikipedia.org/wiki/Database_normalization#Normal_forms">this table</a> (which I also linked to in the intro). It is an interesting field of research, so I encourage you to dig deeper and look into these properties yourself.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I hope you found this guide helpful. If you have any questions or feedback, feel free to reach out! Happy coding :D</p>
<h2 id="appendices">Appendices</h2>
<h3 id="appendix-a-sql-script-converting-unnormalized-data-to-1nf">Appendix A: SQL script converting unnormalized data to 1NF</h3>
<p>This is probably not the best solution. It is a fully contained solution. You are encouraged to copy and paste and experiment with it. For example, if you saved this file as <code>example.sql</code>, you could run the following from the command line (assuming you are using PostgreSQL):</p>
<pre><code><span>$</span><span> createdb <span>test</span></span>
<span>$</span><span> psql -d <span>test</span> -f example.sql</span>
</code></pre>
<p>Similar functionality can be achieved with other datatypes. For example, if your data was in a <code>text ARRAY</code> data type, you could use <code>unnest(books)</code> instead of <code>regexp_split_to_table()</code>.</p>
<pre><code><span>DROP</span> <span>TABLE</span> <span>IF</span> <span>EXISTS</span> users;
<span>CREATE</span> <span>TABLE</span> users (id <span>SERIAL</span> <span>PRIMARY KEY</span>, <span>name</span> <span>text</span>, books <span>text</span>);
<span>INSERT</span> <span>INTO</span> users (<span>name</span>, books) <span>VALUES</span>
  (<span>'Austin'</span>, <span>'East of Eden,Green Eggs and Ham'</span>),
  (<span>'Bertha'</span>, <span>'Grapes of Wrath,The Cat in the Hat'</span>);

<span>ALTER</span> <span>TABLE</span> users <span>ADD</span> <span>COLUMN</span> book <span>text</span>;

<span>DO</span> $$<span>
  <span>DECLARE</span>
    user_record <span>record</span>;
    user_book <span>text</span>;
  <span>BEGIN</span>
    <span>FOR</span> user_record <span>IN</span>
      <span>SELECT</span> * <span>FROM</span> users
    <span>LOOP</span>
      <span>FOR</span> user_book <span>IN</span></span></code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gatlin.io/guides/database-normalization">https://www.gatlin.io/guides/database-normalization</a></em></p>]]>
            </description>
            <link>https://www.gatlin.io/guides/database-normalization</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310646</guid>
            <pubDate>Tue, 02 Mar 2021 01:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Early Byzantine finds at the far ends of the world (2017)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310569">thread link</a>) | @Thevet
<br/>
March 1, 2021 | https://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html | <a href="https://web.archive.org/web/*/https://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-809045710061289481" itemprop="description articleBody"><p>
The following brief post is once again offered largely for the sake of interest, being concerned with the furthest limits of the distribution of early Byzantine material in Eurasia and Africa. What follows consists of a distribution map of fifth- to seventh-century AD Byzantine finds and contemporary imitations accompanied by a brief discussion and illustration of some of the items that have been found in the far west, far east, far north and far south of the 'Old World'. Needless to say, the extensive distribution of early Byzantine material shown here is of interest for a number of reasons from the perspective of this blog, not least the light that it sheds on early medieval Britain's&nbsp;<a href="http://www.caitlingreen.org/2016/04/heptarchy-harun-ibn-yahya.html">Byzantine</a> and <a href="http://www.caitlingreen.org/2016/05/anglo-saxon-finds-france-africa.html">Indian Ocean</a>&nbsp;imports and connections discussed in previous posts.</p><table><tbody>
<tr><td><a href="https://2.bp.blogspot.com/-dSEC_2WafyA/WOS09i45muI/AAAAAAAAAv8/QR2A3JUtm4A-TMc67YlePIsUx9tXciB8QCLcB/s1600/Byzantine_exports_large_labelled.png"><img src="https://3.bp.blogspot.com/-Jt6yOEDgj-E/WOS09ZOtTrI/AAAAAAAAAv4/23d6Z0eyzU0ZING9fzs0H5sBBckgjb_XwCLcB/s1600/Byzantine_exports_small_labelled.png"></a></td></tr>
<tr><td><i>Distribution of early Byzantine items and contemporary imitations found outside of the boundaries of the mid-sixth-century empire, along with a depiction of the empire during the reign of Justinian (c. 565 AD). For a larger version of this map, click <a href="https://2.bp.blogspot.com/-dSEC_2WafyA/WOS09i45muI/AAAAAAAAAv8/QR2A3JUtm4A-TMc67YlePIsUx9tXciB8QCLcB/s1600/Byzantine_exports_large_labelled.png">here</a>. The numbers refer to sections in the text, below. Note, the finds in the Kama region of Russia seem to have arrived there in the eighth to twelfth centuries from Central Asia, hence the inclusion—following Mango (ed.),&nbsp;Byzantine Trade, 4th-12th Centuries (Farnham, 2009), fig. 1.1—of a notional grouping of finds in a regular block to the southeast of the Aral Sea and an arrow indicating the relationship between these and the Russian finds. (Image: C. R. Green, based on the sources listed in <a href="http://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html#fn1">fn. 1</a>)</i></td></tr>
</tbody></table>

<p><b>The Far West (1)</b></p><p>

For both <a href="http://www.ccel.org/ccel/schaff/npnf206.v.LX.html#fna_v.LX-p24.1">St Jerome</a>, writing near Bethlehem in 396, and <a href="https://books.google.co.uk/books?id=4ZUhAQAAIAAJ&amp;q=%22the+island+of+Britain+lies+virtually+at+the+end+of+the+world%22">Gildas</a>, writing around a century later in late fifth- or early sixth-century Britain, the British Isles lay 'virtually at the end of the world towards the west and north-west'. Despite this, there was clearly an intriguing degree of contact between the British Isles and the early Byzantine empire during the fifth to seventh centuries, as has been discussed at length in a <a href="http://www.caitlingreen.org/2016/04/heptarchy-harun-ibn-yahya.html">previous post</a>. In terms of the material evidence for this connection, this is manifested by significant finds of fifth- to sixth-century Eastern Mediterranean and North African <a href="https://books.google.co.uk/books?id=bBwtGITEd1oC&amp;lpg=PA297&amp;pg=PA297#v=onepage&amp;q&amp;f=false">pottery</a> in western Britain and <a href="https://aran.library.nuigalway.ie/handle/10379/3263">Ireland</a> (with around half of the total coming from the probable royal site of <a href="http://www.medievalhistories.com/luxury-tintagel-early-medieval-period/">Tintagel</a>, Cornwall), alongside Byzantine <a href="https://www.academia.edu/11482638/_Early_Byzantine_copper_coins_found_in_Britain_A_review_of_new_finds_recorded_with_the_Portable_Antiquities_Scheme_Ancient_History_Numismatics_and_Epigraphy_in_the_Mediterranean_World_ed._Og%C5%ADz_Tekin_Yayinlari_Istanbul_2009_263-274">coins</a>, metalwork, and a number of burials of people whose <a href="http://www.caitlingreen.org/2015/10/oxygen-isotope-evidence.html">isotope results</a> indicate that they could well have grown up in Byzantine North Africa. It has <a href="https://books.google.co.uk/books?id=kIMmDQAAQBAJ&amp;lpg=PA78&amp;pg=PA78#v=onepage&amp;q&amp;f=false">often</a> been <a href="https://www.reading.ac.uk/web/files/GCMS/RMS-2006-09_A._Harris,_Britain_and_China_at_opposite_ends_of_the_world.pdf">suggested</a> that the material in the west may have arrived via a different mechanism to that in the east, perhaps representing direct, official contact via the Straits of Gibraltar and the Atlantic coast vs indirect transfer via merchants and elite exchange along the rivers of mainland Europe, although finds of late sixth- to early seventh-century Byzantine coins from the Anglo-Saxon royal site of Rendlesham, Suffolk, have recently been <a href="https://www.cambridge.org/core/journals/antiquity/article/div-classtitlesocial-and-economic-complexity-in-early-medieval-england-a-central-place-complex-of-the-east-anglian-kingdom-at-rendlesham-suffolkdiv/FE9E1DB3180F1390E97D97BF28B637D5">interpreted</a> as evidence for 'direct mercantile contacts' with the Byzantine world in eastern Britain too.</p><table><tbody>
<tr><td><a href="https://3.bp.blogspot.com/-s3jgZsYVBSk/WL36HCbCY9I/AAAAAAAAAmY/l6UPI0P3YXkpFM3EloTPM4aDU1uz7H8DwCLcB/s1600/plymouth-amphora-large.jpg"><img src="https://1.bp.blogspot.com/-ABT16_kL9oA/WL36G1VDqLI/AAAAAAAAAmU/9vNExHZEuH8Zqg0dn2EZAGcP28AYnviiACLcB/s1600/plymouth-amphora-small.jpg"></a></td></tr>
<tr><td><i>A fifth- or sixth-century Late Roman 1 amphora from the Eastern Mediterranean found on the sea bed at Plymouth; note, this amphora still has the residue in it of the red wine that it once transported (image: <a href="http://www.promare.co.uk/ships/Finds/Fd_12A10Amphora.html">Ships Project/ProMare</a>, CC BY-NC-SA 2.0)</i></td></tr>
</tbody></table>
<br>
<table><tbody>
<tr><td><a href="https://4.bp.blogspot.com/-YMiu3ZMNvEg/WL38Px2_ujI/AAAAAAAAAmg/PfG2sEkMW_kyeaWUh4BGx8OsJex_01ZywCLcB/s1600/prsw-ireland.jpg"><img src="https://4.bp.blogspot.com/-YMiu3ZMNvEg/WL38Px2_ujI/AAAAAAAAAmg/PfG2sEkMW_kyeaWUh4BGx8OsJex_01ZywCLcB/s1600/prsw-ireland.jpg"></a></td></tr>
<tr><td><i>A rim-sherd of Phocaean Red Slip Ware—high quality red-slipped tableware made in modern Turkey during the late fifth to early sixth century—discovered at Collierstown, Co. Meath, Ireland (image: <a href="https://aran.library.nuigalway.ie/handle/10379/3263">Kelly 2010</a>, CC).</i></td></tr>
</tbody></table>
<br>

<table><tbody>
<tr><td><a href="https://1.bp.blogspot.com/-hBzH_PDM914/WL3_apC7FeI/AAAAAAAAAms/lNlDJRNrVPgl6Ct6q25kgBk_o-py1LBGwCLcB/s1600/SuttonHoo.jpg"><img height="400" src="https://1.bp.blogspot.com/-hBzH_PDM914/WL3_apC7FeI/AAAAAAAAAms/lNlDJRNrVPgl6Ct6q25kgBk_o-py1LBGwCLcB/s400/SuttonHoo.jpg" width="393"></a></td></tr>
<tr><td><i>Byzantine bowls and spoons (with Greek inscriptions) from the Eastern Mediterranean, made c. 600 AD and found in the early seventh-century Sutton Hoo ship burial, Suffolk (image: <a href="http://www.britishmuseum.org/research/collection_online/collection_object_details.aspx?objectId=87283&amp;partId=1">British Museum</a>).</i></td></tr>
</tbody></table>
<br>
<table><tbody>
<tr><td><a href="https://1.bp.blogspot.com/-hDbmpS-O7yE/WL66j_4-CHI/AAAAAAAAAm8/nfBLfiwTc3sitPvyidqHCgpGbf8E6NEOgCLcB/s1600/AN00131074_001_l.jpg"><img height="400" src="https://1.bp.blogspot.com/-hDbmpS-O7yE/WL66j_4-CHI/AAAAAAAAAm8/nfBLfiwTc3sitPvyidqHCgpGbf8E6NEOgCLcB/s400/AN00131074_001_l.jpg" width="381"></a></td></tr>
<tr><td><i>The Wilton Cross, incorporating a Byzantine solidus of Heraclius dating 613–32; made at an East Anglian workshop in the first half of the seventh century and found at Wilton, Norfolk (image: <a href="http://www.britishmuseum.org/research/collection_online/collection_object_details.aspx?objectId=86025&amp;partId=1">British Museum</a>).</i></td></tr>
</tbody></table>
<br>
<table><tbody>
<tr><td><a href="https://1.bp.blogspot.com/-UuBFx2OEv5s/WL67-JywcaI/AAAAAAAAAnE/c_ywBqRiPBIYco-OUNN841NOHyqsfOuQwCLcB/s1600/AN00083896_001_l.jpg"><img height="300" src="https://1.bp.blogspot.com/-UuBFx2OEv5s/WL67-JywcaI/AAAAAAAAAnE/c_ywBqRiPBIYco-OUNN841NOHyqsfOuQwCLcB/s400/AN00083896_001_l.jpg" width="400"></a></td></tr>
<tr><td><i>A sixth- to seventh-century early Byzantine censer, found at Glastonbury Abbey; it was found with traces of burnt incense still remaining within it and the&nbsp;closest parallels for the Glastonbury censer come from Sardis (Turkey), Egypt and Galilee (image: <a href="http://www.britishmuseum.org/research/collection_online/collection_object_details.aspx?objectId=62694&amp;partId=1">British Museum</a>).</i></td></tr>
</tbody></table>

<p><b>The Far East (2, 3, 4)</b></p><p>

If there is a substantial amount of early Byzantine material found in Britain and Ireland, the apparent westernmost extremity of the known world in late antiquity, there is also a notable quantity at the far eastern end too. In <a href="http://www.ccel.org/ccel/schaff/npnf206.v.LX.html#fna_v.LX-p24.1">St Jerome</a>'s letter, cited above, the rhetorical opposite extremity of the world to Britain was given as India, but Roman and Byzantine authors were certainly aware of the existence of China and parts of Southeast Asia. China was, for example, mentioned by <a href="http://sino-platonic.org/complete/spp261_Roman_Chinese.pdf">Roman</a> and <a href="http://heiup.uni-heidelberg.de/journals/index.php/transcultural/article/view/6127/2962">early Byzantine</a> writers from the <a href="https://en.wikipedia.org/wiki/Sino-Roman_relations#Roman_geography">first century BC onwards</a> and it is included not only in Ptolemy's second-century AD <i><a href="https://commons.wikimedia.org/wiki/File:PtolemyWorldMap.jpg">Geography</a></i> (which mentions parts of <a href="https://commons.wikimedia.org/wiki/File:Ptolemy_Asia_detail.jpg">Southeast Asia</a> too), but also on the <i><a href="http://www.euratlas.net/cartogra/peutinger/11_india/india_8_2.html">Tabula Peutingeriana</a></i>, a fascinating map that seems to have had its origins in the <a href="https://en.wikipedia.org/wiki/Tabula_Peutingeriana">Late Roman period</a>. Moreover, <a href="https://books.google.co.uk/books?id=uZ_sAQAAQBAJ&amp;lpg=PA38&amp;pg=PA38#v=onepage&amp;q&amp;f=false">Roman</a> and especially <a href="https://www.academia.edu/1945062/The_Roman_Empire_according_to_the_Ancient_Chinese_Sources">Chinese sources</a> make several <a href="https://en.wikipedia.org/wiki/Sino-Roman_relations#Possible_Roman_Greeks_in_Burma_and_China">references</a> to Hellenistic, Roman and early Byzantine entertainers, merchants and/or embassies being present in China and Southeast Asia, including a <a href="https://www.academia.edu/1945062/The_Roman_Empire_according_to_the_Ancient_Chinese_Sources">mission in 166 AD</a> that arrived via the south coast—probably entering China via Vietnam and claiming to have been sent by the Roman emperor <i>Andun</i> (Antoninus Pius or Marcus Aurelius Antoninus?), although this was perhaps really a commercial action that chose to represent itself this way—and numerous seventh- and eighth-century <a href="https://en.wikipedia.org/wiki/Sino-Roman_relations#Fulin:_Eastern_Roman_embassies">Byzantine</a>&nbsp;<a href="https://byzantineperspectives.wordpress.com/2015/10/17/what-does-tang-china-have-in-common-with-anglo-saxon-england/">embassies</a>&nbsp;to Tang China.</p><p>

In terms of the early Byzantine material found in eastern parts of Eurasia, there is a variety of surviving artefacts ranging from glass vessels, metalwork and textiles through to gold and bronze coinage, with the latter being by far the most numerous category. The most easterly early Byzantine artefacts are actually found in Korea and Japan ('2' on the map, above). The former has seen finds of <a href="https://www.google.com/culturalinstitute/beta/asset/glass-vessels/cwFZdR3ccuXZ-w?hl=en">glass vessels</a> from the late fifth- to early sixth-century AD royal tombs at <a href="http://www.metmuseum.org/toah/hd/sila/hd_sila.htm">Silla, Korea</a>, some of which appear to have actually been <a href="https://books.google.co.uk/books?id=mpanKmU_ckYC&amp;lpg=PA126&amp;pg=PA126#v=onepage&amp;q&amp;f=false">made in</a>&nbsp;<a href="http://ijkh.khistory.org/upload/pdf/ijkh-19-1-1.pdf">the early Byzantine empire</a> and others of which are believed to be <a href="http://www.unescobkk.org/fileadmin/user_upload/culture/Silk_Roads/The_Eastern_Silk_Roads_Story_2015_Conference_Proceedings_UNESCO_re.pdf">imitative</a> of Late Roman/Early Byzantine forms, whilst in Japan there have been not only finds of early Byzantine 'Levantine 1' <a href="https://www.researchgate.net/publication/284359734_Archaeometrical_investigation_of_natron_glass_excavated_in_Japan">glass beads</a> (probably made on the coast of present-day northern Israel) from fifth-century AD tombs, but the important mid-eighth-century AD imperial <a href="https://en.wikipedia.org/wiki/Sh%C5%8Ds%C5%8Di">Shōsōin Repository</a> at Nara, Japan, is also reported to contain a number of Byzantine items including a <a href="http://sino-platonic.org/complete/spp206_sasanian_persia.pdf">cushion cover</a> made in early Byzantine Syria. Interestingly, neither Japan nor Korea is mentioned in Roman or Byzantine sources, although a recent isotopic and mitochondrial DNA <a href="https://www.researchgate.net/publication/236210479_Stable_isotope_and_mtDNA_evidence_for_geographic_origins_at_the_site_of_Vagnari_South_Italy">study of burials</a> on the Imperial estate at Vagnari, southern Italy, has indicated that one of the adults buried there in the first or second century AD could have had Japanese ancestry, given that 'all modern mtDNA matches to her available haplotype sequence are from Japan'.<sup><a href="http://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html#fn2">(2)</a></sup></p><p>

In addition to this material from the very far east, we also have a notable quantity of primarily sixth- to early seventh-century Byzantine <a href="https://www.reading.ac.uk/web/files/GCMS/RMS-2006-09_A._Harris,_Britain_and_China_at_opposite_ends_of_the_world.pdf">gold coins</a> and sixth- to eighth-century imitations from <a href="http://www.silk-road.com/newsletter/vol3num2/4_ying.php">tombs in China</a>, along with a number of <a href="https://books.google.co.uk/books?id=C9A7DAAAQBAJ&amp;lpg=PA29&amp;pg=RA1-PA29#v=onepage&amp;q&amp;f=false">finds</a> of early Byzantine metalwork and <a href="https://www.reading.ac.uk/web/files/GCMS/RMS-2006-06_M-L._Chen,_The_Importation_of_Byzantine_and_Sasanian_Glass_into_China_during_the_fourth_to_sixth_centuries.pdf">glassware</a> (and imitations of the same) from this country too. Both this material and that discussed in the preceding paragraph is <a href="https://www.reading.ac.uk/web/files/GCMS/RMS-2006-09_A._Harris,_Britain_and_China_at_opposite_ends_of_the_world.pdf">often thought</a> <a href="http://www.silk-road.com/newsletter/vol3num2/4_ying.php">to have arrived</a> via Central Asia along the '<a href="https://en.wikipedia.org/wiki/Silk_Road">Silk Road</a>', especially given the presence of a number of <a href="https://www.academia.edu/27959139/Sogdiana_its_Christians_and_Byzantium_a_Study_of_Artistic_and_Cultural_Connections_in_Late_Antiquity_and_Early_Middle_Ages">similar finds</a> in areas such as Uzbekistan and Tajikistan, although some of the Byzantine items found close to the Chinese coast and in Korea and Japan could have alternatively arrived by the less-discussed southern, maritime 'branch' of the Silk Road instead. Certainly, earlier <a href="https://www.academia.edu/1945062/The_Roman_Empire_according_to_the_Ancient_Chinese_Sources">Roman</a> and <a href="https://books.google.co.uk/books?id=uZ_sAQAAQBAJ&amp;lpg=PA38&amp;pg=PA38#v=onepage&amp;q&amp;f=false">Greek</a> <a href="https://www.academia.edu/12682533/The_Power_of_Images_Coin_Portraits_of_Roman_Emperors_on_Jewellery_Pendants_in_Early_Southeast_Asia">mariners</a>&nbsp;made use of this route, and early Byzantine <a href="http://heiup.uni-heidelberg.de/journals/index.php/transcultural/article/view/6127/2962">written sources</a> moreover appear to make reference to it, whilst finds of fifth- to seventh-century&nbsp;<a href="https://en.wikipedia.org/wiki/Sasanian_Empire">Sasanian</a> <a href="https://twitter.com/caitlinrgreen/status/832976763626078211">glassware</a>&nbsp;in Japan are&nbsp;<a href="https://www.academia.edu/28504387/Priestman_2016_The_Silk_Road_or_the_Sea_Sasanian_and_Islamic_Exports_to_Japan">argued</a> to have probably arrived there via the sea route. With regard to this maritime 'road', another relevant find may well be that of a probably sixth-century Byzantine <a href="http://www.siamese-heritage.org/jsspdf/2001/JSS_096_0b_Borrell_EarlyByzantineLampFromPongTuk.pdf">lamp</a> found in Thailand (marked as '3' on the map, above), and it is worth noting in this context that an East Javanese <a href="https://books.google.co.uk/books?id=LhaWBAAAQBAJ&amp;lpg=PT45&amp;pg=PT45#v=onepage&amp;q&amp;f=false"><i>millefiori</i></a>&nbsp;<a href="http://www.thebeadsite.com/abm-rio3.html">bead</a> of sixth-century date has been found at the Byzantine Red Sea port of <a href="https://en.wikipedia.org/wiki/Berenice_Troglodytica">Berenike</a> too (curiously, such beads are <a href="http://www.aihv.org/en/pdf/16-77.pdf">very rare indeed</a> outside of East Java, with the only other concentration really being in the Silla tombs of Korea, mentioned above!).</p><p>

Finally, thousands of fifth- to seventh-century <a href="http://etheses.bham.ac.uk/5357/1/Darley14PhD_redacted.pdf">Byzantine</a>&nbsp;<a href="https://www.academia.edu/10027506/Self_Other_and_the_Use_and_Appropriation_of_Late_Roman_coins_in_south_India_and_Sri_Lanka_4th-7th_centuries_A.D._">gold</a> and&nbsp;<a href="https://www.researchgate.net/publication/271621898_Roman_Coins_from_the_Masson_and_Mackenzie_Collections_in_the_British_Museum">bronze</a> <a href="https://www.researchgate.net/publication/292142132_The_Role_of_Monetary_Networks_in_the_Trade_between_India_and_the_Roman_Empire">coins</a> and imitations are known from India and Sri Lanka ('4' on the map), accompanied by fifth- to sixth-century <a href="http://www.reading.ac.uk:8081/web/files/GCMS/RMS-2006-02_K._R._Dark,_Globalizing_Late_Antiquity.pdf">amphorae</a> on coastal and inland sites in western India. Such finds support the <a href="http://heiup.uni-heidelberg.de/journals/index.php/transcultural/article/view/6127/2962">textual evidence</a> for continued <a href="https://books.google.co.uk/books?id=O_AtKQAACAAJ">Indo-Roman trade</a> and/or <a href="https://en.wikipedia.org/wiki/Indo%E2%80%93Roman_trade_relations">interaction</a> via the Red Sea beyond the more frequently discussed Early Roman era into the Late Roman/Early Byzantine period, as do both the Indo-Pacific imports found at sites such as <a href="https://books.google.co.uk/books?id=bBwtGITEd1oC&amp;lpg=PA345&amp;pg=PA345#v=onepage&amp;q&amp;f=false">Byzantine Berenike</a> and the recent <a href="https://www.academia.edu/22932720/Strontium_isotope_evidence_for_long-distance_immigration_into_the_Byzantine_port_city_of_Aila_modern_Aqaba_Jordan">isotopic analysis</a> of burials of the fourth- to fifth-century AD at the Byzantine Red Sea port of <a href="http://maajournal.com/Issues/2012/Vol12-1/Full8.pdf">Aila</a> (Jordan), which indicates that people from areas beyond western Asia and North Africa were living there then, including some who had potentially grown up in the Indus Valley.</p>
<table><tbody>
<tr><td><a href="https://3.bp.blogspot.com/-8BYIFd7MpxE/WML4qB2Lc9I/AAAAAAAAAoI/6Fia79cNzigqCIW0YG5zbiB87OjujuZzACLcB/s1600/syrian-cushion.jpg"><img height="395" src="https://3.bp.blogspot.com/-8BYIFd7MpxE/WML4qB2Lc9I/AAAAAAAAAoI/6Fia79cNzigqCIW0YG5zbiB87OjujuZzACLcB/s400/syrian-cushion.jpg" width="400"></a></td></tr>
<tr><td><i>A silk cushion cover made in Byzantine Syria and preserved in the eighth-century imperial&nbsp;Shōsōin Repository at Nara, Japan,&nbsp;given to the monastery by the Emperor Shomu in 754; see H. B. Feltham, 'Lions, silks and silver: the influence of Sasanian Persia', Sino-Platonic Papers, 206 (2010), who notes that the cushion represents a copy of Sasanian motifs by 'the Byzantines in Syria' (p. 18). (Image via <a href="https://au.pinterest.com/pin/257338566185793433/">Pinterest</a>; also in Feltham, 2010, fig, 10, CC)</i></td></tr>
</tbody></table>
<br>
<table><tbody>
<tr><td><a href="https://3.bp.blogspot.com/-OsPxTxNufIo/WML7wW9HNFI/AAAAAAAAAoU/y25HO_bBnt0hUx62h3592obLy-F4OBZHQCLcB/s1600/silla-glass.jpg"><img height="275" src="https://3.bp.blogspot.com/-OsPxTxNufIo/WML7wW9HNFI/AAAAAAAAAoU/y25HO_bBnt0hUx62h3592obLy-F4OBZHQCLcB/s400/silla-glass.jpg" width="400"></a></td></tr>
<tr><td><i>Early Byzantine glass and imitations recovered from late fifth- to early sixth-century Silla tombs in Korea. (Image via <a href="https://uk.pinterest.com/pin/563864815815307390/">Pinterest</a>)</i></td></tr>
</tbody></table>
<br>
<table><tbody>
<tr><td><a href="https://3.bp.blogspot.com/-PJVvgG1rBY8/WMMLhJzytwI/AAAAAAAAAok/qOcY75S1gi0YCzIs9IoQ0lbZlRcAvNExwCLcB/s1600/AN00123869_001_l.jpg"><img height="265" src="https://3.bp.blogspot.com/-PJVvgG1rBY8/WMMLhJzytwI/AAAAAAAAAok/qOcY75S1gi0YCzIs9IoQ0lbZlRcAvNExwCLcB/s400/AN00123869_001_l.jpg" width="400"></a></td></tr>
<tr><td><i>A gold imitation of a sixth-century Byzantine coin …</i></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html">https://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html</a></em></p>]]>
            </description>
            <link>https://www.caitlingreen.org/2017/03/a-very-long-way-from-home.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310569</guid>
            <pubDate>Tue, 02 Mar 2021 00:51:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIA’s Plot to Have Climbers Plant Nuclear-Powered Sensors in the Himalayas]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310527">thread link</a>) | @vinnyglennon
<br/>
March 1, 2021 | https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/ | <a href="https://web.archive.org/web/*/https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div id="pico"><p>The year is 1964. The United States and the Soviet Union have narrowly avoided full-scale nuclear destruction and resolved the Cuban Missile Crisis, the Vietnam War looms on the horizon, and Mao Zedong’s China—fresh off a split with the Soviets—has just successfully blown up its first atomic bomb in a dry lakebed in southeastern Xinjiang, near what is now the <a href="https://www.wildcamels.com/what-we-do/lop-nur-nature-reserve/" target="_blank" rel="noreferrer noopener">world’s largest reserve for Bactrian camels</a>. </p><p>China’s nuclear test announced the country as the world’s fifth nuclear-armed nation, though unlike France, the USSR, and the United Kingdom, the Chinese nuclear program was a black box for American intelligence. <a href="http://www2.gwu.edu/~nsarchiv/nukevault/ebb488/docs/Doc%2028%2011-2-64%20inr%20on%20chinese%20test.pdf" target="_blank" rel="noreferrer noopener">Recently declassified government files show</a>, for example, that the U.S. was shocked to learn that the bomb was fueled by uranium, not plutonium. Military-industrial honchos were left scratching their heads as to how to gather intelligence, until a chance meeting between General Curtis LeMay and mountaineer Barry Bishop at a Washington D.C. cocktail party led to one of the most quixotic, unsuccessful operations in the CIA’s long history of screwups.</p><figure><img loading="lazy" width="792" height="612" src="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg" alt="" srcset="https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg 792w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=300,232 300w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=768,593 768w, https://admin.defector.com/wp-content/uploads/sites/28/2021/02/china-debris.jpg?resize=62,48 62w" sizes="(max-width: 792px) 100vw, 792px"><figcaption><a href="https://nsarchive2.gwu.edu/nukevault/ebb488/docs/doc%2033%201-0-65%20circa%20AFtAC%20report.pdf" target="_blank" rel="noreferrer noopener">An Air Force analysis</a> of nuclear debris scatter, which confirmed the use of enriched uranium. The lower of the two large arrows flows from the Xinjiang test site.</figcaption></figure><p>Bishop was part of the first American team to summit Mt. Everest the year prior, and according to <a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">Pete Takeda’s fascinating 2007 <em>Rock And Ice</em> story</a>, he gushed about the unobstructed views he enjoyed from the world’s (<a href="https://defector.com/a-geologist-rocks-my-world-on-why-earths-tallest-mountain-isnt-so-obvious/" target="_blank" rel="noreferrer noopener">arguably</a>) tallest mountain. Takeda writes that LeMay put the pieces together and, “From this casual exchange emerged an unlikely inspiration: Recruit America’s best high-altitude climbers to place a nuclear powered observation device atop the world’s greatest mountain range.” The hope was that a transceiver could pick up radio communications between Chinese nuclear personnel, remaining functional for years off of the heat from decaying plutonium isotopes. Per Takeda, the CIA’s device was an “oven-sized metal bin with five radiating fins” that weighed 125 pounds and was topped by a six-foot long antenna. If this sounds like a crude product of ’60s nuclear frenzy, consider that <a href="https://mars.nasa.gov/mars2020/spacecraft/rover/electrical-power/" target="_blank" rel="noreferrer noopener">NASA’s Perseverance rover</a> is scooting around on Mars thanks to this exact sort of battery. </p><p>Bishop could no longer climb high alpine peaks after <a href="https://www.nationalgeographic.com/magazine/article/first-successful-us-everest-summit-took-a-toll-on-barry-bishops-boots" target="_blank" rel="noreferrer noopener">losing all of his toes in the Everest expedition</a>, but by 1965, the CIA started putting together a team, picked a name (Operation Hat), and chose a mountain. Everest straddled China’s border, so it was out of contention. CIA officials eventually chose Nanda Devi, the tallest peak entirely within India’s borders. Nanda Devi offered two advantages to the Americans: long sightlines into Western China and the help of an Indian state that the U.S. had just supported in its 1962 border skirmish with China. </p><p>At this point in history, Nanda Devi had only been summited by six people, with three others dying in the process, so the CIA recruited a dream team of famous American climbers. The corps included pioneering El Capitan big-waller <a href="https://www.nytimes.com/2018/09/12/obituaries/tom-frost-dead.html" target="_blank" rel="noreferrer noopener">Tom Frost</a>, <a href="https://www.nytimes.com/1998/11/07/us/luther-jerstad-61-alpinist-who-scaled-everest-in-1963.html" target="_blank" rel="noreferrer noopener">1963 Everest</a> veteran Lute Jerstad, <em>Sports Illustrated</em> cover darling <a href="https://gripped.com/profiles/jim-mccarthy-was-first-climber-on-sports-illustrated/" target="_blank" rel="noreferrer noopener">Jim McCarthy</a>, and the unsung alpinist <a href="https://www.americanjournalofsurgery.com/article/S0002-9610(16)31088-1/pdf" target="_blank" rel="noreferrer noopener">Robert Schaller</a>. They <a href="https://wikileaks.org/plusd/cables/1978STATE094511_d.html" target="_blank" rel="noreferrer noopener">underwent a training course</a> on nuclear technology and “the Asian mentality” at a South Carolina military base, though the climbers say they mostly spent time “playing volleyball and doing some serious drinking.” <a href="https://wikileaks.org/plusd/cables/1978STATE094511_d.html" target="_blank" rel="noreferrer noopener">The full team undertook a training mission on Mount McKinley</a> in June with their Indian counterparts, and even though “distressing weather and other difficulties kept them from the summit,” the CIA “chose to ignore” the omens and the American-Indian team set out for Nanda Devi in October 1965. </p><p>The CIA has not yet declassified files from the expedition, including apparently extensive photographs and journal records made by Schaller, so we do not have a detailed account of what happened on the mountain. But we do know how the mission ended: catastrophic failure. A storm pinned several climbers and the device down while they were roughly 1,800 feet from the summit. Indian intelligence lead Capt. M.S. Kohli was forced to call a retreat, and the team stashed the device in a crevice and attempted to anchor it in place, so it would stay put until they could come and retrieve it on the other side of winter.</p><p>McCarthy spoke at length with Takeda <a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">for the <em>Rock And Ice</em> story</a>—which really is great, Takeda makes his own attempt on Nanda Devi and narrowly escapes death by avalanche—and he recalled his fury at the expedition’s failure:</p><blockquote><p>When I realize that they’re dumping the fucking generator and going down the mountain, I’m like, ‘What the fuck are you doing? Have them bring it down! Are you crazy?’ I’m yelling at the top of my lungs.” According to McCarthy, the CIA case officer nearly had to pull him off Kohli. “He says to me,” McCarthy says, ‘You are creating an international incident!’”</p><p>“But,” McCarthy adds, “I had a vision of absolute clarity. We’re going to lose a SNAP generator, powered by plutonium, in the headwaters of the Ganges!”</p><cite><a href="https://rockandice.com/snowball/the-secret-of-nanda-devi/?cn-reloaded=1" target="_blank" rel="noreferrer noopener">Rock And Ice</a></cite></blockquote><p>That might be what wound up happening. Nobody knows where the device ended up, since it disappeared from Nanda Devi at some point in the winter. The CIA ran a total of eight field operations in the region between 1965 and 1968, aimed at both finding the first device and getting another one up and running. Though they eventually implanted a plutonium device on nearby Nanda Kot, they have never been able to find their lost transceiver. The successfully placed device was also quickly buried under the snow and stopped working months later, after producing no useful intelligence.</p><p>The grim failure of Operation Hat resurfaced this month after violent floods killed over 50 people in the Indian state of Uttarakhand. The floods <a href="https://www.nytimes.com/2021/02/07/world/asia/india-glacier-flood-uttarakhand.html" target="_blank" rel="noreferrer noopener">most likely began</a> when a chunk of the Nanda Devi glacier broke off and trapped flowing water, forming a lake that eventually burst through and swept through nearby valleys. The undeniable oddness of a glacial breaking apart during the winter has <a href="https://www.bbc.com/news/world-asia-india-56102459" target="_blank" rel="noreferrer noopener">led some locals to speculate</a> that perhaps the plutonium generator, which is still likely producing heat, led to the deadly floods.</p><p>There’s no evidence for the hypothesis, though even after years of reconnaissance missions and rigorous chemical assays of the surrounding area, nobody knows where the CIA’s lost nuclear-powered spy oven is. </p></div></div></div></div></div>]]>
            </description>
            <link>https://defector.com/cia-climbers-cold-war-nanda-devi-nuclear-device/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310527</guid>
            <pubDate>Tue, 02 Mar 2021 00:44:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. asks Google for detailed search data in antitrust case]]>
            </title>
            <description>
<![CDATA[
Score 185 | Comments 83 (<a href="https://news.ycombinator.com/item?id=26310292">thread link</a>) | @johncena33
<br/>
March 1, 2021 | https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The U.S. government has asked Google to fork over granular data on how its search engine works and is monetized, seeking to prove that the internet giant is a monopoly.</p>

<p>The U.S. Department of Justice and several state attorneys general are seeking comparable data on U.S. search results and related ad from Feb. 2, 2015 to Feb. 8, 2015 and from Feb. 3, 2020 to Feb. 9, 2020, according to a legal filing Monday.</p>

<p>The Alphabet Inc. unit is being asked to share data on how and where users searched in those periods, the quantity of different types of ads, revenue from those ads and what the underlying bids were for them, among other details. The government told the company it wants the information within 30 days.</p>

<p>The Justice Department under former U.S. President Donald Trump and 11 Republican attorneys general originally filed the suit. Three other states have since joined, including California, the site of Googleâ€™s headquarters. The latest data request shows the government is pressing ahead under a new administration led by Democrat Joe Biden.</p>

<p>The U.S. government alleges Googleâ€™s exclusive deals to distribute its search engine on browsers and phones, including Apple Inc.â€™s iPhones, violates the Sherman Actâ€™s prohibition on monopolization. Itâ€™s the most significant U.S. monopoly case since the one against Microsoft Corp. more than 20 years ago.</p>

<p>Google has said its deals donâ€™t prevent consumers from switching to other search providers. The company argues its success rests on superior technology.</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/u-s-asks-google-for-detailed-search-data-in-antitrust-case-1.1570497</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310292</guid>
            <pubDate>Tue, 02 Mar 2021 00:10:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MySQL from Below]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310208">thread link</a>) | @nreece
<br/>
March 1, 2021 | https://blog.koehntopp.info/2021/02/25/mysql-from-below.html | <a href="https://web.archive.org/web/*/https://blog.koehntopp.info/2021/02/25/mysql-from-below.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>When you insert data into a database and run COMMIT you expect things to be there: <a href="https://en.wikipedia.org/wiki/ACID">Atomically, Consistent, Isolated and Durable</a>, like Codd commanded us 40 years ago, but also quickly. There is a surprising amount of sophistication being poured into this, but since I do not want to shame MongoDB and Redis developers in this post, I am not going to talk about that much in this place.</p>

<p>We are instead trying to understand what our databases are doing all day, from the point of view of the storage stack.</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/linux_observability_tools.png" alt=""></p>

<p><em>That Brendan Gregg Graphics</em></p>

<p>Here is your performance tooling (sans EBPF) as shown by Brendan Gregg in various iterations. We are interested into the various blues in this graphic, VFS and downwards. The most detailed information of what goes on in the blue stack is given by blktrace. It’s an I/O request recorder.</p>

<p>Unfortunately, blktrace tooling sucks big time. You have the choice between blkparse, iowatcher and seekwatcher, and they either give you unappealing and hard to read ASCII dumps, or are hard to use and abandoned to boot. A colleague threw <a href="https://www.oakgatetech.com/applications/analytics">Workload Analytics</a> around. And with that you can actually see what goes on.</p>

<p>So, let’s have a look.</p>



<p>When you go to our Grafana, and ask nicely, you can basically divide our databases into three load classes: “200 commit/s”, “2000 commit/s”, and “20.000 commit/s”, so “low write load”, “busy write load” and “should be thinking about what they are doing really soon” write load.</p>

<p>I am using representatives from every workload class to point out a few things.</p>

<h2 id="but-what-about-reads">But what about Reads?</h2>

<p>Amazingly, at work we do not really care much about disk reads from databases.</p>

<p>We build our databases, especially customer facing databases, in a way that we try to hold the working set of the database in memory.</p>

<p>The “working set” of anything is the set of things that you will be needing in the near future. Unfortunately, predicting the future is hard, so what we define as the working set instead is “the set of things that we have most recently used and are therefore hoping to use in the near future again”, which works reasonably well until there is a change in workload pattern.</p>

<p>In our databases, the “anything” that matters is a 16 KB database page as it resides in the InnoDB Buffer Pool. So what we do is simple: We spend money on memory, warm up the InnoDB Buffer Pool and then serve data from memory.
We can prove that works: InnoDB can do point reads from memory at memcache speeds, which is why we don’t use much of memcache and Redis in the first place – they don’t help.</p>

<p>We can also capacity test our databases, and we will find that as we increase the load the number of disk reads does not go up. Data is served from memory, and not from disk.</p>

<p>So what we care about is disk writes. They are the same on every instance of a replication chain, because of the shared nothing architecture of replication: Each chain member must apply the same set of changes from the primary down to all leaf replicas.</p>

<h2 id="the-write-model">The Write Model</h2>

<p>On Commit, we write out 1 KB (or more) of Redo Log. The write happens with <code>O_DIRECT</code> to XFS, and there is a lot of thought that goes into these few words.</p>

<p>Because it is <code>O_DIRECT</code>, the write already writes to disk. There is no need to <code>fsync()</code> or <code>fdatasync()</code> or anything else.</p>

<p><code>O_DIRECT</code> writes also bypass the file system buffer cache, which is good, because then there is less memory pressure and less risk of paging out the database server. Usually when that happens (memory pressure forces paging on mysqld), you die a horrible and hard to debug death in latency problems and SLO violations.</p>

<p>We use XFS. XFS on the average takes twice as long as ext4 to write data to disk, but XFS always takes the same amount of time to write data – it has been specifically designed in a way that there is very low jitter. ext4, on the other hand, is known to have downspikes and large commit wait times every few seconds, and that is really, really bad when you run at 10.000 queries/s.</p>

<p>XFS also is capable of having multiple concurrent writers on a file when the file is open with O_DIRECT. Unlike all other Linux File Systems, <a href="https://blog.koehntopp.info/2018/11/29/but-is-it-atomic.html">it does not lock the file’s in-memory inode globally</a> to guarantee atomic writes in this case. Such a feature is very dear to database people.</p>

<p>The Commit is what users have to wait for. When it is done, the database can do the real data write later, often much later, and in the background. So what we really care for is the actual commit latency.</p>

<p>The real write happens later, in the Checkpoint. <a href="https://blog.koehntopp.info/2020/07/27/mysql-transactions.html">What happens is complicated enough to justify a writeup of its own</a>. But, to make it short, we write data to the Doublewrite Buffer in a few very large linear writes as protection against torn pages, and then we writev() a scatter I/O of 16K pages to update in place.</p>

<p>This is different from Postgres, and enables us to avoid costly vacuum runs. We make an assumption here, and that is: Rollbacks are rare (and expensive in MySQL).</p>

<h2 id="the-test-write-model">The Test Write Model</h2>

<p>All that complexity is basically nonsense for benchmarking.</p>

<p>If you want to know if a thing can run MySQL, and how well, you simply randwrite 16KB pages in <code>O_DIRECT</code> and see what happens. That’s a gross simplification compared to above, but holds up surprisingly well as a model for predicting MySQL speed and capacity.</p>



<p>In order to see what real databases do to their disks, I went to the chosen representative for the 200-class and <code>blktrace</code>’ed it.</p>

<p>It turns out that you can’t <code>blktrace</code> a single disk database machine, because the disk writes from the <code>blktrace</code> will mess up the metrics from the database. It also turns out that <code>systemd</code> mounts a 12GB ramdisk as <code>/run/user/&lt;uid&gt;</code> that can hold a 10 minute <code>blktrace</code> with no problems.</p>

<p>When we feed that trace to Workload Intelligence, we get this:</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/class-200-iops.png" alt=""></p>

<p><em>The low red line is the 200 IOPS baseline load. Turns out, there are spikes, up and past 2000 IOPS.</em></p>

<p>The first thing we learn: Kris is right. There are no reads.</p>

<p>The second thing we learn: 200 IO Operations per Second it may be, but there are spikes, up to and past 2000 IOPS even. They are not long, but they happen often enough.</p>

<p>So how long does it take to write to disk? Well, there is no disk. There is Flash Storage, and it does not even have a disk interface any more – it sits directly on the PCI bus. A Flash drive that is directly on the PCI bus is called NVME instead of SSD (it is otherwise the same drive).</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/class-200-latency.png" alt=""></p>

<p><em>Most of the time there is very little wait.</em></p>

<p>Flash is not fast, but NVME is: The drive not only has flash, it also has (large capacitor buffered) non-volatile memory it uses to buffer write and rearrange things in the background. It also has its own ARM processor with its own operating system.</p>

<p>Sometimes we have to wait a bit, but most of the time it’s really, really fast. How fast? We need to go deeper:</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/class-200-latency-detail.png" alt=""></p>

<p><em>30µs or 0.03ms is the time it takes to write to memory over the PCI bus.</em></p>

<p>When we talk to the remote NVRAM on the other side of the PCI bus, it takes 30µs, or 0.03ms. As long as we do not overwhelm the NVRAM buffers of the drive, we have a 30µs commit latency on local memory.</p>

<p>Another number, which will come in handy later, is the time to cross our entire network stack within the same data center: That’s around 6 switches and routers, and it will add another 60µs to any round trip across the network in the best of all cases. So a remote flash drive never can be faster than around 100µs or 0.1ms.</p>

<p>Where do the writes go? We can plot the Linear Block Addresses and see:</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/class-200-lba.png" alt=""></p>

<p><em>LBA over time. See the position of the log files, and the checkpoints.</em></p>

<p>When you plot “addresses written to over time”, you will see that there is a bunch of blocks that get written to again and again. These are the various logs and write buffers the database uses.</p>

<p>The drive internally has a flash translation layer (FTL), which makes sure that these block rewrites are actually distributed across all the positions in the flash you have. This kind of Wear Leveling makes sure the drive actually can live 7-10 years before the flash wears out.</p>

<p>The SD card or USB memory stick you are using in your local Raspi does not have that, and neither has the on board flash in the entertainment module of your Tesla. That is why they fail rapidly as actual fixed blocks of flash are being rewritten a few thousand times. Use a proper drive with a proper FTL and that does not happen.</p>

<p>In the graphics above you can also see the checkpoints scatter writes happen, and you can see how they are spaced apart widely, many tens of thousands of transactions. Checkpointing allows the database to aggregate changes in in-memory pages (and the log, for persistence). All that complexity is actually saving you disk writes!</p>

<p>Flash does not have a single write head as disk drives do. They are not forced to do things sequentially, but in fact all the various chips in your drive can do things concurrently. Deep disk write queues are necessary to keep all these channels fed for NVME, while they are poison of SSD and HDD.</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/class-200-qdepth.png" alt=""></p>

<p><em>Queue Depth over time</em></p>

<p>A low concurrency hierarchy such as this one is not even touching the true write potential of a single NVME: A single drive can do 20.000 disk writes per second, sequentially in a single thread, if you are pushing really hard, but it can do 800.000 disk writes per second if you are feeding it with sufficient concurrency.</p>

<p>These are two other important numbers to keep in mind. They are the reason why “IOPS Quotas” should be a thing of the past – it is impossible for any reasonable workload to actually exhaust a single NVME drive, and distributed storages usually have hundreds of them.</p>

<p>Let’s have a look at the latency diagram from above, again, and check the distribution of completion times in a Latency Histogram. It tells us how prevalent slow writes are over the observation window:</p>

<p><img src="https://blog.koehntopp.info/uploads/2021/02/class-200-latency-histo.png" alt=""></p>

<p><em>It’s called Flash for a reason.</em></p>

<p>So even with these curtains in the latency over time diagram, we can see that 90% of all writes happen in the 30µs window, and there are …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.koehntopp.info/2021/02/25/mysql-from-below.html">https://blog.koehntopp.info/2021/02/25/mysql-from-below.html</a></em></p>]]>
            </description>
            <link>https://blog.koehntopp.info/2021/02/25/mysql-from-below.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310208</guid>
            <pubDate>Mon, 01 Mar 2021 23:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Fully Weaponized Spectre Exploit Discovered Online]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26310187">thread link</a>) | @arkadiyt
<br/>
March 1, 2021 | https://therecord.media/first-fully-weaponized-spectre-exploit-discovered-online/ | <a href="https://web.archive.org/web/*/https://therecord.media/first-fully-weaponized-spectre-exploit-discovered-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                    
<p>A fully weaponized exploit for the Spectre CPU vulnerability was uploaded on the malware-scanning website VirusTotal last month, marking the first time a working exploit capable of doing actual damage has entered the public domain.</p>



<p>The exploit was discovered by French security researcher Julien Voisin. It targets Spectre, a major vulnerability that was disclosed in January 2018.</p>



<p>According to its website, the <a href="https://spectreattack.com/">Spectre</a> bug is a hardware design flaw in the architectures of Intel, AMD, and ARM processors that allows code running inside bad apps to break the isolation between different applications at the CPU level and then steal sensitive data from other apps running on the same system.</p>



<p>The vulnerability, which <a href="https://pwnies.com/archive/2018/winners/">won a Pwnie Award in 2018</a> for one of the best security bug discoveries of the year, was considered a milestone moment in the evolution and history of the modern CPU.</p>



<p>Its discovery, along with the <a href="https://meltdownattack.com/">Meltdown</a> bug, effectively forced CPU vendors to rethink their approach to designing processors, making it clear that they cannot focus on performance alone, to the detriment of data security.</p>



<p>Software patches were released at the time, but the Meltdown and Spectre disclosures forced Intel to rethink its entire approach to CPU designs going forward.</p>



<h2><strong>Initial Spectre PoCs were all benign</strong></h2>



<p>At the time, the teams behind the Meltdown and Spectre bugs published their work in the form of research papers and some trivial proof-of-concept code to prove their attacks.</p>



<p>Shortly after the Meltdown and Spectre publications, experts at <a href="https://plus.google.com/photos/photo/100383867141221115206/6517535568830348546">AV-TEST</a>, <a href="https://blog.fortinet.com/2018/01/30/the-exponential-growth-of-detected-malware-targeted-at-meltdown-and-spectre">Fortinet</a>, and <a href="https://www.bleepingcomputer.com/news/security/we-may-soon-see-malware-leveraging-the-meltdown-and-spectre-vulnerabilities/">Minerva Labs</a> spotted a spike in VirusTotal uploads for both CPU bugs.</p>



<p>While initially there was a fear that malware authors might be experimenting with the two bugs as a way to steal data from targeted systems, the exploits were classified as harmless variations of the public PoC code published by the Meltdown and Spectre researchers and <a href="https://www.virusbulletin.com/blog/2018/02/there-no-evidence-wild-malware-using-meltdown-or-spectre/">no evidence was found of in-the-wild attacks</a>.</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Meltdown and Spectre always seemed vulnerabilities where for most people and orgs the cure was going to be worse than the disease. <a href="https://t.co/aPOvGD2GSF">https://t.co/aPOvGD2GSF</a></p>— Martijn Grooten (@martijn_grooten) <a href="https://twitter.com/martijn_grooten/status/979076447456432128?ref_src=twsrc%5Etfw">March 28, 2018</a></blockquote>
</div></figure>



<p>But today, <a href="https://dustri.org/b/spectre-exploits-in-the-wild.html">Voisin said</a> he discovered new Spectre exploits—one for <a href="https://www.virustotal.com/gui/file/ecc0f2aa29b102bf8d67b7d7173e8698c0341ddfdf9757be17595460fbf1791a/details">Windows</a> and one for <a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c/details">Linux</a>—different from the ones before. In particular, Voisin said he found a Linux Spectre exploit capable of dumping the contents of <strong><em>/etc/shadow</em></strong>, a Linux file that stores details on OS user accounts.</p>



<p>Such behavior is clearly malicious; however, there is no evidence that the exploit was used in the wild, as it could have also been uploaded on VirusTotal by a penetration tester as well.</p>



<h2><strong>Exploits linked to Immunity’s CANVAS tool</strong></h2>



<p>But the most interesting part of Voisin’s discovery is in the last paragraph of his blog, where he hints that he may have discovered who may be behind this new Spectre exploit.</p>



<p>“Attribution is trivial and left as an exercise to the reader,” the French security researcher said in a mysterious ending.</p>



<p>But while Voisin did not want to name the exploit author, several people were not as shy. Security experts on both Twitter and news aggregation service HackerNews were quick to spot that the new Spectre exploit might be a module for CANVAS, a penetration testing tool developed by Immunity Inc.</p>



<p>“If you are a paid subscriber, you get extra bits [of information] from VirusTotal. One of which is you can see what files are ‘parents’ of the sample,” <a href="https://news.ycombinator.com/item?id=26302565">said a HackerNews user today</a>.</p>



<p>“In this case, there are a bunch of zip files that contain this file, all named Immunity Canvas or similar. Canvas is a pentesting tool where they publish exploits, so I guess he’s saying you can attribute it to Immunity.”</p>



<p>An Immunity spokesperson did not return a request for comment from <em>The Record</em> before this article’s publication to confirm that the Spectre exploits uploaded on VirusTotal last month are indeed Canvas modules.</p>



<p>However, in a tweet today from Dave Aitel, the former Immunity CEO appears to confirm that Voisin’s discovery is indeed the CANVAS Spectre module that his former company was touting back in February 2018.</p>



<figure></figure>



<figure></figure>



<p>Furthermore, shortly after this this article went live, a source in the cybersecurity community who did not want to be named effectively confirmed our report by pointing <em>The Record</em> to a post on an underground hacking forum where a threat actor had published a cracked version of the Immunity CANVAS v7.26 pen-testing tool, along with cracked copies of White Phosphorus and D2, two CANVAS expansion packs that contained two different sets of exploits for various vulnerabilities. Among the vulnerabilities there was also an exploit for CVE- 2017-5715, the vulnerability ID for the Spectre bug.</p>



<figure><img loading="lazy" width="1024" height="471" src="https://www-therecord.recfut.com/wp-content/uploads/2021/03/Screen-Shot-2021-03-01-at-6.25.36-PM-1-1024x471.png" alt="" srcset="https://therecord.media/wp-content/uploads/2021/03/Screen-Shot-2021-03-01-at-6.25.36-PM-1-1024x471.png 1024w, https://therecord.media/wp-content/uploads/2021/03/Screen-Shot-2021-03-01-at-6.25.36-PM-1-300x138.png 300w, https://therecord.media/wp-content/uploads/2021/03/Screen-Shot-2021-03-01-at-6.25.36-PM-1-768x353.png 768w, https://therecord.media/wp-content/uploads/2021/03/Screen-Shot-2021-03-01-at-6.25.36-PM-1-1536x706.png 1536w, https://therecord.media/wp-content/uploads/2021/03/Screen-Shot-2021-03-01-at-6.25.36-PM-1.png 1950w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Dmitry Smilyanets, cyber threat intelligence expert for Recorded Future, told <em>The Record</em> that cracked versions of this pen-testing toolkit have been shared in private Telegram channels for months, since at least October 2020, if not earlier.</p>



<figure><img loading="lazy" width="810" height="448" src="https://www-therecord.recfut.com/wp-content/uploads/2021/03/telegram-leak.png" alt="" srcset="https://therecord.media/wp-content/uploads/2021/03/telegram-leak.png 810w, https://therecord.media/wp-content/uploads/2021/03/telegram-leak-300x166.png 300w, https://therecord.media/wp-content/uploads/2021/03/telegram-leak-768x425.png 768w" sizes="(max-width: 810px) 100vw, 810px"></figure>



<p>These new revelations suggest that these cracked CANVAS versions are most likely the source of the CANVAS Spectre modules that were uploaded on VirusTotal on February 3.</p>



<p>The fact that Immunity had a fully working and fully weaponized Spectre exploit is not a surprise for industry experts, as Aitel’s company was also among the first to put together a fully weaponized exploit for the BlueKeep vulnerability <a href="https://www.zdnet.com/article/us-company-selling-weaponized-bluekeep-exploit/">back in 2019</a>, which it publicly advertised at the time, as a way to boast CANVAS’ superior penetration-testing features.</p>



<h2><strong>Last “patch now” warning!</strong></h2>



<p>Copies of this Spectre exploit are now making the rounds in Discord and Telegram channels run by security researchers, and it’s only a matter of time until they hit GitHub and become broadly available to everyone, including malware authors.</p>



<p>If the exploit code can be weaponized as part of an actual attack still remains to be seen as this is no run-of-the-mill vulnerability, but ready-made exploits that enter the public domain are often abused as it’s easier for threat actors to adapt code written by someone else than write their own from scratch.</p>



<p>Voisin’s discovery is about as close the Spectre doomsday clock can tick close to midnight before attacks get underway, if they haven’t already.</p>
                </article></div>]]>
            </description>
            <link>https://therecord.media/first-fully-weaponized-spectre-exploit-discovered-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26310187</guid>
            <pubDate>Mon, 01 Mar 2021 23:57:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Are So Many Successful CEOs Software Engineers?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309977">thread link</a>) | @LegitGandalf
<br/>
March 1, 2021 | https://iism.org/article/why-are-so-many-successful-ceos-software-engineers-62 | <a href="https://web.archive.org/web/*/https://iism.org/article/why-are-so-many-successful-ceos-software-engineers-62">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iism.org/article/why-are-so-many-successful-ceos-software-engineers-62</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309977</guid>
            <pubDate>Mon, 01 Mar 2021 23:31:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CBT for Insomnia: A Comprehensive Guide]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309815">thread link</a>) | @rahulshiv
<br/>
March 1, 2021 | https://www.sleepedy.com/cbt-for-insomnia/ | <a href="https://web.archive.org/web/*/https://www.sleepedy.com/cbt-for-insomnia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>For years, Cognitive Behavioral Therapy (CBT) has been the gold standard for treating insomnia. CBT techniques for insomnia have been proven to work in numerous clinical trials and are more effective than medication.</p><p>The American Academy for Sleep Medicine, the American College of Physicians, and the European Sleep Research Society all recommend CBT for insomnia (CBT-I) as first-line treatment.</p></div><div><p>
This guide takes about 15-20 minutes to read. Here's a quick overview so you can decide if reading the full guide is worth your time.
  </p><!----></div><h2 id="what-is-cbt">What is CBT?</h2><p>CBT is a form of therapy that was initially developed as a treatment for depression. The Cognitive in CBT refers to mental activity, such as thoughts, beliefs, memories, images or values. The behavioral part includes all the things we do on a daily basis. This can be things you do with others or things you do alone.</p><p>CBT saw it's beginning when the American psychiatrist Aaron T. Beck (and others) noticed a pattern of thinking that was common for many clients with depression. Not very impressed with the result of traditional therapies, they wanted to address these issues with a more straightforward and direct approach. And so Cognitive Behavioral Therapy was born.</p><h3 id="cognitions-thoughts">Cognitions (thoughts)</h3><p>A core principle in CBT is that our emotional reactions and behaviors are influenced by how we think about ourselves, others, and the world around us. Humans have a great capacity for thinking, but that requires time and energy. Most of the time, we take mental shortcuts and react to events that happen without giving them much thought. These shortcuts, or cognitive biases, often lead us to interpret and process information inaccurately.</p><p>If you ask two people to give a presentation on something they are both knowledgeable about, you might get two different reactions. One is hesitant and suggests someone else. The other immediately and enthusiastically agrees. It's the exact same situation. So why do they react so differently?</p><p>CBT explains that this difference in emotional reactions and behaviors comes from different ways of thinking about the situation. One thinks he might start to shake and others will notice. The other one thinks that this is a good opportunity to share his knowledge.</p><p>The common-sense model</p><p><img src="https://www.sleepedy.com/assets/static/model_situation_emotion.a05844e.25c1b7895053af109d8796a6365f759f.svg" width="473" alt="Situation leads to emotion" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 473 69' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-577ab4bd82e2546c7e456c9eec27b8a9'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-577ab4bd82e2546c7e456c9eec27b8a9)' width='473' height='69' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAYAAACCPip6AAAACXBIWXMAAAsTAAALEwEAmpwYAAADrUlEQVRIx51WWU9TURAu0N9AfDfxH/jqIzRB04VuLAXS3haRCqjgwloIlC0uLBElASWAILQUFFliotE3FJXYlhbQaASffNH4QFjaceb03tvLbSHgTSbfmTnbzHfmzLkKLuhZK16fBi7ojWA7al/1YtsDAkrbyfrkdkH4tfZLvr%2bg9iUFfohphBkZGUz4dioJtTMzM2lMKj/2LPmGa/gRA4jHEhorjD9sHtr9iGHENwoKHpXEwAOT8SADngMBH2pLJGmvdHOBsJOCKno9oMQg0wTBwJUK/kNdiXqKY32akcStevLKf70Ce2gKijdmDgr6nGA7Tp9MLn59Dgo7njx/akRClDkfngLHlxmG9jUfODam46eLDpE4cAF7KK6zsYiS4Gk9JGCedDcFBQAK%2bYeBV2DgZwTdujTCSME5BprLrXp37EEP%2bUgZyhD3juB%2bvPiYDfdmOusL8TpvI%2bRkazAMevYVQtpLg7e%2bHwVDbx3kP%2buB/JlusMz3AefHjPg8AbaPY2BdfsL6Chb6WNu28hRsH8ZYn4QEkQDU2yioLIspHQMuJMGgCXMR/6DsoLhQThVvzqXxV8Do3FqkdXY5wTcknHww9NZDvq8LbJ/Gwbo0zLI15tcoWGZ7wTJ3/yi/kFTxqkcVsnsLmIJQ9PYRaOovg6G7FrRNFaCpdYKpvxGMD1yga6sETU0paBvKQH/nFujc1yC7vQq0jeWQ3XGdXQ15BnD%2biQ4KSqU%2bf06j0QCJWq1miCREVCoVaLVaQAKWswrN6YyAwKRJIEC8VmEfWN%2bNwIUrHOSOd%2bKeMd%2bYD7i3ruUqaF3loL99U7RpXWXMPww6aa1KIEDIAFpEf68azENuMA%2b2sDbZsjtvMGLMg81getgIhp46MHTVQM5wGxPbynjspKQECBlQwDIgDwPN49GI%2bBtxG6UWJb0KNlPlGSD6hqdI6%2btaK8E00Azmx27IGW3Hw2kC/d1q0UYHZeipZX6ST%2bahVpYNvF8HCeAdjfJpERV1RMyGKNaAKG4cE2qHeQx543pY0idZgxHwI14Dkn1IgBMDPy3omH1CDTCWbi3Q3D1OVqRZOlOmYX1i9YpqFNUj0kNTol2oYZQ5suIcvwIOGiRhJF7svMntJxDcYJ%2bCQGynoApf9tMroOQrPr0E4itALwK9AvZ1H6sBWKBMzp%2bLNHf3qKf5JJKMBMqAv/Re05MlCGNdop9UhPmI2yXfZmmzBvl/AL35kv%2bAFMl/gFAE9WIGoLP/G3QyAiQZEPkHBM14KrRQEhsAAAAASUVORK5CYII=' /%3e%3c/svg%3e"></p><p>The cognitive model</p><p><img src="https://www.sleepedy.com/assets/static/model_situation_thought_emotion.e4ad7cc.294c7369e1e2d3479ebae5203785d821.svg" width="758" alt="Situation leads to cognitions (negative thoughts) leads to emotion" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 758 69' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a0dae8d490a9960785daa502d0bd80b7'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a0dae8d490a9960785daa502d0bd80b7)' width='758' height='69' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAGCAYAAABzaJivAAAACXBIWXMAAAsTAAALEwEAmpwYAAADgklEQVQ4y41UW0iUURD%2bo6wI6imI3ioiiiyKXoveXNfooXTXrU3N3F0vmARBhXZPk8zUTHMrKysqbXfdtbQbiT10ewkl73Y3lQh6EHoo8z/TN7Nnt82nfhhm/nPmzMz5zjdjuPubyd0XUK5eP0WlZ4qOsbXvZO7HVnL1BTIMfA7vsTiLxTLD0N%2bWonyx4bsYvl8gY7BHPUMhEfz/lR7/KO%2b5%2bwOi9foI7DHoYeh4jrX1cEFcQkJCNIet/MBM1vBJgoxr35i4Pi3%2bGNFrvZITOfxfjcjlUQAJGANB8rwNEQolz7sWcg8Gw/b7u7IOX4Uzk3mf77O924j5AMIiFLk28u/q9q3K/XCPPBwTcXa9uEa7Xt2g7LctlI14IrzPeXsDDC7W/vpnI6%2br%2b86G2ByIvzAWCNSws%2bBbuzyMnOHY7%2b5SzqfWsOChOAcL27zmGQxJfM5jyOWHgiqjo55sZ4vIcbWEnL4KSn/spe1N5eS4UkzOQKVIWmsNAGoWBjAAng/33HMNY7bFmtiBotoAQJ/VaiVLYmIDapuO/eWcCP4mwDW33SpTtuoihTzKfv6ISq0/oewXjqnksn0quXy/SqkqlDXxx4UYkLzxp2vWL1i6BDnqEb8EeTohA4mbNzk0AGn5I4%2bYob/wQCr9kVelXi5WaW21CvWq9Id1ivPuCJ5VaQ/qZA0sUPrhlSHJBoPmzmcNJooyHddKTRRl2moPmymVhSYAMe3eo7K3/fZpuQjOTOR9agMjWjyoYZolyXoKRRWhwBD0MIotkBYYCq2QV2TWALhMvD4KEiBREDmbq8hWc4iQjzKeXKQdoWqRyOWZGfk/n6/euDg%2bHjHbEf8mx4f8sGxK2hMFYFQAmBAAEB%2b1Uuql42SrPki2cwfJXndEND%2bw/cJRyupsZMYL843soZYwbSLUYbpoerKdA0rmROjDe9wOoE7%2b2GO%2b2J4pLTAHxc2L0rPHF89xBeSBoMp8eZ0cDSfBpiqtK8lxvRRMO0NOf6UAwhcHyPI63JJoo6ktsBIyP6YFMnQtE3IWreR6c0daGaBH4mkdkJbWs0yANtwYUjA%2b8xD5H4Ev64%2bQ77CFhikle2fi8nHRIbg/V2wMyWV6ZoSHZ7ePsrqa5AUynzeIzcXKWlcjZb2%2bxReOMoBbDXqdzvHPELRXFM7SOWx5w/f5zO9orv5AdHhLnHB%2b0jEjWnkA0B88OW688/hLQQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e"></p><p>CBT proposes that it’s not the <strong>situation</strong> that makes us feel something, but the <strong>thoughts</strong> about that situation.</p><h3 id="behavior">Behavior</h3><p>Changing what you do is often the most powerful way of changing how you think and feel about something. The behavioral part in CBT is about testing new behaviors and learning what happens when you gain new experiences.</p><p>If you always avoid giving presentations, you will never experience a successful one. Your negative thoughts about yourself in that situation will never change. A common unhelpful belief that people have when speaking to a crowd is that they will get anxious, start to shake, and the audience will see that as a sign of weakness.</p><p>To target the cognition that shaking is a sign of weakness, CBT uses something called a behavioral experiment. In these kinds of experiments, the goal is to get real experiences about what happens if you shake and if it's true that other people will react negatively to this. A typical behavioral experiment might be to videotape yourself talking in front of a crowd. When viewing the video afterward, try to notice the level of shaking and what reaction the group had to this. Most likely, you will see that your shaking was barely noticeable, and those who were listening didn't react at all.</p><h3 id="the-cbt-triangle-putting-it-all-together">The CBT triangle (putting it all together)</h3><p>Therapy involves changing how you feel about something. Whether it is to achieve a goal or to stop being anxious or sad — it's all about changing emotions. Now, this is hard to do directly. We have little control over our emotions; they will pop up whether you like it or not. CBT aims to change how you feel about something through our thoughts (cognitions) and behaviors.</p><p><img src="https://www.sleepedy.com/assets/static/model_thought_emotion_behavior.485f804.33e4fd7021857337e42b912f76ac6948.svg" width="393" alt="The CBT triangle" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 393 174' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-56af8b61d402fee5a6a492789169c2bc'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-56af8b61d402fee5a6a492789169c2bc)' width='393' height='174' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAcCAYAAADRJblSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAIKUlEQVRYw9VXaWxU1xWexUZq0lZK%2b6uVmkhVW1WRWirxI1IrUTnCS0BgG2NsbIIxxjMmIgkRBBG2GBfbwcHYmYK8ZOI1tgOeGS9Ak0CqKjUJFdgGL%2bPdcZriJlEbVXEVRQ2ed/qdM/eOn4dxColN6Eif7rn3vnuW755z3huL5Wv%2bent7LdeuXbMpee/o6ChhPgvZwEiLAaVrlnVDPsC22Cbb/sZ/YQS4JyYm2MmbynEJoKenR8DzcCy0rs%2baxptKd8M9RQAc4cBtSq4YHx9nh2/qDOAABgYGBNevX6e%2bvj4JSMt6naHXTTdvzoCbSrdbkW1j2/daBlSyk%2bYM4AB9Ph%2b1tLRQd3c3Xb58WYK6evUqXbp0iTo7O6mrq0v2GFeuXAnJ4RmgdL9yz2WAJgBjpc4AdpqDGBkZoYKCAnK5XFReXk75%2bfl0/PhxKi0tpaNHj8peWVkZlZSUUHFxsawXFhZSY2MjDQ4OhkrElAGv3FMZ8GUEsPN%2bv5/cbjdVVFRIUPX19VRdXS1kNDQ0iKzn/Fxzc7PItbW1/x8EhJWA7gFfAFy3Btcv6tpANhioeQHKQvb6%2b/tvGXmfn%2bdR1b7GF2NjY0yG%2bxstgfj4eEtcXJzIPDqdTgtuWWeAe3Jykp2cDX%2bVmZvbV3wVzrJuyPIWaGpqstfU1IR8uis/Dlgbg2zV6xcuXLCrDMgfGhpiJz9XWSDA%2bleCWQfrZN1YL9J2161bZzNfxpISwQZMxuTGY2NjrZC/ayqHbwG/grOM5WpcDLCu5awb5XMf21qzZs0DPCYkJMzLyLuRBVY1fgdoB1bwPDs723aXqtCm7JcCz7CckpKy9MGrDNDB/xAYRcoRxu/xmtVqtaBzW3FD3J0XHVNTU7a6ujq7yZ8DSUlJbP%2bQ6gNWc5YueuNTzU8T8BDwH%2bA88ANgF/ajlzINTbZ/AyQBv0b6MwF1ykf7kjdEbQRGjwEeJbuAt8y3sEQE2JSNFZD/qS7hx8B7LIc35qV49ekb%2bCXwMfAzYDmXgskB2xKXob6AYsBruoDXNQFLkgFhBPwUWMnND52YU/CcesZm/kZY7B9eeSGC%2bRJWr17Ntt/ktxCQyuurVq268xLY7vcIcoe8oTES9tLHlqQ9TquJlB2JiYkUFx//HM9TS/Za0yrzQ8%2bbdTK0rdvxJ5Jf2wdaLet2Bt80cQkJD8L%2bAPD5YymJ0ntSjuyy5vQ0WxwTHQvGENI1BL3%2boGxxTHnviLAfoeGLE6tidwNbbpfk2yZgyDNvXOi38qGHl8XFxrpiYx59%2bGunFxyLBjtRGKN4XAi875jsjMq6WBW9/uCT9/PZza1ly7Z1N0XljrbNO48AonIxx2iNFLz544XLy1w6IRIGPVboima9gkFPlPNvf7BnvHpsGRHJM8n7d357N03ZcnpaQvb18xFj8rNvPHqidfBduUOef2z3e29A/jse%2blKoZ6Zzh/H8YOtH%2bkz4WcynMfL%2bKPBzsdV3RvcRDjiKoWuW3zBc43nTb2jCfgIMKx3TZjsoh2ngQxDyIdbE71sweOta6LzfcwMyYvZcsuS9d5acYx3kHA9DpLU7AZ8fa6cn3j9PMLSGg8Lt2SK9qrD2gJa3vFlpD2aBN27H1DnRIRgP6mN/d9x4nXb89bzIzgmsT3YG91me6KS8qbOU9/452c9jHROdEf3jfW4Ms3AwgBEIjjIf9glwyzIXsCxQz%2bm533RO9Hj1fNYx4iPIkt9I3SgV8CNAEfAsUAF8BLh5Xac2zsYgy0jpDPo42hbI%2bpM7kFZ9JJDZeiKQfblB7ORcey1kH1kW2PrnmkDWW9WB7L80Bra%2bXRNAtsz5PN/XWTZkQCDTSGwYSinn%2bmlygk0QQTBO6LCEHkAOMMjP6jnvyTmszUH0GQ7cGvYkz9Mq8qNVuv8WwVYCJ4GzgAF0AWt30YBNEfCoY6SNdRnsm%2bgHmdnv1tOG8v2UevIwJT//FKUce5aSC56hVNdBkde/sIeSDu6kpENPYn0XrS/eQ4n7n6CtXbUhP80xW%2bY7jcXBVglqw4nnKKVkL2V6TtDGiucpveYobW5/iTY1l1Cmr5xwC5TpLaMMzLP%2b%2bHIkEgw0GiEAshCwjz7RPeB%2b4DGWY2JiuCx%2boUsANyYlgDNBAvxeQ5EgBPDI9rZcrBZ/0msKaVPjC5ReX0xpLxfQhuP7aH3hbnr83CnKOFMK/8sozf07QraYCQj5GZkA3GzqSweEweQjTwsZG6vyKTn/aWGb57zPbDPrwu7YwgQg/YSAja5D0Qh2HxBYu3Ytf8j0AheBt/nbnp9JryqInpcB/mAGcBZuu9pE2e/UE0iSLJVsVBnJI1KdNne45Bkn6lsylLMVPmzrbqZQhpvitUgtMMsKKj0MKDNAhsgavAbDwfmwz9jefyY4H547Z9LFegOOIOvSA5wfnOfbfhBwAh0ohXRgJZAAfF%2ba4BsV9rke4GMCpM84xtsN3KaReuqwjBktLxrptYUC3LCRXldkpJ48ZKAUjE2vHhMgI7BfFJrn9J3W2aRjDVi4G3KjYrbngDnX/Gjb/PUF5%2bHn2yRdOYC8ybPM9Gr1GrT/r09u3KRNlUBsHrq3kICb4k6edaGKMk%2bX0uMdvyc0QUl/zsCNpw6jHFyU0VQi5YBmS5vqiuSZjOYXKa3qCIEwkOlRPvsE/FZhpj8AG58BMyEMeWewftuYd3YOnwL/xv6/gEckqLF2m/oGsKu/2Czb9P%2bI4MdPq26CK4BPWAf8%2bZR9CvnVf2YGBAu2XKyawSfwDDIkuDbsnRvH1BrO5fS2yJr4OyT%2bfcax/xc%2b93eqDKvvzwAAAABJRU5ErkJggg==' /%3e%3c/svg%3e"></p><p>We can draw CBT's approach as a triangle because each element is linked together. The way you think affects your behavior, the way you feel affects the way you think, the way you feel affects your behavior, etc.</p><p>To make change happen, we either change how we think about something or the way we react to something or better yet — both at the same time.</p><h3 id="cbt-is-evolving">CBT is evolving</h3><p>CBT has been used by thousands of therapists and millions of patients from all over the world since the 1960s. Since then, different CBT approaches have been developed for a wide range of problems, and research has repeatedly shown its effectiveness. It’s common to talk about CBT as a specific kind of therapy, but in reality there are many models of cognitive behavioral therapies.</p><p>One of these models is CBT for insomnia which this guide is about.</p><h2 id="how-cbt-helps-you-sleep">How CBT helps you sleep</h2><p>CBT helps with unhelpful thinking and behavior, but how it is used to treat insomnia isn’t obvious. To illustrate how insomnia is caused by cognitions and how CBT can help you sleep, let’s use two fictional people who represent two different ways of experiencing sleep. Meet George who has insomnia and Susan who doesn’t.</p><p><img src="https://www.sleepedy.com/assets/static/george.3e8a41b.85ae65f0cbd97e0b741ec52d5570e330.svg" width="392" alt="George struggling to sleep" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 392 429' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-34a6d761ab513e1d2d6c1a6f65779575'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-34a6d761ab513e1d2d6c1a6f65779575)' width='392' height='429' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAABGCAYAAAB8MJLDAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdGklEQVR42tVcB3hU15UewEm278bJOps4LoBr4pLEhXXABhuviW2wHWxMNx0MNkUUA6YLMCBM6NVgjCyKkIQqCBUkJKHee5kZjcpU9TYaTXv/nnPfjDSSAPfsWt/3f/f1e89//nPuve8%2bjULh%2bksoLFUAGMDbpbX6y6YOC1SGOgcBblTojCiu0SGvshqZFWqklFYgobAEsbkFiMzMRWhqJgKTUnEuPglnYuNx8moMjkZcxYGQCOwJDMWOC0Hw9vPH%2bi/OYvUpX6w4fhpLjnyGhQeOYe7eQ5ixez%2bm7vwb3t22G%2bO37MC4jdvw6rot%2bJ81mzD6ow0YtXIdRq74%2bGvjhRUfO19cvYnLrOGTpw1k215YvnaA4mZ/WUqNOHGjuPzRkhp9ZzkZW6Y1OMu1BolKiUsiRirQ1ErZKo2UVqaUkorLpLj8ImdUdp4zIj3bGZyS7vRPTHb6xSU6T0fHOU9ExjgPh0c694VEOHcHhjg/uRDk3Ozn71x35pzjo1O%2bjuUnTjsWHz3lWHjohGPuviOOmXsOOqb67HNM3LHH8fY2H8ebW3bYX9u43f7KOm/76LWb7S%2bu3mgf%2bdGGb4qul9ZtxciPNu5m%2b0at2TSACOlPQHpphWAoIb9oWAl5meAkOFylQFFVrSO/stqRo6x0ZJYpHanFZY6kgmJHfG6BIyYzxx6ZmmEPS0qxX4pPtPvHxNv9ImNsp8Ov2E4Eh9kOX7xk23vW3%2bbzhZ9128nT1o1HT1jXHjhiXbFnf9finZ92LfD%2bpGvmhi2WKWvWW95ZvtoybrGX5ZUFH3a%2bOOf9zlGzF3SOnDW/84WZ8zqfd2PGvM4RM%2bbeHu/N7Rw%2bY2778PfmSCNmzlMNX7DkX9nG4XMW9iegoKhEoW9pFyRUaPUbW%2b1O1DY027UNzVQ2CdTUN6LKVI9KgwlKrQFl1bUopnAoUFYit0yJzKJSpOYVIjErB3FpGYhKSsHl%2bAQER8fC/3Ik/ILD8PnFQBzzO4f9n5/B7mOfwXv/Iazz2YNV23diycYtWLD6Y8zwWomJCxfjzdnzMGbaDLwy9T0ZU6bjfxiTp%2bNlxqRpGD1pqoyJU/ES490peFFgMkZNYEwSx59/46/j2LaRU94bqLjVX05pefc2GRkmk9BkYxK0DU0So7a%2bUaqua5CqjPVSpd4oqbR6qaJGK5VW1UhF6iopv0It5ZRWSJlFJVJqfqGUlJ0rxWdkSTEpadKVhCQp7Fq8FHQ1RjoffkXyCwmTAsIvS76Bl6R9p89IPsdPStsOHpE27NknfbTDR1q6ZZv0/rqN0pzVH0uzP1orzVq1Rpq5crU0Y8VH0nvLV0nTvVZK05atlKYuXSFNWbpcmrzES5q8eJk06cOl0kTChEVL7FO9VmH8%2bx9sZpsmLPEauOBPTyjGA/2NTy0sEWWRpkYwlFJQfKdSb6oxtHWg0ljvUBvr0R91UIsEaYJKT6qgvFGhM6Bcq0cZhVEpK6SqBkWsEpUGeRUqZJdVILO4DKmFxSCCkF5QhPScXMSmpOFKYjLC4hIQFH0NF65cxZehEfg8MBjHLwTg6NkLOEzKOeh7Fvu/%2bBJ7SUF7Tp7G7s8%2bx67jJ7Hj6AlsP3IM2w4dhfeBw9i8/6B914lTWL9n31W250xwqGLemnXCxufeeufmClDpjQpXLzCIy3yV5tlirdFcZqhHhd4klZGRt0edQLknDLdHSa0e%2bWXlKOOkS88opbKUwquk1oBiOldERBZWaUHJF/maGtED5aqrkKMiKDXIpvDLoh4ps1yFzDIVMjgUSyuc6eVqRKZlVZ%2b6cPHnbMv2oyeEY0dPnn7LCFAQ%2bwp9Q6MircYgeoS4asOjpTpTc4WpkQ1zKg2yURU3hUmg/BuggogtIEWUkpG8LY7xswx9UQ%2blsT9UxgYZJhkVhBLaLzU1OCsbWlBubKhPrDH9jm0pb%2b0cMGf9FsVX/m3JUSlKdKY7eLtQZzpRZ3WgSG%2byFQnvmlySd8neA8pbHFfd8rh8jhMph487jG4F5W2gchFK7SUFyWqkbVt9lx35WuNxtkVnrBuYUK3/agKWFmkUWmOdIIA8erHabEWB3mTnECjkB7s8LYzWy4Yz1EyOe1/vcU7f%2bzoBzhUkcz5eotaggqSucl/reZ0nxHPqbgJTd8nO4baRw6QCncmhbjXzvr%2bc1OsGlupNX03AspIqRZWhXuSAYr3pQpUHAVwBs1ugk%2bPdbXiN3gC9Xge9TgeN3uhSg8s7LgUo%2bbgrUVY2NqO63Qw1y1ZLx3UmGd1eNfb3souE7oTLz/VQh6pX20wSkWCvautkZZxnW6jtA8u%2bDgFLizVMwB1uAnSdNmbU7paaysMjbLhOpxeG6/RyqaVS5eF9js1K8oSqrhEqiksNEZpXqERSZCKUTe3Q0vi7VgJqHEBlexdd2wl1SwfUja10TxPUdA8/Q%2blRd7fh3W2RCS/vTZq9%2btsQ4FKAIIAMv2AgAkroYWVub1JZLTwuG8yeZ%2bPd4GNVbhW4GikMM9tRZZNQXteCvS9NxZbBz%2bPo2wsRceQcUuIzkJNfgcoOKzRdDmg67b3ARCg96lf2IaJvDpIJqfvuBLAC9ESA2sAKqBOGuY10e92977ktVOAOAfJ8pdkmjKsmL%2bfklWPn029i8%2b9fw%2baHXob3A6Ow9eGXsPWR0QjYchA1EivBKt9DYALULeZ%2bCmAnaF11cukm3Z0PvlcC%2bGE06rul4fq%2b%2b24VcGJqahNGCALsgN8qH/g8/goy507BF6P/iq1PjsW2P44TJBx%2bc75QgNt4NwFceoZBrYcTPMGkdIfeD0VAP4/fRAUG2ub8wA3hmBZebOuCnuLdf8dnuD5%2bLHDwfXRtn42SRVOhWT4dsZMmYsujY5B6LQ21kFWg8VQB5QJ%2bXpVHO/qCj1f2JOHvkwAKAcG8oR8JfRXhDgG1R/wLL1LJhsUGREGzbCo6t86Bdfsc2HfMAfbMQ97CaVj1m%2bcR6RsmEqOa84bL%2b4IAUhL3Drdrg6cKvlcC1C4CKsmom7HvGRrcDfZ0WXVyYuNkxt7skmCK9IfTZx5aN82Cae1MmNbMBHbPhY7KwFfGQn/%2bKDQ2yPe5FWBxQN3cLrpQrQcBN2tHzQ9BgFCAy6M1fTzg9jgz3x2D7gwtCJAVoCGDKikHmELOQPKeCuvO%2bTB7zxZhIPnMhcNnPrDxHVjP%2bUBthTC%2bJwR6CKi5GQF9c88PSQBL21N2XGG/rql78EM5oK2zRwEs6S7A4vsJsGUS2rxdIbBrNrBtGlqizqO6oQmVFmfP9W4CRAiYhAp57HEz7%2bs8xiA/AAEe/borGalv0icrPd4hcszygIYNcKtATfLWq4ph37cY0o5ZkHbNJcxBc/R5qEkhHCaexvdNgvz8apcKPMEqrPQcgH2/vUCPAlR9xuu9DO8zNGXJMgHucQDHssbchSoyVENovvwlnJvfg1ZVikqw7Jkkixg0uQ0X4BzgQQDnGXYAl0yGxkOFKv0PMBByE9DXUJXH8NhT%2bp4hoG5oFuB9NqKyAyg2VkCXEgac2gbsmA1r8CkUFVyBsq2RxgFERGdP/8/DaJa/urGl12DoZlD9sAqo62fg7eA5gZHJM9DMrBl1pQegjn4E8QefgGnXu2j%2bdCYKdo9Gst89aMkYhWpTEVTNFCr1NHfgeb9rAtVrQnSrKXO3Av4fEOBJgjDe1IEaVSg64u%2bCJfFe6OKHIif0YWQHPYKyqKHouPEgOuN/iebUl6HSaWUZu7rU/s/rTnR93jn0uu7/AQEG2Qilgbypq0VL6gvoSPgt2hMfQGfiEFhvDJaRNISOD6HjD8FMJBiK9xBhFkGc8mYEfD3i/%2b8JkKVJBBhbYSpYC3Pcr8jIh8nYwWi/PgRtifejLek%2btLPxfIyI6Ui4F62pw6DWVsjEuRLct1De/zEB3XFZL3s/ZSTJ/C6Yr/9a9nbyPTBHPYbOiD%2bS4Ww8qeD6PXTuPphjBqOmIppU0C5U8KMkoDshGRtQqamG7cRCWP3GoiF7DtqT7kdn5ONw7p0Ox5EJlBdI%2btf/C6ZCL7SFraNB0VtoiLqI8oZWIs/YKwx%2bXAqgxpc3tqHuOnV5m6eg6/hONF85Cueh8cAnC2E7/boggqVvjvsl9OV7UV2kIQKmw35oOdQ1tfLb3x91CJABlpObgE3vkNFTiYhpkD6lOUDACLTfuJdwn0wA9Q71uYtR1mRDa/BRuu5d6DMTUVHfIoj8EeeAOhhTYtAc/jkaIwNpvP8RzLFkdPJ9IhfI2Z8J%2bBUaMycSAXZo81JprjCRwsCfwqDtx0mA58iMvVhBA5uyJsBYvIri/eeU9R9yGc8JkMYBlBxbUkejgkaLuuxkoZjGq%2bd/vAT0GjazATrO5vVozJgovC13eW4FDBXdX1vSk3RvBfQZN4iAt2FIjSVCWn%2bkBPQhQWloIEOq0ZwynMYANBhKGOrq/90gEuJ%2bDY3uBozJCTRFngVNZSWUpsYfaRLsRQQPhlqgqc6EJWkwjQIHw0xGmxM98QAs1/8T%2bkJvdPjuQ2vgIdGDCO//mAlwr/SoaDSoVEYjL%2bT3qIoaQl3jUNRfHyxgih%2bC2liaG4Q9gKKwqbAfWQNTQnh3D/B3HQd4/QAK4I%2brNJQEM4tL8fKYMRg56ilMePsZzJ89AovmvYCFc0fi3bdHYNbc91BWXYVqZTlUtVp5FOk55f57ELBTpSMC6lxrg3X%2b7tfiyq/T7d3U%2byaUaw3gDy027zyAu%2b5%2bEvc/NAJDHnkRjz/1Jh770xt44pm3MPTRVzBr4QZoW9pRzsvhvWZ9f0cFiJVUY4O8NKYz%2bgkC9CZbz6KlsdeydL%2buz7N0XVdpakC%2bUoP/fuF1DHn4GTzy%2bJ/x1LBX8ezwcXjmz2MxbMQbeOwPo3HybBB0LW1i5bhXL/JDE1ADKDTtFsWJmExFWYdNfByR1tA5RNXaqa/it7nN7U75rQx1SfXN8kKnsd5j2dqIfounrsbI3jfj%2bBl//HbwH/HwY3/G754chaefG4en/nssEfAGnnz6LxgzbgYK1NWCLM8VYdXfQwEas02UDUREcXPnT3g7s9U2zMTv6TodDvndnEN%2bp%2bd%2bVcXEtHeB1%2bDlldxGFyE9WZsbwvFf09iCGfO9cPf9fyDvj8AfnvlLNwHPDn8Tjz4xGgdO%2bEFPYcKEfeve5ruEgNps7d7O0GjvilLqd1RbJTZWUsvotWZX6bmCS8RUulZ/VPz62u1FTn5ETG65Gs88N4bk/yx5f2Qv7z/%2bpzF4690FKKs1iA%2bvbuX9vi9kb/n26dsQQAYpGts7xLa2y7GmtL61PV5ThxqLQ6oVsINRQ0ZWud/x3wRupfA2K6OcpsIc076B4fjtA0/jEZL/U8%2bOwbNk%2bNPP9RBwISxaXOf2vrJPPlF%2bmzdRX5eAmg6K/077IFkFtnEtLPs2C0ILNfYYYzsSG8xIaeyUMpotyG21oriDkiJ5vNrqRE2Xg0ki9CVFVoaawkRrB0IiojDs8WG4%2b9EReOip1/HYM7L0f//ky1i4bCNqm1pEqChvMaFSeX45ouv/9Yg41ud4z8JInfyJjM44sKy%2buT8BZW0WhbLDKn8T1N61qZ6/2GjvtB5PLZfeCcjGqohsaeXlHKyJysemuGLsuFGOfZmVOFGohb%2bqHjGGNmS2dKGCPF/T5ewmQ4QMh4QENCRHoWbha9j/zmvwnjAeM15/m/LAq6SAcbiWnouq%2bqaezN/LEJcC%2bCuwuibxhYmK801Tu/wVCaO5vfu1uUjQJjlBCwW0d6JMZzgjPgGsaxp0y/gvb%2b8SBJS2WXyaiYCq1k7bpqsF0lvnM7AyJB1LLzHSsCQoDYsDU/FhQAo%2bpHJJcDqWhWXi4%2bgCfJquxnllHatFKKSW1MEfWPE6n%2bHkDrQveQ329ZOAT%2bWlsLxN72Pz2TAcy1XjYlElEjQGlPAnMWSMio3i5NpukZOte6XIlW/kZOwBS58EbRYJ2snqVDV35Oa3dP1SfBBubBY93M5LCYrQQpVsfGmrhUNAEKDusB1uJQLKm8y25aG50jv%2bmVgZmoFlIRnw8sByF7yInGXBMjlMyGIianVknlBIRG0ziihcaihUGg%2btR8OSsWhcPRH2XfOA7dMB363QUF1lLeSlti6Uk6Eqs72XMRqX0Z7LZJUudfWFZ/i57pGqLA6HkeooNTteEJ8CN3TcoWq3DjI64cp9dpJGh1VR2yUJZlQdtsRGuiHH2OaY7pcuTQzIwgphZIaAmwA22usmpHDpJmMpbW%2b9XoxztR1QBZyC%2bYNX0LhmEhw754jVYCeVxoJ0qFlxZHAVryKbrb0M7JVgCZyAa1wJmRVGCVuUIkETqnsnaIng1FBPFqs2fLDBN/xfuxXfahlA5A5w9wBu74%2bs4vV7hyQtCymSxn52Q5oalEOG9SegL/oSIsigY0sCKVRCMuF9OR3F3ovRteRVWCgMpE8XiAVR/k6gMSGUki6FjYOSL9VfSyNPncUmDOMkW8UfTVFuURJJhe02kW%2bSGzpxva4D8aYOJFDJ%2b5mUpAvofIVFvr5KJod7MCkgqwzHrmW1%2bWeURFVbHOM8er9uEu4k76vayRvroiocP10WhnfPpGJyYPbXIuC2ZND%2bYiJhzaVkROz1gW41zfbWjJfDwGe2KK0nPkZjciR1m3W40epATKMN0fpWXNI04kypAYdzq7E7TYVtiWXYEFuE1VfzsCIiB17h2VhBCZr318cWYmtCKXxSVTiUUw3fMoMUVtOMOFOHdDajFEevZeF6dQMa%2bOuTDpsfKexn3UlQ2W6NttCJz7K0dsX7wfgHr3Dp7dPfjoBe4CTpIoFzyfLLufAOiMOXR48je/tKNG2aAXhPAbZNlUHKqDq9C2cuBuPD0GwsoXBafMmVeElNXHIi5jBjot3olaADU1z5KE2ic9L04DzsicuX/JJypfz6VjuFm53zHDk9wjUCtC1plg/YHt91HYoFl6SfLQuXxn2WjClB2aLx35YAoQYXCby9KjgNa8IzsfpKHtZGZGL3hUj4njoDzdZFaPWehdIj3kTEJFTuX4tFoTlY4aGm5V%2bzTs/ruAd71z8LK4mMQ7E5UkGTBXqbk0e1VpfN7zMBeXW0k1VndvzTystQLA6VBiwOxStHkzD1uxIQkuG610WEa3slExGahrXhGfggphzhB/cie%2btyzI8shW7/asSePIQFYflUd9ptw%2bt24cd1MQETiACvoBQ8t%2bsq7t1yTbqha4PW6rAbZQKucS/QpaOuKoNi5SckfSIAig9DMepQAkQS/A4EeLnCh0s33M9ayscvpeL98HzE7d6C88eOYe7lYqgOrsehcyFYGJYr6vb6CqNvTUaG6MEmXszCwgvJuPtjcu6Mi5h5IV9qkODQ0QCN8l4GK4AZkbIom/5seUQ3AcP3X//OCpCNlnMB5xL2yCoPrA5JE4ns2p6t2OR/DZuDriP/8DaSfpo89viWBLjby3VOozw29ngCBi4J5fDGvIBCqd4JO890C5s747jvl7jLyafx/i8%2bvgrFByEcBhi2N74XAT3e/GYN8eqVRGUVcMNWuEq%2bbl3AdSyhnmJtUBJ2%2bV8V2%2b7c8W1Czl0nt3062TB4W4xs16IQ%2bOYbpDqHJAhI1DcfUJS3dTmraBDBRDzhkwDuBQYQW8/tjcNfA1yJyCPjfj%2bQQ8CdE9hgkc3JgA9Dsrqv%2ba71MMlvXMjGP625Kuz61fooZNebJVK8Q0shEKo2vqEoabU0aixOUFxI08/nSYp5QaSAMDy9Mwpjz2ViIk2I5Oya/oNhhUfZd/sbI1QGP2N2SA7%2bcCyNHBomvH8XEcC5zuAQ8m87W1p7r6Kg2Zylc9KExe50BpXVSXIIhOFfVoTjL4fiMNYvA%2bMvZGESJRNOKO7yq/DuzeDfgwm3wTt9cUHG2zfBeDfOy/irC2PPZeHJIyn4yYoIkdMUTAKFdmhFg6ON5E%2bOLxgfcP1nihRTyyke/1MI2HkYPO0cqWB2gLjhH5eHY%2bjGK3jQ%2byqGekf1whAXxP7WaDwgENONoYTB3tG4f0sP7vPAvZt7cI8HfsvYFI27%2b%2bCezTHi3G829j7%2ba9r/1YYoAfbwf7rw72si4U7obMugZeFQzA/C/pRqRydPwtq6sp8/fWWg4kK5djLHA00OHDTZkGiYKL35eSZEKFDWVHzgesjim4CPs2L4ujmBvTE3SMiu37XfBB%2b67l8YLD%2bT28TbZIhibqAM3u/bJr7PZfjApS7j%2bRzdf7bA6GwWDrdWEe5U/MLn3L/dMLRoTaJftDqqKSFyt7jnRpVIiiJ%2b2EAGV%2byG6xhXcP%2bWWDx/MAWT/XIxN6AA47/Ixh8/TYQYWIn7LokGcUMYfI%2bQ5C0wwO0x3qdG//vqSMzyz5e%2bzDfgsroRF4pM0oZopfTSkVQ%2bJ3W3bVFwt9HddTBBIq%2bFYkloCU%2bwJI//Q3hMDIf/llG%2bqIpY0VudNmWH1cljgwYnJLpIulrZJP0tuQqLgosw8cscYRyHyYoImmBk1ErRmiaJu1DKIVI9JdI6p8QDDZqL26VEbSt2J2mkMcfT8R9khGjoPFkZA9zeWRre3WDeHuRuuIu0KWdzpTRjOz8TRgpRClM7tc3eBNiNdsmRamiX9iZXSWNPZkr3bYmV6F6JM74AGT3Y%2bxqTB7JD3C9e1ZltDu4Gydbn%2bTcDBAkHspSf8wsKg00CTRltNEFy8NtgHjtTv8mDB2EYw7XtIHBjHCY7nDq6T2sDzdGdUnWng8PJTkpyMiGcW9Ip%2bx5IrZbGncrErzdEy%2bHBhHCoMCnzXeQwyPARB5KlwNI6rktMa6kt9DxJ/NNFDb%2b2Y4cROH%2b1QG5LQVOnFFPVLLFCSOrCeSWtXWikNrMdKn6f2WFzaq1OeyW1lXqBPyn%2bcja2%2bwcFNiUWfhJeaZK4Ah4r68mo2i6nkwhxsFFUOmstTic3hIeS/I8N%2bWYnrhlaEawy2IOU%2bs7ImgbktNuhYzKpu6mhe7nxLD0mg8nMI8UElJikj69WYIJvNkYdprH6/hsYfTQNiy4V4VJZPffVEnmMveSgNkhsMPXbXfuyKqI3JhYe975RdOZIriopUKk355slUZ%2bJ6uNRHg906F4nG80qrmi3svEOaoudHCwxcaeLqiK7p8Ovn7/WTcJLvtFPbEoqPPh5YVVhiNrgSKQhclarFblkVEZzF%2bKNrSBDLacKNXnbUop9vWKyF7/pHz/8N3v87//5znP3PPf5lcc/uJo585OUki/PldbqM1ttwlN6O0Ak2rkhlGdEyLCamiC6YIlffrBSaJ/PiYEZqcjGE7UEUxvoeaeePBb2UN/3mUMOBN2/JDpr4YFsZSwRZCu1ysrQUX06VgzByP%2bnwJMfefBj35pcfESx9MA/iwcsj8kW5WjfaEVUTX3P/9b/1xs/ffDgpaHTQpLHkEHvLY7KmrMwMmPy2wEJL/zC5/w9ijtf/elXLjIuP/zz2RGpE3anlwWRp9qLLG5lycqgJGTnUCMvk4eswlO8z4YbqNGcl84UVyunBN94xf1I/pmPY3nqO3yLa%2b5An3%2bDH3bq8iMrYnM%2bIpVcPVdWayAHSper63FJpbeRwwrWXc/fMezk5Ufc108PTZYdPzMsRZRPHAtTkEcHflFUPejrLKKS7AeRcYNWXcsdOCssZcAMwqKrmQO3pxQPIjJ7PWPw/sB7yVMfHsxWxl1SGSy5HQ45TFyhwl7i0uDyFDW%2bi5S4RzF5y7%2bIH3hoNg96LzR54OTgJJnb2GwF1aeYdzltwLbk4kHu3z/pWec/dOfvDoc8%2bKJv1BN377l4v%2bIfR3c7LK2udeDUkBv9f0tkZrhMxPzINMWM0GTF/MvpA9YnFAwk%2bQ3amVo6iCtaE583cHZ46gAmbU5Eaq/7ZkSkd5M5NyKNtwesSygY1AH0%2btWGhw8FD14UmTGL4vjk0Vx1qm9xtZ7CxexXUtNI%2b%2blr4/O2P/NZxIPu66lOInOY2Ka6u58zKyy1uz5SiWJxVOYAn/SyO/qR4fo7kqseREoe%2bNq5uG7H/y%2bVtnrxPKrYBgAAAABJRU5ErkJggg==' /%3e%3c/svg%3e"></p><p>George has had insomnia for a long time. Over the years he’s had many sleepless nights, spent tossing and turning and waiting for sleep. George's insomnia has been getting worse lately and he frequently wakes up in the middle of the night and can't get back to sleep. For the last couple of months, he hasn’t been getting more than 4 or 5 hours of sleep each night.</p><p><img src="https://www.sleepedy.com/assets/static/susan.9898dd0.5e6da59ae16e2a18943fad1c341e102b.svg" width="206" alt="Susan sleeping" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 206 476' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a722760d8fef9bb81bc1944743dc2b41'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a722760d8fef9bb81bc1944743dc2b41)' width='206' height='476' xlink:href='data:image/svg%2bxml%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAACUCAYAAAAjxi/nAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgAElEQVR42t19B3Qb55UuSMqbXTtn4yS7e7LZ46xjS2Jvkr1usSSLHSRFUiAAdopgEavYSVGiRIokCAzApmKv4%2b44TlyTOGXXzstL4pbY65JNXF7sbOImx04kq1iNIoC5796/DAYgRFISVbw85%2bof1Jn73e/WmYEMhvPyB4bISCfbWr5cMURHT%2bHjUUNUlEtKWFSUG8UVjhJBEh3tFqtf8D3a8%2bK94fiYPmeIiXGx76dtsYbRunSp8xLcfh7lB/z5Mdy/69ypGhXlNKxceQ8qSIopQkG3UFIqwRWMjXUv2n4jI91hOnAiYmImJBA/i4u7DXD1okTqwTnrv5iYPRriuHOhqN6SzGJhcx%2b48jf43i/he5fheh1KGkoBPi7DtQbBakRpQWnA5%2bhxKT6fh7IGJQG//ysI%2budCG8M1EBd3K%2bB7CID30CCX6llyhkiPCSqPCytLyxLqoZFF61yKry9HyUQlNuLqRvkeyq%2bio1x/QDmAMhMdPQYxMVMQG7tbJ3t0Ih/vwvdNolJuFQE5it/zR1x/ieu/43MIlCsWZUUU%2b063lz6D2z1C%2bYiAg4uO3qH3G80/rrrKwayKB4%2bWVsTrivRXRuPQqLu/JCxZh3Irvu8X%2bByi7/KQcnF4MHGoSBwqERc7xRSJjh6HKFSeFELx4Wc8MUwUD22T4PNipce0Te9zAwdtkoEigcL34Pe4jtLrtE/c/i%2b/MVzMTfU00VYZdKSPREdPyOfD6Xn8siB1t9JrRF0rygQe5HMo%2b0mhQGtNACpE4ouMGvNcHTXhuSpqksS7PGrMR0qjsmosCu5Hxfeo%2bB7A19VlUePsOfysygAipbmCqmAAbRNoXh04DBiyPupAAHyA8mXp/3FxE%2bR6s0EIZIZrSSgr43uvRCH/vAPlNdqpRD8mZiezJu5Y1VnNS4ovRUVQKTUp2q6mxPZBYVyLWh1vg00JpdCTYIGtieuhH6UvoRDaE4qhLr4KCuJa4fqYQUAQYGkUBxG/j5jCVi5u4eO0T7dgEQdIPJ4RQXCniFURIvYEKr98ObN8N37pGK5X6YLUpSLgOFBeQpmW1iV6iQMg1Gd4pGUUZtahA47ElRS/OWYbbEyogh1JeWCPywBXQjqMJ6WDOwm3kzJBScpiQttulLEk/vpoUjYDaU3MFiBWSOX9ILhPKRIMEQTp%2bJYJncNXrLhNAyBCrF3x8XdKH/oUpRO/4C5cP%2bQ%2bJhUmanHritQidsJ3JJRn1iLLxUU7oTq%2bGtzJqGB8OgzFZsL9qQWw56Y8GIrPZgqOJs4WuxBHkhHB4CBVxtcCuUDkAkHQKy/0uiOQBW6OhgDgZvFBHykpoy75Lz1HVPIrLH2P0U7179R/UKT8yugR2IyUnkpOh4FYI%2by%2bcR38v%2bYygJ118JP1hbA9OgucyaSkX/SAkPISDFonk9KgMb6CARDoBnODwIGgIOs6gfKvMhbI4kkPQq4EgSvMrOzT%2bZPO0qGEHwwdIAY06E0ww0RyBmyLyYYHMwrg5KgNYKIWYLIWXqkphoEYDsBoojEABA2MICBGEnMYCKVx9cwdYhbmCsEsGBEsWKIPbNINKnlacvsCae1W5/I1nc%2bxg7o6ahLK4zbCJLN8NtyXkg/gqgYYqwGPA1d3DRzZUQVj1%2bSgdY1C2dAgSCAkCCROjBU3xWxnLGOsm/e4GFt9xGYqiJD6fytStr8sxPz4Zdw%2bJN7kW4jCoayPaQ2pPwwjSblMKdeKHDi4fQPAeC14nai8qwZ8tCILni23Qn9UJr4ne8Eg2JEFFBxrMUtcrcsM87OAgcAyFupXKDJdhN76Q0QRiub6ALJQkdbH3A35sW1ofaR%2btBF%2bUWIBmPIrryrVTGibmPBw1nrYGpmJVs0GBd3BKSUEIH4GGGFH4jpIjrYzwJnyUa6FHKeH4hpVoXrXp43L8Ev2iqLBt1DKBzOA03%2bC5XBKY46kHPikfwOjPlldKq%2bBgM%2bTPGk2w3C8kQXFwdgsFht24BrMCn2GoMyQGdsdxIKFpEQG2GGUr%2bhjgImoQQj5o/zpAxAlmNCTaGW5/u5b8pmVfaTsOLe4tDytJ%2b022LdlAxwbssFHmyvgl6UW%2bG5mATyWsx4ewnUkwRgSBAKA3KAivo4xbiEAiIpR5SxgblCkB%2bABogavuxeivGtWGpIROSHaAYNJBbAjJhO%2bv87Eoz4q/9c%2bruhJezUc2FbFnt%2b/dQO8Wl0Kr9hK4b82lMCJYR4byGWODdvAvTJbC5LBAFAB1ZpQogXC%2bQHQjl26wbdk//45fPAn3l35U96pgpxUXNT2WtojXyRrxCMAw0nrYBAB%2bInJDLCrDn5XVwa/Ki%2bB46iUF7PAu%2b0VnAUkIi0eRFAOkLu4RKbAoPlY9nr8nsBUSSvVCi7MBNsSC9j%2bIhdQFcpgSDoKXf%2bwfLlzCaWCuKDKST2VxWWgo8dLebPCFCerXxs9xOr29NgesCfnwkB0JjxlMTPLv1hZgsVPrUb/DzorGRNkRmBZQcQDig3MZRCYdzrKWSyQxRIpz8HIhuG4LKwLsnGfO06HBfrSmIwdQ/S3CP/3hrZ%2boNUp6BDit2BtTrm%2bAxsXsgQVKU5Rz9NBUiD7Yb4JZkarmWjpj9wB/V4GR40J7hotO%2bhBeCLPBP2RPFVSlpDB8fZVeTC5MgtWR/bC0uiJBcYBHgt02aCEANgu099sAAJ9nZRfG9MHnQlFrDbnzQxvZLRCRaQzAuBRpDDRW0t7Qjlyhfc7KxgYnw5WsccsLozJNCnAQFDIZb6DVeS2KKQ8ZgkKkvswdlAAPT5QBs2rOuCKZRNYecpjnTddqzwOsKqQDSYfj43dyWZmoaJ6tEb5cSiOa2TBh5TmwSgnoIGRNKWUNhRnhAfTCzRqf9hdCX9srYA/tVUwJtBK4PyhpRyeKS5mbkEWDwZLsuOFDUXwY%2bwf2GtKFUyPIIN22eDpTa3wr0uxd4lxBfUGrpANk8hykgHfp2roNd7wBOd/l660nQBrXBNMYB2ub04cicYA5XmlZoRfWk3wQWsxvNdWyqxJChzdYWOBkEAgOTJo00rj91F57io29ph9xuV3B6b0JA%2bWPocNpocqsLDC58Zt8EZ3PSyPxAo0epzFAhKKS/p4FTQ/oDjgFZOil4kBfxWdkhqqsqNgR/7uElYPqMt16Ykqtx1o9QdS8mBmsBwO9FhgeqA8sPpDhT/qqYTDA1VcGaewMD5/bKiKyVEUlgVcQTHByYE5icqTTA9vYOnyheoySLx6AFbG2FkQJqGATM0YGY4AidEFcQ6IS%2bsLCIAjswFwBdT2bZhvifp2nfLBtToBQFXcd9PzEYAK2NddDB93FGoFDylHvk7yQVelFhhJOfLzEyP8tWlc9Yrrt9l3MevzeoG%2b99Ybc6E/Lo%2blXmmU4cRcNmGiOQQBQkBE62IEH9qM0/qxQczRAgDQ9/Q3xAwEdGKhlJdiZ81PNnzYUQLHtpbAwb4SZrkTwzbNuhTdSXlKg5qPjwf1CHrqBzEBnLyIogbrfuwyKSu4ko2sP3DohALzOCvHsyE7tjOwfWblPgHg2kcAHJ/d/Li0xiY3toPV9fZ5AGA5GlcKfnevXgd/6S4F73Al82VSmmhNYDDLj9VoFR/FApYRxmoC%2b4QgBjB3QcV/U1cC30rNxyoxh9cIp5goySBNwBB7UzB7LfWDEADAXvEgJAAU/MYZADlzWj8YhPFrsuHRrHz4dMCf3sjSf9m8gZW%2blAXebi6Hl7AEPri9SqsD5qI/gTd1XQ5roeW%2bQrXQ%2blhFhqP4tTnBrA%2bIPjG8ZS7wW/8MQJvraQBY4poXDIAeBNrevCwTXqgq0tphSfkjmBEoLX6MYMhGSU/5YNpTjKAxGrXWVF8sZH4QOEPIZqmbWEADWppSC53fJQC%2bp6sD1ODe3oj%2bMyYC4HwxIBgEO3Zzu2/I5aMwt78lZi4wwX0/WNkA2pPyTq7825vKYCTeOO%2b%2bQ4Egu8cirGPoXENMtOLVTpjgP05eFdEghE909Rng2pghZn19IFzYjnndTs3M4zkm1tyQ4l5R%2b2siFWbVn14EUMieN5tKeZBNMC7I8rMB4FOkqvgaCYAohNyPEAD17AGb7bM5oFZAxIo6gCaxY8INTpUG5wPhEeN6lgVIIdYBigqRsYBiBCt8uLBtZMwhjB9U/Q1h47OQ2eF8AFDvwucHiiyF%2bwmADE4HOo3ETkHBVcvGsLpy4%2boWqXBQG0WNzlELhAJAAwEj9sS1OfDzYgu831XO0hgpuB%2bboiPYDwBWdj4HMmSU3KIOfltbypQeFM3PmSovYwC58brYdsEArRJMJQCi5RCUzuJctXwMhgq2wJqVo7CnuBeS45xwZeQky6WsGtR98UJZIEEgCtPYi3oFCmTj1%2bQw6z6ShS4yvBGmt9fCiW3IjuF6eKmyFLafRsCbtd9Z2SCHVYjLo8Z9MTzr7Y%2bKUi6necDnEZG9S1HJzOvsvqaM7erzrZvg1pJe%2bPP2eliGTIjDsvLr0TtZTRBYEp%2bONbgCsre3C2Aol9%2b9Jh9rhlrwDNXCzBA1O3XwTns5A8p5mkHPL0ZNcTqXQFNkUQfIRuge/4UO0a5nvr58N1yf5PT%2btLFN/XlzK7zb3wBPNbZB9doB%2bHFjF6yIGmK9P/X8ZwOA3kJkXXp%2bD5az03ZbwPxw39ZKjT1yWuw4DfbJY6SKkM5Ood%2bLvkCRM8EHNQDQyjvTr5%2bEK5aOe8Ytm9X9OzbCidFaeKmjGf7U3wyDma2wOSYPJpLTdQdgPCPrswOLxwouPoPldHIJco0D2/zTYwKCeoJv3ryOFVX0PooFNCQdFX3HfHFIDwDNL7Jiu9jkiuoAOmPNQXBnMwAuv2KybHvBCLzW0%2bR5rKZTpTTE2s2pani2vhbalq2D8RWZp50O9f7Pxt4xNDHCxzesh/5bKtg4/OWaYjb60neAsg4gED7sqYAXsZiiQcgkVpeOuAwGin5MNpcLjIpKkLLAQGI%2b5GEgXBo1zliAPcEPGQCJsUrUlcvGvKZvDMMbvU0q9tkqA4AGlKNVcM%2badTAYZ5zzPN6caRCtR9Z8ubYEA105/KSzHTbaRrDAqfGnxVANkDY0rcP32WB3XRd0ZDfD/WtyGZgsRiTPXw77%2b4Ismmmo5rhm39Lo3eQOv2cAfP6flLC4GNebVyzdRZnA%2b9bmRgIBrcIP4KPNfn88beXxQGk8znybFNlZBfe19kK3bQApXwUzDl2FGKIHYI0Uc4sqaKwagp6NQxgjquC39aWsypRD04WcYJXVLDZHnlviR%2bDrUZN3GuRVIBgUbk9K2A1fu3rMY7l5mKMvS1G00v%2bxWpi/KskLqcG58nRw304r0IafJwnQ8Q1g39iPWa8fwd0AXjH9Ce4F/GDUaAVSUYkd9jRtZgAQmDQPoLPOg/OAEHSC1TeG7XNfQuFHf7fsvi/qzw2up54gMmbcu2LZdvX1pjLWsnpFUKKBxa7rc7V6fKEgUKFDUZ2VwKTMmA1aqwbhtmZUZKKKAcCVDC0SgGOOWsi0OOF7nV0MgJMOni0odtwugqVzYSdYVRkc0R1W%2bq8NiFS%2biOnw02UxO6Eiqsr3SFoOHiwfUsoJDNXkg/NSzqiNxf/DVKjrBIUl3WjJUjs80sEVYQC4Tg0AA82NwXCoAVYXuuDZvlbtc/K43uvkNcNCiiMRIGemVuaTS3SwGHD11a4IjIiPRUZPQGL0qHcgMU91JRtVObvXz%2bnpbM18FzZIID7uq2RW8umofHS0DrKsTvi/ve2aIjAHAF7Bmje2N8M3TC54E1d67BOfk6faH881LfS4VFw9kyvzaFu7RK49Pu42ypG%2blNh%2bGEvOVLfHGOF39SWqHF76RHdGNTwVMPaQkddvfXZOAAGT3Z605AdoyVsKFXh56yamiFfXAYaiPwMAgXp6cxusQQZ8hGUyfY8GgDDMXkyXC2yXyQUkAMMSgP7EhDspKh7HnvndScz5CID6w/xCDQBmDREQf1VZNGdApIKFDkgCQJafobQ6uQFe2LIJbkZLfkyKIAAepwyCgSBIxkgAHkeXSccYcNRRp3t/4Kn2B9LytTHZvAxYwQColAD8fVy0s9Gw9NGr3EmZAzuvySefmrntpnVqqAKF1jtWBQYevfWfyDf5x946JV7tbwFT8Siz5D2bekVMQBB0kV4q7xPWP%2bmsZdmC3p%2bPn/VnjZrAeeEknxdKNzhFEFQdHAA6p%2bFDiZ51kSS%2baZgCBL5pBiml7u3WW9K/sz%2b0ls1Cm0paOqV9WDcHlMq/iJZfa1ZQeQUy0JI3rHdD84Yd8GdiAr7u0SnNryey8XQn1rGGLbChfJgBFjw48Y/aqliHKQcnASIUR0N5x1fQCN34bMCVokh9dsX1aJKxlvwDUfQgzdVnyqwq0V5/hYf0OxpyyNPX5A7kFi/a%2bAyQ3i8D2NsDTYy%2bKQgApbI0XLNwpaCWW%2bSAFykekLLuag2M3%2bNnKOVRzVBbMcRAs2AdcGS0LsBlZh2T7pS6X3n0e/R98VjS3xJgeUQoXKyJTt5wqGhh9b6UfDV4Yss7tloW5fVFzwOp%2bbrpLrckKWOrGGZ%2bL5VPFys9JlZQevthVyfsG9kId7RsZpam54klN6LQ6wQAbT/Vo88e/uJJMvPVuuJZboBGVUUa9Exw5Z8mXbFH4MrbEzMM9iSjQUnMFm5gfF7QxENfhOlQDT55IXf4n4Vm2BaVyaj/iSh6fEpg8LoeD5xSn1ReCj0mxVJxJYVzrA72XooR9HqmkAyxEmO6qwe0LDDLDdDt6BhCBWd87FOSaLJtnBlNyFom9AwP9v8I8UIqAYDKexFNH13UiLRWUWk1OPLS6W3yOQpAWtGji%2bL1lUOwysQtyBVXdBIISqpwjQwdQMGA0frujsYgEAJL6bvW5GkBWhf5VQFAhtDxkkDlk7j1sUqSIIzsubaA/MmHvj6DlFdFTlcDTlgg5f/UXq6lSn3Op5ydjVZNDVBEmROEtFO8V7oMucW92Ezp3UCCIFlJbba8DFdkKAaAAONO1HWJ0NEPgD05SwBhNIzG5wgwsodcSblw63X5LMKixdVQp69muYcIfv8z2MgCn96KswFYqHBmkHtQjAhUnm9LAN6gkj04DnAQvLdea6LtPcLYwS5g1FZHMgdh/JrsG/sjMx9/raFkRuR2Nbh3981qYf0MMFp0DDCfHQASBHIpSqvUTuu7STWoWtVdWCWt7xPrNMoVIe8JQlQ0EJANzE9K//6WSEp54goOda6TmDIDSBD66gZZ8Mo8WwYgeGkW7gaUDUYbtmkAyApSXxPcuzawKqQiSLJABPi8kAAMrFptcCQYDcMrcwkM5isY5EZ2Yzw4tH3DjP4sbqj%2bXa6sxJ20wQPVTeyAWQoUipyJ8lI4AC64y9bCrhCR3aRWDwg3oMvxA5ojPwAyFVrmvDvMTm6QxLOCsiL7PkdcLmBR5KFsoL/uN9T5fN4z1MHrDSUwlJANefkDkGp1a1Y8bRDE5zLMDlhbPA7lqa1wx/VZMD1aHXBWWQMAs9GrtcUB9yOQ8qIeUEX5vmJOAEZ1AOAH7hhPzqOBiGfablODdxpwJlccwP9gqUzX8Slx6dC6yga3FI1rVkw7Hb/XlMdKsmgMTHnbmH9TkHuJp2d/BnL5K8IPugO6QxkDPGOc/q%2bQXu5r1p0aAEfiOgJBpos2apAQ0ZnnKqwQigUa%2bjvr4K1NZYx2siZ3JmaBNXszpCALMsxzpTtngMgCiGqDdCu%2bbnLA5mQTDEVnwJbILMBmbdY0WcYAOg9Jp%2bLwGFR9FhD0zxYZL2IeFmSHiXU5fZg3Oznq4cEqlVKi7A/k2Ix8j8bcNJ2h97JT5Fh8uOPToXl1NaxFFqQU8oInMCgGKixfo7nBTRhAKfd/o3AMutZiTFmdDT8ptMArSHGysv5aoyA2qneuzlNFQeTD3D%2bz65oCKosVkeLD51E%2bB1mQTQWSLIzuokA4GJs1TVdyI80YCKg4a5boGoAfFxQyasrCQ1zXq7oSMtSyrC5YbR1Xi0tGVGqASKkMXalLjOAKu9lrtE3Nz5aa7fBAWw%2b83NcMRwcqNaDnGKdTwaZSryIGpqyc34kdLh7PLqZ8XAHqlbWwW2U1FiTkXIbbb%2b5CV8AvPYlR1ntixKYeH7apv60vUffckKti1FVxZ1J56sC82Fx56NrhvPU7YJXZrbZsGGSd3lZUjJqcm8i6olSmWeG22m3wKPYPr21rZuMzrS0et/nHc8HXFkgQFA0AZqBHs9d7HfG5sjdoIz1qolvImGGzKsHQcSBbVofh4gP/iPIcgWCPz6He2zf5bzkzaHUP0p6Q9tAcgUZO5Hdj6G%2b7UPnN1xdNp1hcKlkVKzl1sG4ba2upTaZRFxU1VN%2bfcNQGzgFc1dqMwKvMDryq/%2bIKLM7Q6opWqfqQAb7Hstidac%2bOX5uTJPVwCOWp3nnEbJ4bAHtcrtYj6Dsn3G5BZd%2bm5mICswMFyKmVeUB9Ng1TRKDxoP%2b/vDtqdVVu3oArt2wKdjf1eZ/q6VB/h9Y9pleWzQICFfbNumKkRlagqCgrxoTSTHwoXnzswec9NM2GyXp4srDQpivwllB9I1p%2bw/j15gW6QHy2nwk6EOxxOUucycZVziRjDz5/O1r9QdzJvYjyCO6gBJ9bJt%2bbYnX9wFg6BVNNWzxE7b1DDZqyVDDNCPHorB1CVLli4YPK1vi0u0/G6dRZPcBu7BJ3NhBIJ/D72Q8IwL1dBnRPns6TM8mlT/%2bW%2bcGb1wT0CfOmD91fRcGWf0Dq7ysrd8DPett93%2b/sVGnwccC%2bkdfxZPmxKj8T5hZ2yo4pO1ZHZ658TFml%2bkOUX6PciY9Lcf1n2vcVhpVhyAJB%2baz5fX6%2bP0dCtr9rZBnCGE61AhVMDuZfuCZmL0EGRFSmt7IaIs3sXJuF1Rt2hb6C4lH1nR2N6vN9rfBtjOzkCnWVQzC0sR9cDVvZ2aI7WnpZu0uvf6u1B%2b5HuWtTL%2bxp7vNOtAySG70IUxVrph01q1HROHSNf8H188HHiiwJV501fFupWfyfynCKNOJakclZwQFh6eUbFf9OinMALM6hnLJd1MHNbKraoZKS1xaMwSv9LUzxpLxxlgUo9c0j6o2mMVqnDTfffuWsXylx1aBURyAYJGEwWs2fd9oMMFlpOG9/q9cMkNKGdLMSJgB4OqtkktKclzLA9SL/92EapDGZvvhZgHhyy3ZSZfgEfTey4pJpZ22YFy2NShugux1BQIUduO2sMVyQP6zgyPphgv7/jPJputVFhY6KyqqyyqMhqX5AOn%2br7FTpO3D1ZWBPgN97k9gHi0epJsVwUfylmN3aQeG6jqyPCnhxW5XKymHowpVnHaEqRmOerJIpAuApBrjVGZ66XqF9XRwAZJjseDCKBGDKWLqLFPCkCQXORogB4nu8mcUTBEKGngWrzK4Lq3x6IbeEsZz9WgVtvyIO1IsHvQgASBY4PcQsXJ%2bj/WRZlbC1Zoo7F5gFa9e79f5/FcpJeeCLwQCNBQQmgppVTCAoRr4/zroM4%2bQFpL/FrtERD7DUWLpz0eivE8kCr2ABO8eXiSxIMTlZEL4gf6sKBwwpBVN0AML/lbsJAApai6j8rFjAWeDM0scCo9l%2bAfzfTOnPwTNBwXAEHszvM4vG6eB86YvLgFAseIbXHEpYBjuOC8CCVDMLgOHCEvFBgUtdfBY4KQ5QPEAWTFCazAyoCy4ECLr838joj/5/Dqwv6gJFlxFYXfALzkRXWJrFQZXoeS6AsBJD/5cMeJT7v9OTdg6srwdBMMwn3G31BWFBFgYdmYNxvRQP4H1RrvrOGQMCY4FkwY9EOR6OTNBi0vn1f4vzhgzrGDu4tHOrPATVGGqG1U2PrxUsCOeluXLe/F/2/72y/D3XygewADtF4XYPcSaKcrzQeV6UR9op0v%2bfFHT0pJ8HBnDl/WwTjIiVLMiqdJ5r5R268tfxJdzeJ6joO6cBMFSPwFiwix7fxWMBZ0HquWRBUdf9%2bvSXSs2Pv/09PwAI5QULaM7gPIGPrxTHFJZpdZzL9GfXkMad2Zn/m5UZOqDzpXxQXTAjWOAUGWHJOUuJqWbefCDqsgN8TpSm3jTzeQZADE3I9YQL/hVd8ouSBeekVU7j6U8q/1WUI4KC55X%2b%2bmAomiXJgnZRmyw5J7EgzTyq9/8Civ46/4cLIaJTlJXh26mmUZmeFz8lplkn9ADsWszx11lcTCVToqwLSgL6FNPoIvm/hZeaVVVPy1rgN4s5/lqEjCBnBS%2bwYU2JmzFg0VrlND79kf6/lKLvYo%2b/FqFJksPTFD0LFgeAgkkd/ZWKczT%2bOssmSXOD74nCKJx6g0WJBWnFdn%2b9bVbuk%2b3vRaB88NhMpuVIWR6nF511gwSaL601jSyhaHsOx19nHAz1KRGPa0ywgGWFjLPpEnn9L5sfJVHSLu2iUT4wJWqFkUW5XM4OU892VqBLf02s6LBQ96dcVABobGSxgBVGTWJmwViw1nqGKTE1cPz1uBx/n/f6f%2bHDU5kNfqdv4dPO5FRaqsmfSzGaXobbe%2bX4K%2b1iY0Cga8q6wHhWKTGTz92l9W8i5WkoebH5f6i5oZEPap7gZ7Gc4avMZ/B/nKwqsuvHX1vO8/jrbMtjigse7GKXi242/PSu/lg9wM4A0zl5AcBP/eMv5WJlAOhccyaLp0SHPiWeRvkbcPXHl1E%2bkeOvC13/nyIAUnYSF2I41bVmxWdCl22wOvd2WFyXnX7qKx3Tp78MNv4yY/truTD9/1yX2euvPKH7lmhWUIrSVuT09JbvhBarUnLaAGw0ObAL1MZfTu7/2ARdFPR3albX34aXgo/zcLve6oSOIkVttSre7rJJaLXyS2wWrrzZbrgZXcBq1sZfv6K0gjvy8rLTGXAg59nHA/bNFVfAiI8rUXG0utqO0lqkkOLeNgSiu2wKmq3OxAUDsKlMMWSLS9/yLcoVGRblWIrFRTtT/UHGOfvGB06/xa7wZlmenksRFs/G58pR8U1Wp9rhV1xtszpnOkvGoCXxBtkAAAr6SURBVAsZ0FLk3NNk4f/z1IL%2bGi0OQ4uV%2bz%2bu1jZEsNTq9KwT1k8RB5BqdgoaKiEY4Tzl47QQ9xGlnfKeQ/8VZpLmFOzy8LUNmuLk71xxFA9ZvbdiF7QWOfei5XPPqAhqL%2bL%2bjzu4dTMGEkTXQ/TCqKoS1cx4ELni1rZUMwdlrThAklRxiZzfT0PdKnPq59LM8nsV7YZMNACU4Gvk40TzEIp7e9BYbcUuAmZ3bZGDXVbbaVUiGk7nfEGDuPbGbLJfgl%2b0t6t0AneiTFNQQWBoxwQI7VxtsipQhwdE1qCDM6Og20COvP9HWE4P0lqhlAQrRfecZFUmfsc6FIvw7Qbh36Q083ErU9wnFPeR4nSceLz/0VzkSNbc2XoGZXCjQKvWPPp3%2bAUPtrJ0sgsEEJRefHgQMuCgNQgQBTqLWPRlj/HAKPBAI0odHmy1AIn8tZSB5YRiVLAYX6PtMitXlN5Xzz6r0PczoDvYflhUV6W10dc97WhpSnMdxW5S/ElMd2v9DHZGNFl5HYPxwGArdp8ZCPTXVOS4alORsw938hLttKloAhosbt8mKynL6MgOlqSVhFlLYSJf7wgASYoiJOA5UpaBK5Ql8TKlrah0kQvI2qQ4PncIj%2bluDHLXyWPtLlbCW0T1%2bnLrJMazMxiJNQvl63HtsAbW0GWFE7Hfqen479uqB6CreNSLQMBG8xgBggWHi4HQLpQJBocpxUHSW1PlVFZ8fkWZsjPkcm2oMDGPGNhTPkVKH0P5KSpei%2bz6J3lcnUUuUjyixjwqdECrW89wHlhjUQwNRfzDlUUuQ3ORM2yobFCrpU/25r3u2WKG99qLvb9uroGHatthvLIftpaMALFio9kFtYUIDEo9bjdiCm1GuiNF6XWVM4PAcrGVKMxSFirKrbsLKIpzl3Ni7HG%2bhgrfgywsbbY4vxYYrJ0RZPEG66hmvCbLIv3vls1VdkMdgtFaNGo41G1i/vRRpyVqf1eh72B3IXzavV493pMPJ3rzcbsA/tJdBO8PNMJLm9vhyfYeeKBxK%2bypGQBlwxAMlI9AX%2bmo2lPiIFagdZ0nkQknUI7i9n6U93D7VVTyKVT2m7h2tlgdWajQldHZXQHH1VWkhFFwQyuH3VA6abgX2/Z6q2KoLx0/d2eGD3SZIsSaO7PFCge6Cr0o6iddhcDFBJ/20g%2bs6257GfPfEUZ3iR0ZrfOoYy3w5x2NDxtiHvrC9srhKzFQfbXBMvplpOtl86VlUhqtHdYkqN2CxtlUdh4ulDzQud5woFsDoAu2FcPBrsIZ3FYPdpuA2IDbcLDHrP2QmrwbzKf9YBL77SAfuxHSbXsn1H52WCYM7VZXeAcpW%2bRcIhVmtBZKN6Klm4vP89WhB7rWG1BJCcBOtb%2bYFPYgCCoprwGAq9dRFfDbAiHEA7saCRgWad/e1nLJr3vaI1Kzdxq6SkYNncUjjM595mFhZYfhgv%2bhcnoAvusTAHAGcAAkCDMjlbN%2bPF0n/N4/Wic20p1gTdrZB1f1ElBqwkCxicc1BhitMKjj7RcdAD%2bQAARb/5PO9XB8eykCUDvr1%2bL5/xfCf5JDW6fq6fV78PE/yH3RHWB0M5RKN0PRvUFKpbhJysbkYgDgYQ2AEAw4vNki7%2bsNzQJxV6gAwUvugNsHUIbxtaWzzku5aiLwebo7LJzdIeaim6Sq%2bY1TSh1/j7vWAAN15w0AHgO6yQUKAwBgIHSa4ORwxalZ4HcDDgLFBLr9le4EVWpm8LmnUBrwM5HgrAr5fxuji4URMPieJeLWuQgEBgGqEVIdrgE2%2bSMDTJgZYGf8d7Db4k%2bD3aY6AgADoAe31QPdHATpBrQe6jXPUn4WG7jyEggf3QvMtnc2CDCqvSivo9yFshHlBrpLFNPsaTU3BIy6GK6DioWLNVYGP1r1gVADAVlwZGvxHP%2bHSBAjXJIRjB0EBAdjciMHg9xknN0%2b%2bynK71F%2bjvItfL8D12b8Tgt%2bxxp8nIDuEYPPxaIkorD/fxifN8BY2dkwwGz4pLPQcLiHV4Oo6NMzW4q0QDgXCPJnLub6OZ6QQZKLlwPCQPGRW7HsMdXAQdnTxFd6TGDR60qNT/c9h/GzzSy4omssZjWY4UEAUFGZClUdKwJAoKDoof8pyu3/vwdP9dsAQaCoQiQz/LfOa8BgzOBs8TLFJZO4%2bBhrdrK71286a%2bWx1DUcaMujYChd4S7YXkKxYFpjQFfhbBDE9tGtRaxG4IyonQsMVbdqQmCofmYEM%2bVUclLEk4GzBuBgp1mygLnB/joTbf%2bMgdDNymKfcAP1YFBglGyQaZJqhZnhSvZfaWm/C8BA0YDhCmrPCfEDRrfS0w8oUNaYYStngk8LrC4RT3iaHVy0dKgPiO9sygvD7e9Qb3AEI78OCJUyhN419DGCCibeO2BH2WeFo5hVTgyUwfSOcmKJ6rFvAO9olao6bUdVV/URBOUQAnAY12n2Qy4UB0ixW5sxSDYJaeTxgccByRCPYMDWRQEAeBoMAEFs21D%2bCttK4GivhTpFD0uTCIZIkxKIWWBIQBgonCWqYI6KAE1jSt13eLP1N0e2Fv0ImXP79GDZ5MmhCjf2HD0wVleJ1m9DaUUlbSirUN4UZbaXsYID0LNoRdGhdqueCWEICI8JnabL8XE/ygde9HeqFj/tYazwsqKp2%2bRlgJCC3RorZoGiPU/1BG4fRpYcQ3Ydwe8SYB1H2Yfyx31t%2bbWzjKRUV8AuCnyovGSAq2bTolaG72yvMKCFBQiFJBF%2bNhReigdqRfk%2bygFKl4Bg0HqUuwkp7BHuQuW0V8cONQAEv/iEqAQIudsJdB0YLKP3sQNB9/mc%2bs0GbKBsn0PF3xV1w0kBQO2il8dgxtqgG9vkzkI/G0Sa1LnGP6Jko0yg1Z/B9WNiBTGE4gatpAgpJRT0iC7Tw5jDGcOU19hDYPH1pOhJ7pEpGnP9EsGCSaH4CeECZYZz%2bXegy0wjMz8juk0R0jWCUukX8EBXoJRibBjB9QlU5g1cjx7D7EAlNrFFFYw5js%2bRtQm0I372iNXkEXOJXbxYK6TeIEIAkEk/rcPqBN5xFpyXrvFYvVkLkgeZa3BW4HbEoS5zyMbmUGsWxZF/wffdjOBV4mpHeQgVIsa8hbIPtw%2bK1Q8CBlngAHTqAAgTAHwV5QjLBNwV1p73FhoGBgz7uwqE5deju5gkIOEcFBRRVJ2y%2bOo0XUKsOdhjvhzXr%2bDn9vIsw7KLx4cuhN9j4YCTC4gfU1Gq/gaVfotlA54OrzFcDH8He4tRqQIDDFL8MNNBo7B5ox8YtCTJga71YSHqkFuBd6IzxARyC3zuJpmW2YxgvE5mg1%2bzHsFVfRJriasNF%2bsfBVPpNvvRbY52FBg%2b6i5kDRilW55qC5eIVjybJtJE/0O8jjiBzPiaDMIq/aKMizc9CMB/igD4F9kVfib/DohYIpT8KsoRUv4ot/57BzpMl8kqlU2LlBoZCG%2bHO9uAuYK9KsLwWf6Thddf29aRm7xOcWC6j85NmJ6n5w93W8MozoDDRopLBqwV/u/is8bq8M8sAKze6DKHCzf4KSnv4fOI%2b2QG2N9boKsG%2bQ8rgdP2Be05h%2b2zy4BP%2bkpYlBdseIziABVRuN0jiyAqyGikDq5aCQJPiQ91siHqZ/rvYGfAiZmHPVt5kUSn6fSDGkF9MQtk7hAmlf9MgxB0ZuphUQEeR1kqMwC6iOF/7V/QWP7bMFROALy1vzVPTqcM%2b7rW/e8F4KDoL0TFZxMMsMsK8JPehVn//wMC5pLve/d2gAAAAABJRU5ErkJggg==' /%3e%3c/svg%3e"></p><p>Susan has always been a good sleeper. She always falls asleep within fifteen minutes of going to bed and wakes up feeling refreshed. Susan doesn’t really think much about sleep, it’s just something that happens when she goes to bed.</p><h3 id="why-does-george-have-insomnia-and-not-susan">Why does George have insomnia and not Susan?</h3><p>What may not be obvious but separates George from Susan, is that they have very different beliefs about sleep. They experience precisely the same situation each night; they both go to bed and try to sleep. Their thoughts and feelings in this situation, are very different.</p><p>George worries that it's going to be another night of sleeplessness and that he will be dead tired at work the following day. He thinks about how a lack of sleep might damage his body and wonders if he will ever sleep well again. The minute his head hits the pillow, he's wide awake. His mind races and he starts feeling anxious and upset. He's exhausted but can't seem to fall asleep. After spending quite a bit of time unsuccessfully trying to sleep, he pulls out his phone and listens to a podcast to distract himself. He finally falls asleep a few hours before he has to get up for work.</p><p>Susan goes to bed and doesn't think much about it at all. She is fast asleep fifteen minutes after she turns off the lights.</p><h3 id="thoughts-behavior-and-feelings">Thoughts, behavior, and feelings</h3><p>George’s sleep problems started when the company he was working for experienced financial trouble and had to downsize. He worried about losing his job and not being able to afford rent. George found that he became preoccupied with thoughts of worry most of the day and even more as nighttime approached and it was time to sleep. He tried, as most do when facing problems in life, to think his way out of it. After a while, George noticed that his sleep was getting worse. It frequently took a long time to fall asleep, and he often woke up multiple times every night.</p><p>Fortunately, George didn’t lose his job. The company is now doing fine, and he doesn’t worry about it anymore, but he’s still struggling with sleep.</p><p>George’s story is typical when it comes to insomnia. It's common that some initial stressful life event sets it off, but the problems persist even when the stressor has resolved. It is notable that the event that causes insomnia in the first place varies, but when insomnia has been established, people begin to behave and think the same way.</p><p>CBT does not concern itself much with what initially caused George's insomnia. Instead, it focuses on the thoughts, feelings, and behaviors that maintain it. In George's case, we can see a pattern of him worrying a lot about sleep and the consequences of not getting enough. After a while, he starts to associate the bed with feelings of frustration and anxiety.</p><p>When George's thoughts constantly revolve around sleep and the consequences of him not getting enough, his mind will interpret this as a threat. The brain's threat detection system doesn't make the distinction between thinking about a threat or actually experiencing one. It does what it’s supposed to do and tells the body to get prepared for the threat.</p><p>When the brain signals the body to get ready, the body reacts immediately. It goes into a state of arousal where the main goal is to be prepared to handle anything. Arousal is, in many ways, a state that is the opposite of sleeping. Your heart beats a little faster, your breathing starts to increase in frequency. Pupils dilate, and you are more vigilant. Because the brain believes you are in danger, you go into a mild form of fight-or-flight mode where your senses are heightened, and muscles are ready to spring into action.</p><p>The most convincing and compelling way of learning that a previously held belief is false is experiencing the opposite. George has the view that he has to put in a lot of effort to get to sleep. A goal of CBT for insomnia is going to sleep without thinking or worrying too much about it. We want George to be more like Susan and experience falling asleep without effort, and as a result, learn that he can fall asleep easily without thinking too much about it. To help people get this valuable experience, CBT for insomnia uses something called sleep restriction.</p><h3 id="sleep-restriction">Sleep restriction</h3><p>When people who struggle with sleep hear about sleep restriction the first time, they immediately think it's counterintuitive. Why should you restrict your sleep when you want more of it?</p><p>To answer this question, we need to learn about sleep drive. Sleep drive is the force that makes you sleepy when you have been awake for a long time. To …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sleepedy.com/cbt-for-insomnia/">https://www.sleepedy.com/cbt-for-insomnia/</a></em></p>]]>
            </description>
            <link>https://www.sleepedy.com/cbt-for-insomnia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309815</guid>
            <pubDate>Mon, 01 Mar 2021 23:13:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gradients on grids of pixels/voxels – forward, central, and diagonal differences]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309398">thread link</a>) | @bartwr
<br/>
March 1, 2021 | https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<div><figure><img src="https://lh3.googleusercontent.com/BWwSXvV4LN0Ta6HG1XenEDTm5TnwsPcdWZnJbaNH0aYWJRogW-V7D0BujuJwuDa4c6TcfNzLklDJFzeHNl4jNSXiCjr19Qq8scpGCZrnktYSP6Ns_3x1yMI10rKXZyzghqoySdCt" alt=""></figure></div>



<p>In this post, I will focus on <strong>gradients of image signals defined on grids</strong> in computer graphics and image processing. Specifically, gradients / derivatives of images, height fields, distance fields, when they are represented as discrete, uniform grids of pixels or voxels.</p>



<p>I’ll start with the very basics – what do we typically mean by gradients (as it’s not always “standardized”), what are they used for, what are the ypical methods (forward or central differences), their cons and problems, and then proceed to discuss an interesting alternative with very nice properties – <strong>diagonal gradients</strong>.</p>



<p>My post will conclude with advice on how to use them in practice in a simple useful scheme, how to extend it with a little bit of computations to a super useful concept of a <strong>structure tensor</strong> that can characterize dominating direction of any gradient field, and finish with some signal processing fun – <strong>frequency domain analysis </strong>of forward and central differences.</p>



<h2>Image gradients</h2>



<p>What are image gradients or derivatives? How do you define gradients on a grid?</p>



<p>It’s not very well defined problem on discrete signals, but the most common and useful way to think about it is inspired by signal processing and the idea of sampling:</p>



<p><strong>Assuming there was some continuous signal that got discretized, what would be the partial derivative with regards to the spatial dimension of this continuous signal at gradient evaluation points?</strong></p>



<p>This interpretation is useful both for computer graphics (where we might have discretized descriptions of continuous surfaces; like voxel fields, heightmaps, or distance fields), as well as in image processing (where we often assume that images are “natural images” that got photographed).</p>



<p>Continuous gradients and derivatives used for things like normals of procedural SDFs are also interesting, but a different story. I will not cover those here, and instead recommend you check out <a href="https://www.iquilezles.org/www/articles/normalsSDF/normalsSDF.htm">this cool post</a> by Inigo Quilez with lots of practical tricks (re-reading it I learned about the tetrahedron trick) and advice. I am sure that no matter your level of familiarity with the topic, you will learn something new.</p>



<p>In my post, I will focus on computer graphics, image processing, and basic signal processing takes on the problem. There are two much deeper connections that I haven’t personally worked too much with. So I leave it as something that I wish I can expand my knowledge in the future, but also encourage my readers to explore it:</p>



<p><strong>Further reading one:</strong> The first connection is with <a href="https://en.wikipedia.org/wiki/Partial_differential_equation">Partial Differential Equations</a> and their discretization. Solving PDEs and solving discretized PDEs is something that many specialized scientific domains deal with, and computing gradients is an inherent part of numerical discretized PDE solutions. I don’t know too much about those, but I’m sure literature covers this in much detail.</p>



<p><strong>Further reading two:</strong> The second connection is <a href="https://en.wikipedia.org/wiki/Wavelet">wavelets</a>, filter banks, and the frequency precision / localization trade-off. This is something used in communication theory, electrical engineering, radar systems, audio systems, and many more. While I read and am familiar with <em>some </em>theory, I haven’t found too many practical uses of wavelets (other than the simplest Gabor ones or in use for image pyramids) in my work, so again I’ll just recommend you some more specialized reading.&nbsp;</p>



<h2>Applications</h2>



<p>Ok, why would we want to compute gradients? Two common uses:</p>



<p><strong>Compute surface normals </strong>– when we have something like a scalar field – whether distance field describing an underlying implicit surface, or simply a height field, we might want to compute its gradients to compute normals of the surface, or of the heightfield for normal mapping, evaluating BRDFs and lighting etc. Maybe even for physical simulation, collision, or animation on terrain!</p>



<div><figure><img src="https://lh5.googleusercontent.com/u5cS-rFvdRrpN6iFTGYqDYyF8wMLCtB5-5ir2gQVMaQo8DmURyVdqF8Fyedcx9VW5boiVP8QuQZkL8zAEqG8_TYrkqx6b0bkWajLS-8IJykhlmhtxTH_YEXw_xivXSbd_2rPVLcX" alt=""><figcaption><strong>Left: </strong>an example heightmap image, <strong>right:</strong> partial derivatives (exaggerated for demonstration) that can be used for generating normal maps for lighting, collision, and many other uses in a 3D environment.</figcaption></figure></div>



<p><strong>Find edges, discontinuities, corners, and image features</strong> – the other application that I will focus much more on is simply finding image features like edges, corners, regions of “detail” or texture; areas where signal changes and becomes more “interesting”. The human visual system is actually built from many <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1350218/">edge detectors and local differentiators</a> and can be thought of as a <strong>multi-scale spatiotemporal gradient analyzer</strong>! This is biologically motivated – when signal changes in space or time, it means it’s a potential point of interest or a threat.</p>



<p>The bonus use-case of just computing the gradients is finding the orientation and description of those features. This is bread and butter of any image processing, but also very common in computer graphics – from morphological anti-aliasing, selectively super-sampling only edges, or special effects. I will go back to it in the description of local features in the <strong>Structure Tensor</strong> section, but for now let’s use the most common application – just using the gradient vector magnitude, used for example in the <strong>Sobel operator</strong>: <img width="131" height="55" src="https://lh4.googleusercontent.com/XNZ1Arqp0sBJFnwkaJY9qxwOnn75NM57llXbo-aLmwwwPLxv93Sr8qWfaOswcKcWnvc1Hy-HGWKrsW9KHj10G-UkqOICr3SYO_Q6cXWvYBIZu5EALhRiSfp-mqrHpg6rjRFXJpAP">.</p>



<div><figure><img src="https://lh6.googleusercontent.com/B3C3hX34jil9a3GVJJY8e051jxZV-K2v2k0UqMIi9MkajBeYnB8LhKFLMlhRph-8Oe8-R5WyPzWyA9W6X6FISmSwvJ4hPf_adGwpA1Niwpn4qCNkLKYVUTk3ZK5rdLb1guiQu5rN" alt=""><figcaption>Gradient magnitude can be used for simple edge detection in an image, but also many more (described later in the post!).</figcaption></figure></div>



<h3>Test signals</h3>



<p>I will be testing gradients on three test images:</p>



<ul><li><strong>Siemens star</strong> – a test pattern useful to test different “angles” and different frequencies,</li><li>A simple <strong>box</strong> – has corners that can immediately show problems,</li><li>1 0 1 0 <strong>stripe</strong> pattern – frequencies exactly at Nyquist.</li></ul>



<div><figure><img src="https://lh5.googleusercontent.com/y4CZ84at7ie-Rg3S_l1OQLy0qhoBmxHJXkZukiypUwb55r4dQWIPwGwG1qsdNyKCYqlhkG1TBsaYxOFTXhOFNsCIh47xyYCF5tvX6EhCAXAqORWSOOcWuxs0dF2nSyjyk_4NQan_" alt=""><figcaption>Test patterns / images</figcaption></figure></div>



<p>The Siemens star was rendered at 16x resolution and downsampled with a <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">sharp antialiasing filter </a>(windowed sinc). There is some aliasing in the center, but it’s ok for our use-case (we want to see a sharp signal change there and then detect it).</p>



<h2>Forward differences</h2>



<p>The first, most intuitive approach is computing <strong>forward difference</strong>.</p>



<p>This is an approximation of <img src="https://lh5.googleusercontent.com/hPi-mgITwovkqTtAMg1LBk4GVXtKJqG15oSJn0MgJqljSZYk1CiM-mHoGYsW36452xxG3f2X9-72nQ2XVrTknF9v0IanFpTiRHsoGzPk-L_uVBComQrtujBayBlq_uDvpnF5HNVF" width="22" height="39"> by computing f(x+1) – f(x).</p>



<p>What I love about this solution is that it is both intuitive, naive, as well as theoretically motivated! I don’t want to rephrase the wikipedia and most of readers of my blog don’t care so much for formal proofs, so feel free to <a href="https://en.wikipedia.org/wiki/Finite_difference">have a look there</a>, or in specialized courses (<strong>side note</strong>: 2010s+ are amazing, with so many best professors sharing their course slides openly on the internet…). It’s basically built around the <a href="https://en.wikipedia.org/wiki/Taylor_series">Taylor expansion</a> of the f(x+1) – f(x).</p>



<p>This difference operator is the same as <strong>convolving the image with a [-1, 1] filter</strong>.</p>



<p>It’s easy, works reasonably well, is useful. But there are two bigger problems.</p>



<h3>Problem 1 – even-shift</h3>



<p>If you have <a href="https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/">read my previous blog post</a> – on bilinear down/upsampling – one of challenges might be visible right away. Convolving with an <strong>even-sized filter</strong>, <strong>shifts the whole image </strong>by a half a pixel.</p>



<p>It’s easily visible as well:</p>



<div><figure><img src="https://lh5.googleusercontent.com/Mep5NBimKpkG1wHi1JFZ64tEeZH-Bavx8qZ9abnfIG8f_-vAvZERVKQs84hUSbPSiYkjVmBzyjWbTgL2oSWWyQTwuO1z2xv98LOjHp4pHsD4C09msAmnU9Z5U5Q4VO1rdAIgI24Q" alt=""><figcaption>Images vs image gradient magnitude. Notice the shift to left/top.</figcaption></figure></div>



<p>Depending on the application, this can be a problem or not. “A solution” is simple – undo it with another even sized filter. Perfect solution would be resampling, but resampling by a half pixel is surprisingly challenging (see my <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">another blog post</a>), so instead we can blur it with a symmetric filter. Blurring the gradient magnitude fixes it (at the cost of blur):</p>



<div><figure><img src="https://lh4.googleusercontent.com/Ki309swxJtWYakp2nypvE4UjcgYC0uHBduyuyWzr_pamfzXFHjSlctrfAx1XPJYjk8LIECMlbRkvumjbT1TJkM225HiIggoy3lnu508mDUyDlHfRB2tog1VY82GLMcP61LK6GOO9" alt=""></figure></div>



<p>Blurring with an even sized filter fixes the even sized shift. But one other problem might have became much more visible right now.</p>



<p>Note: You might wonder, what would happen if we would <strong>blur just the partial differences</strong> instead? We will see in a second.</p>



<p>But let’s focus on another, more serious problem.</p>



<h3>Problem 2 – different gradient positions for partial differences</h3>



<p><strong>Second problem</strong> is more severe; what happens if we compute <strong>multiple partial derivatives</strong>; like df/dx and df/dy this way?</p>



<p><strong>Partial derivatives are approximated at different positions!</strong></p>



<div><figure><img src="https://lh6.googleusercontent.com/l11K2D7VeRoitc_dAIwMoC5WB4RPBdcKcdDtq4ysm9z-0LzJICmias8fhGIZQWvdEzJElkTp2xCMRxn1z5EbbYH5xb7Le2AlPFhr4ynlultytNqtm98b1n9d6f_Etu3mMTxpjUiF" alt=""><figcaption>Notice how gradient being defined between pixels means that two partial forward derivatives are defined at different points! This is a big problem.</figcaption></figure></div>



<p>Now let’s have a look at the same plot again, this time focusing on “symmetry”. This shows why it’s a real, not just theoretical issue. If we look at gradients of a Siemens star and the box, we can see some <strong>asymmetry</strong>:</p>



<div><figure><img src="https://lh4.googleusercontent.com/DxZNozMlWMM6xr2c3NejQXpHB9xbiwfs1GyRBeUBQIMoksEisVz5n3jGZs5zWrPZU6xeUvnBaalc3IPTIV8LDoYevY-ZirN-Gsc-XOLwBiGSRzUCuvqIqio3AcmvU5_b1eKzj2aS" alt="" width="507" height="502"><figcaption>Notice left-top gradients being stronger for Siemens star, and producing a “hole” on the box corner. Oops.</figcaption></figure></div>



<p>This is definitely not good and will cause problems in image processing or computing normals, but it’s even worse if we look at the gradient magnitude of a simple “square” in the center of the image – notice what happens to the image corners, <strong>one corner is cut off, and another one 2x too intense</strong>!</p>



<p>This is a big problem for any real application. We need to look at better approximations.</p>



<h2>Central differences</h2>



<p>I mentioned that “blurring” partial derivatives can “recenter” them, right? What if I told you that it is also <strong>numerically more accurate</strong>? This is the so-called <strong>central difference</strong>.</p>



<p>It is evaluated by <img data-attachment-id="4275" data-permalink="https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/gif/" data-orig-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif" data-orig-size="155,39" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gif" data-image-description="" data-medium-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif?w=155" data-large-file="https://bartwronski.files.wordpress.com/2021/02/gif.gif?w=155" src="https://bartwronski.files.wordpress.com/2021/02/gif.gif" alt="">. The division by two is important and intuitively can be understood as dividing by the distance between the pixels, or the differential dx, where dx is 2x larger.</p>



<p>When forward difference was an approximation accurate to the O(h), this one is more accurate, to O(h^2). I won’t explain those terms here, but <a href="https://en.wikipedia.org/wiki/Finite_difference#Relation_with_derivatives">the wikipedia has some basic intro</a>, and in numerical methods literature you can find a more detailed explanation.</p>



<p>It is also <strong>equivalent to “blurring” the forward difference with a [0.5, 0.5] filter</strong>! [0.5, 0.5] o [-1, 1] leads to [-0.5, 0, 0.5]. I was initially very surprised by this connection – of a more accurate, theoretically motivated Taylor expansion, and just “some random ad-hoc practical blur”. This is even sized blur, so this also fixes the half pixel shift problem and centers both partial derivatives correctly:</p>



<div><figure><img src="https://lh6.googleusercontent.com/QawQ4QcbqusIHhs7S0h2kekS4VQDqHCS_WizBd7dgstoHaLu5Lwj9bx_SbJImHNZnlc_aSs7FCzdYF0RW7oYjTTF3qzfoKiNENFh4yzTiYYt_GSO6lkFe-7lP2GpDs0G9XNYS52O" alt="" width="424" height="420"><figcaption>Central difference leads to perfectly symmetric (though not isotropic) results!</figcaption></figure></div>



<p>Problem – missing center…</p>



<p>However, there is another problem. Notice how the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/">https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2021/02/28/computing-gradients-on-grids-forward-central-and-diagonal-differences/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309398</guid>
            <pubDate>Mon, 01 Mar 2021 22:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create Mindmaps from Text]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26309253">thread link</a>) | @omegote
<br/>
March 1, 2021 | https://josetomastocino.github.io/mindmapit/ | <a href="https://web.archive.org/web/*/https://josetomastocino.github.io/mindmapit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://josetomastocino.github.io/mindmapit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309253</guid>
            <pubDate>Mon, 01 Mar 2021 22:22:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD: I love it so much]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309239">thread link</a>) | @aminozuur
<br/>
March 1, 2021 | https://sive.rs/openbsd | <a href="https://web.archive.org/web/*/https://sive.rs/openbsd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2018-04-20</small>
</header>

<p>
	The only operating system I use on my computers is <a href="https://sive.rs/itunes">not Mac</a>, not Windows, and not even Linux.
	It’s <a href="https://www.openbsd.org/">OpenBSD</a>, and I love it so much.
	So I figured I should say a little something about why, and how you can try it.
</p>
<h3>
	It’s probably not for you.
</h3>
<p>
	It’s not for beginners.
	Most people should use <a href="https://www.ubuntu.com/desktop">Ubuntu</a>.
</p><p>
	It’s not for people who want to click a button and have the computer hide the details from you.
</p><p>
	If software bloat doesn’t bother you — if every new Mac/Windows/Linux release you say, “Bring on the features! The more the better!” — it’s not for you.
</p><p>
	But if you’re experienced, like to “look under the hood”, and prefer software that does the minimum necessary, OpenBSD is for you.
</p>
<h3>
	What is it?
</h3>
<p>
	It’s like Linux, but has <a href="https://www.openbsd.org/goals.html">different goals</a>.
</p><p>
	It’s known for its focus on security.
	But, like a well-engineered house will also be earthquake-proof, you don’t have to be paranoid about earthquakes to appreciate great construction.
	To me, the security features are just a side-effect of <a href="https://www.openbsd.org/security.html">great coding</a>.
</p><p>
	OpenBSD comes with a secure minimal <a href="https://www.nostarch.com/pf3">firewall</a>, <a href="https://www.romanzolotarev.com/openbsd/httpd.html">webserver</a>, <a href="https://www.opensmtpd.org/">mailserver</a>, and an optional graphical <a href="http://www.xenocara.org/">desktop</a>.
	So if all you want is a few of those things, you do the default install, tweak one config file, and you’re done.
</p>
<h3>
	Why OpenBSD instead of Linux?
</h3>
<p>
	It’s <strong>uncompromising</strong>.
	It’s not a people-pleaser or vendor-pleaser.
	Linux is in everything from Android phones to massive supercomputers, so has to include features for all of them.
	The OpenBSD developers say no to most things.
	Instead of trying to make it do more, they keep it focused on doing what it does with more security and reliability.
</p><p>
	They <strong>review and remove</strong> code as often as they add.
	If something is unused, unmaintained, or unnecessary, they’ll axe it.
	If it’s unwieldy, they’ll make a <strong>small simple replacement</strong>.
	For examples, see <a href="https://https.www.google.com.tedunangst.com/flak/post/doas">doas</a>, <a href="https://www.opensmtpd.org/">OpenSMTPD</a>, <a href="https://man.openbsd.org/httpd.8">httpd</a>, and <a href="https://www.libressl.org/">LibreSSL</a>.
	This is great for security, too.
	The more code, the more chance of a bug that could compromise your entire computer.
	The less code, the better.
	Each new release seems to be getting <strong>leaner</strong> by removing old cruft.
	No other operating system does that.
</p><p>
	Great <strong>documentation</strong> is a top priority.
	The built-in <a href="https://en.wikipedia.org/wiki/Man_page">man pages</a> are amazing.
	So if you’re stuck on anything, <a href="https://man.openbsd.org/apropos.1">searching</a> the man pages on your own computer is going to give you a better answer than searching Google.
	(This makes it nicer to work offline, too.)
</p><p>
	The <strong>installers</strong> are amazing.
	The <a href="https://www.openbsd.org/faq/faq4.html">initial installation</a> takes like five minutes.
	Hit [Enter] to the defaults, make your username and password, and it’s ready to go.
	Then the <a href="https://www.openbsd.org/faq/faq15.html">software installer</a> is ideal, too.
	Just <a href="https://man.openbsd.org/pkg_info.1">pkg_info</a> to search for something and <a href="https://man.openbsd.org/pkg_add.1">pkg_add</a> to install it in seconds.
	(Which also installs all of its documentation, too.)
</p><p>
	Everything is rock-solid and <strong>just works</strong>.
	Hardware I couldn’t get working in Linux just works on a first try with OpenBSD.
	And because they don’t stay cutting-edge, keeping a cautious pace, it keeps working and doesn’t break.
	The whole system is carefully planned and consistent, instead of a hodge-podge of bits and pieces.
</p><p>
	It’s all free and run by helpful volunteers.
	If you <a href="https://cvsweb.openbsd.org/cgi-bin/cvsweb/ports/">searched ports</a>, but some application you need is missing or out of date, just contact the maintainer and offer some assistance or money to help get it updated or added.
	I’ve donated $3850 to the developers to help improve the OpenBSD port of <a href="https://nodejs.org/">Node.js</a>, <a href="http://elixir-lang.org/">Elixir</a>, <a href="http://www.erlang.org/">Erlang</a>, <a href="https://apps.ankiweb.net/">Anki</a>, <a href="http://www.ledger-cli.org/">Ledger</a>, and <a href="https://www.qutebrowser.org/">Qutebrowser</a>.
</p>
<img alt="" src="https://sive.rs/images/openbsd.gif">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/openbsd</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309239</guid>
            <pubDate>Mon, 01 Mar 2021 22:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National Security Commission on Artificial Intelligence: Final Report]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26309059">thread link</a>) | @infodocket
<br/>
March 1, 2021 | https://reports.nscai.gov/final-report/table-of-contents/ | <a href="https://web.archive.org/web/*/https://reports.nscai.gov/final-report/table-of-contents/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://reports.nscai.gov/final-report/table-of-contents/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26309059</guid>
            <pubDate>Mon, 01 Mar 2021 22:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula 6.0 “Mutara” Beta has been released]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26308596">thread link</a>) | @amarti
<br/>
March 1, 2021 | https://opennebula.io/opennebula-6-0-mutara-beta-is-out/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-6-0-mutara-beta-is-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://opennebula.io/opennebula-6-0-mutara-beta-is-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26308596</guid>
            <pubDate>Mon, 01 Mar 2021 21:22:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Sliding Window Pattern]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26308368">thread link</a>) | @franky47
<br/>
March 1, 2021 | https://nan.fyi/sliding-window | <a href="https://web.archive.org/web/*/https://nan.fyi/sliding-window">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><p><img src="https://nan.fyi/avatar.jpg" alt="Nanda Syahrasyad"></p><p>Nanda Syahrasyad</p></div><p>March 2, 2021</p></div><p>After multiple failed coding assessment tests last summer, I enrolled in the <a href="https://www.educative.io/courses/grokking-the-coding-interview">Grokking the Coding Interview course</a>. The course was different from other data structures and algorithms courses because it focused on common algorithmic <em>patterns</em>. The main idea behind the patterns is this: if you're able to <em>frame</em> a coding problem to match one of the patterns, you're well on your way to reaching an optimal solution.</p><p>While the course itself is incredibly informative, I felt that <em>visualizing</em> the patterns themselves makes them just a bit more clear to understand.</p><p>In this post, I talk about the first pattern that they cover — the sliding window pattern. We'll first walk through a problem without the pattern, then we'll try to iteratively improve our solution, revealing the final pattern in the end.</p><h2>An Addicted Data Scientist</h2><p>Let's pretend that I'm a data scientist that absolutely <em>loves</em> chocolate. As a data scientist, I <em>naturally</em> keep track of the number of chocolates that I eat on a daily basis. One day I wondered — how many chocolates do I eat on average over any consecutive 3 day period? (an every-day question to ask, of course).</p><p>I could do this by hand, but I'm lazy. I also want it to work with <em>any</em> period of consecutive days <strong>and</strong> with any number of data points I may have. So I decide to write an algorithm to answer this question for me.</p><p>The algorithm takes in two parameters — a list of data points <code>chocolates</code>, where each number represents the number of chocolates I ate on a given day, and a number <code>period</code> that represents the period of consecutive days I want to take the average from. The algorithm should output another list of numbers, where each number represents the average number of chocolates eaten over a consecutive <code>period</code> number of days.</p><pre><code>averageChocolatesEaten(chocolates: number[], period: number): number[]
</code></pre><p>For example, if we give the algorithm the list <code>[1, 2, 3, 4]</code> and the period <code>3</code>, the algorithm's going to return the list <code>[2, 3]</code>. <code>[1, 2, 3, 4]</code> breaks down into two 3-day periods, <code>[1, 2, 3]</code>, and <code>[2, 3, 4]</code>, with an average of 2 and 3 respectively.</p><p>How do we design the algorithm?</p><h2>First Approach</h2><p>My first approach to this would be to follow the steps logically:</p><ol><li>Break down the list of numbers to sublists with length <code>period</code> each</li><li>Take the average of each sublist</li><li>Put the averages together</li></ol><p>To build the sublists, we repeatedly take <code>period</code> elements from the list until we hit the end of the list:</p><figure><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p></div><p>[]</p></div><div></div><p>1<!-- --> / <!-- -->8</p></div></figure><p>Since we're already going through each sublist one at a time, we may as well count the sum (and subsequently, the average) as we go. Once we've done that, we have the completed algorithm:</p><figure><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p></div><p>[]</p><p>sum = 1</p></div><div></div><p>1<!-- --> / <!-- -->7</p></div></figure><p>That was easy! We’re not <em>quite</em> done yet though. We can do better.</p><p>On the top right of the animation box you’ll see a number. This number represents the total number of steps the algorithm needs to do to compute its result. Given the list of numbers <code>[1,2,3,4]</code> for example, the algorithm needs 7 steps to get to the final result.</p><p>Let's see what happens to the number of steps when we change the size of the inputs. In the box below, I doubled the size of the data to 8 numbers:</p><figure><div><div></div><div></div><p>1<!-- --> / <!-- -->19</p></div><p>This is an interactive demo! Press the pencil icon to change the values of chocolates and period.</p></figure><p>Notice the number on the top right again — it jumped up to 19 steps! It makes sense for the number to go up, but maybe there's a way so that it doesn't go up <em>as</em> much as it did.</p><h2>A Window of Opportunity</h2><p>Here's the algorithm again. Do you see anything that seems wasteful or unnecessary? Here's a hint — try to see what happens when we <em>transition</em> from one sublist to the next.</p><figure><div><div></div><div></div><p>1<!-- --> / <!-- -->13</p></div></figure><p>Let's look at that transition step one more time:</p><figure><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p><p>0</p><p>9</p></div></div><div></div><p>1<!-- --> / <!-- -->5</p></div></figure><p>When we move from one sublist to the next, we are (quite literally) dropping elements that we have already counted, only to count it again in the next iteration.</p><p>This effect is especially pronounced when the size of <code>period</code> is close to the size of the list of chocolates:</p><figure><div><div><div><div><p>1</p></div><p>2</p><p>3</p><p>4</p><p>0</p><p>9</p></div><p>period = <!-- -->5</p><p>[]</p></div><div></div><p>1<!-- --> / <!-- -->11</p></div><p>The numbers in red are double counted!</p></figure><p>It turns out that no matter what inputs you give the algorithm, this approach will <em>always</em> double count every element except for the first and the last (try playing around with the inputs to convince yourself!)</p><p>So why are we double counting in the first place? If we look at the first two sublists, we see that there's a lot of similarity between the two lists:</p><figure><div><div><p>1</p><p>2</p><p>3</p><p>4</p></div><div><p>1</p><p>2</p><p>3</p><p>4</p></div></div></figure><p>By starting over every time we reach a new element, we don't take advantage of this similarity. If we're somehow able to calculate the average for both sublists without double counting, we would be able to cut down on a lot of needless steps.</p><p>As a matter of fact, there's a way to do exactly that!</p><p>Notice that for the example above, the sum of the second sublist is equal to <strong>the sum of the <em>first</em> sublist minus one and plus four</strong>:</p><figure><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p></div><p>sum: <!-- -->6<!-- --> </p></div><div></div><p>1<!-- --> / <!-- -->3</p></div></figure><p>Generally speaking, the sum of the second sublist is the sum of the first sublist, minus the first element of the first sublist, plus the last element of the second sublist. Using this formula, we can <em>derive</em> the sum of the next sublist from the current one, ultimately avoiding the need to recount everything all over again. By doing this, we reduce the number of steps needed to count the sum from <code>period</code> steps to only one step!</p><p>If we do the subtraction and addition in one step, it's as if we're <em>sliding</em> a <em>window</em> (see where I'm getting at here?) of elements from one sublist to the next:</p><figure><div><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p></div></div><p>sum: <!-- -->6</p></div><div></div><p>1<!-- --> / <!-- -->2</p></div></figure><h2>Rewriting the Algorithm</h2><p>With this key insight let's rewrite the algorithm. Remember that the algorithm receives two inputs - a list of numbers <code>chocolates</code> and the period of consecutive days <code>period</code>.</p><p>The sliding window trick only takes into effect when we transition from one sublist to the next. At the start, we don't even have a sublist, so we have to build the sublist as we did before — by iterating through the first <code>period</code> elements.</p><figure><div><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p></div></div><p>period: 3</p><p>sum: <!-- -->1</p></div><div></div><p>1<!-- --> / <!-- -->3</p></div></figure><p>Then, we use our sliding window trick to slide to the next sublist. Again, what we're really doing here is subtracting the first element of the original sublist and adding the last element of the next sublist. We use this sum to calculate the average of the list and add that average to the final result.</p><figure><div><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p></div></div><p>period: 3</p><p>sum: <!-- -->6</p><p>result: <!-- -->[]</p></div><div></div><p>1<!-- --> / <!-- -->4</p></div></figure><p>Finally, we keep sliding until we hit the end of the chocolates list.</p><figure><div><div><div><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p></div></div><p>period: 3</p><p>sum: <!-- -->9</p><p>result: <!-- -->[
  2
]</p></div><div></div><p>1<!-- --> / <!-- -->3</p></div></figure><p>Putting all three steps together, we get the final algorithm:</p><figure><div><div><p>Building window 🚧</p><div><div><p>1</p><p>2</p><p>3</p><p>4</p><p>5</p><p>6</p></div></div><p>period: 3</p><p>sum: <!-- -->1</p><p>result: <!-- -->[]</p></div><div></div><p>1<!-- --> / <!-- -->7</p></div></figure><p>And there you have it — the sliding window pattern!</p><p>Based on these examples alone, we see that this new version does seem faster — the original algorithm takes 7 steps for a 4-length input, while the sliding window algorithm takes the same amount of steps for a 6-length input.</p><p>This doesn't seem like a fair comparison though, so let's do a test. How would the two algorithms compare when we give it the exact same inputs?</p><figure><div><div><h4>Sliding Window 🏎</h4><h4>Old Algorithm 🐌</h4></div><div></div><p>1<!-- --> / <!-- -->22</p></div><p>The animation speed is set to 400ms for both implementations!</p></figure><p>While the window is building, both algorithms are going at the same pace (try changing the size of <code>period</code> to the size of the list — both algorithms will finish at the same time!). However, once the window is complete, the optimal algorithm blazes off and terminates in less than half the time it takes for the old algorithm to finish.</p><h2>Generalizing the Pattern</h2><p>A pattern wouldn't be much of a pattern if it works for only one use case. What makes the sliding window pattern a pattern is that it secretly hides in a bunch of other similar problems — typically those that involve sublists, subarrays, or substrings. The chocolates problem is just one costume the sliding window pattern puts on.</p><p>Generally speaking, the pattern needs:</p><ol><li>A window, i.e. a fixed range of elements</li><li>A <strong>state</strong> to maintain in that window</li><li>A way to <em>derive</em> the next state using <em>only</em> the current state and the stuff that enters or leaves the window</li></ol><p>"Only" is the keyword here — if we need to go through the <em>entire</em> window again, the pattern wouldn't be any faster than the way we were doing it before.</p><p>The chocolates problem that we were working through meets all of this criteria:</p><ol><li><em>A window</em> — the consecutive period of days</li><li><em>A state to maintain in that window</em> — the total sum of the numbers in the period of days</li><li><em>A way to derive the next state solely by the stuff that enters or leaves the window</em> — to get the next sum, take the current sum, subtract the number that leaves the window and add the number that enters the window</li></ol><p>To end it off, let's look at one more problem that, unfortunately, has <em>nothing</em> to do with chocolates.</p><h3>Permutation in a String</h3><p>Given a string and some pattern, determine if the string contains any permutation&nbsp;of that pattern.</p><p>For example, given the string aaacb and the pattern abc, the algorithm should return true because aaacb contains acb, which is a permutation of abc.</p><p>Before I show you the solution, see if you can frame this problem to fit the sliding window pattern in. Try to use the criteria that we've defined in the previous section.</p><hr><p>Done? Awesome. A bit stuck? No worries. We'll go through the criteria one-by-one to see if we can use the sliding window pattern to solve this problem.</p><p><strong>1. The window</strong></p><p>Figuring out what the window would be is a bit tricky because the problem doesn't explicitly tell you what the size of the substring is.</p><p>If we look back at the definition of a permutation though, we can conclude that two strings of <em>different sizes</em> can never be permutations of one another! After all, the longer string will <em>always</em> have more characters than the other, so you can never rearrange it to create a shorter string.</p><p>Since we're trying to match substrings with the pattern, we can conclude that <strong>the window is the substring of length <code>pattern.length</code></strong>.</p><p><strong>2. A state to maintain in the window</strong></p><p>One way to figure out what state to maintain is to trace back from the result you want — what information do I need to determine if the substring in this window is a permutation of the pattern?</p><p>A way to check if two strings are permutations of each other is to see if they …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nan.fyi/sliding-window">https://nan.fyi/sliding-window</a></em></p>]]>
            </description>
            <link>https://nan.fyi/sliding-window</link>
            <guid isPermaLink="false">hacker-news-small-sites-26308368</guid>
            <pubDate>Mon, 01 Mar 2021 21:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Ethereum 1 Tx at a Time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26308358">thread link</a>) | @timdaub
<br/>
March 1, 2021 | https://rugpullindex.com/blog#ScalingEthereumOneTxAtATime | <a href="https://web.archive.org/web/*/https://rugpullindex.com/blog#ScalingEthereumOneTxAtATime">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <nav>
  <ul>
    <li>
      <a href="https://rugpullindex.com/">
        <img src="https://rugpullindex.com/rpilogo-128x128.png">
        <span>Home</span>
      </a>
    </li>
    <li><a href="https://rugpullindex.com/about">About</a></li>
    <li><a href="https://rugpullindex.com/blog">Blog</a></li>
  </ul>
</nav>

    
<h2 id="ScalingEthereumOneTxAtATime"><a href="#ScalingEthereumOneTxAtATime">§</a> Scaling Ethereum One Tx At A Time</h2>
<h3 id="Mar12021"><a href="#Mar12021">§</a> Mar 1, 2021</h3>
<p>With regards to building rugpullindex.com, there are currently two problems
bugging me. One is that gas prices on the main net are insanely high right
now. And two is that the Ethereum front end space has become even more
hostile than what I was used to before.</p>
<p>In a recent post over on my blog, I've made the argument that "<a href="https://timdaub.github.io/2021/02/22/ethereum-isnt-fun-anymore/">Ethereum isn't
fun anymore</a>"
and that "<a href="https://timdaub.github.io/2020/09/08/web3/">web3 is a stupid idea</a>".
Though I've earned some criticism for these posts, I'd now like to double down.
I have an alternative vision for web3. Purely from a pragmatic, architectural
point of view.</p>
<p>I've written it in long-form over in the <a href="https://github.com/ethereum/EIPs/issues/3304">Ethereum/EIPs issue
section</a> already.  We need to
start thinking practically about light clients now. Ironically, full nodes are
costing developers real dollars today. And building truly decentralized
applications is hardly possible anymore without a credit card—the irony.</p>
<p>I guess nobody designed the Ethereum protocol with light clients in mind.
Still, I think there are small fixes, applied here and there, that could help
dramatically improving user experiences in web3's front ends. So what's the
plan?</p>
<h4 id="ScalingWeb3viaWebRTC"><a href="#ScalingWeb3viaWebRTC">§</a> Scaling Web3 via WebRTC</h4>
<p>Just recently, <a href="https://web.dev/webrtc-standard-announcement/">WebRTC was made a W3C and IETF
standard</a>. WebRTC (or Web
Real-Time Communication) is a concept for sharing data directly between users'
web browsers without going through middlemen like servers. "Over the past year,
WebRTC has seen a 100X increase of usage in Chrome due to increased video
calling from within the browser.", the article states. But WebRTC cannot only
be used for distributing video. Reasonably, we can use it to spread any data.
And one data that I've ranted about not being distributed well enough is that
of the Ethereum blockchain.</p>
<h4 id="andViaWebTorrents"><a href="#andViaWebTorrents">§</a> ... and Via WebTorrents</h4>
<p>WebTorrents allow us to download torrent files directly from the web.
<a href="https://instant.io/">instant.io</a>, for example, enables a user to paste in a
magnet link to download it within the browser instantly. A client could now
easily send a <a href="https://en.wikipedia.org/w/index.php?title=Magnet_URI_scheme&amp;oldid=999476988">magnet
link</a>
to start syndicating files.</p>
<p>In general, torrents have a rather bad reputation, mainly as they've been a
driver of piracy in the past. However, speaking of their technical properties,
torrents are like one of the coolest technologies around.</p>
<ul>
<li>They guarantee file integrity through hashing (similar to content-addressing)</li>
<li>They have built-in incentivization that can drive seeding</li>
<li>Their scale increases with the number of participants (or seeders) increasing</li>
<li>They are "proven" technology.</li>
</ul>
<p>So how does WebRTC, WebTorrents and Web3 fit together?</p>
<h4 id="ethtorrentADecentralizedWeb3Provider"><a href="#ethtorrentADecentralizedWeb3Provider">§</a> ethtorrent, A Decentralized Web3 Provider</h4>
<p>WebTorrent utilizes WebRTC in browser environments. It can fall back into a
<a href="https://github.com/webtorrent/webtorrent-hybrid">webtorrent-hybrid</a> for
server-side usage. What's fantastic is that WebTorrent has a <a href="https://github.com/webtorrent/bittorrent-dht">distributed hash
table built-in</a>. It even allows
specifying a custom hash function. So what's the plan?</p>
<p>For now, the plan is to democratize the access of blockchain data for regular
web3 apps again. The first step towards this will be creating a lean component
that we can use with web3.js. Its goal is to cache and store all requests from
web3.js that have to do with a full transaction or an entire block. We will
await the response, cached for these requests, and offer it for download on
WebTorrent via a custom DHT.</p>
<p>If a second client comes along, for each request they make towards the full
node's RPC endpoint, it will be interrupted, and instead, will consult the
WebTorrent's DHT first. In case the retrieval of a transaction is possible via
torrents, it will make no RPC endpoint call.  That is good for a few reasons:</p>
<ul>
<li>Infura and others bill by requests/day. For an application that needs scale,
this can incur relatively high costs. Decentralized applications shouldn't be
bound to the creator's solvency. After all, smart contracts aren't.</li>
<li>Infura is centralized. If it stops working, the reliant dapp starts working
too.</li>
<li>Many dapps need to send the same data to the same users. It's mostly related
to the application's state at a specific moment. If all users could come in
sync quickly when starting up the application, that'd improve a dapp's user
experience dramatically.</li>
</ul>
<h4 id="WhatNeedstoHappenNow"><a href="#WhatNeedstoHappenNow">§</a> What Needs to Happen Now?</h4>
<p>I'm not sure if I'll handle this project as part of rugpullindex.com. However,
only through it, I had the idea for it. In any case, I think building the
project shouldn't be too much of a hassle as WebTorrent comes with batteries
included. As a start, I'll attempt to create a library that can bootstrap the
Ethereum WebTorrent network for sharing transactions and blocks. Then, I'll
build a simple bootstrapping node capable of talking back to an archive node
for eventually missing transactions or blocks in the DHT.</p>
<p>Then, I think it's a question of whether the idea is accepted and used by the
Ethereum community. However, a web3 provider could significantly reduce the
number of requests a dapp does daily; I could imagine there be a will to give
it a try.</p>
<p>And that's how I want to contribute to scaling Ethereum for now. I hope you
enjoyed reading. Feel free to let me know your thoughts by reaching out to me.
My email is on my blog.</p>
<p>That's all for today.</p>
<p>Best, Tim</p>
<h2 id="Feb242021"><a href="#Feb242021">§</a> Feb 24, 2021</h2>
<ul>
<li>Bug fix: Yesterday, I added anchors to each headline on this page, e.g.
<a href="https://rugpullindex.com/blog#the-algorithm%3B-it's-working!">https://rugpullindex.com/blog#the-algorithm%3B-it's-working!</a>.
However, for links that have a punctuation character at the end, Whatsapp and
Telegram didn't end up making them clickable. They think a user wants to end
a sentence with the exclamation mark character and not that it's part of the
link. I now fixed the problem by removing all special characters from anchor
links.</li>
<li>I designed and added the rugpullindex.com logo. It's a rug with a <code>#</code> :)</li>
<li>I submitted <a href="https://port.oceanprotocol.com/t/rugpullindex-com-round-3-proposal/434">my
proposal</a>
to the OceanDAO's Round 3</li>
<li>Bug fix: Crawler used to run at midnight in "Europe/Berlin" time zone and not
UTC. That has caused numerous problems in the past. To make it all work, I
had to perform an unscheduled crawl before relaunching the server. It could
have been that the site was down for a few minutes. Anyways, now working in
the backend should go more smooth.</li>
</ul>
<h2 id="TheAlgorithmItsWorking"><a href="#TheAlgorithmItsWorking">§</a> The Algorithm; It's Working!</h2>
<h3 id="Feb232021"><a href="#Feb232021">§</a> Feb 23, 2021</h3>
<p>On Feb 18, 2021, the maintainer of the "<a href="https://market.oceanprotocol.com/asset/did:op:C1e2dcCC25ed82AcF79e233780c0f613B1229F82">Oceancap - Datapool Evaluation and
Charting"
(ADASTA-60)</a>"
data set tweeted:</p>
<blockquote><p lang="en" dir="ltr">1.) We decided to
close our Oceancap pool on 21/02 due to the market situation. We are pretty
sure that <a href="https://twitter.com/oceanprotocol?ref_src=twsrc%5Etfw">@oceanprotocol</a>
is working hard on preparing an updated Marketplace in the near future. We are
waiting on the sidelines and take a break for now.</p>— Oceancap -
Datapool Evaluation and Charting (@OCharting) <a href="https://twitter.com/OCharting/status/1362450997050761229?ref_src=twsrc%5Etfw">February
18, 2021</a></blockquote> 
<p>Since rugpullindex.com listed ADASTA-60 in its TOP 25 index for a while, I was
curious how the ranking algorithm would react to the announcement. Remember,
the algorithm ranks a data set based on its market's performance. It works
"autonomously" and isn't capable of comprehending the statement—instead, it's
rating each data set by its market's performance. Our thesis is that if a data
set's market is strong, its value is high too and vice versa.</p>
<p>Here is ADASTA-60's performance within the context of the announcement:</p>
<table>
<thead>
<tr>
<th>Date</th>
<th>Score</th>
<th>Gini</th>
<th>Liquidity (OCEAN)</th>
<th>Price (OCEAN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>2021-02-17T23:01:04.300Z</td>
<td>0.62</td>
<td>0.98</td>
<td>38969</td>
<td>20.80</td>
</tr>
<tr>
<td>2021-02-18T23:01:03.913Z</td>
<td>0.60</td>
<td>0.98</td>
<td>37664</td>
<td>19.60</td>
</tr>
<tr>
<td>2021-02-19T23:01:03.956Z</td>
<td>0.55</td>
<td>0.98</td>
<td>37549</td>
<td>19.47</td>
</tr>
<tr>
<td>2021-02-20T23:01:04.073Z</td>
<td>0.57</td>
<td>0.98</td>
<td>37549</td>
<td>19.47</td>
</tr>
<tr>
<td>2021-02-21T23:03:56.286Z</td>
<td>0.45</td>
<td>0.97</td>
<td>21411</td>
<td>11.10</td>
</tr>
<tr>
<td>2021-02-22T23:01:03.474Z</td>
<td>0.22</td>
<td>0.96</td>
<td>9148</td>
<td>4.74</td>
</tr>
</tbody>
</table>
<p>Looking at the market's data, we can see the following:</p>
<ul>
<li>The share equality of liquidity providers to ADASTA-60's pool has historically
been somewhat on the centralized side, meaning a few LPs had lots of control.
The factor "Gini," close to 1, shows this clearly.</li>
<li>Within just roughly a week, ADASTA-60's liquidity dried up, resulting in a 4x
decrease.</li>
<li>Its price tanked too; ADASTA-60 fell from 20 OCEAN last Wednesday to 4 OCEAN
(5x).</li>
</ul>
<h4 id="Conclusion"><a href="#Conclusion">§</a> Conclusion</h4>
<p>rugpullindex.com's initial thesis that markets are a proxy for data sets has
found some evidence in this particular case. rugpullindex.com successfully
forecasted an investment risk (Gini-Index close to 1) before it manifested
itself. Its algorithm is now automatically decreasing ADASTA-60's stake as the
market reacts to the announcement.</p>
<p>I find this result excited as it's the first time we can see the
collected data and my work in action. 🥳</p>
<p>In the future, I want users to gain the same insights I was able to acquire
today. I'm excited to continue working on that.</p>
<p>Best, Tim</p>
<h2 id="Feb172021"><a href="#Feb172021">§</a> Feb 17, 2021</h2>
<ul>
<li>Further adjustment of ranking algorithm. I had forgotten adding liquidity in
EUR in one subquery.</li>
<li>Added data base index to improve performance of uncached request to root <code>/</code></li>
</ul>
<h2 id="Feb162021"><a href="#Feb162021">§</a> Feb 16, 2021</h2>
<ul>
<li>Refactor some code: I simplified the query that constructs the index ranking.
Over the long term, this change will allow me to make adjustments with more
confidence about the system's correctness.</li>
<li>Ranking now uses Liquidity in EUR to create a relative ranking among data
sets.  See post from Feb 12, 2021 for details.</li>
</ul>
<h2 id="Feb152021"><a href="#Feb152021">§</a> Feb 15, 2021</h2>
<p>As announced on Feb 12, 2021, liquidity and price are now displayed in EUR.
However, EUR values are not yet used within the ranking algorithm.</p>
<h2 id="Feb142021"><a href="#Feb142021">§</a> Feb 14, 2021</h2>
<p>Midnight: After months, I made some changes to the crawler again which lead the
page to be down the last two nights. The reason was a bug in the price crawler.</p>
<p>I was trying to get OCEAN's current EUR price and I was using Coingecko's
<a href="https://www.coingecko.com/api/documentations/v3#/coins/get_coins__id__history">historical
API</a>,
that didn't send back any results (because it's "historical" and not
"present" time). The crawler is now using Coingecko's <a href="https://www.coingecko.com/api/documentations/v3#/operations/simple/get_simple_price">simple
API</a>
to get the price.</p>
<p>A few reflections on what I learned by having to open my
laptop before breakfast and before going to bed on a Saturday:</p>
<ul>
<li>Having to be responsible for a website on the weekend is painful.</li>
<li>Running a crawling script at midnight is good for the user and bad for me. I
only ever find production bugs at night or in the morning. The users probably
never notice...</li>
</ul>
<p>Working on a website that always displays new information is fun. I check
rugpullindex.com myself …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rugpullindex.com/blog#ScalingEthereumOneTxAtATime">https://rugpullindex.com/blog#ScalingEthereumOneTxAtATime</a></em></p>]]>
            </description>
            <link>https://rugpullindex.com/blog#ScalingEthereumOneTxAtATime</link>
            <guid isPermaLink="false">hacker-news-small-sites-26308358</guid>
            <pubDate>Mon, 01 Mar 2021 21:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why does an A note sound different across instruments?]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 90 (<a href="https://news.ycombinator.com/item?id=26308241">thread link</a>) | @OmarShehata
<br/>
March 1, 2021 | https://omarshehata.me/notebook/exploring_sound | <a href="https://web.archive.org/web/*/https://omarshehata.me/notebook/exploring_sound">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="notebook">
	
	<p>From <a href="https://omarshehata.me/notebook">Omar's notebook</a>.</p>
	<hr>
	
	
	<p>
		If you pull up a tuner app on your phone and play an A note on a piano, the tuner will say ~440 hz. Do the same thing on a violin's A note and you'll also get 440 hz.  
	</p>
	<p>
		This seemed impossible based on my understanding of sound, which was: 
	</p>
	<ol>
		<li>Our ears perceive sound by picking up on the frequency of the air vibrating around us.</li>
		<li>Two sounds are different if they have different frequencies, in the same way two colors appear different if they emit light of different wavelengths.</li>
		<li>When we say a sound is 440 hz, that means a point vibrating along that sound wave makes a complete cycle 440 times per second.</li>
	</ol>
	<p>
		So if two sound waves have exactly the same frequency, according to my tuner app, they cannot possibly sound different. But they do! Does that mean there's something else, something <i>more</i> than frequency that can differentiate sound? 
	</p>
	<p>
		There isn't! That's all sound is - vibrations in the air of some specific frequency. 
	</p>
	<p>
		Was the tuner lying? Yes, kind of: when we say a sound is 440 hz, that's not actually a complete description of the sound. It's kind of like telling you a shape has 4 points - you might assume it's a square. But it could be a rectangle, or some completely wacky irregular polygon. 
	</p>
	<h2>Visualizing a couple notes</h2>
	<p>
		Here's an A note from a piano and a violin that I recorded from online virtual instruments. 
	</p>
	<p>
		Click "Play" to hear them. Below each is a small slice of the audio. 
	</p>
	
	<p>Drag and drop your own sound file in these diagrams to use it throughout the article.</p>
	<p>
		They look structurally similar, but they're <i>not</i> the same sound wave. They both have a pattern that repeats ~3 times in 9 milliseconds (or ~440 times per second). So that's what makes them both 440 hz.
	</p>
	<p>
		But that pattern itself that repeats is different. This is why saying "A sound is 440 hz" isn't a complete description, so assumption (3) for me was a misunderstanding.
	</p>
	<p>
		Here is what the sound would look like if the speaker vibrated exactly 440 times per second in a continuous, regular, motion.
	</p>
	
	<p>
		The fact that all 3 of these sound different, even though they are all made of a pattern that repeats at 440 hz, tells me I need to tweak assumption (1). Our ears don't pick up on just a single frequency in the air. If they did, these sounds would be indistinguishable (which I think actually happens for our eyes, see <a href="https://en.wikipedia.org/wiki/Metamerism_(color)">metamerism</a>.)
	</p>
	<p>
		So our ears can detect the internal structure of these patterns. To decompose this structure on a computer, we'll use the Fourier transform.
	</p>
	<h3>
		Performing the Fourier Transform
	</h3>
	<p>
		The Fast Fourier Transform (FFT) algorithm allows you to extract frequencies in a signal.
	</p>
	<p>
		Our signal in this case is a list of amplitudes, how loud the sound is at every sample.
	</p>
	<p>
		When you run the signal through like <code>FFT(signal)</code> you get a list numbers that correspond to a list of frequencies. For example, if the FFT output looks like this:
	</p>
	<p><code>
		[0.001, 0.1, 0.7, 0, 12, 0, 2, 1]
	</code></p><p>
		You'll also have a corresponding list of frequencies:
	</p>
	<p><code>
		[0, 55, 110, 220, 440, 880, 1320, 1760]
	</code></p><p>
		We interpret this to mean 440 is the most significant frequency in this signal, because its FFT coefficient is 12 (the largest), and it's the 5th number. And the 5th frequency in our list is 440. 
	</p>
	<p>
		I've found it easiest to interpret the results of FFT by putting it in a table in terms of the original sound frequency and the relative weights (so I divide all of them by the largest number).
	</p>
	<p>
		Below are the FFT results running on our two 9 ms slices. <a id="compute-fft" href="#">Click to expand</a> the chosen slices. You can also scroll back up to change the slices by hand.
	</p>
	<div id="fft-table-container">
		<div id="fft-table-A-container">
			<h4>Piano A note</h4>
			<p>(<span id="piano-fft-slice-number">10</span> ms slice)</p>
			<table id="fft-table-A">
			  <thead>
			    <tr>
			      <th>Freq. (hz)</th>
			      <th>Weight (%)</th>
			    </tr>
			  </thead>
			  <tbody>
				<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
			</tbody>
			</table>
		</div>
		<div id="fft-table-B-container">
			<h4>Violin A note</h4>
			<p>(<span id="violin-fft-slice-number">10</span> ms slice)</p>
			<table id="fft-table-B">
			  <thead>
			    <tr>
			      <th>Freq. (hz)</th>
			      <th>Weight (%)</th>
			    </tr>
			  </thead>
			  <tbody>
			  	<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
			</tbody>
			</table>
		</div>
	</div>
	<p>Frequencies below 1% weight are omitted from this table.</p>
	<p>
		These tables tell us that both sounds do have ~440 hz as the strongest frequency, but there's other frequencies inside too! The violin one appears a lot more complex, in that it seems to contain a lot more frequencies that contribute significantly.
	</p>
	<p>
		The last step is reconstructing the sound from this table. Representing sound this way is really powerful. This is the basis for a lot of sound analysis/transformations like:
	</p>
	<ul>
		<li><b>Compression?</b> Remove the highest frequencies that our ears can't hear as easily. </li>
		<li><b>Noise filtering?</b> Remove specific known frequencies, that's how you can remove the sound of car horns but keep your voice in a recording.</li>
		<li><b>Auto tune?</b> Check which musical note is closest to the list of frequencies in the sound, and alter/remove/add frequencies to make it sound closer to the note.</li>
		<li><b>Voice recognition?</b> You can think of the frequencies you can create by talking as a unique pattern a software can search for. Like how the letter "E" appears ~11% of the time in most English text. We all have a few frequencies in our voices that appear with predictable probability.</li>
	</ul>
	<p>
		Below is a sandbox for you to explore these ideas of sound reconstruction.
	</p> 
	<p>
		The code returns a <code>outputMultipliers</code> array that scales the original frequencies. A new sound is reconstructed from those new frequencies/weights. You can try <a href="#" id="zero-out">zero-ing out all the high frequencies</a>, or isolate <a href="#" id="single-frequency">a single frequency</a>.
	</p>
	<div id="sandbox">
		
		<p><a href="#" id="run-code">Run</a> <span>(shortcut: CTRL+ENTER)</span><br>
		<a href="#" id="reset-code">Reset code</a></p><div id="note-visualization">
			<div id="output-fft-table">
				<h4>Filtered note</h4>
				<table id="fft-table-output">
				  <thead>
				    <tr>
				      <th>Freq. (hz)</th>
				      <th>Weight (%)</th>
				    </tr>
				  </thead>
				  <tbody>
				  	<tr>
					<td> N/A </td>
					<td> N/A </td>
				</tr>
				</tbody>
				</table>
				<p>Frequencies below 1% weight are omitted from this table.</p>
			</div>
			
		</div>	
	</div>
	<h3>
		Takeaways
	</h3>
	<p>
		So the correct version of assumption (3) is: When we say a sound is 440 hz, we mean that's the frequency with the most weight in the signal. To give a complete description of the sound you need to know (1) all the frequencies it's made of and (2) how much of each frequency to use.  
	</p>
	<p>
		I created this to learn how FFT works. This is the end-to-end demonstration I was looking for to help me understand it. It's best used to test your understanding while reading other materials. I don't have the source code up yet but if you'd like to extend this or use it as a teaching tool just let me know! 
	</p>
	<p>
	 	You can drag and drop any sound file in the very first two figures and all figures will update to use it, including the FFT tables and the code sandbox. Here's a few notes from <a href="https://philharmonia.co.uk/resources/sound-samples/">Philharmonia</a> you can try dragging in:
	</p>
	<ul>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/banjo_a4.mp3" download="">Banjo A note</a></li>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/flute_a4.mp3" download="">Flute A note</a></li>
		<li><a href="https://omarshehata.me/static/whoisomar/images/notebook/sound/saxophone_a4.mp3" download="">Saxophone A note</a></li>
	</ul>
	<p>
		A few key points I needed for a correct implementation:
	</p>
	<ul>
		<li>
			<b>How to retrieve the original frequencies from the FFT output.</b> The FFT only tells you the frequency in terms of how often it repeats in the list of samples. So you need to multiple by the sample rate (like 44100 for most sound) to get frequency per second (Hz). Most FFT libraries in JS do NOT give you a list of the frequencies (just the coefficients). The formula for figuring out what frequency corresponds to what coefficient <a href="https://stackoverflow.com/questions/4364823/how-do-i-obtain-the-frequencies-of-each-value-in-an-fft/4371627#4371627" target="_blank">is described here</a>.
		</li>
		<li>
			<b>You have to take a small slice of the audio.</b> Given that the frequency of the sound changes over time, even when playing a single note, you won't get accurate/expected frequencies if you FFT the entire thing. For example, a piano note has an "attack" and a "decay", you want to take a slice from the middle. 
			<ul>
				<li>See the <a href="https://en.wikipedia.org/wiki/Short-time_Fourier_transform">Short Time Fourier Transform (STFT)</a>. This is computing FFT for a small slice of audio as we just did, but do this for all slices of the audio. You'll get a list of frequencies over time. This is often visualized as a <a href="https://en.wikipedia.org/wiki/Spectrogram">spectrogram</a>.</li>
			</ul>
		</li>
		<li>
			<b>You have to sample an integer number of cycles.</b> If you take an arbitrary slice of a pure A note, you likely will get a lot more than 440 in your FFT table, unless you happen to pick a start and an end that matches a multiple of the cycle length. This article automatically shortens any slice to the nearest cycle (we figure that out by finding the nearest sample where the signal crosses the Y axis). This is also important when playing the reconstructed sound on loop (otherwise you hear a popping sound).
		</li>
		<li>
			<b>The discrete fourier transform (DFT) doesn't include all possible frequencies.</b> In theory, FFT is a continuous sum (AKA an integral) of all possible frequencies in the audio. What we have implemented here is a discrete version, where we sum a finite list of frequencies. In a small slice you may not get 440 exactly as an output, only because it wasn't included as a frequency the algorithm was looking for. I <i>think</i> in principle you could have an implementation that allows you to specify what frequencies must be included (if you know what you're looking for) but I haven't seen such an implementation.
		</li>
		<li>
			<b>FFT isn't magic.</b> A popular analogy is that FFT can take a smoothie and extract all the component that went into it. But this seems impossible??? The trick is the FFT comes in with an assumption of what frequencies might be in there. We go through each possible frequency and ask "How much 440 hz is in this sound?" and "How much 880 hz is in this sound?" and so on. So it's closer to having an unknown substance and figuring out what it is by checking if it reacts to known chemicals/substances.
		</li>
	</ul>
	<p>A few insights I learned from exploring the code sandbox:</p>
	<ul>
		<li><b>The sum of all the frequencies &lt; 1% weight have a big effect.</b> I had these hidden in the FFT tables thinking they weren't significant, and any one of them isn't, but removing them altogether does have a very noticeable effect. Here's a <a href="#" id="remove-low-weight">code snippet</a> (scroll up) that removes all frequencies with weight less than 1%. Or try the opposite, listen to only weights less than 1%.</li>
		<li><b>The high frequencies are a big part of the violin sound.</b> Removing anything at 5000 hz and up makes it no longer really sound like a violin (or just sound really muted). This isn't true for the piano.</li>
		<li><b>A string tuned to 440 hz will never emit frequencies any lower than that</b>. This is true because of the physics of standing waves, but it was really cool to learn about this in theory, and then go back to this interface and see that this was indeed true for all the recordings of notes I had! Without having known this before I …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://omarshehata.me/notebook/exploring_sound">https://omarshehata.me/notebook/exploring_sound</a></em></p>]]>
            </description>
            <link>https://omarshehata.me/notebook/exploring_sound</link>
            <guid isPermaLink="false">hacker-news-small-sites-26308241</guid>
            <pubDate>Mon, 01 Mar 2021 20:52:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tesla’s market share in Europe keeps crumbling, as China reclaims top spot]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26307192">thread link</a>) | @remote_phone
<br/>
March 1, 2021 | http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/ | <a href="https://web.archive.org/web/*/http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://shroommarkets.com/teslas-market-share-in-europe-keeps-crumbling-as-china-reclaims-top-spot-in-global-ev-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26307192</guid>
            <pubDate>Mon, 01 Mar 2021 19:34:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flow Browser Preview for All Raspberry Pi Computers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26306992">thread link</a>) | @porsager
<br/>
March 1, 2021 | https://www.ekioh.com/blog/making-flow-available-on-all-raspberry-pi-computers/ | <a href="https://web.archive.org/web/*/https://www.ekioh.com/blog/making-flow-available-on-all-raspberry-pi-computers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4973" role="article" itemscope="" itemtype="http://schema.org/BlogPosting">
						
	<header>	
		
		
	    </header> <!-- end article header -->
					
    <section itemprop="articleBody">
				<p><span>In the last month we’ve made many improvements to Flow, some of which were prompted by feedback from the previous Pi release. The most obvious useability feature is paste support for the welcome page URL bar. We’ve also made it possible to run Flow on all Raspberry Pi computers.</span></p>
<p><img src="https://www.ekioh.com/wp-content/uploads/PiZero.jpeg" alt="" width="292" height="172"></p>
<p>Earlier Raspberry Pis have a different GPU to the one used on the Pi 4 and Pi 400. They are similar except the earlier GPU only supports OpenGL ES 2.0 rather than OpenGL ES 3.0 which the Pi 4 and Pi 400 support. It therefore made sense for us to target these earlier Pis as a way to exercise Flow’s wider OpenGL ES API support. A lot of STBs and other embedded hardware only offer OpenGL ES 2.0, so Flow’s support for them makes sure we aren’t excluding a chunk of that market.</p>
<p>When we recently added WebGL, Flow’s minimum OpenGL ES API level was increased from 2.0 to ES 3.0. We use Google’s <a href="http://angleproject.org/">ANGLE</a> library as part of our WebGL implementation, as does Chromium, although the way we used it had OpenGL ES 3.0 dependencies in a couple of places. We could have made Flow available without WebGL for OpenGL ES 2.0 platforms, but we didn’t really want to restrict the functionality, so we worked around this.</p>
<p>Flow also requires hardware acceleration which isn’t enabled by default on X11 for earlier Pis. The ‘Fake KMS’ GL Desktop driver is needed for this.</p>
<p>The updated Flow preview is now available on our <a href="https://support.ekioh.com/download/">download</a> site. We’ve run it on the Pi Zero, Pi 1 and Pi 3. The Pi 1 with 256MB is unusably slow because it doesn’t have enough memory so is swapping all the time. None of these are really fast enough for open internet browsing, but for bespoke content they are fine.</p>
<hr>
<p>If you’d like to automatically receive our posts by email please&nbsp;<a href="https://www.ekioh.com/blogregister/">join our mailing list</a>.</p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->	</section> <!-- end article section -->
						
	 <!-- end article footer -->
						
	
<!-- #comments -->	
													
</article></div>]]>
            </description>
            <link>https://www.ekioh.com/blog/making-flow-available-on-all-raspberry-pi-computers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306992</guid>
            <pubDate>Mon, 01 Mar 2021 19:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing dbt + Materialize]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 22 (<a href="https://news.ycombinator.com/item?id=26306861">thread link</a>) | @jldlaughlin
<br/>
March 1, 2021 | https://materialize.com/introducing-dbt-materialize/ | <a href="https://web.archive.org/web/*/https://materialize.com/introducing-dbt-materialize/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Managing data is hard. Managing data pipelines is even harder. The meaning of individual tables or values in your data warehouse gets lost in translation across organizations. Another team’s refactor breaks your team’s pipeline. And, it’s normally very difficult to tell who made what change and when.</p>
<p><a href="https://www.getdbt.com/">dbt</a>, data build tool, alleviates these frustrations by taking over the transformation step in your ETL pipelines. <a href="https://blog.getdbt.com/what--exactly--is-dbt-/">dbt is not itself a data processor</a>, but instead sits on top of your data warehouse that contains your already extracted and loaded data. dbt allows teams to easily test, document, and version-control their data transformations.</p>
<p>While dbt is a great tool for transforming batch data, it cannot currently transform streaming data in real time. (The dbt team explicitly warns users about this in a <a href="https://blog.getdbt.com/is-dbt-the-right-tool-for-my-data-transformations/">few</a> <a href="https://discourse.getdbt.com/t/how-to-create-near-real-time-models-with-just-dbt-sql/1457">places</a>.) Here at <a href="https://materialize.com/">Materialize</a>, we want to help the world stop batching and start streaming. So we* built a dbt adapter that will allow you to transform your streaming data in real time using Materialize as your data warehouse.</p>
<p>The rest of this post will explore why dbt works best with batch data and how using Materialize unlocks streaming transformations. If you’re eager to get started, the <a href="https://github.com/MaterializeInc/materialize/tree/main/misc/dbt-materialize">dbt-materialize adapter is here</a>, and our <a href="https://github.com/MaterializeInc/materialize/tree/main/play/wikirecent-dbt">sample streaming project is here</a>. Note: The dbt-materialize adapter is an <a href="https://github.com/MaterializeInc/materialize/issues/5462">active work in progress</a> and not yet suitable for production use-cases. Please file issues or submit PRs as you see fit, we love feedback!</p>
<p>*The dbt-materialize adapter was originally created by Josh Wills and actively shaped by Jeremy Cohen. Thank you for all of your work and support!</p>
<h2>dbt and batch data</h2>
<p>dbt is great at transforming batch data, but it cannot transform streaming data efficiently in real time. To understand why, let’s take a look at how dbt transforms data under the hood.</p>
<p>dbt users define their desired transformations using <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/">dbt “models”</a>. dbt models are SQL files that contain:</p>
<ul>
<li>A SELECT statement that performs the desired transformation</li>
<li>A <a href="https://docs.getdbt.com/docs/building-a-dbt-project/building-models/materializations/">“materialization”</a> parameter</li>
</ul>
<p>dbt transforms your data each time you <a href="https://docs.getdbt.com/reference/commands/run/">“run”</a> a model. Each time a model is run, dbt queries the underlying data warehouse using that model’s SELECT statement. The result set of the query (the transformed data) is then either returned directly to the user or persisted into your data warehouse, depending on the model’s materialization parameter.</p>
<p>Currently, dbt supports four types of materializations: <em>table</em>, <em>view</em>, <em>incremental</em>, and <em>ephemeral</em>. The <em>table</em> and <em>incremental</em> materializations persist a table, the <em>view</em> materialization creates a view, and the <em>ephemeral</em> materialization, instead of persisting anything, returns results directly using a common table expression (CTE). The good news is that these database objects are totally sufficient to transform batch data. The bad news is that none of these database objects transform streaming data efficiently.</p>
<p>First, what do I mean by batch and streaming data? Batch data, as the name suggests, is any type of data that arrives in discrete batches. This can be once a minute, once an hour, or once a day. The important thing is that no new data arrives between batches. Streaming data, on the other hand, arrives continually and at no particular schedule.</p>
<p>So, why are these database objects sufficient to transform batch data, but not able to efficiently transform streaming data?</p>
<p>Views and CTEs do not physically persist data to your data warehouse. This means that each time you query a model that uses a view or CTE, your data warehouse must re-transform the underlying source data. And, each time you transform your source data, you are paying some cost. While views and CTEs always return up-to-date transformations of your batch and streaming data, they do not do so efficiently.</p>
<p>Tables, on the other hand, do physically persist data. More specifically, tables persist the result set of the last time their model “dbt run.” Unlike views and CTEs, this means that you won’t pay the price of transforming data each time your table is queried. But, this means that your transformed data can quickly become stale as new data arrives. This is not an issue with batch data because you can simply “dbt run” your table each time a new batch arrives. Unfortunately, things aren’t so simple with streaming data.</p>
<p>Because streaming data does not arrive on a schedule, there is no longer a right time to re-run your models to keep them up-to-date. Instead, you’re forced to choose between maximizing data freshness and minimizing transformation costs. You can minimize your costs by limiting how often you recreate your tables, effectively turning your streaming data into batch data. Or, you can maximize your data freshness by continually recreating your tables. But, this approach will cost you time and money, leave you vulnerable to bugs, and still won’t maintain truly up-to-date results.</p>
<p>So, what should you do if you want to transform streaming data with dbt?</p>
<h2>dbt and streaming data</h2>
<p>dbt currently has one official and one unofficial way to approximate transforming streaming data. Neither of these methods truly transforms streaming data in real-time, and both come at a cost.</p>
<p>The first method to approximate transforming streaming data is to create models with an incremental materialization. The first time you run an incremental model, dbt persists your transformation’s result set into a table in your data warehouse. For subsequent runs, dbt only transforms the subset of source data indicated by your model’s filter predicate. (For example, you might have a filter predicate that will only transform data with a timestamp greater than your last model’s run.)</p>
<p>While incremental models reduce the severity of the tradeoff that users face when persisting their transformations in tables (data freshness vs cost), they do not eliminate the tradeoff entirely. By design, you will probably be paying a lesser cost each time you “dbt run” an incremental model. (I say “probably” here because even though you’re only transforming a few rows of data with each run, unless you’re filtering cleverly, your model’s SELECT statement will still have to scan the entire underlying source table or view to discover these rows). While these lesser costs may free you up to run your incremental models more frequently, you still will not be able to run them continuously. By definition, you are still transforming your streaming data with a batch process.</p>
<p>The second way to approximate transforming streaming data is the <a href="https://discourse.getdbt.com/t/how-to-create-near-real-time-models-with-just-dbt-sql/1457">unofficial “lambda view” approach</a>. This method simulates transformations over “near real-time models” by querying a combined historical table and a current view. This approach incurs the cost of querying both of the underlying database objects using some filter, similar to the incremental materialization. The current view of your data returns up-to-date results, but must re-transform the recent data each time.</p>
<p>Neither of these methods can efficiently transform data in real time. (And, they come with <a href="https://discourse.getdbt.com/t/on-the-limits-of-incrementality/303">hairy problems</a> if, say, you have streaming data that might arrive late.) In order to efficiently perform worry-free, real-time transformations of streaming data, dbt would need to persist a database object that updates as new data arrives upstream. Luckily, there is a database object that can do this for us: materialized views.</p>
<h2>dbt and Materialize</h2>
<p>Materialized views in traditional databases behave a bit like dbt’s incremental materialization. When a materialized view is first created, the result set of its query is physically persisted in the database. Then, at some interval or when manually triggered, the stored result set is updated with recent data. Like the incremental materialization, maintaining these materialized views incurs a variety of costs.</p>
<p>This is the exact problem Materialize was created to solve. Unlike traditional materialized views, <a href="https://materialize.com/why-use-a-materialized-view/">our materialized views</a> continually update as new data arrives–no refreshes needed. Better yet, we provide up-to-date results with millisecond latency. (For more information about Materialize and our materialized views, check out <a href="https://materialize.com/docs/">our documentation</a>.)</p>
<p>So, what does this mean for dbt and streaming data? This means that the first time you run a dbt model on top of Materialize, dbt persists a materialized view. <strong>Then, you never have to run your model again.</strong> No matter how much or how frequently your data arrives, your model will stay up to date. No matter when you query your view, it will return a fresh answer. Just by creating your model with our materialized views, you can confidently and efficiently transform streaming data in real time.</p>
<h2>Try it out!</h2>
<p>Excited? Skeptical? Cautiously optimistic? Try it out for yourself! As mentioned before, we have a <a href="https://github.com/MaterializeInc/materialize/tree/main/misc/dbt-materialize">beta dbt-adapter</a> and a <a href="https://github.com/MaterializeInc/materialize/tree/main/play/wikirecent-dbt">demo streaming project</a>. If you have any thoughts, questions, or concerns, please feel free to contact us in our community Slack or in our dbt repos. (Or, when you’re up and running, tell us what you’re transforming in real time!)</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/introducing-dbt-materialize/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306861</guid>
            <pubDate>Mon, 01 Mar 2021 19:13:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Music To Program To]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26306835">thread link</a>) | @sigil
<br/>
March 1, 2021 | https://alangrow.com/blog/music-to-program-to | <a href="https://web.archive.org/web/*/https://alangrow.com/blog/music-to-program-to">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Saturday, February 27, 2021.</p><div>
  

<p>Programming is deep work. Tuning out distractions is key, and music is one of the most effective tools at your disposal.</p>
<p>But not all music helps you program. Music with lyrics can interfere with your ability to read and write code. Music with too many surprises can add rather than remove distraction. After some experimentation, many programmers arrive at the same conclusion: repetitive electronic music helps them program.</p>
<p>After a couple decades of programming, including a decade of remote work with the awesome musician-programmers at <a href="https://blend.io/">blend.io</a> and <a href="https://roli.com/">ROLI</a>, here's some of the music I turn to when I need to Get Shit Done. All music has a Spotify embed and a quick review. Know the mood you're after? Start with this index of mental states. YMMV. Enjoy! ✌️</p>
<h2>By Desired Mental State</h2>
<h3>Focus, Intensity, Urgency 🎯</h3>
<ul>
<li><a href="#deep-dark-minimal">Deep Dark Minimal</a></li>
<li><a href="#basic-channel-sampler">Basic Channel - Sampler</a></li>
<li><a href="#maurizio-m-series">Maurizio: M-Series</a></li>
<li><a href="#tm404-tm404">TM404: TM404</a></li>
<li><a href="#jonas-kopp-desire-ep">Jonas Kopp: Desire EP</a></li>
<li><a href="#etapp-kyle-klockworks-10">Etapp Kyle: Klockworks 10</a></li>
<li><a href="#luke-hess-facette">Luke Hess: Facette</a></li>
<li><a href="#the-field-sound-of-light-nordic-light-hotel">The Field: Sound of Light - Nordic Hotel</a></li>
<li><a href="#eod-questionmarks">EOD: Questionmarks</a></li>
<li><a href="#trickfinger-sampler">Trickfinger - Sampler</a></li>
<li><a href="#tin-man-dripping-acid">Tin Man: Dripping Acid</a></li>
<li><a href="#anthony-naples-fog-fm">Anthony Naples: Fog FM</a></li>
</ul>
<h3>Calmness, Contemplation, Perfection 🧘</h3>
<ul>
<li><a href="#microlith-dance-with-me">Microlith: Dance With Me</a></li>
<li><a href="#martin-schulte-slow-beauty">Martin Schulte: Slow Beauty</a></li>
<li><a href="#steve-reich-music-for-18-musicians">Steve Reich: Music for 18 Musicians</a></li>
<li><a href="#terry-riley-in-c">Terry Riley: In C</a></li>
<li><a href="#eod-utrecht">EOD: Utrecht</a></li>
<li><a href="#automatic-tasty-fieldworks-ep">Automatic Tasty: Fieldwork EP</a></li>
<li><a href="#khotin-baikal-acid">Khotin: Baikal Acid</a></li>
</ul>
<h3>Creative, Energetic, Mischevious 👿</h3>
<ul>
<li><a href="#modern-acid">Modern Acid</a></li>
<li><a href="#beatwife-cornbrail-acid-2">Beatwife: Cornbrail Acid 2</a></li>
<li><a href="#dmx-krew-broken-sd140-part-ii">DMX Krew: Broken SD140 Part II</a></li>
<li><a href="#ceephax-sampler">Ceephax - Sampler</a></li>
</ul>
<h3>Wistful, Reflection 🍂</h3>
<ul>
<li><a href="#mikron-severance">Mikron: Severance</a></li>
<li><a href="#boards-of-canada-music-has-the-right-to-children">Boards of Canada: Music Has The Right To Children</a></li>
<li><a href="#cn-the-expedition-beyond">CN: The Expedition Beyond</a></li>
<li><a href="#four-tet-new-energy">Four Tet: New Energy</a></li>
</ul>
<h2>Playlists</h2>
<p>If you're not sure where to start, pick one of these 2+ hour playlists and dig in. These artists have deeper catalogs you can branch out into.</p>
<h3>Deep Dark Minimal</h3>

<p>Repetitive, trance-inducing electronic music for intense focus and deep work. No vocals or lame chord progressions. Mostly German.</p>


<h3>Modern Acid</h3>

<p>The tasty sounds of the 303 / 707 / 808 / 909 used in new ways. All tracks post 2000. Higher energy, faster tempos, and busier arrangements for active brains. 🧠</p>


<h2>Albums</h2>
<p>Some full-length albums that won't disappoint. Each is good for about an hour of listening.</p>
<h3>Microlith: Dance With Me</h3>

<p>An album of sublime electro from Maltese producer Rhys Celeste. Everything Rhys made until his <a href="https://ra.co/news/38277">tragic death at age 24</a> is worth a listen. See also <a href="https://open.spotify.com/playlist/4CvNSwKn7f9ngVLlP2Jr0O">Float House</a>.</p>


<h3>Beatwife: Cornbrail Acid 2</h3>

<p>A Scottish acid madman with an artist name you can't mention in polite company. Fast, frenetic music with a quirky sense of humor. See also <a href="https://daily.bandcamp.com/lists/braindance-feature">Braindance</a>.</p>


<h3>Tin Man: Dripping Acid</h3>

<p>How much acid is too much acid? This monster neo acid album may provide the answer. Haunting, hypnotic tunes with slow builds.</p>


<h3>Mikron: Severance</h3>

<p>Peaceful, aquatic, ambient techno landscapes from an Irish duo. "Ghost Node" emerges triumphant from the fog.</p>


<h3>Anthony Naples: Fog FM</h3>

<p>Another foggy one with some breakout surprises.</p>


<h3>Boards of Canada: Music Has The Right To Children</h3>

<p>By law I am required to include this album. I'm happy to comply. A landmark in electronic music from the Scottish duo. As good today as it ever was.</p>


<h3>Maurizio: M-Series</h3>

<p>Minimal dub techno from the master of the genre, <a href="#basic-channel-sampler">Basic Channel</a> co-founder Moritz von Oswald. If you're new to dub techno you may be forgiven for thinking "nothing ever happens." That's kind of the point, but it's also not <em>quite</em> true: there's lots of subtle variation if you start looking for it, but never enough to distract if you aren't.</p>


<h3>TM404: TM404</h3>

<p>Even darker minimal dub techno from Swedish producer <a href="https://en.wikipedia.org/wiki/Andreas_Tilliander">Andreas Tilliander</a>.</p>


<h3>CN: The Expedition Beyond</h3>

<p>The year is 3984, and this is the soundtrack to our mysterious space explorations. CN is one of several projects from the outrageously talented and prolific Norwegian producer <a href="https://eodtracks.bandcamp.com/">Stian Gjevik</a>. There's <a href="https://open.spotify.com/album/0YPxzyy8doEk5wh5XT0AkW?si=gUmFatscRnKPufh5M1SfpA">a second album</a> that picks up where this one left off.</p>


<h3>Martin Schulte: Slow Beauty</h3>

<p>Ambient that gets its inspiration from nature. While most music is busy painting portraits, these tracks are content to paint landscapes. If you like this stuff, Schulte has a whole series of albums exploring different seasons and places.</p>


<h3>Four Tet: New Energy</h3>

<p>Natural inspiration in this one too, which comes to you from a cabin in upstate New York.</p>


<h3>Steve Reich: Music for 18 Musicians</h3>

<p>A minimalist classical masterpiece from 1976 that anticipated electronic music as we know it: layering, envelopes, precise rhythms, repetitiveness, gradual rather than sudden harmonic changes...it's all in there. I find it incredible that 18 skilled humans can approximate dense electronic like this. Structurally, 18 Musicans is interesting too, as the interior sections are organized around a cycle of eleven chords. Lots to uncover in repeat listens.</p>


<h3>Terry Riley: In C</h3>

<p>The granddaddy of all minimalist classical masterpieces. For about an hour we never leave the key of C. Unlike Spinal Tap, Riley pulls it off. It's a fascinating and elevating listen.</p>


<h2>EPs</h2>
<p>These are half-albums that nonetheless stand out as excellent music to work to. They vary in length, but are ½ an hour on average.</p>
<h3>EOD: Utrecht</h3>

<p>Lush synth landscapes collide with hard-edge acid techno, leaving you stranded in the best of both worlds. <a href="https://eodtracks.bandcamp.com/">EOD</a> is Norwegian producer Stian Gjevik's main shingle. His melodic gift and impeccable arrangements are on full display here.</p>


<h3>EOD: Questionmarks</h3>

<p>On this EP Gjevik strips away the lushness and really lets the hard-edge techno rip. The sweet melodies and intricate arrangements are still there, but there's an urgency and raw speed that verges on frightening. Don't worry: Gjevik is a professional driver on a closed course.</p>


<h3>Automatic Tasty: Fieldwork EP</h3>

<p>Morning, afternoon, evening, night. What a nice four-part cyclic structure for an EP! Although the instrumentation borrows from the somewhat-dated sounds of early techno, Dillon also weaves in real field recordings from different times of day. The result is charming and feel-good.</p>


<h3>The Field: Sound of Light - Nordic Light Hotel</h3>

<p>Another four-part day cycle EP from Sweden. True to form, these tracks are driving, repetitive, and awash in sound -- the kind of thing that makes you hitch up the sled dogs and log a couple hundred miles of frozen tundra. This is music you can really get lost in.</p>


<h3>DMX Krew: Broken SD140 Part II</h3>

<p>What is an SD140, and are we sure it's safe to use a broken one? I have no idea, but it sounds great. Harsh electro rhythm sounds topped with sweet melodies. "Apple Grid" is a standout.</p>


<h3>Khotin: Baikal Acid</h3>

<p>Dancy, imaginative acid house from up north. Khotin saves the best for last: side B has not one, but two lovely, warm tunes.</p>


<h3>Jonas Kopp: Desire EP</h3>

<p>German minimal techno by way of Argentina. It's dark, but the opener is funkier than your typical Tresor track, and the deep-breathing closer feels like some kind of...weird ascension ritual?</p>


<h3>Etapp Kyle: Klockworks 10</h3>

<p>Dark, driving, haunted minimal techno of the German variety. All of the albums on <a href="https://ra.co/dj/benklock/biography">Ben Klok's</a> Klockworks series are worth a listen, but Klockworks 10 and 16 from this Ukranian producer are standouts.</p>


<h3>Luke Hess: Facette</h3>

<p>Modern Detroit minimal techno. A propulsion system made from deep, dark textures and thumping beats.</p>


<h2>Artist Samplers</h2>
<p>Some artists don't fit well into the album box. And some artists make albums of such breadth that they no longer fit into the "music to work to" box. Here's a few sampler playlists from artists not featured above, but no less deserving.</p>
<h3>Basic Channel - Sampler</h3>

<p><a href="https://en.wikipedia.org/wiki/Basic_Channel">Basic Channel</a> is legend. They more or less invented minimal dub techno. Except for BCD and BCD-2, their output consists of a series of cryptically labeled singles. Here's a curated selection.</p>


<h3>Trickfinger - Sampler</h3>

<p>Did you know John Frusciante -- yes, <a href="https://en.wikipedia.org/wiki/John_Frusciante">that John Frusciante</a> -- has a side gig making acid techno? Insane. I guess that explains the name. There are a couple tracks here where it really does sound like he plucked out techno melodies on the guitar.</p>


<h3>Ceephax - Sampler</h3>

<p>No list would be complete without Andy Jenkinson, AKA Ceephax. Personally I like his stuff more than <a href="https://en.wikipedia.org/wiki/Squarepusher">his brother's</a>. It's funny, nostalgic, a bit unhinged, and full of bonafide musical genius.</p>

  </div></div>]]>
            </description>
            <link>https://alangrow.com/blog/music-to-program-to</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306835</guid>
            <pubDate>Mon, 01 Mar 2021 19:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Screenplay Format Reference]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26306809">thread link</a>) | @jstrieb
<br/>
March 1, 2021 | http://www.trilane.com/ref/index.html | <a href="https://web.archive.org/web/*/http://www.trilane.com/ref/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="915" nof="ly">
  <tbody><tr>
   <td>
    <p><img id="Picture3" height="93" width="90" src="http://www.trilane.com/ref/a_reels.jpg" alt="reels" title="reels"></p>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="12" height="1" alt=""></td>
      <td></td>
     </tr>
     <tr>
      <td></td>
      <td nof="NB_BYVTNN000">[Top]</td>
     </tr>
    </tbody></table>
   </td>
   <td>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="15" height="1" alt=""></td>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="559" height="1" alt=""></td>
     </tr>
     <tr>
      <td></td>
      <td>
       <p><b><span>The Ultimate Screenplay Format Reference</span></b></p>
      </td>
     </tr>
    </tbody></table>
    
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="389" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>FADE IN:</span></p>
          <p><b><span>Table of Contents</span></b></p>
          <p><b><span>measurements</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">typeface</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">margins and tabs</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/measure/measure.html">page numbers</a></span></li>
          </ul>
          <p><b><span>scenes</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html">master scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes.html#SecHeadings">secondary scene headings</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">montage</a>, <a href="http://www.trilane.com/ref/scenes/spcl1/spcl1.html">series of shots</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashback">flashbacks</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#flashseq">flashback sequences</a>, <a href="http://www.trilane.com/ref/scenes/spcl2/spcl2.html#quickflashes">quick flashes</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html">dreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#daydream">daydreams</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#imagining">imaginings</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#vision">visions</a>, <a href="http://www.trilane.com/ref/scenes/spcl3/spcl3.html#animation">animation</a> and sequences thereof</span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html">establishing shots</a></span></li>
           <li><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingScenes"><span>spacing between scenes</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#spacingLines">spacing between lines</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/scenes/scenes2/scenes2.html#transitions">scene transitions<span>, </span><span>MATCH CUT</span></a></span></li>
          </ul>
          <p><b><span>characters</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/chars/chars.html#names"><span>character names</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/chars/chars.html#cues">character cues</a></span></li>
          </ul>
          <p><b><span>narrative and action</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/action/action.html">character introductions</a></span></li>
           <li><a href="http://www.trilane.com/ref/action/action4/action4.html#SUPER"><span>SUPER</span><span>, </span><span>SCROLL</span><span><span>, </span></span></a><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><span>words on TV</span></a></li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV">
           </a><li><a href="http://www.trilane.com/ref/action/action4/action4.html#onTV"><b><span></span></b></a><b><a href="http://www.trilane.com/ref/action/action4/action4.html#insert"><span>INSERT</span></a></b></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#sounds">sounds, MOS</a></span></li><a href="http://www.trilane.com/ref/action/action.html#sounds">
           </a><li><a href="http://www.trilane.com/ref/action/action.html#sounds"><span></span></a><a href="http://www.trilane.com/ref/action/action.html#spfx">special effects (<span>FX</span>, <span>SPFX</span>, <span>SFX</span>)</a></li>
           <li><span><a href="http://www.trilane.com/ref/action/action.html#POVs"><span>POV</span>, <span>CLOSE UP</span>, <span>PULL BACK</span></a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html">slow motion</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#music">music</a>, <a href="http://www.trilane.com/ref/action/action2/action2.html#lyrics">music lyrics</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action2/action2.html#clips">movie clips</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action3/action3.html">unseen characters</a>, <a href="http://www.trilane.com/ref/action/action3/action3.html#phantom">phantom POV</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action4/action4.html#stacking">action stacking</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/action/action5/action5.html">then we see ...</a></span></li>
          </ul>
          <p><b><span>dialog </span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#wrylies">actor’s instructions</a> (a.k.a. wrylies)</span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg.html#os"><span>(O.S.)</span></a> and <a href="http://www.trilane.com/ref/dlg/dlg.html#vo"><span>(V.O.)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg.html#more"><span><span>MORE</span> <span>and</span> </span><span>CONT’D / CONTINUED</span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html">telephone conversations</a></span></li>
           <ul>
            <li><span><span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span>INTERCUT</span></a></span><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a></span></li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a></ul><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut">
           </a><li><a href="http://www.trilane.com/ref/dlg/dlg2/dlg2.html#intercut"><span></span></a><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html">overlapping dialog</a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg3/dlg3.html#computer">computer conversations</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html#foreign">foreign languages</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg4/dlg4.html">telepathic dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html">mute dialog</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#beat"><span>(beat)</span></a></span></li>
           <li><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>-- </span></a></li>
           <li><span><a href="http://www.trilane.com/ref/dlg/dlg5/dlg5.html#punctuation"><span>...</span></a></span></li>
          </ul>
          <p><b><span>miscellaneous</span></b></p>
          <ul>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html">the title page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#firstPage">the first page</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#credits">credits and titles</a></span></li>
           <li><span><a href="http://www.trilane.com/ref/pages/pages.html#lastPage">the last page</a></span></li>
           <li><span>author’s intrusions</span></li>
           <li><span><a href="http://www.trilane.com/ref/misc/misc.html"><span>notes</span></a></span></li>
          </ul>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <div>
             <p><span>Writing a screenplay is difficult.</span></p>
             <p><span>Formatting should be the least of all problems. Actually it’s the most easiest to master, if you follow a set of simple rules.</span></p>
             <p><span><a href="http://astore.amazon.com/trilane-20/detail/1879505843/105-1611443-6684411">Trottier’s Screenwriter’s Bible</a> is currently considered the final authority on formatting issues. I recommend you read it. It will save you a lot of pain.</span></p>
             <p><span>Here you find a reference to those rules. Follow them and your screenplay will be well formatted.</span></p>
            </div>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="122" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="45" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="344" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>If you don’t believe me then take this from a pro:</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="47" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="343" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>“Readers in Hollywood do a great deal of inductive reasoning, which goes something like this: “I just read 99 screenplays, they were all horrible, and they were all written in improper format. Therefore, if screenplay number 100 is also in improper format, it must be horrible, too.”</span></p>
          <p><span><span>Michael Hauge, Collins 2007, Writing Screenplays That Sell </span></span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="49" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="340" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>‘Writing Screenplays That Sell’ is another good book to read.</span></p>
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="262" height="1" alt=""></td>
         <td></td>
        </tr>
        <tr>
         <td></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="80" height="1" alt=""></td>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="311" height="1" alt=""></td>
        </tr>
        <tr>
         <td></td>
         <td>
          <p><span>At the bottom of this page you find a few books that are real helpful in addressing important issues beyond formatting.</span></p>
          <p><span>... all the best for your own screenwriting.</span></p>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
      <td>
       
      </td>
     </tr>
    </tbody></table>
    <table nof="ly">
     <tbody><tr>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="35" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="27" height="1" alt=""></td>
         <td>
          <div>
             <p><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture22" height="125" width="83" src="http://www.trilane.com/ref/a_Writer_s_Journey_Vogler.jpg" alt="Writer's Journey_Vogler" title="Writer's Journey_Vogler"></a><br><span><b><br>The Writer’s Journey<br></b>Christopher Vogler</span></p><p>Paperback <br>300 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/193290736X"><img id="Picture16" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
      <td>
       <table nof="ly">
        <tbody><tr>
         <td><img src="http://www.trilane.com/ref/clearpixel.gif" width="23" height="1" alt=""></td>
         <td>
          <div>
             <div><p><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture23" height="125" width="79" src="http://www.trilane.com/ref/a_Screenwriter_s_Problem_Solver_Field.jpg" alt="Screenwriter's Problem Solver_Field" title="Screenwriter's Problem Solver_Field"></a></p><p><span><b>The Screenwriter’s Problem Solver<br></b>Syd Field</span></p><p>Paperback <br>384 pages</p><p><a href="http://www.trilane.com/store"><span>Trilane aStore</span></a><br><a href="http://astore.amazon.com/trilane-20/detail/0440504910"><img id="Picture18" height="28" width="90" src="http://www.trilane.com/ref/a_buy-from-amazon.jpg" alt="buy-from-amazon" title="buy-from-amazon"></a></p></div>
            </div>
         </td>
        </tr>
       </tbody></table>
      </td>
     </tr>
    </tbody></table>
   </td>
  </tr>
 </tbody></div></div>]]>
            </description>
            <link>http://www.trilane.com/ref/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306809</guid>
            <pubDate>Mon, 01 Mar 2021 19:10:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ten seconds to ponder if a thread is worth it]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 44 (<a href="https://news.ycombinator.com/item?id=26306478">thread link</a>) | @eat_veggies
<br/>
March 1, 2021 | https://blog.jse.li/posts/ten-seconds/ | <a href="https://web.archive.org/web/*/https://blog.jse.li/posts/ten-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      
<p>A userstyle that makes you wait ten seconds before entering a Hacker News thread. I use <a href="https://github.com/openstyles/stylus">stylus</a> to manage mine.</p>
<div><pre><code data-lang="css"><span>.</span><span>subtext</span> <span>{</span>
  <span>--bar-color</span><span>:</span> <span>#f60</span><span>;</span>
  <span>--animation-delay</span><span>:</span> <span>0.5</span><span>s</span><span>;</span>
  <span>--animation-duration</span><span>:</span> <span>9.5</span><span>s</span><span>;</span>

  <span>background-image</span><span>:</span> <span>linear-gradient</span><span>(</span><span>to</span> <span>left</span><span>,</span> <span>transparent</span> <span>50</span><span>%</span><span>,</span> <span>var</span><span>(</span><span>--</span><span>bar</span><span>-</span><span>color</span><span>)</span> <span>50</span><span>%</span><span>);</span>
  <span>background-position</span><span>:</span> <span>right</span><span>;</span>
  <span>background-size</span><span>:</span> <span>201</span><span>%</span><span>;</span>
  <span>display</span><span>:</span> <span>inline</span><span>-</span><span>block</span><span>;</span>
  <span>transition</span><span>:</span> <span>background</span><span>-</span><span>position</span> <span>0.2</span><span>s</span><span>;</span>
<span>}</span>

<span>.</span><span>subtext</span><span>:</span><span>hover</span> <span>{</span>
  <span>background-position</span><span>:</span> <span>left</span><span>;</span>
  <span>transition</span><span>:</span> <span>background</span><span>-</span><span>position</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>duration</span><span>)</span> <span>linear</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>delay</span><span>);</span>
<span>}</span>

<span>.</span><span>subtext</span> <span>a</span><span>[</span><span>href</span><span>^=</span><span>"item"</span><span>]</span> <span>{</span>
  <span>pointer-events</span><span>:</span> <span>none</span><span>;</span>
<span>}</span>

<span>.</span><span>subtext</span><span>:</span><span>hover</span> <span>a</span><span>[</span><span>href</span><span>^=</span><span>"item"</span><span>]</span> <span>{</span>
  <span>animation</span><span>:</span> <span>enable-click</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>duration</span><span>)</span> <span>forwards</span> <span>step-end</span> <span>var</span><span>(</span><span>--</span><span>animation</span><span>-</span><span>delay</span><span>);</span>
<span>}</span>

<span>@</span><span>keyframes</span> <span>enable-click</span> <span>{</span>
  <span>to</span> <span>{</span>
    <span>pointer-events</span><span>:</span> <span>auto</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div><p>Special thanks to Martino di Filippo (<a href="https://github.com/MartinodF">@MartinodF</a>) for showing me the <code>animation-timing-function: step-end</code> CSS property!</p>

    </section></div>]]>
            </description>
            <link>https://blog.jse.li/posts/ten-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306478</guid>
            <pubDate>Mon, 01 Mar 2021 18:46:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Won't Save Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26306372">thread link</a>) | @hackitup7
<br/>
March 1, 2021 | https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A common situation: Things are going fine, but not great at your SaaS business. Your sales team’s win rates aren’t quite high enough. Your marketing pipeline isn’t quite as full as you’d like. Your customers are happy but some are considering other solutions. Overall, your product doesn’t quite feel differentiated enough.</p>

<p>A natural temptation that I’ve seen in this situation is to look to machine learning as the solution to your differentiation woes. If we just sprinkle a dash of the ol’ ML on this bad boy, the thinking goes, we’ll have a product that stands out in the market and that everyone will love. In general, this strategy just doesn’t work.</p>

<h2 id="machine-learning-is-not-unique">Machine Learning Is Not Unique</h2>

<p>First – at this point in time, everybody vaguely knows what machine learning is and has a rough sense for its capabilities. You’re not getting a jump on the market by declaring that you’re going to make your product “powered by AI.” Every Gartner report has some checkbox about building intelligent or predictive features, and it’s no longer a secret that there appears to be some magical pixie dust out there that you can drizzle on your product to make it special.</p>

<p>Using machine learning to differentiate your product is like driving a fancy sports car to stand out when picking someone up for a date. It can be cool, it might even fit your persona, and <em>some</em> people will be impressed. But ultimately it isn’t revolutionary or inherently game changing.</p>

<p><img src="https://staysaasy.com/assets/ml-wont-save/russ.jpg" alt="Tres comas">
We have an ML product, now are you interested?</p>

<p>ML is a buzzword of the moment – and investing in buzzwords is not the route to enduring differentiation. There’s always some technology that’s gotten enough mindshare that everyone is sharing blog posts, frantic manifestos are being written, and investors are hot and bothered. 2 decades ago it was cloud, it’s currently (roughly speaking) machine learning and crypto, and who knows what it will be next.</p>

<p>This doesn’t mean that ML features are useless – if it’s useful, people will pay. But there is essentially no novelty left in the ML play. Even if the underlying trend is meaningful (for example, cloud transformation was and continues to be a big deal!), the biggest trends rapidly become table stakes.</p>

<h2 id="a-lot-needs-to-go-right-for-ml-to-work">A Lot Needs to Go Right for ML to Work</h2>

<p>The barrier to building a profitable, differentiating ML-driven product is high – not only in a technical sense, but also in terms of the role that it solves for your business. It can’t just be slapped on top of your product like salad dressing:</p>

<ul>
  <li>You need to have an ML application that fits your business model – for example, if ConvertKit (which Stay SaaSy uses for our newsletter) adds a crazy send-time-optimization product, that might simply not matter for sites like us that use them to email out blog content</li>
  <li>You need a problem that <em>you</em> can solve but <em>others</em> can’t. In reality, you are probably not orders of magnitude smarter than your competition</li>
  <li>You need to solve a problem that has a tangible business impact – only the most frivolous buyers will purchase something just because it’s cool technology</li>
  <li>You need to actually prove that whatever ML magic you’ve built actually solves a key problem better than anyone else can, or for that matter solves a real problem at all</li>
</ul>

<p><img src="https://staysaasy.com/assets/ml-wont-save/emeril.png" alt="Bam!">
Let’s just slap some machine learning on there, and Bam!</p>

<p>A situation that checks all of the boxes above is the holy grail, but you need to be honest about whether that’s the case. It’s very possible that you’d be better off trying to differentiate your SaaS product by <a href="https://staysaasy.com/product/2020/11/04/selling-to-the-enterprise-expand-playing-field.html">creating a suite of functionality</a> or investing heavily in UX – both strategies that many companies have used to construct defensible product moats.</p>

<p>The concept of provable value is one of the most unknown or unappreciated elements of building a sellable ML product. The more that you can prove that you’re adding revenue or reducing costs, the stickier your revenue will be. When the rubber hits the road and something needs to get cut, the products that add value in a provable and (ideally) deterministic way are the ones who survive.</p>

<p>Many customers want to verify the results of anything that they’re paying for, and black boxes understandably scare them. Hype has created a litany of startups peddling ML snake oil and buyers are rightfully skeptical. This increases the barrier to entry and means that it’s much harder to build an enduring ML product. Not only does your product need to work, but you often need to build significant reporting functionality that allows customers to dissect your product and verify the advantage that you claim to provide. And keep in mind that many customers will approach the problem of analyzing whether your algorithms add value adversarially – teams that wanted to build ML products in-house rather than buying yours will be especially aggressive critics and naysayers.</p>

<h2 id="the-promise-of-machine-learning-as-a-silver-bullet-is-distracting">The Promise of Machine Learning as a Silver Bullet is Distracting</h2>

<p>Perhaps the worst part of hoping that you can dust magical machine learning on top of your product is that it trains you to look for silver bullets. ML feels like a new, magical solution that will solve all of your problems. In reality magic solutions are near-mythical and it’s dangerous to believe in them.</p>

<p>The earlier your startup, the worse the optics of saying that you’re going to dominate your market by sprinkling machine learning on your product. If you have terabytes of unique data and claim that it will unlock the portal to Machine Learning Narnia, or if you have a unique approach and track record that indicates true expertise, reasonable listeners will hear you out and not immediately assume that you’re full of it. But if your non-specialized team is trying to raise some kind of seed fundraising on the back of a machine learning story (“We’re just going to do X, but with ML”), then it should be obvious that you don’t have anything vaguely proprietary. At best, you look overly optimistic; at worst, you look like you have no idea what ML actually entails. Unfortunately, some people will pump you up and make you believe that this strategy is viable –&nbsp;the rest will roll their eyes at your “.ai” domain once you leave the room.</p>

<p>Why does this happen? I think it’s because the talk track “we’re going to do X but with AI” does work on a certain kind of unsophisticated observer. If boasting about ML products is like driving a McLaren, there are indeed investors / buyers who are the equivalent of someone who is really, really captivated by a fancy car. You can’t count on this to be an enduring advantage.</p>

<h2 id="where-machine-learning-matters">Where Machine Learning Matters</h2>

<p>Where I’ve seen machine learning make the biggest difference is in extending a lead that you’ve already earned. An example of where ML can really set a product apart is Photoshop’s ability to do <a href="https://blog.adobe.com/en/publish/2020/10/20/photoshop-the-worlds-most-advanced-ai-application-for-creatives.html#gs.mqvj9d">automatic skin smoothing and sky replacement</a>. This is some hardcore stuff, and Adobe has checked the box on the narrow domain where ML products can make a huge difference:</p>

<ul>
  <li>They have the data and team to solve this problem well</li>
  <li>They have a platform (Photoshop itself!) where automatic image manipulation software can be plugged in to add significant value</li>
  <li>You can actually observe that their technology works.</li>
  <li>Photoshop already exists as the most sophisticated graphics editing software, so adding more sophisticated features on top of it extends their advantage on the market</li>
</ul>

<p>Due to the technical moats that it can create machine learning functionality can be a great accelerant when it works well. But you simply can’t rely on it to be the singular differentiator for your business.</p>

<p><img src="https://thumbs.gfycat.com/AdmiredLawfulBunny-size_restricted.gif" alt="These are not the doors of a billionnaire, Richard!"></p>


    

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/product/2021/02/28/machine-learning-wont-save-your-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306372</guid>
            <pubDate>Mon, 01 Mar 2021 18:41:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distributed Capital]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26306264">thread link</a>) | @langitbiru
<br/>
March 1, 2021 | https://blog.aaronkharris.com/distributed-capital | <a href="https://web.archive.org/web/*/https://blog.aaronkharris.com/distributed-capital">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
      <div><p>In theory, the hard part about finding capital for unproven founders with unproven technologies in unproven markets should be that no one wants the risk. There was a time when that was true, but it isn’t anymore.[1] For a founder, the issue is different: venture capital is abundant, but it’s not very evenly distributed.[2]<br></p><p>There are groups of founders to whom this uneven distribution is an advantage. These founders are well connected or pedigreed and can use their access to capital as an advantage in building their startups. That’s good for them, and they should use every advantage they have.</p><p>But the world of startups would be better overall if capital could more easily find great startups. That should be a given, but in looking at the various bottlenecks in the system, it is clear that, at least some of the time, some of the parties involved are actively impeding access and distribution. Other bottlenecks are the result of the fact that venture markets are immature.</p><p><b>Manufactured&nbsp;impedance</b></p><p>Professional investors are in something of a bind when balancing accessibility and exclusivity. On the one hand, the best investors generally believe that returns are driven by significant outliers. These outliers are unlikely to come from an expected source or pattern match precisely on previous outliers. This means that investors would be best served by having the largest possible funnel and the least biased filtering mechanisms. In other words, investors should treat any and all inbound investment opportunities as potentially incredible and equal weight their attention to them.</p><p>However, this presents a set of problems. Investors who tout their willingness to look at everything equally and actually do so will lose their auras of exclusivity. This aura is important in convincing founders to contact the investor and later when investors try to win deals - when given the opportunity, most people choose exclusive clubs over inclusive clubs.</p><p>Then there’s the practical problem: capital may be abundant, but good people and their time are scarce. Let’s say, for instance, an investor decides to follow the “evaluate all inbound” model. This investor actively markets that she’ll meet every company that emails her. The strategy works and the emails pour in.</p><p>That investor will then need the time to meet hundreds of companies each week. Software can help route and filter, an application process can eliminate some number of in person meetings, but the investor will need partners and staff to deal with volume.[3] New partners and staff cost money, which means raising more funds. Larger teams and larger funds start to impact exclusivity, as does the greater numbers of investments dictated by adding people and looking at more companies.[4] Investors who want to pursue the abundance path will get caught in a recursive loop that seems dangerous to their model.</p><p><b>Structural&nbsp;impedance</b></p><p>The other set of barriers to capital distribution exist because venture markets are relatively new and immature. There are many markets without local venture capital investors. Foreign investors may be interested, but face challenges in understanding the nuances of those markets and those founders.[5] This impedes the flow of capital to companies that should get it.</p><p>Because venture markets are relatively new, they are also unnecessarily opaque. Information within these markets is rightly viewed as incredibly valuable, and so it is rationed by those who have it. This makes it hard for new entrants with money to figure out where to put that money. Instead, LPs are required to route it through the professional venture investors that have access to information about what companies are raising and which are not. The analogy here would be an equities market which forced university endowments to call hedge fund managers to discover what stocks exist.</p><p>There are a number of other structural bottlenecks to evening out the distribution of capital. What is so interesting about these and the manufactured bottlenecks is that they could all be solved by either a new common set of behaviors, or an intermediary that made it significantly easier for startups to access the sources of capital already looking for them.[6]</p><p><i><br>This is the second in a set of essays drawn from watching the interactions between investors and founders during several hundred Series A and B in the last few years. If you are wondering how this dynamic impacts your company, please reach out at&nbsp;<a href="https://blog.aaronkharris.com/cdn-cgi/l/email-protection#6100210000130e0f0a0900131308124f020e0c"><span data-cfemail="a3c2e3c2c2d1cccdc8cbc2d1d1cad08dc0ccce">[email&nbsp;protected]</span></a>.</i></p><p>__</p><p>[1] See <a href="https://blog.aaronkharris.com/abundant-capitalhttps://">https://blog.aaronkharris.com/abundant-capital</a></p><p>[2] Apologies to William Gibson for bastardizing one of my two favorite quotes about the future and technology. The other is from Arthur C. Clarke: "Any sufficiently advanced technology is indistinguishable from magic."</p><p>[3] Operating under the assumption that the investor can successfully generate inbound interest.</p><p>[4] Partners at venture funds are primarily evaluated on the quality of their investments. This means they have to actually make investments, especially early in their careers.</p><p>[5] When Rappi first launched, US investors failed to understand the radical differences in their economics relative to US counterparts. These differences were driven by dramatically lower employment costs and urban densities that were only apparent if you’d studied Latin America enough.</p><p>[6] To some extent, YC’s Demo Day does this for seed stage companies. However this function has not yet been replicated at later stages.</p></div>
    
  </div></div>]]>
            </description>
            <link>https://blog.aaronkharris.com/distributed-capital</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306264</guid>
            <pubDate>Mon, 01 Mar 2021 18:34:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 95% Guide to Optimizing Your Website's Performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26306102">thread link</a>) | @goopthink
<br/>
March 1, 2021 | https://romandesign.co/the-95-guide-to-optimizing-your-website/ | <a href="https://web.archive.org/web/*/https://romandesign.co/the-95-guide-to-optimizing-your-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Site optimization is important and if you're reading this post, I assume we're on the same page with why. I won't tell you that faster sites see more traffic, conversions, and overall engagement. Or that they rank better in search results. Or that it makes for a better experience overall. </p><p>(Nevermind, I just told you anyway.)</p><p>Instead, here's a 95%-of-the-way-there guide to optimizing your site for speed and performance. </p><p>It's 95% because I've focused on the free and mostly-not-technical things that will solve the majority of your challenges. If you need more technical solutions past this guide, then there's something significant that needs unique attention and I can't help you. But I <em>can</em> guarantee that this will solve almost every major problem you have. Especially if you're using Wordpress. </p><h2 id="index-">Index:</h2><ul><li>Testing your site's speed</li><li>What causes performance issues?</li><li>Getting to 80%: Fixing Images</li><li>Getting to 90%: Scripts, Fonts, Cruff Code</li><li>Getting to 95%: CDNs, Caching, Preloading</li><li>Getting to 96%: Bonus on live chat tools</li></ul><p>Let's get started!</p><hr><h2 id="testing-your-site-s-speed"><u>Testing Your Site's Speed</u></h2><p>There are a few ways to test site speed and performance:</p><h3 id="3rd-party-tools">3rd Party Tools</h3><ul><li><a href="https://romandesign.co/p/651e677e-3c8e-422b-b0eb-07235c973d3e/tools.pingdom.com">Pingdom</a> will run a rudimentary but complete speed test on any url you provide</li><li><a href="https://gtmetrix.com/">GTMetrix</a> will run a 3-pass test (and have a slightly less friendly UI). A 3-pass test will help to average out temperamental differences in your server, browser, or testing suite.</li></ul><h3 id="browser-tools">Browser Tools</h3><p>You can run your own tests via your browser's "Inspect"/"Dev Tools" mode. In almost every browser, you can right click anywhere on a page and select the <code>Inspect Element</code> option, or go to the menu and select Develop/Developer and open the <code>Web Inspector</code> mode (different browsers use different names).</p><p>The first test to run is in the <code>Network</code> tab in your Dev Tools.</p><figure><img src="https://romandesign.co/content/images/2021/03/ximage.png.pagespeed.ic.bZCYluizye.png"></figure><p>Make sure to disable cache when you test, and then refresh the page to run the test.</p><p>If you're working with Chrome, you can also use the <code>Lighthouse</code> tab for a more in-depth test:</p><figure><img src="https://romandesign.co/content/images/2021/03/image-1.png"></figure><p>Select all of them and test on mobile for the best report. </p><hr><h2 id="what-causes-performance-issues"><u>What Causes Performance Issues?</u></h2><p>In general, the biggest site speed/performance offenders on sites tends to be:</p><ul><li>Images</li><li>Render-blocking javascript and CSS</li><li>Fonts</li><li>Caching</li></ul><p>... in that order. The reasons for this are:</p><ul><li><em>Images</em><br>These tend to be loaded in too big and make the page heavy. If you're downloading a lot of files, you'll slow down the page. </li><li><em>Render-blocking javascript and CSS</em><br>There are a lot of CSS and Javascript issues to talk about, but the biggest issues are those that are render-blocking – aka, they slow down a page from getting to the point of visibility/interactivity. </li><li><em>Fonts</em><br>Similarly, fonts are a problem when they are loaded in unnecessarily... which happens much more often than you think. </li><li><em>Caching</em><br>This essentially means that you don't take advantage of your browser's and server's memory to make things load faster. </li></ul><p>Past that, you're likely looking at deeply technical issues that can't be solved with a standard guide. </p><hr><h2 id="getting-to-80-fixing-images"><u>Getting to 80%: Fixing Images</u></h2><p>Images are easily the number one item that create problems for websites. </p><p>A web-friendly image should be in the range of 50-150kb, <em>max</em>. &nbsp;But most people load in images that are way bigger. They also upload multiple versions of the same image, rather than reusing the first version. They also load physically bigger images than necessary. </p><p>For example, I recently did a site audit for a good friend and images jumped out as easily the number one issue: he was loading in images at 3mb largest, 200-700kb smaller sizes. That's way too big! 6mb of his 7mb page size ended up being unoptimized images.</p><p>So, what can be done? </p><p>Glad you asked. There are a few things to do for image optimization:</p><ul><li>Sizing images correctly</li><li>Compressing images</li><li>Lazy-loading images</li><li>Loading retina images for retina screens</li></ul><h3 id="sizing-images">Sizing Images</h3><p>Sizing images means not bringing in images that are way bigger than they need to be. Going back to my friend's example for a moment: </p><figure><img src="https://romandesign.co/content/images/2021/03/image-2.png"></figure><p>No reason this image should be 3k x 3k pixels if it is being loaded in only at 255 &nbsp;x 255 px! </p><p>Quick caveat: sometimes there's a reason why you might have a bigger-than average image. For example, make sure to test the images at your correct mobile breakpoints (an image on mobile may need to take up more space than on a desktop layout), and load in images 2x the size of what they should be, <em>at most</em>. </p><p>Why 2x? Because retina screens (i.e, iphones, new android phones) have high pixel density -- meaning that for an image to look "crisp" it needs to be loaded in at exactly 2x size. Learn more here, I won't bore you with technical details: <a href="https://premium.wpmudev.org/blog/make-images-retina-ready/">https://premium.wpmudev.org/blog/make-images-retina-ready/</a> </p><h3 id="image-compression">Image Compression</h3><p>The second major issue is compression: most images have a bunch of unnecessary information such as metadata, backup color-spaces, file instructions, and layers that add weight to an image without adding end-viewer value. So by removing excess data (and consolidating very-similar-pixels i.e., #000000 and #000001 into just one color), you can drastically bring down image size without losing quality.</p><p>There are a lot of image optimization tools. Some – like ImageMagik – underpin run from the command line and form the backbone of other image optimization services, while other have a friendly drag-and-drop UI. Because this is a mostly non-technical guide, my recommendation is to use &nbsp;<a href="https://shortpixel.com/online-image-compression">ShortPixel</a> to optimize every image on your site (you can also download a WordPress plugin to automatically do this for every image, if you're using WordPress). </p><p>There are 3 levels of compression that most off-the-shelf tools will offer: <code>Lossless</code> (<em>only </em>metadata is removed); <code>Glossy</code> (some visual compression, but not enough to make a visual difference), and <code>Lossy</code> (smallest file sizes, but you start to notice visual differences and pixelation). My recommendation is to use Glossy compression because you'll be able to get 60-80% smaller files, without any noticeable loss in quality. </p><h3 id="optimizing-image-loading-technical-">Optimizing Image Loading (Technical)</h3><p>For particularly adventurous optimizers, you can also look into Lazy-Loading images: loading an image only when you scroll over it, or come near it while scrolling, rather than loading every single image in from the start. </p><p>This has a lot of value on image-heavy and 'long' pages. I've used lazy-loading to start loading in images when they are 500 pixels below the fold, and continue this as people scroll down a page. It means you're continually loading files as you scroll, but it creates the perception of fast first-load times because you're only loading in the things someone sees when they first look at your page. </p><p>While there are some plugins for this depending on the site you use, it does require a bit more technical know-how, so I'll leave it for you to do some research on this if it is something you're interested in. </p><p>And remember what I said about retina-sized images? You can use <code>retina.js</code> to ensure you're loading in @2x size images <em>only</em> when needed. Again, this is slightly more technical, but easy enough to implement. </p><p>In summary: size images correctly, save them in sRGB colorspace at 72dpi, and make sure to optimize them -- you'll be 95% there to a faster site. </p><p><em>Side note - </em>Wordpress tends to do their own image compression, which I've found problematic at best, bad at worst. I recommend turning off wordpress's native optimizations, which will ruin your image quality. Quick google search (i.e., <a href="https://www.narga.net/how-to-disable-image-compression-in-wordpress/">https://www.narga.net/how-to-disable-image-compression-in-wordpress/</a>) will tell you how.</p><hr><h2 id="getting-to-90-scripts-fonts-and-cruff-code"><u>Getting to 90%: Scripts, Fonts, and Cruff Code</u></h2><p>Before jumping in here, I want to reiterate that if you handle images correctly, you're 80% of the way there to a faster site. This is the next 10% is a bit more technical, but feel free to read on.</p><h3 id="wordpress-cruff">Wordpress Cruff</h3><p>Wordpress is pretty notorious for loading in a lot of cruff code - visual composer, for example, can slow your site down significantly by loading in a lot of 'just in case' code. So my recommendation is to try out <a href="https://wordpress.org/plugins/autoptimize/">autoptimize</a> as an optimizing plugin. It has a lot of flexibility -- I've used it extensively in deferring script loading and organizing code to speed things up.</p><p>Wordpress plugins are also pretty bad: for the most part, you want to use as few plugins as possible. Most of them are poorly written and will add a lot of unnecessary (or duplicated) code. There are a few plugins that are "okay" -- i.e., anything backend specific like Redis-cache and ShortPixel (see below for redis) that don't affect the front end experience. But others, like social share buttons, will really slow your site down by loading in a lot of tracking pixels, spamware, and simply bad, heavy code.</p><h3 id="render-blocking-scripts">Render Blocking Scripts</h3><p>The biggest things to optimize besides images any render-blocking scripts. Code is loaded and executed in a single-path, sequential order (not multi-threaded aka loading in multiple things at the same time). So if there is a very big file at the start of the load order (usually javascript or a font is the culprit), it will block the rest of the page from loading. </p><p>So you want to find a good balance between loading in the 'skeleton' CSS and content first, and then following everything else to create the illusion that the page has loaded faster. This is called Meaningful Paints, and there are actually a bunch of related metrics around that which you can read here: <a href="https://calibreapp.com/blog/reconsider-tracking-fmp">https://calibreapp.com/blog/reconsider-tracking-fmp</a> ... the TLDR version is that to optimize how fast a page feels, load in the things that don't affect the visual experience last. Autoptimize, mentioned above, is what can help with that: deferred loading. </p><h3 id="fonts">Fonts</h3><p>Fonts - like images - cause a surprising amount of problems, which is why you should strongly consider what fonts are 'essential' to your experience and remove unnecessary fonts from being loaded. </p><p>The biggest mistakes people make here are:</p><ul><li>To load in all of the weights of a font when you might only need regular and italic</li><li>Loading in extra fonts that look nice, but are very rarely used, and</li><li>Loading in full icon fonts when you only need maybe 10 icons max. </li></ul><p>To figure out your font …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://romandesign.co/the-95-guide-to-optimizing-your-website/">https://romandesign.co/the-95-guide-to-optimizing-your-website/</a></em></p>]]>
            </description>
            <link>https://romandesign.co/the-95-guide-to-optimizing-your-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306102</guid>
            <pubDate>Mon, 01 Mar 2021 18:25:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weather Line Is Being Acquired]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26306068">thread link</a>) | @trhaynes
<br/>
March 1, 2021 | https://weatherlineapp.com/blog/weather-line-is-being-acquired | <a href="https://web.archive.org/web/*/https://weatherlineapp.com/blog/weather-line-is-being-acquired">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1614540300996" id="item-603bed7d2d7e382fa901d155"><div><div><div data-block-type="2" id="block-2c87e80e3cbf8569cacc"><div><ul data-rte-list="default"><li><p><em>Weather Line is shutting down on April 1, 2022.</em></p></li><li><p><em>No personal data has been sold.</em></p></li><li><p><em>All active subscriptions have been extended for free.</em></p></li></ul><p>Weather Line has been beloved by so many people across its near-decade long life on the App Store. First and foremost, thank you to everyone that has supported the app over the years. We never could have imagined how far it would go. Weather Line has had a fantastic journey as an indie app, and we are grateful to all of you for that.</p><p>In recent months, we were approached by a buyer. They saw the uniqueness of Weather Line and the strong foundation we’ve built. While we aren’t able to provide further details on their future plans for the app, we hope you can understand, and will look forward to it.</p><p>The acquisition means the app is going away. Today, we removed Weather Line from the App Store. <strong>For all existing Weather Line users, free and paid, the app will continue working for 13 months, until April 1, 2022.</strong></p><p><strong>As a thank you, we’ve extended all active SuperCharge subscriptions for free until the app shuts down.</strong> You do not need to take any actions to redeem this, and there are no circumstances where anyone will be billed again by Weather Line.</p><p>For non-paying users – nothing changes. You can continue using those features for free.</p><p><strong>Rest assured that no user data, email addresses, payment information, or any other sensitive data was transferred to Weather Line’s new owners.</strong> This data has not and will not be sold.</p><p>As an Indie Founder without a day job, being able to sell an app provides for my family in a very difficult climate. There’s a poster on my wall that says, “Make something people want.” While this marks the closing of one chapter, I am humbled and honored to have been able to create something people want. Your support and belief over the last nine years has helped me accomplish that, and I’m so incredibly blessed and thankful.</p><p>Thank you,</p><p>Ryan and Kevin</p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://weatherlineapp.com/blog/weather-line-is-being-acquired</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306068</guid>
            <pubDate>Mon, 01 Mar 2021 18:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Frictionless habit-tracking on iOS (pokeable from your text editor too)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26306018">thread link</a>) | @xenodium
<br/>
March 1, 2021 | http://xenodium.com/frictionless-org-habits-on-ios | <a href="https://web.archive.org/web/*/http://xenodium.com/frictionless-org-habits-on-ios">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-frictionless-org-habits-on-ios">

<p><img src="http://xenodium.com/images/frictionless-org-habits-on-ios/flat_habits.gif" alt="flat_habits.gif" width="80%" height="80%">
</p>

<p>
I've been wanting org to keep track of my daily habits for a little while. The catalist: reading James Clear's wonderful <a href="https://jamesclear.com/atomic-habits">Atomic Habits</a> (along with plenty of lock-down inspiration).
</p>

<p>
As much as I live in Emacs and org mode, it just wasn't practical enough to rely on my laptop for tracking habits. I wanted less friction, so I've been experimenting with building a toy app for my needs. Naturally, org support was a strict requirement, so I could always poke at it from my beloved editor.
</p>

<p>
I've been using the app every day with success. The habits seem to be sticking, but equally important, it's been really fun to join the fabulous world of Emacs/Org with iOS/SwiftUI.
</p>

<p>
This is all very experimental<sup><a id="fnr.1" href="#fn.1">1</a></sup> and as mentioned on <a href="https://www.reddit.com/r/emacs/comments/ljurwx/org_habits_ios_app_want_to_try_it/">reddit</a> (follow-up <a href="https://www.reddit.com/r/emacs/comments/lp62vn/org_habits_ios_app_followup_twoway_edit/">here</a>) and <a href="https://twitter.com/xenodium/status/1361034010047176705">twitter</a>, the app isn't available on the App Store. I may consider publishing if there's enough interest, but in the mean time, you can reach out and install via <a href="https://testflight.apple.com/">TestFlight</a>.
</p>

<p>
Send me an email address to <i>flathabits*at*xenodium.com</i> for a TestFlight invite.
</p>
</div></div>]]>
            </description>
            <link>http://xenodium.com/frictionless-org-habits-on-ios</link>
            <guid isPermaLink="false">hacker-news-small-sites-26306018</guid>
            <pubDate>Mon, 01 Mar 2021 18:18:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Go-land you pay even for what you don't use]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26305839">thread link</a>) | @feross
<br/>
March 1, 2021 | https://notes.volution.ro/v1/2021/02/notes/378ae6f6/ | <a href="https://web.archive.org/web/*/https://notes.volution.ro/v1/2021/02/notes/378ae6f6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="prologue">Prologue</h2><p>Lately I've been programming both in Go and Rust -- among other languages like Python, Erlang, or
Bash (and, yes, Bash is a programming language) -- thus those acquainted with Rust will observe that
the title is a hint to one of Rust's major selling points, that of zero cost abstractions, namely
that you don't pay for what you don't actually use (right now, but you might use in the future).</p><p>However, although the issue I'm about to describe is present to some extent in any programming
language -- from Bash (again, yes, Bash is a programming language, although a very bad one), to
Java, Python, Ruby, NodeJS, and even Rust -- unfortunately in Go it is made even worse by not having
a suitable workaround.</p><p>The issue might seem minor, and usually it is so, especially given that only lately when I've
focused on the start-up performance of one of my tools have I stumbled upon this issue. And in fact
the first time I tackled it was with the overhead introduced by loading some Python modules I didn't
always use.</p><p>But, with Python I expected this to be an issue, and I knew immediately where to look. With Go less
so, and I've done quite a bit of digging to find the problem (but unfortunately no usable
solution)...</p><h2 id="what-are-initializers">What are "initializers"?</h2><p>Starting with Go,
<a href="https://golang.org/doc/effective_go.html#init">package initializers</a>
are nothing more than anonymous functions, tagged <code>init</code>, without any arguments, that are executed (in
quite a
<a href="https://golang.org/ref/spec#Package_initialization">specific order</a>)
before the <code>main</code> function of an executable. (I say "anonymous" and "tagged" because inside the same file you
can have many such initializers, and they can't be called explicitly from anywhere.) Obviously these are
meant for libraries and not executables (which can just call that code at the beginning of <code>main</code>).</p><p>What can you do within these initializers? Basically anything you can in a normal function, just
that it executes before <code>main</code>. For example a library could initialize some private (but global)
variables with something that requires a bit of code to figure out, like configuration files,
runtime parameters, credentials, or loading previously computed and then cached data, etc.</p><p>Needless to say, the unwritten (but unenforced) rule of these initializers is that they should be
short and not stall the start-up needlessly... (Especially since Go has lightweight go-routines that
could do the initialization in the background if more effort is required...)</p><p>For example:</p><pre><code>package somePackage

var someGlobalA someTypeA
var someGlobalB someTypeB

func init () {
    // do some non-trivial, but quick, computation...
    someGlobalA = ...
    someGlobalB = ...
}
</code></pre><p>However, this feature is not specific to Go, and as mentioned all programming languages have some
sort of package / module / library initializers:</p><ul><li>Java has
<a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-8.html#jls-8.7">class static initializers</a>,
again with a
<a href="https://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.4">rigid execution order</a>;</li><li>Python, Ruby, NodeJS, and perhaps most similar interpreted languages, just allow arbitrary code
to be executed at the top-level of a module's body; for example as described
<a href="https://docs.python.org/3/tutorial/modules.html">here for Python</a>,
this code will be executed in the same order the modules are being loaded (first dependencies
then dependents, and so on recursively);</li><li>even Erlang, a functional programming language at heart, has something similar as part of OTP
(Erlang's runtime platform);</li><li>and I'm certain that by now -- in 2 AP, as in second "anno pandemus", or for those reading in the
past the year 2021 AD in the future -- C++ already has found a way to provide weapons of mass
feet shooting for its developers;</li><li>(I would bet the same goes for C# and the entire .NET ecosystem;)</li></ul><p>Regarding the other camp:</p><ul><li>Rust, by design, makes sure that
<a href="https://prev.rust-lang.org/en-US/faq.html#can-i-run-code-before-main">there is no life before main</a>;</li><li>(from what I know) C (the language) doesn't also provide a way to have non constant
static initializers;</li><li>moreover, many C-based libraries (and some well-written C++ ones) provide the user with a
<code>somelib_init</code> function that must be called before any other calls to their functions;</li><li>although GCC (and perhaps many other C compilers and runtimes) do provide a way to have
<a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">initialization functions</a>
(or constructors as they are called); however their main use-case seems to support languages
that do require them;</li><li>(I would also bet, but not a lot, that more functional languages like Haskel, and certainly
Scheme implementations of R7RS, are strict about this;)</li></ul><h3 id="but-wait-as-the-commercial-says-there-is-more">But wait, (as the commercial says), there is more...</h3><p>Most of the languages listed above, not only allow you to provide some means to execute arbitrary
code (in fact that feature is more on the advanced developers side), but also provide the developer
a way to initialize global variables with arbitrary expressions.</p><p>Again, in Go, for example:</p><pre><code>package somePackage

var someGlobalC someTypeC = newSomeC ()

func newSomeC () someTypeC {
    // do some non-trivial, but quick, computation...
    return ...
}
</code></pre><p>Thus, what initially might just seem as some harmless variable initialization, in fact could be a
call to a slow grinding wheel computing the answer to the ultimate question (to which we all know
the answer is usually 43 due to a one-off bug)...</p><h3 id="a-slight-detour-about-finalizers">A slight detour about "finalizers"</h3><p>Although many languages provide "initializers", few provide "finalizers", as in code that is assured
to be run before a program finishes.</p><p>The POSIX standard provides
<a href="https://man7.org/linux/man-pages/man3/atexit.3.html">atexit(3)</a>,
GCC does seem to also provide a way to register "destructors", some languages even expose some
wrappers for it, but none seem to provide some actual facility that are tailored for this specific
use-case... Granted some languages do provide some hooks that trigger when a "scope" finishes -- for
example we have <code>defer</code> in Go, and destructors for Rust and C++ -- however these are meant with
another use-case in mind.</p><p>Strange... Perhaps that's why many servers don't provide a clean way to be shutdown, and instead one
has to clobber them with a definitive <code>SIGKILL</code> after asking nicely in vain with <code>SIGTERM</code>, <code>SIGINT</code>
and other SIG-perhaps-this-works signals...</p><p>Also, as a funny irony, for one application in Rust I encountered a situation where calling the
finalizers (i.e. destructors) took quite some time compared to the total execution time, and I had
to resort to forcibly exiting the process without waiting for Rust to properly finalize.</p><h2 id="so-whats-the-issue">So what's the issue?</h2><p>Seeing that almost every programming language under the sun provides a way to sneak some code to be
executed before <code>main</code>, one would ask why I am complaining about this, and especially why I have
something against how it's implemented in Go?</p><p>Well for starters, Go is not the main culprit. Go doesn't force anyone to use the initializers
features, neither does any other language for that mater.</p><p>Moreover, there is the question of utility: if I <code>import</code> a library doesn't it mean I also intend to
use it? After all Go does an outstanding job of making sure (through compilation errors) that there
are no unused imports.</p><p>And here is where the argument (and especially Go's implementation) starts to show its weakness...</p><p>Imagine for a moment we are building a "do everything within a single statically linked binary"
tool.</p><h3 id="a-side-note-about-single-binary-do-all-tools">A side-note about single-binary do-all tools</h3><p>Why would one want to do this? (That is bundle a set of slightly related tools inside the same
executable.)</p><p>Because it's one of the places where Go really shines, as a systems programming language, especially
today with so many operating systems, let alone Linux and BSD distributions, flavors and
architectures. Thus given how easily I can build an OSX, BSD or even Windows executable from my
Linux, regardless if I use an Intel processor and I target Apple's new M1 ARM processor, and
corroborated with the fact that I don't want to dance the <code>rpm</code> or <code>deb</code> polka (not to speak about
the Windows MSI or OSX DMG baroque dance), I would prefer to just throw one binary for each
supported platform on GitHub's release page and be done with that.</p><p>And it seems this isn't a new or isolated trend, as lots of Go projects ship this way:</p><ul><li>starting with (the C-based)
<a href="https://busybox.net/">Busybox</a>
(that I believe powers at least 75% of all world-wide home and small-business networking
appliances), and its BSD alternative
<a href="https://www.landley.net/toybox/">ToyBox</a>;</li><li>Cloudflare's
<a href="https://github.com/cloudflare/cloudflared">cloudflared</a>
or
<a href="https://github.com/cloudflare/cloudflare-go/tree/master/cmd/flarectl">flarectl</a>;</li><li>Netlify's former
<a href="https://github.com/netlify/netlifyctl">netlifyctl</a>;</li><li>open source projects like
<a href="https://github.com/gohugoio/hugo">Hugo</a>
or
<a href="https://github.com/caddyserver/caddy">Caddy</a>;</li><li>(and I could keep on naming similar tools, written from Python to Erlang;)</li><li>(heck, if I think better, this is exactly what the FlatPack and AppImage projects are selling;)</li></ul><p>What all of these have in common? One (usually statically linked, or self-contained /
self-extracting) binary that can be thrown anywhere on the file-system, and as long as it's in the
<code>$PATH</code>, can easily be used.</p><p>What else do they have in common? Lots of slightly related functionality, which I bet are full of
initializers...</p><h3 id="getting-back-to-our-initializers">Getting back to our initializers...</h3><p>So in this case it seems that even though one imports lots of different libraries, they aren't used
all at the same time; at best one or two major libraries are used to implement a given sub-command.</p><p>However, given how initializers work in Go, that is each initializer for every package is run before
<code>main</code> regardless, all these "small but many" initializers add up and slow the startup process.</p><h3 id="so-you-say-this-is-make-believe-problem">So you say this is "make believe problem"?</h3><p>Well not quite... Let's for a second say that my argument about why I would like to bundle
multiple functionality in the same binary is moot; let's say I pay the cost of using a good tool for
the wrong job. Let's...</p><p>Let us imagine one wants to use the Go built-in
<a href="https://golang.org/pkg/net/rpc/">net/rpc</a>
package, that allows one to easily implement RPC clients and servers over HTTP, plain TCP or UNIX
domain sockets. Now it seems that there are some "debugging" facilities that export some HTML for
the available services -- I don't use this, nor do I have any idea on how they are used, nor can
they be disabled -- and as a consequence in its source code, at line 39 in
<a href="https://golang.org/src/net/rpc/debug.go">debug.go</a>,
there is the following code, which unfortunately, based on my experiments, takes at least 0.5
milliseconds to initialize:</p><pre><code>var debug = template.Must(template.New("RPC debug").Parse(debugText))
</code></pre><p>So to summarize:</p><ul><li>Do I use it? No.</li><li>Can I disable it? No.</li><li>Am I …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notes.volution.ro/v1/2021/02/notes/378ae6f6/">https://notes.volution.ro/v1/2021/02/notes/378ae6f6/</a></em></p>]]>
            </description>
            <link>https://notes.volution.ro/v1/2021/02/notes/378ae6f6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305839</guid>
            <pubDate>Mon, 01 Mar 2021 18:04:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doing the impossible, monetising Chrome Extensions]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26305789">thread link</a>) | @thomasisaac
<br/>
March 1, 2021 | https://tillypay.com/blog/how-to-monetise-a-chrome-extension/ | <a href="https://web.archive.org/web/*/https://tillypay.com/blog/how-to-monetise-a-chrome-extension/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>So here you are, you’ve built a tool for the Chrome Web Store and suddenly you’ve been bestowed with a<strong> couple of thousand users across the globe</strong>.</p><p>One question, would be how to monetise such an impressive piece of tech you’ve created.</p><p>If you’ve spent your time on an Android or iOS, the path to monetisation are far easy &amp; a lot simplier. Somehow, however, <strong>Chrome Extensions don’t carry the same weight</strong> in the mind of the user. They are much more inclined to pay for an app or an ongoing service but Chrome Extensions wind up in the realm of “should be free.”</p><p>A lot of chrome extensions are the child of a large product or a global product itself, cases such as Honey, the coupon finder &amp; Grammerly are super giants that don’t really fall into the realm of developer accidently making a tool valuable to thousands.</p><p>There seems to be a vat of extensions floating around the 20k to 50k mark, not been updated since 2015. What do to?</p><p>Rather than give you a list of things<strong> untried or untested with affiliate links attached, let’s run through stories that I know.</strong></p><p>There's a new platform called <a href="https://monetise.so/">Monetise.so</a>, they have built a Chrome Extension billing platform as a direct replacement for the upcoming sunset of the Chrome Web Store Payments.</p><p>Check them out : <a href="https://monetise.so/">https://monetise.so</a></p><p>It’s no secret that Adblock Plus with their ~100 Million global users have profited from the blockage of adverts existing on internet.</p><p>The business model is unique &amp; simple, they allowed certain whitelisted ads through, non-intrusive and Google paid them an undisclosed amount.</p><p>They are not the only ones who do what they do, but they’re very good at it.<br>They aggregate affiliate schemes across the internet and put them into a single JS file for you to plugin to your site. They also built something for Chrome Extensions, after you include in your code, they will start including logos on Google Search Results, like so:</p><figure><img src="https://tillypay.com/blog/content/images/2020/02/1-tf0Kx1jGsc5mmRHPo7VYXA.png"></figure><p>The DJI link is now monetised and everyone is happy, the user who is paying somewhat for the extension, the extension developer but not Google Chrome, understandably.</p><p>This is malvertising, it’s advertising in a malware way of including unwanted code. Even with it’s horrid name, if privacy is not your thing, then there’s very little impacting the end user. The issue comes when you are allowing a third party with that much access to your google searches, maybe not.</p><p>Actually, I do have access to the maths on this:</p><ul><li><strong>50,000 Weekly Users resulted in about €2.2k a month.</strong></li><li>That’s about <strong>4.4 cent per user,</strong> mostly from Tier 1 GEOs (US, UK, FR, DE)</li></ul><p>Google will kick you out if they find this.<br>It's happened time &amp; time again.</p><p>Revolution, is what they called it.<br>A new way to monetise the internet.</p><p>Yes, but no. Firstly, the UX for your end-user sucks balls.<br>Their brand new computer is down to it’s last leg trying to get the you (the developer), $0.0002 per minute of agony.</p><p>Also, I’ve tried this.<br>I had 10k Weekly Users, that turned into about 30 concurrent users on average at any one time.</p><p>I made $16 a month from Coinhive at 25% of his user’s CPU.</p><p>Back to the drawing board.</p><p><em>Freemium</em><br>Popular topic on the lips of SaaS models, provide something a bit more &amp; users are willing to pay for it. The problem you may have is that you product just isn’t worth a cup of coffee a month. On a popular VPN Chrome extension, they managed to get 50k users a month to pay for their premium product out of a user base of 4 million MAU. Their premium product was pretty damn great too.</p><p>Here are some great stories of Chrome Extensions being monetised in this way:</p><ul><li><a href="https://www.indiehackers.com/interview/how-sharing-helpful-knowledge-helped-me-grow-to-2-500-month-ad9b94660e">Weather App</a> - $2.5k MRR</li><li><a href="https://beebs.io/">Beebs</a> - <a href="https://www.indiehackers.com/interview/from-no-coding-skills-to-50k-downloads-in-two-years-eca7ea8587">$5K MRR</a></li><li>Nighteye, nightmode - <a href="https://www.indiehackers.com/product/night-eye">$2.3k MRR</a></li></ul><p><em>Paid-Only</em><br>Yes, this works well if your product is good enough for the switch.<br>Might be fairly difficult to encourage users to pay for the simple RSS extension you created.</p><p><em>Paywall or not to Paywall</em><br>Paywalling your current userbase guarantees the maximum number of conversions in that time period, everything else is bad news. Chrome extensions have review mechanisms that mean you’ll paywall your userbase &amp; they turn to the review board for revenge. <a href="https://chrome.google.com/webstore/detail/media-hint/akipcefbjlmpbcejgdaopmmidpnjlhnb" rel="noopener nofollow">See here</a>.</p><p>I decided to paywall all the new users but keep the old users free. This way I had 50,000 people who loved &amp; would recommend the extension and a steady stream of newcomers who some (5%) of them would pay a monthly subscription for it.</p><p><strong>The best way to start paywalling is to use <a href="https://monetise.so/">Monetise.so</a>, they are a direct replacement of the Chrome Web Store.</strong></p><p>This could be a possibility for you, I know of a few examples this works well:</p><p><a href="https://chrome.google.com/webstore/detail/tab-for-a-cause/gibkoahgjfhphbmeiphbcnhehbfdlcgo?hl=en" rel="noopener nofollow">Tab for a Cause</a><br>They have a new tab page with an advert on it, they donate roughly ~30% of their Gross Revenue to charities.</p><p>Total Q1 2019 Revenue: <strong>$139,395.93.</strong><br>$0.25 per user per month, not bad at all.</p><p>They have, what you probably don’t is a lot of coverage being at the new tab page of every single user.</p><p><a href="http://ecosia.org/" rel="noopener nofollow"><strong>Ecosi</strong></a>a is the tree planting search engine, uses its advert revenue into planting trees across the planet. It’s difficult to quantify as they have many platforms.<br>However, diverting your user-base to a search engine is quite a profitable business, the difficulty is getting them there in the first place.</p><p>Unsure on the user numbers, but they made €2.5M in the last reported month with 10 million users. &nbsp;</p><p><a href="https://chrome.google.com/webstore/detail/norton-safe-search/gkjahlcnbjiangkneanonnndppicobbd?hl=en" rel="noopener nofollow"><strong>Norton Safe Search</strong></a> is an example of a company forcefully changing your search engine for monetary gain, there is absolutely zero benefit to an anti-virus search engine, none.</p><p>You have to be a position where changing search or implementing adverts seems legitimate. Google will quickly remove your extension if you do that.</p><p>Thee value of switching user for these Bing-copycat search engines is about €0.80 per weekly user for a tier 1 geo; really not bad going.</p><p><a href="https://chrome.google.com/webstore/detail/panda-5-your-favorite-web/haafibkemckmbknhfkiiniobjpgkebko?hl=de&amp;" rel="noopener nofollow"><strong>Panda</strong></a> offer chrome extension, 60K weekly users that probably wittles down to 10k MAU. Squarespace reportedly pay $4k a month for a spot.</p><p>Don’t do this.<br>Like <a href="https://9to5google.com/2019/12/17/chrome-avast-extensions-removed/" rel="noopener nofollow">Avast have done</a>, they collected clickstream data to feed their other suspicously data rich company, <a href="https://www.jumpshot.com/" rel="noopener nofollow">Jumpshot</a>.<br>Like <a href="https://www.businessinsider.com/evidon-sells-ghostery-data-to-advertisers-2013-6?r=DE&amp;IR=T" rel="noopener nofollow">Ghostery</a> have done.</p><p>Both Firefox &amp; Chrome will kick you out even at a whiff of this.<br>Good money, undoubtedly but I have no numbers.<br>I was recently told of a 6 digit figure for access to search data with Jumpshot.</p><p>Hola Unblocker allow for users to access geo-blocked content, but at a cost.<br>Your computer becomes a part of the appropriately named, <a href="https://luminati.io/" rel="noopener nofollow">Luminati</a> network.<br>They then sell your connection to the highest bidder and all sorts can run through the computer. It makes unblocking a doddle. With access to apparently 40M residential IPs, it’s pretty massive and <a href="https://luminati.io/static/IPPN-analysis-2019.pdf?md5=3109015-85e418b7" rel="noopener nofollow">making $40M a year.</a></p><p>If you don't understand residential proxies, here's a<a href="https://proxyscraper.io/what-is-a-residential-proxy/"> little guide.</a></p><p>Lastly, donations. I only really have non-quantitative information on donations for Chrome Extensions.</p><p>They don’t work as well as they should, you might gather bits &amp; pieces of cash here and there but it’s the lowest form of per user donation, you are not wikipedia or the Guardian, remember that.</p><p>If you’ve gathered enough mass and provide a valuable time/money/effort savings product, then I’d opt for the Premium tier.<br>If you can place adverts or have an opportunity to, try that out.<br>Ultimately, get to know your users and get a feel for what fits well.</p><p>Anything untoward is unsustainable.<br>Good luck.</p>
    </section></div>]]>
            </description>
            <link>https://tillypay.com/blog/how-to-monetise-a-chrome-extension/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305789</guid>
            <pubDate>Mon, 01 Mar 2021 18:00:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The small web is beautiful]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26305585">thread link</a>) | @benhoyt
<br/>
March 1, 2021 | https://benhoyt.com/writings/the-small-web-is-beautiful/ | <a href="https://web.archive.org/web/*/https://benhoyt.com/writings/the-small-web-is-beautiful/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">



<div id="content">

<p>March 2021</p>

<blockquote>
  <p>Summary: I believe that small websites are compelling aesthetically, but are also important to help us resist selling our souls to large tech companies. In this essay I present a vision for the “small web” as well as the small software and architectures that power it. Also, a bonus rant about microservices.</p>

  <p><strong>Go to:</strong> <a href="#small-software">Software</a> | <a href="#small-websites">Web</a> | <a href="#emphasize-server-side-not-javascript">Server-side</a> | <a href="#static-sites-and-site-generators">Static sites</a> | <a href="#fewer-dependencies">Dependencies</a> | <a href="#small-analytics">Analytics</a> | <a href="#small-architectures-not-microservices">Microservices</a></p>
</blockquote>

<p>About fifteen years ago, I read E. F. Schumacher’s <em>Small is Beautiful</em> and, despite not being interested in economics, I was moved by its message. Perhaps even more, I loved the terse poetry of the book’s title – it resonated with my frugal upbringing and my own aesthetic.</p>

<p>I think it’s time for a version of that book about technology, with a chapter on web development: <em>The Small Web is Beautiful: A Study of Web Development as if People Mattered.</em> Until someone writes that, this essay will have to do.</p>

<p>There are two aspects of this: first, <strong>small teams and companies</strong>. I’m not going to talk much about that here, but <a href="https://basecamp.com/books">Basecamp</a> and many others have. What I’m going to focus on in this essay is <strong>small websites and architectures</strong>.</p>

<p>I’m not the first to talk about the “small web”, but, somewhat surprisingly, only a few people have discussed it using that term. Here are the main web pages I can find that do:</p>

<ul>
  <li><a href="https://neustadt.fr/essays/the-small-web/">Rediscovering the Small Web</a> by Parimal Satyal: a fabulous article about the joy of small, independent (and sometimes retro) websites in contrast to the “commercial web”.</li>
  <li><a href="https://ar.al/2020/08/07/what-is-the-small-web/">What is the Small Web?</a>, by Aral Balkan of the Small Technology Foundation: more of a manifesto against the surveillance of Big Tech than something concrete, but still interesting.</li>
</ul>

<p>Why aim small in this era of fast computers with plenty of RAM? A number of reasons, but the ones that are most important to me are:</p>

<ul>
  <li>Fewer moving parts. It’s easier to create more robust systems and to fix things when they do go wrong.</li>
  <li>Small software is faster. Fewer bits to download and clog your computer’s memory.</li>
  <li>Reduced power consumption. This is important on a “save the planet” scale, but also on the very local scale of increasing the battery life of your phone and laptop.</li>
  <li>The light, frugal aesthetic. That’s personal, I know, but as you’ll see, I’m not alone.</li>
</ul>

<p>So let’s dive in. I want to cover a bunch of different angles, each with its own subheading.</p>

<h2 id="small-software">Small software</h2>

<p>If we’re going to talk about a small web, we need to start with small <em>software</em>.</p>

<p>As a teen, I learned to program using x86 assembly and <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> – perhaps odd choices, but my dad was heavily into Forth, and I loved how the language was so simple I could write <a href="https://github.com/benhoyt/third">my own bootstrapped compiler</a>.</p>

<p>In terms of career, I started as an embedded programmer – not as in “embedded Linux” but as in microcontrollers where 16KB of RAM was generous. My current laptop has 16GB of RAM, and that’s not a lot by today’s standards. We were building IP-networked products with <em>one millionth</em> the amount of RAM. Those kinds of micros are as cheap as chips (ahem), and still widely used for small electronic devices, sensors, internet-of-things products, and so on.</p>

<p>You have to think about every byte, compile with size optimizations enabled, and reuse buffers. It’s a very different thing from modern web development, where a JavaScript app compiles “down” to a 1MB bundle, or a single Python object header is 16 bytes before you’ve even got any data, or a Go hello-world binary is 2MB even before you’ve added any real code.</p>

<p>How do you create small programs? I think the main thing is that you have to <em>care about size</em>, and most of us don’t think we have time for that. Apart from embedded development, there’s an entire programming subculture called the <a href="https://en.wikipedia.org/wiki/Demoscene">demoscene</a> that cares about this. They have competitions for the smallest 4KB demos: who can pack the most graphical punch into 4096 bytes of executable. That’s smaller than many favicons! (<a href="https://www.youtube.com/watch?v=jB0vBmiTr6o">Elevated</a> and <a href="https://www.youtube.com/watch?v=RCh3Q08HMfs">cdak</a> are two of the highest-rated 4K demos.) Many demosceners go on to become game developers.</p>

<p>It’s not just about executable size … when you’re developing your next command line tool, if you use Go or Rust or even C, your program will be much faster, smaller, and use less memory than a Python or Java equivalent. And easier to install. If you don’t understand why, please do learn. (It’s out of scope for this essay, but to summarize: Go, Rust, and C compile to ready-to-execute machine code, don’t carry around a virtual machine, and don’t have memory overhead for objects like integers.)</p>

<p>But why not apply some of the same principles to web development? In the web world, I think the main trick is to be careful what dependencies you include, and also what dependencies <em>they</em> pull in. In short, know <code>node_modules</code> – or maybe better, <em>no</em> <code>node_modules</code>. More about this <a href="#fewer-dependencies">below</a>.</p>

<p>Niklaus Wirth of Pascal fame wrote a famous paper in 1995 called <a href="https://cr.yp.to/bib/1995/wirth.pdf">A Plea for Lean Software [PDF]</a>. His take is that “a primary cause for the complexity is that software vendors uncritically adopt almost any feature that users want”, and “when a system’s power is measured by the number of its features, quantity becomes more important than quality”. He goes on to describe Oberon, a computer language (which reminds me of Go in several ways) and an operating system that he believes helps solve the complexity problem. Definitely wirth a read!</p>

<p>I’ve been mulling over this for a number of years – back in 2008 I wrote a sarcastic dig at how bloated Adobe Reader had become: <a href="https://blog.brush.co.nz/2008/07/adobe-reader-9/">Thank you, Adobe Reader 9!</a> It was a 33MB download and required 220MB of hard drive space even in 2008 (it’s now a 150MB download, and I don’t know how much hard drive space it requires, because I don’t install it these days).</p>

<p>But instead of just complaining, how do we actually solve this problem? Concretely, I think we need to start doing the following:</p>

<ul>
  <li>Care about size: this sounds obvious, but things only change when people think they’re important.</li>
  <li>Measure: both your executable’s size, and your program’s memory usage. You may want to measure over time, and make it a blocking issue if the measurements grow more than <em>x</em>% in a release. Or you could hold a memory-reduction sprint every so often.</li>
  <li>Language: choose a backend language that has a chance, for example Rust, C or C++, or for servers, Go. These languages aren’t right for everything (like data transformation scripts), but they produce small executables, and they’re good for CLIs and desktop apps.</li>
  <li>Remove: cut down your feature set. Aim for a small number of high-quality features. My car can’t fly or float, and that’s okay – it drives well.</li>
  <li>Say no to new features: unless they really fit your philosophy, or add more than they cost over the lifetime of your project.</li>
  <li>Dependencies: understand the size and complexity of each dependency you pull in. Use only built-in libraries if you can.</li>
</ul>

<h2 id="small-websites">Small websites</h2>

<p>I’m glad there’s a growing number of people interested in small websites.</p>

<p>A few months ago there was a sequence of posts to Hacker News about various “clubs” you could post your small website on: the <a href="https://1mb.club/">1MB Club</a> (<a href="https://news.ycombinator.com/item?id=25151773">comments</a>), <a href="https://512kb.club/">512KB Club</a> (<a href="https://news.ycombinator.com/item?id=25450451">comments</a>), <a href="https://250kb.club/">250KB Club</a> (<a href="https://news.ycombinator.com/item?id=25176663">comments</a>), and even the <a href="https://10kbclub.com/">10KB Club</a> (<a href="https://news.ycombinator.com/item?id=25556860">comments</a>). I think those are a fun indicator of renewed interested in minimalism, but I will say that raw size isn’t enough – a 2KB site with no real content isn’t much good, and a page with 512KB of very slow JavaScript is worse than a snappy site with 4MB of well-chosen images.</p>

<p>Some of my favourite small websites are:</p>

<p><a href="https://news.ycombinator.com/news">Hacker News</a>: I personally like the minimalist, almost brutalist design, but I love its lightness even more. I just downloaded the home page, and loading all resources transfers only 21KB (61KB uncompressed). Even pages with huge comment threads only transfer about 100KB of compressed data, and load quickly. Reddit has become such a bloated mess in comparison. Hacker News, never change!</p>

<p><a href="https://lobste.rs/">Lobsters</a>: a similar news-and-voting site, with slightly more “modern” styling. It uses some JavaScript and profile icons, but it’s still clean and fast, and the total transfer size for the homepage is only 102KB. You just don’t need megabytes to make a good website.</p>

<p><a href="https://sourcehut.org/">Sourcehut</a>: I like the concept behind Drew DeVault’s business, but I love how small and anti-fluff the website is. He has set up a mini-site called the <a href="https://forgeperf.org/">Software Forge Performance Index</a> that tracks size and browser performance of the prominent source code websites – Sourcehut is far and away the lightest and fastest. Even his homepage is only 81KB, including several screenshot thumbnails.</p>

<p><a href="https://sqlite.org/">SQLite</a>: not only is SQLite a small, powerful SQL database engine, the website is fantastically small and content-rich. Even their 7000-word <a href="https://sqlite.org/testing.html">page about testing</a> is only 70KB. How do they do this? It’s not magic: focus on high-quality textual content, minimal CSS, no JavaScript, and very few images (a small logo and some SVGs).</p>

<p><a href="https://lwn.net/">LWN</a>: I’m a little biased, because I’ve written <a href="https://lwn.net/Archives/GuestIndex/#Hoyt_Ben">articles</a> for them, but they’re an excellent website for Linux and programming news. Extremely high-quality technical content (and a high bar for authors). They’re definitely niche, and have a “we focus on quality content, not updating our CSS every year” kind of look – they’ve been putting out great content for 23 years! Their homepage only downloads 44KB (90KB uncompressed).</p>

<p><a href="https://danluu.com/">Dan Luu’s blog</a>: this is one of the more hardcore examples. His inline CSS is only about 200 bytes (the pages are basically unstyled), and his HTML source code doesn’t use any linefeed characters. Kind of a fun point, although then he goes on to load 20KB of Google Analytics JavaScript…</p>

<p>As a friend pointed out, those websites have something of an “anti-aesthetic aesthetic”. I confess to not minding that at all, but on the other hand, small doesn’t have to mean ugly. More and more personal blogs and websites have adopted a small web approach but are more typographically appealing:</p>

<ul>
  <li><a href="https://lucumr.pocoo.org/">Armin Ronacher’s Thoughts and Writings</a></li>
  <li><a href="https://nullprogram.com/">Chris Wellons’ “Null program” blog</a></li>
  <li><a href="http://eradman.com/">Eric Radman’s BSD and SQL blog</a></li>
  <li><a href="https://hugotunius.se/">Hugo Tunius’ programming blog</a></li>
  <li><a href="https://prog21.dadgum.com/">James Hague’s “Programming in the …</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benhoyt.com/writings/the-small-web-is-beautiful/">https://benhoyt.com/writings/the-small-web-is-beautiful/</a></em></p>]]>
            </description>
            <link>https://benhoyt.com/writings/the-small-web-is-beautiful/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26305585</guid>
            <pubDate>Mon, 01 Mar 2021 17:44:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HECnet – The Hobbyist DECnet Network]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26304949">thread link</a>) | @bilegeek
<br/>
March 1, 2021 | http://www.update.uu.se/~bqt/hecnet.html | <a href="https://web.archive.org/web/*/http://www.update.uu.se/~bqt/hecnet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<center><b><span size="+4">HECnet - The hobbyist DECnet network.</span></b></center>
<span size="+2">What is HECnet?</span>
<p>HECnet is a DECnet that connects different people who play around with
  different machines that have the DECnet protocol suite.
  The network should not be regarded as a serious
networking setup, nor should it be expected to work 24/7. It's a hobby
project between people who think it's fun to create a DECnet network.
<br>HECnet is basically a DECnet phase IV network. Currently, the main
router is a PDP-11 running RSX-11M-PLUS. The machine is located in Uppsala,
Sweden.
<br>The connectivity between nodes can be anything that works. The current
connectivity is with an ethernet bridge between sites, DECnet over IP using
Multinet on VMS or RSX, and DECnet over IP on Cisco. Other solutions that
have been used are a virtual serial async. connection talking DDCMP. Other possibilities
are GRE and DECnet over IP.
</p><p><span size="+2">How do I get connected?</span>
</p><p>In order to connect to HECnet, you need to talk with the resposible
person (currently that is <a href="http://www.update.uu.se/~bqt/">Johnny
Billquist</a> &lt;<a href="mailto:bqt@update.uu.se">bqt@update.uu.se</a>&gt;)
about allocating a node name and number. The node names in DECnet phase
IV must be unique within the whole network, so this have to be coordinated.
(Well, technically, you can have local node names defined for machines
at every node in DECnet, but that isn't much fun, is it?)
Secondly, you need a node number. What number depends on where you get
connected.
<br>After that, you need to set up a connection to whatever DECnet router
you should be connected to. How this is done depends on what kind of connection
you will have.
<br>An ethernet bridge will require a separate Unix machine on the same
ethernet segment as your DECnet machines, which then bridges your
ethernet with the rest of HECnet. This is not a full bridge, but only
one that transmits packets for DECnet, so the rest of the network is not
compromised.
On this Unix computer, you need to compile, configure and run the ethernet
bridge program, which can be found <a href="http://www.update.uu.se/~bqt/bridge.tar">&gt;&gt;here&lt;&lt;</a>.
The configuration requires that you talk with someone else running
the bridge, and agreeing on some parameters for the bridge. You should
probably join the HECnet mailing list at this stage before expecting
things to start working.
</p><p><span size="+2">More information?</span>
</p><p>If you want more information, you can write a mail to <a href="http://www.update.uu.se/~bqt/">Johnny
Billquist</a> &lt;<a href="mailto:bqt@update.uu.se">bqt@update.uu.se</a>&gt;
and ask about whatever you want to know. There is also a mailing list,
&lt;<a href="mailto:hecnet@update.uu.se">hecnet@update.uu.se</a>&gt; for discussions
about HECnet. To join you write to &lt;<a href="mailto:majordomo@update.uu.se">majordomo@update.uu.se</a>&gt;,
and the body of the mail should contain "subscribe hecnet" in it.
</p><p><span size="+2">What does HECnet mean?</span>
</p><p>Well, we had problems coming up with a good name, and just for the heck
of it, it was named HECnet (that is also pretty close in sounding to DECnet).
</p><p><span size="+2">Useful links:</span>
</p><p>Here is a short list of links that people might enjoy:
</p><ul>
<li>
<a href="http://mim.update.uu.se/">HECnet information on Mim</a>
</li><li>
<a href="http://mim.update.uu.se/nodedb">HECnet nodename database</a>
 - the nodename database, as managed by MIM:: (RSX-11M-PLUS V4.6)
</li><li>
<a href="http://mim.update.uu.se/hecnet">Mim node info</a> - a
service to get node information. Running on MIM:: (RSX-11M-PLUS V4.6)
</li></ul>


</div>]]>
            </description>
            <link>http://www.update.uu.se/~bqt/hecnet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304949</guid>
            <pubDate>Mon, 01 Mar 2021 17:02:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fighter Pilots Rely on Technology That Will One Day Steal Their Jobs]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26304857">thread link</a>) | @mathatoms
<br/>
March 1, 2021 | https://thedebrief.org/fighter-pilots-rely-on-technology-that-may-one-day-steal-their-jobs/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/fighter-pilots-rely-on-technology-that-may-one-day-steal-their-jobs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p>Advancements in safety software installed onboard military fighter jets have led to systems that are being credited with saving the lives of nearly one dozen fighter pilots and preventing the loss of their aircraft in recent years.</p>

<p>A challenge encountered by fighter pilots maneuvering increasingly powerful planes capable&nbsp;of accelerating to Mach 2 and beyond is avoiding blacking out at the controls. While a relatively infrequent occurrence, it does happen, particularly during training missions. The current generation of F-16 Fighting Falcons and F-35 Lightning IIs has been receiving upgrades to AI-driven software that detects impending ground collisions if a pilot blacks out, taking over control of the aircraft and returning it to a safe heading. This is an admirable advancement in terms of safety, but ironically, the technology driving this software may, before very long, largely eliminate the need for the very pilots it was designed to save.</p>

<h2><b>BACKGROUND: Life-Saving Technology</b></h2>
<p>When pilots experience too much gravitational force during high-speed maneuvers they can succumb to a condition known as&nbsp;G-induced loss of consciousness, or G-LOC. This is characterized by a tendency for the pilot’s blood to flow toward their extremities and away from their brains, which may result in fainting. There are exercises pilots practice to prevent this from happening and modern flight suits are designed to mitigate the effect as well, but both have their limits.</p>

<p>Just last year, two F-16 pilots flying over a test range in Nevada experienced G-LOC events, losing consciousness. In both instances, an onboard system took over control of the planes, righted them in a stable flight configuration and prevented the planes from impacting the ground. A safety review after each incident concluded that both planes would almost certainly have crashed had the software not intervened.</p>

<div>
<figure id="attachment_3668" aria-describedby="caption-attachment-3668"><img src="https://thedebrief.org/wp-content/uploads/2021/02/1024px-F-16C_Fighting_Falcon-e1614590684872.jpeg" alt="F-16" width="760" height="587" data-src="https://thedebrief.org/wp-content/uploads/2021/02/1024px-F-16C_Fighting_Falcon-e1614590684872.jpeg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3668">A US Air Force (USAF) F-16C Fighting Falcon, 120th Fighter Squadron (FS), 140th Fighter Wing (FW), Colorado Air National Guard (Credit: USAF/Public Domain).</figcaption></figure>
</div>

<p>The software that saved the pilots and planes was developed by Lockheed Martin, the same company that manufactures both the F-16 and the F-35. It’s named the Automatic Ground Collision Avoidance System, or AGCAS. The technology is not installed in all combat aircraft yet, but will likely eventually be ubiquitous among our fleets of fighter craft.</p>


<h2><b>ANALYSIS: IS OUR TECHNOLOGY OUTGROWING THE NEED FOR PILOTS?</b></h2>
<p>While the fighter pilots in our combat aircraft are safer today, they’re not nearly as safe as a new generation of pilots who are currently fighting alongside them but doing it from the other side of the world. New generations of <a href="https://thedebrief.org/trump-signs-order-on-threats-posed-by-unmanned-aircraft-systems/">Unmanned Aeriel&nbsp;Vehicles (UAVs)</a>, commonly referred to as drones, have been increasingly taking on combat duties traditionally handled by human pilots. Some of the most popular with many militaries around the world are the&nbsp;General Atomics Aeronautical Systems Inc (GA-ASI) MQ-9 series Reapers and SeaGuardians, among others.</p>

<p>These UAVs can be piloted in real-time by pilots stationed inside of control centers located in Nevada and on other military bases far from the battlefield. When conditions require it, artificial intelligence systems can take over and complete missions, using AI systems even more complex and durable than the AGCAS software currently saving the lives of pilots.</p>

<p>The range of missions that can be executed by these UAVs has gone well beyond simply arming them with cannons and smart bombs to take out specific targets. One class of MQ-9s <a href="https://www.janes.com/defence-news/news-detail/ga-asi-demos-asw-capability-for-reaperseaguardian-uass" target="_blank" rel="noopener">was recently approved</a> for conducting autonomous anti-submarine warfare (ASW) operations for the Navy, demonstrating the ability to deploy sonobuoys&nbsp;into the ocean and sending target data back to its pilot in Nevada. More recently, the&nbsp;Northrop Grumman RQ-4 Global Hawk has been <a href="https://www.janes.com/defence-news/news-detail/usaf-chief-of-staff-sees-agility-prime-aircraft-fulfilling-logistics-missions" target="_blank" rel="noopener">taking on logistics and intelligence duty</a> missions, once the province of planes like the U-2.</p>

<div><p><iframe id="_ytid_89074" width="1170" height="658" data-origwidth="1170" data-origheight="658" src="https://www.youtube.com/embed/Oyu19qNPerc?enablejsapi=1&amp;autoplay=0&amp;cc_load_policy=0&amp;iv_load_policy=1&amp;loop=0&amp;modestbranding=1&amp;fs=1&amp;playsinline=0&amp;controls=1&amp;color=red&amp;cc_lang_pref=&amp;rel=1&amp;autohide=2&amp;theme=dark&amp;" title="YouTube player" allow="autoplay; encrypted-media" allowfullscreen="" data-no-lazy="1" data-skipgform_ajax_framebjll=""></iframe></p></div>


<h2><b>THEY CAN’T REALLY REPLACE HUMAN Fighter PILOTS, RIGHT?</b></h2>
<p>The reality is that aircraft have been evolving and getting “smarter” along with many other avenues of technology, from nearly the moment of their inception. In <a href="https://www.tandfonline.com/doi/full/10.1080/14702436.2019.1676156" target="_blank" rel="noopener">a 2019 research paper</a>published in the journal <i>Defence Studies</i>, Dr.&nbsp;Arash Heydarian Pashakhanlou noted that barely a decade after the Wright Brothers’ famous flight at Kittyhawk, the first autopilot had been developed, capable of keeping a plane at a steady altitude, course, and speed. In the 21st century, the author notes, the autopilot systems in commercial airliners are actually better and more reliable than the humans in the cockpit. Some of the newer versions are actually more reliable for landings and takeoffs, not just maintaining course once the craft reaches cruising altitude.</p>

<p>Obviously, the challenges of flying a fighter jet in combat far exceed those arising in a normal commercial flight between two United States hubs. But that doesn’t mean that the challenges are beyond the reach of current automated piloting systems, assuming the machines haven’t already surpassed the master. Particularly when you consider that the most complicated UAV are still being directly controlled by human pilots at a distance with some AI thrown in as a backstop, human pilots in a craft’s cockpit may already be largely redundant in the latest generations of warfighting aircraft.</p>
<div>
<figure id="attachment_3670" aria-describedby="caption-attachment-3670"><img src="https://thedebrief.org/wp-content/uploads/2021/02/F-35-Sgt.-Katerina-Slivinske-e1614590721394.jpg" alt="fighter pilots" width="760" height="543" data-src="https://thedebrief.org/wp-content/uploads/2021/02/F-35-Sgt.-Katerina-Slivinske-e1614590721394.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3670">(Credit: USAF/Public Domain)</figcaption></figure>
</div>

<p>Compounding the problem is the fact that the military is facing <a href="https://www.military.com/daily-news/2020/02/18/air-force-misses-new-pilot-goal-again-service-pushes-revolutionize-training.html">recurring shortages</a> of pilots. Training a military pilot and putting them into service is a time-consuming and expensive process. But many of them leave the military after their minimum term of service is up, taking lucrative jobs in the commercial sector. This has very likely been one of the factors driving the push to advance the technology of pilotless aircraft.</p>

<h2><b>CONCLUSIONS</b></h2>
<p>Perhaps the question we should be asking ourselves now is not one of <i>when</i> the technology will reach a point where human pilots are no longer needed onboard. We appear to already be there, or we will be when enough of the latest generation of aircraft can be put into service. The real question is what’s holding us back. For the majority of most commercial flights these days, the human pilots in the cockpit are mostly there as passengers except during takeoff and landing unless something anomalous takes place in mid-flight. The technology is already with us and should only continue to improve.</p>

<p>The other advantages to UAVs, particularly for the military, should be obvious even to the layman. Removing people from a warfighting aircraft means you can also remove all of the support systems that serve no purpose other than to keep the human(s) alive. There is no need for ejection seats – or any seats for that matter – or pressurization and oxygen to keep them breathing. Windows, always a weak point in the airframe’s design, are no longer needed since the remote pilot “sees” the environment through sensors. And if one of these drones does go down, you don’t have to send someone to present a flag at the funeral of the pilot.</p>

<p>Recent advances in aviation technology, particularly in the military, have been stunning. Whether for use in peace or wartime, we may be in the process of relegating human pilots to small, leisure-craft or flying extremely complex emergency rescue operations. That would likely be very hard for some of us to wrap our heads around and adjust to. There’s always been something both romantic and heroic about fighter pilots, the brave men and women who take to the skies and risk their lives to move people and freight along with fighting our wars.</p>

<p>Who would remember the day in 1918 when Captain Roy Brown shot down&nbsp;Baron Manfred von Richthofen during World War I if both vehicles were being operated by some kid with a keyboard 10,000 miles away? Indeed, this is the brave new world we are continuing to plunge towards.</p>
									</div>
			</div></div>]]>
            </description>
            <link>https://thedebrief.org/fighter-pilots-rely-on-technology-that-may-one-day-steal-their-jobs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304857</guid>
            <pubDate>Mon, 01 Mar 2021 16:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For Shits and Giggles: Optimized Sampling from Multiple Sensors (Arduino)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26304689">thread link</a>) | @petercrona
<br/>
March 1, 2021 | https://www.babyfriendlyair.com/en/technology/optimized-sequential-sampling-from-multiple-sensors-arduino/ | <a href="https://web.archive.org/web/*/https://www.babyfriendlyair.com/en/technology/optimized-sequential-sampling-from-multiple-sensors-arduino/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

      <div>
        <div>
          <main>
  
  <ul>
    <li>By Peter Crona</li>
    <li title="Published February 27, 2021">February 27, 2021</li>
    <li><a title="All pages tagged 'technology'." href="https://www.babyfriendlyair.com/en/technology/">technology</a></li>
  </ul>

  <p><img src="https://www.babyfriendlyair.com/images/en/technology/unnecessarily-improved-header.jpg" alt=""></p>
<p>I woke up with a nice idea of how I’d use statistics and optimization to improve the precision when measuring pollutants by taking just the right number of samples. Turns out that sensors, at least those I have, give a fairly stable voltage, making it enough to spend a few milliseconds to take 30 samples per sensor or so to get a very stable value, and you’d get pretty good results with just one sample as well. An example of the distribution when sampling from a sensor (for around a second) can be seen in figure 1.</p>
<p>Not into natural language? <a href="https://github.com/babyfriendlyair/posts-code/tree/main/2021-02-27-for-shits-and-giggles-optimized-sequential-sampling-from-multiple-sensors-arduino">Jump straight to the code!</a></p>
<a href="https://www.babyfriendlyair.com/images/en/technology/quite_good_sensor_read.png"><img src="https://www.babyfriendlyair.com/images/en/technology/quite_good_sensor_read.png"></a>
<p><small>Figure 1. A bar chart of values read from a Winsen ZE25-O3 sensor. The values are narrowly centered around a top.</small>
</p>
<p>Nevertheless, I still continued with the idea, as it is still a nice little project for practicing some C++ (currently reading <a href="https://www.stroustrup.com/tour2.html">A Tour of C++</a>) as well as brushing of some statistics and optimization skills. I’m still hopeful that this can come in handy later for future projects, as so many problems we solve are just other problems in disguise anyway.</p>
<p>The problem at hand is that I want to measure the analog output from sensors. My fear was that it would be unstable, because I’ve seen it happen a few times. However, it appears to not be a big problem, as I generally get a standard deviation of around 0.5. My sensor setup can be seen in figure 2, it consists of sensors for measuring ozone, humidity and temperature.</p>
<p><a href="https://www.babyfriendlyair.com/images/en/technology/many_sensors.jpg"><img src="https://www.babyfriendlyair.com/images/en/technology/many_sensors.jpg"></a></p>
<p><small>Figure 2. Picture of sensors, from top left to right bottom: DHT11 (temperature and humidity), MQ131 low concentration (ozone), MQ131 high concentration (ozone) and ZE25-O3 (ozone).</small>
</p>
<p>I wanted to present you with a messy graph of the black MQ131’s analog output. Now when I think about it, perhaps I did see messy data because it was not “burned in” - it is often specified in sensors’ data sheets that the sensor need to be turned on for a few days if it has been unused for long or never used. Nevertheless, by using an appropriate scale for the Y-axis, we can still make it look messy as in figure 3.</p>
<a href="https://www.babyfriendlyair.com/images/en/technology/a2_raw_signal_noise.png"><img src="https://www.babyfriendlyair.com/images/en/technology/a2_raw_signal_noise.png"></a>
<p><small>Figure 3. Voltage varying between samples.</small>
</p>
<p>Rather than the jumpy voltage values in fig. 3, which is likely “noise” rather than true variations in O<sub>3</sub> measurement, we’d prefer something as shown in fig. 4.</p>
<a href="https://www.babyfriendlyair.com/images/en/technology/a2_group_by_30_mean.png"><img src="https://www.babyfriendlyair.com/images/en/technology/a2_group_by_30_mean.png"></a>
<p><small>Figure 4. Same data as in figure 3. but we take the average value for every group of 30 samples and round it.</small>
</p>
<p>In figure 4 we get a completely flat line by simply taking the average of groups of 30 samples and rounding. The idea is that we can get rid of noise in this way by assuming that the ozone concentration is constant (well, that any changes are below our sensor’s resolution) in the time interval we’re working with (eg. 1s).</p>
<p>On one hand, we could just take 30 samples and be fine with that, but on the other hand, it’s more fun and more of a learning experience to try something different. After a bit of thinking, I formulated my problem as:</p>
<blockquote>
<p>I want to sample for a fairly short time and get a decent estimate of the real concentration of the gas under investigation. Under the assumption that the sensor does do its job, but is just suffering from some noise in the measurements.</p>
</blockquote>
<p>The “a fairly short time” comes from that I want to capture changes ASAP, because the concentration might change (truth to be told, I’m also impatient when measuring), an example of this is shown in figure 5, where we no longer have one “top”. Not sampling for too long is particularly important for me because I want to measure many things. For a starter, humidity, temperature and ozone, but hopefully will add nitrogen dioxide, particles, VOC and formaldehyde to that. All of this I would do simultaneously in an ideal world, as I want to explorer the relation between different pollutants later. Furthermore, I want the ability to compare multiple sensors that measure the same thing.</p>
<a href="https://www.babyfriendlyair.com/images/en/technology/a2_noise_two_tops.png"><img src="https://www.babyfriendlyair.com/images/en/technology/a2_noise_two_tops.png"></a>
<p><small>Figure 5. Example of what can happen if we measure for too long. The graph has two “tops” quite far from each other.</small>
</p>
<p>To make things easier, I started to see the problem as a statistical problem:</p>
<blockquote>
<p>There’s a true mean for the concentration in a specific time interval (eg. second). How can we model the quality of our estimate?</p>
</blockquote>
<p>Brushing up on some stats skills <span data-cites="sullivan">[1]</span> <span data-cites="milton_arnold">[2]</span> quickly led me to confidence intervals and in particular margin of error. Assuming that all sensors are equally important, we can minimize the sum of the margin of error for all sensors, subject to a time budget (eg. 1 second) with a fixed desired confidence level (eg. 95%).</p>
<p>With all those ideas we can now break down our problem:</p>
<ol type="1">
<li>Get a good estimate of the standard deviation for each sensor in a second.</li>
<li>Calculate time to sample, so we can see how many samples we afford with a fixed maximum sampling time.</li>
<li>Formulate optimization problem so some solver can solve it (future challenge might be to solve it ourselves in C++ - might be handy to recalculate from time).</li>
</ol>
<p>The optimization problems will look something like:</p>
<p><br><span>$$
\begin{alignat}{2}
&amp;\!\min_{n_x,\ x \in \text{sensors}}        &amp;\,&amp;   \sum_{x \in \text{sensors}} \frac {s_{x}} {\sqrt{n_{x}}} \\
\\
&amp;\text{subject to} &amp;      &amp; \sum_{x\in\text{sensors}} n_x &lt;= \text{timeBudget} \\
\\
&amp;\rlap{s_x\text{: estimated standard deviation of sensor x}} \\
&amp;\rlap{n_x\text{: nr of samples from sensor x}} \\
\end{alignat}
$$</span><br></p>
<p>Basically, we want to minimize the sum of the margin of error of all sensors. The margin of error is actually given by:</p>
<p><br><span>$$t * \frac s {\sqrt{n}}\\$$</span><br></p>
<p>where the t is a constant given the chosen confidence level (eg. 95%) and degrees of freedom defined by the sample size (you just look it up in a table). As it won’t affect our optimization problem, we can simply drop it.</p>
<p>Solving such an optimization problem is a piece of cake for something like WolframAlpha, so after a bit of <a href="https://github.com/babyfriendlyair/posts-code/blob/main/2021-02-27-for-shits-and-giggles-optimized-sequential-sampling-from-multiple-sensors-arduino/sensor/SamplesPerSensorOptimizer.cpp">coding</a> we get:</p>
<blockquote>
<p><a href="https://www.wolframalpha.com/input/?i=min+%280.52+%2F+sqrt%28a%29+%2B+0.28+%2F+sqrt%28b%29+%2B+0.51+%2F+sqrt%28c%29%29+s.t.+a+%2B+b+%2B+c+%3C%3D+8606" title="See in WolframAlpha">min (0.52 / sqrt(a) + 0.28 / sqrt(b) + 0.51 / sqrt(c)) s.t. a + b + c &lt;= 8606</a></p>
</blockquote>
<p>To which WolframAlpha responds:</p>
<blockquote>
<p>(a, b, c)≈(3252.96, 2141.52, 3211.44)</p>
</blockquote>
<p>As expected, we’re asked to sample less from the sensor with the lowest standard deviation. Keep in mind that we get one or more local minima from WolframAlpha. To perhaps make it easier to grasp, consider if we have a lot fewer samples and greater difference in standard deviations. We want to ask three questions to random people out on the street, we happen to know (lucky us!) that they have standard deviations 100, 500 and 2000. We are only allowed to ask 100 questions in total. That would give:</p>
<blockquote>
<p><a href="https://www.wolframalpha.com/input/?i=min+%28100+%2F+sqrt%28a%29+%2B+500+%2F+sqrt%28b%29+%2B+2000+%2F+sqrt%28c%29%29+s.t.+a+%2B+b+%2B+c+%3C%3D+100" title="See in WolframAlpha">min (100 / sqrt(a) + 500 / sqrt(b) + 2000 / sqrt(c)) s.t. a + b + c &lt;= 100</a></p>
</blockquote>
<p>WolframAlpha kindly finds a local minima at:</p>
<blockquote>
<p>(8.85576, 25.8944, 65.2498)</p>
</blockquote>
<p>So, when walking around on the streets in your beautiful city, you’d ask question one 9 times, question two 26 times and question three 65 times. You’d end up with a summed “margin of error” of roughly 379, as opposed to roughly 452 if you’d split how many times you ask each question evenly. For question one, you’d notice that people tend to answer roughly the same, whereas for question three, you see very different answers. So you feel confident that you know roughly what to expect for question one pretty early, but for question three not so much.</p>
<p>As already pointed out, it turned out that we didn’t need to consider the confidence level. However, we could fix the margin of error and confidence level to something we want (eg. 0.5 with 95% confidence), and calculate number of samples needed for that. This would in fact be easier, as we can simply use algebra to calculate the answer, as opposed to formulating and solving an optimization problem.</p>
<p>But let’s move on to actually using the results now, in its simplest form, we can just do something like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>int</span> samplesToTake[] {<span>3253</span>, <span>2142</span>, <span>3211</span>}<span>;</span></span>
<span id="cb1-2"><span>int</span> nrSensors <span>=</span> sizeof(analogSensorReaderArray) </span>
<span id="cb1-3">              <span>/</span> sizeof(analogSensorReaderArray[<span>0</span>])<span>;</span></span>
<span id="cb1-4"><span>for</span> (auto i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> nrSensors<span>;</span> i<span>++</span>) {</span>
<span id="cb1-5">  StreamStats stats {}<span>;</span></span>
<span id="cb1-6">  </span>
<span id="cb1-7">  auto sensor <span>=</span> analogSensorReaderArray[i]<span>;</span></span>
<span id="cb1-8">  <span>for</span> (auto j <span>=</span> <span>0</span><span>;</span> j <span>&lt;</span> samplesToTake[i]<span>;</span> j<span>++</span>) {</span>
<span id="cb1-9">    stats.reportNumber(sensor.read())<span>;</span></span>
<span id="cb1-10">  }</span>
<span id="cb1-11"></span>
<span id="cb1-12">  Serial.<span>print</span>(stats.average())<span>;</span></span>
<span id="cb1-13">  Serial.<span>print</span>(<span>","</span>)<span>;</span></span>
<span id="cb1-14">  Serial.<span>print</span>(sensor.read())<span>;</span></span>
<span id="cb1-15">  Serial.<span>print</span>(<span>","</span>)<span>;</span></span>
<span id="cb1-16">}</span>
<span id="cb1-17"></span>
<span id="cb1-18">Serial.<span>print</span>(dht.readHumidity())<span>;</span></span>
<span id="cb1-19">Serial.<span>print</span>(<span>","</span>)<span>;</span></span>
<span id="cb1-20">Serial.<span>print</span>(dht.readTemperature())<span>;</span></span>
<span id="cb1-21"></span>
<span id="cb1-22">Serial.println()<span>;</span></span></code></pre></div>
<p>Where samplesToTake is just copy-pasted from WolframAlpha (and rounded).</p>
<p>As expected, given the low standard deviation, the difference is not massive. It is easiest to see for the MQ131 low concentration sensor (you might need to zoom in):</p>
<p><a href="https://www.babyfriendlyair.com/images/en/technology/mq131Black.png"><img src="https://www.babyfriendlyair.com/images/en/technology/mq131Black.png"></a></p>
<p><small>Figure 6. Graph for measurements with the MQ131 low concentration. It is visible in the upper graph (by second) how the graph is smoother as we take more samples. mq131Black refers to a single sample, avg30Mq131Black is 30 samples and avgMq131Black is 3253 samples. All taken within an interval of a second. In the hourly average the difference is so small you can’t see it.</small>
</p>
<p>As we did sample from multiple sensors almost simultaneously, I can’t really resist looking at the correlation matrix:</p>
<p><a href="https://www.babyfriendlyair.com/images/en/technology/corrMatrix_BER.png"><img src="https://www.babyfriendlyair.com/images/en/technology/corrMatrix_BER.png"></a></p>
<p><small>Figure 7. Correlation Matrix of all sensors as well as NO, NO<sub>2</sub>, NO<sub>x</sub> and O<sub>3</sub> from a Berlin air quality station.</small>
</p>
<p>A pity is that we get a lower correlation between our Winsen ZE25-O3 sensor and Berlin’s NO<sub>2</sub> measurements than in a <a href="https://www.babyfriendlyair.com/en/technology/measuring-no2-with-a-winsen-ze25-o3-ozone-sensor/">previous experiment</a> (0.60 VS 0.47). However, this might be explained by the correlation with temperature, as the <a href="https://www.babyfriendlyair.com/images/en/technology/temp.png">temperature was pretty much rising throughout the whole measurement period</a>. I also have some suspicions that Berlin’s air quality monitoring wasn’t working that well, for instance, it recently reported several hundreds μg/m<sup>3</sup> of PM10 (which is quite a lot, even if sand that blew up from Sahara can explain elevated levels).</p>
<p>Interesting is to see that all sensors had negative correlation with outdoor ozone. I believe this can partly be explained by that ozone negatively correlates with NO<sub>x</sub>, and the sensors are sensitive to NO<sub>x</sub> which is simply dominating. So as O<sub>3</sub> goes down and NO<sub>x</sub> goes up, we get a higher value. We can also see the …</p></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.babyfriendlyair.com/en/technology/optimized-sequential-sampling-from-multiple-sensors-arduino/">https://www.babyfriendlyair.com/en/technology/optimized-sequential-sampling-from-multiple-sensors-arduino/</a></em></p>]]>
            </description>
            <link>https://www.babyfriendlyair.com/en/technology/optimized-sequential-sampling-from-multiple-sensors-arduino/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304689</guid>
            <pubDate>Mon, 01 Mar 2021 16:45:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CERN Is Using Mini Particle Accelerators to Fight Cancer]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26304539">thread link</a>) | @mjbanias
<br/>
March 1, 2021 | https://thedebrief.org/new-cancer-treatment-uses-a-mini-cern-particle-accelerator-to-blast-tumors-with-ion-beams/ | <a href="https://web.archive.org/web/*/https://thedebrief.org/new-cancer-treatment-uses-a-mini-cern-particle-accelerator-to-blast-tumors-with-ion-beams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span data-preserver-spaces="true">The&nbsp;</span><a href="https://home.cern/news/news/knowledge-sharing/cern-collaborations-open-new-horizons-cancer-therapy" target="_blank" rel="noopener"><span data-preserver-spaces="true">Next Ion Medical Machine Study (NIMMS)</span></a><span data-preserver-spaces="true">&nbsp;uses CERN particle accelerator technology and expertise to build the next generation of small ion accelerators to treat cancerous tumors.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In 1996, CERN co-founded the Proton Ion Medical Machine Study (PIMMS) to treat cancer using beams of charged protons and ions to blast tumors. Called hadron therapy, large particle accelerators create either a proton beam or an ion beam that is tight enough to target tumors deep in the body, near sensitive organs, and reduce possible damage to any surrounding tissue. The four hadron therapy centers in Europe providing hadron therapy have helped cure roughly 260,000 people since they opened. </span></p>
<p><span data-preserver-spaces="true">As a result, Europe has become the leader in cancer treatment worldwide. The biggest hurdle, however, is that building a large particle accelerator is not cheap, and therapy can be a fortune without adequate medical coverage.</span></p>
<p><span data-preserver-spaces="true">Two decades later, major technological breakthroughs may make access to these procedures less expensive. NIMMS will aim to create smaller, more powerful particle accelerators that are cost-effective and use artificial intelligence to treat tumors more effectively. Moreover, while proton-based treatment has been effective over the last several years, today’s carbon ion beam therapy seems to be far more precise and effective.</span></p>
<p><span data-preserver-spaces="true">“NIMMS aims at a technology leap by the wide use of superconductivity and new magnet designs based on recent work for particle physics accelerators,” Dr. Maurizio Vretenar, NIMMS project lead at CERN, told&nbsp;<em>The Debrief.</em>&nbsp;“We are also considering alternative and more compact accelerator designs and extensive use of artificial intelligence in the design and operation of the accelerator.”<br>
</span></p>

<figure id="attachment_3628" aria-describedby="caption-attachment-3628"><img src="https://thedebrief.org/wp-content/uploads/2021/02/GaToroid-e1614342004347.jpg" alt="CERN" width="760" height="515" data-src="https://thedebrief.org/wp-content/uploads/2021/02/GaToroid-e1614342004347.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption id="caption-attachment-3628">This lightweight gantry developed by GaToroid could make hadron therapy easier to access. (Image: CERN)</figcaption></figure>
<p><span data-preserver-spaces="true">Traditional radiotherapy uses X-rays, photons, and, more recently, protons to kill cancer cells with powerful radiation. The problem is that surrounding healthy cells, organs, and tissue can also become damaged. Even proton beams used in hadron therapy can&nbsp;</span><a href="https://cerncourier.com/a/cern-takes-next-step-for-hadron-therapy/" target="_blank" rel="noopener"><span data-preserver-spaces="true">cause damage</span></a><span data-preserver-spaces="true">&nbsp;to surrounding cells. Modern ion radiotherapy is far more precise.</span></p>
<p><span data-preserver-spaces="true">“Ion radiotherapy directly damages the DNA of cancerous cells, creating a large number of double-strand breakings that are not reparable and lead to the death of the cell,” explained Dr. Vretenar. “Ions are much more effective than other forms of radiotherapy, and on top of that, the damage can be easily concentrated on the cancerous region by adjusting the size and the energy of the ion beam, sparing the healthy tissue close to the cancer.”</span></p>
<p><span data-preserver-spaces="true">Because so few facilities can offer hadron therapy, NIMMS is developing models to make the particle accelerators smaller and less expensive. By reducing the barrier to build and operate a particle accelerator, more hospitals may put them into operation. If the system can become small enough, existing medical facilities will not require much additional real estate to install them.&nbsp;</span></p>
<p><span data-preserver-spaces="true">“Our favoured design is a superconducting synchrotron ring only eight meters in diameter, followed by an eight-meter long “snake” made of superconducting magnets that rotates around the patient to deliver the ion beam on the required position. Including all shielding and protections, this system will occupy an area of about 40 meters by 20 meters,” Dr. Vretenar stated.</span></p>
<p><span data-preserver-spaces="true">The specific CERN accelerators Dr. Vretenar refers to create carbon ions at 430 MeV (Mega electron-volt), which is enough energy to pass ions over and through a human body but are small enough that they don’t require a ton of space.&nbsp;</span></p>
<p><span data-preserver-spaces="true">“A new accelerator design with improved intensity and operational flexibility would also enable a wide research programme to optimise ion species and treatment modalities,” Dr. Vretenar wrote in a previous&nbsp;</span><a href="https://cerncourier.com/a/cern-takes-next-step-for-hadron-therapy/" target="_blank" rel="noopener"><span data-preserver-spaces="true">article</span></a><span data-preserver-spaces="true">. “This would allow the exploration of innovative paths to the treatment of cancer such as ultra-short FLASH therapy or the promising combination of ion therapy with immunotherapy, which is expected to trigger an immune response against diffused cancers and metastasis.”</span></p><div><div id="block-wrap-45369" data-id="45369"><div><div><div>		<article>
					<p><a href="https://thedebrief.org/these-anti-solar-panels-dont-need-daylight-to-generate-power/">
				<img width="120" height="120" src="https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-120x120.jpg" alt="solar panels" srcset="https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-120x120.jpg 120w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-150x150.jpg 150w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-70x70.jpg 70w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-240x240.jpg 240w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-360x360.jpg 360w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-540x540.jpg 540w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-720x720.jpg 720w,https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-125x125.jpg 125w" sizes="(max-width: 120px) 100vw, 120px" data-srcset="https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-120x120.jpg 120w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-150x150.jpg 150w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-70x70.jpg 70w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-240x240.jpg 240w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-360x360.jpg 360w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-540x540.jpg 540w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-720x720.jpg 720w, https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-125x125.jpg 125w" data-src="https://thedebrief.org/wp-content/uploads/2021/02/solar-panels-at-night-min-120x120.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">			</a>
		</p>
					
		</article>
		</div></div></div></div></div>
<p><span data-preserver-spaces="true">Dr. Vretenar admits that cancer is a complex disease and is well aware that it cannot be fought with only one type of tool. However, PIMMS has proven that more tools in the kit can lead to victories on the battlefield. The NIMMS project strives to make those tools more affordable and allow more people to access ion-based therapy.&nbsp;</span></p>
<p><span data-preserver-spaces="true">“With this technology, we aim at adding a new flexible and possibly affordable element to the arsenal of cancer-fighting techniques. While conventional radiotherapy will certainly remain in use for a large number of cancers, deep cancers close to critical organs, in particular, the hypoxic type, will be more effectively and precisely cured with ion therapy,” Dr. Vretenar told&nbsp;</span><em><span data-preserver-spaces="true">The Debrief. “</span></em><span data-preserver-spaces="true">On top of that, by sparing radiation to nearby organs, this technique has a positive impact on the quality of life of patients after treatment.”</span></p>
<p><span data-preserver-spaces="true">Dr. Vretenar believes that the future of cancer treatment will be an elegant mix of human specialists and <a href="https://thedebrief.org/deepminds-ai-makes-history-by-solving-protein-folding-problem/" target="_blank" rel="noopener">AI algorithms</a> “that analyze patient DNA information, their previous medical history, and huge amounts of clinical data for similar cancer cases [to] decide the treatment strategy with the highest probability of success.”&nbsp;</span></p>
<p><span data-preserver-spaces="true">The future of cancer treatment will be less invasive as the ability to destroy a tumor without bloodshed is already a reality. If the process can be fine-tuned enough, the next step is to ensure this procedure is available worldwide and accessible to those who need it.&nbsp;</span></p>
<p><b>Join us on</b><a href="https://twitter.com/Debriefmedia"> <b>Twitter</b></a><b> or</b><a href="https://www.facebook.com/thedebriefnews"> <b>Facebook</b></a><b> to weigh in and share your thoughts on the idea of a mini CERN particle accelerator being used to treat cancer. You can also follow all the latest&nbsp; news and exciting feature content from The Debrief on</b><a href="https://flipboard.com/@TheDebrief"> <b>Flipboard</b></a><b>,</b><a href="https://www.instagram.com/thedebriefmedia/"> <b>Instagram</b></a><b>, and don’t forget to subscribe to </b><a href="https://www.youtube.com/channel/UCM32gjHqMnYl_MOHZetC8Eg"><b>The Debrief YouTube Channel</b></a><b> and check out</b><a href="https://www.youtube.com/watch?v=U8SRcxF_RPw"> <b>The Official Debrief Podcast</b></a><b>.&nbsp;</b></p>
									</div>
			</div></div>]]>
            </description>
            <link>https://thedebrief.org/new-cancer-treatment-uses-a-mini-cern-particle-accelerator-to-blast-tumors-with-ion-beams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304539</guid>
            <pubDate>Mon, 01 Mar 2021 16:36:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presenting the first condensed database]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26304202">thread link</a>) | @Malexik
<br/>
March 1, 2021 | https://condensationdb.com/white-paper/ | <a href="https://web.archive.org/web/*/https://condensationdb.com/white-paper/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

          <div>
            <div>
              
              <p>Inspired by the blockchain system, the email system, and git versioning, Condensation is a unique solution to develop scalable and modern applications while providing the features to protect digital rights. Having a system that doesn't need to trust the Cloud enables to ensure the security and the ownership of data.</p>
            </div>

            <figure>
              <video poster="https://condensationdb.com/assets/img/overview-video-poster.png" autoplay="autoplay">
                  <source src="https://condensationdb.com/assets/img/overview-video.mp4" type="video/mp4">
              </video>
              <figcaption>Condensation extends the Cloud with distributed storage servers</figcaption>
            </figure>

          </div>
          
        </section><section>
        <div>
          <div>
            <div>
              <article>
                <h2>The emergence of condensed systems</h2>

                <p>
                While being entirely distributed, Condensation can store and retrieve data like a database or a file system, send data to other users or devices like a messaging system, and share and synchronize data like cloud services. Thereby, Condensation follows a distributed actor-message-passing approach and encrypts all data end-to-end.
                </p>

                <p>
                Condensation builds the bridge between the simplicity of immutable data and the easiness of implementation of mutable documents. On the client, documents are split efficiently into smaller immutable units that can be transferred freely across the network. Then, they can be condensed back when they arrive on the receiver's device. Condensed systems are free from trusting a third-party server and many new features come by design to create trust between clients such as data certification.
                </p>

                <p>
                This shift from merging data on the server to doing it on the client side, opens many new possibilities for application design. Furthermore, it is significantly more efficient if compared to existing solutions which need to build several application layers on top of existing systems to achieve the same functionalities. Before to start explaining the mechanics, this section explains the history of databases and what makes Condensation the next step in the evolution of databases.
                </p>

                <h3>Bridging the gap between mutable and immutable data structures</h3>
                    <p>
                    The structure of today's file and database systems dates back to the 1970s, when storage space was extremely scarce and computers were few. These systems were designed to run on a single machine, and mostly on a single disk.
                    </p>
                    <p>
                    While both databases and file systems have greatly evolved over time, their main structure has hardly changed. Database systems are based on tables with mutable records (rows), while file systems use a hierarchy of folders with mutable files inside. In both systems, data can be modified with little effort, and at any time. It also has the advantage of being very efficient with regards to storage space needs. Data synchronization, however, is notoriously difficult and error prone.
                    </p>
                    <p>
                    In todays' connected world, data is used on different devices, or is shared with other people. And, for most applications, storage space is not a limiting factor any more. Hence, efficient data synchronization is key.
                    </p>

                    <figure>

                      <img src="https://condensationdb.com/assets/img/historic-evolution.png" alt="Image">

                      <figcaption>A historical evolution of data systems</figcaption>
                    </figure>

                    <p>
                    Aside of file and database systems, revision control systems have been developed and used since the 1980s. Some of them, such as git or hq, are fully distributed and do not require any central server whatsoever. Each user has their own version of the data and can merge changes from other users. Such systems allow for efficient and provably correct data synchronization.
                    </p>
                    <p>
                    While they are great for source code management, current version control systems are not suited as general purpose data systems. In order to benefit from such systems, the user needs to have a certain understanding of branches, merging, and conflict resolution, which is far beyond the knowledge of an average computer user. In addition, occasional merge conflicts are inevitable, and prevent such systems from being used in a transparent way.
                    </p>
                    <p>
                    Condensation has been designed from the ground up to address this. The result is a general-purpose data system with lightweight transactions and efficient data synchronization in a completely distributed setting. Merge conflicts are impossible by design, hence no user intervention is required during the synchronization process. The data itself is end-to-end encrypted and may be spread across multiple storage systems.
                    </p>

                    <h3>The evolution of architectures from online to offline and serverless systems.</h3>

                    <p>
                    The structure of the data has a direct influence on the dependency from and the role of a server. With SQL and noSQL databases, the centralized server is needed to synchronize data. Accordingly, it is the place where the application logic occurs. As a result, the system only works when being online. Also, as the data is read and processes by the server, it is vulnerable to data breaches.
                    </p>
                    <p>
                    Working offline became possible later, by storing documents in the application and defining schemas for synchronization when the application is turned back to online mode. However, this process is complex and requires a handling logic on both the client and the server side. Moreover, scaling a central database was a major issue. Many systems developed distributed systems for horizontal scaling but in a controlled data center setup where all servers are entrusted and available.
                    </p>
                    <p>
                    As described previously, Condensation only transfer immutable data on the network, which allows to build fully distributed but yet very simple systems. The following scheme summarizes the comparison between existing systems types.
                    </p>

                    <figure>
                        <img src="https://condensationdb.com/assets/img/cn-architectures.png" alt="Architectures">
                        <figcaption>Condensation shifts intelligence to the client-side and makes servers a simple encrypted storage​</figcaption>
                    </figure>

                    <figure>

                                <table id="table1">
                                  <thead>
                                    <tr>
                                      <th scope="col-3"></th>
                                      <th scope="col-3">
                                        <b>Online-only</b><br>
                                        2000-2015
                                      </th>
                                      <th scope="col-3">
                                        <b>Offline-first</b><br>
                                        2015-2020
                                      </th>
                                      <th scope="col-3">
                                        <b>Condensated</b><br>
                                        2021
                                      </th>
                                    </tr>
                                  </thead>
                                  <tbody>
                                    <tr>
                                      <th scope="row">
                                        <span>Code base</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Small
                                      </td>
                                      <td>
                                          Large
                                      </td>
                                      <td>
                                          Small
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Architecture</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Simple architecture, easy to understand
                                      </td>
                                      <td>
                                          Relatively complex architecture
                                      </td>
                                      <td>
                                          Simple architecture but requires "distributed mindset"
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Structure</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          Centralized with full trust in cloud
                                      </td>
                                      <td>
                                          Centralized with full trust in cloud
                                      </td>
                                      <td>
                                          Distributed/Federated
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Synchronization</span>
                                        <span></span>
                                      </th>
                                      <td>
                                          No synchronization necessary
                                      </td>
                                      <td>
                                          Correct data synchronization (two-way) is hard. Potentially different database schemas on client and server.
                                      </td>
                                      <td>
                                          Based on synchronization<br>
                                          Direct device-to-device sync possible
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Security</span>
                                        <span></span>
                                      </th>
                                      <td>
                                        Transport encryption only
                                      </td>
                                      <td>
                                        Transport encryption and SPOF engineered mitigation
                                      </td>
                                      <td>
                                        End-to-end encryption
                                      </td>
                                    </tr>
                                    <tr>
                                      <th scope="row">
                                        <span>Authentication</span>
                                        <span></span>
                                      </th>
                                      <td>
                                        Login required
                                      </td>
                                      <td>
                                        Login required
                                      </td>
                                      <td>
                                        Login not necessary (but sometimes desired)
                                      </td>
                                    </tr>

                                  </tbody>
                                </table>
                    </figure>

                <p>
                Condensation leverage the advantages of immutable objects. You never have to lock them, which extremely improves concurrency also it improves simplicity as persistance to certify the data isn't compromised and exactly the same as the source. Furthermore, it allows to reduce the memory usage as objects can be reused to create new trees.
                </p>
                <p>
                Developers can benefit from features available by design such as: data certification with user signature, versionning with transaction history, and conflict free merge based on CRDTs.
                </p>
                <p>
                So, Condensation has a hybrid data structure, it merge data into mutable documents stored locally and transfers immutable objects through stores. The stores can be managed in a single server or in a purely distributed manner without introducing complexities.
                </p>
                <p>
                In the following sections, first the data structure is technically described to explain how Condensation transform a document into an immutable merkle tree. Next, to better understand how Condensation manage securely data on the network, the flow of the data through a …</p></article></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://condensationdb.com/white-paper/">https://condensationdb.com/white-paper/</a></em></p>]]>
            </description>
            <link>https://condensationdb.com/white-paper/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304202</guid>
            <pubDate>Mon, 01 Mar 2021 16:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JuliaSymbolics Roadmap: A Modern Computer Algebra System for a Modern Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26304135">thread link</a>) | @dklend122
<br/>
March 1, 2021 | https://juliasymbolics.org/roadmap/#juliasymbolics_roadmap_a_modern_computer_algebra_system_for_a_modern_language | <a href="https://web.archive.org/web/*/https://juliasymbolics.org/roadmap/#juliasymbolics_roadmap_a_modern_computer_algebra_system_for_a_modern_language">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<!-- Content appended here -->
<div>
<p>We need new Computer Algebra Systems (CAS) for this new era of computing. We need a CAS that dispatches in the multiple ways we think. We need a CAS that scales exponentially like our problems. We need a CAS that integrates with our package ecosystem, letting people extend parts and contribute back to the core library all in one language. We need a modern CAS in a modern language.</p>
<p>Symbolics.jl is the answer. Symbolics.jl is a pure Julia CAS which uses the Julia core library to its fullest. It is built from the ground up with performance in mind. We use specialized structures for automatic simplification to match the performance of the most fully optimized C++ libraries. It exploits parallelism at every level; our symbolic simplification takes advantage of Julia's task-based multithreading to transform symbolic equations into parallelized Julia code.</p>
<p>This reconstruction of the idea of CAS in Julia's type system is entirely extensible. New term types enable fast symbolic arithmetic on standard and non-standard algebras; add-on libraries like ModelingToolkit build a bridge from symbolics to numerics. Symbolics.jl and its ecosystem will be the common foundation on which the next generation of Domain-Specific Languages (DSLs) will be constructed, automatically updated and accelerated through with the growth of this system.</p>
<h2 id="the_features_of_symbolicsjl"><a href="#the_features_of_symbolicsjl">The Features of Symbolics.jl</a></h2>
<p>Symbolics.jl at its launch in 2021 is already expansive. It includes:</p>
<ul>
<li><p>Symbolic arithmetic with type information and multiple dispatch</p>
</li>
<li><p>Symbolic polynomials and trigonometric functions</p>
</li>
<li><p>Pattern matching, simplification and substitution</p>
</li>
<li><p>Differentiation</p>
</li>
<li><p>Symbolic linear algebra (factorizations, inversion, determinants, eigencomputations, etc.)</p>
</li>
<li><p>Discrete math (representations of summations, products, binomial coefficients, etc.)</p>
</li>
<li><p>Logical and Boolean expressions</p>
</li>
<li><p>Symbolic equation solving and conversion to arbitrary precision</p>
</li>
<li><p>Support for non-standard algebras (non-commutative symbols and customizable rulesets)</p>
</li>
<li><p>Special functions (list provided by <a href="https://github.com/JuliaMath/SpecialFunctions.jl">SpecialFunctions.jl</a>)</p>
</li>
<li><p>Automatic conversion of Julia code to symbolic code</p>
</li>
<li><p>Generation of (high performance and parallel) functions from symbolic expressions</p>
</li>
<li><p>Fast automated sparsity detection and generation of sparse Jacobian and Hessians</p>
</li>
</ul>
<p>and much more. A lot of these features are for free given its deep integration with multiple dispatch and Julia's type system.</p>
<h2 id="connection_to_the_package_ecosystem"><a href="#connection_to_the_package_ecosystem">Connection to the Package Ecosystem</a></h2>
<h3 id="the_connection_to_the_modelingtoolkitjl"><a href="#the_connection_to_the_modelingtoolkitjl">The Connection to the ModelingToolkit.jl</a></h3>
<p>Here in the Julia world, we like differntial equations, maybe a little too much.</p>
<p>Symbolics.jl grew out of ModelingToolkit.jl, an equation-based modeling system for the Julia programming language. Its vision is that the best system for modeling requires having the ability to symbolically specify models and build a library of transformations for generating more stable and performant code. While software in a similar space like Simulink and Modelica are disconnected from traditional programming languages and symbolic algebra systems, ModelingToolkit.jl weaves them together, allowing all aspects of the Julia programming language and symbolic computing to contribute to the richness of its design.</p>
<p>The ModelingToolkit.jl project has been almost too much of a success in that respect, reaching a feature-base that included an entire CAS as a submodule within itself. It was time for that CAS to be set free. Symbolics.jl is that CAS, now set in its own organization, JuliaSymbolics, with its ability to transform new domains.</p>
<p>ModelingToolkit.jl will continue to provide the symbolic representations of common numeric systems and the SciML organization, such as causal and acausal modeling (Simulink/Modelica) in the domains of:</p>
<ul>
<li><p>Ordinary differential equations</p>
</li>
<li><p>Stochastic differential equations</p>
</li>
<li><p>Partial differential equations</p>
</li>
<li><p>Nonlinear systems</p>
</li>
<li><p>Optimization problems</p>
</li>
<li><p>Optimal Control</p>
</li>
</ul>
<p>It will continue to power the connection the next generation of symbolic-numeric computation, blurring the boundaries by mixing analytical solutions with optimized and parallelized generated code. All symbolic functionality related to those domains will continue to thrive in that package, leaving Symbolics.jl the room to focus on the core of symbolic algebras: polynomials, Grobner bases, and more.</p>
<h3 id="the_connection_to_symbolicutilsjl"><a href="#the_connection_to_symbolicutilsjl">The Connection to SymbolicUtils.jl</a></h3>
<p>Symbolics.jl is an opinionated CAS. It types its variables so that generic Julia functions which require <code>Real</code> numbers can automatically be converted into symbolic expressions. It uses the Leibniz rules for defining derivatives. It does symbolic algebra as "the normal person would expect".</p>
<p>However, there are some use cases in computational algebra which require non-standard rulesets. How would you define symbolic Octonian numbers or define differentiation on non-smooth manifolds that do not satisfy the Leibniz rule? For these questions, mathematicians have traditionally been on their own having to develop new tools from scratch. However, the JuliaSymbolics has refactored its core so that new algebras can easily be implemented and created, and automatically get the optimized high performance of Symbolics.jl. This is SymbolicUtils.jl.</p>
<p>SymbolicUtils.jl is a fast and parallel rule-based rewrite system. By specifying a list of rules, such as trigonometric identities, you can specify new mathematical domains and create the symbolic arithmetic that you need. Symbolics.jl is built on this foundation, adding the common simplification rules for real numbers, derivative definitions and rules for Newton differentiation, and more. However, if you're so inclined, SymbolicUtils.jl is open for you to define BraKet algebras and more.</p>
<h2 id="goals_for_symbolicsjl"><a href="#goals_for_symbolicsjl">Goals for Symbolics.jl</a></h2>
<p>Symbolics.jl will be a never ending project as we wish to provide a high performance implementation of every symbolic algorithm that can and does exist. But, there are specific goals we have in mind.</p>
<h3 id="high-performance_symbolic_arithmetic"><a href="#high-performance_symbolic_arithmetic">High-Performance Symbolic Arithmetic</a></h3>
<p>Anywhere that we are beat in performance is a bug. Please file an issue immediately. This library should use every core, and it should use every core efficiently, allowing the exponential cost of symbolic arithmetic to tackled by the exponential gains in computational power and efficiency.</p>
<h3 id="pervasiveness_throughout_the_julia_dsls"><a href="#pervasiveness_throughout_the_julia_dsls">Pervasiveness Throughout the Julia DSLs</a></h3>
<p>We want to provide a symbolic foundation which all DSLs can rely on. We do not believe that a pharmacometrics library should define how to symbolically calculate a Hessian, and then the mathematical programming library JuMP, etc. We believe that by pooling together on Symbolics.jl, we can accelerate the growth of DSLs throughout the language, offering a way to collaborate towards a single battletested implementation.</p>
<h3 id="bridge_the_gap_from_computer_scientists_to_scientists_and_mathematicans"><a href="#bridge_the_gap_from_computer_scientists_to_scientists_and_mathematicans">Bridge the Gap from Computer Scientists to Scientists and Mathematicans</a></h3>
<p>While "code" is what package developers like to see, math is what practioners are trained on. We are committed to bridging that gap, making it easy to see the LaTeX-ification of the symbolic variables, creating informative displays in notebooks. Symbolics.jl should look and feel like doing math.</p>
<h3 id="feature_completeness"><a href="#feature_completeness">Feature Completeness</a></h3>
<p>We want Symbolics.jl to be the place where you check the documentation immediately for symbolic methods, knowing that if such a method exists then it's implemented there. Symbolics.jl should not just cover the domain but also be an archive of its research and science, making it easy to explore algorithms and compare between them.</p>
<h2 id="next_steps_for_symbolicsjl"><a href="#next_steps_for_symbolicsjl">Next Steps for Symbolics.jl</a></h2>
<p>We have not met all of our goals yet. While much of this roadmap has been accomplished, there is much in our way forward. Some major goals on our sights are:</p>
<ul>
<li><p>Symbolic integration using <a href="https://rulebasedintegration.org/">RUBI</a></p>
</li>
<li><p>Expansive algorithm selection for Grobner Basis</p>
</li>
<li><p>Feature parity with SymPy (<a href="https://github.com/JuliaSymbolics/Symbolics.jl/issues/59">being tracked here</a>)</p>
</li>
<li><p>Integration with distributed and GPU computation</p>
</li>
<li><p>High performance symbolic root finding</p>
</li>
<li><p>Integrating modern techniques like <a href="https://arxiv.org/pdf/1912.01412.pdf">deep learning to accelerate and improve symbolic rule application</a></p>
</li>
<li><p>Tools for <a href="https://herbie.uwplse.org/">transforming generated equations to have minimal floating point error</a></p>
</li>
<li><p>A full reproducible benchmarking suite</p>
</li>
</ul>
<h2 id="how_you_can_join_the_process"><a href="#how_you_can_join_the_process">How You Can Join The Process</a></h2>
<p>If you want to be a part of JuliaSymbolics, that's great, you're in! Here are some things you can start doing:</p>
<ul>
<li><p>Star our libraries like <a href="https://github.com/JuliaSymbolics/Symbolics.jl">Symbolics.jl</a> and our extensions like <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a>. Such recognition drives our growth to sustain the project.</p>
</li>
<li><p>Join our chatroom to discuss with us. Our main chatroom is <code>#symbolic programming</code> on the <a href="https://julialang.zulipchat.com/register/">Julia Zulip</a></p>
</li>
<li><p>If you're a student, find a summer project that interests you and apply for funding through Google Summer of Code or other processes (contact us if you are interested)</p>
</li>
<li><p>Start contributing! We recommend opening up an issue to discuss first, and we can help you get started.</p>
</li>
<li><p>Help update our websites, tutorials, benchmarks, and documentation</p>
</li>
<li><p>Help answer questions on Stack Overflow, the Julia Discourse, and other sites!</p>
</li>
<li><p>Hold workshops to train others on our tools.</p>
</li>
</ul>
<p>There are many ways to get involved, so if you'd like some help figuring out how, please get in touch with us.</p>

</div><!-- CONTENT ENDS HERE -->
    </div></div>]]>
            </description>
            <link>https://juliasymbolics.org/roadmap/#juliasymbolics_roadmap_a_modern_computer_algebra_system_for_a_modern_language</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304135</guid>
            <pubDate>Mon, 01 Mar 2021 16:07:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The curious case of CVE-2020-14381 Linux kernel bug]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26304099">thread link</a>) | @dlgeek
<br/>
March 1, 2021 | https://blog.frizn.fr/linux-kernel/cve-2020-14381 | <a href="https://web.archive.org/web/*/https://blog.frizn.fr/linux-kernel/cve-2020-14381">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://blog.frizn.fr/linux-kernel/">Kernel Linux</a> &gt; <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">The curious case of CVE-2020-14381</a></p>

                    <h3>The curious case of CVE-2020-14381</h3>                    
                    <p>Today is the one-year anniversary of this interesting kernel bug I worked
on last year with <a href="https://twitter.com/bluec0re" target="_blank">@bluec0re</a>,
and as it turns out I wrote something about it during one of these lockdown
weekends so I thought I'd release it. <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2015" target="_blank" title="CVE-2020-14381 get_futex_key use-after-free">The bug itself</a>
was discovered by <a href="https://twitter.com/tehjh" target="_blank">Jann Horn</a>
of Project Zero. While I touch most of the elements required to exploit the
bug, I stay superficial here since the exploit itself is not particularly
exciting. What makes this bug interesting to me is its lifecycle, in particular
how unevenly the patch was applied to the various distributions. I also talk
briefly about hardware side-channels since it was the first time I had ever
used one.</p>

<p><strong>The bug</strong></p><p>It’s already well-described in the bug tracker, but here is another summary.
The <span>futex</span> syscall's main parameter is a userland address, and this address
may belong to a file-backed mapping. In that case, the futex key kernel object
<a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L707" target="_blank">held</a>
and <a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L724" target="_blank">kept</a>
a reference to the inode object, but didn’t hold a reference to the file’s mountpoint.
If the mountpoint were to go away, its associated kernel structures would be
freed, but the inode wouldn’t. That’s an issue because the inode itself has
fields that point to some of these structures, such as its <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L641" target="_blank">super_block</a>
struct.</p>

<p>Further use of the inode by <span>futex</span> code paths may therefore trigger
use-after-frees. One particular code path highlighted by Jann in the bug happens
when the <span>futex</span> is destroyed: the last reference to the inode is released
and the inode needs to be freed. This is done in <span>iput</span> which then calls
<span>iput_final</span>. <span>iput_final</span> and its subcalls will then call inode
management functions stored in the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L1942" target="_blank">super_operations</a>
struct accessed <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1533" target="_blank">from the super_block</a>
object. The first instance happens right at the beginning of <span>iput_final</span> with
a call to the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1539" target="_blank">drop_inode</a>
function.</p>

<p>Exploiting this bug requires being able to:
</p><ul>
  <li>Successfully <span>umount</span> a mountpoint. A no-go a few years ago, but
  possible nowadays with the normalization of unprivileged user namespaces.
  It’s a good example that this feature was never a trivial security tradeoff
  (unprivileged sandboxes v. augmented kernel attack surface) which in turn
  makes it somewhat surprising that all mainstream distributions enabled them by default
  without much debate</li>
  <li>Survive the <span>op-&gt;drop_inode()</span> execution (non-SMEP or a KASLR bypass)</li>
  <li>Survive the <span>op-&gt;drop_inode</span> indirection just before that (non-SMAP
  or a stack/heap leak)</li>
  <li>Do everything in one call, because with an incorrect inode state, a corrupted
  super_block and some linked lists unlinks to do in the remainder of <span>iput_final</span>,
  it’s doubtful we can even get as far as the second <span>super_operations</span>
  function pointer call (<span>evict_inode</span>)</li>
</ul>


<p><strong>Exploitation</strong></p><p>The first exploitation pathway that comes to mind goes as follows:
</p><ul>
  <li>wait for the <span>super_block</span> to be freed. It’s done in <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/super.c#L299" target="_blank">an RCU callback</a>
  so one way or another you need to wait for the end of the RCU grace period
  after <span>umount</span> returns, e.g. with <span>membarrier</span>. For a PoC, spraying
  allocs for the duration of the expedited grace period works well enough since
  the <span>super_block</span> slab, <span>kmalloc-2k</span>, is not super busy.</li>
  <li>overwrite the freed <span>super_block</span> via a dynamic heap allocation primitive
  (e.g. <a href="https://elixir.bootlin.com/linux/v5.4.7/source/net/socket.c#L2264" target="_blank">sendmsg ancillary data</a>).</li>
  <li>point <span>s_op</span> to an attacker-controlled buffer</li>
  <li>point <span>drop_inode</span> to a chain of gadgets that pivot the stack to
  either the <span>super_block</span> or <span>super_operations</span> bufffers (which
  are both necessarily in registers and almost fully controlled). Example of
  common gadgets that would work in this situation would be <span>push reg; jmp/call [reg+x]</span>
  that can then be chained with a <span>pop rsp; ret</span> gadget placed at <span>[reg+x]</span></li>
  <li>do whatever with your unconstrained ROP, fixup the stack and return</li>
</ul>


<p>This would be a sucky exploit to maintain as it relies on precise knowledge
of the kernel image, but that’s as good as it gets for a raw function pointer
execution without a read primitive in kernel space. The portability issues
for exploits like this are in themselves a significant bonus of SMEP: it rarely
prevents exploitation but makes many candidates much less appealing for weaponization.</p>

<p>We can take SMEP for granted. It’s only one CPU generation / 2 years older
than SMAP, but not having it is getting really rare. Plus if your exploit does
rely on no-SMEP but your target ends up having software SMEP enabled, which
you sometimes can't really tell at runtime, you've just turned a privesc attempt into
a lost foothold. No-SMAP however is still a thing for the time being. As a
random example the <a href="https://aws.amazon.com/intel/" target="_blank" title="AWS EC2 intel CPUs">AWS EC2 CPU roster</a>
shows some CPUs that do not support SMAP.</p>

<p><strong>On infoleak bugs</strong></p><p>In any case, to exploit this bug one needs at least one infoleak. The most
important is to get kernel base for gadgets, and then we could use a heap leak
or similar to support SMAP-capable CPUs (to have our "attacker-controlled
buffer" in point 3 above in kernel space). A heap/stack leak can often yield
a .text address as well so having one would kill two birds with one stone.
But, not everyone has the right infoleak in their stash ready to go, contrary
to a common anti-KASLR argument. And even when you do have an infoleak bug,
it doesn't mean that it will help with your current exploit.</p>

<p>For instance, a good infoleak candidate which was released around the same
time last year would be the one with uninitialized memory in coredumps, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-10732" target="_blank">CVE-2020-10732</a>.
But short of a public proof-of-concept, one needs to understand the coredump
generation code, then find an object in that slab that allows us to get
.text, and another one to deduce a heap address you control. In short, at least
as much work as the rest of the exploit we are looking at. And that's without
considering that using two bugs in one exploit also means that you need to
take into account both bugs limitations. Unprivileged user namespaces for the
main bug we are looking at (not a thing on e.g. RHEL 7), and for the coredump,
well the ability to retrieve the core files, i.e. not running in a container.
Luckily for our project, we already knew we were targeting non-SMAP containers
so we were able to avoid spending all that effort on an infoleak bug that
would have ended up being worthless; a luxury that real exploit developpers
preparing capabilities ahead of time do not have. But if we were targeting
SMAP containers, well that would have been it since more effort would have
exceeded our resource budget for this project.</p>

<p><strong>Hardware side-channels</strong></p><p>For kernel .text however, the situation is different since there are generic,
publicly-documented ways to obtain kernel base: hardware vulns. I personally
hadn’t ever used any and even saw them as a niche exploitation technique
relying on opaque CPU heuristics that don’t hold across models - not something
to be considered for resilient exploits. I was simply wrong, but thankfully
had access to many specialists (<a href="https://twitter.com/tehjh" target="_blank">@tehjh</a>,
<a href="https://twitter.com/_fel1x" target="_blank">@_fel1x</a>, <a href="https://twitter.com/_tsuro" target="_blank">@_tsuro</a>)
who knew better.</p>

<p>While side-channels that allow leaking memory across security boundaries
are hopefully bound to be mitigated, there are many side-channels that leak
addresses and which we haven’t heard much about since Spectre and friends.
These ones are probably here to stay even longer. For this project I used <a href="https://github.com/tpn/pdfs/blob/master/Jump%20Over%20ASLR%20-%20Attacking%20Branch%20Predictors%20to%20Bypass%20ASLR%20-%202016%20(micro16).pdf" target="_blank" title="jump over aslr paper">Jump Over ASLR</a>,
which was published before Spectre in 2016. It’s simple to understand (especially
with access to the aforementioned people) and there are PoCs that are just
waiting to be adjusted to your own scenario (e.g. <a href="https://github.com/felixwilhelm/mario_baslr" target="_blank" title="mario_baslr jump over aslr">mario_baslr</a>
from @_fel1x). Jump Over ASLR relies on the inner workings of the Branch Target
Buffer where user and kernel branches may collide. When that happens, the CPU
has more work to do and that can be observed. This allows leaking kernel base 
as long as you have offsets of branches hit during a short kernel path you
can trigger at will: you can then leverage the low entropy of KASLR to try
all possible base addresses and find the one where the branches are hit.</p>

<p>For the parameters (the branches to measure) you can really use whatever
you want. I only tried the <span>creat</span> syscall with arguments that cause a
fast return to userland, and then measured whether the <span>sys_creat</span> and
<span>do_sys_open</span> offsets had been hit. The offsets need to be fairly precise
but not to the byte since there seems to be some aliasing going on in the branch
predictor: I originally used <span>__fentry__</span> as an additional branch target
at a +5 offset for both symbols which still worked even though I later learned
these calls get <a href="https://lwn.net/Articles/747256/" target="_blank">dynamically patched out</a>.
</p>

<p>With proper filtering of both false negatives and false positives (essentially
double checking each address) this works like a charm on recent Intel CPUs,
and it’s one of many such techniques that have been published in the past
6 years or so. That makes it something we should be able to rely on as exploit
developers for the foreseeable future. So for a known kernel image at least,
we are essentially back to pre-KASLR times - and keep in mind that it’s a
field I know fairly poorly so other side-channels are probably even better.</p>

<p><strong>Patch gap</strong></p><p>Ok here is what I personally found really interesting because I had never
looked into kernel bug timelines before. This bug was initially reported on
February 28 2020, and fixed in tip on March 3. At this point it’s essentially
public for anyone keeping an eye out for interesting kernel patches - even
if you don’t spend too much time on it, a <span>reported-by</span> Jann Horn is
worth looking into. The main kernel lines were fixed either on March 25 or
April 2. If you’re thinking “oh wow one whole month”, please be seated for
what’s coming.</p>

<p>Some distros applied the patch almost immediately:
</p><ul>
  <li>Arch Linux: Mar 25</li>
  <li>Gentoo: Mar 25</li>
  <li>Fedora: Mar 26</li>
</ul>


<p>I know they are not supposed to target workstations specifically but outside
of personal servers I don't think I have ever seen them used otherwise. The
2nd batch of distributions that fixed the bug is arguably more server-ready:
</p><ul>
  <li>Ubuntu 18.04 LTS: Apr 7</li>
  <li>Ubuntu 16.04 LTS: Apr 24</li>
  <li>Debian Buster …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">https://blog.frizn.fr/linux-kernel/cve-2020-14381</a></em></p>]]>
            </description>
            <link>https://blog.frizn.fr/linux-kernel/cve-2020-14381</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304099</guid>
            <pubDate>Mon, 01 Mar 2021 16:04:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding the Clothes Dryer Is Expensive]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26304045">thread link</a>) | @sbolt
<br/>
March 1, 2021 | https://www.notion.so/Avoiding-the-dryer-is-expensive-8f355009605d48e0a50b6b756d2f55e9 | <a href="https://web.archive.org/web/*/https://www.notion.so/Avoiding-the-dryer-is-expensive-8f355009605d48e0a50b6b756d2f55e9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Avoiding-the-dryer-is-expensive-8f355009605d48e0a50b6b756d2f55e9</link>
            <guid isPermaLink="false">hacker-news-small-sites-26304045</guid>
            <pubDate>Mon, 01 Mar 2021 16:01:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Billionaires Shouldn't Exist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26303712">thread link</a>) | @itsaj87
<br/>
March 1, 2021 | https://www.highbrowdrivel.com/why-we-need-to-get-rid-of-billionaires-w-lloyd-russell-moyle-mp-and-suse-steed/ | <a href="https://web.archive.org/web/*/https://www.highbrowdrivel.com/why-we-need-to-get-rid-of-billionaires-w-lloyd-russell-moyle-mp-and-suse-steed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="st-container">
        <div>
            <div>
                <div>

                    
  
    






  


                    

                    

    



    <section>
        <div>
            <div>
                
                    <div>
                        

<div>

    



    

    
        
    

    

    

    
        
    

    

    
    

        
            
        

        

        <hr>

        

        <div id="show-notes">
            <p>I have 99 problems and the economic structures that allow billionaires to exist cause 98 of them. In this episode we speak to Suse Steed, who is both a former economist and a comedian (a great venn diagram for a guest on this show) and MP Lloyd Russell-Moyle who went viral after he had the unfortunate experience of dealing with the feigned indignation of Emma Barnett when discussing billionaires.&nbsp;<br>In this episode we discuss:</p><ul><li>Whether you can be a good billionaire</li><li>Why we seem to be against greed in children or animals but accept it in adults&nbsp;</li><li>Just how big a billion actually is&nbsp;</li><li>What it takes to become a billionaire&nbsp;</li><li>Whether billionaires do more good than bad via investment and philanthropy&nbsp;</li><li>And of course, it wouldn't be an episode of Highbrow Drivel without discussing why Elon Musk is such a prick.</li></ul><div><p>Guests: <br><b>Lloyd Russell-Moyle</b> is the MP&nbsp; for Brighton Kemptown and Peacehaven. He is incredibly passionate, articulate and progressive and joy to talk to and listen to. You can follow him on <a href="https://twitter.com/lloyd_rm?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Twitter</a> or learn more about him and his views on <a href="https://russell-moyle.co.uk/">his website. <b>&nbsp;</b></a><b><p>Suse Steed</p></b><br>Is a comedian, writer, performer and former economist. She does a great (and important) job of demystifying the big and confusing ideas of money and finance in a fun and entertaining way. You can follow her on <a href="https://twitter.com/sussteed">Twitter</a> or learn more about her on <a href="http://susiesteed.com/">her website.</a></p></div>
            
        </div>

        

        

    

    
        




    

    

</div>

                    </div>
                    
                        


    
        </div>
    </div></section>



                    

                </div>
            </div>
        </div><!-- END: st-pusher -->
    </div><!-- END: st-container -->
</div></div>]]>
            </description>
            <link>https://www.highbrowdrivel.com/why-we-need-to-get-rid-of-billionaires-w-lloyd-russell-moyle-mp-and-suse-steed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303712</guid>
            <pubDate>Mon, 01 Mar 2021 15:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A case for funding Open Source Software]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26303592">thread link</a>) | @jackyzhao
<br/>
March 1, 2021 | https://blog.jzhao.xyz/posts/paid-open-source/ | <a href="https://web.archive.org/web/*/https://blog.jzhao.xyz/posts/paid-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainText"><h2 id="making-of-open-source-software">Making of Open Source software</h2><p>I’ve recently made my way through <em>Working in Public: The Making and Maintenance of Open Source Software</em> by Nadia Eghbal. Not only does it have some absolutely stunning cover art, it also touches on some thoughts that have been marinating in my head about the intersection of open source and funding. So much so, that I’ve started experiencing the Baader-Meinhof effect, seeing something to do with open source and funding everywhere I look in tweets, conversations, and blogs.</p><p>This blog post is an exploration of processes in open source, the value it provides, and how money fits into the picture.</p><p><img src="https://blog.jzhao.xyz/img/oss_book.jpg" alt="Working in Public: The Making and Maintenance of Open Source Software"><em>Working in Public: The Making and Maintenance of Open Source Software</em></p><h3 id="how-its-made">How it’s made</h3><blockquote><p>“Open source developers were frequently characterized as ‘hobby’ developers, because the assumption was that only companies could make ‘real’ software."<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p></blockquote><p>As it stands, there are two primary schools of thought about how open source software is created.</p><ol><li><p><strong>Firm-based</strong> production involves companies, organizations, governments, or any institution with centralized resources. Their driving thesis is that only companies make software because, from a coordination standpoint, centralized firms are the most efficient way to manage resources. Most development done this way is motivated extrinsically by means of monetary compensation.</p></li><li><p><strong>Commons-based</strong> production is a more vague concept that involves a distributed group of developers that work on a resource that is used, owned, and governed by its own community - free of employer affiliations. Most development done this way is motivated intrinsically, people do work because they want to do it.</p></li></ol><p>Traditionally, software has been seen as a product of firms. Open source developers were often treated as hobbyists and the projects they made trivialized as toys. The assumption was that only companies could make ‘real’ software. However, the rise of Internet computing and collaboration tools like Git have decreased the barrier to entry enough that producing software through a commons is now feasible and very much alive. The success of projects like Apache, Linux, and FreeBSD proved just how successful a commons-based method of production could be.</p><p>Surprisingly, this may also help to explain why some developers view open source and money as completely separate. If the commons-based method of production is rooted in intrinsic motivation, then money, an extrinsic motivator, will be seen as opposite to core ideals that open source stands for.</p><h2 id="creation-vs-maintenance">Creation vs Maintenance</h2><blockquote><p>“Creation is an intrinsic motivator, maintenance usually requires extrinsic motivation”</p><p>@balupton, isaacs/github <a href="https://github.com/isaacs/github/issues/167">#167</a></p></blockquote><p>When an artist finishes a painting, or a runner finishes a marathon, that usually signifies the end of said responsibility. There is no such finish line for an open source project, even after pushing out an initial product.</p><p>Creating a project is fun. It’s a wild exploration into a new idea, a frivolous journey to create something useful or to learn something new. As cloud platforms continue to eat the world, the costs of distributing and sharing a project are almost completely nullified.</p><p>Just a few clicks and a few taps of your keyboard and your project is readily available to any of the 4.66 billion people around the world with internet access. This adrenaline rush of finally releasing the labour of your work onto the world is the moment developers are constantly chasing. For most developers, the process of creation and distribution is intrinsically motivated; it’s an enjoyable process.</p><p>Maintenance is less so. This is akin to a writer that’s been asked to edit and revise the same book day in and day out, long after they’ve reaped the initial financial and reputational rewards from its creation. Even when the creator wants to leave the project to work on something else, they can’t. They’re tightly shackled by the fact that hundreds of thousands of other organizations, companies, and tools rely on their code to keep their operations running. Bringing on additional developers may not help either, as they still require onboarding, code reviews, and general guidance.</p><p>Code may be nearly free to create and distribute, but maintenance is still expensive.</p><h2 id="types-of-code">Types of code</h2><h3 id="code-as-an-artifact">Code as an artifact</h3><p>There are two main ways we can look at code. The first of which is <em>static</em> code. Code that, on its own, does nothing but exists as an archive. Others can copy and download the code without incurring any additional costs to the author. For the maintainers, it should make no difference in regards to cost whether 10 or 10,000 people use it.</p><p>This type of code is a pool resource, it is</p><ol><li><strong>Non-rivalry.</strong> My ability to copy the code doesn’t affect your ability to copy it. (This isn’t exactly true due to some marginal costs but I’ll discuss this later)</li><li><strong>Non-excludable.</strong> If someone has a copy of the code, it is very difficult to prevent them from sharing that code with others.</li></ol><p>Any code that is in this state is easy to share, copy, and distribute. This is the type of code that lives dormant on Github, on StackOverflow answers, and in GitHub’s Arctic Vault<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. However, the main purpose of consuming code is not to simply read and study it, but to actually use it and to let it interact with other code.
In doing so, we bring it to life.</p><h3 id="code-as-an-organism">Code as an organism</h3><blockquote><p>“Open source code derives its value not from its static qualities but from its living ones."<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p></blockquote><p>As soon as you hit CTRL-V on that snippet of code, as soon as that static code is inserted into your own, that code comes to life. It might surface ridiculous amounts of red squigglies, break other code, or force you to rewrite your previous code just to make it work. When code transitions from a resting static state to an active living state, it starts to incur a set of hidden costs.</p><p>Like a living organism in a symbiotic relationship, there is a mutual interdependence between it and others in the software ‘ecosystem’ in order to survive. As a result, this ecosystem requires constant upkeep to ensure that components don’t fall out of balance: dependency bumps, documentation updates, and infrastructure changes.</p><h2 id="free-as-in-speech-not-as-in-beer">Free as in speech, not as in beer</h2><p>‘Free’ software doesn’t refer to its price. In fact, ‘free’ software is often extremely expensive. As Richard Stallman first described free software, it’s “free as in speech, not free as in beer.” The point Stallman was trying to make was that ‘free’ refers to what one could do with the software, rather than the price tag.</p><h3 id="latent-cost-of-software">Latent cost of software</h3><p>In reality, code in its alive state is more like a free puppy. In the beginning, it’s a great and wonderful thing! Super fun and super cute. As it grows and gets older, you realize “geez, it actually takes a lot of my own time to take care of this thing.” Unlike a piece of inanimate furniture, bringing a living creature into one’s home comes with bringing in a new set of responsibilities too.</p><p><strong>Marginal costs</strong> are costs increase on a per-user basis. I mentioned earlier that these costs mean that software is actually rivalrous, meaning that at some point, the project won’t be able to support the n+1th user. Some of this cost comes from physical infrastructure like code hosting and infrastructure. However, the majority of the cost comes from user support. Say you have a billion users and only 0.1% of them require support. If it takes you roughly 10 minutes to resolve each issue, you would still need 20,833 people working 8-hour shifts a day just to be able to keep up with the support volume. Maintainers are constantly wrestling with keeping their issue volume low and questions answered. Eventually, it just becomes a hindrance preventing them from working on the core product.</p><p><strong>Temporal costs</strong> are those which build up and compound over time. Most of it comes from technical debt, choices that are easier today at the expense of time and money in the future. This is the eternal battle against entropy: the inevitable decay of systems over time. When code changes, all the supporting knowledge that surrounds it must be updated too. Documentation, tutorials, programming books, videos, and more slowly become obsolete.</p><p>Paying off these latent costs is seldom intrinsically motivated. When people talk about how fun making new projects is or contributing to open source, it’s never referring to writing documentation or refactoring code. This isn’t the ‘fun’ part of writing software. This is the nasty upkeep that goes into maintaining a building from the 1850s that’s had new rooms, plumbing, and electric wiring frankenstein-ed into it over the years.</p><h2 id="funding-open-source">Funding Open Source</h2><p>I first started on BentoML<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> as a casual contributor last summer, submitting a few decently sized PRs. It was almost all intrinsically motivated; I found issues that I enjoyed working on and that I knew I would learn lots from. Satisfied with my experience, I decided to join the team as a paid contractor expecting to just continue the type of work I was doing in the summer. As issue after issue piled on, I slowly started to realize just how much extra work being a maintainer meant and why it was a paid position. Making proposals, triaging issues, adding tests, and writing documentation took up the majority of my time. While I recognized it was important work, it was not work I was intrinsically motivated to do. Thus, to motivate people like me to get that work done, an extrinsic motivator – in this case, money – needed to be applied.</p><p>How do we best incentivize maintainers to work tasks stripped of the very excitement and promise of creation that initially drew them to the project in the first place? There is a jarring disconnect between work that is needed versus work that is intrinsically motivated. This is where I believe open source funding should play a role. There are two main potential avenues to go about this.</p><h3 id="funding-projects">Funding projects</h3><p>One possibility is to fund projects directly. This route builds a brand around the project. The status of the project then transcends any single person’s contributions and becomes a tangible entity …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jzhao.xyz/posts/paid-open-source/">https://blog.jzhao.xyz/posts/paid-open-source/</a></em></p>]]>
            </description>
            <link>https://blog.jzhao.xyz/posts/paid-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303592</guid>
            <pubDate>Mon, 01 Mar 2021 15:25:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JuliaSymbolics Roadmap: A Modern Computer Algebra System for a Modern Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26303464">thread link</a>) | @ChrisRackauckas
<br/>
March 1, 2021 | https://juliasymbolics.org/roadmap/ | <a href="https://web.archive.org/web/*/https://juliasymbolics.org/roadmap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<!-- Content appended here -->
<div>
<p>We need new Computer Algebra Systems (CAS) for this new era of computing. We need a CAS that dispatches in the multiple ways we think. We need a CAS that scales exponentially like our problems. We need a CAS that integrates with our package ecosystem, letting people extend parts and contribute back to the core library all in one language. We need a modern CAS in a modern language.</p>
<p>Symbolics.jl is the answer. Symbolics.jl is a pure Julia CAS which uses the Julia core library to its fullest. It is built from the ground up with performance in mind. We use specialized structures for automatic simplification to match the performance of the most fully optimized C++ libraries. It exploits parallelism at every level; our symbolic simplification takes advantage of Julia's task-based multithreading to transform symbolic equations into parallelized Julia code.</p>
<p>This reconstruction of the idea of CAS in Julia's type system is entirely extensible. New term types enable fast symbolic arithmetic on standard and non-standard algebras; add-on libraries like ModelingToolkit build a bridge from symbolics to numerics. Symbolics.jl and its ecosystem will be the common foundation on which the next generation of Domain-Specific Languages (DSLs) will be constructed, automatically updated and accelerated through with the growth of this system.</p>
<h2 id="the_features_of_symbolicsjl"><a href="#the_features_of_symbolicsjl">The Features of Symbolics.jl</a></h2>
<p>Symbolics.jl at its launch in 2021 is already expansive. It includes:</p>
<ul>
<li><p>Symbolic arithmetic with type information and multiple dispatch</p>
</li>
<li><p>Symbolic polynomials and trigonometric functions</p>
</li>
<li><p>Pattern matching, simplification and substitution</p>
</li>
<li><p>Differentiation</p>
</li>
<li><p>Symbolic linear algebra (factorizations, inversion, determinants, eigencomputations, etc.)</p>
</li>
<li><p>Discrete math (representations of summations, products, binomial coefficients, etc.)</p>
</li>
<li><p>Logical and Boolean expressions</p>
</li>
<li><p>Symbolic equation solving and conversion to arbitrary precision</p>
</li>
<li><p>Support for non-standard algebras (non-commutative symbols and customizable rulesets)</p>
</li>
<li><p>Special functions (list provided by <a href="https://github.com/JuliaMath/SpecialFunctions.jl">SpecialFunctions.jl</a>)</p>
</li>
<li><p>Automatic conversion of Julia code to symbolic code</p>
</li>
<li><p>Generation of (high performance and parallel) functions from symbolic expressions</p>
</li>
<li><p>Fast automated sparsity detection and generation of sparse Jacobian and Hessians</p>
</li>
</ul>
<p>and much more. A lot of these features are for free given its deep integration with multiple dispatch and Julia's type system.</p>
<h2 id="connection_to_the_package_ecosystem"><a href="#connection_to_the_package_ecosystem">Connection to the Package Ecosystem</a></h2>
<h3 id="the_connection_to_the_modelingtoolkitjl"><a href="#the_connection_to_the_modelingtoolkitjl">The Connection to the ModelingToolkit.jl</a></h3>
<p>Here in the Julia world, we like differntial equations, maybe a little too much.</p>
<p>Symbolics.jl grew out of ModelingToolkit.jl, an equation-based modeling system for the Julia programming language. Its vision is that the best system for modeling requires having the ability to symbolically specify models and build a library of transformations for generating more stable and performant code. While software in a similar space like Simulink and Modelica are disconnected from traditional programming languages and symbolic algebra systems, ModelingToolkit.jl weaves them together, allowing all aspects of the Julia programming language and symbolic computing to contribute to the richness of its design.</p>
<p>The ModelingToolkit.jl project has been almost too much of a success in that respect, reaching a feature-base that included an entire CAS as a submodule within itself. It was time for that CAS to be set free. Symbolics.jl is that CAS, now set in its own organization, JuliaSymbolics, with its ability to transform new domains.</p>
<p>ModelingToolkit.jl will continue to provide the symbolic representations of common numeric systems and the SciML organization, such as causal and acausal modeling (Simulink/Modelica) in the domains of:</p>
<ul>
<li><p>Ordinary differential equations</p>
</li>
<li><p>Stochastic differential equations</p>
</li>
<li><p>Partial differential equations</p>
</li>
<li><p>Nonlinear systems</p>
</li>
<li><p>Optimization problems</p>
</li>
<li><p>Optimal Control</p>
</li>
</ul>
<p>It will continue to power the connection the next generation of symbolic-numeric computation, blurring the boundaries by mixing analytical solutions with optimized and parallelized generated code. All symbolic functionality related to those domains will continue to thrive in that package, leaving Symbolics.jl the room to focus on the core of symbolic algebras: polynomials, Grobner bases, and more.</p>
<h3 id="the_connection_to_symbolicutilsjl"><a href="#the_connection_to_symbolicutilsjl">The Connection to SymbolicUtils.jl</a></h3>
<p>Symbolics.jl is an opinionated CAS. It types its variables so that generic Julia functions which require <code>Real</code> numbers can automatically be converted into symbolic expressions. It uses the Leibniz rules for defining derivatives. It does symbolic algebra as "the normal person would expect".</p>
<p>However, there are some use cases in computational algebra which require non-standard rulesets. How would you define symbolic Octonian numbers or define differentiation on non-smooth manifolds that do not satisfy the Leibniz rule? For these questions, mathematicians have traditionally been on their own having to develop new tools from scratch. However, the JuliaSymbolics has refactored its core so that new algebras can easily be implemented and created, and automatically get the optimized high performance of Symbolics.jl. This is SymbolicUtils.jl.</p>
<p>SymbolicUtils.jl is a fast and parallel rule-based rewrite system. By specifying a list of rules, such as trigonometric identities, you can specify new mathematical domains and create the symbolic arithmetic that you need. Symbolics.jl is built on this foundation, adding the common simplification rules for real numbers, derivative definitions and rules for Newton differentiation, and more. However, if you're so inclined, SymbolicUtils.jl is open for you to define BraKet algebras and more.</p>
<h2 id="goals_for_symbolicsjl"><a href="#goals_for_symbolicsjl">Goals for Symbolics.jl</a></h2>
<p>Symbolics.jl will be a never ending project as we wish to provide a high performance implementation of every symbolic algorithm that can and does exist. But, there are specific goals we have in mind.</p>
<h3 id="high-performance_symbolic_arithmetic"><a href="#high-performance_symbolic_arithmetic">High-Performance Symbolic Arithmetic</a></h3>
<p>Anywhere that we are beat in performance is a bug. Please file an issue immediately. This library should use every core, and it should use every core efficiently, allowing the exponential cost of symbolic arithmetic to tackled by the exponential gains in computational power and efficiency.</p>
<h3 id="pervasiveness_throughout_the_julia_dsls"><a href="#pervasiveness_throughout_the_julia_dsls">Pervasiveness Throughout the Julia DSLs</a></h3>
<p>We want to provide a symbolic foundation which all DSLs can rely on. We do not believe that a pharmacometrics library should define how to symbolically calculate a Hessian, and then the mathematical programming library JuMP, etc. We believe that by pooling together on Symbolics.jl, we can accelerate the growth of DSLs throughout the language, offering a way to collaborate towards a single battletested implementation.</p>
<h3 id="bridge_the_gap_from_computer_scientists_to_scientists_and_mathematicans"><a href="#bridge_the_gap_from_computer_scientists_to_scientists_and_mathematicans">Bridge the Gap from Computer Scientists to Scientists and Mathematicans</a></h3>
<p>While "code" is what package developers like to see, math is what practioners are trained on. We are committed to bridging that gap, making it easy to see the LaTeX-ification of the symbolic variables, creating informative displays in notebooks. Symbolics.jl should look and feel like doing math.</p>
<h3 id="feature_completeness"><a href="#feature_completeness">Feature Completeness</a></h3>
<p>We want Symbolics.jl to be the place where you check the documentation immediately for symbolic methods, knowing that if such a method exists then it's implemented there. Symbolics.jl should not just cover the domain but also be an archive of its research and science, making it easy to explore algorithms and compare between them.</p>
<h2 id="next_steps_for_symbolicsjl"><a href="#next_steps_for_symbolicsjl">Next Steps for Symbolics.jl</a></h2>
<p>We have not met all of our goals yet. While much of this roadmap has been accomplished, there is much in our way forward. Some major goals on our sights are:</p>
<ul>
<li><p>Symbolic integration using <a href="https://rulebasedintegration.org/">RUBI</a></p>
</li>
<li><p>Expansive algorithm selection for Grobner Basis</p>
</li>
<li><p>Feature parity with SymPy (<a href="https://github.com/JuliaSymbolics/Symbolics.jl/issues/59">being tracked here</a>)</p>
</li>
<li><p>Integration with distributed and GPU computation</p>
</li>
<li><p>High performance symbolic root finding</p>
</li>
<li><p>Integrating modern techniques like <a href="https://arxiv.org/pdf/1912.01412.pdf">deep learning to accelerate and improve symbolic rule application</a></p>
</li>
<li><p>Tools for <a href="https://herbie.uwplse.org/">transforming generated equations to have minimal floating point error</a></p>
</li>
<li><p>A full reproducible benchmarking suite</p>
</li>
</ul>
<h2 id="how_you_can_join_the_process"><a href="#how_you_can_join_the_process">How You Can Join The Process</a></h2>
<p>If you want to be a part of JuliaSymbolics, that's great, you're in! Here are some things you can start doing:</p>
<ul>
<li><p>Star our libraries like <a href="https://github.com/JuliaSymbolics/Symbolics.jl">Symbolics.jl</a> and our extensions like <a href="https://github.com/SciML/ModelingToolkit.jl">ModelingToolkit.jl</a>. Such recognition drives our growth to sustain the project.</p>
</li>
<li><p>Join our chatroom to discuss with us. Our main chatroom is <code>#symbolic programming</code> on the <a href="https://julialang.zulipchat.com/register/">Julia Zulip</a></p>
</li>
<li><p>If you're a student, find a summer project that interests you and apply for funding through Google Summer of Code or other processes (contact us if you are interested)</p>
</li>
<li><p>Start contributing! We recommend opening up an issue to discuss first, and we can help you get started.</p>
</li>
<li><p>Help update our websites, tutorials, benchmarks, and documentation</p>
</li>
<li><p>Help answer questions on Stack Overflow, the Julia Discourse, and other sites!</p>
</li>
<li><p>Hold workshops to train others on our tools.</p>
</li>
</ul>
<p>There are many ways to get involved, so if you'd like some help figuring out how, please get in touch with us.</p>

</div><!-- CONTENT ENDS HERE -->
    </div></div>]]>
            </description>
            <link>https://juliasymbolics.org/roadmap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303464</guid>
            <pubDate>Mon, 01 Mar 2021 15:14:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Simple decentralized web hosting on Peergos]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26303144">thread link</a>) | @ianopolous
<br/>
March 1, 2021 | https://peergos.org/posts/p2p-web-hosting | <a href="https://web.archive.org/web/*/https://peergos.org/posts/p2p-web-hosting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You already know that Peergos lets you store and share files securely and privately. Now, you can also host your own website on it!</p>
<p>We always thought getting a website up and running should be one of the easiest things to do on the web. There are plenty of options available for website hosting, but with Peergos there's no need to buy a domain name, arrange TLS certificates, or run a server to host the content. You also don't need any cryptocurrency to post or update your website, so you can get free instantaneous updates and peer-to-peer authenticated delivery. You can sign up to <a href="https://beta.peergos.net/?signup=true">our beta</a> today and get started right away in just two easy steps:</p>
<ol>
<li>
Upload your website files to a directory in Peergos.
</li>
<li>
Go to your profile, set that directory as your website and click publish.
</li>
</ol>

<p>Your personal website will now be available at <tt>https://&lt;your-user-name&gt;.peergos.me</tt>. It doesn't get any simpler than that. Let's see this in action!</p>
<center>
<img alt="www" id="id" src="https://peergos.org/theme/img/blog/p2p-webhosting.gif" width="90%">
<br>
Host your decentralized website directly from Peergos.
</center>
<p>Any changes made to your website files are automatically and instantly reflected in your website. When we say instantaneous, we mean it. Check it out below!</p>
<center>
<img alt="www-update" id="id" src="https://peergos.org/theme/img/blog/p2p-web-update.gif" width="90%">
<br>
Instantaneous and free updates to your decentralized website.
</center>
<p>When you publish a website from Peergos, you can view it through any Peergos gateway. We're running one at <tt>peergos.me</tt>, so your website will be available at <tt>https://&lt;your-user-name&gt;.peergos.me</tt>, and viewable in any browser today. Bear in mind that viewing through a public gateway like that still relies on DNS and the TLS certificate authorities, which are both single points of failure that are vulnerable to attack. However, we can actually get around both of these by viewing someone's site through a local Peergos gateway. To visit someone's site in this way, you just run a local Peergos instance and browse to <tt>http://&lt;username&gt;.peergos.localhost:9000</tt>. The gateway looks up the public key of the username provided in the localhost subdomain via the Peergos PKI, then retrieves the website and serves it. All this is done without relying on DNS or TLS certificates anywhere. We are thus able to use localhost subdomains to achieve isolation and security between different sites served from one local gateway. </p>
<p>Websites hosted on Peergos benefit from our resilient and reliable decentralized architecture. Most of the heavy lifting is done by <a href="https://ipfs.io/">IPFS</a> through content addressing and public key based routing. With our architecture, we add fast mutable pointers and human-readable names. Therefore, you can trust that the content of your website will be readily available without having to rely on a single-point-of-failure-server anywhere. </p>
<p>In the future, we will enable viewing such websites directly inside the Peergos web interface. At that point, Peergos will really start to look like a new web.</p>
<p>There are still a few free accounts available on <a href="https://beta.peergos.net/?signup=true">our beta</a>. Let us know what you think. We're always looking for feedback, so either <a href="mailto://peergos@peergos.org">drop us a line</a> or come say hi in our <a href="https://app.element.io/#/room/#peergos-chat:matrix.org">Matrix chatroom</a>.</p>
<p>Stay tuned for introductions to a few other new features and apps we're building as part of our <a href="https://peergos.org/posts/next-generation-internet">grant</a> from the Next Generation Internet program (<a href="https://pointer.ngi.eu/">NGI POINTER</a>).</p>

<hr>
<center>
<img alt="NGI Pointer" height="65px" id="id" src="https://peergos.org/theme/img/ngi-logo.png">
<img alt="NGI Pointer" height="65" id="id" src="https://peergos.org/theme/img/eu.png">
</center>
<p>
This project has received funding from the European Union’s Horizon 2020 research and innovation programme within the framework of the NGI-POINTER Project funded under grant agreement No 871528</p>

<h4>RECENT POSTS</h4>
    </div></div>]]>
            </description>
            <link>https://peergos.org/posts/p2p-web-hosting</link>
            <guid isPermaLink="false">hacker-news-small-sites-26303144</guid>
            <pubDate>Mon, 01 Mar 2021 14:39:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MKBHD TLDR: Summarizing YouTube Video Reviews with AI]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26302959">thread link</a>) | @tlochhead
<br/>
March 1, 2021 | https://tavis.cc/mkbhd-tldr/ | <a href="https://web.archive.org/web/*/https://tavis.cc/mkbhd-tldr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>YouTube is the fastest-growing platform for all sorts of content. Video reviews being one of them. I love the quality that goes into these reviews.</p>
<p>But what if there was a way to quickly grab consensus of these videos without spending hours watching them all?</p>
<p>TLDR: Yes. With AI.</p>
<p>See the results 👉&nbsp;<a href="https://twitter.com/MKBHDtldr" target="_blank" rel="nofollow noreferrer noopener">twitter.com/MKBHDtldr</a></p>
<p>
  <span>
    <span>
      <img alt="tw1" title="tw1" src="https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/07484/tw1.png" srcset="https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/d76be/tw1.png 135w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/01bf6/tw1.png 270w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/07484/tw1.png 540w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/d7542/tw1.png 810w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/302a4/tw1.png 1080w,
https://tavis.cc/static/24ba817c55dfa182fb76716cc5a07cf0/51800/tw1.png 1196w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<h2>Evolution of AI</h2>
<p>Alongside the rapid growth of YouTube’s popularity is AI innovation. One particular company that is gaining a lot of attention is Elon Musk-backed <a href="https://openai.com/" target="_blank" rel="nofollow noreferrer noopener">OpenAI</a>.</p>
<p>Last week, I was fortunate enough to join their private beta program. So very quickly, I decided to try something I have wanted to do with <a href="https://recorank.com/" target="_blank" rel="noopener">RecoRank</a> for some time: automated YouTube video review analysis using AI.</p>
<p>I’m a huge MKBHD fan. And as one of the top YouTube video reviewers, I tried using OpenAI to summarize his video review transcripts.</p>
<p><a href="https://twitter.com/MKBHDtldr" target="_blank" rel="nofollow noreferrer noopener">The results have been amazing so far.</a></p>
<p>
  <span>
    <span>
      <img alt="tw2" title="tw2" src="https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/07484/tw2.png" srcset="https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/d76be/tw2.png 135w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/01bf6/tw2.png 270w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/07484/tw2.png 540w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/d7542/tw2.png 810w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/302a4/tw2.png 1080w,
https://tavis.cc/static/6f1b83c4efc32943f3b7d83c8c685fe8/51800/tw2.png 1196w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<h2>Achieving These Results</h2>
<p><strong>Step 1: Extract Transcripts</strong></p>
<div data-language="text"><pre><code>from youtube_transcript_api import YouTubeTranscriptApi

subtitles = YouTubeTranscriptApi.get_transcript("dhAmMXCBIcg")

sub_list = []

for subtitle in subtitles:
    sub_list.append(subtitle['text'])

txt = " ".join(sub_list)

print(txt)</code></pre></div>
<p>This simple Python script using <a href="https://pypi.org/project/youtube-transcript-api/" target="_blank" rel="nofollow noreferrer noopener">YouTubeTranscriptApi</a> quickly gets you the transcript of any YouTube video - given that the video has a transcript. The API will produce an error if one does not exist.</p>
<p><strong>Step 2: Summarize with OpenAI</strong></p>
<p>
  <span>
    <span>
      <img alt="openai" title="openai" src="https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/07484/openai.png" srcset="https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d76be/openai.png 135w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/01bf6/openai.png 270w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/07484/openai.png 540w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d7542/openai.png 810w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/302a4/openai.png 1080w,
https://tavis.cc/static/5a02c1c4a0662c4d79c523faba3f6a21/d9ed5/openai.png 2880w" sizes="(max-width: 540px) 100vw, 540px">
    </span>
  </span>
  </p>
<p>I used OpenAI’s <code>tl;dr:</code> (too long; didn’t read) function to achieve AI-generated transcript summaries.</p>
<p>On top of the default settings, I also:</p>
<ul>
<li>Set temperature to <code>0</code> to exclude any improvisation of the results and get the summary with no guesswork</li>
<li>Added <code>The [product name]</code> right after <code>tl;dr:</code> to guide OpenAI on what I wanted (i.e. <code>The iPhone 12 is a great phone, but it's not a huge leap forward.</code> - I didn’t do this for all summaries, but I did find that this method delivered the most consistent results than just using <code>tl;dr</code> on its own)</li>
<li>Deleted enough of the start of the transcript to fit within the 2048 token limit (in the case with most reviews, more of the meat is at the end than the beginning, particularly final thoughts)</li>
<li>Added a return break <code>⏎</code> as a Stop Sequence to limit the results to one paragraph</li>
</ul>
<h2>What’s Next?</h2>
<p>These are just the results of one week of experimentation with OpenAI. Pros and cons are other areas to explore.</p>
<p>These are the pros and cons results for MKBHD’s Samsung Galaxy S21 review:</p>
<div data-language="text"><pre><code>Pros:
– Great display
– Great performance
– Great cameras
– Great battery life
– Great design
– Great value

Cons:
– No expandable storage
– No MST
– No S Pen
– No wireless charging</code></pre></div>
<p>I’m hoping to add these insights to <a href="https://recorank.com/" target="_blank" rel="noopener">RecoRank</a> soon.</p>
<p>My friend Adrian Krebs has a <a href="https://www.buyforlife.com/blog/548RijnkRdPwn1cAI5RDjw/make-better-and-faster-purchasing-decisions-with-ai" target="_blank" rel="noopener">blog post</a> about his trials in this area for his business, <a href="https://buyforlife.com/" target="_blank" rel="noopener">BuyForLife.com</a>. Definitely worth a read.</p>
<p>Have an idea of how OpenAI could be applied for review analysis and summarization? I’d love to hear from you. Hit me up on <a href="https://twitter.com/tavislochhead" target="_blank" rel="nofollow noreferrer noopener">Twitter</a> or send me an email @ tavislochhead [ at ] gmail [ dot ] com.</p></div><p><img src="https://tavis.cc/static/headshot-37e68c3c90409f03180397ce570be16e.jpeg" alt="profile pic"><strong><a href="https://tavis.cc/about">Tavis Lochhead</a></strong> <!-- -->is a seasoned marketer who loves tech and data. Tavis is the founder of<!-- --> <a href="https://recorank.com/" target=" _blank">RecoRank</a> <!-- -->and also consults as a marketer, programmer, and data analyst.</p></div>]]>
            </description>
            <link>https://tavis.cc/mkbhd-tldr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302959</guid>
            <pubDate>Mon, 01 Mar 2021 14:18:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I helped a client cut down 90% of server costs with MySQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26302357">thread link</a>) | @nunodonato
<br/>
March 1, 2021 | https://www.kalaksi.com/u/nunodonato/p/programming-and-software-development/3338 | <a href="https://web.archive.org/web/*/https://www.kalaksi.com/u/nunodonato/p/programming-and-software-development/3338">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                
                                
                <div>
                    
                <div><p>
                    First of all, I hope the title isn't too catchy or misleading. There are no magic secrets here, actually, it's all pretty common stuff for anyone that has some experience with any DBMS. But that is, in itself, part of point of this article: that sometimes the basic stuff can be overlooked. </p><p>

<i>(Editorial note: For privacy reasons I changed the names of several things in order to keep the client identity and industry as less-evident as possible)</i></p><p>

I won a contract to build a platform for a client. This was to be used internally but also as a way for the client's clients to access and analyze data. They had a pretty old platform in place that was aging quite fast and lacked useful features. So they hired a company to get them a more modern platform with a flashy UI. Unfortunately, this company didn't build anything new, rather they used something they already had and made lots of tweaks here and there to try and fit a round peg in a square hole. The end product was interesting at first, but in a short period of time it began to show its weaknesses. So again the need came to actually get something built from the ground up that met the needs of the present and was ready for the future. This is when I come in. </p><p>

The main table of the database holds millions and millions of rows. Although the users are not that many, the amount of data being stored every hour is huge. This means the database grows a couple of Gb every single month. But the main problem of the database was not the storage space it needed - I was told - but that it was so big that needed to be as performant as possible.  </p><p>

The main queries that are done, which retrieve data to be analyzed or compared over spans of time, could take anywhere from 30 to 180seconds, depending on the time span of the query. You read that right, seconds. It was painful to use it. </p><p>

Because they were still maintaining the old platform plus the current one, they had a mixture of MySQL and Postgres running. When I proposed to get a fresh start and merge everything together in just one MySQL database I felt some doubts were raised as if I really knew what I was doing. After all, when performance is an issue postgres is the answer. Right? Not necessarily! </p><p>

<b>Step 1 – Actually utilize the resources you have</b></p><p>

Early on in the development process I got access to the current server so I could look at how things were running. The server had a nice 24Gb of RAM, a recent upgrade was done (I was told) from 16Gb, in order to try and improve things. There was so much of stuff being ran at the same time for this platform to work! I never got to understand properly the whole architecture of it but there was a lot of java everywhere. In spite of the RAM increase, there was no noticeable difference in performance. </p><p>

Upon some looking here and there, I noticed that about 90% of the RAM was free. Does that mean that the recent upgrade was totally mislead and unnecessary? Yes, it does! </p><p>

Worse than that, I ended up finding out that the company that installed the server and platform didn't even bother to do a proper setup of the MySql server. That means that it was using default values! For instance, <b>innodb buffer pool size</b> was 128Mb! No one wonder MySql wasn't touching all that available RAM. It was basically a very costly and nonsense server upgrade. Mainly because the server doesn't even get that many requests .</p><p>

<b>Step 2 – Can you believe it?</b></p><p>

I got a partial dump of the database so that I could run some tests on my dev machine. I had the queries that were run most of the time, in order to make sure I was targeting a good performance increase. </p><p>

On my machine I could get slightly faster query results, but still in the order of about 1min, on average. </p><p>

My second shock of horror was when I discover that this table that holds all the important data had the usual auto-incremented primary key, but no indexes whatsoever. No wonder the queries were taking too long! </p><p>

The queries were most of the time something similar to  </p><p>

<b>SELECT [cols...] FROM [datatable] WHERE user_id = ? AND location_id = ? AND datestamp BETWEEN ? AND ?</b><br>
This was the way to fetch all relevant data from a specific location, from a user, during a span of time. But sometimes, for another kind of analysis, it would drop the location and filter only by user and datetime. </p><p>

The priority for using an index was then <b>User_id 🠖 datestamp 🠖 location_id</b></p><p>

Of course you can create an index for all of these columns, but in a table this big it is also important to keep in mind that indexes can take up a lot of space so you don't want too many of them. </p><p>

I ended up creating a composite index, taking into consideration the priority above and that MySql uses the keys from left to right. </p><p>

That means if the index is <b>[user_id, location_id, datestamp]</b> but location_id is not part of the query, then MySql won't be able to use this index even if datestamp is part of the query. </p><p>

The composite index ended up as <b>[user_id, datestamp, location_id]</b> which is somewhat complex but is able to match exactly the kind of queries the platform needs to do. In the event of wanting to retrieve all data from a user in a certain span of time (ignoring location_id), MySql can ignore the last key because it is on the right side of the index. And because data is never fetched without specifying a clear time period, the first two keys are always used. </p><p>
 
After changing the table accordingly I ran a couple of tests with some of the most demanding queries. Data was now fetched always under 1 second! It was like night and day. </p><p>

I decided to give this a try in a very weak server. I created a new VPS in Digital Ocean and opted from the lowest of the lowest: 1vCPU, 1Gb Ram. Actually faced some troubles to get npm to work due to memory constraints (sigh), but after that was done, everything was still blazing fast. </p><p>

This was only used for demos and eventually the client created their own new VPS to host the new platform once it was done, at a 90% reduced yearly-cost, compared to the current one.  </p><p>

So this is my lesson learnt, coming straight from the trenches: never overlook the simple stuff, and never think that others have done the simple stuff too!</p><p>

<b>So, to conclude</b><br>
- Don't assume the basics have been taking into consideration when you are handling work done by someone else<br>
- Check all the default values and adjust accordingly to your server and needs<br>
- Plan your indexes according to the queries you are supposed to execute
                </p></div>
                </div>
            </div>
        
        

        </div></div>]]>
            </description>
            <link>https://www.kalaksi.com/u/nunodonato/p/programming-and-software-development/3338</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302357</guid>
            <pubDate>Mon, 01 Mar 2021 13:02:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving ADA a Chance]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26302344">thread link</a>) | @jayp1418
<br/>
March 1, 2021 | https://ajxs.me/blog/Giving_Ada_a_chance.html | <a href="https://web.archive.org/web/*/https://ajxs.me/blog/Giving_Ada_a_chance.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<header>
				<a id="header-link" href="https://ajxs.me/">
					
				</a>
			</header>
			<section id="blog-entry">
	
	<div>
		<p><span>TL;DR:</span> Ada is an extremely interesting and robust programming language that has a lot to offer modern developers of system 
	and bare-metal software. At very least, Ada presents many interesting ideas that designers of modern programming languages could stand to learn much from. If you want a 30 second version of this article, check out the 
	<a href="#practical_example">practical example</a> that I provide for a comparison of Ada with C.</p>

<p>
	Much of the technical material presented in this article is available as part of <a href="https://wiki.osdev.org/User:Ajxs">my contributions</a> to <a href="https://wiki.osdev.org/Main_Page">osdev.org</a>
</p>
<p>
	I consider myself a rational man. While I may believe in an entirely deterministic model of the universe, I certainly
	do not believe it to be guided by any conscious process.
	I do not believe in destiny. This absence of guidance makes such fortuitous occurrences as the one I will discuss all
	the more extraordinary, and for this I am all the more grateful.
</p>

<h2>A Chance Collision</h2>
<p>
	By no deliberate design of my own, I happen to live close to a university. Not in the kind of ‘University town’ common
	to much of Europe or the United States, but in the densely packed suburban sprawl of the inner-city. My regular walk
	to and from the local shopping centre takes me past several of the buildings belonging to the highly regarded
	engineering faculty of the aforementioned University.
</p>
<p>
	Making my way home one serendipitous afternoon, I happened across a sizeable stack of books sitting on the curb
	outside one of the University’s engineering buildings. The university was ostensibly in the process of liquidating its stockpile
	of old engineering books, and had left them in a pile for the local council to collect. Amongst material covering a
	wide variety of academic disciplines, two books in particular caught my eye: <i>Building Parallel, Embedded, and
	Real-Time Applications with Ada</i>, and <i>Concurrent and Real-Time Programming in Ada</i>.
</p>
<p>
	I had heard of Ada before. I understood that it came from a pedigree of languages developed for the United States
	military, and that it still occupied a niche in the development of safety-critical applications, nothing more.
	Curious, I threw the books in my bag and off I went.
</p>


<h2>Exceeding My Expectations</h2>
<p>Admittedly, I had pictured Ada’s syntax resembling the uncompromising verbosity and rigid construction of COBOL, or
	perhaps the Lovecraftian hieroglyphics of Fortran’s various eldritch incarnations. Turning the pages, I was pleasantly
	surprised by modern constructs associated with modern high-level languages such as ranges, slicing and
	exception-handling. The syntax — Admittedly verbose by modern standards<sup><a href="#footnote_3">3</a></sup> — seemed deliberately and purposefully
	constructed to make the language comprehensible at a glance.</p>
<p>The fact that Ada was designed with embedded-software in mind was of particular interest to me. I already had some
	limited experience with bare-metal development on the x86 and ARM platforms using C and assembly, so the prospect of
	using higher-level constructs on bare-metal seemed promising to me.</p>

<h2>Not the Camel You Expected</h2>
<p>A common pejorative refrain directed at Ada by its many detractors is that it is a language “designed by committee”,
	or even worse, a language “designed by committee <i>for the military</i>”<sup><a href="#footnote_1">1</a></sup>. The implication of which being that (so-called)
	design by committee precludes it from any real-world practicality. I contend that it is better to design a language to fit an
	existing problem domain than to pick your weapon of choice and set out in search of new problem domains to apply it
	to<sup><a href="#footnote_2">2</a></sup>. I will spare readers a detailed retelling of Ada’s conception within the Department of Defence’s <a href="http://archive.adaic.com/pol-hist/history/holwg-93/holwg-93.htm">‘High Order
	Language Working Group’</a>, save to say that the Ada programming language was born of the need for single, unified
	higher-level language suitable for use in the multitude of Real-Time Embedded systems developed by the DoD<sup><a href="#footnote_4">4</a></sup>. In the
	wise words of the working-group’s chair, Colonel William A. Whitaker: “It was concluded that no existing language
	could be adopted as a single common high order language for the DoD, but that a single language meeting essentially
	all the requirements was both feasible and desirable.”. If such a thing was indeed feasible, the DoD’s deep pockets
	would help it bring it into existence. Ironically, given its status as the de-facto standard language of modern embedded-system development, the C language was considered unsuitable for this purpose: “When Bell Labs were
	invited to evaluate C against the DoD requirements, they said that there was no chance of C meeting the requirements
	of readability, safety, etc.” (Whitaker, 1993). After its successful implementation, in what would prove a controversial decision, the DoD would go so far as to mandate 
	the use of Ada for all in-house software engineering.</p>

<h2>So What Makes It Special?</h2>
<p>
	Ada has many useful features that are of particular interest for low-level programming and operating-system development. One
	feature in particular that impressed me greatly was Ada’s <i>representation clauses</i> (see below). They provide a highly granular way to define the
	in-memory representation of low-level data structures. I was very quickly able to adapt my own long suffering operating-system development project to Ada, improving the
	quality of my codebase greatly in the process. The following section details some of Ada’s features:
</p>

<h3>Custom Types</h3>
<p>
	In addition to being a strongly typed language, Ada allows for the definition of new scalar, enumerated and record types.
	Custom primitive types can also be constrained to a predefined range of values.
	The example below demonstrates the definition of a new integer type based upon Ada’s native <code>Natural</code> type, restricted
	to a predefined range.
	The use of the subtype directive informs the compiler that other variables of the <code>Natural</code> type are compatible with
	the newly defined subtype.
</p>

<div><pre><span></span><span>VGA_COL_COUNT</span> <span>:</span> <span>constant</span> <span>:=</span> <span>80</span><span>;</span>
<span>VGA_ROW_COUNT</span> <span>:</span> <span>constant</span> <span>:=</span> <span>24</span><span>;</span>

<span>subtype</span> <span>Col</span> <span>is</span> <span>Natural</span> <span>range</span> <span>0</span> <span>..</span> <span>VGA_COL_COUNT</span> <span>-</span> <span>1</span><span>;</span>
<span>subtype</span> <span>Row</span> <span>is</span> <span>Natural</span> <span>range</span> <span>0</span> <span>..</span> <span>VGA_ROW_COUNT</span> <span>-</span> <span>1</span><span>;</span>
</pre></div>

<p>
	The below example illustrates the creation of incompatible custom integer types. While their base type and range
	constraints are identical, Ada treats both as separate, incompatible types. An assignment of a variable of one type
	to the value of another is illegal, and will trigger a compile-time error.
</p>

<div><pre><span></span><span>type</span> <span>Integer_1</span> <span>is</span> <span>range</span> <span>1</span> <span>..</span> <span>10</span><span>;</span>
<span>type</span> <span>Integer_2</span> <span>is</span> <span>range</span> <span>1</span> <span>..</span> <span>10</span><span>;</span>
<span>A</span> <span>:</span> <span>Integer_1</span> <span>:=</span> <span>8</span><span>;</span>
<span>B</span> <span>:</span> <span>Integer_2</span> <span>:=</span> <span>A</span><span>;</span> <span>-- illegal!</span>
</pre></div>

<p>
	The following example demonstrates the creation of a custom enumerated type. It also demonstrates a subtype of an enumerated type with a constrained range of values.
</p>

<div><pre><span></span><span>type</span> <span>Day_Of_Week</span> <span>is</span> <span>(</span><span>Monday</span><span>,</span> <span>Tuesday</span><span>,</span>
  <span>Wednesday</span><span>,</span> <span>Thursday</span><span>,</span> <span>Friday</span><span>,</span> <span>Saturday</span><span>,</span> <span>Sunday</span><span>);</span>

<span>subtype</span> <span>Work_Day</span> <span>is</span> <span>Day_Of_Week</span> <span>range</span> <span>Monday</span> <span>..</span> <span>Friday</span><span>;</span>
</pre></div>


<p>
	A variable with the type of <code>Work_Day</code> is restricted to its constrained range. Any attempt to assign a value outside
	of this range to a variable of this type will raise a <code>Constraint_Error</code> exception at runtime.
</p>

<h2>Representation Clauses</h2>
<p>
	Ada allows for explicitly defining the in-memory representation of scalar and compound types. The following example
	demonstrates the definition of a record type (equivalent to structures in C), as well as its associated
	representation in memory.
</p>

<div><pre><span></span><span>----------------------------------------------------------------------------</span>
<span>--  The format of the System Table Descriptor pointer used by the processor</span>
<span>--  to load descriptor tables like the GDT and IDT.</span>
<span>----------------------------------------------------------------------------</span>
<span>type</span> <span>System_Table_Descriptor</span> <span>is</span>
   <span>record</span>
      <span>Size</span>   <span>:</span> <span>Unsigned_16</span><span>;</span>
      <span>Offset</span> <span>:</span> <span>System</span><span>.</span><span>Address</span><span>;</span>
   <span>end record</span>
<span>with</span> <span>Size</span> <span>=&gt;</span> <span>48</span><span>;</span>
<span>for</span> <span>System_Table_Descriptor</span> <span>use</span>
   <span>record</span>
      <span>Size</span>   <span>at</span> <span>0</span> <span>range</span> <span>0</span>  <span>..</span> <span>15</span><span>;</span>
      <span>Offset</span> <span>at</span> <span>0</span> <span>range</span> <span>16</span> <span>..</span> <span>47</span><span>;</span>
   <span>end</span> <span>record</span><span>;</span>
</pre></div>

<p>
	The <code>Size</code> aspect specifier instructs the compiler that the <code>System_Table_Descriptor</code> type must be 48 bits in size. The
	record representation clause instructs the compiler as to the required layout of this record type in memory. This
	example specifies that the <code>Size</code> member should occupy bits 0 to 15, and the <code>Offset</code> member should occupy bits 16 to
	47. This feature is analogous to C’s bit-fields. The following example demonstrates defining the in-memory
	representation of an enumerated type.
</p>

<div><pre><span></span><span>----------------------------------------------------------------------------</span>
<span>--  The privilege level for a particular descriptor.</span>
<span>--  These correspond to the 'protection ring' that this descriptor is</span>
<span>--  accessible from.</span>
<span>----------------------------------------------------------------------------</span>
<span>type</span> <span>Descriptor_Privilege_Level</span> <span>is</span> <span>(</span>
   <span>Ring_0</span><span>,</span>
   <span>Ring_1</span><span>,</span>
   <span>Ring_2</span><span>,</span>
   <span>Ring_3</span>
<span>)</span>
<span>with</span> <span>Size</span> <span>=&gt;</span> <span>2</span><span>;</span>
<span>for</span> <span>Descriptor_Privilege_Level</span> <span>use</span> <span>(</span>
   <span>Ring_0</span> <span>=&gt;</span> <span>0</span><span>,</span>
   <span>Ring_1</span> <span>=&gt;</span> <span>1</span><span>,</span>
   <span>Ring_2</span> <span>=&gt;</span> <span>2</span><span>,</span>
   <span>Ring_3</span> <span>=&gt;</span> <span>3</span>
<span>);</span>
</pre></div>


<p>
	The <code>Size</code> aspect specifier instructs the compiler that the <code>Descriptor_Privilege_Level</code> type must be 2 bits in size.
	The representation clause instructs the compiler as to required representation of each possible value of the
	enumerated type in memory. In this example the value of <code>Ring_0</code> will be represented by a value of <code>0x0</code> in memory, the
	value of <code>Ring_1</code> will be represented by <code>0x1</code>, and so on.
</p>

<h2 id="practical_example">A Practical Example</h2>

<p>
	The following example, and accompanying comparison with C, demonstrates the configuration of a hypothetical UART device by interfacing with an 8-bit memory-mapped configuration register. 
	This example has been adapted from a presentation by AdaCore viewable <a href="https://www.youtube.com/watch?v=qvmDqbuQe-M">here</a>.
</p>

<div><pre><span></span><span>with</span> <span>System.Storage_Elements</span><span>;</span> <span>use</span> <span>System.Storage_Elements</span><span>;</span>

<span>-------------------------------------------------------------------------------</span>
<span>--  Main</span>
<span>-------------------------------------------------------------------------------</span>
<span>procedure</span> <span>Main</span> <span>is</span>
   <span>----------------------------------------------------------------------------</span>
   <span>--  Baud rate type.</span>
   <span>----------------------------------------------------------------------------</span>
   <span>type</span> <span>Baud_Rate_T</span> <span>is</span> <span>(</span><span>b_9600</span><span>,</span> <span>b_14400</span><span>,</span> <span>b_115200</span><span>);</span></pre></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ajxs.me/blog/Giving_Ada_a_chance.html">https://ajxs.me/blog/Giving_Ada_a_chance.html</a></em></p>]]>
            </description>
            <link>https://ajxs.me/blog/Giving_Ada_a_chance.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302344</guid>
            <pubDate>Mon, 01 Mar 2021 13:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why northern Europe is so indebted]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26302336">thread link</a>) | @kome
<br/>
March 1, 2021 | https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/? | <a href="https://web.archive.org/web/*/https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="section-5-61"><div><div id="new_columns-6-61"><div id="div_block-7-61"><p><span id="span-26-61">
<p>You might think the US would be world champion of household debt, yet the highest private indebtment has always been in the Nordic countries. Debt, however, takes different forms, writes <strong>Martino Comelli</strong>. In Scandinavia, inclusive welfare systems make debt into an investment. Elsewhere, gerontocratic welfare and consumer credit can become a burden</p>
<h2>Debt and welfare: a trade-off?</h2>
<p>The economic crisis of 2007–2008 put household debt in the spotlight. <strong><a href="https://en.wikipedia.org/wiki/Financial_crisis_of_2007%E2%80%932008">A common narrative</a></strong> was that cheap credit fuelled a house price bubble in the US. The financial industry sold derivatives based on those debts and many European banks who bought those products went belly up, allowing the crisis to spread across the Atlantic.</p>
<p>Debt, and in particular, household debt, has been regarded with suspicion ever since. Many scholars argue that the rise of household debt was caused by welfare retrenchment, suggesting a trade-off between welfare and debt. A lack of welfare was compensated by private leveraging. Other scholars pointed out that many governments were pushing for asset-based welfare – like buying housing as a form of private welfare – encouraged by steadily rising house prices in the years preceding the crash.</p>
<figure><img loading="lazy" width="683" height="776" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1.png" alt="" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1.png 683w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure1-264x300.png 264w" sizes="(max-width: 683px) 100vw, 683px"><figcaption>Figure 1: Quantity of household debt in OECD countries</figcaption></figure>
<p>Yet empirical data suggests that the welfare-debt trade-off may be mistaken. Curiously, the highest indebtment ratio in the OECD was, and is, in northern European countries such as Denmark, Norway, Sweden and the Netherlands. These are the countries with the most far-reaching welfare programmes, and known to be fiscally responsible. Clearly, the welfare-debt trade-off theory needs a rethink.</p>
<h2>Private debt, public virtues: on the age-orientation of welfare</h2>
<p>Is it, then, a complementary relationship? Generous welfare provides security, encouraging people to borrow more. But this interpretation does not fly either. Many European countries have generous welfare – France for example, has higher social spending than Denmark – but nowhere near the level of household debt of the Nordic countries.</p>
<p><strong><a href="https://doi.org/10.1080/02732173.2021.1875088">My research on the relations between welfare and household debt</a> </strong>offers a novel explanation of the welfare-debt conundrum. There is no trade-off between private debt and welfare, nor is there a complementary relation. What matters is where the welfare money is spent and how. It isn’t necessarily about the quantity of spending, but about its direction.</p>
<blockquote><p>While mortgages are a marker of privilege, another common type of debt, consumer credit, is often a marker of need</p></blockquote>
<p>Most welfare spending is concentrated on older generations, particularly retired people. According to <strong><a href="https://en.wikipedia.org/wiki/Life-cycle_hypothesis">Franco Modigliani</a>'s life-cycle <a href="https://en.wikipedia.org/wiki/Life-cycle_hypothesis">hypothesis</a></strong>, debt is linked to one's stage in life. People take on debt when young because their income is low but their expenses (housing, children, leisure) high – and they pay this debt off as they age.</p>
<p>Countries that not only provide social help for the elderly, but counterbalance that with spending and services for the young and economically active, tend to have higher private debt (see Figure 2). In particular, countries that spend on education and active labour market policies, and those which offer better protection for people in precarious jobs, have the highest levels of private debt.</p>
<p>Household debt is an unintended consequence of assuring a smoother transition to adulthood. In conservative continental European countries, however, despite high welfare spending, welfare is concentrated mostly on the elderly and on people with stable jobs. This discourages younger generations from taking risks, including mortgage debt.</p>
<figure><img loading="lazy" width="980" height="714" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2.png" alt="Figure 2. Quantity of household debt by the age orientation of welfare spending in OECD countries" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2.png 980w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2-300x219.png 300w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure2-768x560.png 768w" sizes="(max-width: 980px) 100vw, 980px"><figcaption>Figure 2. Quantity of household debt by the age orientation of welfare spending in OECD countries.</figcaption></figure>
<p>Note: Figure 2 illustrates an inverse relationship between the elderly orientation of social spending (EBiSS, on the x axis), and the quantity of household debt as % of net disposable income (on the y axis). The EBiSS is a rate between social spending for the economically active (at the numerator) versus spending oriented toward the elderly (at the denominator). A higher value on the EBiSS index means that a greater share of social spending is going to the elderly.</p>
<h2>Consumer credit? The three worlds of debtfare capitalism</h2>
<p>Most of the debt in OECD countries is mortgage debt. While mortgages are a marker of privilege, another common type of debt, consumer credit, is often a marker of need.</p>
<p>If we consider consumer credit, the welfare-debt theory makes sense again. While consumer credit is more the exception than the norm in Europe, and almost absent in the Nordic countries, it is common in Anglo-liberal countries (UK, US and Canada) where it is used by families as a substitute for poor welfare provision.</p>
<figure><img loading="lazy" width="895" height="531" src="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3.png" alt="Figure 3. Clusters measures" srcset="https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3.png 895w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3-300x178.png 300w, https://theloop.ecpr.eu/wp-content/uploads/2021/02/figure3-768x456.png 768w" sizes="(max-width: 895px) 100vw, 895px"><figcaption>Figure 3. Clusters measures</figcaption></figure>
<p>Figure 3 shows three main patterns of private debt/welfare configurations; what we call debtfare:</p>
<ol>
<li>In the Nordic / youth-oriented model, household debt is high, consumer credit is low, and the rate of young people Not in Education, Employment, or Training (NEET) is very low.</li>
<li>
<p>In conservative European countries such as Germany and Italy, there are a lot of NEETs, welfare is orientated toward the elderly, and there is little household debt or consumer credit.</p>
</li>
<li>
<p>In Anglo-liberal countries such as the UK, US and Canada, consumer credit is high, and so is overall debt (though not as high as in the Nordic countries). The share of NEETs is remarkably high, and most welfare is oriented toward the elderly.</p>
</li>
</ol>
<p>Household financialisation, then, follows different paths and patterns. Both liberal and conservative welfare is gerontocratic, and they have a high level of NEETs, but while the former is oriented toward a market solution to inequality (more debt), the latter discourages any form of risk taking.</p>
<p>So, while paying attention to debt is important, it shouldn’t be the only lesson of the 2008 crisis. Further attention should be paid to the macro-sociological conditions that give debt different meanings: inclusive welfare can make debt into an investment, but gerontocratic welfare can make debt a burden.</p>
</span></p><p>This article presents the views of the author(s) and not necessarily those of the ECPR or the Editors of <i>The Loop</i>.</p><div id="div_block-246-61"><p><img id="image-247-61" alt="" src="https://theloop.ecpr.eu/wp-content/uploads/2020/09/ECPR-tag-icon.svg" loading="lazy"></p></div></div></div></div></section></div>]]>
            </description>
            <link>https://theloop.ecpr.eu/why-northern-europe-is-so-indebted/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302336</guid>
            <pubDate>Mon, 01 Mar 2021 12:59:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolidRun 1U 2 node Arm Server]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26302237">thread link</a>) | @cameron_b
<br/>
March 1, 2021 | https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg" data-caption="SolidRun Honeycomb LX2 Server"><img width="696" height="448" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-652x420.jpg 652w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="SolidRun Honeycomb LX2 Server" title="SolidRun Honeycomb LX2 Server"></a><figcaption>SolidRun Honeycomb LX2 Server</figcaption></figure></div>
            <!-- content --><p>SolidRun has a new development in their NXP Layerscape LX2160A based systems this week. The new SolidRun HoneyComb LX2 Server packages two of their familiar HoneyComb LX2K boards into a single chassis. This includes a power supply and accommodations for 2.5″ or 3.5″ SATA storage. While the board at the core of this system is not a new part this does mark a milestone for deploy-ability of Arm systems at a tier that does not have a lot of other attention.<span id="more-51095"></span></p>
<h2>SolidRun HoneyComb LX2 Server Background</h2>
<p>To take a step back and look at where this system lands, the Arm ecosystem currently has a lot of activity at the top and bottom of the price and performance spectrum, with not a lot of options in the middle. That is where SolidRun’s new dual-node server aims to compete.</p>
<figure id="attachment_51102" aria-describedby="caption-attachment-51102"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-server-front/" rel="attachment wp-att-51102"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front.jpg" alt="SolidRun Honeycomb LX2 Server Front" width="1110" height="722" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front.jpg 1110w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-400x260.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-800x520.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-696x453.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-1068x695.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-Front-646x420.jpg 646w" sizes="(max-width: 1110px) 100vw, 1110px"></a><figcaption id="caption-attachment-51102">SolidRun HoneyComb LX2 Server Front</figcaption></figure>
<p>Raspberry Pi systems between $5 and $100 have shipped over 30 million units. Developer kits such as these have earned a level of ubiquity in learning and DIY spaces for making it really easy to try out new concepts in programming or “physical computing.” While the Raspberry Pi Foundation has demonstrated using the Raspberry Pi 4 in production, including running Raspberry Pi 4s to serve their website for the launch of the Pi 4, that is not quite what they are designed for. In that example, the Foundation included their own hardware between more performant load balancers and database machines as a demonstration of their very capable new devices, not quite as a shot across the bow to the Xeons they may have replaced.</p>
<figure id="attachment_49430" aria-describedby="caption-attachment-49430"><a href="https://www.servethehome.com/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-review/myelectronics-nl-apple-mac-mini-and-raspberry-pi-rack-4/" rel="attachment wp-att-49430"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4.jpg" alt="MyElectronics.nl Apple Mac Mini And Raspberry Pi Rack 4" width="800" height="534" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/MyElectronics.nl-Apple-Mac-Mini-and-Raspberry-Pi-Rack-4-629x420.jpg 629w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-49430">MyElectronics.nl Apple Mac Mini And Raspberry Pi Rack</figcaption></figure>
<p>On the other end of the spectrum, several orders of magnitude away, Ampere Altra is making a case for permanently replacing some of those Xeons for certain customers. Ampere’s price-to-performance numbers are impressive, as are figures like 160 cores for a 2 socket server and 128 lanes of PCIe Gen4 per socket. This underscores that this is a platform designed for cloud providers and hyperscalers. You can check out STH’s <a href="https://www.servethehome.com/ampere-altra-wiwynn-mt-jade-server-review-the-most-significant-arm-server/">Ampere Altra Wiwynn Mt. Jade Server Review</a> to learn more.</p>
<figure id="attachment_49505" aria-describedby="caption-attachment-49505"><a href="https://www.servethehome.com/ampere-altra-wiwynn-mt-jade-server-review-the-most-significant-arm-server/amd-epyc-ampere-altra-intel-xeon-cascade-lake-small-2/" rel="attachment wp-att-49505"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1.jpg" alt="AMD EPYC Ampere Altra Intel Xeon Cascade Lake Small" width="800" height="487" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-400x244.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-696x424.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/AMD-EPYC-Ampere-Altra-Intel-Xeon-Cascade-Lake-Small-1-690x420.jpg 690w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-49505">AMD EPYC Ampere Altra Intel Xeon Cascade Lake Small</figcaption></figure>
<p>There is enough intrigue over the top-of-line Arm servers that developers wonder if there is not a better workstation-level/ or entry/mid-range server system. A prospective Arm developer would want something between $100 for a dev board and $4000 per socket for a screaming 2U. (Apologies to the $800 32-core 1.7GHz SKU at the other end of the Ampere Altra line.)</p>
<p>SolidRun has been positioning itself in this space for several years. Its LX2 products continue in active development. HoneyComb’s maturity dovetails with the work SolidRun has been doing on two fronts. It is servicing its niche and driving specific development (for example their high bandwidth networking) but return their development work to benefit the ease of adoption from mainline Linux.</p>
<figure id="attachment_51103" aria-describedby="caption-attachment-51103"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-board-with-annotations/" rel="attachment wp-att-51103"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations.jpg" alt="SolidRun HoneyComb LX2 Board With Annotations" width="1030" height="789" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations.jpg 1030w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-392x300.jpg 392w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-800x613.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-696x533.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-548x420.jpg 548w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-HoneyComb-LX2-Board-with-Annotations-80x60.jpg 80w" sizes="(max-width: 1030px) 100vw, 1030px"></a><figcaption id="caption-attachment-51103">SolidRun HoneyComb LX2 Board With Annotations</figcaption></figure>
<p>The HoneyComb LX2K is a COM Express Type 7 carrier for an NXP Layerscape LX2160A System-on-Chip with 16x Arm A72 cores running up to 2GHz. The COM Express Type 7 module has dual-channel DDR4 in SODIMMs for up to 64GB total. The carrier board exposes 4x SATA, one M.2 and one Micro SD slot for storage, four SFP+ (directly from the SoC) and one RJ45 at 1Gb for networking, dual USB 3.0 ports, and an open-ended PCIe x8 slot on a standard mini ITX form factor using standard ATX power. There is even the ATX standard power indicator and reset button header. The goal seems to be to create a platform that is easy to integrate into existing chassis and systems.</p>
<figure id="attachment_51101" aria-describedby="caption-attachment-51101"><a href="https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/solidrun-honeycomb-lx2-server/" rel="attachment wp-att-51101"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg" alt="SolidRun Honeycomb LX2 Server" width="800" height="515" srcset="https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-400x258.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-696x448.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/02/SolidRun-Honeycomb-LX2-Server-652x420.jpg 652w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-51101">SolidRun HoneyComb LX2 Server</figcaption></figure>
<p>In the context of running highly deployable servers to replace Xeons, this may not be quite the same level of hardware maturity. On the other hand, having a dual-node 1U platform that one can deploy in racks and do Arm development is a big step forward. Not only do we get a bigger CPU, but we also get the ability to use a lot of standard components which will help boost the ecosystem as well. Adding a chassis with cooling and power may not seem like a big deal, but there is a large segment of the market that does not want to search for or cobble together these solutions. Instead, if the nodes are already in a 1U chassis, that lowers the friction and barriers to entry for development. This is still not a $400-500 PC or Atom server. Still, it is an important step in the right direction.</p>
<h2>Final Words</h2>
<p>SolidRun’s HoneyComb LX2K is a platform that is accessible and capable for development on 64-bit Arm architecture as a workstation. It is also becoming more deployment-ready for appliance-type power-conscious edge applications with the 1U chassis. Developers interested in using the HoneyComb board in production have faced the challenge of trying to rack-mount an ITX board. Bamboo Systems in the UK have an answer for developers ready to deploy an 8-node 1U, but that raises the bar back up the scale of Ampere Altra. The challenge with small server nodes is that as one scales, it tends to be more efficient having larger nodes. AWS Gravition2 is an important product for the industry, but it is also tied to the AWS ecosystem. The new availability to deploy two nodes in 1U targets the intersection of accessibility and capability for those interested to kick the tires on Arm in the wild.</p>
<p>We look forward to getting our hands on the dual sled system and doing an in-depth review. We will also pair that with approaching the HoneyComb Board as a workstation for daily-driver use. Leave a comment if you would like to see specific applications explored for either system.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/solidrun-honeycomb-lx2-server-announced-1u-2-node-arm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302237</guid>
            <pubDate>Mon, 01 Mar 2021 12:46:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles of DataOps]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26302065">thread link</a>) | @xoelop
<br/>
March 1, 2021 | https://blog.tinybird.co/2021/02/27/dataops-principles/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/02/27/dataops-principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>These are 10 of the principles of <a href="https://blog.tinybird.co/2021/02/27/dataops/">DataOps</a> that we make available to data teams.</p> <p>While we always challenge our assumptions, this new paradigm guides the way we are building Tinybird, deeply focused on simplicity, speed and developer experience.</p> <h3 id="1-the-data-project"> 1. The Data Project <a href="#1-the-data-project">¶</a> </h3> <p>This is like your framework (<em>think of MVC for web development</em>). It describes how your data should be stored, processed, and exposed through APIs.</p> <p>You put there your <a href="https://docs.tinybird.co/cli.html#data-projects-title">know-how</a>, abstractions and the focus on the problem you are solving.</p> <h3 id="2-serialization"> 2. Serialization <a href="#2-serialization">¶</a> </h3> <p>All your table schemas, transformations and endpoints need to be serializable. Keep <a href="https://docs.tinybird.co/cli.html#datafile-reference-title">the format</a> simple for humans to read and write. If possible, map every resource to a text file.</p> <h3 id="3-version-control"> 3. Version Control <a href="#3-version-control">¶</a> </h3> <p>This is a consequence of having a data project and a file format. Treat your data project as regular source code, and <a href="https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/">push it to a source version control system</a> (e.g. git)</p> <p>From there you get traceability over changes, collaboration, peer reviews, automations and the very same workflow and best practices you are used to as a development team.</p> <h3 id="4-continuous-integration-and-deployment"> 4. Continuous Integration and Deployment <a href="#4-continuous-integration-and-deployment">¶</a> </h3> <p>The key for most of the things developers do is speed. Innovation is iteration and if you are fast you can learn faster and iterate faster.</p> <p>This means making an assumption, running an experiment, learn and repeat, ensuring quality.</p> <p>Your system should allow you to easily create testing environments and use fixtures, so you can build, test and measure your data pipelines and endpoints on every change.</p> <h3 id="5-lead-time"> 5. Lead Time <a href="#5-lead-time">¶</a> </h3> <ul> <li>Deploying to production should be seconds (<em>not minutes or hours</em>)</li> <li>Fixing a bug should be minutes (<em>not hours or days</em>)</li> <li>Developing a new feature should be hours (<em>not days or weeks</em>)</li> </ul> <h3 id="6-data-quality-assurance"> 6. Data Quality Assurance <a href="#6-data-quality-assurance">¶</a> </h3> <p>So you are a data engineer working for a Fortune 500 company, are you confident enough (<em>or even allowed</em>) to make a change in any of your data pipelines and push it to production right away in a matter of minutes?</p> <p>How do you ensure data quality in your data product?</p> <p><strong><a href="https://guides.tinybird.co/guide/implementing-test-strategies">Data needs tests</a>, even more than code.</strong></p> <h3 id="7-tools"> 7. Tools <a href="#7-tools">¶</a> </h3> <p>Pick tools based on your goals, but as a starting point, your tools should make it easy for your team to access, share, and analyze data.</p> <p>You should be able to <a href="https://docs.tinybird.co/cli.html">work from your terminal</a> or IDE without leaving your data project context.</p> <p>Avoid steep learning curves, use a familiar syntax, short and clear so you can run and automate stuff quickly.</p> <p>When it comes to data exploration and problem-solution discovery, you need instant feedback.</p> <h3 id="8-observability"> 8. Observability <a href="#8-observability">¶</a> </h3> <p>You need to run and understand <a href="https://docs.tinybird.co/api-reference/service-datasources.html">your data in production</a> and quickly learn if it’s solving your business problems.</p> <p>Automate <a href="https://guides.tinybird.co/guide/on-the-fly-health-checks">health checks</a>, monitor performance, allow runtime traceability and implement an alerting system.</p> <h3 id="9-recipes-and-building-blocks"> 9. Recipes and building blocks <a href="#9-recipes-and-building-blocks">¶</a> </h3> <p>The data development experience should be as close as the experience you actually have working with some library that you will import and use in any language.</p> <p>Your analysis should be idempotent, composable and immutable. Wrap them and make them reusable right away.</p> <p>Wrap your analyses into <a href="https://github.com/tinybirdco/log_parsing_template">reusable data projects</a>.</p> <h3 id="10-fine-tuning"> 10. Fine Tuning <a href="#10-fine-tuning">¶</a> </h3> <p>Query optimization is a never ending process. You should monitor queries and transformations to build a system that helps <a href="https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/">fine tuning your data products</a>.</p> <h3 id="bonus-track-publication-and-documentation"> Bonus track: publication and documentation <a href="#bonus-track-publication-and-documentation">¶</a> </h3> <p><strong>Data and development teams work together</strong>. Your data are exposed as <a href="https://blog.tinybird.co/2020/08/11/badass-api-endpoint/">auto-documented APIs</a>, so it can be integrated anywhere.</p> <p>Don’t forget about not so cool tools such as <a href="https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/#visualizing-the-correlation-matrix-in-google-sheets">spreadsheets</a> and traditional BI.</p> <p><strong><em>What are your main challenges when dealing with large quantities of data?</em></strong> <a href="https://www.tinybird.co/survey">Tell us about them</a> and get started solving them with Tinybird right away.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/02/27/dataops-principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302065</guid>
            <pubDate>Mon, 01 Mar 2021 12:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding superhuman XSS polyglot payloads with Genetic Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26302016">thread link</a>) | @alaeddine
<br/>
March 1, 2021 | https://blog.ostorlab.co/polyglot-xss.html | <a href="https://web.archive.org/web/*/https://blog.ostorlab.co/polyglot-xss.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Abstract</h2>
<p>The following article is a technical deep dive into how genetic algorithms can be leveraged to create superhuman XSS
polyglot payloads. </p>
<p>We start by highlighting the importance of detecting XSS vulnerabilities, the challenges
faced by automated solutions to fully test real-life applications in a reasonable time, and then we goe into a
technical deep dive on the use of genetic algorithms to create polyglot payloads. </p>
<p>The final part of the article shows examples of the generated payloads and discusses areas for future improvements.</p>
<h2>Cross-site scripting (XSS)</h2>
<p>Cross-site scripting (XSS) is a vulnerability class that affects Web Applications. It concerns also Mobile Applications built
using javascript multi-platform Frameworks, like Cordova or Ionic and browser embedded applications.</p>
<p><img alt="H1" src="https://blog.ostorlab.co/static/img/polyglot_xss/image2.png" title="Hacker One Stats"></p>
<p>According to Hacker One’s "Trends and Security report", XSS is the most reported vulnerability. It has also been
listed in the OWASP Top 10 Security Risk since its start in 2003.</p>
<p><img alt="OWSP" src="https://blog.ostorlab.co/static/img/polyglot_xss/image6.png" title="OWASP Top 10"></p>
<p>Besides the widespread of XSS vulnerabilities, their impact can have severe consequences. For instance, an XSS in Cloud
Console, like AWS can lead to remote code execution in an EC2 instance. An XSS on Google Playstore can lead to malicious
application installation on the targetted user’s mobile device.</p>
<p>XSS has also been used by state-sponsored attackers and criminal organizations to track dissidents and whistleblowers’
locations or to unmask their real identities.</p>
<p>Sources: </p>
<ul>
<li><a href="https://www.csoonline.com/article/3329296/twitter-bug-may-have-been-exploited-by-state-sponsored-hackers.html">Twitter XSS exploited by state-sponsored attackers</a></li>
<li><a href="https://portswigger.net/daily-swig/google-deprecates-xss-auditor-for-chrome">XSS Auditor deprecation</a></li>
</ul>
<p>At the same time, exploitation of XSS is hard to detect. Protection solutions like WAF or RASP are ineffective, to the
point where Chrome XSS Auditor was eventually deprecated because of the prevalence of known bypasses.</p>
<ul>
<li><a href="https://groups.google.com/a/chromium.org/g/blink-dev/c/TuYw-EZhO9g/m/blGViehIAwAJ?pli=1">XSS Auditor Bypasses</a></li>
</ul>
<p>XSS are not only common, but its impact can be devastating and real-life exploitation is hard to detect.</p>
<h2>Spotting XSS</h2>
<p>XSS happens in different forms and shapes. There are reflected XSS, persistent, DOM-based, postMessage-based.</p>
<p>The input of an XSS can come from the path, the parameters, the URL fragment, the cookie, the referrer. It can be
injected from a parent frame or from a child iframe.</p>
<p>Static approaches to detect XSS vulnerabilities are rarely effective due to the highly dynamic nature of the Javascript
language. This fact is exacerbated by Javascript transpiler, minifier, and uglifier that leverage the dynamic nature of
the language for performance and obfuscation reasons.</p>
<p><img alt="JS" src="https://blog.ostorlab.co/static/img/polyglot_xss/image1.png" title="Minified JS"></p>
<p>The most effective way to identify XSS vulnerabilities is using dynamic analysis, which can be further enhanced by different
forms of execution tracing, like trusted-types taint tracing, function hooking, or low-level chrome String tracing.</p>
<p>Detecting XSS with dynamic analysis is simple. It consists of injecting a working payload that would trigger a
callback indicating the success of the injection.</p>
<h2>Dynamic Detection</h2>
<p>Ostorlab’s implementation relies on Chrome to render and test the XSS. Using a full-blown browser allows out-of-the-box
support of the javascript heavy application, like SPA built using frameworks like React, Angular, or Vue.js.</p>
<p>Chrome is started in headless mode with a long list of flags for performance optimization, like disabling certain
human-friendly features, as well as disabling certain security features that could affect the result of the analysis.</p>
<p>Below an example of some of the flags passed to chrome:</p>
<div><pre><span></span><code><span>'--no-default-browser-check'</span><span>,</span>
<span>'--no-first-run'</span><span>,</span>
<span>'--disable-client-side-phishing-detection'</span><span>,</span>
<span>'--disable-component-extensions-with-background-pages'</span><span>,</span>
<span>'--disable-default-apps'</span><span>,</span>
<span>'--disable-extensions'</span><span>,</span>
<span>'--mute-audio'</span><span>,</span>
<span>'--disable-background-timer-throttling'</span><span>,</span>
<span>'--disable-backgrounding-occluded-windows'</span><span>,</span>
<span>'--disable-features=ScriptStreaming'</span><span>,</span>
<span>'--disable-hang-monitor'</span><span>,</span>
<span>'--disable-ipc-flooding-protection'</span><span>,</span>
<span>'--disable-notifications'</span><span>,</span>
<span>'--disable-popup-blocking'</span><span>,</span>
<span>'--disable-prompt-on-repost'</span><span>,</span>
<span>'--disable-renderer-backgrounding'</span><span>,</span>
<span>'--js-flags=--random-seed=XXXXX,</span>
<span>'--use-gl=swiftshader'</span><span>,</span>
<span>'--disable-background-networking'</span><span>,</span>
<span>'--disable-breakpad'</span><span>,</span>
<span>'--disable-component-update'</span><span>,</span>
<span>'--disable-domain-reliability'</span><span>,</span>
<span>'--disable-sync'</span><span>,</span>
<span>'--metrics-recording-only'</span>
</code></pre></div>
<p>Once chrome is running, many test sessions start simultaneously injecting each target input with a payload.</p>
<p>A payload takes a form similar to <code>&lt;svg onload={callback}&gt;</code>.</p>
<p>The callback can have multiple implementations, it can be a Javascript function that can send a request to the server, 
it can be an alert box or console message.</p>
<p>Ostorlab implementation relies on console events to notify of the presence of an XSS. Other approaches have shown
quirks when overloading the callback with any javascript logic, which can lead the code to be hoisted, added to the
bottom of the javascript queue.</p>
<p>The queue is generally overloaded with events caused by the XSS fuzzer and can cause the XSS to be missed if the page
is exited before fully clearing the queue.</p>
<p>Console messages are sent directly by Chrome and can be intercepted using the Chrome Debug protocol.</p>
<ul>
<li><a href="https://chromedevtools.github.io/devtools-protocol/tot/Console/">Chrome Debug Protocol: Console</a></li>
</ul>
<p>The console has however been deprecated in favor of a more powerful replacement, that provides a long-awaited
functionality, stack tracing: </p>
<ul>
<li><a href="https://chromedevtools.github.io/devtools-protocol/tot/Log/">Chrome Debug Protocol: Log</a></li>
</ul>
<h2>The Million Payload Dilemma</h2>
<p>The Achilles heel of XSS dynamic testing the million payload dilemma.</p>
<p>XSS also happens in different contexts on the client-side, it can happen in an <code>a</code> tag, a <code>div</code> tag, in an attribute,
in its content. It can have a size limitation, a character limitation, or it can be caused by injecting a specialized JSON
object and can come from different input sources.
Example of contexts:</p>
<div><pre><span></span><code><span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/html_element"</span><span>)</span>
<span>def</span> <span>test_bed_html_element</span><span>():</span>
   <span>return</span> <span>'''&lt;div&gt;</span><span>{inject}</span><span>&lt;/div&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/js_html_element"</span><span>)</span>
<span>def</span> <span>test_bed_js_html_element</span><span>():</span>
   <span>return</span> <span>'''</span>
<span>       &lt;div id='elmtId'&gt;&lt;/div&gt;</span>
<span>       &lt;script&gt;</span>
<span>       window.onload = () =&gt; {{</span>
<span>           const payload = decodeURIComponent(window.location.hash.substr(1));</span>
<span>           document.getElementById('elmtId').innerHTML = payload;</span>
<span>       }}</span>
<span>       &lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/html_attribute_value_double_quoted"</span><span>)</span>
<span>def</span> <span>test_bed_html_attribute_value_double_quoted</span><span>():</span>
   <span>return</span> <span>'''&lt;div class="</span><span>{inject}</span><span>"&gt;content&lt;/div&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/html_attribute_value_single_quoted"</span><span>)</span>
<span>def</span> <span>test_bed_html_attribute_value_single_quoted</span><span>():</span>
   <span>return</span> <span>'''&lt;div class='</span><span>{inject}</span><span>'&gt;content&lt;/div&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed//html_attribute_value_not_quoted"</span><span>)</span>
<span>def</span> <span>test_bed_html_attribute_value_not_quoted</span><span>():</span>
   <span>return</span> <span>'''&lt;div class=</span><span>{inject}</span><span>&gt;content&lt;/div&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/html_attribute_name"</span><span>)</span>
<span>def</span> <span>test_bed_html_attribute_name</span><span>():</span>
   <span>return</span> <span>'''&lt;div </span><span>{inject}</span><span>='class'&gt;content&lt;/div&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/script_element"</span><span>)</span>
<span>def</span> <span>test_bed_script_element</span><span>():</span>
   <span>return</span> <span>'''&lt;script&gt;</span><span>{inject}</span><span>&lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/js_script_element"</span><span>)</span>
<span>def</span> <span>test_bed_js_script_element</span><span>():</span>
   <span>return</span> <span>'''</span>
<span>       &lt;script id='elmtId'&gt;&lt;/script&gt;</span>
<span>       &lt;script&gt;</span>
<span>       const payload = decodeURIComponent(window.location.hash.substr(1));</span>
<span>       document.getElementById('elmtId').innerHTML = payload;</span>
<span>       &lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/script_element"</span><span>)</span>
<span>def</span> <span>test_bed_script_element</span><span>():</span>
   <span>return</span> <span>'''&lt;script&gt;</span><span>{inject}</span><span>&lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/js_script_element"</span><span>)</span>
<span>def</span> <span>test_bed_js_script_element</span><span>():</span>
   <span>return</span> <span>'''</span>
<span>       &lt;script id='elmtId'&gt;&lt;/script&gt;</span>
<span>       &lt;script&gt;</span>
<span>       const payload = decodeURIComponent(window.location.hash.substr(1));</span>
<span>       document.getElementById('elmtId').innerHTML = payload;</span>
<span>       &lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/script_double_quoted"</span><span>)</span>
<span>def</span> <span>test_bed_script_double_quoted</span><span>():</span>
   <span>return</span> <span>'''&lt;script&gt;var hello="</span><span>{inject}</span><span>";&lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/script_single_quoted"</span><span>)</span>
<span>def</span> <span>test_bed_script_single_quoted</span><span>():</span>
   <span>return</span> <span>'''&lt;script&gt;var hello='</span><span>{inject}</span><span>';&lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/iframe_src"</span><span>)</span>
<span>def</span> <span>test_bed_iframe_src</span><span>():</span>
   <span>return</span> <span>'''&lt;iframe src="</span><span>{inject}</span><span>"&gt;&lt;/iframe&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/js_iframe_src"</span><span>)</span>
<span>def</span> <span>test_bed_js_iframe_src</span><span>():</span>
   <span>return</span> <span>'''</span>
<span>       &lt;iframe id='elmtId'&gt;&lt;/iframe&gt;</span>
<span>       &lt;script&gt;</span>
<span>       const payload = decodeURIComponent(window.location.hash.substr(1));</span>
<span>       document.getElementById('elmtId').setAttribute('src', payload);</span>
<span>       &lt;/script&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/html_comment"</span><span>)</span>
<span>def</span> <span>test_bed_html_comment</span><span>():</span>
   <span>return</span> <span>'''&lt;!-- </span><span>{inject}</span><span> --&gt;'''</span>

<span>@app</span><span>.</span><span>route</span><span>(</span><span>"/test_bed/textarea_element"</span><span>)</span>
<span>def</span> <span>test_bed_textarea_element</span><span>():</span>
   <span>return</span> <span>'''&lt;textarea&gt;</span><span>{inject}</span><span>&lt;/textarea&gt;'''</span>
</code></pre></div>
<p>Let’s do some basic math to understand the scope of the problem.</p>
<p>Let’s imagine we would like to test 30 injection contexts (Ostorlab’s testbed has over 50 injection contexts and we
keep adding new ones) and we would on average test for 20 injection points:</p>
<ul>
<li>Path <code>/{here}/{here2}/{here3}</code></li>
<li>URL Argument <code>/a/b/c?q={here}&amp;{here}=test</code></li>
<li>Fragment <code>a/b/c#{here}</code></li>
<li>Cookies <code>Cookile: {here}={here}</code></li>
<li>Headers <code>{here}: {here}\r\n</code></li>
<li>Body parameters <code>{here}={here}&amp;{here}={here}</code></li>
<li>Referer <code>Referer: {here}</code></li>
<li>Iframe parent injection</li>
</ul>
<p>And we would like to test every page, a web application like Uber, unauthenticated parts only has over 120k page, the
institutional web site of a bank like ING has over 7k pages.</p>
<p>The test with high performances parallel VM would be:</p>
<ul>
<li>30 payloads</li>
<li>20 injection points</li>
<li>20 seconds per test between loading, execution, click event triggering, and callback execution</li>
<li>100 parallel instances</li>
</ul>
<p>Uber test would take 72M payload and 166 days to complete, ING would require 4.2 M requests would take 9 days to
complete.</p>
<p><img alt="req" src="https://blog.ostorlab.co/static/img/polyglot_xss/image4.jpg" title="Request"></p>
<p>Testing every page, in every input, for every vulnerability, covering every context, needs millions of requests, which
requires days, if not weeks to complete.</p>
<h2>Polyglot Payloads</h2>
<p>In order to lower the number of requests needed to fully test an application, combining multiple injection contexts
with a single payload is a very beneficial optimization.</p>
<p>For instance, replacing 30 contexts with a single payload will allow us to go from 166 days of testing to 5 days for
Uber and from 9 days of testing to 7 hours.</p>
<p>The polyglot payload is a known topic among security tester, with even …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ostorlab.co/polyglot-xss.html">https://blog.ostorlab.co/polyglot-xss.html</a></em></p>]]>
            </description>
            <link>https://blog.ostorlab.co/polyglot-xss.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26302016</guid>
            <pubDate>Mon, 01 Mar 2021 12:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Translate’s Exclusion of Indigenous Languages a ‘Squandered’ Opportunity]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26301981">thread link</a>) | @johncena33
<br/>
March 1, 2021 | https://www.huffingtonpost.ca/entry/google-translate-cree-indigenous-language_ca_6035242ac5b67c329620c3e3 | <a href="https://web.archive.org/web/*/https://www.huffingtonpost.ca/entry/google-translate-cree-indigenous-language_ca_6035242ac5b67c329620c3e3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-part="contents">
            <!-- ads_sharebox_260x60 -->
    

        <div><div><p><span>A petition requesting </span><a href="https://www.huffingtonpost.ca/news/google/"><span>Google</span></a><span> add one of Canada’s most common Indigenous languages to its Translate app is gaining traction.&nbsp;</span></p><p><a href="https://www.change.org/p/google-inc-first-nations-languages?recruiter=529834880&amp;recruited_by_id=188a0770-069d-11e6-ba01-81c15d923dbd&amp;utm_source=share_petition&amp;utm_medium=copylink&amp;utm_campaign=petition_dashboard" target="_blank"><span>The petition</span></a><span> had more than 1,600 signatures as of Tuesday.</span></p><p><span>Montreal publisher Joseph John is behind the petition. He tried to use Google’s app to translate his </span><a href="https://www.citizen-canada.ca/" target="_blank"><span>comic book</span></a><span> about an Indigenous superhero into Cree, when he realized it wasn’t an option. He said that’s unacceptable.&nbsp;</span></p>        <!-- entry_paragraph_1_ad -->
    
<p><span>“Google’s exclusion of the most widely spoken First Nations language, Cree, as well as other First Nations languages, from its Google Translate app hurts,” said John in his petition.</span></p><p><span>“Google has squandered a great opportunity to popularize this pristine language with millions of its users.”&nbsp;</span></p><p><span>Cree is one of the most common Indigenous languages spoken in Canada. More than 96,000 people reported speaking it in the 2016 census.&nbsp;</span></p></div><figure>
        </figure><div><p><span>Cree and other </span><a href="https://www.huffingtonpost.ca/2018/06/21/indigenous-languages_a_23465069/"><span>Indigenous languages are declining</span></a><span> in use. In 2016, only 16 per cent of Indigenous people were able to speak an Indigenous language compared to 29 per cent 20 years before, </span><a href="https://www150.statcan.gc.ca/n1/pub/75-006-x/2018001/article/54981-eng.htm" target="_blank"><span>reported Statistics Canada</span></a><span>.&nbsp;</span></p><p><span>Colonialism, residential schools and forced assimilation played </span><a href="https://www.huffingtonpost.ca/2017/05/10/indigenous-language-odawa-ottawa_n_16370410.html"><span>a significant role </span></a><span>in the decline of Indigenous languages. Young Indigenous students weren’t allowed to speak them and were severely punished for doing so. Indigenous parents stopped passing down their mother tongue to protect their children from abuse.&nbsp;</span></p><p><span>John, who immigrated to Canada from India in 2007, said the petition and comic book “Citizen Canada” are about raising awareness about Indigenous cultures.</span></p><p><span>Google Canada said it is gradually adding languages to Translate, which needs millions of examples to learn from.&nbsp;</span></p><p><span>“Unfortunately we don’t have a timeline for that specific language, the process of adding&nbsp; language to Translate takes a big concerted effort from contributors,” said spokesperson Luiza Staniec.&nbsp;</span></p><p>&nbsp;<em><strong>Watch: First Nations Girl kicks starts ribbon skirt movement.</strong></em></p></div><div><p><span>In recent years, there’s been a push to encourage and celebrate Indigenous languages. </span><a href="https://www.huffingtonpost.ca/2019/05/02/nova-scotia-student-blackbird-mikmaq_a_23720775/"><span>A video</span></a><span> of student Emma Stevens singing the Beatles “Blackbird” in Mi’kmaq went viral. MPs have access </span><a href="https://www.huffingtonpost.ca/2018/11/30/indigenous-languages-house-of-commons_a_23605664/"><span>to translators</span></a><span> if they wish to speak an Indigenous language, including Cree, in the House of Commons. A federal court released its </span><a href="https://www.huffingtonpost.ca/entry/federal-court-canada-indigenous-cree-dene-language_ca_5ceeefabe4b07e067d8872e8"><span>first ruling</span></a><span> in Cree and Dene in 2019.&nbsp;</span></p><p><span>Adding Cree to Google Translate should be common sense, said John. The app already includes the Indigenous Polynesian language Maori, which about </span><a href="https://socialreport.msd.govt.nz/cultural-identity/maori-language-speakers.html" target="_blank"><span>50,000 people speak</span></a><span>, and is also an official language of New Zealand.&nbsp;</span></p><p><span>“If Google could find the resources for including Maori on its app, there is no reason to believe that it will have any difficulty in including Canada’s most widely spoken language,” John said.</span></p><p><span>Google has worked with First Nations on promoting awareness about their languages.</span></p><p><span>Google Earth and University of Victoria researchers created a tool that allows users to hear greetings and traditional songs in 55 Indigenous languages from around the world, including Hul’q’umi’num, spoken by First Nations on Vancouver Island.&nbsp;</span></p><p><span>Google also has developed </span><a href="https://blog.google/outreach-initiatives/accessibility/preserving-endangered-languages-noto-fonts/" target="_blank"><span>the Nato font family</span></a><span> to provide the needed symbols to type or text in many endangered Indigenous languages, including Cree. </span></p></div>                
                                
                <!-- start relEntries --><!-- end relEntries --><section></section>
</div>

        

                
        
    </div></div>]]>
            </description>
            <link>https://www.huffingtonpost.ca/entry/google-translate-cree-indigenous-language_ca_6035242ac5b67c329620c3e3</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301981</guid>
            <pubDate>Mon, 01 Mar 2021 12:10:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Go with Tests – Intro to Generics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26301964">thread link</a>) | @quii
<br/>
March 1, 2021 | https://quii.gitbook.io/learn-go-with-tests/meta/intro-to-generics | <a href="https://web.archive.org/web/*/https://quii.gitbook.io/learn-go-with-tests/meta/intro-to-generics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://quii.gitbook.io/learn-go-with-tests/meta/intro-to-generics</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301964</guid>
            <pubDate>Mon, 01 Mar 2021 12:09:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts Around Naming Variables]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26301622">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1 | <a href="https://web.archive.org/web/*/https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        
<blockquote>
<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
</blockquote>
<p>I don't remember when I heard that, but it stuck. When a quip "clicks" for me, I can't rest until I find a framing in which it's disproved. But it's been 6 years now, and I'm still unable to muster a reply to the above other than "Yeah, yeah, it seems so".</p>
<p>I'm pretty sure cache invalidation is the harder of the two, because of some underlying OCD most of us have about picking two arbitrary constants that dictate sweep frequency and TTL. I'd even go as far as to speculate most of the evolution of programming has been a weird spiritual exercise around trying not to pick those two arbitrary numbers. Functional programming as a whole can even be understood as a set of taboos around this, because what good is shared OCD if it doesn't lead to religion.</p>
<p>I digress, I'm neither old, wise nor crazy enough to talk about cache invalidation, so I'll talk about the second hardest thing in programming instead, naming things.</p>
<h2>i - Naming necessity</h2>
<p>Maybe I'm being vague here, but please bear with me, I am trying to introduce the practice that leads to the creation of civilization and distinguishes us from apes</p>
<p>Naming helps one make sense of code.</p>
<p>That's not quite right... naming <em>gives</em> sense to code.</p>
<p>In theory, names could be arbitrary, at the ASM level it's more than reasonable to replace names with addresses. Yet names are so useful, that they persist even when code is compiled, presumably because they help preserve sanity when one is forced to look at the generate ASM.</p>
<p>In so far as names help make sense of code, they operate at different levels.</p>
<p>Names help connect the developer with the end goal of the software. I think the main reason OO became popular as a paradigm for teaching was a culture of example programs that used names referencing the "real world". Using words like "Shop" and "Transaction" and "buy" and "transfer_to", that give the student's bored brain some bit of reality to hang on to.</p>
<p>Names help in building a mental map of software. In this regard, names function much like <a href="https://slatestarcodex.com/2014/11/21/the-categories-were-made-for-man-not-man-for-the-categories/">any other arbitrary category we instil upon the world</a>, be it those that we use to refer to animals, other people, the night's sky or, to make the similarity to code more obvious, the content of one's bowel movement. In this sense, names should optimize for a map of the code that makes sense to the one writing it, you.</p>
<p>I'm just kidding though, the "you" here is really "a team" and the "a team" here is really "a team with people coming and going, people which have imperfect memory and ever-changing minds with which they read that map".</p>
<p>We can already see some tradeoffs here. Names that will help you now are not necessarily ones that will help the team 5 years from now. Maybe <code>let IHateThisFingLoop</code> is a useful outlet for one's anger or <code>val steves_moms = FAT32()</code> provided some much needed comedic relief. But naming for the moment can often backfire. Not only when naming for catharsis. We have such a good map of the code we're working on <strong>now</strong> that an "obvious" name can be a horrible choice in hindsight. Depending on our mental context, the name <code>trx</code> might be a much-welcomed shorthand for <code>write_new_credentials_transaction</code>, or it might be the cause of a security error that makes the news.</p>
<p>Names aren't there just to express the concepts we already have, once a name is chosen, if encountered often enough, it becomes its own concept. One need only looks at the old sciences to see arbitrary variable names that are now rooted in people's mindsdb as describing the fundamental nature of reality in an irreducible way. <code>pi</code> and <code>e</code> as representations of the circle, <code>x</code> as describing the concept of unkown, <code>c</code> as describing the maximum speed an object can travel with if Maxwell's equations are to hold... etc).</p>
<p>If a perfectly-named codebase were to exist, it would provide the reader with an amazing understanding of the things it's used for, in addition to being easy to grok. The sad thing is that "perfectly-named" is something that varies between people and even within people (over time).</p>
<p>I also think that the "experience" people have with names might vary greatly based on the codebases they worked on. Working in a large codebase with loads of existing names and naming standards provides a completely different naming-experience from building something from scratch.</p>
<p>Indeed, understanding a codebase or even a language can probably be boiled down to being familiar with all of its names and naming convention.</p>
<p>There might be a type of person that can remember all the names of the functions in a stdlib and yet know nothing about a language. But, in spite of our education system trying to optimize for the psychiatric illness which would allow this, for the vast majority of people understanding a language still boils down to knowing the vocabulary.</p>
<h2>ii - Naming convention</h2>
<p>The foreplay to naming things is coming up with conventions about naming things. A convention dictates the boundaries of what names one can give in various situations. For example, the conventions I usually impose are:</p>
<ul>
<li>class and struct names should be CammelCase</li>
<li>function and variable names should be snake_case</li>
<li>constants (in the constexpr sense), enum members and global aliases should be ALL_CAPS_SANKE_CASE</li>
<li>function only used inside the file they are in have names starting with <code>_</code></li>
<li>names should be &gt;1 and &lt;20 letters, &gt;0 and &lt;5 words, exceptions are allowed</li>
<li>If the type of a variable is not obvious from usage, have a name that implies the type (e.g. <code>customer_arr</code>, <code>equation_dict</code>)</li>
</ul>
<p>None of it is written down in our coding guidelines, people just sort of "catch onto it", even first-time contributors, I find this fascinating.</p>
<p>There are many things new people seem to miss that I have to re-iterate time and time again, but naming is never one of them. Nor was it ever a problem for me when joining a new team to pick up on their conventions.</p>
<p>Though maybe this ease of adoption would disappear if the conventions were too niche or too many?</p>
<p>Conventions are useful for two major reasons:</p>
<ol>
<li>They reduce the thought space when searching for a good name.</li>
<li>They add meaning to existing names without making them longer.</li>
</ol>
<p>If you want to understand naming go digging for conventions, but due to the above issue (people catch onto them instinctively), good conventions are hard to find. Some conventions were so good they got codified into language syntax.</p>
<p>Did you know <code>const</code> (i.e. immutability) wasn't a thing in any popular programming language until the early 80s when C++ came along? People (presumably) used to write it as part of variable names and hope that it would be respected by convention.</p>
<p>The idea of objects and classes are essentially a mix of naming and file-placement conventions that got mixed, at least in imperative land.</p>
<p>Even more so, one suspects that "types" were originally a mere naming convention, though the asteroid destroyed most of the evidence that could be used to conclude that with certainty. But nowadays "types" seem to be used as part of names in language lacking a type system.</p>
<h2>iii - Naming history</h2>
<p>But, asks the reader of 2050, I heard that back in your days there as a field called "mathematics", a thing humans did before computers, where they tried (and often failed miserably) to <a href="https://blog.cerebralab.com/Neural_networks_as_non-leaky_mathematical_abstraction">use their brains to execute formal logic</a>.</p>
<p>You are quite perceptive in remaking that, and I agree we can't understand naming in programming while ignoring 3000 years of naming in mathematics. The most basic names in programming, those shared between most languages, those of the operators (+,-,*,/,^,&amp; ...etc) are pulled out or inspired from math.</p>
<p>In my arbitrarily chosen view of the world, mathematics was an imperfect tool with imperfect creators built in a time before modern brains and modern machines, thus it's riddled with <a href="https://cerebralab.com/Named_Distributions_as_Artifacts">flaws and limitations</a>. One of the most obvious flaws in the way things were named.</p>
<p>When using "math notation" people tended to prefer very short names, namely 1 symbol long. A programmer might write something akin to:</p>
<pre><code>function calc_quarterly_interest(principal, rate, quarters):
    return principal*rate*time
</code></pre>
<p>Though the most obsessive might go all the way to writing:</p>
<pre><code>function calculate_quarterly_interest(principal, rate, quarters):
    quarterly_returns = multiply(principal, rate)
    return multiply(quarterly_returns, time)
</code></pre>
<p>However, in math notation, it would be considered bad form to write anything longer or more expressive than</p>
<pre><code>i(p,r,q)=p*r*q

</code></pre>
<p>The reason for this, I presume, boils down to two things:</p>
<ol>
<li>Saving paper, which could often be quite expensive and impossible to erase.</li>
<li>Reducing the amount of writing in materials like sand or clay, which are cheap and easy to erase, but difficult to write in.</li>
</ol>
<p>This didn't cause many issues because our brains are not very good at executing formal logic. So a given mathematical construct might have included 2, 3, 5 maybe 10 entities playing around. But to postulate an equation with thousands of variable probably seemed like madness even to a genius like Euler or grand curator like Euclid.</p>
<p>Of course, we live in an age where a mildly talented 8-year-old can pick up a toy language like Scratch and construct such an equation incidentally while writing a web app. Nowadays we need only write the equations, historically our brains were also responsible for executing them. This restricted the realm of possibilities to one so tiny I shudders to think about the lamentable condition of the poor souls that helped us get to where we could build computers.</p>
<p>Still, the reason why the previously mentioned interest computing function would work is that the writer could simply specify beforehand: "p stands for principal, r for rate, q for number of quarters".</p>
<p>This is a practice that remained with us until the 80s in a weird way, the name of variables used to be declared at the beginning of a file before they were initialized. Though it may seem crazy to you, C and C++ allow you to compile the following code:</p>
<pre><code>int a;</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1">https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/The_second_hardest_thing_in_programming_-_Part_1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301622</guid>
            <pubDate>Mon, 01 Mar 2021 11:12:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applicative Parsing]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26301543">thread link</a>) | @gbrown_
<br/>
March 1, 2021 | https://jobjo.github.io/2019/05/19/applicative-parsing.html | <a href="https://web.archive.org/web/*/https://jobjo.github.io/2019/05/19/applicative-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p><a href="https://en.wikipedia.org/wiki/Parser_combinator">Parser combinators</a> are
sets of functions for building parsers in a composable fashion. Haskell’s
<a href="http://hackage.haskell.org/package/parsec">Parsec library</a> and OCaml’s
<a href="https://github.com/inhabitedtype/angstrom">Angstrom</a> are two examples.
Both of these libraries expose <em>monadic</em> interfaces for
describing context-sensitive grammars. This post looks at implementing a more
restricted parsing library, structured around <a href="https://en.wikipedia.org/wiki/Applicative_functor">applicative
functors</a> rather
than monads.</p>

<p>What could justify giving up on monads? Depending on the design, one may get
a few things in return. In this exercise, the aim is for an API with the following
features:</p>

<ol>
  <li>The ability to extract all valid symbols from a parser.</li>
  <li>Allow some form of pretty printing.</li>
  <li>Support multiple evaluation strategies (e.g. backtracking and non-backtracking).</li>
</ol>

<p>To see why (1) is not possible to accomplish with monads, consider a parser
constructed using the monadic <em>bind-operator</em>:</p>



<p>Here, <code>f</code> is a function of the form <code>'a -&gt; 'b parser</code>; that means we don’t
know what sort of parser it produces until it’s provided with a value. Therefore,
we cannot infer all possible symbols consumed by those parsers. The same
reasoning applies to pretty printing.</p>

<h3 id="designing-a-parser-type">Designing a parser type</h3>

<p>The essence of a parser is a function with a type analogous to:</p>

<div><div><pre><code><span>char</span> <span>list</span> <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>*</span> <span>char</span> <span>list</span><span>)</span> <span>option</span>
</code></pre></div></div>

<p>A parser takes a list of characters as input, and, when successful, returns a
parsed value along with the remaining input.</p>

<p>This representation, however, falls short of supporting symbol
extraction, pretty printing, or allowing for multiple evaluation strategies.
To accommodate for those we’d have to embellish the type with more context.
The problem is we don’t necessarily know the complete feature set upfront.
Every time a request for some new capability comes in – be it error reporting,
logging or something else – we would have to go back and change the definition
to accommodate for the new functionality.</p>

<p>Rather than trying to anticipate all use cases upfront, an alternative
approach is to choose a representation that preserves as much structure as
possible, so that alternative interpreters may be added later on. To do that,
we’re effectively going to enumerate the set of parsers, and ways of
combining them, by defining a type for representing an abstract syntax tree
(AST). To this purpose, we’ll use a
<a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>, that
also expresses that different parsers are indexed by different types. The
initial constructors are split into two sets – primitive ones (the
leaf nodes of the tree), and combinators for composing parsers:</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>(* Primitive parsers *)</span>
  <span>|</span> <span>Fail</span>      <span>:</span> <span>string</span>            <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
  <span>|</span> <span>Empty</span>     <span>:</span>                       <span>unit</span> <span>t</span>
  <span>|</span> <span>Return</span>    <span>:</span> <span>'</span><span>a</span>                <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
  <span>|</span> <span>Symbol</span>    <span>:</span> <span>char</span>              <span>-&gt;</span> <span>char</span> <span>t</span>
  <span>(* Composition - applicative *)</span>
  <span>|</span> <span>Map</span>       <span>:</span> <span>(</span><span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span><span>)</span> <span>*</span> <span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>'</span><span>b</span> <span>t</span>
  <span>|</span> <span>Product</span>   <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>*</span> <span>'</span><span>b</span> <span>t</span>       <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>*</span> <span>'</span><span>b</span><span>)</span> <span>t</span>
  <span>(* Composition - alternative *)</span>
  <span>|</span> <span>Either</span>    <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>*</span> <span>'</span><span>a</span> <span>t</span>       <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>
</code></pre></div></div>

<p>The primitive parsers are:</p>

<ul>
  <li><code>Fail msg</code> - a parser that always fails.</li>
  <li><code>Empty</code> - a parser that succeeds when given empty input.</li>
  <li><code>Return x</code> - a parser that does not consume any input and always returns <code>x</code>.</li>
  <li><code>Symbol c</code> - a parser that matches input when the first character is <code>c</code>.</li>
</ul>

<p>The applicative interface is what provides sequential composition, as in:
first parse <code>x</code> with parser <code>p1</code>, then parse <code>y</code> with parser <code>p2</code> and combine
their results.</p>

<p>The <code>Either</code> constructor makes it possible to provide alternative execution
paths, i.e. parsers that succeed on different types of input.</p>

<p>As we don’t want to give users direct access to the type, we’ll mechanically
add some smart constructors:</p>

<div><div><pre><code><span>let</span> <span>empty</span> <span>=</span> <span>Empty</span>

<span>let</span> <span>fail</span> <span>m</span> <span>=</span> <span>Fail</span> <span>m</span>

<span>let</span> <span>return</span> <span>x</span> <span>=</span> <span>Return</span> <span>x</span>

<span>let</span> <span>symbol</span> <span>c</span> <span>=</span> <span>Symbol</span> <span>c</span>

<span>let</span> <span>map</span> <span>f</span> <span>x</span> <span>=</span> <span>Map</span> <span>(</span><span>f</span><span>,</span> <span>x</span><span>)</span>

<span>let</span> <span>product</span> <span>p</span> <span>q</span> <span>=</span> <span>Product</span> <span>(</span><span>p</span><span>,</span><span>q</span><span>)</span>

<span>let</span> <span>either</span> <span>p</span> <span>q</span> <span>=</span> <span>Either</span> <span>(</span><span>p</span><span>,</span><span>q</span><span>)</span>
</code></pre></div></div>

<p>Having an applicative interface means that it is also possible to leverage
the new syntax extension – the <code>let+ .. and+</code> notation – which I’ve described
<a href="http://jobjo.github.io//2019/04/24/ocaml-has-some-new-shiny-syntax.html">here</a>.
Assuming OCaml 4.08 or the dune
<a href="https://discuss.ocaml.org/t/let-syntax-backported-to-ocaml-4-02/3447">future_syntax stanza</a>
, we can add a syntax module, like so:</p>

<div><div><pre><code><span>module</span> <span>Syntax</span> <span>=</span> <span>struct</span>
  <span>let</span> <span>(</span><span>let</span><span>+</span><span>)</span> <span>p</span> <span>f</span> <span>=</span> <span>map</span> <span>f</span> <span>p</span>
  <span>let</span> <span>(</span><span>and</span><span>+</span><span>)</span> <span>p</span> <span>q</span> <span>=</span> <span>product</span> <span>p</span> <span>q</span>
<span>end</span>
</code></pre></div></div>

<p>In addition to these, we’ll include an <code>Ops</code> module with infix versions
and some derived combinators:</p>

<div><div><pre><code><span>module</span> <span>Ops</span> <span>=</span> <span>struct</span>
  <span>open</span> <span>Syntax</span>
  <span>let</span> <span>(</span> <span>&lt;$&gt;</span> <span>)</span> <span>f</span> <span>p</span>   <span>=</span> <span>map</span> <span>f</span> <span>p</span>
  <span>let</span> <span>(</span> <span>&lt;|&gt;</span> <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>either</span> <span>p</span> <span>q</span>
  <span>let</span> <span>(</span> <span>&lt;*&gt;</span> <span>)</span> <span>pf</span> <span>px</span> <span>=</span> <span>let</span><span>+</span> <span>f</span> <span>=</span> <span>pf</span> <span>and</span><span>+</span> <span>x</span> <span>=</span> <span>px</span> <span>in</span> <span>f</span> <span>x</span>
  <span>let</span> <span>(</span> <span>*&gt;</span>  <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>(</span><span>fun</span> <span>_</span> <span>x</span> <span>-&gt;</span> <span>x</span><span>)</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>q</span>
  <span>let</span> <span>(</span> <span>&lt;*</span>  <span>)</span> <span>p</span> <span>q</span>   <span>=</span> <span>const</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>q</span>
<span>end</span>
</code></pre></div></div>

<p>Before moving on, some of the code examples also assume a few general
utility functions:</p>

<div><div><pre><code><span>(* Identity *)</span>
<span>val</span> <span>id</span> <span>:</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>a</span>

<span>(* Const *)</span>
<span>val</span> <span>const</span> <span>:</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span> <span>-&gt;</span> <span>'</span><span>a</span>

<span>(* Forward composition *)</span>
<span>val</span> <span>(</span> <span>&gt;&gt;</span> <span>)</span> <span>:</span> <span>(</span><span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>b</span><span>)</span> <span>-&gt;</span> <span>(</span><span>'</span><span>b</span> <span>-&gt;</span> <span>'</span><span>c</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>-&gt;</span> <span>'</span><span>c</span>

<span>(* Converting a char list to a string *)</span>
<span>val</span> <span>string_of_list</span> <span>:</span> <span>char</span> <span>list</span> <span>-&gt;</span> <span>string</span>

<span>(* And back again *)</span>
<span>val</span> <span>list_of_string</span> <span>:</span> <span>string</span> <span>-&gt;</span> <span>char</span> <span>list</span>
</code></pre></div></div>

<p>Their implementation, along with the complete code is available
<a href="https://gist.github.com/jobjo/13376aaea1151100dd7915dedb35d9d7">here</a>.</p>

<h3 id="building-simple-parsers">Building simple parsers</h3>

<p>How can we use the API to build actual parsers? Let’s consider a few simple
examples. First, a parser that parses a specific string, i.e. a function:</p>

<div><div><pre><code><span>val</span> <span>string</span> <span>:</span> <span>string</span> <span>-&gt;</span> <span>string</span> <span>t</span>
</code></pre></div></div>

<p>To implement the <code>string</code> parser, we can use the <code>symbol</code> primitive and fold over the
given string to combine the parsers using applicative (<code>let+ .. and+)</code> syntax:</p>

<div><div><pre><code><span>let</span> <span>string</span> <span>s</span> <span>=</span>
  <span>let</span> <span>accum</span> <span>c</span> <span>p</span> <span>=</span>
    <span>(* Parse 'x' using the 'symbol c' parser *)</span>
    <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>symbol</span> <span>c</span>
    <span>(* Then parse 'xs' using the 'p' parser *)</span>
    <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>p</span> <span>in</span>
    <span>(* Combine 'x' and 'xs' in a string *)</span>
    <span>Printf</span><span>.</span><span>sprintf</span> <span>"%c%s"</span> <span>x</span> <span>xs</span>
  <span>in</span>
  <span>List</span><span>.</span><span>fold_right</span> <span>accum</span> <span>(</span><span>list_of_string</span> <span>s</span><span>)</span> <span>(</span><span>return</span> <span>""</span><span>)</span>
</code></pre></div></div>

<p>Next, let’s attempt a parser for parsing digits. A version that
detects a single digit may be defined as:</p>

<div><div><pre><code><span>let</span> <span>digit</span> <span>=</span>
  <span>list_of_string</span> <span>"0123456789"</span>
  <span>|&gt;</span> <span>List</span><span>.</span><span>map</span> <span>symbol</span>
  <span>|&gt;</span> <span>List</span><span>.</span><span>fold_left</span> <span>either</span> <span>fail</span>
</code></pre></div></div>

<p>Choosing between a list of parsers is a natural generalization of the binary <code>either</code>
combinator, and deserves its own version:</p>

<div><div><pre><code><span>let</span> <span>choose</span> <span>xs</span> <span>=</span> <span>List</span><span>.</span><span>fold_left</span> <span>either</span> <span>fail</span>
</code></pre></div></div>

<p>We may also generalize the <code>digit</code> definition to take a list of symbols as an argument:</p>

<div><div><pre><code><span>let</span> <span>one_of</span> <span>cs</span> <span>=</span> <span>choose</span> <span>@@</span> <span>List</span><span>.</span><span>map</span> <span>symbol</span> <span>cs</span>
</code></pre></div></div>

<p>Now, <code>digit</code> is achieved by:</p>

<div><div><pre><code><span>let</span> <span>digit</span> <span>=</span> <span>one_of</span> <span>"0123456789"</span>
</code></pre></div></div>

<h3 id="hitting-the-boundaries">Hitting the boundaries</h3>

<p>Next, consider a parser that recognizes arbitrary integers? An integer
consists of at least one digit but we don’t know exactly how many. How can we
define a parser that captures this semantics? As a first try:</p>

<div><div><pre><code><span>let</span> <span>int</span> <span>=</span>
  <span>let</span> <span>rec</span> <span>digits</span> <span>()</span> <span>=</span>
    <span>let</span><span>+</span> <span>d</span>  <span>=</span> <span>digit</span>
    <span>and</span><span>+</span> <span>ds</span> <span>=</span> <span>either</span> <span>(</span><span>digits</span> <span>()</span><span>)</span> <span>(</span><span>return</span> <span>[]</span><span>)</span> <span>in</span>
    <span>d</span> <span>::</span> <span>ds</span>
  <span>in</span>
  <span>map</span> <span>(</span><span>string_of_list</span> <span>&gt;&gt;</span> <span>int_of_string</span><span>)</span> <span>@@</span> <span>digits</span> <span>()</span>
</code></pre></div></div>

<p>Can you spot the problem with the above definition? If not, just try running
it and you’ll find it throwing a <em>stack-overflow</em> exception. The problem is
that the recursive call is never conditional on any base case and is always
eagerly evaluated. We need a way to describe parsers that may consume
arbitrarily large inputs without constructing infinite parsing expressions!
To generalize from the <code>int</code> example, we’re aiming for a combinator with the
following signature:</p>

<div><div><pre><code><span>val</span> <span>many</span> <span>:</span> <span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>(</span><span>'</span><span>a</span> <span>t</span><span>)</span> <span>list</span>
</code></pre></div></div>

<p>One solution would be to introduce a constructor, say <code>Delay</code>,
for representing lazy parsers:</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>...</span>
  <span>|</span> <span>Delay</span> <span>:</span> <span>(</span><span>unit</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>

<span>let</span> <span>delay</span> <span>f</span> <span>=</span> <span>Delay</span> <span>f</span>
</code></pre></div></div>

<p>That is a parser with delayed construction. We may use <code>delay</code> to define
<code>many</code>, as in:</p>

<div><div><pre><code><span>let</span> <span>rec</span> <span>many</span> <span>p</span> <span>=</span>
  <span>let</span> <span>many_one</span> <span>=</span>
    <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>p</span>
    <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>delay</span> <span>@@</span> <span>fun</span> <span>_</span> <span>-&gt;</span> <span>many</span> <span>p</span><span>)</span> <span>in</span>
    <span>x</span> <span>::</span> <span>xs</span>
  <span>in</span>
  <span>either</span> <span>many_one</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>
</code></pre></div></div>

<p>Now, each step of the recursion is evaluated on demand rather than upfront.
This solution would work well if it weren’t for the more ambitious set of constraints
having to do with pretty printing and symbol extraction. The problem is that
in order to extract all possible symbols of a delayed parser, we’d need to evaluate
it; this would unroll the infinite recursion expressed in the <code>many</code> definition, and
once again kill the stack.</p>

<h3 id="fixing-the-parser-definition"><em>Fixing</em> the parser definition</h3>

<p>Is there any fix for the problem of simultaneously having a finite
traversable representation, and providing sufficient expressive power for
describing infinite parsers? The clue is in the question. A way of expressing
recursive structures without recursion is exactly what is offered by the <a href="https://en.wikipedia.org/wiki/Fixed-point_combinator">fixed-point
combinator</a>.</p>

<p>Let’s extend the parser type with a fixed-point constructor (and also get rid of <code>Delay</code>):</p>

<div><div><pre><code><span>type</span> <span>'</span><span>a</span> <span>t</span> <span>=</span>
  <span>...</span>
  <span>|</span> <span>Fix</span> <span>:</span> <span>(</span><span>'</span><span>a</span> <span>t</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span><span>)</span> <span>-&gt;</span> <span>'</span><span>a</span> <span>t</span>

<span>let</span> <span>fix</span> <span>f</span> <span>=</span> <span>Fix</span> <span>f</span>
</code></pre></div></div>

<p>We can then use <code>fix</code> as a remedy for the recursiveness of the definition of <code>many</code>,
from above:</p>

<div><div><pre><code><span>let</span> <span>many</span> <span>p</span> <span>=</span>
  <span>fix</span> <span>@@</span> <span>fun</span> <span>many</span> <span>-&gt;</span>
    <span>let</span> <span>many_one</span> <span>=</span>
      <span>let</span><span>+</span> <span>x</span>  <span>=</span> <span>p</span>
      <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>many</span> <span>in</span>
      <span>x</span> <span>::</span> <span>xs</span>
    <span>in</span>
    <span>either</span> <span>many_one</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>
</code></pre></div></div>

<p>Note that there is <em>no</em> <code>rec</code> keyword in sight. The function <code>fix</code> is just a
handy tool for allowing us to mimic recursive functions. You may be left
wondering how exactly this solves the problem of symbol extraction, given
that we still end up with <code>Fix</code> nodes – functions of type <code>('a t -&gt; 'a t)</code>
– that need to be evaluated. Hopefully, the next sections on interpreting
parsers will bring some clarity on that matter.</p>

<p>Coming back to the example of integer-parsing, here’s how <code>int</code> may be defined
in terms of <code>many</code>:</p>

<div><div><pre><code><span>let</span> <span>int</span> <span>=</span>
  <span>let</span><span>+</span> <span>d</span>  <span>=</span> <span>digit</span>
  <span>and</span><span>+</span> <span>ds</span> <span>=</span> <span>many</span> <span>digit</span> <span>in</span>
  <span>int_of_string</span> <span>@@</span> <span>string_of_list</span> <span>(</span><span>d</span> <span>::</span> <span>ds</span><span>)</span>
</code></pre></div></div>

<p>Again, we may extract the common pattern of parsing one or more times using the same
parser (one or more digits in the example above) by adding a new combinator, as in:</p>

<div><div><pre><code><span>let</span> <span>many_one</span> <span>p</span> <span>=</span>
  <span>let</span><span>+</span> <span>x</span> <span>=</span> <span>p</span>
  <span>and</span><span>+</span> <span>xs</span> <span>=</span> <span>many</span> <span>p</span>
  <span>x</span> <span>::</span> <span>xs</span>
</code></pre></div></div>

<p>Given a parser <code>p</code>, the parser <code>many p</code> succeeds if it can apply <code>p</code> <em>at least</em> one
time on its input.</p>

<p>As a side note, the code generously makes use of the new applicative syntax to
demonstrate how it may be used to write declarative code that also avoids
infix operators. As an alternative, we can define the same functions
without relying on the syntax extension; for instance:</p>

<div><div><pre><code><span>(* Requires Ops module to be open *)</span>

<span>let</span> <span>many</span> <span>p</span> <span>=</span> <span>fix</span> <span>@@</span> <span>fun</span> <span>many</span> <span>-&gt;</span>
  <span>either</span> <span>(</span><span>List</span><span>.</span><span>cons</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>many</span><span>)</span> <span>(</span><span>return</span> <span>[]</span><span>)</span>

<span>let</span> <span>many_one</span> <span>p</span> <span>=</span> <span>List</span><span>.</span><span>cons</span> <span>&lt;$&gt;</span> <span>p</span> <span>&lt;*&gt;</span> <span>many</span>…</code></pre></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jobjo.github.io/2019/05/19/applicative-parsing.html">https://jobjo.github.io/2019/05/19/applicative-parsing.html</a></em></p>]]>
            </description>
            <link>https://jobjo.github.io/2019/05/19/applicative-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301543</guid>
            <pubDate>Mon, 01 Mar 2021 10:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataOps: How to develop, maintain and scale data intensive projects]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26301474">thread link</a>) | @javisantana
<br/>
March 1, 2021 | https://blog.tinybird.co/2021/02/27/dataops/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/02/27/dataops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>As we build Tinybird, we work hand in hand with many data and engineering teams. In the process we are discovering new ways to develop, maintain and scale data intensive projects.</p> <h2 id="anatomy-of-a-modern-data-team"> Anatomy of a modern Data Team <a href="#anatomy-of-a-modern-data-team">¶</a> </h2> <p>If you are into development you have probably heard of the <strong>DevOps</strong> culture: a set of practices and tools that allow development teams to improve their productivity and collaboration when building high quality software products.</p> <p>DevOps is also key for teams that need to <strong>iterate faster</strong> on their quest to find the right thing to build.</p> <p>Things like automated testing, continuous integration and deployment, monitoring, configuration and change management… enable the development and operations teams to work as a single team, with end-to-end ownership of the product they are building.</p> <p>When it comes to data teams things are starting to change. There have been typically three groups in a data team:</p> <ul> <li><em>Data scientists</em>: which most of the time work locally running experiments and analyses, or machine learning models that may later need be productised.</li> <li><em>Data engineers</em>: which write and maintain data pipelines.</li> <li><em>Infrastructure engineers</em>: which are in charge of the “<em>big data</em>” infrastructure.</li> </ul> <p>They used to be siloed groups, with long development cycles and most of the time their outputs are cascaded to the next group. Even more, their final product needed to be integrated by a separate team of developers which built the data product for the end users.</p> <blockquote> <p>The technology and tools that support data intensive applications are only good if they are applied such that it is possible for several people in an organization to collaborate around the same context (the data and the business), iterate on the problem, and continuously deliver high quality solutions.</p> </blockquote> <h2 id="dataops-working-with-data-as-if-it-were-code"> DataOps: working with Data as if it were Code <a href="#dataops-working-with-data-as-if-it-were-code">¶</a> </h2> <p><strong>A similar culture to DevOps can be applied to data teams</strong>: it’s known as DataOps.</p> <p>DataOps is a set of practices and tools that allow data scientists, data engineers, infrastructure engineers and <strong>also developers</strong> to collaborate together having full autonomy, ownership and accountability of the data product.</p> <p>The goal is enabling data teams to handle requirements, develop, deploy and support the data product. With tools that allow them to measure performance, latencies or control SLAs.</p> <p>In the end, making data teams <strong>work with data as if it was source code</strong>, so they can iterate faster towards high quality data products.</p> <p>Continue reading to learn about <a href="https://blog.tinybird.co/2021/02/27/dataops-principles/">10 principles of DataOps we make available for data teams</a>.</p> <p><strong><em>What are your main challenges when dealing with large quantities of data?</em></strong> <a href="https://www.tinybird.co/survey">Tell us about them</a> and get started solving them with Tinybird right away.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/02/27/dataops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301474</guid>
            <pubDate>Mon, 01 Mar 2021 10:46:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spectre exploits in the "wild"]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26301326">thread link</a>) | @todsacerdoti
<br/>
March 1, 2021 | https://dustri.org/b/spectre-exploits-in-the-wild.html | <a href="https://web.archive.org/web/*/https://dustri.org/b/spectre-exploits-in-the-wild.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Someone was silly enough to upload a
<a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c">working spectre (CVE-2017-5753) exploit</a>
for Linux (there is also a
<a href="https://www.virustotal.com/gui/file/ecc0f2aa29b102bf8d67b7d7173e8698c0341ddfdf9757be17595460fbf1791a">Windows one</a> with symbols that I didn't look at.)
on VirusTotal last month, so here is my quick Sunday afternoon lazy analysis.</p>
<p>The binary has its <code>-h</code> option stripped, likely behind a <code>#define</code> to avoid
detection, but some of its parameters are obvious, like specifying
what file to leak, or the kernel base address. The authors didn't check (or care)
that the logging function hasn't been entirely optimized out, leaving a bunch
of strings helping in the reversing process.</p>
<p>The exploit works in four stages:</p>
<ol>
<li>Find the <a href="https://www.halolinux.us/kernel-reference/inode-objects.html">superblock</a>,</li>
<li>Find the <a href="https://en.wikipedia.org/wiki/Inode">inode</a> of the file to dump</li>
<li>Find the corresponding page address</li>
<li>Dumps the content of the file.</li>
</ol>
<p>In the case of <code>/etc/shadow</code>, the default option, the content of the
file is shoved in memory by running the following command in the
background: <code>return system("echo \"whatever\n\" | su - 2&gt; /dev/null")</code>.
In my lab, on a vulnerable Fedora, the exploit is successfully dumping <code>/etc/shadow</code> in a couple of minutes.
Interestingly, there are checks to detect <a href="https://en.wikipedia.org/wiki/Supervisor_Mode_Access_Prevention">SMAP</a>
and abort if it's present. I didn't manage to understand why the exploit was
failing in its presence.</p>
<p>The crux of the exploit is at <code>0x4092f0</code>, using <code>cpuid</code> as a serializing
instruction, <code>rdtsc</code> for timing, and <code>mfence</code>/<code>lfence</code> as barrier, as
documented in the paper. It's also using some tricks to minimize the amount of
readings, like type-specific functions, for example a kernel address has a
specific <em>format</em>.
Thanks to <a href="https://twitter.com/spendergrsec">spender</a> for confirming that the gadget used is likely <code>get_user()</code> in the <code>FIOASYNC ioctl</code>,
which was <a href="https://patchwork.kernel.org/project/kernel-hardening/patch/20180209133935.811950747@linuxfoundation.org/">fixed in 2018</a></p>
<p><a href="https://en.wikipedia.org/wiki/KASLR">KASLR</a> is bypassed when present either by
looking at <code>/proc/kallsyms</code> when available to unprivileged users like it used
to be the case on Fedora until ~recently, or by using the generic
bypass from the <a href="https://gruss.cc/files/prefetch.pdf">prefetch side-channel</a> by Gruss and al.
originating from a library called <code>libkaslr</code>. Amusingly, this method is still
working on an up to date Linux, proving again that <a href="https://grsecurity.net/kaslr_an_exercise_in_cargo_cult_security">KASLR is useless at
best</a>.
For systems that don't have the <code>/proc/kallsym</code> file accessible, the exploit
relies on hardcoded offsets, and while only Fedora, ArchLinux and Ubuntu are currently
supported, there are functions to check for Debian and CentOS. It's a bit
surprising to see hardcoded offsets in an exploit with arbitrary read in
2021.</p>
<p>Unsurprisingly, it had a 
<a href="https://www.virustotal.com/gui/file/6461d0988c835e91eb534757a9fa3ab35afe010bec7d5406d4dfb30ea767a62c/detection">0 detection</a>
rate before I published this blogpost.</p>
<p>Attribution is trivial and left as an exercise to the reader.</p>
    </div></div>]]>
            </description>
            <link>https://dustri.org/b/spectre-exploits-in-the-wild.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301326</guid>
            <pubDate>Mon, 01 Mar 2021 10:21:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Business, Not an Audience]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26301030">thread link</a>) | @jakobgreenfeld
<br/>
March 1, 2021 | https://jakobgreenfeld.com/build_an_audience | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/build_an_audience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you’re reading this, I’m pretty sure you’ve seen the following pattern over and over again:</p>

<ul>
  <li>Creative nonfiction pioneer John McPhee distilled decades of experience and first-hand learnings in a series of essays. (The best of them are now available in a book called “Draft No. 4”.)</li>
  <li>A savvy entrepreneur repackages the advice in a $1000+ cohort-based course.</li>
  <li>Someone takes the course and summarizes what he learned.</li>
  <li>People on Twitter start creating threads summarizing the student’s summaries.</li>
  <li>At some point, the guy who summarized the student’s summaries will get invited to a podcast to summarize his summary of the student’s summary.</li>
</ul>

<p>I wish I was kidding.</p>

<p>This is a picture-perfect example of what Sean Blanda calls the <a href="https://99u.adobe.com/articles/55974/the-creative-worlds-bullshit-industrial-complex">Creative World’s Bullshit Industrial Complex</a>. But my goal here is not to dunk on anyone. Instead I want to focus on something far more important.</p>

<p>The Bullshit Complex is just a symptom. What’s the underlying cause?</p>

<p>First, let me clarify one thing. While I’m convinced that remixed content is largely a waste of time for writers and readers, it’s a free world out there. Do whatever makes you happy. If you focus on remixed or “curated” content I’ll probably not follow you on Twitter or read your blog, but there’s no reason why you should care about that. Ultimately, it’s your own responsibility to decide how you spend your time and what kind of content you consume.</p>

<p>With that out of the way, let’s talk about entrepreneurship.</p>

<p>In recent years one of the most common pieces of advice for aspiring entrepreneurs has become that you should focus on building an audience. Everyone is screaming it from the rooftops.</p>

<p>So when I started to get into entrepreneurship a few months ago, that’s exactly what I did. I spent a lot of time researching what kind of tweets get attention and set the goal for myself to post at least two tweets per week and two blog posts per month. After all, churning out content regularly is key if you want to build an audience, <a href="https://www.youtube.com/watch?t=67&amp;v=cubPiuD7_dA&amp;feature=youtu.be">right</a>?</p>

<p>If you need any evidence how serious I was about the whole building an audience thing, here it is: I created a <a href="https://whattotweet.com/">What to Tweet</a> tool because I was struggling to stick to my Twitter schedule.</p>

<p>Looking back at it now I think I largely wasted my time. And more importantly I see so many people falling into the exact same trap.</p>

<p>Their goal is to become entrepreneurs. But instead of building products, they create content. Or even worse, they do research and take courses on how to create content.</p>

<p>But this doesn’t bring them one inch closer to their goal. It’s just a form of procrastination.</p>

<p>While charging money for something you created is <a href="https://jakobgreenfeld.com/free">scary</a>, there is almost zero risk in putting out free content. And if you’re just remixing other people’s content, the intellectual risk is effectively zero. After all, you can always reply “hey, don’t shoot the messenger”.</p>

<p>This trap is particularly dangerous because it feels like you’re making progress while really you don’t.</p>

<p>Aspiring entrepreneurs are not just wasting a lot of time but also lots of money this way. They spend thousands of dollars on courses that teach them how to remix other people’s content more effectively. They buy the latest hyped-up courses that teach them how to craft more effective tweets, blog posts and Youtube videos.</p>

<p>But don’t get me wrong. <em>Having</em> an audience is awesome and I love great content.</p>

<p>What I’m saying is that too many beginners have their priorities backwards and fall into the “build an audience!” trap.</p>

<p>An exemplary plan looks as follows: “I don’t know what product I should create. So I’m planning to create articles or carousels on Linkedin to find my voice and build an audience.” That’s almost verbatim a paragraph from an email I received two days ago.</p>

<p>You can certainly get a lot of followers by churning out remixed content and feel-good platitudes. But everyone seems to forget that not all audiences are alike.</p>

<p>Let’s say you have 2000 followers that you got by posting feel-good platitudes, whereas I only have two followers called Elon Musk and Paul Graham. Would you swap accounts?</p>

<p>With feel-good platitudes and remixed content you’ll only attract fellow beginners. Everyone else recognizes the content immediately for what it is. Hence, the primary value of your much larger audience is that you’re able to sell them a “How to grow your Twitter following” Gumroad course for $47.</p>

<p>A high-quality audience is an endless source of opportunities. A low quality one is at most a Ponzi scheme.</p>

<p>Many people <a href="https://twitter.com/m_ashcroft/status/1364334719970721793">learn</a> this the hard way. They get lured by the promise that they’ll be able to create content effortlessly and build an audience this way. This is exactly what beginners want to hear and hence what gurus are preaching. “Everything is a remix”. So just progressively summarize a bunch of books and then start sharing pieces you remixed from your summaries.</p>

<p>Students of these courses spent months recording videos and writing thousands of words only to discover that they never said anything meaningful.</p>

<p>Valuable content that truly advances the conversation and gets the attention of people you really want to connect with is never effortless. It’s painful. And I’m not talking about some kind of sophisticated editing process, but the writing itself.</p>

<p>In fact, this is how you know that you’re creating valuable content. You should at least be a little scared before you hit the publish button.</p>

<p>Publishing content online is the best way to become visible so that opportunities can find you. But please don’t try to improve your ability to come up with interesting things by reading and connecting ideas just so that you have something to write about.</p>

<p>If you ever notice that you’re trying to “say something interesting”, stop. You’re just going to feed the Creative World’s Bullshit Industrial Complex.</p>

<p>Your main priority always should be to <em>do</em> meaningful things, to solve real-world problems, to be the man in the arena. And if you share what you learn along the way, people will start to listen. Write when you have something meaningful to say, and not to stick to some self-imposed writing schedule.</p>

<p>A hidden benefit of this strategy is that your writing skills become largely irrelevant. It’s certainly true that great writers like John McPhee can make a topic as boring as <a href="https://www.goodreads.com/book/show/54983.Oranges">Oranges</a> exciting. But if you have a great story to tell or learned something important, people will pay attention no matter how bad your writing is. Not convinced? Just look at the essay you’re reading right now.</p>

<p>Save yourself thousands of dollars. Here’s all the writing advice you need:</p>

<ul>
  <li>Share meaningful first-hand experiences.</li>
  <li>Write as if you were emailing a friend, not to impress an imaginary teacher.</li>
</ul>

<p>Now I’m definitely scared to publish this essay. This is exactly why I’ll do it.</p>

  </div></div>]]>
            </description>
            <link>https://jakobgreenfeld.com/build_an_audience</link>
            <guid isPermaLink="false">hacker-news-small-sites-26301030</guid>
            <pubDate>Mon, 01 Mar 2021 09:31:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gerald Weinberg]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300409">thread link</a>) | @ingve
<br/>
February 28, 2021 | https://deprogrammaticaipsum.com/gerald-weinberg/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/gerald-weinberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>Some books are like mirrors. By that I mean that reading them involves a great deal of looking at oneself, both for praise and loathing. Taking a look back in time, reflecting on all those times we thought we were right and we were wrong, bringing back memories of times long gone, some of them painful, most hopefully fun and joyful.</p>
<p>“The Psychology of Computer Programming” is one of those. In every one of its chapters, Dr. Weinberg reflects on the human aspects of programming. It is, most probably, the first book ever written on the subject of the personality, the interactions and the characteristics of software developers. Let me be clear: this book has been written in 1971, and it has been continuously in print until at least the end of the twentieth century, for almost 30 years. This is the stuff of classics.</p>
<p>There has even been a reviewed “anniversary” edition published in 1999, but I bought a copy of the first edition of the book, and besides the delightful look and feel of the pages, representatives of the typography and design of the seventies, the structure, the flow and the discussion of this book make it stand in a class of its own, and represent a hallmark in our field.</p>
<p>Dr.&nbsp;Weinberg analyzes programming from both individual and collective points of view, including the issues of education, human resources management, and even programming language design. The author actually devotes a section of his book to explain how the design of a programming language impacts the readability and the subsequent maintainability (or lack thereof) of the programs written in it.</p>
<p>Sounds familiar?</p>
<p>Regarding team interactions, the author highlights the issues brought from scaling up programming teams: do small teams face the same issues as larger ones? How do communication patterns emerge and evolve? The author takes pleasure in debunking common myths and misconceptions, some of them still held today by managers all over the world: what are the factors that can cause a project to break down in pieces? The answers will surprise you, and you will wonder why nobody had ever told you to read this book first.</p>
<p>Dr. Weinberg also pays close attention to the individual characteristics of programmers. What defines a good programmer? Why do they take pride in their jobs? What kind of incentives should a company offer to their developers? Nice offices or challenging problems? (I think you can guess the answer to that last question.)</p>
<p>In the humble opinion of the author of these lines, software is primarily a social process, and only later a technical feat. Software is no more a technical product than a book is just a printed object. Software is the result of interactions among people, and as such it will reflect all the contradictions, the failures, the wonders and the joy of the people involved in it. Every single piece of software ever written by humans reflects the underlying moods, psyche and interactions of a group of people. As such, studying the psychology of a programmer yields naturally in a process in which, invariably, the software will be better at the end.</p>
<p>I once saw a joke on Twitter, saying that managing programmers was subject to Heisenberg’s Principle, in that observing programmers changes their behavior. I do not think it is a joke, for I believe that all social systems are, actually, quantum-like systems subject to this principle; the actions of the observer will invariably alter the behavior of the observed. And that is OK, as far as I am concerned. If managers are conscious of this fact, and if they can use this to their advantage, they will be able to build sustainable teams.</p>
<p>Maybe Dr. Weinberg took some inspiration from Melvin Conway, who <a href="https://en.wikipedia.org/wiki/Conway%27s_law" target="_blank" rel="noopener">in 1967 stated</a> that “organizations design systems mirroring their own communication structures”. Now you start to understand why your microservice architecture is a mess, and no, neither Istio nor Prometheus is going to help you with that.</p>
<p>Finally, regarding recruiting: we all know how hard it is to find and recruit software developers, yet I am appalled to see how many companies do as much as they can to destroy the teams they spent so much time and money to build. Why is this? I can only recommend all human resources managers, all project managers, and all developers as well, to get a copy of this book and, as I said at the beginning of this chapter, to take a good look at ourselves in the mirror. We all need a little bit of introspection, and Dr. Weinberg can help.</p>
<p>Legacy buzzword warning: this book is mostly accessible to general audiences, but there are a few sections where the author assumes a certain experience with programming languages, compilers, hardware design or even project management; and in some cases, with the 1971 versions of those.</p>
<p>Cover photo by the author.</p>
	</div></div>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/gerald-weinberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300409</guid>
            <pubDate>Mon, 01 Mar 2021 07:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Last Message Sent on AIM]]>
            </title>
            <description>
<![CDATA[
Score 392 | Comments 204 (<a href="https://news.ycombinator.com/item?id=26300266">thread link</a>) | @luu
<br/>
February 28, 2021 | https://justanman.org/posts/the-last-message-sent-on-aim/ | <a href="https://web.archive.org/web/*/https://justanman.org/posts/the-last-message-sent-on-aim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://justanman.org/images/aol-instant-messenger-shuts-down.png" alt="AOL Instant Messenger ‘Running Man’ waving goodbye"></p>
<p>In the early 2000s social media sites like Facebook and Twitter weren’t commonplace yet. Even text messages, at ten cents each, were something to be rationed. For many teenagers the primary means of communication outside school was AOL Instant Messenger (AIM). So when it was announced in October that they were shutting down AIM after 20 years, I felt a wave of nostalgia for the messaging app of my youth.</p>
<p>It wasn’t clear when they would be pulling the plug for good, but a high school friend and I planned to be online for the occasion. Their website indicated that AIM would continue to work until the morning of December 15, 2017. Assuming this meant UTC time, that put it going offline sometime after 7:00 PM EST on the 14th.</p>
<p>I wondered: Could I be the last person to sign off? The last person to send a message? Would I have anything profound to say?</p>
<p><strong>Research</strong></p>
<p>I decided to research famous last words. First stop: the Book of Revelation. Final chapter, final verse.</p>
<blockquote>
<p>“The grace of our Lord Jesus Christ be with you all. Amen.”</p>
</blockquote>
<p>Not quite what I was looking for.</p>
<blockquote>
<p>“Last words are for fools who haven’t said enough!”</p>
</blockquote>
<p>Too cantankerous. And as a somewhat libertarian leaning person, I wasn’t going to let Karl Marx have the last word.</p>
<p>I’d figure out what to say later and in the meantime started reading about the technology behind AIM. I learned about OSCAR, the proprietary protocol used by AIM and ICQ. Parts of the protocol were documented by AOL in an official SDK. This is what made third-party AIM clients possible. I had used Gaim (now Pidgin) on Linux machines before and indeed, there was even BSFlite, an AIM client for the command line.</p>
<p>AOL’s desktop client no longer worked for me. They had already pulled the iOS app from the App Store. Ditto for Android. Fortunately browser sign on still worked. I was greeted by a familiar interface that supported new features like embedded media and SMS.</p>
<p>I sent a couple test messages from the browser to my phone. Monitoring outbound activity in the Chrome network panel revealed the structure of a request: a simple HTTP POST to a url, with what appeared to be a session ID in the query string and a message body. I tried to send a message using <code>curl</code> and it worked. As long as I was signed on in the browser the request was accepted.</p>
<p>There were several paths to automating this but given the time constraint, something quick and easy would probably suffice. All I had to do was keep sending messages until the server stopped responding.</p>
<p><strong>December 14, 2017: The final countdown</strong></p>
<p>It was almost midnight UTC time. It would be the 15th soon and I didn’t want to miss the shutdown, so I set up a Bash script to run the <code>curl</code> command at one second intervals. Every now and then I had to manually reauthenticate in the browser. It wasn’t elegant but it worked. Now I had to wait…</p>
<p>To pass time I searched Twitter for mentions of AIM’s last day. Plenty of people were reminiscing about their old screen names, but only a handful were actually signing on one last time. I added them to my buddy list and we talked for a bit. One lived in DC, one in Toledo. Another somewhere in Maryland. Two were engineers, one was a wrestling announcer! I made dinner and watched <em>The Office</em> while occasionally checking on the script.</p>
<p>It ran for another six hours until 1:21 AM EST. I witnessed the drama play out in HTTP status codes:</p>
<pre><code>200 OK
200 OK
200 OK
408 Request Timeout
408 Request Timeout
401 Unauthorized
</code></pre><p>And like that, AIM was gone. Requests to aim.com returned an Invalid URL status page. <code>curl</code> returned nothing but 401s.</p>
<p><strong>Epitaph</strong></p>
<p>I examined the script logs and found it – the last message sent on AIM. [1] It was timestamped Fri Dec 15 01:21:42 EST 2017. From me, to me. (I didn’t want to spam anyone.)</p>
<p>I had borrowed the words from Leonard Nimoy’s final tweet:</p>
<blockquote>
<p>“A life is like a garden. Perfect moments can be had, but not preserved, except in memory. LLAP”</p>
</blockquote>
<p>🖖</p>
<p><strong>Notes</strong></p>
<p>[1] At least in my server region.</p>
<p><strong>Thanks</strong> to behind2greeneyes, dalilmoo, croftonworldwide, nuklermuleburger, and sirmatthew84.</p>
<p>If you enjoyed reading this, please consider a donation to the <a href="https://archive.org/donate/">Internet Archive</a>.</p>
<p>You can also read Kat Timpf’s brilliant <a href="https://www.nationalreview.com/2017/10/aol-instant-messenger-eulogy-aim-social-media-millennials/">eulogy for AIM</a>.</p>

      <hr>
      <p>
        For more frequent updates, follow me on Twitter.
      </p>
      <p>
        <a href="https://twitter.com/jtangofx?ref_src=twsrc%5Etfw" data-show-count="false">Follow @jtangofx</a>
      </p>
    </div></div>]]>
            </description>
            <link>https://justanman.org/posts/the-last-message-sent-on-aim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300266</guid>
            <pubDate>Mon, 01 Mar 2021 06:40:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The curious case of CVE-2020-14381]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300234">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://blog.frizn.fr/linux-kernel/cve-2020-14381 | <a href="https://web.archive.org/web/*/https://blog.frizn.fr/linux-kernel/cve-2020-14381">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p><a href="https://blog.frizn.fr/linux-kernel/">Kernel Linux</a> &gt; <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">The curious case of CVE-2020-14381</a></p>

                    <h3>The curious case of CVE-2020-14381</h3>                    
                    <p>Today is the one-year anniversary of this interesting kernel bug I worked
on last year with <a href="https://twitter.com/bluec0re" target="_blank">@bluec0re</a>,
and as it turns out I wrote something about it during one of these lockdown
weekends so I thought I'd release it. <a href="https://bugs.chromium.org/p/project-zero/issues/detail?id=2015" target="_blank" title="CVE-2020-14381 get_futex_key use-after-free">The bug itself</a>
was discovered by <a href="https://twitter.com/tehjh" target="_blank">Jann Horn</a>
of Project Zero. While I touch most of the elements required to exploit the
bug, I stay superficial here since the exploit itself is not particularly
exciting. What makes this bug interesting to me is its lifecycle, in particular
how unevenly the patch was applied to the various distributions. I also talk
briefly about hardware side-channels since it was the first time I had ever
used one.</p>

<p><strong>The bug</strong></p><p>It’s already well-described in the bug tracker, but here is another summary.
The <span>futex</span> syscall's main parameter is a userland address, and this address
may belong to a file-backed mapping. In that case, the futex key kernel object
<a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L707" target="_blank">held</a>
and <a href="https://elixir.bootlin.com/linux/v5.4.7/source/kernel/futex.c#L724" target="_blank">kept</a>
a reference to the inode object, but didn’t hold a reference to the file’s mountpoint.
If the mountpoint were to go away, its associated kernel structures would be
freed, but the inode wouldn’t. That’s an issue because the inode itself has
fields that point to some of these structures, such as its <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L641" target="_blank">super_block</a>
struct.</p>

<p>Further use of the inode by <span>futex</span> code paths may therefore trigger
use-after-frees. One particular code path highlighted by Jann in the bug happens
when the <span>futex</span> is destroyed: the last reference to the inode is released
and the inode needs to be freed. This is done in <span>iput</span> which then calls
<span>iput_final</span>. <span>iput_final</span> and its subcalls will then call inode
management functions stored in the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/include/linux/fs.h#L1942" target="_blank">super_operations</a>
struct accessed <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1533" target="_blank">from the super_block</a>
object. The first instance happens right at the beginning of <span>iput_final</span> with
a call to the <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/inode.c#L1539" target="_blank">drop_inode</a>
function.</p>

<p>Exploiting this bug requires being able to:
</p><ul>
  <li>Successfully <span>umount</span> a mountpoint. A no-go a few years ago, but
  possible nowadays with the normalization of unprivileged user namespaces.
  It’s a good example that this feature was never a trivial security tradeoff
  (unprivileged sandboxes v. augmented kernel attack surface) which in turn
  makes it somewhat surprising that all mainstream distributions enabled them by default
  without much debate</li>
  <li>Survive the <span>op-&gt;drop_inode()</span> execution (non-SMEP or a KASLR bypass)</li>
  <li>Survive the <span>op-&gt;drop_inode</span> indirection just before that (non-SMAP
  or a stack/heap leak)</li>
  <li>Do everything in one call, because with an incorrect inode state, a corrupted
  super_block and some linked lists unlinks to do in the remainder of <span>iput_final</span>,
  it’s doubtful we can even get as far as the second <span>super_operations</span>
  function pointer call (<span>evict_inode</span>)</li>
</ul>


<p><strong>Exploitation</strong></p><p>The first exploitation pathway that comes to mind goes as follows:
</p><ul>
  <li>wait for the <span>super_block</span> to be freed. It’s done in <a href="https://elixir.bootlin.com/linux/v5.4.7/source/fs/super.c#L299" target="_blank">an RCU callback</a>
  so one way or another you need to wait for the end of the RCU grace period
  after <span>umount</span> returns, e.g. with <span>membarrier</span>. For a PoC, spraying
  allocs for the duration of the expedited grace period works well enough since
  the <span>super_block</span> slab, <span>kmalloc-2k</span>, is not super busy.</li>
  <li>overwrite the freed <span>super_block</span> via a dynamic heap allocation primitive
  (e.g. <a href="https://elixir.bootlin.com/linux/v5.4.7/source/net/socket.c#L2264" target="_blank">sendmsg ancillary data</a>).</li>
  <li>point <span>s_op</span> to an attacker-controlled buffer</li>
  <li>point <span>drop_inode</span> to a chain of gadgets that pivot the stack to
  either the <span>super_block</span> or <span>super_operations</span> bufffers (which
  are both necessarily in registers and almost fully controlled). Example of
  common gadgets that would work in this situation would be <span>push reg; jmp/call [reg+x]</span>
  that can then be chained with a <span>pop rsp; ret</span> gadget placed at <span>[reg+x]</span></li>
  <li>do whatever with your unconstrained ROP, fixup the stack and return</li>
</ul>


<p>This would be a sucky exploit to maintain as it relies on precise knowledge
of the kernel image, but that’s as good as it gets for a raw function pointer
execution without a read primitive in kernel space. The portability issues
for exploits like this are in themselves a significant bonus of SMEP: it rarely
prevents exploitation but makes many candidates much less appealing for weaponization.</p>

<p>We can take SMEP for granted. It’s only one CPU generation / 2 years older
than SMAP, but not having it is getting really rare. Plus if your exploit does
rely on no-SMEP but your target ends up having software SMEP enabled, which
you sometimes can't really tell at runtime, you've just turned a privesc attempt into
a lost foothold. No-SMAP however is still a thing for the time being. As a
random example the <a href="https://aws.amazon.com/intel/" target="_blank" title="AWS EC2 intel CPUs">AWS EC2 CPU roster</a>
shows some CPUs that do not support SMAP.</p>

<p><strong>On infoleak bugs</strong></p><p>In any case, to exploit this bug one needs at least one infoleak. The most
important is to get kernel base for gadgets, and then we could use a heap leak
or similar to support SMAP-capable CPUs (to have our "attacker-controlled
buffer" in point 3 above in kernel space). A heap/stack leak can often yield
a .text address as well so having one would kill two birds with one stone.
But, not everyone has the right infoleak in their stash ready to go, contrary
to a common anti-KASLR argument. And even when you do have an infoleak bug,
it doesn't mean that it will help with your current exploit.</p>

<p>For instance, a good infoleak candidate which was released around the same
time last year would be the one with uninitialized memory in coredumps, <a href="https://nvd.nist.gov/vuln/detail/CVE-2020-10732" target="_blank">CVE-2020-10732</a>.
But short of a public proof-of-concept, one needs to understand the coredump
generation code, then find an object in that slab that allows us to get
.text, and another one to deduce a heap address you control. In short, at least
as much work as the rest of the exploit we are looking at. And that's without
considering that using two bugs in one exploit also means that you need to
take into account both bugs limitations. Unprivileged user namespaces for the
main bug we are looking at (not a thing on e.g. RHEL 7), and for the coredump,
well the ability to retrieve the core files, i.e. not running in a container.
Luckily for our project, we already knew we were targeting non-SMAP containers
so we were able to avoid spending all that effort on an infoleak bug that
would have ended up being worthless; a luxury that real exploit developpers
preparing capabilities ahead of time do not have. But if we were targeting
SMAP containers, well that would have been it since more effort would have
exceeded our resource budget for this project.</p>

<p><strong>Hardware side-channels</strong></p><p>For kernel .text however, the situation is different since there are generic,
publicly-documented ways to obtain kernel base: hardware vulns. I personally
hadn’t ever used any and even saw them as a niche exploitation technique
relying on opaque CPU heuristics that don’t hold across models - not something
to be considered for resilient exploits. I was simply wrong, but thankfully
had access to many specialists (<a href="https://twitter.com/tehjh" target="_blank">@tehjh</a>,
<a href="https://twitter.com/_fel1x" target="_blank">@_fel1x</a>, <a href="https://twitter.com/_tsuro" target="_blank">@_tsuro</a>)
who knew better.</p>

<p>While side-channels that allow leaking memory across security boundaries
are hopefully bound to be mitigated, there are many side-channels that leak
addresses and which we haven’t heard much about since Spectre and friends.
These ones are probably here to stay even longer. For this project I used <a href="https://github.com/tpn/pdfs/blob/master/Jump%20Over%20ASLR%20-%20Attacking%20Branch%20Predictors%20to%20Bypass%20ASLR%20-%202016%20(micro16).pdf" target="_blank" title="jump over aslr paper">Jump Over ASLR</a>,
which was published before Spectre in 2016. It’s simple to understand (especially
with access to the aforementioned people) and there are PoCs that are just
waiting to be adjusted to your own scenario (e.g. <a href="https://github.com/felixwilhelm/mario_baslr" target="_blank" title="mario_baslr jump over aslr">mario_baslr</a>
from @_fel1x). Jump Over ASLR relies on the inner workings of the Branch Target
Buffer where user and kernel branches may collide. When that happens, the CPU
has more work to do and that can be observed. This allows leaking kernel base 
as long as you have offsets of branches hit during a short kernel path you
can trigger at will: you can then leverage the low entropy of KASLR to try
all possible base addresses and find the one where the branches are hit.</p>

<p>For the parameters (the branches to measure) you can really use whatever
you want. I only tried the <span>creat</span> syscall with arguments that cause a
fast return to userland, and then measured whether the <span>sys_creat</span> and
<span>do_sys_open</span> offsets had been hit. The offsets need to be fairly precise
but not to the byte since there seems to be some aliasing going on in the branch
predictor: I originally used <span>__fentry__</span> as an additional branch target
at a +5 offset for both symbols which still worked even though I later learned
these calls get <a href="https://lwn.net/Articles/747256/" target="_blank">dynamically patched out</a>.
</p>

<p>With proper filtering of both false negatives and false positives (essentially
double checking each address) this works like a charm on recent Intel CPUs,
and it’s one of many such techniques that have been published in the past
6 years or so. That makes it something we should be able to rely on as exploit
developers for the foreseeable future. So for a known kernel image at least,
we are essentially back to pre-KASLR times - and keep in mind that it’s a
field I know fairly poorly so other side-channels are probably even better.</p>

<p><strong>Patch gap</strong></p><p>Ok here is what I personally found really interesting because I had never
looked into kernel bug timelines before. This bug was initially reported on
February 28 2020, and fixed in tip on March 3. At this point it’s essentially
public for anyone keeping an eye out for interesting kernel patches - even
if you don’t spend too much time on it, a <span>reported-by</span> Jann Horn is
worth looking into. The main kernel lines were fixed either on March 25 or
April 2. If you’re thinking “oh wow one whole month”, please be seated for
what’s coming.</p>

<p>Some distros applied the patch almost immediately:
</p><ul>
  <li>Arch Linux: Mar 25</li>
  <li>Gentoo: Mar 25</li>
  <li>Fedora: Mar 26</li>
</ul>


<p>I know they are not supposed to target workstations specifically but outside
of personal servers I don't think I have ever seen them used otherwise. The
2nd batch of distributions that fixed the bug is arguably more server-ready:
</p><ul>
  <li>Ubuntu 18.04 LTS: Apr 7</li>
  <li>Ubuntu 16.04 LTS: Apr 24</li>
  <li>Debian Buster …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.frizn.fr/linux-kernel/cve-2020-14381">https://blog.frizn.fr/linux-kernel/cve-2020-14381</a></em></p>]]>
            </description>
            <link>https://blog.frizn.fr/linux-kernel/cve-2020-14381</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300234</guid>
            <pubDate>Mon, 01 Mar 2021 06:31:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Paying Me]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300165">thread link</a>) | @hiphipjorge
<br/>
February 28, 2021 | https://www.spakhm.com/p/please-stop-paying-me | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/please-stop-paying-me">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few days ago I realized something. I don’t like writing.</p><p>I realized it because I found creative energy to work on programming projects again, and I experience writing programs differently from how I experience having to write. Even the turn of phrase “having to write” betrays my disposition toward the craft.</p><p>When I’m very excited to build products or just program computers for the joy of programming, I dread going to sleep and every part of me <em>cannot wait</em> to wake up and write code again. I’ve never felt that about writing. Writing has always been a chore. I think I’ve known this all along, but have never been able to admit this to myself until now.</p><p>When you read anything about anything anywhere, it tells you what great [INSERT CALLING HERE] do. Great startup founders and engineers write well and write a lot because without clear writing there is no clear thinking. I think I bought into that too much for my own good. So it feels liberating to say: <strong>I hate writing.</strong> It’s painful and laborious and every good piece of writing I make feels like delivering a baby. A rewarding experience for sure, but I think even the most loving of mothers would stop being so loving if she had to deliver a new baby every week.</p><p>One thing that duped me is a lot of positive reenforcement. My best pieces of writing get tens, sometimes hundreds of thousands of readers, and that gives me an addicting sense of elation. I certainly never expected to make money doing it, but enough of you find my writing sufficiently interesting to offer the ultimate seal of approval— you transfer money from your wallet into mine. I deeply appreciate it, and deeply appreciate you spending time on reading my essays, but unfortunately this isn’t sufficient impetus for me to produce good work. When I’m forced to write on a schedule, my writing sucks and my life is miserable.</p><p>Which is a good reminder why some of my writing is good. It’s good when I have something important to say. Important things are hard to say by definition— if they were easy people would have already talked them out and they probably would have lost their importance. At least they’re hard to say for me. So when I do it it’s always very slow and painful, and it turns out good because I say something that matters to me in a way that nobody else bothered or managed to say. With my particular idiosyncrasies the intersection of that and the business of running a newsletter is an empty set.</p><p>So please stop paying me. For the folks that have prepaid, I’m not exactly sure how Substack tooling handles this situation, but shoot me an email and I’ll figure out how to return a prorated amount.</p><p>I will continue writing. When I have something important to say, I’ll go through the pain necessary for me to say it. I’ll also write about my observations as I pursue my product and programming work— technical, anthropological, and simply keeping you up to do date on what I’m up to. I don’t expect you’ll be hearing from me less often. In fact, I’m hoping this will allow me to write more. But owing people weekly essays as a matter of business isn’t my tao. For all the reasons above, and primarily because it makes the essays suck, and I don’t like producing bad work.</p><p>Until next week, hopefully. Slava.</p></div></div>]]>
            </description>
            <link>https://www.spakhm.com/p/please-stop-paying-me</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300165</guid>
            <pubDate>Mon, 01 Mar 2021 06:11:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neural Network Matrix Visualization]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300106">thread link</a>) | @sidcool
<br/>
February 28, 2021 | https://iism.org/article/neural-network-matrix-visualization-61 | <a href="https://web.archive.org/web/*/https://iism.org/article/neural-network-matrix-visualization-61">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iism.org/article/neural-network-matrix-visualization-61</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300106</guid>
            <pubDate>Mon, 01 Mar 2021 05:56:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Random effects and penalized splines are the same thing]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26300028">thread link</a>) | @whoisnnamdi
<br/>
February 28, 2021 | https://www.tjmahr.com/random-effects-penalized-splines-same-thing/ | <a href="https://web.archive.org/web/*/https://www.tjmahr.com/random-effects-penalized-splines-same-thing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        
        <p>For a long time, I’ve been curious about something. It is a truth I’ve
seen casually dropped in textbooks, package documentation, and tweets:
<strong>random effects and penalized smoothing splines are the same thing</strong>. 
It sounds so profound and enlightened. What does it mean? How are they
the same? What deep statistical <em>gnosis</em> was I missing out on?</p>

<p>I have spent months, off and on, trying to understand this equivalence.
I can’t give you the full mathematical treatment, but I have the gist of
it and I can point you to the equations. In this post, I will try to 
highlight the connections between the two.</p>

<p>Here are the main takeaways:</p>

<ul>
  <li>Mixed effects models (a.k.a. hierarchical models or multilevel
models) use partial pooling to strike a balance between a grand
population mean (complete pooling) and individual group means (no
pooling).</li>
  <li>Smoothing splines work by penalizing model coefficients to reduce
the model degrees of freedom.</li>
  <li>You can use the computational machinery of one framework to estimate
the other.</li>
</ul>

<blockquote data-conversation="none" data-lang="en" data-dnt="true" data-theme="light">
  <p lang="en" dir="ltr">Sadly, I feel like my career has peaked with the creation of this meme <a href="https://t.co/5ilRFonsy7">pic.twitter.com/5ilRFonsy7</a></p>

  <img src="https://www.tjmahr.com/assets/images/spider-smooth.jpg" alt="Spiderman (Penalized smooths) pointing at (and being pointed at) by Spiderman (Random effects)">
  <br>
  — Eric Pedersen (@ericJpedersen) <a href="https://twitter.com/ericJpedersen/status/1293508069016637440?ref_src=twsrc%5Etfw">August 12, 2020</a>
</blockquote>

<h2 id="mixed-model-review">Mixed model review</h2>

<p>Let’s review what these things means. Mixed effects models,
<a href="https://www.tjmahr.com/another-mixed-effects-model-visualization/">apparently</a> the <a href="https://www.tjmahr.com/plotting-partial-pooling-in-mixed-effects-models/">main
focus</a> of <a href="https://www.tjmahr.com/iccbot-comes-online/">this
blog</a> over the years, are used to estimate
“random” or “varying” effects. Here is the classic equation set up:</p>

\[\mathbf{y} = \mathbf{X\beta} + \mathbf{Zb} + \mathbf{\epsilon} \\
\mathbf{b} \sim \textsf{Normal}(0, \sigma_b) \\
\mathbf{\epsilon} \sim \textsf{Normal}(0, \sigma_y) \\
\mathbf{X}: \textrm{fixed effects model matrix} \\
\mathbf{Z}: \textrm{random effects model matrix} \\
\sigma_b, \sigma_y : \textrm{variance components} \\
\sigma_b : \textrm{where the magic happens} \\\]

<p>The magic here is the <em>σ</em><sub><em>b</em></sub>, as it ties all of the
individual effects in <strong>b</strong> under a common distribution. If
<em>σ</em><sub><em>b</em></sub> were replaced with a fixed number like 10, then all
of the effects in <strong>b</strong> would be independent and unaware of each other:
There would be <em>no pooling</em> of information between the groups. If we
remove it from the model—replace <em>σ</em><sub><em>b</em></sub> with 0, so to
speak—then all the group variability is ignored, and there is
<em>complete pooling</em> of information into a single mean effect. With 
<em>σ</em><sub><em>b</em></sub> all the groups can contribute information about the 
distribution of plausible effects, and so, there can be 
<em>partial pooling</em> of information between groups.</p>

<p>Consider the <a href="https://mc-stan.org/rstanarm/reference/rstanarm-datasets.html" title="Documentation on the radon dataset"><code>radon</code> dataset</a> example from <a href="https://amzn.to/3aVa9tB" title="An Amazon Affliate link to Gelman and Hill">Gelman and Hill
(2007)</a>. Radon measurements were taken in Minnesota
counties. We would like to estimate the average radon measurement for
each county. We have a repeated measures situation, and some counties
have more observations than others. We use a Bayesian mixed effects
model with <a href="https://github.com/paul-buerkner/brms">brms</a> to estimate a
population distribution of county estimates, and the county-level
estimates are randomly varying effects. They are drawn from a random
distribution, the scale of which we estimate from the data.</p>

<div><div><pre><code><span>library</span><span>(</span><span>tidyverse</span><span>)</span><span>
</span><span>theme_set</span><span>(</span><span>theme_grey</span><span>(</span><span>base_size</span><span> </span><span>=</span><span> </span><span>14</span><span>))</span><span>
</span><span>library</span><span>(</span><span>brms</span><span>)</span><span>
</span><span>radon</span><span> </span><span>&lt;-</span><span> </span><span>rstanarm</span><span>::</span><span>radon</span><span>

</span><span>b_radon</span><span> </span><span>&lt;-</span><span> </span><span>brm</span><span>(</span><span>
  </span><span>log_radon</span><span> </span><span>~</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>(</span><span>1</span><span> </span><span>|</span><span> </span><span>county</span><span>),</span><span> 
  </span><span>radon</span><span>,</span><span> 
  </span><span>family</span><span> </span><span>=</span><span> </span><span>gaussian</span><span>,</span><span> 
  </span><span>file</span><span> </span><span>=</span><span> </span><span>"radon"</span><span>
</span><span>)</span><span>
</span><span>b_radon</span><span>
</span><span>#&gt;  Family: gaussian </span><span>
</span><span>#&gt;   Links: mu = identity; sigma = identity </span><span>
</span><span>#&gt; Formula: log_radon ~ 1 + (1 | county) </span><span>
</span><span>#&gt;    Data: radon (Number of observations: 919) </span><span>
</span><span>#&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;</span><span>
</span><span>#&gt;          total post-warmup samples = 4000</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Group-Level Effects: </span><span>
</span><span>#&gt; ~county (Number of levels: 85) </span><span>
</span><span>#&gt;               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; sd(Intercept)     0.30      0.05     0.22     0.40 1.00     1782     2894</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Population-Level Effects: </span><span>
</span><span>#&gt;           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; Intercept     1.35      0.05     1.26     1.45 1.00     2749     3198</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Family Specific Parameters: </span><span>
</span><span>#&gt;       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span><span>
</span><span>#&gt; sigma     0.77      0.02     0.73     0.80 1.00     7374     3105</span><span>
</span><span>#&gt; </span><span>
</span><span>#&gt; Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS</span><span>
</span><span>#&gt; and Tail_ESS are effective sample size measures, and Rhat is the potential</span><span>
</span><span>#&gt; scale reduction factor on split chains (at convergence, Rhat = 1).</span><span>
</span></code></pre></div></div>

<p>Here <code>sd(Intercept)</code> corresponds to <em>σ</em><sub><em>b</em></sub>.</p>

<p>We can plot the observed county means alongside the model estimated
ones. First, I do some wrangling so that the difference between observed
means and estimated means are computed for use later on.</p>

<div><div><pre><code><span>radon_aug</span><span> </span><span>&lt;-</span><span> </span><span>radon</span><span> </span><span>%&gt;%</span><span>
  </span><span># add ns and means</span><span>
  </span><span>group_by</span><span>(</span><span>county</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>mutate</span><span>(</span><span>
    </span><span>observed_mean</span><span> </span><span>=</span><span> </span><span>mean</span><span>(</span><span>log_radon</span><span>),</span><span>
    </span><span>county_n</span><span> </span><span>=</span><span> </span><span>n</span><span>()</span><span>
  </span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span> 
  </span><span># add fitted values</span><span>
  </span><span>tidybayes</span><span>::</span><span>add_fitted_draws</span><span>(</span><span>b_radon</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>mutate</span><span>(</span><span>
    </span><span>observed_minus_model</span><span> </span><span>=</span><span> </span><span>observed_mean</span><span> </span><span>-</span><span> </span><span>.value</span><span> 
  </span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span># summarize fitted values</span><span>
  </span><span>ggdist</span><span>::</span><span>median_qi</span><span>(</span><span>.value</span><span>,</span><span> </span><span>observed_minus_model</span><span>)</span><span> 

</span><span>radon_aug</span><span>$</span><span>type</span><span> </span><span>&lt;-</span><span> </span><span>"mixed model estimates"</span><span>
</span><span>radon</span><span>$</span><span>type</span><span> </span><span>&lt;-</span><span> </span><span>"observed means"</span><span>

</span><span>ggplot</span><span>(</span><span>radon_aug</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>aes</span><span>(</span><span>
    </span><span>x</span><span> </span><span>=</span><span> </span><span>fct_rev</span><span>(</span><span>fct_infreq</span><span>(</span><span>county</span><span>)),</span><span> 
    </span><span>y</span><span> </span><span>=</span><span> </span><span>log_radon</span><span>,</span><span> 
    </span><span>color</span><span> </span><span>=</span><span> </span><span>type</span><span>,</span><span> 
    </span><span>shape</span><span> </span><span>=</span><span> </span><span>type</span><span>
  </span><span>)</span><span> </span><span>+</span><span>
  </span><span>stat_summary</span><span>(</span><span>data</span><span> </span><span>=</span><span> </span><span>radon</span><span>,</span><span> </span><span>fun</span><span> </span><span>=</span><span> </span><span>mean</span><span>,</span><span> </span><span>geom</span><span> </span><span>=</span><span> </span><span>"point"</span><span>)</span><span> </span><span>+</span><span>
  </span><span>geom_point</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>.value</span><span>))</span><span> </span><span>+</span><span> 
  </span><span># Want to include y = 0 in the figure</span><span>
  </span><span>geom_blank</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>0</span><span>))</span><span> </span><span>+</span><span>
  </span><span>labs</span><span>(</span><span>
    </span><span>x</span><span> </span><span>=</span><span> </span><span>"county (in increasing order by sample size)"</span><span>,</span><span> 
    </span><span>y</span><span> </span><span>=</span><span> </span><span>"log(radon)"</span><span>
  </span><span>)</span><span> </span><span>+</span><span>
  </span><span>geom_hline</span><span>(</span><span>yintercept</span><span> </span><span>=</span><span> </span><span>fixef</span><span>(</span><span>b_radon</span><span>)[</span><span>1</span><span>])</span><span> </span><span>+</span><span>
  </span><span>scale_color_manual</span><span>(</span><span>values</span><span> </span><span>=</span><span> </span><span>c</span><span>(</span><span>"blue"</span><span>,</span><span> </span><span>"grey40"</span><span>))</span><span> </span><span>+</span><span>
  </span><span>labs</span><span>(</span><span>color</span><span> </span><span>=</span><span> </span><span>NULL</span><span>,</span><span> </span><span>shape</span><span> </span><span>=</span><span> </span><span>NULL</span><span>)</span><span> </span><span>+</span><span>
  </span><span>theme</span><span>(</span><span>
    </span><span>axis.text.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>axis.ticks.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>panel.grid.major.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>panel.grid.minor.x</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>legend.title</span><span> </span><span>=</span><span> </span><span>element_blank</span><span>(),</span><span>
    </span><span>legend.position</span><span> </span><span>=</span><span> </span><span>"top"</span><span>,</span><span> 
    </span><span>legend.direction</span><span> </span><span>=</span><span> </span><span>"horizontal"</span><span>,</span><span>
    </span><span>legend.justification</span><span> </span><span>=</span><span> </span><span>"left"</span><span>,</span><span>
  </span><span>)</span><span> 
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/county-means-1.png" title="A plot showing log radon on the y axis and county on the x asis. There are two sets of overlapping points. There are the observed means in each country and the model estimated means. There is much less variability in the modeled means." alt="A plot showing log radon on the y axis and county on the x asis. There are two sets of overlapping points. There are the observed means in each country and the model estimated means. There is much less variability in the modeled means." width="80%"></p>

<p>We see a classic example of partial pooling. First note that model
estimates (blue circles) are less variable: None go above <em>y</em> = 2 and
only four go below <em>y</em> = 1. For counties with many observations (right
side), the estimated mean is hardly adjusted. There is less of a visual
gap between the observed mean and estimated mean. For counties with less
data (left side), the estimate is pulled towards the population mean
(<code>Intercept</code> in the summary above).</p>

<p>The following plot shows difference between the observed means and
the estimated means, subtracting the grey triangles from the blue squares
in the plot above.</p>

<div><div><pre><code><span>radon_aug</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ungroup</span><span>()</span><span> </span><span>%&gt;%</span><span> 
  </span><span>distinct</span><span>(</span><span>county</span><span>,</span><span> </span><span>county_n</span><span>,</span><span> </span><span>observed_minus_model</span><span>)</span><span> </span><span>%&gt;%</span><span> 
  </span><span>ggplot</span><span>()</span><span> </span><span>+</span><span> 
    </span><span>aes</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>county_n</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>observed_minus_model</span><span>)</span><span> </span><span>+</span><span> 
    </span><span>geom_point</span><span>(</span><span>alpha</span><span> </span><span>=</span><span> </span><span>.5</span><span>)</span><span> </span><span>+</span><span>
    </span><span>labs</span><span>(</span><span>
      </span><span>x</span><span> </span><span>=</span><span> </span><span>"Number of observations in county"</span><span>,</span><span>
      </span><span>y</span><span> </span><span>=</span><span> </span><span>"Observed mean - estimated mean"</span><span>
    </span><span>)</span><span> 
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/shrinkage-by-n-1.png" title="Plot with number of observations on the x axis and the difference between the observed and estimated means on the y axis. There is a smaller difference for counties with more data." alt="Plot with number of observations on the x axis and the difference between the observed and estimated means on the y axis. There is a smaller difference for counties with more data." width="66%"></p>

<p>The contention behind the <em>smooths = random effects</em> claim is that what we
just did is a case of <em>smoothing</em>. These random effects are, in a way, 
smoothed fixed effects.</p>

<blockquote>
  <p>The function <code>random()</code> can be seen as a smoother for use with factors
in <code>gamlss()</code>. It allows the fitted values for a factor predictor to
be shrunk towards the overall mean […]</p>

  <p>— <a href="https://rdrr.io/cran/gamlss/man/random.html" title="random: Specify a random intercept model in a GAMLSS formula">GAMLSS documentation</a> describing a random intercept as a smoother</p>
</blockquote>

<h2 id="but-whats-smoothing">But what’s smoothing?</h2>

<p>Now let’s walk through a generalized additive model in
<a href="https://cran.r-project.org/web/packages/mgcv/index.html">mgcv</a> to
demonstrate a penalized smoothing spline. That was a mouth full, but
basically additive models are like the smoothing expansion pack for the
standard linear model. We’re still doing regression, but we have some
new syntax and our models can do nonlinear relationships more easily
now.</p>

<p>I will walk through a basic example of how a spline’s basis functions
are weighted to approximate a nonlinear trend, but this is not going to
be a full tutorial. Other people have made video introductions to
<a href="https://youtu.be/Zxokd_Eqrcg?t=506" title="Dr. Gavin Simpson - Learning When, Where, and by How Much, Things Change [Remote]">additive models</a> or the <a href="https://youtu.be/q4_t8jXcQgc" title="Noam Ross - Nonlinear Models in R: The Wonderful World of mgcv">mgcv package</a>. I first
learned them from <a href="https://arxiv.org/abs/1703.05339" title="Generalised additive mixed models for dynamic analysis in linguistics: a practical introduction">a tutorial for linguists</a> and then from
<a href="https://amzn.to/37PLa8W" title="An Amazon Affliate link to Simon Wood's GAM textbook">the mgcv textbook</a>, but there are <a href="https://github.com/noamross/gam-resources" title="Resources for Learning About and Using GAMs in R">other resources
online</a>.</p>

<p>We use the <a href="https://rdrr.io/pkg/MASS/man/mcycle.html" title="Documentation on the mcycle dataset"><code>mcycle</code></a> dataset which gives the head
acceleration in a simulated motorcycle accident. We are going to fit a
model, plot the smooth from it, and then we are going to work through
what the model did.</p>

<div><div><pre><code><span>library</span><span>(</span><span>mgcv</span><span>)</span><span>

</span><span>mcycle</span><span> </span><span>&lt;-</span><span> </span><span>MASS</span><span>::</span><span>mcycle</span><span> </span><span>%&gt;%</span><span> 
  </span><span>tibble</span><span>::</span><span>rowid_to_column</span><span>()</span><span>

</span><span># Fit the model</span><span>
</span><span>gam_20</span><span> </span><span>&lt;-</span><span> </span><span>gam</span><span>(</span><span>
  </span><span>accel</span><span> </span><span>~</span><span> </span><span>1</span><span> </span><span>+</span><span> </span><span>s</span><span>(</span><span>times</span><span>,</span><span> </span><span>bs</span><span> </span><span>=</span><span> </span><span>"cr"</span><span>,</span><span> </span><span>k</span><span> </span><span>=</span><span> </span><span>20</span><span>),</span><span> 
  </span><span>data</span><span> </span><span>=</span><span> </span><span>mcycle</span><span>,</span><span> 
  </span><span>method</span><span> </span><span>=</span><span> </span><span>"REML"</span><span>
</span><span>)</span><span>

</span><span>mcycle</span><span>$</span><span>.fitted</span><span> </span><span>&lt;-</span><span> </span><span>fitted</span><span>(</span><span>gam_20</span><span>)</span><span>

</span><span>ggplot</span><span>(</span><span>mcycle</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>aes</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>times</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>accel</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>geom_point</span><span>(</span><span>alpha</span><span> </span><span>=</span><span> </span><span>.5</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>geom_line</span><span>(</span><span>aes</span><span>(</span><span>y</span><span> </span><span>=</span><span> </span><span>.fitted</span><span>),</span><span> </span><span>color</span><span> </span><span>=</span><span> </span><span>"blue"</span><span>)</span><span> </span><span>+</span><span> 
  </span><span>labs</span><span>(</span><span>x</span><span> </span><span>=</span><span> </span><span>"time after impact [ms]"</span><span>,</span><span> </span><span>y</span><span> </span><span>=</span><span> </span><span>"acceleration [g]"</span><span>)</span><span>
</span></code></pre></div></div>

<p><img src="https://www.tjmahr.com/figs/2021-02-26-random-effects-penalized-splines-same-thing/smooth-demo-1.png" title="Scattplot showing time on the x axis and acceleration on the y axis. The model fit is shown in blue. It makes two big turns down and then up." alt="Scattplot showing time on the x axis and acceleration on the y axis. The model fit is shown in blue. It makes two big turns down and then up." width="80%"></p>

<p>So what happened here? We will cover it visually.</p>

<h3 id="splines-are-the-sums-of-weighted-wiggles">Splines are the sums of weighted wiggles</h3>

<p>Let’s look at the regression formula.</p>

<div><div><pre><code><span>formula</span><span>(</span><span>gam_20</span><span>)</span><span>
</span><span>#&gt; accel ~ 1 + s(times, bs = "cr", k = 20)</span><span>
</span></code></pre></div></div>

<p>We told <code>gam()</code> to estimate <code>accel</code> using an intercept term and a smooth
term on the time predictor (<code>s(times, ...)</code>). Specifically, we created
our smooth using a cubic regression spline basis (<code>bs = "cr"</code>) with <code>k
= 20</code> - 1 curves. Our model is
estimating a function by adding up smaller components called <em>basis
functions</em>, and the space that defines those components is the <em>basis</em>.
These basis functions are weighted and summed together to produce a
smooth trend called a <em>spline</em>. The name <em>splines</em> is inspired by
drafting splines which are flexible strips of wood that can be weighted
and anchored in place to make a nice curve.</p>

<p>To reiterate, conceptually, we are decomposing the <code>times</code> predictor
into a bunch of individual wiggly lines (basis functions), and these are
weighted and summed together to approximate some nonlinear function. My
post on <a href="https://www.tjmahr.com/polypoly-package-released/">orthogonal polynomials</a>
illustrates the same principle but with polynomial basis functions.
Richard McElreath provides <a href="https://youtu.be/ENxTrFf9a7c?t=2226" title="Statistical Rethinking Winter 2019 Lecture 04">a friendly 30-minute introduction
splines</a> in a Bayesian model in his Statistical
Rethinking course. One line I appreciate from his description is that
with splines, we replace a predictor variable, like <code>times</code>, with a set
of “synthetic” predictor variables.</p>

<figure>
  <img src="https://www.tjmahr.com/assets/images/2021-02-spline.png" alt="An illustration of a drafting spline."><figcaption>
      A drafting spline is a flexible strip of wood that is anchored at a few points so that one can create smooth curves. …</figcaption></figure></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tjmahr.com/random-effects-penalized-splines-same-thing/">https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</a></em></p>]]>
            </description>
            <link>https://www.tjmahr.com/random-effects-penalized-splines-same-thing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300028</guid>
            <pubDate>Mon, 01 Mar 2021 05:33:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animated PNG vs. Animated Webp vs. GIF]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26300015">thread link</a>) | @panabee
<br/>
February 28, 2021 | https://corydowdy.com/blog/apng-vs-webp-vs-gif | <a href="https://web.archive.org/web/*/https://corydowdy.com/blog/apng-vs-webp-vs-gif">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>With Chrome now supporting Animated PNG as of Chrome 59 we have two image formats that can supplant the old and tired GIF format. Varying posts and sites have different conclusions on when to use APNG versus an animated Webp. In all my findings (linked below where the source Gif comes from) animated webp beats apng in filesize each and every time. Sometimes by not very much. This of course is anecdotal and I'm not as familiar with apng as the creators and others may be so they may be able to squeeze more out of an apng than I can.</p>

<p>All that being said I've heard and read people say "APNG might be bigger but webp takes longer to decode in the browser". That assumes the larger APNG will load faster than the smaller webp. Is that the case though? I assume the smaller webp gets downloaded to the client faster then it'll start decoding faster. Thus animating faster. So lets actually test that instead of me spouting off haha. On to the source GIF.</p>

<p>The GIF I'm using for this post comes from my post on <a href="https://corydowdy.com/blog/converting-mp4-to-webm">Converting MP4 To Webm <span>&nbsp;</span></a>. That was a 1080p video stripped down to about 5 seconds and resized to a width of 800.</p>

<p>Here are the relevant details of the unoptimized GIF:</p>

<ul>
<li>Dimensions: 800x450</li>
    <li>Length: 5s</li>
    <li>Size: ≈37.9MB</li>
</ul>
<h2>Setup</h2>

<p>Before we can even embark on this trip we have to convert the GIF above to an APNG and an Animated Webp. Maybe you can convert the GIF on this page to an APNG and get better results. Please try I don't want to dismiss APNG as much as I think I'm probably coming off as.</p>

<h3>Converting to an Animated PNG (apng)</h3>

<p>Gif2apng offers three different options for converting a GIF to an animated PNG. We have zlib, 7zip and Zopfli compression. Each compression option besides zlib allows you to set an iteration amount which defaults to 15.</p>

<p>I'm using gif2apng version 1.9 <a href="#footnotes-apng">[ 1 ] [ 2 ]</a>. For both 7zip and zopfli I'll use the "default" iterations of 15 and a more aggressive version of 100. Be warned if you want to do this. Depending on your server specs or locally on your own computer and it's specs Zopfli will take a long time. Increasing the iterations for either of the compression algorithms will also increase how long it takes to convert your image to an APNG. Be prepared to set aside a pretty big chunk of time if you do this on your computer :).</p>

<p>After converting the GIF to an Animated PNG I'll also run it through APNGOPT. This should "optimize" the Animated PNG. This too offers differing amount of iterations. I'll use the "default" of 15 for each apng that was converted with the defaults above and 100 for all the 100 iterations.</p>

<h4>APNG Filesize Results</h4>



<p>We can see that Zopfli compression saves the most before running these through apngopt. It's very CPU intensive though. After running these through apngopt things didn't change much or at all.</p>

<div>
<table>
<caption>Filesize of APNG after using APNGOPT</caption>
    <thead><tr>
<th>Compression Type</th>
            <th>Original Size in MB</th>
            <th>APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th>Unoptimized Gif</th>
            <td>≈37.9MB</td>
            <td></td>
        </tr>
<tr>
<th>Animated PNG with Zlib</th>
            <td>≈33.01MB</td>
            <td>≈33.04MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 15 iterations</th>
            <td>≈31.22MB</td>
            <td>≈31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with 7zip 100 iterations</th>
            <td>≈31.22MB</td>
            <td>≈31.21MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 15 iterations</th>
            <td>≈30.92MB</td>
            <td>≈30.91MB</td>
        </tr>
<tr>
<th>Animated PNG with Zopfli 100 iterations</th>
            <td>≈30.87MB</td>
            <td>≈30.86MB</td>
        </tr>
</tbody>
</table>
</div>

<h5 id="apng-footnote-label">APNG Footnotes</h5>

<ol id="footnotes-apng">
<li>On a windows machine just use the GUI they package from sourceforge. It seems to be the most up to date. I haven't had the time to see if the GUI and CLI differ in anyway so that'll be up to you unless you're ok with the output of the GUI then keep on keepin on!</li>
    <li>If you install gif2apng through your OS's package manager (ie: apt-get/apt) depending on your OS's you'll more than likely get version 1.7.</li>
    <li>Depending on your OS again if you use the CLI version of apngopt you'll get versions ranging from 1.1 to 1.4.</li>
</ol>
<h2>Animated Webp</h2>

<p>The same reference gif was converted to a webp using three different options and WebP Encoder version: 0.6.0 (WebP Mux version: 0.4.0).</p>

<p>I didn't dive into the different CLI options available for gif2webp. Things such has <code> -kmin </code> , <code> -kmax </code> — which specify the minimum and maximum distance between consecutive key frames and can improve decoding performance — or adjust the deblocking filter <code> -f </code> from the docs suggested 50. These could with adjustments and tweaking produce smaller or in some instances bigger files. You'll have to test those out for specific images, or use the defaults such as I have.</p>

<ul>
<li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.default.webp">It's default settings (quality 75) <span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.webp">quality of 70 and 6 (-m 6) for the compression mode. It's highest.<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.webp">A quality of 70 with default compression of 4 (lossless)<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.mixed.webp">an unfair mixed mode (lossless and lossy compression) with a quality of 70<span>&nbsp;</span></a></li>
    <li><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/squirrel.q70.m6.mixed.webp">another unfair Quality 70 with Commpression of 6 &amp; Mixed compression (lossy and lossles)<span>&nbsp;</span></a></li>
</ul>
<p>Webp at it's default settings beats (barely) each of the converted APNG's, 30.86MB for the Webp compared to 33.01MB using default APNG settings (zlib) and 30.87MB using zopfli compression @ 100 iterations.</p>

<div>
<table>
<caption>Filesize of Webp &amp; Optimized APNG</caption>
    <thead><tr>
<th>File</th>
            <th>Quality</th>
            <th>Compression Mode</th>
            <th>Webp Size in MB</th>
            <th>Best APNGOPT Size in MB</th>
        </tr></thead>
<tbody>
<tr>
<th rowspan="5">Animated Webp</th>
            <td>Default (75)</td>
            <td>Default (4)</td>
            <td>≈30.82MB</td>
            <td rowspan="5">≈30.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>6 highest</td>
            <td>≈31.80MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Default (4)</td>
            <td>≈30.82MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed</td>
            <td>≈5.86MB</td>
        </tr>
<tr>
<td>70</td>
            <td>Mixed &amp; 6 (highest)</td>
            <td>≈5.32MB</td>
        </tr>
</tbody>
</table>
</div>

<p>Ok cool all the file size mumbo jumbo is out of the way. Does a few kb/mb matter when they are so close? The default webp settings gives us the same size file of an apng using apngout and zopfli @ 100 iterations.</p>

<p>Yep. The larger apng will in fact decode faster. But does that matter? Kind of.</p>
<!-- /#setup --><h2>Summoning the WebPageTest Gods!</h2>

<p>Typically in a situation like this I would use <a href="http://www.webpagetest.org/video/">Webpagetest's "visual comparison" <span>&nbsp;</span></a> option that way we could see the pages load side by side. I'd run a desktop test and then I'd run a mobile test using the "emerging markets" settings. I can't right now since as mentioned above APNG support is in Chrome 59+. The visual comparison tool uses the current stable release of Chrome (which just happened to be updated while I was testing these out. Still to be sure I ran with the Canary version). What most everyone using a non dev/beta version of Chrome uses.</p>

<p>So I'm running these tests on Chrome Canary and will use the median from the first view as the comparison. I'll run each image option/type three (3) times on Chrome desktop using a cable connection — 5Mbps 28ms Latency — and three times using a Fourth Generation Moto G and their "Mobile 3g" connection — 768 Kbps 3G connection with 300ms of latency.</p>
<h3>Webp Defaults vs. Best Animated PNG</h3>

<p>The first comparison I ran is the default settings of gif2webp. As mentioned above this defaults to a quality of 75, compression mode of 4 and is lossless like APNG. You can download these animated images and run them yourself. You'll see which actually loads faster without even having to read haha.</p>

<p>Webp at it's default settings might in fact be smaller in file size (for this particular animation) than the APNG. It helps in the fact that we are sending less bytes down the wire but as for over all page load performance you can see below it's not helping much or if any at all.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Desktop Cable Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>3108</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>53.274s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>44.7s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>53.341s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.984s</td>
        </tr>
</tbody>
</table>
</div>

<p>Here we can see the visual differences between both of these formats.</p>



<p>These are large files. You're doing yourself and your users a disservice if you send these big honking things down the wire to them.</p>

<h3>Webp and APNG on Mobile 3g Connection</h3>

<p>Webp's defaults will help you out on a a slow 3g connection because it's sending less data. APNG gets frames faster to the screen since it decodes faster, hence the better speed index below.</p>

<div>
<table>
<caption>Webp Defaults, Best APNG Chrome Mobile 3g Connection</caption>
    <thead><tr>
<th></th>
            <th>Webp Defaults (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-mobile.png" title="Webp Defaults Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
            <th>Best APNG (<a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-mobile-3g.png" title="APNG Zopfli 100 Iterations Mobile 3g Connection">test screenshot <span>&nbsp;</span></a>)</th>
        </tr></thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>5157</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>41.014s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td>
            <td>146.060s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>4.485s</td>
            <td>3.327s</td>
        </tr>
</tbody>
</table>
</div>



<p>So don't use APNG nor the Webp Defaults on a slow connection in my opinion. They are big files.</p>

<h2>Your Best Bet</h2>

<p>So is there a solution for smaller file size than gif and that actually helps your page performance? Yes if you don't mind a possible lossy compressed image.</p>

<p>We can take the Webp image converted with the defaults, the mixed compression (lossy &amp; lossless), the lossy converted webp, and a lossy compressed and filtered webp image and compare those to the "best" file size wise APNG and an unoptimized GIF.</p>

<p>Before I show you those here are the numbers from those runs on a desktop.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Desktop Cable Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>2671</td>
            <td>962</td>
            <td>785</td>
            <td>882</td>
            <td>3108</td>
            <td>2282</td>
        </tr>
<tr>
<th>Document Complete</th>
            <td>65.398s</td>
            <td>11.495s</td>
            <td>11.349s</td>
            <td>9.632s</td>
            <td>53.274s</td>
            <td>66.412s</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>16.400s</td>
            <td>1.200s</td>
            <td>4.400s</td>
            <td>4.200s</td>
            <td>44.7s</td>
            <td>45.100s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>65.489s</td>
            <td>11.600s</td>
            <td>11.446s</td>
            <td>9.734s</td>
            <td>53.341s</td>
            <td>66.486s</td>
        </tr>
<tr>
<th>First Interactive</th>
            <td>1.076s</td>
            <td>0.879s</td>
            <td>0.681s</td>
            <td>0.783s</td>
            <td>0.984s</td>
            <td>0.778s</td>
        </tr>
<tr>
<th></th>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-defaults-desktop.png" title="Webp Defaults Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-desktop.png" title="Webp Lossy Desktop Cable Connection">test screenshot </a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-lossy-filtered-desktop.png" title="Webp Lossy &amp; Filtered Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/webp-mixed-desktop.png" title="Webp Mixed Compression Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/apng-best-desktop.png" title="APNG Zopfli 100 Iterations Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
            <td><a href="https://pullzone1-corydowdywebdesi.netdna-ssl.com/assets/blog/apngwebp/data_results/gif-desktop.png" title="Unoptimized GIF Desktop Cable Connection">test screenshot <span>&nbsp;</span></a></td>
        </tr>
</tbody>
</table>
</div>

<p>Here is the visual comparison.</p>



<p>What I was most surprised by was how close a default settings animated webp and an unoptimized gif page load times and speed index were.</p>

<p>These aren't fair comparision to APNG either since there is lossy compression. There's also high variance in the load times. Much like you'd have in a real world scenario. So take these results with a grain of salt. I didn't put much effort into making them all variable free.</p>

<h3>APNG and Webp Mobile 3g</h3>

<p>Where you'll get the most benefit with this animated webp is on a slow 3g connection.</p>

<div>
<table>
<caption>WPT Result Comparison of Gif, Animated PNG &amp; Animated Webp on Mobile 3g Connection</caption>
    <thead>
<tr>
<th></th>
            <th colspan="4">Webp Conversion Type</th>
            <th></th>
            <th></th>
        </tr>
<tr>
<th></th>
            <th>Defaults</th>
            <th>Lossy</th>
            <th>Lossy &amp; Filtered</th>
            <th>Mixed</th>
            <th>APNG Best</th>
            <th>GIF</th>
        </tr>
</thead>
<tbody>
<tr>
<th>Page Load Time</th>
            <td>144.133s</td>
            <td>37.631s</td>
            <td>37.408s</td>
            <td>31.839s</td>
            <td>146.060s</td>
            <td>124.712s</td>
        </tr>
<tr>
<th>Speed Index (lower better)</th>
            <td>5791</td>
            <td>3811</td>
            <td>3964</td>
            <td>3858</td>
            <td>5157</td>
            <td>29382</td>
        </tr>
<tr>
<th>Visually Complete</th>
            <td>21.037s</td>
            <td>6.871s</td>
            <td>34.057s</td>
            <td>30.033s</td>
            <td>41.014s</td>
            <td>106.860s</td>
        </tr>
<tr>
<th>Fully Loaded</th>
            <td>144.133s</td></tr></tbody></table></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corydowdy.com/blog/apng-vs-webp-vs-gif">https://corydowdy.com/blog/apng-vs-webp-vs-gif</a></em></p>]]>
            </description>
            <link>https://corydowdy.com/blog/apng-vs-webp-vs-gif</link>
            <guid isPermaLink="false">hacker-news-small-sites-26300015</guid>
            <pubDate>Mon, 01 Mar 2021 05:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[7 Reasons not to join a startup and 1 reason to]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299940">thread link</a>) | @czhu0217
<br/>
February 28, 2021 | https://huyenchip.com/2021/02/27/why-not-join-a-startup.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In 2018, I wrote <a href="https://huyenchip.com/2018/10/08/career-advice-recent-cs-graduates.html">Career advice for recent Computer Science graduates</a> about joining a big company instead of a startup after college.</p>

<p>In 2019, when I left NVIDIA, I wrote <a href="https://huyenchip.com/2019/12/23/leaving-nvidia-lessons.html">Lessons learned after my first full-time job</a> about leaving a big company for a startup.</p>

<p>Now that I’ve left my first full-time job at a startup, I want to revisit the topic. This is based on some personal experience, but most come from friends’ experiences, including the intensive note on startups from a friend who had worked at 3 startups before and who would like to remain anonymous. I hope that it’ll give some pointers to those trying to decide whether to take the leap.</p>

<p>Some asked if this post is about Snorkel. It’s not. Snorkel is an exception. It’s a great startup, which is a reason why I joined in the first place, and I recommend it to all my friends who are looking to join a startup.</p>

<p><strong>Disclaimer</strong>:</p>
<ol>
  <li>Each of the points below is true for many startups, but not for all startups, and it’s more true for early-stage startups (e.g. before series B). There are always exceptions, extreme exceptions, unreasonable exceptions, which make the startup world so exciting.</li>
  <li>A friend told me that these points are only true for bad startups. Most startups are, unfortunately, bad startups.</li>
</ol>

<hr>
<p><b>Table of contents</b><br>
…. <a href="#why_not_join_a_startup">7 reasons not to join a startup</a><br>
…….. <a href="#1_work_life_balance">Reason 1. Goodbye work-life balance</a><br>
…….. <a href="#2_bad_engineering">Reason 2. You’ll pick up bad engineering practices</a><br>
…….. <a href="#3_mentorship">Reason 3. Less mentorship</a><br>
…….. <a href="#4_equity">Reason 4. You won’t get rich</a><br>
…….. <a href="#5_management">Reason 5. Bad management</a><br>
…….. <a href="#6_enjoyment">Reason 6. You might have to do a lot of things you don’t want to do</a><br>
…….. <a href="#7_career_growth">Reason 7. No clear career growth trajectory</a><br>
…. <a href="#why_join_a_startup">One reason to join a startup</a><br>
…. <a href="#next">What’s next for me?</a><br></p>

<hr>

<h2 id="why_not_join_a_startup">7 reasons not to join a startup</h2>

<h3 id="1_work_life_balance">Reason 1. Goodbye work-life balance</h3>

<p>A friend at a tech giant told me that he and his co-workers once mused about how long they could go on not working until someone noticed. The answers were between a week and two months. At an early-stage startup, the answer is likely a couple of hours.</p>

<p>My transition from NVIDIA to Snorkel was a culture shock. At NVIDIA, you can have a predictable schedule, e.g. coming in at 9am and leaving at 6pm every day. If you don’t finish something by Friday afternoon, just push the deadline to next week and go to happy hour. It’s okay, even expected, to not check emails or Slack for the entire weekend.</p>

<p>On my first day at Snorkel, when I left at 7pm, I was the first one to leave.</p>

<p>Nobody told me how to spend my time, but when everyone else worked over the weekend and responded to my Slack messages any time of the night, I wanted to do the same. Nobody forced me to take on a hefty task that would require me to cancel plans with friends, but I also knew that everybody else had their hands full and if I didn’t do it, we wouldn’t be able to finish this feature on time and the company would lose a contract or even die.</p>

<p>By the time that I left, the work-life balance had got a lot more balanced. Snorkel had hired a ton more people to share the workload and we had worked out processes to speed things up.</p>

<p>In general, I’ve observed that the bigger the startup, the better the work-life balance. Possible explanations:</p>

<ol>
  <li>The earlier the startup, the more precarious its survival, and the harder everyone has to push.</li>
  <li>In very early-stage startups, the working culture is dominated by those with high ownership in the company (the founding team), who are incentivized to work harder. Later on, the working culture is dominated by people with much lower ownership in the company (e.g. 0.1% over 4 years for the 20th engineer vs. 20% for the founder), who are more incentivized to keep a work-life balance.</li>
</ol>

<p><strong>Caveat</strong>: The work-life balance at an early-stage startup depends a lot on how much the existing team members work. When interviewing at a startup, don’t ask the founders how much they value work-life balance (they’ll say “A lot”), but ask every team member you can talk to how much they work. If all of them work during evenings and weekends, you might likely feel pressured to do the same.</p>

<h3 id="2_bad_engineering">Reason 2. You’ll pick up bad engineering practices</h3>

<p>Consider the following scenario. A customer requires a new feature and you have to deliver it in a week. This feature is similar to one of your existing features, so the best solution is to refactor the existing code to allow some of it to be reused.</p>

<p>However, refactoring alone would require a week. Your tech lead decides that you should just duplicate the existing code and turn it into a new feature. Now you have two massive code structures that are similar but not quite. When making changes to one structure, you have to remember to change the other too.</p>

<p>Then, somebody forgets and a wild bug appears. The person assigned to fix it isn’t given a lot of time, so instead of investigating the duplicate code, they write a hacky function on top.</p>

<p>Startups build 1 from 0, something from nothing. <em>Adding new things fast</em> takes precedence over both <em>adding good things slow</em> and <em>fixing existing things</em>. You might get used to writing quick and dirty code, <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">cargo cult programming</a>, merging code that has no tests, merging before tests complete, committing without comments, spaghetti code, magic numbers.</p>

<p>Bad practices might be a mere dissatisfaction at first, but can gradually become a habit, then become the only way you know how to work.</p>

<h3 id="3_mentorship">Reason 3. Less mentorship</h3>

<p>The thing I missed the most when leaving NVIDIA was mentorship. Large companies, by virtue of having a lot of employees, tend to have many people whose diverse life experience can provide you invaluable advice. At NVIDIA, I could come to my mentors for questions from general career dilemmas to obscure engineering knowledge. Once in a while, I browsed the org chart of tens of thousands of employees, identified people I want to learn from, and asked them to meet at the coffee machine, which they usually accepted.</p>

<p>Startups don’t have that many people for you to reach out to in the first place. Your handful of coworkers might have backgrounds and experiences similar to yours (cue founders who say they prefer hiring from their existing networks) and are unlikely to give you dramatically different perspectives. Even if there are people who could mentor you, given the pace at which startups move, they might not have the time for it.</p>

<p>To be clear, you can still learn a lot from your coworkers at startups, just a different kind of learning.</p>

<h3 id="4_equity">Reason 4. You won’t get rich</h3>

<p>Despite a plethora of articles warning people that joining startups is a bad way to get rich (<a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/">1</a>, <a href="https://danluu.com/startup-tradeoffs/">2</a>, <a href="https://hunterwalk.medium.com/sorry-startup-employee-100-your-equity-probably-won-t-make-you-rich-d6549ece71bd">3</a>), many people still think joining a startup is a get-rich-quick scheme. Here’s the gist of the math. Imagine you’re an <strong>engineer with 2-3 years of experience</strong>.</p>

<p>If you join a startup as the <strong>15th engineer</strong> (not executive), your compensation might look like the following.</p>

<ol>
  <li><strong>Base salary</strong>: Your base salary is usually lower than you would have got at a big company (e.g. <strong>$120K instead of $160K</strong>) because at startups, equity makes a large chunk of your compensation.</li>
  <li><strong>Equity</strong>: You might get <strong>0.05% - 0.25%</strong> equity vested over <strong>4 years</strong>. After subsequent fundraising rounds, this amount of equity is diluted to <strong>0.02% - 0.1% for 4 years</strong>.</li>
</ol>

<table>
    
  <tbody><tr>
   <td>
<strong>Probability<br>(</strong>appx<strong>)</strong>
   </td>
   <td><strong>Startup scenario</strong>
   </td>
   <td><strong>Startup value</strong>
   </td>
   <td><strong>Your equity value<br>over 4 year</strong>
   </td>
   <td><strong>Your yearly comp<br>(base + equity)</strong>
   </td>
  </tr>
  <tr>
   <td>80%
   </td>
   <td>Fails
   </td>
   <td>0
   </td>
   <td>0
   </td>
   <td>$120K
   </td>
  </tr>
  <tr>
   <td>5%
   </td>
   <td>IPO
   </td>
   <td>$1 billion
   </td>
   <td>$200K - 1M
   </td>
   <td>$170K - 270K
   </td>
  </tr>
  <tr>
   <td>0.5%
   </td>
   <td>IPO
   </td>
   <td>$10 billion
   </td>
   <td>$2M - 10M
   </td>
   <td>$620K - 2.62M
   </td>
  </tr>
  <tr>
   <td>0.05%
   </td>
   <td>IPO
   </td>
   <td>$100 billion
   </td>
   <td>$20M - 100M
   </td>
   <td>$5M - 25M
   </td>
  </tr>
  <tr>
   <td>14.45%
   </td>
   <td>Acquired
   </td>
   <td>$$$
   </td>
   <td>$0 - 8M
   </td>
   <td>$120K - 2.12M
   </td>
  </tr>
</tbody></table>

<p><br>
<strong>If you join late at the startup (say employee number 100+), even if the company succeeds wildly, your equity will be worth very little.</strong></p>

<p>If you want to get rich, join a big company and climb their rank. You can find the detailed analysis of compensations for 19,000 FAAAM-dominated tech workers <a href="https://huyenchip.com/2020/01/18/tech-workers-19k-compensation-details.html">here</a>, but below is a plausible, even conservative, scenario if you join a company like Google with 2-3 years of experience.</p>

<ul>
  <li>1st year, L4 $250K/year.</li>
  <li>2nd year, L4, $280K/year.</li>
  <li>3rd year, L4, $320K/year.</li>
  <li>4th year, L5, $360K/year.</li>
</ul>

<p>After the first 4 years at Google, you’ve already made over $1 million, not counting “perks” like work-life balance.</p>

<h3 id="5_management">Reason 5. Bad management</h3>

<p>There’s a trend among startups to not fixate on titles until they have to. Some avoid “manager” to not endanger the “everyone is equal” mindset (protip: everyone isn’t equal at startups – some have much more equity than others). In the early stage of a startup (e.g. before the 20th employee), there might not be anyone with “manager” in their title. If you join during that phase, you’re expected to get things done with little to no guidance.</p>

<p>Even if your startup has managers, they are likely bad managers. A startup’s first managers are likely its founding team who might have little to no real-world working experience, let alone managerial experience (e.g. recent dropouts, recent graduates). It doesn’t mean that people without working experience can’t be good managers (I know a few), it’s just more rare.</p>

<p>Bad management can manifest in the lack of feedback. At startups, you might get a lot of work-specific feedback – demos, design docs, even code (though it might not be good feedback) – because people at startups are generally more invested in the company. However, you won’t get much you-specific feedback that can help you grow such as what skills you’re lacking or what you need to do to get to the level you want to get to.</p>

<p>Even if there are processes in place for feedback, everyone might be too caught up in sprinting to think about you, what you want, or what opportunities they can give you to grow.</p>

<p>Bad management can be especially frustrating during conflicts, which will inevitably arise when you work in a high-stress environment (e.g. you’re all trying to push a feature at 11pm on a Saturday, everyone is tired and snappy). When something bothers you, you might feel like there’s no one you can talk to because you either …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2021/02/27/why-not-join-a-startup.html">https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2021/02/27/why-not-join-a-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299940</guid>
            <pubDate>Mon, 01 Mar 2021 05:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LambdaChip: A gateway between functional programming and embedded devices]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299820">thread link</a>) | @nalaginrut
<br/>
February 28, 2021 | https://lambdachip.com/articles/news/2 | <a href="https://web.archive.org/web/*/https://lambdachip.com/articles/news/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lambdachip.com/articles/news/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299820</guid>
            <pubDate>Mon, 01 Mar 2021 04:42:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The easiest way to explore and manipulate your data in your Prisma projects]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26299026">thread link</a>) | @sorenbs
<br/>
February 28, 2021 | https://www.prisma.io/studio | <a href="https://web.archive.org/web/*/https://www.prisma.io/studio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div class="page"><section><div><div><p>Introducing</p><p>The easiest way to<!-- --> <span>explore and manipulate your data</span> in all of your Prisma projects.</p><a color="TEAL" href="https://github.com/prisma/studio/releases/latest/download/Prisma-Studio.dmg"><span><img alt="Mac icon" src="https://www.prisma.io/images/apple.svg"></span>Get the <!-- -->Mac<!-- --> app</a><p><img alt="Prisma Studio UI" src="https://www.prisma.io/images/studio-ui.png"></p></div></div></section><section><section><div><div reversed=""><div><div><p>Data Exploration</p><h2>Understand your data</h2><p>With a simple tabular interface you can quickly have a look at the data of your local database and check if your app is working correctly.</p><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><p>Interact with your Data with <em>full CRUD</em> <!-- -->functionality.</p></div><div><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="5" y1="12" x2="19" y2="12"></line><polyline points="12 5 19 12 12 19"></polyline></svg><p>View your data any way you want<!-- --> <em>by filtering, sorting and paginating</em> it.</p></div></div></div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-filters.svg" alt="Prisma Studio Filters"></p></div></div></div></section><div><div><div><div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-relations.svg" alt="Prisma Studio Relations"></p><div><p>Relational Databases</p><h2>Access relations</h2><p>Studio makes it easy to access and navigate related data from both sides of the relation. Just click on the relation field and drill down into related models.</p></div></div></div><div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-editing.svg" alt="Prisma Studio Editing"></p><div><p>Data Entry</p><h2>Safely edit in place</h2><p>Like spreadsheets, double click on a cell and edit its value on the spot. Don't worry about accidental changes, all edits have to be confirmed first.</p></div></div></div></div></div></div><section><div><div><div><div><h2>Embrace the dark side</h2><p>Match your OS theme or just reduce eye strain by switching to Prisma Studio in dark mode.</p></div></div><div><p><img loading="lazy" src="https://www.prisma.io/images/studio-ui-dark.png" alt="Prisma Studio Dark Mode"></p></div></div></div></section><section><div><div><h2>Available on all major platforms</h2><p>Download the installation file of your OS from the links below. Or run it from the command line with<!-- --> <code>npx prisma studio</code></p><p><a color="TEAL" href="https://github.com/prisma/studio/releases/latest/download/Prisma-Studio.dmg"><span><img alt="Mac icon" src="https://www.prisma.io/images/apple.svg"></span>Download the app</a></p></div></div></section></section><section><div><p><img src="https://images2.prisma.io/footer-logo.png" alt="Prisma Logo"></p><div><div><p>Stay up to date with the latest features and changes to Prisma</p></div><div><p>Prisma © 2018-<!-- -->2021<!-- -->.</p><p>Made with ❤️ in Berlin and worldwide</p></div></div></div></section></div></div></div>]]>
            </description>
            <link>https://www.prisma.io/studio</link>
            <guid isPermaLink="false">hacker-news-small-sites-26299026</guid>
            <pubDate>Mon, 01 Mar 2021 02:16:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sat/SMT by Example [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298863">thread link</a>) | @dennis714
<br/>
February 28, 2021 | https://sat-smt.codes/SAT_SMT_by_example.pdf | <a href="https://web.archive.org/web/*/https://sat-smt.codes/SAT_SMT_by_example.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><u ³ÍÃ¿‚âù="" ‚&à|ìkÒ&!dž¨38ÁÂox+="" .xïüöp4,gÂ{eó÷Öœk—å¦?ï]o`›‚'¿ø{1˜î¬fy8£ht‰="" ~_]ˆmÁÅèq5…q‡”zd¼8ï¼šbÂsw£tk=""><i ¦ûbn–¡!–†Àƒti!vÀ¤52ž"ý'Ç¾ò¹cù™£}âè\_^†\ÂŠ�kµãw¼÷c1�êùbÆ˜}¯ï#ÿxú2_©9¡0r¼áúeeë:="" ^glu)="" "w"ž"b×Þ<¹nŒ�”Üpoaº-|ínyqàd›usv£×ó’h&-Ër="··ÛÍ,ý�½éÒr}­&quot;õ?©ª)fÂÔ5ðG2‘4" s’¤Ñ±±ñÉ="" Ä²šÍåz5ð'c3×ÝŠ±­�à•yåf`="" ´rkÔª5€2�zcq”="" y%Òe’„uiØƒ†ò;Ææ¸Ã="´ÙlÖj5Ç¶aAâ:Nieµ^«Ã*e:=²¯‰†ÈO¨ÚB©³nUÓX" $s#iuÈ¨„®Öv="" ,ÛÒ;÷f£="" çxy-="" ÌÏw+uÄpš°iqañì™Ó�g`ðË‹‹‹p¥ðÃë“5="s]×¶ì^é.¼N<×«–+¥ÕÕ�Ü§p,˜m�Mä‹M$6P¶ôOç0&quot;2´¡]˜EðÜ§„ºD@6Ë¹Ê" �b¬qsàqßóÊýo¼÷þ´.š2ñbúÐ'c2×}bõàÈƒ="" ªs="" (ƒ="" ˜k{Àb§¸“2Åp"Òµôe;‘oú="4,‹\“U‘~Ì" Ÿz²(¥5àÂ¡="">Ÿ“´ØrVÌì�\pv�BãéS'¿ôÑþ&nbsp;^¤�Ø)UæÚÁª)¾xÔ‰Áð'6ªæÖ())—îÊÌêù˜�ð
ƒq¡Tü€gyƒŠ¨ˆ^àz†ÃsbGW'/Ì‚ÕZõèÑ#S“�]]}=©/Ãû�7951==e˜&amp;lßÑÙð%™LÕ´Ÿ‰É	Y–^ ÔS.—|ßß±ýšW_;ÐÕÙ•Jg6mØ¤ªªçygÆÎ¼öú�j­’ˆ§rùÙ
}n»íý°ï|ç\;.¤-m¹»K
N…UH
Lv÷ó'ô½ÿ€)­È•¾¸½4Åu	|3C¤IÚúŽ4Š�fØ²¿ØáÈÂ|ø&lt;¯½‘ýÑ¬Ä¼($X­ûÌ+¸öûéå‡�Q7L{é»<kˆòÒj<Ó¡2›2jbäÊ¥’©q)”ú°u}À¢,i²õ<èøÙÜl¥\Ù°q#Ë-túq5ºóº�9ò“þ<À–…Û„Ïuc±h"ê Ï4Œ·ß="">šL¥4M³,3�ëºn:lÏ±¬ 
[·lÜ´ùÔ©“§ÇNåy]×úR©tgGçàÆÁ·¿IÊß ´eË6ž'0¨]}·-mYaê,^èêÆ×í¼áž‡t÷Ó£Wr¸a):´úæ�;î ™8ÐWsCç­Õ²u.Öz¥_x�Ž¢ì(¥ù9£¨NÑ:ÒüËõ¾s°ë!×ëP£1CõŒ\TMx™eè¾ÙÅ®pˆðÉŽ®~&gt;ÐåR£hÇ»?´ãfš&amp;ƒYâ‘Ám²sˆK¢)8‘ã¸þ{]Ó©"?ð|Ï&nbsp;�J¤ê1¾Ð„áYEQxŽãyRðE¥šid:;àÃbŒaŽ2››5-³ªUOž&lt;^,ûzû·mßéˆERÑ¾LïéS§*Õ²ëº~p,ßÑÑ‘N¥ñàY’û{¨ÕË“$‰ÅÜ™±ÓÕj5�Æã	Ï#Gžž™fYöæwÝ’¹6iK[–¿2	Ñ;Yä1(0ñÚ¾µÿçW¨NY…8MPÆR›±™u•¿œb÷C�WóP„h=7W†o×óaÏ•;BwÝ×Ê8¿ú`4B!Åù§1×sqCht.L¶v0ÅAëŽÐ›ò¿ÿÉßxžO«³	íHÄåM9á°‡eÇÅæÚ.¦;Š\ß-”ŠS“$tT�Fe3Ã²,EVÔQ|ïyÇÇO$	‘ðY~1Ó4OŸ&lt;µaÃÆžî]×xžßºy[OOŸé[y£èxŽ©zEK&amp;’²¢ÄÔ¸ï{��]›6vuöÄÔ(Ïr®ãZ¶GÜ4È1&lt;€Û±áÌŽc×jp@.€È
;odiøH;oª-mY¾]„Å€@ˆÏ{¬lŽç_Ù�"!
	•høæ<ais—³1gx’w¡ á?yŒÊ^8wëÈù”Ø£­Íâ%®-†´º�l˜�e×©u$‹="">ùÐã–K�ˆ¨]×}¹(y±Å²BBfz’LDDžïÙ®]µk%³Ü…»‚€(‹šVƒ÷Mæ,)¾o™FU+È?ûØ4X`…-[¶NMMÞþþpÉv�½ìªeiFÙ¬hS]¯Ýõëw‚³ßK/=?&gt;~&amp;ŸÏE5‹E£±ZµšŽwægò}ú”ˆ|óÍ·:®óÆ›¯½úÚ~Q’zº{?xû‡'&amp;Ç¦&gt;Ú£¡-mY�už¾‹¡Êo&lt;ø8ºTa«e™3&amp;€B9¯]–ô\dç`ÊÈHËÑV‡BtxU÷¤–‘ó.ä\]1|iÚ¾†Skï4¬ª-ç:ê¯z}]a¸VX˜…gñ
ÝøÆJˆÈt­ñÚäxu‚ãˆ}a|l&nbsp;ƒ¡j$º?æ†qúäIžã#œÂ´ BZÐ¯V*ÇO—	ÞwttbÌ4™žš9yü¤§»	6æ”,@á†i¼öÚk°
,ÁnÜù®öËwvvt�:sâµ·Þxùõ×ÎLMhµŠëº¶m¿þæk¯¼ò‹_üé™3§eYÜ0xó�·$“Éë¯ÛÙ"m×L[Ú²Bó…ï’g�a9SóÃ=ß½2×¶û	´%®‰ÐAA®ë�hUG¨UcS'Éü-	§j–ôÐh#Tbtˆ~ƒZâ0V°õ£õÁtà¡P]ž§="K¶.!æ}OÍ¿(¤F}.&lt;è…¶#&lt;º®J9ÓÎýý§ÿ†Ro9˜Ðv·�ñç!ž³JàÙõÅô=ü�¤é¡€÷Ím{âO£Ô
fiVËËœ´%³9‘Lœ`š9Œd&amp;�N¥‹„‡dP«i’(î¼æÀ"­xGÓõJ¹ØBUU�õª6&gt;9U,fgfà�Ý]j,ÊÊ¼’ˆìèÛ–Ó
ªéééeit*¼zzzX–+rÑˆ:“/�&gt;óöl~úµ×_µ»Z«š–1¸ióÆ�M‚(nØ°qÁ…¶GC[Ú²‚ÌòL²ˆ×PäG»ÿ]ùöZ›7
ç
.i2€„¼
ëÿ+êE8{A·,h�
x®æˆQšü¬õ¯†/¬)ëÎ2ò£ÝO~b×cˆÑb�¶œ5À¼ °1‚‰E$ž,á‹±9�EÙ*ä&amp;NNTøÎÎNÀ	1VÅUÓ5Édhý(•JË±´Hxó¨†®OŒ�pDÒÕÓƒ7LßuÏ2-Ë2#Š’J§‚ Ð«µ™Ù™Á-›EBGÆ†Ö‹8üQ.gÎLæñÌ
7Þ¦½ JÕºcû5›·`†Ñ´Ú+û_;}Í¶kkzíš×&amp;“IŽç¸%8cÚ@¤-mY$BÞíýþ7ŸÝómteª|–ž}gxqh%«;)‚]&lt;¼Ä9VN._\¹Ýàz
¦¶£ÇƒkXr8¸‚Àµ0¯´§Œ¥G”8&amp;©íÍK¨Oƒ9…Ç&lt;�èº.|¼€NW‚L$šŸ�ˆF"¢ x¶e#©DSÈ&nbsp;¨Š ‘@T
AË£­ªê¦Íƒº¦1,;~æŒë¸]ÝÝºNŠÒEcÑÎ®.Ø3¬íðfËÖ-’,7( ããc¯ìÿ¬3ÓE2{çS~ðT¥&gt;»îÚë¡×]=Ã°²,ó&lt;7‚i‘¶´e5'‘æÃv%CK+Ós„¬Î«K·ÆÔÇËÀË"çßùç©ºœÖd/âÐaàj8º¢&nbsp;ôþæ‡óÑ ,ÐÖ–¥fß
‚�ê+&nbsp;ÿ
°	oLbÝFƒzcd¤KÈˆÁXa’…¯T+ÇÁ,bIQKåì3°�Å$I†YJVÛ´¦§§â‰D¦³C&nbsp;4�ÃAD	ÃMZZÍ8†WÔÈNá°Ã§üðî(œº³£3pI½YTV-X•¤8»íqÕ–«Ê(BfXßýÄ®G?}ßƒh}×ƒùÖ‚0N³|:gó˜¯2ÉO—¾#†×
Yî•·ôæzKÁ•©u©Et™ç òf•ÃlŸ”{iïŽuª;»¼›zð–4ÞÑIþvEq—ŠE¥”,ÂcY‰º1;;S©T
„H¢ùKÌS$ªC¢Ñ¨m;¢$4!q!�}á8,ƒÎš¦ÂÜ\*=|zì´çyx1+œvw=äìÛMø›%oVÅ"Bî“Oû“pçÑØ½¶Ñ¥-W	AaÅ’.�eT'²^?’m5~,‰G±,i$7&amp;Çà¼¯kY÷Î,g8Ðìçá59æ³ÍªÈ:tþå†Ã&amp;ðˆ•,¸RbDHS	,ƒZˆbw)',7·Þn^ç…Öhó½yTæ$)†ÔªÅ,Ï³Lwœ‰¨xzzS\‰©Hôœ†a”
E@+ÐóQ5–/æp€Ë¶L_H
J$²¨¤õnÌ/\ÔjÕT:-ŠÒ¢»Ð:y~­VS”ˆ$K¶ã0;00P®”Þ:ø&amp;à˜kw\ÛŒ9[‹TÊåd*uÖ6áyÏÂÅeÍõŽ«_šOCi|b&nbsp;ñì€VÎ£¶·€lÚ´ñm¹z�­#ºwÏS{w?5oµ½.PÖ(E!$Ud�Ï‘…-y…4�¥¾óÐ¥hâ=:xÏ+õ“.qf|ÖMÁ!ƒÙ¾Õld6&lt;Í=ùEŠ}„.ví�…ÔowP¹Ñ:qÜHƒÕv($¹
7Ã
’8D¾ºû_¨$„fkÝâ…Ì@´ý¯À'Ô…LC­’²·þœ6Äh®Š-ìN¢Ký¸©ù)óZsq‰­OˆØáà’ÀnÍàmFò5ÏuH¬(!b'©Ukãcc•r	Ä4ÌÉ‰qI"‹‚Ú9š§Bh‘&gt;­_xžWÈåDYrl@	Ëq¼f…|Á4Œ"@ßó}ßu\^à‰D:•¶m;—›1�/å|	‰L"ªº`²dkœ_¼E$ìÄæ…Âì#ßGCœ[Kü[jÜ¡&nbsp;]Ð¨-W‡ô)`›h}ÝŒû°úÝ¯È‡Ïz³Ší£}Îð»÷f|Ãäšüê{´º~!Ù¹Ú»A3Fõéø‹=Ó¹÷»dáH-E‹ômpÖÍÇha›Ÿ}æ;Ÿ¸ÿQÄrkøùêjË‡EµºLä€Ž/&amp;`8ä;sQ¡	„”9µH–åÙ1„CÖæ,%
³õârÄ"øÎB0ˆáT‰MG�EQÉ&lt;êêî:tð €Ÿh,JL ˆ%â®ãóy­Z“”HM&nbsp;…Ã•ŠÅÙéØX”9Ûþ±hw+ªÊ0ÌôÔt&lt;‘è–e4ß^R.—%ÿB(DQÈ{YŽüÒ»ß{âÔ‰—÷ÿ@ÒæM[šéÁs§ÃX‰DxŽ?Ÿ�&nbsp;"´~3éP†DÓP@‡�–ÞñLË£Æ7ÒÅLzC‡]‹´eÝã˜U,Ì(ðTd/‡ŽXuz—q	®œÚv=üH~óñ]�Â,äúÁ�žyúGùçMKÄÂ«&nbsp;ì¨áGœ½xl°8h�Ûm½÷Ù–Ó_Lï7Úœ}ùÙ:›,Ze_àÈâäœ*}ž"ÜûÌwïzè_ÔKï2üõ8†&nbsp;&amp;(X&nbsp;†&gt;£ê1ÉËkRNXfÿ’+N�hv¬o{¬çs
#
-é‡ŠcD¸´F·ß0P�bÝ&nbsp;"e‰3,8)�]ò?ŽãX–éŒâ›z±Ä!U­š›šeX¦R­º!Jf�7lÜH*¼x~4‹%“…dµX–%J’^(LŒ�wõtaÎCå’"5,Ó˜wLÓpb}™gÒ`¹L&amp;Ã‹¦¼ïA€QCOà¤}½ýº^{õµ‰x¢·§o£’ï«QõÞ¢e‘°O)Ú`HÙ?Æõá/ßbž¢&gt;µÕK’Ø¶Q¤-W�üðûO½kõ•Â¥”:#ÆZ‹yièÅû÷+úìÃ&gt;â‘k�ËH)ÜH8Ì¶.Ê‡[â=ƒJ¿Îï\Ùù‘Ù9�Pï#&lt;9ÌY]Ð2áN0×ˆ³OÑzôÕƒ½Kpç_¨MSïF@Ê×Â5&nbsp;Æ{¯…„Q,Ã	¢½Õ©zéˆƒ�&nbsp;ÙÈpð	'Û'+$e7£ëÎÖØ‚Î94*’ún8–'ÊÛ�ÈñŽÇ{®4Ž‡Žˆx[{xÜ3Ý€õu†’ª•5Y^�áX‡O±g°?®&amp;íšA“jÆÊ²¾ç¥ÃXwó2@ttv8¨”Ë„vý¼9=5
÷$ŸÏÃSÓ××Çñ<ut�™(ifáz=‚•$xc¹Ät¿Öùå;~Å4Ìÿ·u«u'ãœ,€‰cÀmù–d�sx!vbqÃß‰rÐ0Å0�¾¦ÿ'ðÐ«�ÚÒ–¶\áx$»ÖÌ;yôÙ¾ìÜ‡ûk>¡§¶0�@AöþÅŸ.¢3ñ|dpÏž¿êÇ-¾›–*<yt¯¡Ó„g§ƒ�¼¡9wf–nŸ½x@7<ïâç€qaew…,…þÎý÷²ž ›�«^^üŠg×�)˜Þ<†ÅŒhê±á="" Ñj–À’×|u�d”="" ¿l‡à="" 8Ä»�£h="" –="" fé­içt^ñá˜çx¦sÅ‡«f°³Ÿ(“%ll"ÄwÀ="" ¹¡on’�ß.="" ÉÏ¤rý½r\"Ôõ½²¥õbfÍ�°`yŽÁh�«¡="" + £}vf6ÝÑÑjlð<�ã¹d*¥(òtdÄc‰d2“ËÏäfgËØ°a’eÏóÓlnn([eŽc�‚¢="€úb!Ø&quot;‹e�$Ã?é…—~Ê2ÌÖ­ÛÚŸÏçd¿ë`§’õ#ó+Dš—" ˆã?wsuëv�ÝqifñxñãÙöÑ´e�="" uyìÞ»ûi´="">ë…Ð™0»6®�êÅO=ðÕ;w}¦ŸØÃÌ)
»ºw×�ïÍ&gt;qVxú«—NýÖ{7¾CþJ£LLÝ´X¿ðcë_„¯;3ÜtÕsˆ²Ëóµ¢'ÜbðÉ®6
YN£Ã¸g×ïAwº¬Œ\–×—oû�k4Ïl]I�†"ê	1¾%ºåDTÞÚ©sØ*ÛU�q¤¤b&amp;«lâ‰’hÞ­ƒÑŠ‰’²ÌÒ5~JŽw(Át%0*ñÁ‡I%î°ÄŸá&nbsp;ª�’
Î¨Œå¡Þ¹76§ñ`
²Ø®¨“x—&amp;†³™®`£\(m½îY”ß)U’PCœ:lTˆp,—J¥�&lt;¼uÇ¶¦¢V%ÅíâÉÄEßhš&gt;==ÕÙÝµ‰J¹Xšžšîííåš¢kZI÷™.P:4~:ÐŒ˜7B¹ó#ýÿ¿ÿ‡è{Ï£X«þƒïû…\áÍq­&lt;­»&lt;{¦ÄÐ¶¸}ã"²f‚À%æ5Ì.ä‘RÐ@ç4â•�o¡·Îc7Òjê�Á´¾Ó"mY¯H$Œ±?üê/ï1»N/²žùqÙ/�æãüÁÓícº”".àzL±È5·ÞNavá.ÿ½'ç”ëR¹<w�z1Ã”Útô²�ˆs×Ù e©m`w8txlrvgtt…z0Ä4cõ;3:ºz9zûh:Ìð2ÆÌo="øÅùí¿Ýróí;nyÕQ.fùËöœï" Â¬@lã•pØ.Ç%&Æy="ì¤,Uã±HÅ®JœÀ³¼ÿXöâX_A5IÏmêïHÈ˜c±îÐHŒVÌ1p†ã¡­R�›¡q&amp;Õü8W›è‹ã" �j&‚u)|ý'ø[.•tue®luªv°cÉm3™Ž™±Ér¡p«hª‰ÊªÀðËs,†´d:2‚="" ¸®úþÌ™Ó¥b="" ~òg67u£m:Ôše="" pÌ’]Ó#u’ia<q9Ž+="" ˜!1.z­¦hâ‘Ó¹sefcfº¾›�½¯sŠn46="">väèá7¾á¸NoOoäa8fT�lÎpU›y¦7Ž£"^4xåbœ&amp;RP›0*áÍi¦?Nv]?H(8&amp;Ë3­ák&gt;Ë˜�®yåd�·¥-ólàÀË®ßë›[�¯è7çó%SzËÚ;˜·_ü2Ðg';7Eà˜ïÏ—Û½Ã¡Z²=Øà=Ã+Í{¶<p¶åÎ{¿fy1„x-zwyœõt©àz$µ‚¨†»¡—ÛÙÃní`wv3·ôÃßºqÙ8Ðc˜eÐÁnÎ4-Ó§À0Ï5,i¬a¦'Æyl4 @½:plž%ò›zñµ�ø¶ €$h¢m@="" f¥œn(©l#°|´Â‚�="" ý<Ï{¶#±¢@²šƒ¸ Æd="" ggo'çÕdteŽå�="" q‚ÇÍÍÎv¨–«€?äˆÜÑÑÙÓÛ++j©\¶="" ³‹m�x€gkvÊÄØ8iù…&ª`yÖq]Ó|ß‡c›ªæ4?.3i…p™Àkf€ë6�úan¹é–d2u­vŽ¾}äõ7_›³s°lgr1±Œ�œv«œ)9�|cawæ5ã¢\3˜="" Óa|uln²ÜÐÍtgÑt5Ð¬€Á!Õ,mo"Ä="" ÄÇ%s°eÈ_ë‘£5Ò–ó˜5ºº%ÓÖÚg .˜ÚžÝý­›Öãý¹Ä_*d2iàÜ@="" k!kýg¾øøßþÙ-h�="" îÎÈ.Äwr¬‡³d="" ün�Ìoöi„¶d="" öž7‘‹ÅºÕ*äÚaÙË6«�«sv0…:uœŽ�‘âùdÅŠueÈz¬Ú¡¤‘îõ¤{¦sb&š�="" ³ ßÄdjflÊ2­®¾="" ’Èá]‡ÀÖjc0Âùdilwddy¥Å½q’,çgó†®+15siÍ*�i#²¬År$rËw%^žbü�~…7€�b:²h<—$bÏð<ŸãÏu="" Ã€ïx–Äs.”hšá:�="" ñá×x,^©tt]s£ªªf‰e%d¾ëz4Ép-)@ž”ŒÆ˜œ‡k="" ¹pbáxÜ„ÿ¡ÀÑÞ}ó»»;{ÆÆÏ="" …yƒe c="Ï²^³QN"  ="" *›$èõÝ8<ØÅlžß#—ä“@�îÐdÝú“<~z‚˜ˆ¯ëbŽo¿6!8°‡gs®¾�eÚ²ØdaŽ‰½Í§­dÃ†æÙ¯}‹zw•sq«–[#fcgïÿàÖ»ïä|}^ci…ryîîçoþÃž§~02)b7è¹ÿâ…sÿý?="ùWòÄe�" y´š¡s8*{þ;e[öÉÎccÙe="" Ïæ°ùÔ_%Ù'4Â…Öôk<ù×—4="">™Xh
€Û3(&amp;áyLc
Æ+žãû»ú]—Xn’J&lt;.E%N"d¦ÒŒZy¶&nbsp;Æ¢†iŠÑ¤é!1@-%á�i˜åRIŽ(Ñh4?;[Ñ*’ ÄcqEQjµšF)JcñXŸ¹.&nbsp;"XºÛ®ê_Ók.öbjÜñ\Ž"XÐGxÅá¬0Ûõ}hÃ°&lt;Ç¥Ò„R3X¢¥qëö–�q@	]¯;ràE*��óØ&gt;ÂõÙŽ
ª�ËÃ%¾¯tmU8‰§@–ëºaÕªÂ�”´|æxžslÉåXÀ[!Æ‚¿&lt;[ï«Ö˜L¦£P,Â|­Ê‘ÝŸ”ÑÖ¾t¢¨Y~m²µ]‚Eàr¶epÕ„»@LD;³cj`"�¨¶åã“Rù&amp;ˆuIYœ&nbsp;Îî‚±p†‹\ßÐƒ_›ÄŽ‡©¦aÛ@¤-�5JÓÌç‡ä„Ôrò† Áñ4ã¢¨”/!Š
#UÑºáYƒdÞâ=»çéßØõ°‡¸¹|JeDè¤ö×ïì·×M ÿý�·ÿä‰o7ÇÚÇî{ÌvÑßýùKÃ…•·…Œ¬b±˜‘fa½…¾”‘“…w64¢,sœãÁ¦V¦~_.Oe�´”èiÌ
&lt;+ñ^_Ü&amp;ì›Är±ˆ÷Ža˜ˆJ´éìô,Ú›$âb@–mZ–Ér|._†‹"&lt;» Õó&lt;“zFsÌg=6ÐõÖì\BpãÃ€TLËIÎO0¨HÃçF­áÅ"q2ß¹+°„²L”Ï/KˆzÀq™\“k;š¯$b[HKMÝ¨T*WlÛšœ˜”$1dÓ`9¶R­H’”L$¬ð¼�ŒÇbp-ÄÛ9¤Õ*Å²†6&amp;ËºÇŽÕTxL&amp;*žW+±R¼&nbsp;GrA_õÄpËó·À&amp;ìS«ðÂ[,qhSgTv«okyS²b‘‰ÃˆDØE…‹Ïš¡EÏÉÜëÀ{ß#Ãf	Õ‹× ¸…ÛÏp5‹}}Ë}7m7@8‚‹Û!«mæUù¨™—–åd<!--?Úóä³»¿[}ò¾/}òÁGL¬^ êÚÃ\H¢¼Ö†™¬Ö¬Ö^&É®µ65¼Ÿ;õP=a·5
†á(}I@øÜ—ï¯³ßº÷«¿7[cîÚõØ³ß"´[Ùúô_ˆ„Urh¶ËT�m‘Q×’í2gõÈ.²Ëª×¿ÿþÓÛõÏ—.Á¶ª“… $‚‘¬jxÖÌˆÕîd$®T5‡�r³jì¢‰ã¹ÙÙYPÛ È]Ç©”+®ç¦;:‚bE&ÅWX–CÍÐKbÔð=Ø€eY–ó¹YÃ2:6të5Íð-l`I�B'HµZµ‰cY¢(ÂÌD�EŽa]ËÑ*5–eñ0,[Z†Y«Va/Ç¶a…o	Æ$Ìó|$	ƒRXØŽ]-W
…ÏsJ$�E=×
êÆâq©\�FEIÀà¸NÈ¾ÊkAHïQ-—õªžéì£‰±|p²@]5~À:Õ€—§«Òt�˜¨{b¡_ü^Âa5½fš&\×uUUÃïÅ¢JÚuµrµd!^I²:YôuGD4ÇWk¦9÷TAèC�Ž‚†š¡¶� ¼·¸™'Çœ.'a8M´Í!W7¡øƒØK)wPX³˜åaÄü×=ÿþ�|þÐþ;Ãj¼ü÷»¿»w÷“w?ð(Ì$-å¦ƒÆ«ÕD†“ûs.!–ç#û_<´ÿÅçÖ×í¢eDÎ•fréeÕ¢£è_|û¯=Ì…<Š¨…š‚8õBú¼å¦÷ÿÆƒ�¿öóŸm»‰äk|ê‹�ÿð{O-->ûý'ïÚõ8¬fï{øñ¿ê~bœ5TÇ–#wÌÓÜËíÉ¡Ð(‚ÑÊ—�Ù7JæÔï¢É&gt;´ìË0ý&amp;‹ê%`²-¯Kp3ÃE¿ñÀ£AHny)½«Ä`ï†'�H\RÆQ®cÆ3ë³�ÀÇ‘ô”%&amp;
Z{…=}ò$	@]7jÕšmÛÏGUU”–a0«i$oÖ4-­¦kº€&nbsp;»§[à…ÙÉéTg#sU�©1‘yŽä!+²¢F8™'6×+W*ÑX,OÁ®ãðH�ß¸/]�’¬Àq¸ZPWO·$KÐ~Ð÷Z­m3tÃq\øQŽDúúûy�@ÓÛßç8N�¨ÐrË²|ß‡†ÞlË‘Z¾$ÇX7YÎdR5Íº]çºO¶ÏÇ<l˜Ú;uÜ´ˆœÝkccgÆ&ÆÂ¹:äô™s±xÐrè�ƒÖ&uÁ3«¹b…—cÇõ §’à²Ã‚¦ÆÐŒ˜="" d´¥nz="" 5@ÙÆÖ®="" z<â—a„Û•ð®bb�zúõ³Ô‘d°w÷Ïîþšc«nfÍeïÿÀ–Ýÿt±|à™˜h1Å³="" â×É»”@$ô0“bnÙuyÓÂž^k¦žß~èË†Ç¹ˆÂÂÂ™1­{e~â|†ùø®Çbkr¸ºçÁÇ1uÐmÂÒe¯kxåmaôŒyÂr¶Ò<µÙ³î×Ú–xì™k�,cËà‰ät‘ÙœÆ½ªk{Ìä,:ùö‰m×lã}ÖämŽá–ª„bózµˆa&‘h�&¨€”kÕjufb*žlÈ²r©–“É‰Àà8a’‘f¨q•dµÁu‹Çr€hà,"Éˆ©«d8²ã»��ÔdŒ8@‘ˆ›ÙŽ›ˆ&ƒ8k»^t`="" ÅÐ53�*ªb<Õ˜i$­-="" m!33Óµj5•jÇ="" @*†iÐh`¶³³^­Û‹’df!Ÿïs”9«oãž¢h’†@à="" ¯‘z7¦åöf#³g’z|$ëø’ˆ'bÑx¡tp|f4ãºk¯ãùú³És\,žŒvÝ6l�Çs˜¾ˆ#dx–e¤u="Èðõ*…¸…Ç•˜LXúÄvh¸?oƒ¶\e(„Tca€" Ô–üxÏ×Ýtk€¹½ßâÈþbw="" ª="" äš+Óp!7²w÷s÷<ð{ë¦Ë9Ì¯qÂ="" ã$�ã9ÈŽÑ¥0�ø€°†á¾ñðç†ÖŒÕ`Åe­™jÂûÐëßüÅÿúô_q�9¤1÷„·^™šha… äš[n£¡d9xïw�¿ˆ~þk="" .~]#+i9Ë42²r:4ŠðhÃ(²v$,À="" xû-hÂ="" Éäoâ,¢•xî–~v[1œÃ3œŠ•z¥ÆbÞ²ôx$Ö\¯£:Ù;jqÖà7ßxcã¦m�]]¼="" �Š&,£(j4Õ4­§§'Õ‘ig2€mr™4,÷mß�ÄÔžîuuýÀ¯Ú5�="" �€`-t™'¡="">%$%ÅÙ|OÂ¼£Û
•°8-I(f
—Ì³°ÁäÄ$‚d:Éóì‡©6m½&gt;Û²ào¥\Îd:¡%‚Àr‚/�P×
^l¢XÎÈgQ¯º®[ÌHÁ<e�Ñ‚ãyâ¯ù•mŒÌ3~y,ª*;º¥k;1�”ey@b¶wh}h1êíé —‹��Ý½¹mëqë“1fq…Ë¨\u³rŒÙ-Þ¯lè•ÊêÊÂÜkßÃ,‡Úru£�="" pmÌË{¿÷="" bõöîyfáîÞqÞËr|ïí›Ãwïz="" ÷]d¥Ëpü1="" ŸÚçlštÃ^="" w="" yê™ïù&z§œª¨ò¸fÖÚÔvÁø6--æ¡Å§gd="" ´¾Ó`="" `é:5 «@ìx$“£b&‡ùó�÷‰'§[="" ê4Ñ+Ù“#sÄðÙ•„9Ãk-˜§&ûñ]_êxÝÅ—€s•Ð»…pè)q þ]Ûuõz­4“÷�„®Þî¯¼rÝÎ�Êœy`á="" ‚Ï§oŸt£qdë¹="" †!)Ší¸á”ÖÕÛn™„õy="" y®wœÌ)²Ü«öp�`r2üh•zÀ±u3fk%nÔx´‰\Ø-ðŽ‡m<rþ&èèî¤»c®¥@`xaÅqœ—þólg@)"Ã,˜ŸÉ�È¥zÕ}?Èd’-džgcsü³2ü-‹¼Ào="" ‹â¨70˜eg5o¥dáœü="" ¶ew+Õé©iÆÇ×n¿¾o ÿúëw;vôèÛgjÅ¢$i,Ç3-Ðˆež`,»|<ÝÈ×lî_)‹È;lÓˆi…\í0„°ëû9="">úÊ?=»ç[‡ü¬-†<gß<g§¯¥¢,²��‡íÿÆ¡ý îÝý¤À8ÿîáÏÃo‡¼xøåŸþÑ#¿yÏý_%y¡­žd,¹="" ÚÍÕ2‡Ðr¢ìÑw_<øÊkÙuzÿî@—*¬à<uÜ(ºû¾="" ûˆ#‰¡ÌÒ‰tuöeb‘¥Å°(o¡Ÿª‡ÛÑis,zóå·pd‰©ahå.<4‡ŒŽfgg‡v¸2Ø¡µ4fºzäëoÿ—Æ“èÑhôuöËÃ½vtyk_ß~Ï&¾="" Áj¼ˆufÉàæ-‰tp1_xa¥:;1’¹ºe�@nŽÌ…rq×4‘²t4sd-Ë*•Šýýp-³3$­†cëÄð“¦é˜:„ò³³›7s\ë´Ôª•™É)­vã¾»§Á<ÅÓ8ª¢="" —Ãq“="" ß†©é$Ý·µ ="" À é©©é™©Éê4›àÅ@Ì�i°à="" y–ázÆÆÆÊ…\gw3_íÂÇb¡0="=¥ªQÛ&amp;Áªðå‰cÇsùYâ‘!" bbh"biì=""  ´‰±qâ9="" ¤gÛ6ôäÔÄd¥zi¥Ó7Æâ±�-oxŽ÷Êk="" ="" ùd<©Èjd$�ímËÝiÕáÒÚ.÷wÅ#p�—ˆ´¥-­ÛÌ=""  :Ù?×âyi¾aï´ªzu÷Ö+¿€�‡÷ÿááý="" ="">ð|óìžOÂ€?tà¥kny?Éd¡•»ëU£$¿¯ÔÄ³ËãáßÌ®S¿ÌH9üÜ…ï¶JÝ1DÎ"û-·×íçPoôŽ“€CZ›‚ai�U,r$·ÆõÑ¿ýÊgëCot,2zG�£}%ñ!z_ñ°æºƒf-D‡cæš›ß³ýæÛë×\­ú¢”`SN„»|ûf�©M	)ú•TN)•%™|Œ¨5¬@‚+}Ç|Ç´Kù‚g¹j”¤{$@¦Ò±Ø&lt;K„;ùöÛ†iùžŸ›™@Ã$
ÔüäÄ¸íØÅ|~pó ßbF ¸¤P€–d:2ªªÂAOÚ<r=�ò¾ûžwæô™��Â–·z0 }œ.Žwvtõ¦{b[@k�£ðß‘Ép,—l%y4ù¾e˜•j žŽå¡u†®wtd’É¤¬(áeºŽ«ëzÈµ="" 5��ž�]y7”·�+—Ê¦if::Ò™tÀð^Àòl÷h’|zì$€§§ŽnŠeÃžd,ƒewÇ™ˆ�k�{Ú@¤-—="" ‰ó8÷g�|n¥ó[‡æg�÷‡ößyxÿ¯íÝ}7‡½í7ßfæ="">š-Lå¨#¤M«‡˜ÐoÈ¢Ù½Ã	­©ôãg¾uhÿKCëˆ…föó·öŒÐåð(zhúÁW&gt;þ
�ðYé®Áè­'_¾ûþ‡©oÎ[à›[Dóc,IoV@-X”&nbsp;…?üðûOÌ™çFÏºRL‚/FV.^¤%F$»
÷*;Jy�satÈÁý?»ç€bUOVXÅÄ.VÏ‡ F…�Ý8©Š¶eé5­�Ï“ÔVNˆÇã&nbsp;þ'''+¥R, Bâ-P1Š¸žeÙ¬ 5äìÌ¡)&lt;ŸXUd‘—ÐL4U£QƒäÎ0,]ðD"J"™ŒF£’¬´¶¬\.Û¶�‘’$…¶Š0’#¤4]°&gt;‚&amp;i€›ªÕ�,s ›|W©vvu&amp;Õ€Ÿ‰ÚTLRyZ¸§V­j5M`"ËùB°{ƒ­c;p¢ŽÎNA§§§&nbsp;Ã�‘
¿2zpl›$÷Â„èºJD™™žfHšy&gt;5Øl||¬V©v÷ö�vú˜+XX÷Ï&nbsp;35,0(ªˆ=Ý=ããÅRÑs=I%RˆÁ„�BSÒm Ò–KBˆ²�G¼¶(8¼ÿW?´ŽHîÿèÞÝO‰ŒóæþW®¹õý˜j#úÂ4y^t•Ü˜È,¨¾†[tÑæ�P}õ¥ƒû_znýÞC¢&nbsp;Ïó¦QøÙ¾ôo¾ó—û_Þã­¿ôÆ'~¾¨¥aùàèÓ÷ÉgD&amp;LÑT¬%àHËr³¤¸k!ÌŽg–˜ìzäñ¿úÜu¯`vQåNN·‚v‘°Þèj•Ì†ôi—Ñ4²�žnû³ÏüÉgî½Ï£&lt;\Ø§æÃÕðÎBó!à¾ò|ßØƒ3,
DIëºÊ5‰¤Ò)XúoÂäf±V­™–U­Và
àX›ƒ†6tC’ÄB1o˜ºë:€*BÛF@ÃY	
(Ëˆ¢:2/H¥ÚtÁ¢QlÚB|ß§Ž¤i€À=­Æ4Ÿl¾á#¨i58¼ÚD*å2À)¸ºh&lt;ªJ�šhˆœÈ3Á:–
ø#‹A«LÓ]$áé-VËD&nbsp;|351íQ£jØ¶ˆ˜†ø,L]ž™™6u8Œ	ÈÉ4L%€W`KÇ±¹l	ûº¶“ÎddE&amp;ßû¨b˜ÅB~vüô±ãGåÌ†´‚-Ó&lt;~âm]×-Û*—KÐžŽŽÎ³ï^ˆ´å’(1Êo@äš›ßÈ&nbsp;r	&amp;I˜‘ñ›¯üûÃ$&nbsp;ä)X™í¸ùýa®/H˜–â0»ŽÐœ4`
ulD²Dáhº
f¹ã¯¿ðé—6´~ïáP“M$ûN(¡¿þ·7ÝôaÛç¶Þü¾­7½ÿÓ»¾ü™ûäüÆ]¿XI82‚~°ç»wízÕKÐ
ž½4qsD(uÉà¯�ÈŽË]?žTðÏ&gt;òÂ’ÍËÍJÙE(
A«wCFþÐåšÃoèïŸù³{îûr@2›b	V‹ø4iŽá%�L3;:˜ž()6‚h(%%KUÕhT‘å°N=Ë2¼ êš˜ƒÔ|X¯ð�d±2žOâ-´Z-‘HÂŽõ`‹0|ƒi.[êB!Ÿ#uæüÖ°…+•¢ÏuPð–IªÑJC÷òƒ9ØÁ4’üð¼á�Ag+‘—f¨G±X¬T*ÉTŠ0ˆ`bƒâ#–g	šcÆøU¤(	&nbsp;€%¢ƒt¥à`ÙX,Æ±„Ÿ-7›ëîíÈR*aB‹bšŽCí$©:‚ÁU�¤!ÌØŽ
ÜFxÒxR€&nbsp;	´ª*ÍN�9x`fj¼”› ‰Ä®‘Ëå¦¦¦7
Â…”«e¸Ê¨D¸Ð^¹ûùSmEÙ–Õ7Šø„ÿƒ#æÊøþÿ`÷Ó�¹òRf™ÌéÀOßÿE—‘Z¢ñ‡Õe÷OŽ5h^ƒ…Pj.5}®Ä+©ä‰Žåî½}svý¦Ì,bÊ¶°½Ìïàxîæø�&gt;Ñ8ý™½ÍãFXãSï»q%ï|ã–î}3`%Ê¬h“dRÛ�=W¦(I¥qh%Nâžõ@}DáÎ6¼CópÝÆw‘í©›CVð�„¬ªÃkfØÜ}ÿW?qÿcÔ5æïÉ
úhHŽ‰²E¤üþ�L²áÑ4=LÜˆ6ÂAB‚2Xè[èV;�
Á¡“&nbsp;aÆ�Êrìô™X<n¨d–¨Ò¦œ¼}ô¨¦iÉd*ÓÑêöõ|ßqìl&cb,ª5À%�@å'‰uÁyÅª¶¨tÊ¡…ÔÿìÌ,§·¯ojñ’8rhÌ¶oÔjÐòhŒÀ&À°11xd"¥r‰a¨]#@w�Ž|.ßÕÝ…¦\.�È"�Éå8À.¤6‹?w"@��+µš—œj§�|xž711{%r‰:äò¼Ã‡í?ð²ø jfí†ëß515q­v="">øþnš��u°^WWWwwÏÚ°ˆ„Qcõ’4íœšõ�D¨i�¬A�ìÿéÁý?£_^bWÆP3ïæ­ÑCûÿð!B½³aB&amp;kÓ½{î�‡ðš[n'4'„: d^¤¸„X}CZú&nbsp;^Á&nbsp;^I‹ùñ3ßZß~™ðcÕY;GQ‹õŸb‚Ï=ð»}·ü*&lt;Ò$ƒ:DoaLï¶ñžû¿òìžo×=5Ë·ŽÜQ·nï½ï»{÷|ë7v=Šž„ó‘Yåœ|Euã—móÿXÆµ]|÷ƒ_ûÁ÷ž¬7oQÇ½þ‘‹rÓ„Ö”¡QÚoçë¬¡^Ž}n8Ù7„F‡×Ì°!ñã?‡a±ý¦ÛÈT7ˆ:¬PäxHjÇ°"�»£Ì–Ìœ÷#Ÿ/8$³��ÏqíAh3
EØ(ô¤„y+-.,4|1U„ic"›k4(þJ¥R­T8ž—dp@Ý0|ÏµlRM@	%;hä¦F€†£�˜…Þ	Œ^0;3-+ŠGÊ×®S‚¨¢s¿Ä‡Âàb±T«VôZ&gt;*‘ü¨ÕjÓSS‰dÒÐ4×sa/ha¥§P`ZX÷È0Õr•0Ÿ¦Rall˜iÓ0á¢·ÁÅ#MKÑ&gt;
p	É¬‘Ë•rM«år³“€Wñd:™®Ö*$éfj¢¯§Ó¦Áî®îX,2››!D´–©ÈJÓ¥u¹€-DDH0ZµáÈº—°|Lßxä7[&amp;ÙKïÅšß:´€ûðþ;÷î~’AÞáW^8~àùÿã‘ÏŒ»í–R^HZ~/ôÚ�yˆ”›ÿÑ3ßùáîoe×/�Ù¢ze¨0Ô’ó4‚¾öÔ_¬x¢Œ˜)�ó�ò2ËßußÃ¬«ÿ«ÿðíüåîåb‘‘Fkh�éÞ=Oæ�/yŒR7Ygh‘$;Q›–�?`ä:sÏC�ÜóÀ×a~ë›/ž‹ŒŽ^0Ù·�ì5JÛ”­7ùÜ×?ÒÈä¥›ï;ï Â�y‘q«çu¤ö¯½nÇŽ[?Dõ°�™¥?np&nbsp;Ï^Ãç×KFÐRU1oNc•saï¹(Îr±H´&amp;až°²§~”+q[€
¥Á
K�Ô6¬àÇ04Uf» B“ã°`É&gt;1Ñ2Mh&nbsp;¢ªU�¹	ÚH§Ô¨
'â~�5å��H@Êá’Æë†eÚtöAèyŽücÚ®ç¹†aNŽ�²~dQŠÆCTU­Vj•šiñd*‹‹¤H/ÓÄRšéž:~T$øDÎår•rY¦H¥ÎýJ7ƒŽð‘Ïå�Äíúž²»’˜šž,‹9@®süÄÛ¥RQÓkÇw¦;“é4¬àûîîž[nº5•HÁÓwPñþpüëo¾º¡´*&lt;ãå"á`"%ñ×&nbsp;H2m‘¶ÎÔ–uCI
˜i–¨]«åáˆŽ8´ÿ�xé­ý%æ“ý¼w÷S°à¾ëÁ¯c†'´°tÜÒÙ9ðâçü|ø*»ŸõªsÍHÓdþâ¤È5ñµ½ÞÂ¥Ë‰ð€žCð(Ëm¿åv�Sïzàkd0,‹àì»è»¿§Øqë(htI02FK†ø0­pD4œ�8²$tDal»é6˜"Å_¬§í›_&amp;;—Jsžp¤\EÐ|:'ç&amp;ÛÁk^çÜ:wg†.ÓÀ€~:ô™;¿óæ±‘z‚Æ¤îùgÿêûòM¿t›$ƒxgø³Ôúbà£¹A½v‰.§wÖ'oÂ-	®ä'x§?ê:–¡Õ`A^ƒ}FüÁ`€ðfzjÊ÷CÓTXžÇã$S†Áç¼ Ž�9M-ÊÙ(v¬Vª)Ðô‰8© ‰H2¨v	&nbsp;èìé™™X&lt;¡.áÙiª|¼¤ž„vê®ë–Š%@ÄŠS*ÎkÓE]’õcÚLàçòÀJé®¾®¾
¼5ìúAàY‘FÀ‚&nbsp;DUQZñá½gˆCš¥D”É±q€!a	&lt;	4¾•Tí…®3-«V©Æ}$“$ßG–&nbsp;;k5
PÎÿý³¹@tc&amp;	.±7lØ¶e;O�Q:“éíéŸÿ•;~5O„�Ìó|†HÀ‘B!…‹‚ÛÝu9€Mž„±Èr¼@\WŒ“;ËžIéð˜ËP±¬-—}’°vfŸO~þ¾þÅl1N¬Ai¨µ:Ù|}ùJ,%88|àÅ#û_8úÊO¾ñè½{Ÿùö¡?ºšÌ!õÅ}³Žë¾z¦îçúò¦›?L¾ñlÂâ€„h„ÕQ!.aE˜¹h»ØÐÙzâ¥z•Dê_kTZbV©SlQ-bˆ©;Ôm¿ù¶½_x2$Äxø–¯ýì…êî¤P»×mj£çWoß&gt;‚?H{GçZÝÀ"MƒÇ›97&nbsp;�áá‹œOÒ/¹3ÁåC!?}çÎ�Ûÿ¯ÿôçÿæ_íÖwoûoºñ§‡Oüî—~gø_½¯·o`ðšÉ*v}ÜH·öÎ‚"-18˜„zÎ-MI‚=ìI“?AMP†VžÌe˜˜Ät«A—�Z^‘$XŽçs³ccãº{{â$ÔC¥~IuMC4Õ–×¥™«•0|&nbsp;hXÞ˜ºY­T"‘ˆ¬ÌKÇ…Ÿ|ßoÆšð$†¤Ã4õ=¼‰Fã33S’$/È”9ëj� ÄãZžã%R	…„Ùª’$Â—%ÍÎéAÍtÞ{ãÖL2�©™”¢Æ§L©j³1	%¸BŸ°®Ë‚À÷oˆ(ÊÙVøF�(ÇÊtt˜†�'&nbsp;ý¹Ùè™h,øÀs½©‰‰J¥ªF£axMØ°ÓgNýâåŸ¹Ž[Óçá�üÊ�½=}7ì¼qçõ78–=91Á°œ¬*¦nTJ•-›¶ð‚h”}ØŸº…</n¨d–¨ò¦œ¼}ô¨¦iéd*óñêöõ|ßqìl&cb,ª5à%�@å'‰uáyåª¶¨tê¡…ôÿìì,§·¯ojñ’8rhì¶oôjðòhœà&à°11xd"¥r‰a¨]#@w�ž|.ßõý…¦\.�è"�éå8à.¤6‹?w"@��+µš—œj§�|xž711{%r‰:äò¼ã‡í?ð²ø></r=�ò¾ûžwæô™��â–·z0 }œ.žwvtõ¦{b[@k�£ðß‘ép,—l%y4ù¾e˜•j></gß<g§¯¥¢,²��‡íÿæ¡ý></e�ñ‚ãyâ¯ù•mœì3~y,ª*;º¥k;1�”ey@b¶wh}h1êíé></l˜ú;uü´ˆœýkccgæ&æâ¹:äô™s±xðrè�ƒö&uá3«¹b…—cçõ></p¶åî{¿fy1„x-zwyœõt©àz$µ‚¨†»¡—ûùãní`wv3·ôãßºqù8ðc˜eðánî4-ó§à0ï5,i¬a¦'æyl4 @½:plž%ò›zñµ�ø¶></w�z1ã”útô²�ˆs×ù></yt¯¡ó„g§ƒ�¼¡9wf–nÿ½x@7<ïâç€qaew…,…þîý÷²ž></ut�™(ifáz=‚•$xc¹ät¿öùå;~å4ìÿ·u«u'ãœ,€‰càmù–d�sx!vbqãß‰rð0å0�¾¦ÿ'ðð«�úò–¶\áx$»öì;yôù¾ìü‡ûk></ais—³1gx’w¡></kˆòòj<ó¡2›2jbäê¥’©q)”ú°u}à¢,i²õ<èøùül¥\ù°q#ë-túq5ºóº�9ò“þ<à–…û„ïuc±h"ê></i></u></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sat-smt.codes/SAT_SMT_by_example.pdf">https://sat-smt.codes/SAT_SMT_by_example.pdf</a></em></p>]]>
            </description>
            <link>https://sat-smt.codes/SAT_SMT_by_example.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298863</guid>
            <pubDate>Mon, 01 Mar 2021 01:39:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collection of SolarWinds Articles]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298791">thread link</a>) | @wglb
<br/>
February 28, 2021 | https://ciexinc.com/blog/solarwinds-articles/ | <a href="https://web.archive.org/web/*/https://ciexinc.com/blog/solarwinds-articles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ciexinc.com/blog/solarwinds-articles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298791</guid>
            <pubDate>Mon, 01 Mar 2021 01:21:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Write a Blog]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298750">thread link</a>) | @nindalf
<br/>
February 28, 2021 | https://blog.nindalf.com/posts/why-i-write/ | <a href="https://web.archive.org/web/*/https://blog.nindalf.com/posts/why-i-write/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="wrapper">
            <article>
                <header>
                    
                    <h2>
                    Feb 28, 2021 00:15
                    · 636 words
                    · 3 minute read
                      <span>
                      
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    <h2 id="non-reasons">Non reasons</h2>
<p>Let me first mention reasons that <em>aren’t</em> why I’m writing posts on this blog</p>
<ul>
<li>Becoming a thought leader. My readership is pretty low, unless it reaches the top of HN/reddit. That has only happened a couple of times, so I’m not sure I can replicate it.</li>
<li>Becoming a paid writer. No one is paying for my opinions on things. Especially not when there isn’t a clear theme to my writing other “whatever is on my mind right now”</li>
<li>My social circle thinking of me as “well read” or “intelligent”. I’m honest enough to admit that the opinions of my peers matter to me, but few friends read this blog so it doesn’t make a difference.</li>
</ul>
<hr>
<h2 id="why-i-write">Why I write</h2>
<ol>
<li>To stop ideas rattling in my head. Most of these posts start as half formed abstract ideas. I keep dwelling on them till they become more corporeal. I can’t control this. This bouncing does refine the ideas, but slower than if I had gone through the writing process. When I’m done writing, I’m able to set the idea aside and stop thinking about it. That’s a relief sometimes, especially if it’s a subject that has been upsetting me.</li>
<li>These ideas aren’t fleshed out or even coherent. Sometimes they’re a feeling, a conviction that something has to be so without any words backing it up. Writing forces me to state the hypothesis, gather the evidence and make the case for it.</li>
<li>I edit the posts a couple of times, removing unnecessary words, sentences and phrases. I rewrite unclear passages and remove superfluous ones. I force myself to use simple language because that makes me think clearly. Only when there is nothing left to delete am I satisfied. I can edit written words in a way that thoughts can’t be. I find Orwell’s <a href="https://www.orwellfoundation.com/the-orwell-foundation/orwell/essays-and-other-works/politics-and-the-english-language/">recommendations</a> and <a href="http://hemingwayapp.com/">Hemingway’s style guide</a> helpful here.</li>
</ol>
<hr>
<h2 id="potential-benefits">Potential benefits</h2>
<p>Apart from immediate peace of mind there are some benefits to this I could reap.</p>
<ul>
<li>My memory is unreliable and malleable. I know why I believe the things I do today, but I don’t remember how those views evolved. What conversations led to them? What books, articles and people influenced my thinking? I didn’t keep a record, and can only vaguely recall answers to those questions. For example, I used to oppose reservation (aka affirmitive action) when I was younger. Now I support it. I don’t know when I changed my opinion or what triggered the change.</li>
<li>In 10 years, I’ll be surprised if my views on some things hasn’t changed. In 20 years, I’ll be disappointed if nothing has changed. It would mean that I’ve stagnated intellectually, learned nothing new that forced me to re-evaluate my beliefs. A written record makes it easier to chart this evolution.</li>
</ul>
<hr>
<h2 id="alternatives">Alternatives</h2>
<p>Instead of writing, I could keep a journal that would achieve most of the same effect. However, I put more effort into posts I publish. I spend time editing them, which I never do with notes. That’s why the quality of posts is higher than my notes, even though I put out the occasional turd.</p>
<hr>
<h2 id="potential-downsides">Potential downsides</h2>
<p>It could ossify my thoughts. I mentioned earlier that I stop thinking about topics I’ve already written about. That might not be a good thing if it means my views on that topic stop evolving. I might also be reluctant to change my views from something I’ve publicly soft committed to on a post, to avoid looking like I’m flip flopping.</p>
<p>With any luck, my awful memory will help here. I’ll forget the posts I’ve written so I can think about them anew from fresh angles.</p>
<hr>
<h2 id="conclusion">Conclusion</h2>
<p>I hope I keep writing and reading. I hope I keep changing my mind as I learn new things.</p>
<blockquote>
<p>When the facts change I change my mind. What do you do?</p>
<p><a href="https://quoteinvestigator.com/2011/07/22/keynes-change-mind/">Some guy</a></p>
</blockquote>

                </section>
            </article>

            

            

            

            

        </section></div>]]>
            </description>
            <link>https://blog.nindalf.com/posts/why-i-write/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298750</guid>
            <pubDate>Mon, 01 Mar 2021 01:13:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lisp Machine Manual (1984)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298553">thread link</a>) | @caslon
<br/>
February 28, 2021 | https://hanshuebner.github.io/lmman/title.xml | <a href="https://web.archive.org/web/*/https://hanshuebner.github.io/lmman/title.xml">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><center><heading>Lisp Machine Manual</heading></center><center>Sixth Edition, System Version 99</center><center>June 1984</center><center>Richard Stallman</center><center>Daniel Weinreb</center><center>David Moon</center><nopara></nopara>
<p>This report describes research done at the Artificial Intelligence
Laboratory of the Massachusetts Institute of Technology.  Support for the
laboratory's artificial intelligence research is provided in part by the
Advanced Research Projects Agency of the Department of Defense under Office
of Naval Research Contract number N00014-80-C-0505.
<page></page></p><center><sub-heading>Preface</sub-heading></center>

<p>The Lisp Machine manual describes both the language and the operating system
of the Lisp Machine.  The language, a dialect of Lisp called Zetalisp,
is completely documented
by this manual.  The software environment and operating-system-like parts of
the system contain many things which are still in a state of flux.
This manual confines itself primarily to the stabler parts of the
system.  It describes how to program, but not for the most part how to
operate the machine.  The window system is documented separately in
the Lisp Machine Window System manual.
</p>

<p>Any comments, suggestions, or criticisms will be welcomed.  Please send
Arpa network mail to BUG-LMMAN@MIT-MC.
</p>

<p>Those not on the Arpanet may send U.S. mail to

<lisp><standard>Richard M. Stallman
Artificial Intelligence Lab
545 Technology Square
Cambridge, Mass. 02139</standard>
</lisp></p>

<p>Portions of this manual were written by Mike McMahon and Alan Bawden.
The chapter on the LOOP iteration macro is mostly a reprint of
Laboratory for Computer Science memo TM-169, by Glenn Burke.  Sarah
Smith, Meryl Cohen and Richard Ingria of LMI, and Richard Mlynarik of
MIT, helped to correct the manual.
</p>
<nopara></nopara><center><sub-heading>Personal Note from Richard Stallman</sub-heading></center>
<p>The Lisp Machine is a product of the efforts of many people too
numerous to list here and of the former unique unbureaucratic,
free-wheeling and cooperative environment of the M.I.T. Artificial
Intelligence Laboratory.  I believe that the commercialization of
computer software has harmed the spirit which enabled such systems to
be developed.  Now I am attempting to build a software-sharing movement to
revive that spirit from near oblivion.
</p>

<p>Since January 1984 I have been working primarily on the development of
GNU, a complete Unix-compatible software system for standard hardware
architectures, to be shared freely with everyone just like EMACS.
This will enable people to use computers and be good neighbors legally
(a good neighbor allows his neighbors to copy any generally useful
software he has a copy of).  This project has inspired a growing
movement of enthusiastic supporters.  Just recently the first free
portable C compiler compiled itself.  If you would like to contribute
to GNU, write to me at the address above.  Restrain social decay--help
get programmers sharing again.
</p>
<page></page>
</div></div>]]>
            </description>
            <link>https://hanshuebner.github.io/lmman/title.xml</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298553</guid>
            <pubDate>Mon, 01 Mar 2021 00:42:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking This Serially (RS-232 History)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298546">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://computer.rip/2021-01-12%20taking%20this%20serially.html | <a href="https://web.archive.org/web/*/https://computer.rip/2021-01-12%20taking%20this%20serially.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Conceptually, if we want two computer systems to communicate with each other,
all we need is a data link over which we can send a series of bits. This is
exactly what serial interfaces do. You can probably quickly imagine a simple
and effective scheme to send a series of bits in order, which is precisely why
there are a thousand different standards, many of them are confusingly similar
to each other, and the most popular are remarkably complex.</p>
<p>So, in this message, I will try to break down what exactly a "serial port" is.
I will only be talking about the hardware standards in this case, not the
software side of a COM port in Windows or a tty device in Unix derivatives.
That's an interesting topic, and I hope to write about it some time, but it
will be A Whole Thing. The software situation is at least as complicated as the
hardware side.</p>
<p>With that warning in place, let's look at this strictly from a consumer
perspective. Most computer users, or at least those with experience working
with serial ports, are familiar with serial in the form of a DE9[1] connector,
and often as opposed to a parallel port, which uses a truly enormous DB25
connector in order to send eight bits at a time. These were the two primary
peripheral interfaces of old computers. Actually, that's not quite true; it's
more accurate to say that these two were the primary peripheral interfaces
of early personal computers that managed to survive into the modern era,
basically because they were adopted by various iterations of the IBM PC, which
is the platonic ideal of a personal computer.</p>
<p>To simplify the history somewhat, the pseudo-standard parallel port was
designed in order to simplify the construction of printers. Although that
advantage basically disappeared as printer technology changed, parallel ports
remained conventional for printers for many years after. In practice they had
few advantages over serial connectors and so basically died out with the
printers that used them. We should all be glad, the time it took to send a
rasterized page to a laser printer over a parallel interface was truly
infuriating.</p>
<p>It would be surprising to run into a parallel interface in use these days,
although I'm sure there are a few out there. It is quite common, though, to
find serial ports today. They're remarkably durable. This is partially because
they are extremely simple, and thus inexpensive to implement. It is mostly
because they are predominantly used by the kind of industries that love to
have weird proprietary connectors, and serial is the ultimate way to have a
weird proprietary connector, because it is one of the least standardized
standards I have ever seen.</p>
<p>Serial ports on computers are vaguely related to an EIA/TIA standard called
RS-232. In fact, a number of computers and other devices label these ports
RS-232, which is a bold move because they are almost universally non-compliant
with that specification. There are usually several ways that they violate the
standard, but the most obvious is that RS-232 specifies the use of a DB25
connector, with, you guessed it, 25 pins. "Good god, 25 pins for a simple
serial connection?" you say. That's right, 25 pins. It is precisely because of
that bourgeois excess of pins that personal computer manufacturers, as an
industry, decided to trash the standard and use the smaller DE9 connector
instead.</p>
<p>In order to understand RS-232 and it's amusingly large connector specification
better, we need to understand a bit about the history of the standard.
Fortunately, that will also help a bit in understanding the baffling complexity
of actually making serial interfaces work today.</p>
<p>RS-232 was originally introduced to connect a terminal (originally a TTY) to a
modem. The specification was actually rather specific to that purpose, which
shows when we look at all the bonus pins. More generically, RS-232 is designed
to connect "data terminal equipment" (DTE) to "data communications equipment"
(DCE). As you often run into with these sorts of cabling, the TX pin of one
computer needs to connect to the RX pin of the other, and vice versa. For this
reason, the two devices on a serial connection should have their RX and TX pins
reversed compared to each other. </p>
<p>The terms DTE and DCE are usually used to identify these two different
configurations. That said, it was sometimes necessary to, for example, connect
two computers to each other, when both used the same interface. Further, some
manufacturers made (and continue to make) inconsistent decisions about whether
the computer or peripheral should be DCE or DTE. This necessitates using a
"null modem" cable, which is the equivalent of "crossover" for Ethernet before
GbE specified a far more flexible MDI.</p>
<p>Trying to figure out whether you should use a null modem or straight through
cable, which is usually easiest to do by experimentation, is just the first of
the many fun steps in successfully using a serial device.</p>
<p>Conceptually, RS-232 functions in an extremely simple way. To transmit a one,
you put a high (positive) voltage on the TX pin. To transmit a zero, you put a
low (negative) voltage on the TX pin. This is in reference to a ground pin,
which is usually connected right to local ground.</p>
<p>This gets us to our second bit of serial complexity, after figuring out whether
or not we need to add an extra swap in the RX and TX wires: clock recovery. In
most cases (we'll get to the exceptions later maybe), there is no explicit
clock information provided by a serial connection. Instead, the receiving
device must heuristically recover the clock rate. Some serial devices work this
out by expecting the transmitter to always send a certain preamble (common in
some industrial control and other situations), but the problem is solved more
generally by the convention of sending a "start bit" and "stop bit" of one and
zero successively, before and after each byte. This ensures at least one
transition and helps with detecting the timing of the whole byte.</p>
<p>Most devices expect one and one bit. Some devices expect two of each. Some
devices expect none at all (although they then usually use a protocol that
expects a preamble).</p>
<p>From this mess, you might think that the RS-232 standard does not specify any
method of clock synchronization. In fact, it does. It's just not implemented
on PC serial interfaces.</p>
<p>So I said 25 pins. Now we know what our first five are: we have ground, tx,
rx, and two pins that are used for synchronization, one in each direction.
That's 5. What about the other twenty?</p>
<p>Well, some are just for stuff that no one uses any more. There's a pin to
select the data rate (rarely used and unimplemented on PCs). There's a pin for
a transceiver self-test feature (rarely used and unimplemented on PCs). But
most of all, there is telephone modem arcana.</p>
<p>Remember, RS-232 was designed fairly specifically for a terminal to communicate
with its modem. Modems at the time had some fairly peculiar requirements and
restrictions. An obvious one is that the modem needs to signal the terminal
when it is ringing (in the sense of a phone), and there's a pin for that.
There's also a pin to indicate that the DCE has established a connection with
a remote DCE. There are two pins that the DTE can use to essentially conduct
a handshake with the DCE in preparation for sending data, a requirement due to
the half-duplex nature of modems. There are two pins for similar, but different
readiness negotiation in the other direction.</p>
<p>Most entertaining of all, there is <em>an entire second serial connection.</em> That's
right, the RS-232 standard specifies pins on the cable for a complete second
data path with its own data pins and control pins.</p>
<p>Add all this up and you get somewhere near 25, but not quite, because there are
a few unused.</p>
<p>When early PC manufacturers (but mostly IBM) were hunting around for a fairly
general-purpose interface to connect peripherals, RS-232 looked like a pretty
good solution because it was fairly simple to implement and provided a good
data rate. The problem is that it was over complicated. So, they just took the
parts they didn't like and threw them in the trash. The result is "RS-232
lite," a loosely specified standard that carried RS-232-esque signaling over a
smaller DE9 connector.</p>
<p>Here are the pins of the DE9 connector:</p>
<ol>
<li>Data carrier detect (DCD)</li>
<li>Rx</li>
<li>Tx</li>
<li>Data terminal ready (DTR)</li>
<li>Ground</li>
<li>Data set ready (DSR)</li>
<li>Request to send (RTS)</li>
<li>Clear to send (CTS)</li>
<li>Ring indicator</li>
</ol>
<p>This has the ground and two signal pins that we know we need, and then many,
but not all, of the control pins specified by RS-232. Notably, no clock pins,
meaning that properly synchronous serial standards (like several early computer
network standards) cannot be carried on these RS-232 interfaces. Don't worry,
this didn't stop anyone from trying to do general-purpose networking with these
things.</p>
<p>Quick sidebar: I said positive and negative voltage earlier. The RS-232
standard is really unspecific about these and in newer revisions they can range
from 3 to 25 volts, either positive or negative. As a de facto norm, most
computer "RS-232-ish" interfaces use 13 volts, but there are exceptions. The
standard requires that all interfaces tolerate up to the full 25 volts, but
I would not trust this too far.</p>
<p>So what about all the control pins that PC serial interfaces retain... well,
this gets us into the world of flow control. Often, when communicating with a
peripheral or another computer, it is necessary to somehow signal when you are
capable of receiving data (e.g. room in buffer). This is conventionally done on
serial ports by using the RTS and CTS pins to indicate readiness to receive
data by the DTE and DCE respectively, which is consistent with which ends of
the connection "own" those pins in the proper RS-232 specification. This is all
fine and good.</p>
<p>Except for it's not, because there are a number of serial devices out there
which do not implement the RTS/CTS pins for whatever reason (mostly money
reasons, I assume). So, a second convention …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computer.rip/2021-01-12%20taking%20this%20serially.html">https://computer.rip/2021-01-12%20taking%20this%20serially.html</a></em></p>]]>
            </description>
            <link>https://computer.rip/2021-01-12%20taking%20this%20serially.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298546</guid>
            <pubDate>Mon, 01 Mar 2021 00:41:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use the Principled Volume shader in Blender]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298458">thread link</a>) | @saturn5k
<br/>
February 28, 2021 | https://petarpetkovski.net/how-to-use-the-principled-volume-shader-in-blender/ | <a href="https://web.archive.org/web/*/https://petarpetkovski.net/how-to-use-the-principled-volume-shader-in-blender/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="content" role="main"><div><div><article id="post-3494"><div><p>This is a short tutorial on how to add a volume shader (<a href="https://docs.blender.org/manual/en/latest/render/shader_nodes/shader/volume_principled.html" target="_blank" rel="noopener">Principled Volume</a>) in <a href="https://www.blender.org/" target="_blank" rel="noopener">Blender</a> to achieve an atmospheric and cinematic look. This is for users that are at least already familiar with the Blender UI as I will not be sharing details about scene setup, shortcuts or render settings.</p><p>My scene setup is fairly simple consisting of a few models, a plane with an added displacement/height map (terrain), a sun light and a spot light (for the antenna). As we can see from the screenshots below, the lightning looks very harsh because it illuminates the scene without any diffusion from small particles in the scene such as air/pollution. The scene looks rather plain and boring with no exciting photon action.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/scene-setup-01-1200x669.jpg" alt="" width="1200" height="669" srcset="https://petarpetkovski.net/wp-content/uploads/scene-setup-01-1200x669.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-744x415.jpg 744w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-420x234.jpg 420w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-768x428.jpg 768w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-560x312.jpg 560w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01-1536x857.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/scene-setup-01.jpg 1581w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Here is another look on the 3D environment. On the left side we can see the shader editor screen with the node configuration applied to the main plane to achieve the displaced terrain using a height map. All the view-port rendering is done in Cycles.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/displacement-1200x640.jpg" alt="" width="1200" height="640" srcset="https://petarpetkovski.net/wp-content/uploads/displacement-1200x640.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/displacement-744x397.jpg 744w, https://petarpetkovski.net/wp-content/uploads/displacement-420x224.jpg 420w, https://petarpetkovski.net/wp-content/uploads/displacement-768x409.jpg 768w, https://petarpetkovski.net/wp-content/uploads/displacement-560x298.jpg 560w, https://petarpetkovski.net/wp-content/uploads/displacement-1536x819.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/displacement.jpg 1576w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Next, insert a plain cube into the scene and resize it to match the scene and visible area that will be rendered. We are going to make this cube look as it is made from fog. A foggy cube.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-1200x637.jpg" alt="" width="1200" height="637" srcset="https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-1200x637.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-744x395.jpg 744w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-420x223.jpg 420w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-768x407.jpg 768w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-560x297.jpg 560w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02-1536x815.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/add-volume-shader-02.jpg 1578w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Once we are finished adjusting the cube size, go to the shader editor and apply a “Principled Volume” shader to the cube. Adjust the “Density” and “Emission Strength” values as well as corresponding colors to get the desired fog/atmosphere effect. You can also play with the strength of the sun light that’s illuminating the entire scene to see how it will interact with this newly added volume. You may want to adjust the Prinicpled Volume values depending on the sun strength.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/set-shader-03-1200x628.jpg" alt="" width="1200" height="628" srcset="https://petarpetkovski.net/wp-content/uploads/set-shader-03-1200x628.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-744x390.jpg 744w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-420x220.jpg 420w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-768x402.jpg 768w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-560x293.jpg 560w, https://petarpetkovski.net/wp-content/uploads/set-shader-03-1536x804.jpg 1536w, https://petarpetkovski.net/wp-content/uploads/set-shader-03.jpg 1579w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>Once we are done tweaking and adjusting the volume options and lightning position, we can set up the camera for that perfect angle and wait a couple of minutes for our render to finish. Although by using this method you will get way longer rendering times, the final result is much better and has a more natural look and feel. The light is soft and diffused thanks to the added volume, which makes the scene alive and more present.</p><p><img loading="lazy" src="https://petarpetkovski.net/wp-content/uploads/final-render-04-1.jpg" alt="" width="1200" height="800" srcset="https://petarpetkovski.net/wp-content/uploads/final-render-04-1.jpg 1200w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-744x496.jpg 744w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-420x280.jpg 420w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-768x512.jpg 768w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-560x373.jpg 560w, https://petarpetkovski.net/wp-content/uploads/final-render-04-1-930x620.jpg 930w" sizes="(max-width: 1200px) 100vw, 1200px"></p><p>That’s all for now, and I hope someone gets inspired by this :)</p><p>Read other stuff <a title="Blog" href="https://petarpetkovski.net/blog/">here</a>.</p></div></article></div></div></main></div></div>]]>
            </description>
            <link>https://petarpetkovski.net/how-to-use-the-principled-volume-shader-in-blender/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298458</guid>
            <pubDate>Mon, 01 Mar 2021 00:27:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Planck 6502, an open hardware extensible retro computer]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26298278">thread link</a>) | @jfoucher
<br/>
February 28, 2021 | https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html | <a href="https://web.archive.org/web/*/https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>February 28, 2021 | <span>7</span> Minute Read</p>
  
  <p><img src="https://jfoucher.com/uploads/2021/02/1.jpg" alt="">
    </p>

  <h3 id="retro-computing">Retro computing</h3>

<p>Going back to the roots of your field can provide new insights into your day to day experience. For me, the roots are located in the 70s / 80s a time when personal computers were much simpler and could be fully understood by a regular person. This is a time when the most popular computers were the Vic20, Apple II and later Commodore 64.</p>

<p><img src="https://jfoucher.com/uploads/2021/02/VIC-20.jpg" alt="Vic-20">
<img src="https://jfoucher.com/uploads/2021/02/Apple_II.jpg" alt="Apple II"></p>



<p>These computers booted in less than a second to a raw basic prompt. To be clear: you turn on your computer, and less than one second later you start programming. How wonderful would that be, in our land of a thousand node dependencies, failing composer upgrades and wrong vagrant configurations?</p>

<h3 id="what-to-build">What to build?</h3>

<p>I was increasingly interested in electronics since doing a project for a friend, so I thought to myself “How hard can it be?” Well, as it turns out, quite, but that’s hardly the point right now. The point is: what should I build? I started by building a simple 6502 based computer on a breadboard. I soon realised that if I was to have anything half useful I was going to need the entire breadboard production of China to be delivered to my house. Also breadboard computers are buggy and you can’t move them around because then a cable will come loose and you will spend five hours troubleshooting your code instead.</p>

<p>So I decided I would convert it to PCBs. They are pretty cheap to get delivered from China, but since they take about a month to arrive the rate of iteration is not so great. Better to get it right the first time obviously.</p>

<p>Well I almost did. The first one was very simple, only having a 6502 processor and an 6522 parallel port interface. I interfaced with it from my computer via SPI through an arduino: the 6522 Versatile Interface Adapter can bit bang SPI easily enough. The Arduino Uno/Nano can be an SPI slave easily enough and receive that data. It can then transmit that data to my computer using serial over USB.</p>

<p>That worked fine (after a couple of bodge wires) but was a bit kludgy, having the Arduino sort of hanging there by a few cables.</p>

<p>I then tried to design a single board computer with everything I would ever want on it: serial communication, parrallel port, SPI port(s), i2c port(s), PS/2 port for a keyboard, sound chip, VGA output, etc… The board to house all of this was very big and thus very expensive. Combining this with the previous point regarding getting it right the first time, a single board computer suddenly seemed like not that great of an idea.</p>

<h3 id="the-plan">The plan</h3>

<p>I then decided to build a board with basic circuitry into which other boards that provided actual functionality will be able to plug in. Turns out that already exists and is called a <a href="https://en.wikipedia.org/wiki/Backplane">backplane</a></p>

<p>So backplane it is then. The size limit for this board and all others will be 10cm x 10cm as that it the cheap price limit for most cheap board houses (yes I’m cheap and I like cheap, preferably cheap that works).</p>

<p>Here is the backplane design:</p>

<p><img src="https://jfoucher.com/uploads/2021/02/backplane.png" alt="backplane 3D view"></p>

<p>As you can see, it is mostly just slots to plug in the extension boards. The only active components are the clock generation circuit, and some decoding to activate the expansion slots when they are needed.</p>

<p>The rightmost slot is reserved for the CPU card. The CPU card includes some RAM and ROM, which means the computer is already functional with just this single board plugged in, although admittedly it won’t <em>do</em> much in that configuration.</p>

<p>To get the computer to do stuff it’s best to plug in some additional boards.</p>

<p>The initial design includes an IO board with PS/2 port, SPI ports and a parallel port (and LEDs, of course it has LEDs!) as well as a serial board to allow the user to communicate with the computer.</p>

<p>After waiting patiently forever for the boards to arrive, I put it all together and gave it a try. It did not work at all. Of course there were mistakes on the boards, which confirmed the soudness of my choice of not doing one huge board at once.
However not all the boards were defective, and the bad ones were quickly fixed with a few wires here and there.</p>

<p>After which, plugging a usb to serial adapter into the serial board, and into a usb port on my computer, I could see the Planck computer doing something!</p>

<p>Here it is running <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a> over serial</p>

<p><img src="https://jfoucher.com/uploads/2021/02/running-forth.jpg" alt="Forth over serial on the Planck computer"></p>

<p>I am currently working on more expansion boards, such as an LCD board, a sound card, and a VGA card. <a href="https://jfoucher.com/feed.xml">Stay tuned</a> for more.</p>

<p>For more details about this project, please use the links below:</p>

<ul>
  <li><a href="https://planck6502.jfoucher.com/">Project website</a></li>
  <li><a href="https://gitlab.com/planck-6502/planck-6502">Hardware and source code</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://jfoucher.com/2021/02/planck-6502-open-hardware-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298278</guid>
            <pubDate>Sun, 28 Feb 2021 23:54:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreshBSD 2021: Relaunching the BSD Commit Log Search Engine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26298079">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://freshbsd.org/news/2021/02/28 | <a href="https://web.archive.org/web/*/https://freshbsd.org/news/2021/02/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><h2><a href="https://freshbsd.org/news/2021/02/28">FreshBSD 2021</a></h2></header><section><p>6 weeks ago I created a branch for a significant rework of FreshBSD.  Nearly 300
commits later, and just a week shy of our 15th anniversary, the result is what
you’re looking at now.  I hope you like it.</p>

<p>There’s loads of internal changes, but here’s the main user-facing stuff:</p>



<p>We have a new vector logo I knocked together in <a href="https://inkscape.org/">Inkscape</a>,
a new <a href="https://slimselectjs.com/">drop-down select library</a>, a new pagination
widget that offers to reverse the sort order rather than encouraging you to visit
page 170,000, and a variety of style tweaks to (hopefully) make things a bit nicer.</p>

<h2 id="prettier-urls">Prettier URLs</h2>

<p>The site has a new URL scheme, and a much better system for generating them from queries.
Where possible they’ll be automatically applied using JavaScript to make sharing links
more pleasant.  For example, this monstrosity:</p>

<blockquote>
  <p>/search?q=&amp;project%5B%5D=freebsd&amp;repository%5B%5D=src&amp;branches%5B%5D=releng%2F12.0&amp;sort=commit_date</p>
</blockquote>

<p>Becomes:</p>

<blockquote>
  <p>/freebsd/src/branch/releng/12.0</p>
</blockquote>

<p>Old URLs should continue to work.</p>



<p>A new grouped <code>Source</code> filter replaces <code>Project</code> and <code>Repository</code>, making it much
easier to go straight to the repositories you’re interested in.</p>

<p>There’s also a new filter for merge commits, though this currently only works for git-based
repositories.</p>



<p>According to <a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed Insights</a>:</p>

<ul>
  <li>Old front page: 4,814 DOM elements, 148 KiB, 2.3s to interactive.</li>
  <li>New front page: 1,616 DOM elements, 37 KiB, 0.5s to interactive</li>
</ul>

<p>This is a combination of improvements, including:</p>

<ul>
  <li>Removal of jQuery and Font-Awesome’s WebFont/CSS</li>
  <li>Branch/tag/committer filters being suppressed</li>
  <li>Result counts and aggregations calculated in the background during rendering</li>
  <li>Multithreaded commit rendering</li>
  <li>Reduction in per-page results from 50 to 30</li>
  <li>Improved caching, with a warmup query for the front page on index updates</li>
</ul>



<p>I’ve done a lot of work to improve the quality of the code, which in turn makes
further changes easier and more appealing.  This also brings us closer to the
point at which I’ll be comfortable publishing the codebase.</p>

<p>In the mean time, I hope you continue to find the site useful.  If you have any
feedback, please email me at <a href="mailto:tom@hur.st">tom@hur.st</a>, or Tweet me at
@blaagh.</p>

<p>Cheers.</p>
</section></article></div>]]>
            </description>
            <link>https://freshbsd.org/news/2021/02/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298079</guid>
            <pubDate>Sun, 28 Feb 2021 23:22:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak: A Free Smalltalk System – On RISC OS]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26298075">thread link</a>) | @lproven
<br/>
February 28, 2021 | http://www.rowledge.org/tim/squeak/ | <a href="https://web.archive.org/web/*/http://www.rowledge.org/tim/squeak/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .sidebarContainer -->
			<div>
				<p><span>Squeak: A Free Smalltalk system</span></p><p><img alt="" src="http://www.rowledge.org/tim/squeak/files/page17_1.jpg" width="295" height="205"><br></p><p><span>What is Squeak?</span><br>Squeak is a free Smalltalk system originally released by a team including Alan Kay, Dan Ingalls, Ted Kaehler, John Maloney and Scott Wallace in 1996 when they were working at Apple. You might recognise the first three names from early Smalltalk papers from Xerox PARC. They produced a rather nice Smalltalk system with the unusual virtue that both the image and the Virtual Machine are open source - i.e. free, gratis and "no charge to you sir".<br><span>Finding Out More About Squeak</span><br>To find most of the web resources for Squeak, look at the <a href="http://www.squeak.org/" rel="self">Squeak.Org</a> site. There are lots of pointers to information about Smalltalk, instructions for downloading Squeak, tutorials, FAQs etc. I won't waste space by duplicating any of it here. I do most strongly recommend that you read many of them.<br><span>Squeak runs on...</span><br>Macs, iPhones, most UNIX &amp; Linux systems, Windows of various versions, <a href="http://www.riscos.org/" rel="external">RISC OS</a> and some obscure specialised systems. See the above mentioned master page for details on how to get the files.<br>I’ve spent many years making Smalltalk available for RISC OS and other <a href="http://www.arm.com/" rel="self">ARM</a> based systems including the original Acorn Archimedes &amp; RPC desktops, the Active Book, an early prototype version of the Compaq ‘iPaq’ handheld, the Interval Research ‘MediaPad’, an HP prototype pad-thing and other stuff still secret.<br><span>New News of a newsish nature</span><br>2013 - Squeak is back on RISC OS! Those nice people at the <a href="http://www.rowledge.org/tim/squeak/www.raspberrypi.org" rel="external">Raspberry Pi Foundation</a> sent me a Pi; it has RISC OS on it and I’ve been getting things working on it. </p><p><img alt="IMG_0467" src="http://www.rowledge.org/tim/squeak/files/img_0467.jpg" width="519" height="388"><br></p><div><p>It runs quite nicely in general; the Pi’s RISC OS graphics kernel is a bit slow seeming right now but there is work being done that should improve that significantly. It supports <a href="http://scratch.mit.edu/" rel="external">Scratch</a> as well and runs it decently - though there is a lot of work being done to improve that, too. Somewhat perversely, MIT decided to rewrite Scratch in Flash (belch) ‘for better browser support’ and seem to have abandoned the ‘old’ Squeak based system. Since Flash doesn’t run on RISC OS  nor indeed on ARM systems in general, we’ll be supporting ‘old’ Scratch for a while.<br>You can download a copy of Squeak for RISC OS from the central <a href="http://www.squeakvm.org/riscos" rel="external">squeakvm.org </a>site.<br>Currently I’m working for the Pi foundation to improve Scratch under Raspbian (their linux version) by rewriting some of the more egregiously ugly code, improve algorithms, tweak vm configurations and so on. As of early-2014 it’s significantly faster than the original version with a fair bit more to come. A major project has been <a href="http://www.raspberrypi.org/test-tims-nuscratch-beta/" rel="external">porting the code forwar</a>d to the latest Squeak image so that it can run on the most modern VMs; right now it is using the ‘StackVM’. I hope to get the newer design dynamic translating VM working soon.<br>When and if possible all of this will get moved over to RISC OS but making a living comes first!</p><p> <span>Building the VM with VMMaker</span><br>I also developed and for many years maintained the VMMaker package, the lump of Squeak code that defines and generates the bulk of the VM. See the VMMaker page on the <a href="http://wiki.squeak.org/squeak" rel="self">Squeak Swiki</a> for more info. You can fetch the VMMaker package from <a href="http://map1.squeakfoundation.org/sm" rel="self">SqueakMap</a> or use the SqueakMap tool in the image and look for (guess what) VMMaker. You will also need a <a href="http://subversion.tigris.org/" rel="external">SubVersion</a> client so that you can fetch the handwritten parts of the VM source code from the repository.<br>Once you have mastered the complexities of the VMMaker and successfully built yourself a custom VM you should download<a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/SqueakVMBuilderCertificate.pdf" rel="self"> this certificat</a>e to attest to your mighty geekiness.<br><span>Stuff wot I wrot</span><br>	•	I contributed a chapter describing the structure, function, design and implementation of virtual machines and the lowest level of Smalltalk code to <a href="http://www.amazon.com/Squeak-Open-Personal-Computing-Multimedia/dp/0130280917" rel="external">"Squeak: Open Personal Computing and Multimedia"</a> edited by Mark Guzdial and Kim Rose, published by Prentiss-Hall. An online version of <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/OE-Tour.pdf" rel="self">that chapter is here</a>.<br>	•	I worked on a <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/RTOSinSmalltalk.html.pdf" rel="self">realtime OS in Squeak</a> whilst employed at Interval Research Corp<br>	•	A short paper on making <a href="http://www.rowledge.org/resources/tim's-Home-page/Squeak/LEBB.pdf" rel="self">BitBlt work for little-endian</a> machines without having an intermediate display-on-screen conversion<br><span>Squeak logo artwork</span><br>At the dawn of Squeak-time we needed a logo. Every project needs a logo. I designed one, it caught on and can be found all over the web, on T-shirts, sweatshirts, books, badges, underwear, hats and probably secret spy satellites in geosynchronous orbit. (No, seriously; there is now at least one satellite running Squeak code!)<br>Here are some files of the Squeak logo that you may like to use:-</p></div><p>Feel free to download them and use them for links etc. If you'd like any other size, I can easily generate them for you from vector artwork. If you want to use it for a project of some sort relating to Squeak you are most welcome to do so - if you are making a neat badge or shirt or publishing a book I’d love a copy if at all practical.</p>
				
			</div><!-- .content -->
		</div></div>]]>
            </description>
            <link>http://www.rowledge.org/tim/squeak/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298075</guid>
            <pubDate>Sun, 28 Feb 2021 23:21:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OMU – “One Man Unix”]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 56 (<a href="https://news.ycombinator.com/item?id=26298022">thread link</a>) | @marcodiego
<br/>
February 28, 2021 | http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html | <a href="https://web.archive.org/web/*/http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<center>

</center>
<h2>
History:
</h2>
In the late 1970s and early 1980s (the good old days of "hobby computing") before
the IBM PC and its clones took over the world, various microprocessor based kits
appeared on the hobbyist market. You could build a Z80-based board with 8K of
RAM, and with its hexadecimal keypad and LED display you could run simple
programs laboriously keyed in hex.
<p>
The first generation commercial machines also appeared - usually based on
the 8080 or the Z80 or 6502. The Commodore PET was one of the early sucesses
and it, along with the Commodore 64, Sinclair's three machines (ZX80, ZX81 and
Spectrum) and the BBC Micro probably accounted for most of the infant home-computer
market in Britain.
</p><p>
I decided on a different approach. Unhappy with the concept of having to re-live
the glory-days of the
<a href="http://www.computer50.org/mark1/MM1.html">
Manchester MkI
</a>
with the hobby-boards fraternity (!), and unhappy with the straitjacketed
architectures and joke operating systems of the 1st generation home computers,
I yearned for more. Specifically, what I wanted was something
more like a Unix clone at home. I was used to V7 Unix on the PDP-11 at university
and wasn't keen to step backwards 10 years to the technology of CP/M and BASIC
programming.
<br>
<i>
I wasn't to know that eight years later a guy called Linus
Torvalds was going to think the same thoughts and do much the same things. The
big difference was that he was in the right place and the right time and 
had internet connectivity - I didn't have any of these advantages!
</i>
</p><p>
I went off and built myself a 6809 based computer with 64K of RAM, a 360K
floppy disk drive and an RS232 interface which could drive a glass-TTY.
Please remember that this was 1982. Hard disks, megabytes of RAM and other
familiar modern things were a long way off.
</p><p>
After going through the usual hard work of writing a BIOS complete with
an S-records downloader, I was in a position to write myself an operating
system. Preliminary work on OMU started in late 1983. My earliest surviving
printouts of the sources on yellowed, faded lineprinter paper show that the
bulk of the work on OMU dates from March/April/May 1984.
</p><p>
Work was not helped by the fact that I was having to write a 'C' compiler
in parallel, but certainly by mid 1984 I had a perfectly usable O/S with a
primitive shell, a port of Unix 'ed' for an editor, and with 'fsck' and other
such tools available to repair the filestore disks when they got damaged by
miswrites from the rather dodgy floppy-disk hardware. I remember taking
the machine home over Christmas 1984 and typing up several reports using it
on the kitchen table.
</p><p>
<table>
<tbody><tr>
<td>
I just found this photo of the 1984 machine amongst a box of slides taken
over that Christmas. It appears to be the only photo of the machine I ever
took at the time.
<p>
At this point in its evolution, the hardware was mostly on one double
eurocard, with a floppy-disk interface piggybacked onto it. The floppy-disk
drive is in the metal box at front, and the bigger metal box at the RHS
of the PCBs is the power-supply.
</p></td>
<td>
<a href="http://www.pix.net/mirrored/discordia.org.uk/~steve/omu-big.jpg">
<img src="http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.jpg">
</a>
</td>
</tr>
</tbody></table>
</p><h2>
Features and misfeatures list:
</h2>
<ul>
<li>
Tiny (24K) Kernel.
</li><li>
V7 Unix-compatable filestore (doesn't support triple-indirection blocks).
Not exactly critical on a floppy-disk-only system!
</li><li>
Normal Unix-style use of /dev/* files to interface to devices.
</li><li>
Mountable/dismountable filestores as expected.
</li><li>
Shell is built-in to save space, rather than run as a process.
</li><li>
tty driver is exceedingly minimal, but functional.
</li><li>
No true multitasking (see below).
</li><li>
UIDs and GIDs not implemented. They're ignored on the filestore, and the
process table doesn't bother to hold them. Any files created would be given
UID = GID = 0.
</li></ul>
<p>
The lack of an MMU and the small amount of RAM available meant that I
decided against trying to implement true multitasking. Instead (like DOS
as it happens) I came up with a scheme whereby a process could launch another
process, but would have to wait for it to complete. Clunky, but it worked
OK.
</p><p>
For your entertainment (or possibly if you're interested in the possibility
of porting my old O/S to more modern hardware like that old XT that's
gathering dust under your table) here's a downloadable copy of my
final version of the 6809 OMU as it stood in 1987:
</p><center>

</center>
<p>
In order to make any use of OMU, I had compiled up a set of utilities like
'ed' and 'mount' and 'fsck'. Sadly I don't think I can make their sources
downloadable here as they were based on the Unix V7 sources for which we had
a Bell Labs "academic use" licence at the university.
</p><p>
<strong>
<span color="#FF0000">
NEW!
</span>
</strong>
The above packages now include some utilities which I did write from scratch:
</p><ul>
<li><strong>adb</strong>
An interactive disassembler. (Doesn't debug core-dumps though, just lets
you look at code in files).
</li><li><strong>aka</strong>
("Also Known As") - finds other files hardlinked to the one mentioned on the
command-line.
</li><li><strong>chbase</strong>
Prints the number(s) given on the command-line in octal, decimal &amp; hex.
</li><li><strong>hex</strong>
Makes Motorola S-record files for sending to the 6809. Usually runs on a
host machine (a PDP-11 originally).
</li><li><strong>ida</strong>
An intelligent disassembler - shares source-code with 'adb' above.
</li><li><strong>sh</strong>
The tiny shell needed by the OMU kernel. OMU runs this as if it was the
'init' process.
</li><li><strong>sirius</strong>
An interactive disk-examination program.
</li><li><strong>unhex</strong>
A program to convert Motorola S-records into an OMU-loadable file. Usually
runs on the 6809 itself of course.
</li></ul>
Sorry, no documentation, but the source-code should be documentation enough!
<p>
I
<strong>
don't
</strong>
suggest any modern user of OMU on a 6809 tries getting GNU utilities running
with it! Bear in mind that V7 sources would compile into a smaller executable
than any modern GNU equivalents. With the 64K memory-address limitation of my
6809, this was important! The BIOS and O/S accounted for about 24K of this, so
user-programs were limited to about 40K total. I never did complete my
page-switched 256K memory system.....
</p><p>
Mind you, if you're contemplating porting to a 68000 or IBM-PC, the size
constraints will be much less of a problem.
</p><hr>
<p>
My work on OMU was pretty much unnoticed by anyone else in the world (we didn't
have an internet connection in those days), but others in the Electrical
Engineering dept at Swansea University saw the potential to port OMU to one of
several 68000 single-board-computers which began to appear in the department
from about 1984/85 onwards.
</p><p>
My colleage Terry Barnaby and I were variously involved with porting OMU
to several of these 68000 based SBCs. Terry did most of the work!
The first stage was merely to take OMU and get it to run on the new
hardware much as my 6809 version was doing already. This was accomplishe
reasonably quickly, complete with the addition of the OMU's first driver
for a hard-disk.
The much greater memory-addressing ability of the 68000 coupled with the
fact that the SBCs typically had 256K of RAM on board meant that this version
of OMU soon featured some multi-tasking capabilities (though with no MMU
available the processes had to be well-behaved).
</p><p>
For convenience, the details of the filestore layout and the system-call
interface of 68000 OMU was designed to duplicate those of the commercial 68000
V7 Unix system made by "Codata" (we had just taken delivery of two of these
units to augment the aging PDP-11).
It is I think a credit to OMU's potential that
it soon became possible to compile programs on the Codata, and run them on
OMU with no problems. Indeed, it was also possible to take system binaries
shipped with the Codata and run them on OMU too - an easy way to get 'vi'
and other state-of-the-art (!) software on OMU without having to dig out the
sources and recompile!
</p><center>

</center>
<p>
Terry Barnaby and another of his colleages Tim Ingersoll then made some
fundamental changes to the message-handling abilities of the 68000 OMU port to
make it suitable for Real-Time signal processing and control applications.
This was after all what the two of them really
wanted as part of their Ph.D projects...! In 1988 they finished their
projects, wrote up and left. Part of their legacy was the RTOS version of OMU,
and I managed to salvage a set of sources for that too:
</p><center>

</center>
<p>
If any reader of these pages feels suitably daring they may be able to
beat me to the target of porting OMU (probably working from Terry's and my
initial 68000 version above) to the IBM PC. I consider that there really is no
point in aiming for the 386 processor machines onwards as Linux already does
everything you could hope for on that class of machines.
</p><p>
It does however seem that there is mileage in starting with the boot-loader
that comes with
<a href="http://metalab.unc.edu/pub/micro/pc-stuff/freedos/">
FreeDOS
</a>,
and getting OMU to run on 8086/80286 machines of which there must be
<strong>
loads
</strong>
lying around virtually unwanted these days.
</p><p>
If you do decide to try such a thing, then I wish you the best of luck and
I'll offer any email help I can. My email address is in the README file
included with the any of the sets of downloadable sources.
</p><h2>
Acknowledgements:
</h2>
My thanks go to Terry and Tim whose work in enhancing OMU is credited here
and really should have been reflected in a name-change from OMU back in the
Eighties! (I never did get it straight in my mind as to whether the "one man"
mentioned in the title were there to signify the number of authors or
the number of simultaneous users. Either way, neither was very relevant once
as the software started its modest spread in the department.)
<p>
My thanks also go to Alan Cox (he of Linux networking and kernel hacking fame)
without whose prodding this page might never have been written.
</p><center>
<a href="http://www.pix.net/mirrored/discordia.org.uk/~steve/steve.html">
Home
</a>
</center>
<hr>
<p>
Copyright (c) 1999, Steve Hosgood


</p></div>]]>
            </description>
            <link>http://www.pix.net/mirrored/discordia.org.uk/~steve/omu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26298022</guid>
            <pubDate>Sun, 28 Feb 2021 23:15:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Tungsten Fabric”: open-source network virtualization]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297724">thread link</a>) | @autoditype
<br/>
February 28, 2021 | https://tungstenfabric.github.io/website/ | <a href="https://web.archive.org/web/*/https://tungstenfabric.github.io/website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p><img src="https://github.com/tungstenfabric/website/raw/master/TungstenFabric_Gradient_RGB-03.png" height="75" alt="Tungsten Logo Gradient"></p>

<hr>

<p>Tungsten Fabric is an open source network virtualization solution for
providing connectivity and security for virtual, containerized or
bare-metal workloads.</p>

<p>Tungsten Fabric supports integrations with the following orchestrators:</p>
<div><div><pre><code>Openstack
Kubernetes
Openshift
vCenter
BYOO [Bring your own orchestrator]
</code></pre></div></div>

<p>Tungsten Fabric is a part of the <a href="https://www.lfnetworking.org/">Linux Foundation Networking Fund</a>, a project of the <a href="http://linuxfoundation.org/">Linux Foundation</a>.</p>

<hr>

<h2 id="start-using-tungsten-fabric">Start using Tungsten Fabric</h2>
<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-15-minute-deployment-with-k8s-on-AWS.html">Deploy Tungsten Fabric in 15 minutes on AWS with Kubernetes</a></p>

<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-Centos-one-line-install-on-k8s.html">Deploy Tungsten Fabric on Kubernetes in 1-step command - Centos</a></p>

<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-Ubuntu-one-line-install-on-k8s.html">Deploy Tungsten Fabric on Kubernetes in 1-step command - Ubuntu</a></p>

<p><a href="https://github.com/Juniper/contrail-ansible-deployer/wiki/Contrail-with-Openstack-Kolla">Deploy Tungsten Fabric On-Prem with Openstack</a></p>

<p><a href="https://tungstenfabric.github.io/website/Tungsten-Fabric-Architecture.html">Tungsten Fabric Detailed Architecture Document</a></p>

<p><a href="https://tungstenfabric.github.io/website/L10N/Tungsten-Fabric-Architecture-CN.html">Tungsten Fabric Detailed Architecture Document (Simplified Chinese)</a></p>

<h2 id="becoming-a-contributor">Becoming a contributor</h2>

<p>Whether you want to fix a typo in comments or introduce a brand new feature,
there are a few steps which make the process smoother:</p>

<ul>
  <li>
    <p>Create a <a href="https://identity.linuxfoundation.org/">Linux Foundation ID</a>, if you don’t have one yet. You’ll need this to subscribe to the mailing lists and to access the bugs and blueprints.</p>
  </li>
  <li>
    <p>Subscribe to the <a href="https://lists.tungsten.io/g/dev">dev@lists.tungsten.io</a> mailing list. If you wish, there are also <a href="https://lists.tungsten.io/">several other mailing lists</a> you can join as well.</p>
  </li>
  <li>
    <p>The wiki currently contains legal and technical docs, event decks and similar resources to boost your
understanding of Tungsten Fabric. This material will eventually be moving to
<a href="https://wiki.tungsten.io/">the wiki</a> or Git repositories.</p>
  </li>
  <li>
    <p><a href="https://join.slack.com/t/tungstenfabric/shared_invite/enQtMzM0MjMyMDIzMzk3LTZmY2FmY2JlZmRjN2YxMzgyOTNkNDZiNTRiYWU0NTRmNzI3N2RjMDIwY2UxZDlkODgzZDE0YzQ3MTlhNTg0N2I">Join Slack</a>. Post your questions to relevant channels, don’t abuse @here,
get help and help others. The mailing list works best for long-running
discussions; Slack is great for ad-hoc conversations.</p>
  </li>
  <li>
    <p>Before you push anything, you’ll need to sign a Contributor License Agreement
or CLA: either Individual CLA (ICLA) if you are an independent contributor, or
Corporate CLA (CCLA). We suggest you sign a CCLA if you are employed at a company
which pays you for your Tungsten Fabric-related work. CCLA also simplifies things
if your teammates plan to contribute as well. Both ICLA and CCLA are legal documents.
Please read them carefully. It’s usually smart to run the document past your
company’s legal department before signing and submitting it, if only to verify
that your contribution will be within your company’s policy. You can find all
ICLA/CCLA documents in the <a href="https://wiki.tungsten.io/display/TUN/Contributor+License+Agreement">Tungsten Fabric CLA Wiki</a>.</p>
  </li>
  <li>
    <p>If you’ve found a bug, <a href="https://jira.tungsten.io/projects/TFB/issues/TFB-15?filter=allopenissues">file a bug report</a> against the respective release in
Jira. Be sure to describe both expected and actual behavior. You’ll need
the bug ID later, so please do this even if you feel the change is trivial.</p>
  </li>
  <li>If you plan to develop a new feature, you must create or provide three things:
    <ul>
      <li><a href="https://jira.tungsten.io/projects/TFP/issues/TFP-6?filter=allopenissues">A blueprint</a>. A blueprint is a short piece of text describing which feature do you propose, why it is good to have it in Tungsten Fabric, and who will be developing it. Blueprints are very important as they are used to plan future releases of Tungsten Fabric.</li>
      <li><a href="https://github.com/Juniper/contrail-specs">A detailed technical spec</a>. Each blueprint should link to a more detailed technical specification document. These specifications must be submitted to the <a href="https://github.com/Juniper/contrail-specs">contrail-specs</a> GitHub repository. They are not stored or tracked in Jira.</li>
      <li><a href="https://jira.tungsten.io/projects/TFB/issues/TFB-15?filter=allopenissues">A Jira bug ticket</a>. While the blueprint briefly describes the work that will be done, the ticket is where the work actually happens (commits get linked to the ticket).</li>
      <li>Here is <a href="https://jira.tungsten.io/browse/TFP-13">an example of a complete Jira blueprint</a>.</li>
    </ul>
  </li>
  <li>Although contrail-specs and other Tungsten Fabric repositories are hosted on
<a href="http://github.com/tungstenfabric">GitHub</a>, they are managed with Gerrit. Please don’t send Pull Requests to the
GitHub repositories, and go to <a href="https://review.opencontrail.org/">https://review.opencontrail.org</a> instead.
Blueprint specs are submitted this way as well.</li>
  <li>
    <p>Note that Tungsten Fabric is currently migrating from Juniper owned <a href="https://review.opencontrail.org/">https://review.opencontrail.org</a> to [https://github.com/tungstenfabric/] email discuss@lists.tungsten.io for the latest information.</p>
  </li>
  <li>After getting Gerrit access as described below, clone the specs repository
with the command:
<code>git clone https://review.opencontrail.org/Juniper/contrail-specs</code>
and install the <a href="https://docs.openstack.org/infra/git-review/">git-review extension</a> which will allow you to submit specs as
well as code changes. In order to write a spec, start by copying the template
<code>blueprint_template.md</code> to a meaningful name in the appropriate subdirectory
for the release that you would like to target.</li>
</ul>

<p>With all of these in place, you are now ready to submit your specs and code to
Tungsten Fabric! How to write these specs and code is a different story though,
but we hope the links in the next section will help you to get started. You may
also want to consult a more detailed how-to available <a href="https://github.com/Juniper/contrail-community-docs/blob/master/Contributor/GettingStarted/getting-started-with-opencontrail-development.md">here</a>, in the
contrail-community-docs repo. And of course, feel free to ask questions on the
mailing list and in Slack channels!</p>

<h2 id="start-developing-tungsten-fabric">Start developing Tungsten Fabric</h2>

<p><a href="https://github.com/Juniper/contrail-dev-env">Build Tungsten Fabric</a></p>

<p><a href="https://github.com/Juniper/contrail-ansible-deployer/wiki/Debugging-contrail-code-in-contrail-microservices">Debug Tungsten Fabric</a></p>

<h3 id="development-timeline">Development Timeline</h3>

<p>NOTE: The columns and dates below are subject to change. An effort is still
underway to reconcile Tungsten Fabric processes and previously established
Juniper practices with respect to Contrail development timelines.</p>

<table>
  <thead>
    <tr>
      <th>Release</th>
      <th>Blueprint Due</th>
      <th>Specification Due</th>
      <th>Dev Complete</th>
      <th>GA Release</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5.0</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>2018-04-23</td>
    </tr>
    <tr>
      <td>5.0.1</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>&nbsp;</td>
      <td>2018-07-16</td>
    </tr>
    <tr>
      <td>5.1</td>
      <td>2018-07-15</td>
      <td>2018-08-22</td>
      <td>TBD</td>
      <td>Q1 2019</td>
    </tr>
  </tbody>
</table>

<h4 id="column-meanings">Column Meanings</h4>
<ul>
  <li>Release: The numeric identifier of the release</li>
  <li>Blueprint Due: Tungsten Fabric currently uses Jira, so the blueprint
due here refers to the <a href="https://jira.tungsten.io/projects/TFP/issues/TFP-6?filter=allopenissues">Jira Blueprint</a> which will be reviewed by the TSC for strategic alignment and release planning.</li>
  <li>Specification Due: The specification or “spec” is design document with
section headings that should be filled in, or at least though about and decided
to be non-applicable. Specs should be submitted as described earlier in this
document.</li>
  <li>Dev Complete: This column may be considered synonymous with “feature freeze”
and is intended to mark the transition from “new development” to “testing,
debugging and making production-ready”.</li>
  <li>GA Release: This column is the target release date. Historically Contrail has
usually missed release dates in order to finish incomplete features. Tungsten
Fabric will attempt to move to a time based release model, but this is still
under discussion.</li>
</ul>


      </section>
    </div></div>]]>
            </description>
            <link>https://tungstenfabric.github.io/website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297724</guid>
            <pubDate>Sun, 28 Feb 2021 22:30:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China and Huawei. The UK Gets a Lesson in Go]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297524">thread link</a>) | @nickdothutton
<br/>
February 28, 2021 | https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/ | <a href="https://web.archive.org/web/*/https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">




  <article>
    

    <section>




<p>4300 words, 14 minutes.</p>

<blockquote>
<p>This post was circulated privately in April 2020. Three months later the government announced that <a href="https://web.archive.org/web/20201101124331/https://www.gov.uk/government/news/huawei-to-be-removed-from-uk-5g-networks-by-2027">Huawei 5G equipment will be removed from the UK by 2027</a>, a reversal of their previous position. I’ve updated the timeline with that development. Otherwise, the text is almost unchanged from the original. Keep that in mind. It follows my <a href="https://blog.eutopian.io/huawei-5g/">July 2019</a> post on the consideration the UK and its allies are giving to Huawei as a supplier of 5G mobile equipment. If you didn’t read that, now is a good time. - Nick Hutton, 29th November 2020.</p>
</blockquote>

<p><img src="https://blog.eutopian.io/images/go-players.jpg" alt="Chinese Playing Go">
</p><center>
Chinese men playing Go. Ming Dynasty (1368–1644). Artist unknown.
</center>

<p><em>4000 years ago the Chinese invented “Go”. Unlike Indo-European Chess, Go takes longer to play and uses a larger board. In Go, the goal is not to confront your opponent directly as one does in Chess. The winning system in Go is to surround them gradually and occupy their territory.</em></p>

<h3 id="current-events">Current Events</h3>

<p>In the nine months since my last post, the UK elected a Prime Minister, formed a new government, resiled from the European Union, and fought a global pandemic. However, we’ve struggled to reach a consensus on whether or not we should buy 5G network equipment from Huawei, a designated <a href="https://www.ncsc.gov.uk/guidance/ncsc-advice-on-the-use-of-equipment-from-high-risk-vendors-in-uk-telecoms-networks#section_5">High-Risk Vendor</a>. Here’s a summary of events since my last post:</p>

<ul>
<li>The government announced Huawei can supply up to 35% of edge (non-core) equipment to Mobile Network Operators.<sup id="fnref:1"><a rel="footnote" href="#fn:1">1</a></sup></li>
<li>NCSC’s Technical Director, Dr Ian Levy lamented the lack of 5G suppliers, endorsed the Edge vs Core distinction for improving supplier diversity, and endorsed technical measures as an effective strategy for mitigating the security risks.<sup id="fnref:2"><a rel="footnote" href="#fn:2">2</a></sup></li>
<li>USA, Australia, and New Zealand restated a commitment to ban Huawei from national mobile networks. Canada was “studying the British decision (to permit Huawei)”.<sup id="fnref:3"><a rel="footnote" href="#fn:3">3</a></sup></li>
<li>The EU released a toolbox for 5G to “identify a possible common set of measures which are able to mitigate the main cybersecurity risks of 5G networks.”<sup id="fnref:4"><a rel="footnote" href="#fn:4">4</a></sup></li>
<li>Parliament debated the security implications of the “up to 35%” decision.<sup id="fnref:5"><a rel="footnote" href="#fn:5">5</a></sup></li>
<li>I wrote this post and circulated it privately among interested parties.</li>
<li>A Commons Defence sub Committee was convened to inquire into the security of the UK 5G networks.<sup id="fnref:6"><a rel="footnote" href="#fn:6">6</a></sup></li>
<li>MPs attempted unsuccessfully to have High-Risk Vendors excluded from 5G networks.<sup id="fnref:7"><a rel="footnote" href="#fn:7">7</a></sup></li>
<li>Huawei presented the ITU with a vision of an Internet where nation-states are the locus of control.<sup id="fnref:8"><a rel="footnote" href="#fn:8">8</a></sup></li>
<li>The US began requiring a license for the export of certain technologies that help foreign manufacturers produce semiconductors which are then sold to Huawei.<sup id="fnref:9"><a rel="footnote" href="#fn:9">9</a></sup></li>
<li>The Prime Minister instructed officials to draw up plans to reduce Huawei’s involvement in UK 5G to zero.<sup id="fnref:10"><a rel="footnote" href="#fn:10">10</a></sup></li>
<li>China’s UK ambassador said abandoning Huawei could jeopardise the UK’s new nuclear power plants and high-speed rail.<sup id="fnref:11"><a rel="footnote" href="#fn:11">11</a></sup></li>
<li>The government announced a ban on buying new Huawei 5G equipment after 2020 and ordered its removal by 2027.<sup id="fnref:12"><a rel="footnote" href="#fn:12">12</a></sup></li>
<li>NCSC’s Dr Levy blogged again, about how “everything had changed”. Huawei was out.<sup id="fnref:13"><a rel="footnote" href="#fn:13">13</a></sup></li>
<li>TikTok, the popular Chinese owned social media company announced it would scrap plans for a UK HQ.<sup id="fnref:14"><a rel="footnote" href="#fn:14">14</a></sup></li>
<li>Installation of new Huawei 5G equipment is to be prohibited after September 2021, earlier than anticipated.<sup id="fnref:15"><a rel="footnote" href="#fn:15">15</a></sup></li>
<li>As of 29th November 2020, UK network operators continued to buy and install Huawei equipment and contend that it will save them hundreds of millions of pounds compared to other vendors.</li>
</ul>

<p>I’m going to talk about the UK’s strategy for dealing with High-Risk Vendors. First in general terms and then specifically about statements made by Dr Levy about Huawei before the UK’s eventual about-face. I’ll focus on the technical aspects of risk mitigation and in so doing move this discussion from the abstract to the concrete. Finally, I’ll attempt to place the UK’s strategy within the wider context of future UK/China relations.</p>

<blockquote>
<p>Why after all this time are we still talking about Huawei?</p>
</blockquote>

<h3 id="man-in-the-vendor">Man In The Vendor</h3>

<p><a href="https://www.ncsc.gov.uk/collection/supply-chain-security">Supply Chain Risk</a> or “Man In The Vendor” (MiTV) as I call it, is one of Cyber Security’s <a href="https://en.wikipedia.org/wiki/Wicked_problem"><em>wicked problems</em></a>. Wickedness isn’t about difficulty. Wicked problems are different because traditional processes can’t resolve them satisfactorily. They have countless causes or factors, are hard to describe, and don’t have a right answer. I use the term MiTV because “Supply Chain Risk” sounds like something you could dilute or diversify away. It sounds like something you could outsource or insure against. MiTV sounds like what it is. There’s a man. He’s in the vendor. He has something to gain from being there.</p>

<blockquote>
<p>MiTV is hard to detect and counter in enterprise environments and <em>very hard</em> within mobile network operators. By definition, a network operator’s business is the shared use of that hardware and software. Different customer’s traffic, management traffic, security-critical commands and data, all flowing through the same chassis, circuit boards, processors, and memory. You trust the system to keep all this separate. When you have a MiTV, the system lies to you. - <a href="https://blog.eutopian.io/huawei-5g/">“The Eutopian. 29th July 2019”</a>.</p>
</blockquote>

<h3 id="mitv-in-practice">MiTV In Practice</h3>

<p>Any vendor can suffer a MiTV. Most incidents go unreported. How does this man get in the vendor and what does he do? No need for abstract threats. We have real cases. We don’t even have to put ourselves in the mind of a foreign adversary.</p>

<ol>
<li>Vendors are <a href="https://en.wikipedia.org/wiki/Dual_EC_DRBG">pressured</a> by governments to weaken their security.</li>
<li>Supply chains are <a href="https://web.archive.org/web/20200421225552/https://arstechnica.com/tech-policy/2014/05/photos-of-an-nsa-upgrade-factory-show-cisco-router-getting-implant/">compromised</a> and hardware or software tampered with.</li>
<li>Vendor operations are <a href="https://theintercept.com/2015/02/19/great-sim-heist/">hacked</a>.</li>
<li>Sometimes the man isn’t just in the vendor, he <a href="https://web.archive.org/web/20200512022950/https://www.srf.ch/news/schweiz/geheimdienstaffaere-cryptoleaks-weltweite-spionage-operation-mit-schweizer-firma-aufgedeckt">owns it</a>.</li>
<li>Infiltration can be so <a href="https://web.archive.org/web/20200421033936/https://krebsonsecurity.com/2020/02/hackers-were-inside-citrix-for-five-months/">deep</a> that the man might as well be writing the vendor’s product.</li>
<li>Sometimes the man <em>is</em> <a href="https://web.archive.org/web/20200530081851/https://www.wired.com/2015/12/researchers-solve-the-juniper-mystery-and-they-say-its-partially-the-nsas-fault/">writing the vendor’s product</a>.</li>
</ol>

<p>Once a man is in the vendor he can tamper with the software, hardware, or firmware that makes up their product. He can introduce malicious code or physical components before, and sometimes after equipment enters service. Even <a href="https://web.archive.org/web/20200601080443/https://arstechnica.com/information-technology/2013/12/inside-the-nsas-leaked-catalog-of-surveillance-magic/">cables</a> can be turned against you when you can’t trust your supply chain.</p>

<p>Not only can a network operator’s equipment be made to lie to them, but it’s common for mobile network operators to outsource some of the build and management of their networks to the equipment vendor. The operator buys a package. Equipment, support, and services to keep it running. It’s convenient because expertise is hard to come by and such equipment needs frequent updates. These arrangements provide an opportunity for compromise of the network throughout its lifecycle. In these cases, the hardware or software product doesn’t need to be flawed or weakened when you buy it. It’s enough that the engineers managing it and the tools and systems they bring to that task can become vectors for exploitation or attack. Unwittingly or otherwise.</p>

<h3 id="mitv-an-adversary-s-long-term-strategy">MiTV, An Adversary’s Long Term Strategy</h3>

<p>MiTV has long-term advantages for the adversary. It’s something he can <em>invest in</em> because it pays regular dividends in the long run. It provides persistent access to information and systems in a way that’s hard to prevent, hard to detect, hard to shut down, and hard to trace back to a particular moment in time. While the adversary is in the vendor and the vendor’s product is in your network he gathers sensitive information, collects credentials, and profiles users he can then target to further his mission. Or just bides his time, knowing that he can activate his implant at a time of his choosing. It’s for this reason that such programmes are so valuable to intelligence agencies and their existence remains such a closely guarded secret, even years after they’ve stopped producing operationally useful information.</p>

<p>The man in the vendor isn’t always a state or state-affiliated. However, they tend to be more patient, better funded, harder to detect, and more likely to be interested in <em>specific</em> information or a specific class of target than most. MiTV is a tactic employed by states with a tier-1 offensive cyber security capability. This means the US, UK, Russia, Israel, and of course China. This list isn’t exhaustive. My first MiTV was in the 90s and probably French. They were replacing router firmware with a modified version to gain access to a negotiating team within a large defence contractor. That said, attribution was then as it is now, <em>difficile</em>.</p>

<p>It’s these kinds of threats posed by these actors in general and (one presumes) China in particular that Dr Levy <a href="https://www.ncsc.gov.uk/blog-post/the-future-of-telecoms-in-the-uk">said in January</a> could be countered with technical measures. Measures like limiting Huawei to peripheral (non-core) parts of the network. Measures like network segmentation, anomaly detection, and integrity checking. Measures presumably implemented and operated by security teams at national mobile network operators. Three, O2, Vodafone, and EE. Companies that despite the efforts of their security teams, are hacked <a href="https://www.cybereason.com/blog/operation-soft-cell-a-worldwide-campaign-against-telecommunications-providers">regularly</a>.</p>

<p>Remember, individuals within security teams at mobile operators are drawn from the same pool of people that failed to even detect <a href="https://www.ncsc.gov.uk/news/apt10-continuing-target-uk-organisations">APT10’s</a> multi-year <a href="https://www.reuters.com/investigates/special-report/china-cyber-cloudhopper/">Cloud Hopper</a> operation.</p>

<h3 id="the-odds">The Odds</h3>

<blockquote>
<p>Cyber Security isn’t a numbers game, but <a href="https://web.archive.org/web/20190403010530/https://foreignpolicy.com/2010/03/03/chinas-hacker-army">Foreign Policy magazine</a> estimates China’s <a href="https://en.wikipedia.org/wiki/Chinese_cyberwarfare">“hacker army”</a> at between 50,000 and 100,000 people. It’s against this army that security teams at national mobile operators will be pitted. Are already pitted. Regardless of whether or not such an army is granted a strategic advantage by the presence of Huawei hardware and software. The supply chain to which they may or may not have special access.</p>
</blockquote>

<p>Installing 3rd party security solutions on top of mobile network assets (if such solutions were available, which they are not) offers no meaningful assurance against a MiTV. The first thing a MiTV does is prevent its detection by <a href="https://dl.acm.org/doi/pdf/10.1145/358198.358210">subverting any direct method of observation</a>. Detecting a MiTV is a little like trying to spot a stealth aircraft using the “hole” in the picture where the object is, or the airflow disruption it leaves in its wake. Hard to sense directly. I’m highly critical of analogies in cyber security, so I won’t labour this one further. Suffice it to say that many MiTV operations have only been discovered because the “man” made a mistake. A slip-up. …</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/">https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/</a></em></p>]]>
            </description>
            <link>https://blog.eutopian.io/huawei-5g-the-uk-gets-a-lesson-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297524</guid>
            <pubDate>Sun, 28 Feb 2021 22:02:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HardenedBSD February 2021 Status Report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297430">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://hardenedbsd.org/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report | <a href="https://web.archive.org/web/*/https://hardenedbsd.org/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="page" class="page">

     <!-- /header -->

    
    <!-- Messages and Help -->
        
    <!-- Breadcrumbs -->
    
    
    <!-- Three column 3x33 Gpanel -->
    
    <div id="columns">
      <div>

        <div id="content-column">
          <div>

            
            <section id="main-content" role="main">

                                            <header id="main-content-header">

                                      
                  
                  
                </header>
                            
                              <div id="content">
                  <div id="block-system-main">  
  
  <article id="node-221" about="/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report" typeof="sioc:Item foaf:Document" role="article">
  
  
      
  
  <div>
    <div><div><div property="content:encoded"><p>This month was a busy one, especially for our infrastructure. We purchased and received three refurbished Dell servers and one Cavium ThunderX server. Two of the three Dell servers were deployed. One is being used for our GitLab migration[1][2]. The second one is being set up as the HardenedBSD 14-CURRENT nightly build and package build server.</p>
<p>With the ThunderX server, we now have a production-capable arm64 server. I'm hoping that we can promote arm64 as a teir 1 architecture by the end of March. Though the server is deployed, I still need to copy the build scripts over and perform is final configuration.</p>
<p>FreeBSD recently landed a W^X implementation (congrats!), but it interferes with our PaX-inspired implementation. In addition to infrastructure work, I've been looking into this. I'm only able to reproduce when building packages--when there's a heavy load on the system. I'm working on some candiate patches, but they're not ready for commit.</p>
<p>The new package build server can be reached at [3]. The Tor onion service address is [4].</p>
<p>The next non-hackery item on my list is to reach out to 2020 donors that donated $250 USD or more to HardenedBSD. I need to give them their tax statement in case they itemize their taxes. I also need to reach out to recent donors to see if they want their name listed on our donations page.</p>
<p>I appreciate the help and support from the community. It's because of you that this project is possible. Your donations enable me to serve you.</p>
<p>[1]: <a href="https://git.hardenedbsd.org/">https://git.hardenedbsd.org/</a><br>
[2]: <a href="https://groups.google.com/a/hardenedbsd.org/g/users/c/wZgihY3PR8E/m/gVbZydJGAQAJ">https://groups.google.com/a/hardenedbsd.org/g/users/c/wZgihY3PR8E/m/gVbZ...</a><br>
[3]: <a href="http://ci-08.md.hardenedbsd.org/">http://ci-08.md.hardenedbsd.org/</a><br>
[4]: <a href="http://t3xwovqp3hijxp2wskcg2ot5jqpwjd63uaeodsp3ltduhvpxb47aegad.onion/">http://t3xwovqp3hijxp2wskcg2ot5jqpwjd63uaeodsp3ltduhvpxb47aegad.onion/</a></p>
</div></div></div>  </div>

  
  
  <span property="dc:title" content="HardenedBSD February 2021 Status Report"></span><span property="sioc:num_replies" content="0" datatype="xsd:integer"></span></article>

  </div>                </div>
              
              <!-- Feed icons (RSS, Atom icons etc -->
              
            </section> <!-- /main-content -->

            
          </div>
        </div> <!-- /content-column -->

                
      </div>
    </div> <!-- /columns -->

    
    <!-- four-4x25 Gpanel -->
    
          
    
  </div> <!-- /page -->
</div></div>]]>
            </description>
            <link>https://hardenedbsd.org/article/shawn-webb/2021-02-28/hardenedbsd-february-2021-status-report</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297430</guid>
            <pubDate>Sun, 28 Feb 2021 21:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIT with Restrictions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26297240">thread link</a>) | @fuckthemachine
<br/>
February 28, 2021 | https://blog.yossarian.net/2020/06/03/You-may-not-use-my-projects-in-a-military-or-law-enforcement-context | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/06/03/You-may-not-use-my-projects-in-a-military-or-law-enforcement-context">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jun 3, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#devblog">devblog</a>
    
  
  </p>


<p>As of yesterday and continuing into today, I will be adding the following rider
to the majority of my <a href="https://github.com/woodruffw">open-sourced projects</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre>The following terms additionally apply and override any above terms for
applicable parties:

You may not use, copy, modify, merge, publish, distribute, sublicense,
and/or sell copies of the Software in a military or law enforcement context,
defined as follows:

1. A military context is a professional context where the intended application
of the Software is integration or use with or by military software, tools
(software or hardware), or personnel. This includes contractors and
subcontractors as well as research affiliates of any military organization.

2. A law enforcement context is a professional context where the intended
application of the Software is integration or use with or by law enforcement
software, tools (software or hardware), or personnel. This includes
contractors and subcontractors as well as research affiliates of any law
enforcement organization.

Entities that sell or license to military or law enforcement organizations
may use the Software under the original terms, but only in contexts that do
not assist or supplement the sold or licensed product.

Students and academics who are affiliated with research institutions may use
the Software under the original terms, but only in contexts that do not assist
or supplement collaboration or affiliation with any military or law
enforcement organization.
</pre></td></tr></tbody></table></code></pre></div></div>

<p>In plain English: if you work for the military (<em>any</em> military) or law enforcement
(<em>any</em> law enforcement), you will not be allowed to use my projects in a professional
setting. You may continue to use them in a <strong>personal</strong> setting with no restrictions.</p>

<p>If you work for a company that sells or licenses to a military or law enforcement
organization, you may continue to use my projects in professional settings that
are <em>not</em> connected to the settings in which you sell or license to those organizations.
Just as above, you may continue to use them under their original terms in a personal setting
with no restrictions.</p>

<p>If you are a student or academic at a research institution, you may continue to use my projects
in professional settings that are not connected to the work of your institution on
military or law enforcement contracts or programs. Just as above, you may continue to use them
under their original terms in a personal setting with no restrictions.</p>

<p>I’m not a lawyer, and I didn’t consult with one. I have no idea how enforceable this is.
You’re welcome to use it as well, provided that you understand that it could be legal nonsense.</p>

<h2 id="open-source">“Open source”?</h2>

<p>Like all definitions, “open source” is a convention. We get to choose what we make of it<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<p>I’m okay with calling these terms “permissive” rather than “open,” but I’ll leave that
up to others to settle.</p>

<h2 id="what-about">What about…?</h2>

<p>I am painfully aware of the fact that millions of people are employed by the defense and law
enforcement industries, either directly, indirectly, or by proxy. I count myself as one of them.</p>

<p>I am aware that defense and law enforcement are functionally middle-class job programs and
are populated primarily by disaffected and myopic, not malicious, individuals. I realize
that these industries are frequently highly specialized and that individuals in these industries
may feel like they have no other recourse for their livelihoods.</p>

<p>I am also aware that I am a small fry. My (personal) projects are insignificant within the
greater pantheon of open source. I will continue to contribute to other projects under
their terms, advocating for modification of those terms when I believe it to be appropriate.</p>

<p>I plan to add a badge
<a href="https://raster.shields.io/badge/license-MIT%20with%20restrictions-green.png">like this</a> to projects
that have been relicensed. My intent is to <strong>not</strong> sandbag users with new terms.</p>

<p>I act in spite of all of these things. I believe that I have a moral obligation to do so.
I believe that it is the <em>least</em> I can do, in the context of my hobby and passion. I will do more.</p>

<p>I’m happy to discuss it with you, reader. My contact information is
<a href="https://yossarian.net/">on my site</a>.</p>

<hr>




<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2020/06/03/You-may-not-use-my-projects-in-a-military-or-law-enforcement-context</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297240</guid>
            <pubDate>Sun, 28 Feb 2021 21:29:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Associative Arrays in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26297204">thread link</a>) | @avivallssa
<br/>
February 28, 2021 | https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/ | <a href="https://web.archive.org/web/*/https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.migops.com/blog/2021/02/28/handling-global-associative-arrays-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297204</guid>
            <pubDate>Sun, 28 Feb 2021 21:25:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exponential exploit: Why AppSec is hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26297016">thread link</a>) | @beny23
<br/>
February 28, 2021 | https://beny23.github.io/posts/one_plus_one_is_crash/ | <a href="https://web.archive.org/web/*/https://beny23.github.io/posts/one_plus_one_is_crash/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this blog post, I would like to explore how missing input validation even in a trivial service
can leave parts of server infrastructure crumbling.</p><p>In my opinion, this why securing applications (AppSec) is very difficult. Put supply chain attacks, unpatched systems
and misconfiguring services to one side for a minute and consider that a lot of software is written by
developers who do not necessarily consider all the edge cases or implications of what can go
wrong even in the simplest of pieces of code (or just copy/paste from Stackoverflow).<br>Unfortunately, vulnerable software in all sectors can get rushed out due to deadlines or inexperience
and it is my opinion that poor coding practices in applications provide an interesting attack vector
everywhere.</p><p>Allow me to demonstrate: Given the following (admittedly oversimplified) problem statement:</p><blockquote><p>Write a microservice that increments a decimal number by one</p></blockquote><p>Keeping it simple and very generic, I came up with the following Spring Boot application:</p><div><div><table><tbody><tr><td><pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td><td><pre><code data-lang="java">@RestController
<span>public</span> <span>class</span> <span>DemoController</span> <span>{</span>

    @PostMapping<span>(</span><span>"/increment"</span><span>)</span>
    @ResponseBody
    DemoModel <span>increment</span><span>(</span>@RequestBody DemoModel model<span>)</span> <span>{</span>
        DemoModel result <span>=</span> <span>new</span> DemoModel<span>();</span>
        result<span>.</span><span>setNumber</span><span>(</span>model<span>.</span><span>getNumber</span><span>().</span><span>add</span><span>(</span>BigDecimal<span>.</span><span>ONE</span><span>));</span>
        <span>return</span> result<span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table></div></div><p>My model looked like so</p><div><div><table><tbody><tr><td><pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td><td><pre><code data-lang="java"><span>public</span> <span>class</span> <span>DemoModel</span> <span>{</span>
    <span>private</span> BigDecimal number<span>;</span>

    <span>public</span> BigDecimal <span>getNumber</span><span>()</span> <span>{</span>
        <span>return</span> number<span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>setNumber</span><span>(</span>BigDecimal number<span>)</span> <span>{</span>
        <span>this</span><span>.</span><span>number</span> <span>=</span> number<span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table></div></div><p>A reasonable implementation. I even used <code>BigDecimal</code> so that I don’t have rounding/precision
issues, and the service is pretty trivial:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td><td><pre><code data-lang="bash">$ curl http://localhost:8080/increment <span>\
</span><span></span>  -d <span>'{"number":1}'</span> <span>\
</span><span></span>  -H <span>"Content-Type: application/json"</span>
<span>{</span><span>"number"</span>:2<span>}</span>
</code></pre></td></tr></tbody></table></div></div><p>As it turns out - quite a bit.</p><p>Here is a view of what the CPU did on my mac after hitting the service with a few requests over
a 10-minute period:</p><p><img src="https://beny23.github.io/images/one_plus_one_is_crash_cpu_stats.png" alt=""></p><p>And here’s the memory:</p><p><img src="https://beny23.github.io/images/one_plus_one_is_crash_memory_stats.png" alt=""></p><p>And what was the culprit. Not a vulnerability in Sprint Boot, not thousands of requests
(as a matter of fact there were just 4 requests, you can see it in the CPU graph, each time another request
came in, another CPU was used up 100%).</p><p>The requests were just:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="bash">curl http://localhost:8080/increment <span>\
</span><span></span>  -d <span>'{"number":9999999e99999999}'</span> <span>\
</span><span></span>  -H <span>"Content-Type: application/json"</span> &gt;/dev/null
</code></pre></td></tr></tbody></table></div></div><p>The number <code>9999999e99999999</code> has near enough <code>10,000,000</code> digits. If I wanted to send such
a number without the scientific notation (the <code>e</code> in the number), I’d have to send a payload that’s
many 10 megabytes big. That would get noticed very quickly. However, the payload is miniscule. And when java
is calculating this number (the plus 1 operation), it takes a long time because it tries to make an exact calculation.
I didn’t wait around to find out how long the CPU was busy. I just killed the
program after 10 minutes.</p><p>Imagine how much havoc such a vulnerability can create in a cloud setting, where instances sit in
Auto Scaling Groups. Imagine 100 such requests hit your instances. Every time we get 100% CPU, we
spin up another instance, that’s expensive. And as the processing also uses up quite a bit of memory,
it’s very likely that other requests don’t get a look-in.</p><p>This makes a very effective Denial of Service attack. Sure, when identified it is easy enough to fix by
not allowing the scientific notation understood by <code>BigDecimal</code> as input to JSON, but that’s not provided
as standard. How can you be sure that your codebase isn’t vulnerable?</p><p>In my opinion this is where development and testing teams need to have the experience in spotting these
potential issues. The above is just one example of how a seemingly innocuous piece of code can be abused.</p><p>How would your code fare against the <a href="https://github.com/minimaxir/big-list-of-naughty-strings">Big List of Naughty Strings</a>?</p><ul></ul></div></div>]]>
            </description>
            <link>https://beny23.github.io/posts/one_plus_one_is_crash/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26297016</guid>
            <pubDate>Sun, 28 Feb 2021 21:00:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little League wants all your information]]>
            </title>
            <description>
<![CDATA[
Score 383 | Comments 184 (<a href="https://news.ycombinator.com/item?id=26296845">thread link</a>) | @ColinWright
<br/>
February 28, 2021 | https://honeypot.net/post/little-league-wants-all-your-information/ | <a href="https://web.archive.org/web/*/https://honeypot.net/post/little-league-wants-all-your-information/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <div>
                <h3>Little League wants all your information</h3>
                
                    <p><em></em>
                        <span> Sun, Feb 28, 2021 
                                           </span>
                        <em></em>
                        <span>2-minute read</span>
                    </p>
                
            </div>

            <p>To sign kids up for our city’s Little League baseball program, you have to prove that they’re residents, which is reasonable. What’s not reasonable is the amount of information you have to provide on the registration website. You have to upload scans of a document in each of 3 categories:</p>
<blockquote>
<p><strong>Proof of Residency 1</strong>
Choose one of the following: Driver’s license, School records, Vehicle records, Employment records, Insurance documents</p>
<p><strong>Proof of Residency 2</strong>
Choose one of the following: Welfare/child care records, Federal records, State records, Local records, Support payment records, Homeowner or tenant records, Military records</p>
<p><strong>Proof of Residency 3</strong>
Choose one of the following: Voter’s registration, Utility bills, Financial records, Medical records, Internet, cable, or satellite bills</p>
</blockquote>
<p>That alone is ripe for identity theft, but couple it with their privacy policy which includes this (emphasis mine):</p>
<blockquote>
<p>Without limitation, this typically requires the use of certain personal information, including registration data, event data, and other personal information, to provide program information, <strong>special offers or services through Little League and/or its trusted sponsors, partners, or licensees</strong>, to fulfill your requests for information or products/services, to maintain a list of verified and eligible participants, to maintain a list of volunteers and provide them with the operating tools to manage leagues, or to respond to your inquiries about our programs.</p>
</blockquote>
<p>In other words, you have to upload your most private information and agree to allow them to do as they like with it, including sharing it with whomever they like for any reason they choose.</p>
<p>This is unacceptable.</p>
</div></div>]]>
            </description>
            <link>https://honeypot.net/post/little-league-wants-all-your-information/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296845</guid>
            <pubDate>Sun, 28 Feb 2021 20:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Demand for Software Engineers Will Stay High]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296653">thread link</a>) | @gamma3
<br/>
February 28, 2021 | https://coding-time.co/software-engineers-demand/ | <a href="https://web.archive.org/web/*/https://coding-time.co/software-engineers-demand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header></header><section itemprop="articleBody"><p><span>
      <a href="https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/2cefc/demand-supply.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Classic Supply and Demand Chart" title="Classic Supply and Demand Chart" src="https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/f058b/demand-supply.png" srcset="https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/c26ae/demand-supply.png 158w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/6bdcf/demand-supply.png 315w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/f058b/demand-supply.png 630w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/40601/demand-supply.png 945w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/78612/demand-supply.png 1260w,
https://coding-time.co/static/3d51c2c03f9d59800b7e42b89ca21fa0/2cefc/demand-supply.png 1400w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy">
  </a>
    </span></p>
<p>It seems like everybody needs software engineers. Demand is much higher than supply. This translates to jobs with good pay and lots of options to choose from. Want a full-time job? Startup job with equity? Remote contract work with 3 months off every year? No problem!</p>
<p>When I was just beginning to learn about programming, I wondered whether there would always be a need for millions and millions of programmers.</p>
<p>After my 15 years in the industry it looks like the demand is going nowhere. Some stats from the <a href="https://www.bls.gov/ooh/computer-and-information-technology/software-developers.htm">US Department of Labor</a>:</p>
<table>
<thead>
<tr>
<th>Software Development Jobs in the US</th>
<th>Number</th>
<th>Increase</th>
</tr>
</thead>
<tbody>
<tr>
<td>In 2016</td>
<td>1,256,200</td>
<td></td>
</tr>
<tr>
<td>In 2019</td>
<td>1,469,200</td>
<td>+17%</td>
</tr>
</tbody>
</table>
<blockquote>
<p>Job Outlook, 2019-29 is 22% (much faster than average). The average growth rate for all occupations is 4 percent.</p>
</blockquote>
<p>In the United Kingdom alone, there are now <a href="https://www.forbes.com/sites/davidprosser/2018/04/06/uk-technology-start-ups-hit-all-time-high/#5654d1415d85">10k technology startups</a>.</p>
<p>Here are my observations on why that is:</p>
<h3>1. The whole world runs on&nbsp;software</h3>
<p>This is probably obvious because the transition has been ongoing for a few generations. However, it cannot be understated. Almost every business / organisation in the world needs a website or an app, plus lots of software. At my current company with 80 employees we use more than 20 different SaaS solutions for HR, accounting, recruiting and more. Every person with internet access (which eventually will be the whole world) uses apps and websites every day, and many people use software at work. Large companies often need custom software.</p>
<h3>2. Most things get built many&nbsp;times</h3>
<p>Why is there Bing when there is Google? Why are there a thousand competing e-commerce platforms? Why are there so many messaging apps, each built from scratch by a different team? This seems like duplicated effort but it’s normal. It’s just how competition works and it is not unique to software. For example, there are many car companies, each with tens of thousands of employees designing and building very similar cars.</p>
<p>Part of the reason is software is still local. There is “X of Asia” for almost any X you can think of.</p>
<h3>3. Code has limited&nbsp;lifetime</h3>
<p>It might seem that once an app is built it is “done”. When I worked at Facebook friends asked me “Is there still anything to do?” However, most code is being changed constantly and most companies are constantly hiring. Each line of code has a lifetime of only a few years. Sometimes as a product gets old it is easier to throw it away and rebuild using modern technologies. I have seen this happen to custom in-house systems and public-facing websites. This is again similar to car companies constantly innovating and designing new cars.</p>
<p>From the 3 points above you can already see a clear pattern:</p>
<ul>
<li>We need more and more software</li>
<li>There are more and more software solutions to do anything</li>
<li>Each solution requires software engineers constantly</li>
</ul>
<p>But what if programming becomes easier over time? Surely we would need fewer programmers then? Read on…</p>
<h3>4. Code sharing didn’t&nbsp;happen</h3>
<p>In the 90s there was a dream of code sharing, where we design software components with business logic inside them and anyone will be able to reuse them like lego bricks. This didn’t work out, not even reusing business logic across projects written in Java. Across technology stacks, the story is even worse. There was COM but it was Windows-only. Yes, you can call Rust from Python but it’s not become the standard way of building software. There are many programming languages and new ones keep appearing. At my last company for example, we rewrote a part of an existing codebase from Ruby to Rust.</p>
<p>Code reuse did improve over the years thanks to package managers, GitHub and an explosion of open source libraries. Systems like npm are a huge step forward. However, we came nowhere near the dream of true code sharing. Open source libraries help a lot but not enough to significantly slow the demand for engineers.</p>
<h3>5. Tools are improving but projects are getting more&nbsp;complex</h3>
<p>Using a language with a garbage collector in a modern IDE with lots of libraries and going “serverless” is more productive than writing C++ in 1995. Can you now hire five times fewer engineers than in 1995 for the same project? Probably. But instead, it’s more likely you hire the same number of engineers and the project will be more ambitious because customers came to expect more.</p>
<h3>6. New platforms come&nbsp;out</h3>
<p>Ten years ago it was enough to hire web developers. Now you need to hire web, Android and iOS developers. Depending on your product, you may also build Messenger bots and WeChat apps.</p>
<p>The biggest step forward here was probably the web. Suddenly you didn’t have to build a Mac, Linux, and Windows desktop apps but could just build your product in JavaScript and then it would work anywhere (minus browser incompatibilities, this got better over time). The fact web standards happened is a small miracle — remember <a href="https://en.wikipedia.org/wiki/Browser_wars">Browser Wars</a>? However, because of mobile, the web is now less relevant than it was 10 years ago. Today, frameworks like Unity, React Native or Flutter are trying to abstract over multiple platforms to make software development easier and cheaper.</p>
<h3>7. Extra (for fun): AI to replace software engineers?</h3>
<p>Imagine someone designs software that can replace most engineers. For example, instead of a team of 6 engineers, there would be one human “tech lead” who specifies high-level requirements and the program translates them into bug-free code.</p>
<p>No-one has a good idea when this could happen. If it happens the demand for engineers would drop immensely. But with such technology the demand for humans in other professions would likely drop too, so relative to other professions programming <em>might</em> still be in demand.</p></section><hr></article></div>]]>
            </description>
            <link>https://coding-time.co/software-engineers-demand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296653</guid>
            <pubDate>Sun, 28 Feb 2021 20:17:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mrcal: Principled Camera Calibrations]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296625">thread link</a>) | @dima55
<br/>
February 28, 2021 | http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
This is a big deal.
</p>

<p>
In my day job I work with images captured by cameras, using those images to
infer something about the geometry of the scene being observed. Naturally, to
get good results you need to have a good estimate of the behavior of the lens
(the "intrinsics"), and of the relative geometry of the cameras (the
"extrinsics"; if there's more than one camera).
</p>

<p>
The usual way to do this is to perform a "calibration" procedure to compute the
intrinsics and extrinsics, and then to use the resulting "camera model" to
process the subsequent images. Wikipedia has <a href="https://en.wikipedia.org/wiki/Camera_resectioning">an article</a>. And from experience,
the most common current toolkit to do this appears to be <a href="https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html">OpenCV</a>.
</p>

<p>
People have been doing this for a while, but for whatever reason the existing
tools <i>all</i> suck. They make basic questions like "how much data should I gather
for a calibration?" and "how good is this calibration I just computed?" and "how
different are these two models?" unanswerable.
</p>

<p>
This is clearly seen from the links above. The wikipedia article talks about
fitting a pinhole model to lenses, even though no real lenses follow this model
(telephoto lenses do somewhat; wider lenses don't at all).
</p>

<p>
And the OpenCV tutorial cheerfully says that
</p>

<pre>Re-projection error gives a good estimation of just how exact the found
parameters are. The closer the re-projection error is to zero, the more accurate
the parameters we found are.
</pre>

<p>
This statement is trivially proven false: throw away most of your calibration
data, and your reprojection error becomes very low. But we can all agree that a
calibration computed from less data is actually worse. Right?
</p>

<p>
All the various assumptions and hacks in the existing tooling are fine as long
as you don't need a whole lot of accuracy out of your results. I need a lot of
accuracy, however, so all the existing tools don't work for my applications.
</p>

<p>
So I built a new set of tools, and have been using them with great delight. I
just got the blessing to do a public release, so I'm announcing it here. The
tools are
</p>

<ul>
<li><a href="https://github.com/dkogan/mrgingham">mrgingham</a>: a chessboard corner finder. OpenCV has one, but as far as I can
tell, it doesn't work; and it is very slow to tell you that. mrgingham is
relatively quick, robust to all sorts of lens behaviors, and reports the
accuracy of its output. This is a C++ library with Python bindings, and a
commandline tool. 99% of the time the commandline tool is what I use.
</li>

<li><a href="https://github.com/dkogan/mrcal">mrcal</a>: a large toolkit to run calibrations, to manipulate images and camera
models in all sorts of ways, and to visualize stuff. This toolkit does a
<i>lot</i>. It's a C library and a Python library and a number of commandline
tools. Currently the C library exists primarily in the service of the other
two, but it's already very capable, and will become more so over time.
</li>
</ul>

<p>
mrcal does a whole lot to produce calibrations that are as good as possible, and
it will tell you just how good they are, and it includes visualization
capabilities for extensive user feedback. An overview of the capabilities of the
toolkit (with lots of pretty pictures!) is at the <a href="http://mrcal.secretsauce.net/tour.html">tour of mrcal.</a>
</p>

<p>
There's a <i>lot</i> of documentation and examples, but up to now I have been the
primary user of the tools. So I expect this to be somewhat rough when others
look at it. Bug reports and patches are welcome.
</p>

<p>
mrcal is an excellent base, but it's nowhere near "done". The documentation has
some notes about the planned features and improvements, and I'm always reachable
by email.
</p>

<p>
Let me know if you try it out!
</p>

  </div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/28_mrcal-principled-camera-calibrations.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296625</guid>
            <pubDate>Sun, 28 Feb 2021 20:15:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The American-Dream-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 20 (<a href="https://news.ycombinator.com/item?id=26296397">thread link</a>) | @jger15
<br/>
February 28, 2021 | https://www.thepullrequest.com/p/the-american-dream-as-a-service | <a href="https://web.archive.org/web/*/https://www.thepullrequest.com/p/the-american-dream-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h5>Austen Allred is the CEO and founder of Lambda School, a unique coding school that pioneered the ‘income-sharing agreement’ (ISA) model, whereby students only pay if they’re hired in their field of study. Lambda came out of incubator Y Combinator, before which he lived in his two-door Honda Civic and scalped soccer tickets at Stanford Stadium to get by. Prior to Bay Area entrepreneurship, he did a two-year mission to the Ukraine where he learned Russian and knocked on lots of doors. The interview was conducted via Zoom with Austen in Southern Utah, from where he routinely tweets out enviable photography of Utah’s stunning landscape.</h5><p><strong>Your posts are some of the most uplifting things in my feed. They’re either screenshots from an internal Slack or a retweet, and it’s a Lambda student saying: I went from making $20,000 in some service job, and now I'm making $80,000/year doing something technical at (say) Cisco, and you've totally changed my life. </strong></p><p><strong>One thing you often post that I think isn’t obvious to people who don't run a socio-economic escalator is all the necessary polish and look-and-feel of being part of the bougie techie class. For example, how you have this email protocol to set up a meeting. Or that if you think you're underpaid, you go in and you say, </strong><em><strong>screw you, pay me more or I leave</strong></em><strong>. It's intriguing that you don’t only have to educate them to turn them into front end engineers, you also have to teach them the social skills around that to become that bougie techie person.</strong></p><p>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. It's very clear in all these protocols that we have in tech that you and I understand, you have to learn them the hard way. I'll give you a couple of examples. When I was in sixth grade, I was selling stuff on eBay. I was just this kid trying to hustle, and I had this mentor/entrepreneur who came into high school every now and then and just talked with us. And I was like, okay, real talk! What do I need to do to be taken seriously, because nobody takes me seriously because I'm a 15-year-old kid? And he sat me down and he said: <em>We are going to start using this thing called Gmail</em>. <em>I'm going to send you an invite, and you're going to set up firstname.lastname@gmail.com, no numbers, no nonsense, nothing else, you're going to have no signature, and you're only ever going to send text emails for the rest of your life.</em> <em>That's step one</em>. He just walked me through all this really, really basic stuff. </p><p>There was this other time I was in college…I was hustling and trying to get into startups and there was this guy at a conference I wanted to work with, so I went up and talked to him. And I said <em>what can I do to be like you? </em>He gave me his business card and said <em>just ping me next week</em>. </p><p>I spent hours and hours and hours looking up what <em>ping me</em> meant. I couldn't find anything. So eventually I called somebody and said <em>hey, this guy said ping me. What does that mean?</em> <em>How do I ping? </em>And that person was like, <em>no, no, it’s a call or an email or anything really, just reach out to them. Doesn’t matter how.</em> <em>That's all that ping means</em>. <em>You know, like a cell tower. Ping!</em> I was like, <em>ohhhhhhhh!</em> There's so much little stuff like that. Another classic example is intros, right? Or using Google Calendar. I didn't know how to use Google Calendar until I showed up in my first job. Someone tells me, <em>I am gonna put some time on your calendar</em>. And I think: <em>Oh, I guess I have a calendar</em>. That's not obvious if you don't come from, frankly, a certain class. But all of those things are important; if you don't intro somebody the right way to a VC, they know you're a dunce, automatically. There’s nobody that sits you down and says <em>hey, you're gonna say thank you so-and-so, moving you to BCC</em>. It's not hard, but nobody ever tells you that anywhere.</p><h4>I've heard it described as ‘the bottom 1000 universities’: Assume there's some algorithm that spits out the combination of <em>is expensive</em> and <em>is ineffective</em>. There are at least 1000 universities in the US that should cease to exist. There are many universities that net do more harm than good.</h4><p><strong>There's no tech charm school that teaches you how to do all that stuff.</strong></p><p>Totally. And I'm sure there's more stuff. When one of our first students got hired at Uber, he showed up with his laptop. They tell him: <em>you're a mobile developer</em>. And he's like, <em>I can't be a mobile developer, I don't have a phone</em>. He didn't have a smartphone. So he called me freaking out: <em>What am I gonna do!? Uber wants to hire me. I don't have a smartphone.</em> I told him: <em>Uber does not care about that, Uber’s gonna have a thousand phones, that's the least of Uber’s worries. They're gonna give you a laptop too.</em> </p><p>Then he shows up to work on day one and they tell him: <em>Alright, you know, put in your bank account information here to get direct deposit.</em> He's like, <em>no just cut me a check and I’ll run to the check-cashing store.</em> </p><p>The Uber people reached out to me and said: <em>We don’t know if this is going to work.</em> I was like, <em>he's a smart guy, it’s just that he doesn't have a bank account</em>. So now we set up bank accounts for every student that doesn't have a bank account. The best way I think to describe Lambda School is the American-Dream-as-a-service. </p><p><strong>Wow. That’s the corporate anthem right there.</strong></p><p>(Laughs.)</p><p><strong>There so much cultural encoding in an interview which, as you said, is just filtering for class. But…as these are technical people, there’s actually an objective standard of merit. </strong></p><p>There are a whole swath of white collar jobs that the interview process literally is like, <em>Hey, I'm gonna play a little verbal tennis with you and see if you can stand your ground and if you can, you get the job</em>. That's probably the average white collar job.</p><h4>That's one of the really weird things: The hiring process is not just a filter for skills, it's also a filter for class. And people don't talk about or acknowledge that. </h4><p><strong>Speaking of other jobs, do you see Lambda expanding to other fields? Is that even possible? </strong></p><p><strong>The thing that obviously aligns incentives is to look at education as a hard-nosed business proposition. I'm sure you personally care, but the reason why you care as a business owner is because you want them to get the job because otherwise you're not gonna get paid, right? You’ve invested a year and a half in this person, and they can't blow it up because they don’t know about direct deposits, so you fix that. Which is good, and certainly a lot better than the business model universities have. But that model only works if there's some pretty predictable future stream of income along with pretty predictable employment demand. Can you imagine non-technical professions like trucking and nursing that have high demand and high wages? </strong></p><p>The cool thing about the incentive alignment is that we're not going to train you to be a sociologist, because it just doesn't work. A common critique of the ISA model is: <em>oh, now people aren't going to study poetry anymore.</em> And my response to that is: <em>yeah, we're not a university, we're a trade school</em>. The university has 18 million things that it does for you, and we cut cut off a tiny sliver of that, which is: we're going to help you get a better job, we're going to help you improve your state in life. That's all we do. </p><p>There are actually more high-paying jobs available than there are people to fill those roles. And that's true all over the place. I think about it as an optimization problem. You've got all this latent human potential, and it's just kind of bouncing around. Sometimes it goes to school, and it picks stuff at random to study, and you know what you know because of who you’re surrounded by.</p><p>One aspect of Lambda School that I think is underappreciated is a whole lot of people come in having no idea of what software is, having no idea that there's such a thing as a software engineer. We have people who join and think it's like, <em>I'm gonna fix printers</em>. They know that tech is a high-paying field, but they're not surrounded it. If you're in the inner city, or in a rural area, you don't know a computer programmer. </p><p>One way to think about Lambda is like fintech: You have all these transactions that are moving all over the place, but what makes it all work is a clearinghouse that moves all the money to where it needs to go. I think of Lambda as kind of an economic clearinghouse: Here's all of the untapped human potential, here's all the would-be labor, and over here’s all the jobs that need to be done. There's nothing connecting the two right now other than sheer happenstance and going to university, or maybe you hear that there's a good job over here somewhere.</p><p>But right now the situation is not: <em>I'm making $50k, here's my skill set and my interest, I want to make $90k</em>. Somebody should be able to tell you how to do that, and right now, nobody can. That’s crazy. More than half of GDP is just people working, and that's completely unoptimized. </p><p><strong>Right. Even I, who came from a middle-class background and went to the university track, it seemed like a recently poorly-managed process and I only ended up in science and technology by sheer happenstance…</strong></p><p>You stumbled in, yeah? I feel the same way, and the interesting thing now is, depending on which way you happen to stumble, you can end up fabulously rich or destitute based on your stumblings. </p><h4>The other broken piece is the notion that you go to school once for 10 years when you're 18, and you'll be able to ride that for the rest of your career. That’s probably false for a whole lot of people.</h4><p><strong>So this model you’re describing, where you basically connect people from one income level to another higher one via various different processes. I’m curious what other connections you can imagine existing. </strong></p><p>The way to answer that is to see where all the shortages are, where are people trying to hire and those people don’t exist? Tech is an obvious one, but it’s all over the place in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thepullrequest.com/p/the-american-dream-as-a-service">https://www.thepullrequest.com/p/the-american-dream-as-a-service</a></em></p>]]>
            </description>
            <link>https://www.thepullrequest.com/p/the-american-dream-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296397</guid>
            <pubDate>Sun, 28 Feb 2021 19:46:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I cut GTA Online loading times by 70%]]>
            </title>
            <description>
<![CDATA[
Score 3669 | Comments 664 (<a href="https://news.ycombinator.com/item?id=26296339">thread link</a>) | @kuroguro
<br/>
February 28, 2021 | https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/ | <a href="https://web.archive.org/web/*/https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>GTA Online. <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/9vgo0g/how_the_fuck_are_20_minute_load_times_acceptable/">Infamous</a> for its slow loading times. Having picked up the game again to finish some of the newer heists I was <em>shocked</em> (/s) to discover that it still loads just as slow as the day it was released 7 years ago.</p>
<p>It was time. Time to get to the bottom of this.</p>
<h2 id="Recon"><a href="#Recon" title="Recon"></a>Recon</h2><p>First I wanted to check if someone had already solved this problem. Most of the results I found pointed towards anecdata about <a target="_blank" rel="noopener" href="https://metro.co.uk/2017/11/01/why-does-gta-v-take-so-long-to-load-7041927/">how the game is so sophisticated</a> that it needs to load so long, stories on how the <a target="_blank" rel="noopener" href="https://steamcommunity.com/app/271590/discussions/0/217690940938819317/">p2p network architecture</a> is rubbish (not saying that it isn’t), some elaborate ways of <a target="_blank" rel="noopener" href="https://gtaforums.com/topic/908000-fastest-way-to-load-into-gtao-single-player-first-or-straight-in/">loading into story mode and a solo session after that</a> and a couple of mods that allowed skipping the startup R* logo video. Some more reading told me we could save a whopping 10-30 seconds with these combined!</p>
<p>Meanwhile on my PC…</p>
<h2 id="Benchmark"><a href="#Benchmark" title="Benchmark"></a>Benchmark</h2><figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br></pre></td><td><pre><span>Story mode load time:  ~1m 10s</span><br><span>Online mode load time: ~6m flat</span><br><span>Startup menu disabled, time from R* logo until in-game (social club login time isn't counted).</span><br><span></span><br><span>Old but decent CPU:   AMD FX-8350</span><br><span>Cheap-o SSD:          KINGSTON SA400S37120G</span><br><span>We have to have RAM:  2x Kingston 8192 MB (DDR3-1337) 99U5471</span><br><span>Good-ish GPU:         NVIDIA GeForce GTX 1070</span><br></pre></td></tr></tbody></table></figure>

<p>I know my setup is dated but what on <em>earth</em> could take 6x longer to load into online mode? I couldn’t measure any difference using the story-to-online loading technique <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/kycy7a/gtao_loading_times_using_different_methods/">as others have found before me</a>. Even if it did work the results would be down in the noise.</p>
<h2 id="I-Am-Not-Alone"><a href="#I-Am-Not-Alone" title="I Am (Not) Alone"></a>I Am (Not) Alone</h2><p>If <a target="_blank" rel="noopener" href="https://www.reddit.com/r/gtaonline/comments/ht4i56/your_average_online_loading_time/">this poll</a> is to be trusted then the issue is widespread enough to mildly annoy more than 80% of the player base. It’s been 7 years R*!</p>
<p><img src="https://nee.lv/images/pasted-0.png" alt="🎵What does the poll say?🎵"></p>
<p>Looking around a bit to find who are the lucky ~20% that get sub 3 minute load times I came across <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RdCqDdjp6iU">a</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=pJzr3qfyCyg">few</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=RK7BUFx_NGk">benchmarks</a> with high-end gaming PCs and an online mode load time of about 2 minutes. I would <del>kill</del> <em>hack</em> for a 2 minute load time! It does seem to be hardware-dependent but something doesn’t add up here…</p>
<p>How come their story mode still takes near a minute to load? (The M.2 one didn’t count the startup logos btw.) Also, loading story to online takes them only a minute more while I’m getting about five more. I know that their hardware specs are a lot better but surely not 5x better.</p>
<h2 id="Highly-accurate-measurements"><a href="#Highly-accurate-measurements" title="Highly accurate measurements"></a>Highly accurate measurements</h2><p>Armed with such powerful tools as <em>the Task Manager</em> I began to investigate what resources could be the bottleneck.</p>
<p><img src="https://nee.lv/images/pasted-1.png" alt="Can you smell it?"></p>
<p>After taking a minute to load the common resources used for both story and online modes (which is near on par with high-end PCs) GTA decides to max out a single core on my machine for four minutes and do nothing else.</p>
<p>Disk usage? None! Network usage? There’s a bit, but it drops basically to zero after a few seconds (apart from loading the rotating info banners). GPU usage? Zero. Memory usage? Completely flat…</p>
<p>What, is it mining crypto or something? I smell code. <em>Really bad code</em>.</p>
<h2 id="Single-thread-bound"><a href="#Single-thread-bound" title="Single thread-bound"></a>Single thread-bound</h2><p>While my old AMD CPU has 8 cores and it does pack a punch, it was made in the olden days. Back when AMD’s <a target="_blank" rel="noopener" href="https://valid.x86.fr/bench/6u7sdy/1">single-thread performance</a> was <em>way</em> behind Intel’s. This might not explain all of the load time differences but it should explain most of it.</p>
<p>What’s odd is that it’s using up <em>just</em> the CPU. I was expecting vast amounts of disk reads loading up resources or loads of network requests trying to negotiate a session in the p2p network. But this? This is probably a bug.</p>
<h2 id="Profiling"><a href="#Profiling" title="Profiling"></a>Profiling</h2><p>Profilers are a great way of finding CPU bottlenecks. There’s only one problem - most of them rely on instrumenting the source code to get a perfect picture of what’s happening in the process. And I don’t have the source code. Nor do I need microsecond-perfect readings - I have 4 minutes’ worth of a bottleneck.</p>
<p>Enter stack sampling: for closed source applications there’s only one option. Dump the running process’ stack and current instruction pointer’s location to build a calling tree in set intervals. Then add them up to get statistics on what’s going on. There’s only one profiler that I know of (might be ignorant here) that can do this on Windows. And it hasn’t been updated in over 10 years. It’s <a target="_blank" rel="noopener" href="http://lukestackwalker.sourceforge.net/">Luke Stackwalker</a>! Someone, please give this project some love :)</p>
<p><img src="https://nee.lv/images/pasted-2.png" alt="The power of statistics compels you!"></p>
<p>Normally Luke would group the same functions together but since I don’t have debugging symbols I had to eyeball nearby addresses to guess if it’s the same place. And what do we see? Not one bottleneck but two of them!</p>
<h2 id="Down-the-rabbit-hole"><a href="#Down-the-rabbit-hole" title="Down the rabbit hole"></a>Down the rabbit hole</h2><p>Having borrowed <em>my friend’s</em> completely legitimate copy of <em>the industry-standard disassembler</em> (no, I really can’t afford the thing… gonna learn to <a target="_blank" rel="noopener" href="https://ghidra-sre.org/">ghidra</a> one of these days) I went to take GTA apart.</p>
<p><img src="https://nee.lv/images/pasted-3.png" alt="Gibberish Galore"></p>
<p>That doesn’t look right at all. Most high-profile games come with built-in protection against reverse engineering to keep away pirates, cheaters, and modders. Not that it has ever stopped them.</p>
<p>There seems to be some sort of an obfuscation/encryption at play here that has replaced most instructions with gibberish. Not to worry, we simply need to dump the game’s memory while it’s executing the part we want to look at. The instructions have to be de-obfuscated before running one way or another. I had <a target="_blank" rel="noopener" href="https://github.com/glmcdona/Process-Dump">Process Dump</a> lying around, so I used that, but there are plenty of other tools available to do this sort of thing.</p>
<h2 id="Problem-one-It’s…-strlen"><a href="#Problem-one-It’s…-strlen" title="Problem one: It’s… strlen?!"></a>Problem one: It’s… strlen?!</h2><p>Disassembling the now-less-obfuscated dump reveals that one of the addresses has a label pulled out of somewhere! It’s <code>strlen</code>? Going down the call stack the next one is labeled <code>vscan_fn</code> and after that the labels end, tho I’m fairly confident it’s <a target="_blank" rel="noopener" href="https://github.com/chakra-core/ChakraCore/blob/master/pal/src/safecrt/sscanf.c#L47"><code>sscanf</code></a>.</p>
<p><img src="https://nee.lv/images/pasted-4.png" alt="A graph a day keeps the skeptics away"></p>
<p>It’s parsing something. Parsing what? Untangling the disassembly would take forever so I decided to dump some samples from the running process using <a target="_blank" rel="noopener" href="https://x64dbg.com/">x64dbg</a>. Some debug-stepping later it turns out it’s… JSON! They’re parsing JSON. A whopping <strong>10 megabytes</strong> worth of JSON with some <strong>63k item entries</strong>.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br></pre></td><td><pre><span>...,</span><br><span>{</span><br><span>    <span>"key"</span>: <span>"WP_WCT_TINT_21_t2_v9_n2"</span>,</span><br><span>    <span>"price"</span>: <span>45000</span>,</span><br><span>    <span>"statName"</span>: <span>"CHAR_KIT_FM_PURCHASE20"</span>,</span><br><span>    <span>"storageType"</span>: <span>"BITFIELD"</span>,</span><br><span>    <span>"bitShift"</span>: <span>7</span>,</span><br><span>    <span>"bitSize"</span>: <span>1</span>,</span><br><span>    <span>"category"</span>: [<span>"CATEGORY_WEAPON_MOD"</span>]</span><br><span>},</span><br><span>...</span><br></pre></td></tr></tbody></table></figure>

<p>What is it? It appears to be data for a “net shop catalog” according to some references. I assume it contains a list of all the possible items and upgrades you can buy in GTA Online.</p>
<p><strong>Clearing up some confusion: I beleive these are in-game money purchasable items, not directly linked with <a target="_blank" rel="noopener" href="https://gta.fandom.com/wiki/Cash_Cards">microtransactions</a>.</strong></p>
<p>But 10 megs? That’s nothing! And using <code>sscanf</code> may not be optimal but surely it’s not that bad? Well…</p>
<p><img src="https://nee.lv/images/pasted-5.png" alt="Ouch!"></p>
<p>Yeah, that’s gonna take a while… To be fair I had no idea most <code>sscanf</code> implementations called <code>strlen</code> so I can’t blame the developer who wrote this. I would assume it just scanned byte by byte and could stop on a <code>NULL</code>.</p>
<h2 id="Problem-two-Let’s-use-a-Hash-…-Array"><a href="#Problem-two-Let’s-use-a-Hash-…-Array" title="Problem two: Let’s use a Hash- … Array?"></a>Problem two: Let’s use a Hash- … Array?</h2><p>Turns out the second offender is called right next to the first one. They’re both even called in the same <code>if</code> statement as seen in this ugly decompilation:</p>
<p><img src="https://nee.lv/images/pasted-6.png" alt="Beggar thy neighbour"></p>
<p>All labels are mine, no idea what the functions/parameters are actually called.</p>
<p>The second problem? Right after parsing an item, it’s stored in an array (or an inlined C++ list? not sure). Each entry looks something like this:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br></pre></td><td><pre><span><span><span>struct</span> {</span></span><br><span>    <span>uint64_t</span> *hash;</span><br><span>    <span>item_t</span>   *item;</span><br><span>} entry;</span><br></pre></td></tr></tbody></table></figure>

<p>But before it’s stored? It checks the <em>entire</em> array, one by one, comparing the hash of the item to see if it’s in the list or not. With ~63k entries that’s <code>(n^2+n)/2 = (63000^2+63000)/2 = 1984531500</code> checks if my math is right. Most of them useless. You have unique <em>hashes</em> why not use a <em>hash map</em>.</p>
<p><img src="https://nee.lv/images/pasted-7.png" alt="Oof!"></p>
<p>I named it <code>hashmap</code> while reversing but it’s clearly <code>not_a_hashmap</code>. And it gets even better. The hash-array-list-thing is empty before loading the JSON. And all of the items in the JSON are unique! They don’t even <em>need</em> to check if it’s in the list or not! They even have a function to directly insert the items! Just use that! Srsly, WAT!?</p>
<h2 id="PoC"><a href="#PoC" title="PoC"></a>PoC</h2><p>Now that’s nice and all, but no one is going to take me seriously unless I test this so I can write a clickbait title for the post.</p>
<p>The plan? Write a <code>.dll</code>, inject it in GTA, <a target="_blank" rel="noopener" href="https://github.com/TsudaKageyu/minhook">hook</a> some functions, ???, profit.</p>
<p>The JSON problem is hairy, I can’t realistically replace their parser. Replacing <code>sscanf</code> with one that doesn’t depend on <code>strlen</code> would be more realistic. But there’s an even easier way.</p>
<ul>
<li>hook strlen</li>
<li>wait for a long string</li>
<li>“cache” the start and length of it</li>
<li>if it’s called again within the string’s range, return cached value</li>
</ul>
<p>Something like:</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br><span>22</span><br><span>23</span><br><span>24</span><br><span>25</span><br><span>26</span><br><span>27</span><br><span>28</span><br><span>29</span><br><span>30</span><br><span>31</span><br><span>32</span><br><span>33</span><br><span>34</span><br><span>35</span><br><span>36</span><br></pre></td><td><pre><span><span><span>size_t</span> <span>strlen_cacher</span><span>(<span>char</span>* str)</span></span></span><br><span><span></span>{</span><br><span>  <span>static</span> <span>char</span>* start;</span><br><span>  <span>static</span> <span>char</span>* end;</span><br><span>  <span>size_t</span> len;</span><br><span>  <span>const</span> <span>size_t</span> cap = <span>20000</span>;</span><br><span></span><br><span>  </span><br><span>  <span>if</span> (start &amp;&amp; str &gt;= start &amp;&amp; str &lt;= end) {</span><br><span>    </span><br><span>    len = end - str;</span><br><span></span><br><span>    </span><br><span>    </span><br><span>    <span>if</span> (len &lt; cap / <span>2</span>)</span><br><span>      MH_DisableHook((LPVOID)strlen_addr);</span><br><span></span><br><span>    </span><br><span>    <span>return</span> len;</span><br><span>  }</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  </span><br><span>  len = builtin_strlen(str);</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  <span>if</span> (len &gt; cap) {</span><br><span>    start = str;</span><br><span>    end = str + len;</span><br><span>  }</span><br><span></span><br><span>  </span><br><span>  <span>return</span> len;</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<p>And as for the hash-array problem, it’s more straightforward - just skip the duplicate checks entirely and insert the items directly since we know the values are unique.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br><span>11</span><br><span>12</span><br><span>13</span><br><span>14</span><br><span>15</span><br><span>16</span><br><span>17</span><br><span>18</span><br><span>19</span><br><span>20</span><br><span>21</span><br></pre></td><td><pre><span><span><span>char</span> __fastcall <span>netcat_insert_dedupe_hooked</span><span>(<span>uint64_t</span> catalog, <span>uint64_t</span>* key, <span>uint64_t</span>* item)</span></span></span><br><span><span></span>{</span><br><span>  </span><br><span>  <span>uint64_t</span> not_a_hashmap = catalog + <span>88</span>;</span><br><span></span><br><span>  </span><br><span>  <span>if</span> (!(*(<span>uint8_t</span>(__fastcall**)(<span>uint64_t</span>*))(*item + <span>48</span>))(item))</span><br><span>    <span>return</span> <span>0</span>;</span><br><span></span><br><span>  </span><br><span>  netcat_insert_direct(not_a_hashmap, key, &amp;item);</span><br><span></span><br><span>  </span><br><span>  </span><br><span>  <span>if</span> (*key == <span>0x7FFFD6BE</span>) {</span><br><span>    MH_DisableHook((LPVOID)netcat_insert_dedupe_addr);</span><br><span>    unload();</span><br><span>  }</span><br><span></span><br><span>  <span>return</span> <span>1</span>;</span><br><span>}</span><br></pre></td></tr></tbody></table></figure>

<p>Full source of PoC <a target="_blank" rel="noopener" href="https://github.com/tostercx/GTAO_Booster_PoC">here</a>.</p>
<h2 id="Results"><a href="#Results" title="Results"></a>Results</h2><p>Well, did it work then?</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br></pre></td><td><pre><span>Original online mode load time:        ~6m flat</span><br><span>Time with only duplication check patch: 4m 30s</span><br><span>Time with only JSON parser patch:       2m 50s</span><br><span>Time with both issues patched:          1m 50s</span><br><span></span><br><span>(6*60 - (1*60+50)) / (6*60) = 69.4% load time improvement (nice!)</span><br></pre></td></tr></tbody></table></figure>

<p>Hell yes, it did! :))</p>
<p>Most likely, this won’t solve everyone’s load times - there might be other bottlenecks on different systems, but it’s such a gaping hole that I have no idea how R* has missed it all these years.</p>
<h2 id="tl-dr"><a href="#tl-dr" title="tl;dr"></a>tl;dr</h2><ul>
<li>There’s a single thread CPU bottleneck while starting up GTA Online</li>
<li>It turns out GTA struggles to parse a 10MB JSON file</li>
<li>The JSON parser itself is poorly built / naive and</li>
<li>After parsing there’s a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</a></em></p>]]>
            </description>
            <link>https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296339</guid>
            <pubDate>Sun, 28 Feb 2021 19:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create animated GIF and WebP from videos using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 51 (<a href="https://news.ycombinator.com/item?id=26296315">thread link</a>) | @Audiolite
<br/>
February 28, 2021 | https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article class="page">
    <div>
      
      <div>

        

<p>Saturday, February 27, 2021</p>

<p><a href="https://mattj.io/posts/">Click here to go to all posts</a>. <em>Also published on <a href="https://mattjoseph.medium.com/create-animated-gif-and-webp-from-videos-using-ffmpeg-f1012267935a" target="_blank" rel="noopener">Medium</a></em></p>

<p><em>A guide to using FFmpeg to create all the animated content you want.</em></p>

<p>Whether it’s for a website, a presentation, or sharing a fun clip with a friend on chat, you might want to convert a video to an animated GIF or animated WebP. Unfortunately, the visual tools for doing this vary by your operating system. Additionally, most conversion tools don’t support <a href="https://en.wikipedia.org/wiki/WebP" target="_blank" rel="noopener">the WebP format</a>, even in 2021. WebP is based on VP8, a relatively recent video codec standard compared to the <a href="https://en.wikipedia.org/wiki/GIF" target="_blank" rel="noopener">GIF image format</a>.</p>

<p>So, this guide is for those who are willing to learn a bit of terminal in order to convert any video to the animated format of their choosing. The best part: this will work on all major operating systems and gives you all the control of the output you could want!</p>


<figcaption>Example GIF of typing "GIF" on a mechanical keyboard</figcaption>

<p>Let’s get started!</p>

<h2 id="prerequisites">Prerequisites</h2>

<p>To use this guide, you will need the following:</p>

<ul>
  <li>Basic knowledge of how to open and use the terminal on your operating system. If you need a cheat sheet or introductory guides, check out <a href="https://terminalcheatsheet.com/" target="_blank" rel="noopener">Terminal Cheat Sheet</a>.</li>
  <li>FFmpeg v4+ installed on your operating system and executable from your path. Here are some suggested places to learn down to do this:
    <ul>
      <li>macOS: <a href="https://superuser.com/a/624562" target="_blank" rel="noopener">https://superuser.com/a/624562</a></li>
      <li>Windows: <a href="https://video.stackexchange.com/a/20496" target="_blank" rel="noopener">https://video.stackexchange.com/a/20496</a></li>
      <li>Linux: Use your preferred package manager (e.g., <code>sudo apt install ffmpeg</code> on Ubuntu)</li>
    </ul>
  </li>
</ul>

<h2 id="what-isffmpeg">What is&nbsp;FFmpeg?</h2>

<p><a href="https://en.wikipedia.org/wiki/FFmpeg" target="_blank" rel="noopener">From Wikipedia</a>:</p>

<blockquote>
  <p>FFmpeg is a free and open-source software project consisting of a large suite of libraries and programs for handling video, audio, and other multimedia files and streams.</p>
</blockquote>

<p>For our purposes, we will use it to convert between formats, such as videos to GIFs or animated WebP. It has many uses, so I recommend checking it out for all your video processing needs!</p>

<h2 id="before-you-start-make-sure-you-can-run-ffmpeg-from-yourterminal">Before you start: make sure you can run FFmpeg from your&nbsp;terminal</h2>

<p>Since all of these commands require FFmpeg, we need to make sure it’s available.</p>

<p>Open your terminal, and run this:</p>



<p>If FFmpeg is available, you will note output similar to this:</p>

<div><div><pre><code>FFmpeg version 4.3.1 Copyright © 2000–2020 the FFmpeg developers
...
</code></pre></div></div>


<figcaption>Checking the FFmpeg version on Linux</figcaption>

<p>Version 4 or higher of FFmpeg is recommended for this guide.</p>

<p>If you get an output that says something similar to <code>command not found: ffmpeg -version</code>, then check the <strong>Prerequisites</strong> section above and make sure you have FFmpeg installed on your system.</p>

<h2 id="convert-to-an-animated-gif-usingffmpeg">Convert to an animated GIF using&nbsp;FFmpeg</h2>

<h3 id="convert-a-whole-video-togif">Convert a whole video to&nbsp;GIF</h3>

<p><strong>Base command</strong></p>

<div><div><pre><code>ffmpeg -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop $NUMBER_OF_LOOPS $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated GIF.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop 0 sample_recording.gif
</code></pre></div></div>

<h3 id="convert-part-of-a-video-togif">Convert part of a video to&nbsp;GIF</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting part of a video to an animated GIF:</p>

<div><div><pre><code>ffmpeg -ss $INPUT_START_TIME -t $LENGTH -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop $NUMBER_OF_LOOPS $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_START_TIME - number of seconds in the input video to start from.
# * $LENGTH - number of seconds to convert from the input video.
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated GIF.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -ss 32.5 -t 7 -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse" \
-loop 0 sample_recording.gif
</code></pre></div></div>

<h2 id="convert-to-an-animated-webp-usingffmpeg">Convert to an animated WebP using&nbsp;FFmpeg</h2>

<h3 id="convert-a-whole-video-to-animatedwebp">Convert a whole video to animated&nbsp;WebP</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting an entire video to an animated WebP. You can use options like FPS, output width, and quality to determine the file size and quality of your output:</p>

<div><div><pre><code>ffmpeg -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v $OUTPUT_QUALITY -loop $NUMER_OF_LOOPS \
-preset picture -an -vsync 0 $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $OUTPUT_QUALITY - quality of the WebP output. Start with `50`.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated WebP.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v 50 -loop 0 \
-preset picture -an -vsync 0 sample_recording.webp
</code></pre></div></div>

<h3 id="convert-part-of-a-video-to-animatedwebp">Convert part of a video to animated&nbsp;WebP</h3>

<p><strong>Base command</strong></p>

<p>This is the base command with various options for converting part of a video to an animated WebP:</p>

<div><div><pre><code>ffmpeg -ss $INPUT_START_TIME -t $LENGTH -i $INPUT_FILENAME \
-vf "fps=$OUTPUT_FPS,scale=$OUTPUT_WIDTH:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v $OUTPUT_QUALITY -loop $NUMER_OF_LOOPS \
-preset picture -an -vsync 0 $OUTPUT_FILENAME

# Change these placeholders:
# * $INPUT_START_TIME - number of seconds in the input video to start from.
# * $LENGTH - number of seconds to convert from the input video.
# * $INPUT_FILENAME - path to the input video.
# * $OUTPUT_FPS - ouput frames per second. Start with `10`.
# * $OUTPUT_WIDTH - output width in pixels. Aspect ratio is maintained.
# * $OUTPUT_QUALITY - quality of the WebP output. Start with `50`.
# * $NUMBER_OF_LOOPS - use `0` to loop forever, or a specific number of loops.
# * $OUTPUT_FILENAME - the name of the output animated WebP.
</code></pre></div></div>

<p><strong>Example usage of this command</strong></p>

<p>Here is an example of this command with the input options filled out:</p>

<div><div><pre><code>ffmpeg -ss 32.5 -t 7 -i "sample_recording.mp4" \
-vf "fps=10,scale=720:-1:flags=lanczos" \
-vcodec libwebp -lossless 0 -compression_level 6 \
-q:v 50 -loop 0 \
-preset picture -an -vsync 0 sample_recording.webp
</code></pre></div></div>

<h2 id="when-should-i-use-an-animated-gif-versus-an-animatedwebp">When should I use an animated GIF versus an animated&nbsp;WebP?</h2>

<p>This depends on the quality, size, and support you want for your output. Modern browsers have support for animated WebP and the quality tends to be higher, but the processing power required is also higher.</p>

<h2 id="next-steps">Next steps</h2>

<p>This guide serves as a brief introduction to using FFmpeg to create an animated GIF or animated WebP from a video, but there is so much more you can do with the tool. There are also many options that FFmpeg supports for these formats that are not covered.</p>

<p>You can also get the code for all the commands and examples in one place by <a href="https://gist.github.com/devadvance/f2ad3cfe38afe3eeef64c72c46692158" target="_blank" rel="noopener">visiting the GitHub Gist here</a>.</p>


      </div>
    </div>
  </article></div>]]>
            </description>
            <link>https://mattj.io/posts/2021-02-27-create-animated-gif-and-webp-from-videos-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296315</guid>
            <pubDate>Sun, 28 Feb 2021 19:35:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Minimal Browser]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26296082">thread link</a>) | @autoditype
<br/>
February 28, 2021 | https://manuelmoreale.com/a-minimal-browser | <a href="https://web.archive.org/web/*/https://manuelmoreale.com/a-minimal-browser">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><a href="https://manuelmoreale.com/"></a><p>As a web developer I have a love &amp; hate relationship with browsers. On one side, I need them to function properly in order to do my job, on the other I want them to be as minimal as possible. At the same time I’m trying to spend less and more meaningful time on the browser which is why I decided to minimize it. I’m on a Mac and I decided to use Safari as my primary browser. Now, before you start screaming at the screen, I know what you’re thinking: Safari is awful. And I don’t disagree with that. Being awful is a plus. I don’t want to be comfortable, I want my browser to behave badly which is why Safari, with all its weird and stupid bugs is perfect. My safari looks like this:</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/a3cde09051-1611495857/safari-1-1216x-q70.jpg 1216w"></p></div><figcaption>pretty minimal...</figcaption></figure>
<p>Here’s how the taskbar is set up if you’re curious and want to do it yourself.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2435099ee2-1611495857/safari-2-1216x-q70.jpg 1216w"></p></div><figcaption>GTFO icons!</figcaption></figure>
<p>As you can see, I removed pretty much everything. Only thing left is the search bar at the center. I can use gestures and the keyboard to navigate through tabs and go back and forth through the history so I don’t need any button at the top. I’m also trying to have as fewer tabs open as possible. This is something that’s part of my commitment to be digitally minimal.</p>
<h2>Few extra settings</h2>
<p>In addition to the minimal taskbar, there are a couple of extra steps I took in order to have a more minimalist browser.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/2ce9f2c4d0-1611495857/safari-3-1216x-q70.jpg 1216w"></p></div></figure>
<p>Both new windows and tabs open on a blank page. That’s because I don’t want to get distracted by icons. If I open the browser I want to stay focused on the current task and not browse mindlessly.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/5bf1323c1b-1611495857/safari-4-1216x-q70.jpg 1216w"></p></div></figure>
<p>I’m also loading a custom css file, which I use to hide stuff from websites I use somewhat regularly. It’s used primarily to hide parts of the sites, change the typography or the colors. Nothing super crazy but definitely helpful.</p>
<h2>What about the other browsers</h2>
<p>A yes, the other browsers. We’re talking about Firefox and Chrome right?  Chrome is my dev browser because Safari’s webtools are frankly a pile of hot garbage. My Chrome looks like this:</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/b8c3d35836-1611495857/chrome-1-1216x-q70.jpg 1216w"></p></div></figure>
<p>The new tab is a custom extension I coded months ago. <a href="https://chrome.google.com/webstore/detail/minimal-new-page/danoojfpckpaacgbaebfakjeepeenaop" rel="noopener noreferrer" target="_blank">It’s available for free on the Chrome App store</a> or whatever is called. You can’t really remove many things from Chrome. All the extensions are hidden, home icon is obviously gone but other than that it looks pretty much like a normal Chrome installation.</p>
<p>Firefox is a bit more interesting. I don’t use Firefox a lot to be honest with you even though has got much better lately and I quite like it as a browser. Still, if it’s your primary browser and you want to minimize it, this is what you can do. My Firefox looks like this:</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/d4c53b9400-1611495857/ff-1-1216x-q70.jpg 1216w"></p></div></figure>
<p>As you can see, almost everything is gone from the sidebar. Only things you can’t remove are the two arrows but I moved one of the two on the opposite side in order to have a less busy left corner. Only other thing left is the search bar.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/f442c2e48d-1611495857/ff-2-1216x-q70.jpg 1216w"></p></div></figure>
<p>I’m also using the dark color scheme. You can change the theme down at the bottom of the customization page.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/638f8831f7-1611495857/ff-3-1216x-q70.jpg 1216w"></p></div></figure>
<p>As for the settings, like I did for Safari, an empty page is shown every time I open a new tab or window. This is super helpful to cut down distractions.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/cba5cf6b18-1611495857/ff-4-1216x-q70.jpg 1216w"></p></div></figure>
<p>Another thing you can do is turn off those obnoxious notifications requests. To do that you need to go in the Privacy &amp; Security section inside the settings and click on the Settings... button next to Notifications.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/e3598d4a06-1611495857/ff-5-1216x-q70.jpg 1216w"></p></div></figure>
<p>Then, at the bottom of the new window, you’ll find a checkbox to disable all new requests. Toggle that and you’ll be good to go. This is something you can do in Safari as well btw. You can find the same option under Settings &gt; Websites &gt; Notifications.</p>
<figure data-template="without"><div><p><img alt="" loading="lazy" sizes="(min-width: 2000px) 1216px, (min-width: 1000px) 1024px, (min-width: 500px) 776px,  340px" src="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6.jpg" srcset="https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-340x-q70.jpg 340w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-776x-q70.jpg 776w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-1024x-q70.jpg 1024w, https://manuelmoreale.com/media/pages/thoughts/a-minimal-browser/ad7f1b67b6-1611495857/ff-6-1216x-q70.jpg 1216w"></p></div></figure>
<p>And that’s it. Enjoy your simpler browser. And let me know if you think there’s something else that could be done to improve the browsing experience.</p></div></div>]]>
            </description>
            <link>https://manuelmoreale.com/a-minimal-browser</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296082</guid>
            <pubDate>Sun, 28 Feb 2021 19:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Troubleshooting a Stuck Process]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26296039">thread link</a>) | @JoshMcguigan
<br/>
February 28, 2021 | https://www.joshmcguigan.com/blog/troubleshooting-stuck-process/ | <a href="https://web.archive.org/web/*/https://www.joshmcguigan.com/blog/troubleshooting-stuck-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I was recently troubleshooting an issue where a process seemed to be stuck, not making any progress. Eventually I was able to track down the problem, but along the way I found a few quick ways to start gathering information about a running process.</p>
<p>These tips apply only to Linux systems. I’m sure other operating systems have similar tools, but I am not familiar with them so I won’t mention them here.</p>
<p>I use <code>sleep</code> as an example program to “troubleshoot” throughout this article. You will probably want to replace <code>sleep</code> in my examples below with something more interesting.</p>
<h2>strace</h2>
<p>strace prints out the system calls made by a particular process. One option when using strace is to start the program from within strace:</p>
<div data-language="bash"><pre><code>
$ <span>strace</span> <span>sleep</span> <span>10</span>

execve<span>(</span><span>"/usr/bin/sleep"</span>, <span>[</span><span>"sleep"</span>, <span>"10"</span><span>]</span>, 0x7ffc0b292728 /* <span>54</span> vars */<span>)</span> <span>=</span> <span>0</span>
<span>..</span>.
clock_nanosleep<span>(</span>CLOCK_REALTIME, <span>0</span>, <span>{</span>tv_sec<span>=</span><span>10</span>, <span>tv_nsec</span><span>=</span><span>0</span><span>}</span>, 0x7ffd8fa9ef30<span>)</span> <span>=</span> <span>0</span>
<span>..</span>.</code></pre></div>
<p>strace has lots of output so I removed most of it, but watching the output live you can see which system call your process is getting stalled on. In this case it is <code>clock_nanosleep</code>.</p>
<p>Sometimes you realize you want to see what a process is doing after the process has already started - in that case you can use strace to attach to an existing process by PID:</p>
<div data-language="bash"><pre><code>
$ <span>sleep</span> <span>10</span> <span>&amp;</span>

$ pgrep <span>sleep</span> <span>|</span> <span>xargs</span> -n1 <span>sudo</span> <span>strace</span> -p </code></pre></div>
<p>Here we use <code>pgrep</code> to get the process ID of the <code>sleep</code> process, then use strace to attach to that process. Be aware that <code>pgrep</code> uses a regular expression to match the process name, so you might want to use <code>pgrep ^sleep$</code> or <code>pidof sleep</code> for stricter matching. </p>
<p>The downside to attaching strace to a running application is that if the process has already called into a blocking system call, as is likely the case here with sleep, you won’t see anything with strace until that system call returns and a next system call is invoked.</p>
<h2>procfs kernel stack</h2>
<p>If you use strace to attach to a running process and find it stalled on a blocking syscall (so strace is not providing any output), you can use procfs to determine the currently running syscall, as well as the full kernel stack trace.</p>
<div data-language="bash"><pre><code>
$ <span>sleep</span> <span>10</span> <span>&amp;</span>

$ pgrep <span>sleep</span> <span>|</span> <span>xargs</span> -I % <span>sudo</span> <span>cat</span> /proc/%/stack
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> hrtimer_nanosleep+0xca/0x1a0
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> common_nsleep+0x40/0x50
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> __x64_sys_clock_nanosleep+0xd1/0x140
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> do_syscall_64+0x33/0x40
<span>[</span><span>&lt;</span><span><span>0</span>&gt;</span><span>]</span> entry_SYSCALL_64_after_hwframe+0x44/0xa9</code></pre></div>
<p>Here again we can see we are stuck in the <code>clock_nanosleep</code> system call, but this time we are able to figure it out while the process is blocked on the system call, whereas with strace we would have had to start tracing <em>before</em> the process calls the blocking system call.</p>
<h2>userspace trace</h2>
<p>Now you might want to know where in the application code the syscall was called from. Or an alternate case would be that you find the application isn’t stuck in kernel space but rather is stuck executing application code.</p>
<p>You can use <code>gdb</code> to see the current userspace stack trace.</p>
<div data-language="bash"><pre><code>
$ <span>sleep</span> <span>10</span> <span>&amp;</span>

$ pgrep <span>sleep</span> <span>|</span> <span>xargs</span> -n1 <span>sudo</span> gdb --batch -ex <span>"thread apply all bt"</span> -p
0x00007f8b1b29f0da <span>in</span> clock_nanosleep@GLIBC_2.2.5 <span>(</span><span>)</span> from /usr/lib/libc.so.6

Thread <span>1</span> <span>(</span>process <span>132170</span> <span>"sleep"</span><span>)</span>:







<span>[</span>Inferior <span>1</span> <span>(</span>process <span>132170</span><span>)</span> detached<span>]</span></code></pre></div>
<p>The usefulness of this information depends on the existence of debug symbols, so you may not get much out of it unless you can re-compile the application with debug symbols included.</p>
<div data-language="bash"><pre><code>$ pgrep rust-analyzer <span>|</span> <span>xargs</span> -n1 <span>sudo</span> gdb --batch -ex <span>"thread apply all bt"</span> -p



Thread <span>1</span> <span>(</span>LWP <span>113543</span> <span>"rust-analyzer"</span><span>)</span>:

















</code></pre></div>
<p>This demonstrates what the output might look like for an appication compiled with debug symbols.</p>
<h2>Conclusion</h2>
<p>These tools probably aren’t enough to immediately root cause an issue, but they are a great way to gather some initial information which can help guide further troubleshooting effort.</p></div></div>]]>
            </description>
            <link>https://www.joshmcguigan.com/blog/troubleshooting-stuck-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296039</guid>
            <pubDate>Sun, 28 Feb 2021 19:03:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Perl Saved the Human Genome Project (1996)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26296030">thread link</a>) | @todsacerdoti
<br/>
February 28, 2021 | https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html | <a href="https://web.archive.org/web/*/https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<hr>

<!-- the article goes here -->


<h4><i>Lincoln D. Stein</i></h4>

<!-- packages described, if necessary -->


<tt>
<b>DATE:</b> Early February, 1996
<br> 
LOCATION: Cambridge, England, in the conference room of the largest DNA sequencing center in Europe.
<br> 
<b>OCCASION:</b> A high level meeting between the computer scientists of this center and the largest DNA sequencing center in the United States. 
<br>
<b>THE PROBLEM:</b> Although the two centers use almost identical laboratory techniques, almost identical databases, and almost identical data analysis tools, they still can't interchange data or meaningfully compare results.
<br><b>THE SOLUTION:</b> Perl. 
</tt>
<p>
The human genome project was inaugurated at the beginning of the decade as an ambitious international effort to determine the complete DNA sequence of human beings and several experimental animals. The justification for this undertaking is both scientific and medical. By understanding the genetic makeup of an organism in excruciating detail, it is hoped that we will be better able to understand how organisms develop from single eggs into complex multicellular beings, how food is metabolized and transformed into the constituents of the body, how the nervous system assembles itself into a smoothly functioning ensemble. From the medical point of view, the wealth of knowledge that will come from knowing the complete DNA sequence will greatly accelerate the process of finding the causes of (and potential cures for) human diseases.
</p><p> 
Six years after its birth, the genome project is ahead of schedule. Detailed maps of the human and all the experimental animals have been completed (mapping out the DNA using a series of landmarks is an obligatory first step before determining the complete DNA sequence). The sequence of the smallest model organism, yeast, is nearly completed, and the sequence of the next smallest, a tiny soil-dwelling worm, isn't far behind. Large scale sequencing efforts for human DNA started at several centers a number of months ago and will be in full swing within the year.
</p><p> 
The scale of the human DNA sequencing project is enough to send your average UNIX system administrator running for cover. From the information-handling point of view, DNA is a very long string consisting of the four letters G, A, T and C (the letters are abbreviations for the four chemical units that form the "rungs" of the DNA double helix ladder). The goal of the project is to determine the order of letters in the string. The size of the string is impressive but not particularly mind-boggling: 3 x 109 letters long, or some 3 gigabytes of storage space if you use 1 byte to store each letter with no compression techniques.</p><p> 
Three gigabytes is substantial but certainly manageable by today's standards. Unfortunately, this is only what's required to store the finished data. The storage requirements for the experimental data needed to determine this sequence is far more vast. The essential problem is that DNA sequencing technology is currently limited to reading stretches of at most 500 contiguous letters. In order to determine sequences longer than that, the DNA must be sequenced as small overlapping fragments called "reads" and the jigsaw puzzle reassembled by algorithms that look for areas where the sequences match. Because the DNA sequence is nonrandom (similar but not-entirely-identical motifs appear many times throughout the genome), and because DNA sequencing technology is noisy and error-prone, one ends up having to sequence each region of DNA five to ten times in order to reliably assemble the reads into the true sequence. This increases the amount of data to manage by an order of magnitude. On top of this is all the associated information that goes along with laboratory work: who performed the experiment, when it was performed, the section of the genome that was sequenced, the identity and version of the software used to assemble the sequence, any comments someone wants to attach to the experiment, and so forth. In addition, one generally wants to store the raw output from the machine that performs the sequencing. Each 500 letters of sequence generates a data file that's 20-30 kilobytes long!
</p><p> 
That's not the whole of it. It's not enough just to determine the sequence of the DNA. Within the sequence are functional areas scattered among long stretches of nonfunctional areas. There are genes, control regions, structural regions, and even a few viruses that got entangled in human DNA long ago and persist as fossilized remnants. Because the genes and control regions are responsible for health and disease, one wants to identify and mark them as the DNA sequence is assembled. This type of annotation generates yet more data.
</p><p> 
Altogether, people estimate that some one to ten terabytes of information will need to be stored in order to see the human genome project to its conclusion. 
</p><p>
So what's Perl got to do with it? From the beginning, researchers realized that informatics would have to play a large role in the genome project. An informatics core formed an integral part of every genome center that was created. The mission of these cores was two-fold: to provide computer support and databasing services for their affiliated laboratories, and to develop data analysis and management software for use by the genome community as a whole. 
</p><p>
It's fair to say that the initial results of the informatics groups efforts were mixed. Things were slightly better on the laboratory management side of the coin. Some groups attempted to build large monolithic systems on top of complex relational databases; they were thwarted time and again by the highly dynamic nature of biological research. By the time a system that could deal with the ins and outs of a complex laboratory protocol had been designed, implemented and debugged, the protocol had been superseded by new technology and the software engineers had to go back to the drawing board.
</p><p> 
Most groups, however, learned to build modular, loosely-coupled systems whose parts could be swapped in and out without retooling the whole system. In my group, for example, we discovered that many data analysis tasks involve a sequence of semi-independent steps. Consider the steps that one may want to perform on a bit of DNA that has just been sequenced. First there's a basic quality check on the sequence: is it long enough? Are the number of ambiguous letters below the maximum limit? Then there's the "vector check." For technical reasons, the human DNA must be passed through a bacterium before it can be sequenced (this is the process of "cloning"). Not infrequently, the human DNA gets lost somewhere in the process and the sequence that's read consists entirely of the bacterial vector. The vector check ensures that only human DNA gets into the database. Next there's a check for repetitive sequences. Human DNA is full of repetitive elements that make fitting the sequencing jigsaw puzzle together challenging. The repetitive sequence check tries to match the new sequence against a library of known repetitive elements. A penultimate step is to attempt to match the new sequence against other sequences in a large community database of DNA sequences. Often a match at this point will provide a clue to the function of the new DNA sequence. After performing all these checks, the sequence along with the information that's been gathered about it along the way is loaded into the local laboratory database.
</p><p> 
The process of passing a DNA sequence through these independent analytic steps looks kind of like a pipeline, and it didn't take us long to realize that a UNIX pipe could handle the job. We developed a simple Perl-based data exchange format called <i><i>boulderio</i></i> that allowed loosely coupled programs to add information to a pipe-based I/O stream. <i><i>boulderio</i></i> is based on tag/value pairs. A Perl module makes it easy for programs to reach into the input stream, pull out only the tags they're interested in, do something with them, and drop new tags into output the stream. Any tags that the program isn't interested in are just passed through to standard output so that other programs in the pipeline can get to them.
</p><p> 
Using this type of scheme, the process of analyzing a new DNA sequence looks something like this (this is not exactly the set of scripts that we use, but it's close enough):

</p><pre>name_sequence.pl &lt; new.DNA |
quality_check.pl | 
vector_check.pl |
find_repeats.pl |
search_big_database.pl |
load_lab_database.pl
</pre>
<p>
A file containing the new DNA sequence is processed by a Perl script named <tt>name_sequence.pl</tt>, whose only job is to give the sequence a new unique name and to put it into <i><i>boulderio</i></i> format. Its output looks like this:

</p><pre> 
NAME=L26P93.2 
SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC...
</pre>
<p>

The output from name_sequence.pl is next passed to the quality checking program, which looks for the SEQUENCE tag, runs the quality checking algorithm, and writes its conclusion to the data stream. The data stream now looks like this:

 </p><pre>NAME=L26P93.2 
SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC...
QUALITY_CHECK=OK 
</pre>
<p>

Now the data stream enters the vector checker. It pulls the SEQUENCE tag out of the stream and runs the vector checking algorithm. The data stream now looks like this:

</p><pre> 
NAME=L26P93.2 SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC......
QUALITY_CHECK=OK 
VECTOR_CHECK=OK 
VECTOR_START=10 
VECTOR_LENGTH=300 
</pre>
<p>

This continues down the pipeline, until at last the <tt>load_lab_database.pl</tt> script collates all the data, makes some final conclusions about whether the sequence is suitable for further use, and enters all the results into the laboratory database. 
One of the nice features of the <i>boulderio</i> format is that multiple sequence records can be processed sequentially in the same UNIX pipeline. An "=" sign marks the end of one record and the beginning of the next:
	
</p><pre>	 
NAME=L26P93.2 
SEQUENCE=GATTTCAGAGTCCCAGATTTCCCCCAGGGGGTTTCCAGAGAGCCC... 
=
NAME=L26P93.3 
SEQUENCE=CCCCTAGAGAGAGAGAGCCGAGTTCAAAGTCAAAACCCATTCTCTCTC... 
= 
</pre>
<p>

There's also a way to create subrecords …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html">https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html</a></em></p>]]>
            </description>
            <link>https://www.foo.be/docs/tpj/issues/vol1_2/tpj0102-0001.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26296030</guid>
            <pubDate>Sun, 28 Feb 2021 19:01:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[World Beer Index 2021: The Cost and Consumption of Beer Around the World]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26295875">thread link</a>) | @giuliomagnifico
<br/>
February 28, 2021 | https://www.expensivity.com/beer-around-the-world/ | <a href="https://web.archive.org/web/*/https://www.expensivity.com/beer-around-the-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry-content">
<p>Beer. Everybody likes to drink it. Nobody likes to pay for it. Still, the cost of a beer stings more or less depending on where in the world you’re drinking.</p>
<p>Expensivity wondered just how much the cost of beer differs from country and the effect the price of beer has on national consumption. We researched the price of a beer around the world and used World Health Organization statistics to figure out who’s drinking it all.</p>
<p><em>All prices are in US dollars. All beers are 33cl (330ml) bottles.</em></p>
<h2><strong>Key Findings</strong></h2>
<ul><li><strong>Qatar</strong> has the <strong>most expensive beer in the world</strong>, with an average price of <strong>US$11.26</strong> per 33cl (330ml) bottle.</li><li>The <strong>cheapest beer</strong> is in <strong>South Africa</strong>, where the average price is <strong>$1.68</strong> per bottle.</li><li>The <strong>Czech Republic</strong> has the <strong>highest consumption rate</strong>, with <strong>468 beers</strong> per person per year.</li><li><strong>Germans</strong> spend an average <strong>$1,907.78 per year</strong> on beer, the <strong>top figure</strong> in our study.</li></ul>
<h2><strong>Qatar Wins World Cup for Expensive Beer</strong></h2>
<p>A beer in Qatar is expensive. The mostly Muslim country introduced a <a href="https://www.nytimes.com/2019/01/01/world/middleeast/qatar-tax-alcohol.html">100% tax</a> on alcohol imports ahead of the 2022 World Cup, and visitors need a special permit to drink alcohol. China looks pretty expensive too, but consider that we averaged the price of a hotel beer ($13.61) and a supermarket beer ($1.81). </p>
<figure><a href="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg"><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg" alt="The Price of Beer Around The World" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure>
<p><a href="https://www.expensivity.com/wp-content/uploads/2021/02/1-The-Price-of-A-Beer-Map-avg-price.jpg"><strong>Tap on the map to see it full size</strong></a></p>
<p>It’s clear the steep prices are aimed at visitors. Beer is cheapest in South Africa, where a <a href="https://www.dailymaverick.co.za/article/2020-10-26-counting-the-cost-of-cheap-easily-available-alcohol-in-south-africa/">culture of buying in bulk</a> tends to keep prices down.</p>
<h2><strong>The International Beer Index in Full</strong></h2>
<p>Where there is beer, there are beer geeks. Here is Expensivity’s data in full so you can find out exactly what kind of beer culture to expect from country to country. Click the arrows to sort by price, consumption, or total spend.</p>

<p>The ten countries with the highest average annual beer bill each have beer that costs upwards of four bucks. However, second-placed Poland is notable for its 62¢ carry-out beer, suggesting that much of Poland’s $1,738 average beer bill is built up by hotel-faring bachelor parties.</p>
<p>Bosnia is an outlier among the big drinkers: the country is in eighth place for beer consumption by bottle (331/year) but 30<sup>th</sup> for overall spend ($647.21), thanks to an average price that comes in under two bucks.</p>
<h2><strong>Germany Spends the Most On Beer</strong></h2>
<p>Haitians just aren’t that into beer. Spirits account for a whopping<a href="https://www.statista.com/statistics/973941/alcohol-consumption-latin-america-country-drink-type/"> 97% of booze consumed</a> in Haiti, where people drink fewer than four beers per year on average, with an annual beer bill of $10.02. That’s the lowest beer consumption and spend in our study.</p>
<div><figure><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg" alt="How Much Do People Spend on Beer Annually?" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></figure></div>
<p><a rel="noreferrer noopener" href="https://www.expensivity.com/wp-content/uploads/2021/02/2-How-Much-Do-People-Spend-Map-avg-spend.jpg" target="_blank"><strong>Tap on the map to see it full size</strong></a></p>
<p>At the other end of the scale, Germans spend just shy of $2k/year on beer. We found 15 countries with more expensive beer than Germany, but the nation sinks 411 bottles per person annually, so it pays the most in total. Germany is known for its<a href="https://www.dw.com/en/beer-culture-this-is-how-germany-drinks/a-19201434"> beer culture</a> and a stringent (delicious) beer purity law that has stood for over 500 years.</p>
<h2><strong>Czechia and Spain Lead Drinking Contest</strong></h2>
<p>So, who’s drinking all the beer? The Czech Republic takes the title, with 468 beers per person per year. However, capital Prague is the fourth most-visited city in Europe and infamous for its bachelor parties (<a href="https://www.lonelyplanet.com/articles/prague-different-type-visitor-after-lockdown">for now at least</a>). Like sunny Spain, in second place, Czechia’s beer consumption may be significantly swelled by visiting merry-makers.</p>
<div><figure><a href="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg"><img width="1200" height="800" src="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg" alt="How Much Beer Do People Drink In Different Countries?" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg 1200w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-300x200.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-1024x683.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-768x512.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed-1090x726.jpg 1090w" sizes="(max-width: 1200px) 100vw, 1200px"></a></figure></div>
<p><a href="https://www.expensivity.com/wp-content/uploads/2021/02/3-How-Much-Beer-Do-People-Drink-Map-avg-consumed.jpg"><strong>Tap on the map to see it full size</strong></a></p>
<p>Haiti drinks the least beer, counted per bottle or per spend. Most of the countries with a low beer intake can credit their predominantly Muslim populations for the abstinence. Armenia is an exception. The west Asian country drinks just 40 beers per person annually, with locals favoring<a href="https://theculturetrip.com/europe/armenia/articles/alcoholic-drinks-you-should-try-in-armenia/"> brandy, vodka, and wine</a>.</p>
<p>Armenians might not drink much beer, but the beer they drink is delicious, cheap, and<a href="https://www.smithsonianmag.com/travel/armenia-might-be-one-oldest-and-youngest-beermaking-countries-world-180964860/"> finely crafted</a>. Wherever you’re drinking in the world, be sure to check out the tradition behind your beer, as well as the cost – nothing adds<a href="https://www.expensivity.com/expensivity-by-the-ounce/"> value</a> to your experience like a beer with a story!</p>
<figure><img width="1024" height="690" src="https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1024x690.jpg" alt="" srcset="https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1024x690.jpg 1024w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-300x202.jpg 300w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-768x517.jpg 768w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP-1536x1034.jpg 1536w, https://www.expensivity.com/wp-content/uploads/2021/02/lager-beer-with-homemade-pretzels-5FDLUTP.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
<h3><strong>METHODOLOGY &amp; SOURCES</strong></h3>
<p>We collated the prices of a 330ml bottle of beer in supermarkets around the world using online shops, focusing on well-known beer brands such as Corona and Heineken. When we couldn’t find the price via an online shop, we used <a href="https://www.numbeo.com/cost-of-living/">numbeo.com</a>.</p>
<p>To gain an average price, we called up hotels to find out the price of a beer from their lobby bar, and when this wasn’t available, we used menus from bars found online. Once all the data was collected, we calculated the average price in US dollars using <a href="http://xe.com/">xe.com</a>.</p>
<p>Using the <a href="https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-total-per-capita-(15-)-consumption-(in-litres-of-pure-alcohol)-with-95-ci">World Health</a> <a href="https://www.who.int/data/gho/data/indicators/indicator-details/GHO/alcohol-consumption-of-pure-alcohol-by-type-of-beverage-(-)">Organisation statistics</a>, we found the amount of alcohol consumption per capita and the percentage of annual beer consumption.</p>
</div></div>]]>
            </description>
            <link>https://www.expensivity.com/beer-around-the-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295875</guid>
            <pubDate>Sun, 28 Feb 2021 18:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Tips for React Developers]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295794">thread link</a>) | @psuranas
<br/>
February 28, 2021 | https://prateeksurana.me/blog/javascript-tips-for-react-developers/ | <a href="https://web.archive.org/web/*/https://prateeksurana.me/blog/javascript-tips-for-react-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I have been working with React for the past couple of years, so naturally, I am not really proud of the code that I wrote when I was just beginning with React, because now I know the mistakes I made which I wasn't aware of back then.</p><p>But fast-forwarding to today, I have learned quite a bit along the way through contributing to open source, watching/reading some interesting blogs and conference talks and viewing how other people write code.</p><p>Here are some Javascript tips that would've helped my past self and maybe you, in writing more efficient and maintainable React code -</p><h2><a id="1-use-conditional-rendering-effectively" href="#1-use-conditional-rendering-effectively"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 1. Use conditional rendering effectively</a></h2><p>As a React developer, you must've been in a situation where you only want to display a component when a certain condition from a prop or state is satisfied or render different components depending on the different values of the state.</p><p>For instance, if you have a component where you want to show a loading indicator when the request is being made and render the component with data when the request is successful, this is the way I like to do it -</p><pre><code><span>const</span> <span>SomeComponent</span> <span>=</span> <span>(</span><span><span>{</span> isLoading<span>,</span> data <span>}</span></span><span>)</span> <span>=&gt;</span> <span>{</span><p>	<span>if</span><span>(</span>isLoading<span>)</span> <span>{</span><br>    <span>return</span> <span><span><span>&lt;</span><span>Loader</span></span><span>/&gt;</span></span><br>  <span>}</span></p><p>  <span>return</span> <span>(</span><br>     <span><span><span>&lt;</span><span>DataHandler</span></span><span>&gt;</span></span><span><br>       .<br>       .<br>     </span><span><span><span>&lt;/</span><span>DataHandler</span></span><span>&gt;</span></span><br>  <span>)</span><span>;</span></p><p><span>}</span></p></code></pre><p>But what if you want to render something inside JSX when a particular condition is satisfied in that case you can use the Logical AND operator (<code>&amp;&amp;</code>) to render it -</p><pre><code><span>const</span> <span>Button</span> <span>=</span> <span>(</span><span><span>{</span> showHomeIcon<span>,</span> children<span>,</span> onClick <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><br>  <span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>button<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span>onClick<span>}</span></span><span>&gt;</span></span><span><br>    </span><span>{</span>showHomeIcon <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>HomeIcon</span></span> <span>/&gt;</span></span><span>}</span><span><br>    </span><span>{</span>children<span>}</span><span><br>  </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><br><span>)</span><span>;</span></code></pre><p>Although a more useful scenario would be doing something like this, where you have an optional prop called icon which is a string and contains the name of the icon that can be used to render the icon component accordingly -</p><pre><code><span>const</span> <span>Button</span> <span>=</span> <span>(</span><span><span>{</span> icon<span>,</span> children<span>,</span> onClick <span>}</span></span><span>)</span> <span>=&gt;</span> <span>(</span><br>  <span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>button<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span>onClick<span>}</span></span><span>&gt;</span></span><span><br>    </span><span>{</span><span>}</span><span><br>    </span><span>{</span><span>typeof</span> icon <span>===</span> <span>"string"</span> <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>Icon</span></span> <span>name</span><span><span>=</span><span>{</span>icon<span>}</span></span> <span>/&gt;</span></span><span>}</span><span><br>    </span><span>{</span>children<span>}</span><span><br>  </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><br><span>)</span><span>;</span><p><br><span><span><span>&lt;</span><span>Button</span></span> <span>icon</span><span><span>=</span><span>"</span>home<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span>handleClick<span>}</span></span><span>&gt;</span></span><span>Home</span><span><span><span>&lt;/</span><span>Button</span></span><span>&gt;</span></span></p><p><br><span><span><span>&lt;</span><span>Button</span></span> <span>onClick</span><span><span>=</span><span>{</span>handleClick<span>}</span></span><span>&gt;</span></span><span>About</span><span><span><span>&lt;/</span><span>Button</span></span><span>&gt;</span></span></p></code></pre><p>So this solves the problem when you only have one component but what about when you have two or more than two components that you want to render based on some prop or state variable?</p><p>For two components ternary operator is my goto method, because of its simiplicity -</p><pre><code><span>const</span> <span>App</span> <span>=</span> <span>props</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> canViewWelcomeText <span>=</span> <span>isUserAuthenticated</span><span>(</span>props<span>)</span><span>;</span><p>  <span>return</span> canViewWelcomeText <span>?</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>Hey, there! Welcome back. Its been a while.</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span> <span>:</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>You need to login to view this page</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><p>And if you have quite a few components that need to be rendered from a condition, then switch case is probably the best one to go with -</p><pre><code><span>const</span> <span>getCurrentComponent</span> <span>=</span> <span>currentTab</span> <span>=&gt;</span> <span>{</span><br>  <span>switch</span> <span>(</span>currentTab<span>)</span> <span>{</span><br>    <span>case</span> <span>'profile'</span><span>:</span><br>      <span>return</span> <span><span><span>&lt;</span><span>Profile</span></span> <span>/&gt;</span></span><span>;</span><br>    <span>case</span> <span>'settings'</span><span>:</span><br>      <span>return</span> <span><span><span>&lt;</span><span>Settings</span></span> <span>/&gt;</span></span><span>;</span><br>    <span>default</span><span>:</span><br>      <span>return</span> <span><span><span>&lt;</span><span>Home</span></span> <span>/&gt;</span></span><span>;</span><br>  <span>}</span><br><span>}</span><span>;</span><p><span>const</span> <span>Dashboard</span> <span>=</span> <span>props</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> <span>[</span>currentTab<span>,</span> setTab<span>]</span> <span>=</span> React<span>.</span><span>useState</span><span>(</span><span>'profile'</span><span>)</span><span>;</span></p><p>  <span>return</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>"</span>dashboard<span>"</span></span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;</span><span>PrimaryTab</span></span> <span>currentTab</span><span><span>=</span><span>{</span>currentTab<span>}</span></span> <span>setTab</span><span><span>=</span><span>{</span>setTab<span>}</span></span> <span>/&gt;</span></span><span><br>      </span><span>{</span><span>getCurrentComponent</span><span>(</span>currentTab<span>)</span><span>}</span><span><br>    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><h2><a id="2-avoid-using-truthy-tests" href="#2-avoid-using-truthy-tests"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 2. Avoid using truthy tests</a></h2><p>If you are familiar with JavaScript then you might be aware of <a href="https://developer.mozilla.org/en-US/docs/Glossary/Truthy">truthy</a> and <a href="https://developer.mozilla.org/en-US/docs/Glossary/Falsy">falsy</a> values. So a truthy test is nothing but using this coercion ability of JavaScript in control flow statements like this</p><pre><code><br><br><span>if</span> <span>(</span>somVar<span>)</span> <span>{</span><br>	<span>doSomething</span><span>(</span><span>)</span><span>;</span><br><span>}</span> </code></pre><p>This might look good at first if you want to avoid something like <code>null</code> since it is a falsy value so the statement will work as expected. But the catch here is that this is prone to bugs that can be very difficult to track down. This is because the above statement would block the flow for not <code>null</code> but also for all these falsy values of <code>someVar</code> which we might want to avoid -</p><pre><code>someVar <span>=</span> <span>0</span><br>someVar <span>=</span> <span>""</span><br>someVar <span>=</span> <span>false</span><br>someVar <span>=</span> <span>undefined</span></code></pre><p>So what is the correct way for these checks?</p><p>The valid way is being as straightforward as possible for these checks to avoid any bugs from creeping in. For the above case it would be -</p><pre><code><br><span>if</span> <span>(</span>someVar <span>!==</span> <span>null</span><span>)</span> <span>{</span><br>	<span>doSomething</span><span>(</span><span>)</span><span>;</span><br><span>}</span></code></pre><blockquote><p>If you're sure that the variable being passed is a boolean then you can use the former approach.</p></blockquote><p>This also applies when doing conditional rendering with the Logical and operator that we saw in the previous tip.</p><p>If the first operator is falsy then JavaScript returns that object. So in case of an expression like <code>0 &amp;&amp; "javascript"</code> will return <code>0</code> and <code>false &amp;&amp; "javascript"</code> will return <code>false</code> . This can bite you if you were doing something like this -</p><pre><code><br><br><span>{</span>cats<span>.</span>length <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>AllCats</span></span> <span>cats</span><span><span>=</span><span>{</span>cats<span>}</span></span> <span>/&gt;</span></span><span>}</span><p><br><br><span>{</span>cats<span>.</span>length <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span><span><span>&lt;</span><span>AllCats</span></span> <span>cats</span><span><span>=</span><span>{</span>cats<span>}</span></span> <span>/&gt;</span></span><span>}</span></p></code></pre><h2><a id="3-use-optional-chaining-and-nullish-coalescing" href="#3-use-optional-chaining-and-nullish-coalescing"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 3. Use optional chaining and nullish coalescing</a></h2><p>When dealing with data in our apps we often need to deal with parts of data that call be <code>null</code> or <code>undefined</code> and provide default values.</p><p>Let's suppose we have an API that returns the details of a Pet in the following format -</p><pre><code><br><span>{</span><br>  id<span>:</span> <span>42</span><span>,</span><br>  name<span>:</span> <span>'Ghost'</span><span>,</span><br>  type<span>:</span> <span>'Mammal'</span><span>,</span><br>  diet<span>:</span> <span>'Carnivore'</span><br>  owner<span>:</span> <span>{</span><br>    first_name<span>:</span> <span>'Jon'</span><span>,</span><br>    last_name<span>:</span> <span>'Snow'</span><span>,</span><br>    family<span>:</span> <span>{</span><br>      name<span>:</span> <span>'Stark'</span><span>,</span><br>      location<span>:</span> <span>'Winterfell'</span><br>    <span>}</span><br>  <span>}</span><br><span>}</span></code></pre><p>So you could do something like this if you wanted the first name of the pet owner</p><pre><code><span>const</span> ownerName <span>=</span> pet<span>.</span>owner<span>.</span>first_name<span>;</span></code></pre><p>But like all things in the universe can't be perfect, our API doesn't guarantee that all the details would be available for any given pet and can be <code>null</code> or <code>undefined</code>.</p><p>In that case, the above line of code can result and the following error "Reference error cannot read property <code>first_name</code> of <code>null</code>" and crash your app if the owner is <code>null</code>.</p><p>This is where <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Optional_chaining">optional chaining</a> saves you. The optional chaining operator (<code>?.</code>) allows you to read the property deep in the chain without having to validate whether the chain is valid, and instead of a reference error, it would return the same old <code>undefined</code>.</p><p>So we could easily check for the owner name or even the owner family name without worrying about any errors, like this -</p><pre><code><span>const</span> ownerName <span>=</span> pet<span>?.</span>owner<span>?.</span>first_name<span>;</span><br><span>const</span> ownerFamily <span>=</span> pet<span>?.</span>owner<span>?.</span>family<span>?.</span>name<span>;</span></code></pre><blockquote><p>Optional chaining can also be used with function calls on properties you are not really sure to exist. For instance, you can do this with an array <code>friends?.join(",")</code> , this won't result in an error if friends is anything other than an array, even <code>undefined</code>.</p></blockquote><p>Now, this would avoid errors but you still wouldn't want your users to show <code>undefined</code> in case it is not available. This is where Nullish Coalescing comes in -</p><pre><code><span>const</span> ownerName <span>=</span> pet<span>?.</span>owner<span>?.</span>first_name <span>??</span> <span>'Unknown'</span><span>;</span></code></pre><p>The <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Nullish_coalescing_operator">Nullish Coalescing operator</a> (<code>??</code>) returns the right hand side operand when the left hand side is <code>null</code> or <code>undefined</code> and otherwise it returns the left hand side operand.</p><p>You might think here that the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Logical_OR">Logical Or operator</a> (<code>||</code>) would also have done the same thing. Well in that case I hope you haven't forgotten the truthy and falsy hell of JavaScript that we just covered. Since this operator would return the right hand side operand for all falsy values and can cause hard to debug errors as mentioned in the previous section.</p><blockquote><p>Since these methods were recently released with <a href="https://auth0.com/blog/javascript-whats-new-es2020/">ECMAScript 2020 spec</a> browser compatibility for these methods is still in the preliminary stages and only the modern browsers support it right now.</p><p>But don't worry most setups we use to compile our apps have already got us covered. If you're using TypeScript ≥ 3.7 then <a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-7.html">these methods are supported out of the box</a>.</p><p>Else if you're using a typical Webpack + babel setup then you can include the <a href="https://babeljs.io/docs/en/babel-plugin-proposal-optional-chaining"><code>@babel/plugin-proposal-optional-chaining</code></a> and <a href="https://babeljs.io/docs/en/babel-plugin-proposal-nullish-coalescing-operator"><code>@babel/plugin-proposal-nullish-coalescing-operator</code></a> plugins in your babel config to support these methods.</p></blockquote><h2><a id="4-avoid-premature-optimization" href="#4-avoid-premature-optimization"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" height="20" width="20" xmlns="http://www.w3.org/2000/svg"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg> 4. Avoid premature optimization</a></h2><p>Be really careful when you want to memoize something in React, because if not done properly it might lead to even worse performance.</p><p>I have often seen people prematurely optimizing everything they come across without considering the cost it comes with. For instance, using <code>useCallback</code> in situations like this -</p><pre><code><span>const</span> <span>MyForm</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> <span>[</span>firstName<span>,</span> setFirstName<span>]</span> <span>=</span> React<span>.</span><span>useState</span><span>(</span><span>''</span><span>)</span><span>;</span><p>  <span>const</span> <span>handleSubmit</span> <span>=</span> <span>event</span> <span>=&gt;</span> <span>{</span><br>    <br>  <span>}</span><span>;</span></p><p>    <br>  <span>const</span> handleChange <span>=</span> React<span>.</span><span>useCallback</span><span>(</span><span>event</span> <span>=&gt;</span> <span>{</span><br>    <span>setFirstName</span><span>(</span>event<span>.</span>target<span>.</span>value<span>)</span><span>;</span><br>  <span>}</span><span>,</span> <span>[</span><span>]</span><span>)</span><span>;</span></p><p>  <span>return</span> <span>(</span><br>    <span><span><span>&lt;</span>form</span> <span>onSubmit</span><span><span>=</span><span>{</span>handleSubmit<span>}</span></span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;</span>input</span> <span>type</span><span><span>=</span><span>"</span>text<span>"</span></span> <span>name</span><span><span>=</span><span>"</span>firstName<span>"</span></span> <span>onChange</span><span><span>=</span><span>{</span>handleChange<span>}</span></span> <span>/&gt;</span></span><span><br>      </span><span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>submit<span>"</span></span> <span>/&gt;</span></span><span><br>    </span><span><span><span>&lt;/</span>form</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><p>Now you might've heard that <code>useCallback</code> is known to improve performance by memoizing the function and only updating it when the dependencies change. That is true but you need to understand that <strong>every optimization comes with a cost associated with it</strong>.</p><p>In the above case, you are doing more work by creating a <code>useCallback</code> which in itself is running some logical expression checks, hence you're better off with just defining the inline function directly like this -</p><pre><code><span>const</span> <span>handleChange</span> <span>=</span> <span>event</span> <span>=&gt;</span> <span>{</span><br>    <span>setFirstName</span><span>(</span>event<span>.</span>target<span>.</span>value<span>)</span><span>;</span><br><span>}</span><span>;</span></code></pre><p>The same things apply with <code>React.memo</code>. If you have a component like this that accepts children props, then memoizing the component is basically useless if the children are not memoized -</p><pre><code><span>const</span> UselessMemoizedHeader <span>=</span> React<span>.</span><span>memo</span><span>(</span><span>(</span><span><span>{</span> children <span>}</span></span><span>)</span> <span>=&gt;</span> <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>{</span>children<span>}</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>)</span><span>;</span><p><span>const</span> <span>SomeComponent</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span><br>  <span>const</span> <span>[</span>count<span>,</span> setCount<span>]</span> <span>=</span> React<span>.</span><span>useState</span><span>(</span><span>0</span><span>)</span><span>;</span><br>  <span>return</span> <span>(</span><br>    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;</span><span>UselessMemoizedHeader</span></span><span>&gt;</span></span><span><br>        </span><span><span><span>&lt;</span>span</span><span>&gt;</span></span><span>Header</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span><br>      </span><span><span><span>&lt;/</span><span>UselessMemoizedHeader</span></span><span>&gt;</span></span><span><br>      Count: </span><span>{</span>count<span>}</span><span><br>      </span><span><span><span>&lt;</span>button</span> <span>type</span><span><span>=</span><span>"</span>button<span>"</span></span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>currentCount</span> <span>=&gt;</span> currentCount <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span><br>        Increment count<br>      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span><br>    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><br>  <span>)</span><span>;</span><br><span>}</span><span>;</span></p></code></pre><p>In the above case, the <code>UselessMemoizedHeader</code> component would re-render every time you increment the count even though you might think it is memoized.</p><p>But why? Since memo just does a shallow comparison of the current props and previous props, and because the children prop won't be <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Equality_comparisons_and_sameness">refrentially equal</a> you end up re-rendering the <code>UselessMemoizedHeader</code> component every time the count changes.</p><p>Your code ends up being even worse off because of that unnecessary children prop comparison on every render.</p><p>So when do you actually need to memoize? Well Kent C. Dodds <a href="https://kentcdodds.com/blog/usememo-and-usecallback">covers all the above things with when you should memoize in great detail</a> …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://prateeksurana.me/blog/javascript-tips-for-react-developers/">https://prateeksurana.me/blog/javascript-tips-for-react-developers/</a></em></p>]]>
            </description>
            <link>https://prateeksurana.me/blog/javascript-tips-for-react-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295794</guid>
            <pubDate>Sun, 28 Feb 2021 18:36:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tools I use to protect my privacy online]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26295775">thread link</a>) | @sdas7
<br/>
February 28, 2021 | https://consult.sauvik.me/posts/stay-safe-online/ | <a href="https://web.archive.org/web/*/https://consult.sauvik.me/posts/stay-safe-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It shouldn’t have to be this way, but the burden of protecting your privacy as you browse the web is your own. I do what I can in my research and consulting to advocate for systemic change in design and policy to reduce the burden on the individual user; but that kind of change is slow to fruit. Meanwhile, there are tools that you, the individual, can use to partially protect yourself against the forces of surveillance capitalism and other institutional privacy threats. I will share five that I use myself.</p><hr><h2 id="i-use-the-dashlane-vpn-to-curtail-web-tracking-and-circumvent-regional-content-filters">I use the Dashlane VPN to curtail web tracking and circumvent regional content filters</h2><p>You probably already know about Virtual Private Networks (VPNs). If you work at a sufficiently large institution, chances are your workplace has one in place to allow you remote access to the institution’s intranet. VPNs do more than helping employers facilitate secure intranet access, however. VPNs help obfuscate your web traffic — both from the websites you visit, and from your Internet Service Provider (e.g., Verizon, Comcast, AT&amp;T).</p><p>Eliding key technical details, you can think of a VPN as a middleman / intermediary between you and the Internet-at-large. While this slows down your connection slightly, the benefit is that the rest of your web traffic is encrypted and routed through this middleman. This provides privacy benefits because, without the use of something like a VPN, ISPs can track every website you visit online. If you visit websites over plain HTTP (instead of HTTPS), they can only track what you do on those websites. And any personal data that your ISP keeps on you can be subpoena’d by, e.g., law enforcement. Moreover, ISPs can sell this information freely — e.g., to advertising brokers, who may want to sell you targeted ads based on the websites you have frequented. You consented to this when you agreed to their terms of service.</p><p>Does that sound a little shady? It is! There are only a handful of ISPs in the country; in specific regions, there may be only one. And they work tirelessly to make sure that competitors cannot make headway. So most people do not have a real choice when it comes to their ISP. They agree to the terms because what else can they do if they want Internet?</p><p>Using a VPN service, the ISP will no longer be able to see what you download and what websites you visit. They <em>will</em> be able to see some meta-data, however — e.g., that you are using a VPN, the encrypted data you are receiving and when you are connecting.</p><p>VPNs also allow you to hide or disguise yourself from the websites you visit. Indeed, many VPNs have servers all over the world. So, if there is content that is being blocked in the U.S. but not in Germany, you can use a VPN to make it seem like you are connecting from Germany.</p><p>The downside? Middlemen are usually inefficient — and indeed, using a VPN will make your connection a little slower than if you were to not use it. Also, private VPN services cost money —&nbsp;usually between $5 and $15 / month. Moreover, you are simply displacing trust from the ISP to the VPN service. While your ISP will not be able to see the websites you visit, the VPN service will be able to. Because of this, as a part of their terms of service, good private VPN services should be stateless — they should not keep any record of the websites you visit through the VPN. This is also why you probably do <em>not</em> want to use your corporate VPN for surfing the web privately —&nbsp;your employer will be able to see your web traffic if you do so.</p><p>Private VPN services are now common — some popular private VPN services include Express VPN and Nord VPN. I have not used either, so I will not comment on them. But I know many people who use those services and have not heard any direct complaints.</p><p>I use the Dashlane VPN, and it works great. I use the Dashlane VPN because I use the Dashlane premium password manager, and the VPN service is included in the fee I pay for Dashlane premium. If you would like to try Dashlane premium for free for six months, you may use <a href="https://www.dashlane.com/cs/s23HfOIFsAxE">this referral link</a>.</p><h2 id="i-use-firefox-with-ublock-origin--decentraleyes-for-curtailing-web-trackers-while-browsing">I use Firefox with uBlock Origin + Decentraleyes for curtailing web trackers while browsing</h2><p>ISPs are just one threat to your privacy; many of the websites you visit also track and store as much information about you as they can — the websites you visit, what you do on them, at what time of day, etc. Why? Because the prevailing business model of the web is surveillance capitalism — keeping track of your personal data allows advertisers to develop rich profiles of what you like and what they would like you to like. These data, in turn, can be used to serve you with personalized advertisements —&nbsp;and it’s important to note that these advertisements are not just obvious ones like Nike shoes you might like, but also things like article recommendations from political campaigns.</p><p>Stopping this tracking and nudging is not easy, but it starts with your choice of web browser. If you care about privacy, do not use web browsers released by institutions that have little vested interest in protecting your personal data.</p><p>I use Firefox. Firefox has some nice in-built or officially supported privacy-preserving features — e.g., automated tracking prevention and containers. Containers help you isolate cookies to prevent third-party tracking. For example, with the Facebook container add-on on Firefox, you can be assured that Facebook cookies will not be</p><p>In addition to these in-built features, I also use a few extensions to further subvert tracking efforts. The most important is <a href="https://ublockorigin.com/">uBlock Origin</a>, an extension that automatically blocks thousands of known tracking scripts and advertisements. The second is <a href="https://decentraleyes.org/">Decentraleyes</a>, which blocks requests for common scripts distributed through centralized CDNs and provides local versions of those scripts instead — e.g., for Google fonts. This prevents the hosts of those CDNs (often large companies like Google, Microsoft, Facebook) from tracking which websites you visit when those websites request content from those CDNs. Both of these extensions are open source; so I trust them more than I do less transparent alternatives like Ghostery.</p><p>Other privacy enthusiasts use Brave instead of Firefox. Brave is a relatively new web browser that has in-built tracker protection. It is also piloting an interesting new business model for <a href="https://brave.com/intro-to-brave-ads/">privacy-preserving targeted ads</a> —&nbsp;the goal is to match a local “interests” profile that never leaves your computer with a set of candidate advertisements; this way, you get targeted advertisements without being tracked by a remote entity.</p><p>So why do I use Firefox and not Brave? I used to use Brave; I like Brave. But it started getting very slow for collaborative text editing on Overleaf on my machine. So, I switched to Firefox as my primary browser because I spend a lot of time writing papers on overleaf. There is also <a href="https://www.coindesk.com/brave-browsers-affiliate-link-controversy-explained">refer gate</a> — i.e., Brave’s autocompleting of urls to cryptocurrency webpages to append their own affiliate codes. This has since been fixed, but it did build some enmity with the community.</p><p>My main qualm with Firefox is that while Mozilla is doubling down on its identity as a consumer privacy company, <a href="https://www.ghacks.net/2020/12/10/mozillas-revenue-jumped-to-828-million-u-s-dollar-in-2019/">the majority of its revenues do still come from Google ads</a> — when you search for something through the Mozilla browser and you click on an ad on Google, Mozilla gets a royalty. While this is not a direct conflict of interest, it does mean that Mozilla profits from surveillance capitalism, too.</p><h2 id="i-use-protonmail-for-secure-encrypted-email-that-is-not-tracked-or-analyzed">I use ProtonMail for secure, encrypted email that is not tracked or analyzed</h2><p>Would it surprise you to learn that many free email services analyze your email? It shouldn’t; it’s how spam detection works, for example. But services like Gmail analyze your email for a lot more than spam detection. As with most other Google services, Gmail is beautiful, fast, usable and free. But in using it, you consent to Google being able to track what you say, what people are saying to you, and who you know. That information can be used by Google to learn more about you and your interests to serve you personalized ads; it can also be subpoena’d by the government.</p><p>I won’t dwell on this point for long, because most people understand email privacy without me needing to delve into the technical details. There are many secure email alternatives to Gmail now; what you are looking for, again, is service provided by a company that does not make its money from collecting personal data. Ideally, you will also want to find a company with servers hosted in a country with stronger consumer privacy protections —&nbsp;e.g., Switzerland or Estonia.</p><p>I use <a href="https://protonmail.com/">ProtonMail</a>. It has a clean interface, and provides a host of nice security features (included end-to-end encryption and self-destructing messages).</p><h2 id="i-use-signal-for-end-to-end-encrypted-messaging">I use Signal for end-to-end encrypted messaging</h2><p>For all the same reasons that you might want privacy-preserving email, you want privacy-preserving messaging as well and this means a messaging service that utilizes end-to-end encryption (E2EE). E2EE means that only the sender and intended receivers will be able to read the messages. Nobody else — not even the service it self — will be able to read the messages.</p><p>While there are a number of E2EE messaging applications on the marketplace, I use and recommend Signal for two reasons. First, security in theory is different than security in practice. The Signal protocol is open-source and has been vetted by many in the security community, and so it easier to trust its security “in practice”. Second, at least partially owing to WhatsApp’s recent announcement that it will share data with Facebook, a lot of people now use Signal — and that’s important because a messenger is only useful if the person you want to message uses it! In fact, some research I did back in 2016 found that the key driver of secure messaging use was not promises of security, but simply the presence of one’s friends on the platform <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p><h2 id="i-use-duckduckgo-for-tracking-free-search">I use DuckDuckGo for tracking-free search</h2><p>If you are reading this blog post, I do not think I have to convince you that search engines like Google track …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://consult.sauvik.me/posts/stay-safe-online/">https://consult.sauvik.me/posts/stay-safe-online/</a></em></p>]]>
            </description>
            <link>https://consult.sauvik.me/posts/stay-safe-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295775</guid>
            <pubDate>Sun, 28 Feb 2021 18:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lean into Procrastination]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26295774">thread link</a>) | @patapizza
<br/>
February 28, 2021 | https://jodent.io/posts/lean-into-procrastination | <a href="https://web.archive.org/web/*/https://jodent.io/posts/lean-into-procrastination">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://jodent.io/posts/lean-into-procrastination</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295774</guid>
            <pubDate>Sun, 28 Feb 2021 18:34:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The A-Z80 FPGA CPU (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26295630">thread link</a>) | @mariuz
<br/>
February 28, 2021 | https://baltazarstudios.com/z80-cpu/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80-cpu/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p>This article contains a brief overview and a background of the&nbsp;<em>A-Z80</em> CPU created for FPGA boards and a <em>ZX Spectrum</em> implementation tied to it.</p>
<p>(You can find the Russian translation of this article here: <a href="https://howtorecover.me/z80-s-nulya" target="_blank" rel="noopener noreferrer">https://howtorecover.me/z80-s-nulya</a>)<br>
<span id="more-1108"></span></p>
<p>Every so often I let go of all that's on my mind and simply brainstorm and play with new ideas and their combinations (mostly based on the retro stuff). Then I pick what seems to excite me the most and deep dive into it.</p>
<figure id="attachment_1156" aria-describedby="caption-attachment-1156"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/ideas.jpg"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-512x341.jpg" alt="(partial) list of brainstorming ideas (2014)" width="512" height="341" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-512x341.jpg 512w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-150x100.jpg 150w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-1024x683.jpg 1024w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas-960x640.jpg 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/ideas.jpg 1039w" sizes="(max-width: 512px) 100vw, 512px"></a><figcaption id="caption-attachment-1156">(partial) list of brainstorming ideas (2014)</figcaption></figure>
<p>This time (early 2014), I wanted to re-make a <em>Sinclair ZX Spectrum</em> on an <strong>FPGA</strong>. There were already several implementations available and most of them used "off the shelf" components. One could simply pluck components written in Verilog (CPU, ULA) and with some glue logic quickly build a retro FPGA solution. There is no fun in doing that - or at least nothing much to learn about each component as one could learn by creating them from scratch.</p>
<p>I wanted to start with the Zilog Z80 CPU. Since the real people design their own CPUs (right?!), I decided I would make my own version of it. 🙂</p>
<p>Both parts of this project (the&nbsp;<a title="A Z80 From the Ground Up" href="https://baltazarstudios.com/z80-ground/" target="_blank" rel="noopener noreferrer">A-Z80 CPU</a> and a <a title="Sinclair ZX Spectrum on the A-Z80" href="https://baltazarstudios.com/sinclair-zx-spectrum-z80/" target="_blank" rel="noopener noreferrer">ZX Spectrum</a> code that uses it) are fully described in separate blogs, and here I will try to tie them together using a somewhat less technical narrative.</p>
<p>I started reverse-engineering Zilog Z80 CPU about a year ago by running a working chip on a&nbsp;custom Arduino dongle board. I described it <a href="https://baltazarstudios.com/arduino-zilog-z80/" target="_blank" rel="noopener noreferrer">here</a>. It was interesting to see how the pins responded to various scenarios. I was mostly interested in <a href="https://baltazarstudios.com/zilog-z80-undocumented-behavior/" target="_blank" rel="noopener noreferrer">undocumented behaviour</a>&nbsp;hoping it will give me some hints on the CPU's internal architecture.</p>
<p>Then, I've found a set of articles by Ken Shirriff who actually reverse-engineered large portions of&nbsp;the&nbsp;Z80 from an image of a die. I've found the knowledge of "reading a die image" very exciting and the skill (in a weird way) very useful, so painstakingly I've learned to do the same. I reverse engineered a few other pieces of that silicon, like the <a href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noopener noreferrer">IR</a> register and a <a href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noopener noreferrer">data pin</a>. Soon I got a hang of it&nbsp;and started "reading" other parts, as needed. It felt like a whole new world opened right in front of my eyes! Not much unlike stereogram images: as you look at it long enough, gates suddenly pop up in your mind and you start seeing transistors, pull-ups and latches out of a tangled mesh of colorful flat traces.</p>
<p>I had purchased an Altera FPGA board with a desire to learn that technology after working on a project at my work which was using one, quite beefy, Altera chip. Designing a circuitry on my own, I felt, was an exciting challenge and a great learning opportunity. Soon, I figured out how Verilog/SystemVerilog "works"; a language not too difficult to learn for any software person. I also brushed up on a logic design (I had one lousy taught EE class some 20 years ago).</p>
<p>Long story short, I started implementing selected parts of Z80 in the <em>Quartus</em> schematic editor and wrote related&nbsp;<em>ModelSim</em> tests one by one: first came the ALU (since it's design was well described by Ken), then the register file, sequencer, etc. Frankly, I did not know how would all of that fit or work <em>together</em>; I was simply enjoying the process, one block at a time. I just <em>loved</em> seeing wires toggling and gates doing their thing in a&nbsp;ModelSim simulation: a certain deep understanding of a digital design sank in while playing with it.</p>
<p><a href="https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-512x307.png" alt="modelsim_run" width="512" height="307" srcset="https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-512x307.png 512w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-150x90.png 150w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-1024x615.png 1024w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run-960x577.png 960w, https://baltazarstudios.com/wp-content/uploads/2014/09/modelsim_run.png 1680w" sizes="(max-width: 512px) 100vw, 512px"></a></p>
<p>I also read all I could get my hands on: patents on Z80 (and other CPUs) which provided valuable insights; talks, lectures and over time I got a pretty good ideas on how it all&nbsp;<em>should</em>&nbsp;work.</p>
<p>The most complicated task was to create the instruction timing matrix. Using all the information gathered in the process, I created an Excel spreadsheet with the exact timing of required micro-operations for each M (machine) and T (clock) stated of each opcode class.</p>
<p>This matrix defines the CPU and ensures it is fully Z80-compatible. In fact, if you modify it, you could create new instructions, enhance the CPU or even create a completely different one and the design would still just work!</p>
<p>The following set of images show the complete timing matrix printed from <a href="https://baltazarstudios.com/webshare/A-Z80/timings.xps" target="_blank" rel="noopener noreferrer">this XPS file</a>. It is printed into 8 consecutive images; click on each to see it in a full, readable size:</p>
<figure id="attachment_1159" aria-describedby="caption-attachment-1159"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-116x150.png" alt="A-Z80 Timings 1/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.1.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1159">A-Z80 Timings 1/8</figcaption></figure>
<figure id="attachment_1160" aria-describedby="caption-attachment-1160"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-116x150.png" alt="A-Z80 Timings 2/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.2.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1160">A-Z80 Timings 2/8</figcaption></figure>
<figure id="attachment_1161" aria-describedby="caption-attachment-1161"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-116x150.png" alt="A-Z80 Timings 3/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.3.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1161">A-Z80 Timings 3/8</figcaption></figure>
<figure id="attachment_1162" aria-describedby="caption-attachment-1162"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-116x150.png" alt="A-Z80 Timings 4/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.4.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1162">A-Z80 Timings 4/8</figcaption></figure>
<figure id="attachment_1163" aria-describedby="caption-attachment-1163"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-116x150.png" alt="A-Z80 Timings 5/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.5.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1163">A-Z80 Timings 5/8</figcaption></figure>
<figure id="attachment_1164" aria-describedby="caption-attachment-1164"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-116x150.png" alt="A-Z80 Timings 6/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.6.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1164">A-Z80 Timings 6/8</figcaption></figure>
<figure id="attachment_1165" aria-describedby="caption-attachment-1165"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-116x150.png" alt="A-Z80 Timings 7/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.7.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1165">A-Z80 Timings 7/8</figcaption></figure>
<figure id="attachment_1166" aria-describedby="caption-attachment-1166"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8.png"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-116x150.png" alt="A-Z80 Timings 8/8" width="116" height="150" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-116x150.png 116w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-396x512.png 396w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-791x1024.png 791w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8-960x1242.png 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/timings.xps_.8.png 1632w" sizes="(max-width: 116px) 100vw, 116px"></a><figcaption id="caption-attachment-1166">A-Z80 Timings 8/8</figcaption></figure>
<p>Each column, <strong>B</strong> through <strong>AH</strong>, contains zero or more micro-operations on specific internal design blocks (<a href="https://baltazarstudios.com/webshare/timing_macros.i.html" target="_blank" rel="noopener noreferrer">this file</a> deciphers the tokens used). Groups of instructions are listed in a row as statically decoded by the PLA table, each line corresponding to specific M and T cycle.</p>
<p>Rather early in the process, I devised several tests, including a&nbsp;full <em>Fuse</em>-based test suite which could run every instruction against a set of known results. That test proved the most valuable: it enabled to flag regressions as well as to check that the instructions were implemented correctly.</p>
<p>After some time, I was able to combine several Z80 instructions and run them in sequence. Enjoying many exciting milestone moments along the way, the one that stuck was when the PC register correctly incremented and was fetching successive instructions. They were also correctly executed since each one was tested separately: it all just worked!</p>
<p>After adding a virtual UART module in Verilog, I was able to get simple "Hello, world" programs sending the text out to a terminal! The same output would be captured by&nbsp;ModelSim simulating that code. It proved very helpful having several different ways to test and correlate the results.</p>
<p>The most difficult part was getting the interrupt handling done just right. Z80 has 3 interrupt modes (im0, im1, im2), maskable INT with two flags (the enable bit and its shadow) and non-maskable NMI. INT is level-triggered while the NMI is latched, edge-triggered and has precedence over INT. The pins should be checked at known times and be inhibited in certain situations, including during the execution of some instructions. It all needed to be working perfectly at known clock boundaries.</p>
<p>The solution ended up very elegant and used minimum number of extra gates: besides necessary state flags and priority logic, it used a couple of control signals wired just right: see the timings page 7, lines 1028-1060, entry "rst p" and how the instruction RST38 is being used to handle both NMI and INT (im2) at the same time. You start seeing a beauty of the original Mr. Faggin's design when you realize the coherence of the known behavior and the most optimal implementation. The simplicity of it became the proof of the implementation.</p>
<p>Once the CPU was wrapped up, it could run any code sequence using any instruction assembled and pushed onto a simple "board" model. That included some devilish and mean-designed interrupt-bombardment tests. It also run well known ZEXDOC and ZEXALL programs. They all passed except several XF/YF (undocumented flags) behavioral tests for 2 sets of instructions. Those are <em>really</em> weird and if you have ever played with Z80 emulators you would know what I mean. This particular Z80 behavior is likely a side-effect of internal bus charge/discharge cycles and some spurious control signals; various second-sourced and cloned Z80 chips also behave differently in these scenarios. I decided not to sweat over it as it had no practical impact.</p>
<p>Frankly, at this stage, I was already satisfied with the results since my original goal was to understand and replicate the internal architecture of the Z80, and I have achieved it.</p>
<p>Compare the following image - a conceptual block diagram of the A-Z80 CPU - with the annotated image of a Z80 die from the top&nbsp;of this article to see the similarity in the layout. I have placed schematic modules at the locations roughly corresponding to their positions on the Z80 die. Not to scale. You should be able to trace major buses (data bus in green and address bus in red) and zoom into detailed diagrams to see gate level implementations of the blocks. A few System Verilog sources appear just symbolically; naturally, the complete code would not fit on a printed page. Open it up in an image viewer that can zoom and pan.</p>
<figure id="attachment_1184" aria-describedby="caption-attachment-1184"><a href="https://baltazarstudios.com/webshare/A-Z80/a-z80-block-diagram.psd" target="_blank" rel="https://drive.google.com/file/d/0bykupmks9xs3awetblndzuczrfu/view?usp=sharing noopener noreferrer"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/a-z80-block-diagram-thumb.png" alt="A-Z80 block diagram (thumb)" width="256" height="175" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/a-z80-block-diagram-thumb.png 256w, https://baltazarstudios.com/wp-content/uploads/2015/01/a-z80-block-diagram-thumb-150x103.png 150w" sizes="(max-width: 256px) 100vw, 256px"></a><figcaption id="caption-attachment-1184">A-Z80 block diagram; click to expand</figcaption></figure>
<p>By that time, I was already fairly fluent in Verilog so the coding of a <em>ZX Spectrum</em> model was not a problem. First, I added a video unit by picking one (most suitable) VGA timing standard and was able to display static screens from various games. Then came the correct character blink and border behavior. After that: keyboard interface, speaker, mic - all fairly simple modules. Once I got all internal mappings correctly set up, I powered it up, flashed it with the newest FPGA file and, to my huge excitement, saw a black screen clearing up and the magic "<strong>(C) 1982 Sinclair Research Ltd</strong>" prompt on the screen! I can't tell you just how exciting that moment was; I kept resetting it over and over just to see it appearing again!</p>
<p>Soon I was able to load and play games!</p>
<figure id="attachment_1186" aria-describedby="caption-attachment-1186"><a href="https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon.jpg"><img loading="lazy" src="https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-512x341.jpg" alt="The Legend of Avalon, Graftgold Ltd, 1984" width="512" height="341" srcset="https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-512x341.jpg 512w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-150x100.jpg 150w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-1024x683.jpg 1024w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon-960x640.jpg 960w, https://baltazarstudios.com/wp-content/uploads/2015/01/zx-spectrum-avalon.jpg 1152w" sizes="(max-width: 512px) 100vw, 512px"></a><figcaption id="caption-attachment-1186">The Legend of Avalon, Graftgold Ltd, 1984</figcaption></figure>
<p>But, there was one problem: the design would randomly reboot or lock up. I spent a long time debugging it but a chance conversation with Ed (a co-worker of mine, Ed is a world-class chip designer who <em>really</em> knows this stuff) would reveal a possible problem: trying to follow the exact Z80 architecture, I have used transparent latches in my FPGA design throughout. Well, no FPGA designs use latches these days. Ed told me a latch design would have never worked [reliably]. Well, I <em>did</em> make it work, somehow. Kind of.</p>
<p>Back to the drawing board and one month later, I have re-implemented the whole design to use flip-flops. Accordingly, I also had to modify a few timings here and there. The new design is fully synchronous and meets all&nbsp;timings; it is being checked using the&nbsp;<em>TimeQuest</em> static timing analyzer tool and have fully constrained timings (using SDC files). In the meantime, I've also found and fixed several issues including one important bug fix in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80-cpu/">https://baltazarstudios.com/z80-cpu/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80-cpu/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26295630</guid>
            <pubDate>Sun, 28 Feb 2021 18:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weird architectures weren't supported to begin with]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 254 (<a href="https://news.ycombinator.com/item?id=26294397">thread link</a>) | @woodruffw
<br/>
February 28, 2021 | https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Feb 28, 2021</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#rant">rant</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<hr>

<h4 id="preword">Preword</h4>

<p>This post contains my own opinions, not the opinions of my employer or any open source groups I
belong or contribute to.</p>

<p>It’s also been rewritten 2½ times, and (I think) reads confusingly in places. But I promised
myself that I’d get it out of the door instead of continuing to sit on it, so here we go.</p>

<hr>

<p>There’s been a decent amount of <del>drama</del> debate in the open source community about <em>support</em>
recently, originating primarily from
<a href="https://github.com/pyca/cryptography/issues/5771">pyca/cryptography’s decision to use Rust for some ASN.1 parsing routines</a><sup id="fnref:asn1" role="doc-noteref"><a href="#fn:asn1">1</a></sup>.</p>

<p>To summarize the situation: building the latest <code>pyca/cryptography</code> release from scratch now requires
a Rust toolchain. The only currently<sup id="fnref:gccrust" role="doc-noteref"><a href="#fn:gccrust">2</a></sup> Rust toolchain is built on <a href="https://llvm.org/">LLVM</a>, which
supports a (relatively) limited
<a href="https://llvm.org/docs/CompilerWriterInfo.html">set of architectures</a>. Rust further whittles this
set down into <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">support tiers</a>, with
some targets not receiving automated testing (tier 2) or official builds (tier 3).</p>

<p>By contrast, upstream<sup id="fnref:gcchell" role="doc-noteref"><a href="#fn:gcchell">3</a></sup> GCC supports a <a href="https://gcc.gnu.org/backends.html">somewhat larger</a>
set of architectures. But C<sup id="fnref:c" role="doc-noteref"><a href="#fn:c">4</a></sup>, cancer that it is, finds its way onto every architecture with or
without GCC (or LLVM’s) help, and thereby bootstraps <a href="https://github.com/python/cpython">everything</a>
<a href="https://www.gnome.org/">else</a>.</p>

<p>Program packagers and distributors (frequently separate from project maintainers themselves)
are very used to C’s universal presence. They’re so used to it that they’ve built generic
mechanisms for putting entire distributions onto new architectures with
only a single assumption: the presence of a serviceable C compiler.</p>

<p>This is the heart of the conflict: Rust (and many other modern, safe languages) use LLVM for its
relative simplicity<sup id="fnref:simple" role="doc-noteref"><a href="#fn:simple">5</a></sup>, but LLVM does not support either native or cross-compilation to many
less popular (read: niche) architectures. Package managers are increasingly finding that one of
their oldest assumptions can be easily violated, and they’re not happy about that.</p>

<p>But here’s the problem: <em>it’s a bad assumption</em>. The fact that it’s the default
represents an <strong>unmitigated</strong> security, reliability, and reproducibility <em>disaster</em>.</p>

<h2 id="a-little-thought-problem">A little thought problem</h2>

<p>Imagine, for a moment, that you’re a maintainer of a popular project.</p>

<p>Everything has gone right for you: you have happy users, an active development base, and maybe even
corporate sponsors. You’ve also got a CI/CD pipeline that produces canonical releases of your
project on tested architectures; you treat any issues with uses of those releases as a bug in the
project itself, since you’ve taken responsibility for packaging it.</p>

<p>Because your project is popular, <strong>others</strong> also distribute it: Linux distributions, third-party
package managers, and corporations seeking to deploy their own controlled builds. These others have
slightly different needs and setups and, to varying degrees, will:</p>

<ul>
  <li>Build your project with slightly (or completely) different versions of dependencies</li>
  <li>Build your project with slightly (or completely) different optimization flags and other potentially
ABI-breaking options</li>
  <li>Distribute your project with insecure or outright broken defaults</li>
  <li>Disable important security features because other parts of their ecosystem haven’t caught up</li>
  <li>Patch your project or its build to make it “work” (read: compile and not crash immediately) with
completely new dependencies, compilers, toolchains, architectures, and environmental constraints</li>
</ul>

<p>You don’t know about <em>any</em> of the above until the bug reports start rolling in: users will report
bugs that have already been fixed, bugs that you explicitly document as caused by unsupported
configurations, bugs that <em>don’t make any sense whatsoever</em>.</p>

<p>You struggle to debug your users’ reports, since you don’t have access to the niche
hardware, environments, or corporate systems that they’re running on. You slowly burn out
as an unending torrent of already fixed bugs that never seem to make it to your users. Your
user base is unhappy, and you start to wonder why you’re putting all this effort into
project maintenance in the first place. Open source was supposed to be fun!</p>

<p>What’s the point of this spiel? It’s <em>precisely</em> what happened to <code>pyca/cryptography</code>:
nobody asked them whether it was a good idea to try to run their code on
<a href="https://en.wikipedia.org/wiki/PA-RISC">HPPA</a>, much less
<a href="https://en.wikipedia.org/wiki/IBM_System/390">System/390</a><sup id="fnref:s390" role="doc-noteref"><a href="#fn:s390">6</a></sup>; some packagers just went ahead
and did it, and are frustrated that it no longer works. People just <em>assumed</em> that it
would, because there is <em>still</em> a norm that everything flows from C, and that any
host with a halfway-functional C compiler should have the entire open source ecosystem
at its disposal.</p>

<h3 id="reflections-on-trusting-random-platforms">Reflections on trusting random platforms<sup id="fnref:rott" role="doc-noteref"><a href="#fn:rott">7</a></sup></h3>

<p>Security-sensitive software<sup id="fnref:security" role="doc-noteref"><a href="#fn:security">8</a></sup><sup>,</sup><sup id="fnref:reliability" role="doc-noteref"><a href="#fn:reliability">9</a></sup>, <em>particularly</em> software written
in unsafe languages, is <strong>never</strong> secure in its own right.</p>

<p>The security of a program is a function of its own design and testing,
<em>as well as</em> the design, testing, and basic correctness of its underlying platform: everything from
the userspace, to the kernel, to the compilers themselves. The latter
is an <strong>unsolved problem</strong> in the <em>very best of cases</em>: bugs are <em>regularly</em>
found in even the most mature compilers (Clang, GCC) and their most mature backends (x86, ARM). Tiny
changes to or differences in build systems can have profound effects at the binary level, like
<a href="https://insights.sei.cmu.edu/cert/2018/08/when-aslr-is-not-really-aslr---the-case-of-incorrect-assumptions-and-bad-defaults.html">accidentally removing security mitigations</a>.
Seemingly innocuous patches can make otherwise safe code
<a href="https://wiki.gentoo.org/wiki/Hardened/GNU_stack_quickstart">exploitable</a> in the context of
other vulnerabilities.</p>

<p>The problem gets worse as we move towards niche architectures and targets that are used
primarily by small hobbyist communities.
Consider <a href="https://en.wikipedia.org/wiki/Motorola_68000_series">m68k</a>
(one of the other architectures affected by <code>pyca/cryptography</code>’s move to Rust): even
GCC <a href="https://gcc.gnu.org/legacy-ml/gcc-patches/2019-10/msg02044.html">was considering</a> removing
support due to lack of maintenance, until hobbyists stepped in. That isn’t to say that any
<em>particular</em> niche target is full of bugs<sup id="fnref:although" role="doc-noteref"><a href="#fn:although">10</a></sup>; only to say that it’s a greater likelihood
for niche targets <em>in general</em>. <strong>Nobody</strong> is regularly testing the mountain of userspace
code that implicitly forms an operating contract with arbitrary programs on these platforms.</p>

<p>Project maintainers don’t want to chase down compiler bugs on ISAs or systems that they never
intended to support in the first place, and aren’t receiving any active support feedback about.
They <em>especially</em> don’t want to have vulnerabilities associated
with their projects because of buggy toolchains <em>or</em> tooling inertia when working on security
improvements.</p>

<h3 id="some-more-finger-pointing">Some more finger-pointing</h3>

<p>As someone who <em>likes</em> C: this is all C’s fault. Really.</p>

<p>Beyond language-level unsafety (plenty of people have
<a href="https://fishinabarrel.github.io/">covered that already</a>), C is <em>organizationally</em> unsafe:</p>

<ul>
  <li>
    <p>There’s no standard way to write tests for C.</p>

    <p>Functional and/or unit tests <em>alone</em> would go a long
way in assuring baseline correctness on weird architectures or platforms, but the cognitive
overhead of testing C <em>and</em> getting those tests running ensures that well-tested builds of C
programs will continue to be the exception, rather than the rule.</p>
  </li>
  <li>
    <p>There’s no standard way to build C programs.</p>

    <p><a href="https://blog.yossarian.net/2019/04/23/Make-is-probably-fine">Make is fine</a>, but it’s not standard.
Disturbingly large swathes of critical open source infrastructure are compiled using a hodgepodge
of Make, autogenerated rules from autotools, and the maintainer’s boutique shell scripts. One
consequence of this is that C builds tend to be flexible <em>to a fault</em>: prospective packagers
can inject all sorts of behavior-modifying flags that may not be attested directly
in the compiled binary or other build products. The result: it’s almost impossible to prove that
two separate builds on different machines are the same, which means more maintainer pain.</p>
  </li>
  <li>
    <p>There’s no standard way to distribute C programs.</p>

    <p>Yes, I know that package managers exist. Yes, I know how to statically link. Yes, I know how to
vendor libraries and distribute self-contained program “bundles”. None of these are or amount to
a <em>complete</em> standard, and each introduces additional logistical or security problems.</p>
  </li>
  <li>
    <p>There’s no such thing as truly cross-platform C.</p>

    <p>The C abstract machine, despite looking a lot like a PDP-11, leaks the underlying memory
and ordering semantics of the architecture being targeted. The result is that even seasoned
C programmers regularly rely on architecture-specific assumptions when writing ostensibly
cross-platform code: assumptions about the atomicity of reads and writes, operation ordering,
coherence and visibility in self-modifying code, the safety and performance of unaligned accesses,
and so forth. Each of these, apart from being a potential source of unsafety, are <strong>impossible
to detect</strong> statically in the general case: they are, after all, perfectly correct
(and frequently intended!) on the programmer’s host architecture.</p>
  </li>
</ul>

<p>By contemporary programming language standards, these are conspicuous gaps in functionality:
we’ve long since learned to bake testing, building, distribution, and sound abstract machine
semantics into the standard tooling for languages (and language design itself). But their absence
is <strong>doubly pernicious</strong>: they ensure that C remains a perpetually
unsafe development ecosystem, <em>and</em> an appealing target when bootstrapping a new platform.</p>

<h2 id="the-life-of-a-package-maintainer-is-hard">The life of a package maintainer is hard</h2>

<p>The project maintainer isn’t the only person hurting in the status quo.</p>

<p>Everything stated above <em>also</em> leads to a bum job for the lowly package maintainer<sup id="fnref:yt" role="doc-noteref"><a href="#fn:yt">11</a></sup>. They’re
(probably) also an unpaid open source hobbyist, and they’re operating with constraints that
the upstream isn’t likely to immediately understand:</p>

<ul>
  <li>The need to link against versions of dependencies that have already been packaged (and perhaps patched)</li>
  <li>ABI and ISA subset constraints, stemming from a need to distribute binaries that function with
relatively old versions of <code>glibc</code> or x86-64 CPUs without modern extensions</li>
  <li>Limited visibility into each project’s test suite and how to run it, much less what to do when
it fails</li>
</ul>

<p>They <em>also</em> have to deal with users who are unsympathetic to those reports, and who:</p>

<ul>
  <li>Rarely submit reports to the packager (they bug the project directly instead!), or …</li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with">https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2021/02/28/Weird-architectures-werent-supported-to-begin-with</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294397</guid>
            <pubDate>Sun, 28 Feb 2021 16:22:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging K8s services: 3 tools for 3 scenarios]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26294015">thread link</a>) | @erkanerol
<br/>
February 28, 2021 | https://erkanerol.github.io/post/debugging-k8s-services/ | <a href="https://web.archive.org/web/*/https://erkanerol.github.io/post/debugging-k8s-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>Feb 28, 2021 · <a href="https://erkanerol.github.io/post/debugging-k8s-services/#disqus_thread">Comments</a><br><a href="https://erkanerol.github.io/categories/software">Software</a><a href="https://erkanerol.github.io/categories/k8s">k8s</a><a href="https://erkanerol.github.io/categories/en">EN</a></span></p><p>While developing/debugging applications that serve services on k8s in production, you need some tools/commands. This blog post explains three different scenarios+tools for you.</p><blockquote><p>Please ping me if there is something wrong. <a href="https://twitter.com/erkan_erol_">https://twitter.com/erkan_erol_</a></p></blockquote><h2 id="setup">Setup</h2><p>Here is our basic setup to explain the scenarios.</p><p><img src="https://erkanerol.github.io/img/k8s-services/Setup.png" title="Setup"></p><p>We have 3 services. <code>service-front</code> is exposed to the public via an ingress. <code>service-front</code> depends on <code>service-middle</code> and <code>service-middle</code> depends on <code>service-back</code>. The communications are done through k8s services.</p><p>To install this setup, here are the necessary commands:</p><pre><code>kubectl create ns service-debug
kubectl -n service-debug run service-back --image=erkanerol/service-back:v1 --port=8080 --expose=true --labels="app=back"
kubectl -n service-debug run service-middle --image=erkanerol/service-middle:v1 --port=8081 --expose=true --labels="app=middle"
kubectl -n service-debug run service-front --image=erkanerol/service-front:v1 --port=8082 --expose=true --labels="app=front"
</code></pre><p>Here is the source code of these services: <a href="https://github.com/erkanerol/service-examples-for-blog">https://github.com/erkanerol/service-examples-for-blog</a></p><h4 id="scenario">Scenario:</h4><p>As a developer, I want to send some requests to <code>service-back</code> directly and see the result without touching the other services.</p><h4 id="problem">Problem:</h4><p><code>service-back</code> is not exposed to the public and you cannot send requests to it directly.</p><h4 id="solution">Solution:</h4><p>With <code>kubectl port-forward</code>, it is possible to open a tunnel from your local machine to the <code>service-back</code> in the cluster. See <a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward">https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#port-forward</a></p><h4 id="steps">Steps:</h4><p>Run the command below in a terminal.</p><pre><code>$ kubectl -n service-debug port-forward service/service-back 8080:8080
Forwarding from 127.0.0.1:8080 -&gt; 8080
Forwarding from [::1]:8080 -&gt; 8080
</code></pre><p><br>Then run the curl command below in another terminal to see that you are able to access <code>service-back</code></p><pre><code>$ curl localhost:8080
Timestamp from back:1614508193
</code></pre><h4 id="how-does-it-work">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level1.png" title="Level1"></p><p><code>kubectl</code> starts a process which binds <code>localhost:8080</code>. It listens that port and establishes a connection to api-server, which forwards the requests to <code>service-back</code>.</p><h4 id="scenario-1">Scenario:</h4><p>As a developer, I want to run <code>service-front</code> in my local machine so that I can put breakpoints in my IDE to debug my application.</p><h4 id="problem-1">Problem:</h4><p><code>service-front</code> is designed to run in Kubernetes and it accesses <code>service-middle</code> via the k8s service. The service name is hardcoded or hard to be configurable or you are too lazy to mock the dependencies in your local machine.</p><h4 id="solution-1">Solution:</h4><p><code>kubefwd</code> is a useful tool for this problem. It does bulk port-forwarding and manages dns entries in your local machine. See <a href="https://github.com/txn2/kubefwd">https://github.com/txn2/kubefwd</a></p><h4 id="steps-1">Steps:</h4><p>Run the command below in a terminal</p><pre><code>$ sudo KUBECONFIG=$KUBECONFIG kubefwd svc -n service-debug -l app=middle
</code></pre><blockquote><p>Note that <code>kubefwd</code> requires root privileges and it has to be run with <code>sudo</code>. Set <code>KUBECONFIG</code> variable without any home folder reference beforehand.</p></blockquote><p>In another terminal, run <code>front</code> application in your local machine. Note that you can run it in debug mode as well and put breakpoints.</p><pre><code>$ cd /tmp
$ git clone https://github.com/erkanerol/service-examples-for-blog.git
$ cd service-examples-for-blog/front
$ go run main.go
</code></pre><p>In another terminal, Send a request to <code>front</code> app to see that your front app serves locally and it accesses <code>service-middle</code> in the cluster.</p><pre><code>$ curl localhost:8082
Response from service middle:'Response from service back:'Timestamp from back:1614513901''
</code></pre><h4 id="how-does-it-work-1">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level2.png" title="Level2"></p><p>As you can see from the logs of <code>kubefwd</code></p><pre><code>...
INFO[14:07:38] 'cat /etc/hosts' to see all host entries.    
INFO[14:07:38] Loaded hosts file /etc/hosts                 
INFO[14:07:38] HostFile management: Original hosts backup already exists at /root/hosts.original 
...
INFO[14:07:38] Port-Forward: 127.1.27.1 service-middle:8081 to pod service-middle:8081 
...
</code></pre><p>It starts a process that binds <code>127.1.27.1:8081</code> and manipulates the <code>/etc/hosts</code> for <code>service-middle</code></p><pre><code>$ cat /etc/hosts |grep service-middle
127.1.27.1       service-middle.default service-middle.default.svc service-middle.default.svc.cluster.local service-middle.default.minikube service-middle.default.svc.minikube service-middle.default.svc.cluster.minikube service-middle service-middle.service-debug service-middle.service-debug.svc service-middle.service-debug.svc.cluster.local service-middle.service-debug.minikube service-middle.service-debug.svc.minikube service-middle.service-debug.svc.cluster.minikube
</code></pre><div><p>Then your local <code>front</code> app can access the <code>service-middle</code> like in k8s cluster without any extra effort.</p></div><h4 id="scenario-2">Scenario:</h4><p>As a developer, I want to run <code>service-middle</code> in my local machine so that I can put breakpoints in my IDE to debug my application.</p><h4 id="problem-2">Problem:</h4><p><code>service-middle</code> is designed to run in Kubernetes. It accesses <code>service-back</code> via k8s services. Also, its consumer <code>service-front</code> is running on k8s. The services are not available in your local machine and it is hard to mock all these environments in your local machine.</p><h4 id="solution-2">Solution:</h4><p><code>telepresence</code> is a useful tool for this problem. See <a href="https://www.telepresence.io/">https://www.telepresence.io/</a></p><h4 id="steps-2">Steps:</h4><p>Delete <code>service-middle</code> from your k8s cluster at first. We will run it locally.</p><pre><code>kubectl -n service-debug delete service service-middle --ignore-not-found=true
kubectl -n service-debug delete pod service-middle --ignore-not-found=true
</code></pre><p><br>Run telepresence for <code>service-middle</code></p><pre><code>telepresence --namespace service-debug --new-deployment service-middle --expose 8081
</code></pre><p><br>In another terminal, run <code>middle</code> application in your local machine. Note that you can run it in debug mode as well and put breakpoints.</p><pre><code>$ cd /tmp
$ git clone https://github.com/erkanerol/service-examples-for-blog.git
$ cd service-examples-for-blog/middle
$ go run main.go
</code></pre><p><br>In another terminal, run the command below to send a request to <code>service-front</code> via a temporary pod in the cluster.</p><pre><code>$ kubectl -n service-debug run curl -it  --rm=true --image=curlimages/curl --restart=Never -- http://service-front:8082 
Response from service middle:'Response from service back:'Timestamp from back:1614517363''pod "curl" deleted
</code></pre><p>Note that your request goes to <code>service-front</code> in k8s, which sends a request to <code>service-middle</code> in your local machine, which sends a request to <code>service-back</code> in the cluster.</p><h4 id="how-does-it-work-2">How does it work?</h4><p><img src="https://erkanerol.github.io/img/k8s-services/Level3.png" title="Level3"></p><p>Basically, <code>telepresence</code> deploys a proxy/fake agent into cluster and opens a two-way tunnel between your local environment and the cluster via that agent. Then you are able to run the <code>middle</code> service in your local machine without adapting the consumers/dependent services.</p><p>A detailed explanation about how telepresence works is available here: <a href="https://www.telepresence.io/discussion/how-it-works">https://www.telepresence.io/discussion/how-it-works</a></p><h2 id="summary">Summary</h2><ul><li>If you need to access a service without exposing it to public, <code>kubectl port-forward</code> is enough.</li><li>If you need to run a service locally for debugging and your service needs to access other services on k8s, <code>kubefwd</code> is enough. It manages DNS entries in your local machine and opens a one-way tunnel from your machine to cluster for the dependencies of your service.</li><li>If you need to run a service locally for debugging and your application has some consumers in the cluster, <code>telepresence</code> is your tool. It opens two-way network channel and it forwards requests from cluster to your local instance as well.</li></ul><p>p.s. Admission webhooks in Kubernetes are similar to <code>service-middle</code>. They receive some requests from api-server and they may send some requests to other services in the cluster. Therefore, <code>telepresence</code> is a useful tool for debugging admission webhooks. In the next blog post, I am going to explain how to debug validating webhooks.</p></div></div></div>]]>
            </description>
            <link>https://erkanerol.github.io/post/debugging-k8s-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26294015</guid>
            <pubDate>Sun, 28 Feb 2021 15:28:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Developers Still Want Swag?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26293564">thread link</a>) | @domrdy
<br/>
February 28, 2021 | https://codesubmit.io/blog/do-developers-want-swag/ | <a href="https://web.archive.org/web/*/https://codesubmit.io/blog/do-developers-want-swag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <section>
                
                <div>
                    <p>Over the years, company merchandise or, as the cool kids call them, swag (which stands for “stuff we all get”), especially from tech companies, has become something of a talking point and even a status symbol in some circles. </p><p>For some, it’s a status symbol to signal to others that you’re old school, you were around before <em>it all began</em>. As one <a href="https://qr.ae/pNjt1g">Quora user</a> pointed out, “what you really want is the swag from companies that looked impressive, but then died... You want that Enron keychain. You want the stuff that says, <em>I was there. I'm still here. They're not.</em> It makes a statement. ” </p><p>For others, it’s not about getting yet another Google water bottle or Facebook T-shirt. It’s about getting really useful stuff that’s durable, exclusive and memorable. That could be a <a href="https://qr.ae/pNjttJ">messenger bag from Quora</a>, a <a href="https://www.kapwing.com/blog/what-happened-when-we-asked-200-companies-for-free-swag/">Tile from Airtable</a>, or <a href="https://www.kapwing.com/blog/what-happened-when-we-asked-200-companies-for-free-swag/">an apron from Airbnb</a>. </p><p>According to <a href="https://swapnil.net/">Swapnil Agarwal</a>, the developer behind <a href="https://devswag.io/">DevSwag</a>, a site that curates opportunities for developers to collect swag, developers love swag because it helps them find their community. </p><blockquote><em>“For some developers, scoring swag feels like a badge of honor, achievement unlocked! They are more than happy to don a tee with a geeky quote or put a sticker on their laptop. This helps them project their preferences and find their tribe easily.” </em></blockquote><h3 id="why-do-companies-bother-with-swag"><strong>Why do companies bother with swag? </strong></h3><p>Companies invest in swag for various reasons. The most obvious one is to create hype and buzz around your brand. Did you know that one of the <a href="https://brightideaspromotional.co.uk/info/the-history-of-the-promotional-merchandise-industry/">earliest forms of swag</a> were the commemorative buttons produced to celebrate George Washington becoming the first President of the newly formed United States of America in 1789? It was 100 years later when two printers in Ohio, Jasper Meek and Henry Beach, realized that they could print advertisements on school bags, card cases and even horse hats, that the swag industry really began. </p><p>Since then, companies have been using swag to promote their brand, products and services. Think about those Slack socks, and <a href="https://twitter.com/tferriss/status/320447454657003520?lang=en">Tim Ferriss’ favorite Duolingo shirt</a>. The exposure those companies got from their swag, and still do to this day, is an investment that has definitely paid off. </p><p>Swag is also a good way to market to your own employees or show them your appreciation. It is also a great <a href="https://qz.com/work/1860082/employee-swag-is-a-remote-worker-culture-builder/">physical representation of a company's culture</a>. With the pandemic keeping people at home and employees working remotely, company swag offers that little bit of “connectedness” that we used to get from conversations around the coffee machine. &nbsp;</p><p>Companies are also using swag to incentivize people to contribute or engage with a brand or products. “Let's say (a company) wants to get beta users for a dev tool. It's far easier to get them with swag giveaways rather than traditional advertising,” says Swapnil.</p><p>Launched in 2018, <a href="https://devswag.io/">DevSwag</a> curates different opportunities available for developers to collect swag, and ranks the task difficulty for each opportunity. Tasks and rewards range from leaving a review for a podcast in exchange for stickers, to fixing a bug in exchange for a pair of socks. </p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/swapnil-agarwal-devswag-1.png"></figure><h3 id="who-s-giving-out-swag"><strong>Who’s giving out swag? </strong></h3><p>The <a href="https://www.prnewswire.com/news-releases/asi-reports-2019-promo-sales-hit-high-of-25-8-billion-301010174.html">Advertising Speciality Institute</a> (ASI) reported that sales for company merchandise rose by 4.7% compared to 2018, &nbsp;reaching a record high of USD 25.8 billion in 2019. </p><p>At the height of the promotional products industry, the team at <a href="https://www.kapwing.com/blog/what-happened-when-we-asked-200-companies-for-free-swag/">Kapwing</a> noticed that companies seemed to be giving out swag liberally and wanted to test out how common this was. So, they posed as college seniors “fan mailing” 201 companies asking if they could get some swag. </p><figure><img src="https://lh5.googleusercontent.com/rGPMgvcTt4KKhIrcgICRVaaLcLqUBPx6ZDykvj2O426dHotfPZDHP7FBx9dMPLAI9YNP2DzBdetRrZsT6vnX3B2k0_nJ_mTpcKNCUzyfGNX7RxO50JckzK013wyzXDFZT74STRby"><figcaption>Source: Kapwing</figcaption></figure><p>Out of 201 companies, they successfully contacted 188 of them. They eventually received a response from 146 companies. Of those, they noted that B2C companies were more likely to respond than B2B companies, and B2C companies were more likely to offer swag than B2B companies. </p><p>Interestingly, tech or SaaS companies were the least likely to respond compared to other business types like apparel, beverage, and consumer goods. Their response rate was at 64% compared to other business types (82% to 87%). They also found that small to medium sized companies were more likely to give out company swag; these are companies with 11 to 49 employees, or companies with 50 to 249 employees respectively. </p><h3 id="is-swag-losing-its-swag"><strong>Is swag losing its <em>swag</em>?</strong> </h3><p>In 2019, <a href="https://www.theguardian.com/fashion/2019/apr/03/patagonia-fleece-vest-tech-bro-uniform">Patagonia</a> decided to shift its sales program to only work with companies that meet certain social and environmental standards, or in their words “mission-driven companies that prioritize the planet”. &nbsp;The company now requires more information about the type of company “whose name will appear on the Patagonia product and how the product will be used. We reserve the right to refuse service.”</p><p>Just as companies are becoming more conscious about what their brands stand for, their swag, their suppliers and swag recipients are becoming increasingly integrated into the brand’s narrative. The public’s perception of a brand, especially those of global powerhouses like Google, Facebook, Netflix, and Amazon, largely impact the swaggi-ness of a brand’s swag. </p><p>In January 2021, in light of Facebook banning former US President Donald Trump on social media, Facebook’s internal security team released a memo warning employees not to wear or carry Facebook-branded swag in public. As reported by <a href="https://gizmodo.com/facebook-warns-employees-not-to-wear-company-gear-in-pu-1846040220">Gizmodo</a>, “while the memo doesn’t appear to explicitly say Facebook employees are at risk of physical assault by Trump supporters, it’s easy to read between the lines”.</p><p>Public perception and public events also play a large role in the perceived swaggi-ness of a company. Just a week after Facebook’s memo, <a href="https://www.businessinsider.com/goldman-sachs-rebrands-storm-hill-event-capitol-violence-washington-dc-2021-1">Goldman Sachs</a>, had to quickly rebrand a virtual event they had organized to lobby Congress to help small businesses across America. The event that was originally called “Storm the Hill” definitely did not sit well with both organizers nor participants after what happened in Washington DC, and participants were urged not to wear the branded t-shirts that were mailed out to them prior.</p><p>Another factor that keeps swag cool and swaggy is its exclusivity. Slack’s socks, once exclusive, have now made their way to <a href="https://slack.shop/">Slack.shop</a>. Slack fans can now buy a pack of six pairs of socks for €49.80 along with a Slack t-shirt and a baby onesie. </p><figure><img src="https://codesubmit.io/blog/content/images/2021/02/slack-socks-1.png"><figcaption>The exclusivity of Slack's socks are gone, but fans and aspiring employees can <em>almost</em> live the dream by purchasing them online.</figcaption></figure><h3 id="the-environmental-impact-of-swag"><strong>The environmental impact of swag</strong></h3><p>At the end of 2019, the Meeting, Incentives, Conferences and Events (MICE) industry was <a href="https://www.cwt-meetings-events.com/futuretrends/page/3/1">expected to grow by USD 840 billion (8%) in 2020</a> with 52% more event websites popping up compared to 2019. CWT Meetings and Events reported that companies were spending 25% to 30% of their overall marketing budgets on live events. </p><p>It is common for people to attend these conferences and collect as many tote bags, t-shirts, water bottles, usb sticks, pens, stress balls, stickers, notebooks, hats, rubber wrist bands, beer bottle openers, and everything else that can be made cheaply and quickly, with a company’s logo slapped on for swagginess. </p><p>As <a href="https://www.fastcompany.com/90260185/its-time-to-stop-spending-billions-on-cheap-conference-swag">Elizabeth Segran</a> wrote, many of these companies’ merchandise aren’t well made or well designed, meaning that we’re likely to throw them out after just a handful of uses. </p><blockquote><em>“When you think about all the energy and resources that go into making just one of the tote bags that I have just thrown into the trash–only to end up in a landfill–the impact is staggering.”</em></blockquote><p>A quick Google search will show you that companies often compete over costs, but low costs comes at a high price for workers in countries like China, where most of these promotional products are made. By now, we’re aware of <a href="https://www.globalsources.com/NEWS/SIC-making-it-in-china-the-factory-workers-that-make-your-products.HTM">poor working conditions</a>, lack of safety standards, and very low wages. </p><p>This is why companies like Google have a vetted list of merchandise suppliers they work with—companies that sustainably source their materials and do not violate labour laws, meaning without child labour or inhumane working conditions. This could be the way forward for other companies who want to invest in company merchandise. </p><p>For Segran, the answer to both creating hype while reducing swag’s impact on the environment is to get rid of it entirely. As an alternative, she writes, “consider offering experiences. For instance, I’d appreciate a back massage at a conference, or perhaps a yoga class, or a free headshot. I’d even enjoy a good meal instead of a swag bag.” </p><p>She continues, “if you wrap the event in your branding, there’s a good chance your target customer will remember that experience long after the tote bag is stuffed in a landfill somewhere.”</p><h3 id="to-swag-or-not-to-swag"><strong>To swag or not to swag?</strong></h3><p>A quick browse of some HR groups on Facebook and LinkedIn uncover conversations where HR professionals are debating whether to give out company merchandise to employees over the recent year-end holidays, or if they should opt for gift cards as they’re a more “practical” way to support employees in this economic climate. Many rallied behind gift cards, especially the ever-versatile Visa gift cards, accepted nearly everywhere in the United States.</p><p>But if we’re real here, a multi-billion dollar industry is not going to disappear overnight or any time in the near future. In fact, ASI reported that while total swag sales dropped by 44% in Q2 2020, it had recovered about 20% of sales in Q3 2020 and a further 8% in Q4 2020. Total product sales for 2020 was USD 20.7 billion. </p><p>With the world going remote and people working from home, what swag did we spend all that money on? In 2020, it comes as no surprise that products like hand sanitizers contributed USD 1.4 billion in sales (7%), while other pandemic-related swag like branded cloth masks and other PPE made up USD 4.6 billion in sales (22%). </p><p>I believe that companies are becoming more intentional with the swag they give out. <a href="https://blog.duolingo.com/thinking-outside-the-box-engaging-our-team-with-interactive-care-packages/">Duolingo</a>, for example, worked with <a href="https://www.swagup.com/">SwagUp</a> to create monthly “Interactive Care Packages” for employees during the pandemic to break up the monotony of staying at home. The care packages were designed to …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codesubmit.io/blog/do-developers-want-swag/">https://codesubmit.io/blog/do-developers-want-swag/</a></em></p>]]>
            </description>
            <link>https://codesubmit.io/blog/do-developers-want-swag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293564</guid>
            <pubDate>Sun, 28 Feb 2021 14:19:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Email Cleaner: Clean tracking links and pixels from email newsletters]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26293424">thread link</a>) | @bengtan
<br/>
February 28, 2021 | https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/ | <a href="https://web.archive.org/web/*/https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<div>
  <article>
    

    

    
    
    <h2>Overview</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#what-is-it">What is it?</a></li>
    <li><a href="#email-cleaner">Email Cleaner</a></li>
    <li><a href="#getting-started">Getting started</a>
      <ul>
        <li><a href="#forwarding-loops">Forwarding loops</a></li>
      </ul>
    </li>
    <li><a href="#how-it-works">How it works</a></li>
    <li><a href="#benefits">Benefits</a></li>
    <li><a href="#plain-text-emails">Plain text emails</a></li>
    <li><a href="#caveats">Caveats</a></li>
    <li><a href="#privacy">Privacy</a></li>
    <li><a href="#feedback">Feedback</a></li>
  </ul>
</nav>
    <p>I’m supposed to be blogging instead of doing <a href="https://bengtan.com/blog/app-startup-vs-content-startup/">“app startup”</a> things but I got sidetracked and built another side project (again).</p>
<p>I’ve been getting into email newsletters. Over the last month, I’ve gone from zero newsletters to eleven of them. My inbox is now overflowing with newsletters. Maybe I’ll have to cut back but that’s a story for another time.</p>
<p>I have a new pet hate: Links in email newsletters.</p>
<p>They are user-hostile. Substack is the worst. Their URLs look like this:</p>
<p><a href="http://email.substack.com/c/ejXDKM2OhCAMgJ9muI3hT3QOHPayr2EKVIesgwbquL794njbhEIhNP36eSCclnzYdSnEzm2gY0WbcC8zEmFmW8E8xGBlb1pljGTBdsJpLVksw5gRXxBnS3lDtm5ujh4oLulTIVvJnjbgCKC51hxawbuuxzCCcwHAo0CprrawhYjJo8U35mNJyGb7JFrLTX3d5Hdd-743CWjL2PjlVR8gU_qZLpoGLdre3LkUd87Vw9wrnZX1ymUN3XbtoxENjIYbFKBVq3wrxlF47oLolZNKonrcNC-bKwT-RzT4u1aKRBHmd8S99mTZOkwTQRL153TOfZKcYw_1fG0p0jFgAjdjuIzQJfbjaJgwYa7CwwBkhRGq75Xu-4fpLgVVmZKdFNUzqxxhqVXJ_uP4AyNKkNQ">http://email.substack.com/c/ejXDKM2OhCAMgJ9muI3hT3QOHPayr2EKVIesgwbquL794njbhEIhNP36eSCclnzYdSnEzm2gY0WbcC8zEmFmW8E8xGBlb1pljGTBdsJpLVksw5gRXxBnS3lDtm5ujh4oLulTIVvJnjbgCKC51hxawbuuxzCCcwHAo0CprrawhYjJo8U35mNJyGb7JFrLTX3d5Hdd-743CWjL2PjlVR8gU_qZLpoGLdre3LkUd87Vw9wrnZX1ymUN3XbtoxENjIYbFKBVq3wrxlF47oLolZNKonrcNC-bKwT-RzT4u1aKRBHmd8S99mTZOkwTQRL153TOfZKcYw_1fG0p0jFgAjdjuIzQJfbjaJgwYa7CwwBkhRGq75Xu-4fpLgVVmZKdFNUzqxxhqVXJ_uP4AyNKkNQ</a></p>
<p>What is that, Substack?! Is that really a URL with 400+ characters?!</p>
<p>I have an ingrained habit of hovering over links. This allows me to see where it links to and decide whether to click on it.</p>
<p>It’s a good habit.</p>
<p>It’s also a security “best practice”. Hovering over a link helps to check whether it’s a phishing link.</p>
<p>Email newsletters have broken this. I have no idea where these user-hostile links go. For their own self interest, mailing list service providers have denied me a basic tenet of the web: Knowing what I’m clicking on before I click.</p>
<p>It’s also demeans the newsletter. A newsletter which purports to send me a ‘list of interesting links’ is just sending me a list of crap because I’m not clicking on those I-have-no-idea-where-it’s-going links.</p>
<p>If the link was something like <a href="http://www.google.com/url?sa=t&amp;url=https://www.wikipedia.org/&amp;usg=AOvVaw3ay7vaEtH0yTTYdDmrvinX">http://www.google.com/url?sa=t&amp;url=https://www.wikipedia.org/&amp;usg=AOvVaw3ay7vaEtH0yTTYdDmrvinX</a> I wouldn’t be as peeved because I can see where it links to.</p>
<p>But no, I don’t think they’ll compromise.</p>
<p>Not happy.</p>
<p>I set about trying to make the situation palatable. I asked <a href="https://news.ycombinator.com/item?id=26188976">here</a>, <a href="https://www.reddit.com/r/SomebodyMakeThis/comments/ln4dep/smt_hover_over_links_in_email_newsletters_and_see/">here</a>, and <a href="https://www.indiehackers.com/post/17a17962db">here</a> but I didn’t find anything satisfactory.</p>
<p>So I built my own solution.</p>
<h2 id="what-is-it">What is it?</h2>
<p>I hooked a script up to an email address. Upon receiving an email, the script will replace tracking links with their destination URL, remove tracking pixels, and send it back to the sender.</p>
<p>Then, I set up a gmail filter to forward my newsletters to the script.</p>
<p>Yay!</p>
<p>Now, when I receive an email newsletter, gmail forwards it to the script. The script sends it back to me with nice clean URLs. Once again, I can see where links lead to before I decide whether to click.</p>
<p>Tracking parameters (ie. <code>utm_*</code>) and tracking pixels are removed as well. (I don’t care strongly about this but it was easy to add so I did.)</p>
<h2 id="email-cleaner">Email Cleaner</h2>
<p>For lack of a better name, I’m calling it <strong>Email Cleaner</strong>. <strong>It cleans crap from email newsletters</strong>.</p>
<p>(Alternatively, I considered calling it ‘<strong>UntrackMe: Remove tracking from email newsletters</strong>’. Which sounds better?)</p>
<p>I’m letting others try it. Maybe other people find it useful too. If there’s enough interest, I’ll turn it into a proper side project.</p>
<h2 id="getting-started">Getting started</h2>
<p>To try Email Cleaner, forward an email newsletter to <code>email-cleaner@bengtan.com</code>.</p>
<p>In a minute or two, you should get the newsletter sent back to you (from <code>no-reply@bengtan.com</code>) with cleaned links and tracking pixels removed.</p>
<p>If you decide you like it, you can set up your email program to automatically forward email newsletters to <code>email-cleaner@bengtan.com</code>.</p>
<p>How you do this depends on your email program so you’ll have to work it out youself.</p>
<p>Note: Please don’t set up your email program to automatically delete after forwarding. Since this is a new service, it’s a good idea to retain the original emails in case something goes wrong.</p>
<h3 id="forwarding-loops">Forwarding loops</h3>
<p>If your automatic forwarding configuration mistakenly forwards the cleaned email (from Email Cleaner) back to Email Cleaner, it will detect this and send you an email with the message “Infinite loop detected”. If you get such an email, please adjust your forwarding configuration so you don’t forward cleaned emails to Email Cleaner.</p>
<p>If you use gmail (like I do), this can be accomplished by adding the condition <code>-subject:[email-cleaner]</code> to your forwarding filter.</p>
<h2 id="how-it-works">How it works</h2>
<p>Email Cleaner works as follows:</p>
<ul>
<li>It scans the email for links which match the following regular expressions:</li>
</ul>
<div><pre><code data-lang="js">	<span>'\.list-manage\.com/track/click'</span>,
	<span>'//click\.convertkit-mail\.com/'</span>,
	<span>'//email\.substack.*/c/'</span>,
	<span>'//apple\.co/'</span>,
	<span>'//t\.co/'</span>,
</code></pre></div><ul>
<li>If a link matches, then it’s a tracking link. Email Cleaner crawls the link to see if it’s a 3xx redirect. If it is, then the link is replaced by the destination URL.
<ul>
<li>Any URL query parameters which are <code>mc_cid</code>, <code>mc_eid</code>, or start with <code>utm_</code> are also removed.</li>
</ul>
</li>
<li>Then, Email Cleaner scans the email for tracking pixels. If any are found, it removes them.</li>
<li>Finally, the email is sent back to the sender.</li>
</ul>
<p>Email Cleaner is quite safe and conservative. It will only crawl links which are obviously tracking links.</p>
<p>Email Cleaner currently handles three major mailing list service providers (MailChimp, ConvertKit, Substack). I’d happily add more. Just let me know.</p>
<p>Note that Email Cleaner doesn’t magically bypass the tracking links. Instead, it triggers all of them from a data centre somewhere. It’s privacy-by-obfuscation instead of privacy-by-abstention. But it does prevent your web browser/IP address/location from being leaked.</p>
<h2 id="benefits">Benefits</h2>
<ul>
<li>Email newsletters are more user friendly. (I’m more inclined to click on a link if I see it’s a reputable website.)</li>
<li>Helps detect phishing attacks.</li>
<li>Better user privacy.</li>
<li>Plain text emails are readable again.</li>
</ul>
<h2 id="plain-text-emails">Plain text emails</h2>
<p>The last benefit was an unexpected side effect.</p>
<p>Whilst writing Email Cleaner, I discovered that plain text versions of email newsletters are completely unreadable.</p>
<p>They look something like this:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [httр://email.substack.com/c/eJxdkc-OgyAQh5-m3Grkr3rgsJd9DQM4WlIFA2O7vv1O2-xlE2CSHzPhy0dwCEsup91zRfY6Rjx3sAmegAiF7BsUE71mvZJcKUa87qgTgpG4mVAAXjYuGssOZN3dEkeLMafPBpOMzFp1wluppHM9Z2FoQQQbnAqd8tx2A7_P2t1HSCNoeEM5cwKy6Blx3R7868F-qkFqjviMK_hom1ym2rrqmr5twVfecTZHLs9tziuJmrWMtqy6kJ0cGtrYoFoF1Aou-ShpCHRsnac9d4wz4MNDtNvuNrTjkzbwu1YNCaNd3hGOZsykaAdpQptonZyur2v3dT1tan7tKeJpIFm3gL954I31Q8hMkKBU3N5Y1FRR3vdc9P2guhtABcZZx2ilTKoOn-tW0v90_AEVdJLl]. At a conference five years earlier [httр://email.substack.com/c/eJxdkEtuhDAMhk8zWSLyBBZZVKp6jSghDkTDJCiYody-YdhV8kO2bPn3N1qEKZdTr3lDcgWD5wo6wbEtdQVEKOyoUMY4WdEbLY0RbLId90oJFus4F4DNxdViOYDth19jcBhzek8ILdjNDk5xrQxozWenoTNmkL2cvQoimFaZz7PumCKkABYeUM6cgK32hrjXi_y6iG9aIW_7QUS3WJGQm1wWSv2aXwVvMd1jWq7O5wOvmwsUQL26NF3_7qiNRStawVtBW-lODw1v3GxaA9wpqWUgxpmH1k-8l15IAXK4qLYevqILd97Az05sCaNbHxGeTcisWA9pQZc4dS4vG5RuLxkj1e1IEc8RkvMrTB9P-NH9NjcukKDQN0yjQ8sNl30vVd8PpvuIIZFSdIKTfUYcU6apZP9x_AIL9Jrk], however, the concepts were discussed in detail, just not named.&nbsp;</p>
</blockquote>
<p>Is that supposed to be readable?! (It’s not just Substack. The other providers are almost just as bad.)</p>
<p>Email Cleaner changes it to:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [httрs://en.wikipedia.org/wiki/Dartmouth_workshop]. At a conference five years earlier [httрs://computerhistory.org/blog/thinking-about-machines-and-thinking/], however, the concepts were discussed in detail, just not named.&nbsp;</p>
</blockquote>
<p>which is moderately readable.</p>
<p>It would be even better if it was:</p>
<blockquote>
<p>Most agree that the term Artificial Intelligence was codified at a Dartmouth workshop in 1956 [0]. At a conference five years earlier [1], however, the concepts were discussed in detail, just not named.&nbsp;</p>
<p>[0] httрs://en.wikipedia.org/wiki/Dartmouth_workshop<br>
[1] httрs://computerhistory.org/blog/thinking-about-machines-and-thinking/</p>
</blockquote>
<p>but that’s a story for another time. (I don’t know if it’s worth the effort to do this. Do many people still read emails in plain text?)</p>
<h2 id="caveats">Caveats</h2>
<p>Please note that Email Cleaner is only a proof of concept. It’s an experiment. I wouldn’t even call it an MVP.</p>
<p>It’s useful to me, but I don’t know if it’s useful for others. I’d like to find out.</p>
<p>I don’t know how long Email Cleaner will last since:</p>
<ul>
<li>It’s vulnerable to spam (There’s no authentication or access control), and</li>
<li>It’s not scalable (It’s running on a tiny server).</li>
</ul>
<p>Once the spam bots arrive, or too many people use it, it’ll probably have to stop.</p>
<p>Or if there’s sufficient interest, I’ll rewrite it into a proper side project.</p>
<h2 id="privacy">Privacy</h2>
<p>Please don’t forward any personal or private emails to Email Cleaner. Only forward publicly available email newsletters (Paid newsletters are okay).</p>
<p>All received emails go to Email Cleaner’s inbox. I hope to accumulate more test data with which to conduct further research on mailing list service providers and improve Email Cleaner.</p>
<p>There’s not really a privacy policy. This is an experiment.</p>
<p>If you forward emails to Email Cleaner, I consider that as your opt-in.</p>
<p>Anything you forward to Email Cleaner could be used to improve Email Cleaner.</p>
<p>OTOH, I don’t know anything about you anyway. All I have is an email address and what email newsletters you subscribe to (whatever can be inferred from that).</p>
<h2 id="feedback">Feedback</h2>
<p>Since this is a new and experimental service, please don’t expect it to be perfectly reliable nor correct. If you forward an email to Email Cleaner and don’t get a reply in a few minutes, maybe something broke. Please get in touch with me and I’d be happy to look into it.</p>
<p>If you have any questions, suggestions, criticisms, etc. — please also let me know. I’d be happy to talk.</p>
<p>I hope you like Email Cleaner! Thanks for reading!</p>




  </article>


  
</div>
    </div></div>]]>
            </description>
            <link>https://bengtan.com/blog/email-cleaner-clean-tracking-links-and-pixels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293424</guid>
            <pubDate>Sun, 28 Feb 2021 13:55:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Remember Everything with Save All]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26293123">thread link</a>) | @quarok
<br/>
February 28, 2021 | https://www.saveall.ai/event/hackernews202102 | <a href="https://web.archive.org/web/*/https://www.saveall.ai/event/hackernews202102">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.saveall.ai/event/hackernews202102</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293123</guid>
            <pubDate>Sun, 28 Feb 2021 13:02:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can do better than Redis as a data layer for your models]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26293114">thread link</a>) | @jamesblonde
<br/>
February 28, 2021 | http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it | <a href="https://web.archive.org/web/*/http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.logicalclocks.com/blog/ai-ml-needs-a-key-value-store-and-redis-is-not-up-to-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-26293114</guid>
            <pubDate>Sun, 28 Feb 2021 13:02:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reasoning about Taxes]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 78 (<a href="https://news.ycombinator.com/item?id=26292993">thread link</a>) | @acqbu
<br/>
February 28, 2021 | https://www.billdietrich.me/ReasonTaxes.html | <a href="https://web.archive.org/web/*/https://www.billdietrich.me/ReasonTaxes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.billdietrich.me/ReasonTaxes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292993</guid>
            <pubDate>Sun, 28 Feb 2021 12:42:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hunting two PDP-1 photos (which are not what they seem)]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26292781">thread link</a>) | @masswerk
<br/>
February 28, 2021 | https://www.masswerk.at/nowgobang/2021/train-spotting-1 | <a href="https://web.archive.org/web/*/https://www.masswerk.at/nowgobang/2021/train-spotting-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.masswerk.at/nowgobang/2021/train-spotting-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292781</guid>
            <pubDate>Sun, 28 Feb 2021 12:02:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indeed MPH: Fast and Compact Immutable Key-Value Stores]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292427">thread link</a>) | @gbrown_
<br/>
February 28, 2021 | https://engineering.indeedblog.com/blog/2018/02/indeed-mph/ | <a href="https://web.archive.org/web/*/https://engineering.indeedblog.com/blog/2018/02/indeed-mph/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://engineering.indeedblog.com/blog/2018/02/indeed-mph/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292427</guid>
            <pubDate>Sun, 28 Feb 2021 10:56:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing Vat Solutions for Bootstrapped UK Businesses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26292256">thread link</a>) | @ianwootten
<br/>
February 28, 2021 | https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/ | <a href="https://web.archive.org/web/*/https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.ianwootten.co.uk/2021/02/23/comparing-vat-solutions-for-bootstrapped-uk-businesses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292256</guid>
            <pubDate>Sun, 28 Feb 2021 10:24:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The KimKlone Microcomputer]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26292235">thread link</a>) | @gbrown_
<br/>
February 28, 2021 | https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html | <a href="https://web.archive.org/web/*/https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://laughtonelectronics.com/Arcana/KimKlone/Kimklone_intro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292235</guid>
            <pubDate>Sun, 28 Feb 2021 10:19:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Actually Portable Executables]]>
            </title>
            <description>
<![CDATA[
Score 667 | Comments 152 (<a href="https://news.ycombinator.com/item?id=26292166">thread link</a>) | @krab
<br/>
February 28, 2021 | https://ahgamut.github.io/c/2021/02/27/ape-cosmo/ | <a href="https://web.archive.org/web/*/https://ahgamut.github.io/c/2021/02/27/ape-cosmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div>  <p><span>27 Feb 2021</span></p><p>I came across <a href="https://github.com/jart/cosmopolitan">Cosmopolitan</a> on Hacker News, and I was initially confused, due to a few memories of cross-compilation nightmares: while it should be possible to compile for the same architecture regardless of operating system, wouldn’t the OS get confused by the leading bytes of the executable? I read the <a href="https://justine.lol/ape.html">article</a> explaining how it works, but most of it went over my head.</p> <p>The example on the <a href="https://github.com/jart/cosmopolitan">Github README</a> used the following script for compilation:</p> <div><div><pre><code>gcc <span>-g</span> <span>-O</span> <span>-static</span> <span>-nostdlib</span> <span>-nostdinc</span> <span>-fno-pie</span> <span>-no-pie</span> <span>-mno-red-zone</span> <span>\</span>
  <span>-o</span> hello.com.dbg hello.c <span>-fuse-ld</span><span>=</span>bfd <span>-Wl</span>,-T,ape.lds <span>\</span>
  <span>-include</span> cosmopolitan.h crt.o ape.o cosmopolitan.a
objcopy <span>-S</span> <span>-O</span> binary hello.com.dbg hello.com
</code></pre></div></div> <p>I converted it into a simple Makefile to run the compilation commands. I tried a bunch of simple C programs (basic arithmetic, reading and writing to files) on Linux+Windows (compiled on Linux), and all of them worked.</p> <h2 id="compiling-lua-with-cosmopolitan">Compiling Lua with Cosmopolitan</h2> <p>I decided to try compiling a high-level language built on C. I originally picked Python, but the Makefile for Python seemed too complicated to mess with, so I then picked <a href="https://www.lua.org/download.html">Lua</a>, which looked much simpler in comparison.</p> <p>I started out by blindly copy-pasting the flags and includes used in the sample compilation on Github. Ah, it would have been wonderful for my laziness if it compiled out of the box. Following is a play-by-play commentary of trying to compile Lua.</p> <p>First problem I ran into was header clashes: if I didn’t put <code>-nostdlib -nostdinc</code> while compiling each object file, <code>-include cosmopolitan.h</code> would clash with the system headers. But blocking the system headers meant I would have to change every <code>#include</code> of a system header. I created a bunch of dummy headers with the same names as those in the <a href="https://en.cppreference.com/w/c/header">C stdlib</a> and and included to those instead.</p> <p>Naming clashes: some of the macros in <code>cosmopolitan.h</code> clashed with macro/function names in Lua: <code>reverse</code> and <code>isempty</code>. I changed the Lua source to avoid this.</p> <p>A macro <code>FIRST_RESERVED</code> was broken because <code>UCHAR_MAX</code> was missing. I thought <code>UCHAR_MAX</code> was supposed to be in <code>limits.h</code> – the <code>limits.h</code> part of <code>cosmopolitan.h</code> did not have <code>UCHAR_MAX</code> (It had <code>SCHAR_MAX</code>, though.) I added in a <code>#define</code> stating <code>UCHAR_MAX</code> as <code>__UINT8_MAX__</code> (ie 255).</p> <p>The default Lua Makefile attempts to use <code>_setjmp</code>/<code>_longjmp</code> in <code>ldo.c</code> when on Linux. I disabled the <code>LUA_USE_LINUX</code> flag for compiling the object files, but this caused an issue with <code>tmpnam</code> in <code>loslib.c</code> (<code>mkstemp</code> is available in Cosmopolitan). I changed the Lua source to use <code>setjmp</code>/<code>longjmp</code>. A similar issue showed in <code>lauxlib.c</code> for <code>sys/wait.h</code> (which is a no-op in non-POSIX systems, as per the Lua source code), and in <code>liolib</code> for <code>sys/types.h</code> so disabled <code>LUA_USE_POSIX</code> over there as well.</p> <p>The <code>localeconv()</code> function (part of <code>locale.h</code>) was not implemented in <code>cosmopolitan.h</code>, and this caused an error while compiling <code>lobject.c</code> (macro <code>lua_getlocaledecpoint()</code> depended on <code>localeconv()</code>). Changed the macro to just return <code>'.'</code>.</p> <p>The <code>panic</code> function in Lua <code>static int panic (lua_state*)</code> clashed with that in Cosmopolitan <code>void panic(void)</code>. Renamed the lua function to <code>lua_panic</code>. This triggered an error where the <code>panic</code> function was being called in <code>luaL_newstate</code>, so I changed the name there as well.</p> <p><code>luaL_loadfilex</code> caused a <em>frame size error</em> – I have never seen this before. A quick internet search shows that this is because a large buffer is allocated on stack when entering the function, and yes, <code>luaL_loadfilex</code> allocates a <code>loadF</code> object containing a <code>char</code> buffer of <code>BUFSIZ</code>. I reduced the size of the buffer to <code>BUFSIZ - 64</code>.</p> <p><code>loslib.c</code> reuiqres the <code>setlocale()</code> and <code>LC_*</code> from <code>locale.h</code>, which is defined as an extern value in <code>cosmopolitan.h</code>, but that definition is somehow not enough.. screw it, I just disabled <code>os_setlocale</code> in <code>loslib.c</code>, and then it compiles.</p> <h2 id="linking-the-object-files">Linking the object files</h2> <p>Ok, time for linking …</p> <div><div><pre><code>gcc -std=gnu99 -o lua   lua.o liblua.a -lm -Wl,-E -ldl
/usr/bin/ld: errno: TLS definition in //lib/x86_64-linux-gnu/libc.so.6 section
.tbss mismatches non-TLS reference in liblua.a(lauxlib.o)
/usr/bin/ld: //lib/x86_64-linux-gnu/libc.so.6: error adding symbols: bad value
collect2: error: ld returned 1 exit status
</code></pre></div></div> <p>I forgot, I shouldn’t <code>-lm</code> or <code>-ldl</code>. Ok, let’s try with all the object files instead of <code>liblua.a</code>:</p> <div><div><pre><code>/usr/bin/ld.bfd: lvm.o: in function `l_strcmp':
lvm.c:(.text+0x59): undefined reference to `strcoll'
/usr/bin/ld.bfd: lmathlib.o: in function `math_tanh':
lmathlib.c:(.text+0x21f): undefined reference to `tanh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_sinh':
lmathlib.c:(.text+0x24f): undefined reference to `sinh'
/usr/bin/ld.bfd: lmathlib.o: in function `math_cosh':
lmathlib.c:(.text+0x27f): undefined reference to `cosh'
collect2: error: ld returned 1 exit status
</code></pre></div></div> <p>Umm… okay, it looks like some of the functions defined in the cosmopolitan header are yet to be implemented in the static library. That’s okay, I can just quickly fill in the math functions, and I’ll comment out <code>strcoll</code> for now, just because I want to see it compile…. and it successfully compiles!! Let’s run <code>objcopy</code> before trying it out on a system though.</p> <div><div><pre><code>$ objcopy -S -O binary lua lua.exe
$ ls -al
-rwxr-xr-x 1 1953720 Feb 27 01:33 lua
-rwxr-xr-x 1 344064 Feb 27 01:39 lua.exe
</code></pre></div></div> <p>That size reduction seems a little too drastic, but let’s see if it runs on Linux:</p> <p><img src="https://ahgamut.github.io/assets/images/linux_screen.png" alt=""></p> <p>Awesome. How about Windows?</p> <p><img src="https://ahgamut.github.io/assets/images/windows_screen.png" alt=""></p> <h2 id="summary-it-is-actually-portable">Summary: it <em>is</em> actually portable</h2> <p>This is pretty incredible: I just had to modify a few lines in a Makefile and some C source files, and I got a Lua executable that works both on Linux and Windows (and possibly others as well). Granted, there are still some details to be filled out (floating point calculation above prints a <code>g</code>), but Cosmopolitan is currently at release 0.0.2, so there is a lot of time.</p> <p>Hopefully this means that other languages that have source code completely in C can also be compiled once and run anywhere. Actually Portable Python next, maybe?</p> </div> </div></div>]]>
            </description>
            <link>https://ahgamut.github.io/c/2021/02/27/ape-cosmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26292166</guid>
            <pubDate>Sun, 28 Feb 2021 10:06:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take a look at Nomad before jumping on Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 80 (<a href="https://news.ycombinator.com/item?id=26291975">thread link</a>) | @sofixa
<br/>
February 28, 2021 | https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/ | <a href="https://web.archive.org/web/*/https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        
        <h2>Table of Contents</h2>
        
         
      
      <h2 id="pre-introduction">Pre-introduction</h2>
<p>Recently I stumbled upon and then stumbled upon again on <a href="https://blog.dave.tf/post/new-kubernetes/">David Anderson</a>’s interesting post about “new Kubernetes”, based on a discussion he had with <a href="https://timewitch.net/">Vallery Lancey</a> about what they would do differently if they were rewriting Kubernetes from scratch. Interestingly, a decent part of the proposals for a “new Kubernetes” are design choices made by Hashicorp for <a href="https://www.nomadproject.io/">Nomad</a>, which is a pretty underrated orchestrator, and drastically simpler ( one of the main goals of said “new Kubernetes”).</p>
<p>Some people are aware that Docker Swarm kinda exists but is abandonware/on life support, and isn’t really recommended anymore, but it still comes up in discussions due to how easy it is to use. For most, that leaves Kubernetes as the only “serious” option, but it is a <em>very</em> complex piece of software, with a lot of moving parts, which isn’t actually required or need in most cases.</p>

  <figure>
    <img src="https://atodorov.me/img/nomad/kubernetes.jpg#center">
    
  </figure>


<p>This inspired me to write a series on Nomad, what it is, why it’s great, where it’s lacking and how to use it.</p>
<h2 id="introduction---what-is-nomad-and-why-its-great">Introduction - what is Nomad and why it’s great</h2>
<p>Hashicorp’s Nomad is a simple to run and maintain, yet very flexible task scheduler/orchestrator. It relies on plugins for execution, autoscaling and other features, and can run pretty much anything via its <code>task drivers</code> - Docker, contairnerd, LXC, rkt, podman, Java, fork/exec, QEMU, firecracker, FreeBSD jails.</p>
<p>It comes in the form of a single binary, run in two modes (<code>server</code>, in groups of 3 or 5, which make scheduling decisions and host the APIs and configuration, and an unlimited number of <code>worker</code>s which actually run whatever it is you want to run), and can be automatically clustered via <a href="https://consul.io/">Consul</a>. The configuration ( both for jobs and of Nomad itself) is in <a href="https://github.com/hashicorp/hcl">HCL</a> (I’ll get into more detail about how great that is a bit later) or JSON (mainly for when the jobs are submitted by machines/scripts/tooling and not humans). Multiple clusters can be connected via <a href="https://learn.hashicorp.com/tutorials/nomad/federation?in=nomad/manage-clusters">multi-region federation</a> for sharing ACLs and for API forwarding ( you can submit a job or request logs to any server for any region and it will be forwarded to the appropriate server). Deployments can be complex out of the box ( rolling, canary, blue/green), and everything is version controlled and rollbackable.</p>
<p>Like most HashiCorp tools, it’s “open core”, meaning that the majority of features are available in an <a href="https://github.com/hashicorp/nomad">open source</a> version, and some more advanced/enterprise-y ones ( in Nomad’s case, <a href="https://www.hashicorp.com/blog/hashicorp-nomad-multi-cluster-deployment">multi-region/cluster deployments</a> - deploying something simultaneously to multiple separate clusters, policy as code with <a href="https://docs.hashicorp.com/sentinel/nomad">Sentinel</a> and similar ) require upgrading to Nomad Enterprise.</p>
<h2 id="primitives">Primitives</h2>
<ul>
<li><code>job</code> is a declarative file which contains groups of tasks, each task being a container/binary/anything run by an exec driver</li>
<li><code>system</code> jobs (run on all client nodes, equivalent to Kubernetes DaemonSets, for monitoring/logging agents/load balancers)</li>
<li><code>periodic</code> jobs (equivalent to cronjobs)</li>
<li><code>service</code>, which registers as a Consul service and is thus discoverable ( via API or DNS)</li>
<li><code>deployment</code>, each version of a job, they’re tracked and can be rollbacked to</li>
<li><code>allocation</code>, each instance of a task ( group ) on a node</li>
<li><code>namespace</code>, a logical unit to organise jobs in and ACLs around</li>
</ul>
<h3 id="jobs">Jobs</h3>
<p>Example of a very basic job that runs a Docker container (<code>jaegertracing/all-in-one:1.21</code>), with limits of 1000Mhz of CPU and 1024MB of RAM, and registers the service with Consul:</p>
<div><pre><code data-lang="hcl"><span>job</span> <span>"jaeger"</span> {
        type <span>=</span> <span>"service"</span>
        <span>group</span> <span>"api"</span> {
            <span>task</span> <span>"jaeger"</span> {
                driver <span>=</span> <span>"docker"</span>
                <span>config</span> { 
                  image <span>=</span> <span>"jaegertracing/all-in-one:1.21"</span>
                }
                <span>resources</span> {
                  cpu <span>=</span> <span>1000</span>
                  memory <span>=</span> <span>1024</span>
                }
                <span>service</span> {
                  name <span>=</span> <span>"jaeger-query"</span>
                }
            }
        }            
}
</code></pre></div><p>Note that this is a <em>very</em> basic job, there are no healthchecks, no persistent storage, no extra configuration, no update strategy, no autoscaling, no exposed ports.</p>
<h4 id="deployment-history-and-rollback">Deployment history and rollback</h4>
<p>Nomad tracks each job’s full definitions and deployment history, and allows you to easily rollback and compare them, via the UI, CLI or API, e.g.:</p>
<div><pre><code data-lang="bash"><span># List the versions of the job named "opentelemetry-collector"</span>
$ nomad job history opentelemetry-collector
Version     <span>=</span> <span>1</span>
Stable      <span>=</span> false
Submit Date <span>=</span> 2021-01-08T21:30:30+01:00

Version     <span>=</span> <span>0</span>
Stable      <span>=</span> true
Submit Date <span>=</span> 2021-01-08T21:29:48+01:00

<span># Check the difference between versions</span>
$ nomad job history -p opentelemetry-collector
Version     <span>=</span> <span>1</span>
Stable      <span>=</span> false
Submit Date <span>=</span> 2021-01-08T21:30:30+01:00
Diff        <span>=</span>
+/- Job: <span>"opentelemetry-collector"</span>
+/- Task Group: <span>"opentelemetry-collector"</span>
  +/- Task: <span>"opentelemetry-collector"</span>
    +/- Config <span>{</span>
          args<span>[</span>0<span>]</span>:  <span>"--config=local/otel/config.yaml"</span>
      +/- image:    <span>"otel/opentelemetry-collector-contrib:0.15.0"</span> <span>=</span>&gt; <span>"otel/opentelemetry-collector-contrib:0.16.0"</span>
          ports<span>[</span>0<span>]</span>: <span>"health"</span>
          ports<span>[</span>1<span>]</span>: <span>"jaeger_thrift_compact"</span>
        <span>}</span>

Version     <span>=</span> <span>0</span>
Stable      <span>=</span> true
Submit Date <span>=</span> 2021-01-08T21:29:48+01:00

<span># Revert job "opentelemetry-collector" to version 0</span>
$ nomad job revert opentelemetry-collector <span>0</span>

</code></pre></div><h4 id="state-tracking-and-job-planning">State tracking and job planning</h4>
<p>Nomad keeps the desired state and its history, and with <code>nomad job plan</code>, similar to <code>terraform plan</code>, allows us to preview what will change upon applying a new job file. There’s also a feature to verify nothing has changed between the <code>plan</code> and <code>run</code> (equivalent to <code>terraform apply</code> with a plan file) with the <code>-check-index</code> flag:</p>
<div><pre><code data-lang="bash">$ nomad job plan otel.nomad
+/- Job: <span>"otel"</span>
+/- Task Group: <span>"opentelemetry"</span> <span>(</span><span>1</span> create/destroy update<span>)</span>
  +/- Task: <span>"opentelemetry-collector"</span> <span>(</span>forces create/destroy update<span>)</span>
    +/- Config <span>{</span>
          args<span>[</span>0<span>]</span>:  <span>"--config=local/otel/config.yaml"</span>
      +/- image:    <span>"otel/opentelemetry-collector-contrib:0.15.0"</span> <span>=</span>&gt; <span>"otel/opentelemetry-collector-contrib:0.20.0"</span>
          ports<span>[</span>0<span>]</span>: <span>"health"</span>
          ports<span>[</span>1<span>]</span>: <span>"jaeger_thrift_compact"</span>
        <span>}</span>
Scheduler dry-run:
- All tasks successfully allocated.

Job Modify Index: <span>413</span>
To submit the job with version verification run:

nomad job run -check-index <span>413</span> otel.nomad

When running the job with the check-index flag, the job will only be run <span>if</span> the
job modify index given matches the server-side version. If the index has
changed, another user has modified the job and the plan<span>'</span>s results are
potentially invalid.
</code></pre></div><p>Overall, it’s a very useful feature, especially when collaborating, locally or via CI/CD.</p>
<h4 id="checking-the-status-and-logs">Checking the status and logs</h4>
<p>To check the status of a job, there are a few commands under <code>nomad job</code> and <code>nomad alloc</code></p>
<div><pre><code data-lang="bash">$ nomad job status otel
ID            <span>=</span> otel
Name          <span>=</span> otel
Submit Date   <span>=</span> 2021-02-27T20:41:29+01:00
Type          <span>=</span> service
Priority      <span>=</span> <span>50</span>
Datacenters   <span>=</span> dc1
Namespace     <span>=</span> default
Status        <span>=</span> running
Periodic      <span>=</span> false
Parameterized <span>=</span> false

Summary
Task Group  Queued  Starting  Running  Failed  Complete  Lost
otel      <span>0</span>       <span>0</span>         <span>1</span>        <span>0</span>       <span>0</span>         <span>0</span>

Latest Deployment
ID          <span>=</span> ea533b6f
Status      <span>=</span> successful
Description <span>=</span> Deployment completed successfully

Deployed
Task Group  Desired  Placed  Healthy  Unhealthy  Progress Deadline
otel      <span>1</span>        <span>1</span>       <span>1</span>        <span>0</span>          2021-02-27T20:51:45+01:00

Allocations
ID        Node ID   Task Group  Version  Desired  Status   Created  Modified
89031cfd  d3cbeb7e  otel      <span>0</span>        run      running  20s ago  4s ago

<span># logs are at the allocation level ( similar to Kubernetes, where they're at the container level), so we get them with the alloc id</span>
$ nomad alloc logs 89031cfd
<span>[</span>...<span>]</span>
</code></pre></div><h4 id="lifecycle-and-sidecars">lifecycle and sidecars</h4>
<p>Nomad allows defining the lifecycle of tasks in task groups, and their status, with the <code>lifecycle</code> stanza. We can have <code>prestart</code> ( for initialisation ), <code>poststart</code> ( companion, for proxying (aka ambassador and adapter pattern in Kubernetes )) or <code>poststop</code> for clean up, and via the <code>sidecar</code> bool we define whether or not it should run as long as the main task(s), e.g.:</p>
<div><pre><code data-lang="hcl">  <span>task</span> <span>"init"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"prestart"</span>
      sidecar <span>=</span> <span>false</span>
    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"alpine/httpie"</span>
      command <span>=</span> <span>"http"</span>
      args <span>=</span> [
        <span>"POST"</span>,
        <span>"https://some-internal-service-for-provisioning-stuff.local/v1/new"</span>,
        "job_id<span>=</span><span>'</span><span>${</span><span>NOMAD_JOB_ID</span><span>}</span><span>!'"</span>
      ]
    }
  }

  <span>task</span> <span>"fluentd"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"poststart"</span><span> # should start after the main task
</span><span></span>      sidecar <span>=</span> <span>true</span><span> # should run as long as the main task does, and be restarted if it fails
</span><span></span>    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"fluentd/fluentd"</span>
    }
    ...
  }

  <span>task</span> <span>"main-app"</span> {
    ...
  }

  <span>task</span> <span>"cleanup"</span> {
    <span>lifecycle</span> {
      hook <span>=</span> <span>"poststop"</span>
    }
    driver <span>=</span> <span>"docker"</span>
    <span>config</span> {
      image <span>=</span> <span>"alpine"</span>
      command <span>=</span> <span>"rm -rf"</span>
      args <span>=</span> [
        <span>"/var/lib/volume-with-super-secret-data"</span>
      
    }
  }
</code></pre></div><h3 id="aclrbac">ACL/RBAC</h3>
<p>ACL ( access-control list ), or RBAC ( role-based access control ) as it’s known in Kubernetes, allow defining who can do what, so that not everyone with network access can have full administrator privileges and run/stop whatever. Nomad’s ACL system is pretty similar to Consul and Vault’s, and uses JSON ( mostly for non-humans ) or HCL to define <code>policies</code> with <code>rules</code>, which describe what action is allowed on what object.</p>
<div><pre><code data-lang="hcl"><span># a basic policy which allows the predefined read policy with read-only access to list and read:
</span><span># job, volume and scaling details, and extra capabilities for job creation and log access within the default namespace
</span><span></span><span>namespace</span> <span>"default"</span> {
  policy <span>=</span> <span>"read"</span>
  capabilities <span>=</span> [<span>"submit-job","dispatch-job","read-logs"</span>]
}
</code></pre></div><p>Assignment of policies is done only via the CLI, unlike Kubernetes where that happens in YAML, as does policy management:</p>
<div><pre><code data-lang="bash"><span># create/update the policy within Nomad</span>
nomad acl policy apply -description <span>"Application Developer policy"</span> my-policy my-policy.hcl
nomad acl token create -name<span>=</span><span>"Test token"</span> -policy<span>=</span>my-policy -type<span>=</span>client
Accessor ID  <span>=</span> …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/">https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/</a></em></p>]]>
            </description>
            <link>https://atodorov.me/2021/02/27/why-you-should-take-a-look-at-nomad-before-jumping-on-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291975</guid>
            <pubDate>Sun, 28 Feb 2021 09:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Left Node for Deno]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26291506">thread link</a>) | @fazlerocks
<br/>
February 27, 2021 | https://tastet.tech/why-i-left-node-for-deno | <a href="https://web.archive.org/web/*/https://tastet.tech/why-i-left-node-for-deno">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1611746956772/OLz2GztHg.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=compress"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text">
<p>If you don’t know  <a target="_blank" href="https://deno.land/">Deno</a> , it is a javascript runtime like Nodejs but with some changes.</p>
<p>We are not going to talk about the technical aspect here but only the advantages and disadvantages that I have in working with Deno.</p>

<h2 id="write-and-play">Write and play</h2>
<p>With Deno, you no longer need to install packages with package managers like NPM, so no more heavyweight node_modules folder on your computer (and also on your conscience).</p>
<p>Imports are done with Urls which can be either in deno's package manager with versioning, or directly on the git directory of your favorite library.</p>
<p>To illustrate that, here a sample code to start a web server with Deno and  <a target="_blank" href="https://oakserver.github.io/oak/">Oak Server</a> :</p>
<pre><code><span>import</span> { Application } <span>from</span> <span>"https://deno.land/x/oak/mod.ts"</span>;

<span>const</span> app = <span>new</span> Application();

app.use(<span>(<span>ctx</span>) =&gt;</span> {
  ctx.response.body = <span>"Hello world!"</span>;
});

<span>await</span> app.listen(<span>"127.0.0.1:8000"</span>);
</code></pre>
<p>You can also run codes that are not on your computer like <a target="_blank" href="https://deno.land/x/nessie@1.1.3">Nessie</a> which lets you perform database migrations directly from the command line with Deno.</p>
<pre><code>deno run --allow-net --allow-read --allow-write https://deno.land/x/nessie/cli.ts init
</code></pre>
<h2 id="typescript">Typescript</h2>
<p>Yes, Deno uses typecript by default for your code writing to avoid many errors, and since typescript is the norm in this perfect world, all libraries written in Deno uses typescript are typed.</p>
<p>And typescript is fully integrated into our IDEs, the code is easier to debug! 😁</p>
<h2 id="webassembly">WebAssembly 👀</h2>
<p>Deno integrates browser APIs and therefore has the WASM API allowing you to use functions written in other languages directly in your code.</p>
<p>I was personally tired of seeing Python run after installing each dependency in my NodeJs projects, it gave an impression of instability and that’s verified by running a code on different OS ...</p>
<p>But it's resolved as WASM is universal and standardized!</p>
<h2 id="browser-apis">Browser APIs</h2>
<p>Deno has (again) a big advantage, that offering browser APIs to make the javascript development environment more homogeneous with front-end javascript development.</p>
<p>For example : the standardized function " <a target="_blank" href="https://developer.mozilla.org/fr/docs/Web/API/Fetch_API/Using_Fetch">fetch</a> " is available with Deno.</p>
<h2 id="custom-formatter">Custom Formatter</h2>
<p>Deno integrates a custom formatter to make the code in your project between each developer more homogeneous with the <code>deno fmt</code> command</p>

<p>I only see 2 problems using Deno :</p>
<h2 id="instability">Instability</h2>
<p>Since Deno is still young, the libraries and the runtime may have bugs.</p>
<p>I have often had to spend long hours debugging my code to fix crashes.</p>
<p>Often due to a bad cache or a version change in a dependency or runtime.</p>
<p>On the other hand, the more we advance in time, the more stable Deno is and the libraries also with a strong open source community.</p>
<p>For example, I have more easily participated in open source projects using the deno runtime to improve them than NodeJs.</p>
<h2 id="libraries">Libraries</h2>
<p>The number of available libs is still quite low, again due to Deno's age, but this number is increasing day by day (javascript ecosystem, lol)!</p>

<p>In the end, I use Deno whenever I have to do something other than frontend, instead of using NodeJs, if the library I want to use doesn't exist, then I create it and make it public to help other people.</p>
<p>And I learned a lot from the open-source community by operating like this!</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://tastet.tech/why-i-left-node-for-deno</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291506</guid>
            <pubDate>Sun, 28 Feb 2021 07:49:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ROG AI Overclocking on Linux]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26291486">thread link</a>) | @dragon-rabbit
<br/>
February 27, 2021 | https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>ASUS Republic of Gamers (ROG) has released an AI overclocking tool on BIOS, which allows the PC users who are not experienced in overclocking to overclock the CPU and boost the operating system performance.</p>



<p>I am using a ROG Z390 MAXIMUS XI HERO (WI-FI) motherboard and an Intel i9-9900K CPU. In this blog post, I would like to share my experience with the ROG AI overclocking on Linux.</p>

<h3 id="benchmark-tools">Benchmark Tools</h3>

<p>Here are some benchmark tools that are available on Linux.</p>

<h4 id="blender">Blender</h4>

<p>Blender has a benchmark tool called <a href="https://opendata.blender.org/">Blender Open Data</a>, which allows you to benchmark your CPU or GPU.</p>

<div><div><pre><code>$ wget https://opendata.blender.org/cdn/BlenderBenchmark2.0/launcher/benchmark-launcher-2.0.5-linux.tar.gz
$ tar xvf benchmark-launcher-2.0.5-linux.tar.gz 
$ ./benchmark-launcher 
</code></pre></div></div>

<!-- <div class = "titled-image">
<figure class = "titled-image">
    <img src = "https://leimao.github.io/images/blog/2021-03-29-ROG-Linux-AI-Overclocking/blender.png" style = "width: 70%; height: 70%">
    <figcaption>Causal Diagram</figcaption>
</figure>
</div> -->

<p>Blender is also a free and open source 3D creation suite. We could install it on Ubuntu using the following command.</p>

<div><div><pre><code>$ sudo apt-get update
$ sudo apt-get install blender
</code></pre></div></div>

<h4 id="prime95">Prime95</h4>

<p>Prime95 is used for â€œburningâ€� your CPU. It is also available on Linux.</p>

<div><div><pre><code>$ wget http://www.mersenne.org/ftp_root/gimps/p95v303b6.linux64.tar.gz
$ tar xvf p95v303b6.linux64.tar.gz
$ ./mprime
</code></pre></div></div>

<h4 id="openssl">OpenSSL</h4>

<p>OpenSSL comes with Linux by default. It can also be used for â€œburningâ€� your CPU.</p>

<div><div><pre><code>$ openssl speed -multi 16
</code></pre></div></div>

<h4 id="turbostat">TurboStat</h4>

<p>TurboStat is a tool to monitor Intel CPU usages. We will mainly use it to monitor the CPU clock speed.</p>

<div><div><pre><code>$ sudo apt-get install linux-tools-$(uname -r) linux-cloud-tools-$(uname -r)
$ sudo modprobe msr
$ sudo turbostat
</code></pre></div></div>

<h3 id="rog-ai-overclocking">ROG AI Overclocking</h3>

<p>ROG AI overclocking could be done at BIOS level.</p>

<ol>
  <li>Go into BIOS and set all the BIOS configurations to default, save and reboot.</li>
  <li>Go into OS and run one of the benchmark tools mentioned above, reboot.</li>
  <li>Go into BIOS and turn on AI overclock and XMP, save and reboot.</li>
</ol>

<div>
<figure>
    <img src="https://leimao.github.io/images/blog/2021-03-29-ROG-Linux-AI-Overclocking/bios.png">
    <figcaption>ROG BIOS AI Overclocking</figcaption>
</figure>
</div>

<p>Before ROG AI overclocking, the stabilized CPU clock speed for all 8 cores of my i9-9900K during OpenSSL benchmarking was around 4.1-4.2 GHz. After ROG AI overclocking, it became 4.6-4.7 GHz.</p>



<p>For i9-9900KS, I believe it is possible to overclock all 8 cores to 5.0 GHz.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.asus.com/Microsite/motherboard/Intelligent-motherboard/AI-Overclocking.html">ROG AI Overclocking</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/ROG-Linux-AI-Overclocking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291486</guid>
            <pubDate>Sun, 28 Feb 2021 07:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust, Zig, and the Futility of “Replacing” C]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 121 (<a href="https://news.ycombinator.com/item?id=26291054">thread link</a>) | @ghoward
<br/>
February 27, 2021 | https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/ | <a href="https://web.archive.org/web/*/https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>This post has been discussed on <a href="https://news.ycombinator.com/item?id=26291054#26294846">Hacker News</a>, <a href="https://www.reddit.com/r/rust/comments/luawx6/rust_zig_and_the_futility_of_replacing_c/"><code>/r/rust</code></a>, and
<a href="https://lobste.rs/s/1iiifg"><code>lobste.rs</code></a>.</p><p>I should not have posted this to Hacker News on a Saturday night right before
going to bed, but in my defense, this post blew up in a way I didn’t expect.</p></div><h2 id="introduction">Introduction</h2><p>There was a recent <a href="https://github.com/pyca/cryptography/issues/5771">dust-up on GitHub</a> surrounding the decision by the
<a href="https://github.com/pyca/cryptography">Cryptography library</a> (which I will call <code>cryptography</code> for convenience) to
switch to <a href="https://www.rust-lang.org/">Rust</a>.</p><p>One of the distro maintainers of my distro of choice, <a href="https://www.gentoo.org/">Gentoo</a>, filed a bug
report with the <code>crytography</code> saying that the switch broke builds on several
platforms that Gentoo still supports. The <code>cryptography</code> authors replied that
those platforms are not really used anymore, and that they were going to stick
with Rust because it has better memory safety than C. They also argued that it
is better to force better programming languages on people because of better
security.</p><p>At first glance, it appears that the better argument is on the side of the
<code>cryptography</code> maintainers, but after thinking about it carefully, I think they
are wrong.</p><h2 id="reasons">Reasons</h2><p>There are a few reasons why I believe the <code>cryptography</code> maintainers are at
fault.</p><h3 id="due-diligence">Due Diligence</h3><p>First, their argument for Rust (and against C) because of memory safety implies
that they have not done due diligence in finding and fixing such bugs.</p><p>I can almost hear the rage of my readers against that paragraph above and
against the fact that I don’t have a commenting system on my blog. So let me
answer the comments preemptively.</p><p>“They are volunteers, giving their time away for free!”</p><p>Yes, but they also <em>intend</em> for their code to be used widely. They managed to
succeed in that, so they now have some obligation to their users.</p><p>“They don’t have any obligation!”</p><p>If a software project actively goes out and gets users, which just about any
project with a serious number of users has done, then yes, they have an
obligation to those users. The reason is that they sold users on the idea of
using their software. In other words, they were marketing their software, which
means making promises.</p><p>In fact, when people release <em>libraries</em> and try to get users for them, it’s
<em>because</em> they want them to be used by downstream programmers. A programmer
might write a program to scratch an itch and release it, but that reasoning
applies much less to libraries, in my opinion.</p><p>“Okay, but they didn’t get anything in return, so there’s still no obligation.”</p><p>In return, the users gave them <strong>relevance</strong>.</p><p>One of the most vocal (in favor of Rust) developers of <code>cryptography</code> works for
Red Hat Security Engineering (if I read his GitHub profile right). I don’t know
if his work on <code>cryptography</code> helped him get that job, but it might have.</p><p>Another of the most vocal developers has a computer security company. I would
bet money that his work on <code>cryptography</code> gives his company relevance.</p><p>So they did <em>not</em> get “nothing” from users. Quite the opposite, in fact.</p><p>By the way, this position comes from my own experience pushing my <a href="https://git.yzena.com/gavin/bc"><code>bc</code></a>. I
managed to convince the FreeBSD project to <a href="https://github.com/freebsd/freebsd-src/tree/main/contrib/bc">make it the default</a> in FreeBSD
13.</p><p>Once I did that, I shouldered, willingly, the need to keep FreeBSD happy. And
while I have made mistakes, I have done well so far.</p><p>And with my <code>bc</code>, <strong>I did my due diligence with memory safety</strong>. I fuzzed my
<code>bc</code> and eliminated all of the bugs. I even run the generated fuzzer test cases
through AddressSanitizer, and my entire test suite is run through Valgrind
<em>and</em> AddressSanitizer. I also add failing fuzzer cases to my test suite, which
means I run more and more test cases through both of those frightfully
effective tools.</p><p>For the record, those tools are only effective with effective test suites, which
I spent a lot of time building. But <em>building</em> such a test suite is part of due
diligence itself.</p><p>So it follows that if the developers have <em>not</em> done their due diligence, their
users should <strong>leave</strong>, either by forking the project or creating a new one.
The relevance they gave to the <code>cryptography</code> authors should disappear.</p><h3 id="battle-tested-c-code">Battle-Tested C Code</h3><p>In fact, I have done enough due diligence with my <code>bc</code> that I would consider it
a dereliction of duty to Rewrite It in Rust (RIIR).</p><p>Why would it be a dereliction of duty? Because rewriting it in Rust would cause
<em>more</em> bugs, not less. This is because of several reasons:</p><ol><li>I would need to <em>redesign</em> it to fit the language.</li><li>I would need to <em>reimplement</em> it, and new implementations always have bugs.</li><li>The C code is battle-tested, both by me (using fuzzing and other techniques)
and by users.</li></ol><p>That last point is the most crucial, especially in the case of <code>cryptography</code>.</p><p>If the developers of <code>cryptography</code> claim that they have, in fact, done their
due diligence with regards to memory safety in their C code, then they are
claiming that it’s battle-tested.</p><p>The saying that “a bird in the hand is worth two in the bush,” and in this case,
<em><strong>if</strong></em> the <code>cryptography</code> developers are claiming that they have done their
due diligence, they are throwing away a bird in the hand for a single one in the
bush.</p><div><p><strong>Edit (28 Feb 2021)</strong>: This part of the post seems to be misunderstood widely,
so I am going to attempt to clarify.</p><p>People are arguing that having safe C code requires a frozen, small codebase
with a thorough test suite. And then they debate my position based on the belief
that the codebase needs to evolve.</p><p>For the record, I agree with them that in order to have safe C code, the
codebase must be small and frozen.</p><p>What I am arguing is that <strong>crypto</strong> code <em>should</em> be small and frozen, with a
thorough test suite. I wrote about that <a href="https://gavinhoward.com/2019/11/finishing-software/">here</a>.</p></div><p>And if that’s the case, their users should <strong>leave</strong> and take <code>cryptography</code>'s
relevance with them.</p><h3 id="desktops-and-smartphones-are-not-the-only-computers">Desktops and Smartphones Are Not the Only Computers</h3><p>The users of <code>cryptography</code> were claiming in the bug report discussion that Rust
is not portable to many platforms, and the authors said that they don’t have the
time or resources to target those platforms. Fair enough.</p><p>But then they claim that the <em>users</em> should put in the effort to port Rust to
their platforms. This is wrong.</p><p>The <code>cryptography</code> authors also claim that the platforms that Rust doesn’t
support do not matter. As we will see below, this is false.</p><p>While I agree that the <code>cryptography</code> authors are not responsible for porting
Rust to other platforms, the users of those platforms are not either.</p><p>That responsibility falls on the Rust developers.</p><p><em>They</em> were the ones who sold Rust to those who have used it, so as above,
<em>they</em> have the responsibility for supporting their users.</p><p>Granted, the Rust developers have made no claim about being portable to every
platform. But they <em>have</em> claimed that it is <a href="https://www.rust-lang.org/what/embedded">appropriate for embedded
software</a>.</p><p>If it were true, this would be great. After all, <a href="https://youtu.be/3HxPzutkNYw?t=257">IoT devices outnumber
desktops and smartphones by at least one order of magnitude</a>.</p><p>But there are a lot of them that LLVM, Rust’s backend, cannot generate code
for. In fact, there are a lot of them that <em>C++</em> cannot run on.</p><div><p><strong>Edit (28 Feb 2021)</strong>: Also, the Rust developers are the developers with the
most experience reading ISA manuals knowing how to make a compiler generate
code. So they are still the best placed to support those “esoteric”
architectures.</p><p>And if they do not know how to read ISA manuals and generate code, it’s because
they lean too heavily on LLVM.</p></div><p>Make no mistake; embedded software is still running the majority of devices in
the world. And C is the king of embedded software.</p><p>I don’t know exact numbers, but I wouldn’t be surprised if the majority of
programmable devices in the world cannot run Rust.</p><p>Thus, because Rust uses LLVM, it is not portable.</p><p>And in my opinion, Rust is not appropriate for the embedded space.</p><p>So in this case, I would consider that the <code>cryptography</code> developers were
victims of the Rust developers.</p><h3 id="gcc-is-not-the-only-compiler"><code>gcc</code> Is Not the Only Compiler</h3><p>That isn’t the only problem.</p><p>There is a <a href="https://github.com/Rust-GCC/gccrs">project to make <code>gcc</code> able to compile Rust</a>. That’s commendable.</p><p>However, many people seem to believe that once it’s done, Rust will be portable.
That is not the case.</p><p>Why? Simple: <strong><code>gcc</code> is not the only compiler</strong>.</p><p>There is plenty of code out there that uses dead simple C compilers, like
<a href="https://bellard.org/tcc/">tcc</a>, <a href="http://sdcc.sourceforge.net/">sdcc</a>, and others. And often, they have <a href="https://embeddedgurus.com/stack-overflow/2012/06/optimizing-for-the-cpu-compiler/">good reason to do
so</a>.</p><p>Adding a <code>gcc</code> frontend, while it will improve the situation, will not make Rust
as portable as C. Period.</p><h3 id="pushing-for-progress-hinders-it">Pushing for Progress Hinders It</h3><p>The other thing that the <code>cryptography</code> authors claim is that their users who
refuse to adopt Rust are hindering progress.</p><p>That may be true, but it is also true that forcing “progress” on others hinders
<em>true</em> progress.</p><p>By forcing users to either adopt Rust or pin their dependency on <code>cryptography</code>
to the most recent version without it, they are forcing those users to use
stagnant code.</p><p>Isn’t that the very opposite of progress?</p><h2 id="cryptography-at-fault"><code>cryptography</code> at Fault</h2><p>Those reasons lay out why I think the <code>cryptography</code> authors should shoulder the
blame for this situation, and I think I can explain where they went wrong.</p><ol><li>They let ideology come before pragmatic engineering.</li><li>They sold <code>cryptography</code> to users.</li><li>They knew that switching to Rust would break existing users and did it
anyway.</li><li>They either did not do their due diligence for memory safety, or they did
and threw that battle-tested code out.</li></ol><h2 id="portability">Portability</h2><p>To be honest, I used to think that it was better to switch to a better language
than C.</p><p>I had several talks with Linux distro maintainers, as well as a talk with my
father-in-law, that convinced me that C’s portability is still important enough
that it should be used.</p><p>Unless, of course, you <em>explicitly</em> target only certain platforms. But you had
better be prepared to never target others.</p><p>In fact, after talking with the distro maintainers, who have had to build Rust,
I am also convinced that it’s not just about being portable, it’s also about how
<em>easy</em> it is to <em>build</em> software.</p><p>Rust’s bootstrap is <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">complicated</a>, and it is one of the worst things about
it.</p><p>If building software in Rust means building Rust for a <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">Tier 3</a> platform,
you can bet that <a href="https://drewdevault.com/2021/02/09/Rust-move-fast-and-break-things.html">people will stick with C</a>.</p><h3 id="zig">Zig</h3><p>I want to take a moment to talk about Zig.</p><p>Zig might be one of the most promising up-and-coming languages of recent memory.</p><p>But it will ultimately fail to reach its goal.</p><p>You see, Zig is meant to replace C. But …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/">https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/</a></em></p>]]>
            </description>
            <link>https://gavinhoward.com/2021/02/rust-zig-and-the-futility-of-replacing-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26291054</guid>
            <pubDate>Sun, 28 Feb 2021 06:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Horizonator: Terrain renderer based on SRTM DEMs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290718">thread link</a>) | @pabs3
<br/>
February 27, 2021 | http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html | <a href="https://web.archive.org/web/*/http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>
Check this out:
</p>


<p><img src="https://github.com/dkogan/horizonator/raw/master/example-interactive.png" alt="example-interactive.png">
</p>

<p>
I just resurrected and cleaned up an old tool I had lying around. It's now nice
and usable by others. This tool loads terrain data, and renders it from the
ground, simulating what a human or a camera would see. This is useful for
armchair exploring or for identifying peaks. This was relatively novel when I
wrote it &gt;10 years ago, but there are a number of similar tools in existence
now. <i>This</i> implementation is still useful in that it's freely licensed and
contains APIs, so fancier processing can be performed on its output.
</p>

<p>
Sources and (barely-complete-enough) documentation live here:
</p>

<p>
<a href="https://github.com/dkogan/horizonator">https://github.com/dkogan/horizonator</a>
</p>

  </div></div>]]>
            </description>
            <link>http://notes.secretsauce.net/notes/2021/02/27_horizonator-terrain-renderer-based-on-srtm-dems.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290718</guid>
            <pubDate>Sun, 28 Feb 2021 04:38:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Intro to Ephemeral Environments]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290634">thread link</a>) | @gk1
<br/>
February 27, 2021 | https://releaseapp.io/ephemeral-environments | <a href="https://web.archive.org/web/*/https://releaseapp.io/ephemeral-environments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://releaseapp.io/ephemeral-environments</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290634</guid>
            <pubDate>Sun, 28 Feb 2021 04:16:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Some Thoughts on Community]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290434">thread link</a>) | @sarvasvkulpati
<br/>
February 27, 2021 | https://sarvasvkulpati.com/blog/community | <a href="https://web.archive.org/web/*/https://sarvasvkulpati.com/blog/community">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><main><article><div><p>There's been an explosion of people creating communities on the internet. I've thought about them a lot, and wrote this to compile some of those thoughts in a single document.</p><p>What is a community? For my purposes, I’ve found a useful definition.</p><blockquote><p>A group of people, united by a shared passion or purpose, who interact with each other.</p></blockquote><p>Looking at the definition, there are only two things a community needs.</p><ul><li>A shared passion or purpose</li><li>People interacting with each other</li></ul><p>Here’s some examples of communities:</p><table><thead><tr><th>Community</th><th>Shared passion/purpose</th><th>People interacting</th></tr></thead><tbody><tr><td>Your high school</td><td>Learn (apparently)</td><td>Talking in classrooms, lunches, groupchats</td></tr><tr><td>React developers</td><td>Using the same language, interested in the development of the language</td><td>Tweeting at each other, reddit, forums</td></tr></tbody></table><p>The strength of a community, then, comes from the strength of this shared passion/purpose and the depth and frequency of interactions. And so, a useful formula for measuring the strength of a community could be:</p><p><span></span> = strength of the passion/ideal</p><p><span></span> = the ith connection</p><p><span></span> = the depth of the ith connection</p><p>We can come up with a few interesting observations through this formula.</p><ul><li><p>Notice that this definition doesn’t talk about technology or the platform used to bring these people together. <strong>Putting people into a group chat doesn’t make it a community.</strong> In fact, a group chat isn’t even necessary to build a community. There’s clearly a React developer community on the internet, but there isn’t any specific platform or group chat they congregate at. In that sense, communities can be thought of as the superset of the platform they exist on. A single community can use many platforms to interact with each other, but the discord server or slack channel they use isn’t the community itself.</p></li><li><p><strong>The strength of the shared passion/purpose acts as a force multiplier on the connections in a community.</strong> If there is no shared P, the community has no strength. Getting people together who don’t have a shared passion is the same thing as putting a bunch of random people in a group chat and calling it a community.</p></li><li><p><strong>It’s much easier to connect with people who have the same values and passions as you do, so the stronger P is, the stronger every single connection is right at the outset.</strong> So (somewhat obviously), the more passionate people are, the easier is it so make a community with them. Conversely, without a strong shared ideal, it’ll be very difficult to get people to interact and form deep connections.</p></li><li><p>The shared purpose can even be something as trivial as having to be in the same place at the same time. But if you’ve left high school, you’ll notice how you probably haven’t kept in touch with 90% of the people you knew, even if it felt like you knew them really well during your time there. That leads us to another important point- <strong>there is a hierarchy of shared experiences that bring people together.</strong> You didn’t keep in touch simply because the strength of your connection was based on location, which is very weak compared to shared passions or experiences.</p></li></ul><p><img src="https://sarvasvkulpati.com/hierarchy.jpeg" alt="shared purpose hierarchy"></p><p>A community with a few deeply passionate people is much stronger than one with many shallow ones. You’d think that it’s merely the area under the curve (connections x depth of connections), but there’s a third dimension here-  P would likely be much higher in communities with deeper connections, making those communities stronger.</p><p><img src="https://sarvasvkulpati.com/3d.jpeg" alt="3d graph of P, depth and connections"></p><p>Notice that frequency of interaction is not a factor at all. It’s only useful to the extent that it increases the depth of relationships in a community- beyond that, it doesn’t make a difference.</p><p>Think of your closest group of friends. You could meet them all after months and you’d still feel the same sense of community you did before. The strength of your connection superseded the need to constantly interact. And so, the DAUs of a community is a terrible way to measure its strength. This is not to say it doesn’t matter, just that while frequent interactions may lead to deep connections, deep connections don’t necessarily mean frequent interactions.</p><h2>Who’s a community for?</h2><p>The need for deep connections means that communities specifically built for the internet can only fulfill a certain set of users.</p><p>The issue is <a href="https://en.wikipedia.org/wiki/Dunbar%27s_number">Dunbar’s number</a>. Humans can only maintain ~150 deep connections, and the vast majority of these are taken up by in person relationships. But to make online communities, you need people to make strong relationships. So, in a sense, you need people with enough ‘mental social capacity’ to form those deep relationships with people online.</p><p>This required ‘mental social space’ means that online communities need to cater to people who are missing some sort of social interaction offline. And so, they need to find a way to offer connections that people cannot find in person.</p><p>From a social lens, the internet is an aggregation of extremes. It allows everyone in the long tail to suddenly have an abundance of people like them. This means that people with unconvential interests who couldn't find their people in person, can do so online. So the the gamer, the programmer, the digital artist in school- they don’t need to feel so different anymore.</p><p>For example, I’ve been interested in startups for years now, and after bingeing <a href="https://blog.ycombinator.com/category/podcast/">YC’s podcasts</a>, I realised that I needed a way to find people with the SV mindset. Twitter allowed me to find many people my age with similar interests, <a href="https://twitter.com/sarvasvkulpati/status/1247181074611851267?lang=en">Enlite</a> allowed me to meet a bunch of really interesting people, and interning at <a href="https://pioneer.app/">Pioneer</a> gave me a glimpse of what it’s like to work at startups. All of these happened without meeting a single one of of these people in person.</p><p><a href="https://hackclub.com/">HackClub</a> is a perfect example of a community that’s built to cater to a group of people who miss some sort of social interaction offline. It’s still strangely difficult to find kids who are interested in coding and building things, and Hack Club fills that gap by giving young hackers an online community of people just like them. It works so well because it manages to both</p><ul><li>Cater to highly passionate people</li><li>Cater to people who don’t usually find their communities in person</li></ul><h2>Building strong community</h2><p>While finding many people with a high P is a prerequisite, you need to then get them to interact with each other, to weave the web of connections that form the thing you’ll call your community. When you first bring people together, each individuals connections will look like this:</p><p><img src="https://sarvasvkulpati.com/connections.jpeg" alt="a graph of connections against depth"></p><p>Each member will have fairly weak connections with all the other members.The mistake I made when I first started Enlite was thinking that putting a bunch of people in a slack channel would mean that all of them interact with every other member all the time. That wasn’t the case. Instead, a small, core group of people emerged.</p><p>When you’re in school, you’ll notice that cliques naturally form. No amount of social engineering would get the jocks to suddenly integrate with the nerds. Similarly, the formation of cliques in a community is pretty normal, and in fact, is a great thing. It means people are falling into subsets of others they are comfortable with.</p><p>However, you don’t want insulated cliques. While there should be strong connections within them, they should also be connected to each other. Should this succeed, your community will look like this:</p><p><img src="https://sarvasvkulpati.com/graph.jpeg" alt="network of members in a community"></p><p>Any individual in your community will end up with a T shaped profile- many fairly shallow connections, a few very deep ones. The width of the stem would depend on the number of online friends they mentally have space to make as well as their success with connecting to people within the community.</p><p><img src="https://sarvasvkulpati.com/depth.jpeg" alt="depth"></p><p>Much like any social product, Enlite has a retention curve, and about a third are still active. An interesting observation is that the members who initially attended the most video calls are the ones who are now the most active in chat. My theory is that they acquired the best relationships and so, felt incentivised to talk and share opinions and progress on projects.</p><h2>Creating strong connections</h2><p>But how do you facilitate creating these strong connections? Something I’ve noticed is that every relationship: teacher-student, parent-child, friend-friend, follows a timeline</p><p><img src="https://sarvasvkulpati.com/friendGraph.jpeg" alt="friendship timeline"></p><p>In a sense, the depth of a relationship could be measured by how much a pair knows and understands about what makes the other tick. You could have a wild drinking buddy and always have fun but unless you have some deep conversations, you don’t have a deep relationship. To increase the depth of the relationship quickly, you need to increase the bandwidth of communication- doing so allows both people to understand each other faster, and so, speeds up the timeline of the relationship.</p><p>For example, <a href="https://twitter.com/aadillpickle">Aadil</a> and I followed each other on twitter for a while. I saw his tweets, he saw mine, sometimes we interacted with each other. But then, when making Enlite, I got on a zoom call with him. Within 30 minutes, we were much, much better friends. It felt like the amount our friendship progressed in a few months of interacting with each other on Twitter was repeated several times over in 1 zoom call.</p><p>Of course, different mediums have different bandwidth, but there’s a tradeoff- the higher the bandwidth, the higher the barrier of entry. Scheduling a zoom call, for example, is much harder than sending a Twitter DM.</p><p><img src="https://sarvasvkulpati.com/bars.jpeg" alt="bar charts of communication mediums compared"></p><p>In this sense, audio is probably best placed at the intersection of bandwidth and friction. On audio calls, you don’t need to care about how you look, you don’t need to constantly stay in a ‘switched on’ state and stare at the camera throughout, and it’s much easier to hop on and off. This is probably why platforms like Discord and Clubhouse are growing so fast as a tool to grow communities.</p><h2>A summary</h2><p>In conclusion:</p><ul><li>Communities = passion x interaction x strength of interactions</li><li>You don't need a group chat for a community, and putting people into a group chat doesn't make it one</li><li>Communities need to cater for connections people don't find in person</li><li>Creating connections requires a high bandwidth of communication. When in doubt, choose video</li><li>Frequent activity doesn't necessarily mean a strong community</li></ul></div></article></main></div></div>]]>
            </description>
            <link>https://sarvasvkulpati.com/blog/community</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290434</guid>
            <pubDate>Sun, 28 Feb 2021 03:30:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[There is only one poverty strategy: (broad based) growth (Part I) (2019)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290383">thread link</a>) | @tosh
<br/>
February 27, 2021 | https://lantpritchett.org/there-is-only-one-poverty-strategy-broad-based-growth-part-i/ | <a href="https://web.archive.org/web/*/https://lantpritchett.org/there-is-only-one-poverty-strategy-broad-based-growth-part-i/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-441">
		<!-- .entry-header -->

	
	<div>
		
<p>Here is a number to remember:&nbsp; .994 (and not because 994 is the country
telephone code for Azerbaijan).</p>



<p>The measure of poverty most commonly used by the World Bank is the “headcount”: the proportion of people below a poverty line,  a fixed level of income or consumption expenditures (CEX) per capita. &nbsp;The Foster, Greer and Thorbecke (1986) measures of poverty are weighted sums of people from a given distribution of consumption expenditures (or income), and the headcount is the simple case where the weights are equal for each person, irrespective of how far from the poverty line their CEX is. </p>



<p>This leads to a simple question:&nbsp; “How much of the  observed variation in headcount poverty rates across countries is due to variation in the median of the distribution of consumption expenditures?”&nbsp;&nbsp; </p>



<p>The answer, shown in Figure 1, is (roughly) “All of
it.”&nbsp; The R-Squared of the median (with
various powers to account for non-linearity) for explaining headcount poverty
for the three poverty lines is: </p>



<ul><li>$5.50 per day, R-Squared=.988,
correlation(poverty, predicted)=.994</li><li>$3.20 per day, R-Squared=.988, correlation(poverty,
predicted)=.994</li><li>$1.90 per day, R-Squared=.983,
correlation(poverty, predicted)=.991 </li></ul>



<p>The simple correlation between the actual $3.20/day or $5.50/day headcount poverty rate and headcount poverty as predicted using only the median of the country distribution is .994 and for $1.90 it is .991.&nbsp; These are about as high a correlation as real world data can produce.&nbsp; </p>



<p><strong>Figure 1:&nbsp; Headcount poverty rates are extremely highly associated with median consumption expenditures </strong></p>



<figure><img loading="lazy" width="749" height="353" src="https://lantpritchett.org/wp-content/uploads/2019/02/image.png" alt="" srcset="https://lantpritchett.org/wp-content/uploads/2019/02/image.png 749w, https://lantpritchett.org/wp-content/uploads/2019/02/image-300x141.png 300w" sizes="(max-width: 706px) 89vw, (max-width: 767px) 82vw, 740px"></figure>



<p><em>Source:&nbsp;
Author’s calculations based on data from:&nbsp; “</em><a href="http://iresearch.worldbank.org/PovcalNet/povDuplicateWB.aspx">PovcalNet:
the on-line tool for poverty measurement developed by the Development Research
Group of the World Bank</a>”</p>



<p>The regression uses the 389 country/time observations from
the World Bank data that are based on consumption expenditures (not income) and
recent data (not distant extrapolations). Since headcount poverty is a partial
integral of a distribution of consumption expenditures the relationship between
the median and headcount has to be non-linear.&nbsp;
I use powers of the median from -2 to 5 to allow for flexible
non-linearity. </p>



<p>Nancy Birdsall and Christian Meyer have argued that for
development issues “<a href="https://www.cgdev.org/publication/median-message-good-enough-measure-material-well-being-and-shared-development-progress">The
Median is the Message</a>.” &nbsp;For headcount
poverty they are <em>completely</em> right. &nbsp;The answer to the question:&nbsp; “Why does a country at a given time have
headcount poverty rate it does?” is “Because of its median of consumption
expenditure.” Pretty much full stop.&nbsp; &nbsp;Conditional on the median, any and all other factors
or variables can explain <em>at most</em> 1.2
percent of the variation in country headcount poverty rates (maybe 0, but <em>at most </em>1.2). &nbsp;</p>



<p>You might be saying, “Lant, why are you making such a big
deal of this correlation?”&nbsp; Well, thanks
for asking.&nbsp; </p>



<p>This very tight correlation is not built in.&nbsp; One can usefully decompose (as many have done)
the difference in poverty rates comparing two distributions (between countries
or over time) into three elements on the (mostly accurate) assumption the
distribution is log-normal (that is, the natural log of consumption
expenditures is distributed as a Gaussian normal distribution):</p>



<ol><li>Differences in the central tendency of the log-normal distribution,</li><li>Differences in the variance of the log-normal distribution and</li><li>Differences in the distribution below the poverty line being more or less favorable to poverty than would be expected of a log-normal of a given central tendency and variance (as the log-normal is a two-parameter distribution this forces an exact shape).</li></ol>



<p>How much of the variance in headcount poverty is an
empirical fact that depends on the actual distributions of consumption
expenditures across countries and the fact that (2) and (3) account for 1.2
percent of the variance could have been otherwise, it is not cooked into
definitions.&nbsp; In fact, one can easily
imagine policies or programs that would bring up the lower tail, and hence
reduce poverty, much more than the log-normal would predict.&nbsp; So it is a striking finding that <em>both </em>differences in variance
(inequality) with the assumption of log-normality and deviations from
log-normality below the poverty line <em>together
</em>account for at most 1.2 percent of observed variation in poverty.</p>



<p>Included in the country/time varying factors whose variation
in the observed data <em>cannot</em> explain
more than 1.2 percent of the observed variation in headcount poverty rates are
things like: “budget (government or other) devoted to anti-poverty programs”
and “efficacy of the design of anti-poverty programs” or “whether the country’s
anti-poverty programs are ‘evidence based’” or, for that matter, any
interaction of those factors, like:&nbsp;
“whether a country devoted budget to well-designed anti-poverty programs
based on evidence.”&nbsp; The median explains
nearly all variation in poverty across countries with no reference to targeted
programs of any kind: not micro-credit, not conditional cash transfers, not
chickens, not livelihood programs, nothing that claims to impact poverty
without changing the median. </p>



<p>Given the amount of time, energy, intellectual firepower, academic
publication, and advocacy that go into discussions of anti-poverty <em>programs</em> one might think they are a
large part of the “solution” to global poverty.&nbsp;
But they just have not been.&nbsp; If
your median consumption expenditure went up then your headcount poverty went
down and <em>nothing</em> else that any
country has done besides that seems to be very important in explaining poverty
reduction.</p>



<p>The relative importance of growth of median consumption expenditures versus “all else” can be illustrated with two different poverty lines at two different levels of income, the “extreme poverty” penurious poverty line that the World Bank often uses (but which I think is fundamentally <a href="http://www.effective-states.org/the-mdgs-were-a-disaster-meet-lant-pritchett/">illegitimate</a> as it is too low) and the “$5.50/day” line (which I think is still too low).</p>



<p>The predicted level of $1.90/day “extreme poverty” for a
country at the average income of the lowest quartile of countries is 72.2%.&nbsp; If its poverty rate were better by one
standard deviation of the residual conditional on the median it would fall to
only 68.6 percent.&nbsp; Even if it had the
best poverty conditional on its median for any country in the bottom quartile
it would fall by about 10 percentage points to 62.7 percent.&nbsp; In contrast, if that country grew by two
percent a year for 20 years (which is roughly the average growth in the post
WWII era) poverty would fall to 35.9 percent—about in half.&nbsp; If it grew at 4 percent per capita for 20
years (this is about one standard deviation above the average growth of 2
percent) predicted headcount poverty would fall to 12.1%.&nbsp; Sustaining rapid growth starting from a low
median consumption expenditures reduces poverty <em>50 percentage points</em> more than having the <em>best</em> observed poverty conditional on the low median.&nbsp; With sustained growth <em>half the population </em>moves out of extreme poverty compared to 10
percent even the <em>best</em> observed
poverty with stagnant income (and just to be clear, the data here don’t tell
what accounts for these observed low poverty rates conditional on the median). </p>



<p><strong>Figure 2:&nbsp; Even getting to the best headcount poverty for a given median expenditures versus the average produces a small gain relative to the poverty reduction from sustained growth of the median</strong></p>



<figure><img loading="lazy" width="481" height="289" src="https://lantpritchett.org/wp-content/uploads/2019/02/image-1.png" alt="" srcset="https://lantpritchett.org/wp-content/uploads/2019/02/image-1.png 481w, https://lantpritchett.org/wp-content/uploads/2019/02/image-1-300x180.png 300w" sizes="(max-width: 481px) 100vw, 481px"></figure>



<p>I do the same exercise with the second quartile of income
and the $5.50/day poverty line, with roughly the same results.&nbsp; Even the best performance for poverty
conditional on median produces gains much, much, smaller than the gains in
poverty reduction from sustained rapid growth.</p>



<p>The results of these regressions are just facts about the
world and do not directly reveal causal structures.&nbsp; In particular, there may well be cost
effective poverty reducing programs that merit support by governments and/or
philanthropists.&nbsp; The cross-national
correlations can only speak to what <em>have been</em>
the correlates of poverty, not <em>what could
be.&nbsp; </em>But, while one doesn’t want to
over-interpret facts, neither does one want to under-fact interpretations of
very specific and particular empirical findings about specific programs
either.&nbsp; </p>



<p>The next time you hear the phrase “solve global poverty” remember the number: .994.&nbsp; If what follows “solve global poverty” isn’t about raising median consumption expenditures a very good question is: “why not?”</p>



<p>(This blog is titled “Part I” because I plan a Part II that
does a bit more on the technical issues of these types of decompositions and a
Part III that discusses a bit the broader implications.&nbsp; But, unlike the Lord of the Rings (in which
all three were filmed at the same time) these are not yet written and the
future is unpredictable).</p>
	</div><!-- .entry-content -->

	
</article></div>]]>
            </description>
            <link>https://lantpritchett.org/there-is-only-one-poverty-strategy-broad-based-growth-part-i/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290383</guid>
            <pubDate>Sun, 28 Feb 2021 03:19:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Tree: React Aside from the UI]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26290183">thread link</a>) | @valand
<br/>
February 27, 2021 | https://valand.dev/blog/post/machine-tree-react | <a href="https://web.archive.org/web/*/https://valand.dev/blog/post/machine-tree-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Among a nauseatingly huge number of "modern web UI frameworks" out there, React stands tall. It is a very nimble library to write a JavaScript-based app on top of. React app code can stay way more clear, consistent, and recognizable regardless of complexity, compared to other frameworks. Why? Because unlike other frameworks, which are more of a template engine, React focuses on assisting to build an asynchronous machine tree.</p>
<p><em>Update:</em></p>
<ul>
<li><em>Looking forward for comments, feedback, etc. Do submit here <a href="https://news.ycombinator.com/item?id=26290183">HN</a>.</em></li>
</ul>
<figure>
<p><img src="https://valand.dev/d444d442389ff931c3a3b3f063043aba/opening.svg" alt="overview"></p>
<figcaption>React Webpage as of node tree</figcaption>
</figure>
<p>Illustrated above, on the right, a simple webpage. It contains a huge main section and three links on the left for the users to navigate between three pages. On the left is the visual of the React nodes that make up the simple web page. The nodes form a tree. Each node has one or more relationships to other nodes, which tells us a story:</p>
<p>This <code>App</code> has a <code>Router</code> that regulates the application routing system which affects everything below it. The page has <code>Sidebar</code> that has three <code>Link</code>s, and a <code>Main</code> section that renders a <code>Page</code>.</p>
<p>React works by enabling developers to compose <a href="https://reactjs.org/docs/components-and-props.html">React components</a> in the <a href="https://reactjs.org/docs/faq-internals.html">shape of a tree</a>. This tree-shaped composition is a hierarchy of mini machines. Each component, each machine, has its own domain/problem/concern/task.</p>
<figure>
<p><img src="https://valand.dev/440633a416591a2018205acb69e828d1/event-propagation.gif" alt="event-propagation"></p>
<figcaption>Event and effects chained into a flow</figcaption>
</figure>
<p>How does this work under the hood?</p>
<ul>
<li><code>Router</code> manages a state that describes what route it is now on and how it changes, and it affects every descendant of it. It provides its state and methods to its descendants.</li>
<li><code>Link</code> renders an element and listens to it for "click" events. If there's a "click", it notifies the nearest ancestor <code>Router</code> component via the method it passed.</li>
<li><code>Main</code> listens/subscribes to the nearest ancestor <code>Router</code>. Any change in the <code>Router</code>'s state causes <code>Main</code> to re-renders too.</li>
</ul>
<p><em>Note: Render is the term in React world equivalent to refreshing a component. It doesn't directly concern any GPU-related computation.</em></p>
<p>Those seem a lot for simple interaction, how is it easier in React?</p>
<p><strong>1) React automates spawning/despawning children</strong>. With this, you don't need to write "if [some condition] AND [Child is not spawned] then spawn Child". React simplifies this:</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>
</span><span>
</span><span>
</span><span>
</span><span>const</span><span> </span><span>Main</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>:</span><span> </span><span>{</span><span> </span><span>path</span><span>:</span><span> </span><span>string</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>  </span><span>&lt;&gt;</span><span>
</span><span>    </span><span>{</span><span>props</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>"/home"</span><span> </span><span>&amp;&amp;</span><span> </span><span>&lt;</span><span>HomePage</span><span> </span><span>/&gt;</span><span>}
</span><span>    </span><span>{</span><span>props</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>"/about"</span><span> </span><span>&amp;&amp;</span><span> </span><span>&lt;</span><span>AboutPage</span><span> </span><span>/&gt;</span><span>}
</span><span>    </span><span>{</span><span>props</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>"/contact-us"</span><span> </span><span>&amp;&amp;</span><span> </span><span>&lt;</span><span>ContactUsPage</span><span> </span><span>/&gt;</span><span>}
</span><span>  </span><span>&lt;/&gt;</span><span>
);</span></code></pre>
    </div>
<p>The above snippet declares that a certain condition causes a certain page to be shown, if path is <code>/home</code>, the component renders <code>HomePage</code>, and so on. The expression between the sign <code>{}</code> is a JavaScript expression.</p>
<p><code>Main</code> seems like a simple function, but because it is returning a <code>ReactNode</code> it can be a component. Once a component function is included in a render via <code>ReactDOM.render</code>, React creates a subroutine that manages components in a tree. The function above receives <code>path</code> as props. Props are values passed by the parent component into this component. When a prop changes, it will trigger a re-render. A re-render is when React calls this function again. How the props change though is not our concern for now.</p>
<p>If a render's result differs from the previous render's, maybe because of changing props, React will <a href="https://reactjs.org/docs/reconciliation.html">reconcile</a> the two return values. If both renders yield a child component, say, <code>HomePage</code> and <code>AboutPage</code>, the previous component, <code>HomePage</code> will be removed from the tree, and the new component <code>AboutPage</code> will replace it.</p>
<p>This is the famous declarative syntax of React people talking about.</p>
<p><em>Notes:</em></p>
<ul>
<li><em><code>&lt;&gt;</code> and <code>&lt;/&gt;</code> is a shorthand for <a href="https://reactjs.org/docs/fragments.html">React Fragment</a></em></li>
<li><em>Other than <code>props</code> change, <code>state</code> change and other dependencies (e.g. <a href="https://reactjs.org/docs/context.html">context</a>, <a href="https://reactjs.org/docs/refs-and-the-dom.html">ref</a>) change also cause rerender.</em></li>
</ul>
<p><strong>2) React provides free <a href="https://en.wikipedia.org/wiki/Dependency_injection">dependency injection</a> via <a href="https://reactjs.org/docs/context.html">context</a>.</strong> What is dependency injection? It is basically a technique to inject object/data/function as a dependency into another object. In React case the injection happens to a component. A component can specify that it needs a certain dependency and we can build an environment that can provide it. To be more specific, a <code>Link</code> component uses <code>Router</code> as a dependency to work. It needs access to a <code>Router</code> to tell that it is clicked and a change to a route is to be made. <code>Link</code> can be written like this:</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>Link</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>:</span><span> </span><span>{</span><span> </span><span>to</span><span>:</span><span> </span><span>string</span><span>;</span><span> </span><span>children</span><span>:</span><span> </span><span>React</span><span>.</span><span>ReactNode</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>const</span><span> </span><span>routerAPI</span><span> </span><span>=</span><span> </span><span>useContext</span><span>(</span><span>RouterAPIContext</span><span>);

</span><span>  </span><span>
</span><span>  </span><span>
</span><span>  </span><span>return</span><span> </span><span>(
</span><span>    </span><span>!!</span><span>routerAPI</span><span> </span><span>&amp;&amp;</span><span> </span><span>(
</span><span>      </span><span>&lt;</span><span>a</span><span>
</span><span>        </span><span>href</span><span>=</span><span>"#"</span><span>
</span><span>        </span><span>onClick</span><span>=</span><span>{(</span><span>e</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>          </span><span>e</span><span>.</span><span>preventDefault</span><span>();</span><span> </span><span>
</span><span>          </span><span>routerAPI</span><span>.</span><span>push</span><span>(</span><span>props</span><span>.</span><span>to</span><span>);</span><span> </span><span>
</span><span>        </span><span>}}
</span><span>      </span><span>&gt;</span><span>
</span><span>        </span><span>{</span><span>children</span><span>}
</span><span>      </span><span>&lt;/</span><span>a</span><span>&gt;</span><span>
</span><span>    </span><span>)
</span><span>  </span><span>);
};</span></code></pre>
    </div>
<p>In the above snippet, Link uses <code>routerAPI</code>. Link also receives the props <code>to</code> and <code>children</code> from its parent component. As explained in point 1, if either <code>to</code>, <code>children</code> or <code>routerAPI</code> changes, the <code>Link</code> will be re-rendered. <code>Link</code> will be used/rendered like this:</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>Sidebar</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>    </span><span>&lt;</span><span>Link</span><span> </span><span>to</span><span>=</span><span>"/home"</span><span>&gt;</span><span>Home</span><span>&lt;/</span><span>Link</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Link</span><span> </span><span>to</span><span>=</span><span>"/about"</span><span>&gt;</span><span>About</span><span>&lt;/</span><span>Link</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Link</span><span> </span><span>to</span><span>=</span><span>"/contact-us"</span><span>&gt;</span><span>Contact Us</span><span>&lt;/</span><span>Link</span><span>&gt;</span><span>
);
</span><span>
</span></code></pre>
    </div>
<p>Also, let's change <code>Main</code> to use context so it doesn't need to be the child of <code>Router</code>. We need to introduce <code>Route</code> which uses <code>Router</code> too.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>Route</span><span> </span><span>=</span><span> </span><span>(</span><span>props</span><span>:</span><span> </span><span>{</span><span> </span><span>path</span><span>:</span><span> </span><span>string</span><span>;</span><span> </span><span>render</span><span>:</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>React</span><span>.</span><span>ReactNode</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>const</span><span> </span><span>routerData</span><span> </span><span>=</span><span> </span><span>useContext</span><span>(</span><span>RouterDataContext</span><span>);
</span><span>  </span><span>
</span><span>  </span><span>return</span><span> </span><span>!!</span><span>routerData</span><span> </span><span>&amp;&amp;</span><span> </span><span>routerData</span><span>.</span><span>path</span><span> </span><span>===</span><span> </span><span>props</span><span>.</span><span>path</span><span> </span><span>?</span><span> </span><span>props</span><span>.</span><span>render</span><span>()</span><span> </span><span>:</span><span> </span><span>null</span><span>;
};

</span><span>const</span><span> </span><span>Main</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>  </span><span>&lt;&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Route</span><span> </span><span>path</span><span>=</span><span>"/home"</span><span> </span><span>render</span><span>=</span><span>{()</span><span> </span><span>=&gt;</span><span> </span><span>&lt;</span><span>HomePage</span><span> </span><span>/&gt;</span><span>}</span><span> </span><span>/&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Route</span><span> </span><span>path</span><span>=</span><span>"/about"</span><span> </span><span>render</span><span>=</span><span>{()</span><span> </span><span>=&gt;</span><span> </span><span>&lt;</span><span>AboutPage</span><span> </span><span>/&gt;</span><span>}</span><span> </span><span>/&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Route</span><span> </span><span>path</span><span>=</span><span>"/contact-us"</span><span> </span><span>render</span><span>=</span><span>{()</span><span> </span><span>=&gt;</span><span> </span><span>&lt;</span><span>ContactUsPage</span><span> </span><span>/&gt;</span><span>}</span><span> </span><span>/&gt;</span><span>
</span><span>  </span><span>&lt;/&gt;</span><span>
);</span></code></pre>
    </div>
<p><strong>3) React allows internal states and asynchronous actions in the components.</strong> This is the main reason I see React components as machines. React provides the <a href="https://reactjs.org/docs/hooks-faq.html">functions <code>useState</code> and <code>useEffect</code></a> (or alternatively state attribute and lifecycle methods if <a href="https://reactjs.org/docs/components-and-props.html#function-and-class-components">class component style</a> is used) that allow a component to have its own lifecycle. We will use them to implement <code>Router</code> which is a simple routing "system" for the application.</p>
<p>Let's start with <code>Router</code>'s core functionality first. I will use React's new addition, <a href="https://reactjs.org/docs/hooks-intro.html">hooks</a>, to demonstrate the ease to compose logics in React. Writing hooks is just as simple as writing components, except, instead of returning <code>React.ReactNode</code>, they return whatever you need.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>
</span><span>
</span><span>type</span><span> </span><span>RouterCoreAPI</span><span> </span><span>=</span><span> </span><span>{
</span><span>    </span><span>events</span><span>:</span><span> </span><span>{
</span><span>        </span><span>
</span><span>    	</span><span>pathChange</span><span>:</span><span> </span><span>TypedEvent</span><span>&lt;</span><span>null</span><span>&gt;</span><span>
</span><span>    </span><span>},
</span><span>    </span><span>path</span><span>:</span><span> </span><span>string</span><span>;
</span><span>    </span><span>push</span><span>:</span><span> </span><span>(</span><span>path</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>unknown</span><span>;
};
</span><span>const</span><span> </span><span>useRouterCoreAPI</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>    </span><span>const</span><span> </span><span>[</span><span>core</span><span>,</span><span> </span><span>setCore</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>&lt;</span><span>null</span><span> </span><span>|</span><span> </span><span>RouterCoreAPI</span><span>&gt;</span><span>(</span><span>null</span><span>);
</span><span>    </span><span>useEffect</span><span>(()</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span>		</span><span>
</span><span>        </span><span>const</span><span> </span><span>pathChange</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>TypedEvent</span><span>&lt;</span><span>null</span><span>&gt;</span><span>();
</span><span>        </span><span>const</span><span> </span><span>newCore</span><span>:</span><span> </span><span>RouterCoreAPI</span><span> </span><span>=</span><span> </span><span>{
</span><span>      		</span><span>events</span><span>:</span><span> </span><span>{</span><span> </span><span>pathChange</span><span>,</span><span> </span><span>},
</span><span>            </span><span>path</span><span>:</span><span> </span><span>""</span><span>,
</span><span>            </span><span>push</span><span>:</span><span> </span><span>(</span><span>newPath</span><span>:</span><span> </span><span>string</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>                </span><span>newCore</span><span>.</span><span>path</span><span> </span><span>=</span><span> </span><span>newPath</span><span>;
</span><span>                </span><span>pathChange</span><span>.</span><span>emit</span><span>();
</span><span>            </span><span>},
</span><span>        </span><span>};
</span><span>        </span><span>setState</span><span>(</span><span>newCore</span><span>);</span><span>	</span><span>
</span><span>    </span><span>},</span><span> </span><span>[]);</span><span>					</span><span>
</span><span>	</span><span>return</span><span> </span><span>core</span><span>;
};

</span><span>
</span><span>type</span><span> </span><span>RouterData</span><span> </span><span>=</span><span> </span><span>{
</span><span>    </span><span>path</span><span>:</span><span> </span><span>string</span><span>;
};
</span><span>const</span><span> </span><span>useRouterData</span><span> </span><span>=</span><span> </span><span>(</span><span>core</span><span>:</span><span> </span><span>null</span><span> </span><span>|</span><span> </span><span>RouterCore</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>const</span><span> </span><span>[</span><span>state</span><span>,</span><span> </span><span>setState</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>&lt;</span><span>null</span><span> </span><span>|</span><span> </span><span>RouterData</span><span>&gt;</span><span>;
</span><span>	</span><span>useEffect</span><span>(()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>        </span><span>if</span><span> </span><span>(</span><span>!</span><span>core</span><span>)</span><span> </span><span>return</span><span>;</span><span>		</span><span>
</span><span>        </span><span>const</span><span> </span><span>unsub</span><span> </span><span>=</span><span> </span><span>core</span><span>.</span><span>events</span><span>.</span><span>pathChange</span><span>.</span><span>subscribe</span><span>(()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>            </span><span>setState</span><span>({</span><span> </span><span>path</span><span>:</span><span> </span><span>core</span><span>.</span><span>path</span><span> </span><span>});
</span><span>        </span><span>});
</span><span>        </span><span>setState</span><span>({</span><span> </span><span>path</span><span>:</span><span> </span><span>core</span><span>.</span><span>path</span><span> </span><span>});

</span><span>        </span><span>
</span><span>        </span><span>
</span><span>        </span><span>
</span><span>        </span><span>return</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>            </span><span>unsub</span><span>();
</span><span>        </span><span>};
</span><span>    </span><span>},</span><span> </span><span>[</span><span>core</span><span>]);
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>
</span><span>    </span><span>return</span><span> </span><span>state</span><span>;
};</span></code></pre>
    </div>
<p>Now that the logic is established, let's use the logic in the <code>Router</code> component. <code>Router</code> is a component wrapper and a context provider so that it renders its <code>props.children</code> into it and API and data can be used by <code>Link</code> and <code>Route</code>.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>
</span><span>const</span><span> </span><span>RouterAPIContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>&lt;</span><span>RouterCoreAPI</span><span>&gt;</span><span>(</span><span>null</span><span>);
</span><span>const</span><span> </span><span>RouterDataContext</span><span> </span><span>=</span><span> </span><span>React</span><span>.</span><span>createContext</span><span>&lt;</span><span>RouterData</span><span>&gt;</span><span>(</span><span>null</span><span>);
</span><span>const</span><span> </span><span>Router</span><span> </span><span>=</span><span> </span><span>({</span><span> </span><span>children</span><span> </span><span>}:</span><span> </span><span>{</span><span> </span><span>children</span><span>:</span><span> </span><span>React</span><span>.</span><span>ReactNode</span><span> </span><span>})</span><span> </span><span>=&gt;</span><span> </span><span>{
</span><span>  </span><span>
</span><span>  </span><span>const</span><span> </span><span>coreAPI</span><span> </span><span>=</span><span> </span><span>useRouterCoreAPI</span><span>();
</span><span>  </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>useRouterData</span><span>(</span><span>coreAPI</span><span>);
</span><span>  </span><span>return</span><span> </span><span>(
</span><span>    </span><span>&lt;</span><span>RouterAPIContext</span><span> </span><span>value</span><span>=</span><span>{</span><span>coreAPI</span><span>}</span><span>&gt;</span><span>
</span><span>      </span><span>&lt;</span><span>RouterDataContext</span><span> </span><span>value</span><span>=</span><span>{</span><span>data</span><span>}</span><span>&gt;</span><span>{</span><span>children</span><span>}</span><span>&lt;/</span><span>RouterDataContext</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;/</span><span>RouterAPIContext</span><span>&gt;</span><span>
</span><span>  </span><span>);
};</span></code></pre>
    </div>
<p>Last let's use <code>Router</code> and other components to compose the whole app.</p>

    <div data-language="text/typescript-jsx">
      <pre><code><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>(
</span><span>  </span><span>&lt;</span><span>Router</span><span>&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Main</span><span> </span><span>/&gt;</span><span>
</span><span>    </span><span>&lt;</span><span>Sidebar</span><span> </span><span>/&gt;</span><span>
</span><span>  </span><span>&lt;/</span><span>Router</span><span>&gt;</span><span>
);</span></code></pre>
    </div>
<p>Look at that beautiful directive. It literally describes the architecture of the whole application.</p>
<p><em>Note: Using hooks in this particular case is unnecessary as it was for a demonstration of React's composability. Extracting logic to a hook is done usually because: 1.) The extracted part of the logic is reusable in other components, or 2.) the logic is simply too long and can be extracted without inciting semantic dissonance.</em></p>
<p><strong>4) React doesn't stray far from its host, JavaScript, and JavaScript VM.</strong> This point is an important and powerful concept in a library like React. JSX is a superset of JavaScript rather than another whole language. In consequence, writing React, with or without JSX/TSX, feels like writing JavaScript/TypeScript. If you pass a function as a prop in JSX, you write a JavaScript function.</p>
<p>In contrast, other web UI library such as Vue, Angular, or Svelte uses a separate templating language for its templating purpose. In Vue, for example, oftentimes you are required to write a <a href="https://vuejs.org/v2/guide/computed.html"><code>computed</code> function</a> to bridge a value in the Vue instance to the template. Meanwhile JSX's <code>&lt;ComponentName attribute={value}&gt;{childrenNode}&lt;/ComponentName&gt;</code> roughly translates to <code>React.createElement(ComponentName, { attribute: value }, [childrenNode])</code> with <code>key</code> attributes added on compile time.</p>
<p>Being a superset of JavaScript, JSX makes React many-folds more expressive and consistent to JavaScript than its competitors. Consistency keeps syntactical ambiguousness low, while expressiveness helps with productivity, enabling sentences to be written concisely, packing more dense meaning in shorter expressions.</p>
<p>Being a superset of JavaScript also allows compiler and IDE programmer to reuse existing JavaScript/TypeScript parser …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://valand.dev/blog/post/machine-tree-react">https://valand.dev/blog/post/machine-tree-react</a></em></p>]]>
            </description>
            <link>https://valand.dev/blog/post/machine-tree-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290183</guid>
            <pubDate>Sun, 28 Feb 2021 02:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before you buy a Soviet Camera]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 62 (<a href="https://news.ycombinator.com/item?id=26290128">thread link</a>) | @brudgers
<br/>
February 27, 2021 | https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/ | <a href="https://web.archive.org/web/*/https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
 <!-- A generated by theme --> 



 <!-- end A --> 

<p><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web.jpg" alt="Drug and Zenit-3M cameras (Pic: Stephen Dowling)" width="2500" height="1633" srcset="https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web.jpg 2500w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-300x196.jpg 300w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1024x669.jpg 1024w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-768x502.jpg 768w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1536x1003.jpg 1536w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-2048x1338.jpg 2048w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-696x455.jpg 696w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-1068x698.jpg 1068w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-643x420.jpg 643w, https://kosmofoto.com/wp-content/uploads/2021/01/drug-zenit_web-600x392.jpg 600w" sizes="(max-width: 2500px) 100vw, 2500px"></p>
<p>It begins in October 1927, with a single camera exhibited in Moscow at an Exposition of Photographic Technique in the new Soviet capital, Moscow. Bostelman’s camera is a small 35mm camera with a simple, single-speed shutter and a winding key to advance the film. The camera’s back is removable, and removing it turns the rest of the camera into an enlarger which can be used to make prints.<span data-ez-name="kosmofoto_com-box-3"></span></p>
<p>It never makes it into production, but Bostelman’s simple snap-shooter is the first Soviet camera. What comes after this is first a trickle, and then a flood.</p>
<p>Fifty years later, and the Soviet camera industry is the second-largest in the world – second only to Japan, whose bands such as Nikon, Canon, Minolta Olympus and Pentax have become household names. The Soviet Union has its own heavyweights, and between them they have churned out dozens and then hundreds of different camera designs as the decades tick by.</p>
<p>Thanks to a mix of espionage, war reparations, ingenious design and a desire to show the West a thing or two, the USSR’s camera makers come up with a Soviet answer to almost every camera type made in the West, though not necessarily at the same time. Soviet designers devised a myriad of different models, some of the brutishly simple, others showing real flair and ingenuity.</p>
<p>Odd, then, that the entirety of a photographic industry spread across the largest country ever formed and spanning more than 60 years can get judged off first impressions. In the last 20 years, I’ve lost count of the number of times I’ve seen people declaim the quality of all Soviet cameras based off a single flea-market <a href="https://kosmofoto.com/2018/12/zenit-e-russian-camera-review/">Zenit-E</a> which might have mouldering in someone’s basement for the last 30 years.<span data-ez-name="kosmofoto_com-medrectangle-4"></span></p>
<p>This is something I’ve learned having spent the last 20 years collecting and using Soviet cameras. The first one I came across was a Soviet-era <a href="https://kosmofoto.com/2017/06/lomo-lc-a-cameras-lc-wide-lca-120/">Lomo LC-A</a> compact in a camera shop in London’s West End; a solid black rectangle with surprising heft and exotic Cyrillic lettering. That Lomo sparked an enduring love for film cameras of all shapes and sizes, and a particular interest in those made behind the Iron Curtain.</p>
<p>In New Zealand, where I grew up, Soviet cameras were almost unknown. But that wasn’t the case in Western Europe. The boom years of the Soviet photographic industry during the Cold War coincided with a new age of prosperity and consumerism west of Berlin. More people had the money and time to travel, and they wanted cameras with which to document it. The Soviet Union wanted hard currency and had a smorgasbord of cameras that could be sold at subsidised prices. Along with the Praktica cameras of East Germany’s vast Pentacon, Soviet cameras appealed to a huge swathe of photographers with a limited budget.</p>
<figure id="attachment_24709" aria-describedby="caption-attachment-24709"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C.jpg" alt="Zorki-3C (Pic: Paulo Moreira)" width="1000" height="713" srcset="https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C.jpg 1000w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-300x214.jpg 300w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-768x548.jpg 768w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-696x496.jpg 696w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-589x420.jpg 589w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-100x70.jpg?crop=1 100w, https://kosmofoto.com/wp-content/uploads/2021/01/Zorki-3-C-600x428.jpg 600w" sizes="(max-width: 1000px) 100vw, 1000px"><figcaption id="caption-attachment-24709">The Zorki-3C is typical of Soviet rangefinder design from the 1950s and 60s (Pic: Paulo Moreira)</figcaption></figure>
<p><span data-ez-name="kosmofoto_com-box-4"></span>This article – and it’s a big one, so get a drink handy – is an attempt to dispel some of the myths that have developed around Soviet cameras, especially since the 1990s. It’s not trying to pretend that it’s only politics got in the way of the USSR’s cameras, and that every Zenit and Zorki is a match for a Nikon or a Leica. Some of the horror stories you might have heard about Soviet camera quality are 100% true. But not every Soviet camera is a lemon, and some are capable of taking fantastic images if you take the trouble to learn their strengths and, yes, their weaknesses.</p>

<h4><span id="The_big_five"></span><strong>The big five</strong><span></span></h4>
<p>But first, a little history.</p>
<p>The Soviet camera industry was dominated by five big names: <a href="http://camera-wiki.org/wiki/KMZ"><strong>KMZ</strong></a> (<em>Krasnogorskiy Mechanicheskiy Zavod</em>) in Moscow, <a href="https://en.wikipedia.org/wiki/LOMO"><strong>Lomo</strong></a> in St Petersburg, <a href="https://en.wikipedia.org/wiki/Kiev_(brand)"><strong>Kiev-Arsenal</strong></a> and <a href="https://en.wikipedia.org/wiki/FED_(camera)"><strong>FED</strong></a> in Ukraine and <a href="https://vintagecameralab.com/brand/mmz/"><strong>MMZ</strong></a> (the home of BelOMO) in what is now Belarus. Some of these bureaus concentrated on one particular style of camera – FED, for instance, became known for Leica-copy rangefinders they started making in the 1930s and they were kept in production until almost the end of the Soviet Union itself.</p>
<p><a href="https://ko-fi.com/Z8Z2KH28" target="_blank" rel="noopener"><img src="https://az743702.vo.msecnd.net/cdn/kofi2.png?v=0" alt="Buy Me a Coffee at ko-fi.com" height="36"></a> <em>Found this guide useful? Please add a contribution via Ko-Fi. You’ll help pay for the site’s hosting and make sure Kosmo Foto is free to read for years to come.</em></p>
<p>The cameras created ranged from rudimentary compacts simple enough for children to ambitious designs intended to compete with the very best the West had to offer. The latter were a kind of photographic soft power – with no internal market to pay top dollar for them, the higher-spec cameras were touted as evidence of Soviet ingenuity and engineering prowess</p>
<figure id="attachment_22492" aria-describedby="caption-attachment-22492"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2018/12/zenite4-e1590396414210.jpg" alt="Zenit-e (Pic: Stephen Dowling)" width="2000" height="1500"><figcaption id="caption-attachment-22492">The Zenit-E is the most-produced 35mm SLR in history (Pic: Stephen Dowling)</figcaption></figure>
<p>Much simpler cameras were made in Soviet industrial quantities: million after million. This model became the dominant one from the mid 1970s. Camera designers were no longer urged to make cameras to compete with the best of the West, but to tweak tried-and-trusted designs a little each time. You can see this in the successive designs that came after the ubiquitous Zenit-E SLR and Lomo’s simple <a href="https://en.wikipedia.org/wiki/Smena_(camera)">Smena viewfinder camera</a>. Despite cosmetic changes on the outside, underneath little changed from camera to camera.</p>
<p>A leading Soviet camera collector named Viktor Suglob recently produced a Russian-language book called ‘<a href="http://ussrphoto.com/Wiki/default.asp?WikiCatID=39&amp;ParentID=4&amp;ContentID=311&amp;Item=1200+Cameras+from+USSR+by+Suglob%2C+Shaternik%2C+Kochergin">1200 Soviet Cameras</a>’, an encyclopaedia of almost every prototype and production camera devised over nearly 75 years of the USSR. Many of these, of course, were never produced beyond a few samples or pre-production models. But hundreds of designs did make it into production. Today, millions of these cameras – from KMZ and Lomo, MMZ and FED – still survive in working condition.</p>
<h4><span id="The_major_models"></span><strong>The major models</strong><span></span></h4>
<p>If you’re curious about Soviet cameras, you’ll find the easily available cameras falling into seven main groups:<span data-ez-name="kosmofoto_com-large-leaderboard-2"></span></p>
<ul>
<li><strong>Leica copy rangefinders:</strong> Mostly made by FED in Kharkiv in the Ukraine and under the “Zorki” name from KMZ in Moscow. These cameras use the same <a href="https://camerapedia.fandom.com/wiki/39mm_screw_lenses">L39 screw mount</a> that Leica rangefinders did up until the mid-1950s. These cameras were produced, in various forms, until the early 1990s.</li>
<li><strong>Contax-style rangefinders:</strong> The Kiev brand started out copying the Contax II rangefinder produced in Germany before the war, initially with Contax parts taken as war reparations. The “<a href="http://camera-wiki.org/wiki/Kiev_rangefinder">Kiev Contax</a>” line of cameras was made until the late 1980s</li>
<li><strong>Zenit SLRs:</strong> KMZ produced the Soviet Union’s widest array of SLR cameras under the Zenit name. The earliest versions were little more than a <a href="https://en.wikipedia.org/wiki/Zorki_1">Zorki rangefinder</a> with a reflex prism attached, but the line grew more popular in the late 1960s with the Zenit-E, the first Soviet SLR to use the M42-screw mount. M42 Zenits were made until the early 2000s, and a narrower range of cameras from the mid-1980s until the mid-2000s used the Pentax K mount. Lomo, and Kiev also produced SLRs, but these are far less common.</li>
<li><strong>Simple viewfinder cameras:</strong> Both Lomo in St Petersburg and MMZ in Minsk produced very similar families of snapshooters, rectangular viewfinder cameras with a simple shutter and a three-element glass lens. MMZ’s were called <a href="https://camerapedia.fandom.com/wiki/Vilia">Vilia</a> and Lomo’s were known as Smenas. Just two Smenas – the <a href="https://kosmofoto.com/2020/03/these-are-the-most-produced-35mm-cameras-of-all-time/">Smena-8 and the 8M</a> – were built to the tune of around 21 million, making them the most-produced 35mm cameras of all time. These cameras are cheap and rudimentary, but their glass lens definitely elevate them out of toy camera territory.</li>
<li><strong>Simple TLRs:</strong> Medium format cameras were not produced in the same breadth and scale as 35mm cameras, but there were still some successful models. The <a href="https://en.wikipedia.org/wiki/Lubitel">Lubitel family</a> of cheap 120-format TLRs are the easiest to find. Built out of plastic but with glass Triplet-style lenses, these Lomo-made cameras were produced from the 1940s until after the fall of the Soviet Union.</li>
<li><strong>Medium format SLRs:</strong> The Soviet Union’s equivalent to the <a href="https://www.japancamerahunter.com/2019/04/camera-geekery-pentax-67/">Pentax 67</a> was the <a href="https://vintagecameradigest.wordpress.com/2016/09/08/the-kiev-6c-a-photographic-artifact-of-the-cold-war/">Kiev-6C</a>, which eventually evolved into the <a href="http://mattsclassiccameras.com/slr/kiev-60/">Kiev-60</a>. These are big, heavy SLR cameras with a rougher finish than their Western counterparts but with a range of very well-regarded lenses.</li>
<li><strong>Hasselblad-style medium-format cameras: </strong>The Kiev factory also produced a series of Hasselblad-style focal plane cameras, the Kiev-80 and <a href="http://camera-wiki.org/wiki/Kiev_88">88</a> being the best-known of them. The lenses made for the Kiev-6/60 were also produced for some versions of this camera range. They are cheap – especially compared to Hasselblads – but they don’t come with a great reputation for reliability.</li>
</ul>
<p>There were many other brands and minor camera ranges made in the USSR (the plucky Lomo LC-A compact spawned a movement in photography all on its own), but these are the main ones. They are all reasonably easy to find – very easy in the case of Zenit SLRS and FED rangefinders – and there’s no shortage of spare parts or repairers that can coax them back to life should anything be wrong.</p>
<p>Kosmo Foto released the video below last year as a guide for common models to investigate:</p>
<p><iframe src="https://www.youtube.com/embed/wGlfbl5Oa_k" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<h4><span id="Better_dead_than_Red"></span><strong>Better dead than Red?</strong><span></span></h4>
<p>Make no mistake – many film camera shooters regard Soviet cameras as uniformally awful, junk that should live in a landfill rather than a camera cabinet. Most of these photographers would sooner cut off a limb than handle a clunky Zenit or Zorki.</p>
<p>But the Soviet camera industry had peaks and troughs – periods when construction and quality control were high and times when standards were lax and reliability low. A Soviet rangefinder from the mid-1950s is from a very different system to one produced in the “Year of Stagnation” of the late 1970s.</p>
<figure id="attachment_21874" aria-describedby="caption-attachment-21874"><img loading="lazy" src="https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder.jpg" alt="Zorki 1 (Pic: Paulo Moreira)" width="1840" height="1840" srcset="https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder.jpg 1840w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-300x300.jpg 300w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1024x1024.jpg 1024w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-150x150.jpg 150w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-768x768.jpg 768w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1536x1536.jpg 1536w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-696x696.jpg 696w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-1068x1068.jpg 1068w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-420x420.jpg 420w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-600x600.jpg 600w, https://kosmofoto.com/wp-content/uploads/2020/04/Zorki-1-Jupiter-12-with-external-viewfinder-100x100.jpg 100w" sizes="(max-width: 1840px) 100vw, 1840px"><figcaption id="caption-attachment-21874">The Zorki 1, fitted here with an external turret finder for different lenses (Pic: Paulo Moreira)</figcaption></figure>
<p>The bad reputation which Soviet cameras isn’t undeserved,” says Jay Javier, the Filipino photographer and camera collector behind the <a href="https://www.fedka.com/jay/">Fed Zorki Survival Site</a>. “Many were really badly designed or made. As these creatures become more known, thanks to the internet, the bad ones get to be publicly shamed and justly avoided. Many of the generalisations in this respect turn out to be valid.”</p>
<p>Soviet quality control, especially in later years, sometimes left a lot to be desired. Cameras leaving the factory were supposed to be inspected and given a passport signed by a factory foreman ensuring they were working correctly. This The older …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/">https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/</a></em></p>]]>
            </description>
            <link>https://kosmofoto.com/2021/01/read-this-before-you-buy-a-soviet-camera/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26290128</guid>
            <pubDate>Sun, 28 Feb 2021 02:31:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How fighting games use delay-based and rollback netcode (2019)]]>
            </title>
            <description>
<![CDATA[
Score 293 | Comments 106 (<a href="https://news.ycombinator.com/item?id=26289933">thread link</a>) | @Kinrany
<br/>
February 27, 2021 | https://ki.infil.net/w02-netcode.html | <a href="https://web.archive.org/web/*/https://ki.infil.net/w02-netcode.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<div>
					<div id="content">

						<!-- Content -->
					
							<article>

								<div>
								
								<div>
								<p><a href="https://ki.infil.net/words.html">
								<img src="https://ki.infil.net/images/words/header.gif"></a>
								
								</p></div>
								
								
								
								
								<hr>
								
								<div>
								
								<div>
								<p>Netcode</p>
								<p>Explaining how fighting games use delay-based and rollback netcode</p>
								<p>October 16, 2019</p>
								
								
								
								
								</div>
								
								</div>
							
								
								<!-- blog navigation -->
								
								
								

								<div>
								<div><p>
								<em>I would like to thank <a href="https://twitter.com/Krazhier">krazhier</a> and <a href="https://twitter.com/TheKeits">Keits</a> for taking hours out of their busy schedules to discuss technical aspects of netcode with me, and <a href="https://twitter.com/Sajam">Sajam</a> for taking time to answer interview questions and being supportive throughout the writing process. I would also like to especially thank <a href="https://twitter.com/MagicMoste">MagicMoste</a> for making all the wonderful videos you see in this article. All their help was offered for free and I am thankful for their friendship.
								</em></p><p><em>

								This article has been <a href="https://arstechnica.com/gaming/2019/10/explaining-how-fighting-games-use-delay-based-and-rollback-netcode/">cross-posted on Ars Technica</a>.
								</em></p><p><em>

								You may also enjoy <a href="https://www.youtube.com/watch?v=1RI5scXYhK0">watching a video feature</a> on the topics in this article.
								</em>							
								</p></div>
								</div>

								
															
								<!-- Infil -->
								<div><p><img src="https://ki.infil.net/images/words/infil_smiling_2.jpg"></p>
								<p>
								Welcome back to Fightin’ Words! It’s been a while since we last discussed how the <a href="https://ki.infil.net/w01-bugs.html">most famous fighting game bugs</a> have impacted the community’s favorite games. Today’s topic is a bit more technical, but it’s an equally important factor in how our favorite modern games are played -- we’re going to be doing a <strong>deep dive into netcode</strong>.								
								</p>
								</div>

								<hr><!-- Infil -->
								<div><p><img src="https://ki.infil.net/images/words/infil_lecture.jpg"></p>
								<div><p>
								At its core, netcode is simply a method for two or more computers, each trying to play the same game, to talk to each other over the internet. While local play always ensures that all player inputs arrive and are processed at the same time, <strong>networks are constantly unstable</strong> in ways the game cannot control or predict. Information sent to your opponent may be delayed, arrive out of order, or become lost entirely depending on dozens of factors, including the physical distance to your opponent, if you’re on a WiFi connection, and whether your roommate is watching Netflix.
								</p><p>
								Online play in games is nothing new, but fighting games have their own set of unique challenges. They tend to involve direct connections to other players, unlike many other popular game genres, and <strong>low, consistent latency</strong> is extremely important because muscle memory and reactions are at the core of virtually every fighting game. As a result, two prominent strategies have emerged for playing fighting games online: <strong>delay-based netcode</strong> and <strong>rollback netcode</strong>. 
								</p></div>
								</div>

								<div><p><img src="https://ki.infil.net/images/words/infil_thoughtful.jpg"></p>
								<div><p>
								There’s been a renewed passion in the fighting game community that <strong>rollback is the best choice</strong>, and fighting game developers who <a href="https://www.youtube.com/watch?v=qW61xJNJ9m8">choose to use delay-based netcode</a> are <a href="https://www.youtube.com/watch?v=iTUtnclr2hs">preventing the growth of the genre</a>. While people have been passionate about this topic <a href="https://www.youtube.com/watch?v=Tu2kAdmUCaI&amp;t=42m34s">for many years</a>, frustrations continue to rise as new, otherwise excellent games repeatedly have bad online experiences.
								</p><p>

								There are relatively few easy-to-follow explanations for what exactly rollback netcode is, how it works, and why it is so good at hiding the effects of bad connections (though <a href="http://mauve.mizuumi.net/2012/07/05/understanding-fighting-game-networking.html">there are some</a>). Because I feel this topic is extremely important for the future health of the fighting game community, I want to help squash some misconceptions about netcode and explain both netcode strategies thoroughly so everyone can be informed as they discuss. If you stick around to the end, I’ll even <strong>interview some industry experts and community leaders</strong> on the topic!
								</p><p>
								Before we dig into the details, though, let’s get one thing straight.
										
								</p></div>
								</div>

								<hr><!-- Infil -->
								<!-- header -->
								

								<div><p><img src="https://ki.infil.net/images/words/infil_smiling_3.jpg"></p>
								<div><p>
										Both companies and players should care about good netcode because <strong>playing online is no longer the future -- it's the present</strong>. 
								</p><p>
										While most other video game genres have been this way for a decade or longer, fighting game developers seem to be resistant to embracing online play, perhaps because of the genre’s roots in offline settings such as arcades and tournaments. Playing offline is great, and it will always have considerable value in fighting games, but it’s simply a reality that <strong>a large percentage of the player base will never play offline</strong>. For many fighting game fans, playing online <em>is</em> the game, and a bad online experience prevents them from getting better, playing or recommending the game to their friends, and ultimately causes them to <a href="https://youtu.be/iTUtnclr2hs?t=758">simply go do something else</a>.
								</p><p>
										Even if you think you have a good connection, or live in an area of the world with robust internet infrastructure, good netcode is still mandatory. Plus, lost or delayed information happens regularly even on the best networks, and poor netcode can <a href="https://twitter.com/john_takeuchi/status/1162562266027327488">actively hamper matches</a> no matter how smooth the conditions may be. Good netcode also has the benefit of connecting regions across greater distances, effectively uniting the global player base as much as possible.

										<!-- gif 1A -->
										</p><div><!-- image -->
											<figure>
												
											<figcaption>Bad netcode can ruin matches. This match, played online between two Japanese players, impacted who gets to attend the Capcom Pro Tour finals. <a href="https://twitter.com/john_takeuchi/status/1162562266027327488">(source)</a>
											</figcaption></figure></div>
										
								</div>
								</div>

								<div><p><img src="https://ki.infil.net/images/words/infil_content.jpg"></p>
								<div><p>
										What about those who never play online because they much prefer playing offline with their friends? The <strong>healthy ecosystem</strong> that good netcode creates around a game benefits everyone. There will be more active players, more chances to consume content for your favorite game -- from tech videos to spectating online tournaments to expanding the strategy of lesser-used characters -- and more excitement surrounding your game in the FGC. Despite <a href="http://ki.infil.net/">Killer Instinct</a>’s pedigree as an excellent game, there’s no doubt that its superb rollback netcode has played a huge part in the sustained growth of its community.
								</p><p>

										Good netcode matters, period. So let’s talk about it.
										
								</p></div>
								</div>
								
								
								<!-- blog navigation -->
								
								
								

								</div>
								
							</article>
				
					</div>
				</div>
			</section></div>]]>
            </description>
            <link>https://ki.infil.net/w02-netcode.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289933</guid>
            <pubDate>Sun, 28 Feb 2021 01:47:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Good Enough” Architecture]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26289677">thread link</a>) | @zwliew
<br/>
February 27, 2021 | https://mrh.io/notes/stefan-tilkov-good-enough-architecture/ | <a href="https://web.archive.org/web/*/https://mrh.io/notes/stefan-tilkov-good-enough-architecture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Adaptive Leadership for Technical Projects</strong></p><div><div><div><dl><dt><span role="img" aria-label="">🌌 </span><a href="https://github.com/orbitdb/orbit-db" target="_blank">OrbitDB</a></dt><dd>P2P databases for the distributed web, build on CRDTs</dd><dt><span role="img" aria-label="">🦀 </span><a href="https://github.com/ipfs-rust/rust-ipfs" target="_blank">Rust IPFS</a></dt><dd>A Rust implementation of the Interplanetary File System</dd></dl></div><div><dl><dt><span role="img" aria-label="">📈 </span><a href="https://tallylab.com/" target="_blank">TallyLab</a></dt><dd>A privacy-first, end-to-end encrypted time-series data platform</dd><dt><span role="img" aria-label="">⚓ </span><a href="https://github.com/hackforthesea/2020" target="_blank">Hack for the Sea</a></dt><dd>An annual hackathon where technology and the ocean meet.</dd></dl></div></div></div><p><small>This website does not track you.<br>The best way to reach out is via <a href="mailto:mark@mrh.io">e-mail</a>.</small></p><div><h2>by Stefan Tilkov</h2><p>April 01, 2020<!-- --> ｜ <span><a href="https://mrh.io/notes/tags/talk%20notes">Talk Notes</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/goto%202019">GOTO 2019</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/stefan%20tilkov">Stefan Tilkov</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/software%20architecture">Software Architecture</a><span>, </span></span><span><a href="https://mrh.io/notes/tags/microservices">Microservices</a></span></p><div><p> <iframe src="https://www.youtube.com/embed/PzEox3szeRc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>
<center>
<p><a href="https://mrh.io/notes/stefan-tilkov-good-enough-architecture/@stilkov">@ stilkov</a> |
<a href="https://files.gotocon.com/uploads/slides/conference_16/846/original/2019-10-23-Good-Enough-Architecture--GOTO.pdf">slides</a> |
<a href="https://www.youtube.com/watch?v=PzEox3szeRc">video</a></p>
</center>
<p><strong>Abstract:</strong> In this session, we’ll take a look at some of the ways we can determine whether the development efforts we’re undertaking suffer from too much or too little focus on architecture. We’ll examine a number of real-world examples that are intended to inspire either admiration or terror, and try to find some recipes of how we can get more of the former and less of the latter in our own projects.</p>
<hr>
<h2>Definitions of Architecture</h2>
<p><a href="http://www.iso-architecture.org/ieee-1471/cm/">ISO/IEC/IEEE 42010</a>:</p>
<blockquote>
<p>Fundamental concepts or properties of a system in its environment embodied in its elements, relationships, and in the principles of its design and evolution</p>
</blockquote>
<p><a href="https://handbookofsoftwarearchitecture.com/">Grady Booch</a>:</p>
<blockquote>
<p>Architecture represents the significant design decisions that shape a system, where significant is measured by <em>cost of change</em></p>
</blockquote>
<p>Stefan Tilkov:</p>
<blockquote>
<p>Whatever the architect considers important enough to merit their attention</p>
</blockquote>
<p><span>
      <a href="https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/d43b4/software-scaling-dimensions.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Graph of software scaling dimensions" title="Graph of software scaling dimensions" src="https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/fcda8/software-scaling-dimensions.png" srcset="https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/12f09/software-scaling-dimensions.png 148w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/e4a3f/software-scaling-dimensions.png 295w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/fcda8/software-scaling-dimensions.png 590w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/efc66/software-scaling-dimensions.png 885w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/c83ae/software-scaling-dimensions.png 1180w,
https://mrh.io/static/eb7d86f249430088e95925b46b67d9d9/d43b4/software-scaling-dimensions.png 1202w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p><em>Different organizations and applications will require different architectures, and those architectures will change over time</em></p>
<h2>Cases:</h2>
<h3>#1 Non-Extensible Extensibility</h3>
<p>Highly customizable multi-tenant e-commerce solution with lots of features, which has to balance between large customers with specific needs and small customers with generic needs</p>
<ul>
<li>If you attempt to design something that satisfies everybody, you will satisfy nobody.</li>
<li>Highly specific is often preferable to generic</li>
</ul>
<h3>#2 Perilously fine-grained</h3>
<p>Large-scale B2B food retailer building a new logistics system, hired &gt;200 developers to build a microservice-based system. Each developer “owned”
a microservice, which was hell to scale. Eventually moved away from ‘EntityService’ pattern</p>
<ul>
<li>Everybody wants to be <a href="https://www.youtube.com/watch?v=CZ3wIuvmHeM">Netflix</a> but nobody is</li>
<li>Small is not always beautiful</li>
<li>Refactoring within team boundaries much easier than globally</li>
<li>Ignore organizational parameters at your own risk</li>
</ul>
<h3>#3 Your system WILL be dynamic</h3>
<p>Large-scale insurance system with &gt;100 developers. 2 releases / year with 2-week modeling period  What if you miss this slot?</p>
<ul>
<li>Centralized responsibility hurts</li>
<li>Faces with too much rigidity, a way around the rules will be found</li>
<li>Just because you’re used to it doesn’t make it acceptable</li>
</ul>
<h3>#4 Free-style Architecture</h3>
<p>A small E-Commerce / Online shop which grew fast to 100-120 developers over ~10 self-contained teams</p>
<ul>
<li>Avoid increasing the numbers of developers if you can</li>
<li>Move to system of systems</li>
<li>If you don’t actively create an architecture, be prepared to deal with the one that emerges.</li>
<li>Loose coupling requires very few rules, but they need to be enforced strictly</li>
</ul>
<p><span>
      <a href="https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fe8a7/strength-of-decoupling.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Strength of decoupling" title="Strength of decoupling" src="https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fcda8/strength-of-decoupling.png" srcset="https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/12f09/strength-of-decoupling.png 148w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/e4a3f/strength-of-decoupling.png 295w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fcda8/strength-of-decoupling.png 590w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/efc66/strength-of-decoupling.png 885w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/c83ae/strength-of-decoupling.png 1180w,
https://mrh.io/static/7af498861373ca5607fa68e05f221a8a/fe8a7/strength-of-decoupling.png 1223w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3>#5 Cancerous Growth</h3>
<p>Financial services provider with independent brokers as clients, 20 years of company history. Spun off new company and just copied system and then <em>shared the database</em>. Also implemented own encryption in Borland C++ and noticed bug after encryption own database</p>
<ul>
<li>Successful systems often end up with the worst architecture</li>
<li>Unmanaged evolution will lead to complete chaos</li>
<li>Don’t be afraid of some light architectural governance</li>
</ul>
<h3>#6 Improve with less intelligence</h3>
<p>Bank with multiple CotS systems, phased out proprietary solution to replace with OSS. Replaced “Magical Integration Broker” with much more simple dockerized pubsub solution.</p>
<ul>
<li><a href="https://martinfowler.com/articles/microservices.html">Smart endpoints, dumb pipes</a> AKA never put too much logic or intelligence into infrastructure</li>
<li>Valuespecific over generic solutions</li>
</ul>
<h2>Final Takeaways</h2>
<ol>
<li>Don’t be afraid of architecture</li>
<li>Choose the simplest thing that will work</li>
<li>Create evolvable structures</li>
<li>Manage your system’s architectural evolution</li>
<li>Don’t create road blocks - create value and get out of the way</li>
</ol>
<p>Have a talk you want to see notes on? E-mail <a href="mailto:mark@mrh.io">mark@mrh.io</a></p></div><hr><ul><li><a rel="prev" href="https://mrh.io/ipfs-private-networks/">← <!-- -->Private IPFS Networks</a></li><li><a rel="next" href="https://mrh.io/notes/interledger/">Notes: Interledger Architecture<!-- --> →</a></li></ul></div></div></div>]]>
            </description>
            <link>https://mrh.io/notes/stefan-tilkov-good-enough-architecture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26289677</guid>
            <pubDate>Sun, 28 Feb 2021 00:54:15 GMT</pubDate>
        </item>
    </channel>
</rss>
