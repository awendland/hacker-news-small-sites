<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 01 Oct 2020 04:26:33 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 01 Oct 2020 04:26:33 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[What is the C++ standard library?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625526">thread link</a>) | @bvaldivielso
<br/>
September 29, 2020 | https://cor3ntin.github.io/posts/std/ | <a href="https://web.archive.org/web/*/https://cor3ntin.github.io/posts/std/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><a href="https://xkcd.com/2347/">
<img src="https://imgs.xkcd.com/comics/dependency.png">
</a>
</p>
<hr>
<p><strong>DISCLAIMER</strong></p>
<p>The following represent my opinions, not that of the C++ committee (WG21), any of its members or any other person mentioned in this article.</p>
<hr>
<p>I think the most fundamental work done by WG21 is trying to answer meta-questions about itself.
What is C++, what is its essence, what should we focus on? How to evolve a language with a growing community,
a growing committee?
A language that is deployed on billions of devices, with an estimated 50 billions actively maintained lines of code.
During a CppCon panel last week I was asked about stability VS evolution. This is a hot topic,
one that may never stop being on people’s mind.</p>
<p>There are a lot of interesting meta-questions worth asking about the standard library too.
A question that comes over and over again, is what does it mean to deprecate something, why and when.
Another is what to put in there to begin with.</p>
<p>I wrote a few times on the subject <a href="https://cor3ntin.github.io/posts/what_should_go_in_stl/">before</a>,
hopefully, I will be self-consistent. Not promising anything!</p>
<p>Bryce Adelstein Lelbach, then chair of LEWGI coined the phrase</p>
<blockquote>
<p>Knowing that our resources are scarce and our time is limited, do we want to give more time to this proposal?</p>
</blockquote>
<p>This has become somewhat of a meme in the committee.
Since then, we shipped C++20, Bryce became chair of LEWG (which is a super difficult job that he does brilliantly),
and oh. There is this pandemic you might have heard about.</p>
<p>Never have the scarcity of our resources and the limitedness of our time be more apparent.</p>
<p>We try to make the best of the situation, but I think it’s fair to say that WG21’s output is
reduced. And frankly, we cannot ask of anyone to prioritize C++ standardization with all that’s going on right now.
But even at the best of times, C++ library design is a costly, lengthy process involving a lot of people.
Which is good, <a href="https://en.wikipedia.org/wiki/Linus%27s_law">Linus’s law</a>, plays a huge role in the quality of the standard library.</p>
<p>I don’t know that this used to be a question anyone asked. For a very long time, there were few enough proposals
that they virtually could accept all of those they liked.
At the beginning of the committee, there even was a single pipeline for both language and library.
We can argue whether the separation of rooms we have today is always sensible.
Most of the time library features can be added without new language proposal, but at the same time ADL, customization points,
overload sets etc have been growing pain point for the library, and no organization can escape Conway’s law.</p>
<p>Anyway, the influx of new proposal has grown enough in the past few years that LEWG has now the luxury
and the burden to chose which direction to go in and how to use its far too limited time.</p>
<h2 id="standardization-is-expensive">Standardization is expensive</h2>
<p>I think the life cycle of a library feature goes a bit like this:</p>
<ul>
<li>Someone floats an idea and write a paper</li>
<li>The paper is matured over 1-10 years</li>
<li>There is some latency for implementations (6 months - 5 years) - at least 3 or 4 implementations</li>
<li>There is a ton of latency in deploying toolchains where people can use them (this might be a story for another day)</li>
<li>There is a literal ton of people writing blog posts / textbooks / conference talks about that one feature</li>
<li>Then there is a slow adoption and debate about whether adopting the feature is good or not</li>
</ul>
<p>And every step is resources constrained. Deprecation and removal is also very slow.
People are still using components that were deprecated 10, 20 years ago.</p>
<p>Critical flight software at NASA is estimated at 1000$ per line.
I wouldn’t be surprised if the standard library costs more.
And so, one of the way to answer
“Should that piece of code be in the standard” can maybe be reformulated as “Would this benefit from the standardization process?”</p>
<p>Fundamentally, that makes the standard library a bad package manager.
If the only motivation for something to be in the standard is to palliate to the lack of good package managers,
then it’s probably not a good motivation.
(Especially as the standard library is super bad at availability. it will be years until <code>&lt;ranges&gt;</code> is everywhere.)</p>
<p>Of course, that argument falls flat if you consider <code>std::vector</code>. It doesn’t <em>need</em> to be there, but we are all sure glad it is.
So there is an <em>universality</em> argument to be made too.
If something is universally useful (for example, 90% of programs would use it), then it starts to be a very compelling
feature for the standard library.</p>
<p>Some features can’t live anywhere but in the STL:</p>
<p>Type traits, and everything that needs or benefits from compiler magic and intrinsics.
<a href="http://eel.is/c++draft/support.srcloc">source_location</a>, <a href="https://wg21.link/p0881r6">std::stacktrace</a>, <a href="https://wg21.link/p1885r2">encoding detection</a>,
Reflection support library and other introspection capabilities, <a href="https://wg21.link/p0627r3">std::unreachable</a>, <a href="https://wg21.link/p1773r0">std::assume</a>,
<a href="https://wg21.link/p1040r6">std::embed</a>.
All of these are magic and rely on the compiler. In other words they cannot be implemented portably outside of the standard library.
These are necessary for communicating between user code and compiler, and are the basis of higher-level components.
A logger would use <code>std::source_location</code> for example.</p>
<p>This is especially true of reflection: until C++ gets reflection, an entire class of program cannot be written.
Pattern matching make it possible to write cleaner code. Reflection make it possible to write… code.
Code that you cannot otherwise emulate in standard C++, regardless how much you try.
And that can be pretty expensive across the industry.</p>
<p>So library components that make new things possible are high on the list of the things I think should go in the standard library.</p>
<p>Then, even more obvious, come amelioration to what’s already there.
As standard types get deployed, the committee has to improve them. Both in response to usage experience and to increase synergy between types
or add obvious features that were missing, bug fix, support for new language features.
As such, this <a href="https://wg21.link/p1679r3">std::string::contains</a> proposal might not be the most exciting that will land in 23,
but it might be one of the most useful for many people.</p>
<p>This is the rationale for my own  <a href="https://wg21.link/p2019r0">thread name proposal</a>.
It is not possible to name threads created by <code>std::thread</code>,
and people who rely on that (for ex. the game industry) need to write an entire thread class to replace <code>std::thread</code>, just for this extra piece of functionality.
Other people might give a name to their threads if it’s easy, but might not bother if it implies reimplementing <code>std::thread</code> themselves.
The cost/benefit of using a feature decreases if that feature is present in the standard library. But that is mostly true for small quality-of-life features,
not larger features that are application critical.</p>
<p>There are also vocabulary types: types that are designed to be the glue between libraries, a universal language for interface boundaries.
These get used everywhere. We spend a lot of time getting them right because of this by-design pervasiveness. <code>std::span</code> might simultaneously
be the simplest type of C++20 and also the one that took the most work getting right.
One example of glaringly missing vocabulary type is <a href="https://wg21.link/p1059r0"><code>std::expected</code></a>:
A type that is a bit stuck in another super important meta-conversation: What are the error handlings mechanism that should be used and promoted in C++?
We still have to answer that question.</p>
<p>But… I am not sure types are the right kind of entities at interfaces boundary.
Concepts make for a better vocabulary because they prescribe interfaces, not implementations. (<code>span</code> is nothing if not ““template erasure”” over any <code>contiguous_range</code>).
So maybe the standard library should mainly provide concepts to tie all 3rd parties together? The <code>&lt;concept&gt;</code> header is a good start here.</p>
<p>There is however an issue with just trying to add concepts in the standard.
Concepts are informed by concrete types and how they are used, they cannot be pulled out of thin air. Not without making mistakes anyway, and <a href="https://www.youtube.com/watch?v=v_yzLe-wnfk">concepts are not amendable to mistakes</a>.</p>
<p>So, it would seem that if the STL is to have concepts, it need algorithms.</p>
<blockquote><p lang="en" dir="ltr">Generic Programming pro tip: Although Concepts are constraints on types, you don't find them by looking at the types in your system. You find them by studying the algorithms.<a href="https://twitter.com/hashtag/cpp?src=hash&amp;ref_src=twsrc%5Etfw">#cpp</a></p>— Eric Niebler (@ericniebler) <a href="https://twitter.com/ericniebler/status/990390059579789312?ref_src=twsrc%5Etfw">April 29, 2018</a></blockquote>


<p>Good algorithms are agnostic of domain-specific knowledge and can be used in the widest variety of situations.
Algorithms are not useful to people who write games, or people who make microcontrollers, they are useful to people who write C++.
I’d write better code if I was able to recognise more algorithms.</p>
<p>A focus of C++20 was concepts and ranges, and I hope this remains the case in future versions of C++. views in particular are one of these things people might not actively looked for if available by default.
I sure think <code>views::product</code> is more maintainable than nested loops, but I might not try to find a library that has it, if it’s not in the standard.</p>
<p>So, magic types, vocabulary types, concepts and improvements of existing facilities. A good list of what might be LEWG priorities.</p>
<p>But what about networking, Unicode, processes, 15D graphics, audio, a web engine, ML facilities, JSON parsing, crypto, blockchains, Http, event handling, regexes that don’t suck, etc?</p>
<p>These sure make a great front page cover.
But here is the thing:</p>
<p>WG21 is… kinda bad at design?
Not because we are inherently inept, but because library design is fundamentally hard.
And what we understand to be good library design is a somewhat fast-moving target.</p>
<p>The STL is the foundation of the entire C++ ecosystem. And often used to demonstrate how to use new features and write good code. And we try to cover as many use cases as possible.
Design is finding a path in the maze of the design space, and at each crossing, we go in the direction that we think is the most widely useful.
Problem is, the numbers of crossings grows exponentially with the number of abstraction layers or the complexity of the domain.
It soon becomes impossible to please everybody, or even a majority of people.</p>
<p><code>vector</code> has a few knobs: allocation strategies, growth strategies, error handling etc. It’s a manageable number of knobs that we can tweak …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cor3ntin.github.io/posts/std/">https://cor3ntin.github.io/posts/std/</a></em></p>]]>
            </description>
            <link>https://cor3ntin.github.io/posts/std/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625526</guid>
            <pubDate>Tue, 29 Sep 2020 09:18:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Fix PostgreSQL Performance Issues with PG Extras]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625471">thread link</a>) | @todsacerdoti
<br/>
September 29, 2020 | https://pawelurbanek.com/postgresql-fix-performance | <a href="https://web.archive.org/web/*/https://pawelurbanek.com/postgresql-fix-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
    <p><img title="PostgreSQL performance checklist is represented by a notebook Photo by Aaron Burden on Unsplash" alt="PostgreSQL performance checklist is represented by a notebook Photo by Aaron Burden on Unsplash" data-src="https://pawelurbanek.com/assets/postgres-performance-notebook-223d1a2313851e07a649511f2ec7d7d7bbcf49c50cff6fbccf133f7a50a164f1.jpg" src="https://pawelurbanek.com/assets/postgres-performance-notebook-thumb-d32ee718054bdb4e0941997a0fef3c2040885ba2197dfc125668a82f6dea1a0b.jpg">
    </p>
  

  

  <p>PostgreSQL database queries are a common performance bottleneck for web apps. Before you resort to more complex optimization techniques like caching or read replicas, you should double-check if your database engine is correctly tuned and queries are not underperforming.</p>

<p>PG Extras is a tool that allows you to spot common PostgreSQL pitfalls. <a href="https://github.com/pawurb/ruby-pg-extras" target="_blank">Ruby</a>, <a href="https://github.com/pawurb/rails-pg-extras" target="_blank">Rails</a>, <a href="https://github.com/pawurb/ecto_psql_extras" target="_blank">Elixir</a>, and <a href="https://github.com/pawurb/node-postgres-extras" target="_blank">NodeJS</a> implementations are currently available.</p>

<p>In this blog post, I present a step by step guide on using PG Extras library to spot and resolve common PostgreSQL database performance issues.</p>



<p>Please refer to READMEs of respective implementations for installation details.  API is almost identical for all the versions. Let’s compare the invocation of the <code>cache_hit</code> method:</p>

<p><code>Ruby</code></p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>cache_hit</span></code></pre></figure>

<p><code>Rails</code></p>

<figure><pre><code data-lang="ruby"><span>RailsPGExtras</span><span>.</span><span>cache_hit</span></code></pre></figure>

<p><code>Elixir</code></p>

<figure><pre><code data-lang="elixir"><span>EctoPSQLExtras</span><span>.</span><span>query</span><span>(</span><span>:cache_hit</span><span>,</span> <span>YourApp</span><span>.</span><span>Repo</span><span>)</span></code></pre></figure>

<p><code>NodeJS</code></p>

<figure><pre><code data-lang="javascript"><span>PostgresExtras</span><span>.</span><span>cache_hit</span><span>()</span></code></pre></figure>

<p>In this blog post, I’ll be using examples from the pure Ruby version.</p>

<h3 id="enable-pg_stat_statements-extension">Enable <code>pg_stat_statements</code> extension</h3>

<p>Some of the PG Extras methods depend on the <code>pg_stat_statements</code> extension. If you are using a default Heroku PostgreSQL plugin or <a href="https://aws.amazon.com/rds/" target="_blank">AWS RDS</a>, you should be good to go without making any changes.</p>

<p>To check if the extension is already enabled you can use PG Extras itself:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>extensions</span>

<span>...</span>
<span>|</span> <span>pg_stat_statements</span> <span>|</span> <span>1.7</span> <span>|</span> <span>1.7</span> <span>|</span> <span>track</span> <span>execution</span> <span>statistics</span> <span>of</span> <span>all</span> <span>SQL</span> <span>statements</span> <span>executed</span>
<span>...</span></code></pre></figure>

<p>If <code>pg_stat_statements</code> is not listed you should check out <a href="https://www.postgresql.org/docs/current/pgstatstatements.html" target="_blank">these docs</a> for info on installing it.</p>

<p>Now that you’ve set up the library in the language of your choice let’s start checking our database’s health.</p>

<p><strong>[Important]</strong> <em>Make certain to run all the checks on a warmed up production database. Under the hood, PG Extras performs a lightweight queries on PostgreSQL metadata tables. It will not impact your production workload.</em></p>

<h2 id="1-validate-your-database-specs-with-cache-hit-ratios">1) Validate your database specs with cache hit ratios</h2>

<p>In theory, the simplest solution to optimize the underperforming database is to scale it up vertically. Before you start throwing money at your performance issues, it’s good to check if it will actually help.</p>

<p>PostgreSQL tracks access patterns of your data and keeps frequently read chunks in a memory cache. A reliable indicator that a database should be scaled up is an invalid cache hit ratio.</p>

<p>You can check index and table cache hit ratios using the following code:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>cache_hit</span>

      <span>name</span>      <span>|</span>         <span>ratio</span>
<span>----------------+------------------------</span>
 <span>index</span> <span>hit</span> <span>rate</span> <span>|</span>        <span>0.999577</span>
 <span>table</span> <span>hit</span> <span>rate</span> <span>|</span>        <span>0.988721</span></code></pre></figure>

<p>If you want to drill down into each individual’s table and index cache hit ratios, you can use <code>table_cache_hit</code> and <code>index_cache_hit</code> methods.</p>

<p>The rule of the thumb is that values should be above 99%. If your database cache hit ratios are lower, it’s either not correctly configured or should be scaled up to increase the performance.</p>

<p>Heroku PostgreSQL ships with already optimized settings and does not allow you to change them. If you see low cache hit ratios, your best bet is to provision a more powerful database instance.</p>

<p>Amazon RDS is notorious for shipping the database instances with incorrect default settings. If you’re using it, make sure to tweak them before deciding to scale up the instance. <a href="https://pgtune.leopard.in.ua/" target="_blank">PGTune</a> is the best tool to help you tweak the most important Postgres buttons and dials to the correct values.</p>

<h2 id="2-remove-unused-indexes">2) Remove unused indexes</h2>

<p>Overusing indexes is a recipe for a sluggish web app.</p>

<p>The more indexes you add, the more write operations have to be performed on each data update. Misconfigured indexes also tend to unecessarily bloat the size of a database, slowing down the backup/restore/upgrade operations.</p>

<p>It’s entirely possible that some of your indexes and not used and can be safely removed.</p>

<p>PG Extras <code>unused_indexes</code> method can help you spot them:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>unused_indexes</span>

          <span>table</span>      <span>|</span>                       <span>index</span>                <span>|</span> <span>index_size</span> <span>|</span> <span>index_scans</span>
<span>---------------------+--------------------------------------------+------------+-------------</span>
 <span>public</span><span>.</span><span>grade_levels</span> <span>|</span> <span>index_placement_attempts_on_grade_level_id</span> <span>|</span> <span>97</span> <span>MB</span>      <span>|</span>           <span>0</span>
 <span>public</span><span>.</span><span>observations</span> <span>|</span> <span>observations_attrs_grade_resources</span>         <span>|</span> <span>33</span> <span>MB</span>      <span>|</span>           <span>0</span>
 <span>public</span><span>.</span><span>messages</span>     <span>|</span> <span>user_resource_id_idx</span>                       <span>|</span> <span>12</span> <span>MB</span>      <span>|</span>           <span>0</span></code></pre></figure>

<p>Few <code>index_scans</code> on an index that has been around for a while means that it should be removed. If the index is large, remember to use the <a href="https://www.postgresql.org/docs/current/sql-dropindex.html" target="_blank"><code>CONCURRENTLY</code></a> option when dropping it, to avoid exclusively blocking the whole related table.</p>

<p><code>index_size</code> method can give you a quick overview of how much space your database indexes are taking:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>index_size</span>

     <span>name</span>            <span>|</span>  <span>size</span>
<span>-----------------------------------------------</span>
 <span>index_a_name</span>        <span>|</span> <span>5196</span> <span>MB</span>
 <span>index_b_name</span>        <span>|</span> <span>4045</span> <span>MB</span>
 <span>index_b_name</span>        <span>|</span> <span>2611</span> <span>MB</span></code></pre></figure>

<h2 id="3-add-missing-indexes">3) Add missing indexes</h2>

<p>Now that we’ve removed unused indexes, let’s add some new ones. We don’t want them to share the fate of their recently deprovisioned cousins. Let’s look at PG Extras <code>seq_scans</code> and <code>calls</code> methods before deciding on what should be indexed.</p>

<p>A <em>sequential scan</em> is an action that Postgres performs if it cannot find an index necessary to fulfill the query condition. For the following query:</p>

<figure><pre><code data-lang="sql"><span>SELECT</span> <span>*</span> <span>FROM</span> <span>USERS</span> <span>WHERE</span> <span>AGE</span> <span>=</span> <span>18</span><span>;</span></code></pre></figure>

<p>the related <code>EXPLAIN ANALYZE</code> query output will show <code>Seq scan on users Filter: AGE = 18</code> or <code>Index Scan using users_age_index Index Cond: AGE = 18</code> depending on whether the index on <code>age</code> column is present or not.</p>

<p><code>seq_scans</code> method displays the number of <code>Seq Scan</code> operations for each table:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>seq_scans</span>

               <span>name</span>                <span>|</span>  <span>count</span>
<span>-----------------------------------+----------</span>
 <span>learning_coaches</span>                  <span>|</span> <span>44820063</span>
 <span>states</span>                            <span>|</span> <span>36794975</span>
 <span>grade_levels</span>                      <span>|</span> <span>13972293</span>
 <span>charities_customers</span>               <span>|</span>  <span>8615277</span></code></pre></figure>

<p>Now that we know which tables are often read inefficiently, we can use <code>calls</code> and <code>outliers</code> methods to list the most often executed and most time-consuming queries.</p>

<p>Both of those methods let you extract the raw query string. You can use it to perform <code>EXPLAIN ANALYZE</code> and check if the query planner does <code>Seq scan</code> on one of the tables.</p>

<p>By correlating all those sources of data, you should be able to spot queries that are consuming a lot of your database resources and are potentially missing an index.</p>

<p>Watch out to avoid premature optimization by adding unnecessary indexes. PostgreSQL will often fallback to <code>Seq Scan</code> instead of <code>Index Scan</code> on small tables, for which using the index would be less efficient than reading the whole table row by row.</p>

<h2 id="4-identify-deadlocks">4) Identify deadlocks</h2>

<p>PostgreSQL uses locks to ensure data consistency in multithreaded environments. There are different kinds of locks, but we’ll focus on <code>ExclusiveLock</code> and <code>RowExclusiveLock</code>. A healthy web app should never lock for more than a couple of hundred of miliseconds.</p>

<p>Deadlock is two more or database locks blocking each other and not able to continue execution. An implementation error that results in a deadlock might have disastrous consequences for your application. The queue of requests not able to proceed could start piling up and eventually crash your servers.</p>

<p>Common reasons for deadlocks and locks that are granted for too long:</p>

<ul>
  <li>too broad database transaction scope</li>
  <li>adding or removing index without using the <code>CONCURRENTLY</code> option</li>
  <li>updating lots of rows at once</li>
  <li>adding a new column with the default value (before PostgreSQL 12)</li>
</ul>

<h3 id="how-to-detect-locks-and-deadlocks">How to detect locks and deadlocks</h3>

<p>You can use <code>locks</code> method to see all the currently obtained locks together with the source query:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>locks</span>

 <span>procpid</span> <span>|</span> <span>relname</span> <span>|</span> <span>transactionid</span> <span>|</span> <span>granted</span> <span>|</span>     <span>query_snippet</span>     <span>|</span> <span>mode</span>             <span>|</span>       <span>age</span>
<span>---------+---------+---------------+---------+-----------------------+-------------------------------------</span>
   <span>31776</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span> <span>&lt;</span><span>IDLE</span><span>&gt;</span> <span>in</span> <span>transaction</span> <span>|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>29.837898</span>
   <span>31776</span> <span>|</span>         <span>|</span>          <span>1294</span> <span>|</span> <span>t</span>       <span>|</span> <span>&lt;</span><span>IDLE</span><span>&gt;</span> <span>in</span> <span>transaction</span> <span>|</span> <span>RowExclusiveLock</span> <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>29.837898</span>
   <span>31912</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span> <span>select</span> <span>*</span> <span>from</span> <span>hello</span><span>;</span>  <span>|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>19</span><span>:</span><span>17.94259</span>
    <span>3443</span> <span>|</span>         <span>|</span>               <span>|</span> <span>t</span>       <span>|</span>                      <span>+|</span> <span>ExclusiveLock</span>    <span>|</span>  <span>00</span><span>:</span><span>00</span><span>:</span><span>00</span></code></pre></figure>

<p>The mere presence of locks does not mean that something is wrong with your database. Only locks that are granted for too long are potentially problematic. You can use the following Ruby snippet integrated into the background job to alert you if this happens:</p>

<figure><pre><code data-lang="ruby"><span>TRESHOLD_SECONDS</span> <span>=</span> <span>1</span>

<span>long_locks</span> <span>=</span> <span>RubyPGExtras</span><span>.</span><span>locks</span><span>(</span><span>in_format: :hash</span><span>).</span><span>select</span> <span>do</span> <span>|</span><span>lock</span><span>|</span>
  <span>Time</span><span>.</span><span>parse</span><span>(</span><span>lock</span><span>.</span><span>fetch</span><span>(</span><span>"age"</span><span>)).</span><span>seconds_since_midnight</span> <span>&gt;</span> <span>TRESHOLD_SECONDS</span>
<span>end</span>

<span>raise</span> <span>"Long running locks: </span><span>#{</span><span>long_locks</span><span>}</span><span>"</span> <span>if</span> <span>long_locks</span><span>.</span><span>present?</span></code></pre></figure>

<p>If you notice extended locks, you can use the <code>blocking</code> method to check which SQL statements cannot continue execution because of a lock:</p>

<figure><pre><code data-lang="ruby"><span>RubyPGExtras</span><span>.</span><span>blocking</span>

 <span>blocked_pid</span> <span>|</span>    <span>blocking_statement</span>    <span>|</span> <span>blocking_duration</span> <span>|</span> <span>blocking_pid</span> <span>|</span>                                        <span>blocked_statement</span>                           <span>|</span> <span>blocked_duration</span>
<span>-------------+--------------------------+-------------------+--------------+------------------------------------------------------------------------------------+------------------</span>
         <span>461</span> <span>|</span> <span>select</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>from</span> <span>app</span> <span>|</span> <span>00</span><span>:</span><span>00</span><span>:</span><span>03</span><span>.</span><span>838314</span>   <span>|</span>        <span>15682</span> <span>|</span> <span>UPDATE</span> <span>"app"</span> <span>SET</span> <span>"updated_at"</span> <span>=</span> <span>'2013-03-04 15:07:04.746688'</span> <span>WHERE</span> <span>"id"</span> <span>=</span> <span>12823149</span> <span>|</span> <span>00</span><span>:</span><span>00</span><span>:</span><span>03</span><span>.</span><span>821826</span></code></pre></figure>

<p>If your app is crashing because of deadlocks, you can use the <code>kill_all</code> to terminate all the database processes before you manage to resolve the underlying cause.</p>

<h2 id="5-get-rid-of-unnecessary-bloat">5) Get rid of unnecessary bloat</h2>

<p>The way PostgreSQL works is that it never updates or removes the data in place but instead marks each row as visible or not for transactions using two meta columns <code>xmin</code> and <code>xmax</code>. Rows no longer visible for any of the currently active transactions are called <em>dead rows</em> or <em>bloat</em>.</p>

<p>Dead rows are regularly <em>garbage collected</em> by a process called <em>AUTOVACUUM</em>, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pawelurbanek.com/postgresql-fix-performance">https://pawelurbanek.com/postgresql-fix-performance</a></em></p>]]>
            </description>
            <link>https://pawelurbanek.com/postgresql-fix-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625471</guid>
            <pubDate>Tue, 29 Sep 2020 09:06:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When the Impact of Digital Tech on Our Mental Health Begins to Matter]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625172">thread link</a>) | @Lima_Writes
<br/>
September 29, 2020 | https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter | <a href="https://web.archive.org/web/*/https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://lifebeyond.one/blogs/tech-impact/when-the-impact-of-digital-tech-on-our-mental-health-begins-to-matter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625172</guid>
            <pubDate>Tue, 29 Sep 2020 07:57:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep your GitHub forks up to date]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24625051">thread link</a>) | @reconquestio
<br/>
September 29, 2020 | https://samizdat.dev/keep-your-github-forks-up-to-date/ | <a href="https://web.archive.org/web/*/https://samizdat.dev/keep-your-github-forks-up-to-date/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>Sometimes I do fork repositories and do some tweaks here and there for my personal needs which ain’t
really going to be merged into the upstream repository.</p>
<p>One thing that used to concern me is that I needed to manually rebase my changes onto the upstream
to have new goods but keep my changes on top of them.</p>
<p>Fortunately, GitHub Actions supports the <code>schedule</code> trigger for workflows and this is what we are
going to use.</p>
<p>The CI plan is simple and straightforward:</p>
<ul>
<li>Tigger by a schedule or by a manual run.</li>
<li>Fetch &amp; checkout repository.</li>
<li>Specify an upstream Git URL. Unfortunately, GitHub doesn’t expose an environment variable of a
upstream repository (or I didn’t find it).</li>
<li>Rebase onto upstream.</li>
<li>Push changes.</li>
</ul>
<div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span><span>'Rebase'</span><span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>schedule</span><span>:</span><span>
</span><span>    </span>- <span>cron</span><span>:</span><span> </span><span>'*/15 * * * *'</span><span>
</span><span>  </span><span>workflow_dispatch</span><span>:</span><span>
</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>rebase</span><span>:</span><span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>    </span>- <span>uses</span><span>:</span><span> </span>actions/checkout@v2<span>
</span><span>    </span>- <span>uses</span><span>:</span><span> </span>shitiomatic/forkbacon@master<span>
</span><span>      </span><span>with</span><span>:</span><span>
</span><span>        </span><span>upstream_url</span><span>:</span><span> </span><span>"upstream url here"</span><span>
</span><span>        </span><span>upstream_branch</span><span>:</span><span> </span><span>"master"</span><span>
</span><span>        </span><span>branch</span><span>:</span><span> </span><span>"master"</span><span>
</span><span>        </span><span>method</span><span>:</span><span> </span><span>"rebase"</span><span>
</span></code></pre></div><p>Almost there. GitHub doesn’t sync &amp; install schedules for forked repositoies without a manual run or
an additional push. Go to Actions, find Rebase workflow and click on the Run workflow button.</p>
<p>That’s it, really. If the rebase fails, GitHub will send you an email letting you know about it.</p>
</article>

        </div></div>]]>
            </description>
            <link>https://samizdat.dev/keep-your-github-forks-up-to-date/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24625051</guid>
            <pubDate>Tue, 29 Sep 2020 07:33:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing an accessible color palette with magic numbers]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24624914">thread link</a>) | @darekkay
<br/>
September 29, 2020 | https://darekkay.com/blog/accessible-color-palette/ | <a href="https://web.archive.org/web/*/https://darekkay.com/blog/accessible-color-palette/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>A low text contrast is the <a href="https://webaim.org/projects/million/" target="_blank" rel="noopener">most common accessibility issue</a>. 86% of the top 1,000,000 websites have at least one contrast ratio violation, which may lead to a bad user experience. Our favorite orange website isn’t leading by example, either. Some comments are almost unreadable:</p><figure><picture><img src="https://darekkay.com/blog/accessible-color-palette/hacker-news.png" srcset="https://darekkay.com/blog/accessible-color-palette/hacker-news.png, https://darekkay.com/blog/accessible-color-palette/hacker-news-2x.png 2x" alt="Insufficient contrast ratio on Hacker News"></picture><figcaption>Insufficient contrast ratio on Hacker News</figcaption></figure><p>There are various tools that help us <em>identify</em> and <em>fix</em> contrast ratio issues on our websites. This post presents an approach for designing and structuring color palettes so that we can prevent such issues <em>before</em> they arise: “magic numbers”.</p><h2 id="Which-contrast-ratio-is-accessible"><a href="#Which-contrast-ratio-is-accessible" title="Which contrast ratio is accessible?"></a>Which contrast ratio is accessible?</h2><p>How do we know whether the contrast ratio between a text and its background is sufficient? The <em>Web Content Accessibility Guidelines</em> (WCAG) <a href="https://www.w3.org/TR/WCAG20-TECHS/G18.html" target="_blank" rel="noopener">define</a> minimum required contrast ratios, based on colors, text properties (size, boldness) and conformance levels (AA vs. AAA):</p><figure><table><thead><tr><th></th><th>Level AA</th><th>Level AAA</th></tr></thead><tbody><tr><td><strong>small text</strong></td><td>4.5+</td><td>7+</td></tr><tr><td><strong>large text</strong></td><td>3+</td><td>4.5+</td></tr></tbody></table><figcaption>Minimum required contrast ratio values</figcaption></figure><p>Note: <em>large text</em> is defined as <em>19px+ bold</em> or <em>24px+ normal</em>.</p><p>As a rule of thumb, try to go for a <strong>4.5:1</strong> minimum contrast ratio, which will pass <strong>WCAG AA</strong> independent of the text size. This provides a good cost-value trade-off and is often the legal accessibility requirement.</p><p>Calculating the accessibility conformance manually is tedious. Instead, I suggest using a tool like <a href="https://contrast-ratio.com/" target="_blank" rel="noopener">contrast-ratio.com</a>. DevTools in <a href="https://developer.mozilla.org/en-US/docs/Tools/Accessibility_inspector#Color_contrast" target="_blank" rel="noopener">Firefox</a> and <a href="https://umaar.com/dev-tips/236-accessible-colour-suggestions/" target="_blank" rel="noopener">Chrome</a> provide great built-in browser support. Finally, <a href="https://github.com/dequelabs/axe-cli" target="_blank" rel="noopener">axe-core</a> will scan a website for all kinds of accessibility violations.</p><p>Those tools are a great way to find contrast ratio issues, but let me describe a technique to prevent them in the first place.</p><h2 id="Magic-numbers"><a href="#Magic-numbers" title="Magic numbers"></a>Magic numbers</h2><p>Most color palettes divide their colors into grades (e.g. <code>pink-10</code> … <code>pink-90</code>).</p><p>Let’s define a <em>difference between two color grades</em> as <strong>magic number</strong>, e.g.:</p><ul><li>Colors: <code>blue-80</code> and <code>orange-30</code></li><li>Magic number: <code>80 - 30</code> = <code>50</code></li></ul><p>What if we could find a magic number for the whole palette that ensures a sufficient color contrast between two colors? The first time I’ve heard about this concept was in a <a href="https://pspeter3.com/blog/2020/02/19/accessible-contrast-shades/" target="_blank" rel="noopener">blog post</a> from Phips Peter. I’ve learned about the <a href="https://designsystem.digital.gov/design-tokens/color/overview/" target="_blank" rel="noopener">U.S. Web Design System</a> and was immediately hooked. The color system provides the following magic numbers:</p><ul><li>A magic number of <strong>40+</strong> ensures a contrast ratio of <strong>3+</strong></li><li>A magic number of <strong>50+</strong> ensures a contrast ratio of <strong>4.5+</strong></li><li>A magic number of <strong>70+</strong> ensures a contrast ratio of <strong>7+</strong></li></ul><p>By looking at the color names, I know that <code>red-40</code> and <code>gray-90</code> (= <code>50</code>) will definitely pass <em>WCAG AA</em> (required contrast ratio <code>4.5+</code>), while <code>red-60</code> and <code>gray-90</code> (= <code>30</code>) will not. This leads to a <em>fantastic</em> designer/developer experience. I don’t have to use a contrast checker or look anything up to ensure a sufficient contrast ratio. A difference of 50 or more is all I care about.</p><h2 id="Calculating-magic-numbers-for-an-existing-color-palette"><a href="#Calculating-magic-numbers-for-an-existing-color-palette" title="Calculating magic numbers for an existing color palette"></a>Calculating magic numbers for an existing color palette</h2><p>Some libraries define their magic numbers in the documentation, but what about others?</p><p>I have written <a href="https://github.com/darekkay/a11y-contrast" target="_blank" rel="noopener">a11y-contrast</a> to calculate the magic numbers for any color palette that follows a grade naming pattern (e.g. <code>red-20</code>). This tool also finds all violations for any given magic number. This way you can prevent regression issues after adding or adjusting a color value.</p><figure><picture><img src="https://darekkay.com/blog/accessible-color-palette/a11y-contrast.png" srcset="https://darekkay.com/blog/accessible-color-palette/a11y-contrast.png, https://darekkay.com/blog/accessible-color-palette/a11y-contrast-2x.png 2x" alt="CLI output with magic numbers and a list of violations"></picture><figcaption>CLI output with magic numbers and a list of violations</figcaption></figure><p>I’ve calculated the magic numbers for some common color palettes:</p><table><thead><tr><th></th><th>3+</th><th>4.5+</th><th>7+</th></tr></thead><tbody><tr><td><a href="https://designsystem.digital.gov/design-tokens/color/system-tokens/" target="_blank" rel="noopener">USWDS</a></td><td>40</td><td>50</td><td>70</td></tr><tr><td><a href="https://www.ibm.com/design/v1/language/resources/color-library/" target="_blank" rel="noopener">IBM v1</a></td><td>50</td><td>60</td><td>70</td></tr><tr><td><a href="https://github.com/carbon-design-system/carbon/tree/master/packages/colors" target="_blank" rel="noopener">IBM Carbon v2.1</a></td><td>50</td><td>50</td><td>70</td></tr><tr><td><a href="https://tailwindcss.com/docs/customizing-colors/#default-color-palette" target="_blank" rel="noopener">Tailwind v1</a></td><td>60</td><td>70</td><td>80</td></tr><tr><td><a href="https://github.com/tailwindlabs/tailwindcss/pull/2132" target="_blank" rel="noopener">Tailwind v2</a> (proposal)</td><td>50</td><td>60</td><td>80</td></tr><tr><td><a href="https://yeun.github.io/open-color/" target="_blank" rel="noopener">Open Color</a></td><td>-</td><td>-</td><td>-</td></tr></tbody></table><p>Here are my takeaways:</p><ul><li><strong>USWDS</strong> defines <em>by far</em> the most colors (461!), and yet it uses the smallest magic numbers. This leads to a much wider spectrum of allowed color combinations than any of the other color palettes I’ve checked.</li><li><strong>Open color</strong> doesn’t have <em>any</em> magic numbers. This means I cannot reliably derive the contrast ratio from the color naming (e.g., <code>gray-90/red-20</code> is fine, but <code>red-90/red-20</code> is not).</li><li>Both <a href="https://github.com/uswds/uswds/issues/3329" target="_blank" rel="noopener">USWDS</a> and <a href="https://github.com/carbon-design-system/carbon/issues/6130" target="_blank" rel="noopener">IBM Carbon</a> previously contained minor violations, showing the importance of automatic tests.</li></ul><h2 id="Defining-luminance-bounds-with-fixed-magic-numbers"><a href="#Defining-luminance-bounds-with-fixed-magic-numbers" title="Defining luminance bounds with fixed magic numbers"></a>Defining luminance bounds with fixed magic numbers</h2><p>Predefined color palettes are great, but what if we want to change or add a color? What grade does a certain color map to?</p><p>Because the contrast ratio between two colors depends only on their <a href="https://www.w3.org/TR/WCAG20-TECHS/G17.html" target="_blank" rel="noopener">luminance values</a>, it is possible to create a mapping from a color to a grade between 0 and 100. For the USWDS color palette, here are the <a href="https://github.com/uswds/uswds/issues/3329#issuecomment-594762982" target="_blank" rel="noopener">luminance bounds</a>:</p><table><thead><tr><th>grade</th><th>min luminance (%)</th><th>max luminance (%)</th></tr></thead><tbody><tr><td>0</td><td>100</td><td>100</td></tr><tr><td>5</td><td>85</td><td>93</td></tr><tr><td>10</td><td>75</td><td>82</td></tr><tr><td>20</td><td>50</td><td>65</td></tr><tr><td>30</td><td>35</td><td>45</td></tr><tr><td>40</td><td>25</td><td>30</td></tr><tr><td>50</td><td>17.5</td><td>18.3</td></tr><tr><td>60</td><td>10</td><td>12.5</td></tr><tr><td>70</td><td>5</td><td>7</td></tr><tr><td>80</td><td>2</td><td>4</td></tr><tr><td>90</td><td>0.05</td><td>1.5</td></tr><tr><td>100</td><td>0</td><td>0</td></tr></tbody></table><p><a href="https://github.com/thisisdano" target="_blank" rel="noopener">Dan O. Williams</a> — a USWDS maintainer — optimized those values for <em>consistency</em> instead of <em>coverage</em>. This means there are more colors that don’t fit into <em>any</em> bound, even though they would technically pass the WCAG contrast ratio. While this setup is more constraining, I agree with the consistency benefits.</p><blockquote><p>It’s important that our color system be consistent and predictable, that users know what they’re getting when they choose a color of a certain grade. This makes us inclined to favor smaller, more equal ranges, and consistent spacing between ranges.</p></blockquote><p>If you want to calculate the luminance value and the potential USWDS grade of any color, check out my <a href="https://darekkay.com/dev/color-tools.html">Color Tools</a>.</p><picture><source type="image/webp" srcset="https://darekkay.com/blog/accessible-color-palette/color-palette.webp, https://darekkay.com/blog/accessible-color-palette/color-palette-2x.webp 2x"><img src="https://darekkay.com/blog/accessible-color-palette/color-palette.jpg" srcset="https://darekkay.com/blog/accessible-color-palette/color-palette.jpg, https://darekkay.com/blog/accessible-color-palette/color-palette-2x.jpg 2x" alt=""></picture><h2 id="Conclusion"><a href="#Conclusion" title="Conclusion"></a>Conclusion</h2><p>Let me summarize all the theory into some <strong>actionable advice</strong>. There are two ways to create an accessible color palette with <em>magic numbers</em>:</p><ol><li>Create a color palette first and calculate the magic numbers with <a href="https://github.com/darekkay/a11y-contrast" target="_blank" rel="noopener">a11y-contrast</a>. Depending on the colors, the magic numbers might be rather high or even non-existent (see Open Color).</li><li>Define luminance bounds with fixed magic numbers and use only colors that can be mapped. This approach is more constraining and requires more work, but the result is a future-proof and consistent color palette.</li></ol><p>If you don’t want to go through all the work, I suggest you try out the <a href="https://designsystem.digital.gov/design-tokens/color/system-tokens/" target="_blank" rel="noopener">USWDS color palette</a>.</p></div></div></div>]]>
            </description>
            <link>https://darekkay.com/blog/accessible-color-palette/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624914</guid>
            <pubDate>Tue, 29 Sep 2020 07:09:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fun Yet Effective Meetings]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24624819">thread link</a>) | @thesnide
<br/>
September 28, 2020 | https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html | <a href="https://web.archive.org/web/*/https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <blockquote>
  <p>⚠️ This article is extreme &amp; satirical on the purpose of being thought-provoking. Therefore, please, do take it with some grain of salt.</p>

  <p>This is a followup of my <a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working is a paradigm shift</a>.</p>
</blockquote>



<p>My #1 advice about distributed teams is actually even the case in colocated teams:
<strong>Try as hard as possible to avoid meetings, use textual IM instead</strong> as <a href="https://blog.codinghorror.com/meetings-where-work-goes-to-die/">meetings are where work goes to die</a>.
I know it sounds pretty dull, but if you really think about it you’ll see that it’s usually wasted time.
The usual pattern of decision taking is:</p>

<div><div><pre><code>1. if you don’t have a clue, ask someone else.
2. to ask him, schedule a meeting
3. to schedule a meeting, you have to find a slot
4. that usually postpones the decision
</code></pre></div></div>

<p>Postponing the decision is usually what one really wants, even unknowingly: “<em>to be able to have an excuse not to decide at once</em>”.</p>

<p>It’s a very very fair humane reaction, I also fell myself into that trap.</p>

<p><img src="https://blog.pwkf.org/assets/images/out-of-window.jpg" alt="Thrown out of the fence for proposing an textual chat"></p>



<p>I end up having the following workflow:</p>

<ul>
  <li>Avoid email loops. Those have too much overhead, and will divide your audience pretty quickly.</li>
  <li>Create a slack channel instead of the email loop. This will retain the whole conversation in 1 central place.</li>
  <li>Systematically push back on any meetings. Accept them only if you have a clear statement of who will drive it.</li>
  <li>
    <p>Meetings should be a broadcast mode. All the Q&amp;A should go back to the slack channel.</p>

    <ul>
      <li>Having everything searchable makes it super easy for
        <ul>
          <li>newcomers that can simply scroll back</li>
          <li>old timers such as me that forget and can also simply scroll back</li>
        </ul>
      </li>
      <li>
        <p>Even recorded meetings are a vast of time if you need to find an information, as it’s not indexed.</p>
      </li>
      <li>If not recorded, sending the minutes afterwards are usually a loss of information.
        <ul>
          <li>It’s still very important to extract “executive summaries” from those meetings, even only textual. As can be posted on a public place for massive &amp; broad sharing.</li>
          <li>Yet, the real context on those summaries will be kept inside the whole meeting</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<blockquote>
  <p><strong>Context effectively fights Cargo Cult</strong></p>

  <p>Usually the why of decisions are not provided in a “<a href="https://english.stackexchange.com/questions/120739/a-peek-into-the-sausage-factory">build the sausage</a>” manner. But after a while, the hypothesis of the decision are not true anymore, and therefore another decision has to be taken.</p>

  <p>This is not possible when loss of information occurs and that’s when <a href="https://en.wikipedia.org/wiki/Cargo_cult_programming">Cargo cult</a> begins to creep in.</p>
</blockquote>

<p>In a record-everything scenario, context switch is just a matter of reading back some previous messages. Otherwise you’ll spend numerous times “explaining the context” in a meeting to everyone. And then everyone will just move to something else, and you’ll have pitiful engagement, while still spending time on it.</p>

<p><strong>A company that use its time effectively, is a company that moves much faster than its competitors</strong>, no matter the skillsets in that company. Even if you have the brightest minds, if you waste their talents in boring activities, you’ll dry them up. And either they’ll leave, or worse, they <a href="https://www.sbnonline.com/article/the-quit-and-stay-syndrome-a-business-epidemic-thats-a-silent-profit-killer/">quit &amp; stay</a>.</p>

<blockquote>
  <p>💡 This enabled me to scale to a reasonable multitasking ability while curbing its overhead to a manageable level</p>
</blockquote>

<p><strong>That’s why “startups” are so effective</strong> : they are small and therefore very fast. Being fast brings capacity to try &amp; fail, and therefore agility.</p>

<blockquote>
  <p>💡 <strong>time is the only really scarse resource in a company</strong> : you can’t buy it back, no matter the price.</p>
</blockquote>

<h2 id="why-you-should-only-have-fun-ones">Why you should only have fun ones</h2>

<p>That said, I do agree that travelling is necessary. But we should name the real usecase of travelling : having <em>fun</em> <strong>together</strong>.</p>

<p>The nicest part of that purpose is :</p>

<ul>
  <li>you can plan it far in advance</li>
  <li>you can also budget it in advance</li>
  <li>you can mentally map yourself in those fun times, and focus on actual work right now.</li>
</ul>



<p>The most used reason for meetings is “alignments”, but it is very usually wasted as :</p>

<ul>
  <li>There’s always someone missing for that meeting</li>
  <li>No-one really wants to write the minutes out of it</li>
  <li>If written nonetheless, those minutes are only seldom capturing the <em>why</em> the decision is reached. Which is the most important part!</li>
</ul>

<p>The “<em>there’s always someone missing from that meeting</em>” is the worst part, as usually, that is the one that says “what you decided cannot be done”. And you’ll end up with yet another round of thinking at best. At worst you’ll try to shoehorn your precious alignment (that did sink a huge travel budget) into the needs of that missing person.</p>

<blockquote>
  <p>💡 We can draw a parallel to the paradigm shift I mentioned earlier:</p>
</blockquote>

<ul>
  <li><strong>F2F</strong> Meetings are the <strong>monolith</strong> way.</li>
  <li>Informal, dedicated &amp; <strong>textual meetings</strong> are the <strong>micro-services</strong> way.</li>
</ul>

<p>Now, one immediately notices the following:</p>

<ul>
  <li><strong>People are very much at ease with monoliths</strong>. It takes a huge mental leap to go micro-services.</li>
  <li><strong>Micro-services have an overhead</strong>. But no-one will argue that they can scale way better.</li>
  <li>Monoliths can seldomly be distributed the way micro-services can : you’ll quickly end up with that infamous distributed monolith pattern.</li>
</ul>

<blockquote>
  <p>💡 Now, let’s travel only for “team building” purposes.</p>

  <p>You can plan them in advance, and you won’t have over-budget ones. As their outcome is predictable, and if there’s someone missing, it won’t jeopardy the whole travelling.</p>
</blockquote>

<p>A final word of caution, the reference to scaling is <strong>not about runtime performance</strong>. It’s more about <strong>organisation size</strong>. As Martin Fowler said : <em>don’t even consider microservices unless you have a system that’s too complex to manage as a monolith</em>.</p>

<p>So, it usually makes very much sense to start with a small, colocated team, that has traditional meetings. The trick is to recognize the need to change the paradigm when the team grows, as it always done smoothly over the months. Just don’t forget to have good meeting hygiene (written inputs &amp; outputs), as <strong>even monoliths should be nicely modular</strong>.</p>

<blockquote>
  <p>I posted those 2 articles (<a href="https://blog.pwkf.org/2020/09/26/remote-working-is-a-paradigm-shift.html">Remote-mostly working</a>, <a href="https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html">Effective Meetings</a>) internally to my company some years ago, but I’m republishing those publicly to help others the same way it helped us.</p>
</blockquote>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://blog.pwkf.org/2020/09/27/we-should-only-have-fun-meetings.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624819</guid>
            <pubDate>Tue, 29 Sep 2020 06:54:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blur attacks bypass Bluetooth Classic and BLE security mechanisms CVE-2020-15802]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624206">thread link</a>) | @a5withtrrs
<br/>
September 28, 2020 | https://hexhive.epfl.ch/BLURtooth/ | <a href="https://web.archive.org/web/*/https://hexhive.epfl.ch/BLURtooth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      <h2 id="blur-attacks">BLUR attacks</h2>

<p>BLURtooth (the BLUR attacks) exploits the lack of cross-transport key
validation, allowing an attacker to bypass Bluetooth Classic and Bluetooth Low
Energy security mechanisms.</p>

<p>Bluetooth’s cross-transport key derivation (CTKD) is vulnerable to attacks
enabling to attack Bluetooth Classic from Bluetooth Low Energy and vice versa.
A remote attacker in Bluetooth range may impersonate, man-in-the-middle, and
establish malicious sessions with arbitrary devices.</p>

<ul>
  <li><strong><em>Security Impact:</em></strong> device impersonation, man-in-the-middle, malicious
session establishment with arbitrary devices</li>
  <li><strong><em>Affected Devices:</em></strong> the attack is standard compliant, so all BT/BLE
devices supporting CTKD are likely vulnerable; all our tested devices are
vulnerable</li>
  <li>BLURtooth is tracked under <a href="https://kb.cert.org/vuls/id/589825">CVE-2020-15802</a></li>
  <li><strong><em>Credit:</em></strong> Daniele Antonioli and Mathias Payer
from École Polytechnique Fédérale de Lausanne (EPFL),
Nils Ole Tippenhauer from Helmholtz Center for Information Security (CISPA),
and Kasper Rasmussen from University of Oxford.</li>
  <li><strong><em>Contacts at EPFL:</em></strong>
<a href="mailto:daniele.antonioli@epfl.ch,mathias.payer@nebelwelt.net">Daniele Antonioli and Mathias Payer</a></li>
</ul>

<h2 id="summary">Summary</h2>

<p>Here, we provide more details about a set of novel and standard-compliant
Bluetooth vulnerabilities affecting both Bluetooth Classic (BT) and Bluetooth
Low Energy (BLE).  The uncovered vulnerabilities affect a security mechanism
called cross-transport key derivation (CTKD). CTKD is used to improve the
usability of Bluetooth pairing by allowing to generate BT and BLE pairing keys
just by pairing two devices either on BT or BLE (rather than pairing them two
times).</p>

<p>However, we find that CTKD introduces cross-transport security issues and that
an attacker can abuse those issues to attack BT from BLE and vice versa.  In
particular, our attacks enable to impersonate, man-in-the-middle, and establish
malicious sessions with arbitrary devices by abusing CTKD, while defeating all
the security mechanisms put in place by BT and BLE.  Our work is named BLURtooth
and the related attacks are called BLUR attacks as they blur the security
boundary between BT and BLE.</p>

<p>The team behind this work consists of
<a href="https://francozappa.github.io/">Daniele Antonioli</a>
and
<a href="https://nebelwelt.net/">Mathias Payer</a>
from the <a href="https://hexhive.epfl.ch/">HexHive group</a> at
École Polytechnique Fédérale de Lausanne (EPFL),
<a href="https://tippenhauer.de/">Nils Ole Tippenhauer</a>
from Helmholtz Center for Information Security (CISPA), and
<a href="https://www.cs.ox.ac.uk/people/kasper.rasmussen/">Kasper Rasmussen</a>
from the University of Oxford.</p>

<p>In the remainder of this document, we provide information on
technical details, disclosure, impact, our proposed mitigation, the response
from the Bluetooth SIG.</p>

<h2 id="technical-details">Technical Details</h2>

<p>The Bluetooth standard includes two technologies <em>Bluetooth Classic (BT)</em> (also
known as Bluetooth BR/EDR) and <em>Bluetooth Low Energy (BLE)</em>. The majority of
mobile devices, including laptops, smartphones, tablets, headphones, and
smartwatches, support both and are defined as <em>dual-mode</em> Bluetooth devices. To
securely use dual-mode devices over BT and BLE a user has to pair her devices
two times, once for BT and once for BLE. As pairing the same device is
considered <em>user-unfriendly</em>, in 2014, with the release of Bluetooth version
4.2, the Bluetooth standard introduced a security mechanism that allows a user
to pair dual-mode Bluetooth devices once (either over BT or BLE) and then
securely use them both over BT and BLE. This security mechanism is called
<em>cross-transport key derivation (CTKD)</em>, and, as the name implies, it enables
deriving pairing keys across different transports (i.e.  derive a BT pairing key
from BLE and vice versa).</p>

<p>Despite being a security-critical mechanism, CTKD is not part of the Bluetooth
threat model and there are no security evaluations of CTKD. Those reasons
motivated us to perform a security analysis of CTKD, resulting in our findings.
In particular, CTKD is affected by 5 major issues (i.e.  vulnerabilities)
enabling an attacker to abuse Bluetooth roles, association, security modes,
keys, and pairing states across BT and BLE. Such issues derive from the <em>lack of
a cross-transport threat model</em> in the Bluetooth standard. The standard
considers BT and BLE with separate threat models and security architectures
while, through CTKD, opens avenues for cross-transport attacks (i.e., attacks
that exploit BT by taking advantage of a vulnerability in BLE or vice versa).</p>

<p>We demonstrate that the identified CTKD issues can be exploited by a remote
attacker in Bluetooth range with the victims. In particular, the attacker can
perform impersonation, man-in-the-middle, and malicious session establishment
attacks while bypassing all the security mechanisms provided by BT and BLE
(including Secure Connections or strong association).  Those are very serious
attacks that violate the security guarantees promised by Bluetooth.  We
confirmed the feasibility of our attacks by testing them on 13 common Bluetooth
devices using 10 unique Bluetooth chips. All of them were vulnerable.</p>

<p>You will find technical details about CTKD, our security analysis, a detailed
discussion of the threads, a discussion, and potential mitigations in our
<a href="https://arxiv.org/abs/2009.11776">BLURtooth preprint</a>.</p>

<h2 id="disclosure">Disclosure</h2>

<p>We discovered the vulnerability in March 2020 and responsibly disclosed our
findings along with suggested countermeasures to the Bluetooth SIG in May 2020.
We kept our findings private and the Bluetooth SIG publicly disclosed them,
without informing us, on the 10th of September of 2020.  Our work is assigned
<em><a href="https://kb.cert.org/vuls/id/589825">CVE-2020-15802</a></em>.</p>

<h2 id="impact">Impact</h2>

<p>The BLUR attacks are a <em>significant threat for all Bluetooth users and
the related vulnerabilities remain 0-days</em>. Our claim
is backed up by our experimental results where we successfully conducted
impersonation, man-in-the-middle, and malicious sessions establishment attacks
on 13 different devices. Our device sample include manufacturers such as
Dell, Google, Lenovo, Samsung, and Sony, operating systems, such as Windows
10, Linux, and Android, and Bluetooth chip manufacturers such as Cypress,
Qualcomm, Intel, Broadcom, and Cambridge Silicon Radio (CSR).</p>

<h2 id="our-mitigations">Our Mitigations</h2>

<p>As part of our disclosure, we provided <em>concrete fixes to combat the BLUR
attacks</em>. In particular, we recommended disabling the capability to overwrite
keys via CTKD in certain circumstances, enforce strong association and Secure
Connections and roles across BT and BLE, disable pairing over BT and/or BLE when
not needed, and add user notifications in case of odd behaviors. Our fixes can
be implemented at the standard level and do not require vendor-specific
features.</p>

<h2 id="response-from-the-bluetooth-sig">Response from the Bluetooth SIG</h2>

<p>At the time of writing, there are <em>no deployed patches</em> to address the BLUR
attacks on actual devices.  The Bluetooth SIG suggested that version 5.1 of the
standard will contain guidelines to mitigate the BLUR attacks (e.g., disable key
overwrites in certain circumstances as proposed in our countermeasures), but
such guidelines are not (yet) public and we cannot comment on them.  The
Bluetooth SIG provides a <a href="https://www.bluetooth.com/learn-about-bluetooth/bluetooth-technology/bluetooth-security/blurtooth/">public statement about BLURtooth and the BLUR
attacks</a>.</p>


      
    </div></div>]]>
            </description>
            <link>https://hexhive.epfl.ch/BLURtooth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624206</guid>
            <pubDate>Tue, 29 Sep 2020 04:43:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Vision – Coalition for App Fairness]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24624006">thread link</a>) | @tambourine_man
<br/>
September 28, 2020 | https://appfairness.org/our-vision/ | <a href="https://web.archive.org/web/*/https://appfairness.org/our-vision/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="primary"><main id="main"><article class="page" id="post-394" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div itemprop="text"><div data-elementor-type="wp-page" data-elementor-id="394" data-elementor-settings="[]"><div><div><section data-id="e1785ac" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"></section><section data-id="29e5348" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="df3eaf0" data-element_type="column"><div><div><div data-id="9fdb9b1" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:300}" data-widget_type="text-editor.default"><div><p>The world’s most popular online platforms and the app stores that govern access to them have become a critical gateway to the consumers of digital products and services worldwide. While they can be beneficial when fairly operated, they can also be used by platform owners to hurt developers and consumers. As enforcers, regulators and legislators around the world seek to address these important issues, we, the Coalition for App Fairness, urge them to recognize that every app developer, regardless of size or the nature of the developer’s business, is entitled to fair treatment by these app stores and the platform owners who operate them, and should be afforded the following rights:</p></div></div></div></div></div></div></div></section><section data-id="e9c6c37" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;gradient&quot;,&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="537c477" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;,&quot;animation&quot;:&quot;fadeInUp&quot;,&quot;animation_delay&quot;:300}"><div><div><section data-id="ec9b1aa" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="5b0d45c" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a4f6862" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b88d1ba" data-id="info_box5f7556b88d1ba" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_1.png" alt="one"></p><div><p>No developer should be required to use an app store exclusively, or to use ancillary services of the app store owner, including payment systems, or to accept other supplementary obligations in order to have access to the app store.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="5eefa74" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="143ef27" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b88f345" data-id="info_box5f7556b88f345" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_2.png" alt="two"></p><div><p>No developer should be blocked from the platform or discriminated against based on a developer’s business model, how it delivers content and services, or whether it competes in any way with the app store owner.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="a36f301" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="c13739d" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="dd74397" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b8925b0" data-id="info_box5f7556b8925b0" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_3.png" alt="three"></p><div><p>Every developer should have timely access to the same interoperability interfaces and technical information as the app store owner makes available to its own developers.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="d7acc59" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="c8f0078" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b894872" data-id="info_box5f7556b894872" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_4.png" alt="four"></p><div><p>Every developer should always have access to app stores as long as its app meets fair, objective and nondiscriminatory standards for security, privacy, quality, content, and digital safety.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="c3f38e1" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="c29ef73" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="6d00f0d" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b897286" data-id="info_box5f7556b897286" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_5.png" alt="five"></p><div><p>A developer’s data should not be used to compete with the developer.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="7c1173a" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="aaac757" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b8994f2" data-id="info_box5f7556b8994f2" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_6.png" alt="six"></p><div><p>Every developer should always have the right to communicate directly with its users through its app for legitimate business purposes.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="00e085e" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="0931faa" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="be80356" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b89bd1a" data-id="info_box5f7556b89bd1a" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_7.png" alt="seven"></p><div><p>No app store owner or its platform should engage in self-preferencing its own apps or services, or interfere with users’ choice of preferences or defaults.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="c58956e" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="e726b73" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b89dd2d" data-id="info_box5f7556b89dd2d" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_8.png" alt="eight"></p><div><p>No developer should be required to pay unfair, unreasonable or discriminatory fees or revenue shares, nor be required to sell within its app anything it doesn’t wish to sell, as a condition to gain access to the app store.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section><section data-id="b79a45e" data-element_type="section" data-settings="{&quot;animation&quot;:&quot;none&quot;}"><div><div><div data-id="35127a4" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="669eafc" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b8a0514" data-id="info_box5f7556b8a0514" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_9.png" alt="nine"></p><div><p>No app store owner should prohibit third parties from offering competing app stores on the app store owner’s platform, or discourage developers or consumers from using them.</p></div></div></div></div></div></div></div></div></div></div></div><div data-id="e891f97" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="a8cb9a4" data-element_type="widget" data-widget_type="tp-info-box.default"><div><div id="info_box5f7556b8a25d5" data-id="info_box5f7556b8a25d5" data-connection="" data-eventtype=""><div><div><div><div><p><img src="https://appfairness.org/wp-content/uploads/2020/09/icon-number_10.png" alt="ten"></p><div><p>All app stores will be transparent about their rules and policies and opportunities for promotion and marketing, apply these consistently and objectively, provide notice of changes, and make available a quick, simple and fair process to resolve disputes.</p></div></div></div></div></div></div></div></div></div></div></div></div></div></section></div></div></div></div></div></section><section data-id="d605c57" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"><div><div><div data-id="1d8304b" data-element_type="column"><div><div><div data-id="15c3e7a" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:400}" data-widget_type="text-editor.default"><div><p>The Coalition for App Fairness was created by industry leading companies who want to see freedom of choice for consumers and a level playing field for businesses. This is an open call to all developers, big and small, to join us – and together we will fight back against the monopolist control of the app ecosystem by Apple.</p></div></div></div></div></div></div></div></section></div></div></div></div></article></main></div></div></div></div>]]>
            </description>
            <link>https://appfairness.org/our-vision/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24624006</guid>
            <pubDate>Tue, 29 Sep 2020 03:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Possible reason for crashes of the Nvidia RTX 3080 and RTX 3090]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623963">thread link</a>) | @g42gregory
<br/>
September 28, 2020 | https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/ | <a href="https://web.archive.org/web/*/https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-149171"><div><div><div><div><div><p>Not only the editors and testers were surprised by sudden instabilities of the new GeForce RTX 3080 and RTX 3090, but also the first customers who were able to get board partner cards from the first wave. An interesting pattern of behavior emerged that did not affect all cards or manufacturers and the problems only occurred at certain boost clock rates above or just around 2 GHz. To make matters worse, NVIDIA has obviously also slightly undermined the quality management of the board partners (AIC) due to the secrecy – unconsciously, of course, but with plausible consequences. A chain of adverse circumstances? This could well be the case, because this explains the somewhat diffuse error pattern from the most diverse forums.</p><h3><span><strong>Start of production without real function control?</strong></span></h3><p>Let’s start with the latter, before I get lost in the technical analyses. You probably remember when I wrote that the board partners couldn’t use working drivers yet and only work with a very limited driver and NVPunish. Since the driver problem lasted until shortly before the launch, but the first wave of cards had to be produced already, the functional testing of the first models was obviously limited to power-on and thermal stability. Running, not running. However, this does not say much about the chip quality and the possible maximum frequencies that the respective chip can safely handle.</p><p>Thus, it would at least be plausible that cards could have been sold as OC cards, which wouldn’t have passed a real quality test at the manufacturer with the delivered settings. Real binning? Nothing. Subsequent selection of particularly overclocked cards? Impossible, in fact. And so it is by no means impossible that one or the other “Potato” chip could also have gotten lost on such an OC card. We know the consequences from the posts of the buyers in the relevant forums.</p><h3><span><strong>Wrong component selection? Plausible!</strong></span></h3><p>Now let’s come to the fact that even good chips have dropped out now and then. That they are good, you can see for yourself e.g. by the boost cycle and the temperatures. So it is quite easy to find out with a selected card. This brings us now to a point that I was actually very unconsciously haunting the back of my mind at first, and which then solidified into a realization when comparing the boards of different models So let’s go directly to the “reference board” PG132, which can also be understood as a so-called Base Design. Especially the backside and especially the area below the BGA is interesting. What is interesting about such drawings and the so-called BoM (Bill of Materials) is that you are offered different placement alternatives.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg" alt="" width="980" height="765" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC-300x234.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Bottom-POSCAP-vs-MLCC-768x600.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>I will (have to) simplify the following for better understanding. Below the BGA we see the six NECESSARY capacitors for filtering high frequencies on the voltage rails, i.e. NVVDD and MSVDD. Apart from the fact that there is still enough high-frequency “garbage” from the voltage converters, it is mainly the so-called GPU load including all jumps caused by boost, which leads to very broadband frequency mixtures, which become more extreme the higher the boost clock goes. The BoM and the drawing from June leave it open whether large-area POSCAPs (Conductive Polymer Tantalum Solid Capacitors) are used (marked in red), or rather the somewhat more expensive MLCCs (Multilayer Ceramic Chip Capacitor). The latter are smaller and have to be grouped for a higher capacity.</p><p>According to the list and specifications of Nvidia, both are possible. In terms of quality, however, good MLCCs are better able to filter the very high frequency components in particular. In the end, this is simple practical knowledge, which only often enough collides with the world view of a financial controller.&nbsp; If one searches the forums, it seems that the Zotac Trinity is particularly affected when it comes to instabilities starting at certain boost clock rates from around 2010 MHz. A feat, because Zotac is relying on a total of six cheaper POSCAPs.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg" alt="" width="980" height="390" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity-300x119.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Zotac-Trinity-768x306.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>And what does NVIDIA do with its own Founders Editions? One does it obviously better, because I could not reproduce these stability problems with any FE even very clearly beyond 2 GHz (fan to 100%). If something went wrong, it was almost certainly a driver problem. If we take a look at the FE, we see only four SP-CAPs (red) and in the middle two MLCC groups of 10 individual capacitors each (green). This is definitely the better solution and the optimal compromise. because especially the middle areas should best be provided with suitable filters (short circuit of the high-frequency frequency mixtures).</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg" alt="" width="980" height="406" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1-300x124.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Founders-1-768x318.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>If it is only about NVVDD, a single MLCC block may be sufficient to solve the most serious problems. For example, MSI uses only one on the Gaming X Trio, which is theoretically enough, but could have been better solved if, for example, the 2.1 GHz were to be used with water. Whether this is still enough would of course have to be tested. PC Partner, Zotac’s mother company, seems to have recognised this and is obviously changing its cards. By the way, the following example is from a soldering experiment that was NOT made by Zotac, but which confirmed the effectiveness of MLCC smoothing very impressively. One can almost be envious of these soldering skills.</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg" alt="" width="980" height="497" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC-300x152.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Hand-made-MLCC-768x389.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>By the way, you also have to praise a company here that recognized the whole thing from the start and didn’t even let it touch them, as the Asus TUF RTX 3080 Gaming consequently did without POSCAPs and only used MLCC groups. My compliments, it fits!</p><p><a href="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg"><img loading="lazy" src="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg" alt="" width="980" height="439" srcset="https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1.jpg 980w, https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1-300x134.jpg 300w, https://www.igorslab.de/wp-content/uploads/2020/09/Asus-TUF-1-768x344.jpg 768w" sizes="(max-width: 980px) 100vw, 980px"></a></p><p>Interestingly, all board partners are silent on this issue, no matter who you ask. No answer is also an answer, because this behaviour is the absolute exception and almost resembles a muzzle decree. This is because components are normally spoken freely when the launch has already taken place. But here comes nothing but meaningful silence. This also applies to the question of whether the BoM was subsequently changed again to completely exclude the exclusive use of POSCAPs/SP-CAPs.</p><p>Sometimes things are so obvious that you really have to look several times to see them. But once you have understood it, many things suddenly go from nebulous to plausible. NVIDIA, by the way, cannot be blamed directly, because the fact that MLCCs work better than POSCAPs is something that any board designer who hasn’t taken the wrong profession knows. Such a thing can even be simulated if necessary. I will of course stay on it, because my interest is naturally aroused.</p><p>Please read also the latest follow up to that sory:</p><h2><a href="https://www.igorslab.de/en/nvidia-geforce-rtx-3080-und-rtx-3090-and-the-crash-why-the-capacitors-are-so-important-and-what-are-the-object-behind/" target="_blank" rel="noopener noreferrer">NVIDIA GeForce RTX 3080 and RTX 3090 and the crashes – Why capacitors are so important and what’s behind them</a></h2><p><iframe title="Aufgedeckt: Gründe, warum eine NVIDIA GeForce RTX 3080 oder RTX 3090 oberhalb 2 GHz crashen könnten!" width="1320" height="743" src="https://www.youtube.com/embed/7YQ7rNgoqMA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p> </div></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.igorslab.de/en/what-real-what-can-be-investigative-within-the-crashes-and-instabilities-of-the-force-rtx-3080-andrtx-3090/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623963</guid>
            <pubDate>Tue, 29 Sep 2020 03:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenStreetMap State of the Map conf 2020 – a few thoughts on the experiment]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623160">thread link</a>) | @pabs3
<br/>
September 28, 2020 | http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/ | <a href="https://web.archive.org/web/*/http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Last weekend has been the <a href="https://2020.stateofthemap.org/">2020 State of the Map conference</a> – which did not take place like it was originally planned and as it has been conducted in the past years at a specific physical place (in this case Capetown, South Africa) but was done in a purely virtual distributed form across the internet.</p>
<p>I regard this change – forced by the pandemic situation we all struggle with these days in some form – as in a way a welcome disruption.  Due to an outside event the powers-that-be have been forced to try something they would not have tried probably in many years to come otherwise.</p>
<p>The implementation of the virtual distributed conference as an afterthought on an originally planned physical single place event led of course to some flaws and inconsistencies in the practical setup and to not using the full potential of the virtual setting in all of its aspects.  This is obviously owed a lot to the desire not to throw away work already done.  The most obvious issue resulting from that approach is that the main conference program contained almost exclusively program items submitted by people under the original premise of a physical conference – or in other words:  The chance to hold a talk at the virtual conference still depended on the willingness and ability of people to travel to South Africa and be there for the talk in person.</p>
<p>This means the conference in its program was not even remotely as diverse as it could have been it it had been set up as a distributed remote conference in the first place.  This should IMO be kept in mind by everyone evaluating how SotM 2020 turned out.</p>
<p>I regard the whole event mostly as an experiment to test various techniques and methods and means of communication to have a virtual conference in the OSM context.  This applies both to behind-the-scene infrastructure and the public interfaces.  If the SotM WG documents and shares their findings publicly that could have use far beyond SotM for the OSM community.</p>
<h3>Practical observations from the conference</h3>
<p>The pads for collecting questions and comments on talks worked great.  This is definitely a concept that could play a central role in future distributed conferences.  Initially the questions were asked anonymously which has led in particular in case of Frederik’s talk to quite a lot of people making vile comments under the disguise of anonymity.  It was later established that questions and comments should be signed.  I also think that the use of pads could be extended to non-talk program items like self organized sessions.</p>
<div id="attachment_9119"><p><a href="https://pad.sotm.bitcast.co.za/p/general-feedback"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad.png" alt="" width="512" height="429" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_pad-320x268.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>general feedback pad of the conference – there was a similar pad for questions and comments on each of the talks</p></div>
<p>The attractiveness of the pads to a large extent comes from the real time capability (which is essential for a real time conference obviously) combined with the non-linear free form structure of the text (which contrasts pleasantly with most other real time communication channels that tend to have a strictly linear structure).</p>
<p>There are quite a few things that could be improved about the audio.  This starts with the levels of the pause music relative to the talk audio levels and continues with reverberations in poorly dampened rooms of some presenters and feedback noise in some people’s audio setup.  That is mostly a matter of sufficient testing and experience with setting up and adjusting equipment in a way that works well.  That takes time from everyone involved obviously.  This is the hardest the first time but gets easier once you gain experience.  And i am confident with the corona virus crisis incentivizing many people to gain more practice in remote communication knowledge and experience in this field is much improving every day.  More communication about how to ensure good audio recording and communication quality within the community, sharing experiences and techniques used, would definitely be helpful.</p>
<p>None the less what also became clear to me during the conference is that the willingness of people to engage in communication was very clearly in the order written conversation &gt; audio communication &gt; video.  I think this is an observation to consider for any audio or video conversation in the OSM context.  Video meetings might be very convenient for heavily engaged extroverted community members with a pre-existing prominence but for many people this can be a source of discomfort.  And cultural and language barriers can be strongly emphasized by use of real time audio and especially video communication.</p>
<h3>Comments on the talks</h3>
<p>I have not watched all the talks of the conference so this is more a list of anecdotal observations than a complete review.  All the talks of the main conference program were pre-recorded while the Q&amp;A after the talks were live.  The pre-recorded talks offered a lot of options for presenters which would not be available in a live conference talk and which were used very differently by the presenters.  Ilya in his talk <em><a href="https://2020.stateofthemap.org/sessions/CKYTVS">Send me a Postcard</a></em> IMO showed the most innovative approach to this.  Watching this talk is recommended to anyone who in the future might be in the position to pre-record a conference talk as a positive example.</p>
<p>Some of the talks i watched so far that i consider particularly interesting:</p>
<div id="attachment_9121"><p><a href="https://2020.stateofthemap.org/sessions/RRVNAM"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_allan2-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Allan’s American perspective on the political spectrum of OSM</p></div>
<p>Allan’s keynote <em><a href="https://2020.stateofthemap.org/sessions/RRVNAM">Winds of Change in OpenStreetMap</a></em> – While this did not provide much new information of substance to those following OSMF politics in general and who have read past statements from Allan on that subject, it seems to provide a valuable glimpse into the current mentality of the OSMF board regarding their work.  Although Allan had a prominent disclaimer that these are his personal views and do not represent those of the board, it is quite clear from statements and actions of other board members that they see many of these things similarly.  There is quite a lot of accurate analysis in the talk but also quite a few highly questionable selective perceptions, assumptions and conclusions.  I might comment about some of those separately although it is not clear at this time if the board is currently willing to openly discuss the merits of their views and opinions on the OSM community and the future of the OSM project and on the OSMFs role and defend their views and conclusions on these matters in a public setting.</p>
<div id="attachment_9122"><p><a href="https://2020.stateofthemap.org/sessions/DYXWDC"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_fred-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Frederik explaining OpenStreetMap</p></div>
<p>Frederik’s talk <em><a href="https://2020.stateofthemap.org/sessions/DYXWDC">There might have been a misunderstanding…</a></em> – As usual Frederik explains in a well understandable way many of the central aspects of the OpenStreetMap project which new contributors as well as data users often struggle with because they differ from what people are used to, either in other internet communities or in the world of geodata.  Naturally, a lot of these frequently misunderstood aspects of OSM are also fairly controversial and this has – as hinted above – led to a lot of critical and in parts insulting comments on the talk by people who would like these things to change and for OSM to become more compatible with their expectations.  What Frederik presents however is for the most part not wishful thinking – presenting how he would like OSM to be – but how OpenStreetMap actually works and functions based on knowledge derived from many years of practical involvement in the project.  Other long term participants will largely be able to confirm that.  So whether you like these aspects of OSM or not and in what direction you might want OSM to develop in the future this is a very useful talk to watch to understand how OpenStreetMap ticks.  </p>
<div id="attachment_9123"><p><a href="https://2020.stateofthemap.org/sessions/RHDUV9"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_mikel-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Mikel mocking concerns about conflicts of interest of corporate employees in the OSMF</p></div>
<p>Mikel’s talk <em><a href="https://2020.stateofthemap.org/sessions/RHDUV9">An Incomplete History of Companies and Professionals in OpenStreetMap</a></em> – Essentially Mikel is painting corporate activities in OSM and their history in rosy colors while saying: just pay no attention to all the skeletons lying around here.  A lot could be criticized about selective presentations of facts as well as factual and logical errors or about the technique of jokingly dismissing and ridiculing differentiated philosophical critique of the influence of corporate interests in OSM.  Anyway – I think this is a valuable talk to watch to get a glimpse into the mindset of many corporate employees involved in OSM as part of or in relation to their job.  </p>
<div id="attachment_9124"><p><a href="https://2020.stateofthemap.org/sessions/DZ8PWQ"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_janet-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Janet explaining aid work in rural Tanzania</p></div>
<p>Janet’s talk <em><a href="https://2020.stateofthemap.org/sessions/DZ8PWQ">Building mapping communities in rural Tanzania – challenges, successes and lessons learnt</a></em> – I found this interesting because of a certain observation.  In the beginning a number of specific non mapping related examples are shown of aid being given to people in rural areas of Tanzania for everyday life problems.  And emphasis is admirably given to helping locals solving these problems themselves in a sustainable and independent fashion using locally available means.  Yet when it comes to mapping and digital technology the same initiative (and from what i know also many other humanitarian mapping projects) critiquelessly rely on commercial services and proprietary tools and encourage locals to use and rely on those services and tools that increase and perpetuate dependence of local people on non-local corporations for their local mapping work instead of educating people in using open source technology and tools they can manage and control themselves.</p>
<p>To be clear, i am not at all saying that this talk in any way constitutes an example for particularly bad practice in that regard, on the contrary the examples shown illustrate a principal awareness of the issue that is missing elsewhere.  But to me it demonstrates quite well how fundamentally different measures are applied to the goal of supplying aid in a way that enables locals to solve serious problems in a sustainable fashion outside the digital world and within it.  </p>
<div id="attachment_9125"><p><a href="https://2020.stateofthemap.org/sessions/CKYTVS"><img src="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya.png" alt="" width="512" height="288" srcset="http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya.png 512w, http://blog.imagico.de/wp-content/uploads/2020/07/sotm2020_ilya-320x180.png 320w" sizes="(max-width: 512px) 100vw, 512px"></a></p><p>Ilya making a case for sending postcards in an innovative style video</p></div>
<p>Ilya’s talk <em><a href="https://2020.stateofthemap.org/sessions/CKYTVS">Send me a Postcard</a></em> – I mentioned his talk already above as an example for making innovative use of the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/">http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/</a></em></p>]]>
            </description>
            <link>http://blog.imagico.de/sotm-2020-a-few-thoughts-on-the-experiment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623160</guid>
            <pubDate>Tue, 29 Sep 2020 01:09:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia mixed precision GEMM codegen meets and exceeds CUBLAS]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24623153">thread link</a>) | @amkkma
<br/>
September 28, 2020 | https://juliagpu.org/2020-09-28-gemmkernels/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-09-28-gemmkernels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        





<i data-feather="calendar"></i> <time datetime="2020-09-28">Sep 28, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Thomas Faignaert, Tim Besard, Bjorn De Sutter


<p>General Matrix Multiplication or GEMM kernels take center place in high performance
computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as
NVIDIA’s Tensor Cores. In this paper we show how it is possible to program these
accelerators from Julia, and present abstractions and interfaces that allow to do so
efficiently without sacrificing performance.</p>
<p>A pre-print of the paper has been published on arXiv:
<a href="https://arxiv.org/abs/2009.12263">arXiv:2009.12263</a>. <br> The source code can be found on
GitHub:
<a href="https://github.com/thomasfaingnaert/GemmKernels.jl">thomasfaingnaert/GemmKernels.jl</a>.</p>
<p>With the APIs from GemmKernels.jl, it is possible to instantiate GEMM kernels that perform
in the same ball park as, and sometimes even outperform state-of-the-art libraries like
CUBLAS and CUTLASS. For example, performing a mixed-precision multiplication of two 16-bit
matrixes into a 32-bit accumulator (on different combinations of layouts):</p>


<figure>
	<img src="https://juliagpu.org/2020-09-28-gemmkernels/mixed_precision.png" alt="Performance of mixed-precision GEMM">
</figure>

<p>The APIs are also highly flexible and allow customization of each step, e.g., to apply the
activation function <code>max(x, 0)</code> for implementing a rectified linear unit (ReLU):</p>
<div><pre><code data-lang="julia">a <span>=</span> CuArray(rand(<span>Float16</span>, (M, K)))
b <span>=</span> CuArray(rand(<span>Float16</span>, (K, N)))
c <span>=</span> CuArray(rand(<span>Float32</span>, (M, N)))
d <span>=</span> similar(c)

conf <span>=</span> GemmKernels<span>.</span>get_config(
    gemm_shape <span>=</span> (M <span>=</span> M, N <span>=</span> N, K <span>=</span> K),
    operator <span>=</span> Operator<span>.</span>WMMAOp{<span>16</span>, <span>16</span>, <span>16</span>},
    global_a_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float16</span>},
    global_c_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float32</span>})

GemmKernels<span>.</span>matmul(
    a, b, c, d, conf;
    transform_regs_to_shared_d <span>=</span> Transform<span>.</span>Elementwise(x <span>-&gt;</span> max(x, <span>0</span>)))
</code></pre></div><p>The GemmKernels.jl framework is written entirely in Julia, demonstrating the
high-performance GPU programming capabilities of this language, but at the same time keeping
the research accessible and easy to modify or repurpose by other Julia developers.</p>



      </main>
    </div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-09-28-gemmkernels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24623153</guid>
            <pubDate>Tue, 29 Sep 2020 01:08:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenBSD on the Desktop (Part I)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24622788">thread link</a>) | @upofadown
<br/>
September 28, 2020 | https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html | <a href="https://web.archive.org/web/*/https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Let's install OpenBSD on a Lenovo Thinkpad X270. I used this computer for my
computer science studies. It has both Arch Linux and Windows 10 installed as
dual boot. Now that I'm no longer required to run Windows, I can ditch the dual
boot and install an operating system of my choice.</p>

<p>First, I grab my work Thinkpad running Arch Linux and some USB dongle big enough
for the <a href="https://cdn.openbsd.org/pub/OpenBSD/6.7/amd64/miniroot67.fs">amd64 miniroot
image</a> (roughly
five megabytes, that is). This small image does not include the file sets, which
will be downloaded during installation instead. I also download the <a href="https://mirror.ungleich.ch/pub/OpenBSD/6.7/amd64/SHA256">SHA256
checksums</a> from the
Swiss mirror, and verify the downloaded image, before I copy it on my dongle:</p>
<pre><code>$ sha256sum -c --ignore-missing SHA256 
miniroot67.fs: OK
$ sudo dd if=miniroot67.fs of=/dev/sda bs=1M
</code></pre>

<p>The Thinkpad X270 is connected to my network through Ethernet. The WiFi firmware
usually needs to be installed separately, so only Ethernet will work out of the
box. The BIOS has UEFI activated. OpenBSD and UEFI has issues on older hardware
(at least on a 2014 Dell laptop I have), but let's try it on this laptop,
anyway.</p>
<p>I plug in the dongle prepared before, and start the computer. I interrupt
the regular boot with Enter and pick an alternative boot method by pressing F12.
Now I pick my USB dongle. After roughly a minute, the installer has been
started. Now I follow these steps:</p>
<ul>
<li>I choose the option <code>I</code> to install OpenBSD.</li>
<li>For the keyboard layout, I pick <code>sg</code>, for Swiss German.</li>
<li>As a hostname, I simply pick <code>x270</code>, because it's a Thinkpad X270, and I'm not
  very creative when it comes to naming things.</li>
<li>From the available network options (<code>iwm0</code>: WiFi, <code>em0</code>: Ethernet, and
  <code>vlan0</code>: Virtual LAN), I pick <code>em0</code>.</li>
<li>I try to get an IPv4 address over DHCP, which seems to work very quickly.</li>
<li>Next, I type in my very secret root password twice.</li>
<li>I do <em>not</em> start <code>sshd</code> by default, because I don't need to connect to this
  machine through SSH. It's supposed to be a workstation, not a server.</li>
<li>The X Window System should not be started by <code>xnodm(1)</code>, so I leave it to
  <code>no</code>.</li>
<li>Neither do I want to change the default to <code>com0</code>.</li>
<li>I set up my user <code>patrick</code> with my proper name <code>Patrick Bucher</code>, and a decent
  password.</li>
<li>The time zone has been detected properly as <code>Europe/Zurich</code>, which I just
  leave the way it is.</li>
<li>The installer detected two disks: <code>sd0</code> and <code>sd1</code>. Since <code>sd0</code> is the detected
  SSD in my laptop, the UEFI issue from my Dell laptop doesn't exist on this
  computer. I pick <code>sd0</code> for the root disk, since <code>sd1</code> is my USB dongle.</li>
<li>I choose to use the whole disk with a GPT partitioning schema, because it's
  2020.</li>
<li>An auto-allocated layout for <code>sd0</code> is presented. It looks decent to me, so I
  just go with that auto layout.</li>
<li>I don't want to initialize another disk, so I just press Enter (<code>done</code>).</li>
<li>Since the miniroot image does not come with the file sets, I pick <code>http</code> as
  the location for the sets.</li>
<li>I don't use a proxy, and use the mirror <code>mirrog.ungleich.ch</code> and the server
  directory <code>pub/OpenBSD/6.7/amd64</code> as proposed.</li>
<li>Next, I unselect the game sets by entering <code>-game*</code>. (I heard that they're not
  much fun to play.) I leave all the other sets activated, including the <code>x</code>
  sets, which will be required for the GUI later on.</li>
<li>After those sets are installed, I press Enter (<code>done</code>). Now the installer
  performs various tasks, after which I choose to <code>halt</code> the computer. This
  gives me time to remove the USB dongle.</li>
</ul>

<p>I now restart my laptop, and OpenBSD boots. This takes more time than booting
Arch Linux, which uses <code>systemd</code>, whereas OpenBSD uses <code>rc</code>, which performs the
startup tasks sequentially.</p>
<p>There's a message showing up that various firmware (<code>intel-firmware</code>,
<code>iwm-firmware</code>, <code>inteldrm-firmware</code>, <code>uvideo-firmware</code>, and <code>vmm-firmware</code>) has
been installed automatically. Very nice, indeed.</p>
<h2>WiFi Connection</h2>
<p>Now that the <code>iwm-firmware</code> has been installed, I can connect right away to my
WiFi network <code>frzbxpdb5</code>. I create a file called <code>/etc/hostname.iwm0</code>, wich
<code>hostname</code> being a literal string, and <code>iwm0</code> being the WiFi network card. The
connection to my WiFi network consists of a single line:</p>
<pre><code>dhcp nwid frzbxpdb5 wpakey [my-wpakey]
</code></pre>
<p>Whereas <code>frzbxpdb5</code> is my WiFi network's ESSID, and <code>[my-wpakey]</code> needs to be
replaced by the actual WPA key.</p>
<p>Then the networking can be restarted for that device:</p>
<pre><code># sh /etc/netstart iwm0
</code></pre>
<p>This script is kind enough to set the file permissions of <code>/etc/hostname.iwm0</code>
to <code>640</code>, and then connects to my WiFi network.</p>
<p>I unplug the Ethernet cable and <code>ping openbsd.org</code>, which works fine, even after
a restart.</p>

<p>My GUI on Unix-like systems is based on the Dynamic Window Manager (<code>dwm</code>) and a
couple of other tools, such as <code>dmenu</code>, <code>st</code>, <code>slstatus</code>, <code>slock</code>, all created and
maintained by the <a href="http://suckless.org/">Suckless</a> community.</p>
<p>This software doesn't come with configuration facilities, but needs to be
configured in the respective C header file <code>config.h</code>, and then re-compiled.
Even though OpenBSD offers <code>dwm</code> as a package, customizing and configuring that
window manager requires to build it from source.</p>
<h2>Building <code>dwm</code> and Friends</h2>
<p>First, I need to install <code>git</code> to fetch the source code:</p>
<pre><code># pkg_add git
</code></pre>
<p>Then I fetch the source code for <code>dwm</code>, <code>dmenu</code>, <code>st</code>, and <code>slstatus</code> from <a href="http://suckless.org/">Suckless</a>:</p>
<pre><code>$ git clone https://git.suckless.org/dwm
$ git clone https://git.suckless.org/dmenu
$ git clone https://git.suckless.org/st
$ git clone https://git.suckless.org/slstatus
</code></pre>
<h3>Building <code>dwm</code></h3>
<p>Next, I try to build <code>dwm</code>:</p>
<pre><code>$ cd dwm
$ make
</code></pre>
<p>This fails with an error message (<code>'ft2build.h' file not found</code>), which reminds
me of building <code>dwm</code> on FreeBSD roughly a month before. Since I can finde the
header file at another location:</p>
<pre><code># find / -type f -name ft2build.h
/usr/X11R6/include/freetype2/ft2build.h
</code></pre>
<p>I simply can modify the <code>config.mk</code> accordingly by changing</p>
<pre><code>FREETYPEINC = /usr/include/freetype2
</code></pre>
<p>to</p>
<pre><code>FREETYPEINC = $(X11INC}/freetype2
</code></pre>
<p>Actually, I only need to comment the above line, and uncomment the line below</p>
<pre><code># OpenBSD (uncomment)
</code></pre>
<p>The Suckless folks obviously are friendly towards OpenBSD, which is also
noticable in other places (more evidence to be shown further below).</p>
<p>The next compilation attempt succeeds:</p>
<pre><code>$ make
</code></pre>
<p>So let's install <code>dwm</code>, too:</p>
<pre><code># make install
</code></pre>
<p>By default, and as to be seen in <code>config.h</code>, the keyboard combination
<code>[Alt]+[Shift]+[Enter]</code> (deeply engraved into the muscle memories of many <code>dwm</code>
users) starts the <code>st</code> terminal. This will be built in a while. However, I
prefer to use the <em>Super</em> or <em>Windows</em> key instead of <code>Alt</code>, since the former
is of no use in OpenBSD, and the latter still comes in handy when working with
the emacs readline mode. Therefore, I change the <code>MODKEY</code> from</p>
<pre><code>#define MODKEY Mod1Mask
</code></pre>
<p>to</p>
<pre><code>#define MODKEY Mod4Mask
</code></pre>
<p>Then I rebuild and reinstall <code>dwm</code>:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>st</code></h3>
<p>Let's switch over to the <code>st</code> source directory and just try to compile it:</p>
<pre><code>$ cd ../st
$ make
</code></pre>
<p>Here, we get a warning that the function <code>pledge</code> (an OpenBSD mitigation, which
is built into the <code>master</code> branch, but surrounded by an <code>ifdef</code> preprocessor
statement, so that it will only be compiled for OpenBSD) is imported implicitly.
Let's just ignore this warning for now.</p>
<p>What's worse, the compilation fails with the error message:</p>
<pre><code>ld: error: unable to find library -lrt
</code></pre>
<p>Here, the FAQ comes in handy, stating that</p>
<pre><code>If you want to compile st for OpenBSD you have to remove -lrt from
config.mk, ...
</code></pre>
<p>Having done so in <code>config.mk</code>, <code>st</code> compiles without any further issues, and,
thus, can be rebuilt and installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>dmenu</code></h3>
<p>Even OpenBSD users with Suckless tools have to open another GUI application than
a terminal emulator once in a while. For this purpose, Suckless offers <code>dmenu</code>.
Let's switch over to it and compile it:</p>
<pre><code>$ cd ../dmenu
$ make
</code></pre>
<p>Again, we have the issue with <code>ft2build.h</code>, which can be resolved as above with
<code>dwm</code>: by using the proper path for <code>FREETYPEINC</code> in <code>config.mk</code>. Afterwards,
the build succeeds, and <code>dmenu</code> can be installed:</p>
<pre><code># make install
</code></pre>
<h3>Building <code>slstatus</code></h3>
<p><code>dwm</code> has a status bar on the top right, which can be used to show various
information. I used to write some shell commands in <code>.xinitrc</code> to compose such a
status line, and then set it by <code>xset -b</code> once every five seconds or so. This
approach generates a multitude of processes every couple of seconds.</p>
<p><code>slstatus</code> is a C programm that is capable of showing various kinds of more or
less useful information. Let's switch over to <code>slstatus</code> and see, what is
available in <code>config.def.h</code>:</p>
<pre><code>$ cd ../slstatus
$ less config.def.h
</code></pre>
<p>The comments section lists different functions (<code>battery_perc</code> for the battery
percentage, <code>datetime</code> for date and time information, <code>temp</code> for thermal
information, etc.). I usually display the CPU load, the battery percentage, the
memory usage, the current keyboard layout, and the current date and time.</p>
<p>Before configuring those, let's try to compile <code>slstatus</code>:</p>
<pre><code>$ make
</code></pre>
<p>This worked fine, so let's configure the information to be displayed in
<code>config.h</code>:</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    "%s",     "%F %T" },
};
</code></pre>
<p>This renders the current date as follows:</p>
<pre><code>$ date +"%F %T"
2020-09-05 19:26:38
</code></pre>
<p>I also like to have the weekday included, but not the seconds, so I define a
different argument string:</p>
<pre><code>$ date +"%a %Y-%m-%d %H:%M"
Sat 2020-09-05 19:27
</code></pre>
<p>That's better, so let's use it in <code>config.h</code> (surrounded with some spaces in the
format string):</p>
<pre><code>static const struct arg args[] = {
    /* function    format    argument */
    { datetime,    " %s ",   "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>The other settings I like to have do not require any arguments, at least not on
OpenBSD, so I only need to define a decent format string (with <code>|</code> as a
seperator) for those:</p>
<pre><code>static const struct arg args[] = {
    /* function    format           argument */
    { cpu_perc,     " cpu: %s%% |", NULL },
    { battery_perc, " bat: %s%% |", NULL },
    { ram_used,     " mem: %s |",   NULL },
    { keymap,       " %s |"         NULL },
    { datetime,     " %s ",         "%a %Y-%m-%d %H:%M" },
};
</code></pre>
<p>This actually compiles, so let's install it:</p>
<pre><code># make install
</code></pre>
<h2>Configuring X Startup</h2>
<p>Now that all software is compiled and installed, let's run X. To do so, a file
<code>.xinitrc</code> in the user's directory is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html">https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</a></em></p>]]>
            </description>
            <link>https://paedubucher.ch/articles/2020-09-05-openbsd-on-the-desktop-part-i.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24622788</guid>
            <pubDate>Tue, 29 Sep 2020 00:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decorating a home office when you’re a gigantic nerd]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24621390">thread link</a>) | @animationwill
<br/>
September 28, 2020 | https://www.intergalacticprimate.com/decorating-a-home-office-when-youre-a-gigantic-nerd/ | <a href="https://web.archive.org/web/*/https://www.intergalacticprimate.com/decorating-a-home-office-when-youre-a-gigantic-nerd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>I’ve been working at home now for a month and a half, and part of the deal was turning the attic into my home office. We put up shelves, reorganised all my books, and then I started pulling things out of boxes, moving things around, and although it’s still a work-in-progress, it’s still filled with things I like.</p>



<p>See, I really like having things around me. They give me something to look at when I need a five-second break. </p>



<p>Other people keep on complaining about how cluttered I make things, but it’s not clutter to me – everything has a place, and it’s all a good place.</p>



<p>So here are just some of the things around me.</p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-magikarporgonite.jpg" alt="A shelf with graphic novels. In front of the books is a card with a magikarp on it, a small toy catbus, a small lucky cat, a small elephant, a knitted pumpkin, and a cone made from resin with glitter and rocks in it." srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-magikarporgonite.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-magikarporgonite-300x150.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-magikarporgonite-768x384.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>A Magikarp card from <a rel="noreferrer noopener" href="https://www.etsy.com/uk/shop/JoshuaDunlop" target="_blank">Joshua Dunlop</a>, a catbus from <em>My Neighbour Totoro</em>, a maneki neko, a little fuzzy elephant, a knitted pumpkin, and a cone of <a rel="noreferrer noopener" href="https://www.lifeenergysolutions.com/orgonite/" target="_blank">orgonite</a>, in front of my <a rel="noreferrer noopener" aria-label="Ernie Bushmiller Nancy (opens in a new tab)" href="https://www.gocomics.com/nancy-classics" target="_blank">Ernie Bushmiller </a><em><a rel="noreferrer noopener" aria-label="Ernie Bushmiller Nancy (opens in a new tab)" href="https://www.gocomics.com/nancy-classics" target="_blank">Nancy</a></em> compendiums, <a href="https://www.dreadcentral.com/reviews/169192/junji-itos-cat-diary-yon-mu-manga/">Junji Ito’s </a><em><a href="https://www.dreadcentral.com/reviews/169192/junji-itos-cat-diary-yon-mu-manga/">Cat Diary</a></em>, and a bunch of <em><a href="http://www.fantagraphics.com/howtoreadloveandrockets" target="_blank" rel="noreferrer noopener" aria-label="Love and Rockets (opens in a new tab)">Love and Rockets</a></em> compilations. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-nagamagikarp-931x1024.jpg" alt="A stuffed toy Naga and a stuffed toy Magikarp tucked between shelves" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-nagamagikarp-931x1024.jpg 931w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-nagamagikarp-273x300.jpg 273w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-nagamagikarp-768x845.jpg 768w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-nagamagikarp.jpg 1000w" sizes="(max-width: 931px) 100vw, 931px"></figure>



<p>A stuffed <a href="https://bulbapedia.bulbagarden.net/wiki/Magikarp_%28Pok%C3%A9mon%29" target="_blank" rel="noreferrer noopener" aria-label="Magikarp (opens in a new tab)">Magikarp</a> and a stuffed <a rel="noreferrer noopener" href="https://avatar.fandom.com/wiki/Naga" target="_blank">Naga</a>. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-barbies.jpg" alt="Two Barbie dolls still in their boxes, next to a container of knitting needles" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-barbies.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-barbies-150x150.jpg 150w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-barbies-300x300.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-barbies-768x768.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p><a rel="noreferrer noopener" aria-label="Game Developer Barbie (opens in a new tab)" href="https://barbie.mattel.com/shop/en-us/ba/career-dolls/barbie-careers%C2%A0game-developer-doll-dmc33" target="_blank">Game Developer Barbie</a> and <a href="https://en.wikipedia.org/wiki/Computer_Engineer_Barbie" target="_blank" rel="noreferrer noopener" aria-label="Computer Engineer Barbie (opens in a new tab)">Computer Engineer Barbie</a> next to a jar of knitting needles, with “steampunk” goggles in front of them. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-godzillajaws.jpg" alt="A bookshelf with a Funko Pop of Jaws next to a drawing of Godzilla" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-godzillajaws.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-godzillajaws-300x180.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-godzillajaws-768x461.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>A Funko Pop Jaws with an air tank in his mouth and a drawing of Godzilla by <a rel="noreferrer noopener" href="https://www.instagram.com/aguirrefirth/" target="_blank">Anson Aguirre Firth</a>. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-twinpeaks.jpg" alt="Four Twin Peaks Funko Pops next to a picture of the Black Lodge" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-twinpeaks.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-twinpeaks-300x180.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-twinpeaks-768x461.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>Twin Peaks Funko Pops (The Log Lady, Audrey Horne, Dale Cooper, and Bob), in a laser-cut box I made, next to a print of the Black Lodge, from <a rel="noreferrer noopener" href="https://www.theretrodraughtsman.co.uk/" target="_blank">Cult Locations Ink</a>. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-eltingvilleclub.jpg" alt="A comic board with a hand-drawn sketch by Evan Dorkin" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-eltingvilleclub.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-eltingvilleclub-150x150.jpg 150w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-eltingvilleclub-300x300.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-eltingvilleclub-768x768.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>A sketch of Bill from the <a rel="noreferrer noopener" aria-label="Eltingville Club (opens in a new tab)" href="https://en.wikipedia.org/wiki/Eltingville_(comics)" target="_blank">Eltingville Club</a> by <a rel="noreferrer noopener" href="http://www.houseoffunstudio.com/" target="_blank">Evan Dorkin</a>, that he did for me at San Diego Comic Con in 1995. Behind him is a Funko Pop of Deckard from <em>Blade Runner 2049</em>.</p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-startreknovels.jpg" alt="A collection of Star Trek novels on a bookshelf" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-startreknovels.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-startreknovels-300x210.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-startreknovels-768x538.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p><em>Star Trek</em> novels, some of which are from around 1990 and still have “property of Katie Bolin” on the inside front cover. (Come on, I was 13.)</p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-unicorngoldblum.jpg" alt="A tape dispenser in the shape of a unicorn and a mug filled with small keychains" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-unicorngoldblum.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-unicorngoldblum-300x210.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-unicorngoldblum-768x538.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>A rainbow tape dispenser in the shape of a unicorn and a Jeff Goldblum mug currently filled with keychains. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-husbanddadmissatombomb.jpg" alt="A photo and a postcard hanging off of clips with a skull on a shelf behind them" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-husbanddadmissatombomb.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-husbanddadmissatombomb-150x150.jpg 150w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-husbanddadmissatombomb-300x300.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-husbanddadmissatombomb-768x768.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>A postcard of <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Miss_Atomic_%28pageants%29" target="_blank">Miss Atomic Bomb 1957</a> and a photo of my dad and my husband, with a skull behind them. The eyes have LEDs that glow. (The skull, not my dad or husband. Although I wouldn’t put it past them.)</p>



<div><figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-pikachucalendar.jpg" alt="A picture in an embroidery hoop and a calendar hanging on a wall" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-pikachucalendar.jpg 400w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-pikachucalendar-120x300.jpg 120w" sizes="(max-width: 400px) 100vw, 400px"></figure></div>



<p>A Pikachu t-shirt I turned into a wall decoration, and a Poundland Kitten calendar where I’ve been decorating all the kittens to match the season. Being August, this kitten likes festivals. Obviously. </p>



<figure><img loading="lazy" src="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-mirrorball.jpg" alt="A mirror ball hanging from the ceiling" srcset="https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-mirrorball.jpg 1000w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-mirrorball-150x150.jpg 150w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-mirrorball-300x300.jpg 300w, https://www.intergalacticprimate.com/wp-content/uploads/2019/08/homeoffice-mirrorball-768x768.jpg 768w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>

And, finally, the obligatory mirror ball.

</p>
		</div></div>]]>
            </description>
            <link>https://www.intergalacticprimate.com/decorating-a-home-office-when-youre-a-gigantic-nerd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621390</guid>
            <pubDate>Mon, 28 Sep 2020 21:25:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hanging Gardens of Babylon]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24621384">thread link</a>) | @quickfox
<br/>
September 28, 2020 | https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/ | <a href="https://web.archive.org/web/*/https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Imagine that you are a traveler in the Near East of… 600 BC, let us say. You have been tramping along for many days on a road beside the great river known as the Euphrates, which flows swiftly now under the scorching mid-summer sun. The only sign that you are getting closer to your destination has been the gradually increasing traffic on both the river and the road. For your destination is Babylon, the city where all roads lead, the largest, richest, most glamorous metropolis in the world.</p>
<p>You catch your first glimpse of the city as a glittering pinpoint sparkling high up on the southern horizon in front of you, so indistinct that you initially suspect it to be a mirage. But you soon glean from the conversation of your fellow travelers, not to mention the way they quicken their tempo in excitement, that they see it as well. This far-off glint, you realize, must be Babylon’s crowning glory: the ziggurat known as Etemenanki, which scrapes the sky in honor of the city’s patron god Marduk.</p>
<p>The land beyond the road and river becomes marshy as you continue your journey; it is in fact a man-made marsh, meant to serve as the city’s first line of defense, slowing any enemy army that dares to approach. Soon the city’s walls come into view, ringed by a wide moat diverted from the Euphrates. These walls are the tallest and widest to be found anywhere in the world — so wide that a four-horse chariot can be comfortably driven along their ramparts, with plenty of space left over on either side for observation towers and barracks for the garrison that mans them day and night.</p>
<p>You pass through one of the largest of the city’s sturdy gates; it is made entirely of finest bronze, including even the pillars and lintels. You know that each gate is dedicated to a different deity; this one is that of Urash, the god of the earth.</p>
<p>Beyond it is a teeming, sun-baked warren of streets and alleys running every which way, echoing with the shouts of merchants hawking every form of good and service imaginable, redolent of roasting meat and sweating humanity, spices and garbage, flowers and feces. It would be trivially easy to get lost forever in this maze, but you are fortunate enough to have an unfailing guide: you continue to stick close to the river, which runs under the walls and, you know, right through the center of the city. It provides a haven of relative peace and shade along its length, what with the bronze flood gates that separate it from the city streets and the towering palm trees that have been planted along its banks. The river, you know, is the lifeblood of the great city; its water is carried to every corner of Babylon by an elaborate network of aqueducts and canals. It is the only reason so many people are able to live packed so tightly together in this land that sees almost no rainfall at all for over half of every year.</p>
<p>You follow your faithful guide the Euphrates for quite some distance more. Whenever a gap in the trees and buildings permits an unobstructed view of the horizon, you can see that Etemenanki has drawn still closer to you. At last you arrive at a second ring of walls, and the colossal Ishtar Gate which allows you to pass through them. Soaring above the buildings in front of it to a height of more than ten times that of a man, the gate is enameled, from its base to the crenelated bastions at its top, in a striking deep blue, its surface covered with ochre-hued bas-reliefs of bulls and dragons and lions, bordered by floral designs in striking white. The goddess it honors is one of the oldest of all the deities of this part of the world — far older than the city’s patron Marduk, although you are in no position to realize this. She is the goddess of the most essential things in life: sex and love, war and power.</p>
<figure id="attachment_1793" aria-describedby="caption-attachment-1793"><img src="https://analog-antiquarian.net/wp-content/uploads/2020/09/1280px-Ishtar_gate_in_Pergamon_museum_in_Berlin.-1024x730.jpg" alt="" width="640" height="456" srcset="https://analog-antiquarian.net/wp-content/uploads/2020/09/1280px-Ishtar_gate_in_Pergamon_museum_in_Berlin.-1024x730.jpg 1024w, https://analog-antiquarian.net/wp-content/uploads/2020/09/1280px-Ishtar_gate_in_Pergamon_museum_in_Berlin.-300x214.jpg 300w, https://analog-antiquarian.net/wp-content/uploads/2020/09/1280px-Ishtar_gate_in_Pergamon_museum_in_Berlin.-768x548.jpg 768w, https://analog-antiquarian.net/wp-content/uploads/2020/09/1280px-Ishtar_gate_in_Pergamon_museum_in_Berlin..jpg 1280w" sizes="(max-width: 640px) 100vw, 640px"><figcaption id="caption-attachment-1793">A reproduction of the Ishtar Gate, found in the Pergamon Museum, Berlin. (<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">Radomir Vrbovsky</a>)</figcaption></figure>
<p>Passing through the gate, whose thick cedar portals stand open in this time of peace, you find yourself on the grandest street in the world, the fabled Processional Way. Its surface of limestone and red-hued breccia is as smooth as glass and meticulously clean, making a marked contrast to the dust and squalor on the other side of the gate. Indeed, to pass through the Ishtar Gate is to pass into another realm entirely. Here all of the streets run straight, forming an orderly grid, while the buildings as well are tall, stately, and uniform. Most of all, though, you feel yourself to have surfaced within an explosion of color after many long days of being submerged in an arid ocean of dull browns. Brilliant blues, yellows, and whites are enameled everywhere, sometimes forming pictures, sometimes decorative patterns, sometimes ceremonial inscriptions, sometimes merely solid blocks of color for its own sake.</p>
<p>The Processional Way runs alongside the foot of Etemenanki. Said monument is, you can now see, a stepped pyramid of six stages, its sides a riot of colors, its dizzying peak seeming to merge with the sun itself. You have heard many stories of this, the world’s highest ziggurat. You know, for example, that it takes so long to ascend it that there is a shelter at the midway point with water and benches for the weary. You know that a shrine stands at the very top for the suppliants who come there to look down upon the awe-inspiring sprawl of the city while they pray. And you know that a single bed is also perched up there. Every night, so you have been told, one Babylonian woman of exceptional character and grace is allowed to sleep there at the top of this ladder to heaven, where the god Marduk himself visits her and has intercourse with her — some say spiritual intercourse, some say sexual.</p>
<p>On the other side of the Processional Way, you see another splash of color: a piercing botanical green this time. Here stands another terraced ziggurat, covered at every level with greenery that has no business growing in this land at this parched season of the year. The king of Babylon ordered it built for his favorite queen, who hails from a far-off land of dripping forests and babbling brooks, where water is plentiful rather than the scarce resource it is here. On its terraces can be found exotic trees and flowers the likes of which almost no Babylonian will ever see in their native habitats. The hydraulic engineering that brings the water of the Euphrates up to the thirsty greenery is a tribute to the sheer know-how of Babylon’s most accomplished men. Up at the botanical ziggurat’s top, which is lower but also much broader than that of Etemenanki, the king’s wives and his royal harem wander without their veils — wearing no clothing at all, some say — through a shady, fragrant paradise that rings with melodious birdsong. These are the Hanging Gardens of Babylon.</p>
<p>Such, at any rate, is one version of the ancient legend of Babylon and its Hanging Gardens. But when we wake from our daydream, we find that the real history is, as is so often the case, a thornier matter than the legend. In fact, the questions of when the Hanging Gardens were built, who built them, where they stood, what form they took, and whether they ever really existed at all have been vexing historians and archaeologists for centuries. Join me now as we look into the mystery that continues to surround an ancient vision of paradise so tempting, so evocative as to feel almost primal.</p>
<hr>
<p>You’re probably familiar with a certain species of travel book which only seems to grow more popular as time goes on: the pre-crafted traveler’s bucket list, offering up some absurd number of sights which everyone supposedly needs to see before she dies. These are aspirational, imaginative exercises at least as much as practical ones. After all, how many people have the time and money in the course of a single lifetime to visit — to pick a popular number among the list-makers — 1001 tourist traps scattered all over the world? Undoubtedly&nbsp; fewer than the number who enjoy dreaming about it.</p>
<p>It may surprise you to realize that such books are heirs to a long tradition. It turns out that the ancients had their bucket lists as well, albeit with a more modest number of entries. Anyone irritated by the widespread urge to list and rank every darn thing in modern times, anyone tempted to blame the short attention spans of our Internet-addled brains for the phenomenon, can perhaps take some comfort in knowing that the compulsion to make lists of things isn’t really so new at all. How else to explain the Seven Wonders of the World?</p>
<p>We can trace the Seven Wonders back to Herodotus, an Athenian scholar who set out circa 450 BC to write a history of the then-recently concluded Greco-Persian Wars; such, that is, was his ostensible purpose. But Herodotus was, bless his heart, a curious sort, and as he traveled all over the ancient world in the course of his research he just couldn’t resist writing down all of the interesting things he saw and heard about. Thus, in addition to being a massively important historical text, the only source we have describing countless pivotal events, Herodotus’s <em>Histories</em> can also be seen as the world’s first travel memoir. We know that he distilled from his longer work a list of Wonders of the World, presumably the first ever of its kind, but it exists today only as a passing reference in other works; the last extant copies of it were likely burned along with the Library of Alexandria during the early centuries after Christ. His bucket list would, needless to say, make for fascinating reading today.</p>
<p>After Herodotus, our investigation is stymied by yet more works which once existed but are now lost to us. We know, for example, that one Callimachus of Cyrene compiled an intriguing-sounding “collection of Wonders in lands throughout the world” in around 250 BC. Unfortunately, that is all we know of it; we know neither how many nor which Wonders he chose to include, nor how he framed the discussion, only that a work by that title once existed.</p>
<p>But then, probably only a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/">https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/</a></em></p>]]>
            </description>
            <link>https://analog-antiquarian.net/2020/09/25/chapter-1-the-ancients-bucket-list/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621384</guid>
            <pubDate>Mon, 28 Sep 2020 21:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nix × IPFS – Milestone 1]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24621276">thread link</a>) | @Fnoord
<br/>
September 28, 2020 | https://blog.ipfs.io/2020-09-08-nix-ipfs-milestone-1/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-08-nix-ipfs-milestone-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by John Ericson on 2020-09-08</p>

      

      

<p><a href="https://obsidian.systems/">Obsidian Systems</a> is adding support for IPFS to Nix so that build products can be persisted to and fetched from IPFS. This adds resiliency and makes it easier for Nix users to reproduce and distribute their work - by caching and distributing source code (and hopefully in the future intermediate build steps) peer to peer by using IPFS content addresses (CIDs).</p>

<h2 id="what-is-nix">What is Nix?</h2>

<p><a href="https://nixos.org/">Nix</a> is usually used as a package manager, but at its heart is a general-purpose build tool, like Make, Ninja, or Bazel.</p>

<p>What distinguishes Nix is its focus on sandboxing build steps and caching build artifacts.
With these features, neither the plans nor the build artifacts can have hidden dependencies, so builds can be reproduced and build artifacts shared robustly.</p>

<p>This makes Nix an ideal build tool to use with a peer-to-peer system like IPFS.
Indeed, the premier project using Nix is Nixpkgs, a package collection (with associated Linux distro) that is one of the largest most widely-contributed projects on GitHub.</p>

<h2 id="why-we-use-nix">Why we use Nix</h2>

<p>Obsidian Systems is an end-to-end software product consultancy serving everyone from recently funded startups to large institutions.
We have made Nix an integral part of both our production deployments and developer workflows since our founding 2014.</p>

<p>Nix is an indispensable tool for us because we frequently need to switch between projects, and Nix makes setting up and sharing per-project development environments trivial.
It has also made it easy to package software that the end user installs on their own machines, such as blockchain wallets.</p>

<h2 id="challenges-that-inspired-our-use-of-ipfs">Challenges that inspired our use of IPFS</h2>

<p>While Nix build plans are reproducible, one limitation that remains is the availability of the initial data—source code.
Nix plans have what are known as “fixed output derivations”.
These are unsandboxed build steps, with network access to download various sources.
They produce data that must match a pre-fixed hash, so the lack of sandboxing cannot be exploited to result in nondeterministic output.</p>

<p>The big problem with this is that if the URL becomes inaccessible or the data downloaded is non-deterministic (e.g. due to some metadata), this build step will fail —
in other words, we are facing the exact same problems around linkrot IPFS is trying to solve with the web in general!
The IPFS solution is the right one —
we shouldn’t be relying on the <em>location</em> at which some source code was originally uploaded.
And we’re already identifying source code by content addresses, so IPFS solution isn’t even a huge leap from our existing tooling and community practices.</p>

<p>Yes, we can already pin and cache the results of those fixed-output build steps just as we do with regular build steps, but we’re stuck with our own cache of source code completely independent from what upstream offers.
It is tedious and inefficient for users of Nix to each maintain their own uncooperative caches of source code, and even more so for the downstream user who would have to manually configure each of the caches individually, when all they want is some source code that is self-authenticating due to the content-address.</p>

<h2 id="value">Value</h2>

<p>For the Nix community at large, we finally have a chance to leverage our hard work on reproducibility and make it a practical reality.
Rather than relying on our centralized <a href="https://cache.nixos.org/">cache.nixos.org</a> to build artifacts before sources rot away, everyone should feel free to use Nixpkgs as a source or binary distro—as was originally intended.</p>

<p>For users of Obsidian’s open-source software specifically, they finally have an easy and robust way to trust neither our own pre-built binaries or <strong>cache.nixos.org</strong>’s, but build everything from source, which makes auditing security-critical code easier.</p>

<p>Ideally, we want to cache and distribute source code in collaboration with the upstream developers themselves and other downstream distributions.
<a href="https://ipld.io/">IPLD</a>, more than any other schema we’ve seen, understands the value of addressing data with its original intended “native” references, rather than some bespoke 3rd-party format that others cannot understand.</p>

<p>We think this is the key to enable that cooperation.
Upstream devs can simply continue working with git repos (or any other version control system with content-addressing that IPLD supports).
Downstream distros consume that data directly, without any conversion steps that obscure the data’s authenticity.
Neither party is faced with doing chores that the other used to handle.</p>

<h2 id="scope">Scope</h2>

<p>We aim to address these problems in two distinct phases.</p>

<h3 id="milestone-1-distribution-with-ipfs">Milestone 1: Distribution with IPFS</h3>

<p>We wanted Nix to be able to use IPFS as a “substituter” or provider of source/build artifacts alongside the other sorts of substituters that exist today.</p>

<p>As part of this, we taught Nix git tree hashing, so it can content-address git repos in a way IPFS will understand —
which helps IPFS, Nix, upstream collaborators, and other parties with an interest in archiving and disseminating source code find a common way to reference these artifacts.
While the git hashing scheme has its limitations, we think it is the best method for multi-party collaboration on git data.</p>

<p>Looking ahead to using IPFS for build products and deployments, we also added support for a metadata format around git tree hashing for IPFS and Nix to also convey data with run-time dependencies between separately-installed file system trees.
Finally, we provide a way for existing Nix build artifacts to be converted to this new data format.</p>

<h3 id="milestone-2-building-with-ipfs">Milestone 2: Building with IPFS</h3>

<p>Nix doesn’t actually content-address data produced by regular build steps (as opposed to the “fixed output” build steps described above).
Instead, it addresses them based on the plan from which they were made.</p>

<p>Situations exist — such as when someone edits a comment — where the plan changes but the results don’t.
Besides causing extra rebuilding downstream, this muddles the separation between the raw data and its provenance.
With peer-to-peer systems, it doesn’t matter who is <em>providing</em> the data (and we want to take advantage of that not mattering), but it absolutely does matter who is <em>claiming</em> what the data represents.</p>

<p>With this core improvement, we can make new improved versions of build plans in IPLD and produce our newly supported IPFS-compatible formats directly from each build step, no manual conversions from legacy input-addressed data needed. This final step brings everything from both milestones together.</p>

<p>For a complete breakdown, visit our <a href="https://github.com/ipfs/devgrants/blob/master/open-grants/open-proposal-nix-ipfs.md">open grant proposal</a>.</p>

<h2 id="what-was-accomplished">What was accomplished</h2>

<p>We’re happy to announce completion of Milestone 1! In response to community feedback, we were also able to do some extra work to get the Nix community started on using IPFS before migrating to the ideal git tree hashing.</p>

<p>This neatly lays the groundwork for some of our Milestone 2 objectives.
We hope this step can help everyone transition to using IPFS more gracefully.</p>

<p>Get started using our <a href="https://github.com/obsidiansystems/ipfs-nix-guide/">guide repo</a> and, in particular, our <a href="https://github.com/obsidiansystems/ipfs-nix-guide/blob/master/tutorial.md">tutorial</a>.</p>

<p>Finally, we recently did an interview on the <a href="https://zimbatm.com/NixFriday/">Nix Friday</a> stream going over all our work, and also discussing more broadly how we see the IPFS and Nix ecosystems fitting together.
You can watch a recording <a href="https://www.youtube.com/watch?v=FievtzvDbs82">here</a>:</p>


<p>
  <iframe src="//www.youtube.com/embed/FievtzvDbs8" allowfullscreen="" title="YouTube Video"></iframe>
</p>


<h2 id="what-s-next">What’s Next?</h2>

<p>We’ve begun implementing Milestone 2, including the improved build steps that produce content-addressed data.
We expect this to be the bulk of the work, with the final IPFS integration being relatively smooth, as by that point the concepts of Nix and IPFS will align so neatly!</p>

<p>We’ve been fastidious about juggling many branches to separate feature work from general improvements of the internals, and thus have been able to upstream many of those improvements.</p>

<p>We like this approach because it allows us to continuously engage with the community, and leaves much more readable diffs for the features themselves.</p>

<p>We hope you can give the demo a spin and like what you see.
Stay tuned for milestone 2!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-08-nix-ipfs-milestone-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621276</guid>
            <pubDate>Mon, 28 Sep 2020 21:13:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The SaaS website content you need to close sales]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24621132">thread link</a>) | @franciscassel
<br/>
September 28, 2020 | https://www.mikesonders.com/saas-website-content/ | <a href="https://web.archive.org/web/*/https://www.mikesonders.com/saas-website-content/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>The beauty of using keyword research to do market research is that we can literally uncover and quantify <em>exactly</em>&nbsp;what information a specific audience is looking for.</p>



<p>In this case, <strong>I’ve analyzed the online searches of thousands of B2B SaaS buyers to uncover exactly&nbsp;what information they want when considering a SaaS purchase.</strong></p>



<p>Based on the results, I can confidently say your SaaS website probably isn’t delivering everything SaaS buyers need. </p>



<p>I’m going to share the results of my analysis, and then show you how to translate the results into SaaS website content that answers prospect questions, addresses their objections, and gives them the confidence to purchase.</p>



<p>So if you’re ready to pave the way for more leads and revenue, let’s get started.</p>



<h3><strong>Contents</strong></h3>



<ul><li><a href="#quick">A quick note on methodology</a></li><li><a href="#results">The results: What SaaS buyers are searching for</a></li><li><a href="#best">Best practices: Creating the website content SaaS buyers want</a></li><li><a href="#method">Methodology &amp; raw data</a></li></ul>



<p>The recommendations in this post assume you’ve found product-market fit. Otherwise, building out your website content perhaps shouldn’t be at the top of your list of concerns.</p>



<h2 id="quick">A quick note on methodology</h2>



<p>If you’d like to see my full research methodology, you can <a href="#method">jump to the Methodology section</a> at the end of the post.</p>



<p>In short: I selected ten well-known B2B SaaS brands from among the <a href="https://www.mikesonders.com/largest-saas-companies/">largest SaaS companies</a> in the world. I then identified the ~16K branded searches (e.g., “hubspot pricing”, “servicenow login”, “zendesk support”, etc.) that people enter into Google to search for information on these brands.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image1-1024x248.png" alt="Branded keyword modifiers" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image1.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image1-300x73.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image1-768x186.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Among those ~16K branded search terms, I analyzed their modifiers to find the ones common to most of the ten SaaS brands. Of those common modifiers, I identified the ones that searchers use when considering a potential SaaS purchase.</p>



<p>E.g., “hubspot pricing” is a search that a potential buyer would use when considering a purchase; “hubspot investor relations” and “hubspot login” are not.</p>



<p>That is, <strong>I uncovered the search terms SaaS buyers use most commonly in the “consideration” phase of the buyer journey</strong>&nbsp;— when they’re gathering the information they need to decide (1) whether to make a purchase (i.e., convert) and (2) which vendor will get their money.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image11.png" alt="SaaS conversion funnel" width="550" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image11.png 788w, https://www.mikesonders.com/wp-content/uploads/2020/09/image11-300x236.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image11-768x604.png 768w" sizes="(max-width: 788px) 100vw, 788px"></figure></div>



<p>Using median search volumes, I indexed the relative demand for the information implied by each “consideration” modifier.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image6.png" alt="Branded search terms for SaaS reviews" width="550" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image6.png 804w, https://www.mikesonders.com/wp-content/uploads/2020/09/image6-300x193.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image6-768x495.png 768w" sizes="(max-width: 804px) 100vw, 804px"><figcaption><em>The median search volume for “reviews” keywords is 225.</em></figcaption></figure></div>



<h2 id="results">The results: What SaaS buyers are searching for </h2>



<h3>Pre-sale</h3>



<p>Search volumes for SaaS pricing information are so high–more than nine times higher than searches for “alternatives”–that including&nbsp;pricing data would have blown out the scale of a consolidated chart.</p>



<p>So, I show here the results across two charts, indexing to the demand for “alternatives” information in both:</p>



<figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info.png" alt="" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info.png 994w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info-300x93.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-pricing-info-768x238.png 768w" sizes="(max-width: 994px) 100vw, 994px"></figure>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1.png" alt="" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1.png 1020w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1-300x296.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-consideration-info-1-768x757.png 768w" sizes="(max-width: 1020px) 100vw, 1020px"></figure></div>



<p>It’s no coincidence that this chart looks like a bisected funnel.</p>



<p>Generally speaking, most buyers start their journey at the top of this list (with pricing) and proceed downward. As buyers fail to find satisfactory information that matches up with their needs, they fall out of the funnel.</p>



<p>For example:</p>



<ul><li>If the price is out of budget range, they’re going to be much less interested in getting a demo.</li><li>If the demo goes poorly (or simply shows that the solution doesn’t their your requirements), there’s not much reason to explore integrations.</li><li>If the solution doesn’t offer the specific integrations they need, getting a free trial is likely moot.</li></ul>



<p>The path of the B2B buyer journey certainly varies. Still, this chart paints a clear picture regarding the relative importance of different features, resources, and information SaaS buyers are seeking.</p>



<p>Correspondingly, <strong>you can use these data to prioritize the content (and features!) you create to keep buyers in your funnel and convince them that you’re the best solution</strong>.</p>



<p>Please note: it’s not that lower relative demand for certain information (e.g. “free trial) means that the information isn’t important. (Offering a free trial, if possible, is very important!) To some degree, it simply means there are fewer prospects left in the funnel at that stage seeking that information.</p>











<h3 id="post">Pre- and post-sale</h3>



<p>There’s a set of your resources–like your API documentation or support site–that your existing customers will Google instead of trying to find on your site.</p>



<p>So, it’s not <em>just</em>&nbsp;potential buyers creating the search demand for the following terms.</p>



<p>But I know from <a href="https://www.mikesonders.com/about/">my experience</a>&nbsp;that SaaS buyers oftentimes want to make sure these resources are available before they’ll pull the trigger on any purchase. &nbsp;&nbsp;</p>



<p>And (robustly) <strong>providing these resources is not only an excellent way to close more sales — it sets your customers up to succeed with your product, thereby improving your retention rates</strong>.</p>



<figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post.png" alt="" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post.png 876w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post-300x292.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/saas-content-pre-post-768x747.png 768w" sizes="(max-width: 876px) 100vw, 876px"></figure>



<p>In the next sections, I’ll show you best practices for putting these data into action as compelling content on your website.</p>



<h2 id="best">Best practices: Creating the website content SaaS buyers want</h2>



<h3 id="h.eaif2yj0bxlo">Pricing</h3>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image17-1024x647.png" alt="Help Scout pricing page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image17.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image17-300x190.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image17-768x486.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image17-1536x971.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>It makes sense that there’s a steep drop-off in demand for pricing information versus any other purchase-consideration information.</p>



<p>Pricing information is among the easiest to find on a SaaS website, and it’s a very straightforward litmus test that kicks off (or puts an abrupt stop to) the buying process:</p>



<p><em>Is the price low enough for me to consider, or is it so expensive that I shouldn’t even bother continuing to look into this solution?</em></p>



<p>Pricing can also put off potential buyers when it’s too confusing or when it’s simply missing from the website.</p>



<h4 id="h.fv29gmntzagy">Confusing pricing</h4>



<p>Do your pricing plans <a href="https://twitter.com/mikesonders/status/1285643715554549760" target="_blank" rel="noopener noreferrer">compare apples to apples</a>? Your mileage will vary, but I’ve helped clients <a href="https://twitter.com/mikesonders/status/1257751045729595394" target="_blank" rel="noopener noreferrer">double conversion rates</a>&nbsp;by simply clarifying their pricing pages. (Those links point to threads of mine on Twitter where I provide more details.)</p>



<h4 id="h.tgobcgqit9vl">Missing pricing</h4>



<p>You might (or might not) have good reasons for not providing pricing information on your website.</p>



<p>To avoid unnecessarily driving away prospective customers, <a href="https://businesscasualcopywriting.com/show-pricing-on-website/" target="_blank" rel="noopener noreferrer">consider these alternative approaches</a>&nbsp;formulated by <a href="https://twitter.com/JoelKlettke" target="_blank" rel="noopener noreferrer">Joel Klettke</a>.</p>



<h3 id="h.xvesd4pfueqe">Alternatives</h3>



<p>It makes logical sense that someone considering a meaningful purchase would want to uncover and evaluate all the appropriate alternatives.</p>



<p>That’s why a lot of people in the beginning of the SaaS buyer journey Google things like “[brand] alternative”, “[brand] competitors”, and “alternatives to [brand]”.</p>



<p>In the SaaS world, the search results for these queries tend to be dominated by listicles from the software comparison sites like Capterra, G2, and TrustRadius.</p>



<p>So your most important step is to <strong>make sure your app has a profile on the comparison sites that appear when someone searches on “[your_brand] alternatives”</strong>. And, of course, populate those profiles with positive reviews from customers — which I’ll discuss in a section below.</p>



<p>You should also consider or experiment with paying for better surfacing of your app on those comparison sites. It’s not uncommon for paid campaigns like these to be a top source of leads for SaaS startups.</p>



<p><strong>You can (and should) rank a page from your own site for these “alternatives” queries</strong>, <strong>whether someone is searching for alternatives to your brand, or to one of your competitors.</strong></p>



<p>I recommend following both of these methods:</p>



<h4 id="h.x05igpe9c7lt">The Best [Competitor] Alternative</h4>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image22-1024x512.png" alt="Plivo best alternative page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image22.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image22-300x150.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image22-768x384.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image22-1536x768.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Create a page on your marketing site or blog that positions your solution as the “Best [Competitor] Alternative”, where [Competitor] is a well-known brand in your vertical against whom you can position yourself effectively. &nbsp;</p>



<p>Start with the most well-known of your competitors, as more people will be searching for alternatives for them.</p>



<p>Here are a few examples of pages that follow this method and rank among the top search results for their respective “[competitor] alternatives” searches:</p>



<ul><li><a href="https://www.plivo.com/twilio-alternative/" target="_blank" rel="noopener noreferrer">Twilio Alternative | The best alternative to Twilio API | Plivo</a></li><li><a href="https://www.salesmate.io/pipedrive-crm-alternative/" target="_blank" rel="noopener noreferrer">One Of The Best Pipedrive Alternatives | Salesmate CRM</a></li><li><a href="https://supportbee.com/zendesk-alternative" target="_blank" rel="noopener noreferrer">A simpler, and smarter Zendesk alternative – SupportBee</a></li></ul>



<h4 id="h.z4bgyoba3kj">[Your_brand] Alternatives</h4>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image26-1024x742.png" alt="Jira alternatives page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image26.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image26-300x218.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image26-768x557.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image26-1536x1114.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>Yes, <a href="https://www.atlassian.com/software/jira/comparison" target="_blank" rel="noopener noreferrer">like JIRA</a>, you can have a page on your site that lists your competitors.</p>



<p>Why?</p>



<p>One, prospective buyers are going to discover your competitors, anyway.</p>



<p>Two, when someone is searching for alternatives to your solution, appearing in the search results at least gives you a chance&nbsp;to position yourself relative to your competition. To present your relative strengths and clarify your best-fit customer.</p>



<p>Otherwise, you’re letting your competitors or a 3rd-party site like Capterra define your positioning for you.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image4-1024x433.png" alt="JIRA alternatives search results" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image4.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image4-300x127.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image4-768x325.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image4-1536x650.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Atlassian has the fourth organic result when people search for alternatives to their product, JIRA.</em></figcaption></figure></div>



<p>Surprisingly, not many of the big SaaS brands–other than JIRA and <a href="https://www.salesforce.com/in/hub/crm/viable-salesforce-alternatives/" target="_blank" rel="noopener noreferrer">Salesforce</a>–have implemented this defensive strategy. &nbsp;</p>



<h3 id="h.r797chgho5xp">Demo</h3>



<p>Prospects want to see your solution in action. There’s a reason “Schedule a Demo” and similar are such common calls to action (CTAs) on SaaS websites–especially for sales-driven (vs. self-service) products.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image5-1024x609.png" alt="Churn Buster request a demo page" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image5.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image5-300x178.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image5-768x457.png 768w, https://www.mikesonders.com/wp-content/uploads/2020/09/image5-1536x914.png 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>



<p>But maybe you’ve got a relatively low-priced solution and it doesn’t make sense to schedule live demos with every prospect.</p>



<p>In that case, consider recording a demo and posting the video to a “demo” page on your website.</p>



<p>And I’d recommend uploading that demo to YouTube and giving the video a straightforward title.</p>



<p>Search results for “[brand] demo” typically feature video packs, and those video packs sometimes appear even before the brand’s own, relevant website content.</p>



<p><strong>Having demo content on your website <em>and</em>&nbsp;on YouTube gives you a chance to own more real estate in search results</strong>, thereby giving you a better chance to own the narrative.</p>



<div><figure><img src="https://www.mikesonders.com/wp-content/uploads/2020/09/image23-1024x832.png" alt="Shartsheet demo in search results" srcset="https://www.mikesonders.com/wp-content/uploads/2020/09/image23.png 1024w, https://www.mikesonders.com/wp-content/uploads/2020/09/image23-300x244.png 300w, https://www.mikesonders.com/wp-content/uploads/2020/09/image23-768x624.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Smartsheet created demo content on both its website and on YouTube, allowing it to dominate the first search results for “smartsheet demo”.</em></figcaption></figure></div>



<h3 id="h.toefavd2jjr">Reviews</h3>



<p>In competitive industries, search results for “[brand] reviews” are dominated by the big review-aggregation sites like G2, Capterra, and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikesonders.com/saas-website-content/">https://www.mikesonders.com/saas-website-content/</a></em></p>]]>
            </description>
            <link>https://www.mikesonders.com/saas-website-content/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24621132</guid>
            <pubDate>Mon, 28 Sep 2020 20:56:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software metrics: a guide for modern dev leaders]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24620919">thread link</a>) | @necco908
<br/>
September 28, 2020 | https://linearb.io/blog/17-software-metrics-for-modern-dev-leaders/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/17-software-metrics-for-modern-dev-leaders/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/17-Metrics-Blog-Cover.png.webp 1200w" sizes="(max-width: 1200px) 100vw, 1200px">
<img src="https://linearb.io/wp-content/uploads/2020/06/17-Metrics-Blog-Cover.png" alt="Software metrics for modern dev leaders" srcset="https://linearb.io/wp-content/uploads/2020/06/17-Metrics-Blog-Cover.png 1200w, https://linearb.io/wp-content/uploads/2020/06/17-Metrics-Blog-Cover-300x157.png 300w, https://linearb.io/wp-content/uploads/2020/06/17-Metrics-Blog-Cover-1024x536.png 1024w, https://linearb.io/wp-content/uploads/2020/06/17-Metrics-Blog-Cover-768x402.png 768w" sizes="(max-width: 1200px) 100vw, 1200px">
</picture>
</figure>



<h2><strong>Software metrics that help accelerate delivery, maintain a positive culture, and translate dev activity to business value</strong></h2>



<h3><strong>Motivation to be data-driven</strong></h3>



<p>As dev leaders, we spend most of our time translating between two groups of people in two parallel universes. Most CEOs and board members come from the business side (sales, marketing, finance) and while they enjoy the outcomes of engineering, they don’t fully understand how we work. At the same time, many engineers don’t fully understand the business side of the organization. This is the background of most dev leaders. The right software metrics can help provide a common language between dev leaders and business executives. </p>



<figure><blockquote><p>Save or share “17 Software Metrics for Modern Dev Leaders”. </p><p><a href="https://linearb.io/metrics-modern-dev-leaders-purple/" target="_blank" rel="noreferrer noopener">Click here to download</a></p></blockquote></figure>



<p>Driven to help our teams succeed and bridge the gap between engineering and the business, many of us have turned to data and metrics. But what software metrics truly help us accelerate delivery and correlate to KPIs the business cares about (revenue, leads, retention)?</p>



<p>We would all agree that measuring the right things is important. But some software development teams still use legacy measurements that actually stop them from getting better. We call these metrics anti-KPIs. Some of the most common software development anti-KPIs include <a href="https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/" target="_blank" rel="noreferrer noopener">velocity (story points completed)</a>, lines of code, code commits, Jira tickets completed.</p>



<div><figure><img src="https://linearb.io/wp-content/uploads/2020/06/Anti-KPI-1024x1024.png" alt="" width="256" height="256" srcset="https://linearb.io/wp-content/uploads/2020/06/Anti-KPI-1024x1024.png 1024w, https://linearb.io/wp-content/uploads/2020/06/Anti-KPI-300x300.png 300w, https://linearb.io/wp-content/uploads/2020/06/Anti-KPI-150x150.png 150w, https://linearb.io/wp-content/uploads/2020/06/Anti-KPI-768x768.png 768w, https://linearb.io/wp-content/uploads/2020/06/Anti-KPI.png 1394w" sizes="(max-width: 256px) 100vw, 256px"></figure></div>



<p>What do these anti-KPIs all have in common? First, they may on the surface indicate that your contributors are busy but they don’t actually help you figure out if you’re providing value to customers.</p>



<p>Second, they encourage the wrong behavior. Is writing more code good? Maybe. Or maybe it is a sign of inefficiency. Do completed Jira tasks show productivity? Most developers would argue that what happens in Jira has little to do with the “real work” of writing code. Third, and worst of all, these anti-KPIs can easily be gamed.&nbsp;</p>



<p>Your contributors that are struggling might be tempted to inflate these anti-KPI numbers (which they can do easily) which actually blocks you from giving them the help they need.&nbsp;</p>



<p>So what should modern dev leaders measure? Keep reading to discover 17 software metrics that matter for dev leaders and how to use them.</p>







<h2><strong>Which Software Metrics to Measure?</strong></h2>



<p>At LinearB we think of operational excellence in software engineering as the pursuit of predictably delivering projects, with high quality, maintaining efficient working hours, with happy contributors and teams, continuously improving. That’s a lot 🙂 But we think it’s possible.</p>



<p>It can seem overwhelming – especially if you’re not sure how you’re doing against all of those dimensions and what steps can be taken to improve. We worked backwards from the goal of delighting our customers and being operationally excellent and came up with 12 key performance indicators. Some you’re probably already measuring. Some may be new to you.</p>



<p>We look at three categories of software metrics:</p>



<ul><li>Delivery Pipeline</li><li>Investment Profile</li><li>Quality</li></ul>



<p>And we measure those categories across 2 dimensions</p>



<ul><li>Iteration</li><li>Team</li></ul>







<figure><blockquote><p>Looking for key metrics about your team, updated in real-time?</p><p><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Give LinearB a try. Free for 21 days</a>.</p></blockquote></figure>



<h3><strong>Measure Your Software Delivery Pipeline</strong></h3>



<p>Your software delivery pipeline is what enables your team to deliver code to production. It includes all of the phases from “work requested” all the way through release to production and validation. Some of the common phases include development work beginning, pull request open, pull request merge, and release to prod.</p>



<p>Efficient delivery pipelines lead to predictable value delivery, happy developers, happy product owners, and happy customers. Frustrations arise with inefficient pipelines. These situations can happen when code is merged and ready to be released but “the release is not until next week” or when a developer has opened a pull request but it takes days to receive a review or when a story has been sitting in the backlog for weeks.</p>



<p>Measuring the stages of your delivery pipeline allows for bottleneck detection. This provides a high leverage point to increase your delivery performance because it impacts all teams and contributors.</p>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/05/cycle.png.webp 1800w" sizes="(max-width: 1800px) 100vw, 1800px">
<img src="https://linearb.io/wp-content/uploads/2020/05/cycle.png" alt="Cycle time is a key software metric for modern dev leaders." srcset="https://linearb.io/wp-content/uploads/2020/05/cycle.png 1800w, https://linearb.io/wp-content/uploads/2020/05/cycle-300x210.png 300w, https://linearb.io/wp-content/uploads/2020/05/cycle-1024x717.png 1024w, https://linearb.io/wp-content/uploads/2020/05/cycle-768x538.png 768w, https://linearb.io/wp-content/uploads/2020/05/cycle-1536x1075.png 1536w" sizes="(max-width: 1800px) 100vw, 1800px">
</picture>
</figure>



<h4><strong>ESSENTIAL SOFTWARE METRICS FOR DELIVERY PIPELINE</strong></h4>



<p><strong><a href="https://linearb.io/cycle-time/" target="_blank" rel="noreferrer noopener"><em><span>Cycle Time:</span></em> </a></strong>The amount of time from work started until work finished.</p>



<p>Why it matters: Cycle time is the #1 indicator of your speed to value and efficiency ratio.</p>



<p>Note: Many of you are already measuring (or trying to measure) cycle time. But what do you do when you think your cycle time is too high? The next four software metrics help you diagnose where to spend your time to drive cycle time down.</p>



<p><span><strong><em>Deployment Frequency:</em> </strong></span>The number of releases per day.</p>



<p>Why it matters: This is a strong indicator of how much value your team is capable of getting into the hands of customers. Even if you have an efficient pipeline, if your deployment frequency is low, you may not be delivering enough value.</p>



<p><em><strong><span>Lead time:</span></strong> </em>The amount of time from work requested until release.</p>



<p>Why it matters: Start time + Cycle time = Lead time. Once you understand your cycle time, looking at start time can tell you how long it takes on average to get through your product management process and backlog. If you have high start times it could be an indication you need to hire more contributors or change the way you set expectations with customers and your sales team.</p>



<p><em><strong><span>Time to release:</span></strong></em> The amount of time from Pull Request Merged to Production Release</p>



<p>Why it matters: Your developers may have finished their job but your customers may not be getting the value. If time to release is high, it could mean you need to invest more in continuous deployment (CD) or that you have an opportunity to move to a micro-service architecture.&nbsp;</p>



<p><strong><span><em>Time to merge</em>:</span></strong> The amount of time from first Commit to PR Merged</p>



<p>Why it matters: This is a key indicator of your cycle time. It can show the efficiency of your pipeline and it affects all members of your team. If time to merge is high it could be an indication that you’re lacking automation or your team needs additional coaching or process or an indicator your developers are not getting enough detail from product management.</p>



<p><strong><span><em>Review request waiting time or pickup time</em>:</span></strong> The amount of time it takes from the pull request submitted until review begins.</p>



<p>Why it matters: Efficient teams have a low pickup time. The less time PRs spend waiting for review, the faster they are released. This metric is important for all dev teams but is even more critical for remote dev teams.&nbsp;</p>



<iframe width="560" height="400" src="https://www.youtube.com/embed/NKSqXi2q4f0?rel=0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><p>Long-living PRs increase pickup time and can derail cycle time.



</p>



<h3><strong>Measure Your Investment Profile</strong></h3>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/Group-547.png.webp 1238w" sizes="(max-width: 1238px) 100vw, 1238px">
<img src="https://linearb.io/wp-content/uploads/2020/06/Group-547.png" alt="Software metrics about the investment profile help dev leaders see how teams allocate resources." srcset="https://linearb.io/wp-content/uploads/2020/06/Group-547.png 1238w, https://linearb.io/wp-content/uploads/2020/06/Group-547-300x130.png 300w, https://linearb.io/wp-content/uploads/2020/06/Group-547-1024x445.png 1024w, https://linearb.io/wp-content/uploads/2020/06/Group-547-768x334.png 768w" sizes="(max-width: 1238px) 100vw, 1238px">
</picture>
</figure>



<p>The most valuable asset that your organization possesses is your people’s time. It is a scarce and limited resource. There are many forces pulling at your team’s time. Your CEO wants to deliver new value to customers, your engineers want non functional investment, the support team wants to fix bugs, and your sales team brings customer commitments. Lacking visibility into where your team is actually spending time makes balancing all of these forces very difficult.</p>



<p>Your investment profile is a data-driven representation of the types of work in which your team is spending effort. The work types typically include, but are not limited to, stories, non-functional tasks, and bugs.</p>



<p>Measuring and tracking your investment profile puts you back in control. It allows you to determine if your actual investment areas match your expected investment areas. It also allows you to be in the driver’s seat when interacting with stakeholders like your CEO or Product lead.</p>



<h4>ESSENTIAL SOFTWARE METRICS FOR INVESTMENT PROFILE</h4>



<p><strong><span><em>Story to Bug Ratio:</em> </span></strong>The ratio of completed stories to completed bug.</p>



<p>Why it matters: You probably know how many production bugs you have but do you know the effect it has on your customer-facing work? Your contributors certainly know when they feel like they are spending too much time on bugs. Quantifying the impact can help you decide if you have a bigger issue to investigate.</p>



<p><em><strong><span>Support &amp; Sales Issues:</span></strong> </em>The percentage of work dedicated to one-off requests coming from the support or sales team.</p>



<p>Why it matters: If you build software for large enterprises, developing based on support and sales team requirements may be a great use of resources. If not, if this ratio of work is high, it could be an indication of planning issues.</p>







<h3><strong>Measure Your Work Quality</strong></h3>



<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/06/Group-548.png.webp 1200w" sizes="(max-width: 1200px) 100vw, 1200px">
<img src="https://linearb.io/wp-content/uploads/2020/06/Group-548.png" alt="Software metrics like work breakdown can help predict quality issues." srcset="https://linearb.io/wp-content/uploads/2020/06/Group-548.png 1200w, https://linearb.io/wp-content/uploads/2020/06/Group-548-300x258.png 300w, https://linearb.io/wp-content/uploads/2020/06/Group-548-1024x881.png 1024w, https://linearb.io/wp-content/uploads/2020/06/Group-548-768x660.png 768w" sizes="(max-width: 1200px) 100vw, 1200px">
</picture>
</figure>



<p>Most teams have experienced the situation where low quality leads to missed delivery dates, iteration interruptions, long hours, unhappy customers, and a frustrated engineering organization. On the flip side, high quality leads to predictable delivery, efficient work hours, happy customers, and a happy engineering organization.</p>



<p>There are many different metrics that you could measure as an engineering leader. Some of the classics range from test coverage to service uptime. While these metrics are great, we have found that there are a few metrics that really help to measure delivery predictability.</p>



<h4>ESSENTIAL SOFTWARE METRICS FOR QUALITY</h4>



<p><strong><span><em><a href="https://video.drift.com/v/ab9M6hmJei6/" target="_blank" rel="noreferrer noopener">High-risk work:</a></em> </span></strong>Branches with large change and high rework or refactored work.</p>



<p>Why it matters: The general rule on most dev teams is that the larger the change, the higher the risk (i.e. branches with 300 lines of code are riskier than small branches). Branches with a high percentage of rework and refactored work are also riskier. High-risk work is a leading indicator of quality.</p>



<p><span><strong><em>Code Rework</em>: </strong></span>Percentage of recently delivered code your team is already rewriting.</p>



<p>Why it matters: A high rework percentage could mean you have a training issue, you’re rushing the process, your review process is lacking or you have a breakdown in communication with product management.</p>



<p><em><span><strong>Bugs Found in Prod:</strong></span></em> The number of bugs found in production per time period.</p>



<p>Why it matters: …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/17-software-metrics-for-modern-dev-leaders/">https://linearb.io/blog/17-software-metrics-for-modern-dev-leaders/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/17-software-metrics-for-modern-dev-leaders/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24620919</guid>
            <pubDate>Mon, 28 Sep 2020 20:30:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Field Guide to Genetic Programming (2008) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24620614">thread link</a>) | @optimalsolver
<br/>
September 28, 2020 | http://libros.metabiblioteca.org:8080/bitstream/001/184/4/978-1-4092-0073-4.pdf | <a href="https://web.archive.org/web/*/http://libros.metabiblioteca.org:8080/bitstream/001/184/4/978-1-4092-0073-4.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://libros.metabiblioteca.org:8080/bitstream/001/184/4/978-1-4092-0073-4.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24620614</guid>
            <pubDate>Mon, 28 Sep 2020 19:53:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Negotiating the developer-to-tester ratio. 3:1 is just the beginning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24620351">thread link</a>) | @ohjeez
<br/>
September 28, 2020 | https://www.functionize.com/blog/how-many-developers-does-it-take-to-test-a-product/ | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/how-many-developers-does-it-take-to-test-a-product/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/09/ft-devs-to-qa-ratio.jpg" alt="How many developers does it take to test a product?" srcset="https://www.functionize.com/wp-content/uploads/2020/09/ft-devs-to-qa-ratio.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/09/ft-devs-to-qa-ratio-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/09/ft-devs-to-qa-ratio-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/09/ft-devs-to-qa-ratio-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Most development shops want QA testers involved in creating their new software. But what’s the proper ratio of testers to developers? Yes, “it depends,” but let’s look at the answers to, “…on what?”</p></blockquote>
<p>Development shops generally agree that quality assurance testing is a good thing, but that attitude is by no means universal. Even when development teams want QA testing, they may disagree about how many team members should devote themselves to testing full time rather than writing code. In a few organizations, the policy seems to be that developers should do their own testing, eliminating any need for separate testers.</p>
<p>Adding to the lack of agreement is the fact that not all types of development are the same. For example, teams developing interactive, informational webpages require different testing procedures than do teams creating airliner control systems. Likewise, some approaches, such as Agile development, have a built-in tester-to-developer ratio in which QA testers are an essential part of the team.</p>
<p>Still, in general there must be an ideal ratio of testers to developers, right? Well, maybe. As with everything else, the most you can say is that “it depends.” There are lots of <a href="https://www.functionize.com/blog/8-ways-to-know-that-its-time-to-hire-a-new-qa-tester/">reasons to say, “It’s time to hire a new QA professional,”</a> after all.</p>
<p>So if you realistically need a QA team, how big should it be?</p>
<h3>Start with one tester for two-to-five developers, and adjust accordingly</h3>
<p>Again and again, I was told about that popular ratio: one tester for every three to four developers. But use that as a starting point, not a <a href="https://amzn.to/32XAB1A" target="_blank" rel="noopener noreferrer">formal design pattern</a>, urge experienced developers and testers.</p>
<p>“There is no set-in-stone ratio that works perfectly for every scenario,” said James Boatwright, CEO of&nbsp;<a href="https://www.thecodegalaxy.com/" target="_blank" rel="noopener noreferrer">Code Galaxy</a>, which teaches programming skills to children. The testing scenarios should guide you. “While in most cases, for every two to five developers, one tester would be fine, some circumstances may require one tester for every developer, or maybe even two developers,” he says. This allows testers to focus on specific platforms or use cases.</p>
<p>As Jimmy Kamboj, founder of custom software firm <a href="https://www.imensosoftware.com/" target="_blank" rel="noopener noreferrer">Imenso&nbsp;Software</a>, says, many variables come into play, ranging from <a href="https://www.functionize.com/blog/5-rules-for-successful-test-automation/">the availability of automation tools in testing</a> to the income reliability of the project, to how much of the testing can be automated. “While one good tester is enough for a set of three, perhaps even four developers, a lot of things – like what is the scale of the project and what is being built – is extremely crucial to determine the ideal ratio,” he explains.</p>
<p>If your project uses Agile methodology, <a href="https://www.functionize.com/blog/lets-make-testing-agile-they-said-uh-what-did-they-mean-by-that/">expect to hire more testers</a>, because its premise includes the expectation that the testers are actively involved in improving the product. &nbsp;At custom web development company <a href="https://sprout.co.id/" target="_blank" rel="noopener noreferrer">Sprout</a>, squads have four developers, one user interface/user experience specialist, one product person, and one QA tester, says the company’s director, Arnold Sebastian Egg. After a sprint is complete, an automated QA engineer automates the previous test scripts of the previous test journey to make sure quality is maintained, Egg adds.</p>
<p>While a 3:1 ratio is the popular answer, it’s certainly not the <em>only</em> answer. For Reuben Yonatan, founder and CEO of&nbsp;<a href="https://getvoip.com/">GetVoIP</a>, development team size is usually five or six developers. “An average team will therefore have two testers and five developers to make a total of seven. I am comfortable with that ratio, and from experience, more developers might hinder the product instead of enhancing it.”</p>
<h3>Adjust developer:tester ratio based on expertise requirements – and tester experience</h3>
<p>Complex projects require more people to connect the dots, or specialists who know <a href="https://www.functionize.com/blog/what-testers-should-know-about-domain-knowledge/">how to find bugs in particular knowledge domains</a> (such as security testing or mobile applications). That may justify hiring someone with particular knowledge. That boosts the “standard” ratio to one QA tester for every two developers.</p>
<p>“The more complex a project, the more developers and testers it requires,” says Michal Kowalkowski, co-founder and CEO of <a href="https://www.nospoilers.ai/" target="_blank" rel="noopener noreferrer">NoSpoilers.AI</a>, where the developer:tester ratio is currently 3:1. “But writing tests can prove slower than the actual development.”</p>
<p>“Some features we develop take less time to test and troubleshoot, but some features are really complex,” agrees Oleg Donets, CEO at <a href="https://odmsoft.com/" target="_blank" rel="noopener noreferrer">ODMsoft</a>, which currently employs seven developers and two testers. “If we decide to get more developers on board, we’d try to keep the QA people in the same ratio.”</p>
<p>The ratio of two developers to one tester is used by Daniel Florido, lead developer at web development firm <a href="https://pixelstorm.com.au/" target="_blank" rel="noopener noreferrer">Pixelstorm</a>. “Testers are not just responsible for testing software end output.&nbsp;All development tasks should be tested, for technical bugs, device, and browser bugs as well as functional testing and usability testing.” That also enables developers and testers to learn one another’s style and practices. Testers may learn about a developer’s the strengths and weaknesses, and find out how to best provide feedback. Doing so, explains Florido, improves efficiency as well as team morale.</p>
<p>“We’ve spent years working out&nbsp;the right ratio for both profitability and accurate product delivery,” Florido continues.&nbsp;“For a tester to do what they need to with complete focus, this is the ideal outcome.”</p>
<h3>Look at other ratios, too</h3>
<p>But you should look at more than the number comparison for “developer head count.” Jon Quigley, principal of <a href="https://www.valuetransform.com/" target="_blank" rel="noopener noreferrer">Value Transformation</a>, allocates testers in a development environment based on financial number. “It should be 30% to 50% of the hours or money. For every two people that’s one tester or testing activity.”</p>
<p>Depending on project size, that testing activity could involve a lot of people. Quigley’s specialty is mission critical applications, including automotive, heavy truck, and mining equipment product development. A single failure could lead to death or disaster.</p>
<h3>Can you afford to hire another tester? Can you afford <em>not</em> to?</h3>
<p>Whatever your team’s need for QA testing, and its ability to hire good people, the need for QA testers can only grow. David Moise, president of <a href="https://decideconsulting.com/" target="_blank" rel="noopener noreferrer">Decide Consulting</a>, says that this could be a challenge. “There is a 9:1 ratio of developers to testers in the job market,” Moise says, noting that this has improved from an earlier ratio of 11:1. “To include front end people, it’s more like 13:1.”</p>
<p>That means it’s harder to hire QA testers that it used to be. “The skills are changing and there are more demands on what people need to have,” Moise says. “Before, you needed just to have experience testing. Now you need experience using automated platforms. They’re more expensive.”</p>
<p>What this means to the tester-to-developer ratio: It’s going to cost companies more to hire the testing staff they need. (On the other hand, if you’re a tester looking for a new job, this means you can ask for more money! Yay you! Just be sure to <a href="https://www.functionize.com/blog/what-should-be-on-a-qa-testers-resume/">level-up your QA tester’s resume</a>.)</p>
<p>And before you can accomplish that, you need buy-in from the people who hold the purse strings – who think that the developers can do it all. According to Sami Ullah, spokesperson for <a href="https://www.kualitatem.com/" target="_blank" rel="noopener noreferrer">Kulitatem</a>, a software QA testing company, some companies simply don’t want to spend the money. “They think QA as overhead for the company,” Ullah explains. That might happen, he posits, when “the company is quite small so they can’t afford hiring separate QA staff; the company has not defined departments and roles; they don’t realize the importance of QA (which they will eventually realize, after rolling out buggy applications in production).”</p>
<p>“Management has to see the value in QA,” Moise says. The considerations need to include the cost to fix a bug versus finding in during development. The amount of risk are you willing to tolerate, and the potential damage to your product’s reputation if your software looks bad. “Some companies don’t get it,” he says.</p>
<blockquote><p>Who does that hiring? Who makes this decision? As our white paper argues, perhaps it should be <a href="https://www.functionize.com/project/why-your-enterprise-needs-a-cqo-chief-quality-officer/">the chief quality officer</a>.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/WR-NBC-Photo-72DPI.jpg" alt="Wayne Rash"></p>
<div>
<p><span>by</span> Wayne Rash</p>
<p>Wayne Rash is based in Washington and has been writing about science and technology for nearly 40 years. He is a contributor to Forbes.com and a columnist for eWEEK. He is a frequent speaker on technology and has been a guest on NPR, NBC, PBS, CNN and Fox News.</p>
</div>

</div>
</div>
  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/how-many-developers-does-it-take-to-test-a-product/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24620351</guid>
            <pubDate>Mon, 28 Sep 2020 19:27:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on running spaCy: commercial open-source NLP]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24620337">thread link</a>) | @dsr12
<br/>
September 28, 2020 | https://ines.io/blog/spacy-commercial-open-source-nlp | <a href="https://web.archive.org/web/*/https://ines.io/blog/spacy-commercial-open-source-nlp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As more and more people and companies are getting involved with open-source
software, balancing the expectations of an open community and a traditional
provider vs. consumer relationship is becoming increasingly difficult. Are
maintainers becoming too authoritarian? Are users becoming too demanding? Are
large companies selling out open-source?</p>
<p>In this post I’ll share some lessons we’ve learned from running
<a href="https://spacy.io/" target="_blank" rel="noopener nofollow noreferrer">spaCy</a>, the popular and fast-growing library for Natural
Language Processing in Python. I’ll also give you my perspective on how to make
commercial open-source work for both users and developers.</p>
<h2>Unpacking open-source</h2>
<p>Looking at the open-source ecosystem as one giant space with a fixed set of
rules and best practices can be problematic and frustrating. It’s frustrating
for maintainers of private projects, who end up overwhelmed by the flood of bug
reports and often demanding support requests. It’s frustrating for companies who
open-source their tools and are suddenly expected to get as many contributors
involved as possible. And it’s frustrating for users, who keep getting told to
“submit a PR or shut up”, and are struggling to decide which project to adopt
and trust.</p>
<p>Most open-source projects roughly fall into one of three categories:</p>





























<table><thead><tr><th></th><th><h4>Private</h4><em>“I made a thing and it’s over here.”</em></th><th><h4>Community</h4><em>“Let’s make a thing together.”</em></th><th><h4>Commercial</h4><em>“We made a product and it’s free.”</em></th></tr></thead><tbody><tr><td><strong>Maintainer Control</strong></td><td>high</td><td>low</td><td>high</td></tr><tr><td><strong>Maintainer Responsibility</strong></td><td>low</td><td>medium</td><td>high</td></tr><tr><td><strong>User Responsibility</strong></td><td>high</td><td>high</td><td>low</td></tr></tbody></table>
<p>Private projects are usually maintained by one person making most of the
decisions, but bearing little responsibility. After all, it’s just a person
sharing their code or showcasing their work, hoping it might be useful to
others. Community projects tend to make decisions collectively: maintainers take
responsibility for the software, but ultimately, users are expected to get
involved, instead of only making demands. In return, they get a say in the
project direction.</p>
<p>Commercial projects on the other hand generally stay more centralised:
maintainers often run a business related to their software and retain more
control over their project, while investing more resources and expecting less of
their users. Even projects by very large companies like Google and Facebook with
sizable developer communities roughly follow the same line of thought.</p>
<h2>A case for centralised, commercial open-source</h2>
<p>In many ways, <a href="https://spacy.io/" target="_blank" rel="noopener nofollow noreferrer">spaCy</a> is a pretty typical commercial
open-source project. It’s developed and maintained by mostly two people – Matt
and me. spaCy puts our work in front of many developers, which has allowed us to
bootstrap our company <a href="https://explosion.ai/" target="_blank" rel="noopener nofollow noreferrer">Explosion AI</a> independently through
consulting work while keeping our software free.</p>
<p>spaCy’s strength is that it’s easy to use, fast and opinionated. There’s only
one implementation of each component, and we’re trying to make it the best
possible one. At the same time, the core of spaCy is inherently hard to
contribute to. It’s fast because it’s written in <a href="http://cython.org/" target="_blank" rel="noopener nofollow noreferrer">Cython</a>, a
relatively niche language. The API is easy to use because it’s cohesive and was
mostly written by a single author.</p>
<p>All of this makes spaCy a good fit for production use, and we’re excited to see
more and more companies using it to power great products. But growth also comes
with responsibility. By making the choice to adopt our open-source software, our
users are offering us a large amount of trust upfront. <strong>We’re asking for
that trust, so we need to keep up our end of the bargain</strong>. If something is
broken, <em>we</em> need to fix it. If we rely on users to report problems, <em>we</em> better
make their experience pleasant. If we’re encouraging people to use spaCy in
production, <em>we</em> are responsible for making it work. And if we want to keep
spaCy cohesive and maintain attention to detail, <em>we</em> need to take the lead.</p>
<p>As we’re moving into a phase with more options for contributions, we want to
encourage them where they make the biggest difference: language data,
interoperation, tests and documentation. After we provided more docs and
refactored our website’s markup language, we saw a big increase in small pull
requests – from fixing minor typos in the docs (I admire everyone who goes out
of their way to do this!) to adding tokenizer exceptions for Bengali or Hebrew.</p>
<p>Our community consists of people with very different backgrounds and motivations
– developers who’ve been working in computational linguistics since before it
was cool, deep learning engineers training models with text input, data
scientists and digital humanities researchers, mobile app developers working on
their first bot and computer science students looking to get started. (For the
record, my background is front-end development, marketing and linguistics.) <strong>AI
is not a field of homogenous skills and experiences</strong>, and if we want to build
great software, need to adapt the way we think about community-driven
development.</p>
<h2>Challenges for open-source NLP</h2>
<p>One of the biggest challenges for Natural Language Processing is dealing with
fast-moving and unpredictable technologies. Most open-source development follows
a basic assumption: There’s a bug, and there’s a fix. There’s a feature, and
there’s an implementation. The quality of the code may vary and there are always
trade-offs. But ultimately, there’s a path, and there’s a goal. This is a lot
less true in AI or NLP.</p>
<p>Since spaCy was released, the best practices for NLP have changed considerably.
This also means that the library has had to change a lot. For instance,
dependency labels used to be much more relevant – now, our biggest focus is
getting spaCy up to speed with deep learning. However, new features and
enhancements are still based on very subjective assumptions about how people are
going to do NLP in the future. And it’s not only about code. There’s another
component that’s just as important: <strong>statistical models</strong>.</p>
<p>In the past, spaCy’s models had to be downloaded via a server maintained by us.
Although they played a huge part in spaCy’s performance, they were mostly hidden
away from the user. This was problematic – black-boxing technology is pretty
much the opposite of what we want to stand for. But how do you “open-source”
large binary data?</p>
<p>In spaCy v1.7, we finally introduced a
<a href="https://spacy.io/docs/usage/saving-loading" target="_blank" rel="noopener nofollow noreferrer">new way of loading models</a>, by
wrapping them as Python packages that can be installed via pip. All files are
also available attached to individual
<a href="https://github.com/explosion/spacy-models/releases" target="_blank" rel="noopener nofollow noreferrer">GitHub releases</a>,
containing more information on the model’s capabilities, license and data. We’ve
also included a model packaging tool in spaCy’s CLI so users can package their
own models.</p>
<p>Aside from the obvious advantages, like native versioning and pip installation,
model as packages send a much more <strong>reasonable message</strong>: A model is a
component of your application, just like any other dependency. In reality,
there’s not one “the model”. There can be many different ones with different
capabilities, that will produce very different results depending on what you do
with them. You can train your own models from scratch, or update existing ones.
And you can package and share your models with the community, just like we do.</p>
<h2>Giving projects a voice</h2>
<p>Whether you want it or not, your project will have a voice. Yours. This includes
everything you say and do – from documentation you write to issues you answer.
If a project sends mixed messaging, it causes confusion and conflicts. The
website says “Use our software!”, while the maintainers say “PR or GTFO”. The
community guidelines say that “there are no stupid questions, just stupid
answers”, while the maintainers mock their user’s issues on Twitter. Being rude
is not quirky, and it doesn’t save you any time or money either. People will not
appreciate your work more if you put them down.</p>
<p>This is also important to keep in mind when talking about diversity in
open-source and building an inclusive community. It’s not enough to simply adopt
community standards and state that “everybody’s welcome”. If this is what you
believe in, it also needs to be reflected in the overall messaging of your
project. (GitHub’s
<a href="https://opensource.guide/building-community/" target="_blank" rel="noopener nofollow noreferrer">Open Source Guide</a> has a nice
summary on this topic.) There’s also a difference between giving detailed
guidance, and enforcing strict rules. People are less likely to invest time and
contribute to a project if there’s a high potential of “doing things wrong” —
either due to lack of clarity, or arbitrary and overly rigid rules where every
deviation will be scrutinised.</p>
<p>Another root cause of mixed messaging is a lack of predictability. Users and
contributors should know where the project is going – even if ultimately, the
maintainers are going to be the ones making the decisions.
<a href="https://medium.com/swlh/the-unreliable-startup-69461f629383" target="_blank" rel="noopener nofollow noreferrer">Unreliable startups</a>
and their amazing journeys have made people wary of being lured in with big
promises, only to be let down.</p>
<p>One of our goals for spaCy is to focus on communicating our plans and ideas more
openly. This is one of the downsides of being such a small team: a lot of
decisions happen in one or two heads, which deprives the community of insights
into the process. Some of our decisions have been
<a href="https://github.com/explosion/spaCy/issues/962" target="_blank" rel="noopener nofollow noreferrer">more controversial</a> than others,
but no matter how much thought we put into them, it becomes irrelevant if we
don’t talk about it publicly. (Docker’s
<a href="https://github.com/moby/moby/pull/32691" target="_blank" rel="noopener nofollow noreferrer">recent fiasco</a> is an example of how
this can go very wrong and cause a lot of frustration.)</p>
<h2>Avoiding issue tracker bankruptcy</h2>
<p>By running spaCy in a centralised way, we accept that we have to be the main
source of support for now. This is hard, and we’ve not always been doing a great
job at this. It’s easy to get get stressed out when seeing the issue count go up
and falling behind on maintenance. We’ve all seen it before in other projects:
issues keep piling up and the maintainers, unable to keep up, eventually declare
issue tracker bankruptcy.</p>
<p><span>
      <a href="https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/02884/open-source_bankruptcy.jpg">
    <span></span>
  <picture>
        <source srcset="https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/3f012/open-source_bankruptcy.webp 198w, https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/e5ab5/open-source_bankruptcy.webp 395w, https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/c6f09/open-source_bankruptcy.webp 590w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
        <source srcset="https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/fbe57/open-source_bankruptcy.jpg 198w, https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/e4247/open-source_bankruptcy.jpg 395w, https://ines.io/static/e01c7326e8deb5bf061bea74e956066e/02884/open-source_bankruptcy.jpg 590w" sizes="(max-width: 590px) 100vw, 590px" type="image/jpeg">
        <img src="https://d33wubrfki0l68.cloudfront.net/d8ba0c2197bf3af4bd78d213599ff9f1083b7e18/44328/static/e01c7326e8deb5bf061bea74e956066e/02884/open-source_bankruptcy.jpg" alt="Screenshot of GitHub tab bar with lots of issues and pull requests" title="Screenshot of GitHub tab bar with lots of issues and pull requests" loading="lazy">
      </picture>
  </a>
    </span></p><p>We try to label issues as they come in, even if we don’t have time to reply or
get to the bottom of them. Of course, reorganising the reports won’t actually
fix any bugs – but it makes it …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ines.io/blog/spacy-commercial-open-source-nlp">https://ines.io/blog/spacy-commercial-open-source-nlp</a></em></p>]]>
            </description>
            <link>https://ines.io/blog/spacy-commercial-open-source-nlp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24620337</guid>
            <pubDate>Mon, 28 Sep 2020 19:25:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are shutting down Covid-19 projections using Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24620310">thread link</a>) | @dsr12
<br/>
September 28, 2020 | https://youyanggu.com/blog/six-months-later | <a href="https://web.archive.org/web/*/https://youyanggu.com/blog/six-months-later">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">

		<div data-page-title="Six Months Later – Youyang Gu">

			<section>

	<div>

		
		<p>September 28th, 2020</p>

		<p>It’s been six months since I made my first COVID-19 projections. What started as a small side project became a months long endeavor. 180 days and 180 forecasts later, the pandemic shows no signs of abating as we head towards winter. When I started <a href="https://covid19-projections.com/">covid19-projections.com</a>, there were only a handful of existing models, and very few of them were accurate. Now, there are over 30 models on the <a href="https://www.cdc.gov/coronavirus/2019-ncov/covid-data/forecasting-us.html">CDC Forecasting</a> page. A lot of great progress has been made in the modeling space over the past six months, and I hope others will get to better know these other models in the months to come. After much consideration, I have come to the difficult decision to not extend my projections beyond November 1, 2020. I plan to make the last forecast update to <i>covid19-projections.com</i> on Monday, October 5. This was undoubtedly a tough choice for me, and I hope to convey my thoughts in this post.</p>

<h3 id="winding-down">Winding Down</h3>

<p>There are several reasons that went into my decision, which I describe below:</p>

<ul>
  <li>Back in March and April, I was concerned by the lack of high-quality models being cited in the news and media. The numbers being referenced ranged widely from <a href="http://www.healthdata.org/news-release/ihme-hold-media-briefing-4-pm-eastern-today-details-below">60,000 deaths</a> to <a href="https://www.imperial.ac.uk/mrc-global-infectious-disease-analysis/covid-19/report-9-impact-of-npis-on-covid-19/">2,200,000 deaths</a> in the US by August. My goal was to create a more realistic and accurate model, and hence <em>covid19-projections.com</em> was born. Looking back now, I believe I was able to achieve what I had set out to accomplish. In the months since, several other reliable models have emerged. Hence, I believe this is an appropriate time for me to wind down.</li>
  <li>In the beginning, the majority of my time was spent on building a model from scratch: learning about infectious diseases, incorporating a machine learning layer, and iteratively learning the various epidemiolgical parameters. As time went on and my model became more mature, the focus of the work changed. Lately, a lot of my time is being spent making minor adjustments and tweaks to refine the model’s performance. I feel that I am now spending more time on maintaining the model rather than making new advancements, which is something I hope to change.</li>
  <li>As one can imagine, building and maintaining a COVID-19 model takes a lot of time and effort. Many models have entire groups dedicated to the project, as well as the funding and resources necessary to continue this project for the foreseeable future. Unfortunately, I do not fall under this category. Since Day 1, I have been the sole author of the model and have not relied on any external funding. The only things I used to build this model was a laptop, <a href="https://twitter.com/youyanggu">a Twitter account</a>, and $20 to buy the domain name <em>covid19-projections.com</em>. As much as I would like to continue working on this project, my current setup is not sustainable or scalable in the long run.</li>
  <li>Looking at COVID-19 data on a daily basis for the past six months can be exhausting. Taking a step back would allow me to explore new ideas.</li>
</ul>

<p>With that said, I firmly believe that the modeling community is in good hands. Below, I will present a few models that I have found to be the most reliable.</p>

<h3 id="model-alternatives">Model Alternatives</h3>

<p>I know this news is disappointing for the many people who have been closely following my model over the past few months, so I want to provide a few reputable alternatives. It’s important that we focus on models which have a proven track record and not just those that have generated the biggest headlines. No single model is perfect, hence this is why I believe it is important to look at different models and understand the assumptions of each one in order to interpret the forecasts. Due to this reasoning, I recommend the <a href="https://covid19forecasthub.org/">COVID-19 Forecast Hub</a>, which aggregates forecasts from over 30 models and sends them to the <a href="https://www.cdc.gov/coronavirus/2019-ncov/covid-data/forecasting-us.html">CDC</a> each week to help inform public health decision making.</p>

<p>From among the Forecast Hub, below are a list of models that I have found to be the most reliable over the past few weeks and months. You can find a visualization of all the models listed below <a href="https://viz.covid19forecasthub.org/">here</a>. In addition to forecasting reported deaths, the below models also have forecasts for <a href="https://www.cdc.gov/coronavirus/2019-ncov/cases-updates/forecasts-cases.html">confirmed cases</a>. The USC, COVIDAnalytics, and LANL models also have forecasts for international countries.</p>

<ul>
  <li><a href="https://viz.covid19forecasthub.org/">COVIDhub Ensemble</a> - An aggregation of the forecasts of ~30 models submitted to the <a href="https://covid19forecasthub.org/">COVID-19 Forecast Hub</a>. The combined forecast is then published on the <a href="https://www.cdc.gov/coronavirus/2019-ncov/covid-data/forecasting-us.html">CDC website</a>. You can find the pre-print <a href="https://www.medrxiv.org/content/10.1101/2020.08.19.20177493v1">here</a>. Because it is able to combine the forecasts of so many models, it is more accurate than any single model alone. Hence, if one were to only use one model, this would be the one to use.</li>
  <li>UMass Amherst - An early model that has consistently performed well since its release in May. It is made by the <a href="https://reichlab.io/">Reich Lab</a>, the same group that runs the COVID-19 Forecast Hub. The downside is that it only forecasts 4 weeks out and has no visualizations (other than on the Forecast Hub).</li>
  <li><a href="https://covid19.uclaml.org/">UCLA</a> - Another early model that has consistently performed well. It also has forecasts for the reproduction number (Rt). The visualizations are very well-done.</li>
  <li><a href="https://pandemicnavigator.oliverwyman.com/forecast?mode=country&amp;region=United%20States&amp;panel=mortality">Oliver Wyman</a> - A new model released in June that instantly became one of the top-performing models since its release. It only has public forecasts 4 weeks into the future.</li>
  <li><a href="https://www.covidanalytics.io/">COVIDAnalytics (MIT DELPHI)</a> - A top-performing model for US nationwide forecasts.</li>
  <li><a href="https://scc-usc.github.io/ReCOVER-COVID-19/#/">USC</a> - A new model released in July that has made great improvements over the past few weeks. It is one of the only models (along with my own) to make daily updates.</li>
  <li><a href="https://covid-19.bsvgateway.org/">Los Alamos National Lab (LANL)</a> - One of the top-performing models from April-July, but has been under-forecasting recently.</li>
  <li>Other up-and-coming Forecast Hub models that have performed well thus far: CMU, LNQ, JCB</li>
</ul>

<p>I highly recommend those who have been following my work to take some time studying the aforementioned models. I have personally spoken to most of the groups and have listened to their presentations. I can attest to their proven track record and hope they can continue to provide reliable forecasts in the weeks and months to come. When viewed in tandem, these models can help provide a clearer picture of what will most likely happen in the upcoming weeks. While not crystal balls, I believe these forecasts can be very useful tools for researchers and policy makers.</p>

<p>The above list is not necessarily an exhaustive list of reliable models. You can learn more about my weekly evaluations of the different models <a href="https://covid19-projections.com/about/#historical-performance">here</a>. I hope to continue updating these model evaluations in the near future.</p>

<h3 id="whats-next">What’s Next</h3>

<p>Ending my model forecasts does not mean that my work in COVID-19 is over. This decision will allow me to dedicate my freed up time to other areas of COVID-19 data analysis. In this day and age, misinterpretation of data (both intentional and unintentional) is pervasive. Anyone can cherry-pick data to support his or her narrative. My goal is to continue presenting COVID-19 data in a rigorous, unbiased manner. Follow me on Twitter at <a href="https://twitter.com/youyanggu">@youyanggu</a> to stay up to date with my latest analysis.</p>

<p>I am forever grateful to have the support of so many people from across the US and around the world. I want to thank everyone who believed in my work from the early days, especially Nicholas Reich, his group at UMass Amherst, and the scientists at the CDC. I also want to thank all the scientists, researchers, and everyone else with whom I’ve had the pleasure of interacting with online; at a time where in-person contact has been limited, these interactions have been tremendously helpful. I feel honored to be able to contribute to the scientific community in improving our understanding of the disease. This was certainly not something that I, a data scientist with no background in infectious diseases, expected just a year ago. I haven’t always been right, but I’m thankful to be part of a community that is constantly helping me learn.</p>

<p>I am currently working on a piece that outlines the things I have learned over the past six months. I hope to post it here in the next week or two. Stay tuned!</p>

<h3 id="get-in-touch">Get in Touch</h3>

<p>While I no longer will be making public forecasts, I hope to continue to be involved in the forecasting space in some shape or form. If you are interested in hearing more about my work, feel free to send me a message.</p>

<p>I still don’t know what the future holds. I am always open to new challenges and projects, especially those involving the use of data-oriented modeling to tackle public health problems. If you have any suggestions or ideas, please don’t hesitate to reach out to me using the contact button below. I would love to get in touch.</p>

<p><a href="https://youyanggu.com/contact">Contact Me</a></p>

<p>In the meantime, let’s all work together to continue fighting this pandemic. Each one of us <em>can</em> make a difference.</p>

<h4 id="--youyang"><em>- Youyang</em></h4>

<p><br>
<a href="#top">Back to Top</a></p>


	</div>

</section>

		</div>

	</div></div>]]>
            </description>
            <link>https://youyanggu.com/blog/six-months-later</link>
            <guid isPermaLink="false">hacker-news-small-sites-24620310</guid>
            <pubDate>Mon, 28 Sep 2020 19:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MySQL's Gotchas]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24619777">thread link</a>) | @awmarthur
<br/>
September 28, 2020 | https://www.dolthub.com/blog/2020-09-28-mysql-gotchas/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-28-mysql-gotchas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://github.com/liquidata-inc/dolt">Dolt</a> is Git for data. Git
versions files, Dolt versions tables. Dolt comes with a SQL engine
built in, which lets you run SQL queries against any version of the
data you've committed. Our goal is to become fully SQL compliant and
compatible with MySQL's dialect. To this end, we've contributed
to <a href="https://github.com/dolthub/sqllogictest">sqllogictest</a> and
<a href="https://www.dolthub.com/blog/2020-05-04-adopting-go-mysql-server/">adopted</a>
the go-mysql-server project.
We've made significant progress on <a href="https://www.dolthub.com/blog/2019-12-17-one-nine-of-sql-correctness/">our journey</a>
to full SQL correctness.
As of publishing time, we're 92% correct according to sqllogictest.
Along the way we've learned a lot about MySQL's idiosyncrasies and
found some pretty inexplicable behavior.
Today we're going to share some of our favorites.</p>
<h2>MySQL: the Javascript of Databases</h2>
<p>People love the hate. I've watched endless software talks
on brilliant technologies given by top industry experts.
My favorite software talk?
<a href="https://www.destroyallsoftware.com/talks/wat">"Wat"</a>,
the JS-roasting classic by Gary Bernhardt.
Sure, self-driving cars and planet-scale data systems are cool,
but still not as interesting as </p>
<div data-language="javascript"><pre><code><span>%</span> node
<span>&gt;</span> <span>{</span>is<span>:</span> <span>"this"</span><span>}</span> <span>+</span> <span>[</span><span>"a"</span><span>,</span> <span>"number?"</span><span>]</span>    
<span>NaN</span> </code></pre></div>
<p>In the words of one of Dolthub's founders, "MySQL is the Javascript of databases".
It's got its rough spots, but it's a known entity.
Let's take a look at some of those rough spots. </p>
<h2>GOTO FAIL</h2>
<p>MySQL has no problem letting you shoot yourself in the foot.</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> default_fail <span>(</span>
    pk <span>int</span> <span>NOT</span> <span>NULL</span> <span>PRIMARY</span> <span>KEY</span> <span>DEFAULT</span> <span>(</span><span>NULL</span><span>)</span>
<span>)</span><span>;</span></code></pre></div>
<p>Much like <code>{} + []</code> this example is something you're not likely to run into,
on the other hand why doesn't this just error?</p>
<p>Foreign Keys, like all database constraints, are crucial to ensuring data integrity.
That's why you probably should't be able to link these two columns with disparate data domains:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> parent <span>(</span>
    id <span>ENUM</span><span>(</span><span>'a'</span><span>,</span><span>'b'</span><span>,</span><span>'c'</span><span>)</span> <span>PRIMARY</span> <span>KEY</span>
<span>)</span><span>;</span>
<span>CREATE</span> <span>TABLE</span> child <span>(</span>
    parent_id <span>ENUM</span><span>(</span><span>'x'</span><span>,</span><span>'y'</span><span>,</span><span>'z'</span><span>)</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>FOREIGN</span> <span>KEY</span> <span>(</span>parent_id<span>)</span> <span>REFERENCES</span> parent<span>(</span>id<span>)</span>
<span>)</span><span>;</span></code></pre></div>
<p>Things are complicated even further by MySQL's implementation of enums:</p>
<div data-language="sql"><pre><code><span>INSERT</span> <span>INTO</span> parent <span>(</span>id<span>)</span> <span>VALUES</span> <span>(</span><span>'a'</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> child <span>(</span>parent_id<span>)</span> <span>VALUES</span> <span>(</span><span>'x'</span><span>)</span><span>;</span></code></pre></div>
<p>This actually <em>doesn't</em> fail because enums are translated to integers
and in this instance both 'a' and 'x' evaluate to 1. Gotcha.</p>
<p>The first two examples can really be attributed to user error.
If you're going to mess with the schema of a database,
you should know enough not to make those mistakes.
But it turns out there are even more interesting ways to break relations
between MySQL objects. Consider this table, view, and insert trigger:</p>
<div data-language="sql"><pre><code>mysql<span>&gt;</span> <span>CREATE</span> <span>TABLE</span> users <span>(</span>
    id <span>int</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>level</span> <span>int</span>
<span>)</span><span>;</span>
mysql<span>&gt;</span> <span>CREATE</span> <span>VIEW</span> cohorts <span>AS</span> 
    <span>SELECT</span> <span>level</span><span>,</span> <span>count</span><span>(</span><span>level</span><span>)</span> <span>FROM</span> users 
        <span>GROUP</span> <span>BY</span> <span>level</span> <span>ORDER</span> <span>BY</span> <span>level</span> <span>ASC</span><span>;</span>
mysql<span>&gt;</span> <span>CREATE</span> <span>TRIGGER</span> start_level_zero
    BEFORE <span>INSERT</span> <span>ON</span> users
    <span>FOR EACH ROW</span> 
        <span>SET</span> NEW<span>.</span><span>level</span> <span>=</span> <span>0</span><span>;</span></code></pre></div>
<p>Now say we want to change the name of the column <code>level</code>...</p>
<div data-language="sql"><pre><code>mysql<span>&gt;</span> <span>ALTER</span> <span>TABLE</span> users <span>RENAME</span> <span>COLUMN</span> <span>level</span> <span>TO</span> <span>status</span><span>;</span>
    Query OK<span>,</span> <span>0</span> <span>rows</span> affected <span>(</span><span>0.01</span> sec<span>)</span>
    Records: <span>0</span>  Duplicates: <span>0</span>  <span>Warnings</span>: <span>0</span>

mysql<span>&gt;</span> <span>INSERT</span> <span>INTO</span> users <span>VALUES</span> <span>(</span><span>4</span><span>,</span><span>0</span><span>)</span><span>;</span>
    ERROR <span>1054</span> <span>(</span><span>42</span>S22<span>)</span>: Unknown <span>column</span> <span>'level'</span> <span>in</span> <span>'NEW'</span>
mysql<span>&gt;</span> <span>SELECT</span>  <span>*</span> <span>FROM</span> cohorts<span>;</span>
    ERROR <span>1356</span> <span>(</span>HY000<span>)</span>: <span>View</span> <span>'cohorts'</span> <span>references</span> invalid <span>table</span><span>(</span>s<span>)</span> <span>or</span> <span>column</span><span>(</span>s<span>)</span> <span>or</span> <span>function</span><span>(</span>s<span>)</span> <span>or</span> <span>definer</span><span>/</span><span>invoker</span> <span>of</span> <span>view</span> lack rights <span>to</span> <span>use</span> them</code></pre></div>
<p>Broken! The column rename left the view and the trigger statement referencing the old column name.
Everything that depends on that column name must be updated.
<code>Unknown column 'level' in 'NEW'</code> doesn't clue you in that your trigger is broken,
and until you figure it out you won't be able to make any inserts to <code>users</code>.</p>
<p>Now let's take a look at MySQL's type system, which I have to say is <em>especially</em> Javascripty.
Our table definition is: </p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> types_table <span>(</span>
    pk <span>int</span> <span>primary</span> <span>key</span><span>,</span> s <span>varchar</span><span>(</span><span>20</span><span>)</span><span>,</span> b <span>bool</span>
<span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> types_table <span>VALUES</span>
    <span>(</span><span>0</span><span>,</span> <span>"abc"</span><span>,</span> <span>true</span><span>)</span><span>,</span>
    <span>(</span><span>1</span><span>,</span> <span>"xyz"</span><span>,</span> <span>false</span><span>)</span><span>;</span></code></pre></div>
<p>Suppose we made wanted to find rows with <code>s = "abc"</code>, but we made a mistake and typed <code>b</code> instead of <code>s</code>. </p>
<div data-language="sql"><pre><code>mysql<span>&gt;</span> <span>SELECT</span> <span>*</span> <span>FROM</span> types_table <span>WHERE</span> b <span>=</span> <span>"abc"</span>  
<span>+</span>
<span>|</span> pk <span>|</span> s    <span>|</span> b    <span>|</span>
<span>+</span>
<span>|</span>  <span>1</span> <span>|</span> xyz  <span>|</span>    <span>0</span> <span>|</span>
<span>+</span>
<span>1</span> <span>row</span> <span>in</span> <span>set</span><span>,</span> <span>1</span> warning <span>(</span><span>0.00</span> sec<span>)</span></code></pre></div>
<p>MySQL is happy to perform type coercion, interpret <code>"abc"</code> as <code>false</code>, and execute the query.
It even spits out <code>1 warning</code> at the end, which is mea culpa if I've ever seen it.</p>

<p>Understanding and modeling MySQL's behaviors is important because it lets
us leverage the massive MySQL ecosystem.
Our SQL parser and server are based on Vitess and support the standard MySQL wire protocol.
This means we can support a wide range of sql <a href="https://www.dolthub.com/docs/integrations/programmatic-clients/">integrations</a>
with minimal effort.
However, as some of the examples above showed, following along bit for bit isn't necessarily a good idea.
Datetime conversion is one example of how we choose to deviate from the MySQL standard.
The following query casts a datetime to an integer. </p>
<div data-language="sql"><pre><code>
<span>SELECT</span> <span>CONVERT</span><span>(</span><span>CONVERT</span><span>(</span><span>"2020-08-07 06:05:04"</span><span>,</span> <span>DATETIME</span><span>)</span><span>,</span> SIGNED<span>)</span><span>;</span> </code></pre></div>
<p>MySQL chooses to use ISO8601 which have the format <code>YYYYMMDDHHMMSS</code>.
Dolt, on the other hand, uses standard Unix timestamps for this cast.</p>
<div data-language="sql"><pre><code>
<span>SELECT</span> <span>CONVERT</span><span>(</span><span>CONVERT</span><span>(</span><span>"2020-08-07 06:05:04"</span><span>,</span> <span>DATETIME</span><span>)</span><span>,</span> SIGNED<span>)</span><span>;</span> </code></pre></div>
<p>Choosing where and how to deviate from the standard isn't an exact science,
it involves some estimation and a lot of listening to your users.
Generally we seek to maximize compatibility while also createing intuitive behaviors.</p>

<p>Building a relational database is a lot of work.
Reaching 100% compatibility with an industry standard like MySQL adds another layer of difficulty.
SQL is the lingua franca of data analysis and Git is the same for version control.
We believe that your data deserves the power of both, and that migrating to Dolt should be a seamless transition.
Our journey is ongoing, but we hope you'll come along for the ride.
As always, <a href="https://www.dolthub.com/contact">let us know</a> what you think about Dolt and what we should build next. </p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-28-mysql-gotchas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24619777</guid>
            <pubDate>Mon, 28 Sep 2020 18:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful and Beneficial (2012)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24619745">thread link</a>) | @panic
<br/>
September 28, 2020 | http://mikekchar.github.io/portfolio//UsefulAndBeneficial | <a href="https://web.archive.org/web/*/http://mikekchar.github.io/portfolio//UsefulAndBeneficial">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    <p>Long ago a master woodcarver and his assistant were walking along a
road when they happened upon a huge tree.  It was at least 1000 years
old and was so large that it stretched from horizon to horizon.  At
its base, a shrine dedicated to the spirit of the tree was doing a
brisk business catering to the many pilgrims who had traveled to see
it.</p>

<p>The assistant stopped and looked astonished at the magnificent tree.
As a man in love with his trade he could not help but to be moved by
such an amazing tree.  However, the master woodcarver continued along
his way, scarcely giving the tree a second glance.</p>

<p>“How can you, a master woodcarver who has spent his long life working
in wood, not be struck by such a sight?” the assistant inquired.</p>

<p>“That tree is not fit for carving.  Its limbs are twisted and its
trunk full of knots.  A cabinet made from it would warp.  A boat made
from it would sink.  It is useless!”</p>

<p>That night, the assistant dreamed of the tree.  In his dream the tree
spoke to him, “Humans are so blind.  They look at me and don’t see the
secret of my success.  I am useless, but it is precisely because I am
useless that I have survived to become great.  Had my wood been useful
for any purpose, I would long ago have succumbed to the axe and the
saw.  I would have died to satisfy the whims of others.”</p>

<p>The assistant awoke from his dream with new understanding, but one
question still plagued him.  Later that day he told the master
woodcarver of his dream and asked, “The tree said that it could thrive
because it could not be used.  But doesn’t the shrine use the tree?
Is the tree not being useful to the shrine.”</p>

<p>“What does a tree care if a shrine worships it?  It is true that the
tree is beneficial to the shrine, but it is not being used.  It is
free to be a tree and to live as it chooses.  In fact, by being
beneficial to the shrine, it receives benefit in return.  The shrine,
not wanting to lose the benefit of the tree, protects it from storms
and waters it during droughts.  In this way, the tree has learned to
achieve ultimate success.”</p>

<p>I read a similar story many years ago as a struggling computer
programmer in Canada.  It is not a new story. It is a compilation of a
few similar stories from taoist literature.  It is at least 2500 years
old.</p>

<p>It is very easy to fall into the trap of trying to be useful.  We do
what we are told to do and suffer through the many things which we
don’t enjoy.  But we risk becoming the woodcarver’s wood rather than
the tree.  We struggle to be useful but then resent the fact that we
are used.</p>

<p>In every job there are countless ways to be beneficial.  We can choose
things that we, ourselves, value and do them independently.  If we
choose wisely these will be things that the people around us benefit
from.  The more we choose to benefit others by being
ourselves, the more others will come to rely on our unique strengths.  Instead
of finding ways to use us, they will simply be delighted by our
presence.</p>

	    </div><p><strong>Note:</strong> This website uses Google Analytics to 
    collect statistics.  If you wish to avoid being tracked, please 
    disable Javascript for this website (using the NoScript plugin, 
    for instance).
</p></div>]]>
            </description>
            <link>http://mikekchar.github.io/portfolio//UsefulAndBeneficial</link>
            <guid isPermaLink="false">hacker-news-small-sites-24619745</guid>
            <pubDate>Mon, 28 Sep 2020 18:23:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Head of MS Estonia investigation: Estonia sank on collision with submarine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24619728">thread link</a>) | @mpweiher
<br/>
September 28, 2020 | https://news.err.ee/1140442/head-of-ms-estonia-investigation-estonia-sank-on-collision-with-submarine | <a href="https://web.archive.org/web/*/https://news.err.ee/1140442/head-of-ms-estonia-investigation-estonia-sank-on-collision-with-submarine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Margus Kurm, former state prosecutor and head of the government's investigative committee looking into the sinking of ferry MS <em>Estonia </em>in 2005-2009, said in an interview with ETV's "Pealtnägija" that new scenes of the shipwreck show the ship most likely sank after a collision with a submarine.</p><div><p><strong>You have seen these clips that have reached the media repeatedly and before anyone else. What was your first reaction and emotion seeing scenes of the dive?</strong></p><p>The first reaction was shocking. Not because the hole (in the ship's hull - ed.) was visible but rather because it was discovered so simply.</p><p><strong>Explain, what is the location of this hole and what is the meaning of it?</strong></p><p>The meaning is [MS] <em>Estonia</em> did not sink because of a bow visor breaking, it was a collision with something large enough to create a four-meter long hole in the ship's hull.</p><p><strong>This is an unbelievable twist!</strong></p><p>It is not unbelievable in that sense. That there could be a hole on the ship has been mentioned in previous evidence and analyses. It is evidence for something that has long been speculated.</p><p><strong>But a collision? With what?</strong></p><p>Considering that the tear is below the water line and considering noone has ever mentioned that another ship could have sunk with <em>Estonia </em>and none of the survivors have said they saw a ship close to <em>Estonia - </em>the most likely cause is <em>Estonia </em>collided with a submarine.</p><p><strong>That means there should be a damaged submarine somewhere?</strong></p><p>Yes, it means there should be a damaged submarine somewhere. But I will specify a bit. If one says a collision with a submarine, the first thought is the submarine ran into <em>Estonia </em>from its side. It might not have been so simple. It was more likely a intrusion. That <em>Estonia </em>and a submarine went in the same direction. And we can not rule out that <em>Estonia </em>might have hit the submarine, grazed the submarine. The question is what was a submarine doing on <em>Estonia's</em> route.</p><p><strong>There has been mentions of an explanation that perhaps the hole developed after the ship had sunk. There is a theory that it bumped into a large rock or cliff while sinking and that caused the hole.</strong></p><p>I do not consider that likely. The part, the section where the damage was found has never touched the seabed. The position that <em>Estonia </em>is in post-accident was documented during dives conducted in 1994. There have been figures drawn, graphics made on how <em>Estonia </em>lies on the seabed. The entire bottom of the ship, including the vehicle deck, on both sides, is out of water. It is a simple thing, everyone can check it on paper at home. We know, according to the report that the ship is under a 211-degree angle. Meaning, if we draw a straight line vertically on <em>Estonia</em>'s hull, from funnel to keel, and compare it to the seabed, the angle is 211 degrees.</p><p>In addition, from the footage provided, we know that <em>Estonia</em>'s so-called hotel part is partly under mud but a large part still sticks out. A part of the captain's deck is also out. You can draw a two-dimensional picture of the position <em>Estonia </em>is in underwater. It clearly shows that the entire bottom, including vehicle deck, is away from the seabed.</p><p>And therefore, a statement has been made that the location of the damages was not visible earlier. It absolutely was. The entire bottom, including the vehicle deck, was away from the seabed and could have been filmed in 1994.</p><p><strong>Which in turn leads to the point that in 1994, when the official investigative dives took place, the holes we see today were not spotted?</strong></p><p>Yes. And that has been a large problem. Two options, it either was not filmed or was filmed and not made public. The second option is most likely, because the footage was lost.</p><p><strong>The fact we have not been made aware of the hole for 26 years or it has been covered up is scandalous enough?</strong></p><p>Well, I think so.</p><p><strong>Once again. The hole, as it has been filmed by the documentary crew, would explain all those questions to you, but to anyone else still bothered by it?</strong></p><p>This will sound funny but the hole fits <em>Estonia's </em>hull well. It explains all questions up in the air for 26 years. Firstly, it explains how water was able to get under the vehicle deck. Secondly, it explains why <em>Estonia </em>did not keel over in a few minutes.</p><p>If a large amount of water reaches the vehicle deck or a ferry loses stability in another way, it keels over in minutes, sinks, windows go under water and the ship's so-called superstructure breaks, it's larger, it gets heavier, sinks and the bottom, where the air is, rises to the top and since the air can not escape, the ship remains on the surface for hours or even days. This did not happen with <em>Estonia. </em><em>Estonia </em>did not keel over in minutes, it stood up for half an hour. And once it finally tipped over, it sunk in ten minutes.</p><p>This hole solves all contradictory evidence as well. Since it is no longer necessary to bend the statements made by three young seamen, who saw from the machine room that the ramp was closed.</p><p>And most importantly - one of the men said in addition that he had seen from a camera pointed at the ramp that it was closed and water was coming in from the sides, he saw the side of the ship, from a camera pointed at the maritime pilot's door that there was water on the vehicle deck. Since the ship was angled, there was water on the starboard decks and there was enough to reach the front lights of the cars on board. Estimatedly, 500-700 tons of it.</p><p>All experts are in agreement that there is too much water for it to have come in from the sides of the ramp. But there is not enough water there for it to have come in from the opened ramp. If the ramp is open, 2000 tons would flow in a minute. There was 500-700 tons. Therefore, there was water on the vehicle deck. But it must have come in from someone else, not the ramp. And as we can see from the new footage, the tear reaches both the bottom and top of the vehicle deck. Meaning the hole - considerably smaller that an opened ramp - was where the water came from.</p><p><strong>What should be done now with this information?</strong></p><p>The wise don't rush (an Estonian idiom - ed.). I think the government should firstly sit down calmly and think deeply about the situation. And ask who we can trust at a time like this. And also think about how to win back the public's trust.</p><p>Let's go back in time. Everyone, who spoke of any kind of weapon smuggling, were ridiculed. It turned out in 2005 that there indeed were weapons transported. People speaking of a hole in the ship's hull all these years have been ridiculed. It was considered impossible. Now, 26 years later, we have footage of there being a hole.</p><p>If we add to it that less than a month after the sinking, there was an idea to cover the ship in concrete. A gravesite peace was agreed to in 1995. An international investigative committee had not yet been able to start their investigation when the Swedish government came out with an idea to cover the ship with concrete. And before the committee finished, the shipwreck was locked down. It is unheard of that the most critical piece of evidence is locked.</p><p><strong>From the first reactions of the government of Estonia and other countries, I gather that there is a new investigation to be done, including a robot investigation. Would that satisfy you?</strong></p><p>Yes and no. Like I said - the question is whether there is enough trust to conduct such research today. I think, considering all that has been mentioned, the Swedes should no longer be trusted on this topic. Does the Estonian government have enough trust credit to conduct an investigation, trusted by its people and the public as a whole? I do not think so. Meaning, if another investigation is conducted, it must be completely transparent. It would be good if the investigation would be headed by someone outside the government sector.</p><p>Secondly, the investigation committee must have representatives from Sweden and Finland as well. And thirdly, to me, there must be press involved. This investigation should be completely transparent. It should be followable online, in essence. If there is a dive, ETV must be there with cameras and film it. So everyone could see what is done, how it is done and what are the results. If we do not achieve such transparency, it is difficult to trust the final results of the committee.</p><p>But before all, I would recommend the Estonian government to sit down with the Swedes and ask if they have any documents archived where it says what actually happened. And if there are any people in Sweden who know what happened and are prepared to talk about it.</p><p><em><strong>The further details and circumstances of MS Estonia's doom will be discussed at length on "Pealtnägija" on Wednesday.</strong></em></p><p><strong>Background</strong></p><p>The ferry Estonia sank on the night of September 28, 1994, sailing from Tallinn to Stockholm.&nbsp;The sinking of Estonia is the largest maritime disaster in peacetime in the Baltic Sea, killing 852 people from 17 countries.</p><p>The shipwreck was investigated by a joint committee formed by the governments of Estonia, Finland and Sweden between 1994 and 1997 and by a government commission headed by the Public Prosecutor's Office in 2005-2009.&nbsp;</p><p>In 1995, Estonia, Finland and Sweden signed an agreement to protect the shipwreck, which prohibits diving to the wreck.</p><p>The disaster is commemorated by the "Broken Line" monument in Tallinn.</p><figure content-photo-template2="" data-photo-id="688654"><img data-photo-id="688654" src="https://s.err.ee/photo/crop/2019/09/23/688654h12eet24.jpg"><figcaption>The 'Broken Line' monument in Tallinn.<span> Source: </span>Jan Pohunek/Creative Commons</figcaption></figure><p>--</p><p><em>Follow ERR News on <a href="https://www.facebook.com/ERRNews/">Facebook</a> and <a href="https://twitter.com/errnews">Twitter</a> and never miss an update!</em></p>									</div></div>]]>
            </description>
            <link>https://news.err.ee/1140442/head-of-ms-estonia-investigation-estonia-sank-on-collision-with-submarine</link>
            <guid isPermaLink="false">hacker-news-small-sites-24619728</guid>
            <pubDate>Mon, 28 Sep 2020 18:22:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promising computer simulations for stellarator plasmas]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24619682">thread link</a>) | @sizzle
<br/>
September 28, 2020 | https://www.ipp.mpg.de/4928395/05_20 | <a href="https://web.archive.org/web/*/https://www.ipp.mpg.de/4928395/05_20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>Path to higher thermal insulation of the plasma / Reduction of plasma turbulence</p>
  

  

  <p>The turbulence code GENE (Gyrokinetic Electromagnetic Numerical Experiment), developed at Max Planck Institute for Plasma Physics (IPP) at Garching, Germany, has proven to be very useful for the theoretical description of turbulence in the plasma of tokamak-type fusion devices. Extended for the more complex geometry of stellarator-type devices, computer simulations with GENE now indicate a new method to reduce plasma turbulence in stellarator plasmas. This could significantly increase the efficiency of a future fusion power plant.</p>
  
  
<figure data-description="Turbulence calculation with the GENE-3D code for Wendelstein 7-X: The snapshot shows the turbulent variation of the plasma density over different cross-sections of the plasma ring. In contrast to tokamaks, whose ring-shaped plasma has the same cross-section everywhere, the cross-section changes its shape in stellarators." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Turbulence calculation with the GENE-3D code for Wendelstein 7-X: The snapshot shows the turbulent variation of the plasma density over different cross-sections of the plasma ring. In contrast to tokamaks, whose ring-shaped plasma has the same cross-section everywhere, the cross-section changes its shape in stellarators.
        </p>
        <p>
           Illustration: IPP, A. Bañón Navarro
        </p>
    </figcaption>
</figure>



<p>For the fusion researchers at IPP, who want to develop a power plant based on the model of the sun, the turbulence formation in its fuel – a hydrogen plasma – is a central research topic. The small eddies carry particles and heat out of the hot plasma centre and thus reduce the thermal insulation of the magnetically confined plasma. Because the size and thus the price of electricity of a future fusion power plant depends on it, one of the most important goals is to understand, predict and influence this “turbulent transport”.</p>
<p>Since the exact computational description of plasma turbulence would require the solution of highly complex systems of equations and the execution of countless computational steps, the code development process is aimed at achieving reasonable simplifications. The GENE code developed at IPP is based on a set of simplified, so-called gyrokinetic equations. They disregard all phenomena in the plasma which do not play a major role in turbulent transport. Although the computational effort can be reduced by many orders of magnitude in this way, the world’s fastest and most powerful supercomputers have always been needed to further develop the code. In the meantime, GENE is able to describe the formation and propagation of small low-frequency plasma eddies in the plasma interior well and to reproduce and explain the experimental results – but originally only for the simply constructed, because axisymmetric fusion devices of the tokamak type.</p>
<p>For example, calculations with GENE showed that fast ions can greatly reduce turbulent transport in tokamak plasmas. Experiments at the ASDEX Upgrade tokamak at Garching confirmed this result. The required fast ions were provided by plasma heating using radio waves of the ion cyclotron frequency.</p>






<p><strong>A tokamak code for stellarators</strong><br>In stellarators, this turbulence suppression by fast ions had not been observed experimentally so far. However, the latest calculations with GENE now suggest that this effect should also exist in stellarator plasmas: In the Wendelstein 7-X stellarator at IPP at Greifswald, it could theoretically reduce turbulence by more than half. As IPP scientists Alessandro Di Siena, Alejandro Bañón Navarro and Frank Jenko show in the journal Physical Review Letters, the optimal ion temperature depends strongly on the shape of the magnetic field. Professor Frank Jenko, head of the Tokamak Theory department at IPP in Garching: “If this calculated result is confirmed in future experiments with Wendelstein 7-X in Greifswald, this could open up a path to interesting high-performance plasmas”.</p>
<p>In order to use GENE for turbulence calculation in the more complicated shaped plasmas of stellarators, major code adjustments were necessary. Without the axial symmetry of the tokamaks, one has to cope with a much more complex geometry for stellarators.</p>
<p>For Professor Per Helander, head of the Stellarator Theory department at IPP in Greifswald, the stellarator simulations performed with GENE are “very exciting physics”. He hopes that the results can be verified in the Wendelstein 7-X stellarator at Greifswald. “Whether the plasma values in Wendelstein 7-X are suitable for such experiments can be investigated when, in the coming experimental period, the radio wave heating system will be put into operation in addition to the current microwave and particle heating,” says Professor Robert Wolf, whose department is responsible for plasma heating.</p>


<figure data-description="Turbulence in the plasma of the Wendelstein 7-X stellarator, calculated with the GENE-3D code: The magnetic cage generated by the magnetic coils (grey) shapes and encloses the plasma. The turbulent variation of the plasma density is to be seen in the plasma cross-section." data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Turbulence in the plasma of the Wendelstein 7-X stellarator, calculated with the GENE-3D code: The magnetic cage generated by the magnetic coils (grey) shapes and encloses the plasma. The turbulent variation of the plasma density is to be seen in the plasma cross-section.
        </p>
        <p>
           Illustration: IPP, A. Bañón Navarro
        </p>
    </figcaption>
</figure>



<div><p><strong>GENE becomes GENE-3D</strong><br>According to Frank Jenko, it was another “enormous step” to make GENE not only approximately, but completely fit for the complex, three-dimensional shape of stellarators. After almost five years of development work, the code GENE-3D, now presented in the “Journal of Computational Physics” by Maurice Maurer and co-authors, provides a “fast and yet realistic turbulence calculation also for stellarators”, says Frank Jenko. In contrast to other stellarator turbulence codes, GENE-3D describes the full dynamics of the system, i.e. the turbulent motion of the ions and also of the electrons over the entire inner volume of the plasma, including the resulting fluctuations of the magnetic field.</p></div>
<p>Isabella Milch</p>


<p><strong>Publications</strong></p>

<div>
  <p>
  1.
</p>

  

  <div>
    
    <p>Turbulence suppression by energetic particle effects in modern optimized stellarators</p>
    <p>Physical Review Letters, 2020</p>
  </div>
</div>


<div>
  <p>
  2.
</p>

  

  <div>
    <p>M. Maurer et al.</p>
    <p>GENE-3D – A global gyrokinetic turbulence code for stellarators</p>
    <p>Journal of Computational Physics, 2020</p>
  </div>
</div>

  
</div></div>]]>
            </description>
            <link>https://www.ipp.mpg.de/4928395/05_20</link>
            <guid isPermaLink="false">hacker-news-small-sites-24619682</guid>
            <pubDate>Mon, 28 Sep 2020 18:17:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24619560">thread link</a>) | @andreyk
<br/>
September 28, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>“Deep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.” -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‘tsunami’. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‘Deep Learning’ was anything fancy or just a scaled up version of the ‘artificial neural nets’ that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‘big neural nets’  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, Jürgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is Jürgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is “Deep Learning” a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets’ return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let’s start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here’s why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‘learning’ a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google’s current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don’t match any of the points we started with. Don’t worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt’s <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‘bias’ input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb’s Rule:</p>

<blockquote>
  <p>“When an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A’s efficiency, as one of the cells firing B, is increased.”</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‘learn’ a function from, for each example increase the weights if the Perceptron output for that example’s input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24619560</guid>
            <pubDate>Mon, 28 Sep 2020 18:08:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I No Longer Hate America]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24618682">thread link</a>) | @djsumdog
<br/>
September 28, 2020 | https://battlepenguin.com/politics/why-i-no-longer-hate-america/ | <a href="https://web.archive.org/web/*/https://battlepenguin.com/politics/why-i-no-longer-hate-america/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

  

  <article>
    

    <figure>
  
  <img src="https://battlepenguin.com/images/politics/america/us-flag.jpg" alt="Red, White &amp; Blue by Luke Michael">
  
  
  <figcaption>
      
         <a href="https://instagram.com/farcivilian">
      

      Red, White &amp; Blue by Luke Michael

      
         </a>
      
  </figcaption>
  
</figure>

<p>Years ago, a friend told me he was going to visit his sister in Queensland, Australia. I was <a href="https://battlepenguin.com/tech/tech-culture-shock-from-america-to-the-south-pacific-and-seattle-to-chicago/#wellington-new-zealand">living in New Zealand</a> at the time, and we made plans to meet up. We ended up <a href="https://battlepenguin.com/philosophy/perspective/exploration/">hiking</a> through some <a href="https://journeyofkhan.us/photo/rock-face-at-alligator-falls/">spectacular parks</a> and <a href="https://journeyofkhan.us/photo/base-of-alligator-falls/">amazing waterfalls</a>. On one of our hikes, my friend asked me, “Why do you hate America?” It’s one of those lines often parodied from early 2000s Fox News broadcasts, during the height of outrage over the Iraq war.</p>

<p>At the time, I did hate a lot of American foreign policy, and found there <a href="https://battlepenguin.com/politics/video/does-voting-make-a-difference/">was little difference between US political parties</a>. I had my reasons for leaving, yet I eventually came back to America. Having traveled through and lived in different places around the world, I saw the trade-offs in the different values held by nationals of various countries. I still take issue with many policies in the United States, but I believe there are many aspects to American law and ideology, that respect individual rights and freedoms in fundamentally unique ways. America may run afoul of letting people slide through the cracks, but it is also a nation suited to help people succeed at their dreams.</p>

<!--more-->

<p>My father had a front vanity plate on his car, displaying an American Flag, with a Bald Eagle and the words <em>In God We Trust.</em> His family survived the partition after India gained independence from the British Raj. My grandfather almost lost his life to three men who wanted to take the house he was squatting. Both he and my mother’s family fled war, and struggled against poverty. In a Sociology class I took in my undergraduate years, I had a professor who told us that climbing up the economic ladder to a different social class is not very common. George Carlin famously said, <em>“That’s why they call it the American Dream, because you have to be asleep to believe it.<sup id="fnref:1"><a href="#fn:1">1</a></sup>“</em>. I internalized that message as reality, while ignoring that my father, perhaps against all odds, had literally achieved the American Dream.</p>

<h3 id="problems">Problems</h3>

<figure>
  
  <img src="https://battlepenguin.com/images/politics/america/doctor-sign.jpg" alt="Sign stating: Please Be Advised That Staff Are Not Able To Discuss Lab Results &amp; Other Reports Over The Phone. You Will Be Notified Only If There are Significant Abnormal Findings. Test Results Are Usually Available Within 3-5 Days. Thank You. Clayton Park Medical Clinic">
  
  
</figure>

<p>A Canadian friend sent me an image from her doctor’s office. I thought she was complaining about the notice that test results wouldn’t be discussed over the phone, but she was actually concerned that results would take several days, even for tests that were done in a doctors office and available immediately in other countries. I worked for a health insurance company <a href="https://battlepenguin.com/politics/universalhealthcare/">during the 2008 health care debates</a>, and took issue with the sad state of the <a href="https://battlepenguin.com/politics/returning-to-america-and-the-unaffordable-care-act/">Affordable Care Act</a> upon my return to the US. Canada’s national health system does work fairly well for most common conditions, but surgeries can have long wait times. A number of Canadians, who can afford it, will travel to the United States for medical procedures<sup id="fnref:9"><a href="#fn:9">2</a></sup>. Canadians do pay less for many prescription drugs, but that may change with Trump’s recent executive orders around pharmaceutical pricing<sup id="fnref:10"><a href="#fn:10">3</a></sup>.</p>

<p>In Australia, voting is ranked with instant runoff. Citizens put down numbers indicating their preferences in order, making it impossible to throw a vote away, and voting is mandatory. New Zealand uses Mixed-member Proportional Representation (MMP) allowing each voter two votes. This system is somewhat complicated, but it basically allows for a representative distribution of parliament seats based upon the proportion of votes given to each political party<sup id="fnref:11"><a href="#fn:11">4</a></sup>. America has a first past the post system, and while this system falls behind in proportional representation of the population, it attempts to favor representation of individual states in blocks by means of a complex and controversial electoral college system.</p>

<p>While I was living in New Zealand, one of my friends was wrestled to the ground unjustly by a police officer. When he went to file a complaint, the officer’s partner attempted to intimidate him. While I was in Croatia, I was illegally searched by a police officer at a bus station. <a href="https://battlepenguin.com/politics/why-i-no-longer-hate-the-police/">Police misconduct</a> is on the forefront of news and politics in America today, but the US is not exceptional when it comes to police corruption. It can be found in police forces around the world, but so can good, honest constables who simply want to do the right thing.</p>

<p>I could go on comparing Native Americas and Aboriginals, transportation, drug policy or any number of areas where America might either excel or fall short. America has a lot of problems, but it’s also the third largest country by population. The second largest is where my family is from. India has a functioning democracy, with an impoverished population. China, the largest country by population, is ruled by a Communist government that arrests dissidents and places members of their ethnic minority in reeducation camps. Every nation has problems, and every country’s population lives with the trade-offs that come from complex socioeconomic and geopolitical policies.</p>

<h3 id="the-freedom-to-speak">The Freedom to Speak</h3>

<p>On March 15th, 2019, an Australian man shot up two mosques in Christchurch, New Zealand<sup id="fnref:2"><a href="#fn:2">5</a></sup>. He live-streamed the atrocity. Although the video was taken down from Facebook, there were copies people had archived. Possession of the video, as well as the shooter’s manifesto, are illegal in New Zealand without special permission from the government. The video is horrific, and in the United States, it would likely be removed from many platforms. However, it wouldn’t be illegal to possess or distribute. In New Zealand, having a copy of the video or manifesto can carry sentences of up to 14 years, and several people were arrested and prosecuted for possession of the material<sup id="fnref:3"><a href="#fn:3">6</a></sup>.</p>

<p>The majority of my friends in New Zealand, fully support this form of government censorship<sup id="fnref:4"><a href="#fn:4">7</a></sup>. Even Americans I knew who had immigrated, told me they fully understood and accepted this limitation when they became citizens. If this level of censorship happened in the US, citizens would likely be outraged. From the time we are young, we are taught that <em>freedom of speech</em> is an essential part of our civil liberties, and our identities as Americans. It’s the first amendment made to the United States Constitution; the first in our <em>Bill of Rights</em>.</p>

<p>New Zealand doesn’t have a constitution, and Australia does not have a bill of rights. Victoria, Australia passed a Charter of Human Rights in 2006, but its provisions are limited to the state of Victoria<sup id="fnref:5"><a href="#fn:5">8</a></sup>. China has the freedom of speech written into their constitution<sup id="fnref:6"><a href="#fn:6">9</a></sup>, which is a complete and total joke as their only political party exerts Orwellian style censorship over all 1.5 billion Chinese people.</p>

<blockquote>
  <p><em>“Congress shall make no law respecting an establishment of religion, or prohibiting the free exercise thereof; or abridging the freedom of speech, or of the press; or the right of the people peaceably to assemble, and to petition the government for a redress of grievances.”</em> -Amendment I, Constitution of the United States</p>
</blockquote>

<p>Mike Ward is a French Canadian comedian who once made a joke about a child who was chronically ill, and was fined $80,000 CAD by the Quebec’s Human Rights Tribunal for his joke<sup id="fnref:13"><a href="#fn:13">10</a></sup>. The Scottish comedian Mark Meechan trained his dog to raise his paw when he heard the phrase “gas the Jews” for a video he used on a comedy routine. In 2018, Ward was fined £800 in the United Kingdom for violating a communication act for offensive speech. In many nations, jokes can result in fines or prison.</p>

<p>The freedom to speak does not guarantee the freedom to be heard. You can ignore those you disagree with. If you run a forum or social media platform in America, and you have a user who says something you disagree with, you are well within your rights to <a href="https://battlepenguin.com/politics/twitter-is-trying-to-erase-the-past/">delete their content</a> or ban their account. Except for a few states, employers are free to fire people based on their political views as well. The goal of the First Amendment is to protect individuals against persecution from their government. It prevents individuals from being arrested for voicing their opinions. Contrary to what Chris Cuomo says on CNN, the constitution does require that those who assemble must do so peaceably<sup id="fnref:16"><a href="#fn:16">11</a></sup>.</p>

<p>Very few high income nations have true freedom of speech, to the extent we have in the United States. There are limits to that freedom, of course. Although you may advocate for the use of force, immediate and immanent threats of directed violence are typically not protected. Obscenities, images of child abuse, direct threats to individuals, and lying materially to officers of the Federal Government are also not protected by the freedom of speech.</p>

<p>Still, Americas laws and protections are far that above other developed nations. The ability to speak ones mind, without fear of prosecution from the government, is a civil liberty vital to ensuring a free State and protecting against authoritarianism. Although the debate about this basic freedom may be more contentious in the age of <a href="https://battlepenguin.com/philosophy/society/how-social-media-destroyed-my-generation/">social media</a>, the America I grew up in is one where we do not fear ideas.</p>

<h3 id="the-pandemic">The Pandemic</h3>

<p>In Melbourne, Australia, a woman was choked by a police officer and arrested for not wearing a mask. She had a medical exemption, but she probably should have just said so instead of flipping off the police officer<sup id="fnref:17"><a href="#fn:17">12</a></sup>. Another woman in Melbourne was arrested for a Facebook post promoting a lockdown protest<sup id="fnref:12"><a href="#fn:12">13</a></sup>, which shows the limitations of Victoria’s Charter of Human Rights<sup id="fnref:5:1"><a href="#fn:5">8</a></sup>. When I bought this up with friends I knew in Melbourne, all of them supported the lockdown measures<sup id="fnref:20"><a href="#fn:20">14</a></sup>.</p>

<p>From the beginning of the pandemic, I was <a href="https://battlepenguin.com/philosophy/covid-19-is-two-diseases/">concerned about overreactions</a>. Many of those concerns <a href="https://battlepenguin.com/politics/secondary-effects/">turned out to sadly be true</a>. In late August, nearly 40,000 people in Germany<sup id="fnref:14"><a href="#fn:14">15</a></sup> and thousands of people in London<sup id="fnref:15"><a href="#fn:15">16</a></sup>, gathered in protests against the lockdowns. Just like <a href="https://battlepenguin.com/politics/this-is-not-a-time-of-honor/#protest">similar protests in the United States</a>, these groups are often ridiculed by the main stream media, but at least they have the right to gather. In Australia, BLM protests were ruled unlawful in Sydney. While I agree with Sky News’s evaluation of the protests being for a “Marxist movement<sup id="fnref:18"><a href="#fn:18">17</a></sup>,” such …</p></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://battlepenguin.com/politics/why-i-no-longer-hate-america/">https://battlepenguin.com/politics/why-i-no-longer-hate-america/</a></em></p>]]>
            </description>
            <link>https://battlepenguin.com/politics/why-i-no-longer-hate-america/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24618682</guid>
            <pubDate>Mon, 28 Sep 2020 16:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All DuckDuckGo bang operators on one page]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24618447">thread link</a>) | @MichaelMoser123
<br/>
September 28, 2020 | https://mosermichael.github.io/duckduckbang/html/main.html | <a href="https://web.archive.org/web/*/https://mosermichael.github.io/duckduckbang/html/main.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mosermichael.github.io/duckduckbang/html/main.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24618447</guid>
            <pubDate>Mon, 28 Sep 2020 16:34:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coding for Kids Is Not Just Another Fad]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24618292">thread link</a>) | @teragoodness
<br/>
September 28, 2020 | https://livetechnoid.com/8-reasons-coding-for-kids-is-not-just-another-fad/ | <a href="https://web.archive.org/web/*/https://livetechnoid.com/8-reasons-coding-for-kids-is-not-just-another-fad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-22192"><div><div itemprop="text"><p><img src="https://i2.wp.com/livetechnoid.com/wp-content/uploads/2020/09/Coding-for-Kids.png?resize=560%2C315&amp;ssl=1" alt="8 Reasons Coding for Kids is Not Just Another Fad" width="560" height="315" srcset="https://i2.wp.com/livetechnoid.com/wp-content/uploads/2020/09/Coding-for-Kids.png?w=560&amp;ssl=1 560w, https://i2.wp.com/livetechnoid.com/wp-content/uploads/2020/09/Coding-for-Kids.png?resize=300%2C169&amp;ssl=1 300w" sizes="(max-width: 560px) 100vw, 560px" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20560%20315'%3E%3C/svg%3E" data-lazy-srcset="https://i2.wp.com/livetechnoid.com/wp-content/uploads/2020/09/Coding-for-Kids.png?w=560&amp;ssl=1 560w, https://i2.wp.com/livetechnoid.com/wp-content/uploads/2020/09/Coding-for-Kids.png?resize=300%2C169&amp;ssl=1 300w" data-lazy-src="https://i2.wp.com/livetechnoid.com/wp-content/uploads/2020/09/Coding-for-Kids.png?resize=560%2C315&amp;ssl=1"></p><h2><span id="Is_Coding_a_Fad">Is Coding a Fad?</span></h2><p>In short, no. Coding is a field that is growing and changing quickly; there is a world of opportunity for young students looking to get involved in the tech world. Opponents to this position might argue that today’s popular languages, like Python, won’t be used ten or fifteen years down the line. So what’s the use in learning these programming languages?</p><h2><span id="8_Reasons_Coding_for_Kids_is_Not_Just_Another_Fad">8 Reasons Coding for Kids is Not Just Another Fad</span></h2><p>While it is true that programming will continue to advance, it is important to remember that there is so much more to learning a coding language like Python than memorizing syntax and applications. When we teach coding, we teach concepts beyond one particular language. Students gain knowledge about how computers process and “think” about a given problem, regardless of which language they are learning. They gain important intuition about fundamental concepts, like basic control structures (e.g. loops and conditional statements) and algorithms, that will undoubtedly be useful in our highly technological future. Below are 8 of the many reasons why coding for kids is not just another trendy or silly fad.</p><p><em><strong>Also, See:</strong></em></p><ul><li><a href="https://livetechnoid.com/how-to-encourage-stem-in-early-education/" rel="noopener follow" data-wpel-link="internal" target="_self"><em><strong>How to Encourage STEM in Early Education</strong></em></a></li><li><em><strong><a href="https://livetechnoid.com/beginner-python-draw-a-harry-potter-symbol/" rel="noopener follow" data-wpel-link="internal" target="_self">Beginner Python: Draw a Harry Potter Symbol</a></strong></em></li><li><em><strong><a href="https://livetechnoid.com/5-reasons-why-having-multiple-mentors-prepares-kids-for-the-future/" rel="noopener follow" data-wpel-link="internal" target="_self">5 Reasons Why Having Multiple Mentors Prepares Kids for the Future</a></strong></em></li></ul><h3><span id="Our_world_is_growing_more_technological">Our world is growing more technological</span></h3><p>In the 21st century, we have seen enormous developments in the technology industry. The world is moving in a direction that is both fast-paced and information-centred. Data is quickly becoming one of the most valuable resources in the global economy, and individuals with digital literacy are becoming more valued in the labour market. With all of this in mind, it’s hard to ignore the massive role that fields like data science and software engineering, both largely centred around coding, are going to have. Figures estimate seemingly outrageous numbers – <a href="https://hostingtribunal.com/blog/how-fast-is-technology-growing/" data-wpel-link="external" target="_blank" rel="nofollow external noopener">an estimated fifty billion smart devices are projected to be in use by 2020</a> – illustrating the abundance of technology in our lives.</p><p>With such statistics in our near futures, it is clear to see that industries are changing. The internet is a hub of information, applications, e-commerce, social networking, and communication platforms, all of which are designed to increase efficiency, performance, and convenience. As industries become digitized, new jobs are simultaneously emerging. Coding is an asset that will only continue to grow as we move forward as an increasingly connected society.</p><h3><span id="It_teaches_kids_to_strategize_for_unique_solutions">It teaches kids to strategize for unique solutions</span></h3><p>Computer science is a highly useful tool beyond its direct applications. As there is rarely one right answer to a given problem, computer science encourages students to create solutions that are unique. For computer scientists, this means that coders have a great amount of leeway to create their own intuitive solutions.</p><p>Teaching kids how to code <a href="https://news.harvard.edu/gazette/story/2014/11/coding-and-creativity/" data-wpel-link="external" target="_blank" rel="nofollow external noopener">pushes young students to actually learn</a>, not just memorize facts and regurgitate them. It challenges students to critically think about a problem, what they want to accomplish, and how to get it done. There are plenty of kid-friendly coding languages, such as <a href="https://junilearning.com/blog/scratch-beginning-coding-language-for-kids" data-wpel-link="external" target="_blank" rel="nofollow external noopener">Scratch</a>, that give young students the opportunity to build unique projects using coding techniques. Scratch also allows coders to share their projects with the world. This connectivity can inspire new and aspiring coders to learn from their peers and guide them through more complicated projects and concepts. This collaborative environment also allows students to work together and learn from one another. Encouraging kids to utilize these programs not only teaches them useful skills for computer science, but it also allows them to exercise their creativity.</p><h3><span id="It_teaches_students_to_not_give_up">It teaches students to not give up</span></h3><p>Most coders will advise, while there is plenty of room for creativity in coding, there is also plenty of room for error. Learning to code teaches students how not to give up on their solutions, but rather to debug their code, even when repeated error messages appear. Coders tease out solutions by using their understanding of computational thinking (see point 6) to isolate any errors and achieve the goal at hand.</p><p>That code can always be improved upon motivates coding students to go back and better their solutions, an incredibly valuable skill set to have in general. Code also instils resilience, yet another invaluable tool in the workplace. While programming can feel tedious, frustrating, and difficult at times, the process of problem-solving inherently makes for better coders and better students.</p><h3><span id="It_can_be_applied_to_almost_everything_that_students_are_learning">It can be applied to almost everything that students are learning</span></h3><p>Computer science is expanding into every corner of the world, with applications for anything one can imagine and automated services that are permeating thousands of business models worldwide. On top of that, programming incorporates many mathematical concepts, and it can complement the concepts students are learning in their math classes.</p><p>Coding also <a href="https://blog.mindresearch.org/blog/coding-mathematical-practices" data-wpel-link="external" target="_blank" rel="nofollow external noopener">promotes problem-solving</a>, an important skill for any student. Beyond math, students can use code to support other interests they may have. With coding, young professionals’ career options extend across industries. By teaching kids how to code, students will find the confidence and tools to explore aspects of software engineering, data analysis, video game development, and mobile app development – in just about any industry that they know and love.</p><h3><span id="It_is_challenging_and_collaborative">It is challenging and collaborative</span></h3><p>Coding challenges young students to explore new fields. Computer science is a collaborative field, allowing individuals to work together to complement one another’s skill sets, and write code that is efficient and intuitive. Students can and often do learn to code in a group setting, so that they can discuss their ideas and learn from each other’s successes. Learning to code encourages students to work together when they reach a roadblock. It promotes collaboration via idea exchange and allows students’ to compare and contrast solutions. Teaching kids about computer programming can be a catalyst for inspiring teamwork and leadership among students.</p><h3><span id="It_teaches_students_about_computational_thinking">It teaches students about computational thinking</span></h3><p>Whichever languages a student decides to pursue – Python, Java, or any of the long list of popular coding languages today – will help them develop computational thinking. This means that students will learn how to effectively break down problems into manageable parts, observe patterns in data, identify how these patterns are generated, and develop the step-by-step instructions for solving those problems.</p><p>Computational thinking and digital literacy are arguably the most important aspect to learning to code at any age due to the huge technological shift in nearly every industry on the global market (see point 1). Establishing a foundation in computational thinking will pave the way for future success in and outside CS related fields. All students can benefit from understanding computational thinking, as it applies to the technological aspects of daily life.</p><h3><span id="Its_good_for_the_brain">It’s good for the brain</span></h3><p>Like any good challenge, coding is an excellent way to strengthen young, developing brains. It encourages students to combine their knowledge of computational learning and out-of-the-box thinking to strategize unique solutions.</p><p><a href="https://medium.com/datadriveninvestor/coding-is-good-for-your-brain-e067063a493e" data-wpel-link="external" target="_blank" rel="nofollow external noopener">Multiple studies</a> support the hypothesis that learning to code has real, long term benefits on young children. Researchers have found that individuals who code tend to have reduced odds of getting neurodegenerative diseases in older age. Coders also tend to do better in cognitive tasks, because coding activates areas of the brain that are associated with memory, attention, and logic. Learning to code at an early age supports neural connections in these regions, leading to high performance in other fields, as well.</p><h3><span id="Its_fun">It’s fun!</span></h3><p>While we may be slightly biased, computer science is an educational way to bring fun into your children’s lives! Computer science is one of the few fields of study in which students can see the immediate outcome of their work as they build out their projects – by running their code, they get instant, live feedback.</p><p>Programs like <a href="https://scratch.mit.edu/" data-wpel-link="external" target="_blank" rel="nofollow external noopener">Scratch</a> and <a href="https://repl.it/" data-wpel-link="external" target="_blank" rel="nofollow external noopener">Repl.it</a> utilize software that is kid-friendly and permits students to visualize their projects as they come to life! They can build code that creates a videogame or a website and share their work with friends. Developing kids’ proficiency with computer science now will lead to a future generation of coders who have the skill set to advance our world.</p><p><em><strong>Also, See:</strong></em></p><ul><li><em><strong><a href="https://livetechnoid.com/5-best-ways-to-learn-internet-marketing/" rel="noopener follow" data-wpel-link="internal" target="_self">5 Best Ways to Learn Internet Marketing</a></strong></em></li><li><em><strong><a href="https://livetechnoid.com/how-to-get-into-a-top-tier-computer-science-program/" rel="noopener follow" data-wpel-link="internal" target="_self">How to Get into a Top-Tier Computer Science Program</a></strong></em></li><li><em><strong><a href="https://livetechnoid.com/computer-maintenance-upgrade/" rel="noopener follow" data-wpel-link="internal" target="_self">Free Tutorial on Computer Maintenance and Upgrade</a></strong></em></li></ul><p><i>This </i><a href="https://junilearning.com/blog/guide/8-reasons-coding-for-kids-not-a-fad/?utm_source=gf&amp;utm_medium=reasons_coding_for_kids_not_another_fad&amp;utm_campaign=outreach" data-wpel-link="external" target="_blank" rel="nofollow external noopener"><i>article</i></a><i> originally appeared on </i><a href="https://junilearning.com/?utm_source=gf&amp;utm_medium=reasons_coding_for_kids_not_another_fad&amp;utm_campaign=outreach" data-wpel-link="external" target="_blank" rel="nofollow external noopener"><i>junilearning.com</i></a><i>&nbsp;</i></p></div></div></article></div>]]>
            </description>
            <link>https://livetechnoid.com/8-reasons-coding-for-kids-is-not-just-another-fad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24618292</guid>
            <pubDate>Mon, 28 Sep 2020 16:19:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Than JSON]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24618121">thread link</a>) | @susam
<br/>
September 28, 2020 | https://wiki.alopex.li/BetterThanJson | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/BetterThanJson">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>I want to take a brief look at various data serialization formats and compare them. Basically the goal is to answer the question, “can we find something better than JSON?” However, note that we are looking at these things for DATA SERIALIZATION, not for config files and stuff, so that’s the goal by which these will be judged.</p>
<p>There’s two orthogonal axes to look at these things under:</p>
<ul>
<li>Self-describing vs.&nbsp;schema-defined formats</li>
<li>Human readable vs.&nbsp;machine-readable formats</li>
</ul>
<p>That is, whether the type information for a structure is defined in a separate file (a schema) that a receiving program checks against, or whether the message itself contains type information. It’s almost exactly the difference between statically and dynamically typed programming languages. Like programming languages, both have pros and cons, neither of them are always better than the other. The goal of this is to compare apples to apples, so we’re gonna note which category these things fall into but not make value judgements based on them. There’s also fuzzy edges; many self-describing formats optionally have a schema layer too. Similarly, we will not really compare tooling quality; the goal is to look at the intrinsic properties of the formats. The culture surrounding them may be considered though.</p>
<p>This is also important not to conflate with an RPC protocol, though many of these things are used IN RPC protocols. Keep in mind that HTTP/REST interfaces are often just a type of RPC protocol, whether realized that way or not.</p>
<p>Up to date as of September 2019. Doesn’t try to include myriad minor things, ’cause there’s only so much time in the world.</p>

<h2 id="json">JSON</h2>
<p><a href="http://json.org/">http://json.org/</a></p>
<p>What everything gets currently compared against. We all know JSON, we all agree it’s Sorta Good Enough but really is kinda crap.</p>
<p><strong>Category:</strong> Human-readable, self-describing. (<a href="https://json-schema.org/">https://json-schema.org/</a> exists but does not seem very widely used.) Has an <a href="https://en.wikipedia.org/wiki/JSON-RPC">RPC protocol</a> but it also seems lightly used, <a href="https://jsonapi.org/">this</a> might be more general.</p>
<p><strong>Users:</strong> Everyone</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Similar to major programming languages – Easy to understand and debug</li>
<li>Simple – Easy to read, write, and understand… at least for simple things. <a href="http://seriot.ch/parsing_json.php">Turns out there’s a lot of gotcha’s though.</a></li>
<li>Pretty compact if minified</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Type system is pretty shit – no date/time, no real integers, no real structs, no unions/tuples/etc</li>
<li>Tends to discourage schema’s – “So simple it doesn’t need it”, until it becomes less simple.</li>
<li>No normalized form – fields may be reordered, <em>duplicated</em>, etc. Makes hashing it hard, gotta read whole message to begin verifying it, etc.</li>
<li>No comments – harder to write well than you might think!</li>
<li>No good way to contain binary data</li>
</ul>
<h2 id="yaml">YAML</h2>
<p><a href="https://yaml.org/">https://yaml.org/</a></p>
<p>Started out as a simpler alternative to XML.</p>
<p><strong>Category:</strong> Human-readable, self-describing.</p>
<p><strong>Users:</strong> Lots of people</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Vaguely simple to read and write, in its basic form</li>
<li>Low visual noise</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Way too complicated – they made it a strict superset of JSON for some damn reason, and nobody uses that form, so it’s just a pile of wasted effort</li>
<li>Reference impl incomplete, other impl’s disagree with each other and the spec</li>
</ul>
<h2 id="xml">XML</h2>
<p><a href="https://en.wikipedia.org/wiki/XML">https://en.wikipedia.org/wiki/XML</a></p>
<p>Not sure anyone really knows how XML happened. It’s basically the W3C’s fault, I think? It’s okay for some things but in the end I’m not sure it’s something anyone actually <em>wants</em> to use, it’s just going to be one more of those mistakes of the past.</p>
<p><strong>Category:</strong> Human-readable, self-describing with common schema usage. Has an <a href="https://en.wikipedia.org/wiki/XML-RPC">RPC protocol</a> and many other complicated things.</p>
<p><strong>Users:</strong> Everyone who can’t avoid it.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Promotes schemas and validation</li>
<li>Simple to use for simple things</li>
<li>Actually pretty decent for documents</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>I’ve never gotten schemas and validation to actually work in practice</li>
<li>Everything is string-ly typed</li>
<li>No real arrays</li>
<li>Complicated as frig</li>
<li>Very verbose</li>
<li>There’s like 3-4 different ways to do everything</li>
<li>Still no good way to contain binary data</li>
</ul>

<h2 id="protobuf">Protobuf</h2>
<p><a href="https://developers.google.com/protocol-buffers/">https://developers.google.com/protocol-buffers/</a></p>
<p>aka Protocol Buffers, but that’s a pretty dumb name. Google’s common, fast on-the-wire serialization format.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Has an <a href="https://grpc.io/">RPC protocol</a> built around it.</p>
<p><strong>Users:</strong> Google, basically everyone</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Backed by Google, so it’s going to be good at the things Google values</li>
<li>Basically reasonable</li>
<li>Now has some support for versioning schemas, though it’s a hard problem in general</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Backed by Google, so it’s going to be good at the things Google values</li>
<li>Not particularly simple</li>
<li>Wire protocol may be more work than it needs to be</li>
<li>Its type system <a href="http://reasonablypolymorphic.com/blog/protos-are-wrong/index.html">could maybe be better</a></li>
</ul>
<h2 id="capn-proto">Cap’n Proto</h2>
<p><a href="https://capnproto.org/">https://capnproto.org/</a></p>
<p>The Other Binary Serialization Protocol.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Designed primarily for RPC, which is built in to the reference implementation.</p>
<p><strong>Users:</strong> sandstorm.io, various other people but it doesn’t seem like that many</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Designed to be fast</li>
<li>Made by one of the people who worked heavily on Protobuf at Google, so <a href="https://capnproto.org/faq.html#how-do-i-make-a-field-required-like-in-protocol-buffers">there’s lots of experience behind it</a>. That said, doesn’t mean this cat’s always <em>right</em>, but there’s certainly opinions that are trying to be expressed.</li>
<li>Sophisticated RPC comes as part of the standard package</li>
<li>Designed for zero-copy deserialization</li>
<li>Designed for schema to evolve</li>
<li>Adorable name</li>
<li>Very explicit about correctness and conformance things such as field ordering and layout</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Very explicit about correctness and conformance things such as field ordering and layout</li>
<li>Lots of the docs and concepts are pretty low level, you usually ain’t gonna need it</li>
<li>Seems more complicated than protobuf – this might be one reason there’s fewer 3rd-party implementations</li>
</ul>
<h2 id="thrift">Thrift</h2>
<p><a href="https://thrift.apache.org/">https://thrift.apache.org/</a></p>
<p>Apache’s version of Protobuf. Does anyone actually use this? Facebook, apparently, since they invented it and then gave it to Apache. Anyone else?</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Designed primarily for RPC.</p>
<p><strong>Users:</strong> Basically just Facebook?</p>
<p><strong>Pros:</strong></p>
<ul>
<li>It works?</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Docs suck</li>
<li>Apache is the tragic junkyard of open source projects</li>
<li>Apparently still not as good as flatbuffers, see below</li>
</ul>
<h2 id="flatbuffers">Flatbuffers</h2>
<p><a href="https://google.github.io/flatbuffers/">https://google.github.io/flatbuffers/</a></p>
<p>Feels a little like Google’s answer to Cap’n Proto, as it has some of the same design goals – zero-copy serialization and layouts that are more amenable to versioning.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Includes RPC protocol.</p>
<p><strong>Users:</strong> Google, Cocos2D, Facebook’s mobile client</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Designed for zero-copy deserialization</li>
<li>Designed for schema to evolve</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Kinda feels like the problem is already solved by capnp</li>
<li>Includes a JSON parser for some reason?</li>
<li>Type system is kinda anemic with regards to unions</li>
</ul>
<h2 id="cbor">CBOR</h2>
<p><a href="https://cbor.io/">https://cbor.io/</a></p>
<p>Basically a binary re-imagining of JSON.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> ???</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Pretty good type system – there’s things like fixnum’s, datetime’s, blobs, etc</li>
<li>Compact</li>
<li>Built-in extensibility</li>
<li>Designed to be a drop-in replacement for JSON</li>
<li>IETF standard</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Kinda more complicated than it needs to be, though this is for the sake of compactness and comprehensive types. Numbers are densely packed into fewer bits when possible, for example.</li>
<li>Doesn’t actually seem that widely adopted for some reason?</li>
</ul>
<h2 id="msgpack">Msgpack</h2>
<p><a href="https://msgpack.org/">https://msgpack.org/</a></p>
<p>The Other CBOR, or rather, <a href="https://news.ycombinator.com/item?id=14067747">CBOR is derived from this</a>. Designed to be simple and compact. Kinda a <em>lot</em> like a slightly chopped down CBOR, actually, their integer specification stuff looks nearly identical.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> Redis, a few others?</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Simple</li>
<li>Compact</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Specification is kinda weak</li>
<li>No real tuple or enum types</li>
<li>Why not just CBOR?</li>
</ul>
<h2 id="bson">BSON</h2>
<p><a href="http://bsonspec.org/">http://bsonspec.org/</a></p>
<p>As the name implies, a binary-ifcation of JSON. Created by MongoDB as its internal data format.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> MongoDB</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Type system is full of deprecated and MongoDB-specific shit but is reasonably pragmatic</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Type system is reasonably pragmatic but is full of deprecated and MongoDB-specific shit</li>
<li><strong>C strings</strong> – though there’s random non-C strings in places as well.</li>
<li>Its arrays are a travesty against serializarion</li>
<li>Basically an implementation detail of MongoDB, and it looks like it</li>
</ul>

<p>Things that are interesting but not actually in the scope of serialization languages, or are otherwise irrelevant.</p>
<h2 id="toml">TOML</h2>
<p><a href="https://github.com/toml-lang/toml">https://github.com/toml-lang/toml</a></p>
<p>Invalid, it’s designed as a config language, not a serialization format. It’s basically an attempt to make something as simple and ubiquitous as windows .INI files that is an actual specification rather than a fashion.</p>
<p><strong>Category:</strong> Human-readable, sorta self-describing though usually you have a specific data structure you’re trying to fit it into.</p>
<p><strong>Users:</strong> Various, notably Cargo (Rust’s build tool)</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Work well as a config language without deeply nested structures</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Works poorly when you try to make deeply nested structures</li>
</ul>
<h2 id="ron">RON</h2>
<p><a href="https://github.com/ron-rs/ron">https://github.com/ron-rs/ron</a></p>
<p>Rusty Object Notation. Because shoehorning Rust’s ML-y type systeminto JSON isn’t very much fun. Works startlingly well for this purpose but is basically untried elsewhere.</p>
<p><strong>Category:</strong> Human-readable, sorta self-describing though usually you have a specific data structure you’re trying to fit it into.</p>
<p><strong>Users:</strong> A few, notably <a href="https://amethyst.rs/">Amethyst</a>.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Good type system for sophisticated functional-style languages</li>
<li>Simple and reasonably compact</li>
<li>Actually very good at what it does</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Young, underspecified, Rust-centric</li>
</ul>
<h2 id="bincode">Bincode</h2>
<p><a href="https://github.com/servo/bincode">https://github.com/servo/bincode</a></p>
<p>Included mainly for completeness. It’s not standardized outside of a single particular implementation which doesn’t promise stability, so not intended for general-purpose use. It’s intended as a fast and easy RPC/IPC format for Servo, and the actual format is basically an implementation detail of that goal.</p>
<p><strong>Users:</strong> Servo, programs written by introverts who don’t care about being able to talk to each other. (Turns out this is a useful niche though, who knew.)</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Compact, fast, simple.</li>
<li>Works basically transparently for IPC with Rust code.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Anything other than that specific version of that specific library is undefined. If you’re OK with that though, it’s great.</li>
</ul>
<h2 id="asn.1">ASN.1</h2>
<p><a href="https://en.wikipedia.org/wiki/Abstract_Syntax_Notation_One">https://en.wikipedia.org/wiki/…</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/BetterThanJson">https://wiki.alopex.li/BetterThanJson</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/BetterThanJson</link>
            <guid isPermaLink="false">hacker-news-small-sites-24618121</guid>
            <pubDate>Mon, 28 Sep 2020 16:05:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Vassallo has made $200k with a Twitter course]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24618058">thread link</a>) | @Pete-Codes
<br/>
September 28, 2020 | https://www.petecodes.io/daniel-vassallo-200k-revenue-report/ | <a href="https://web.archive.org/web/*/https://www.petecodes.io/daniel-vassallo-200k-revenue-report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.petecodes.io/content/images/size/w300/2020/09/Screenshot-2020-09-28-at-13.30.39.png 300w,
                            https://www.petecodes.io/content/images/size/w600/2020/09/Screenshot-2020-09-28-at-13.30.39.png 600w,
                            https://www.petecodes.io/content/images/size/w1000/2020/09/Screenshot-2020-09-28-at-13.30.39.png 1000w,
                            https://www.petecodes.io/content/images/size/w2000/2020/09/Screenshot-2020-09-28-at-13.30.39.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.petecodes.io/content/images/size/w2000/2020/09/Screenshot-2020-09-28-at-13.30.39.png" alt="Daniel Vassallo has made $200k by teaching how to get a Twitter following">
            </figure>

            <section>
                <div>
                    <p>Daniel Vassallo is a former Software Engineer at AWS who <a href="https://danielvassallo.com/only-intrinsic-motivation-lasts/">quit his job last year</a> in order to work on his products. Along the way he started to pick up a following on Twitter and made a video course on <a href="https://gumroad.com/a/466973811/PBkrO">how to build an audience.</a> I'm excited about chatting to him on Zoom today - <a href="https://gum.co/ICuKS">you're welcome to ask him questions too</a>! </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/ICuKS"><img src="https://www.petecodes.io/content/images/2020/09/Screenshot-2020-09-28-at-13.01.37.png" alt="Screenshot-2020-09-28-at-13.01.37"></a></p>
<!--kg-card-end: markdown--><p>In a very short space of time <a href="https://twitter.com/dvassallo/status/1281263000792346627?s=20">he has earned over $200,000 from just this course</a>. It's pretty incredible given this was just a product he made while he was working on his next big project, <a href="https://userbase.com/">Userbase, which lets you make serverless web apps</a>. </p><p>I don't think Daniel had any idea his course would blow up the way it did. He helped himself by writing a post about quiting his $500k job at Amazon. That definitely helped him get some initial followers. </p><p>Of course with an existing audience he was able to have a big advantage over other content producers. And as word spread of his course, he got more followers! And so his credentials improved meaning he sold more courses! Because if you see someone selling a course on getting more Twitter followers and they themselves have an audience which keeps growing, naturally you are attracted to their product. And so the cycle continues. </p><p>If you are interested in the specifics of the course, <a href="https://www.petecodes.io/review-daniel-vassallo-twitter-audience-course/">I wrote a review here</a>. </p><p>Of course there are already lots of Twitter courses available online. So what made Daniel's course stand out? </p><p>Firstly, he used social proof and early buyers generated a lot of positive reviews. I should know as I bought a copy after seeing that Randall Kanna had seen her following shoot up after taking the course. Word spread quickly in tech circles that it was a quality course. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">An unexpected $1K day today, came out of nowhere. This month will likely close at ~$12K, and I did no direct promotion. No tweets, no paid ads — just word of mouth. Very satisfied, and thank you for all the support! 🙏 <a href="https://t.co/LQ1pnLyR05">pic.twitter.com/LQ1pnLyR05</a></p>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1287954138634977281?ref_src=twsrc%5Etfw">July 28, 2020</a></blockquote>

</figure><h2 id="using-affiliates-to-generate-income-passively">Using affiliates to generate income passively </h2><p>Secondly, he has been clever in using the Gumroad affiliates system. Gumroad is awesome as it has a really flexible affiliates feature open to anyone on the platform. You are able to set what % of a sale each affiliate is going to get. Of course, Daniel only has to pay when someone makes a sale. So with affiliates he has people like me speading the word about his courses and making money for him passively. It also helps that he gives 50% to affiliates which is a good incentive to share his course. </p><figure><img src="https://www.petecodes.io/content/images/2020/09/Screenshot-2020-09-28-at-12.51.07.png" alt=""></figure><h2 id="a-high-price-point-communicates-quality">A high price point communicates quality</h2><p>He also set a high price point which conveys value. It can be paradoxical but if people pay a high price it can be better as no-one wants to believe they paid too much. So they justify it to themselves. It's also more likely they will complete the course. </p><p>Like most people, I have a graveyard of free and very cheap courses in my Udemy course. I also have a tonne of free ebooks I've never read. In contrast, I just ordered Steph Smith's Doing Content Right ebook which cost me $30. As it cost me more I'm more motivated to read it as I want to get my money's worth. With free and very cheap books, I value them less. </p><p>Stella Artois was able to craft a better image in the UK in the 90s by a clever slogan - "reassuringly expensive". This is still one of my favourite marketing campaigns of all time! Instead of having people question the price you make the higher price a signal of quality. </p><figure><img src="https://www.petecodes.io/content/images/2020/09/iu-54.jpeg" alt=""></figure><h2 id="ask-daniel-your-questions">Ask Daniel your questions </h2><p>I'm looking forward to chatting with <a href="https://gum.co/ICuKS">Daniel today on Zoom</a> at 10am Seattle time. For 30 minutes I'm going to be asking him questions and then I'm passing the mic, so to speak, to anyone who wants it! I've organised two chats like this already; one with Anne-Laure Le Cunff and last week I spoke to Ben Tossell. </p><p>I've reduced prices by 50% to $15. This gives you access to the Zoom call with Danial as well as next Monday's chat with Scott Keyes, the co-founder of Scott's Cheap Flights. </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/ICuKS"><img src="https://www.petecodes.io/content/images/2020/09/Screenshot-2020-09-28-at-13.01.37.png" alt="Screenshot-2020-09-28-at-13.01.37"></a></p>
<!--kg-card-end: markdown-->
                </div>
            </section>

                <section>
    <h3>Subscribe to Pete Codes </h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.petecodes.io/daniel-vassallo-200k-revenue-report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24618058</guid>
            <pubDate>Mon, 28 Sep 2020 15:59:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Talk to Customers During an Incident]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24617918">thread link</a>) | @redRanger72
<br/>
September 28, 2020 | https://iamevan.me/categories/sre/customer-communication-during-incidents-the-how-to-of-status-page-updates/ | <a href="https://web.archive.org/web/*/https://iamevan.me/categories/sre/customer-communication-during-incidents-the-how-to-of-status-page-updates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://iamevan.me/images/posts/2020-09-27-Customer-Communication-During-Incidents-The-How-To-Of-Status-Page-Updates.jpg" alt=""></p>
<p>Something often overlooked during an incident is how we communicate with our customers and reassure them of the situation. How you convey an incident to the people paying for your service can make all the difference when it comes to contract renewal period. At a past company, our sales team regularly reported back from client meetings that they consistently mentioned how helpful and reassuring status page updates from the SRE team were, even when our service was fully down. We need to stop treating our customers like they’re non-technical children and give them information that will help them make their usage of us more reliable in the long-term.</p>

<p>The most likely and easiest point of contact for a technical team to customers is the status page. It’s the first port of call when you suspect a third-party is causing issues or not behaving itself. It doesn’t really matter what yours looks like as long as it provides the functionality for people to view timestamped updates posted by your oncall team during an incident.</p>
<p>A good status page helps build trust with our users, and show a glimpse into how we behave during incidents and how committed we are not only to reduce the number and impact of incidents, but to be transparent about them (sometimes sharing your mistakes is a good way of shaming yourself into fixing them!).</p>
<p>This will be an ongoing record of of past and present incidents so our customers can have a reasonable and current idea of: 1) how well our services are performing; and 2) if an issue they are experiencing is related to a wider problem or just isolated to them.</p>
<p><img src="https://media.giphy.com/media/citBl9yPwnUOs/giphy.gif" alt="Homer  Simpson hovering over a computer that says “to start, press any key” and homer is thinking aloud “Where’s the ‘any’ key?" "=""></p>
<h2 id="who-writes-the-message">Who Writes The Message</h2>
<p>Assuming you follow something like the <a href="https://en.wikipedia.org/wiki/Incident_Command_System">Incident Command System</a>, this task can either be done by the Incident Commander or delegated to someone else. It’s upto the person leading the incident to decide who updates and how frequently they update.</p>
<h2 id="how-quickly-should-an-update-go-out">How Quickly Should An Update Go Out?</h2>
<p>Simple answer: <strong>as soon as possible</strong>.</p>
<p>Until we’ve posted something, our users won’t know that we know something is wrong and are working to mitigate it. Generally, if you work for a sizeable company, you’ll have experienced the floods of emails to support with “my shit’s broken, yo! WHERE’S YOUR STATUS PAGE?” and while it’s true you can never eliminate all of those, putting up something as soon as you are alerted to an incident is definitely going to help minimise them a lot (and your customers will appreciate you more for it).</p>
<p>With that said though, there is a trade-off to how quick an update goes out. You need to find a balance between providing accurate and relevant information (what the exact impact is and the actual start time of an incident) versus having a fast response. There’s no definitive answer here, it’s mostly something you’ll work out with experience but remember: You can always update the status page to be more specific later, it’s good to err on the side of quickness than waiting too long.</p>
<h2 id="how-often-should-we-update">How Often Should We Update?</h2>
<p>The team should sit down and decide on an appropriate interval to use for incidents going forward. In the past, I’ve found 20 minute intervals works well enough as a starting point.</p>
<p>In that case, you should aim to have an update out every 20 minutes with relevant information - <strong>do not copy and paste the same message</strong>. If we are at a point where there is no new information to be added, it might be time to consider increasing the update interval.</p>
<p>Increasing the interval should be explicitly stated in an update. If we’re moving from 20 minutes to 1 hour, we should state the current impact and say that our customers should expect an update in an hour or less if more information becomes relevant.</p>
<p>Increasing the interval can also be a good way to free up an extra person from the communication role if there aren’t enough hands on deck.</p>
<p>Giving people a reasonable timeframe for more information eases stress and allows them to plan their own mitigation strategy if they rely on our service. We also don’t want someone furiously refreshing our page for hours waiting for an update that isn’t coming.</p>

<p>I would wager you aren’t lucky to have a staff of technical writers on hand to pen your updates, so these messages fall to regular ol' engineers. That also means we don’t expect you to write the next literary masterpiece. What we do want to accomplish is:</p>
<ul>
<li>Clear communication</li>
<li>The right amount of details</li>
<li>A good representation of the company in the public eye</li>
</ul>
<p>Take some time to consider the right tone of your communication, maybe write a doc outlining some common examples for the team.</p>
<h2 id="the-title">The Title</h2>
<p>The title is a very important part of an update. Sometimes it’s the only thing the user sees before making the decision of clicking to see the rest or not, so we need to help the user answer the following question: “Do I need to care about this?”. How do we do this? By stating how it affects <strong>them</strong> as clearly as possible.</p>
<p><img src="https://media.giphy.com/media/3o6UBiAQ9Ws8UWdmqA/giphy.gif" alt="Miss Hoover from the Simpsons sitting in a classroom, reaching under the desk to push a big red button labelled “Independent Thought Alarm”"></p>
<blockquote>
<p>“Website Issues”</p>
</blockquote>
<p>Is quite vague and very poor at indicating what’s actual affected.</p>
<blockquote>
<p>“Increased API Response Times”</p>
</blockquote>
<p>Is much better and clearly identifies the service affected, what symptoms to look for and how that may affect the customer.</p>
<h2 id="the-message">The Message</h2>
<p>How you write this is going to come down to a mixture of experience and empathy. You’re going to need to put yourself in your customer’s shoes and think “what would <em>I</em> care about if I saw this incident?”</p>
<p>You’re going to need a couple elements for certain though:</p>
<ol>
<li>The exact time <em>the problem started</em>. Be sure to include a timezone to avoid an ambiguity. Also important to note that this is <em>not</em> necessarily the same time you opened the status page or were alerted to the problem.</li>
<li>A clear description of what <strong>is</strong> and <strong>isn’t</strong> impacted. This should include information a customer can use to diagnose if their particular issue is related to the incident. It’s also a great time to state what isn’t affected by the incident and relieve some stress. For example: if you ingest user data but are just having delays processing it, it can be good to state that ingestion is unaffected and no user data has been lost.</li>
<li>The exact time of the update and when the issue has been resolved. Again, with timezones, these will help customers build a timeline to compare to their own logs.</li>
<li>A technical description of the problem. Your customers are smarter than you give them credit for and deserve to be treated like adults. Be open in your communication of what the problem is because it will also build respect for the next element.</li>
<li>What are we doing to resolve the problem? Don’t just say “we are dealing with the situation” or “we’re applying a fix” because that isn’t fair to your customers. This is also going to be very useful to you when you create a postmortem for the incident.</li>
</ol>
<h2 id="some-general-tips">Some General Tips</h2>
<ul>
<li>Don’t apologise or use “sorry for the inconvenience” <a href="https://signalvnoise.com/posts/1528-the-bullshit-of-outage-language">bullshit language</a></li>
<li>Be clear, be concise and state the impact up front</li>
<li>Be as specific as possible, but only when it helps</li>
<li>24hr UTC is the crowned king of timestamps</li>
<li>Generic maintenance pages frustrate/scare people</li>
<li>Please, for the love of god do not copy and paste the same variation of the same message <a href="https://status.datadoghq.com/incidents/6s5xxxjh33lh">over</a> and <a href="https://www.githubstatus.com/incidents/pbz6fh7mz86w">over</a> and <a href="https://www.hetzner-status.de/en.html">over</a> again</li>
</ul>
<p>For more info:</p>
<ul>
<li><a href="https://www.hostedgraphite.com/blog/how-to-write-a-status-page-update">“How To Write A Status Page Update”</a> by Fran Garcia</li>
<li><a href="https://signalvnoise.com/posts/1528-the-bullshit-of-outage-language">“The Bullshit Of Outage Language”</a> by David H. Hanson</li>
<li><a href="https://www.atlassian.com/blog/statuspage/how-to-write-a-good-status-update">“How To Write A Good Status Update”</a> by Blake Thorne</li>
</ul>
<p><img src="https://media.giphy.com/media/3o8doT9BL7dgtolp7O/giphy.gif" alt="Carl from the Simpsons performing the chef’s kiss"></p>

<p>These are all examples of postmortems but you’ll notice that a lot of the language is the same and some include all the status updates as well. They’re useful examples as both status updates and postmortems and I would highly recommend reading all the different styles.</p>
<ul>
<li><a href="https://status.hostedgraphite.com/incidents/xdrrb9g3lxm7">The Short all-rounder</a></li>
<li><a href="https://www.traviscistatus.com/incidents/khzk8bg4p9sy">Sometimes, there is no “What Went Well”</a></li>
<li><a href="https://aws.amazon.com/message/4372T8/">The Essay Alternative</a></li>
<li><a href="https://blog.cloudflare.com/how-and-why-the-leap-second-affected-cloudflare-dns/">Sometimes, it’s more of a story</a></li>
<li><a href="https://circleci.statuspage.io/incidents/hr0mm9xmm3x6">A Very Technical Timeline</a></li>
<li><a href="https://sb.status.hostedgraphite.com/incidents/f51fnwjvxx0k">A Lot Of Timelines (and some internal tracking)</a></li>
</ul>

        </div></div>]]>
            </description>
            <link>https://iamevan.me/categories/sre/customer-communication-during-incidents-the-how-to-of-status-page-updates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617918</guid>
            <pubDate>Mon, 28 Sep 2020 15:47:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive GCC (igcc) – a REPL for C/C++]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24617861">thread link</a>) | @pmoriarty
<br/>
September 28, 2020 | http://www.artificialworlds.net/wiki/IGCC/IGCC | <a href="https://web.archive.org/web/*/http://www.artificialworlds.net/wiki/IGCC/IGCC">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">

<p><a href="#home"><span>Introduction</span></a> | <a href="#download"><span>Downloading and using</span></a> | <a href="#developing"><span>Developing</span></a> | <a href="#links"><span>Links</span></a> | <a href="#copyright"><span>Copyright</span></a>
</p>

<p>Interactive GCC (igcc) is a real-eval-print loop (REPL) for C/C++ programmers.
</p>
<p>It can be used like this:
</p><pre> $ ./igcc 
 g++&gt; int a = 5;
 g++&gt; a += 2;
 g++&gt; cout &lt;&lt; a &lt;&lt; endl;
 7
 g++&gt; --a;
 g++&gt; cout &lt;&lt; a &lt;&lt; endl;
 6
 g++&gt; 
</pre><p>It is possible to include header files you need like this:
</p><pre> $ ./igcc 
 g++&gt; #include &lt;vector&gt;
 g++&gt; vector&lt;int&gt; myvec;
 g++&gt; myvec.push_back( 17 );
 g++&gt; printf( "%d\n", myvec.size() );
 1
 g++&gt; myvec.push_back( 21 );
 g++&gt; printf( "%d\n", myvec.size() );
 2
 g++&gt; 
</pre><p>Compile errors can be tolerated until the code works:
</p><pre> $ ./igcc
 g++&gt; #include &lt;map&gt;
 g++&gt; map&lt;string,int&gt; hits;
 g++&gt; hits["foo"] = 12;
 g++&gt; hits["bar"] = 15;
 g++&gt; for( map&lt;string,int&gt;::iterator it = hits.begin(); it != hits.end(); ++it )
 [Compile error - type .e to see it.]
 g++&gt; {
 [Compile error - type .e to see it.]
 g++&gt; 	cout &lt;&lt; it-&gt;first &lt;&lt; " " &lt;&lt; it-&gt;second &lt;&lt; endl;
 [Compile error - type .e to see it.]
 g++&gt; }
 bar 15
 foo 12
 g++&gt; 
</pre><p>Extra include directories can be supplied:
</p><pre> $ ./igcc -Itest/cpp -Itest/cpp2
 g++&gt; #include "hello.h"
 g++&gt; hello();
 Hello, 
 g++&gt; #include "world.h"
 g++&gt; world();
 world!
 g++&gt; 
</pre><p>Libs can be linked:
</p><pre> $ ./igcc -lm
 g++&gt; #include "math.h"
 g++&gt; cout &lt;&lt; pow( 3, 3 ) &lt;&lt; endl; // Actually a bad example since libm.a is already linked in C++
 27
 g++&gt; 
</pre><p>Your own libs can be linked too:
</p><pre> $ ./igcc -Itest/cpp -Ltest/cpp -lmylib
 g++&gt; #include "mylib.h"
 g++&gt; defined_in_cpp();
 defined_in_cpp saying hello.
 g++&gt; 
</pre><p>The <code>cstdio</code>, <code>iostream</code> and <code>string</code> headers are automatically included, and the <code>std</code> namespace is automatically in scope.
</p>
<h2>Downloading and using</h2>
<p>Download the IGCC tarball from the <a href="https://sourceforge.net/projects/igcc/files/" rel="nofollow">Sourceforge download area</a>.
</p>
<p>Untar it like so:
</p><pre> tar -xjf igcc-0.1.tar.bz2
</pre><p>And then start the program like this:
</p><pre> cd igcc-0.1
 ./igcc
</pre><p>Then type the C++ code you want to execute. It will be compiled with GCC and the results (if any) will be displayed.
</p>
<p>Type <code>.h</code> to see some (minimal) help.
</p>
<h2>Developing</h2>
<p>IGCC is a small python wrapper around GCC.
</p>
<p>Check out the code from git like this:
</p>
<pre> git clone git://igcc.git.sourceforge.net/gitroot/igcc/igcc
</pre><p>Or browse the source on <a href="http://igcc.git.sourceforge.net/git/gitweb.cgi?p=igcc/igcc;a=tree" rel="nofollow">IGCC Gitweb</a>.
</p>
<h2>Links</h2>
<ul><li><a href="http://sourceforge.net/projects/igcc/" rel="nofollow">IGCC Sourceforge page</a>
</li><li><a href="http://www.artificialworlds.net/" rel="nofollow">Andy Balaam's home page</a>
</li><li><a href="http://www.artificialworlds.net/blog" rel="nofollow">Andy Balaam's blog</a>
</li></ul><h2>Copyright</h2>
<p>IGCC is Copyright (C) 2009 Andy Balaam
</p>
<p>IGCC is Free Software released under the terms of the GNU General Public License version 2 or later.
</p>
<p>IGCC comes with NO WARRANTY.
</p>
<p>See the file <a href="http://igcc.git.sourceforge.net/git/gitweb.cgi?p=igcc/igcc;a=blob_plain;f=COPYING.txt;hb=HEAD" rel="nofollow">COPYING</a> for more information.
</p>
</div></div>]]>
            </description>
            <link>http://www.artificialworlds.net/wiki/IGCC/IGCC</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617861</guid>
            <pubDate>Mon, 28 Sep 2020 15:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C standard function 'tdelete()' has a memory bug since its inception]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24617723">thread link</a>) | @cee-studio
<br/>
September 28, 2020 | https://www.cee.studio/tdelete.html | <a href="https://web.archive.org/web/*/https://www.cee.studio/tdelete.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="markdown-content">
  
  <p><strong>tdelete()</strong>, a POSIX function included in Libc, can return dangling pointers.
      In <strong>tdelete()</strong>'s man page<sup>1</sup>, the <strong>RETURN
      VALUE</strong> specifies that "tdelete() returns a pointer to the parent of the
      item deleted, or NULL if the item was not found.".  In the
      <a href="https://github.com/cee-studio/tdelete" target="_blank">testing</a> of both musl libc and
      glibc, <strong>tdelete()</strong> returns dangling pointers. The output of the test (as seen below)
      shows that two dangling pointers are returned.

    </p><pre><code>Testing glibc's implementation of tdelete for a returning dangling address bug

  allocate 0x7fd9f70b0324
  allocate 0x7fd9f70b0388
  allocate 0x7fd9f70b03ec
  allocate 0x7fd9f70b0450
  free 0x7fd9f70b0324
  tdelete returns 0x7fd9f70b0388
  free 0x7fd9f70b0388
  tdelete returns 0x7fd9f70b03ec
  free 0x7fd9f70b03ec
  tdelete returns 0x7fd9f70b03ec &lt;- dangling pointer
  free 0x7fd9f70b0450
  tdelete returns 0x7fd9f70b0450 &lt;- dangling pointer

Testing musl libc's implementation of tdelete for a returning dangling address bug

  allocate 0x7f2ecf539324
  allocate 0x7f2ecf539388
  allocate 0x7f2ecf5393ec
  allocate 0x7f2ecf539450
  free 0x7f2ecf539324
  tdelete returns 0x7f2ecf539388
  free 0x7f2ecf539388
  tdelete returns 0x7f2ecf5393ec
  free 0x7f2ecf5393ec
  tdelete returns 0x7f2ecf5393ec &lt;- dangling pointer
  free 0x7f2ecf539450
  tdelete returns 0x7f2ecf539450 &lt;- dangling pointer
</code>
</pre>

    <p>Returning a dangling pointer is dangerous, especially for library
        functions, and dereferencing the dangling pointer can cause memory
        errors. This bug was reported by Cee.Studio when we implemented a map
        container as a thin wrapper of the <strong>tsearch()</strong> family
        functions. Here is the
        <a href="https://cee.studio/?bucket=200928-vhV&amp;name=tsearch" target="_blank">live demo</a> to see how
        the problem is reported. The following is the report:</p>
    <pre><code>    Warning: returning a dangling address.
    # The address-to-be-returned is of a memory-block (start:0x922a070, size:16 bytes) allocated at
    #    file:/tsearch.c::81, 6
    #    file:/prog.c::28, 8
    #    [libc-start-main]
    # The memory-block has been freed at
    #    file:/tdelete.c::45, 2
    #    file:/prog.c::32, 14
    #    [libc-start-main]
    # The memory-block has been freed, and its allocation location could have
    # been distorted by subsequent reuses.
    #
    # Stack trace (most recent call first)
    # [0]  file:/prog.c::32, 14
    # [1]  [libc-start-main]
    https://cee.studio/explanation
</code></pre><p>
    Even if the latest <strong>tdelete()</strong> man page<sup>2</sup> warns
    about the risk of dangling pointers, this still caught us off guard.
    Our man page does not have the warning and the page returned by Google
    does not have it. <strong>Some automatic mechanisms need to be
    employed to make sure the uses of C functions are correct.</strong></p><p>Stensal SDK re-implements C/C++ like a <strong>memory-safe</strong>
        language. It can help uncover subtle memory bugs like never before.</p>
    

</div></div>]]>
            </description>
            <link>https://www.cee.studio/tdelete.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617723</guid>
            <pubDate>Mon, 28 Sep 2020 15:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Repurposing my old Chromebook to a low power home server]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24617661">thread link</a>) | @boros2me
<br/>
September 28, 2020 | https://tamas.dev/repurpose/asus/c300/chromebook/home/server/chromeos/linux/docker/containers/2020/09/28/repurpose-chromebook-low-power-home-server.html | <a href="https://web.archive.org/web/*/https://tamas.dev/repurpose/asus/c300/chromebook/home/server/chromeos/linux/docker/containers/2020/09/28/repurpose-chromebook-low-power-home-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="cant-sell-it-repurpose-it">Can’t sell it? Repurpose it!</h2>
<p>It was around 4 years ago when I bought a used, slightly beat up Asus C300 Chromebook from a friend of mine for £50. It served me well, I installed Linux on it and used it to work on some side projects while commuting. However as time passed by, I slowly forgot about it and it ended up in a box, being put away. I always thought it’s a shame to just let it sit there, but I don’t wanted to sell it for pennies and neither I wanted to throw it out as it is a perfectly fine machine for some lightweight tasks. I always had the idea to convert it to a home server (yes, with a 7W TDP Celeron N2830 CPU), but couldn’t really find a guide online that explains how to do it and neither I had the urge to do the experimenting myself, up until now.</p>

<h2 id="the-setup">The setup</h2>

<p><a href="https://tamas.dev/static/2020-09-28/chromebook.jpg" target="_blank"><img src="https://tamas.dev/static/2020-09-28/chromebook.jpg" alt="Chromebook home server"></a></p>

<ul>
  <li>1x Asus C300 Chromebook</li>
  <li>1x 128GB USB drive</li>
  <li>1x vertical stand</li>
  <li>1x GalliumOS installed</li>
</ul>

<p>In order to run a generic home server, I knew ChromeOS will just not cut it, it has to be proper Linux. The distribution didn’t really matter as I was going to use Docker anyways (and docker-compose) to run all server applications in containers. Fortunately I already had experience installing GalliumOS, therefore it became my distribution of choice. GalliumOS is an Ubuntu based distro, specifically created to be running on ChromeOS devices. I had to update the firmware on my Chromebook (it’s a very simple, less than 10 steps process) then install the OS using a tool called chrx (another 2-3 steps). Once done, I was able to dual boot my Chromebook and got a fully operational Linux laptop.</p>

<h2 id="software-configuration">Software configuration</h2>

<p>Once I had the OS up and running, I wanted to configure it so I can use it in closed-display (clamshell) mode as leaving it running with the display open wouldn’t be too practical. I knew MacBooks had these option, but I also knew you had to have an external display and keyboard/mouse connected to it in order to make it work. Luckily with Linux, the only limit is your imagination (and your coding/Google-ing skills)! Since GalliumOS is Ubuntu based as mentioned before, I was certain there are people using Ubuntu who want their system to stay awake even after they shut the display. And I was not wrong. Simply editing <code>logind.conf</code> and turning off all power savings and auto-sleep functions through the GUI did the job.</p>

<p>The next thing I had to install was sshd, but thanks to this Reddit post I found out it was as simple as <code>apt install</code>-ing it (again, it’s basically a skinny version of Ubuntu). Left all settings to default, then I SSH-ed from another box. All went smooth, I logged in from the remote machine, started <code>htop</code> and closed the lid to see that the configuration actually works! I left the connection open for about an hour, just to be 100% sure no sleep mode will kick in, then I considered the project a success. Was much smoother than I anticipated.</p>

<h2 id="servers-n-containers">Servers ‘n containers</h2>

<p>Although I would <strong><em>not recommend</em></strong> running any production workload on a <em>Chromebook</em> via <em>Wifi</em> connection, it’ll serve perfectly fine as my home cron/CI server, especially knowing it can run on batteries for 10 hours (allegedly), without having a UPS. Following the documentation I installed Docker with no problem whatsoever and docker-compose as well. I also plugged in a tiny 128GB USB thumb drive I found laying around on my desk, as the built in eMMC is not the most spacious storage ever made. I re-formatted the drive to ext4, then mounted and finally updated Docker to use the partition on the USB device for data storage, which includes all containers, volumes, etc.
In case you’re curious, please see the list of the containerised servers I used with some explanation to the whys below.</p>

<h3 id="portainer">Portainer</h3>

<p>Website: <a href="https://www.portainer.io/">https://www.portainer.io/</a></p>

<p>Portainer provides a very user-friendly way to manage containers on remote boxes. Via a web interface, it provides information about resource utilisation, logs, etc. for each container.</p>

<h3 id="grafana--influxdb--telegraph">Grafana + InfluxDB + Telegraph</h3>
<p>Grafana website: <a href="https://grafana.com/">https://grafana.com/</a></p>

<p>InfluxDB website: <a href="https://www.influxdata.com/">https://www.influxdata.com/</a></p>

<p>Telegraf website: <a href="https://www.influxdata.com/time-series-platform/telegraf/">https://www.influxdata.com/time-series-platform/telegraf/</a></p>

<p>I use this combo to monitor average packet loss, ping, DNS query time, CPU temperature and CPU/Memory/Disk utilisation.</p>

<h3 id="jenkins-ci">Jenkins CI</h3>
<p>Website: <a href="https://www.jenkins.io/">https://www.jenkins.io/</a></p>

<p>I use Jenkins for all the cron/CI jobs I have, to build/deploy and run automated tests on some of my side projects.</p>

<h3 id="sonatype-nexus">Sonatype Nexus</h3>
<p>Website: <a href="https://www.sonatype.com/nexus/repository-oss">https://www.sonatype.com/nexus/repository-oss</a></p>

<p>To cut back on network utilisation, I’ve set Nexus up as well as a local docker/npm/pypi cache.</p>

<h3 id="future-improvements">Future improvements</h3>
<p>I’ll stop at this point as I reached my goal with this project (as always, the journey was more important than the result itself), this little device has loads of potential with it’s 2x USB ports, a full size HDMI port and even an audio jack. At the end of the day, I feel much better to put this neat little tech in use, and convinced myself I don’t need to buy <em>yet another</em> RaspberryPI for a future project that’ll never come.</p>

<hr>

<p>Resources used:</p>

<p><a href="https://uk.store.asus.com/asus-chromebook-c300ma-13-3-light-weight-laptop-intel-dual-core-2gb-32gb-emmc.html">ASUS Chromebook C300</a></p>

<p><a href="https://ark.intel.com/content/www/us/en/ark/products/81071/intel-celeron-processor-n2830-1m-cache-up-to-2-41-ghz.html">Intel Celeron N2830</a></p>

<p><a href="https://galliumos.org/">GalliumOS</a></p>

<p><a href="https://wiki.galliumos.org/Installing">Installing GalliumOS</a></p>

<p><a href="https://chrx.org/">chrx</a></p>

<p><a href="https://askubuntu.com/a/372616">How can I tell Ubuntu to do nothing when I close my laptop lid?</a></p>

<p><a href="https://www.reddit.com/r/GalliumOS/comments/5b7vwi/does_galliumos_not_come_with_ssh_abilities/d9mx0ie/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">Does GalliumOS not come with ssh abilities installed?</a></p>

<p><a href="https://stackoverflow.com/a/52018760">How to change the default location for “docker create volume” command?</a></p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://tamas.dev/repurpose/asus/c300/chromebook/home/server/chromeos/linux/docker/containers/2020/09/28/repurpose-chromebook-low-power-home-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617661</guid>
            <pubDate>Mon, 28 Sep 2020 15:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flexible Performant GEMM Kernels on GPUs in Native Julia]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24617647">thread link</a>) | @ViralBShah
<br/>
September 28, 2020 | https://juliagpu.org/2020-09-28-gemmkernels/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-09-28-gemmkernels/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        





<i data-feather="calendar"></i> <time datetime="2020-09-28">Sep 28, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Thomas Faignaert, Tim Besard, Bjorn De Sutter


<p>General Matrix Multiplication or GEMM kernels take center place in high performance
computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as
NVIDIA’s Tensor Cores. In this paper we show how it is possible to program these
accelerators from Julia, and present abstractions and interfaces that allow to do so
efficiently without sacrificing performance.</p>
<p>A pre-print of the paper has been published on arXiv:
<a href="https://arxiv.org/abs/2009.12263">arXiv:2009.12263</a>. <br> The source code can be found on
GitHub:
<a href="https://github.com/thomasfaingnaert/GemmKernels.jl">thomasfaingnaert/GemmKernels.jl</a>.</p>
<p>With the APIs from GemmKernels.jl, it is possible to instantiate GEMM kernels that perform
in the same ball park as, and sometimes even outperform state-of-the-art libraries like
CUBLAS and CUTLASS. For example, performing a mixed-precision multiplication of two 16-bit
matrixes into a 32-bit accumulator (on different combinations of layouts):</p>


<figure>
	<img src="https://juliagpu.org/2020-09-28-gemmkernels/mixed_precision.png" alt="Performance of mixed-precision GEMM">
</figure>

<p>The APIs are also highly flexible and allow customization of each step, e.g., to apply the
activation function <code>max(x, 0)</code> for implementing a rectified linear unit (ReLU):</p>
<div><pre><code data-lang="julia">a <span>=</span> CuArray(rand(<span>Float16</span>, (M, K)))
b <span>=</span> CuArray(rand(<span>Float16</span>, (K, N)))
c <span>=</span> CuArray(rand(<span>Float32</span>, (M, N)))
d <span>=</span> similar(c)

conf <span>=</span> GemmKernels<span>.</span>get_config(
    gemm_shape <span>=</span> (M <span>=</span> M, N <span>=</span> N, K <span>=</span> K),
    operator <span>=</span> Operator<span>.</span>WMMAOp{<span>16</span>, <span>16</span>, <span>16</span>},
    global_a_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float16</span>},
    global_c_layout <span>=</span> Layout<span>.</span>AlignedColMajor{<span>Float32</span>})

GemmKernels<span>.</span>matmul(
    a, b, c, d, conf;
    transform_regs_to_shared_d <span>=</span> Transform<span>.</span>Elementwise(x <span>-&gt;</span> max(x, <span>0</span>)))
</code></pre></div><p>The GemmKernels.jl framework is written entirely in Julia, demonstrating the
high-performance GPU programming capabilities of this language, but at the same time keeping
the research accessible and easy to modify or repurpose by other Julia developers.</p>



      </main>
    </div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-09-28-gemmkernels/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617647</guid>
            <pubDate>Mon, 28 Sep 2020 15:27:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Basic CQRS by refactoring a Go project]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24617237">thread link</a>) | @roblaszczak
<br/>
September 28, 2020 | https://threedots.tech/post/basic-cqrs-in-go/ | <a href="https://web.archive.org/web/*/https://threedots.tech/post/basic-cqrs-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It’s highly likely you know at least one service that:</p><ul><li>has one big, unmaintainable model that is hard to understand and change,</li><li>or where work in parallel on new features is limited,</li><li>or can’t be scaled optimally.</li></ul><p>But often, bad things come in threes. It’s not uncommon to see services with all these problems.</p><p>What is an idea that comes to mind first for solving these issues?
Let’s split it into more microservices!</p><p>Unfortunately, without proper research and planning, the situation after blindly refactoring may be actually worse than before:</p><ul><li><strong>business logic and flow may become even harder to understand</strong> – a complex logic is often easier to understand if it’s in one place,</li><li><strong>distributed transactions</strong> – things are sometimes together for a reason; a big transaction in one database is much faster and less complex than distributed transaction across multiple services,</li><li><strong>adding new changes may require extra coordination</strong>, if one of the services is owned by another team.</li></ul><p><img src="https://threedots.tech/media/introducing-cqrs/more-microservices.jpg" alt="MAKE MORE MICROSERVICES!"></p><p>Microservices are useful, but they will not solve all your issues...</p><p>To be totally clear – I’m not an enemy of microservices.
<strong>I’m just against blindly applying microservices in a way that introduces unneeded complexity and mess instead of making our lives easier.</strong></p><p>Another approach is using CQRS (Command Query Responsibility Segregation) with previously described
<a href="https://threedots.tech/post/introducing-clean-architecture/">Clean Architecture</a> and <a href="https://threedots.tech/post/ddd-lite-in-go-introduction/">DDD Lite</a>.
<strong>It can solve the mentioned problems in a much simpler way.</strong></p><h3 id="isnt-cqrs-a-complex-technique">Isn’t CQRS a complex technique?</h3><p>Isn’t CQRS one of these C#/Java/über enterprise patterns that are hard to implement, and make a big mess in the code?
A lot of books, presentations, and articles describe CQRS as a very complicated pattern.
But it is not the case.</p><p><strong>In practice, CQRS is a very simple pattern that doesn’t require a lot of investment.</strong>
<strong>It can be easily extended with more complex techniques like event-driven architecture, event-sourcing, or polyglot persistence.</strong>
But they’re not always needed.
Even without applying any extra patterns, CQRS can offer better decoupling, and code structure that is easier to understand.</p><p>When to not use CQRS in Go?
How to get all benefits from CQRS?
You can learn all that in today’s article. 😉</p><p>Like always, I will do it by refactoring <a href="https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example" target="_blank">Wild Workouts</a> application,</p><h3 id="how-to-implement-basic-cqrs-in-go">How to implement basic CQRS in Go</h3><p>CQRS (Command Query Responsibility Segregation) was initially <a href="https://cqrs.files.wordpress.com/2010/11/cqrs_documents.pdf" target="_blank">described by Greg Young</a>.
<strong>It has one simple assumption: instead of having one big model for reads and writes, you should have two separate models.
One for writes and one for reads.</strong>
It also introduces concepts of <em>command</em> and <em>query</em>, and leads to splitting application services into two separate types: command and query handlers.</p><p><img src="https://threedots.tech/media/introducing-cqrs/non-cqrs-architecture.jpg" alt="Non-CQRS architecture"></p><p>Standard, non-CQRS architecture</p><p><img src="https://threedots.tech/media/introducing-cqrs/cqrs-architecture.jpg" alt="CQRS architecture"></p><p>CQRS architecture</p><h4 id="command-vs-query">Command vs Query</h4><p>In simplest words: <strong>a Query should not modify anything, just return the data.
A command is the opposite one: it should make changes in the system, but not return any data.</strong>
Thanks to that, our queries can be cached more efficiently, and we lower the complexity of commands.</p><p>It may sound like a serious constraint, but in practice, it is not.
Most of the operations that we execute are reads or writes. Very rarely, both.</p><p>Of course, for a query, we don’t consider side effects like logs, or metrics as modifying anything.
For commands, it is also a perfectly normal thing to return an error.</p><p>How does the most basic implementation look in practice?
In the <a href="https://threedots.tech/post/introducing-clean-architecture/" target="_blank">previous article</a>,
Miłosz introduced an application service that executes application use cases.
Let’s start by cutting this service into separate command and query handlers.</p><h4 id="approvetrainingreschedule-command">ApproveTrainingReschedule command</h4><p>Previously, the training reschedule was approved from the application service <code>TrainingService</code>.</p><div><pre><code data-lang="diff"><span>- func (c TrainingService) ApproveTrainingReschedule(ctx context.Context, user auth.User, trainingUUID string) error {
</span><span>-  return c.repo.ApproveTrainingReschedule(ctx, trainingUUID, func(training Training) (Training, error) {
</span><span>-     if training.ProposedTime == nil {
</span><span>-        return Training{}, errors.New("training has no proposed time")
</span><span>-     }
</span><span>-     if training.MoveProposedBy == nil {
</span><span>-        return Training{}, errors.New("training has no MoveProposedBy")
</span><span>-     }
</span><span>-     if *training.MoveProposedBy == "trainer" &amp;&amp; training.UserUUID != user.UUID {
</span><span>-        return Training{}, errors.Errorf("user '%s' cannot approve reschedule of user '%s'", user.UUID, training.UserUUID)
</span><span>-     }
</span><span>-     if *training.MoveProposedBy == user.Role {
</span><span>-        return Training{}, errors.New("reschedule cannot be accepted by requesting person")
</span><span>-     }
</span><span>-
</span><span>-     training.Time = *training.ProposedTime
</span><span>-     training.ProposedTime = nil
</span><span>-
</span><span>-     return training, nil
</span><span>-  })
</span><span>- }
</span></code></pre></div><p>There were some magic validations there.
They are now done in the domain layer.
I also found out that we forgot to call the external <code>trainer</code> service to move the training. Oops. 😉
Let’s refactor it to the CQRS approach.</p><p>We start the implementation of a <em>command</em> with the command structure definition.
That structure provides all data needed to execute this command.
If a command has only one field, you can skip the structure and just pass it as a parameter.</p><p>It’s a good idea to use types defined by domain in the command, like <code>training.User</code> in that case.
We don’t need to do any casting later, and we have type safety assured.
<strong>It can save us a lot of issues with string parameters passed in wrong order.</strong></p><div><pre><code data-lang="go"><span>package</span> <span>command</span>

<span>// ...
</span><span></span>
<span>type</span> <span>ApproveTrainingReschedule</span> <span>struct</span> {
   <span>TrainingUUID</span> <span>string</span>
   <span>User</span>         <span>training</span>.<span>User</span>
}
</code></pre></div><p>The second part is a <em>command handler</em> that knows how to execute the command.</p><div><pre><code data-lang="go"><span>package</span> <span>command</span>

<span>// ...
</span><span></span>
<span>type</span> <span>ApproveTrainingRescheduleHandler</span> <span>struct</span> {
   <span>repo</span>           <span>training</span>.<span>Repository</span>
   <span>userService</span>    <span>UserService</span>
   <span>trainerService</span> <span>TrainerService</span>
}

<span>// ...
</span><span></span>
<span>func</span> (<span>h</span> <span>ApproveTrainingRescheduleHandler</span>) <span>Handle</span>(<span>ctx</span> <span>context</span>.<span>Context</span>, <span>cmd</span> <span>ApproveTrainingReschedule</span>) (<span>err</span> <span>error</span>) {
	<span>defer</span> <span>func</span>() {
		<span>logs</span>.<span>LogCommandExecution</span>(<span>"ApproveTrainingReschedule"</span>, <span>cmd</span>, <span>err</span>)
	}()

	<span>return</span> <span>h</span>.<span>repo</span>.<span>UpdateTraining</span>(
		<span>ctx</span>,
		<span>cmd</span>.<span>TrainingUUID</span>,
		<span>cmd</span>.<span>User</span>,
		<span>func</span>(<span>ctx</span> <span>context</span>.<span>Context</span>, <span>tr</span> <span>*</span><span>training</span>.<span>Training</span>) (<span>*</span><span>training</span>.<span>Training</span>, <span>error</span>) {
			<span>originalTrainingTime</span> <span>:=</span> <span>tr</span>.<span>Time</span>()

			<span>if</span> <span>err</span> <span>:=</span> <span>tr</span>.<span>ApproveReschedule</span>(<span>cmd</span>.<span>User</span>.<span>Type</span>()); <span>err</span> <span>!=</span> <span>nil</span> {
				<span>return</span> <span>nil</span>, <span>err</span>
			}

			<span>err</span> <span>:=</span> <span>h</span>.<span>trainerService</span>.<span>MoveTraining</span>(<span>ctx</span>, <span>tr</span>.<span>Time</span>(), <span>originalTrainingTime</span>)
			<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
				<span>return</span> <span>nil</span>, <span>err</span>
			}

			<span>return</span> <span>tr</span>, <span>nil</span>
		},
	)
}
</code></pre></div><p>The flow is much easier to understand now.
You can clearly see that we approve a reschedule of a persisted <code>*training.Training</code>, and if it succeeds, we call the external <code>trainer</code> service.
Thanks to techniques described in the <a href="https://threedots.tech/post/ddd-lite-in-go-introduction/">DDD Lite article</a>, the command handler doesn’t need to know when it can perform this operation.
It’s all handled by our domain layer.</p><p>This clear flow is even more visible in more complex commands.
Fortunately, the current implementation is really straightforward.
That’s good.
<strong>Our goal is not to create complicated, but simple software.</strong></p><p>If CQRS is the standard way of building applications in your team, it also speeds up learning the service by your teammates who don’t know it.
You just need a list of available commands and queries, and to quickly take a look at how their execution works.
Jumping like crazy through random places in code is not needed.</p><p>This is how it looks like in one of my team’s most complex services:</p><p><img src="https://threedots.tech/media/introducing-cqrs/complex-command.jpg" alt="Example commands list of a complex application"></p><p>Example application layer of one service at <a href="https://www.karhoo.com/" rel="noreferrer" target="_blank">Karhoo</a>.</p><p>You may ask - shouldn’t it be cut to multiple services?
<strong>In practice, it would be a terrible idea.</strong> A lot of operations here need to be transitionally consistent.
Splitting it to separate services would involve a couple of distributed transactions (<em>Sagas</em>).
It would make this flow much more complex, harder to maintain, and debug.
It’s not the best deal.</p><p>It’s also worth mentioning that all of these operations are not very complex.
<strong>Complexity is scaling horizontally excellently here.</strong>
We will cover the extremely important topic of splitting microservices more in-depth soon.
Did I already mention that we messed it up in Wild Workouts on purpose? 😉</p><p>But let’s go back to our command. It’s time to use it in our HTTP port.
It’s available in <code>HttpServer</code> via injected <code>Application</code> structure, which contains all of our commands and queries handlers.</p><div><pre><code data-lang="go"><span>package</span> <span>app</span>

<span>import</span> (
   <span>"github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/internal/trainings/app/command"</span>
   <span>"github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/internal/trainings/app/query"</span>
)

<span>type</span> <span>Application</span> <span>struct</span> {
   <span>Commands</span> <span>Commands</span>
   <span>Queries</span>  <span>Queries</span>
}

<span>type</span> <span>Commands</span> <span>struct</span> {
   <span>ApproveTrainingReschedule</span> <span>command</span>.<span>ApproveTrainingRescheduleHandler</span>
   <span>CancelTraining</span>            <span>command</span>.<span>CancelTrainingHandler</span>
   <span>// ...
</span></code></pre></div><div><pre><code data-lang="go"><span>type</span> <span>HttpServer</span> <span>struct</span> {
   <span>app</span> <span>app</span>.<span>Application</span>
}

<span>// ...
</span><span></span>
<span>func</span> (<span>h</span> <span>HttpServer</span>) <span>ApproveRescheduleTraining</span>(<span>w</span> <span>http</span>.<span>ResponseWriter</span>, <span>r</span> <span>*</span><span>http</span>.<span>Request</span>) {
   <span>trainingUUID</span> <span>:=</span> <span>chi</span>.<span>URLParam</span>(<span>r</span>, <span>"trainingUUID"</span>)

   <span>user</span>, <span>err</span> <span>:=</span> <span>newDomainUserFromAuthUser</span>(<span>r</span>.<span>Context</span>())
   <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
      <span>httperr</span>.<span>RespondWithSlugError</span>(<span>err</span>, <span>w</span>, <span>r</span>)
      <span>return</span>
   }

   <span>err</span> = <span>h</span>.<span>app</span>.<span>Commands</span>.<span>ApproveTrainingReschedule</span>.<span>Handle</span>(<span>r</span>.<span>Context</span>(), <span>command</span>.<span>ApproveTrainingReschedule</span>{
      <span>User</span>:         <span>user</span>,
      <span>TrainingUUID</span>: <span>trainingUUID</span>,
   })
   <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
      <span>httperr</span>.<span>RespondWithSlugError</span>(<span>err</span>, <span>w</span>, <span>r</span>)
      <span>return</span>
   }
}
</code></pre></div><p>The command handler can be called in that way from any port: HTTP, gRPC, or CLI.
It’s also useful for executing migrations and <a href="https://github.com/ThreeDotsLabs/wild-workouts-go-ddd-example/blob/22c0a25b67c4669d612a2fa4a434ffae8e35e65a/internal/trainer/fixtures.go#L62" target="_blank">loading fixtures</a> (we already do it in Wild Workouts).</p><h4 id="requesttrainingreschedule-command">RequestTrainingReschedule command</h4><p>Some command handlers can be very simple.</p><div><pre><code data-lang="go"><span>func</span> (<span>h</span> <span>RequestTrainingRescheduleHandler</span>) <span>Handle</span>(<span>ctx</span> <span>context</span>.<span>Context</span>, <span>cmd</span> <span>RequestTrainingReschedule</span>) (<span>err</span> <span>error</span>) {
	<span>defer</span> <span>func</span>() {
		<span>logs</span>.<span>LogCommandExecution</span>(<span>"RequestTrainingReschedule"</span>, <span>cmd</span>, <span>err</span>)
	}()

	<span>return</span> <span>h</span>.<span>repo</span>.<span>UpdateTraining</span>(
		<span>ctx</span>,
		<span>cmd</span>.<span>TrainingUUID</span>,
		<span>cmd</span>.<span>User</span>,
		<span>func</span>(<span>ctx</span> <span>context</span>.<span>Context</span>, <span>tr</span> <span>*</span><span>training</span>.<span>Training</span>) (<span>*</span><span>training</span>.<span>Training</span>, <span>error</span>) {
			<span>if</span> <span>err</span> <span>:=</span> <span>tr</span>.<span>UpdateNotes</span>(<span>cmd</span>.<span>NewNotes</span>); <span>err</span> <span>!=</span> <span>nil</span> {
				<span>return</span> <span>nil</span>, <span>err</span>
			}

			<span>tr</span>.<span>ProposeReschedule</span>(<span>cmd</span>.<span>NewTime</span>, <span>cmd</span>.<span>User</span>.<span>Type</span>())

			<span>return</span> <span>tr</span>, <span>nil</span>
		},
	)
}
</code></pre></div><p>It may be tempting to skip this layer …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://threedots.tech/post/basic-cqrs-in-go/">https://threedots.tech/post/basic-cqrs-in-go/</a></em></p>]]>
            </description>
            <link>https://threedots.tech/post/basic-cqrs-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617237</guid>
            <pubDate>Mon, 28 Sep 2020 14:51:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why don't aid agencies like to hire local talent?]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24617019">thread link</a>) | @filleduchaos
<br/>
September 28, 2020 | https://karmacolonialism.org/why-dont-aid-agencies-like-to-hire-local-talent/ | <a href="https://web.archive.org/web/*/https://karmacolonialism.org/why-dont-aid-agencies-like-to-hire-local-talent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/karmacolonialism.org\/why-dont-aid-agencies-like-to-hire-local-talent\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/karmacolonialism.org\/why-dont-aid-agencies-like-to-hire-local-talent\/&quot;}">
<p>When UNICEF needed photos from Bolivia, India, Jordan, Malawi, Myanmar and Niger to illustrate their clean-water campaign, did they hire local photographers in each of those countries?</p>



<p>No, they engaged an Australian man living in New York.</p>



<p>The photographer they chose was the award-winning Ashley Gilbertson, at VII Photo Agency, who produced good work for their “<a href="https://www.independent.co.uk/life-style/health-and-families/features/unicef-wateris-ashley-gilbertson-s-photo-essay-reveals-lengths-families-have-go-access-clean-water-a6715511.html">#Wateris: a family affair</a>” campaign. In my opinion, however, that’s no excuse for UNICEF hiring him rather than local photographers in each country.</p>



<p>But that’s how most Western aid agencies work. Three years later, UNICEF published “Crisis in the Central African Republic” (shown at top). Every single photo is tagged “Gilbertson VII Photo”.</p>



<figure><img data-attachment-id="4186" data-permalink="https://karmacolonialism.org/why-dont-aid-agencies-like-to-hire-local-talent/local-talent-v02/" data-orig-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?fit=1900%2C675&amp;ssl=1" data-orig-size="1900,675" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Local talent v02" data-image-description="" data-medium-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?fit=300%2C107&amp;ssl=1" data-large-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?fit=584%2C208&amp;ssl=1" loading="lazy" width="584" height="208" src="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=584%2C208&amp;ssl=1" alt="" srcset="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=1024%2C364&amp;ssl=1 1024w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=300%2C107&amp;ssl=1 300w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=768%2C273&amp;ssl=1 768w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=1536%2C546&amp;ssl=1 1536w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=1200%2C426&amp;ssl=1 1200w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=500%2C178&amp;ssl=1 500w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?w=1900&amp;ssl=1 1900w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?w=1752&amp;ssl=1 1752w" sizes="(max-width: 584px) 100vw, 584px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=1024%2C364&amp;ssl=1 1024w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=300%2C107&amp;ssl=1 300w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=768%2C273&amp;ssl=1 768w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=1536%2C546&amp;ssl=1 1536w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=1200%2C426&amp;ssl=1 1200w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=500%2C178&amp;ssl=1 500w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?w=1900&amp;ssl=1 1900w, https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?w=1752&amp;ssl=1 1752w" data-lazy-src="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/09/Local-talent-v02.jpg?resize=584%2C208&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Five reports from U.N. agencies and Western NGOs show life in the global South. Why don’t they use photographers who live there?</figcaption></figure>



<p>It’s not just UNICEF. The strip aboveshows reports published (often jointly) by World Vision, Save the Children, Plan International, ChildFund, and W.H.O., as well as UNICEF. The first report is titled<em> Progress on household drinking water, sanitation and hygiene 2000-2017; Special focus on inequalities.</em> It was published by UNICEF and the World Health Organization. The cover photograph is by an Italian man.</p>



<p>In these five reports, U.N. agencies and international NGOs tell how they help people in Africa, Asia and the Middle East. But the cover photos (and often most or all of the photos inside) were taken by Americans and Western Europeans.</p>



<p>If these organizations are concerned about inequalities, why don’t they make it a policy to always hire local talent in the countries they wish to help?</p>



<p>It seems like a no-brainer. Hiring local photographers would provide jobs where jobs are needed. It would help people in the global South to build their resumes and develop stronger skills. It would reward those who have invested in doing so. It would mean that aid money which is supposed to help these countries, would actually go <em>into </em>them without immediately bouncing back out. It would show respect for the local people, rather than treating them merely as a population in need of help.</p>



<p>Aid agencies typically hire local staff only for low- and mid-level positions. That’s an important story, but a different one. Here, I’m asking: Why do they so often pass up local talent when they need video work, graphic designers, and photographers, in favor of Westerners?</p>



<p>For some jobs, such as a big video project, they may argue that the skills needed aren’t available locally. Given the poor state of public education in most of these countries – much of which is a result of policies pushed by the U.N. – there may be some validity to this. But freezing out locals is not going to improve the situation, it simply creates greater inequality. At the very least, these agencies should insist on local involvement as much as possible. They do not.</p>



<p>In the case of photography, there’s simply no good excuse. Every country has photographers able to produce excellent work… and they’ll charge less than a globe-trotting Westerner. Why does the aid industry give so many assignments — especially the bigger ones with higher pay and travel opportunities and which are crucial for building up resumes — to Westerners?</p>



<p>Several factors are clearly at work.</p>



<p>First, it’s easier. Aid workers usually only stay in a country for one or two years. They socialize with other ex-pats, who often make a comfortable living by providing free-lance services to NGOs. Nurturing these connections comes naturally, and will benefit everybody’s career and social life.</p>



<p>Furthermore, the aid industry comes with an Us-and-Them mindset. <em><strong>We </strong></em>are the ones with answers, and we’re paid to help. <em><strong>They </strong></em>are the ones who need our help; they’ll be the subject of our photos. In this ethos, Westerners are the first people considered for any skilled job.</p>



<p>And there is a bias, whatever you wish to call it. The Western aid worker is more comfortable working with other Westerners. There are cultural, and often language, differences if you work with local talent. Aid workers may, without even consciously thinking about it, assume that people like themselves will do a better job.</p>



<p>But while we might understand all this, that doesn’t excuse it. Karma colonialism is the nicest term we can think of for this behavior.</p>



<h2>Twitter comments</h2>



<p><em>The tweet which announced this story has generated some lively commentary. Here are highlights.</em></p>



<p><strong>Taremwa karakire, @TaremwaD:</strong> I relate to this story. I was once part of a USAID project in Uganda where they always hired photographers all the way from USA to come and document the project.</p>



<p><strong>Learning counsel, @Its_Kimani: </strong>The writer dares not say the reasons as: (1) Perpetuating the White saviour complex; (2) Reinforcement of racist stereotypes by having people not tell their own story.<br>[<em>Author replies:</em> I decided it was more effective to let readers draw their own conclusions on this. I don’t know if that makes me a coward, or a diplomat. You, sir, are neither. Thanks for commenting.]</p>



<p><strong>RazorRibbon, @SpacemanAp:</strong> Because their photographer will capture Africa in the worse light possible and keep perpetuating the image of Africa they want the world to see and believe as per their real mission.<br>[<em>Author replies:</em> This is an important dynamic, and I missed it in the story. Several readers made similar comments, such as the next couple. Thank you, all.]</p>



<p><strong>Mana, @Jun1orm: </strong>A local photographer will do his best to make his community show the best it has to offer while a foreign one will do exactly what they want.</p>



<p><strong>iNk, @nwaoma007:</strong> The Australian man knows that his brief is to tell a specific facet of the story which promotes the narrative UNICEF wants to disseminate.</p>



<p><strong>Khanyi, @choolwekm:</strong> It seems to me they want to maintain the status quo to remain relevant.</p>



<p><strong>Sunflower, @TalelovesSuga:</strong> This is why I don’t like it when a white person points a camera at me… You can find yourself on a UNICEF poster.</p>



<p><strong>Ruby, @Oghenerume9:</strong> I had always known this in my heart but it was confirmed when I was working for one NGO and actually saw with my eyes that it was all fraud. Life has been worse for the poor in developing countries since more and more NGO’s came around</p>



<p><strong>O&amp;B, @The44Families: </strong>This is business people. You really believe UNICEF and Co want equality and self sufficiency in Africa, Asia, and Latin America?<br>Say they succeed is their purported goals, what then will be the reason(s) to keep them around?<br>They need the needy to be relevant</p>



<p><strong>Takor, @Takor61802157:</strong> Foreign bodies talk negative things about third world countries, they don’t take photos of the good things in third world countries only negative ones.</p>



<p><strong>david pearce, @davidpe11188501: </strong>A local head of UNRWA [United Nations Relief and Works Agency for Palestine Refugees in the Near East] told me that the children learn to cry on command for foreign visitors, esp photographers. Otherwise, the children look and act quite normally. They need crying children to sell their product.<br>[<em>Author adds:</em> In her book <em>The Crisis Caravan,</em> Dutch journalist Linda Polman records many stories of the quest for heart-rending photos. Of a camp for amputees in Sierra Leone, she writes: “Like pit bulls in a kindergarten, journalists from all over the world pounced on the story of the amputees. From CNN and the New York Times to Dutch public television and the South China Morning Post, they all managed to find Murray Town Camp. ‘It’s never been so easy to collect money as it is with the pictures of these poor devils,’ said an INGO staff member in Freetown.”]</p>



<p><strong>Faye Pixie, @PixieFaye:</strong> The Us and Them thing is so true. Even if some of these organizations are trying to be benign, they’re still being colonialists about our countries. Photography is inherently biased as you choose what you want to photograph to “spread awareness”.</p>



<p><strong>Benson Ndehi, @BNdehi: </strong>I once had a small gig with UNICEF in Nairobi. The waste was unbelievable. Everyone had a network printer, for example.<br>[<em>Author adds:</em> In his book<em> Another Quiet American,</em> Brett Dakin tells of when he was working in a government tourism office that got support from the U.N. Development Programme. One day the UNDP sent them a new printer, which could do everything: Print in color, collate, and bind. They had never asked for it, didn’t need it, and never figured out how to use it, so it sat unused. He writes, “The UNDP had simply decided to dump a few thousand dollars of gear on the NTA. Whether or not it would be of use was immaterial.”</p>



<h2>Related stories</h2>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/karmacolonialism.org\/why-dont-aid-agencies-like-to-hire-local-talent\/&quot;}"><li><figure><img data-attachment-id="2997" data-permalink="https://karmacolonialism.org/blog/shadow-ghostwriters-p-272-v02-thumb/" data-orig-file="https://i2.wp.com/karmacolonialism.org/wp-content/uploads/2020/05/shadow-ghostwriters-p-272-v02-thumb.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="shadow ghostwriters -p-272- v02 thumb" data-image-description="" data-medium-file="https://i2.wp.com/karmacolonialism.org/wp-content/uploads/2020/05/shadow-ghostwriters-p-272-v02-thumb.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/karmacolonialism.org/wp-content/uploads/2020/05/shadow-ghostwriters-p-272-v02-thumb.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/05/shadow-ghostwriters-p-272-v02-thumb.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2997" data-full-url="https://karmacolonialism.files.wordpress.com/2020/05/shadow-ghostwriters-p-272-v02-thumb.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/05/shadow-ghostwriters-p-272-v02-thumb.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="2824" data-permalink="https://karmacolonialism.org/why-does-the-aid-industry-resist-cash-transfers/cash-assistance-refugees-p-264-275x200/" data-orig-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/05/cash-assistance-refugees-p-264-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="cash assistance refugees -p-264- 275×200" data-image-description="" data-medium-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/05/cash-assistance-refugees-p-264-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/05/cash-assistance-refugees-p-264-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/05/cash-assistance-refugees-p-264-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2824" data-full-url="https://karmacolonialism.files.wordpress.com/2020/05/cash-assistance-refugees-p-264-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/05/cash-assistance-refugees-p-264-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption><strong>Left:</strong> <a href="https://karmacolonialism.org/the-shadow-government/">The Shadow Government.</a> UNICEF produces reports — not always good ones! — for weak governments to publish as their own. This ends up being even worse than it sounds.<br><strong>Right:</strong> <a href="https://karmacolonialism.org/cash-transfers-an-alternative-approach-to-aid/">Cash transfers.</a> Why not just give aid funds directly to the people you want to help? This approach has been done, results have been studied — and it proves quite effective.</figcaption></figure>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/karmacolonialism.org\/why-dont-aid-agencies-like-to-hire-local-talent\/&quot;}"><li><figure><img data-attachment-id="2213" data-permalink="https://karmacolonialism.org/dumping-on-the-global-south-and-getting-paid-for-it/100818-n-7241l-026-5/" data-orig-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/seabees-djibouti-p-5-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;11&quot;,&quot;credit&quot;:&quot;U.S. Navy&quot;,&quot;camera&quot;:&quot;NIKON D3&quot;,&quot;caption&quot;:&quot;100818-N-7241L-026\rDJIBOUTI (Aug. 18, 2010) Seabees assigned to Naval Mobile Construction Battalion (NMCB) 7, Combined Joint Task Force-Horn of Africa Detachment, prepare concrete forms at Ecole 5, a five-room school under construction near Camp Lemonnier. (U.S. Navy photo by Mass Communication Specialist 2nd Class Nathan Laird\/Released)&quot;,&quot;created_timestamp&quot;:&quot;1282156815&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;14&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.002&quot;,&quot;title&quot;:&quot;100818-N-7241L-026&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="100818-N-7241L-026" data-image-description="" data-medium-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/seabees-djibouti-p-5-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/seabees-djibouti-p-5-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/04/seabees-djibouti-p-5-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2213" data-full-url="https://karmacolonialism.files.wordpress.com/2020/04/seabees-djibouti-p-5-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/04/seabees-djibouti-p-5-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="2207" data-permalink="https://karmacolonialism.org/dumping-on-the-global-south-and-getting-paid-for-it/needy-children-p-22-275x200-2/" data-orig-file="https://i2.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/needy-children-p-22-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="needy children -p-22- 275×200" data-image-description="" data-medium-file="https://i2.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/needy-children-p-22-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i2.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/needy-children-p-22-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/04/needy-children-p-22-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2207" data-full-url="https://karmacolonialism.files.wordpress.com/2020/04/needy-children-p-22-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/04/needy-children-p-22-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption><strong>Left:</strong> <a href="https://karmacolonialism.org/pygmalion-and-golem-poor-expectations-get-poor-results/">Pygmalion and Golem.</a> U.S. Navy crew builds a school in Djibouti. That seems nice. But it sends a deeply harmful message: “You can’t do anything without our help.”<br><strong>Right:</strong> <a href="https://karmacolonialism.org/unicef-needs-the-needy/">Unicef needs the “needy.”</a> This photo is from a Unicef fundraising appeal for “needy families.” It is the very opposite of the “empowerment” that they talk about.</figcaption></figure>



<h2>Other stories of interest</h2>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/karmacolonialism.org\/why-dont-aid-agencies-like-to-hire-local-talent\/&quot;}"><li><figure><img data-attachment-id="2206" data-permalink="https://karmacolonialism.org/dumping-on-the-global-south-and-getting-paid-for-it/pope-francis-p-170-275x200-2/" data-orig-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/pope-francis-p-170-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pope francis -p-170- 275×200" data-image-description="" data-medium-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/pope-francis-p-170-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/pope-francis-p-170-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/04/pope-francis-p-170-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2206" data-full-url="https://karmacolonialism.files.wordpress.com/2020/04/pope-francis-p-170-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/04/pope-francis-p-170-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="2211" data-permalink="https://karmacolonialism.org/dumping-on-the-global-south-and-getting-paid-for-it/superbowl-shirts-p-4-275x200-2/" data-orig-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/superbowl-shirts-p-4-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="superbowl shirts -p-4- 275×200" data-image-description="" data-medium-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/superbowl-shirts-p-4-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/superbowl-shirts-p-4-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/04/superbowl-shirts-p-4-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2211" data-full-url="https://karmacolonialism.files.wordpress.com/2020/04/superbowl-shirts-p-4-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/04/superbowl-shirts-p-4-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption><strong>Left:</strong> <a href="https://karmacolonialism.org/who-says-its-colonialism/">The new colonialism.</a> Is the West really trying to impose a new form of colonialism? Many people have made the suggestion. Pope Francis, for example.<br><strong>Right:</strong> <a href="https://karmacolonialism.org/world-vision-passes-out-losing-team-tshirts/">World Vision</a> undermines local economies by giving away leftover merchandise where it’s not needed. It makes no sense — until you understand the financial incentives.</figcaption></figure>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/karmacolonialism.org\/why-dont-aid-agencies-like-to-hire-local-talent\/&quot;}"><li><figure><img data-attachment-id="2482" data-permalink="https://karmacolonialism.org/unesco-nokia-report-p-245-275x200/" data-orig-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/unesco-nokia-report-p-245-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="unesco nokia report -p-245- 275×200" data-image-description="" data-medium-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/unesco-nokia-report-p-245-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i0.wp.com/karmacolonialism.org/wp-content/uploads/2020/04/unesco-nokia-report-p-245-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/04/unesco-nokia-report-p-245-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="2482" data-full-url="https://karmacolonialism.files.wordpress.com/2020/04/unesco-nokia-report-p-245-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/04/unesco-nokia-report-p-245-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="3113" data-permalink="https://karmacolonialism.org/timor-where-did-all-the-aid-go/crystalball-seascape-p-208-275x200/" data-orig-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/06/crystalball-seascape-p-208-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-orig-size="275,200" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="crystalball seascape -p-208- 275×200" data-image-description="" data-medium-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/06/crystalball-seascape-p-208-275x200-1.jpg?fit=275%2C200&amp;ssl=1" data-large-file="https://i1.wp.com/karmacolonialism.org/wp-content/uploads/2020/06/crystalball-seascape-p-208-275x200-1.jpg?fit=275%2C200&amp;ssl=1" loading="lazy" width="275" height="200" src="https://karmacolonialism.files.wordpress.com/2020/06/crystalball-seascape-p-208-275x200-1.jpg?w=275&amp;resize=275%2C200" alt="" data-id="3113" data-full-url="https://karmacolonialism.files.wordpress.com/2020/06/crystalball-seascape-p-208-275x200-1.jpg" data-recalc-dims="1" data-lazy-src="https://karmacolonialism.files.wordpress.com/2020/06/crystalball-seascape-p-208-275x200-1.jpg?w=275&amp;is-pending-load=1#038;resize=275%2C200" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption><strong>Left:</strong> <a href="https://karmacolonialism.org/unesco-sells-its-brand-nokia-buys/">Cellphones and literacy.</a> UNESCO took money from big tech to publish a deceitful report that benefited the company that gave it the money. If an African president had done that, what would we call it?<br><strong>Right:</strong> <a href="https://karmacolonialism.org/better-ways-to-help/">What would make a better future?</a> There are ways that wealthier countries can genuinely help others, if they want to. Give the aid money …</figcaption></figure></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karmacolonialism.org/why-dont-aid-agencies-like-to-hire-local-talent/">https://karmacolonialism.org/why-dont-aid-agencies-like-to-hire-local-talent/</a></em></p>]]>
            </description>
            <link>https://karmacolonialism.org/why-dont-aid-agencies-like-to-hire-local-talent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24617019</guid>
            <pubDate>Mon, 28 Sep 2020 14:35:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2 Months of Daily Blogging]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24616932">thread link</a>) | @mcrittenden
<br/>
September 28, 2020 | https://critter.blog/2020/09/28/2-months-of-daily-blogging/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/09/28/2-months-of-daily-blogging/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-1598">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>For the past 8 weeks, I’ve posted to this blog every weekday. That’s 40 posts and counting. </p>



<figure><img data-attachment-id="1601" data-permalink="https://critter.blog/image-4-3/" data-orig-file="https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png" data-orig-size="787,234" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-4" data-image-description="" data-medium-file="https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png?w=300" data-large-file="https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png?w=580" src="https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png?w=787" alt="" srcset="https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png 787w, https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png?w=150 150w, https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png?w=300 300w, https://mikecrittendenhome.files.wordpress.com/2020/09/image-4.png?w=768 768w" sizes="(max-width: 787px) 100vw, 787px"></figure>



<p>It started as a personal experiment (because <a href="https://critter.blog/2020/09/21/experimenting-on-myself/">personal experiments are my new thing</a>):</p>



<figure><div>
<div><blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Inspired by Seth Godin, I'm gonna do an experiment for the month of August where I wrote a blog post every weekday. We'll see how much I hate this by the end.</p>— Mike Crittenden (@mcrittenden) <a href="https://twitter.com/mcrittenden/status/1290647256576729092?ref_src=twsrc%5Etfw">August 4, 2020</a></blockquote></div>
</div></figure>



<p>By the time August was up, I was having too much fun to stop.</p>



<hr>



<p>Here are a few of my original misconceptions:</p>



<p>“<em>I won’t be able to think of that many topics!</em>” Turns out, the more I write, the easier it is to think of more things to write about. My ideas list is growing faster than my published list. </p>



<p>“<em>It’ll start to feel like a chore.</em>” I’m not saying this will never happen, but it hasn’t happened yet. I still look forward to it every day. </p>



<p>“<em>It will take a lot of time, and some days I’ll be too busy.” </em>I got around this by telling myself that it’s fine if some posts are only a paragraph or two. My rule of thumb is “anything longer than a Tweet is long enough for a blog post.” Everyone should write more, <a href="https://mementomori.bearblog.dev/shorter/">shorter blog posts</a>.</p>



<p>“<em>Nobody will read it.” </em>First of all, I was wrong. I got a lot more traffic than I expected (see the stats at the bottom). But it didn’t matter anyway, because traffic is irrelevant. Writing without an audience is better than not writing, which brings me to:</p>



<p><i>“</i><em>Writing won’t benefit me much.” </em>Oh, past Critter, you sweet little idiot. Writing daily has helped me in two major ways:</p>



<p><strong>#1: I don’t know what I think about something until I start writing about it</strong>. I make connections and discover opinions I didn’t know existed in my brain. Yeah I know, “everyone knows that writing helps you think.” But experiencing it firsthand has been bizarre and fantastic.</p>



<p><strong>#2: It’s helpful to have a blog post handy when I get into a discussion with someone</strong>. Instead of summarizing my thoughts over and over again to different people, I can shoot them a link. <em>Beware, it’s tricky to do this without sounding like a know-it-all jerk</em>. But in the right context and with the right tone, it can work and save everyone a lot of time.</p>



<hr>



<p>Finally, some stats for those 8 weeks, if you’re curious:</p>



<ul><li>Total views: 67,198</li><li>Total visitors: 49,560</li><li>Most popular post: <a href="https://critter.blog/2020/08/11/that-coworker-who-never-stops-refactoring/">That coworker who never stops&nbsp;refactoring</a> (23,370 views)</li><li>2nd most popular post: <a href="https://critter.blog/2020/08/10/wiki-bankruptcy/">Wiki bankruptcy</a> (17,852 views)</li><li>Biggest referrer: Hacker News (responsible for 31,023 views)</li></ul>



<p>The <a href="https://en.wikipedia.org/wiki/Pareto_principle">Pareto Principle</a> (i.e., the 80/20 rule) is popping up here. Out of those 40 posts, the top 2 brought in almost 2/3 of the views. In fact, the top 8 posts (i.e., the top 20%) accounted for 85% of the views. So instead of 80/20 it’s <strong>85/20</strong> so far!</p>



<p>Another example: Hacker News gave me almost half of my traffic.</p>



<hr>



<p>I plan to keep the streak going as long as possible. Seth Goden says <a href="https://seths.blog/2018/10/the-first-1000-are-the-most-difficult/">the first 1000 are the most difficult</a>, and I’d like to see if that’s true.</p>



<p>If you’ve made it this far, <strong>I challenge you to write every day for just one week</strong>. If you want to stop at the end of the week, then stop. But if not, keep going and see where it takes you. </p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/09/28/2-months-of-daily-blogging/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24616932</guid>
            <pubDate>Mon, 28 Sep 2020 14:27:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The failed promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24616859">thread link</a>) | @flipchart
<br/>
September 28, 2020 | https://lea.verou.me/2020/09/the-failed-promise-of-web-components/ | <a href="https://web.archive.org/web/*/https://lea.verou.me/2020/09/the-failed-promise-of-web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Web Components had so much potential to empower HTML to do more, and make web development more accessible to non-programmers and easier for programmers. Remember how exciting it was every time we got new shiny HTML elements that actually <em>do stuff</em>? Remember how exciting it was to be able to do sliders, color pickers, dialogs, disclosure widgets straight in the HTML, without having to include any widget libraries?</p>



<p>The promise of Web Components was that we’d get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We’d just include a script, and boom, we have more elements at our disposal!</p>



<p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p>



<figure><img src="https://live.staticflickr.com/2025/32441377780_e3acf6de12_b.jpg" alt=""><figcaption>This is what the roots of a Banyan tree look like. <a href="https://www.flickr.com/photos/79721788@N00/32441377780/">Photo by David Stanley on Flickr (CC-BY)</a>. </figcaption></figure>



<p>Perusing the components on <a href="https://www.webcomponents.org/">webcomponents.org</a> fills me with anxiety, and I’m perfectly comfortable writing JS — I write JS for a living! What hope do those who can’t write JS have? Using a custom element from the directory often needs to be preceded by a ritual of npm flugelhorn, import clownshoes, build quux, all completely unapologetically because “here is my truckload of dependencies, yeah, what”. Many steps are even omitted, likely because they are “obvious”. Often, you wade through the maze only to find the component doesn’t work anymore, or is not fit for your purpose.</p>



<p>Besides setup, the main problem is that HTML is not treated with the appropriate respect in the design of these components. They are not designed as closely as possible to standard HTML elements, but <em>expect</em> JS to be written for them to do anything. HTML is simply treated as a shorthand, or worse, as merely a marker to indicate where the element goes in the DOM, with all parameters passed in via JS. I recall <a href="https://adactio.com/articles/12839#webcomponents">a wonderful talk by Jeremy Keith</a> a few years ago about this very phenomenon, where he discussed <a href="https://shop.polymer-project.org/">this e-shop Web components demo by Google</a>, which is the poster child of this practice. These are the entire contents of its <code>&lt;body&gt;</code> element:</p>



<pre><code>&lt;body&gt;
	&lt;shop-app unresolved=""&gt;SHOP&lt;/shop-app&gt;
	&lt;script src="node_assets/@webcomponents/webcomponentsjs/webcomponents-loader.js"&gt;&lt;/script&gt;
	&lt;script type="module" src="src/shop-app.js"&gt;&lt;/script&gt;
	&lt;script&gt;window.performance&amp;&amp;performance.mark&amp;&amp;performance.mark("index.html");&lt;/script&gt;
&lt;/body&gt;</code></pre>



<p>If this is how Google is leading the way, how can we hope for contributors to design components that follow established HTML conventions?</p>



<p>Jeremy criticized this practice from the aspect of backwards compatibility: when JS is broken or not enabled, or the browser doesn’t support Web Components, the entire website is blank. While this is indeed a serious concern, my primary concern is one of <strong>usability</strong>: <strong>HTML is a lower barrier to entry language</strong>. Far more people can write HTML than JS. Even for those who do eventually write JS, it often comes after spending years writing HTML &amp; CSS.</p>



<p>If components are designed in a way that requires  JS, this excludes thousands of people from using them. And even for those who <em>can</em> write JS, HTML is often easier: you don’t see many people rolling their own sliders or using JS-based ones once <code>&lt;input type="range"&gt;</code> became widely supported, right?</p>



<p>Even when JS is unavoidable, it’s not black and white. A well designed HTML element can reduce the amount and complexity of JS needed to a minimum. Think of the <code><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/dialog">&lt;dialog&gt;</a></code> element: it usually does require *some* JS, but it’s usually rather simple JS. Similarly, the <code>&lt;video&gt;</code> element is perfectly usable just by writing HTML, and has a comprehensive JS API for anyone who wants to do fancy custom things.</p>



<p>The other day I was looking for a simple, dependency free, tabs component. You know, the canonical example of something that is easy to do with Web Components, the example 50% of tutorials mention. I didn’t even care what it looked like, it was for a testing interface. I just wanted something that is small and works like a normal HTML element. Yet, it proved so hard I ended up writing my own!</p>



<h3>Can we fix this?</h3>



<p>I’m not sure if this is a design issue, or a documentation issue. Perhaps for many of these web components, there are easier ways to use them. Perhaps there are vanilla web components out there that I just can’t find. Perhaps I’m looking in the wrong place and there is another directory somewhere with different goals and a different target audience. </p>



<p>But if not, and if I’m not alone in feeling this way, we need a directory of web components with strict inclusion criteria:</p>



<ul><li><strong>Plug and play.</strong> No dependencies, no setup beyond including one <code>&lt;script&gt;</code> tag. If a dependency is absolutely <em>needed</em> (e.g. in a map component it doesn’t make sense to draw your own maps), the component loads it automatically if it’s not already loaded.</li><li>Syntax and API follows <a href="https://www.smashingmagazine.com/2017/02/designing-html-apis/"><strong>conventions established by built-in HTML elements</strong></a> and anything that <em>can</em> be done without the component user writing JS, <em>is</em> doable without JS, per <a href="https://www.w3.org/2001/tag/doc/leastPower.html">the W3C principle of least power</a>.</li><li><strong>Accessible by default</strong> via sensible ARIA defaults, just like normal HTML elements.</li><li><strong>Themable</strong> via <code><a href="https://developer.mozilla.org/en-US/docs/Web/CSS/::part">::part()</a></code>, selective inheritance and custom properties. Very minimal style by default. Normal CSS properties should just “work” to the the extent possible.</li><li><strong>Only one component of a given type</strong> in the directory, that is <strong>flexible</strong> and <strong>extensible</strong> and continuously iterated on and improved by the community. Not 30 different sliders and 15 different tabs that users have to wade through. No branding, no silos of “component libraries”. Only elements that are designed as closely as possible to what a browser would implement in every way the current technology allows.</li></ul>



<p>I would be up for working on this if others feel the same way, since that is not a project for one person to tackle. <em>Who’s with me?</em></p>



<p><strong>UPDATE:</strong> Wow this post blew up! Thank you all for your interest in participating in a potential future effort. I’m currently talking to stakeholders of some of the existing efforts to see if there are any potential collaborations before I go off and create a new one. <a href="https://twitter.com/leaverou">Follow me on Twitter to hear about the outcome</a>!</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://lea.verou.me/2020/09/the-failed-promise-of-web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24616859</guid>
            <pubDate>Mon, 28 Sep 2020 14:20:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Y Combinator worth it?]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 119 (<a href="https://news.ycombinator.com/item?id=24616649">thread link</a>) | @gk1
<br/>
September 28, 2020 | https://drodio.com/our-ycombinator-experience/ | <a href="https://web.archive.org/web/*/https://drodio.com/our-ycombinator-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://drodio.com/content/images/size/w300/2020/09/IMG_1431.jpg 300w,
                            https://drodio.com/content/images/size/w600/2020/09/IMG_1431.jpg 600w,
                            https://drodio.com/content/images/size/w1000/2020/09/IMG_1431.jpg 1000w,
                            https://drodio.com/content/images/size/w2000/2020/09/IMG_1431.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://drodio.com/content/images/size/w2000/2020/09/IMG_1431.jpg" alt="Is Y Combinator worth it?">
            </figure>

            <section>
                <div>
                    <p>Back in late 2016, I started <a href="http://www.armory.io/">Armory </a>in my garage (pictured above) with my two co-founders. We also applied to Y Combinator. I often have founders ask me if YC is worth it right around now, during YC application season. </p><p>The short answer is <code>Yes, you should at least apply to see if you get in.</code> The longer answer is <code>It depends a lot more on <em>you </em>than YC (kind of like asking "is exercise worth it?").</code> Armory participated in the Winter 2017 batch, as well as the Fall 2019 Growth program.</p><p>YC is not just one thing. It's a series of people, experiences and resources that scale with your company as it grows. Here's a detailed look into what's been valuable, and what you can do to get full value from YC:</p><h2 id="optimizing-our-initial-w17-yc-batch-experience-">Optimizing our initial W17 YC &nbsp;batch experience:</h2><ul><li>YC's biggest initial benefit is that it creates intense focus in a short period of time, and at the end of the program, YC has nailed product-market-fit to help you pick up a good sized initial investment via Demo Day. If you hit it hard, you won't have any problem raising money. That alone is very valuable in the early stages of a startup's life, and it's a self-reinforcing cycle: The more initial traction you have, the more investment you can quickly pick up (and vice versa).</li><li>We secured several million dollars in SAFE notes in the span of a couple of days after demo day – and we could have picked up more if we'd wanted to. More on that below. It helps to be organized because you'll have to prioritize and manage a lot of investor interest in a short period of time. </li></ul><blockquote>I'd recommend using a Trello board like the one below to manage investor interest (you can <strong><a href="https://trello.com/b/jsHJLVMB/ycombinator-demo-day/drodio/recommend">make a copy of it here</a></strong>). This board is also valuable for future rounds; I used a variation of it for Armory's Series A and B as well <em>(that's a whole other blog post; LMK if you'd like me to write it).</em></blockquote><!--kg-card-begin: html--><p><img src="https://p-qkfvwn.b3.n0.cdn.getcloudapp.com/items/xQuL5Bz9/Screen%20Recording%202020-09-11%20at%2003.41.17%20PM.mp4" width="800"></p><!--kg-card-end: html--><ul><li>If you decide to apply to YC, the #1 piece of advice I can provide is <code>Show, Don't Tell.</code> The more you can show YC that you've already got early traction, the more likely it is that your application will be accepted for an interview, and that you'll get in (or at least invited back for a 2nd interview.) And it's good practice to focus on getting early, external validation, because that's what you'll be doing non-stop once you get into YC. Nicolae has <a href="https://medium.com/@nicolaerusan/modeling-what-startup-growth-actually-looks-like-73cc4720230e">a good breakdown here</a> of the 5% to 6% <em>weekly</em> growth that you should be targeting. The YC batch experience is an intense experience where you identify your top growth metric, focus on optimizing it, measure your results, and then do <em>whatever it takes </em>to unblock that growth. Rinse and repeat each week with all the founders around you doing the same thing. &nbsp;</li><li>You're more likely to be accepted if you are not a solo founder. I personally like the "hacker and hustler" combo for the fastest growth iterations &amp; unblocking. If you're afraid of getting strong external signals of validation for an MVP product, you won't do well in YC. One of my favorite sayings is <code>perfectionists are <em>imperfect </em>with their time.</code> And time is in short supply, with the Demo Day clock looming from the very first day of the program. A few other very appropriate sayings: <code>Build the right thing fast, instead of the wrong thing right,</code> and <code>There's <em>always </em>one more thing you can do [to increase growth]. And after that, there's <em>one more thing</em>.</code> I find that often, people are their own enemies when it comes to the headspace you need to be in to be a successful YC founder. Don't doubt yourself. Believe in your ability to create value. And don't be shy about being relentless in pursuing that external validation to prove it.</li></ul><p>Below is Armory's Demo Day video from 2017. I've blurred out some of our early customer names, but other than that, it's the full video. This is the first time it's been shown publicly. We spent the YC batch program getting our first customers to sign contracts (the "hustler" piece) while we built out the first version of Armory's platform (the "hacker" piece), which is built using an open source continuous software delivery project called <a href="http://www.spinnaker.io/">Spinnaker</a>. By the time Demo Day rolled around, we had multiple paid customer commitments and could articulate a long-term vision for Armory<em> (which has remained largely unchanged since our early days in the garage – that's also a whole other blog post!).</em> I've heard people say there's $100 Billion worth of VC funds in the room for YC Demo Day. I can believe that, and I wouldn't be surprised if it's well over that. </p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/IvZjbN2kil0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><ul><li><strong>Other things we did well: </strong>YC has guest speakers come speak once weekly at dinner during the program, and there are really valuable nuggets of wisdom shared during those dinners. For example, Lyle Fong, the founding CEO of Lithium, gave a talk at a dinner about how he had to educate CMOs on the kind of social media platform Lithium was, so he made a maturity model diagram. That sparked Armory's creation of this "<a href="http://go.armory.io/stages">Stages of Software Delivery</a>" diagram, which we've used extensively to help Global 2,000 enterprises understand what their future pain points will be as they adopt the cloud, as well as the benefits they can expect to garner.</li><li><strong>Things we could have done better: </strong>We've never utilized YC Office Hours as effectively as we could have. There are YC partners and domain experts that make themselves available to talk through challenges a business is having. I recommend leaning into that more than we did.</li></ul><h2 id="optimizing-yc-s-growth-program-ycg-f19-">Optimizing YC's Growth Program (YCG F19):</h2><figure><img src="https://drodio.com/content/images/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg" alt="" srcset="https://drodio.com/content/images/size/w600/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 600w, https://drodio.com/content/images/size/w1000/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 1000w, https://drodio.com/content/images/size/w1600/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 1600w, https://drodio.com/content/images/2020/09/0CC9DBF0-5451-4BDD-8F7F-2F1BEDA3D330.jpeg 2388w" sizes="(min-width: 720px) 720px"></figure><p>In the fall of 2019, I participated in the "graduate" YC program, for YC companies that are scaling. I consider this program to be even more valuable than the initial YC batch experience. It's more intimate – our group was about 15 CEOs – and everyone is dealing with (or has just dealt with) the same types of issues. If the first YC batch experience is about figuring how to drive relentless early traction and growth, the YC growth program is about figuring out how to scale that growth, in every sense of the word – how to scale your functions, your executives, your culture, your size, your<em>self</em>. And the vibe is entirely different: In the early YC batch days, you're just trying to make your startup <em>become relevant and survive.</em> But in the Growth program, it's clear that all the startups who have made it this far are solving a real problem for the world, and have a lot of growth in front of them. And the problems are much more abstract – more about how to align <em>people and processes </em>to scale the magic that's made the business get this far. I've made some incredible, true friendships from this group, and we continue to help each other via WhatsApp and meet on a regular basis. </p><ul><li>My #1 tip is to capture as much of the content as you can to share in permissioned ways with your executive team and managers. By the time you participate in this program, your company will have grown well beyond just the founders. Many of the great tips you'll hear will come from the dinners you attend, as well as how your fellow CEOs have managed similar issues. I highly recommend <a href="http://go.armory.io/Otter">installing Otter.ai on your phone</a> so you can ask the person sharing pro-tips if you can record it and make an auto-transcript to share with your execs. I did this a bunch during the program <em>(Oleg, I'm looking at you, buddy!).</em></li></ul><p>If you have the chance to do the YC Growth program, you should absolutely do it. <em>(I'll invite the CEOs from our batch to leave more thoughts in the comments below).</em></p><h2 id="the-big-thing-to-understand-about-yc-before-you-join-">The big thing to understand about YC <em>before </em>you join:</h2><p>So yes, YC is very much worthwhile. What you get out of YC will very much be dependent on what you put into it. I haven't even mentioned the internal YC forum (cheekily called "BookFace") where several thousand YC alums serve as a resource for each other, as well as YC's <a href="https://www.workatastartup.com/">Work at a Startup</a> recruiting tool, the private VC resource rating directory, YC's <a href="https://blog.ycombinator.com/ycs-series-a-guide/">Series A program</a>, and other similar resources. &nbsp;</p><p>Here's the main thing you need to understand before you apply: YC has <a href="https://www.ycombinator.com/deal/">a "standard deal"</a> where they take a 7% stake in your company. YC also gets pro-rata rights in future funding rounds. If your company is really successful, you may find yourself in a position where you need to negotiate some of those pro-rata rights in order to make the round work (i.e., make enough room to accomodate new new investor demand). While YC will do its best to work with you based on your specific situation, you need to understand that you're signing up for a standard deal up-front, and that early seed-stage commitment may upset other investors. Other angel/seed/Series A investors can become unhappy when having to live on a cap table alongside YC.</p><p>Hope that helps! Feel free to ask any questions in the comments – and if you're also a YC alum, please share your pro-tips as well!</p>
                </div>
            </section>


            

            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://drodio.com/our-ycombinator-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24616649</guid>
            <pubDate>Mon, 28 Sep 2020 13:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mental Models for Challenging Problems]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24616598">thread link</a>) | @nicotesla
<br/>
September 28, 2020 | https://blog.codelitt.com/5-mental-models/ | <a href="https://web.archive.org/web/*/https://blog.codelitt.com/5-mental-models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="Post__Main-Content">
        <div>
          <p>I'm an avid reader. For a long time now, my primary source of information has come in the form of newsletters. The main advantage of the newsletter format for me is that I can surround myself with information sources I trust. This approach makes it easy to organize the content I'm interested in. Of course, my interests are always evolving depending on what's happening at any given moment in my life. I try not to replace the types of information I expose myself to, but <em>am</em> always trying to find the best sources. It's great because on any given day I can find an article about the latest release of a JS library alongside one about Engineering leadership and management.</p><p>A while ago I started noticing that most of my newsletters would share an article or two on <strong>mental models</strong>. I loved the name but didn't really engage with the idea initially. One day, I made the decision to bookmark <a href="https://www.julian.com/blog/mental-model-examples">this article</a> and promised myself that I would read it someday. I suppose I was tired of seeing headlines about the concept (and remaining uninformed about it). </p><figure><img src="https://res-1.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/mental-models-engineers-2.jpg"></figure><p>The day I decided to dive into the topic, I immediately found myself wishing that I'd taken it up sooner. Being the CTO at Codelitt, I spend a considerable chunk of my energy on decision making. Logically, this means that any improvement in this area would mean a big return in time and effort which could then be applied elsewhere in the company. </p><p>The following is an excerpt from <a href="https://www.julian.com/blog/mental-model-examples">Julian's blog</a> where he provides an awesome explanation on the subject.</p><blockquote>Mental models do two things: they help you assess how systems work and they help you make better decisions. These two concepts underlie everything you do.<p>For example, how does a rocket engine work? And which type of rocket fuel should you use?</p><p>The rocket engine is a system for you to assess. It has many parts that depend on each other, and you want to understand how. As for which type of fuel to use, that's a decision you make.</p></blockquote><p>Below we have a few mental models that I find myself using on a daily basis when making software engineering decisions. Each concept has a summary that is pulled directly from one source - <a href="https://fs.blog/">Shane Parrish's Farnam Street blog</a> - which I highly recommend.</p><h3 id="redundancy">Redundancy</h3><p>A good engineer never assumes the perfect reliability of the components of the system. He or she builds in redundancy to protect the integrity of the total system. Without the application of this robustness principle, tangible and intangible systems tend to fail over time.</p><h3 id="bottlenecks">Bottlenecks</h3><p>A bottleneck describes the place at which a flow (of a tangible or intangible) is stopped, thus holding it back from continuous movement. As with a clogged artery or a blocked drain, a bottleneck in production of any good or service can be small but have a disproportionate impact if it is in the critical path.</p><figure><img src="https://res-4.cloudinary.com/hepw4b4yn/image/upload/q_auto/v1/ghost-blog-images/mental-models-engineers-3.jpg"></figure><h3 id="emergence">Emergence</h3><p>Higher-level behavior tends to emerge from the interaction of lower-order components. The result is frequently not linear – not a matter of simple addition – but rather non-linear, or exponential. An important resulting property of emergent behavior is that it cannot be predicted from simply studying the component parts.</p><h3 id="first-principles-thinking">First Principles Thinking</h3><p>First principles thinking is one of the best ways to reverse-engineer complicated situations and unleash creative possibility. Sometimes called reasoning from first principles, it’s a tool to help clarify complicated problems by separating the underlying ideas or facts from any assumptions based on them. What remains are the essentials. If you know the first principles of something, you can build the rest of your knowledge around them to produce something new.</p><h3 id="first-conclusion-bias">First-Conclusion Bias</h3><p>As Charlie Munger famously pointed out, the mind works a bit like a sperm and egg: the first idea gets in and then the mind shuts. Like many other tendencies, this is probably an energy-saving device. Our tendency to settle on first conclusions leads us to accept many erroneous results and cease asking questions; it can be countered with some simple and useful mental routines.</p><p>If you would like to see more on mental models, check out the <a href="https://fs.blog/mental-models/">Farnan Street blog</a>.</p><hr><p>Want to read more about how Kaio thinks?</p><ul><li><a href="https://blog.codelitt.com/contractor-to-cto/">Check out his journey to become CTO of Codelitt</a></li><li><a href="https://blog.codelitt.com/design-system/">Read about his perspective on the importance of establishing a design system</a></li></ul>
        </div>
      </section></div>]]>
            </description>
            <link>https://blog.codelitt.com/5-mental-models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24616598</guid>
            <pubDate>Mon, 28 Sep 2020 13:54:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why you need a service registry]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24616442">thread link</a>) | @lawrjone
<br/>
September 28, 2020 | https://blog.lawrencejones.dev/service-registry/ | <a href="https://web.archive.org/web/*/https://blog.lawrencejones.dev/service-registry/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Building a service registry, a structure that tracks all people, services and
systems that interact with your infrastructure, can be extremely powerful.</p>

<p>If you pick the right format, it can be the glue between totally distinct
toolchains. Placing the registry at the heart of all your other tools means you
no longer need to worry about keeping it up-to-date: the registry defines what
is created, rather than describing it.</p>

<p>By distributing the registry so every developer, infrastructure component or
one-off script can easily read it, you’ll find use cases for this data
everywhere. You can even push this data into systems like your monitoring stack,
allowing automated systems to make decisions on the ownership information it
provides.</p>

<p>As part of a revamp of our infrastructure tooling, we’ve introduced a service
registry into GoCardless. This post explains how we built the registry and some
of the use cases we’ve found for it.</p>



<p>The GoCardless service registry is a <a href="https://jsonnet.org/">Jsonnet</a> library, stored as a
file inside the same Git repository that contains our infrastructure
configuration. Jsonnet, for those not familiar, is an extension to JSON that
aims to support flexible reuse and customisation of data structures.</p>

<p>Jsonnet files evaluate to JSON, and the service registry is no different:</p>

<div><div><pre><code><span>$</span><span> </span>jsonnet registry.jsonnet
<span>{
  "clusters": [...],
  "services": [...],
  "teams": [...],
  "projects": [...],
  ...,
}
</span></code></pre></div></div>

<p>Perhaps you thought a service registry was a webserver, maybe hooked up to a
database, serving the data via a REST API? That wouldn’t be strange, and there
are many systems that do just that, but I’d suggest the approach of building a
registry out of a single JSON file (compiled from whatever templating language
you choose, be it Jsonnet or otherwise) has several advantages:</p>

<ul>
  <li>JSON files are so universally compatible that you’ll be able to use this
anywhere</li>
  <li>If you’ve already adopted Git-ops workflows, tracking changes to the registry
in Git should feel very natural</li>
  <li>It’s just data, and your registry is only as good as the data you put in it.
Removing the distraction of building an API means you encourage a focus on
building the right data model, which is what really matters</li>
</ul>

<p>From the output of the <code>jsonnet registry.jsonnet</code> command, you can see we’re
tracking our Kubernetes <code>clusters</code>, any <code>services</code> that we run, organisation
<code>teams</code> who interact with the services, and Google Cloud Platform <code>projects</code>.</p>

<p>You don’t need to start by tracking all these types, but the simplicity of a
Jsonnet library means it costs very little to add a new type. We began with
<code>services</code>, then wanted to ensure no service referenced an invalid team. It was
a natural evolution to add <code>teams</code>, and this pattern has happened many times
over.</p>

<h2 id="service-entry-make-it-rain">Service entry (make-it-rain)</h2>

<p>Our registry began as a list of services, where each service had a
<code>metadata.jsonnet</code> that defined its service entry.</p>

<p>For the purpose of this post, imagine we have a (fake) service called
<code>make-it-rain</code>, which has a service entry that looks like this:</p>

<div><div><pre><code><span>// Example service called make-it-rain, powering a dashboard of falling</span>
<span>// gold coins whenever anyone takes a payment via GoCardless.</span>
<span>//</span>
<span>// Banking teams love money, which is why they created this dashboard.</span>
<span>// It's officially owned by banking-integrations, but core-banking</span>
<span>// sometimes optimise the React code.</span>
<span>//</span>
<span>// It consumes data about new payments from Google Pub/Sub, and has a</span>
<span>// separate Google Cloud Platform project for each of its environments,</span>
<span>// of which there are two: staging and production.</span>
<span>service</span><span>.</span><span>new</span><span>(</span><span>'make-it-rain'</span><span>,</span> <span>'gocardless/make-it-rain'</span><span>)</span> <span>+</span>
<span>service</span><span>.</span><span>mixin</span><span>.</span><span>withTeam</span><span>(</span><span>'banking-integrations'</span><span>)</span> <span>+</span>
<span>service</span><span>.</span><span>mixin</span><span>.</span><span>withAlertsChannel</span><span>(</span><span>'make-it-rain-alerts'</span><span>)</span> <span>+</span>
<span>service</span><span>.</span><span>mixin</span><span>.</span><span>withGoogleServices</span><span>([</span>
  <span>'pubsub.googleapis.com'</span><span>,</span>
<span>])</span> <span>+</span>
<span>service</span><span>.</span><span>mixin</span><span>.</span><span>withEnvironments</span><span>([</span>
  <span>environment</span><span>.</span><span>map</span><span>(</span>
    <span>// By default, every environment should have banking-integrations as</span>
    <span>// admins, and core-banking as operators (they provide on-call cover</span>
    <span>// for the falling gold coins).</span>
    <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>rbac</span><span>.</span><span>withAdmins</span><span>(</span><span>'banking-integrations'</span><span>)</span> <span>+</span>
    <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>rbac</span><span>.</span><span>withOperators</span><span>(</span><span>'core-banking'</span><span>),</span>
    <span>function</span><span>(</span><span>environment</span><span>)</span> <span>[</span>
      <span>environment</span><span>.</span><span>new</span><span>(</span><span>'staging'</span><span>)</span> <span>+</span>
      <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>withGoogleProject</span><span>(</span><span>'gc-prd-make-it-stag-833e'</span><span>)</span> <span>+</span>
      <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>withTargets</span><span>([</span>
        <span>argocd</span><span>.</span><span>new</span><span>(</span><span>cluster</span><span>=</span><span>'compute-staging-brava'</span><span>,</span> <span>namespace</span><span>=</span><span>'make-it-rain'</span><span>),</span>
      <span>]),</span>
      <span>// Unlike most services, the production environment should permit</span>
      <span>// a non-engineering team to open consoles. Sometimes we take a</span>
      <span>// manual payment outside of GoCardless, and banking-operations</span>
      <span>// open a make-it-rain console and run a script, so we don't miss</span>
      <span>// any gold coins.</span>
      <span>environment</span><span>.</span><span>new</span><span>(</span><span>'production'</span><span>)</span> <span>+</span>
      <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>rbac</span><span>.</span><span>withOperatorsMixin</span><span>(</span><span>'banking-operations'</span><span>)</span> <span>+</span>
      <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>withGoogleProject</span><span>(</span><span>'gc-prd-make-it-prod-1eb1'</span><span>)</span> <span>+</span>
      <span>environment</span><span>.</span><span>mixin</span><span>.</span><span>withTargets</span><span>([</span>
        <span>argocd</span><span>.</span><span>new</span><span>(</span><span>cluster</span><span>=</span><span>'compute-banking'</span><span>,</span> <span>namespace</span><span>=</span><span>'make-it-rain'</span><span>),</span>
      <span>]),</span>
    <span>],</span>
  <span>),</span>
<span>])</span>
</code></pre></div></div>

<p>Take a moment to read the Jsonnet- this produces a JSON structure that you can
see <a href="https://gist.github.com/lawrencejones/b209a1a5da864b987cbedb1dffef6116#file-make-it-rain-json">here</a>. It includes a definition of the service and
all its environments, with a list of deployment targets for each environment
that defines where the deployment lives.</p>

<p>There’s some configuration of team permissions and Google Cloud Platform
references- we’ll see how we can use them next.</p>



<p>Once you have a list of service entries like make-it-rain, we can use it
to tightly integrate with all the rest of our infrastructure tools.</p>

<p>Most infrastructure teams deal with many (in my mind, too many) tools.  The
GoCardless team provisions infrastructure with <a href="https://www.terraform.io/">terraform</a>, manages
virtual machines with <a href="https://www.chef.io/products/chef-infra">Chef</a>, and <a href="https://kubernetes.io/">Kubernetes</a> resources with
Jsonnet templating. Other teams may use far more.</p>

<p>Thankfully, our service registry is plain ol’ JSON, and easily consumed by all
of these tools. Once imported, we can begin provisioning infrastructure in
response to changes in the registry. This is a change from the registry
describing the infrastructure at a point-in-time, to becoming the definition
what really exists.</p>

<p>When you must update registry to create infrastructure, you guarantee the
registry is up-to-date, and know it can no longer become stale. This allows you
to trust the registry in use-cases that weren’t possible if it could fall
out-of-date, a benefit we’ll see when we integrate it with our
<a href="#tooling">tools</a>.</p>

<p>Let’s see how this works in practice.</p>

<h2 id="kubernetes">Kubernetes</h2>

<p>When someone creates a service like make-it-rain, we’ll import their entry into
the registry. Our CD pipelines will detect a registry change and begin
provisioning core resources required for every service.</p>

<p>First, we have a Jsonnet templated cluster service that we use to create
privileged Kubernetes cluster resources, such as namespaces. As the templating
imports the registry as just another Jsonnet file, it will detect we’re missing
a namespace (<code>make-it-rain</code>) in the <code>compute-staging-brava</code> and
<code>compute-banking</code> clusters, and automatically create them.</p>

<p>After we have a namespace, we’ll create the supporting resources.  Included in
this are resource quotas, limiting the amount of cluster resource make-it-rain
could consume- these limits can be tweaked or overriden in the cluster service
Jsonnet:</p>

<div><div><pre><code><span>// utopia/services/cluster/instances/compute-staging.jsonnet</span>
<span>cluster</span> <span>{</span>
  <span>spaces</span><span>+:</span> <span>{</span>
    <span>'make-it-rain'</span><span>+:</span> <span>{</span>
      <span>quota</span><span>+:</span> <span>{</span>
        <span>spec</span><span>+:</span> <span>{</span>
          <span>// These React apps are getting crazy...</span>
          <span>hard</span><span>+:</span> <span>{</span> <span>cpu</span><span>:</span> <span>'32'</span><span>,</span> <span>memory</span><span>:</span> <span>'32Gi'</span> <span>},</span>
        <span>},</span>
      <span>},</span>
    <span>},</span>
  <span>},</span>
<span>}</span>
</code></pre></div></div>

<p>Permissions are one of the more complicated things about managing Kubernetes
clusters. Especially when aiming for a Devops workflow, with application
engineers empowered to care for their own Kubernetes resources, you want to
establish a consistent permission model up-front. Consistency means you can
accurately describe your security stance for audits, and helps maintain
productivity for engineers who work across multiple teams.</p>

<p>Your registry, being the authoritative definition of service RBAC, can be used
to power your Kubernetes RBAC and enforce that consistency. Looking at our
make-it-rain production environment, we can see the RBAC fields:</p>

<div><div><pre><code><span>{</span><span>
  </span><span>"type"</span><span>:</span><span> </span><span>"Service"</span><span>,</span><span>
  </span><span>"spec"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"name"</span><span>:</span><span> </span><span>"make-it-rain"</span><span>,</span><span>
    </span><span>"repository"</span><span>:</span><span> </span><span>"gocardless/make-it-rain"</span><span>,</span><span>
    </span><span>"team"</span><span>:</span><span> </span><span>"banking-integrations"</span><span>,</span><span>
    </span><span>"environments"</span><span>:</span><span> </span><span>[</span><span>
      </span><span>{</span><span>
        </span><span>"type"</span><span>:</span><span> </span><span>"Environment"</span><span>,</span><span>
        </span><span>"spec"</span><span>:</span><span> </span><span>{</span><span>
          </span><span>"name"</span><span>:</span><span> </span><span>"staging"</span><span>,</span><span>
          </span><span>"rbac"</span><span>:</span><span> </span><span>{</span><span>
            </span><span>"admins"</span><span>:</span><span> </span><span>[</span><span>
              </span><span>"banking-integrations"</span><span>
            </span><span>],</span><span>
            </span><span>"operators"</span><span>:</span><span> </span><span>[</span><span>
              </span><span>"core-banking"</span><span>
            </span><span>],</span><span>
            </span><span>"viewers"</span><span>:</span><span> </span><span>[]</span><span>
          </span><span>}</span><span>
        </span><span>}</span><span>
      </span><span>},</span><span>
      </span><span>...</span><span>
    </span><span>]</span><span>
  </span><span>}</span><span>
</span><span>}</span><span>
</span></code></pre></div></div>

<p>We made a decision to model just three roles for a service, viewer, operator and
admin- from our experience, it seems this is flexible enough for almost all use
cases. We thought it would be great if all permissions granted to humans were
derived from these member lists, instead of scattering the membership across our
infrastructure configuration (Kubernetes, terraform, Chef).</p>

<p>Now we have our registry, we can do just that. Using Kubernetes permissions as
an example, it’s simple to:</p>

<ul>
  <li>Identify the list of teams who are viewers, operators, or admins for any
services that exist within each cluster namespace</li>
  <li>Use these lists to create <code>RoleBinding</code>s in the service namespace, granting
appropriate permissions to each member of the roles</li>
</ul>

<p>We implement this in a single file, <code>cluster/app/spaces-rbac.jsonnet</code>, which
allows us to map over all namespaces in a cluster and provision the
<code>RoleBinding</code> Kubernetes resources. Jsonnet is great for this type of data
manipulation, proving–yet again!–how using a static registry does not limit how
flexibly you can query the data.</p>

<h2 id="google-cloud-platform">Google Cloud Platform</h2>

<p>It’s not just Kubernetes resources in Jsonnet, though. GoCardless is a heavy
user of Google Cloud Platform, and if this permission model is sound, we should
be able to apply it to our Cloud estate too.</p>

<p>For this, we have a …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.lawrencejones.dev/service-registry/">https://blog.lawrencejones.dev/service-registry/</a></em></p>]]>
            </description>
            <link>https://blog.lawrencejones.dev/service-registry/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24616442</guid>
            <pubDate>Mon, 28 Sep 2020 13:35:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zig's New Relationship with LLVM]]>
            </title>
            <description>
<![CDATA[
Score 430 | Comments 262 (<a href="https://news.ycombinator.com/item?id=24615916">thread link</a>) | @todsacerdoti
<br/>
September 28, 2020 | https://kristoff.it/blog/zig-new-relationship-llvm/ | <a href="https://web.archive.org/web/*/https://kristoff.it/blog/zig-new-relationship-llvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>While not yet at version 1.0, Zig is about to reach a new level of maturity and stability.</p><div><p>In the early days, Zig was but a thin frontend in front of LLVM. This was instrumental for getting started quickly and filling in gaps of Andrew’s knowledge as a compiler developer. Now, the training wheels of the bicycle are coming off, and LLVM is transitioning into an optional component.</p>
<p><span>
      <a href="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/98017/protty1.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/f5e3c/protty1.webp 100w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/f2fbe/protty1.webp 200w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/e227a/protty1.webp 400w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/efddf/protty1.webp 441w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/c0399/protty1.png 100w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/9ec3c/protty1.png 200w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/c7805/protty1.png 400w,
https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/98017/protty1.png 441w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/2cc08c37498f0cec888734c477d5f358/c7805/protty1.png" alt="protty1" title="protty1">
      </picture>
  </a>
    </span></p>
<p>The work to replace the current C++ compiler implementation with a new pure Zig version has begun. Moving to a self-hosted implementation is usually considered a step towards maturity, with most benefits being felt by developers of the language itself. As an example, <a href="https://www.youtube.com/watch?v=cF1zJYkBW4A" target="_blank" rel="nofollow noopener noreferrer">Go lost</a> some speed of compilation by switching to the self-hosted compiler but, in exchange, it streamlined the toolchain, removed dependencies, and improved the whole development experience.</p>
<p>The move to a self-hosted compiler for Zig has similar advantages for the core contributors, but it also <strong>makes LLVM an optional dependency</strong>, <strong>increases compilation speed</strong> (instead of losing it), and adds an amazing feature for debug builds of your code: <strong>incremental compilation with in-place binary patching</strong>, <a href="https://kristoff.it/blog/what-is-zig-comptime/">another</a> <a href="https://kristoff.it/blog/zig-colorblind-async-await/">unique</a> Zig feature.</p>
<h2 id="speeding-up-compilation"><a href="#speeding-up-compilation" aria-label="speeding up compilation permalink"></a>Speeding up compilation</h2>
<p>Most languages offer some form of caching to speed up compilation, starting from C’s compilation units, up to modules, packages, and other comparable boundaries in more modern languages.</p>
<p>Zig also implements a caching system that comes particularly handy when building a project that mixes C and Zig source code, or when using Zig as a C compiler with the <code>zig cc</code> command. Zig keeps track of all the files involved in the compilation, so it can very easily know when an object file can be reused, and this is <a href="https://andrewkelley.me/post/zig-cc-powerful-drop-in-replacement-gcc-clang.html" target="_blank" rel="nofollow noopener noreferrer">only one of the advantages</a> of using Zig to compile C code.</p>
<p>Zig sources always get bundled into a single compilation unit, so the caching system in its current form doesn’t provide any speedup when editing and recompiling a pure Zig project. The upside is that, not only compiling Zig code is very fast, but also that incremental compilation will provide smart caching for Zig code, more than making up for what we can’t get from simple caching.</p>
<h2 id="incremental-compilation"><a href="#incremental-compilation" aria-label="incremental compilation permalink"></a>Incremental compilation</h2>
<p>Incremental compilation is a form of caching that acts at a higher granularity level than normal “compilation unit”-level caching. The Rust blog has a <a href="https://blog.rust-lang.org/2016/09/08/incremental.html" target="_blank" rel="nofollow noopener noreferrer">great post</a> that explains how it works.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/d4d70/rust.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/f5e3c/rust.webp 100w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/f2fbe/rust.webp 200w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/e227a/rust.webp 400w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/965c5/rust.webp 600w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/0cbce/rust.webp 800w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/16e88/rust.webp 964w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/c0399/rust.png 100w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/9ec3c/rust.png 200w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/c7805/rust.png 400w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/34e8a/rust.png 600w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/8ff1e/rust.png 800w,
https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/d4d70/rust.png 964w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/c8f09130b97cf9ec0fd60c85eb21418e/c7805/rust.png" alt="rust" title="Taken from the Rust blog post linked above.">
      </picture>
  </a>
    </span>
    <figcaption>Taken from the Rust blog post linked above.</figcaption>
  </figure>
<p>In the case of Rust, the compiler builds a dependency graph at the AST level and then saves it to disk alongside the cached intermediate results (object files). When a new compilation is requested, the compiler will be able to easily notice which parts of the AST have changed and thus invalidate all the intermediate results that depend on it.</p>
<p>One important detail about this graph is the fact that the right-most box is always invalidated. In other words, the final executable is always re-linked from scratch starting from a mix of old and newly generated object files. It’s clear that this has to be the case, since the final executable depends on everything else and so any meaningful change to the code will invalidate it, but this is where the Zig self-hosted compiler brings a new ingenious idea to the table.</p>
<h2 id="in-place-binary-patching"><a href="#in-place-binary-patching" aria-label="in place binary patching permalink"></a>In-Place Binary Patching</h2>
<p>As of Zig version 0.6.0, regardless of the type of release (debug, release-safe, release-fast), there is always a final step delegated to <strong>LLVM, which takes at least 70% of the total compilation time</strong> including when compiling a debug build, where optimizations aren’t even enabled.</p>
<p><strong>The self-hosted compiler will not depend on LLVM for debug builds</strong> and will be able to cut compilation time considerably, <strong>basically reducing that 70% to almost zero</strong>, just by virtue of being a simpler piece of software compared to LLVM. </p>
<p>On top of that, since the compiler will have full control over the whole process, it will generate machine code using an ad-hoc strategy optimized for incremental compilation, allowing the compiler to patch the final executable in-place with the new changes. </p>
<p>In-place binary patching is based on a granularity of top-level declarations. Each global variable and function can be independently patched because the final binary is structured as a sequence of loosely coupled blocks. Another important characteristic is that all this information is kept in memory, so the compiler will stay open between compilations.</p>
<p> If you want to see the self-hosted compiler in action, here’s a 5 minute demo by Andrew:</p>

          <p>
            <iframe src="https://www.youtube-nocookie.com/embed/R5FKgi9BYyU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
          </p>
          
<h2 id="designing-machine-code-for-incremental-compilation"><a href="#designing-machine-code-for-incremental-compilation" aria-label="designing machine code for incremental compilation permalink"></a>Designing machine code for incremental compilation</h2>
<p>Efficient in-place binary patching is something that can only be accomplished by tightly coupling the compiler frontend and backend. Part of the reason this feature is so rarely seen in the wild is that it goes against our better sense of abstraction and clean code organization. But we must never forget: abstraction is just a tool to reach a practical outcome, and not always the most appropriate one.</p>
<p>In order to perform in-place binary patching, we need code to be <a href="https://en.wikipedia.org/wiki/Position-independent_code" target="_blank" rel="nofollow noopener noreferrer">position independent</a>. This allows us to move it around in virtual memory when a function grows outside its allocated boundary. We also need to be able to reference virtual addresses indirectly, so that N callsites do not need to be updated when a function is moved to a new virtual address.</p>
<p>To accomplish this Zig uses a Global Offset Table for all function calls.</p>
<p>However, that only solves functions. There are more components to consider here, such as debug information. When we add new lines to a function, that modifies the debug information, which is used to print stack traces! Solving this involves creatively organizing an allocation scheme for debug line information, and figuring out how to do NOPs. Andrew’s journey here involved creating a <a href="http://dwarfstd.org/ShowIssue.php?issue=200803.1" target="_blank" rel="nofollow noopener noreferrer">proposal for a new DWARF line number opcode</a>.</p>
<p>This problem must be solved repeatedly for each kind of linking backend - ELF, DWARF, PE, PDB, MachO, and WebAssembly. Special thanks for the contributors who have stepped up and taken on the added challenge of supporting in-place binary patching: <a href="https://github.com/alexnask" target="_blank" rel="nofollow noopener noreferrer">Alexandros Naskos</a>, <a href="http://www.jakubkonka.com/" target="_blank" rel="nofollow noopener noreferrer">Jakub Konka</a>, and <a href="https://ifreund.xyz/" target="_blank" rel="nofollow noopener noreferrer">Isaac Freund</a>.</p>
<p>Be on the lookout for a more technical post on <a href="https://andrewkelley.me/" target="_blank" rel="nofollow noopener noreferrer">Andrew’s blog</a>, where he’ll dive into some of these fascinating details — <strong>including how this design gets us 90% of the way to hot code swapping!</strong></p>
<h2 id="when-is-it-going-to-be-ready"><a href="#when-is-it-going-to-be-ready" aria-label="when is it going to be ready permalink"></a>When is it going to be ready?</h2>
<p>The self-hosted backend is <a href="https://github.com/ziglang/zig/projects/2" target="_blank" rel="nofollow noopener noreferrer">still a work in progress</a>, but all the functionalities presented in this post have been designed and prototyped to the point where it’s just a matter of doing the methodical part of the work.</p>
<p>The self-hosted backend will ship in Zig 0.7.0 behind a flag, supporting only a subset of the Zig language. In the meantime, the core development team and a few other contributors are sprinting forward with more language support and additional targets. The current aim is to fully replace the C++ implementation with the self-hosted backend for Zig 0.8.0, roughly 7 months from now.</p>
<p>If you like where Zig is going, there’s no better time <a href="https://github.com/ziglang/zig/wiki/Community" target="_blank" rel="nofollow noopener noreferrer">to join the Zig community</a> than now, and if you want to help speed the development up, please <a href="https://ziglang.org/zsf/" target="_blank" rel="nofollow noopener noreferrer">consider donating to the Zig Software Foundation</a> to allow core developers to spend more time working on Zig.</p>
<figure>
    <span>
      <a href="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/8eeed/protty2.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/f5e3c/protty2.webp 100w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/f2fbe/protty2.webp 200w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/e227a/protty2.webp 400w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/44d87/protty2.webp 407w" sizes="(max-width: 400px) 100vw, 400px" type="image/webp">
        <source srcset="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/c0399/protty2.png 100w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/9ec3c/protty2.png 200w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/c7805/protty2.png 400w,
https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/8eeed/protty2.png 407w" sizes="(max-width: 400px) 100vw, 400px" type="image/png">
        <img src="https://kristoff.it/static/2ec6c0ef555e8f1383c4cb5d7b3edba2/c7805/protty2.png" alt="protty2" title="Thanks to kprotty for the cute doodles!">
      </picture>
  </a>
    </span>
    <figcaption>Thanks to kprotty for the cute doodles!</figcaption>
  </figure></div></div>]]>
            </description>
            <link>https://kristoff.it/blog/zig-new-relationship-llvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615916</guid>
            <pubDate>Mon, 28 Sep 2020 12:32:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Multivariate Temporal Autoencoder for Predictive Reconstruction of Deep Sequence]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24615738">thread link</a>) | @shivinski
<br/>
September 28, 2020 | https://altumintelligence.com/articles/a/Multivariate-Temporal-Autoencoder-for-Predictive-Reconstruction-of-Deep-Sequences | <a href="https://web.archive.org/web/*/https://altumintelligence.com/articles/a/Multivariate-Temporal-Autoencoder-for-Predictive-Reconstruction-of-Deep-Sequences">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<div>
		<div id="description-text-article">
			<p>
	This article demonstrates a multi-branch deep neural network approach to tackling the problem of multivariate temporal sequence prediction by modelling a latent state vector representation of data windows through the use of a recurrent autoencoder and predictive model.
</p>

<p>
	The research paper for this article can be downloaded from the following link:
</p>
<p>
	<a href="https://bit.ly/MvTAe" target="_blank"><i></i> https://bit.ly/MvTAe</a>
</p>
<p>
	The complete code can be found at the following GitHub repository:
</p>
<p>
	<a href="https://github.com/jaungiers/MvTAe-Multivariate-Temporal-Autoencoder" target="_blank"><i></i> https://github.com/jaungiers/MvTAe-Multivariate-Temporal-Autoencoder</a>
</p>

<h2>Introduction</h2>

<p>
	Temporal sequence prediction problems have been studied for centuries using ever more complex methods with the aim of capturing hidden patterns within and predicting those patterns going forward. Any temporal process has drivers which determine its behavior, in theory any and all of these drivers can be modelled given enough data about that process at a point in time and a complex enough model - in practice however this is currently unfeasible for a variety of reasons, the main of which are capturing the data, computing the captured dimensionality of the data and modelling the complex interaction of many dimensions interacting in various correlated ways.
</p>
<p>
	An example of the complexity of such a problem might be the seemingly stochastic path of a raindrop down a window. By all respects this raindrop would appear to be taking a random walk down the windowpane, with the left and right movements seemingly unable to be determined or modelled. Consider however having the position of every water molecule, every glass molecule, their respective temperatures and their historical interactions graph with every other molecule available as data at every granular point in time. Given this information, it is reasonable to assume that there exists a model which can be created that is accurately able to specify where the raindrop will go next, and by extrapolating, where it will end up when it reaches the bottom of the windowpane.
</p>
<p>
	The problem of course with the above example is that there currently exists no such method of capturing every observable aspect of a universe at a point in time. Hence for now the best we can do is look to create a model to approximate the hidden drivers of the raindrop given the best data we can gather.
</p>
<p>
	Whilst this isn't optimal for the example raindrop problem, the good news is that there are ample problems where a large amount of data can be gathered at very fine points in time and hence a model can be created to forecast the problem process.
</p>
<p>
	Processes which have a small, closed universe of potential drivers that influence their behavior are easier to forecast for greater sequential steps ahead, whereas processes which are exposed to a great variety of influencing drivers succumb to the exponential decay of accuracy through chaos and as such are only able to be modelled very short sequential steps ahead. The more influencing drivers of a system can be worked into the model however, the more accurate the prediction process will be going forward.
</p>
<p>
	This research focuses on building a model which can process multivariate temporal sequences of data, which in real-world data problems act as the influencing drivers of a process and which learns to build a hyperdimensional approximate representation of the drivers and process in an unsupervised manner. This trained hyperdimensional hidden representation then acts to train a secondary predictive model branch to forecast sequential steps ahead. The model is created using a multi-branch deep neural network approach utilizing the autoencoding principle and building on a sequence to sequence approach created by Sutskever et al. for creating the hyperdimensional hidden state representation. The model is henceforth referred to as Multivariate Temporal Autoencoder (MvTAe).
</p>
<p>
	The dataset used in this research is created to be of a toy-dataset nature used to demonstrate the MvTAe model in simple yet fully functional circumstances. This research is not concerned with the other major challenge of real-world usage concerning observation, measurement and data processing.
</p>

<br>
<h2>Synthetic Multivariate Temporal Dataset</h2>

<p>
	<img src="https://altumintelligence.com/assets/multivariate-temporal-autoencoder-for-predictive-reconstruction-of-deep-sequences/dataset_full.png">
	<br><span>Synthetic multivariate temporal data across all dimensions</span>
</p>

<p>
	To train and test our multivariate temporal autoencoder model we create a synthetic toy-dataset which contains several specific dimensions:
</p>

<ul>
	<li>sine_1 : a sinusoidal wave with a cycle period of 100 timesteps and an amplitude of 1.</li>
	<li>sine_2 : a sinusoidal wave with a cycle period of 1000 timesteps and an amplitude of 5.</li>
	<li>noise : a gaussian distribution of stochastic noise between -1 and +1.</li>
	<li>combined_signal : a sum of sine_1 and sine_2. This will be used as the Y target variable we are looking to predict and will NOT be included in the X training data that the autoencoder branch of MvTAe sees.</li>
</ul>

<p>
	The dataset is created in this way as to provide a way to test our autoencoder model for several important attributes. The first sinusoidal wave is a repeating pattern over time which will test the ability of our model to capture the sequential process of this pattern. The second sinusoidal wave creates a longer term cyclical sequence pattern which our model will not be able to see in full for each training example and hence it tests the models ability to capture cyclical trends. The noise dimension adds an extra dimension of redundant information to test the models ability to identify and disregard dimensions which do not contribute to the latent drivers of the data. Finally, the combined signal will test the ability of the predictive branch of MvTAe to combine signals from the two visible dimensions into this third hidden target dimension.
</p>
<p>
	In the autoencoder branch of the model this combined signal dimension is not used as input, since in this stage the aim is to create a latent vector representation of the visible X dimensions of the dataset. In the second-stage predictive branch the combined signal is used as the Y target for future predictions.
</p>
<p>
	To feed our model, the dataset is split into sliding windows of length N with step S between each window. This approach allows the training of our autoencoder branch to lookback across N temporal steps to determine relationship patterns within the temporal sequence. The Y targets of our first-stage autoencoder branch are the inverse of our inputs along the temporal axis. The Y targets of our second-stage predictive branch will be the <img src="http://latex.codecogs.com/svg.latex?t_{i+1}">combined_signal dimension for each window of <img src="http://latex.codecogs.com/svg.latex?t_{i-N}%20\rightarrow%20t_{i}">.
</p>

<p>The code for creating the normalized sliding windows across dimensions and the accompanying target variable is below</p>
<pre><code>idx_front = 0
idx_rear = window_size
features_x = ['sine_1', 'sine_2', 'noise']
feature_y = 'combined'

tr_data_windows_size = int(np.ceil((data['sine_1'][:idx_val_split].shape[0]-window_size-1)/step_size))
tr_data_windows = np.empty((tr_data_windows_size, len(features_x), window_size))
tr_data_windows_y = np.zeros(tr_data_windows_size)

i = 0
pbar = tqdm(total=tr_data_windows_size-1, initial=i)
while idx_rear + 1 &lt; data['sine_1'][:idx_val_split].shape[0]:
    # create x data windows
    for j, feature in enumerate(features_x):
        _data_window, _hi, _lo = norm(data[feature][idx_front:idx_rear])
        tr_data_windows[i][j] = _data_window
        
    # create y along same normalized scale
    _, hi, lo = norm(data[feature_y][idx_front:idx_rear])
    _y = norm(data[feature_y][idx_rear], hi, lo)[0]
    tr_data_windows_y[i] = _y
    
    idx_front = idx_front + step_size
    idx_rear = idx_front + window_size
    i += 1
    pbar.update(1)
pbar.close()

# reshape input into [samples, timesteps, features]
tr_data_size = tr_data_windows.shape[0]
tr_input_seq = tr_data_windows.swapaxes(1,2)
</code>
</pre>


<p>
	<img src="http://latex.codecogs.com/svg.latex?W_{normalized}%20=%20\frac{W_{(i-N)\rightarrow%20i}^{k}%20-%20min(W_{(i-N)%20\rightarrow%20i}^{k})}{max(W_{(i-N)%20\rightarrow%20i}^{k})%20-%20min(W_{(i-N)%20\rightarrow%20i}^{k})}">
	<br><span>Eqn. 1 Normalization process</span>
</p>

<p>
	As is standard practice when training deep neural networks for optimal converging performance, we normalize our data. As we are dealing with temporal data windows along multiple dimensions, we treat each window and each dimension within the window as independent in terms of normalization. What this means is that for each window W of dimension k we normalize the data independently of all other k dimensions within that window. For the normalization process itself we use standard MinMax Normalization. As such, the normalization process can be summed up as per eqn. 1.
</p>

<pre><code>def norm(data, hi=None, lo=None):
    hi = np.max(data) if not hi else hi
    lo = np.min(data) if not lo else lo
    if hi-lo == 0:
        return 0, hi, lo
    y = (data-lo)/(hi-lo)
    return y, hi, lo
</code>
</pre>


<p>
	<img src="http://latex.codecogs.com/svg.latex?W_{denormalized}%20=%20W_{(i-N)%20\rightarrow%20i}^{k}%20\times%20(hi_{i}^{k}%20-%20lo_{i}^{k})%20+%20lo_{i}^{k}">
	<br><span>Eqn. 2 De-normalization process</span>
</p>

<p>
	Furthermore, when used in real-world predictive applications it is usually advantageous for the final predictive output of the model to be on the absolute scale of the input data. As such, a de-normalization process is required to bring data back to the input scale. With MinMax normalization we normalize data using the min (lo) and max (hi) values of the data window and hence these values created during the normalization process are required for the de-normalization process. We define this de-normalization process as per eqn. 2.
</p>

<pre><code>def reverse_norm(y, hi, lo):
    x = y*(hi-lo)+lo
    return x
</code>
</pre>

<p>
	<img src="https://altumintelligence.com/assets/multivariate-temporal-autoencoder-for-predictive-reconstruction-of-deep-sequences/datawindows_subplots.png">
	<br><span>Normalized data window dimensions and Y target normalized with the hi, lo values from the X window</span>
</p>

<br>
<h2>Multivariate Temporal Autoencoder Model (MvTAe)</h2>

<p>
	<img src="https://altumintelligence.com/assets/multivariate-temporal-autoencoder-for-predictive-reconstruction-of-deep-sequences/mvtae_model_diagram.png">
	<br><span>High-level architecture diagram of the MvTAe model</span>
</p>

<p>
	The first-stage in our predictive problem is the representation of our multidimensional temporal sequences in an optimized vector format representing the features of the multivariate series in such a way that the full series dynamics can be captured. This process can more commonly be known as feature engineering and is usually a step that requires domain knowledge and a manual feature creation process when building approximations of latent drivers.
</p>
<p>
	The MvTAe model acts to compress the sequence into a hidden state vector representation in an unsupervised manner, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altumintelligence.com/articles/a/Multivariate-Temporal-Autoencoder-for-Predictive-Reconstruction-of-Deep-Sequences">https://altumintelligence.com/articles/a/Multivariate-Temporal-Autoencoder-for-Predictive-Reconstruction-of-Deep-Sequences</a></em></p>]]>
            </description>
            <link>https://altumintelligence.com/articles/a/Multivariate-Temporal-Autoencoder-for-Predictive-Reconstruction-of-Deep-Sequences</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615738</guid>
            <pubDate>Mon, 28 Sep 2020 12:11:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alar: The making of an open-source dictionary]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24615530">thread link</a>) | @ronakjain90
<br/>
September 28, 2020 | https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>ನಮಸ್ಕಾರ (Namaskāra)! This is not a post on fintech, or even technology for that matter. This is the story of a product of tenacity, selflessness, and passion; a product that will transcend and outlive most technology we know of. This is the story of a massive dictionary that will become the window to a language spoken by tens of millions of people for generations to come, a resource its author has donated to posterity. This is the story of V. Krishna, <a href="https://alar.ink/"><em>Alar</em></a>, his Kannada-English dictionary, and its accidental discovery and open sourcing at an unlikely place, a stock brokerage, Zerodha. This post is also a personal note, something I have not attempted in a long time.</p><h3 id="prologue">Prologue</h3><p>I have been running <a href="https://olam.in/">Olam</a>, an English-Malayalam and Malayalam-Malayalam dictionary, since 2010. It was built out of the frustration of not having an easily accessible online Malayalam dictionary, of the frustration at dictionary websites that insulted the reader’s intelligence with poor usability, terrible ad-ridden spamminess, and no respect for language. Olam’s website has stayed exactly the same for 10 years. It has an input box that responds to dictionary lookups in under ~50ms, exactly as it did in 2010. It is actively used by millions of Malayalam speakers.</p><p>The first version of the Olam corpus was seeded with unattributed word lists I scraped together from random parts of the web, and several thousand entries I entered myself. Since then, the English-Malayalam dictionary has been expanding slowly with crowdsourced entries.</p><p>The entire Olam corpus is <a href="https://olam.in/open">open source</a> (licensed under <a href="https://opendatacommons.org/licenses/odbl/summary/">OdBL</a>), or open data, rather. While the English-Malayalam corpus is crowdsourced, the Malayalam-Malayalam corpus (now known as the <em>Datuk Corpus</em>) was created out of the mammoth digitisation project the late <a href="https://www.asianetnews.com/pravasam/datuk-kj-joseph-passes-away-pm1xdr">“Datuk” K. J. Joseph</a> undertook in the late 90s, when he single-handledly digitised an out-of-copyright Malayalam-Malayalam dictionary along with many other books and posted them online at the expense of copious amounts of time out of his retirement. He was a Malayali settled in Malaysia, a prominent active social worker and educator. The Malaysian government conferred the title “Datuk” upon him in recognition of his exemplary services in the country, which then ended up being his nickname too. I do not know of the origin of the dictionary Datuk digtised, but it is poignant to think that the original author’s work lives on after a century.</p><p>I discovered the RTF file Datuk had posted a decade prior on an inactive Yahoo groups page around the time I was working on Olam. Needless to say, I was stumped by the scope of this project, and immediately started working on integrating it into Olam. It took more than two years of on and off work to convert the text from the original ASCII input to Unicode, and to clean, structure, and correct close to 200,000 entries. The dataset was named <em>Datuk Corpus</em>, and was published on Olam in 2013. I wrote to the Swathanthra Malayalam Computing (SMC) mailing list <a href="http://lists.smc.org.in/pipermail/discuss-smc.org.in/2013-May/015592.html">announcing it</a>, and we launched it with some fanfare at the SMC conference held in Thrissur, Kerala, that year. Datuk’s story was covered by the press, and his work was now open and available to everyone.</p><p>Shortly thereafter, I was connected to Datuk by an old friend of his I had met at the conference, and we spoke briefly on the phone. He had seen the news clip of the dictionary’s release, and was thrilled to know that his work was now accessible as he had originally intended. Open data lives on. He found it amusing that a random stranger had somehow unearthed a relic he had lost to the annals of internet history. Life is absurd like that, shaped in infinite ways by tiny, random events.</p><p>Datuk <a href="https://www.facebook.com/amma.org.my/posts/tribute-to-the-late-datuk-k-j-josephthe-late-datuk-k-j-joseph-was-a-prominent-ed/2157527197640248/">passed away in January 2019</a>. He was 89 years old. RIP Datuk. Your work’s utility will span generations. The data you created will proliferate and continue to be useful to humanity in ways we never imagined. Such is the beauty of open data. I consider it a privilege to have been able to speak to you just that one time.</p><h3 id="open-data">Open data</h3><blockquote><p><a href="https://en.wikipedia.org/wiki/Open_data">Open data</a> is the idea that some data should be freely available to everyone to use and republish as they wish, without restrictions from copyright, patents or other mechanisms of control.</p></blockquote><p>I shudder to think of a world without Wikipedia. The open data movement shares strong parallels with the Free and Open Source Software (FOSS) movement. The gist is that certain knowledge should be freely available to everyone with no restrictions and with one goal—collective advancement of humanity.</p><p>I consider dictionaries to be on top of that list. The stepping stone to language, the underpinning of civilisation. Dictionaries should be open, free, and easily accessible to everyone, everywhere. If we cannot share something as fundamental as language without motives of profit, we ought to do some serious introspection as members of an advanced civilisation.</p><p>An open data dictionary for every Indian language, the largest collection of open source dictionaries in the world, would be an immense resource for not only India but for humanity in general. Ideally, this is the kind of project governments should do. State governments could very easily partner with local universities and undertake the creation and maintenance of open data dictionaries.</p><p>That said, at Zerodha, we would be happy to fund projects to create high quality open data dictionaries if there are scholars out there working on them.</p><h3 id="a-kannada-dictionary">A Kannada dictionary</h3><p>I moved from Kerala to Bengaluru in early 2012 to get access to fast internet. Bengaluru is a melting pot of people from all over India, and English is the glue that holds the “IT sector” together. I can comprehend Kannada speech reasonably well and speak rather poorly, but cannot read the script, thanks to the lack of opportunities to learn over the many years spent between home, where we speak Malayalam, and work, an English speaking environment. With the guilt of not being able to learn Kannada, and the great satisfaction of having Olam as an open data corpus, I had been looking for ways to build a Kannada dictionary right after I had moved to Bengaluru.</p><p>Sometime in 2016, I presented the idea of having an open source Kannada dictionary created from scratch to Nithin. He was immediately on board to commission the project. A perk I enjoy, the privilege of having a resourceful backer who believes in public good. Not knowing where to start, I asked around a few places but nothing materialised for the next two years, and as always, I continued to bring up this conversation once in a while.</p><p>Then, sometime in October 2018, I randomly brought up the conversation again, and Srihari, who had just joined the tech team, happened to overhear it. He vaguely remembered that someone in his family had been associated with a dictionary for a long time. This would be one of those minuscule, random events that would significantly change the timeline; the <a href="https://en.wikipedia.org/wiki/Butterfly_effect">Butterfly effect</a> in action. I crossed my fingers and he soon setup a meeting with V. Krishna, the relative of his. Shortly thereafter, Srihari, Sharath (also from the tech team), and I went to <a href="http://www.kagapa.in/">KaGaPa’s</a> office to meet V. Krishna and to find out what exactly it was that Srihari remembered about him and a dictionary. KaGaPa (Kannada Ganaka Parishat) created the popular Nudi font and input method for Kannada, an important early innovation for digital Kannada, and V. Krishna had worked with them on several projects.</p><p>V. Krishna and Narasimhamurthy, KaGaPa’s proprietor, spoke passionately about Kannada literature and digitisation projects in the quaint little office room, surrounded by stacks of old Kannada books and literature. It was the perfect setting. Then, the extremely soft-spoken and mild-mannered V. Krishna fired up a computer and showed us his lifelong side project, his Kannada-English dictionary. Researched and written over a period of more than 40 years, 150,000+ Kannada words and 240,000+ English definitions, all neatly typed up in a Word document, complete with parts of speech tags and phonetic notations with diacritics for Kannada words. The ambition of the project, its scholarly quality, the depth of the data, the culmination of one man’s passion, perseverance, and tenacity over a lifetime, all lying in obscurity, stumbled upon by sheer coincidence. Absolutely mind blowing.</p><h3 id="v-krishna">V. Krishna</h3><figure><img src="https://zerodha.tech/static/images/vkrishna-alar.png" alt="V. Krishna's photo" height="150"></figure><p>V. Krishna was born in 1950 in the Malanayakana Halli village in Mysore district in Karnataka. He studied in a Kannada medium school, followed by a year at a pre-university college that he was forced to drop out of before moving to Bengaluru with his family in 1968.</p><p>He found a job at the Indian Agricultural Research Institute (IARI) in 1970. At IARI, around this time, noticing him struggle with the English language, his boss casually suggested that he procure a dictionary to learn English. This conversation would turn out to be pivotal, and would set V. Krishna on a lifelong journey of language research and scholarship, an amazing case of autodidacticism.</p><p>So, he took his boss’s advice and got himself an English dictionary and started studying it. Then he got himself another dictionary, and another, until he had five of them. At the same time, he took an interest in Kannada literature and started studying Kannada and English together. To help with this, he started jotting down notes, and at some point, began structuring them. A dictionary was being born. In the meanwhile, he took evening classes and obtained a commerce degree in 1976 from MES college, Malleshwaram.</p><p>Around 1980, <a href="https://en.wikipedia.org/wiki/Kannada_Sahitya_Parishat">Kannada Sahitya Parishattu</a> published a Kannada - English dictionary, and unsurprisingly, V. Krishna got himself a copy. He was surprised by the sheer number of errors he spotted—more than 200 in the first 50 pages. He wrote to the editor with his findings, and impressed by it, the editor met him in person in Bengaluru, where V. Krishna presented his manuscripts to him. Surprised by its quality, he suggested that V. Krishna continue his work and turn it into a full-fledged dictionary. This was the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/">https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615530</guid>
            <pubDate>Mon, 28 Sep 2020 11:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scorpion Transforming Computer Chair]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24615351">thread link</a>) | @jacquesm
<br/>
September 28, 2020 | https://www.cluvens.net/news/this-villainous-scorpion-can-transform | <a href="https://web.archive.org/web/*/https://www.cluvens.net/news/this-villainous-scorpion-can-transform">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.cluvens.net/news/this-villainous-scorpion-can-transform</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615351</guid>
            <pubDate>Mon, 28 Sep 2020 11:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebRTC Streaming Free Trial with full features]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24615349">thread link</a>) | @kerrarbone
<br/>
September 28, 2020 | https://antmedia.io/free-trial | <a href="https://web.archive.org/web/*/https://antmedia.io/free-trial">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
</section>
<section>
<div>
<div>
<div>
<div> <h2>What Does Your <span>14 days</span> Free Trial Include?</h2> <table> <tbody> <tr> <td>Ultra Low Latency<br> One-to-Many WebRTC Streaming</td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>End-to-End Latency </td> <td>0.5 Seconds (500ms)</td> </tr> <tr> <td>Scaling </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>RTMP(Ingesting) to WebRTC (Playing) </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Hardware Encoding (GPU) </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Adaptive Bitrate </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Secure Streaming </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>iOS &amp; Android WebRTC SDK </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>iOS &amp; Android RTMP SDK </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>H.264,H.265 and VP8 </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>RTMP, RTSP, MP4 and HLS Support </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>WebRTC to RTMP Adapter </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>360 Degree Live &amp; VoD Streams </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Web Management Dashboard </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>IP Camera Support </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Re-stream Remote Streams </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Open Source </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Simulcasting to Periscope </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Simulcast to Facebook &amp; Youtube </td> <td><img src="https://antmedia.io/img/icons/true-icon.svg"></td> </tr> <tr> <td>Support</td> <td>E-mail, On-site</td> </tr> </tbody> </table></div><div>
<h2><span>Free</span> Trial Sign Up</h2>
<div>
<div id="wpforms-32285"><form id="wpforms-form-32285" data-formid="32285" method="post" enctype="multipart/form-data" action="/free-trial/" data-token="13e5cb6f6af763785252f5ffbfd20a16"><div><p><label for="wpforms-32285-field_0">Name Surname <span>*</span></label></p><p><label for="wpforms-32285-field_1">Email <span>*</span></label></p><p><label for="wpforms-32285-field_5">Company Name</label></p><p><label for="wpforms-32285-field_2">Tell us about your project &amp; Let us help <span>*</span></label></p></div></form></div></div></div></div></div></div></section></div></div>]]>
            </description>
            <link>https://antmedia.io/free-trial</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615349</guid>
            <pubDate>Mon, 28 Sep 2020 11:07:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behavioral Programming and Tic Tac Toe (2018)]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24615316">thread link</a>) | @sktrdie
<br/>
September 28, 2020 | https://lmatteis.github.io/react-behavioral/ | <a href="https://web.archive.org/web/*/https://lmatteis.github.io/react-behavioral/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lmatteis.github.io/react-behavioral/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615316</guid>
            <pubDate>Mon, 28 Sep 2020 11:02:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Trust, and how we never see your Cryptocurrency Private Keys]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24615290">thread link</a>) | @timothy-quinn
<br/>
September 28, 2020 | https://blog.congruentlabs.co/building-trust-and-how-we-never-see-your-crypto-private-keys/ | <a href="https://web.archive.org/web/*/https://blog.congruentlabs.co/building-trust-and-how-we-never-see-your-crypto-private-keys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.congruentlabs.co/content/images/size/w300/2020/09/Cryptography-Banner.png 300w,
                            https://blog.congruentlabs.co/content/images/size/w600/2020/09/Cryptography-Banner.png 600w,
                            https://blog.congruentlabs.co/content/images/size/w1000/2020/09/Cryptography-Banner.png 1000w,
                            https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Cryptography-Banner.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.congruentlabs.co/content/images/size/w2000/2020/09/Cryptography-Banner.png" alt="Building Trust, and how we never see your Cryptocurrency Private Keys">
            </figure>

            <section>
                <div>
                    <p>Building trust with new products and services is difficult, but I'm hoping as the <a href="https://signata.net/">Product Manager for Signata</a> I can help build that trust with you by trying to be as open as possible in how our product works. You might simply ask why we don't just make our code base open source and be done with it? Well, making a product open source isn't as simple as flipping the switch to "public" for our source code - there are several larger considerations that have to take place around access controls to the repositories, ensuring we're in a state that we can actually make it public, test and release processes, legal requirements, intellectual property, and more.</p><p>We aren't discounting the idea of open sourcing our products (or at least some parts of them), but for now we're just a start-up and we just don't have the resources available to make that transition safely without sacrificing effort on actually building our products.</p><p>So, for now, I'll at least give some in-depth information on how we provide assurance to you, dear reader, that we never see your cryptocurrency private keys.</p><h2 id="so-what-s-a-private-key">So, what's a Private Key?</h2><p>Most people who've dabbled in cryptocurrency will run into the idea of <em>addresses</em> - these are effectively the names of our wallets that we can share with one-another to send coins around.</p><figure><img src="https://blog.congruentlabs.co/content/images/2020/09/image-19.png" alt=""><figcaption>An example of a LItecoin address</figcaption></figure><p>What that address actually is though is just a unique way of sharing a <em>public key</em>. When you start looking into the world of cryptography, you'll probably come across the concept of <strong>key pairs </strong>- these are <em>public </em>and <em>private </em>keys that are mathematically related to each other. A cryptocurrency address is just a form of <strong>Public Key</strong>, and if it's your own public key then you've likely got its corresponding <strong>Private Key</strong> as well. It's got the <em>public</em> part in it's name because you can safely share it around with the general public. The <em>private</em> part though is something you just keep to yourself - should you ever give anyone your private key, then they have the power to send your cryptocurrency wherever they want as if it was their own.</p><p>You can also think of it like internet banking - your address/public key is like your bank account number that you give out to people for them to send you money. The username and password you log in to your internet banking website with is like your private key. If you gave someone else your login details for your bank, then they'll be able to pretend to be you, and send your money wherever they like.</p><blockquote>Just as a side note: a cryptographic "key" is just a really large number - basically a number that is so large and complex that it's next to impossible to guess.</blockquote><p>Now that we've defined private keys, let's look at your YubiKeys.</p><h2 id="how-we-set-up-your-yubikey">How we set up your YubiKey</h2><p>One of the core design decisions we made with Signata was to remain zero-knowledge about our customer's private keys. If we were to have any knowledge of them, then that would just open us up to becoming a huge target for hackers. Being zero-knowledge comes with a price though - should you, dear reader, ever forget your passwords for Signata, then we don't have any way to recover your data for you.</p><p>So before we look at how we protect your cryptocurrency Private Keys, we first need to look at how exactly we set up your YubiKeys with our system, as they're integral to how we protect your cryptocurrency Private Keys.</p><p>When you first add a YubiKey to Signata, you'll get asked for your <strong>Recovery Passphrase</strong> and <strong>PIN</strong>:</p><figure><img src="https://blog.congruentlabs.co/content/images/2020/09/image-20.png" alt="" srcset="https://blog.congruentlabs.co/content/images/size/w600/2020/09/image-20.png 600w, https://blog.congruentlabs.co/content/images/2020/09/image-20.png 893w" sizes="(min-width: 720px) 720px"></figure><p>Your Recovery Passphrase is a 12 word mnemonic, which is converted into a "seed" - you set this up the first time you run the desktop application. We then convert that seed into a byte buffer, and then we make two ten thousand round PBKDF2 hashes of those bytes. The first hash is without any salt, and the second hash is with some salt that's saved in your account:</p><!--kg-card-begin: markdown--><pre><code>const seed = mnemonicToSeedSync(recoveryPassphrase).toString('hex');
const seedBuf = Buffer.from(seed, 'hex');
const h1 = forge.util.bytesToHex(forge.pkcs5.pbkdf2(seed, '', 10000, 512));
const h2 = forge.util.bytesToHex(forge.pkcs5.pbkdf2(h1, recoveryPassphraseSalt, 10000, 512));
</code></pre>
<!--kg-card-end: markdown--><p>The 2-step hashing process is designed to serve the purpose of letting us validate the first hash with some locally cached data that doesn't need to know the salt assigned to your account, and the second hash is stored in your Signata account so we can verify your hash on our back-end servers without you actually needing to send us your mnemonic. If someone managed to compromise our back-end servers and happened to be intercepting a check of your passphrase, then they couldn't actually see your mnemonic as they'd only see a PBKDF2 hash of it.</p><p>If the PBKDF2 hashes of your seed are correct for your account, then we move to the next step. We generate a new RSA2048 Encryption Key Pair for your YubiKey, and then we use AES128 encryption to encrypt it with the "seed" that we generated before. We then store that encrypted RSA Encryption Key Pair onto your account as a secure backup, and the RSA Key Pair is injected into the Encryption Key slot of your YubiKey.</p><blockquote>We use RSA2048 because that's the maximum most smartcard like devices can handle, including YubiKeys. We also use AES128 as there are no known weaknesses with that algorithm, and it doesn't have export restrictions like AES256 has in some countries.</blockquote><p>With your recovery passphrase you can, at any time, set up additional YubiKeys with the same Encryption Key installed in them if you want spare devices or you happen to lose your YubiKey.</p><p>Now, onto the cryptocurrency addresses themselves.</p><h2 id="how-we-protect-your-private-keys">How we protect your Private Keys</h2><p>With your YubiKey set up as above, we're then ready to start protecting your cryptocurrency addresses. Adding or Importing addresses works in exactly the same way, with the Import just relying on you providing the private key of the address instead of us creating a new one for you.</p><figure><img src="https://blog.congruentlabs.co/content/images/2020/09/image-21.png" alt="" srcset="https://blog.congruentlabs.co/content/images/size/w600/2020/09/image-21.png 600w, https://blog.congruentlabs.co/content/images/2020/09/image-21.png 889w" sizes="(min-width: 720px) 720px"></figure><p>When an address is created in Signata, the very first thing that happens is we generate a <strong>session key</strong>:</p><!--kg-card-begin: markdown--><pre><code>const sessionKey = await generateSessionKey();
const sessionKeyBuf = Buffer.from(sessionKey.randomString, 'ascii');
</code></pre>
<!--kg-card-end: markdown--><p>Then we RSA encrypt that session key using your YubiKey:</p><!--kg-card-begin: markdown--><pre><code>const encryptedSessionKey = await newDevice.encryptData(sessionKey.randomString);
</code></pre>
<!--kg-card-end: markdown--><p>And then we create your new address and AES encrypt the WIF and Private Key using that session key:</p><!--kg-card-begin: markdown--><pre><code>const encryptedWif = await aesEncrypt(
    sessionKeyBuf,
    Buffer.from(privateKey.toWIF(), 'utf-8'),
);
</code></pre>
<!--kg-card-end: markdown--><p>So why don't we just RSA encrypt the WIF and Private Key with the YubiKey and skip that session key step? Well encrypting data with the RSA algorithm is not designed for encrypting large amounts of data. In fact if you try to, a lot of libraries and devices will actually just refuse to process it if it's too big, because it's just too slow and inefficient.</p><p>Instead, RSA is designed to work <em>in conjunction with</em> symmetric algorithms like AES - you use AES to encrypt data, and then you use RSA to encrypt the much smaller AES encryption key. You end up with the ability to encrypt large amounts of data quickly and securely, but also the added usefulness of asymmetric encryption with RSA.</p><blockquote>If you're wondering how those session keys are generated - we actually do that in Python, generating them using your underlying Operating System random number generators.</blockquote><p>So in the end we store in the Signata database 3 values. Your session key encrypted by the YubiKey, the cipher text encrypted by the session key, and some salt that was generated for the encryption process.</p><!--kg-card-begin: markdown--><pre><code>wif = {
    sessionKey: encryptedSessionKey.encryptedData,
    cipherText: encryptedWif.encryptedData,
    salt: encryptedWif.salt,
};
</code></pre>
<!--kg-card-end: markdown--><p>To get access to your Private Key again, we just reverse the process - we decrypt the session key using your YubiKey, and then we decrypt the cipher text with the session key and salt together.</p><h2 id="how-it-all-fits-together">How it all fits together</h2><p>At a higher level, you can think of our zero-knowledge feature like this:</p><ol><li>Your recovery passphrase protects your YubiKeys. We have zero knowledge of your recovery passphrase.</li><li>Your YubiKeys protect your cryptocurrency addresses.</li><li>The Signata database never stores anything that isn't encrypted by you.</li></ol><p>I apologise if this got a little too deep into the weeds - a lot of terminology and concepts were thrown in without explanation, but I wanted to make sure anyone who already understands cryptography would at least get the gist of what we're talking about. If you have any questions, or want anything better explained, just let me know in the comments below :)</p><p>Start protecting your cryptocurrency today <a href="https://signata.net/">by downloading Signata for free</a>.</p>
                </div>
            </section>

            
            
        </article>
    </div>
</div></div>]]>
            </description>
            <link>https://blog.congruentlabs.co/building-trust-and-how-we-never-see-your-crypto-private-keys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615290</guid>
            <pubDate>Mon, 28 Sep 2020 10:57:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto Reading]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24615223">thread link</a>) | @dayve
<br/>
September 28, 2020 | https://danromero.org/crypto-reading/ | <a href="https://web.archive.org/web/*/https://danromero.org/crypto-reading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Below is a list of worthwhile posts about cryptocurrency. Best to read in chronological order:</p><div>
  <p>Â© 2020 | <a href="https://danromero.org/feed.xml">RSS</a> | <a href="https://twitter.com/dwr">@dwr</a> | <a href="mailto:hello@danromero.org" title="">hello@danromero.org</a></p>
</div></div>]]>
            </description>
            <link>https://danromero.org/crypto-reading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615223</guid>
            <pubDate>Mon, 28 Sep 2020 10:44:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Addiction Ruined the Internet]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24615106">thread link</a>) | @midef
<br/>
September 28, 2020 | https://www.superhighway98.com/addiction | <a href="https://web.archive.org/web/*/https://www.superhighway98.com/addiction">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-765880898db5f75e5dd3"><div><p>Before there was a World Wide Web, there was Usenet: a distributed forum and archive* that was designed for academia. </p><p>The freshmen who flooded Usenet groups each fall were reined-in and taught the ropes by established users. But, that noble task became impossible in September 1993. That was the month when "America Online" granted Usenet access to its customers.</p><h2><strong>The September that never ended</strong></h2><p>Recalling the parable of "<a href="https://en.wikipedia.org/wiki/Eternal_September">Eternal September</a>" is my admission that the Internet has been on the supposed road to ruin since before the World Wide Web was even born. Of course, the web was never a utopia and I don't believe that it should be one.</p><p>Nevertheless, I do believe that the Internet is becoming a tool that is used to divide, to misinform and to escape reality. There are many scapegoats, but modern-day poisons like social media are merely a new form of an old disease: addiction.</p><h2><strong>America offline</strong></h2><p>In the last two decades, America has suffered a staggering rise in <a href="https://apnews.com/article/f1f81ade0748410aaeb6eeab7a772bf7">alcohol consumption</a>, <a href="https://www.pewtrusts.org/en/research-and-analysis/blogs/stateline/2019/11/01/as-meth-use-surges-one-region-tries-to-combat-the-pull">methamphetamine use</a>, <a href="https://www.hsph.harvard.edu/nutritionsource/an-epidemic-of-obesity/">obesity</a>, <a href="https://www.americangaming.org/new/commercial-casino-gaming-revenue-reaches-41-7-billion-in-2018-an-all-time-high/">gambling</a>, <a href="https://www.debt.org/faqs/americans-in-debt/">consumer debt</a>, <a href="https://www.cdc.gov/injury/features/prescription-drug-overdose/index.html">prescription drug abuse</a>, <a href="https://www.pewresearch.org/politics/interactives/political-polarization-1994-2017/">political polarization</a>, <a href="https://www.cdc.gov/injury/features/prescription-drug-overdose/index.html">overdose deaths</a> and <a href="https://www.nimh.nih.gov/health/statistics/suicide.shtml">suicide</a>.</p><p>This rise in compulsive, self-destructive behavior predates the web, but the Internet is where those suffering from mental illness are spending an increasing amount of time. Meanwhile, technologists are actively trying to <a href="https://www.amazon.com/Hooked-How-Build-Habit-Forming-Products/dp/1591847788">exploit this sickness for profit</a>.</p><h2><strong>Addiction is a contagious disease</strong></h2><p>If something is addicting, it will ultimately result in <em>a</em>nger, <em>d</em>enial, <em>d</em>ouble-standards, <em>i</em>ntolerance, <em>c</em>ontrarianism, <em>t</em>rickery, <em>i</em>ntransigence, <em>n</em>egligence and <em>g</em>aslighting. Those who've lived with an addict know these forms of emotional abuse.</p><p>But, the side effects of this abuse aren't easily predicted.</p><p>A child with an alcoholic parent may grow up to shun alcohol as an adult, yet become addicted to seeking the love and attention of unavailable persons. Meanwhile, an available person, like a child, may turn to video games or social media to cope with the reality of having a cold and unloving parent. And so the cycle continues.</p><h2><strong>Sharing a digital household</strong></h2><p>When we visit Facebook, Twitter, YouTube, Reddit, comment sections and forums, we make ourselves vulnerable to emotional abuses that we carry into our offline lives. And what we do (or avoid doing) in our offline lives is reflected in our online behaviors.</p><h2><strong>Grant me the serenity…</strong></h2><p>I cannot “fix” other people, therefore, I cannot fix the web. But, if I’m courageous enough to admit my own shortcomings, I can work toward fixing myself.  Maybe the web will get better as a result.</p><p><a href="https://www.superhighway98.com/">&lt;- RETURN TO SUPERHIGHWAY 98</a></p><p><a href="https://www.superhighway98.com/seo">HOW SEO RUINED THE INTERNET -&gt;</a></p><p>###</p><p>*Google acquired the Usenet archive in 2001, and after letting it languish for more than a decade, <a href="https://www.vice.com/en_us/article/jp5a77/google-a-search-company-has-made-its-internet-archive-impossible-to-search">rendered it unsearchable in 2015</a>. </p><p>This is one of several ways that <a href="https://www.superhighway98.com/google">Google has ruined the Internet</a>.<br></p></div></div></div></div>]]>
            </description>
            <link>https://www.superhighway98.com/addiction</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615106</guid>
            <pubDate>Mon, 28 Sep 2020 10:28:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[View my personal Blog site]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24615075">thread link</a>) | @pr2tik1
<br/>
September 28, 2020 | https://pr2tik1.github.io/blog/ | <a href="https://web.archive.org/web/*/https://pr2tik1.github.io/blog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <div>
<p>Welcome to my personal blog page. I write mostly on deep learning and data science. I will be happy to hear your thoughts and feedback. 
View my recent posts below.</p>

<h2 id="-thought">💭 Thought</h2>

<hr>

<p>Inspired by Patrick Winston’s teachings(<a href="https://youtu.be/Unzc731iCUY">view here</a>) where he shares the formula of the quality of communication. 
For me, <b>Quality of work</b> is the combination of Knowledge, Practice and Persistence.</p>

<p><img src="https://pr2tik1.github.io/blog/images/Eqn.png" alt=""></p>

<h2 id="-medium-posts">📜 Medium Posts</h2>

<hr>

<p>View my post published on Medium,</p>

<ul>
  <li><a href="https://towardsdatascience.com/what-happens-to-programmers-in-2020-d04a6bd7452f?source=friends_link&amp;sk=a880dfdd6435c792d33b284c98705a62">What happens to developers in 2020?</a></li>
  <li><a href="https://towardsdatascience.com/exploring-neural-networks-and-their-fascinating-effectiveness-81ebc054cb16">Universal Approximation Theorem of Neural Networks</a></li>
  <li><a href="https://towardsdatascience.com/understanding-kaplan-meier-estimator-68258e26a3e4">Kaplan Meier Estimator</a></li>
  <li><a href="https://medium.com/towards-artificial-intelligence/neural-networks-from-scratch-a-brief-introduction-for-beginners-d3776599aaac?source=friends_link&amp;sk=701beeb7b1be2e6c85c641119ca35e72">Exploring Neural Networks</a></li>
</ul>

<hr>





  

  <!-- Hide posts if front matter flag hide:true -->
  
  

  <!-- Sort posts by rank, then date -->
  
  
  

 
  

   <!-- Assemble final sorted posts array -->
  
  <ul><li><div><p><img src="https://pr2tik1.github.io/blog/images/img.png">
      </p><div>
        <h3>
          <a href="https://pr2tik1.github.io/blog/pytorch/cnn/pca/t-sne/2020/09/08/Sketch-Recognition.html">
            Doodle Images Classification using PyTorch
          </a>
        </h3>
        <p>Multi-Class Image Classification using modified LeNet architecture(Convolutional Neural Network) implemented in PyTorch.</p>
          <p>Sep 8, 2020</p>
      </div>
  </div></li></ul>

    </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://pr2tik1.github.io/blog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615075</guid>
            <pubDate>Mon, 28 Sep 2020 10:22:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Visualize Supporting and Disputing Citations]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24615070">thread link</a>) | @darosati
<br/>
September 28, 2020 | https://scite.ai/visualizations/global-analysis-of-genome-transcriptome-9L4dJr?dois[0]=10.1038%2Fmsb.2012.40&dois[1]=10.7554%2Felife.05068&focusedElement=10.7554%2Felife.05068 | <a href="https://web.archive.org/web/*/https://scite.ai/visualizations/global-analysis-of-genome-transcriptome-9L4dJr?dois[0]=10.1038%2Fmsb.2012.40&dois[1]=10.7554%2Felife.05068&focusedElement=10.7554%2Felife.05068">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="scite-app"><div><div><p><a href="https://scite.ai/visualizations/global-analysis-of-genome-transcriptome-9L4dJr?dois[0]=10.1038%2Fmsb.2012.40&amp;dois[1]=10.7554%2Felife.05068&amp;focusedElement=10.7554%2Felife.05068">Announcing Visualizations: see scite Smart Citations in context. <span>Explore now.</span></a></p><div><div><div><div><div><p><a href="https://scite.ai/"><img alt="logo" src="https://d1lv4filxk1370.cloudfront.net/assets/images/beta-logo.svg"></a></p></div></div></div></div><div><div><div><div><div><p><label><span>Show mentioning cites</span></label></p><p><label><span>Hide unselected cites</span></label></p><p><label>Layout</label></p></div></div></div></div></div></div><div><div><div><div><div><h3>About us</h3><p>scite is a Brooklyn-based startup that helps researchers better discover and evaluate scientific articles through Smart Citationsâ€“citations that display the context of the citation and describe whether the article provides supporting or contradicting evidence. Scite is used by researchers from dozens of countries and is funded in part by the National Science Foundation and the National Institute of Drug Abuse of the National Institutes of Health</p><div><p><img loading="lazy" alt="national science foundation logo" src="https://d1lv4filxk1370.cloudfront.net/assets/images/nsf-logo.png"></p><picture><source srcset="https://d1lv4filxk1370.cloudfront.net/assets/images/nih-logo.webp" type="image/webp"><img loading="lazy" alt="national institute of health logo" src="https://d1lv4filxk1370.cloudfront.net/assets/images/nih-logo.jpg"></picture></div></div><div><h3>Contact</h3><div><p>hi@scite.ai</p><p>334 Leonard St, #6</p><p>Brooklyn, NY 11211</p></div></div></div><div><p><span>Copyright Â© <!-- -->2020<!-- --> scite Inc. All rights reserved.</span></p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://scite.ai/visualizations/global-analysis-of-genome-transcriptome-9L4dJr?dois[0]=10.1038%2Fmsb.2012.40&amp;dois[1]=10.7554%2Felife.05068&amp;focusedElement=10.7554%2Felife.05068</link>
            <guid isPermaLink="false">hacker-news-small-sites-24615070</guid>
            <pubDate>Mon, 28 Sep 2020 10:21:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Durability: NVMe Disks]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24614893">thread link</a>) | @ingve
<br/>
September 28, 2020 | https://www.evanjones.ca/durability-nvme.html | <a href="https://web.archive.org/web/*/https://www.evanjones.ca/durability-nvme.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h3>[ 2020-September-27 10:26 ]</h3>
<p>Durability is the guarantee that data can be accessed after a failure. It seems like this should be very simple: either your system provides durable data storage, or it does not. However, durability is not a binary yes/no property, and instead should be defined as the <em>kinds</em> of failures you want your data to survive. Since there is usually some performance penalty for durability, many systems provide a way for only "important" writes to be durable, while "normal" writes will eventually be durable, with no specific guarantee about when. Finally, durability is rarely tested, since <em>really</em> testing it involves cutting the power to computer systems, which is disruptive and hard to automate. Production environments are designed to avoid these failures, so bugs are rarely triggered and hard to reproduce.</p>

<p>I've recently been investigating the durability guarantees in cloud platforms. I decided to start at the beginning: what guarantees are provided by the disks we connect to computers? To find out, I read the relevant sections of the Non-Volatile Memory Express (NVMe) specification (version 1.4a), since it is the newest standard for high-performance SSDs. It also has an <a href="https://nvmexpress.org/developers/nvme-specification/">easy to find, freely available specification</a>, unlike the older SATA or SCSI standards that were originally designed for magnetic disks. In the rest of this article, I will attempt to summarize the durability NVMe devices provide. I believe that most of this should also apply to SATA and SCSI. NVMe was designed as a higher performance replacement for those protocols, so the semantics can't be too different.</p>


<h2>Ordering and atomicity</h2>

<p>Before we can discuss durability, we should discuss some basic semantics of NVMe writes. Commands are submitted to devices using a set of queues. At some time later, the device acknowledges that the commands have completed. There is no ordering guaranteed between commands. From Section 6.3: "each command is processed as an independent entity without reference to other commands [...]. If there are ordering requirements between these commands, host software or the associated application is required to enforce that ordering". This means if the order matters, the software needs to wait for commands to complete before issuing the next commands. However, read commands are guaranteed to return the most completed write (Section 6.4.2.1), although they may also return data from uncompleted writes that have been queued.</p>

<p>A related issue with concurrent updates is atomicity. If there are concurrent writes to overlapping ranges, what are the permitted results? The answer is there are no guarantees. Specifically, "After execution of command A and command B, there may be an arbitrary mix of data from command A and command B in the LBA [logical block address] range specified" (Section 6.4.2). This seems to permit literally any result in the case of concurrent writes, such as alternating bytes from command A and command B.</p>

<p>NVMe includes <em>optional</em> support for atomic writes, with different values for "normal operation" and after power failure. The couple of NVMe devices I looked at don't support atomic writes, but apparently some higher-end devices do. The device exposes the size of atomic writes so software can configure itself to use it. For example, <a href="https://mariadb.com/kb/en/atomic-write-support/">see the MariaDB documentation about atomic writes</a>. This can replace MySQL's "doublewrite buffer," which is a mechanism that provides atomic writes on devices that don't natively support them (nearly all disks).</p>

<p>Basically, NVMe provides "weak" semantics similar to shared memory in multi-threaded programs. There are no guarantees if there are concurrent operations. This means if the order of writes matters, the software needs to submit the commands and wait for them to complete, and never have concurrent writes to overlapping ranges.</p>


<h2>The Flush command</h2>

<p>Without special commands, NVMe provides no guarantees about what data will survive a power failure (Section 5.15.2.2, Figure 249 in the documentation about the Atomic Write Unit Power Fail (AWUPF) field and Section 6.4.2.1). My reading of this means devices are permitted to return an error for all ranges where writes were "in flight" at the time of failure. If you want to be completely safe, you should avoid overwriting critical data by using write-ahead logging. This matches the semantics I found during <a href="https://www.evanjones.ca/intel-ssd-durability.html">power fail testing of SATA magnetic hard drives and SSDs in 2010</a>.</p>

<p>The first NVMe mechanism that can be used to ensure data is durably written is the Flush command (Section 6.8). It writes everything in the write cache to non-volatile memory. More specifically, "The flush applies to all commands [...] completed by the controller prior to the submission of the Flush command" (Section 6.8). This means if you want a durable write, you need to submit the write, wait for it to complete, submit the flush, and wait for that to complete. If you submit writes after submitting the flush, but before it completes, they might also be flushed ("The controller may also flush additional data and/or metadata", section 6.8). Most importantly, if you issue a flush, and it fails in the middle, there is no guarantee about what writes might exist on disk. The disk could have any of the writes, with no relation to the order they were submitted or completed. It could also choose to return an error for all the ranges.</p>


<h2>Force Unit Access (FUA)</h2>

<p>The second mechanism to ensure durability is to set the Force Unit Access option on Write commands. This means that "the controller shall write that data and metadata, if any, to non-volatile media before indicating command completion" (Section 6.15 Figure 404). In other words, data written with a FUA write should survive power failures, and the write will not complete until that is true. Interestingly, you can also specify FUA on a Read command, which is a bit surprising. It forces the referenced data to be flushed to non-volatile media, before reading it (Section 6.9, Figure 374). This mean you can do a set of normal writes, then selectively flush a small portion of it by executing a FUA read of the data you want committed.</p>


<h2>Disabling write caching</h2>

<p>The last mechanism that may ensure durability is to explicitly disable the write cache. If an NVMe device has a volatile write cache, it must be controllable. This means you can disable it (Section 5.21.1.6). It appears to me that if the cache is disabled, then every write must not complete until it is written to non-volatile media, which should be equivalent to setting the FUA bit on every write. However, this is not clearly described in the specification, and I suspect this is rarely used.</p>


<h2>Devices with power loss protection</h2>

<p>Finally, it is worth pointing out that some disks provide "power loss protection." This means the device has been designed to complete any in-flight writes when power is lost. This can be implemented by providing backup power with a supercapacitor or battery that is used to flush the cache. In theory, these devices should show that they do not have volatile write cache, so software could detect that and just use normal writes. However, these devices should ideally also treat FUA writes the same as non-FUA writes, and ignore cache flushes. As a result, I think it is best to design software for disks that have caches, since it can then work with any storage device. If you are using a device with power loss protection, you should still get better performance and some additional protection from failures.</p>

</div></div>]]>
            </description>
            <link>https://www.evanjones.ca/durability-nvme.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614893</guid>
            <pubDate>Mon, 28 Sep 2020 09:52:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Type Systems Explained with Examples]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24614788">thread link</a>) | @thanato0s
<br/>
September 28, 2020 | https://thevaluable.dev/type-system-explained/ | <a href="https://web.archive.org/web/*/https://thevaluable.dev/type-system-explained/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
        

        <section>
            
                <picture>
                    
                        <source srcset="https://thevaluable.dev/images/2020/type_system/type_psycho.webp" type="image/webp">
                    
                    <img src="https://thevaluable.dev/images/2020/type_system/type_psycho.jpg" alt="The Joker is just a type of psychopath">
                </picture>
            

            <p>“My language is better because it has a strong type system!” screams Dave, your colleague developer, trying to push the programming language Cobol for the next micro-service of your company.</p>
<p>Among developers, discussions about programming languages and their type systems can get quickly emotional. During these discussions, we often hear the words “type systems”, “data type”, “type inference”, “static typing”, “weak typing”, “coercion”, and more.</p>
<p>The goal of this article is to see the meaning of all these words with examples, for you to have good foundations and understand the type system of your favorite programming language. More precisely, we’ll see:</p>
<ul>
<li>What are types and why we need them.</li>
<li>When type checking occurs.</li>
<li>What are primitive types, composite types, and Abstract Data Types (ADT).</li>
<li>Type declaration and changing types can be implicit or explicit.</li>
<li>Types and functions.</li>
<li>What is type strength.</li>
<li>What is type safety.</li>
</ul>
<p>I’ll use two different languages to illustrate the ideas, Golang and PHP. If you don’t know them, don’t worry! The examples are straightforward and easy to understand.</p>
<p>I encourage you to use some <a href="https://repl.it/languages/php_cli" target="_blank" rel="noopener">PHP interpreter online</a> and the <a href="https://play.golang.org/" target="_blank" rel="noopener">Go playground</a> while reading, to play and experiment by yourself. This will help you understand the different concepts.</p>
<p>I won’t go into the gory details here. As you’ll see, it’s difficult to generalize something which is specific to a programming language. Yet, this article will give you a good overview of the usual properties of most type systems.</p>
<p>We’ll go progressively from clear waters to the muddy ideas, so take your rubber boots, get ready for the swamp, and let’s go!</p>
<h2 id="whats-a-type">What’s a Type?</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/type_system/state_not_type.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/type_system/state_not_type.jpg" alt="State and types are different">
</picture>



<p>A type system is made of types. I know, it’s mind-blowing. These types are also called <em>data types</em>. What are they?</p>
<h3 id="syntax-and-semantics">Syntax and Semantics</h3>
<p>First, let’s clarify the difference between the <em>syntax</em> and the <em>semantics</em> of a programming language.</p>
<p>For example. the syntax of your mother tongue is the set of rules dictating the structure of the sentences. For many spoken languages, you’ll need a subject and a verb for your sentence to be correct. Programming languages have instead different constructs like <em>expressions</em>, <em>control structures</em>, or <em>statements</em>.</p>
<p>For example, for a <em>if</em> statement to be syntactically correct in PHP, you’ll need:</p>
<ul>
<li>A condition.</li>
<li>Some parenthesis.</li>
<li>Some curly brackets.</li>
</ul>
<p>Something like that: <code>if (1 == 1) { echo "I knew it!"; }</code>.</p>
<p>The semantics, on the other hand, is the meaning behind the constructs. For example, the semantics of an <em>if</em> statement can be explained as follows:</p>
<ol>
<li>The condition is executed.</li>
<li>If the condition is true, the body of the statement is executed.</li>
<li>If the condition is false, the body of the statement is not executed.</li>
<li>The execution continues.</li>
</ol>
<p>Why do we need syntax and semantics? It’s meant to communicate with two different kinds of entities:</p>
<ul>
<li>Your colleagues developers need to understand what the heck you did.</li>
<li>The computer needs to “understand” the instructions to execute them.</li>
</ul>
<h3 id="definition-of-a-type">Definition of a Type</h3>
<p>To come back to our subject, a type can attach semantics to data. For example, in PHP:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>
<span>$integer</span><span>;</span>

<span>echo</span> <span>gettype</span><span>(</span><span>65</span><span>)</span> <span>.</span> <span>"</span><span>\n</span><span>"</span><span>;</span>
<span>// =&gt; integer
</span><span></span>
<span>$integer</span> <span>=</span> <span>65</span><span>;</span>
<span>echo</span> <span>gettype</span><span>(</span><span>$integer</span><span>)</span> <span>.</span> <span>"</span><span>\n</span><span>"</span><span>;</span>
<span>// =&gt; integer
</span></code></pre></div><p>In Mathematics, 65 is part of the set of integers, so PHP consider the value 65 as type integer. Your variable <code>$integer</code> has the value 65 too, so it’s an integer, too.</p>
<p>When you assign 65 to the variable <code>$integer</code>, you give it a semantics it didn’t have when we declared it, on the second line. This semantics will let you know what you can do with the variable.</p>
<p>We can conclude that:</p>
<ul>
<li>A type gives semantics to a piece of data.</li>
<li>A type is a set of value. For the type integer, it will be a range of decimals. For the type string, it will be a range of possible strings.</li>
</ul>
<h2 id="why-do-we-need-types">Why Do We Need Types?</h2>
<h3 id="representation-and-semantics">Representation and Semantics</h3>
<p>When you declare a variable and assign it a value, the memory hold this value in <em>binary</em>. Our counting system is <em>decimal</em>, which means that the numbers we know and use everyday are very different in binary:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$integer</span> <span>=</span> <span>65</span><span>;</span> <span>// Decimal notation
</span><span></span>
<span>printf</span><span>(</span><span>"Binary notation of %d: %b </span><span>\n</span><span>"</span><span>,</span> <span>$integer</span><span>,</span> <span>$integer</span><span>);</span>
<span>// =&gt; Binary notation of 65: 1000001 
</span></code></pre></div><p>Binary is just another way to represent numbers, <em>and only numbers</em>.</p>
<p>Dave, your colleague developer, is full of questions while reading these lines. “How does a character, such as ‘A’, is saved in memory?”, he wonders. “It’s not a number! It can’t be represented in binary!”.</p>
<p>Dave is right. The character has to be converted first into a decimal number, following the <a href="https://en.wikipedia.org/wiki/ASCII" target="_blank" rel="noopener">ASCII standards</a>. Then, this <em>ASCII code</em> is saved in memory.</p>
<p>Now, let’s try this:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$integer</span> <span>=</span> <span>65</span><span>;</span>
<span>printf</span><span>(</span><span>"Binary representation: %b </span><span>\n</span><span>"</span><span>,</span> <span>$integer</span><span>);</span>
<span>// =&gt; Binary representation: 1000001
</span><span></span>
<span>$character</span> <span>=</span> <span>'A'</span><span>;</span>
<span>$ascii</span> <span>=</span> <span>ord</span><span>(</span><span>'A'</span><span>);</span> <span>// Ascii code of 'A'.
</span><span></span><span>printf</span><span>(</span><span>"Ascii code: %d </span><span>\n</span><span>"</span><span>,</span> <span>$ascii</span><span>);</span>
<span>// =&gt; Ascii code: 65
</span><span></span>
<span>printf</span><span>(</span><span>"Binary representation: %b </span><span>\n</span><span>"</span><span>,</span> <span>$ascii</span><span>);</span>
<span>// =&gt; Binary representation: 1000001 
</span></code></pre></div><p>The integer 65 and the string ‘A’ have the same binary representation in memory!</p>
<p>Dave is confused. In despair, he asks the sky: “How the hell our program knows that <code>$integer</code> is equal to 65, and <code>$character</code> is equal to <code>'A</code>’? How?”. Indeed, in memory, the two values of <code>$character</code> and <code>$integer</code> are exactly the same: <code>1000001</code>. When we use these two variables in our code, the type system of our language will <em>interpret</em> the two values in memory, and it will decide what is a character and what is an integer.</p>
<p>This is important to understand, since this interpretation is not always accurate for some types, like floating point numbers.</p>
<p>A type will determine as well how you store a value in memory. For a character and an integer, we saw that they are stored the same way. The way to store floating point numbers, for example, is quite different.</p>
<p>The memory storage is nicely abstracted by the type system for us, developers, not to think about these confusing 0 and 1. You can then focus on more important problems, at least when the abstraction doesn’t leak. If you’re not sure what’s an abstraction, I wrote <a href="https://thevaluable.dev/abstraction-software-development/">a detailed article about it</a>.</p>
<h3 id="a-set-of-rules">A Set of Rules</h3>
<p>A type system is as well a set of rule, more or less strict. You can’t do everything you want with some types.</p>
<p>Let’s take another example:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>printf</span><span>((</span><span>3</span> <span>+</span> <span>"Hello World!"</span><span>)</span> <span>.</span> <span>"</span><span>\n</span><span>"</span><span>);</span>
<span>// =&gt; PHP Warning:  A non-numeric value encountered in /home/myusername/phpgoodies/test.php on line 3
</span><span>// =&gt; 3
</span><span></span>
<span>printf</span><span>(</span><span>"The execution continue!"</span><span>);</span>
<span>// =&gt; The execution continue!
</span></code></pre></div><p>This code makes little sense. I try to reinvent Mathematics by adding the integer 3 to a string. PHP will throw a warning, but it will still give a result, <code>3</code>. When you violate the rules of a type system, the outcome can range between these two extremes:</p>
<ol>
<li>The interpreter or compiler will silently try to fix the problem and continue.</li>
<li>The interpreter or compiler will throw an error and stop.</li>
</ol>
<p>In the case of our example, PHP will throw a warning, but the execution will still continue. You can even get rid of the warning in the infamous <code>php.ini</code>.</p>
<p>To compare with another language, let’s take the exact same thing in Golang:</p>
<div><pre><code data-lang="golang"><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>3</span> <span>+</span> <span>"Hello World"</span><span>)</span>
    <span>// =&gt; invalid operation: 3 + "Hello World" (mismatched types untyped int and untyped string)
</span><span></span>    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"The execution continue!"</span><span>)</span>
<span>}</span>
</code></pre></div><p><em><a href="https://play.golang.org/p/2JEY0GmHnYF" target="_blank" rel="noopener">Playground</a></em></p>
<p>The compiler will grant you with an error and your program won’t even be compiled.</p>
<h2 id="built-in-types-vs-our-own-abstractions">Built-in Types vs Our Own Abstractions</h2>
<p>Programming languages, more often than not, have a whole set of types you can use, out of the box. These types are called <em>primitive types</em>. For example: <code>integer</code>, <code>boolean</code>, <code>float</code>, and more.</p>
<p>Often, you’ll be able to use as well <em>composite types</em>, a type containing multiple values, and possibly multiple primitive types. It’s what we call more commonly <em>data structures</em>.</p>
<p>For example, an array is a composite type:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>$integerArray</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>];</span>
<span>$multipleTypeArray</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>"two"</span><span>,</span> <span>5.4</span><span>];</span>

</code></pre></div><p>The rules attached to these data types are imposed by the compiler (or the interpreter) of your language of choice.</p>
<p>Since the raise of the <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.136.3043&amp;rep=rep1&amp;type=pdf" target="_blank" rel="noopener">Abstract Data Types</a> (ADT), you have the power, in high level programming languages, to create your own types. For example, in PHP:</p>
<div><pre><code data-lang="php"><span>&lt;?php</span>

<span>class</span> <span>Shipment</span>
<span>{</span>
    <span>public</span> <span>function</span> <span>send</span><span>()</span>
    <span>{</span>
        <span>echo</span> <span>"Send powerful shipment!"</span><span>;</span>
    <span>}</span>
<span>}</span>

<span>$shipment</span> <span>=</span> <span>new</span> <span>Shipment</span><span>();</span>
<span>$shipment</span><span>-&gt;</span><span>send</span><span>();</span>
</code></pre></div><p>When you write <code>$shipment = new Shipment()</code>, you create an instance of the class <code>Shipment</code>. The object <code>$shipment</code> can be considered as well of type <code>Shipment</code>.</p>
<p>When you think about it, a type can be seen as a set of possible values, a category, or a group. A class has the <a href="https://www.merriam-webster.com/dictionary/class" target="_blank" rel="noopener">same definition (see entry 3)</a>.</p>
<p>We can say as well that the object <code>$shipment</code> is an abstraction of its class, and its interface (the way you interact with the abstraction) is the method <code>send()</code>.</p>
<p>We created some rules for our new type:</p>
<ul>
<li>The only interface available is the method <code>send()</code>.</li>
<li>The method <code>send()</code> return a string, not an integer.</li>
</ul>
<p>In Golang, you don’t have classes, but you can create custom types, too:</p>
<div><pre><code data-lang="golang"><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
<span>)</span>

<span>type</span> <span>minute</span> <span>int</span>

<span>func</span> <span>(</span><span>m</span> <span>minute</span><span>)</span> <span>second</span><span>()</span> <span>int</span>  <span>{</span>
    <span>return</span> <span>int</span><span>(</span><span>m</span><span>)</span> <span>*</span> <span>60</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>var</span> <span>min</span> <span>minute</span>
	<span>min</span> <span>=</span> <span>2</span>
	<span>fmt</span><span>.</span><span>Printf</span><span>(</span><span>"%d minutes are %d seconds"</span><span>,</span> <span>min</span><span>,</span> <span>min</span><span>.</span><span>second</span><span>())</span>
    <span>// 2 minutes are 120 seconds
</span><span></span><span>}</span>
</code></pre></div><p><em><a href="https://play.golang.org/p/rm1aRW2vZip" target="_blank" rel="noopener">Playground</a></em></p>
<p>In that case, the new type <code>minute</code> gets the same set of rules as the type <code>int</code>. Then, you can attach methods to this new type <code>minute</code>, like the method <code>second()</code>.</p>
<h2 id="type-checking">Type Checking</h2>

<picture>
    <source srcset="https://thevaluable.dev/images/2020/type_system/type_wizard.webp" type="image/webp">
    <img src="https://thevaluable.dev/images/2020/type_system/type_wizard.jpg" alt="Some types are obvious">
</picture>



<p>If types push us to respect some rules, a programming language need an algorithm to check if we respect them. This is called <em>type checking</em>.</p>
<p>Even if type systems can be very similar or very different, depending on the programming language, we are humans, so we need to group these disparate things in categories to understand them.</p>
<p>There are two important categories of type checking: <em>static type …</em></p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thevaluable.dev/type-system-explained/">https://thevaluable.dev/type-system-explained/</a></em></p>]]>
            </description>
            <link>https://thevaluable.dev/type-system-explained/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614788</guid>
            <pubDate>Mon, 28 Sep 2020 09:38:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do things that don't require scale]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24614691">thread link</a>) | @davnicwil
<br/>
September 28, 2020 | https://davnicwil.com/do-things-that-dont-require-scale/ | <a href="https://web.archive.org/web/*/https://davnicwil.com/do-things-that-dont-require-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="41"><div data-reactid="42"><div data-reactid="43"><p data-reactid="45">If you're interested in startups, "Do things that don't scale" is something you've likely heard. To me it's execution advice - in the beginning use your relatively small size as a strength by doing things that have outsized short term impact but are infeasible in the long run at scale.</p><p data-reactid="46"><!-- react-text: 47 -->Here's a corollary for the business idea itself: also make sure you start by doing things that don't <!-- /react-text --><span data-reactid="48">require</span><!-- react-text: 49 --> scale.<!-- /react-text --></p><p data-reactid="51">If your small size is the only advantage you have for execution, you'd better make sure the actual business idea works when it's all you have, too, because execution doesn't matter if the idea fundamentally won't work.</p><p data-reactid="52">It sounds obvious, but it's a mistake many people make - I've made it myself repeatedly - and it's especially hard to spot when you're caught up in how great you think an idea is. It might indeed be great, but you're just not in a position to make it work when you're starting from scatch.</p><p data-reactid="53"><!-- react-text: 54 -->You can do things that don't scale to accelerate a good idea, but by definition you actually can't do that if the idea itself<!-- /react-text --><!-- react-text: 55 --> <!-- /react-text --><span data-reactid="56">requires</span><!-- react-text: 57 --> scale. The idea has to work on day 1, for customer 1.<!-- /react-text --></p><p data-reactid="59">A common root of the issue, I believe, is looking at already successful products and imagining how they could be iterated upon or diverged from in new and interesting ways. Such divergent ideas are often very reasonable, good even, the problem is that they require the same scale to work as the products they are based upon.</p><p data-reactid="60"><!-- react-text: 61 -->It's all too easy to ignore that part, or convince yourself that the huge scale is somehow a positive since it proves there's a strong market for this product. It's the other way round: often the strong market &amp; huge scale <!-- /react-text --><span data-reactid="62">are</span><!-- react-text: 63 --> the product.<!-- /react-text --></p><p data-reactid="65">Here's a few good ways to think about whether your idea is one that requires scale or not. Of course every product is different, and there are many more, but following the 80% rule I think most ideas can be caught with the following:</p><p data-reactid="66">First, look at the history of the product it's based upon or one it's similar to. Did it come out of an already huge company? If not, how did it evolve as it scaled? Did it keep roughly the same manifestation and business model, or did these change substantially? Be skeptical if so.</p><p data-reactid="67">Second, does it have network effects? These are obvious in B2C, less so in B2B. Be skeptical if you have a per-seat pricing model and your strategy is bottom-up expansion within organisations starting from a few accounts. Be extra skeptical if these accounts are free.</p><p data-reactid="68">Third, how synchronous and mission critical is it? Be skeptical if it going down would cause interruption to workflows that couldn't be worked around or deferred. Be incredibly skeptical if this is true round the clock and on weekends. That kind of service level implies significant and robust automation and support, which require scale.</p><p data-reactid="69">Fourth, how much does the business model depend on volume? Losing a bit of money on first customers as you bootstrap and learn is not an issue. Be skeptical, though, if this would need to be sustained to bootstrap your way to some required volume which is quite a way beyond those first few customers.</p></div></div></div></div>]]>
            </description>
            <link>https://davnicwil.com/do-things-that-dont-require-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614691</guid>
            <pubDate>Mon, 28 Sep 2020 09:23:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of XML]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 115 (<a href="https://news.ycombinator.com/item?id=24614404">thread link</a>) | @tannhaeuser
<br/>
September 28, 2020 | https://blog.frankel.ch/defense-xml/ | <a href="https://web.archive.org/web/*/https://blog.frankel.ch/defense-xml/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting"> <meta itemprop="mainEntityOfPage" content="//defense-xml/"> <meta itemprop="description" content="">  <figure itemscope="" itemprop="image" itemtype="http://schema.org/ImageObject"> <meta itemprop="url" content="https://blog.frankel.ch/assets/resources/defense-xml/XML_icon.svg"> </figure> <section> <div itemprop="articleBody"> <p>When I started my career, XML was ubiquitous. The meta-information in a Java JAR file - the manifest - follows a proprietary format. But Java EE designers built it from the ground up on XML: meta-information of all artifacts is in XML format <em>e.g.</em> <code>web.xml</code>, <code>ejb-jar.xml</code>, <code>application.xml</code>, etc.</p> <p>Java EE is one example I experienced personally. But XML was everywhere in the enterprise world at the time. Its prevalence manifested itself in two areas: configuration and data transfer.</p> <p>Ever since then, it would be an euphemism to say XML has been losing in popularity. Other formats, such as JSON and YAML, have replaced it in the hearts of developers. In this post, I’d like to:</p> <ul><li><span>Explore some of the reasons why the mighty XML has fallen</span></li><li><span>Raise some downsides of the popular alternatives</span></li><li><span>And describe how XML already solved those problems</span></li></ul> <div> <h2 id="the-downfall-of-xml">The downfall of XML</h2> <div> <p>I think there are several reasons that led to the downfall of XML. It’s not a single one, but the conjunction of them that led to the current state.</p> <div> <h3 id="associated-with-enterprise">Associated with "Enterprise"</h3> <p>I’m afraid the worst flaw of XML is its close association with the enterprise world. As everybody knows, Enterprise is notoriously bad - by definition: bloated, heavy, not nimble, etc. And yes, that’s sarcasm if you wondered.</p> <p>In general, perception trumps truth. Developers are no different in that regard. In the end, that’s how Hype-Driven Developers - and most developers, perceive XML nowadays.</p> </div> <div> <h3 id="lack-of-integration-with-front-end">Lack of integration with front-end</h3> <p>One of the main usages of XML was in the realm <a href="https://en.wikipedia.org/wiki/SOAP" target="_blank" rel="noopener">SOAP web services</a>. Let’s be frank about it: the ease of consuming those web services from JavaScript and/or the browser is not spectacular.</p> <p>It' no wonder that JavaScript Object Notation, <em>aka</em> JSON became a <em>de facto</em> standard. JSON brought <a href="https://en.wikipedia.org/wiki/Representational_state_transfer" target="_blank" rel="noopener">REST</a> along with it. As its name implies, JSON is JavaScript native, while XML is not.</p> </div> <div> <h3 id="steep-first-steps">Steep first steps</h3> <p>JSON is quite easy to start with, YAML even more so. Even with bare XML, one has the concept of namespaces, which are not beginner-friendly. XML allows one document to use elements from different namespaces. On the flip side, it makes designing simple documents more complicated.</p> <p>XML has a lot of powerful features, but all this power can be confusing to beginners. I willingly admit that they make easy things more complex than they should.</p> </div> <div> <h3 id="performance">Performance</h3> <p>I’ve stumbled upon the performance "argument" a couple of time. This is usually "proven" by using a sample describing the same in XML, JSON and YAML. Because of its opening <strong>and</strong> closing tags, the writer shows that XML is quite noisy compared to the other two.</p> <p>IMHO, this argument is shallow, as all 3 formats are text-based. Thus, you can - and should - compress files. Parsing might be a bit slower, but it depends a lot on the exact parser (and the associated technology stack). In the end, the overhead of transmitting and parsing in XML - if any - is negligible compared to the total time in the whole use-case.</p> <p>People who favor YAML over JSON use the same reasoning: less characters.</p> </div> <div> <h3 id="abuse">Abuse</h3> <p>The above reasons are more or less congruent with XML. Yet, I’m more than willing to admit architects have been abusing XML. I’ve personally seen SOAP webservices with payload in the order of several megabytes. At that time, you might imagine the performance of such design was not stellar.</p> </div> </div> </div> <div> <h2 id="failings-of-alternatives">Failings of alternatives</h2> <div> <p>JSON, YAML &amp; al. all have their own failings. Here’s a sample of them:</p> <ul><li><span>JSON has no comments. The most usual fallback is to use the <code>"_comment"</code> property.</span><div> <div> <pre><code data-lang="json"><span>{</span><span>
  </span><span>"foo"</span><span>:</span><span> </span><span>{</span><span>
    </span><span>"_comment"</span><span> </span><span>:</span><span> </span><span>"My important comment"</span><span>,</span><span>
    </span><span>"bar"</span><span>:</span><span> </span><span>true</span><span>
  </span><span>}</span><span>
</span><span>}</span></code></pre> </div> </div></li><li><span>YAML has no governing body. Individuals manage the specification.</span></li><li><span>YAML has <strong>22 ways to write booleans</strong> - no less!</span></li></ul> <div> <div> <div> <blockquote> <p>Anyone who uses YAML long enough will eventually get burned when attempting to abbreviate Norway.</p> </blockquote>  </div> </div> </div> <div> <div><blockquote><div lang="en" dir="ltr"><p>YAML is to config syntaxes what Python is to programming languages. Seriously, significant whitespaces?</p><p>Have fun with a 500 lines of YAML to configure your Kubernetes deployment, and come back to explain why *you* hate it.</p></div>— Nicolas Frankel (@Home for a long time I believe) (@nicolas_frankel) <a href="https://twitter.com/nicolas_frankel/status/1273888063463325697?ref_src=twsrc%5Etfw">June 19, 2020</a></blockquote>  </div> </div> <p>To cope with the above, other formats have poped-up:</p> <ul><li><span><a href="https://github.com/toml-lang/toml" target="_blank" rel="noopener"><abbr title="Tom’s Obvious, Minimal Language">TOML</abbr></a> draws its inspiration from the <a href="https://en.wikipedia.org/wiki/INI_file" target="_blank" rel="noopener"><code>.ini</code></a> format. It allows nested hierarchies of properties</span></li><li><span>Lightbend pushes the <abbr title="Human-Optimized Config Object Notation">HOCON</abbr> format:</span></li></ul> <div> <div> <div> <blockquote> <p>This is an informal spec, but hopefully it’s clear.</p> </blockquote>  </div> <p>This one statement doesn’t fill me confidence.</p> </div> </div> </div> </div> <div> <h2 id="the-original-sin-the-lack-of-grammar">The original sin: the lack of grammar</h2> <div> <p>Whatever the format, regardless of their own specific downsides, one of the most important issue is for clients to decide if the read data is <em>correct</em> or not.</p> <p>When using JSON and YAML, the different clients need to provide <em>ad hoc</em> validation. Issues arise when the provider changes the data format:</p> <ol><li><span>How to make clients aware that the format changed?</span></li><li><span>What information to communicate to the client about the format change?</span></li><li><span>How to keep validation synchronized across clients?</span></li></ol> <p>XML has this issue solved since the beginning by providing a <strong>grammar</strong>. A grammar plays the same role for a XML document as constraints and types in a SQL database. The most important difference is that you can externalize the grammar.</p> <p>Several XML grammar implementations are available: <a href="https://www.w3.org/XML/1998/06/xmlspec-report-19980910.htm" target="_blank" rel="noopener">Document Type Definition</a>, <a href="https://www.w3.org/XML/Schema" target="_blank" rel="noopener">XML Schema</a>, <a href="https://relaxng.org/" target="_blank" rel="noopener">Relax NG</a>, etc. The most widespread one is XML Schema. Since a XML Schema is also written in XML format, a web server can host it. Then you can reference it by a publicly-accessible URL.</p> <p>This approach solves the above issues: when a client receives an XML document, the former looks at the XML Schema URL. It can then fetch it, and check that the data conforms to the schema.</p> <p>Changing the data format is as simple as versioning the XML Schema file, and publishing it under a new URL.</p> </div> </div> <div> <h2 id="other-benefits-of-xml">Other benefits of XML</h2> <div> <p>In this section, I’d like to list a couple of benefits of using XML.</p> <div> <dl> <dt>Public open stewardship</dt> <dd> <p>XML is not under the stewardship of a single person or a company, but of a <abbr title="Non-Governmental Organization">NGO</abbr>, namely the <a href="https://www.w3.org/" target="_blank" rel="noopener">W3C</a>. A W3C specification has a <a href="https://www.w3.org/2019/Process-20190301/" target="_blank" rel="noopener">publicly documented process and defined lifecycle</a>.</p> </dd> <dt>Battle-proven</dt> <dd> <p>XML is not hype, but benefits from plenty of documentation, blog posts, and <a href="https://stackoverflow.com/questions/tagged/xml" target="_blank" rel="noopener">FAQs</a> available</p> </dd> <dt>Composable</dt> <dd> <p>While XML doesn’t strictly enforces namespaces, it’s considered a good practice. This way, similarly-named entities defined in different namespaces can co-exist in the same document without confusion about semantics.</p> </dd> <dt>Different flavors</dt> <dd> <p>XML parsing comes into two flavors:</p> <ol><li><span>Tree-based parsing <em>i.e.</em> <a href="https://dom.spec.whatwg.org/" target="_blank" rel="noopener">Document Object Model</a>. It loads the whole document in memory</span></li><li><span>Event-based parsing <em>i.e.</em> <a href="http://www.saxproject.org/" target="_blank" rel="noopener">Simple API for XML</a>. It makes possible the parsing of large documents. Note that SAX is <strong>not</strong> a W3C specification.</span></li></ol> </dd> <dt>Implementation in different languages</dt> <dd> <p>Every commonly-used language in the industry offers at least one XML parsing implementation. This is either baked in the standard library that comes along the language, or available in a third-party one. Here are a couple of them:</p> </dd> </dl> </div>  <div> <dl> <dt>Document transformation</dt> <dd> <p><abbr title="eXtensible Stylesheet Language Transformation">XSLT</abbr> is <a href="https://www.w3.org/TR/1999/REC-xslt-19991116" target="_blank" rel="noopener">a W3C specification</a>. It allows to transform one XML document into another document in a declarative way. Target documents can be either XML themselves, or not.</p> </dd> <dt>Document querying</dt> <dd> <p><abbr title="XML Path Language">XPath</abbr> is <a href="https://www.w3.org/TR/2017/REC-xpath-31-20170321/" target="_blank" rel="noopener">another W3C specification</a>. It defines how to query XML documents, similar to CSS selectors.</p> </dd> </dl> </div> </div> </div> <div> <h2 id="conclusion">Conclusion</h2> <div> <p>XML has a lot of advantages compared to other more alternative technologies. In addition to what I described above, it benefits from a <a href="https://www.w3.org/standards/xml/" target="_blank" rel="noopener">rich ecosystem</a>.</p> <p>It’s not considered hype by a lot of young (and not so young) developers. I believe would be beneficial if our industry would value more battle-proven technologies than new shiny ones.</p> </div> </div>    </div> </section>   </article> </div> </div></div>]]>
            </description>
            <link>https://blog.frankel.ch/defense-xml/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614404</guid>
            <pubDate>Mon, 28 Sep 2020 08:40:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TILs about Node.js Fundamentals from the Node.js Design Patterns Book]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24614312">thread link</a>) | @loige
<br/>
September 28, 2020 | https://www.swyx.io/til-node-fundamentals-design-patterns-book/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/til-node-fundamentals-design-patterns-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I started reading <a href="https://www.nodejsdesignpatterns.com/">Node.js Design Patterns</a> this week. I got the Third Edition, and have not spent any time looking into what's changed from prior editions. The first 6 chapters cover fundamental knowledge, before getting into the meaty named Design Patterns, so these notes are from that first "half" of the book.</p>
<section>
  <h2 id="1-libuv-and-the-reactor-pattern"><a href="#1-libuv-and-the-reactor-pattern">1. <code>libuv</code> and the Reactor Pattern</a></h2>
  <p><code>libuv</code> is something I've often heard about as a low level Node.js library, but now I have a glimpse of what it does for us. As the book says:</p>
  <blockquote>
    <p>Libuv represents the low-level I/O engine of Node.js and is probably the most important component that Node.js is built on. Other than abstracting the underlying system calls, libuv also implements <strong>the reactor pattern</strong>, thus providing an API for creating event loops, managing the event queue, running asynchronous I/O operations, and queuing other types of task.</p>
  </blockquote>
  <p>The <a href="https://en.wikipedia.org/wiki/Reactor_pattern">Reactor pattern</a>, together with demultiplexing, <a href="https://www.youtube.com/watch?v=8aGhZQkoFbQ">event queues and the event loop</a>, is core to how this works - a tightly coordinated dance of feeding async events into a single queue, executing them as resources free up, and then popping them off the event queue to call callbacks given by user code.</p>
  <p>
    <img src="https://dev-to-uploads.s3.amazonaws.com/i/mj0r6gwfwiv5nqcfhkn5.png" alt="Alt Text">
  </p>
</section>
<section>
  <h2 id="2-module-design-patterns"><a href="#2-module-design-patterns">2. Module Design Patterns</a></h2>
  <p>I am superficially familiar with the differences between CommonJS modules and ES Modules. But I liked the explicit elaboration of 5 module definition patterns in CommonJS:</p>
  <ul>
    <li>Named exports: <code>exports.foo = () =&gt; {}</code></li>
    <li>Exporting a function: <code>module.exports = () =&gt; {}</code></li>
    <li>Exporting a class: <code>module.exports = class Foo() {}</code></li>
    <li>Exporting an instance: <code>module.exports = new Foo()</code> which is <em>like</em> a singleton, except when it is not because of multiple instances of the same module.</li>
    <li>Monkey patching other modules (useful for <a href="https://github.com/nock/nock">nock</a>)</li>
  </ul>
  <p>In ES Modules, I enjoyed the explanation of "read-only live bindings", which will look weird to anyone who has never seen it and has always treated modules as stateless chunks of code:</p>
  <pre><code><span>// counter.js</span>
<span>export</span><span> </span><span>let</span><span> count </span><span>=</span><span> </span><span>0</span>
<span>export</span><span> </span><span>function</span><span> </span><span>increment</span><span> </span><span>()</span><span> </span><span>{</span>
<span>   </span><span>count</span><span>++</span><span> </span>
<span>}</span>

<span>// main.js</span>
<span>import</span><span> </span><span>{</span><span> </span><span>count</span><span>,</span><span> </span><span>increment</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>./counter.js</span><span>'</span>
<span>console</span><span>.</span><span>log</span><span>(count) </span><span>// prints 0</span>
<span>increment</span><span>()</span>
<span>console</span><span>.</span><span>log</span><span>(count) </span><span>// prints 1</span>
<span>count</span><span>++</span><span> </span><span>// TypeError: Assignment to constant variable!</span>
</code></pre>
  <p>This mutable module internal state pattern is endemic in <a href="https://twitter.com/swyx/status/1221586490674696193?s=20">Svelte and Rich Harris' work</a> and I enjoy how simple it makes code look. I don't know if there are scalability issues with this pattern but so far it seems to work fine for ES Modules people.</p>
  <p>The last important topic I enjoyed was ESM and CJS interop issues. <code>ESM</code> doesn't offer <code>require</code>, <code>__filename</code> or <code>__dirname</code>, so you have to reconstruct them if needed:</p>
  <pre><code><span>import</span><span> </span><span>{</span><span> </span><span>fileURLToPath</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>url</span><span>'</span>
<span>import</span><span> </span><span>{</span><span> </span><span>dirname</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>path</span><span>'</span>
<span>const</span><span> __filename </span><span>=</span><span> </span><span>fileURLToPath</span><span>(</span><span>import</span><span>.</span><span>meta</span><span>.</span><span>url) </span>
<span>const</span><span> __dirname </span><span>=</span><span> </span><span>dirname</span><span>(__filename)</span>

<span>import</span><span> </span><span>{</span><span> </span><span>createRequire</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>module</span><span>'</span>
<span>const</span><span> require </span><span>=</span><span> </span><span>createRequire</span><span>(</span><span>import</span><span>.</span><span>meta</span><span>.</span><span>url)</span>
</code></pre>
  <p>ESM also cannot natively import JSON, as of the time of writing, whereas CJS does. You can work around this with the <code>require</code> function from above:</p>
  <pre><code><span>import</span><span> </span><span>{</span><span> </span><span>createRequire</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>module</span><span>'</span>
<span>const</span><span> require </span><span>=</span><span> </span><span>createRequire</span><span>(</span><span>import</span><span>.</span><span>meta</span><span>.</span><span>url) </span>
<span>const</span><span> data </span><span>=</span><span> </span><span>require</span><span>(</span><span>'</span><span>./data.json</span><span>'</span><span>) </span>
<span>console</span><span>.</span><span>log</span><span>(data)</span>
</code></pre>
  <p>Did you know that? I didn't!</p>
  <blockquote>
    <p>In semi-related news - <a href="https://twitter.com/MylesBorins/status/1311033983824793601?s=20">Node v14.13 will allow named imports from CJS modules</a> - probably the last step in ESM "just working" in Node.js</p>
  </blockquote>
</section>
<section>
  <h2 id="3-unleashing-zalgo"><a href="#3-unleashing-zalgo">3. Unleashing Zalgo</a></h2>
  <p>APIs are usually either sync or async in Node.js, but TIL you can design APIs that are <em>both</em>:</p>
  <pre><code><span>function</span><span> </span><span>createFileReader</span><span> </span><span>(</span><span>filename</span><span>)</span><span> </span><span>{</span><span> </span>
<span>  </span><span>const</span><span> </span><span>listeners</span><span> </span><span>=</span><span> [] </span>
<span>  </span><span>inconsistentRead</span><span>(</span><span>filename</span><span>,</span><span> </span><span>value</span><span> </span><span>=&gt;</span><span> </span><span>{</span>
<span>    </span><span>listeners</span><span>.</span><span>forEach</span><span>(</span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listener</span><span>(</span><span>value</span><span>)) </span>
<span>  </span><span>}</span><span>)</span>
<span>  </span><span>return</span><span> </span><span>{</span>
<span>    </span><span>onDataReady</span><span>:</span><span> </span><span>listener</span><span> </span><span>=&gt;</span><span> </span><span>listeners</span><span>.</span><span>push</span><span>(</span><span>listener</span><span>) </span>
<span>  </span><span>}</span>
<span>}</span>
</code></pre>
  <p>This looks innocent enough, except when you use it as async and then sync:</p>
  <pre><code><span>const</span><span> reader1 </span><span>=</span><span> </span><span>createFileReader</span><span>(</span><span>'</span><span>data.txt</span><span>'</span><span>)  </span><span>// async</span>
<span>reader1</span><span>.</span><span>onDataReady</span><span>(data </span><span>=&gt;</span><span> </span><span>{</span>
<span>   </span><span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>First call: </span><span>${</span><span>data</span><span>}`</span><span>)</span>
<span>   </span><span>const</span><span> </span><span>reader2</span><span> </span><span>=</span><span> </span><span>createFileReader</span><span>(</span><span>'</span><span>data.txt</span><span>'</span><span>)  </span><span>// sync</span>
<span>   </span><span>reader2</span><span>.</span><span>onDataReady</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> </span><span>{</span>
<span>     </span><span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>Second call: </span><span>${</span><span>data</span><span>}`</span><span>) </span>
<span>   </span><span>}</span><span>)</span>
<span>}</span><span>)</span>
<span>// only outputs First call - never outputs Second call</span>
</code></pre>
  <p>This is because module caching in Node makes the first call async and the second call sync. <a href="https://blog.izs.me/2013/08/designing-apis-for-asynchrony">izs famously called this "releasing Zalgo"</a> in a blogpost.</p>
  <p>You can keep Zalgo caged up by:</p>
  <ul>
    <li>using direct style functions for synchronous APIs (instead of <a href="https://en.wikipedia.org/wiki/Continuation-passing_style">Continuation Passing Style</a>)</li>
    <li>make I/O purely async by only using async APIs, using CPS, and deferring synchronous memory reads by using <code>process.nextTick()</code></li>
  </ul>
  <p>The same line of thinking can also be done for EventEmitter Observers as it is for Callbacks.</p>
  <blockquote>
    <p>Callbacks should be used when a result must be returned in an asynchronous way, while events should be used when there is a need to communicate that something has happened.</p>
  </blockquote>
  <p>You can combine both the Observer and Callback patterns, for example with the <a href="https://www.npmjs.com/package/glob"><code>glob</code> package</a> which takes both a callback for its simplier, critical functionality and a <code>.on</code> for advanced events.</p>
  <p>A note on ticks and microtasks:</p>
  <ul>
    <li><code>process.nextTick</code> sets up a microtask, which executes just after the current operation and before any other I/O</li>
    <li>whereas <code>setImmediate</code> runs after ALL I/O events have been processed.</li>
    <li><code>process.nextTick</code> executes earlier, but runs the risk of I/O [starvation] (<a href="https://en.wikipedia.org/wiki/Starvation_(computer_science)">https://en.wikipedia.org/wiki/Starvation_(computer_science)</a>) if takes too long.</li>
    <li><code>setTimeout(callback, 0)</code> is yet another phase behind <code>setImmediate</code>.</li>
  </ul>
</section>
<section>
  <h2 id="4-managing-async-and-limiting-concurrency-with-async"><a href="#4-managing-async-and-limiting-concurrency-with-async">4. Managing Async and Limiting Concurrency with <code>async</code></a></h2>
  <p>It's easy to spawn race conditions and accidentally launch unlimited parallel execution bringing down the server, with Node.js. The <a href="https://github.com/caolan/async">Async</a> library gives battle tested utilities for defining and executing these issues, in particular, queues that offer limited concurrency.</p>
  <p>The book steps you through 4 versions of a simple web spider program to develop the motivations for requiring managing async processes and describe the subtle issues that present themselves at scale. I honestly cant do it justice, I didn't want to just copy out all the versions and discussions of the web spider project as that is a significant chunk of the book, you're just gonna have to read thru these chapters yourself.</p>
</section>
<section>
  <h2 id="5-streams"><a href="#5-streams">5. Streams</a></h2>
  <p>I've often commented that <a href="https://twitter.com/swyx/status/1201528574236217345">Streams are the best worst kept secret of Node.js</a>. Time to learn them. Streams are more memory and CPU efficient than full buffers, but they are also more <em>composable</em>.</p>
  <p>Each stream is an instance of <code>EventEmitter</code>, streaming either binary chunks or discrete objects. Node offers <a href="https://nodejs.org/api/stream.html#stream_api_for_stream_consumers">4 base abstract stream classes</a>:</p>
  <ul>
    <li><code>Readable</code> (where you can read in <a href="https://nodejs.org/api/stream.html#stream_two_reading_modes">flowing (push) or paused (pull) mode</a>)</li>
    <li><code>Writable</code> - you're probably familiar with <code>res.write()</code> from Node's <code>http</code> module</li>
    <li><code>Duplex</code>: both readable and writable</li>
    <li><code>Transform</code>: a special duplex stream with two other methods: <code>_transform</code> and <code>_flush</code>, for data transformation</li>
    <li><code>PassThrough</code>: a <code>Transform</code> stream that doesnt do any transformation - useful for observability or to implement late piping and lazy stream patterns.</li>
  </ul>
  <pre><code><span>import</span><span> </span><span>{</span><span> </span><span>PassThrough</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>'</span><span>stream</span><span>'</span>
<span>let</span><span> bytesWritten </span><span>=</span><span> </span><span>0</span>
<span>const</span><span> monitor </span><span>=</span><span> </span><span>new</span><span> </span><span>PassThrough</span><span>() </span>
<span>monitor</span><span>.</span><span>on</span><span>(</span><span>'</span><span>data</span><span>'</span><span>,</span><span> </span><span>(</span><span>chunk</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span>
<span>  </span><span>bytesWritten</span><span> </span><span>+=</span><span> </span><span>chunk</span><span>.</span><span>length</span><span> </span>
<span>}</span><span>)</span>
<span>monitor</span><span>.</span><span>on</span><span>(</span><span>'</span><span>finish</span><span>'</span><span>,</span><span> </span><span>()</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span> </span>
<span>  </span><span>console</span><span>.</span><span>log</span><span>(</span><span>`${</span><span>bytesWritten</span><span>}</span><span> bytes written</span><span>`</span><span>)</span>
<span>}</span><span>)</span>
<span>monitor</span><span>.</span><span>write</span><span>(</span><span>'</span><span>Hello!</span><span>'</span><span>) monitor</span><span>.</span><span>end</span><span>()</span>

<span>// usage</span>
<span>createReadStream</span><span>(filename)</span>
<span> </span><span>.</span><span>pipe</span><span>(</span><span>createGzip</span><span>())</span>
<span> </span><span>.</span><span>pipe</span><span>(monitor) </span><span>// passthrough stream!</span>
<span> </span><span>.</span><span>pipe</span><span>(</span><span>createWriteStream</span><span>(</span><span>`${</span><span>filename</span><span>}</span><span>.gz</span><span>`</span><span>))</span>
</code></pre>
  <p>izs recommends <a href="https://www.npmjs.com/package/minipass">minipass</a> which implement a PassThrough stream with some better features. Other useful stream utils:</p>
  <ul>
    <li><a href="https://github.com/maxogden/mississippi">https://github.com/maxogden/mississippi</a></li>
    <li><a href="https://www.npmjs.com/package/streamx">https://www.npmjs.com/package/streamx</a></li>
    <li>You can make streams lazy (create proxies for streams, so the stream instance isn't until some piece of code is consuming) with <a href="https://www.npmjs.com/package/lazystream">lazystream</a>.</li>
  </ul>
  <p>Although the authors do recommend that piping and error handling be best organized with the native <a href="https://nodejs.org/api/stream.html#stream_stream_pipeline_source_transforms_destination_callback">stream.pipeline</a> function.</p>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/til-node-fundamentals-design-patterns-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24614312</guid>
            <pubDate>Mon, 28 Sep 2020 08:28:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The patch-based Git workflow]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24613989">thread link</a>) | @garritfra
<br/>
September 28, 2020 | https://garrit.xyz/blog/patch-based-git-workflow/ | <a href="https://web.archive.org/web/*/https://garrit.xyz/blog/patch-based-git-workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>September 28, 2020</p><p>If you have ever contributed to an open source project, chances are you have opened a pull request on GitHub or a similar platform to present your code to the maintainers. While this is a very approachable way of getting your code reviewed, some projects have decided against using pull requests and instead accept patches via email.</p><h2 id="an-introduction-to-patches"><a href="#an-introduction-to-patches"></a>An introduction to patches</h2><p>A patch is essentially a git commit expressed in plain text. It describes what commit the change is based on, and what has changed. A basic patch looks like this:</p><div><pre><p><span>From 92132241233033a123c4fa833449d6a0d550219c Mon Sep 17 00:00:00 2001</span></p><p><span>From: Bob &lt;bob@example.com&gt;</span></p><p><span>Date: Tue, 25 May 2009 15:42:16 +0200</span></p><p><span>Subject: [PATCH 1/2] first change</span></p><p><span>---</span></p><p><span> test.txt |    1 +-</span></p><p><span> 1 files changed, 1 insertions(+), 1 deletions(-)</span></p><p><span>diff --git a/test.txt b/test.txt</span></p><p><span>index 7634da4..270eb95 100644</span></p><p><span>--- a/test.txt</span></p><p><span>+++ b/test.txt</span></p><p><span>@@ -1 +1 @@</span></p><p><span>-Hallo Bob</span></p><p><span>+Hallo Alice!</span></p></pre></div><p>As you can see, it is very readable for both the reviewer and the machine.</p><h2 id="sending-and-receiving-patches"><a href="#sending-and-receiving-patches"></a>Sending and receiving patches</h2><p>The easiest way you can generate a patch from a commit is to use <code>git-format-patch</code>:</p><p>This will generate a <code>.patch</code> file, that can be embedded into an email and sent to the maintainers. Oftentimes they will then reply to your mail with some inline comments about your code.</p><p>To simplify this process further, git has the <code>send-email</code> command, which let’s you send the patch directly to someone without needing to embed it manually. I won’t go into details about this, but there is a <a href="https://git-send-email.io/">well written guide</a> on how to set it up.</p><p>If you have received a patch from someone, you can apply it to your tree with the <code>am</code> (apply mail) command:</p><div><pre><p><span>git am &lt; 0001-first-change.patch</span></p></pre></div><p>check your <code>git log</code> to see the patch in form of the latest commit.</p><h2 id="why-even-bother"><a href="#why-even-bother"></a>Why even bother</h2><p>You might think that this is just a silly and outdated approach to collaborative development. “Why not simply open a pull request?” you might ask. Some projects, especially low-level oriented ones like the Linux kernel, do not want to rely on third-party platforms like GitHub to host their code, with good reasons:</p><ol><li>Everyone can participate! You don’t need to register an account on some proprietary website to collaborate in a project that uses a patch-based workflow. You don’t even have to expose your identity, if you don’t want to. All you need is an email-address, and frankly most of us have one.</li><li>It’s plain simple! Once you get used to generating and applying patches on the command line, it is in fact easier and faster than opening a pull request in some clunky GUI. It doesn’t get simpler than plain text.</li><li>It is rewarding! Once you have submitted a patch to a project, there is no better feeling than getting a simple “Applied, thanks!” response from a maintainer. And if it’s a response that contains feedback rather than an approval, it feels even better to submit that reworked code again and get it eventually applied.</li></ol><h2 id="conclusion"><a href="#conclusion"></a>Conclusion</h2><p>The patch-based workflow is an alternative way to collaborate with developers. If it helps you in your day to day business depends on the projects you are contributing to, but in the end it is always good to have many tools under your belt.</p></div></div>]]>
            </description>
            <link>https://garrit.xyz/blog/patch-based-git-workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24613989</guid>
            <pubDate>Mon, 28 Sep 2020 07:35:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Low Code Evaluation Tool]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24613739">thread link</a>) | @kinj28
<br/>
September 28, 2020 | https://www.dronahq.com/low-code-evaluation-tool/?ref=show-hn | <a href="https://web.archive.org/web/*/https://www.dronahq.com/low-code-evaluation-tool/?ref=show-hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="nz-content">
	<div>
			<!-- post start -->
	<div id="post-10448" class="page">
		<section>
			<div data-animation-speed="35000" data-parallax="false"><div><div><div data-effect="none" data-align="left"><div>
        <!-- ******************************************************************************** -->
    <!-- Block 7 CFA - Form -->
    <!-- ******************************************************************************** -->
    <div id="download">
      <div>
        <div><div><p>How top enterprise IT Leaders are selecting the right tools for accelerating growth at speed?</p>
<p>Evaluation Tool takes into consideration various parameters, providing clear direction for enterprise leaders. It offers a practical way forward with selecting the right platform.</p>
<p>Download it today.</p>
</div>
            
        </div>
        
      </div>
    </div></div></div></div></div></div><div data-animation-speed="35000" data-parallax="false"><div><div><div data-effect="none" data-align="left"><div>
        <!-- ******************************************************************************** -->
    <!-- Block 7 CFA - Form -->
    <!-- ******************************************************************************** -->
    <div id="">
      <div>
        <div><p> <h2>How app development platforms rank  </h2> </p>
            
        </div>
        <div>
            <p><img src="https://www.dronahq.com/wp-content/uploads/2020/08/Integration-Pages-Illustrations-1.png" alt="" width="660" height="460" srcset="https://www.dronahq.com/wp-content/uploads/2020/08/Integration-Pages-Illustrations-1.png 660w, https://www.dronahq.com/wp-content/uploads/2020/08/Integration-Pages-Illustrations-1-300x209.png 300w" sizes="(max-width: 660px) 100vw, 660px"></p>
            
        </div>
      </div>
    </div></div></div></div></div></div><div data-animation-speed="35000" data-parallax="false"><div><div><div data-effect="none" data-align="left"><div><!-- ******************************************************************************** -->
    <!-- Feature - Three Columns -->
    <!-- ******************************************************************************** -->
    <div id="">
        <div>
            <p>
                        How this scorecard works</p>
            <p>This tool was built work as a simple litmus test for you to evaluate necessary LC/NC platform capabilities for your enterprise.</p>
            <div>
        <div>
                    <p><img src="https://www.dronahq.com/wp-content/uploads/2019/06/Work-Order-Maintenance.svg" alt="Inventory processes management">
                    </p>
                    <p>
                        Scoring a Platform</p>
                    <p>Head over to ‘Scoring’ tab. Enter the vendor name, date of the evaluation and start evaluating vendors against the parameters. Click on the drop-down cells to select the best-fit answer. A score will automatically get assigned.</p>
                    
                </div>
        <div>
                    <p><img src="https://www.dronahq.com/wp-content/uploads/2019/07/HR-Apps.svg" alt="visbility and improves analytics">
                    </p>
                    <p>
                        Comparing Vendors</p>
                    <p>For every criterion listed in the ‘Scoring’ tab, a weight has been assigned to parameters that facilitate app development. Under the ‘Comparison’ tab, you can find the aggregate weight calculated.</p>
                    
                </div>
        <div>
                    <p><img src="https://www.dronahq.com/wp-content/uploads/2019/06/Better-Customer-Satisfaction.svg" alt="Better Customer Satisfaction">
                    </p>
                    <p>
                        No-Code Weightage</p>
                    <p>We assigned the greatest weight to parameters that facilitate development without coding on account of the high speed of development no-code provides. The weight reduces as we move towards code.</p>
                    
                </div>
        </div>
        </div>
    </div>
        <!-- ********************** -->
        <!-- block 4 Single Image -->
        <!-- ********************** -->
        <div id="">
            <div><p>Trusted by </p> 
                
               
                   <p><img src="https://www.dronahq.com/wp-content/uploads/2018/01/DHQ-Customers-stripe.png" alt="DronaHQ Customer using Low Code app development tools"></p>                
            </div>
        </div></div></div></div></div></div>
		</section>
	</div>
	<!-- post end -->
	</div>
</div><div>
				
											
							
            <p>Copyright © Deltecs Infotech Pvt Ltd. All Rights Reserved</p>						
														
			</div></div>]]>
            </description>
            <link>https://www.dronahq.com/low-code-evaluation-tool/?ref=show-hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24613739</guid>
            <pubDate>Mon, 28 Sep 2020 07:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stupid solutions: Live server push without JS]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24613610">thread link</a>) | @lawik
<br/>
September 27, 2020 | https://underjord.io/live-server-push-without-js.html | <a href="https://web.archive.org/web/*/https://underjord.io/live-server-push-without-js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-09-25</small><!-- RSS:2020-09-25T17:00:00Z -->
<p>
    So in my post <a href="https://underjord.io/is-this-evil.html">Is this evil?</a> I covered a way of tracking users with CSS. While
    thinking about those weird ways of using the web I also started thinking about pushing live data to clients
    without JS. Or at least maintaining a connection.
    So WebSockets requires JS. WebRTC requires JS. Even HLS (video streaming), which would otherwise
    be super cool, with captions for accessibility. But no. Or rather, maybe on Apple platforms. Eh. Not good enough.
</p>
<p>And then it hit me. From some old Nerves projects I'd seen, that there is a standard for just sending a stream of
    JPEG frames as a video. MJPEG. Did you know about MJPEG? Lots of people don't. It is used by lots of webcams and
    security cameras. Common option for Raspberry Pi hacks as well. MJPEG is super simple which is its big advantage.
</p>
<p>But video is what we expect. I was going for something else. So this could be used for a CI status light, showing
    any amount of visual status information. I use it for this:</p>
<p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>
<p>That's live. Or dead if my server falls over.</p>
<p>So how does MJPEG work. Well, you take an <code>&lt;img&gt;</code> tag and you shove an MJPEG URL into it. Done.</p>
<p>Okay, that's how you use it. Not how it works. I implemented it in Elixir, Elixir is quite good at keeping state and
    serving updates. Links are below. But basically the browser opens the connection, receives some headers and some
    chunks of data and then realizes it is dealing with MJPEG. It wil then just expect the chunks to keep coming.
    Indefinitely. Because this is live video. Frame by frame of JPEG.</p>
<p>The basic code for the MJPEG headers and chunking was lifted from a pi camera repo made by the Nerves team. It had a
    lot of Frank Hunleth and Connor Rigby in it so kudos to those guys as always. This is what I did with it: <a href="https://github.com/lawik/mjpeg/blob/master/lib/mjpeg.ex">lawik/mjpeg</a></p>
<p>My server implementation is here and uses the above code: <a href="https://github.com/lawik/mjpeg_example/blob/master/lib/mjpeg_example.ex">lawik/mjpeg_example</a></p>
<p>So I receive the connection and then that calls my MjpegExample GenServer to persist the connection and keep track of
    how to notify that connection about new data. It also triggers an update to notify everyone already connected.</p>
<p>This is not polished, it is hammered together and I'm curious to see if it falls over the next time I get a decent
    amount of traffic.</p>
<p>I really like this approach because it is a fun hack that simply happens to work across browsers and quite well at
    that. I like how it is just an img element and no frills. I added lazy loading because that works more nicely with
    things like Google Lighthouse scores and the loading experience (your browser doesn't spend a few seconds thinking
    about loading the image).</p>
<p>Unfortunately it is absolutely a poor choice to actually use aside from fun and hacky stuff. There is no good way of
    doing accessibility with it. You can update the pixels and that is it. Unless you can chunk-stream a txt-file in an
    iframe.
    Haven't tried that yet...</p>
<p>So, don't use it. But isn't it pretty neat?</p>
<p>Of course, much like the CSS tracking, this can be used for evilish things. You can absolutely keep track of how long
    someone keeps receiving your frames and use that for your analytics. I also find it neat that it lets me know
    concurrent users. I just log the number along with sending it out because I want to know at what number it breaks
    and out of curiosity but you can probably do some mildly untoward things with this. Oh.. Wait. You could serve
    rotating ads with this. You know what the last frame you sent was so if you get a click on it you can direct that
    particular user to the right thing. New title: Ad placement entirely without JS, ugh, no thanks. Moving on.</p>
<p>If you know how to make this more dirty, hacky and fun or even more useful or accessible feel free to get in touch at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on
    Twitter where I'm <a href="https://twitter.com/lawik">@lawik</a>.</p><p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>

</div></div>]]>
            </description>
            <link>https://underjord.io/live-server-push-without-js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24613610</guid>
            <pubDate>Mon, 28 Sep 2020 06:36:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Absolute Minimum Every Engineer Must Know About Authentication and Encryption]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24611972">thread link</a>) | @ldelossa
<br/>
September 27, 2020 | https://www.ldelossa.is/blog/absolute-minimum-cryptography | <a href="https://web.archive.org/web/*/https://www.ldelossa.is/blog/absolute-minimum-cryptography">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <div><article>  <p>It's common to hear engineers muttering "cryptography is scary" or "oh no its a cert problem."</p> <p>The topic is a dense one full of maths, mailing lists, and vulnerabilities which quite literally shock the world. It's understandable how a lot of engineers put learning about the topics to another day.</p> <p>In my career I have been asked to build two different certificate signing backends for IoT purposes. These tasks provided the opportunity to work with authentication, encryption, and cryptography at a lower level then typical.</p> <p>This post will outline the bare minimum engineers should understand before working with authentication and encryption systems.</p> <h2>Part 1: Conceptual Overview</h2> <p>This section will provide a gentle introduction to authentication and encryption. These topics are to be read as a conceptual overview and not as literal implementation details.</p> <h3>Authentication and Encryption</h3> <p>Cryptography can lend itself to many utilities but as software developers our usage centers around authentication and encryption.</p> <p>Authentication is the act of identification. Cryptography can guarantee authentication and thus provide trust that the subject you are communicating with is indeed who they say they are. Authentication is implemented by cryptographic signing.</p> <p>Encryption is the act of concealing communications from unintended audiences. When a communication is encrypted it is guaranteed to be viewable only by the intended party.</p> <p>Authentication and encryption are used together to device a notion of trust in our applications and on the internet.</p> <h3>Cryptographic Signing</h3> <p>Cryptographically signing a message proves authentication in a single direction. It works like so:</p> <ul> <li>Sender: constructs a message to be sent.</li> <li>Sender: constructs a key to sign the message with.</li> <li>Sender: uses a signing algorithm to sign the bits of the message with the constructed keys.</li> <li>Sender: sends message along with signature to client.</li> <li>Receiver: receives the message and signature.</li> <li>Receiver: retrieves the sender's key.</li> <li>Receiver: uses the sender's key to sign the received message.</li> <li>Receiver: compares the sender's signature with the one computed by the receiver itself.</li> </ul> <p>If the receiver sees both signatures as equal and knows it can trust the key used to create the signature, the receiver can trust the message is from the sender.</p> <p>The various ways to securely transfer the sender's key to the receiver will be covered a bit later in the post.</p> <p>Typical signing algorithms are:</p> <ul> <li>HS256 - HMAC with SHA256</li> <li>RSA256 - RSA Signature with SHA256</li> </ul> <h3>Cryptographic Encryption</h3> <p>While similar in procedure, cryptographic encryption serves a separate purpose. It works like so:</p> <ul> <li>Sender: constructs a key</li> <li>Sender: construct a message to send</li> <li>Sender: run the message bits and the key through an encryption algorithm, producing unintelligible ciphertext.</li> <li>Sender: sends cipher text message to receiver.</li> <li>Receiver: receives the message</li> <li>Receiver: retrieves the sender's key</li> <li>Receiver: runs the message's ciphertext and the retrieved key through the same encryption algorithm, producing an intelligible message.</li> </ul> <p>In the above scenario the key is being utilized on every message to encrypt the message and conceal its contents.</p> <p>Typical encryption algorithms are:</p> <ul> <li>DES &amp; 3DES</li> <li>RSA</li> <li>Blowfish</li> <li>AES</li> </ul> <h2>Part 2: Applied Technologies</h2> <p>Several widely used technologies apply signing and encryption in practice. We will cover the following:</p> <ul> <li>Private Key Infrastructure And x509 Certificates</li> <li>TLS (SSL)</li> <li>JSON Web Tokens / JSON Web Signatures</li> </ul> <h3>Private Key Infrastructure And x509 Certificates</h3> <p>Private key infrastructure, or PKI for short, is a grouping of technologies, protocols, and policies. This grouping can be used in tandem to ensure both authentication and encryption and securely transfer keys between parties.</p> <p>PKI is based on a private/public key model. In this model a private key is used for signing or encryption while the public key is used for verification or decryption.</p> <p>*aside: Often the terms "asymmetric" and "symmetric" encryption come up. When the same key is used to encrypt and decrypt a message, this is known as "symmetric" encryption. When a key is used to encrypt a message as a different key is used to decrypt the message, this is known as "asymmetric" encryption. Public/Private key encryption is considered "asymmetric".</p> <p>The private key is kept secret and used to sign data while the public key can verify what the private key signs. The public key can never be used to derive the private key and this is mathematically proven.</p> <p><em>aside: PKI infrastructure will typically use RSA public and private keys. We dig into this more later in the post.</em></p> <p>In our examples above the sender would sign a message with its private key, make its public key available to the receiver, and the receiver would verify the message utilizing the sender's public key.</p> <p>PKI is called an 'infrastructure' because it provides a trust policy in addition to authentication and encryption.</p> <p>In PKI the trust policy takes the form of a tree. At the root of the tree is the "root CA", where CA is short for certificate authority. The root can create one or more "intermediate CA(s)" by creating and signing their certificate with its own private key, providing authenticity that the intermediate CA was created by the root. This creates a chain of trust as I can confirm an intermediate is signed by its root by obtaining the root's public key and verifying the certificate's signature.</p> <p>The intermediate CA is then kept online while the root CA is kept offline. This is for security purposes, if the intermediate CA private keys are compromised they can be revoked and the collateral damage can be managed. If the root CA's key is compromised all certificates created by any CA in the tree must be revoked.</p> <p>A diagram can help provide a visual aide.</p> <p><img alt="pki hierarchy diagram" src="https://www.ldelossa.is/pki_hierarchy_diagram.png"></p> <p>Each node in the chain has both a private key and a certificate.</p> <p>PKI utilizes a standardized certificate model specified in <a href="https://tools.ietf.org/html/rfc2459">rfc-2459</a>.</p> <p>A certificate is an envelope containing metadata and the public key of the owner. It may be used as follows:</p> <ul> <li>Sender: Signs a message with it's private key.</li> <li>Sender: Sends message to receiver.</li> <li>Receiver: Receives message.</li> <li>Receiver: Obtains the sender's certificate.</li> <li>Receiver: Verifies the certificate's authenticity by following the certificate trust chain.</li> <li>Receiver: Extracts public key from certificate and verifies message.</li> </ul> <p>Note that it is not enough to simply extract the public key and verify the message. The receiver must verify the encountered certificate was indeed signed by the issuer's private key. This is typically performed by the receiver having a local copy of popular root and intermediate certificates, extracting the public key from the one matching the issuer of the encountered certificate, and verifying the signature.</p> <p>It is worthwhile to take a pragmatic look at setting up a root CA, intermediate, and signing client certificates. A wonderful tutorial can be found <a href="https://jamielinux.com/docs/openssl-certificate-authority/">here</a></p> <h3>TLS</h3> <p>TLS utilizes PKI to implement encryption over HTTP also known as "HTTPS". TLS guarantees that every bit of data between two HTTP clients is encrypted and unintelligible to any other parties which may route the traffic.</p> <p>TLS is a protocol which exchanges asymmetric keys, generates symmetric keys, and uses the symmetric keys to encrypt data between parties.</p> <p>When a browser connects to an HTTPS website a handshake occurs. Within this handshake the server's certificate is verified and a set of symmetric keys are crafted. All communication on this secure channel is now encrypted and decrypted with the symmetric keys.</p> <p>The reason symmetric keys are used is for performance. Encrypting and decrypting with a private/public key can be expensive due to key size. Encryption and decryption can occur quicker with smaller symmetric keys.</p> <p>TLS also provides authentication.</p> <p>Each https server is assigned a client certificate. From our PKI diagram, client certificates are the leafs. When a user requests information from a server, the user's browser will check the server's certificate. If the browser cannot prove the certificate was created by a trusted root or intermediate CA the connection will fail.</p> <p><em>aside: if you ever had to install a certificate bundle to a server because ssl was failing you are installing a well known set of trusted root and intermediate certificates. This is used in the above verification process.</em></p> <p>With TLS comes maintenance. TLS certificates expire over time and must be kept up to date. Traditionally a server TLS certificate would be purchased from a well known root CA such as DigiTrust. Today, "let's encrypt" has paved the way for free certificates, albeit these certs expire much sooner then ones you can purchase from a trusted root ca.</p> <h3>JSON Web Tokens and JSON Web Encryption</h3> <p>JSON Web Tokens or JWT for short has become a popular form of authentication in modern web applications. When coupled with JSON Web Encryption both authentication and encryption can be utilized.</p> <p>The ubiquity of JWT and JSE is due to it's simplicity and ease of use. Both specifications use JSON to transfer a signed and optionally encrypted token between parties.</p> <p>This token can optionally contain claims, key/value information potentially useful for the receiving party along with several other "sections" which are base64 encoded and signed. The full details of generating a token can be viewed <a href="https://jwt.io/introduction/">here</a>.</p> <p>The flow of jwt interaction follows:</p> <ul> <li>Sender: generates the header and the payload for the JWT.</li> <li>Sender: generate the signature for the JWT utilizing a key.</li> <li>Sender: places the token in an "authorization" http header.</li> <li>Receiver: parses the "authorization" header and retrieves the token.</li> <li>Receiver: retrieves the sender's key.</li> <li>Receiver: verifies the signature portion with the sender's key.</li> </ul> <p>JWT alone provides no key transfer facilities and the token's data is in plain text. However, with JSON Web Encryption (JWE) it becomes possible to piggyback off PKI and retrieve public keys via the public key infrastructure.</p> <p>More than a high level overview is further then this post would like to go. If you are interested in …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ldelossa.is/blog/absolute-minimum-cryptography">https://www.ldelossa.is/blog/absolute-minimum-cryptography</a></em></p>]]>
            </description>
            <link>https://www.ldelossa.is/blog/absolute-minimum-cryptography</link>
            <guid isPermaLink="false">hacker-news-small-sites-24611972</guid>
            <pubDate>Mon, 28 Sep 2020 01:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TailwindCSS Tutorial – Getting started in 15mins]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24610944">thread link</a>) | @nelsonmichael
<br/>
September 27, 2020 | https://nelsonmichael.dev/tailwindcss-tutorial-getting-started-in-15mins | <a href="https://web.archive.org/web/*/https://nelsonmichael.dev/tailwindcss-tutorial-getting-started-in-15mins">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600404035503/LaC1fjqFq.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Frameworks are tools designed to help developers perform various tasks with ease, they bring in a certain level of abstraction so that you can do a whole lot with just a single piece of code or a line of code however the case may be.</p>
<p>Essentially frameworks are designed to help speed up your build process and ultimately give you a clean finish.</p>
<p>As a frontend web developer, you have heard or came across a couple of frameworks, like Bootstrap, Materialize, Foundation, or maybe TailwindCSS which is our focus for today.</p>
<p>At the end of this article, you would understand what TailwindCSS is, the difference between TailwindCSS from other CSS frameworks, it's pros, and cons and how to install and use it in your project.</p>
<h2 id="what-is-tailwindcss">What is TailwindCSS</h2>
<p><a target="_blank" href="https://tailwindcss.com/">TailwindCSS</a> is a low-level utility first CSS framework. Like Bootstrap, it is a CSS framework but unlike Bootstrap which comes straight out of the box with predefined components like cards, buttons, or dropdowns, TailwindCSS gives you a whole lot of power and flexibility with its utility classes which let you build your own components.</p>
<p>Essentially TailwindCSS doesn't have a set look or feel, where you can look at a website and tell that it was built with Bootstrap, you can't do that with Tailwind CSS, each component you see on a website built with TailwindCSS is custom to the developers taste, and that's the beauty of Tailwind CSS. </p>
<p>Let's look at an example below, to solidify your understanding of this  concept; </p>
<pre><code>    <span>&lt;<span>div</span> <span>class</span>=<span>"rounded shadow bg-white"</span>&gt;</span>

    <span>&lt;/<span>div</span>&gt;</span>
</code></pre><p>In the example above we used three utility classes on our <code>div</code> element, notice how we never left our HTML file? Now let's look at how we could have done that with Vanilla CSS.</p>
<pre><code><span>div</span>{

    <span>border-radius </span>: <span>15px</span>;
    <span>box-shadow</span>: <span>2px</span> <span>2px</span> <span>5px</span> <span>rgba</span>(<span>0</span>, <span>0</span>, <span>0</span>, <span>0.5</span>);
    <span>background-color</span>:white;
}
</code></pre><p>let's see a couple of other examples to spike your excitement some more;</p>
<h3 id="hover-based-classes">Hover based classes</h3>
<pre><code> &lt;a <span><span>class</span>="<span>bg</span>-<span>blue</span>-400 <span>hover</span>:<span>bg-transparent"&gt;click me!</span>&lt;<span>/a</span>&gt;</span>
</code></pre><h4 id="pure-css">pure CSS</h4>
<pre><code><span>a</span>{
    <span>background-color</span>: <span>#76a9fa</span>;
}

<span>a</span><span>:hover</span>{
    <span>background-color</span>: transparent;
}
</code></pre><h3 id="focus-based-classes">Focus based classes</h3>
<pre><code>  &lt;<span>input</span> <span>type</span>="text" placeholder="no outline" <span>class</span>="outline-none " /&gt;
</code></pre><h4 id="pure-css">pure CSS</h4>
<pre><code><span>input</span>{
    <span>outline</span>: <span>0</span>;
}
</code></pre><h3 id="responsive-based-classes">Responsive based classes</h3>
<pre><code> &lt;img <span>class</span>=<span>"w-16 md:w-32 lg:w-48"</span> src=<span>"..."</span>&gt;
</code></pre><h4 id="pure-css">pure CSS</h4>
<pre><code><span>img</span>{
    <span>width</span>:<span>4rem</span>;
}

<span>@media</span> (<span>min-width:</span> <span>768px</span>){
      <span>img</span>{
             <span>width</span>:<span>8rem</span>;  
     }
}

<span>@media</span> (<span>min-width:</span> <span>1024px</span>){
      <span>img</span>{
             <span>width</span>:<span>12rem</span>;  
     }
}
</code></pre><p>Now do you see the power and flexibility of TailwindCSS, just by adding a few classes, we can do something amazing where we would have otherwise have to have written more lines of code.</p>
<blockquote>
<p><strong>NOTE:</strong> You should already have an understanding of CSS before using TailwindCSS, TailwindCSS is not a replacement for CSS.</p>
</blockquote>
<h2 id="how-does-tailwindcss-work">How does TailwindCSS work?</h2>
<p><img src="https://i.imgur.com/h3pPokP.png" alt=""></p>
<p>Tailwind works simply by converting its core styles and functionality into vanilla CSS that can be used in our HTML file. Let me further explain this;</p>
<p>We create an <strong>src</strong> and <strong>public</strong> folder in our project directory, the <strong>src</strong> folder is going to have a <strong>styles.css</strong> file in it, this file is where we import tailwinds core styles and functionalities.</p>
<p>Now at build time tailwind is going to convert those core styles and functionalities into vanilla CSS and then sent to the <strong>styles.css</strong> file in our public folder which we can use in our HTML.</p>
<p>No problem if you don't quite understand this now, as you read further, you would get a grasp of it.</p>
<h2 id="installation-and-setup">Installation and Setup</h2>
<h3 id="install-using-npm-node-package-manager">Install using npm (node package manager)</h3>
<p>let me walk you through a quick installation process and how to get tailwind CSS set up for a simple <strong>Hello world</strong> project.</p>
<ol>
<li>Make sure you have node-js installed on your computer before you can use npm. You can install node-js <a target="_blank" href="https://nodejs.org/en/download/">here</a>.</li>
<li><p>Once you have node installed, create a new folder in your desktop directory or where ever you would like to have the folder.</p>
<p> let's do that from the command line using these simple steps:</p>
<ul>
<li>open up the command line </li>
<li>create a new folder with this command, <code>mkdir folder name</code></li>
<li>now go into that directory using <code>cd folder name</code></li>
<li>open up your folder in your favorite text editor</li>
</ul>
</li>
<li><p>Now that you have created a new folder and navigated into it, you need to create a new <strong>package.json</strong> file using npm like so; <code>npm init -y</code></p>
<p> the <strong>package.json</strong> file helps to keep track of all your dependencies.</p>
</li>
<li><p>The next step is to install tailwindCSS using <code>npm install tailwindcss</code> on the command line. This will install tailwindcss dependency into then <strong>package.json</strong> file.</p>
<p> Now you should see a <strong>node_module</strong> folder in your project folder, a <strong>package-lock.json</strong> file and you should have tailwindCSS as a dependency in your <strong>package.json</strong> file</p>
<p> <img src="https://i.imgur.com/kVmDrMl.png" alt="tailwindcss example"></p>
<p> great if you can see this, you are on the right track, let's carry on.</p>
</li>
<li><p>Create a new <strong>src</strong> folder and <strong>public</strong> folder in your project directory.</p>
<ul>
<li>Inside the <strong>src</strong> folder create a <strong>styles.css</strong> file</li>
<li><p>now let us add tailwinds core styles into our <strong>styles.css</strong> file. We do so by pasting these directives onto our stylesheet </p>
<pre><code>  <span>@tailwind</span> base;

  <span>@tailwind</span> components;

  <span>@tailwind</span> utilities;
</code></pre></li>
</ul>
</li>
<li><p>Now we can we process the <strong>styless.css</strong> file in our <strong>src</strong> folder so that it can bring out a final output file in our <strong>public</strong> folder;</p>
<ul>
<li>go to your <strong>package.json</strong> file, there is a section called <strong>scripts</strong> which allows us to register different scripts into our terminal, right now you should see a <strong>test</strong> script there.</li>
<li><p>now we have to change the test script into our own script which is going to convert tailwindCSS into vanilla CSS, pretty sweet right. we can do that with the line of code below;</p>
<pre><code>  <span>"build"</span>:<span>"tailwindcss build src/styles.css -o public/styles.css"</span>
</code></pre><p>let's analyze this line of code. On the left-hand side of the colon, we have <strong>build</strong> which can be called anything we like, it is essentially the name of our script. </p>
<p>the right side of the colon holds <strong>tailwindcss build</strong> which is our tailwind package, also we have <strong>src/styles.css</strong> which is specifying our source file with the tailwind directives.</p>
<p>Then we specify our output using <strong>-o</strong> and the destination of our output file which is <strong>public/styles.css</strong></p>
</li>
<li><p>now lets run our build script on the terminal, like so; <code>npm run build</code>, build here is the name of our script file which we created earlier.</p>
<p>Awesome, now we have tailwindCSS set up and working perfectly, we can now use it to finish our simple hello world project.</p>
</li>
</ul>
</li>
<li><p>Create an HTML file in the <strong>public</strong> folder and have it linked to our newly built vanilla CSS file in the same folder and let's add some tailwind utilities to it, like so;</p>
</li>
</ol>
<pre><code>    <span>&lt;<span>h1</span> <span>class</span>=<span>"text-4xl font-bold text-center text-blue-500"</span>&gt;</span>Hello world !<span>&lt;/<span>h1</span>&gt;</span>
</code></pre><h2 id="tailwindcss-vs-bootstrap">TailwindCSS vs Bootstrap</h2>
<table>
<thead>
<tr>
<td>TailwindCSS</td><td>Bootstrap</td></tr>
</thead>
<tbody>
<tr>
<td>Tailwind lets you build your own components.</td><td>Comes with predefined components.</td></tr>
<tr>
<td>It is very customizable.</td><td>It is difficult to create a unique design.</td></tr>
</tbody>
</table>
<h2 id="pros-and-cons">Pros and Cons</h2>
<h3 id="pros">Pros</h3>
<ul>
<li>utility first</li>
<li>highly flexible and customizable </li>
<li>Responsive</li>
<li>Build a beautiful responsive website without leaving your HTML</li>
</ul>
<h3 id="cons">Cons</h3>
<ul>
<li>Tailwind comes with a pretty large file, and unless you purge it, you have this large file with unused CSS.</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Frameworks are designed to make our lives easier, and TailwindCSS does a pretty good of that, it provides us with a lot of power and flexibility with its utility classes, to help us make very customizable components and ultimately give us a good finish.</p>
<p>You've made it to the end of this article, I hope it explains the concept of tailwindCSS to you. </p>
<p>You can follow me on twitter <a target="_blank" href="https://twitter.com/D_kingnelson">@D_kingnelson</a>.</p>
</div></div></section></div></div>]]>
            </description>
            <link>https://nelsonmichael.dev/tailwindcss-tutorial-getting-started-in-15mins</link>
            <guid isPermaLink="false">hacker-news-small-sites-24610944</guid>
            <pubDate>Sun, 27 Sep 2020 23:05:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for immersive video calls]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24610166">thread link</a>) | @luu
<br/>
September 27, 2020 | https://www.benkuhn.net/vc/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/vc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spend a lot of my day on video calls. Wave is a distributed company, so they’re the main way we communicate. But compared to talking in person, they feel unnatural:</p><ul><li>Most people have low-quality microphones and webcams that make them look and sound bad.</li><li>There’s a lag between when you say something and when the other person hears it, making it hard to navigate conversational <a href="https://en.wikipedia.org/wiki/Turn-taking" target="_blank">turn-taking</a>.</li><li>If you’re using headphones, you can’t hear your own voice very well.</li><li>Because of <a href="https://en.wikipedia.org/wiki/Echo_suppression_and_cancellation" target="_blank">echo cancellation</a>, you often can’t talk when someone else is also talking, which makes the conversation flow less well.</li></ul><p>I started wondering how much nicer video calls would feel if I fixed these problems. So I spent way too much time fiddling with gear and software. This post summarizes what I’ve learned.</p><p>Collectively, these recommendations have had a pretty big impact: when talking one-on-one to friends with equally good setups, I’ve been able to go 4+ hours without feeling fatigued.</p><p><em><small>Epistemic status: best guess; not a professional; almost certainly contains wrong bits. Tell me which ones by comment or <a href="https://www.benkuhn.net/contact/">email</a>!</small></em></p><h2 id="omg-ben-dont-make-me-read-your-4500-word-doorstopper-just-tell-me-what-to-do">omg ben don’t make me read your 4500 word doorstopper, just tell me what to do</h2><p>Here’s how I would stack-rank my advice for my past self. (Of course, your personal ranking might be different depending on your situation.)</p><ol><li><p>($depends) Don’t work in a space where your noise can bother other people, or vice versa.</p></li><li><p>($10-30) If you ever have network issues, run <a href="https://amzn.to/3luTVdV" target="_blank">a cable</a> between your computer and router. You’ll probably need an <a href="https://amzn.to/2YOFis9" target="_blank">adapter</a>. (Contrary to popular belief that a bad connection is your ISP’s fault, it’s <a href="https://www.benkuhn.net/wireless/">more likely to be flaky wifi</a>.)</p></li><li><p>(~$100) Buy <a href="https://amzn.to/3bULynH" target="_blank">open-back headphones</a>, which let you hear your own voice normally and are extremely comfortable.</p></li><li><p>(~$30) Switch from your built-in computer mic to a <a href="https://www.sweetwater.com/store/detail/BoomProMic--v-moda-boompro-microphone-communication-mic-for-headphones" target="_blank">headset mic</a> (and <a href="https://amzn.to/3hOU5JU" target="_blank">pop filter</a>), which will sound much better and pick up less noise. Note this requires a headset with detachable cable, like the one I linked above.</p><p>You can now leave yourself unmuted! If the other person also has headphones, you can also talk at the same time. Both of these will make your conversations flow better.</p></li><li><p>($0) Prefer Zoom to most alternatives; it has higher sound quality, better echo cancellation, and fewer silly behaviors. If you have headphones and a good mic, enable “original sound” to turn off some unnecessary audio filtering.</p></li><li><p>(~$200) Get a second monitor for notes so that you can keep Zoom full-screen on your main monitor. It’s easier to stay present if you can always glance at people’s faces. (I use an iPad with <a href="https://support.apple.com/en-us/HT210380" target="_blank">Sidecar</a> for this; for a dedicated device, the right search term is <a href="https://amzn.to/3iZRUVz" target="_blank">“portable monitor”</a>. Also, if your meetings frequently involve presentations or screensharing, consider getting a third monitor too.)</p></li><li><p>($0?) Arrange your lighting to cast lots of diffuse light on your face, and move any lights that shine directly into your camera. Lighting makes a bigger difference to image quality than what hardware you use!</p></li><li><p>(~$20-80 if you have a nice camera) Use your camera as a webcam. There’s software for <a href="https://www.usa.canon.com/internet/portal/us/home/support/self-help-center/eos-webcam-utility" target="_blank">Canon</a>, <a href="https://fujifilm-x.com/en-us/support/download/software/x-webcam/" target="_blank">Fujifilm</a>, <a href="https://downloadcenter.nikonimglib.com/en/download/sw/176.html" target="_blank">Nikon</a>, and <a href="https://support.d-imaging.sony.co.jp/app/webcam/en/" target="_blank">Sony</a> cameras (Windows-only for Nikon and Sony); for others, if they can output clean HDMI (check <a href="https://www.elgato.com/en/gaming/cam-link/camera-check" target="_blank">this list</a>), you can buy an <a href="https://amzn.to/3kgunjj" target="_blank">HDMI capture card</a>. You will also want to be able to plug your camera into a power source, for which you may need a “dummy battery.”</p></li><li><p>(~$40 if you have a smartphone with a good camera) Use that as a webcam via <a href="https://reincubate.com/camo/" target="_blank">Camo</a>.</p></li><li><p>(~$350) If you don’t own a nice camera but want one, you can get a used entry-level mirrorless camera + lens + dummy battery + boom arm. See <a href="#a-note-on-camera-buying">buying tips below</a>.</p></li></ol><p>More detailed recommendations and justifications follow.</p><h2 id="network">Network</h2><p>Connection problems are the thing that makes video calls suck the most. They do this in three different ways:</p><ol><li><p>If your connection ever gets really bad, your audio will break up, which is exhausting to listen to and ruins the flow.</p></li><li><p>Even if it doesn’t get that bad, a poor connection will increase <em>latency</em>, or the time between when you speak and when the other person hears you. High latency is what causes the dreaded “you first, no <em>you</em> first” dance.</p></li><li><p>Finally (and least importantly), a bad connection limits the amount of data you can exchange, forcing you to use lower-quality video. This doesn’t really matter if you’re using a webcam, but by the end of this post, you might have a good enough camera that it matters.</p></li></ol><p>I wrote a whole post of its own on how to troubleshoot your home network for video calls, but realistically, most connection problems are because <a href="https://www.benkuhn.net/wireless/">wifi sucks</a> and you can avoid them by not using wifi. So, first try running an <a href="https://amzn.to/3luTVdV" target="_blank">Ethernet cable</a> between your computer and your router. If you still notice high latency or your connection dropping, or if you really can’t run a cable for some reason, <a href="https://www.benkuhn.net/vcnet/">check the guide</a> for more troubleshooting advice.</p><h2 id="audio">Audio</h2><p>Video improvements are flashy and noticeable, but audio is the reason you’re having the call, thus ultimately more important. So audio comes first.</p><h3 id="get-away-from-other-people">Get away from other people</h3><p>This is a basic prerequisite for everything below. Coworking spaces and cafés are nice if you plan to be silent all day, but will make natural-feeling meetings impossible due to your crippling self-consciousness about noise levels. If you’re going to be on a call for more than 5 minutes, get your own space.</p><p>(If you are committed to taking your meetings in a crowded and noisy space, ignore the rest of the audio section. You’re mostly just doomed to crappy calls in this case, though you might be able to limit the damage by getting <a href="https://www.sweetwater.com/store/detail/BoomProMic--v-moda-boompro-microphone-communication-mic-for-headphones" target="_blank">a nice headset mic</a> and installing <a href="https://krisp.ai/" target="_blank">krisp.ai</a>.)</p><p>If you’re talking to someone else who’s in a noisy environment, you can apparently also use krisp.ai to filter their audio yourself, though I haven’t tried this.</p><h3 id="get-full-duplex-audio-with-no-echo">Get full-duplex audio with no echo</h3><p>One key ingredient to making voice conversations feel “natural” is that both participants need be able to talk and hear the other person talking at the same time (“full-duplex audio”). Full-duplex audio is important because it allows you to talk simultaneously (“overlap”) with the other person.</p><p>You might think that overlap should be rare, because interrupting someone else is rude. While that’s true of large-scale overlaps, we often use small-scale overlaps to <a href="https://en.wikipedia.org/wiki/Turn-taking#Overlap" target="_blank">negotiate conversational turn-taking</a> (e.g. starting talking when the speaker is trailing off but hasn’t finished), or to signify that we’re paying attention (“uh-huh,” “yeah”).</p><p>The hard problem of full-duplex audio is that if someone else is talking, their voice is going to come out of your computer’s speakers and go back into your microphone. If your computer leaves the microphone on, in that case, it’ll end up playing back an “echo” of their own voice to them, which is extremely annoying. So video call tries to filter out feedback from your speakers into your microphone, which is called <a href="https://en.wikipedia.org/wiki/Echo_suppression_and_cancellation" target="_blank">echo cancellation</a>.</p><p>Unfortunately, removing <em>only</em> the speaker echo from your microphone stream is really hard to do. So instead, the software often ends up completely muting your mic if someone else is talking. If you’ve ever tried to micro-overlap with someone and noticed that their audio cut out briefly, that’s what’s going on.</p><p>If your listeners can’t overlap with you, it’s harder to tell whether they’re following along, and it’s harder to negotiate whose turn it is to speak. This makes the conversation feel less natural, especially in larger groups.</p><p>To get full-duplex audio, you need to (a) have an audio setup that doesn’t produce echoes, then (b) convince your video call app not to try to suppress echoes.</p><p>(a), “an audio setup that doesn’t produce echoes,” means that your microphone should not pick up any sound from your speakers. In practice this means that your “speakers” must be headphones.</p><p>(b), “convince your video call app not to try to suppress echoes,” seemed surprisingly tricky when I tried to research it, because each video call app has its own heuristics for when to engage echo-cancellation.</p><p>So I did my own tests of echo cancellation Zoom, Skype, and Hangouts in Chrome and Firefox. I started a chat between two computers, both with headphones attached—a setup that should have required no echo cancellation. I then played music into the microphone of one computer. On the other, I spoke into the microphone and listened for whether the music got quieter.</p><p>Zoom, Skype and Hangouts in Firefox all seemed to slightly decrease the audio volume when I spoke, indicating light echo cancellation. For Hangouts in Chrome, the audio cut out <em>completely</em> every time I said anything. In Zoom, I was able to eliminate all echo cancellation by selecting the “use original audio” option, which you can also permanently enable for particular audio devices—I’d recommend doing this.</p><h3 id="throw-your-wireless-headset-in-the-trash">Throw your wireless headset in the trash</h3><p>The gear I recommend in this guide is all wired, not Bluetooth. While Bluetooth seems like it should be great, in practice it has <a href="https://www.benkuhn.net/wireless/">horrible problems with audio latency, quality and reliability</a>. Also, I don’t think wireless open-back headphones (see below) exist.</p><p>If you finished the previous paragraph and still think you can get away with using wireless audio gear, read the post at the link :)</p><h3 id="hear-yourself-clearly-with-open-back-headphones">Hear yourself clearly with open-back headphones</h3><p>Most headphones are <em>closed-back</em>, which means they form an acoustic seal over your ear that attenuates outside sound. This is good for “noise isolation” when you’re listening to music. But it’s bad in calls because it also isolates you from your own voice, making you sound muffled and unnatural to yourself. (The same thing also happens with any earbuds that form a seal, i.e. pretty much everything except EarPods or non-Pro AirPods.)</p><p>Personally, without the feedback from hearing myself, I also tend to start speaking louder or shouting on calls. This tires out my voice, and can get stressful for whoever I’m <del>shouting at</del> talking to.</p><p>To avoid this, you can buy <em>open-back headphones</em>, which have mesh instead of a closed covering over your ears. I bought the <a href="https://amzn.to/3bULynH" target="_blank">Philips SHP9500</a>, which I like a lot; I haven’t tested any other pairs. (I chose a low-end pair because for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/vc/">https://www.benkuhn.net/vc/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/vc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24610166</guid>
            <pubDate>Sun, 27 Sep 2020 21:12:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thoughts on Structured Editing: Breaking Away from Syntax]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24609942">thread link</a>) | @marcusbuffett
<br/>
September 27, 2020 | https://mbuffett.com/posts/structured-editing-syntax/ | <a href="https://web.archive.org/web/*/https://mbuffett.com/posts/structured-editing-syntax/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I was aimlessly browsing Github and came across
<a href="https://github.com/kneasle/sapling">sapling</a>, a very early-stage structured
editor. It was inspired by <a href="http://shtanton.com/ex.html">this blog post</a>, which
talks about structured editing.</p>
<p>Structured editing has had my interest for a while. I’ve put a lot of time and
effort into getting really good at text editing, but I’m holding out hope that
in 10 years plaintext editing will be outdated. The idea behind structured
editing is to edit code instead of text, so instead of “move cursor to next
parentheses, delete in parentheses”, you’d have operations like “change function
argument”.</p>
<h2 id="formatting">Formatting</h2>
<p>With auto-formatters like <a href="https://github.com/rust-lang/rustfmt">rustfmt</a>,
<a href="https://golang.org/cmd/gofmt/">gofmt</a>, and <a href="https://prettier.io/">prettier</a>,
some of the promise of structured editors have been achieved in regular editors.
Because now the ambiguity of syntax is eliminated by formatters. These editors
take the text, transform it into an AST (abstract syntax tree), and then print
the AST, using their formatting rules.</p>
<p>Conveniently, they provide an easy way to get started with creating a structured
editor. Ex. since rustfmt can already print an AST, why not use the output of
rustfmt to display the AST in a structured editor. I added some syntax
highlighting to rustfmt and got something like this:</p>
<p><img src="https://mbuffett.com/rust.png"></p><h3 id="customization">Customization</h3>
<p>I’m not a semicolon fan; sometimes I wish Rust was written python-style, with
newlines meaning new statement, instead of semicolons representing the end of a
statement. It’s always a pain when
I forget a semicolon, and I wish my editor would just automatically insert them
for me. Since they’re always followed by a newline, they’re just a wasted character, in my mind.</p>
<p>Well now I’ve got this alpha structured editor, how about I just remove
the semicolons when printing the AST? Obviously I couldn’t do this in a
plaintext editor, since the code wouldn’t be valid. But the underlying AST is
the same regardless of how I print it, so let’s print without semicolons:</p>
<p><img src="https://mbuffett.com/no-semicolons.png"></p><h3 id="taking-it-further">Taking it further</h3>
<p>There’s so many details of a language that matter more
than syntax; performance, type system, available libraries, community, standard
library, dev tools, etc. Unfortunately, syntax is the first thing people see,
and therefore gets a disproportionate amount of attention. There’s also the
inertia of C-style syntax; languages that want to have any chance of being
popular have to use curly brackets for blocks, parens for invocations, dots for
method access, etc.</p>
<p>I think structured editors offer an escape from this. For example, here’s the
same example from above, with the same AST, but with python-esque syntax instead:</p>
<p><img src="https://mbuffett.com/python.png"></p><p>Now when learning Rust coming from Python, I wouldn’t need to learn about
implicit returns, or re-learn that <code>{}</code> means a block, instead of <code>:</code>. The
underlying AST has the <code>block</code> and <code>return</code> nodes, and I can view them however
I’m most comfortable. This would free up time to learn more important things,
like lifetimes and borrowing.</p>
<h2 id="other-syntax-thoughts">Other syntax thoughts</h2>
<h3 id="unicode-symbols">Unicode symbols</h3>
<p>Some languages, like Haskell, have embraced unicode symbols. Using <code>∀</code> instead
of <code>forall</code>, or <code>→</code> instead of <code>-&gt;</code> is becoming more popular. The problem is
that these are a lot harder to type. With a structured editor, you wouldn’t be
typing these anyway, so it’s no longer such a tradeoff between unicode and ASCII
characters.</p>
<h3 id="non-text-representations">Non-text representations</h3>
<p>When you have an editor representing an AST, you’re not limited to text to
convey information. For example, instead of writing <code>mut foo</code> for mutable
params to a function, you may want mutable params to have a squiggly line below
them. Or maybe you want a graph-like representation of your code instead of
text, to get an idea of which functions call which other functions.</p>
<h3 id="parsing-considerations">Parsing considerations</h3>
<p>Part of the discussion around Go generics involved the use of <code>&lt;&gt;</code> brackets for
generics, like in other languages. If you use angle brackets, seeing a <code>&lt;</code> means
you then have to determine whether what follows is a type or an expression,
which results in unbounded lookahead, something the compiler devs wanted to
avoid for performance reasons. So now Go developers have to get used to seeing
and using <code>[]</code> brackets for generics. If structured editors and ASTs were used
instead, not only would there not be a parsing step at all, eliminating the
unbounded lookahead problem, but Go developers could use whatever generic
annotation they like.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Don’t know if I have much of a conclusion, besides that I hope
that syntax will continue to lose importance as a defining characteristic of a
language. It’s already been losing importance with auto-formatters. In the
languages I use where auto-formatters are the norm, I’ve seen way less
bikeshedding about spaces vs tabs, bracket styles, trailing commas, etc.</p>

        </div></div>]]>
            </description>
            <link>https://mbuffett.com/posts/structured-editing-syntax/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609942</guid>
            <pubDate>Sun, 27 Sep 2020 20:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling to Assembly from Scratch: the book, released]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24609774">thread link</a>) | @halst
<br/>
September 27, 2020 | https://keleshev.com/cas | <a href="https://web.archive.org/web/*/https://keleshev.com/cas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://keleshev.com/cas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609774</guid>
            <pubDate>Sun, 27 Sep 2020 20:09:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Napkin Project]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24609749">thread link</a>) | @albertzeyer
<br/>
September 27, 2020 | https://web.evanchen.cc/napkin.html | <a href="https://web.archive.org/web/*/https://web.evanchen.cc/napkin.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><span>
<a href="https://web.evanchen.cc/upload/recent-flowchart.png">
<img src="https://web.evanchen.cc/upload/recent-flowchart.png" width="250">
<br>(click to enlarge)</a>
</span></p>
<h2>Download</h2>
<p><strong>Download the <a href="https://venhance.github.io/napkin/Napkin.pdf">most recent draft of Napkin</a>.</strong></p>
<h2>Project Status</h2>
<p>The <strong>recent v1.5</strong> is a new update which revises
many of the earlier chapters as well as adding new content
in real analysis, measure theory, and algebraic geometry.
It is however even more visibly incomplete,
with several chapters scheduled but not yet written.
In addition, many chapters still lack problems or solutions.</p>
<p>See link above for the most recent draft,
and <a href="https://usamo.wordpress.com/napkin/">here for an listing periodic snapshots</a>.
You can also view the
<a href="https://github.com/vEnhance/napkin/">source code on GitHub</a>;
the most recent version is
<a href="https://venhance.github.io/napkin">automatically compiled from that source</a>.</p>
<p>I would very highly appreciate any corrections, suggestions, or comments.</p>
<h2>Description</h2>
<p>The Napkin project is a personal exposition project of mine
aimed at making higher math accessible to high school students.
The philosophy is stated in the preamble:</p>
<blockquote>
<p>I'll be eating a quick lunch with some friends of mine who are still in high school.
They'll ask me what I've been up to the last few weeks, and I'll tell them that I've been learning category theory.
They'll ask me what category theory is about.
I tell them it's about abstracting things by looking at just the structure-preserving morphisms between them, rather than the objects themselves.
I'll try to give them the standard example Gp, but then I'll realize that they don't know what a homomorphism is.
So then I'll start trying to explain what a homomorphism is, but then I'll remember that they haven't learned what a group is.
So then I'll start trying to explain what a group is, but by the time I finish writing the group axioms on my napkin, they've already forgotten why I was talking about groups in the first place.
And then it's 1PM, people need to go places, and I can't help but think:</p>
<p><em><span>Man, if I had forty hours instead of forty minutes, I bet I could actually have explained this all.</span></em></p>
<p>This book is my attempt at those forty hours.</p>
</blockquote>
<p>This project has evolved to more than just forty hours.</p>
<h2>Current Table of Contents</h2>
<ol>
<li>Groups</li>
<li>Metric spaces</li>
<li>Homomorphisms and quotient groups</li>
<li>Rings and ideals</li>
<li>Flavors of rings</li>
<li>Properties of metric spaces</li>
<li>Topological spaces</li>
<li>Compactness</li>
<li>Vector spaces</li>
<li>Eigen-things</li>
<li>Dual space and trace</li>
<li>Determinant</li>
<li>Inner product spaces</li>
<li>Bonus: Fourier analysis</li>
<li>Duals, adjoint, and transposes</li>
<li>Group actions overkill AIME problems</li>
<li>Find all groups</li>
<li>The PID structure theorem</li>
<li>Representations of algebras</li>
<li>Semisimple algebras</li>
<li>Characters</li>
<li>Some applications</li>
<li>Quantum states and measurements</li>
<li>Quantum circuits</li>
<li>Shor's algorithm</li>
<li>Limits and series</li>
<li>Bonus: A hint of p-adic numbers</li>
<li>Differentiation</li>
<li>Power series and Taylor series</li>
<li>Riemann integrals</li>
<li>Holomorphic functions</li>
<li>Meromorphic functions</li>
<li>Holomorphic square roots and logarithms</li>
<li>Measure spaces</li>
<li>Constructing the Borel and Lebesgue measure</li>
<li>Lebesgue integration</li>
<li>Swapping order with Lebesgue integrals</li>
<li>Bonus: A hint of Pontryagin duality</li>
<li>Random variables (TO DO)</li>
<li>Large number laws (TO DO)</li>
<li>Stopped martingales (TO DO)</li>
<li>Multivariable calculus done correctly</li>
<li>Differential forms</li>
<li>Integrating differential forms</li>
<li>A bit of manifolds</li>
<li>Algebraic integers</li>
<li>Unique factorization (finally!)</li>
<li>Minkowski bound and class groups</li>
<li>More properties of the discriminant</li>
<li>Bonus: Let's solve Pell's equation!</li>
<li>Things Galois</li>
<li>Finite fields</li>
<li>Ramification theory</li>
<li>The Frobenius element</li>
<li>Bonus: A Bit on Artin Reciprocity</li>
<li>Some topological constructions</li>
<li>Fundamental groups</li>
<li>Covering projections</li>
<li>Objects and morphisms</li>
<li>Functors and natural transformations</li>
<li>Limits in categories (TO DO)</li>
<li>Abelian categories</li>
<li>Singular homology</li>
<li>The long exact sequence</li>
<li>Excision and relative homology</li>
<li>Bonus: Cellular homology</li>
<li>Singular cohomology</li>
<li>Application of cohomology</li>
<li>Affine varieties</li>
<li>Affine varieties as ringed spaces</li>
<li>Projective varieties</li>
<li>Bonus: B\'ezout's theorem</li>
<li>Morphisms of varieties</li>
<li>Sheaves and ringed spaces</li>
<li>Localization</li>
<li>Affine schemes: the Zariski topology</li>
<li>Affine schemes: the sheaf</li>
<li>Interlude: nineteen examples of affine schemes</li>
<li>Morphisms of locally ringed spaces</li>
<li>Interlude: Cauchy's functional equation and Zorn's lemma</li>
<li>Zermelo-Fraenkel with choice</li>
<li>Ordinals</li>
<li>Cardinals</li>
<li>Inner model theory</li>
<li>Forcing</li>
<li>Breaking the continuum hypothesis</li>
</ol>
            </div></div>]]>
            </description>
            <link>https://web.evanchen.cc/napkin.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609749</guid>
            <pubDate>Sun, 27 Sep 2020 20:05:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Trades from the House of Representatives in 2020]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24609686">thread link</a>) | @volatilitywave
<br/>
September 27, 2020 | https://glimpse.info/congress | <a href="https://web.archive.org/web/*/https://glimpse.info/congress">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://glimpse.info/congress</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609686</guid>
            <pubDate>Sun, 27 Sep 2020 19:59:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sans Bullshit Sans: A font to fight against BS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24609556">thread link</a>) | @gsempe
<br/>
September 27, 2020 | http://pixelambacht.nl/2015/sans-bullshit-sans/ | <a href="https://web.archive.org/web/*/http://pixelambacht.nl/2015/sans-bullshit-sans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <article>
    
    <p>February 26, 2015</p>

    <p>Ever wonder what exactly is inside a font? We know it contains letters — or actually, drawings of letters, but what else is in there? Well, why not crack one open and see, and while we’re there, find a way to make this world a little less buzzwordy?</p>

<h2 id="laying-out-our-plan">Laying out our plan</h2>

<p>We’re going to create a font called <a href="http://www.sansbullshitsans.com/">Sans Bullshit Sans</a> and it’ll do something like this:</p>

<p><img src="http://pixelambacht.nl/img/sans-bullshit-sans-in-action.gif" alt="A text full of buzzwords is being typed out, with all the buzzwords being replaced with a sign saying 'bullshit'"></p>

<p>When using Sans Bullshit Sans, every buzzword will be replaced by a Comic Sans-styled censorship bar. And the cool part is, we won’t be using CSS or JavaScript for this, but plain ol’ OpenType font technology.</p>

<p>We’ll need three things for this project:</p>

<ol>
  <li>A font we can examine and edit</li>
  <li>Tools that allow us to edit fonts with a texteditor</li>
  <li>Our own ligatures</li>
</ol>

<p>We’ll take care of step one right away. Since we’re more or less reverse-engineering a font, we need one that allows us to legally do this. I decided on the open source font <a href="https://www.google.com/fonts/specimen/Droid+Sans">Droid Sans</a>, as its Apache license allows us to modify and redistribute it afterwards. Download it and save it to your favorite font hackin’ directory.</p>



<p>Most font tools focus on the designey part of fonts: drawing the actual letter shapes, and tweaking their details like kerning and hinting. Think of them like Photoshop for fonts: very graphical and with quite a steep learning curve.</p>

<p>But there is another way to edit fonts. Once they have been saved as a TTF, they hold all their data in a special format. This is the <a href="http://en.wikipedia.org/wiki/OpenType">OpenType format</a>, in which each letter has its own occurrence in various <em>tables</em>, each describing a specific property of that letter.</p>

<p>For example, the <em>glyf</em> table holds information about the shape of the characters in a font — it actually stores a drawing for each character. Other tables hold different info: the name of the type’s designer, the maximum height of the font, or which combinations of letters should be replaced by a ligature.</p>

<p>Fonts are binary files, generally unsuitable for being picked apart by humans. So if we want to look at those tables, we better translate them into something more readable, like plain text. Luckily for us, there’s TTX/Fonttools, a command line tool that converts fonts to XML and vice versa. The XML document can be opened, read, and edited with your favorite text editor and is actually quite readable for us humans.</p>

<p>You can download the original version on <a href="http://sourceforge.net/projects/fonttools/">Sourceforge</a>, but I recommend <a href="https://github.com/behdad/fonttools/">a fork by Behdad Esfahbod</a>. It’s actively maintained and gets bugfixes and new features (for instance, decoding of the <a href="http://pixelambacht.nl/2014/multicolor-fonts/">new color tables</a>. Follow either page’s installation instructions, or <a href="http://glyphrstudio.com/ttx/">this detailed one</a> for Windows.</p>

<h2 id="looking-under-droid-sans-hood">Looking under Droid Sans’ hood</h2>

<p>With TTX/Fonttools installed, let’s fire it up and have it decode Droid Sans:</p>

<figure><pre><code data-lang="bash"><span>$ </span>ttx DroidSans.ttf</code></pre></figure>

<p>TTX/Fonttools translates all the binary data in <code>DroidSans.ttf</code> to XML. While it does so, the output looks a little like this:</p>

<figure><pre><code data-lang="bash">Dumping <span>"DroidSans.ttf"</span> to <span>"DroidSans.ttx"</span>...
Dumping <span>'GlyphOrder'</span> table...
Dumping <span>'head'</span> table...
Dumping <span>'hhea'</span> table...
Dumping <span>'maxp'</span> table...
Dumping <span>'OS/2'</span> table...
Dumping <span>'hmtx'</span> table...
Dumping <span>'cmap'</span> table...
Dumping <span>'fpgm'</span> table...
Dumping <span>'prep'</span> table...
Dumping <span>'cvt '</span> table...
Dumping <span>'loca'</span> table...
Dumping <span>'glyf'</span> table...
Dumping <span>'name'</span> table...
Dumping <span>'post'</span> table...
Dumping <span>'gasp'</span> table...
Dumping <span>'FFTM'</span> table...
Dumping <span>'GDEF'</span> table...
Dumping <span>'GPOS'</span> table...
Dumping <span>'GSUB'</span> table...</code></pre></figure>

<p>You can see that besides the <em>glyf</em> table we talked about, there are about 18 other tables in Droid Sans. Some fonts have less, some more, but there’s always a basic set of tables that are needed for a valid font.</p>

<p>These tables hold every single detail about the font: a list which letters are in the font, the shapes of the letters, the name of the font — everything. Let’s take a quick look at Droid Sans’ <em>head</em> table, which contains global information about the font:</p>

<figure><pre><code data-lang="xml"><span>&lt;head&gt;</span>
  <span>&lt;!-- Most of this table will be recalculated by the compiler --&gt;</span>
  <span>&lt;tableVersion</span> <span>value=</span><span>"1.0"</span><span>/&gt;</span>
  <span>&lt;fontRevision</span> <span>value=</span><span>"1.0"</span><span>/&gt;</span>
  <span>&lt;checkSumAdjustment</span> <span>value=</span><span>"0x2e9ffae7"</span><span>/&gt;</span>
  <span>&lt;magicNumber</span> <span>value=</span><span>"0x5f0f3cf5"</span><span>/&gt;</span>
  <span>&lt;flags</span> <span>value=</span><span>"00000000 00011111"</span><span>/&gt;</span>
  <span>&lt;unitsPerEm</span> <span>value=</span><span>"2048"</span><span>/&gt;</span>
  <span>&lt;created</span> <span>value=</span><span>"Mon May 17 19:56:38 2010"</span><span>/&gt;</span>
  <span>&lt;modified</span> <span>value=</span><span>"Fri Jul  9 07:55:05 2010"</span><span>/&gt;</span>
  <span>&lt;xMin</span> <span>value=</span><span>"-352"</span><span>/&gt;</span>
  <span>&lt;yMin</span> <span>value=</span><span>"-492"</span><span>/&gt;</span>
  <span>&lt;xMax</span> <span>value=</span><span>"1966"</span><span>/&gt;</span>
  <span>&lt;yMax</span> <span>value=</span><span>"1907"</span><span>/&gt;</span>
  <span>&lt;macStyle</span> <span>value=</span><span>"00000000 00000000"</span><span>/&gt;</span>
  <span>&lt;lowestRecPPEM</span> <span>value=</span><span>"8"</span><span>/&gt;</span>
  <span>&lt;fontDirectionHint</span> <span>value=</span><span>"2"</span><span>/&gt;</span>
  <span>&lt;indexToLocFormat</span> <span>value=</span><span>"0"</span><span>/&gt;</span>
  <span>&lt;glyphDataFormat</span> <span>value=</span><span>"0"</span><span>/&gt;</span>
<span>&lt;/head&gt;</span></code></pre></figure>

<p><a href="http://www.microsoft.com/typography/otspec/head.htm">This table is required</a> for all OpenType fonts, and contains info like the minimum and maximum size for all glyphs in the font, and the number of units per em, which is the grid the glyphs are drawn against.</p>

<p>For now we’re only interested in those units per em:</p>

<figure><pre><code data-lang="xml"><span>&lt;unitsPerEm</span> <span>value=</span><span>"2048"</span><span>/&gt;</span></code></pre></figure>

<p>When we create our ligatures, we’ll use the same value. That way the dimensions of our characters, most importantly the vertical height, will match up precisely with that of Droid Sans.</p>

<p>For now we leave the TTX file for what it is. We’ll come back to it later when we add our actual ligatures.</p>

<h2 id="designing-our-ligatures">Designing our ligatures</h2>

<p>This is the plan: we have <a href="http://ngenworks.com/blog/250-buzzwords-we-love-to-hate/">a list of buzzwords</a>, and we’re going to (ab)use the OpenType feature of <em>ligatures</em> to replace those words with something of our own choosing: a sign that says “bullshit”:</p>

<p><img src="http://pixelambacht.nl/img/bs-medium.svg" alt="Crude hand drawn black bar with the word 'bullshit' written over it"></p>

<p>A ligature is when a string of characters (or a sequence of <em>glyphs</em> representing those characters) are replaced by one single glyph:</p>

<p><img src="http://pixelambacht.nl/img/infinite.svg" alt=""></p>

<p>Ligatures improve legibility: instead of awkwardly overlapping parts of the letters (like the upper curve of the <em>f</em> and the dot of the <em>i</em>), the type designer can create a custom shape that looks a lot nicer. Another function of ligatures is joining letters in a different way in handwritten or brush typefaces. Fun fact: the well known ampersand, <em>&amp;</em>, was originally a ligature for “et”, meaning “and” in Latin.</p>

<p>Not all fonts offer ligatures: it’s the choice of the type designer, or the distributor of the font, to create or include them. For instance, Google’s web versions are stripped of ligatures so they result in smaller files. Type aficionados might cringe, but it makes sense: ligature support in web browsers is still kinda shaky, so it would be a waste to have people download stuff they can’t use.</p>

<p>For ligatures to work, a font has to have a <em>GSUB</em> table (the Glyph Substitution table), which has entries about which combination of letters should be replaced by a ligature. It’ll say “for the letter combination <em>f</em> and <em>i</em>, show the <em>fi</em>-ligature.”</p>

<p>We’re going to use this table to turn words like “synergy” into a “bullshit”-ligature.</p>

<p>It’s probably worth noting that what we’re doing here is far from proper use of the ligature functionality. True type-folks will rightfully scoff at this juvenile misuse of a feature like this, but I thought it was a neat way to learn about how fonts work.</p>

<p>With that disclaimer out of the way, let’s draw three ligatures — one for short words, one for medium words, and one for long words. Fire up Illustrator or any other vector drawing tool that can save SVGs, and draw our soon-to-be ligatures:</p>

<p><img src="http://pixelambacht.nl/img/three-bullshits.svg" alt=""></p>

<p>Looking good? I think so. Let’s turn these into ligatures!</p>

<h2 id="turning-svg-files-into-a-font">Turning SVG files into a font</h2>

<p>We now have three SVG files and a reverse-engineered font waiting for ‘em. But even though both SVG and glyphs are vector images, they’re different formats, so we can’t just copy them over. We need to convert them to something OpenType can understand.</p>

<p>To do this, I find it easiest to create a new font from our SVGs, with specs matching our target font. If we’d pass that font through TTX, we can simply copy-and-paste the parts of the XML.</p>

<p>To create a font from SVGs, we can choose from a wide range of command line tools, web apps, or full-fledged font editors. I used the web based tool <a href="http://icomoon.io/">Icomoon</a>.</p>

<p>The steps are straightforward: create a new empty font, import the SVG images, and export the font. All Icomoon’s settings can be left on default, except the units per em. If we keep those the same as Droid Sans’, we can simply copy our glyphs over without recalculating dimensions and offsets. On the download screen, click the preferences-button and head over to the font metrics. Under “Em square height” we fill in 2048, the number we noted from Droid Sans.</p>

<p>To make creating our own ligatures a lot easier, we already define one for each SVG. Click the “fi” button on the top of the screen to enable ligatures for our font, and you’ll see an input field appear for each character. Enter a word, like “ninja” for the smallest ligature, to create a <em>GSUB</em> table entry that we’ll use as blueprint for our word list.</p>

<p>We’re ready to download the font! Unzip it, and move the TTF over to your font hackin’ directory.</p>

<h2 id="transplanting-our-ligatures">Transplanting our ligatures</h2>

<p>We now have a font that contains only our three bullshit drawings — no letters, no punctuation marks, no icons, just our bullshit images. At this point, they’re mapped to characters in <a href="http://en.wikipedia.org/wiki/Private_Use_Areas">Unicode’s PUA</a> (0xE600, 0xE601 and 0xE602). As you will see in a minute, these codes also make up their internal name.</p>

<p>Next step: moving our bullshit characters over to Droid Sans. We do this by converting <code>bullshit.ttf</code> to <code>bullshit.ttx</code> so it’s openable in our favorite text editor. This is the same thing as we did with Droid Sans:</p>

<figure><pre><code data-lang="bash"><span>$ </span>ttx bullshit.ttf</code></pre></figure>

<p>We don’t need everything in this TTX file. All the data we’re interested in is contained in five tables:</p>

<ul>
  <li>GlyphOrder (entry GlyphID)</li>
  <li>hmtx (entry mtx)</li>
  <li>cmap (entry map)</li>
  <li>glyf (entry TTGlyph)</li>
  <li>GSUB</li>
</ul>

<p>As we seen before, each table handles one specific feature or detail for each of the characters in a font. Let’s take a look:</p>

<h3 id="table-one-glyphorder">Table one: GlyphOrder</h3>

<p>This is a table generated by the TTX/Fonttools tool, and is not part of the OpenType spec. It simply lists all the characters inside the font. The glyph ordering is stored explicitly-but-implicitly in the <em>glyf</em> table, TTX/Fonttools just makes it easier for you to reorder them by giving you this <em>GlyphOrder</em> table.</p>

<p>We need to take our two entries in <code>bullshit.ttx</code> and stick ‘em to the end of the <em>GlyphOrde…</em></p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://pixelambacht.nl/2015/sans-bullshit-sans/">http://pixelambacht.nl/2015/sans-bullshit-sans/</a></em></p>]]>
            </description>
            <link>http://pixelambacht.nl/2015/sans-bullshit-sans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609556</guid>
            <pubDate>Sun, 27 Sep 2020 19:42:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elementary schools deliberately fail to teach knowledge, hurting children]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24609304">thread link</a>) | @jseliger
<br/>
September 27, 2020 | https://www.persuasion.community/p/they-dont-need-no-education | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/they-dont-need-no-education">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76d8ea4d-10bf-46e0-9d06-cedcebc1b849_5300x3535.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F76d8ea4d-10bf-46e0-9d06-cedcebc1b849_5300x3535.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/76d8ea4d-10bf-46e0-9d06-cedcebc1b849_5300x3535.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:13717881,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Take two first-grade classrooms, both full of bright-eyed, eager children from low-income families. In one, the lesson focuses on how a caption differs from a title or a subtitle, in that it’s a “label for a picture.” The children clamor to know more about the pictures themselves: What’s the shark eating? What planet is that? But the teacher deflects their questions, trying to get the six-year-olds to focus on locating the captions.</p><p>In the other classroom, children listen in fascination as their teacher reads a book about mummies. In passing, the teacher points out a caption on a photo of a sarcophagus. But the focus is on mummies: how they were preserved, how scientists can tell that they had used hair gel or eaten vegetable soup when they were alive. At the end, the kids are full of questions, which the teacher answers until it’s time to stop.&nbsp;</p><p>The first class reflects the now standard approach of focusing on “comprehension skills” like finding the main idea, making inferences or identifying text features like captions. The theory is that kids who master these skills will, later on, be able to use them to acquire knowledge from their own reading—and to do well on high-stakes standardized reading tests.</p><p>As a result, the subjects that could build kids’ knowledge—social studies, science, the arts—<a href="http://www.ascd.org/publications/educational_leadership/mar11/vol68/num06/High-Stakes_Testing_Narrows_the_Curriculum.aspx">have, over the last twenty years, been edged out</a> to make more time for comprehension skill practice. But as cognitive scientists&nbsp;<a href="https://www.nytimes.com/2017/11/25/opinion/sunday/how-to-get-your-mind-to-read.html">have discovered</a>, the key factor in comprehension isn’t skill; it’s subject-specific knowledge and vocabulary. And so, for all its good intentions, the approach that now dominates public schools across America only ends up further penalizing disadvantaged students. (Comprehension, of course, is only one aspect of reading. Children also need to learn how to sound out words—and there are huge problems with the way many schools teach that, also with&nbsp;<a href="https://www.apmreports.org/episode/2020/08/06/what-the-words-say">a disproportionately negative impact</a> on disadvantaged students.)</p><p>Children from wealthier and better educated families are likely to pick up the background knowledge they need to understand a wide variety of texts at home. Their parents are better able to provide enriching experiences and engage them in conversations that involve sophisticated concepts and vocabulary. Such kids start school better equipped to understand more complex books. And because knowledge tends to build on related knowledge, they’re able to acquire more knowledge through their reading, allowing them to read even more complex books.&nbsp;</p><p>Meanwhile, their less advantaged peers fall farther behind every year. By high school, the gap between these two groups is huge—as is the gap between what teenagers are assumed to know and what many actually do. At high schools serving low-income populations, students may arrive unaware of the difference between a city and a state or a country and a continent, or confuse the Civil War with the Civil Rights movement. That’s because they have not been taught these things early enough.</p><p>Testing may have exacerbated the focus on skills over content. But the roots of the obsession with skills go deeper. They rest on suspicion of the very idea that knowledge should be transmitted.</p><p>For decades, prospective teachers have been inculcated with the belief that it’s better for students to discover knowledge for themselves than to have someone explain things to them. Storing information in your head, they are told, is unnecessary since students can always look up what they need; besides, kids find facts boring. Far better, the theory goes, to focus on skills like comprehension and critical thinking. And many educators are skeptical of&nbsp;<em>any&nbsp;</em>prescribed curriculum on the grounds that teachers should be guided by the interests of their particular students.</p><p>Learners do need to participate in constructing their knowledge, and students who are merely lectured at can become disengaged. But we can’t assume that all elementary students will acquire the&nbsp;information they need for themselves. For children starting out with limited knowledge of the world, this approach is often a dead end.</p><p>When students are new to a topic, direct instruction&nbsp;<a href="https://www.tandfonline.com/doi/abs/10.1207/s15326985ep4102_1">works best</a>. Factual knowledge&nbsp;<a href="https://www.aft.org/sites/default/files/periodicals/Crit_Thinking.pdf">is also a prerequisite</a> for critical thinking: the more knowledge you have relating to a topic, the better equipped you are to think about it critically. And despite the current pedagogical consensus, kids are excited about discovering things and learning facts. As for following students’ interests, kids rarely express interest in subjects they don’t know anything about—and they often become intensely interested in new topics if they’re explained in an engaging way.</p><p>Another objection to foregrounding content is that it may reflect political or cultural bias. That objection isn’t new. An effort to craft voluntary national history standards in the 1990s foundered when right-wingers denounced them as being anti-American and focusing too squarely on marginalized groups. Conversely, leftists have, since at least the 1980s, expressed concerns that students of color will not feel represented if the knowledge covered in schools is too “Eurocentric,” or if all the books they study are written by dead white males.</p><p>Now, the old battles over historical and cultural content are being reignited. In some quarters, attributes like rational, linear thinking and an emphasis on the written word are <a href="https://www.amny.com/opinion/cathy-young-nyc-diversity-1-31720835/">being</a> denounced as part of&nbsp;<em>white culture</em>. Donald Trump is making “left-wing indoctrination” in the nation’s schools a campaign issue,&nbsp;<a href="https://www.whitehouse.gov/briefings-statements/remarks-president-trump-white-house-conference-american-history/">citing</a>, among other things, the New York Times’ 1619 Project, which has inspired a&nbsp;<a href="https://pulitzercenter.org/lesson-plan-grouping/1619-project-curriculum">curriculum</a> focused on the history and legacy of slavery. To avoid battles over “whose” knowledge to teach, even some who acknowledge the defects of a skills-focused curriculum may feel the need to stick with it.&nbsp;</p><p>But if we don’t provide all children with access to the knowledge that children of the elite routinely acquire, we will continue to preserve, not lessen, social inequities. One group of students—and adults—will understand references to key cultural touchstones while others will feel mystified and excluded.&nbsp;</p><p>Over the past few years, some new curricula for elementary schools have put the emphasis on building knowledge rather than skills. But some on the left have resisted these initiatives on the ground that they don’t sufficiently center the experience of black and brown students. </p><p>If these critics aim to help disadvantaged students gain the kind of education that will enable them to escape poverty and fulfill their responsibilities as citizens, it’s incumbent on them to create curricula that answer these objections&nbsp;<em>and&nbsp;</em>build knowledge. The worst thing we can do to children who rely on schools for their education is to deny them access to knowledge until it’s too late.</p><p><strong>Natalie&nbsp;Wexler&nbsp;is the author of&nbsp;The Knowledge Gap: The Hidden Cause of American's Broken Education System—And How to Fix It.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/they-dont-need-no-education</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609304</guid>
            <pubDate>Sun, 27 Sep 2020 19:09:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s use of Swift and SwiftUI in iOS 14]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 129 (<a href="https://news.ycombinator.com/item?id=24609096">thread link</a>) | @Timac
<br/>
September 27, 2020 | https://blog.timac.org/2020/0927-state-of-swift-ios14/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/0927-state-of-swift-ios14/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
            

            <div id="container">


<div>
    <article>
        

        <div>
    <p>Swift was introduced a couple of years ago at Apple's 2014 WWDC. Over the years I analyzed iOS to measure how many built-in applications were using Swift. iOS 9 released in 2015 included a single application written with Swift: Calculator. Since then this number has grown with each iOS release: <a href="https://blog.timac.org/2016/1101-apples-use-of-swift-in-ios-10-1-and-macos-10-12/">iOS 10.1</a>, <a href="https://blog.timac.org/2017/1115-state-of-swift-ios11-1-macos10-13/">iOS 11.1</a>, <a href="https://blog.timac.org/2018/0924-state-of-swift-ios12/">iOS 12.0</a> and finally <a href="https://blog.timac.org/2019/0926-state-of-swift-ios13/">iOS 13.1</a>.</p>
<p>iOS 14 is now available so let's check how this number evolved since iOS 13. Apple announced SwiftUI during WWDC 2019, a year ago. In this article I will also try to measure which built-in apps are using this new UI framework.</p>

<p>The methodology and tools used for this article have been detailed in the previous posts. If you are interested, please refer to <a href="https://blog.timac.org/2016/1101-apples-use-of-swift-in-ios-10-1-and-macos-10-12/">Apple’s use of Swift in iOS 10.1 and macOS 10.12</a>.</p>
<p>Later in this article, I describe how I adjusted the tools to detect SwiftUI.</p>

<p>iOS 14.0 contains 351 binaries and frameworks using Swift. Note that these binaries might contain a single line of Swift code and are not necessarily entirely written in Swift. This list has been built using iOS 14.0 (18A373) for iPhone 11 Pro Max:</p>
<pre><code>/Applications/ActivityMessagesApp.app/PlugIns/ActivityMessagesExtension.appex/ActivityMessagesExtension
/Applications/AppStore.app/AppStore
/Applications/AppStore.app/PlugIns/ProductPageExtension.appex/ProductPageExtension
/Applications/AppStore.app/PlugIns/SubscribePageExtension.appex/SubscribePageExtension
/Applications/BusinessExtensionsWrapper.app/PlugIns/Business.appex/Business
/Applications/Diagnostics.app/Diagnostics
/Applications/FindMy.app/FindMy
/Applications/FindMy.app/PlugIns/FindMyNotificationsContent.appex/FindMyNotificationsContent
/Applications/FindMy.app/PlugIns/FindMyNotificationsService.appex/FindMyNotificationsService
/Applications/FindMy.app/PlugIns/FindMySiriIntents.appex/FindMySiriIntents
/Applications/FTMInternal-4.app/FTMInternal-4
/Applications/GameCenterUIService.app/PlugIns/GameCenterMessageExtension.appex/GameCenterMessageExtension
/Applications/Health.app/Health
/Applications/HealthENBuddy.app/HealthENBuddy
/Applications/HealthENLauncher.app/HealthENLauncher
/Applications/InCallService.app/InCallService
/Applications/Magnifier.app/Magnifier
/Applications/MobilePhone.app/MobilePhone
/Applications/MobileSlideShow.app/PlugIns/PhotosReliveWidget.appex/PhotosReliveWidget
/Applications/MobileTimer.app/PlugIns/WorldClockWidget.appex/WorldClockWidget
/Applications/SharingViewService.app/SharingViewService
/Applications/Sidecar.app/PlugIns/ContinuityCamera.appex/ContinuityCamera
/Applications/Sidecar.app/PlugIns/ContinuityDisplay.appex/ContinuityDisplay
/Applications/Sidecar.app/PlugIns/ContinuityMarkup.appex/ContinuityMarkup
/Applications/Sidecar.app/PlugIns/ContinuitySignature.appex/ContinuitySignature
/Applications/Sidecar.app/PlugIns/ContinuitySketch.appex/ContinuitySketch
/Applications/Sidecar.app/Sidecar
/Applications/SleepLockScreen.app/SleepLockScreen
/private/var/staged_system_apps/AppleTV.app/PlugIns/TVWidgetExtension.appex/TVWidgetExtension
/private/var/staged_system_apps/Books.app/Books
/private/var/staged_system_apps/Books.app/Frameworks/BookCore.framework/BookCore
/private/var/staged_system_apps/Books.app/Frameworks/JSApp.framework/JSApp
/private/var/staged_system_apps/Calculator.app/Calculator
/private/var/staged_system_apps/Files.app/Files
/private/var/staged_system_apps/Fitness.app/Fitness
/private/var/staged_system_apps/Fitness.app/PlugIns/FitnessWidget.appex/FitnessWidget
/private/var/staged_system_apps/Maps.app/PlugIns/GeneralMapsWidget.appex/GeneralMapsWidget
/private/var/staged_system_apps/Measure.app/Measure
/private/var/staged_system_apps/MobileCal.app/PlugIns/CalendarWidgetExtension.appex/CalendarWidgetExtension
/private/var/staged_system_apps/MobileNotes.app/MobileNotes
/private/var/staged_system_apps/MobileNotes.app/PlugIns/com.apple.mobilenotes.SharingExtension.appex/com.apple.mobilenotes.SharingExtension
/private/var/staged_system_apps/MobileNotes.app/PlugIns/com.apple.mobilenotes.WidgetExtension.appex/com.apple.mobilenotes.WidgetExtension
/private/var/staged_system_apps/Music.app/Frameworks/MusicApplication.framework/MusicApplication
/private/var/staged_system_apps/Music.app/Frameworks/MusicApplication.framework/XPCServices/MusicScriptUpdateService.xpc/MusicScriptUpdateService
/private/var/staged_system_apps/Music.app/Music
/private/var/staged_system_apps/Music.app/PlugIns/MediaPicker.appex/MediaPicker
/private/var/staged_system_apps/Music.app/PlugIns/MusicMessagesApp.appex/MusicMessagesApp
/private/var/staged_system_apps/Music.app/PlugIns/MusicNotificationContentExtension.appex/MusicNotificationContentExtension
/private/var/staged_system_apps/Music.app/PlugIns/MusicWidgets.appex/MusicWidgets
/private/var/staged_system_apps/Music.app/PlugIns/PlaybackIntent.appex/PlaybackIntent
/private/var/staged_system_apps/News.app/PlugIns/NewsAudioExtension.appex/NewsAudioExtension
/private/var/staged_system_apps/News.app/PlugIns/NewsTag.appex/NewsTag
/private/var/staged_system_apps/News.app/PlugIns/NewsToday2.appex/NewsToday2
/private/var/staged_system_apps/News.app/PlugIns/NewsTodayIntents.appex/NewsTodayIntents
/private/var/staged_system_apps/Podcasts.app/Frameworks/AppStoreKit.framework/AppStoreKit
/private/var/staged_system_apps/Podcasts.app/Frameworks/NowPlayingUI.framework/NowPlayingUI
/private/var/staged_system_apps/Podcasts.app/Frameworks/PodcastsStoreUI.framework/PodcastsStoreUI
/private/var/staged_system_apps/Podcasts.app/PlugIns/PodcastsClassKitExtension.appex/PodcastsClassKitExtension
/private/var/staged_system_apps/Podcasts.app/PlugIns/PodcastsWidget.appex/PodcastsWidget
/private/var/staged_system_apps/Podcasts.app/Podcasts
/private/var/staged_system_apps/Reminders.app/PlugIns/RemindersIntentsExtension.appex/RemindersIntentsExtension
/private/var/staged_system_apps/Reminders.app/PlugIns/RemindersIntentsUIExtension.appex/RemindersIntentsUIExtension
/private/var/staged_system_apps/Reminders.app/PlugIns/RemindersSharingExtension.appex/RemindersSharingExtension
/private/var/staged_system_apps/Reminders.app/PlugIns/RemindersSpotlightIndexExtension.appex/RemindersSpotlightIndexExtension
/private/var/staged_system_apps/Reminders.app/PlugIns/RemindersWidgetExtension.appex/RemindersWidgetExtension
/private/var/staged_system_apps/Reminders.app/Reminders
/private/var/staged_system_apps/SequoiaTranslator.app/PlugIns/CacheDeleteExtension.appex/CacheDeleteExtension
/private/var/staged_system_apps/SequoiaTranslator.app/SequoiaTranslator
/private/var/staged_system_apps/Shortcuts.app/Shortcuts
/private/var/staged_system_apps/Stocks.app/PlugIns/StocksDetailIntents.appex/StocksDetailIntents
/private/var/staged_system_apps/Stocks.app/PlugIns/StocksWidget.appex/StocksWidget
/private/var/staged_system_apps/Stocks.app/Stocks
/private/var/staged_system_apps/Tips.app/PlugIns/TipsSwift.appex/TipsSwift
/private/var/staged_system_apps/Weather.app/PlugIns/WeatherWidget.appex/WeatherWidget
[...]
</code></pre>
<p>You can get the full list here: <a href="https://blog.timac.org/2020/0927-state-of-swift-ios14/BinariesUsingSwift.txt">BinariesUsingSwift.txt</a></p>

<p>SwiftUI, announced at WWDC 2019, is a new framework to build user interfaces with Swift. As a consequence a binary using SwiftUI will use Swift. Can we get the list of built-in apps using SwiftUI?</p>
<p>When I worked on the iOS 14 widgets for <a href="https://apps.apple.com/app/clatters/id1480930237">Clatters 3.0</a>, I noted that the widgets were linking against <code>/System/Library/Frameworks/SwiftUI.framework/Versions/A/SwiftUI</code>.</p>
<p><em>( <a href="https://apps.apple.com/app/clatters/id1480930237">Clatters</a> lets you easily monitor in one place your brand, product or any other keyword on your favorite social networks - Twitter, Reddit, HackerNews and even comments on the iOS App Store. You should check it out at <a href="https://apps.apple.com/app/clatters/id1480930237">https://apps.apple.com/app/clatters/id1480930237</a>! 😜 )</em></p>
<p>The script detecting Swift could easily be adjusted to detect SwiftUI by using this line:</p>
<pre><code>otool -L $1 2&gt;/dev/null | grep -o /System/Library/Frameworks/SwiftUI.framework/SwiftUI | wc -l
</code></pre>

<p>Until now I did not publish the list of apps using SwiftUI in iOS. To have a first reference, I built the list for iOS 13.7. With no surprise, iOS 13.7 only contained a handful of binaries relying on SwiftUI:</p>
<pre><code>/Applications/SharingViewService.app/SharingViewService
/System/Library/Frameworks/SwiftUI.framework/SwiftUI
/System/Library/PrivateFrameworks/Settings/LegalAndRegulatorySettingsPrivate.framework/LegalAndRegulatorySettingsPrivate
/System/Library/PrivateFrameworks/Settings/SettingsUIKitPrivate.framework/SettingsUIKitPrivate
/System/Library/PrivateFrameworks/Settings/WallpaperSettings.framework/WallpaperSettings
/System/Library/PrivateFrameworks/VideosUI.framework/VideosUI
</code></pre>

<p>iOS 14.0 contains a lot more binaries using SwiftUI. The primary reason is without a doubt WidgetKit, the first public SwiftUI-only framework.
Each widget available in iOS 14 appears in this list. Another shiny new iOS 14 feature is the Translate app  which appears to be built with SwiftUI.</p>
<pre><code>/Applications/MobilePhone.app/MobilePhone
/Applications/MobileSlideShow.app/PlugIns/PhotosReliveWidget.appex/PhotosReliveWidget
/Applications/MobileTimer.app/PlugIns/WorldClockWidget.appex/WorldClockWidget
/Applications/SharingViewService.app/SharingViewService
/Applications/SleepLockScreen.app/SleepLockScreen
/private/var/staged_system_apps/AppleTV.app/PlugIns/TVWidgetExtension.appex/TVWidgetExtension
/private/var/staged_system_apps/Fitness.app/PlugIns/FitnessWidget.appex/FitnessWidget
/private/var/staged_system_apps/Maps.app/PlugIns/GeneralMapsWidget.appex/GeneralMapsWidget
/private/var/staged_system_apps/MobileCal.app/PlugIns/CalendarWidgetExtension.appex/CalendarWidgetExtension
/private/var/staged_system_apps/MobileNotes.app/PlugIns/com.apple.mobilenotes.WidgetExtension.appex/com.apple.mobilenotes.WidgetExtension
/private/var/staged_system_apps/Music.app/PlugIns/MusicWidgets.appex/MusicWidgets
/private/var/staged_system_apps/News.app/PlugIns/NewsTag.appex/NewsTag
/private/var/staged_system_apps/News.app/PlugIns/NewsToday2.appex/NewsToday2
/private/var/staged_system_apps/Podcasts.app/PlugIns/PodcastsWidget.appex/PodcastsWidget</code></pre></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.timac.org/2020/0927-state-of-swift-ios14/">https://blog.timac.org/2020/0927-state-of-swift-ios14/</a></em></p>]]>
            </description>
            <link>https://blog.timac.org/2020/0927-state-of-swift-ios14/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24609096</guid>
            <pubDate>Sun, 27 Sep 2020 18:43:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Picat 3.0 released (logic-based multi-paradigm programming language)]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24608997">thread link</a>) | @callmekit
<br/>
September 27, 2020 | http://picat-lang.org/updates.txt | <a href="https://web.archive.org/web/*/http://picat-lang.org/updates.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://picat-lang.org/updates.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24608997</guid>
            <pubDate>Sun, 27 Sep 2020 18:32:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discrete Optimization for On-Call Scheduling]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24608417">thread link</a>) | @dowakin
<br/>
September 27, 2020 | https://optduty.com/blog/2020-08-29-schedule-optimization/ | <a href="https://web.archive.org/web/*/https://optduty.com/blog/2020-08-29-schedule-optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>The engineering team of <a href="https://www.rainforestqa.com/">RainforestQA (YC S12)</a> is remote and distributed around the globe, with developers in America, Europe, and Asia. Our working hours cover almost all time-zones, about 22 hours from full time-zone coverage. Yet for distributing our on-call schedule, we were unhappy with PagerDuty’s standard daily rotation. ​​For a distributed team, why does somebody need to be on-call at night when other team members are working right now?</p>
<h2 id="the-tyrant">The Tyrant</h2>
<p>Starting in 2017, a new internal project for on-call scheduling was born - the Tyrant - as tool to handle On-Call scheduling across time-zones.</p>
<p>Over time the project evolved - scheduling algorithm and technology. In 2019, during a hackathon session in Kuala Lumpur (<a href="https://www.rainforestqa.com/blog/2019-10-09-a-guide-to-running-company-offsites">learn how to run off-sites for distributed teams</a>), the latest version created with discrete optimization as its core.</p>
<p>Tyrant runs as a cron job every Saturday. It gets hour’s preferences from developers, builds on-call schedule, and pushes it to PagerDuty ​​plus emails to folks.</p>
<p>This series of blog posts will describe all the technical details about using discrete optimization for building schedule.</p>
<p><img src="https://static.optduty.com/images/schedule_after-min.png"></p>
<h2 id="what-is-discrete-optimization">What is Discrete Optimization</h2>
<p>Discrete optimization is the selection of a best element (answer) with regard to some criterion, and where some of the variables are restricted to be discrete. For practical purposes it is a DSL. A user models the problem in specific language, and solvers finds the best answer.</p>
<p>I had used discrete optimization for a few small hobby projects and for programming challenges. But for a long time I could not find a use in day-to-day jobs; every time I had a project solvable by discrete optimization - some naive algorithms always beat it. Sometimes by speed; sometimes better quality over naive algorithms was not worth paying by extra complexity.</p>
<p>Tyrant is a completely different story. As it creates the schedule only once per week, speed isn’t important - the quality of the result is.</p>
<p><img src="https://www.minizinc.org/MiniZn_logo.png" width="100"></p>
<p>Tyrant’s core is implemented in <a href="https://www.minizinc.org/">MiniZinc</a> and the first 3 blog posts will cover it. MiniZinc is a high-level modelling language and compiler. MiniZinc compiles into FlatZinc, a low-level language that is understood by a wide range of solvers (an implementation of a discrete optimization algorithm). For us it means faster development, self-explanatory model, and ability to switch solvers.</p>

<p><img src="https://scipopt.org/images/newscippy.png" width="100"></p>
<p>In Part 4, we’ll look inside MiniZinc by manually translation an on-call model to low-level mixed integer format <a href="http://polip.zib.de/pipformat.php">PIP-format</a>, and then solve the problem with <a href="https://www.scipopt.org/">SCIP</a> solver.</p>

<h3 id="introduction-to-minizinc">Introduction to MiniZinc</h3>
<p>Let’s explore a simple problem to familiarize ourselves with the basic MiniZinc syntax. Imagine a small car factory named “BetterThanTesla”. You have 100 lithium batteries, and 190000 kilograms of metal. Building a “Cybertruck” requires 1 battery and 2500 kg of metal, while building “Model3” requires also 1 battery, but only 1500 kg of metal. You would like to know how many of each cars to produce to maximize profit if you can sell “Cybertruck” for $40k and “Model3” for $35k.</p>
<div><pre><code data-lang="MiniZinc"><span>int</span>: total_nb_battery <span>=</span> <span>100</span>;  <span>% fixed, input parameters
</span><span></span><span>int</span>: total_kg_metal <span>=</span> <span>190000</span>; <span>% fixed, input parameters
</span><span></span>
<span>% variable, possible number of different cars
</span><span></span><span>var</span> <span>0</span><span>..</span>total_nb_battery: nb_cybertruck;
<span>var</span> <span>0</span><span>..</span>total_nb_battery: nb_model3;

<span>var</span> <span>int</span>: profit <span>=</span> nb_cybertruck <span>*</span> <span>40000</span> <span>+</span> nb_model3 <span>*</span> <span>35000</span>;

<span>% limit total number of kilograms
</span><span></span><span>constraint</span> nb_cybertruck <span>*</span> <span>2500</span> <span>+</span> nb_model3 <span>*</span> <span>1500</span> <span>&lt;=</span> total_kg_metal;
<span>% limit total number of batteries
</span><span></span><span>constraint</span> nb_cybertruck <span>+</span> nb_model3 <span>&lt;=</span> total_nb_battery;

<span>solve</span> <span>maximize</span> profit;
</code></pre></div><p>The amount of words to describe the problem in English would be about the same as in MiniZinc. The code is self-explanatory even without knowing a lot about the syntax.</p>
<p>There’s a few nuances:</p>
<ul>
<li><code>int</code> (first 2 lines) fixed integer variables - value should be defined</li>
<li><code>var int</code> unfixed integer variable - MiniZinc figures out the value later</li>
<li><code>constraint</code> some expression that should be true</li>
</ul>
<p>The line: <code>var 0..total_nb_battery: nb_model3;</code> says variable <code>nb_model3</code> should be an integer from 0 to total_nb_battery. This could be written as:</p>
<div><pre><code data-lang="MiniZinc"><span>var</span> <span>int</span>: nb_model3;
<span>constraint</span> nb_model3 <span>&gt;=</span> <span>0</span>;
<span>constraint</span> nb_model3 <span>&lt;=</span> total_nb_battery;
</code></pre></div><p>The last line <code>solve maximize profit</code> tells MiniZinc what to optimize.</p>
<p>If you run: <code>minizinc hello1.mzn --output-objective</code>, you should get how many cars to build in order to maximize profit: $3.7M:</p>
<div><pre><code data-lang="MiniZinc">nb_cybertruck <span>=</span> <span>40</span>;
nb_model3 <span>=</span> <span>60</span>;
_objective <span>=</span> <span>3700000</span>;
<span>----------</span>
<span>==========</span>
</code></pre></div><p><code>---</code> means it found a solution, <code>===</code> means it found the optimal solution.</p>
<p><a href="https://github.com/skrypka/minizinc_workshop/tree/master/hello1">Source code of hello world</a></p>
<h3 id="with-data-file">With data file</h3>
<p>To reuse the model we skip defining fixed variables in the model.</p>
<div><pre><code data-lang="MiniZinc"><span>int</span>: total_nb_battery;
<span>int</span>: total_kg_metal;
</code></pre></div><p>And create separate data file <code>hello2.dzn</code>:</p>
<div><pre><code data-lang="MiniZinc">total_nb_battery <span>=</span> <span>100</span>;
total_kg_metal <span>=</span> <span>190000</span>;
</code></pre></div><p>Command to run model with the separate data file: <code>minizinc hello2.mzn hello2.dzn</code> (Btw, file extension is important for MiniZinc)</p>
<p><a href="https://github.com/skrypka/minizinc_workshop/tree/master/hello2">Source code of hello world with data file</a></p>
<h2 id="building-our-first-on-call-schedule-model">Building our first On-call schedule model</h2>
<p>Now we’re prepared to build our first, simplified on-call scheduling model. For input, the model takes developers' preferences (does developer X want to be on-call at hour Y). The output: assign a developer to every hour next week.
The final assignment should follow only one constraint: assign a developer to an hour according to their preferences.</p>
<h3 id="data-structures-of-scheduling-model">Data Structures of scheduling model</h3>
<p>A famous book by Niklaus Wirth was named <code>Algorithms + Data Structures = Programs</code>. For discrete optimization modeling, MiniZinc does <code>Algorithms</code>, so only <code>Data Structures</code> left to us. For this problem, we have 2 core data structures to define: Input and Output.</p>
<p>For output we use an array <code>assignment</code>, which maps from week hour to a developer. The size is 168 (7 days * 24 hours).</p>
<div><pre><code data-lang="MiniZinc"><span>int</span>: nb_workers;
<span>set</span> <span>of</span> <span>int</span>: HOURS <span>=</span> <span>1</span><span>..</span><span>168</span>;
<span>set</span> <span>of</span> <span>int</span>: WORKERS <span>=</span> <span>1</span><span>..</span>nb_workers;

<span>array</span>[HOURS] <span>of</span> <span>var</span> WORKERS: assignment;
</code></pre></div><p>Consider <code>set of int</code> as some sort enumeration of numbers from start to end (including end). MiniZinc arrays have named indexes. In our example, <code>assignment</code> has named indexes based on range <code>HOURS</code> (1..168). The statement <code>array[HOURS] of var WORKERS: assignment = [7, 8, 9, ..]</code> means developer <code>7</code> will be on-call at hour <code>1</code> (first index of <code>HOURS</code> range).</p>
<p>Input data will also be array, but 2 dimensional, with size <code>WORKERS</code> × <code>HOURS</code>. It’s a mapping from a developer and an hour to a 0..1 integer. Where 1 means a developer is available for on-call.</p>
<div><pre><code data-lang="MiniZinc"><span>array</span>[WORKERS, HOURS] <span>of</span> <span>0</span><span>..</span><span>1</span>: working_hours;
</code></pre></div><p>Example of a data file (notice how rows separated with <code>|</code> symbol):</p>
<div><pre><code data-lang="MiniZinc">nb_workers <span>=</span> <span>3</span>;

working_hours <span>=</span> [|
<span>0</span>, <span>0</span>, <span>1</span>, <span>..</span><span>.</span>, <span>0</span> |
<span>0</span>, <span>1</span>, <span>1</span>, <span>..</span><span>.</span>, <span>0</span> |
<span>1</span>, <span>0</span>, <span>0</span>, <span>..</span><span>.</span>, <span>1</span> |];
</code></pre></div><p>One note about nb_workers. Theoretically we could get the value of <code>nb_workers</code> from <code>working_hours</code>, but in practice it’s chicken or egg problem. MiniZinc needs to know <code>nb_workers</code> to define indexes(type) for the <code>working_hours</code> array.</p>
<h3 id="constraint-and-objective">Constraint and objective</h3>
<p>We have only one constraint for now: follow the <code>working_hours</code> input data. We iterate all elements of the <code>working_hours</code> array, and if some developer is unavailable at a specific hour (== 0), then <code>assignment</code> at that hour should not be equal to the unavailable worker.</p>
<div><pre><code data-lang="MiniZinc"><span>constraint</span> <span>forall</span>(h <span>in</span> HOURS, w <span>in</span> WORKERS)(
    working_hours[w, h] <span>=</span> <span>0</span> <span>-&gt;</span> assignment[h] <span>!=</span> w
);
</code></pre></div><p><code>-&gt;</code> means implication. For me it’s easier to understand in pseudocode:</p>
<div><pre><code data-lang="python"><span>if</span> working_hours[w, h] <span>==</span> <span>0</span>:
    add_constraint(assignment[h] <span>!=</span> w)
</code></pre></div><p>Unlike the car example, here we don’t need optimization, as we don’t have an the expression to optimize. Instead, we ask to satisfy all constraints:</p>
<p>A solution will be available in a few milliseconds.</p>
<div><pre><code data-lang="MiniZinc">assignment <span>=</span> <span>array1d</span>(<span>1</span><span>..</span><span>168</span>, [<span>1</span>, <span>1</span>, <span>1</span>, <span>..</span><span>.</span>, <span>1</span>]);
<span>----------</span>
</code></pre></div><p>The solution says it’s not so much fun to be the first developer.</p>
<p><a href="https://github.com/skrypka/minizinc_workshop/tree/master/oncall1">Source code of unfair model</a></p>
<h3 id="fairness">Fairness</h3>
<p>Let’s add fairness to the model. Fairness means total on-call hours for each developers should be as similar as possible. To make life easier later we can create an intermediate array <code>total_hours</code>, which for every developer returns the number of hours on-call for the week.</p>
<div><pre><code data-lang="MiniZinc"><span>array</span>[WORKERS] <span>of</span> <span>var</span> <span>int</span>: total_hours <span>=</span> [
    <span>sum</span>( [assignment[h]<span>=</span>w | h <span>in</span> HOURS ] )
    | w <span>in</span> WORKERS
];
</code></pre></div><p>Here we can see new syntax, a list comprehension. We iterate for every worker, and in the inner list comprehension, calculate the actual number of working hours.</p>
<p>To ask for fairness, we need an expression to convert <code>total_hours</code> to one number. One option is <code>min-max</code>:</p>
<div><pre><code data-lang="MiniZinc"><span>solve</span> <span>minimize</span> <span>max</span>(total_hours) <span>-</span> <span>min</span>(total_hours);
</code></pre></div><p>The minimal possible objective is 0 when all developers has equal total on-call hours per week. The expression is provably correct, but in practice it’s pretty slow with default optimizer. MiniZinc assigns the first developer to all hours as initial solution and tries to improve it.</p>
<p><img src="https://static.optduty.com/images/blog/oncall2-slow.gif" alt="slow min max optimization">
(pay attention to the objective value)</p>
<p>One option to fix it is to ask MiniZinc to select developers randomly during search with search annotation. As I’ll focus on another solution, to find our more, check out check out <a href="https://www.minizinc.org/doc-2.4.3/en/mzn_search.html">this part of MiniZinc tutorial</a>.</p>
<div><pre><code data-lang="MiniZinc"><span>solve</span> :: <span>int_search</span>(assignment, first_fail, indomain_random)
      <span>minimize</span> <span>max</span>(total_hours) <span>-</span> <span>min</span>(total_hours);
</code></pre></div><p><img src="https://static.optduty.com/images/blog/oncall2-fast.gif" alt="fast min max optimization"></p>
<p><a href="https://github.com/skrypka/minizinc_workshop/tree/master/oncall2">Source code of min-max model</a></p>
<h3 id="even-fairer-fairness">Even fairer fairness</h3>
<p>The min-max objective is simple, but unfortunately, in some edge cases, it will not work. Minimum and maximum create boundaries and the algorithm will try to push them together as much as possible, but it will not try to optimize developers between boundaries.</p>
<p>Instead, we could use a much more complicated expression:</p>
<div><pre><code data-lang="MiniZinc"><span>var</span> <span>int</span>: absolute_diff <span>=</span> <span>sum</span>(w1 <span>in</span> WORKERS, w2 <span>in</span> WORKERS <span>where</span> w1 <span>&gt;</span> w2)(
     <span>abs</span>(total_hours[w1] <span>-</span> total_hours[w2])
);
</code></pre></div><p>Again there is new syntax, but it’s slightly different list comprehension with an aggregation function on top. We iterate for all unique workers pairs and for each pair, calculate the absolute difference. As the last step, we sum all such differences.</p>
<p>Only one line left, to ask to minimize the sum of absolute differences:</p>
<div><pre><code data-lang="MiniZinc"><span>solve</span> <span>minimize</span> absolute_diff;
</code></pre></div><p><a href="https://github.com/skrypka/minizinc_workshop/tree/master/oncall3">Source code of absolute diff model</a></p>
<h2 id="working-with-optional-variable">Working with optional variable</h2>
<p>What …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://optduty.com/blog/2020-08-29-schedule-optimization/">https://optduty.com/blog/2020-08-29-schedule-optimization/</a></em></p>]]>
            </description>
            <link>https://optduty.com/blog/2020-08-29-schedule-optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24608417</guid>
            <pubDate>Sun, 27 Sep 2020 17:35:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are we observable yet? An introduction to Rust telemetry]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24608100">thread link</a>) | @LukeMathWalker
<br/>
September 27, 2020 | https://www.lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/ | <a href="https://web.archive.org/web/*/https://www.lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  <article>
    
      
      
<ul id="frontmatter">
    <li>
        <time datetime="2020-09-27T15:00:10.47Z">September 27, 2020</time>
    </li>
    <span></span>
    <li> 10063 words </li>
    <span></span>
    <li> 51 min </li>
</ul>

      <p><em><a href="https://zero2prod.com/"><strong>Zero To Production In Rust</strong></a> is an opinionated introduction to backend development in Rust.<br>
You can pre-order the book on <a href="https://zero2prod.com/">zero2prod.com</a>.<br>
<a href="https://www.lpalmieri.com/subscribe">Subscribe to the newsletter</a> to be notified when a new episode is published.</em></p>

<ol start="0">
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#0-previously-on-zero-to-production">Previously On Zero To Production</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#1-unknown-unknowns">Unknown Unknowns</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#2-observability">Observability</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#3-logging">Logging</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#3-1-the-log-crate">3.1. The <code>log</code> Crate</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#3-2-actix-webs-logger-middleware">3.2. <code>actix-web</code>'s <code>Logger</code> Middleware</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#3-3-the-facade-pattern">3.3. The Facade Pattern</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#4-instrumenting-post-subscriptions">Instrumenting POST /subscriptions</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#4-1-interactions-with-external-systems">4.1. Interactions With External Systems</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#4-2-think-like-a-user">4.2. Think Like A User</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#4-3-logs-must-be-easy-to-correlate">4.3. Logs Must Be Easy To Correlate</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-structured-logging">Structured Logging</a>
<ul>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-1-the-tracing-crate">5.1. The <code>tracing</code> Crate</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-2-migrating-from-log-to-tracing">5.2. Migrating From <code>log</code> To <code>tracing</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-3-tracings-span">5.3. <code>tracing</code>'s <code>Span</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-4-tracing-futures">5.4. <code>tracing-futures</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-5-tracings-subscriber">5.5. <code>tracing</code>'s <code>Subscriber</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-6-tracing-subscriber">5.6. <code>tracing-subscriber</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-7-tracing-bunyan-formatter">5.7. <code>tracing-bunyan-formatter</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-8-tracing-log">5.8. <code>tracing-log</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-9-cleaning-up-initialisation">5.9. Cleaning Up Initialisation</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-10-logs-for-integration-tests">5.10. Logs For Integration Tests</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#instrument">5.11. Cleaning Up Instrumentation Code - <code>tracing::instrument</code></a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-12-request-id">5.12. Request Id</a></li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#5-13-leveraging-the-tracing-ecosystem">5.13. Leveraging The <code>tracing</code> Ecosystem</a></li>
</ul>
</li>
<li><a href="https://lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/#6-next-on-zero-to-production">Summary</a></li>
</ol>

<p>In Chapter 3 we managed to put together a first implementation of <code>POST /subscriptions</code> to fulfill one of the user stories of our email newsletter project:</p>
<blockquote>
<p>As a blog visitor,<br>
I want to subscribe to the newsletter,<br>
So that I can receive email updates when new content is published on the blog.</p>
</blockquote>
<p>We have not yet created a web page with a HTML form to actually test the end-to-end flow, but we have a few black-box integration tests that cover the two basic scenarios we care about at this stage:</p>
<ul>
<li>if valid form data is submitted (i.e. both name and email have been provided), the data is saved in our database;</li>
<li>if the submitted form is incomplete (e.g. the email is missing, the name is missing or both), the API returns a 400.</li>
</ul>
<p>Should we be satisfied and rush to deploy the first version of our application on the coolest cloud provider out there?<br>
Not yet - we are not yet equipped to properly run our software in a production environment.<br>
We are blind: the application is not <strong>instrumented</strong> yet and we are not collecting any <strong>telemetry data</strong>, making us vulnerable to <strong>unknown unknowns</strong>.</p>
<p>If most of the previous sentence makes little to no sense to you, do not worry: getting to the bottom of it is going to be the main focus of this chapter.</p>
<blockquote>
<p><em>Discuss the article on <a href="https://news.ycombinator.com/item?id=24608100">HackerNews</a> or <a href="https://www.reddit.com/r/rust/comments/j0uo0t/are_we_observable_yet_an_introduction_to_rust/">r/rust</a></em>.</p>
</blockquote>

<p>We have a few tests. Tests are good, they make us more confident in our software, in its correctness.<br>
Nonetheless, a test suite is not <em>proof</em> of the correctness of our application. We would have to explore significantly different approaches to <em>prove</em> that something is correct (e.g. <a href="https://lamport.azurewebsites.net/tla/formal-methods-amazon.pdf">formal methods</a>).<br>
At runtime we will encounter scenarios that we have not tested for or even thought about when designing the application in the first place.</p>
<p>I can point at a few blind spots based on the work we have done so far and my past experiences:</p>
<ul>
<li>what happens if we lose connection to the database? Does <code>sqlx::PgPool</code> try to automatically recover or will all database interactions fail from that point onwards until we restart the application?</li>
<li>what happens if an attacker tries to pass malicious payloads in the body of the POST <code>/subscriptions</code> request (i.e. extremely large payloads, attempts to perform <a href="https://en.wikipedia.org/wiki/SQL_injection">SQL injection</a>, etc.)?</li>
</ul>
<p>These are often referred to as <strong>known unknowns</strong>: shortcomings that we are aware of and we have not yet  managed to investigate or we have deemed to be not relevant enough to spend time on.<br>
Given enough time and effort, we <em>could</em> get rid of most known unknowns.</p>
<p>Unfortunately there are issues that we have not seen before and we are not expecting, <strong>unknown unknowns</strong>.</p>
<p>Sometimes experience is enough to transform an unknown unknown into a known unknown: if you had never worked with a database before you might have not thought about what happens when we lose connection; once you have seen it happen once, it becomes a familiar failure mode to look out for.</p>
<p>More often than not, unknown unknowns are peculiar failure modes of the specific system we are working on.<br>
They are problems at the crossroads between our software components, the underlying operating systems, the hardware we are using, our development process peculiarities and that huge source of randomness known as "the outside world".<br>
They might emerge when:</p>
<ul>
<li>the system is pushed outside of its usual operating conditions (e.g. an unusual spike of traffic);</li>
<li>multiple components experience failures at the same time (e.g. a SQL transaction is left hanging while the database is going through a <a href="https://www.postgresql.org/docs/current/warm-standby-failover.html">master-replica failover</a>);</li>
<li>a change is introduced that moves the system equilibrium (e.g. tuning a retry policy);</li>
<li>no changes have been introduced for a long time (e.g. applications have not been restarted for weeks and you start to see all sorts of memory leaks);</li>
<li>etc.</li>
</ul>
<p>All these scenarios share one key similarity: they are often impossible to reproduce outside of the live environment.<br>
What can we do to prepare ourselves to deal with an outage or a bug caused by an unknown unknown?</p>

<p>We must assume that we will not be there when an unknown unknown issue arises: it might be late at night, we might be working on something else, etc.<br>
Even if were paying attention at the very same moment something starts to go wrong, it often isn't possible or practical to attach a debugger to a process running in production (assuming you even know in the first place <em>which</em> process you should be looking at) and the degradation might affect multiple systems at once.<br>
The only thing we can rely on to understand and debug an unknown unknown is <strong>telemetry data</strong>: information about our running applications that is collected automatically and can be later inspected to answer questions about the state of the system at a certain point in time.</p>
<p>What questions?<br>
Well, if it is an unknown unknown we do not really know <em>in advance</em> what questions we might need to ask to isolate its root cause - that's the whole point.<br>
The goal is to have an <strong>observable application</strong>.<br>
Quoting from <a href="https://www.honeycomb.io/what-is-observability/">Honeycomb's observability guide</a></p>
<blockquote>
<p>Observability is about being able to ask arbitrary questions about your environment without — and this is the key part — having to know ahead of time what you wanted to ask.</p>
</blockquote>
<p>"arbitrary" is a strong word - as all absolute statements, it might require an unreasonable investment of both time and money if we are to interpret it literally.<br>
In practice we will also happily settle for an application that is <em>sufficiently</em> observable to enable us to deliver the level of service we promised to our users.</p>
<p>In a nutshell, to build an observable system we need:</p>
<ul>
<li>to instrument our application to collect high-quality telemetry data;</li>
<li>access to tools and systems to efficiently slice, dice and manipulate the data to find answers to our questions.</li>
</ul>
<p>We will touch upon some of the options available to fulfill the second point, but an exhaustive discussion is outside of the scope of this book.<br>
Let's focus on the first for the rest of this chapter.</p>

<p>Logs are the most common type of telemetry data.<br>
Even developers who have never heard of observability have an intuitive understanding of the usefulness of logs: logs are what you look at when stuff goes south to understand what is happening, crossing your fingers extra hard hoping you captured enough information to troubleshoot effectively.</p>
<p>What are logs though?<br>
The format varies, depending on the epoch, the platform and the technologies you are using.<br>
Nowadays a <strong>log record</strong> is usually a bunch of text data, with a line break to separate the current record from the next one.
For example</p>
<pre><code><span>The</span><span> application is starting on port 8080
</span><span>Handling</span><span> a request to /index
</span><span>Handling</span><span> a request to /index
</span><span>Returned</span><span> a 200 OK
</span></code></pre>
<p>are four perfectly valid log records for a web server.</p>
<p>What does the Rust ecosystem have to offer us when it comes to logging?</p>
<h2 id="3-1-the-log-crate">3.1. The <code>log</code> Crate</h2>
<p>The go-to crate for logging in Rust is <a href="https://docs.rs/log"><code>log</code></a>.</p>
<p><code>log</code> provides five macros: <a href="https://docs.rs/log/0.4.11/log/macro.trace.html"><code>trace</code></a>, <a href="https://docs.rs/log/0.4.11/log/macro.debug.html"><code>debug</code></a>, <a href="https://docs.rs/log/0.4.11/log/macro.info.html"><code>info</code></a>, <a href="https://docs.rs/log/0.4.11/log/macro.warn.html"><code>warn</code></a> and <a href="https://docs.rs/log/0.4.11/log/macro.error.html"><code>error</code></a>.<br>
They all do the same thing - emit a log a record - but each of them uses a different <strong>log level</strong>, as the naming implies.<br>
<em>trace</em> is the lowest level: trace-level logs are often extremely verbose and have a low signal-to-noise ratio (e.g. emit a trace-level log record every time a TCP packet is received by a web server).<br>
We then have, in increasing order of severity, <em>debug</em>, <em>info</em>, <em>warn</em> and <em>error</em>.<br>
Error-level logs are used to report serious failures that might have user impact (e.g. we failed to handle an incoming request or a query to the database timed out). </p>
<p>Let's look at a quick usage example:</p>
<pre><code><span>fn </span><span>fallible_operation</span><span>() -&gt; Result&lt;String, String&gt; { ... }

</span><span>pub fn </span><span>main</span><span>() {
    </span><span>match </span><span>fallible_operation</span><span>() {
        Ok(success) =&gt; {
            log::info!("</span><span>Operation succeeded: {}</span><span>", success);
        }
        Err(err) =&gt; {
            log::error!("</span><span>Operation failed: {}</span><span>", err);
        }
    }
}
</span></code></pre>
<p>We are trying to perform an operation that might fail.<br>
If it succeeds, we emit an info-level log record.<br>
If it doesn't, we emit an error-level log record.</p>
<p>Notice as well how <code>log</code>'s macros support the same interpolation syntax provided by <code>println</code>/<code>print</code> in the standard library.</p>
<p>We can use <code>log</code>'s macros to <em>instrument</em> our codebase.<br>
Choosing what information should be logged about the execution of a particular function is often a <em>local</em> decision: it is enough to look at the function to decide what deserves to be captured in a log record. This enables libraries to be instrumented effectively, extending the reach of our telemetry outside the boundaries of the code we have written first-hand.</p>
<h2 id="3-2-actix-web-s-logger-middleware">3.2. <code>actix-web</code>'s <code>Logger</code> Middleware</h2>
<p><code>actix_web</code> provides a <a href="https://docs.rs/actix-web/2.0.0/actix_web/middleware/struct.Logger.html"><code>Logger</code> middleware</a>. It emits a log record for every incoming request.<br>
Let's add it to our application.</p>
<pre><code><span>//! src/startup.rs
</span><span>use crate</span><span>::routes::{health_check, subscribe};
</span><span>use </span><span>actix_web::dev::Server;
</span><span>use </span><span>actix_web::web::Data;
</span><span>use </span><span>actix_web::{web, App, HttpServer};
</span><span>use </span><span>actix_web::middleware::Logger;
</span><span>use </span><span>sqlx::PgPool;
</span><span>use </span><span>std::net::TcpListener;

</span><span>pub fn </span><span>run</span><span>(</span><span>listener</span><span>: TcpListener, </span><span>db_pool</span><span>: PgPool) -&gt; Result&lt;Server, std::io::Error&gt; {
    </span><span>let</span><span> db_pool = Data::new(db_pool);
    </span><span>let</span><span> server = HttpServer::new(</span><span>move </span><span>|| {
        App::new()
            </span><span>// Middlewares are …</span></code></pre></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/">https://www.lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/</a></em></p>]]>
            </description>
            <link>https://www.lpalmieri.com/posts/2020-09-27-zero-to-production-4-are-we-observable-yet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24608100</guid>
            <pubDate>Sun, 27 Sep 2020 17:02:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grade school math cranked up in one page of concepts and symbols]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24608049">thread link</a>) | @R3G1R
<br/>
September 27, 2020 | https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div id="theme-content-section"><div><section data-css="tve-u-16ec5d248bb"><p><span>I</span>n basic mathematics, many different symbols exist and are adopted widely. The following is a compilation of the most commonly-used symbols in <strong>arithmetic</strong> and <strong>common mathematics</strong>, along with other symbols whose usage covers multiple subfields of mathematics.</p><p>For readability purpose, these symbols are categorized by their <strong>function</strong> into tables. Other comprehensive lists of symbols — as categorized by subject&nbsp;and type — can be also found in the relevant pages below (or in the navigational panel).</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Mathematical_Constants"></span>Mathematical Constants<span></span></h2><p>In common mathematics, <strong>constants</strong> are often used to denote key natural numbers, integers, real numbers and complex numbers. The following table documents the most common of these — along with their name, usage and function.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$0$ (<strong>Zero</strong>)</td><td>Additive identity of common numbers</td><td>$5 + 0 = 0 + 5 = 0$</td></tr><tr><td>$1$ (<strong>One</strong>)</td><td>Multiplicative identity of common numbers</td><td>$6 \times 1 = 6$</td></tr><tr><td>$\sqrt{2}$ (<strong><a href="https://en.wikipedia.org/wiki/Square_root_of_2" target="_blank" aria-label="Square root of $2$ (opens in a new tab)" rel="noreferrer noopener">Square root of $2$</a></strong>)</td><td>Positive number whose square is $2$. Pythagoras’ constant. Approximately $1.414$.</td><td>$\sqrt{2}$ is often considered to be the “simplest” irrational number.</td></tr><tr><td>$e$ (<strong><a href="https://en.wikipedia.org/wiki/E_(mathematical_constant)" target="_blank" aria-label="Euler's number (opens in a new tab)" rel="noreferrer noopener">Euler’s number</a></strong>)</td><td>Base of <a href="https://mathvault.ca/logarithm-theory/#Natural_Logarithm_Base_e" target="_blank" aria-label="natural logarithm (opens in a new tab)" rel="noreferrer noopener">natural logarithm</a>. Limit of sequence $\left( 1+\frac{1}{n} \right)^n$. Approximately $2.718$.</td><td>$\ln e = 1$</td></tr><tr><td>$\pi$ (<strong><a href="https://en.wikipedia.org/wiki/Pi" target="_blank" aria-label="Pi (opens in a new tab)" rel="noreferrer noopener">Pi</a></strong>, Archimedes’ constant)</td><td>Ratio of a circle’s circumference and diameter. Half-circumference of unit circle.</td><td>$\pi$ is irrational and approximately  $3.1416$.</td></tr><tr><td>$\varphi$ (Phi, <strong><a aria-label="Golden ratio (opens in a new tab)" href="https://en.wikipedia.org/wiki/Golden_ratio" target="_blank" rel="noreferrer noopener">golden ratio</a></strong>)</td><td>Ratio between two positive numbers $a &gt; b$ such that $\frac{a+b}{a} = \frac{a}{b}$. Positive root of polynomial $x^2-x-1$.</td><td>$\varphi = \dfrac{1+\sqrt{5}}{2} \approx 1.618$</td></tr><tr><td>$i$ (<strong><a href="https://en.wikipedia.org/wiki/Imaginary_unit" target="_blank" aria-label="Imaginary unit (opens in a new tab)" rel="noreferrer noopener">Imaginary unit</a></strong>)</td><td>Principal square root of $-1$. Foundational component of complex numbers.</td><td>$i^2 = (-i)^2 = -1$</td></tr></tbody></table></figure><h2><span id="Delimiters"></span>Delimiters<span></span></h2><p><a href="https://en.wikipedia.org/wiki/Delimiter" target="_blank" rel="noopener noreferrer">Delimiters</a> are symbols used to signal the <strong>separation</strong> between different independent mathematical entities. These include the common delimiters such as parentheses, brackets and braces, and the use of delimiters in the context of intervals.</p><h3><span id="Common_Delimiters"></span>Common Delimiters<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$.$</td><td><strong>Decimal separator</strong></td><td>$15.35 + 8.25 = 23.60$</td></tr><tr><td>$,$</td><td><strong>Object separator</strong></td><td>$\{ 5, 0, 2 \}$</td></tr><tr><td>$:$</td><td><strong>Ratio indicator</strong></td><td>$4 : 3 = 1024 : 768$</td></tr><tr><td>$(), [], \{ \}$</td><td><strong>Order-of-operation indicators</strong></td><td>$\left[(2+3) + 4\right] + 5$</td></tr><tr><td>$( )$</td><td><strong><a href="https://en.wikipedia.org/wiki/Tuple" target="_blank" aria-label="Tuple (opens in a new tab)" rel="noreferrer noopener">Tuple</a>-indicator</strong></td><td>$(4, 7, 11, 15)$</td></tr></tbody></table></figure><h3><span id="Intervals"></span>Intervals<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$[a, b]$</td><td><strong><a href="https://en.wikipedia.org/wiki/Interval_(mathematics)#Including_or_excluding_endpoints" target="_blank" aria-label="Closed interval (opens in a new tab)" rel="noreferrer noopener">Closed interval</a></strong> from $a$ to $b$</td><td>$\pi \in [3, 5]$</td></tr><tr><td>$(a, b)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Interval_(mathematics)#Including_or_excluding_endpoints" target="_blank" aria-label="Open interval (opens in a new tab)" rel="noreferrer noopener">Open interval</a></strong> from $a$ to $b$</td><td>$(1, 9) =$<br>$\{x \in  \mathbb{R} \mid \\ 1 &lt; x &lt; 9\}$</td></tr><tr><td>$[a, b)$</td><td><strong><a href="https://en.wikipedia.org/wiki/Interval_(mathematics)#Including_or_excluding_endpoints" target="_blank" aria-label="Right-open interval (opens in a new tab)" rel="noreferrer noopener">Right-open interval</a></strong> from $a$ to $b$</td><td>$[e, \pi) \subseteq [1, \infty)$</td></tr><tr><td>$(a, b]$</td><td><strong><a href="https://en.wikipedia.org/wiki/Interval_(mathematics)#Including_or_excluding_endpoints" target="_blank" aria-label="Left-open interval (opens in a new tab)" rel="noreferrer noopener">Left-open interval</a></strong> from $a$ to $b$</td><td>$0 \notin (0, 100]$</td></tr></tbody></table></figure><h2><span id="Operators"></span>Operators<span></span></h2><p>Operators are placeholder symbols used to denote <a href="https://mathvault.ca/math-glossary/#operation" target="_blank" rel="noopener noreferrer"><strong>mathematical operations</strong></a>, which take one or multiple mathematical objects to another similar object. In common mathematics, these include the arithmetic operators, and other number-related unary operators.</p><h3><span id="Arithmetic_Operators"></span>Arithmetic Operators<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$x + y$</td><td><strong>Sum</strong> ($x$ plus $y$)</td><td>$\dfrac{3}{5} + \dfrac{2}{3} = \dfrac{19}{15}$</td></tr><tr><td>$x-y$</td><td><strong>Difference</strong> ($x$ minus $y$)</td><td>$13-1.\overline{3} = 11.\overline{6}$</td></tr><tr><td>$-x$</td><td><strong><a aria-label="Additive inverse (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Additive_inverse" target="_blank">Additive inverse</a></strong> (negative $x$)</td><td>$(-1.5) + 1.5 =0$</td></tr><tr><td>$x \times y$, $x \cdot y$, $xy$</td><td><strong>Product</strong> ($x$ times $y$)</td><td>$2 \times (3 + 5) = \\ 6 + 10$</td></tr><tr><td>$x \div y$, $\, x / y$</td><td><strong><a aria-label="Quotient (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Quotient" target="_blank">Quotient</a></strong> ($x$ over $y$)</td><td>$16 \div 2.5 = 6.4$</td></tr><tr><td>$\dfrac{x}{y}$</td><td><strong>Fraction</strong> of $x$ over $y$</td><td>$\dfrac{3}{8}=0.375$</td></tr><tr><td>$x^y$</td><td><strong>Power</strong> ($x$ raised to $y$)</td><td>$3^{10} = 9^5$</td></tr><tr><td>$\pm$</td><td><strong><a href="https://en.wikipedia.org/wiki/Plus%E2%80%93minus_sign" target="_blank" aria-label="Plus-and-minus operator (opens in a new tab)" rel="noreferrer noopener">Plus-and-minus operator</a></strong></td><td>With the <a aria-label="quadratic formula (opens in a new tab)" href="https://mathvault.ca/quadratic-factorisation/#The_General_Method_Theory" target="_blank" rel="noreferrer noopener">quadratic formula</a>, we have that $x = \dfrac{-b \pm \sqrt{\Delta}}{2a}$.</td></tr><tr><td>$\mp$</td><td><strong><a href="https://en.wikipedia.org/wiki/Plus%E2%80%93minus_sign#Minus%E2%80%93plus_sign" target="_blank" aria-label="Minus-and-plus operator (opens in a new tab)" rel="noreferrer noopener">Minus-and-plus operator</a></strong></td><td>$5 \pm (-3) = 5 \mp 3$</td></tr></tbody></table></figure><h3>Number-related Unary Operators<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\sqrt{x}$</td><td><strong><a href="https://en.wikipedia.org/wiki/Square_root" target="_blank" aria-label="Principal square root (opens in a new tab)" rel="noreferrer noopener">Principal square root</a></strong> of $x$</td><td>$\sqrt{30}= \\ \sqrt{2 \cdot 3 \cdot 5}$</td></tr><tr><td>$\sqrt[n]{x}$</td><td><strong><a aria-label="n-th root (opens in a new tab)" href="https://en.wikipedia.org/wiki/Nth_root" target="_blank" rel="noreferrer noopener">nth root</a></strong> of $x$</td><td>$\sqrt[3]{125}=5$</td></tr><tr><td>$|x|$</td><td><strong><a href="https://en.wikipedia.org/wiki/Absolute_value" target="_blank" aria-label="Absolute value (opens in a new tab)" rel="noreferrer noopener">Absolute value</a></strong> of $x$</td><td>$|-5| = |5| = 5$</td></tr><tr><td>$x \%$</td><td>$x$ <strong>percent</strong></td><td>$5 \% \doteq \dfrac{5}{100}$</td></tr></tbody></table></figure><h2><span id="Relational_Symbols"></span>Relational Symbols<span></span></h2><p>In mathematics, relational symbols are used to denote <a href="https://mathvault.ca/math-glossary/#relation" target="_blank" rel="noopener noreferrer"><strong>mathematical relations</strong></a>, which take one or multiple mathematical objects to form full mathematical sentences. In arithmetic and common mathematics, these include the relational symbols related to equality and comparison.</p><h3><span id="Equalitybased_Relational_Symbols"></span>Equality-based Relational Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$x \doteq y$, $x \overset{df}{=} y$,<br>$x := y$</td><td>$x$ is <strong>defined as</strong> $y$</td><td>$\mathbb{R}_+ \doteq \\ \{ x \in \mathbb{R} \mid x &gt; 0 \}$</td></tr><tr><td>$x = y$</td><td>$x$ is <strong>equal to</strong> $y$</td><td>$ \pi = \dfrac{C}{d}$</td></tr><tr><td>$x \ne y$</td><td>$x$ is <strong>not equal</strong> to $y$</td><td>$\sqrt{3} \ne 1.7$</td></tr><tr><td>$x \approx y$</td><td>$x$ is <strong>approximately equal</strong> to $y$</td><td>$\dfrac{5}{7} \approx 0.714$</td></tr><tr><td>$f(x) \propto g(x)$</td><td>Function $f$ is <strong><a href="https://en.wikipedia.org/wiki/Proportionality_(mathematics)#Direct_proportionality" target="_blank" aria-label="directly proportional (opens in a new tab)" rel="noreferrer noopener">directly proportional</a></strong> to function $g$</td><td>$\dfrac{\pi}{2} x^2 \propto 3x^2$</td></tr></tbody></table></figure><h3><span id="Comparisonbased_Relational_Symbols"></span>Comparison-based Relational Symbols<span></span></h3><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$x &lt; y$</td><td>$x$ is <strong>less than</strong> $y$</td><td>$2 &lt; e$</td></tr><tr><td>$x &gt; y$</td><td>$x$ is <strong>greater than</strong> $y$</td><td>$\dfrac{13}{4} &gt; 3$</td></tr><tr><td>$x \le y$</td><td>$x$ is <strong>less than or equal to</strong> $y$</td><td>$1 \le n^2$</td></tr><tr><td>$x \ge y$</td><td>$x$ is <strong>greater than or equal to</strong> $y$</td><td>$n! \ge 2^n$ for $n \ge 4$</td></tr></tbody></table></figure><h2><span id="Notational_Symbols"></span>Notational Symbols<span></span></h2><p>Notational symbols are often <strong>conventions</strong> and <strong>shorthands</strong> which don’t fall into the categories of constants, delimiters, operators and relational symbols. The following table documents some of these in the context of common mathematics — along with their usage and meaning.</p><figure><table><thead><tr><th>Symbol Name</th><th>Explanation</th><th>Example</th></tr></thead><tbody><tr><td>$\ldots, \cdots$</td><td><strong><a href="https://en.wikipedia.org/wiki/Ellipsis#In_mathematical_notation" target="_blank" aria-label="Horizontal ellipsis symbols (opens in a new tab)" rel="noreferrer noopener">Horizontal ellipsis symbols</a></strong></td><td>$3 + 7 + 11 + \cdots + 43$</td></tr><tr><td>$\infty$</td><td><strong><a href="https://en.wikipedia.org/wiki/Infinity_symbol" target="_blank" aria-label="Infinity symbol (opens in a new tab)" rel="noreferrer noopener">Infinity symbol</a></strong></td><td>$\dfrac{1}{1} + \dfrac{1}{2} + \cdots = \infty$</td></tr><tr><td>$Q. E. D.$, $\square$, $\blacksquare$</td><td><strong><a href="https://mathvault.ca/math-glossary/#qed" target="_blank" aria-label="QED (opens in a new tab)" rel="noreferrer noopener">QED</a></strong> / <span><a aria-label="End-of-the-proof symbols (opens in a new tab)" rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Tombstone_(typography)" target="_blank">End-of-the-proof symbols</a></span></td><td>Hence $1 + \cdots + n = \frac{n(n+1)}{2}$, as desired. $\, \blacksquare$</td></tr><tr><td> ※,  ⨳</td><td><strong><a href="https://en.wikipedia.org/wiki/Contradiction#Symbolic_representation" target="_blank" aria-label="Contradiction symbols (opens in a new tab)" rel="noreferrer noopener">Contradiction symbols</a></strong></td><td>Squaring both sides of the equation yields that $2 &lt; 1$.  ⨳</td></tr></tbody></table></figure><p>For the master list of symbols, see <a href="https://mathvault.ca/hub/higher-math/math-symbols">mathematical symbols</a>. For lists of symbols categorized by <strong>type</strong> and <strong>subject</strong>, refer to the relevant pages below for more.</p><div><div><div><figure><img loading="lazy" width="400" height="518" src="https://mathvault.ca/wp-content/uploads/Math-Symbols-eBook-Cover.png" alt="Cover of Math Vault's Comprehensive List of Mathematical Symbols eBook" title="Math Symbols eBook Cover"></figure><div><p>Prefer the PDF version instead?</p><p>Get the master summary of mathematical symbols in <strong>eBook form</strong> — along with each symbol’s usage and LaTeX code.</p></div></div></div></div><h2><span id="Additional_Resources"></span>Additional Resources<span></span></h2><ul><li><a href="https://mathvault.ca/higher-math-learning-guide"><strong>Definitive Guide to Learning Higher Mathematics</strong></a>: A standalone, 10-principle framework for tackling higher mathematical learning, thinking and problem solving efficiently</li><li><a href="https://mathvault.ca/10-commandments/"><strong>10 Commandments of Higher Mathematical Learning</strong></a>: An illustrated web guide on 10 scalable rules for learning higher mathematics</li></ul></section></div></div></div></div></div>]]>
            </description>
            <link>https://mathvault.ca/hub/higher-math/math-symbols/common-math-symbols/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24608049</guid>
            <pubDate>Sun, 27 Sep 2020 16:56:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Instant SVG icon search with over 50K+ icons indexed]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24607452">thread link</a>) | @Fileformat
<br/>
September 27, 2020 | https://iconsear.ch/search.html | <a href="https://web.archive.org/web/*/https://iconsear.ch/search.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <nav>
        <a href="https://iconsear.ch/search.html">
            <img alt="IconSear.ch Logo" src="https://iconsear.ch/favicon.svg">
            IconSear.ch
        </a>
        <ul>
            <li><a href="https://iconsear.ch/search.html"><img alt="Search" src="https://iconsear.ch/images/navbar/search-solid.svg"><span>Search</span></a></li>
            <li><a href="https://iconsear.ch/icons/index.html"><img alt="Icons" src="https://iconsear.ch/images/navbar/file-image-regular.svg"><span>Icons</span></a></li>
            <li><a href="https://iconsear.ch/sources/index.html"><img alt="Sources" src="https://iconsear.ch/images/navbar/code-branch-regular.svg"><span>Sources</span></a></li>
            <li><a href="https://iconsear.ch/faq.html"><img alt="FAQ" src="https://iconsear.ch/images/navbar/info-circle-regular.svg"><span>FAQ</span></a></li>
        </ul>
    </nav>
    <div>
        <div>
            <div>
                
                <hr>

<form action="/search.html" id="search_form" method="GET">
    <div>
        <div>
            <p><label for="q">Search query</label></p><div>
                
            </div>
        </div>
    </div>
    
</form>

<div>
    <p><a href="https://github.com/coreui/coreui-icons/blob/master/svg/free/cil-compress.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/coreui/coreui-icons/master/svg/free/cil-compress.svg" title="cil-compress from CoreUI Icons"></a>
                <a href="https://github.com/michaelampr/jam/blob/master/svg/speaker.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/michaelampr/jam/master/svg/speaker.svg" title="speaker from Jam Icons"></a>
                <a href="https://github.com/primer/octicons/blob/master/icons/fold-up-24.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/primer/octicons/master/icons/fold-up-24.svg" title="fold-up-24 from Octicons (Github Primer)"></a>
                <a href="https://github.com/Iconscout/unicons/blob/master/svg/line/eye.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Iconscout/unicons/master/svg/line/eye.svg" title="eye from Unicons"></a>
                <a href="https://github.com/Iconscout/unicons/blob/master/svg/line/balance-scale.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Iconscout/unicons/master/svg/line/balance-scale.svg" title="balance-scale from Unicons"></a>
                <a href="https://github.com/denali-design/denali-icons-svg/blob/master/svg/battery-low-solid.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/denali-design/denali-icons-svg/master/svg/battery-low-solid.svg" title="battery-low-solid from denali-design"></a>
                <a href="https://github.com/Templarian/WindowsIcons/blob/master/WindowsPhone/svg/appbar.diagram.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Templarian/WindowsIcons/master/WindowsPhone/svg/appbar.diagram.svg" title="appbar.diagram from templarian-windows"></a>
                <a href="https://github.com/ant-design/ant-design-icons/blob/master/packages/icons-svg/svg/outlined/subnode.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/ant-design/ant-design-icons/master/packages/icons-svg/svg/outlined/subnode.svg" title="subnode from ant-design"></a>
                <a href="https://github.com/ant-design/ant-design-icons/blob/master/packages/icons-svg/svg/outlined/smile.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/ant-design/ant-design-icons/master/packages/icons-svg/svg/outlined/smile.svg" title="smile from ant-design"></a>
                <a href="https://github.com/twbs/icons/blob/main/icons/display-fill.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/twbs/icons/main/icons/display-fill.svg" title="display-fill from twbs"></a>
                <a href="https://github.com/coreui/coreui-icons/blob/master/svg/free/cil-transfer.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/coreui/coreui-icons/master/svg/free/cil-transfer.svg" title="cil-transfer from CoreUI Icons"></a>
                <a href="https://github.com/xtoolkit/Micon/blob/master/icons/mdl2/Play.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/xtoolkit/Micon/master/icons/mdl2/Play.svg" title="Play from xtoolkit"></a>
                <a href="https://github.com/RRZE-PP/rrze-icon-set/blob/master/bicons/16x16/actions/download.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/RRZE-PP/rrze-icon-set/master/bicons/16x16/actions/download.svg" title="download from rrzepp"></a>
                <a href="https://github.com/ionic-team/ionicons/blob/master/src/svg/shield-checkmark-sharp.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/ionic-team/ionicons/master/src/svg/shield-checkmark-sharp.svg" title="shield-checkmark-sharp from Ionicons"></a>
                <a href="https://github.com/tailwindlabs/heroicons/blob/master/src/outline/shield-check.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/tailwindlabs/heroicons/master/src/outline/shield-check.svg" title="shield-check from Hero Icons"></a>
                <a href="https://github.com/teenyicons/teenyicons/blob/master/src/outline/angular.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/teenyicons/teenyicons/master/src/outline/angular.svg" title="angular from teenyicons"></a>
                <a href="https://github.com/ionic-team/ionicons/blob/master/src/svg/arrow-up-circle-outline.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/ionic-team/ionicons/master/src/svg/arrow-up-circle-outline.svg" title="arrow-up-circle-outline from Ionicons"></a>
                <a href="https://github.com/Keyamoon/IcoMoon-Free/blob/master/SVG/456-hackernews.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Keyamoon/IcoMoon-Free/master/SVG/456-hackernews.svg" title="[456-hackernews from IcoMoon"></a>
                <a href="https://github.com/uditkumar489/Icon-pack/blob/master/Education/svg/workspace.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/uditkumar489/Icon-pack/master/Education/svg/workspace.svg" title="workspace from uditkumar489"></a>
                <a href="https://github.com/primer/octicons/blob/master/icons/calendar-16.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/primer/octicons/master/icons/calendar-16.svg" title="calendar-16 from Octicons (Github Primer)"></a>
                <a href="https://github.com/RRZE-PP/rrze-icon-set/blob/master/bicons/16x16/emblems/slide-audio.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/RRZE-PP/rrze-icon-set/master/bicons/16x16/emblems/slide-audio.svg" title="slide-audio from rrzepp"></a>
                <a href="https://github.com/microsoft/vscode-icons/blob/master/icons/dark/output.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/microsoft/vscode-icons/master/icons/dark/output.svg" title="output from VSCode Icons (Microsoft)"></a>
                <a href="https://github.com/Templarian/MaterialDesign/blob/master/svg/folder-clock-outline.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Templarian/MaterialDesign/master/svg/folder-clock-outline.svg" title="folder-clock-outline from Material Design"></a>
                <a href="https://github.com/tailwindlabs/heroicons/blob/master/src/solid/search-circle.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/tailwindlabs/heroicons/master/src/solid/search-circle.svg" title="search-circle from Hero Icons"></a>
                <a href="https://github.com/microsoft/vscode-icons/blob/master/icons/dark/arrow-small-right.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/microsoft/vscode-icons/master/icons/dark/arrow-small-right.svg" title="arrow-small-right from VSCode Icons (Microsoft)"></a>
                <a href="https://github.com/frexy/glyph-iconset/blob/master/svg/si-glyph-heart-delete.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/frexy/glyph-iconset/master/svg/si-glyph-heart-delete.svg" title="ssi-glyph-heart-delete from frexy"></a>
                <a href="https://github.com/Remix-Design/RemixIcon/blob/master/icons/Development/git-repository-private-fill.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Remix-Design/RemixIcon/master/icons/Development/git-repository-private-fill.svg" title="git-repository-private-fill from remix-design"></a>
                <a href="https://github.com/vaadin/vaadin-icons/blob/master/assets/svg/indent.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/vaadin/vaadin-icons/master/assets/svg/indent.svg" title="indent from vaadin"></a>
                <a href="https://github.com/carbon-design-system/carbon/blob/master/packages/icons/src/svg/32/transgender.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/carbon-design-system/carbon/master/packages/icons/src/svg/32/transgender.svg" title="transgender from Carbon Design Icons (IBM)"></a>
                <a href="https://github.com/Keyamoon/IcoMoon-Free/blob/master/SVG/143-key2.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/Keyamoon/IcoMoon-Free/master/SVG/143-key2.svg" title="[143-key2 from IcoMoon"></a>
                <a href="https://github.com/xtoolkit/Micon/blob/master/icons/mdl2/WifiCall1.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/xtoolkit/Micon/master/icons/mdl2/WifiCall1.svg" title="WifiCall1 from xtoolkit"></a>
                <a href="https://github.com/vaadin/vaadin-icons/blob/master/assets/svg/folder-open.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/vaadin/vaadin-icons/master/assets/svg/folder-open.svg" title="folder-open from vaadin"></a>
                <a href="https://github.com/denali-design/denali-icons-svg/blob/master/svg/folder-add-solid.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/denali-design/denali-icons-svg/master/svg/folder-add-solid.svg" title="folder-add-solid from denali-design"></a>
                <a href="https://github.com/coreui/coreui-icons/blob/master/svg/free/cil-line-style.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/coreui/coreui-icons/master/svg/free/cil-line-style.svg" title="cil-line-style from CoreUI Icons"></a>
                <a href="https://github.com/vaadin/vaadin-icons/blob/master/assets/svg/medal.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/vaadin/vaadin-icons/master/assets/svg/medal.svg" title="medal from vaadin"></a>
                <a href="https://github.com/game-icons/icons/blob/master/lorc/swirl-string.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/game-icons/icons/master/lorc/swirl-string.svg" title="swirl-string from game-icons"></a>
                <a href="https://github.com/tabler/tabler-icons/blob/master/icons/award.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/tabler/tabler-icons/master/icons/award.svg" title="award from tabler"></a>
                <a href="https://github.com/akveo/eva-icons/blob/master/package/icons/outline/svg/plus-outline.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/akveo/eva-icons/master/package/icons/outline/svg/plus-outline.svg" title="plus-outline from Eva Icons"></a>
                <a href="https://github.com/frexy/glyph-iconset/blob/master/svg/si-glyph-old-phone.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/frexy/glyph-iconset/master/svg/si-glyph-old-phone.svg" title="ssi-glyph-old-phone from frexy"></a>
                <a href="https://github.com/tailwindlabs/heroicons/blob/master/src/solid/x-circle.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/tailwindlabs/heroicons/master/src/solid/x-circle.svg" title="x-circle from Hero Icons"></a>
                <a href="https://github.com/frexy/glyph-iconset/blob/master/svg/si-glyph-arrow-thin-right-bottom.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/frexy/glyph-iconset/master/svg/si-glyph-arrow-thin-right-bottom.svg" title="ssi-glyph-arrow-thin-right-bottom from frexy"></a>
                <a href="https://github.com/carbon-design-system/carbon/blob/master/packages/icons/src/svg/32/align--vertical-center.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/carbon-design-system/carbon/master/packages/icons/src/svg/32/align--vertical-center.svg" title="align--vertical-center from Carbon Design Icons (IBM)"></a>
                <a href="https://github.com/ant-design/ant-design-icons/blob/master/packages/icons-svg/svg/filled/down-square.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/ant-design/ant-design-icons/master/packages/icons-svg/svg/filled/down-square.svg" title="down-square from ant-design"></a>
                <a href="https://github.com/microsoft/vscode-icons/blob/master/icons/light/issue-reopened.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/microsoft/vscode-icons/master/icons/light/issue-reopened.svg" title="issue-reopened from VSCode Icons (Microsoft)"></a>
                <a href="https://github.com/zavoloklom/material-design-iconic-font/blob/master/svg/2.2/01%20-%20web%20application/search-replace.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/zavoloklom/material-design-iconic-font/master/svg/2.2/01%20-%20web%20application/search-replace.svg" title="search-replace from Material Design Iconic Font"></a>
                <a href="https://github.com/ionic-team/ionicons/blob/master/src/svg/caret-up.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/ionic-team/ionicons/master/src/svg/caret-up.svg" title="caret-up from Ionicons"></a>
                <a href="https://github.com/encharm/Font-Awesome-SVG-PNG/blob/master/black/svg/file-pdf-o.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/encharm/Font-Awesome-SVG-PNG/master/black/svg/file-pdf-o.svg" title="file-pdf-o from encharm"></a>
                <a href="https://github.com/game-icons/icons/blob/master/delapouite/graduate-cap.svg"><img onload="removeLoading(this)" src="https://raw.githubusercontent.com/game-icons/icons/master/delapouite/graduate-cap.svg" title="graduate-cap from game-icons-white"></a>
    </p>
</div>


    <hr>
       </div>
  </div>
</div>
        
    

</div>]]>
            </description>
            <link>https://iconsear.ch/search.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24607452</guid>
            <pubDate>Sun, 27 Sep 2020 15:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic layout algorithms compute layouts for diagrams]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24607054">thread link</a>) | @wiradikusuma
<br/>
September 27, 2020 | https://rtsys.informatik.uni-kiel.de/elklive/ | <a href="https://web.archive.org/web/*/https://rtsys.informatik.uni-kiel.de/elklive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <p><img src="https://rtsys.informatik.uni-kiel.de/elklive/img/elk.svg" width="150" alt=""></p>
                <p>
                    Automatic layout algorithms compute layouts for diagrams.
                    Never tried them?
                    Well, here's your chance.
                    Choose one of the thingies below and start playing!
                </p>
            </div>
        </div>

        <div>
            <div>
                <div>
                    <div>
                        <h3><a href="https://rtsys.informatik.uni-kiel.de/elklive/elkgraph.html">Interactive Editor</a></h3>
                        <p>
                            Interactively edit a textual description of a graph
                            while a corresponding diagram is generated on-the-fly.
                            Basically,
                            build your own graphs
                            and see what automatic layout does with them.
                            You can choose out of the following two formats,
                            both supporting content&nbsp;assist (<code>Ctrl+Space</code>) and formatting (<code>Shift+Alt+F</code>):
                        </p>
                        
                    </div>
                </div>
            </div>
            <div>
                <div>
                    <div>
                        <h3><a href="https://rtsys.informatik.uni-kiel.de/elklive/examples.html">Examples</a></h3>
                        <p>
                            An annotated collection of example graphs.
                            Their main purpose is to illustrate
                            various configuration possibilities,
                            in particular those that are often-used.
                        </p>
                        <p>
                            The source of the examples can be found in ELK's
                            <a href="https://github.com/eclipse/elk-models">models repository</a>.
                            Pull-requests with concise and new examples are very welcome.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div>
                <div>
                    <div>
                        <div>
                            <h3><a href="https://rtsys.informatik.uni-kiel.de/elklive/models.html">Model Browser</a></h3>
                            <p>
                                An interactive browser
                                for the Eclipse Layout Kernel's
                                <a href="https://github.com/eclipse/elk-models">repository of test models</a>.
                                See what automatic layout does to diagrams
                                that we have created for you
                                (well, mainly for us, but you may look at them, too).
                            </p>
                            <p>
                                Layout is performed within your browser using elkjs (latest).
                            </p>
                        </div>
                    </div>
                </div>
            <div>
                <div>
                    <div>
                        <h3><a href="https://rtsys.informatik.uni-kiel.de/elklive/conversion.html">Graph Format Conversion</a></h3>
                        <p>
                            A side-by-side view of two graph formats.
                            Allows to interactively convert one graph format into another.
                            It's possible to invoke the conversion programmatically,
                            see the site for details.
                        </p>
                        <p>
                            Supports ELK's Xtext-based <code>elkt</code>, <code>json</code>, and <code>elkg</code> (XMI) formats.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <div><div>
            
            <div>
                <div>
                    <p><strong>Used Technologies</strong></p>
                    <dl>
                        <dt>
                            <a href="https://www.eclipse.org/elk/">Eclipse Layout Kernel (ELK)</a>
                        </dt>
                        <dd>
                            Java-based implementations of automatic layout algorithms.
                            This is what computes layouts for the diagrams so you don't have to.
                        </dd>
                        <dt>
                            <a href="https://github.com/kieler/elkjs/">elkjs</a>
                        </dt>
                        <dd>
                            JavaScript-based version of ELK, automatically transpiled from the Java sources.
                        </dd>
                        <dt>
                            <a href="https://github.com/eclipse/sprotty">Sprotty</a>
                        </dt>
                        <dd>
                            A next-gen web-based graphics framework.
                            This is what shows the diagrams.
                        </dd>
                        <dt>
                            <a href="https://microsoft.github.io/monaco-editor/">Monaco Editor</a>
                        </dt>
                        <dd>
                            The code editor that powers <a href="https://github.com/Microsoft/vscode">Visual Studio Code</a>.
                            The thing that lets you specify your graphs.
                        </dd>
                        <dt>
                            <a href="https://github.com/eclipse/lsp4j">LSP4J</a>
                        </dt>
                        <dd>
                            A Java binding for the <a href="https://github.com/Microsoft/language-server-protocol">Language Server Protocol</a>.
                            This adds code completion and error markers to the editor.
                        </dd>
                        <dt>
                            <a href="http://xtext.org/">Xtext</a>
                        </dt>
                        <dd>
                            A framework for development of programming languages and domain-specific languages.
                            Our textual languages were built with this.
                        </dd>
                    </dl>
                </div>
            </div>
        </div></div>
    </div></div>]]>
            </description>
            <link>https://rtsys.informatik.uni-kiel.de/elklive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24607054</guid>
            <pubDate>Sun, 27 Sep 2020 14:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Alar: The making of an open source dictionary]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24606845">thread link</a>) | @knadh
<br/>
September 27, 2020 | https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>ನಮಸ್ಕಾರ (Namaskāra)! This is not a post on fintech, or even technology for that matter. This is the story of a product of tenacity, selflessness, and passion; a product that will transcend and outlive most technology we know of. This is the story of a massive dictionary that will become the window to a language spoken by tens of millions of people for generations to come, a resource its author has donated to posterity. This is the story of V. Krishna, <a href="https://alar.ink/"><em>Alar</em></a>, his Kannada-English dictionary, and its accidental discovery and open sourcing at an unlikely place, a stock brokerage, Zerodha. This post is also a personal note, something I have not attempted in a long time.</p><h3 id="prologue">Prologue</h3><p>I have been running <a href="https://olam.in/">Olam</a>, an English-Malayalam and Malayalam-Malayalam dictionary, since 2010. It was built out of the frustration of not having an easily accessible online Malayalam dictionary, of the frustration at dictionary websites that insulted the reader’s intelligence with poor usability, terrible ad-ridden spamminess, and no respect for language. Olam’s website has stayed exactly the same for 10 years. It has an input box that responds to dictionary lookups in under ~50ms, exactly as it did in 2010. It is actively used by millions of Malayalam speakers.</p><p>The first version of the Olam corpus was seeded with unattributed word lists I scraped together from random parts of the web, and several thousand entries I entered myself. Since then, the English-Malayalam dictionary has been expanding slowly with crowdsourced entries.</p><p>The entire Olam corpus is <a href="https://olam.in/open">open source</a> (licensed under <a href="https://opendatacommons.org/licenses/odbl/summary/">OdBL</a>), or open data, rather. While the English-Malayalam corpus is crowdsourced, the Malayalam-Malayalam corpus (now known as the <em>Datuk Corpus</em>) was created out of the mammoth digitisation project the late <a href="https://www.asianetnews.com/pravasam/datuk-kj-joseph-passes-away-pm1xdr">“Datuk” K. J. Joseph</a> undertook in the late 90s, when he single-handledly digitised an out-of-copyright Malayalam-Malayalam dictionary along with many other books and posted them online at the expense of copious amounts of time out of his retirement. He was a Malayali settled in Malaysia, a prominent active social worker and educator. The Malaysian government conferred the title “Datuk” upon him in recognition of his exemplary services in the country, which then ended up being his nickname too. I do not know of the origin of the dictionary Datuk digtised, but it is poignant to think that the original author’s work lives on after a century.</p><p>I discovered the RTF file Datuk had posted a decade prior on an inactive Yahoo groups page around the time I was working on Olam. Needless to say, I was stumped by the scope of this project, and immediately started working on integrating it into Olam. It took more than two years of on and off work to convert the text from the original ASCII input to Unicode, and to clean, structure, and correct close to 200,000 entries. The dataset was named <em>Datuk Corpus</em>, and was published on Olam in 2013. I wrote to the Swathanthra Malayalam Computing (SMC) mailing list <a href="http://lists.smc.org.in/pipermail/discuss-smc.org.in/2013-May/015592.html">announcing it</a>, and we launched it with some fanfare at the SMC conference held in Thrissur, Kerala, that year. Datuk’s story was covered by the press, and his work was now open and available to everyone.</p><p>Shortly thereafter, I was connected to Datuk by an old friend of his I had met at the conference, and we spoke briefly on the phone. He had seen the news clip of the dictionary’s release, and was thrilled to know that his work was now accessible as he had originally intended. Open data lives on. He found it amusing that a random stranger had somehow unearthed a relic he had lost to the annals of internet history. Life is absurd like that, shaped in infinite ways by tiny, random events.</p><p>Datuk <a href="https://www.facebook.com/amma.org.my/posts/tribute-to-the-late-datuk-k-j-josephthe-late-datuk-k-j-joseph-was-a-prominent-ed/2157527197640248/">passed away in January 2019</a>. He was 89 years old. RIP Datuk. Your work’s utility will span generations. The data you created will proliferate and continue to be useful to humanity in ways we never imagined. Such is the beauty of open data. I consider it a privilege to have been able to speak to you just that one time.</p><h3 id="open-data">Open data</h3><blockquote><p><a href="https://en.wikipedia.org/wiki/Open_data">Open data</a> is the idea that some data should be freely available to everyone to use and republish as they wish, without restrictions from copyright, patents or other mechanisms of control.</p></blockquote><p>I shudder to think of a world without Wikipedia. The open data movement shares strong parallels with the Free and Open Source Software (FOSS) movement. The gist is that certain knowledge should be freely available to everyone with no restrictions and with one goal—collective advancement of humanity.</p><p>I consider dictionaries to be on top of that list. The stepping stone to language, the underpinning of civilisation. Dictionaries should be open, free, and easily accessible to everyone, everywhere. If we cannot share something as fundamental as language without motives of profit, we ought to do some serious introspection as members of an advanced civilisation.</p><p>An open data dictionary for every Indian language, the largest collection of open source dictionaries in the world, would be an immense resource for not only India but for humanity in general. Ideally, this is the kind of project governments should do. State governments could very easily partner with local universities and undertake the creation and maintenance of open data dictionaries.</p><p>That said, at Zerodha, we would be happy to fund projects to create high quality open data dictionaries if there are scholars out there working on them.</p><h3 id="a-kannada-dictionary">A Kannada dictionary</h3><p>I moved from Kerala to Bengaluru in early 2012 to get access to fast internet. Bengaluru is a melting pot of people from all over India, and English is the glue that holds the “IT sector” together. I can comprehend Kannada speech reasonably well and speak rather poorly, but cannot read the script, thanks to the lack of opportunities to learn over the many years spent between home, where we speak Malayalam, and work, an English speaking environment. With the guilt of not being able to learn Kannada, and the great satisfaction of having Olam as an open data corpus, I had been looking for ways to build a Kannada dictionary right after I had moved to Bengaluru.</p><p>Sometime in 2016, I presented the idea of having an open source Kannada dictionary created from scratch to Nithin. He was immediately on board to commission the project. A perk I enjoy, the privilege of having a resourceful backer who believes in public good. Not knowing where to start, I asked around a few places but nothing materialised for the next two years, and as always, I continued to bring up this conversation once in a while.</p><p>Then, sometime in October 2018, I randomly brought up the conversation again, and Srihari, who had just joined the tech team, happened to overhear it. He vaguely remembered that someone in his family had been associated with a dictionary for a long time. This would be one of those minuscule, random events that would significantly change the timeline; the <a href="https://en.wikipedia.org/wiki/Butterfly_effect">Butterfly effect</a> in action. I crossed my fingers and he soon setup a meeting with V. Krishna, the relative of his. Shortly thereafter, Srihari, Sharath (also from the tech team), and I went to <a href="http://www.kagapa.in/">KaGaPa’s</a> office to meet V. Krishna and to find out what exactly it was that Srihari remembered about him and a dictionary. KaGaPa (Kannada Ganaka Parishat) created the popular Nudi font and input method for Kannada, an important early innovation for digital Kannada, and V. Krishna had worked with them on several projects.</p><p>V. Krishna and Narasimhamurthy, KaGaPa’s proprietor, spoke passionately about Kannada literature and digitisation projects in the quaint little office room, surrounded by stacks of old Kannada books and literature. It was the perfect setting. Then, the extremely soft-spoken and mild-mannered V. Krishna fired up a computer and showed us his lifelong side project, his Kannada-English dictionary. Researched and written over a period of more than 40 years, 150,000+ Kannada words and 240,000+ English definitions, all neatly typed up in a Word document, complete with parts of speech tags and phonetic notations with diacritics for Kannada words. The ambition of the project, its scholarly quality, the depth of the data, the culmination of one man’s passion, perseverance, and tenacity over a lifetime, all lying in obscurity, stumbled upon by sheer coincidence. Absolutely mind blowing.</p><h3 id="v-krishna">V. Krishna</h3><figure><img src="https://zerodha.tech/static/images/vkrishna-alar.png" alt="V. Krishna's photo" height="150"></figure><p>V. Krishna was born in 1950 in the Malanayakana Halli village in Mysore district in Karnataka. He studied in a Kannada medium school, followed by a year at a pre-university college that he was forced to drop out of before moving to Bengaluru with his family in 1968.</p><p>He found a job at the Indian Agricultural Research Institute (IARI) in 1970. At IARI, around this time, noticing him struggle with the English language, his boss casually suggested that he procure a dictionary to learn English. This conversation would turn out to be pivotal, and would set V. Krishna on a lifelong journey of language research and scholarship, an amazing case of autodidacticism.</p><p>So, he took his boss’s advice and got himself an English dictionary and started studying it. Then he got himself another dictionary, and another, until he had five of them. At the same time, he took an interest in Kannada literature and started studying Kannada and English together. To help with this, he started jotting down notes, and at some point, began structuring them. A dictionary was being born. In the meanwhile, he took evening classes and obtained a commerce degree in 1976 from MES college, Malleshwaram.</p><p>Around 1980, <a href="https://en.wikipedia.org/wiki/Kannada_Sahitya_Parishat">Kannada Sahitya Parishattu</a> published a Kannada - English dictionary, and unsurprisingly, V. Krishna got himself a copy. He was surprised by the sheer number of errors he spotted—more than 200 in the first 50 pages. He wrote to the editor with his findings, and impressed by it, the editor met him in person in Bengaluru, where V. Krishna presented his manuscripts to him. Surprised by its quality, he suggested that V. Krishna continue his work and turn it into a full-fledged dictionary. This was the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/">https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/alar-the-making-of-an-open-source-dictionary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606845</guid>
            <pubDate>Sun, 27 Sep 2020 14:23:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First 100 Days as an Engineering Manager – In a Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24606770">thread link</a>) | @yarapavan
<br/>
September 27, 2020 | https://npr.codes/my-first-100-days-as-an-engineering-manager-in-a-pandemic-f55732ac0b1e | <a href="https://web.archive.org/web/*/https://npr.codes/my-first-100-days-as-an-engineering-manager-in-a-pandemic-f55732ac0b1e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://npr.codes/@xiehan?source=post_page-----f55732ac0b1e--------------------------------" rel="noopener"><img alt="Nara Kasbergen" src="https://miro.medium.com/fit/c/96/96/1*qzUraPTQi3X9BfUyyKKh8g.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="7e3e">In May 2020, I took a sharp right turn in my career: I transitioned from being a lead software engineer to an engineering manager with three wonderful and talented direct reports. Ordinarily, that career trajectory change might have been relatively unremarkable; engineers make this leap all the time. But there’s a pandemic going on, and to say that it’s been tough would be an understatement. There have been tears. There have been times when I’ve wanted to chuck my laptop out the window. And there have also been awesome, rewarding moments that have reminded me that if I could go back in time and make the choice again, I’d still go down the same path. But I’ve often joked that I tend to play life on hard mode, and this has <em>certainly</em> been an example of that.</p><p id="fbc4">My job change was both sudden and not: the timing was a surprise, but I probably would have ended up here someday no matter what. However, the pandemic has had a major impact on my understanding of the role, and it’s strange to think that I’ve only <em>ever</em> been a manager during a pandemic. I believe this lends me a unique perspective, which is why I wanted to share my experiences, especially if I can help anyone else currently going through this transition or beginning the move soon.</p><p id="92ae">And part of the point of this article is simply catharsis. I’ve always processed what’s happened to me the best by writing about it, and the ~100-day mark (coinciding with <a rel="noopener" href="https://npr.codes/zen-days-at-npr-5334c205f972">Intersession at NPR</a>, the perfect opportunity for me to take a break from project work for 3 days to write this) seemed like an ideal moment to pause and reflect on the past few months and what I’ve learned.</p><p id="b594">So, strap in and let’s go on a journey together!</p></div></div></section><section><div><div><p id="2eff">Before I begin to summarize my experiences <em>since</em> becoming a manager, I wanted to spend a little more time describing the events and circumstances leading up to my role change, because context is everything; even if you went through the same transition at the same time, many of your experiences are likely different. My subsequent thoughts, struggles, and learnings are a product of my background, values, the organizational context I work within, the people I work closely with, and how the pandemic has affected me personally on top of professionally.</p><p id="5848">By way of background, here is a brief timeline of some of the most significant milestones leading up to my role change:</p><ul><li id="a1da"><strong>March 24, 2014</strong>: I started at NPR as a software engineer</li><li id="d96b"><strong>September 2017</strong>: I became a founding member of and the senior developer on the newly-created Voice &amp; Emerging Platforms team</li><li id="9ceb"><strong>October 2018</strong>: We decided to create a second voice-focused scrum team</li><li id="db76"><strong>May 2019</strong>: The second Voice Platforms team was finally in place, and I began transitioning my role from senior developer to tech lead</li><li id="eb44"><strong>September 16, 2019</strong>: I was officially promoted to lead software engineer</li><li id="55de"><strong>January 29, 2020</strong>: I was asked by our VP of Technology whether I would be interested in becoming the manager for Voice &amp; Emerging Platforms</li><li id="fb49"><strong>February 28, 2020</strong>: My reports’ previous manager left, and I took over as interim/unofficial engineering manager</li><li id="329f"><strong>May 11, 2020</strong>: My role officially changed to engineering manager</li></ul><p id="3a18">When I started at NPR in March of 2014, Digital Media (our department)’s tech team had two managers, one for all software engineers and one for the small handful of sysadmins, though a second developer manager vacancy was filled later that year. By that time, we had ~25 individual contributors on the team, a mix of software engineers, mobile engineers, QA analysts, support analysts, and sysadmins/DevOps engineers. Both developer managers had roughly 10–12 engineers reporting to them. We did only incremental hiring over the next couple of years, until an internal departmental merger in the spring of 2017 led to several new engineers moving into the team, leading to the decision to create two more developer manager roles, the last of which was finally filled in May 2018 (with another external hire — up until then we’d never had someone promoted into management internally). Despite some reshuffling of who reported to who, by that point, we had grown to nearly 50 engineers, and the original manager who had hired me had become a Senior Director with only the other managers reporting directly to him, which meant we once again had anywhere from 10–14 ICs reporting to each manager. Throughout, there were always questions about how technical these managers were expected to be, but it was generally acknowledged that with so many direct reports, it didn’t leave them with enough bandwidth for much more than participation in high-level technical discussions.</p><p id="f00a">At the same time, we always had anywhere from 6 to 12 <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)" rel="noopener">scrum</a> teams focused on a specific project or product. In other words, our management structure was entirely divorced from our team assignments. This was generally considered to be a good thing at the time, because many of these project teams were intentionally short-lived, and during my first couple of years at NPR in particular, it was not unusual for someone to change teams every 9 months or so on average. Because of our reporting structure, that meant folks could change teams without needing to change managers, and thus gave us maximum flexibility and made it easier to circulate knowledge and prevent silos. For the longest time, most folks seemed happy with this setup.</p><p id="b79c">But as the tech team grew, the reporting structure made less and less sense, especially as our scrum teams had become more static over time, and our projects grew more complex and began to require a lot more cross-team coordination. The final straw came in the fall of 2019, when one manager suddenly left and another was about to embark on a 3-month sabbatical — leaving our team of ~50 ICs with only two managers for at least the next several months. It was clear that something needed to change both to address the immediate problem now and to prevent us from spreading ourselves too thin like this again in the future.</p><p id="0b1c">Now, I’ll put a pin in that for a bit and circle back to my own personal journey, because it’ll help explain why and how <em>I</em> became a manager. First, it’s important to know that I had already been expecting to go into management eventually — but I thought it was still 5–10 years off. That was a conscious decision, not an assumption about my age or tenure; I knew it was possible to go into management at this stage of my career, but I didn’t think it was the right time for me personally. I was still enjoying my role as an individual contributor, and I’d also observed other managers over the years who had struggled with the transition, often because they were moving into management <em>and</em> starting a family at the same time. Given the stage where I was at in my personal life, I decided I’d rather stay an individual contributor until after I got married and had children, deferring the challenging transition into management until after I’d settled into parenthood.</p><p id="45f7">But I knew that all roads would ultimately lead to management for me, because I knew it aligned with my values. I believe that <em>humans</em> are simultaneously the best and hardest part of software development — not code. And while I recognize that it’s possible to be a very empathetic and human-oriented lead IC, somewhere along the way, I realized that I’m more likely to be able to make the kinds of meaningful changes to make life better for the humans building our software as a manager. I’ve always been instinctively drawn to process improvements so that we don’t just solve a problem once, we prevent it from ever happening again in the future. And in many ways, a manager’s job is to continuously advocate for process changes in order to improve the lives of your team.</p><p id="2214">One memory that stands out dates back to October 2017, when I attended (and spoke at) the <a href="https://ghc.anitab.org/" rel="noopener">Grace Hopper Celebration for Women in Computing</a> for the first time. I attended a session titled “Technical to Manager: Making the Leap or Not”, which was a panel discussion featuring a diversity of experiences: a woman who had deliberately gone into management, a woman who had deliberately stayed an IC, a woman who had gone into management and hated it and went back to being an IC, and a woman who had managed to carve out a fairly unique role where she got to do equal parts of both. At one point, the woman who had deliberately gone into management made a comment that you’ll likely know management is right for you if you find yourself (perhaps subconsciously!) trading your books and blog posts and podcasts about technology for books and blog posts and podcasts about psychology and sociology. I realized already back then that that was me; while I was still doing both, I was getting more value out of reading articles from the Harvard Business Review than I was reading technical blogs.</p><p id="c78b">I still thought the move into management was many years away for me, but I ended up taking (unknowingly at the time) tentative steps toward this journey beginning in October 2018, when, as I alluded to in the timeline above, we decided to create a second voice-focused scrum team. Up until then, the engineering portion of our team had consisted of three developers, of whom I was the most senior. My manager at the time encouraged me to leverage this opportunity to move into a lead software engineer role, because our engineering ladder centered on one of the key requirements for a lead being to lead projects across multiple teams — and the addition of the second Voice team would certainly give me ample opportunity to do that.</p><p id="260d">The new scrum team was in place by May 2019, and I was incredibly proud of the combined unit we built, captured a few months later in this photo (a bit outdated now, as a couple of folks have since moved on to other teams):</p></div></div><div><div><div><figure><div><div><div><p><img alt="A group photo of the combined Voice &amp; Emerging Platforms team from October 2019." src="https://miro.medium.com/max/8576/1*eHOmjfxiKM382kxy0flixw.jpeg" width="4288" height="2848" srcset="https://miro.medium.com/max/552/1*eHOmjfxiKM382kxy0flixw.jpeg 276w, https://miro.medium.com/max/1104/1*eHOmjfxiKM382kxy0flixw.jpeg 552w, https://miro.medium.com/max/1280/1*eHOmjfxiKM382kxy0flixw.jpeg 640w, https://miro.medium.com/max/1456/1*eHOmjfxiKM382kxy0flixw.jpeg 728w, https://miro.medium.com/max/1632/1*eHOmjfxiKM382kxy0flixw.jpeg 816w, https://miro.medium.com/max/1808/1*eHOmjfxiKM382kxy0flixw.jpeg 904w, https://miro.medium.com/max/1984/1*eHOmjfxiKM382kxy0flixw.jpeg 992w, https://miro.medium.com/max/2000/1*eHOmjfxiKM382kxy0flixw.jpeg 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*eHOmjfxiKM382kxy0flixw.jpeg?q=20"></p></div></div></div><figcaption>From top left: Kaivon Jones (developer), Greg Sauer (QA), Vince Farquharson (designer), Nara Kasbergen (tech lead). Second row: Ha-Hoa Hamano (product owner), Joseph Price (product owner), Tommy O’Keefe (developer), Bina Zafar (developer), Anne Li (editorial SME), Alexander Diaz …</figcaption></figure></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://npr.codes/my-first-100-days-as-an-engineering-manager-in-a-pandemic-f55732ac0b1e">https://npr.codes/my-first-100-days-as-an-engineering-manager-in-a-pandemic-f55732ac0b1e</a></em></p>]]>
            </description>
            <link>https://npr.codes/my-first-100-days-as-an-engineering-manager-in-a-pandemic-f55732ac0b1e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606770</guid>
            <pubDate>Sun, 27 Sep 2020 14:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making Sense of Change Data Capture Pipelines for Postgres by Debezium Connector]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24606602">thread link</a>) | @turkogluc
<br/>
September 27, 2020 | https://turkogluc.com/postgresql-capture-data-change-with-debezium/ | <a href="https://web.archive.org/web/*/https://turkogluc.com/postgresql-capture-data-change-with-debezium/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                <p>Should you need to get familiar with <a href="https://turkogluc.com/apache-kafka-connect-introduction/">Kafka Connect Basics</a> or <a href="https://turkogluc.com/kafka-connect-jdbc-source-connector/">Kafka JDBC Connector</a><strong> </strong>check out the previous post. This post focuses on PostgreSQL backup-replication mechanism and streaming data from database to Kafka with using Debezium connector.</p><p>There are basically 3 major methods to perform backups or replication in PostgreSQL:</p><ul><li>Logical dumps (Extracting SQL script that represents the data, for example with using <a href="https://www.postgresql.org/docs/12/app-pgdump.html">pg_dump</a>)</li><li>Transactional Log Shipping (Using Write-Ahead Log)</li><li>Logical Decoding</li></ul><p>The first method is relatively harder to maintain and creates more load on the database. <code>Log shipping</code> and <code>Logical Decoding</code> is low level solutions that make use of transaction logs and have the major advantage of efficiency.</p><h2 id="understanding-the-transactional-log">Understanding the Transactional Log</h2><p>Transactional Log is the essential part of the modern relational database systems. It is basically <strong>history log of all actions and changes</strong> applied on the database. The database stores the data eventually in the filesystem, however this I/O operation is relatively costly and if any failure interrupts the writing process the file becomes inconsistent and it would not be easy to recover. </p><p>Therefore database writes the data to a log which is called <strong>Write-Ahead Log</strong> (WAL) directly and transaction is completed. When the data is logged in the WAL, it is considered to be successfully stored even though it is not written to file system yet. So even if system crashes or some failure arises, it will be read from the log when system restarts. </p><p>A process constantly reads the WAL, sets a <code>checkpoint</code> as point in time and writes the changes appended since the last checkpoint time to the actual database file system (every 5 mins by default). As the disk space is limited, the WAL files that are already processed are either archived or recycled (old ones are removed) in order to clean up disk space.</p><p>Each transaction log is divided into 16 MB file that is called <strong>WAL segment</strong> that consist of <strong>records</strong>. Each record has an identifier named <strong>Log Sequence Number</strong> (LSN) that shows the physical location of the record. Processing the transactions and checkpointing could be demonstrated as follows:</p><figure><img src="https://turkogluc.com/content/images/2020/09/Screenshot-2020-09-27-at-01.51.59.png"></figure><h2 id="it-s-all-about-wal-">It's All About WAL!</h2><p>The WAL has important role in replication as it contains the details about transactions, and these records are very important and useful in terms of representing the database state. Note that the WAL segments are not stored forever, once it is consumed it is removed from the disk. So one way to backup locally is copying segment files to a different directory (default dir: <code>pg_wal</code>). Sharing these records with remote servers gives the opportunity to create replicas efficiently.</p><h3 id="transactional-log-shipping">Transactional Log Shipping</h3><p>It is a solution to replicate the database in different servers by shipping the WAL segments. Replica server operates on recovery mode all the time and replays the WAL records that it receives to be consistent with primary server. This solution could be implemented by sending the complete 16MB WAL segments files or streaming individual records as they are written. Streaming is a better solution in terms of durability. See the details of psychical replication implementation details: <a href="https://www.postgresql.org/docs/13/warm-standby.html">Log Shipping</a>.</p><figure><img src="https://turkogluc.com/content/images/2020/09/Screenshot-2020-09-27-at-10.36.31.png"></figure><p>In Log Shipping method the segment files which contains binary data copied physically (byte-by-byte) to another server. So it can be also called <strong>physical replication</strong>. This approach has some limitations and drawbacks as it is not possible to replicate between different versions of Postgres or different operating systems, and also it can not replicate part of a database. Logical replication is introduced to address these limitations.</p><h3 id="logical-replication">Logical Replication</h3><p>Logical replication is a method that decodes the binary WAL records into a more understandable format and sends this decoded data to remote server. It uses <code>publish</code> and <code>subscribe</code> model with one or more subscribers receiving data from publishers. In contrast to physical replication, there is no Primary and Standby servers but data can flow both sides, but from publishers to subscribers. Publisher creates a <a href="https://www.postgresql.org/docs/13/sql-createpublication.html"><code>PUBLICATION</code></a>:</p><pre><code>CREATE PUBLICATION mypublication FOR TABLE users, departments;
CREATE PUBLICATION alltables FOR ALL TABLES;</code></pre><p>And Subscribers creates <code><a href="https://www.postgresql.org/docs/13/sql-createsubscription.html">SUBSCRIPTION</a></code>:</p><pre><code>CREATE SUBSCRIPTION mysubcribtion
         CONNECTION 'host=localhost port=5432 user=foo dbname=foodb'
        PUBLICATION mypublication, alltables;</code></pre><p>The changes send by publisher are replicated in the subscriber database to ensure that the two databases remain in sync. It is important to remember that after some time WAL segments are deleted. So if a subscriber stops for some and the the WAL record is deleted in the publisher it causes a FATAL error. </p><p><strong><a href="https://www.postgresql.org/docs/13/logicaldecoding-explanation.html">Replication slots</a></strong> solves this problem for us. By assigning a subscriber to a replication slot we can guarantee that the WAL records that it related with the subscription are not going to be removed until the subscriber consumes them. <code>CREATE SUBSCRIPTION</code> command automatically generates a replication slot in the publisher side for us so we do not need to create it manually.</p><figure><img src="https://turkogluc.com/content/images/2020/09/Screenshot-2020-09-27-at-12.14.55.png"></figure><p>Now having the necessary knowledge of PostgreSQL replication concepts we can proceed to configure and manage the Debezium Connector.</p><h2 id="debezium-connector">Debezium Connector</h2><p>Debezium is an open source <strong>Change Data Capture</strong> platform that turns the existing database into event streams. Debezium Kafka Connector captures each row level change in the database and sends them to Kafka topics.</p><figure><img src="https://turkogluc.com/content/images/2020/09/debezium-architecture.png"></figure><p>Debezium uses the <code>logical replication</code> feature of PostgreSQL in order to capture the transaction records from the WAL. The connector acts the subscriber role for the changes published from tables. It handles all the low level configuration for us, as creating publisher, subscribers replication slots etc.</p><p>In order to use the connector we need an <code>output plugin</code> installed in the PostgreSQL server so that it can decode the WAL records. Debezium connector supports number of output plugins:</p><ul><li><a href="https://github.com/debezium/postgres-decoderbufs"><code>decoderbufs</code></a>: based on Protobuf and maintened by Debezium Community</li><li><a href="https://github.com/eulerto/wal2json/blob/master/README.md"><code>wal2json</code></a>: based on JSON</li><li><code>pgoutput</code>: is the standard logical decoding output plug-in in PostgreSQL, also supported by Debezium Community.</li></ul><p>I personally recommend using <code>pgoutput</code> as it is the native plugin and it does not require any additional installation. If you would like to use another plugin you need to install it in the database server. See the <a href="https://debezium.io/documentation/reference/1.2/postgres-plugins.html">documentation</a> for installing plugins. We can setup the all architecture with the following steps</p><h3 id="1-running-kafka-cluster">1-Running Kafka Cluster</h3><p>We can use the following docker-compose file to get Kafka cluster with a single broker up and running.</p><pre><code>version: '2'
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:latest
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  control-center:
    image: confluentinc/cp-enterprise-control-center:5.5.1
    hostname: control-center
    container_name: control-center
    depends_on:
      - zookeeper
      - kafka
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

  postgresql:
    image: postgresql:12
    hostname: postgresql
    container_name: postgresql
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: demo
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: root
</code></pre><p>Note that confluent center is optional and used only as the user interface for Kafka broker.</p><h3 id="2-preparing-debezium-connector-plugin">2- Preparing Debezium Connector Plugin</h3><p>Download the <a href="https://debezium.io/releases/1.2/">Debezium PostgreSQL Connector</a> plugin and extract the zip file to the Kafka Connect's plugins path. While we start Kafka Connector we can specify a plugin path that will be used to access the plugin libraries. For example <code>plugin.path=/usr/local/share/kafka/plugins</code>. Check <a href="https://docs.confluent.io/current/connect/managing/install.html#connect-install-connectors">Install Connector Manually</a> documentation for details.</p><h3 id="3-running-kafka-connect"><strong>3- Running Kafka Connect</strong></h3><p>We can run the Kafka Connect with <code>connect-distributed.sh</code> script that is located inside the kafka <code>bin</code> directory. We need to provide a properties file while running this script for configuring the worker properties.</p><p>We can create create <code>connect-distributed.properties</code> file to specify the worker properties as follows:</p><pre><code># A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
bootstrap.servers=localhost:29092

# unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs
group.id=connect-cluster

# The converters specify the format of data in Kafka and how to translate it into Connect data. 
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter.schemas.enable=true

# Topic to use for storing offsets. This topic should have many partitions and be replicated and compacted.
offset.storage.topic=connect-offsets
offset.storage.replication.factor=1

# Topic to use for storing connector and task configurations; note that this should be a single partition, highly replicated,
config.storage.topic=connect-configs
config.storage.replication.factor=1

# Topic to use for storing statuses. This topic can have multiple partitions and should be replicated and compacted.
status.storage.topic=connect-status</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://turkogluc.com/postgresql-capture-data-change-with-debezium/">https://turkogluc.com/postgresql-capture-data-change-with-debezium/</a></em></p>]]>
            </description>
            <link>https://turkogluc.com/postgresql-capture-data-change-with-debezium/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606602</guid>
            <pubDate>Sun, 27 Sep 2020 13:51:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating the Dunlop Crybaby Wah Pedal in LTSpice]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24606460">thread link</a>) | @cushychicken
<br/>
September 27, 2020 | http://cushychicken.github.io/ltspice-dunlop-crybaby/ | <a href="https://web.archive.org/web/*/http://cushychicken.github.io/ltspice-dunlop-crybaby/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The Dunlop CryBaby is a timeless effect pedal. Jimi Hendrix, Eric Clapton, David Gilmour, and a host of other rock musicians began popularizing the wah effect in the mid 60s, and just about every rock guitarist onwards has toyed with them at one point or another. Seems like a natural choice to look at next using LTSpice.</p><p>If you’d like to follow along at home, <a href="https://github.com/Cushychicken/ltspice-guitar-pedals/tree/master/dunlop-crybaby-wah">I’ve put the LTSpice file up on GitHub for your persual</a>. Find mistakes? Want to submit mods? Feel free to submit a pull request.</p><p>This is the first design I’ve analyzed with no opamps. Cool! Light on active components, but heavy on fun circuit tricks.</p><p>The bulk of the excitement in the Dunlop CryBaby is in the Active Filter + Output section, but we’ll take a look at the Input and Feedback Follower segments as well. (Power is very simple - a few bulk caps, and a Zener for reverse voltage clamping in the event that the battery accidentally gets wired backwards. Doesn’t meaningfully affect any of the audio stuff we’re discussing.)</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600979249553.png" alt="Dunlop Crybaby - Whole Schematic"></p><p>This isn’t anything special - just a high impedance BJT follower. This forms a nice, cheap buffer to redrive the input signal into the downstream components.</p><p><img src="http://cushychicken.github.io/assets/images/2020-09-25-ltspice-dunlop-crybaby/Image-1600979302189.png" alt="Input Buffer"></p><p>Q1 is actually strongly biased. Based on my limited research, this is pretty rare in guitar pedals. Lotsa vendors out there who want to save a few fractions of a cent on a resistor, apparently. That, and the fact that audio electronics is a pretty small community. Lots of designers bouncing from one company to the next, and a reasonable amount of ripping off of other companies’ designs.</p><p>At the end of the day, though, lousy biasing isn’t that big of a deal. This is just audio. It’s not medical equipment, or critical infrastructure. Worst case, the biasing sucks, and someone’s pedal dies.</p><p>Q2 is a standard common-emitter amp. It also provides the bias for Q3, the downstream feedback amplifier, via R11.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600979345975.png" alt="Active Filter + Output Stage"></p><p>L1 and C11 form a resonant tank. This LC tank circuit accentuates different frequencies based on the setting of the potentiometer (R14 + R12), which alters the feedback into the tank. (More on the Q3 feedback circuit in a minute.)</p><p>This affects the damping, and also the resonant frequency, of the resonant tank. It’s easiest to see in the time domain; a simple step response shows that for Rtone = 100 ohms, you get a mildly underdamped circuit with a resonance at ~2.1kHz.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600979387157.png" alt="Step Response: Rtone=100 ohm"></p><p>Crank Rtone up to 100kOhm (i.e. short the feedback path to the output), and you get a wildly underdamped circuit with a resonance at ~430Hz.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600979449819.png" alt="Step Response: Rtone=100k"></p><p>The feedback follower is really just another emitter follower, like the input stage. Unlike the input stage, it’s got a potentiometer serving as a variable attenuator at the input.</p><p><img src="http://cushychicken.github.io/assets/images/Image-1600979641895.png" alt="Feedback Follower"></p><p>Rtone is really controlling two things:</p><ul><li>how much current is fed back into the LC tank in the active filter stage, and</li><li>which frequencies are fed back into the LC stage.</li></ul><p>Rtone and C8 form a very simple RC filter which determines which range of frequencies get fed back. When the potentiometer is at 100k, Vfb_in shorts to Vout, and you’re feeding the unattenuated signal back into the LC tank, with no meaningful guitar frequencies suppressed: \[R12||C8 = (100k\Omega) || (0.22uF) = 7.2[Hz]\]</p><p>Conversely, when the potentiometer starts to short Vfb_in to GND, you’re not feeding anything back into the tank. The RC passband moves down, with most current getting shunted to ground instead of thru C8: \[R12||C8 = (100 \Omega) || (0.22uF) = 7200[Hz]\]</p><p>You can see this as you plot Vfb_in against Vout for a sweep of Rtone values across frequencies:</p><p><img src="http://cushychicken.github.io/assets/images/image-20200925141159987.png" alt="Vbn_in magnitude decreases as Rtone shorts to GND"></p><p>Without the feedback component, Q2 is basically just an active highpass filter. The feedback element formed by Rtone, C8, and Q3 is a variable lowpass filter. Adding feedback mixes this lowpass element with the highpass filter, forming an <em>active bandpass filter</em>.</p><p>The net effect of this a nice moving central peak in the magnitude response of the Wah pedal, allowing you to accentuate any signals within the 500Hz to 2kHz band:</p><p><img src="http://cushychicken.github.io/assets/images/Image-1601057975751.png" alt="Tone Setting vs Frequency"></p><p>Plotting phase with this many sweep components is a bit of an eye exam, but it reveals a pretty useful corollary to understanding the Wah at a conceptual level:</p><p><img src="http://cushychicken.github.io/assets/images/Image-1601058017485.png" alt="Tone Setting vs Frequency, with Phase"></p><p>Note that the peak of each output magnitude in the plot aligns nicely with the 180deg phase delta of the input. That’s not an accident - in fact, that’s the crux of what this pedal is doing. The feedback stage is a simple emitter follower. An emitter follower inverts whatever signal it is fed, leaving you with a signal shifted 180 degrees at the output. That shifted signal, in this case, is fed back into the input, through the resonant tank. If you’ve done any oscillator design, this 180 degree criterion will sound familiar:</p><ul><li>take a high gain amplifier,</li><li>offset its output 180 degrees from the input,</li><li>and feed the output back into the input,</li></ul><p>…and you have an oscillator! That’s the same idea behind the CryBaby. It’s basically a crude voltage tuned oscillator, but without the near-infinite gain. You’re effectively selecting the oscillator tuning frequency by controlling how much current is fed back into the LC tank.</p><p>ElectroSmash, of course, is an excellent reference on all things guitar pedal, and <a href="https://www.electrosmash.com/crybaby-gcb-95">their wah analysis is no exception</a>.</p><p>The timeless R.G. Keen also has <a href="http://www.geofex.com/article_folders/wahpedl/wahped.htm#whatwah">a wondrous overview of wah pedals</a>, consisting of both circuit and qualitative analysis.</p></div></div>]]>
            </description>
            <link>http://cushychicken.github.io/ltspice-dunlop-crybaby/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606460</guid>
            <pubDate>Sun, 27 Sep 2020 13:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The failed promise of Web Components]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24606342">thread link</a>) | @yannikyeo
<br/>
September 27, 2020 | https://blog.carlmjohnson.net/post/2020/web-components/ | <a href="https://web.archive.org/web/*/https://blog.carlmjohnson.net/post/2020/web-components/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><blockquote><p>The promise of Web Components was that we’d get this convenience, but for a much wider range of HTML elements, developed much faster, as nobody needs to wait for the full spec + implementation process. We’d just include a script, and boom, we have more elements at our disposal!</p><p>Or, that was the idea. Somewhere along the way, the space got flooded by JS frameworks aficionados, who revel in complex APIs, overengineered build processes and dependency graphs that look like the roots of a banyan tree.</p></blockquote><p>I think the issue is deeper than Verou’s complaints, although those are valid. Web Components don’t actually to solve the problem they purport to solve. The pitch is “get <strong>semantic elements</strong> from <strong>across the web</strong><i>!</i>” But those are <strong>wrong problems</strong> to try to solve.</p><hr><p>First of all, if search engines and screen readers don’t know about <code>&lt;my-tag&gt;</code>, it’s <strong>not semantic</strong> in any meaningful sense. There is already a very good way to provide semantic information to search engines: use <a href="https://en.wikipedia.org/wiki/JSON-LD">JSON-LD</a> to provide <a href="https://schema.org/">schema.org</a> metadata. For accessibility, you need to either use the correct HTML5 element or use <a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/An_overview_of_accessible_web_applications_and_widgets">ARIA attributes</a>, and this process is going to be the same whether you’re using Web Components or something else.</p><p>So next, <strong>“from across the web”</strong> is a performance killer. No matter how good networks and browsers get in the foreseeable future, you’re not going to be able to build a content page from multiple domains in under a second just due to the latencies involved in connecting, and that’s the performance goal content sites should be meeting. You need to at minimum host the scripts on your site. Once you’re doing that, the temptation to just go ahead and bundle them is pretty strong. Yes, HTTP2 makes the price of having several small modules much lower, but it’s hard to argue against minifying, concatenating, and tree shaking to pick up any remaining performance benefits. Now you’ve landed into the mess that it is modern JS bundling, for better or worse. Remember that best case here is that you end up at the fourth phase of <a href="https://twitter.com/carlmjohnson/status/982747054614220800">the dialectic of dependencies</a>: being overrun by low quality user written components.</p><hr><p>Okay, so what about the JavaScript for Web Components themselves. They have this system in which you subclass <code>HTMLElement</code> and register the class as custom element with <code>customElements.define()</code>. What does this buy you over and above just using <code>document.querySelectorAll("[data-my-element]")</code>? Not a lot. It gets you a system of lifecycle hooks. Cool, I guess, but it doesn’t actually have any tools to manage your <em>data</em> lifecycle, so it’s not actually very useful. If you store your data in the DOM, it just becomes a bunch of strings on elements, and this stinks because most of you data is boolean (Is the widget open or closed? Am I waiting on a fetch to finish?) and has to be mutilated to fit into string (<code>el.attr === "true"</code> makes Alan Turing’s ghost cry). And forget about compound types like arrays and maps. The only practical solution there is to serialize the data to JSON and store that on the element, which is crazy. So, you can use the Web Component custom element lifecycle to manage <em>element</em> creation and deletion, but you need to have some other system for rationalizing the data lifecycle if your component is more complex than a <code>&lt;details&gt;</code> box.</p><p>Web Components are also associated with <code>&lt;template&gt;</code> and <code>&lt;slot&gt;</code> elements, but this is a substitute templating language, and it stinks. There are three competing schools of templating, each with its own niche. There are old school <a href="https://mustache.github.io/mustache.5.html">Mustache</a>/<a href="https://handlebarsjs.com/">Handlebars</a>/<a href="https://shopify.github.io/liquid/">Liquid</a>/<a href="https://jinja.palletsprojects.com/en/2.11.x/">Jinja</a>-style templates where the HTML is treated as raw text but with auto-escaping and some looping constructs. There are <a href="https://docs.angularjs.org/tutorial/step_02">Angular</a>/<a href="https://vuejs.org/v2/guide/">Vue</a>/<a href="https://github.com/alpinejs/alpine">Alpine</a>-style templates which treat HTML as a first class concept, and there are attributes for interpolation and looping. And there is <a href="https://crank.js.org/">JSX</a>, which sort of combines the two, allowing for intermingling of regular JavaScript and pseudo-XML. <code>&lt;template&gt;</code>/<code>&lt;slot&gt;</code> is pretty much unusable because it doesn’t actually address the hard parts of templating, which are interpolating and looping. Again, it’s not buying you much versus just writing a <a href="https://gist.github.com/carlmjohnson/45c0b8394f28b2ee3662edfeb80d29ee">quickie <code>document.createElement</code> helper function</a>.</p><p>So what’s left is <a href="https://developer.mozilla.org/en-US/docs/Web/Web_Components/Using_shadow_DOM">Shadow DOM</a>. Shadow DOM is a feature for when you need to include an element on a page that breaks out of the styles of its parents. That <em>is</em> sometimes useful. But it is also extremely niche and should be part of CSS and not part of JS. The fundamental thing that Shadow DOM does is to allow an element of the page to have its own CSS reset. There’s no reason we couldn’t have that as part of CSS itself instead (perhaps by changing the rules for <code>@import</code> to allow it to be nested instead of only at the top level).</p><hr><p>I am a person who is in the market for the sort of thing that Web Components are supposedly good at. For <a href="https://www.spotlightpa.org/">my day job</a>, I distribute embed codes so that our partners can embed little widgets that let you sign up for <a href="https://www.spotlightpa.org/newsletters/">the Spotlight PA newsletter</a> from their sites. It’s supposed to be the clear use case. But even if I were willing to sacrifice IE11 compatibility (not a big deal but I prefer not to do so gratuitously), I don’t see why I should prefer that my embed code look like this:</p><div><pre><code data-lang="html"><span>&lt;</span><span>script</span> <span>src</span><span>=</span><span>"https://example.com/embed.js"</span> <span>async</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
<span>&lt;</span><span>spl-embed</span> <span>version</span><span>=</span><span>"1"</span> <span>src</span><span>=</span><span>"https://www.spotlightpa.org/embeds/newsletter/"</span><span>/&gt;</span>
</code></pre></div><p>Instead of what it actually looks like, which is this:</p><div><pre><code data-lang="html"><span>&lt;</span><span>script</span> <span>src</span><span>=</span><span>"https://www.spotlightpa.org/embed.js"</span> <span>async</span><span>&gt;&lt;/</span><span>script</span><span>&gt;</span>
<span>&lt;</span><span>div</span>
  <span>data-spl-embed-version</span><span>=</span><span>"1"</span>
  <span>data-spl-src</span><span>=</span><span>"https://www.spotlightpa.org/embeds/newsletter/"</span>
<span>&gt;&lt;/</span><span>div</span><span>&gt;</span>
</code></pre></div><p>Yes, shorter tags would be nicer, but how does it actually benefit performance, search engines, or accessibility?</p><p>As it turns out, I <em>do</em> use Shadow DOM, but just to reset the CSS around my iframe to make sure it is responsively sized.</p><p>If I could get the ear of W3C, I would ask them to create a way for iframes to be properly sized without requiring JavaScript to communicate the size from within the iframe to the host page. That’s something that would actually make my life easier, unlike Web Components, which are basically just failed solutions to the wrong problems.</p></section></div>]]>
            </description>
            <link>https://blog.carlmjohnson.net/post/2020/web-components/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606342</guid>
            <pubDate>Sun, 27 Sep 2020 13:05:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using redo to manage R data analysis workflow]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24606188">thread link</a>) | @todsacerdoti
<br/>
September 27, 2020 | http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/ | <a href="https://web.archive.org/web/*/http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p>Real world data analysis projects are often quite complicated.
They can involve multi-gigabyte input files, complex data cleaning procedures, week-long computations, and elaborate reports.
Making changes and then tracking down the parts that need to be recomputed becomes close to impossible.
In this article I describe my approach for dealing with this problem, which is based on a lesser known build automation tool - redo<a href="#fn:1" id="fnref:1" title="see footnote"><sup>◦</sup></a>.</p>

<h2 id="redo">Redo</h2>

<p>Data science projects typically have complex pipelines involving input files, code, results, and reports.
Analyses can be computationally intensive and take hours if not days or weeks to complete.
Hence data science practitioners need to be able to make changes without restarting the whole pipeline from scratch.
Workflow management becomes essential and many projects turn to build automation tools like Make<a href="#fn:2" id="fnref:2" title="see footnote"><sup>◦</sup></a>.
However Make has its warts, in particular when applied to data analysis, and so people end up designing their own variants, such as SCons<a href="#fn:3" id="fnref:3" title="see footnote"><sup>◦</sup></a>, Snakemake<a href="#fn:4" id="fnref:4" title="see footnote"><sup>◦</sup></a>, and Drake<a href="#fn:5" id="fnref:5" title="see footnote"><sup>◦</sup></a>, among others.</p>

<p>One lesser known alternative to the above mentioned tools goes by the name of “redo”.
Redo is a recursive build automation system that promises to be simpler and more powerful than Make.
Unlike Make or its derivatives redo is tiny, recursive, and has no special syntax of its own.
It allows us to declare target dependencies straight from within the code being executed, which enables writing scripts that “know” they will need to rerun themselves whenever their input data changes all without maintaining a separate dependency configuration file.
In this demonstration we will be using the redo version by “apenwarr”<a href="#fn:6" id="fnref:6" title="see footnote"><sup>◦</sup></a> who rediscovered, documented, and popularized the idea and is the author and current maintainer of its most comprehensive implementation<a href="#fn:7" id="fnref:7" title="see footnote"><sup>◦</sup></a>.</p>

<h2 id="setup">Setup</h2>

<p>A typical data analysis workflow has four parts: 1) obtaining the data; 2) cleaning the data; 3) estimating a model; 4) producing a report.
Similarly our dummy project will consist of four steps:</p>

<ol>
<li>Obtain a dataset of chicken weights and their feed supplements.</li>
<li>Subset the data by only selecting one type of feed supplement.</li>
<li>Produce a “model” for the selected supplement using empirical density estimation.</li>
<li>Summarise the obtained results in a report.</li>
</ol>

<p>Each step will produce an output and save the results to a separate file.
To keep things simple all the scripts for the steps above will be written in R.
The overall goal is to construct a pipeline that can detect changes in our stored data files or our code and automatically reproduce the final report with all its dependencies.
This demonstration will start simple and add complexity along the way.</p>

<h2 id="doingandredoing">Doing and redoing</h2>

<p>Let’s start with the most basic redo command.
In the first step we have to obtain a dataset of chicken weights plus the type of supplements they were fed and store it in a file.
The dataset is already freely available from within R so all we have to do is save it.
We enter the commands to do the task in a file named <code>'rawdata.rds.do'</code>:</p>

<pre><code>1.  #!/usr/bin/env Rscript
2.
3.  outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.  saveRDS(chickwts, file = outfile)
</code></pre>

<p>Then to obtain the data file we go to a command line and call redo:</p>

<pre><code>$ redo rawdata.rds

redo:  rawdata.rds
</code></pre>

<p>Which creates the <code>'rds'</code> file named <code>'rawdata.rds'</code> containing the data and informs us about the result.</p>

<p>Some explanation is necessary.
The redo command simply takes an argument and tries to produce a file of the same name.
In this case the argument was <code>'rawdata.rds'</code> and, given the command, redo starts looking for instructions about how to produce it.
The rule for storing instructions is quite simple - they are stored in a separate file with a name constructed by adding a <code>'.do'</code> suffix to the original argument.
In other words - redo looks for instructions about producing <code>'rawdata.rds'</code> file in a file named <code>'rawdata.rds.do'</code>.</p>

<p>The file itself is treated as a shell script.
This is why it is started with a hash-bang<a href="#fn:8" id="fnref:8" title="see footnote"><sup>◦</sup></a> sequence followed by a path to a program that will be used to interpret the instructions.
We want to write our script in R so we specify Rscript.</p>

<p>Finally, when redo calls our script with <code>'redo rawdata.rds.do'</code> it passes three arguments to it:
1) The target name itself - <code>'rawdata.rds'</code>, 2) The basename of the target file - <code>'rawdata'</code>, 3) The temporary file to save the data in - <code>'rawdata.rds.redo.tmp'</code>.
After the execution finishes the file stored in the temp file (3rd argument) will be moved to the target (1st argument).
This mechanism makes sure that in the case of failed computation the existing target will not be corrupted.
And that is why we do not specify the output filename within the script ourselves but rather use the 3rd variable provided by redo.</p>

<p>The dataset is obtained and stored and so the first step of this project is now complete.</p>

<h2 id="dependencies">Dependencies</h2>

<p>What happens if we execute the previous redo command again? - nothing spectacular:</p>

<pre><code>$ redo rawdata.rds

redo  rawdata.rds
</code></pre>

<p>Redo executed the instruction file again and reproduced the output.
But there exists another command called <code>redo-ifchange</code> that behaves a bit differently:</p>

<pre><code>$ redo-ifchange rawdata.rds
</code></pre>

<p>After calling this command - nothing happens.
<code>redo-ifchange</code> differs from redo in an important way: it checks if any dependencies needed to reproduce the specified output have changed.
In our case redo knows only a single dependency for our <code>'rawdata.rds'</code> file - the ‘do’ instruction file itself.
It hasn’t changed so <code>redo-ifchange</code> halts and does not reproduce the target.</p>

<p>So let’s move on to the second step of the project and select a feed type.
To achieve this we produce a separate R file called <code>'subdata.rds.do'</code>:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.
5.   system("redo-ifchange rawdata.rds")
6.   rawdata &lt;- readRDS("rawdata.rds")
7.
8.   subdata &lt;- rawdata[rawdata$feed == "soybean", ]
9.
10.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Take a closer look at the 5th line in the file above.
Here, before loading the data, we call the <code>redo-ifchange</code> command on it.
At this step the script temporarily halts and checks if our requested data file, <code>rawdata.rds</code>, needs to be recomputed.
If the target file is missing or some of its dependencies have changed it will be regenerated by calling the <code>'rawdata.rds.do'</code> script.
And if nothing changed the 5th line passes without redoing anything and the already existing data file is used.</p>

<p>Now, to obtain the output for the second step, we request the file with redo, just like before:</p>

<pre><code>$ redo subdata.rds

redo subdata.rds
</code></pre>

<p>All done, the result is stored in <code>'subdata.rds'</code>.
Currently we have the following files in our project:</p>

<pre><code>$ tree
.
├── rawdata.rds
├── rawdata.rds.do
├── subdata.rds
└── subdata.rds.do
</code></pre>

<p>Let’s remove all the <code>'rds'</code> data files and try reproducing the <code>'subdata.rds'</code> again:</p>

<pre><code>$ rm *.rds
$ redo subdata.rds

redo  subdata.rds
redo    rawdata.rds
</code></pre>

<p>Here we asked for <code>'subdata.rds'</code> but redo was smart enough to reproduce both of the data files.
What we did, in essence, is declared a dependency between two R scripts from within the script itself.</p>

<h2 id="defaultinstructions">Default instructions</h2>

<p>Before moving on we have to spend some time on a few redo implementation details.
By convention when we call <code>'redo a.b.rds'</code> command redo starts looking for an <code>'a.b.rds.do'</code> script.
But if the file doesn’t exist redo will search for a different file named <code>'default.b.rds.do'</code> which should store general instructions for producing any <code>'*.b.rds'</code> file.
As an example we rename our previous <code>'subdata.rds.do'</code> file to <code>'default.subdata.rds.do'</code>.
Now this do script will get executed whenever we use redo to request a file that ends with <code>'subdata.rds.do'</code>:</p>

<pre><code>$ mv subdata.rds.do default.subdata.rds.do
$ redo a.subdata.rds b.subdata.rds

redo a.subdata.rds
redo b.subdata.rds
</code></pre>

<p>Since both files generated above were produced by the same script <code>'default.subdata.rds.do'</code> they are identical - they both hold the data for soybean feed.
Those files will no longer be needed for our demonstration so we can get rid of them:</p>

<pre><code>$ rm *subdata.rds
$ tree
.
├── default.subdata.rds.do
├── rawdata.rds
└── rawdata.rds.do
</code></pre>

<h2 id="parameters">Parameters</h2>

<p>The default instructions introduced above can be exploited to implement parameters in our do scripts.
In the current stage we have a script - <code>'default.subdata.rds.do'</code> that is executed whenever we request an ‘rds’ file that ends with <code>'subdata.rds'</code>.
It always produces the data for the soybean feed but we can make it return different outputs based on the prefix of the target file.</p>

<p>Currently the feed types we are selecting are hard-coded in the code itself.
It would be nicer if we can specify them as parameters passed to the R script.
We rewrite <code>'default.subdata.rds.do'</code> file:</p>

<pre><code>1.   #!/usr/bin/env Rscript
2.
3.   outfile &lt;- commandArgs(trailingOnly = TRUE)[3]
4.   feed    &lt;- strsplit(outfile, "\\.")[[1]][1]
5.
6.   system("redo-ifchange rawdata.rds")
7.   rawdata &lt;- readRDS("rawdata.rds")
8.
9.   subdata &lt;- rawdata[rawdata$feed == feed, ]
10.
11.  saveRDS(subdata, file = outfile)
</code></pre>

<p>Two changes were made:
1) the 4th line uses the prefix of the output file in order to decide which feed type should be returned;
2) the 9th line then uses the selected feed type in order to subset the data.
This allows us to request various types of feed data:</p>

<pre><code>$ redo soybean.subdata.rds

redo soybean.subdata.rds

$ redo casein.subdata.rds

redo casein.subdata.rds
</code></pre>

<p>And now we have separate types in separate files.</p>

<h2 id="redoingwithparameters">Redoing with parameters</h2>

<p>In the third step we need a do script that, given subsetted feed data, estimates the density function and stores the result to a separate file.
Like the previous script, we want it to be general and produce the results for any selected feed type.
For this to work we have to know which input file to load based on the given output file.
If the script will be called by <code>'redo soybeen.density.rds'</code> command our target will be <code>'soybean.density.rds'</code>.
And from this we can deduce that the input file needed to obtain its density is <code>'soybean.subdata.rds'</code>.</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/">http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</a></em></p>]]>
            </description>
            <link>http://karolis.koncevicius.lt/posts/using_redo_to_manage_r_data_analysis_workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606188</guid>
            <pubDate>Sun, 27 Sep 2020 12:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jeff Orlowski: We Need to Rethink Social Media Before It’s Too Late]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24606093">thread link</a>) | @tannhaeuser
<br/>
September 27, 2020 | https://respectinvestment.com/news/we-need-to-rethink-social-media-before-its-too-late-weve-accepted-a-faustian-bargain-jeff-orlowski/ | <a href="https://web.archive.org/web/*/https://respectinvestment.com/news/we-need-to-rethink-social-media-before-its-too-late-weve-accepted-a-faustian-bargain-jeff-orlowski/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tps_slideContainer_15397"><div>

<p>When people envision technology overtaking society, many think of The Terminator and bulletproof robots. Or Big Brother in George Orwell’s Nineteen Eighty-Four<em>, </em>a symbol of external, omnipotent oppression.</p>
<p>But in all likelihood, dystopian technology will not strong-arm us. Instead, we’ll unwittingly submit ourselves to a devil’s bargain: freely trade our subconscious preferences for memes, our social cohesion for instant connection, and the truth for what we want to hear.</p>
<p>Indeed, as former insiders at Google, Twitter, Facebook, Instagram and YouTube attest in our new documentary, <a href="http://thesocialdilemma.com/" data-link-name="in body link">The Social Dilemma</a><em>, </em>this is already happening. We already live in a version of Aldous Huxley’s Brave New World<em>.</em> As Neil Postman puts it in his 1985 book Amusing Ourselves to Death: Public Discourse in the Age of Show Business:</p>
<div>
<blockquote>
<p>In Huxley’s vision, no Big Brother is required to deprive people of their autonomy, maturity, and history. As he saw it, people will come to love their oppression, to adore the technologies that undo their capacities to think.</p>
</blockquote>
</div>
<p>The technology that threatens our society, democracy, and mental health is lurking in our bedrooms, sometimes lying on our pillows, as we fall asleep. We awake to its call, bring its chiming notifications to dinner, and blindly trust where it guides us. We scroll insatiably, unsuspecting that the technology that connects us, especially now in a distanced world, is also controlling us.</p>

<p>Our social media platforms are powered by a surveillance-based business model designed to mine, manipulate, and extract our human experiences at any cost, causing a breakdown of our information ecosystem and shared sense of truth worldwide. This extractive business model is not built <em>for </em>us but built to <em>exploit</em> us.</p>
<p>A <a href="https://www.pewresearch.org/fact-tank/2019/07/25/americans-going-online-almost-constantly/" data-link-name="in body link">third</a> of American adults, and nearly half of those aged 18-29, say they are online “almost constantly”. But, unlike the citizens of Brave New World, we’re miserable. As our time online has gone up, so have anxiety, depression and suicide <a href="https://academic.oup.com/aje/article/185/3/203/2915143" data-link-name="in body link">rates</a>, particularly among youth.</p>
<p>Social media is also derailing productive public discourse. A largely ignored <a href="https://www.wsj.com/articles/facebook-knows-it-encourages-division-top-executives-nixed-solutions-11590507499" data-link-name="in body link">internal memo</a> to senior executives at Facebook in 2018 explained: “Our algorithms exploit the human brain’s attraction to divisiveness.” Left unchecked, the algorithms will feed users “more and more divisive content in an effort to gain user attention and increase time on the platform”.</p>
<p>In 2014, <a href="https://www.pewresearch.org/politics/2014/06/12/political-polarization-in-the-american-public/" data-link-name="in body link">Pew Research Center</a> found that partisan antipathy and division in America is “deeper and more extensive than at any point in the last two decades”. Over the past six years, social media has only exacerbated these sentiments. In 2019, 77% of Republicans and 72% of Democrats <a href="https://www.pewresearch.org/politics/2019/10/10/partisan-antipathy-more-intense-more-personal/" data-link-name="in body link">said</a> voters in both parties “not only disagree over plans and policies, but also cannot agree on the basic facts”.</p>
<div>
<p><img alt="'Facebook's recent measures do not address the fundamental problem of their exploitative business model.'" src="https://i.guim.co.uk/img/media/791367d1f965680b32dec327b89de8cd12a16632/348_608_2957_1775/master/2957.jpg?width=445&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=6ab86e610ff41614d84794d1015c51b3" height="1775" width="2957"></p>
</div>
<p>In The Social Dilemma, Tristan Harris, a former Google design ethicist and the co-founder of the <a href="https://www.humanetech.com/" data-link-name="in body link">Center for Humane Technology</a>, points out that far before technology overpowers human strengths, it will overwhelm human weaknesses. Sophisticated algorithms learn our emotional vulnerabilities and exploit them for profit in insidious ways.</p>
<p>By surveilling nearly all of our online activity, social media platforms can now predict our emotions and behaviors. They leverage these insights and auction us to the highest advertising bidder, and they have consequently become some of the <a href="https://www.nytimes.com/2020/01/24/opinion/sunday/surveillance-capitalism.html" data-link-name="in body link">richest companies in the history of the world</a>.</p>
<p>But users aren’t just being sold a pair of shoes. The targeting capabilities of these platforms give anyone with a motive the power and precision to influence us cheaply and with phenomenal ease. <a href="https://www.nytimes.com/2019/09/26/technology/government-disinformation-cyber-troops.html" data-link-name="in body link">Disinformation campaigns</a> have been cited in more than 70 countries, and doubled from 2017 to 2019.</p>
<p>The whistleblower Sophie Zhang has <a href="https://www.buzzfeednews.com/article/craigsilverman/facebook-ignore-political-manipulation-whistleblower-memo" data-link-name="in body link">revealed</a> how pervasive the problem is on Facebook’s platform, and how little the company acts on it. Facebook recently <a href="https://www.nytimes.com/2020/09/03/technology/facebook-election-chaos-november.html" data-link-name="in body link">rolled out</a> a series of updates to mitigate political misinformation in the upcoming US presidential election, including a bar on political ads one week before election day, but these measures are too little, too late, and they do not address the fundamental problem of their exploitative business model.</p>
<p>After nearly three years of working on this film, I now see “the social dilemma” as a foundational problem of our time, underlying many of the other societal conflicts that require compromise and a shared understanding to fix. If two sides are constantly fed reflections of their pre-existing ideologies and outrageous straw men of opposing views, we will never be able to build bridges and heal the challenges that plague humanity.</p>
<p>But there is hope. In The Terminator sequels, Arnold Schwarzenegger comes back as a good guy. “Who sent you?” John Connor asks. The Terminator answers, “You did. Thirty-five years from now, you reprogrammed me to be your protector.”</p>
<p>In the absence of time travel, the solution needs to incorporate the work and voices of devoted activists, organizations, scholars, and those who have experienced the harms of exploitative technology, which amplifies systemic oppression and inequality. We can’t rely on the people who created the problem to be the ones to solve it. And I won’t trust these social media companies until they change their business model to serve us, the public. Humans created this technology, and we can – and have a responsibility to – change it.</p>
<ul>
<li>
<p>Jeff Orlowski is the director of the documentary <a href="https://www.thesocialdilemma.com/" data-link-name="in body link">The Social Dilemma</a></p>
</li>
</ul>

</div></div></div>]]>
            </description>
            <link>https://respectinvestment.com/news/we-need-to-rethink-social-media-before-its-too-late-weve-accepted-a-faustian-bargain-jeff-orlowski/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24606093</guid>
            <pubDate>Sun, 27 Sep 2020 12:19:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is This Real Life?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24605777">thread link</a>) | @grimzucchini
<br/>
September 27, 2020 | https://julian.digital/2020/09/25/is-this-real-life/ | <a href="https://web.archive.org/web/*/https://julian.digital/2020/09/25/is-this-real-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
 		
<p>In his bestselling book <a href="https://www.goodreads.com/book/show/23692271-sapiens">Sapiens</a>, Yuval Harari argues that humans became the dominating species of planet earth because we are the only animal that can cooperate in large numbers. This, he claims, is due to humans’ ability to believe in purely imaginative things and concepts. A company like Google, for example, doesn’t <em>really</em> exist. Sure, there’s the Google.com website and physical Google offices with real Google employees – but the idea of Google as a company is just a fictional concept. It only exists because multiple people believe in it. The same is true for legal systems, nations, religion or money. Every large human cooperation system is based on a fictional idea that only lives in our collective minds.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/09/qanon.gif" media="min-width: 600px">What Harari doesn’t discuss in his book is the extreme other end of this cognitive ability: Conspiracy theories. I’ve been fascinated by <a href="https://reallifemag.com/this-is-not-a-game/">Jon Glover’s recent essay on QAnon</a>, in which he compares conspiracy theorizing to alternate-reality games. Participating in QAnon conspiracies, he says, feels like playing a real-life multiplayer game based on secret insider knowledge.</p>



<p>Social media has made conspiracy theorizing so addictive and immersive that the line between story and reality can become incredibly blurry. </p>



<p><i>“A lot of these groups are like cults […] They have beliefs that border on religiosity … And when you contradict them, it’s like telling them Jesus isn’t real.”</i></p>



<p>The religion analogy is interesting because it’s a perfect example of why fact checking as a countermeasure is useless. <a href="https://toolbox.google.com/factcheck/about">Google</a>, <a href="https://www.facebook.com/journalismproject/programs/third-party-fact-checking">Facebook</a> &amp; <a href="https://www.reuters.com/article/us-twitter-factcheck/with-fact-checks-twitter-takes-on-a-new-kind-of-task-idUSKBN2360U0?il=0">co</a> have all introduced fact checks and fake news labels to combat conspiracy theories. It’s naive to think that they will work.</p>



<p>Think about it: Science (which, you could argue, is also a form of fact checking) has been around for centuries trying to debunk most religious beliefs – and yet religion still plays a major role in Western society. If entire education systems teaching millions of people about science haven’t worked, why do you think adding a small fact check disclaimer below a YouTube video would?</p>



<p>In fact – as you would expect from a perfect alternate-reality game – fact checks (and how to circumvent them) have <a href="https://twitter.com/elisethoma5/status/1303630697567928320">actually long been part of the game</a>.</p>



<p>It’s worth pointing out that science is also just another belief system. We laugh about <a href="https://en.wikipedia.org/wiki/Modern_flat_Earth_societies">flat earthers</a>, but how many people can actually explain why the world is round in a scientifically correct way? Most of us don’t <em>know</em> science, we <em>believe</em> in science.</p>



<center><img src="https://julian.digital/wp-content/uploads/2020/09/reality.gif"></center>



<p>What should give us hope though is the fact that many people believe in *both* science and religion despite their contradictions. This means that multiple realities can co-exist even when they are at odds with each other.</p>



<p>We don’t live in just one reality – we switch between different realities (and play different characters within them). It’s a bit like <a href="https://en.wikipedia.org/wiki/Westworld_(TV_series)">Westworld</a>, where guests can explore different theme parks: Westworld, Shogunworld, Warworld, etc.</p>



<p>Similar to Westworld, it’s increasingly becoming more difficult to distinguish between what’s real and what isn’t. As Aaron Z. Lewis points out in his brilliant essay <a href="https://aaronzlewis.com/blog/2019/05/29/you-can-handle-the-post-truth/">You Can Handle the Post-Truth</a>, we have created a fragmented reality with hyper-realistic CGI influencers, bots, deepfakes, AI pretending to be humans and humans pretending to be AI. We don’t live in a single timeline with a single history, but in a variety of “<em>contradictory reality bubbles</em>“.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/09/narrativeviolations.png"></p><p>Bruno Maçães paints a similar picture in his excellent book <a href="https://www.goodreads.com/book/show/52914599-history-has-begun">History Has Begun</a>. America, he believes, is in the process of transforming into a new, post-liberal society, distinct from current Western civilization. It’s a society that has not only been heavily shaped by television but one where reality and fantasy overlap.</p>



<p>This transformation has been in the making for a while: Kennedy had the aura of a movie star and leveraged his image through the medium of television. Nixon created the first political soap opera with the Watergate scandal. And with Reagan an actual movie star moved into the White House.</p>



<p>Trump is the ultimate culmination of this trend. His entire presidency feels scripted. His tweets end with <a href="https://twitter.com/realdonaldtrump/status/1265819308699070464?lang=en">cliffhangers</a>. A House of Cards screenwriter would not have been able to come up with a better story.</p>



<p>Reagan and Arnold Schwarzenegger used the social capital and entertainment skills they acquired as actors to appear more likable and competent as politicians, but at least they tried to be politicians. Trump, on the other hand, uses politics as another stage for his acting performance.</p>



<p><em>“Americans see the world as an action movie”</em> Maçães writes. I think this became especially apparent during the current covid-19 crisis and the most recent wildfires in California. People in my social media timelines seemed only superficially worried. Instead, their posts contained an underlying sense of excitement about real life finally catching up with the science fiction aesthetics of Blade Runner and Akira.</p>



<p>Perhaps this is Hollywood’s greatest achievement: It gets us excited about our dystopian future. The world might be ending, but at least it’s an ending that’s entertaining to watch.</p>



<p><iframe width="100%" height="348" src="https://www.youtube.com/embed/x_m9TUP_t_Y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>



<p>If Hollywood created the fantasy worlds that reality is catching up with today, who is creating the fantasy worlds of tomorrow?</p>



<p>Maçães thinks the answer is Silicon Valley, which he describes as <em>“a fantasy land where engineering talent and capital come together to power the serious project of creating new worlds out of nothing”</em>. It’s one of the most idiosyncratic descriptions of how startups work that I have read. VCs are the new Hollywood studios; founders are the directors and actors.</p>



<p>A founder’s job is essentially to create the most compelling narrative of what their company will look like in 10 to 20 years time. <a href="https://alexdanco.com/2020/09/17/are-founders-allowed-to-lie/">It’s not lying, it’s telling pre-truths</a>. Being contrarian just means that you came up with a novel fantasy plot no one else had thought of yet.</p>



<p>Sometimes founders are able to re-create the fantasy narratives of their pitch decks. Sometimes you end up with Theranos.</p>



<p>And even when you do end up with Theranos, at least you get material for an exciting new Netflix series. Perhaps VCs should buy the movie rights to the startups they invest in as a hedge against their biggest portfolio failures?</p>



<p>The concept of the tech industry as a creator of fantasy worlds immediately reminded me of a conversation I had with my friend <a href="https://twitter.com/cutler_max">Max</a> recently. His theory is that it’s not the lack of tech talent or venture capital that explains why Europe hasn’t been able to create a tech ecosystem on par with the US. It’s the absence of religiosity that has kept Europe from creating its own Google or Facebook. The US is able to create larger companies because it’s able to believe in larger and more ambitious narratives.</p>



<p><img src="https://julian.digital/wp-content/uploads/2020/09/escher.png"></p><p>Silicon Valley is not just creating new fantasy worlds, it is building tools that allow others to create their own fantasy worlds. Enter social media.</p>



<p>If TV has taught us to think of ourselves as characters in the story of our lives, then social media has allowed us to actually write and edit the script and build fictional characters. Social media is essentially the democratization of virtual world building.</p>



<p>As I wrote in <a href="http://julian.digital/2020/03/28/signaling-as-a-service/">Signaling-as-a-Service</a>, Twitter, Snapchat and Facebook are just massive virtual status arenas that allow us to build social capital through signaling. Some of that social capital might be built on top of real stories and actual achievements, but most of it is not based on reality. Every time you are applying an Instagram filter, you are already changing reality.</p>



<p>It’s not just that we bend reality in our social media narratives, we also play different characters. As <a href="https://www.youtube.com/watch?v=e3Zs74IH0mc">Chris Poole already pointed out</a> years ago, we all have multiple (online) identities. There is not just one reflection of yourself – identity is prismatic. Twitter-Julian (armchair intellectual) is not the same as Instagram-Julian (hobby photographer) or Facebook-Julian (high-school drinking buddy). Google Circles and Facebook Lists always got this wrong: They let us change who we shared <em>with</em>, but not who we shared <em>as</em>.</p>



<p>This is why social networking is not a winner-take-all market. We need different channels for our different, contradicting online personas. </p>



<p>The problem is not that we live in multiple realities or that these realities are sometimes at odds with each other. What’s problematic is that we sometimes get so immersed in one virtual world, that we forget about all the other realities – which brings us back to the problem of online conspiracies.</p>



<p>In Christopher Nolan’s Inception, Dom Cobb uses <a href="https://www.youtube.com/watch?v=XQPy88-E2zo">a spinning tractricoid top that tells him if he is awake or still dreaming</a>. You can think of the mechanisms I describe in <a href="http://julian.digital/2020/08/06/proof-of-x/">Proof of X</a> as social media’s equivalent of the spinning top. As <a href="https://nymag.com/intelligencer/2017/10/you-can-rent-a-grounded-private-jet-to-take-instagram-photos.html">influencers rent grounded private jets</a> to pretend living a billionaire lifestyle, social networks introduce new proof-of-work hurdles to make sure our status games remain grounded in truth. Proof of reality.</p>



<p>It feels like some of the new virtual realities we have created need more than that. A kill switch that automatically brings us back to base reality.</p>



<p>So if you have reached this point of my essay, perhaps now would be a good time to close your browser window and enjoy real life. Or at least <a href="https://www.simulation-argument.com/simulation.html">the closest simulation you have thereof</a>. </p>



<center><img src="https://julian.digital/wp-content/uploads/2020/09/spinning.gif"></center>







<p><em>Thanks to <a href="https://twitter.com/aaronzlewis">Aaron Z. Lewis</a>,  <a href="https://twitter.com/einkoenig">Jan König</a> and <a href="https://twitter.com/cutler_max">Max Cutler</a> for reading drafts of this post. If you have thoughts on this essay, please leave them <a href="https://twitter.com/lehrjulian/status/1309492861474410496">here</a>.</em></p>
 	</div></div>]]>
            </description>
            <link>https://julian.digital/2020/09/25/is-this-real-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605777</guid>
            <pubDate>Sun, 27 Sep 2020 11:08:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Epoch Graphics Engine]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24605771">thread link</a>) | @mmphosis
<br/>
September 27, 2020 | https://6502disassembly.com/a2-epoch/engine.html | <a href="https://web.archive.org/web/*/https://6502disassembly.com/a2-epoch/engine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p><a href="https://6502disassembly.com/a2-epoch/">(back to project page)</a></p>



<p>The graphics may be a bit flickery, with a lot of color clashing when
things overlap, but the pixel fill rate is outstanding.

</p><p>The per-object overhead is fairly high, especially for objects that move.
You can observe this by slowing the movement rate of a player projectile
to a crawl (<code>515a:20 00</code>) and tapping the space bar rapidly.
Performance with two dozen projectiles in flight is rather poor; compare
it to the very good performance of the title demo (19-rectangle Epoch logo
and 8 stars), and space region 5 (1 ship and up to 32 stars).</p>

<p>Even so, the cost of moving and projecting objects is lower than it is
in games like Elite or Stellar 7, because Epoch takes a few shortcuts.</p>


<h2>General</h2>

<p>Epoch uses a left-handed three-dimensional coordinate system, with
the viewer at (0,0,0), +X to the right, +Y downward, and +Z away (into the
screen).  The viewer is always at (0,0,0), looking directly down the Z axis
with +Y upward, so object coordinates are always in eye (camera) space.
The view area is treated as square, using a perspective projection with a
45-degree FOV, so an object at (100,100,100) would be at the bottom-right
corner of the screen, as would an object at (200,200,200).</p>

<p>The "far" plane is at Z=+32767, so X/Y are limited to (-32767,+32767).
Anything that moves outside the view frustum is discarded.  If it moves past
the near plane at Z=0, player collision tests are applied.</p>


<p>All math, including object movement and perspective projection, is done
with simple arithmetic and about 4KB of lookup tables.</p>

<p>The points, lines, and rectangles that make up an object are always
drawn parallel to the viewer.</p>

<p>The game uses the full hi-res screen, which is 280 pixels wide.
That's more than will fit in a single byte, so screen X coordinates are
expressed as a signed value in the range [-139,139] (one byte holds the
magnitude, another byte holds the sign).  Y coordinates are simply [0,191].
Because the screen itself is not square, rendered element widths are
effectively multiplied by (280/192)=~1.46 (assuming ideal projection).</p>

<p>The <a href="https://6502disassembly.com/a2-epoch/objects.html">objects</a> page explains how objects are
defined.  The most important thing to know is that each object is defined
as a set of elements, which may be points, horizontal lines, vertical lines,
or filled rectangles in different colors.</p>


<h2>Movement</h2>

<p>There are three sources of movement:</p>
<ol>
  <li>Projectiles, enemy ships, and explosion chunks have nonzero
    movement vectors.  (Stars, bases, and time portals don't move
    on their own.)</li>
  <li>The player can move forward.</li>
  <li>The player can turn.</li>
</ol>

<p>If the coordinates were maintained in world space, player rotation
would be something applied at the very end, right before projection.
Because they're always in eye space, every object's position and motion
vector must be updated when the player rotates.</p>

<p>To see why this is, consider what happens when a player projectile
('#') is fired:</p>

<pre>  [player] ...# --&gt;
</pre>
<p>The projectile is moving directly away from the player, with a velocity
vector (0,0,N).  If the player instantly pitched up 45 degrees, the
projectile should be at the bottom of the screen, moving down and away:</p>
<pre>  [player] .
            .
             .
              #

                \
                 v
</pre>
<p>This clearly requires updating the object's position, using a rotation
equation that keeps it at a constant distance.  We also need to update the
movement vector, because if we don't, the projectile will move away as if
it were fired from a position below the player, rather than being fired
by the player:</p>

<pre>  [player] .
            .
             .
              # --&gt;
</pre>

<p>The effects of player rotation on movement are absent or minimal for most
things, because the object is either motionless or moving relatively slowly.
The main exception is player projectiles, which disappear quickly enough
that small errors will go unnoticed.</p>

<p>To see this in the game, reduce the player projectile velocity, fire a
shot, then pitch the camera so the projectile is at the edge of the screen
and check the new vector.  In one test, the vector changed from
xyz=[$0000,0000,0090] to [$0000,0064,0072], which isn't perfect
(speed of 151 vs. 144) but is pretty close, and the projectile doesn't
appear to rise or fall as it recedes into the distance.</p>

<p>One potential area of difficulty is that the game is always dealing with
movement deltas.  When pitching upward in the earlier experiment, the game
updated the vector each frame based on the joystick offset in that frame.
This is different from a conventional world-space approach, in which the
rotations are based on absolute position and orientation.  The reason deltas
can be problematic is that, if the math is imprecise, small errors can
add up over time.</p>


<h4>Double-Plane Quirk</h4>

<p>The 100-point alien ship is defined as two planes, one behind
the other.  The rear plane is defined last, which means it's drawn
on top of the front plane, which causes some erasure artifacts.
But there's a far stranger quirk.</p>

<p>If you disable the ship's forward movement in its object definition
(<code>4aa2:00 00</code>), and apply the game tweaks mentioned on
the main page to create a region of space with one alien ship and
nothing else, you can fly right up to the ship and examine it.  As
you get close, the difference in Z-depth between the two planes
starts to expose the limitations of the coordinate accuracy.</p>

<p>Because shapes are defined without a common center point, the
planes will start to move independently.  If you get fairly close
and move the crosshairs around for a bit, you can see the pieces
start to separate:</p>

<a href="https://6502disassembly.com/a2-epoch/images/drift-before.gif"><img src="https://6502disassembly.com/a2-epoch/images/drift-before.gif" alt="drift-before" width="140" height="96"></a>
<a href="https://6502disassembly.com/a2-epoch/images/drift-after.gif"><img src="https://6502disassembly.com/a2-epoch/images/drift-after.gif" alt="drift-after" width="140" height="96"></a>

<p>If you get really close, the rear part (which you can identify by the
lack of a flashing dot in the middle) will actually start to wander off:</p>

<a href="https://6502disassembly.com/a2-epoch/images/drift-active.gif"><img src="https://6502disassembly.com/a2-epoch/images/drift-active.gif" alt="drift-active" width="140" height="96"></a>

<p>In other games that scale with distance, such as Elite or Stellar 7,
this doesn't happen because the position is determined by a point at the
center of the object.  Epoch applies position adjustment to the element
coordinates individually, which works fine so long as all points are at
the same Z depth.  In practice this effect isn't really noticeable when
playing the game because the enemy ship will fly past before it has time
for the two parts to drift noticeably.</p>

<h4>Movement Implementation</h4>

<p>There are two parts, object movement and element movement.</p>

<p>Epoch doesn't store a position for the object, so the object move
routine is only responsible for updating the object movement vectors.
For enemy ships this is done periodically, to give the ships a little
more life than a homing drone (which they mostly feel like anyway).
For everything else, this is only done when the joystick causes the
view angles to change.  This change must be applied to the object's
movement vector, for the reasons discussed earlier.</p>

<p>The element movement code updates each element's position (defined
as left/top and possibly right and/or bottom) with the object's
motion vector, adds the player's forward motion, and applies the
joystick angles to the positions.  The latter isn't quite right, for a
couple of reasons:</p>
<ol>
  <li>Changes to the joystick position don't change the Z coordinates.
    So rotating something from the center to the side makes it farther away.
    However, the projection scaling is based purely on Z distance, so
    things don't actually get smaller as they move away from the center
    of the screen.</li>
  <li>All elements remain parallel to the screen.  Elements should
    appear to rotate so they face toward the viewer as the viewer rotates,
    not slide sideways.  This doesn't feel off because it's just Epoch's
    visual style.  (FWIW, Doom did the same thing with equipment and
    corpses.)</li>
</ol>

<p><i>(Details TBD; math tables at $1000, $ac00, and $b500 require
further examination.  Tables in C++ form
<a href="https://6502disassembly.com/a2-epoch/extra/math_tab.cpp">here</a>.)</i></p>


<h2>Drawing and Erasing</h2>

<p>The basic redraw loop looks like this:</p>
<ul>
  <li>For each object:
    <ul>
      <li>For each element in the object:
        <ul>
          <li>Erase element from previous position</li>
          <li>Draw element in new position</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Pretty straightforward, notable only in that we erase and redraw each
element before moving on to the next, which means that we'll create some
visual artifacts when an object is in motion if the new position of an
element overlaps the old position of a later element.  Doing it this way
is important to reduce flicker when not using page-flipping.  Erasing the
entire object before redrawing it would increase the amount of time that the
pixels are black, making it more likely that the screen refresh would
show a blank space.</p>

<p>Every element can have one or two of the six hi-res colors assigned.
If two colors are assigned, the renderer will alternate between them at
a rate specified within the element.  As an optimization, black elements
are erased, but not explicitly drawn.  This can cause some interesting
effects when elements overlap.</p>

<h4>Unrolled Loops</h4>

<p>The fastest way to draw a rectangle on the hi-res screen is to draw it
in vertical stripes.  Part of this is because, with 7 pixels per byte
(more or less), the bit patterns for odd columns and even columns are
different.  By drawing columns, we reduce the number of times we have to
switch color patterns.</p>

<p>But the most important reason is that we can use something like this:</p>
<pre>    sta   $2000,y
    sta   $2400,y
    sta   $2800,y
    sta   $2c00,y
    sta   $3000,y
    sta   $3400,y
    sta   $3800,y
    sta   $3c00,y
    ...
</pre>

<p>This is faster than doing the same operation in a loop, because we
don't have to update the loop counter or execute a branch instruction.
Call this with the value to store in the A-reg and the column in the Y-reg,
and we can write bytes to the screen about as fast as can be done on a 6502
(5 cycles per byte).</p>

<p>If we want to blend with existing pixels rather than overwrite them,
we can do something like this:</p>
<pre>    txa
    ora   $2000,y
    sta   $2000,y
    txa
    ora   $2400,y
    sta   $2400,y
    txa
    ora   $2800,y
    sta   $2800,y
    ...
</pre>
<p>This time we pass the value to blend in the X-reg.  For this we have
to spend 11 cycles per byte.</p>

<p>This is a great …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://6502disassembly.com/a2-epoch/engine.html">https://6502disassembly.com/a2-epoch/engine.html</a></em></p>]]>
            </description>
            <link>https://6502disassembly.com/a2-epoch/engine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605771</guid>
            <pubDate>Sun, 27 Sep 2020 11:06:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Terraspace All: Deploy Multiple Stacks or Terraform Modules at Once]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24605717">thread link</a>) | @kiyanwang
<br/>
September 27, 2020 | https://blog.boltops.com/2020/09/19/terraspace-all-deploy-multiple-stacks-at-once | <a href="https://web.archive.org/web/*/https://blog.boltops.com/2020/09/19/terraspace-all-deploy-multiple-stacks-at-once">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  
    <div><p><iframe src="https://www.youtube.com/embed/GjlWeYAGWIE" frameborder="0" allowfullscreen=""></iframe></p></div>
  
    <!--summary-->

<p>Today, we’ll cover a cool <a href="https://terraspace.cloud/">Terraspace</a> feature. It allows you to deploy all of your infrastructure in a single command.</p>



<p>Terraspace calculates the dependencies and deploys your code in the right order.</p>

<!--more-->

<h2 id="terraform-recommendations">Terraform Recommendations</h2>

<p>First, let’s talk about some Terraform recommendations. They recommend separating your code on a <a href="https://www.terraform.io/docs/cloud/guides/recommended-practices/part1.html#one-workspace-per-environment-per-terraform-configuration">per configuration and environment basis</a>. Here are examples straight from the docs.</p>

<ul>
  <li>billing-app-dev</li>
  <li>billing-app-prod</li>
  <li>networking-dev</li>
  <li>networking-prod</li>
</ul>

<p>Here’s a table to help explain these “scoped configurations” in different contexts:</p>

<table>
  <thead>
    <tr>
      <th>Product</th>
      <th>Scope</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Terraform Cloud</td>
      <td>A workspace</td>
    </tr>
    <tr>
      <td>Terraform OSS</td>
      <td>A terraform module with a separate statefile</td>
    </tr>
    <tr>
      <td>Terraspace</td>
      <td>A stack</td>
    </tr>
  </tbody>
</table>

<p>Believe the reasons for the strategy are because:</p>

<ol>
  <li>It avoids a monolithic structure and statefile that can take forever to run. See: <a href="https://github.com/hashicorp/terraform/issues/18981">Terraform takes a very long time to run</a>. It’s not fun to wait 20+ minutes for your <code>terraform apply</code>.</li>
  <li>It’s safer to update. Since the changes are more limited in scope, the blast radius is reduced.</li>
  <li>It helps decouple the code to logically reusable units.</li>
</ol>

<p>You deploy these “scoped configurations” separately.</p>

<h2 id="the-problem">The Problem</h2>

<p>One of the main issues with separating your code into separate stacks is that you have to deploy them independently. For example, you must manually deploy the VPC and then the instance afterward. You lose a significant advantage of what Terraform does: orchestration.</p>

<h2 id="enter-terraspace-all">Enter Terraspace All</h2>

<p>The <code>terraspace all</code> commands solves this problem by calculating the dependency graph and deploying the stacks in the correct order for you. Terraspace also parallelizes the batches. Here’s a dependency graph example.</p>

<p><img src="https://img.boltops.com/boltops/tools/terraspace/dependencies/deploy-all-a1.png" alt=""></p>

<p>Let’s deploy:</p>

<div><div><pre><code>$ terraspace all up
Will run:
   terraspace up b2 # batch 1
   terraspace up c1 # batch 1
   terraspace up c3 # batch 1
   terraspace up d1 # batch 1
   terraspace up b1 # batch 2
   terraspace up c2 # batch 2
   terraspace up b3 # batch 3
   terraspace up a1 # batch 4
Are you sure? (y/N)
</code></pre></div></div>

<p>Once you confirm, Terraspace deploys the batches in parallel. Essentially, Terraspace handles the orchestration.</p>

<div><div><pre><code>Are you sure? (y/N) y
Batch Run 1:
Running: terraspace up b2 Logs: log/up/b2.log
Running: terraspace up c1 Logs: log/up/c1.log
Running: terraspace up c3 Logs: log/up/c3.log
Running: terraspace up d1 Logs: log/up/d1.log
terraspace up b2:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up c1:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up c3:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up d1:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
Batch Run 2:
Running: terraspace up b1 Logs: log/up/b1.log
Running: terraspace up c2 Logs: log/up/c2.log
terraspace up b1:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
terraspace up c2:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
Batch Run 3:
Running: terraspace up b3 Logs: log/up/b3.log
terraspace up b3:  Apply complete! Resources: 1 added, 0 changed, 0 destroyed.
Batch Run 4:
Running: terraspace up a1 Logs: log/up/a1.log
terraspace up a1:  Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
Time took: 41s
$
</code></pre></div></div>

<p>Terraspace provides a reduced-noise summary of the runs. The full logs are also written for further inspection and debugging. The <a href="https://terraspace.cloud/reference/terraspace-log/">terraspace log</a> command is useful for viewing the logs.</p>

<h2 id="how-to-configure-dependencies">How to Configure Dependencies</h2>

<p>To configure dependencies, you merely wire stack outputs to inputs variables of another stack. Here is an example of an instance stack that depends on a vpc stack.</p>

<p>app/stacks/vpc/outputs.tf</p>

<div><div><pre><code>output "vpc_id" {
  description = "VPC ID"
  value       = aws_vpc.this.id
}
</code></pre></div></div>

<p>app/stacks/instance/variables.tf</p>

<div><div><pre><code>variable "vpc_id" {
  description = "VPC to launch instance in"
  type        = string
  default     = null
}
</code></pre></div></div>

<p>Wire them together with the <code>output</code> helper in the instance tfvars file.</p>

<p>app/stacks/instance/tfvars/base.tfvars</p>

<div><div><pre><code>vpc_id = &lt;%= output('vpc.vpc_id') %&gt;
</code></pre></div></div>

<p>Terraspace infers the dependency from this connection. It’s that simple.</p>

<p>Learn more: <a href="https://terraspace.cloud/docs/dependencies/deploy-multiple/">Deploy Multiple Stacks</a>.</p>

<h2 id="visualizing-with-graphs">Visualizing with Graphs</h2>

<p>You can create a visual dependency graph diagram with:</p>



<p>The earlier example dependency graph was generated with this command. Here’s the graph again:</p>

<p><img src="https://img.boltops.com/boltops/tools/terraspace/dependencies/deploy-all-a1.png" alt=""></p>

<h2 id="targeting-subgraphs-and-subtrees">Targeting Subgraphs and Subtrees</h2>

<p>You can also target subgraphs by specifying stack names. Example:</p>

<div><div><pre><code>terraspace all graph b1 b3
</code></pre></div></div>

<p>Produces:</p>

<p><img src="https://img.boltops.com/boltops/tools/terraspace/dependencies/deploy-all-a1-sub-b1-b3.png" alt=""></p>

<p>You can filter for stacks with any of all commands. Here’s an example with up:</p>

<div><div><pre><code>$ terraspace all up b1 b3
Will run:
   terraspace up c1 # batch 1
   terraspace up c3 # batch 1
   terraspace up d1 # batch 1
   terraspace up b1 # batch 2
   terraspace up c2 # batch 2
   terraspace up b3 # batch 3
Are you sure? (y/N)
</code></pre></div></div>

<p>This targets the b1 and b3 stacks and their dependencies.</p>

<h2 id="tearing-it-all-down">Tearing it All Down</h2>

<p>Finally, to tear down all the infrastructure.</p>

<div><div><pre><code>$ terraspace all down
Will run:
   terraspace down a1 # batch 1
   terraspace down b3 # batch 2
   terraspace down b1 # batch 3
   terraspace down c2 # batch 3
   terraspace down b2 # batch 4
   terraspace down c1 # batch 4
   terraspace down c3 # batch 4
   terraspace down d1 # batch 4
Are you sure? (y/N)
</code></pre></div></div>

<p>Once you’re ready, type <code>y</code> and enter.</p>

<div><div><pre><code>Are you sure? (y/N) y
Batch Run 1:
Running: terraspace down a1 Logs: log/down/a1.log
terraspace down a1:  Changes to Outputs:
terraspace down a1:  Destroy complete! Resources: 2 destroyed.
Batch Run 2:
Running: terraspace down b3 Logs: log/down/b3.log
terraspace down b3:  Changes to Outputs:
terraspace down b3:  Destroy complete! Resources: 1 destroyed.
Batch Run 3:
Running: terraspace down b1 Logs: log/down/b1.log
Running: terraspace down c2 Logs: log/down/c2.log
terraspace down b1:  Changes to Outputs:
terraspace down b1:  Destroy complete! Resources: 1 destroyed.
terraspace down c2:  Changes to Outputs:
terraspace down c2:  Destroy complete! Resources: 1 destroyed.
Batch Run 4:
Running: terraspace down b2 Logs: log/down/b2.log
Running: terraspace down c3 Logs: log/down/c3.log
Running: terraspace down d1 Logs: log/down/d1.log
Running: terraspace down c1 Logs: log/down/c1.log
terraspace down b2:  Changes to Outputs:
terraspace down b2:  Destroy complete! Resources: 1 destroyed.
terraspace down c1:  Changes to Outputs:
terraspace down c1:  Destroy complete! Resources: 1 destroyed.
terraspace down c3:  Changes to Outputs:
terraspace down c3:  Destroy complete! Resources: 1 destroyed.
terraspace down d1:  Changes to Outputs:
terraspace down d1:  Destroy complete! Resources: 1 destroyed.
Time took: 48s
$
</code></pre></div></div>

<p>The infrastructure is destroyed in reverse order.</p>

<h2 id="more-commands">More Commands</h2>

<p>There are more <a href="https://terraspace.cloud/reference/terraspace-all/">all commands</a>: <a href="https://terraspace.cloud/reference/terraspace-all-plan/">plan</a>, <a href="https://terraspace.cloud/reference/terraspace-all-up/">up</a>, <a href="https://terraspace.cloud/reference/terraspace-all-down/">down</a>, <a href="https://terraspace.cloud/reference/terraspace-all-show/">show</a>, <a href="https://terraspace.cloud/reference/terraspace-all-output/">output</a>, <a href="https://terraspace.cloud/reference/terraspace-all-graph/">graph</a>, <a href="https://terraspace.cloud/reference/terraspace-all-refresh/">refresh</a>, <a href="https://terraspace.cloud/reference/terraspace-all-providers/">providers</a>, etc. We’ve covered the essential ones to get started in this post. Learn more:</p>

<ul>
  <li><a href="https://terraspace.cloud/docs/intro/deploy-all/">Deploy All</a>: Intro docs.</li>
  <li><a href="https://terraspace.cloud/docs/dependencies/deploy-all/">Deploy Multiple</a>: Covers tfvars and some other options more closely.</li>
  <li><a href="https://terraspace.cloud/reference/terraspace-all/">Terraspace All</a>: CLI Reference Docs.</li>
  <li><a href="https://github.com/boltops-tools/terraspace-graph-demo">Terraform Graph Demo</a>: Example GitHub Repo to demonstrate deploying multiple stacks and their dependencies.</li>
</ul>

<h2 id="the-best-of-both-worlds">The Best of Both Worlds</h2>

<p>Terraspace helps you solve the issue of having to deploy individual stacks manually. Instead of having to run <code>terraspace up</code> individually, it allows you to deploy all stacks with a single command:</p>



<p>Additionally, you can target <a href="https://terraspace.cloud/docs/dependencies/subgraphs/">subgraphs</a> to deploy:</p>



<p>Lastly, you can always drop down and run the individual stack to debug. Example:</p>

<div><div><pre><code>terraspace up c1
terraspace up b1
</code></pre></div></div>

<p>Terraspace gives you the best of both worlds. To learn more about Terraspace check out <a href="https://terraspace.cloud/">terraspace.cloud</a>.</p>



<p>You may also be interested in:</p>

<ul>
  <li><a href="https://blog.boltops.com/2020/09/28/terraform-vs-terragrunt-vs-terraspace">Terraform vs Terragrunt vs Terraspace</a></li>
  <li><a href="https://blog.boltops.com/2020/08/22/introducing-terraspace-the-terraform-framework">Introducing Terraspace: The Terraform Framework</a></li>
</ul>


  </div><div>
    <p>Thanks for reading this far. If you found this article useful, I'd really appreciate it if you share this article so others can find it too! Thanks 😁 Also follow me on <a href="https://twitter.com/tongueroo">Twitter</a>.</p>

    <p><img src="https://blog.boltops.com/img/share/social-boltops-3.gif"></p>

    <p>Got questions? Check out <a href="https://www.boltops.com/">BoltOps</a>.</p>

    

 </div></div>]]>
            </description>
            <link>https://blog.boltops.com/2020/09/19/terraspace-all-deploy-multiple-stacks-at-once</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605717</guid>
            <pubDate>Sun, 27 Sep 2020 10:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hal Finney’s proposal for optimizing Bitcoin to be enabled in Bitcoin Core]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 162 (<a href="https://news.ycombinator.com/item?id=24605568">thread link</a>) | @syck
<br/>
September 27, 2020 | https://www.btctimes.com/news/hal-finneys-proposal-for-optimizing-bitcoin-to-be-enabled-in-bitcoin-core | <a href="https://web.archive.org/web/*/https://www.btctimes.com/news/hal-finneys-proposal-for-optimizing-bitcoin-to-be-enabled-in-bitcoin-core">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a itemprop="keywords" title="category page" href="https://www.btctimes.com/news/tag/bitcoin">Bitcoin</a><a itemprop="keywords" title="category page" href="https://www.btctimes.com/news/tag/technology">Technology</a></p><!----><h2 itemprop="headline"> Hal Finney’s Proposal for Optimizing Bitcoin to Be Enabled in Bitcoin Core </h2><!----><!----><!----><p dir="ltr">Today, a <a href="https://patents.google.com/patent/US7110538B2/en" target="_blank">patent involving the acceleration of cryptographic operations on elliptic curves</a> has expired. Invented by Gallant, Lambert, and Vanstone, this technique is commonly referred to as GLV Endomorphism and can now be activated in Bitcoin Core in order to improve the speed and efficiency of Bitcoin’s signature verification.</p><h2 dir="ltr">Hal Finney, GLV Endomorphism, and Patents</h2><p dir="ltr">The use of GLV Endomorphism was first explored by Hal Finney, one of Bitcoin’s earliest contributors and the <a href="https://bitcointalk.org/index.php?topic=155054.0" target="_blank">first person to receive a Bitcoin transaction from Satoshi Nakamoto</a>.</p><p dir="ltr">In his <a href="https://bitcointalk.org/index.php?topic=3238.msg45565#msg45565" target="_blank">bitcointalk.org post</a> on February 8th, 2011, Finney shared that he had been inspired to experiment with this technique after reading the <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.394.3037&amp;rep=rep1&amp;type=pdf" target="_blank">Guide to Elliptic Curve Cryptography, by Hankerson, Menezes and Vanstone</a> - the same Vanstone who submitted the patent. His initial tests were promising, revealing an estimated 25% increase in the optimization of signature verification.</p><p dir="ltr">Since then, the feature has been implemented in Bitcoin Core but has yet to be enabled due to the existing patent around the cryptography that was filed on December 23rd, 1999.&nbsp;</p><p dir="ltr">“Implementing it was one of the original motivations in developing the libsecp256k1 library, which has since replaced all cryptographic use of OpenSSL in Bitcoin Core,” shared Andrew Poelstra of <a href="https://blockstream.com/" target="_blank">Blockstream</a> with the BTC Times. “(But) it was disabled by default to avoid patent concerns and has never been enabled in Bitcoin Core.”</p><p dir="ltr">With the patent expiring, Bitcoin developers will now move quickly to enable GLV Endomorphism: the feature had actually been rigorously tested throughout the development of the libsecp256k1 library, making the optimization just as well-tested and mature as any other part of the library.</p><p dir="ltr">Once activated, nodes should expect to see a significant drop in ongoing resource usage as Bitcoin Core will now utilize the new signature verification method for freshly received transactions and blocks.</p><p dir="ltr">“Once you've caught up to the tip, nodes need to verify every new transaction and block that comes in. All of that will see a direct reduction in CPU usage,” <a href="https://twitter.com/pwuille" target="_blank">Pieter Wuille</a> of <a href="https://chaincode.com/" target="_blank">Chaincode Labs</a> told the BTC Times.&nbsp;</p><p dir="ltr"><a href="https://twitter.com/adam3us" target="_blank">Dr. Adam Back</a> of Blockstream commented, “this performance improvement was first drawn attention to for use in Bitcoin by Hal Finney. Even though he’s no longer with us, his contributions can still be felt.”</p><p dir="ltr">The use of GLV Endomorphism is expected to be activated in Bitcoin Core with the next Core release.</p><!----><div><div><p><img src="https://image.btctimes.com/fit-in/200x200/e299a519b673472199379a1e21e051db.png"></p><p>69</p><p><span>+ 1</span></p></div></div><div><div itemprop="about"><p><a href="https://www.btctimes.com/author/andrew-yang"><img itemprop="image" src="https://image.btctimes.com/fit-in/400x200/4c95a781454f486088a15c0976d544ba.jpg"></a></p></div><p> Andrew Yang is a researcher obsessed with Bitcoin and the Lightning Network. </p></div><!----></div></div>]]>
            </description>
            <link>https://www.btctimes.com/news/hal-finneys-proposal-for-optimizing-bitcoin-to-be-enabled-in-bitcoin-core</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605568</guid>
            <pubDate>Sun, 27 Sep 2020 10:14:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPG as SSH agent; notes for current best practices]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24605463">thread link</a>) | @dijit
<br/>
September 27, 2020 | http://blog.dijit.sh/gpg-ssh-notes-for-current-best-practices | <a href="https://web.archive.org/web/*/http://blog.dijit.sh/gpg-ssh-notes-for-current-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="bcRUCzpZk7CiGhPPwnJRU3">
	<time datetime="2020-08-16">August 16, 2020</time>
  
	<p>When I start at a new company, I always do a refresher on my key security.</p>

<p>One thing I always hate about SSH is that the encryption scheme is pretty basic actually, and once your ssh-agent is loaded- anything can just request a sign/authorize.</p>

<p>So, in tried and true “over engineering” fashion, I’ve taken to using my GPG key as my ssh key instead, and using gpg-agent instead of ssh-agent.</p>

<p>Another thing is to use elliptic curves instead of RSA, RSA is still secure, but ECC (ECDSA) is faster and theoretically more resistant, and everything from 2016 onwards supports it, so it’s fair to assume it is supported in my SSH programs of choice. :)</p>

<p>First, to create a ECDSA key we have to use expert mode with the <code>--full-gen-key</code>:</p>

<pre><code>jan.harasym@sm-mbp-jmh ~ % gpg2 --full-gen-key --expert
gpg (GnuPG/MacGPG2) 2.2.20; Copyright (C) 2020 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Please select what kind of key you want:
   (1) RSA and RSA (default)
   (2) DSA and Elgamal
   (3) DSA (sign only)
   (4) RSA (sign only)
   (7) DSA (set your own capabilities)
   (8) RSA (set your own capabilities)
   (9) ECC and ECC
  (10) ECC (sign only)
  (11) ECC (set your own capabilities)
  (13) Existing key
  (14) Existing key from card
</code></pre>

<p>We want to use ECC and ECC here, or “ECC (set your own capabilities)” and skip to the <code>addkey</code> section.</p>

<pre><code>Your selection? 9
</code></pre>

<p>Next we choose our ciphers:</p>

<pre><code>Please select which elliptic curve you want:
   (1) Curve 25519
   (3) NIST P-256
   (4) NIST P-384
   (5) NIST P-521
   (6) Brainpool P-256
   (7) Brainpool P-384
   (8) Brainpool P-512
   (9) secp256k1
</code></pre>

<p>NIST P-521 is the strongest, but NIST P-256 will be more compatible.</p>

<pre><code>Your selection? 5
</code></pre>

<p>And finally expiry and user-info.</p>

<pre><code>Please specify how long the key should be valid.
         0 = key does not expire
      &lt;n&gt;  = key expires in n days
      &lt;n&gt;w = key expires in n weeks
      &lt;n&gt;m = key expires in n months
      &lt;n&gt;y = key expires in n years
Key is valid for? (0) 0

Key does not expire at all
Is this correct? (y/N) y

GnuPG needs to construct a user ID to identify your key.

Real name: Jan Martin Harasym
Email address: jmh@xxx.com
Comment: Expert Online Infrastructure Engineer :: Live Operations
You selected this USER-ID:
    "Jan Martin Harasym (Expert Online Infrastructure Engineer :: Live Operations) &lt;jmh@xxx.com&gt;"

Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O
&lt;...&gt;

pub   nistp521 2020-08-16 [SC]
      6F1AA563C75BA41387FDDAD7DE3F72240989604A
uid                      Jan Martin Harasym (Expert Online Infrastructure Engineer :: Live Operations) &lt;jmh@xxx.com&gt;
sub   nistp521 2020-08-16 [E]

</code></pre>

<p>Now we need to add a key which can be used for authorization, for this we can create a subkey, remove the encryption capability and enable the authorization one.<br>
(Failing this, we can ask for setting our own capabilities during the initial key creation above)</p>

<p>Make sure it’s <code>ECC (set your own capabilities)</code> when selecting a key type.</p>

<pre><code>jan.harasym@sm-mbp-jmh ~ % gpg2 --expert --edit-key 6F1AA563C75BA41387FDDAD7DE3F72240989604A

Secret key is available.

gpg: checking the trustdb
gpg: marginals needed: 3  completes needed: 1  trust model: pgp
gpg: depth: 0  valid:   1  signed:   0  trust: 0-, 0q, 0n, 0m, 0f, 1u
sec  nistp521/DE3F72240989604A
     created: 2020-08-16  expires: never       usage: SC  
     trust: ultimate      validity: ultimate
ssb  nistp521/697423BAAFF6B653
     created: 2020-08-16  expires: never       usage: E   
[ultimate] (1). Jan Martin Harasym (Expert Online Infrastructure Engineer :: Live Operations) &lt;jmh@xxx.com&gt;

gpg&gt; addkey
Please select what kind of key you want:
   (3) DSA (sign only)
   (4) RSA (sign only)
   (5) Elgamal (encrypt only)
   (6) RSA (encrypt only)
   (7) DSA (set your own capabilities)
   (8) RSA (set your own capabilities)
  (10) ECC (sign only)
  (11) ECC (set your own capabilities)
  (12) ECC (encrypt only)
  (13) Existing key
  (14) Existing key from card
Your selection? 11

Possible actions for a ECDSA/EdDSA key: Sign Authenticate 
Current allowed actions: Sign 

   (S) Toggle the sign capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? S

Possible actions for a ECDSA/EdDSA key: Sign Authenticate 
Current allowed actions: 

   (S) Toggle the sign capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? A

Possible actions for a ECDSA/EdDSA key: Sign Authenticate 
Current allowed actions: Authenticate 

   (S) Toggle the sign capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? q
Please select which elliptic curve you want:
   (1) Curve 25519
   (3) NIST P-256
   (4) NIST P-384
   (5) NIST P-521
   (6) Brainpool P-256
   (7) Brainpool P-384
   (8) Brainpool P-512
   (9) secp256k1
Your selection? 5
Please specify how long the key should be valid.
         0 = key does not expire
      &lt;n&gt;  = key expires in n days
      &lt;n&gt;w = key expires in n weeks
      &lt;n&gt;m = key expires in n months
      &lt;n&gt;y = key expires in n years
Key is valid for? (0) 
Key does not expire at all
Is this correct? (y/N) y
Really create? (y/N) y
We need to generate a lot of random bytes. It is a good idea to perform
some other action (type on the keyboard, move the mouse, utilize the
disks) during the prime generation; this gives the random number
generator a better chance to gain enough entropy.

sec  nistp521/DE3F72240989604A
     created: 2020-08-16  expires: never       usage: SC  
     trust: ultimate      validity: ultimate
ssb  nistp521/697423BAAFF6B653
     created: 2020-08-16  expires: never       usage: E   
ssb  nistp521/5A4C21BF1FC787DB
     created: 2020-08-16  expires: never       usage: A   
[ultimate] (1). Jan Martin Harasym (Expert Online Infrastructure Engineer :: Live Operations) &lt;jmh@xxx.com&gt;

gpg&gt; Save changes? (y/N) y
</code></pre>

<p>Tell gpg-agent to enable ssh support:</p>

<pre><code>echo &gt; ~/.gnupg/gpg-agent &lt;&lt;EOF
default-cache-ttl 600
max-cache-ttl 7200
enable-ssh-support
write-env-file ~/.gpg-agent-info
EOF
</code></pre>

<p>And finally we need to tell the gpg-agent which key we want to load, however this is done by using the ‘keygrip’, not the ‘keyID’, you can get the keygrip with the following:</p>

<pre><code>jan.harasym@sm-mbp-jmh ~ % gpg -K --with-keygrip
/Users/jan.harasym/.gnupg/pubring.kbx
-------------------------------------
sec   nistp521 2020-08-16 [SC]
      6F1AA563C75BA41387FDDAD7DE3F72240989604A
      Keygrip = 1114A87C954A99D1BE2BBBCEFD2FEF4A8F81A17B
uid           [ultimate] Jan Martin Harasym (Expert Online Infrastructure Engineer :: Live Operations) &lt;jmh@xxx.com&gt;
uid           [ultimate] [jpeg image of size 8037]
ssb   nistp521 2020-08-16 [E]
      Keygrip = 8E504AC5A41C7C71905604E83B2F150B562ADFAE
ssb   nistp521 2020-08-16 [A]
      Keygrip = 1DB1E97B20FD54DF2BAB906EA64C30081DEA8C32
</code></pre>

<p>Look for the keygrip which is associated with the <code>[A]</code> capability in my case:</p>

<pre><code>ssb   nistp521 2020-08-16 [A]
      Keygrip = 1DB1E97B20FD54DF2BAB906EA64C30081DEA8C32
</code></pre>

<p>And enable the “A” key by adding it to the bottom of the sshcontrol file:</p>

<pre><code>echo '1DB1E97B20FD54DF2BAB906EA64C30081DEA8C32' &gt; ~/.gnupg/sshcontrol
</code></pre>

<hr>

<p><strong>EDIT</strong>:</p>

<p>AWS does not like strong keys, so for AWS I did the same as above but when I added a key for authorization I chose RSA:4096 instead.</p>

<pre><code>jan.harasym@sm-mbp-jmh / % gpg2 --expert --edit-key 6F1AA563C75BA41387FDDAD7DE3F72240989604A
gpg (GnuPG/MacGPG2) 2.2.20; Copyright (C) 2020 Free Software Foundation, Inc.
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.

Secret key is available.

sec  nistp521/DE3F72240989604A
     created: 2020-08-16  expires: never       usage: SC  
     trust: ultimate      validity: ultimate
ssb  nistp521/697423BAAFF6B653
     created: 2020-08-16  expires: never       usage: E   
ssb  nistp521/5A4C21BF1FC787DB
     created: 2020-08-16  expires: never       usage: A   
[ultimate] (1). Jan Martin Harasym (Expert Online Infrastructure Engineer :: Live Operations) &lt;jmh@xxx.com&gt;
[ultimate] (2)  [jpeg image of size 8037]

gpg&gt; addkey
Please select what kind of key you want:
   (3) DSA (sign only)
   (4) RSA (sign only)
   (5) Elgamal (encrypt only)
   (6) RSA (encrypt only)
   (7) DSA (set your own capabilities)
   (8) RSA (set your own capabilities)
  (10) ECC (sign only)
  (11) ECC (set your own capabilities)
  (12) ECC (encrypt only)
  (13) Existing key
  (14) Existing key from card
Your selection? 8

Possible actions for a RSA key: Sign Encrypt Authenticate 
Current allowed actions: Sign Encrypt 

   (S) Toggle the sign capability
   (E) Toggle the encrypt capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? A

Possible actions for a RSA key: Sign Encrypt Authenticate 
Current allowed actions: Sign Encrypt Authenticate 

   (S) Toggle the sign capability
   (E) Toggle the encrypt capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? S

Possible actions for a RSA key: Sign Encrypt Authenticate 
Current allowed actions: Encrypt Authenticate 

   (S) Toggle the sign capability
   (E) Toggle the encrypt capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? E

Possible actions for a RSA key: Sign Encrypt Authenticate 
Current allowed actions: Authenticate 

   (S) Toggle the sign capability
   (E) Toggle the encrypt capability
   (A) Toggle the authenticate capability
   (Q) Finished

Your selection? Q
RSA keys may be between 1024 and 4096 bits long.
What keysize do you want? (2048) 4096
Requested keysize is 4096 bits
Please specify how long the key should be valid.
         0 = key does not expire
      &lt;n&gt;  = key expires in n days
      &lt;n&gt;w = key expires in n weeks
      &lt;n&gt;m = key expires in n months
      &lt;n&gt;y = key expires in n years
Key is valid for? (0) 
Key does not expire at all
Is this correct? (y/N) y
Really create? (y/N) y
We need …</code></pre></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.dijit.sh/gpg-ssh-notes-for-current-best-practices">http://blog.dijit.sh/gpg-ssh-notes-for-current-best-practices</a></em></p>]]>
            </description>
            <link>http://blog.dijit.sh/gpg-ssh-notes-for-current-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605463</guid>
            <pubDate>Sun, 27 Sep 2020 09:47:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nearly every time I restart my Macs I get Kernel Panics, this is why]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24605451">thread link</a>) | @john_alan
<br/>
September 27, 2020 | https://jm33.me/digging-into-a-macos-kernel-panic.html | <a href="https://web.archive.org/web/*/https://jm33.me/digging-into-a-macos-kernel-panic.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
                    <nav>
                        <h3>Table of Contents</h3>
                        
                    </nav>
                    <hr>
                <p><img alt="macos restart" src="https://jm33.me/img/mac_panic/restart_problem.webp"></p>

<h2 id="background">background</h2>
<p>i bought a macbook pro (16", 2019) in May as my XPS died (motherboard fried maybe?). personally i dont like apple at all, but fuck it, i had never used a mac before, so why not? i really love to try new things</p>
<p>for my experience i am satisfied with my macbook, except for some stupid issues, one of which is what im going to dig into in this article</p>
<p><strong>shutdown/restart hang (caused by a kernel panic)</strong></p>
<p>i found many users have encounterd the (almost) same panic: <a href="https://forums.macrumors.com/threads/constant-kernel-panics-userspace-watchdog-timeout-no-successful-checkins-from-com-apple-windowserver.2222878/">https://forums.macrumors.com/threads/constant-kernel-panics-userspace-watchdog-timeout-no-successful-checkins-from-com-apple-windowserver.2222878/</a></p>
<p>Also on reddit: <a href="https://www.reddit.com/r/MacOS/comments/hwk0o5/how_to_stop_watchdog_timeout_kernel_panics/">it's the exactly same panic</a></p>
<p>if you look at the posts you will find they are actually having different problems except all the problems lead to (the same) watchdog timeout</p>
<p>my panic report looks like this:</p>
<div><pre><span></span>panic(cpu 2 caller 0xffffff7f881a1aae): watchdog timeout: no checkins from watchdogd in 302 seconds (11 totalcheckins since monitoring last enabled), shutdown in progress
Backtrace (CPU 2), Frame : Return Address
0xffffff83b0783c40 : 0xffffff800771f5cd
0xffffff83b0783c90 : 0xffffff8007858b05
0xffffff83b0783cd0 : 0xffffff800784a68e
0xffffff83b0783d20 : 0xffffff80076c5a40
0xffffff83b0783d40 : 0xffffff800771ec97
0xffffff83b0783e40 : 0xffffff800771f087
0xffffff83b0783e90 : 0xffffff8007ec2838
0xffffff83b0783f00 : 0xffffff7f881a1aae
0xffffff83b0783f10 : 0xffffff7f881a1486
0xffffff83b0783f50 : 0xffffff7f881b6d9c
0xffffff83b0783fa0 : 0xffffff80076c513e
      Kernel Extensions in backtrace:
         com.apple.driver.watchdog(1.0)[B435C72B-B311-3C67-8AA1-1D5CE0FAD429]@0xffffff7f881a0000-&gt;0xffffff7f881a8fff
         com.apple.driver.AppleSMC(3.1.9)[4589419D-7CCC-39A9-9E2F-F73FE42DD902]@0xffffff7f881a9000-&gt;0xffffff7f881c7fff
            dependency: com.apple.driver.watchdog(1)[B435C72B-B311-3C67-8AA1-1D5CE0FAD429]@0xffffff7f881a0000
            dependency: com.apple.iokit.IOACPIFamily(1.4)[0A7D7382-66FE-391B-9F93-97A996256C25]@0xffffff7f88109000
            dependency: com.apple.iokit.IOPCIFamily(2.9)[BE052F4D-9B80-3FCD-B36D-BACB7DEE0DF2]@0xffffff7f88112000
</pre></div>
<p>everytime the hang happens, it eventually gives me a backtrace like this</p>
<p>i called customer service, the friendly tech support suggested that i should reinstall the system (if i cant figure out how to reproduce the panic),
so i erased the partition table and restarted from scratch, then the hang happened again after a few shutdowns</p>
<p>i was really upset, but as i cant reproduce the panic, i cant even ask apple to fix it</p>
<p>then i decided to look into the panic myself</p>
<h2 id="the-backtrace">the backtrace</h2>
<p>the first glance at panic report tells me it might be something wrong with <a href="https://en.wikipedia.org/wiki/System_Management_Controller">SMC</a>, i followed apple's guide to reset SMC, without luck</p>
<p>apple diagnostics reports no issue</p>
<p>so it must be in the kernel right?</p>
<p>lets start reading the backtrace</p>
<p>by reading <a href="https://en.wikipedia.org/wiki/Call_stack">Call Stack</a> you will have a basic understanding of how kernel subroutines get executed</p>
<p>so how is it executed? just read from brace bottom to top</p>
<p>first thing first, the panic report only gives me related kernel extensions, to find out exactly what code is causing the panic, we have to get symbols from the kernel (extensions)</p>
<p>we dont need to download anything to debug such a problem, the kernel is installed on our machine, just copy it, along with all the related extensions:</p>
<div><pre><span></span>/System/Library/Kernels/kernel <span># kernel</span>
/System/Library/Kernels/Extensions <span># extensions</span>
</pre></div>
<p>follow <a href="https://www.repleo.nl/wordpress/symbolicate-os-x-kernel-panics-using-lldb/">https://www.repleo.nl/wordpress/symbolicate-os-x-kernel-panics-using-lldb/</a> to locate symbols</p>
<p>the kernel slide bytes, and AppleSMC text base address can be found in the panic report, like this:</p>
<div><pre><span></span>Kernel slide:     0x0000000007400000

com.apple.driver.AppleSMC(3.1.9)[4589419D-7CCC-39A9-9E2F-F73FE42DD902]@0xffffff7f881a9000-&gt;0xffffff7f881c7fff
</pre></div>
<p><img alt="lldb" src="https://jm33.me/img/mac_panic/lldb.webp"></p>
<p>from this screenshot we can see more clearly about what's going on, the backtrace tree is now symbolicated</p>
<h2 id="lets-reverse-some-code">lets reverse some code</h2>
<p>as far as i know AppleSMC kext is proprietary, the only way to know what it does is to reverse it</p>
<p>from lldb, we dont see anything worthy of reversing, its just a watchdog timeout call</p>
<p>anyways, AppleSMC module seems interesting, lets reverse it</p>
<p>after loading the AppleSMC binary, we have to rebase the binary so it matches the address at runtime: Edit, segment, rebase program</p>
<p>press G then paste the address <code>0xffffff7f881b6d9c</code>, we get:</p>
<p><img alt="inlockunlock" src="https://jm33.me/img/mac_panic/ida.webp">
<img alt="inlockunlock code" src="https://jm33.me/img/mac_panic/ida_pseudocode.webp"></p>
<div><pre><span></span><span>__int64</span> <span>__fastcall</span> <span>SMCWatchDogTimer</span><span>::</span><span>watchdogThread</span><span>(</span><span>SMCWatchDogTimer</span> <span>*</span><span>this</span><span>)</span>
<span>{</span>
  <span>char</span> <span>v1</span><span>;</span> <span>// al</span>
  <span>int</span> <span>v2</span><span>;</span> <span>// ecx</span>
  <span>thread_act_t</span> <span>v3</span><span>;</span> <span>// eax</span>
  <span>unsigned</span> <span>int</span> <span>v4</span><span>;</span> <span>// eax</span>
  <span>uint64_t</span> <span>v5</span><span>;</span> <span>// rbx</span>
  <span>SMCWatchDogTimer</span> <span>*</span><span>v6</span><span>;</span> <span>// rdi</span>
  <span>integer_t</span> <span>policy_info</span><span>;</span> <span>// [rsp+8h] [rbp-38h]</span>
  <span>int</span> <span>v9</span><span>;</span> <span>// [rsp+Ch] [rbp-34h]</span>
  <span>int</span> <span>v10</span><span>;</span> <span>// [rsp+10h] [rbp-30h]</span>
  <span>int</span> <span>v11</span><span>;</span> <span>// [rsp+14h] [rbp-2Ch]</span>
  <span>char</span> <span>v12</span><span>;</span> <span>// [rsp+18h] [rbp-28h]</span>
  <span>__int64</span> <span>v13</span><span>;</span> <span>// [rsp+20h] [rbp-20h]</span>

  <span>v1</span> <span>=</span> <span>IOWatchdogmacOS</span><span>::</span><span>check_coprocessor_system</span><span>(</span><span>this</span><span>,</span> <span>0L</span><span>L</span><span>);</span> <span>// maybe it's related to T2 chip?</span>
  <span>v2</span> <span>=</span> <span>30</span><span>;</span>
  <span>if</span> <span>(</span> <span>v1</span> <span>)</span>
    <span>v2</span> <span>=</span> <span>60</span><span>;</span>
  <span>*</span><span>((</span><span>_DWORD</span> <span>*</span><span>)</span><span>this</span> <span>+</span> <span>63</span><span>)</span> <span>=</span> <span>v2</span><span>;</span>
  <span>nanoseconds_to_absolutetime</span><span>(</span><span>1000000L</span><span>L</span><span>,</span> <span>&amp;</span><span>v12</span><span>);</span>
  <span>clock_interval_to_absolutetime_interval</span><span>(</span><span>10L</span><span>L</span><span>,</span> <span>1000000000L</span><span>L</span><span>,</span> <span>&amp;</span><span>v13</span><span>);</span>
  <span>policy_info</span> <span>=</span> <span>v13</span><span>;</span>
  <span>v10</span> <span>=</span> <span>v13</span><span>;</span>
  <span>v9</span> <span>=</span> <span>*</span><span>(</span><span>_DWORD</span> <span>*</span><span>)</span><span>&amp;</span><span>v12</span><span>;</span>
  <span>v11</span> <span>=</span> <span>1</span><span>;</span>
  <span>v3</span> <span>=</span> <span>current_thread</span><span>();</span>
  <span>v4</span> <span>=</span> <span>thread_policy_set</span><span>(</span><span>v3</span><span>,</span> <span>2u</span><span>,</span> <span>&amp;</span><span>policy_info</span><span>,</span> <span>4u</span><span>);</span>
  <span>if</span> <span>(</span> <span>!</span><span>v4</span> <span>)</span>
  <span>{</span>
    <span>while</span> <span>(</span> <span>1</span> <span>)</span>
    <span>{</span>
      <span>IOLockLock</span><span>(</span><span>*</span><span>((</span><span>_QWORD</span> <span>*</span><span>)</span><span>this</span> <span>+</span> <span>29</span><span>));</span>
      <span>v5</span> <span>=</span> <span>mach_absolute_time</span><span>();</span>
      <span>if</span> <span>(</span> <span>!*</span><span>((</span><span>_BYTE</span> <span>*</span><span>)</span><span>this</span> <span>+</span> <span>248</span><span>)</span> <span>)</span>
        <span>IOWatchdog</span><span>::</span><span>checkWatchdog</span><span>(</span><span>this</span><span>);</span>
      <span>IOLockUnlock</span><span>(</span><span>*</span><span>((</span><span>_QWORD</span> <span>*</span><span>)</span><span>this</span> <span>+</span> <span>29</span><span>));</span> <span>// `0xffffff7f881b6d9c`</span>
      <span>clock_delay_until</span><span>(</span><span>v13</span> <span>+</span> <span>v5</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>v6</span> <span>=</span> <span>(</span><span>SMCWatchDogTimer</span> <span>*</span><span>)</span><span>v4</span><span>;</span>
  <span>SMCWatchDogTimer</span><span>::</span><span>watchdogThread</span><span>(</span><span>v4</span><span>);</span>
  <span>return</span> <span>SMCWatchDogTimer</span><span>::</span><span>extendWatchdog</span><span>(</span><span>v6</span><span>);</span>
<span>}</span>
</pre></div>
<p>I don't think the <code>while (1)</code> loop is ever going to end. When <code>thread_policy_set</code> fails, it enters the loop and never breaks out.</p>
<p><code>v13</code> represents 1 sec I think. Basically this loop puts a mutex io lock, then feeds watchdog (when the timer pointer plus 248 is null or whatever), finally it sleeps for 1 sec, repeats the loop.</p>
<div><pre><span></span><span>if</span> <span>(</span><span>!*</span><span>((</span><span>_BYTE</span><span>*</span><span>)</span><span>this</span> <span>+</span> <span>248</span><span>))</span>
    <span>IOWatchdog</span><span>::</span><span>checkWatchdog</span><span>(</span><span>this</span><span>);</span>
</pre></div>
<p>When it stops feeding the watchdog, watchdog timeouts after about 3 min, hence the panic.</p>
<h2 id="whats-watchdog">whats watchdog</h2>
<p>from <code>man watchdogd</code></p>
<blockquote>
<p>watchdogd ensures that the system is healthy and able to make forward progress throughout the system lifecycle.
    If watchdogd or the Watchdog KEXT determine that the system is unhealthy they will attempt to take corrective action and ultimately may panic the system to get it back to a usable state.</p>
</blockquote>
<p>from <a href="https://en.wikipedia.org/wiki/Watchdog_timer">https://en.wikipedia.org/wiki/Watchdog_timer</a></p>
<blockquote>
<p>For example, in the case of the Linux operating system, a user-space watchdog daemon may simply kick the watchdog periodically without performing any tests. As long as the daemon runs normally, the system will be protected against serious system crashes such as a kernel panic. To detect less severe faults, the daemon[4] can be configured to perform tests that cover resource availability (e.g., sufficient memory and file handles, reasonable CPU time), evidence of expected process activity (e.g., system daemons running, specific files being present or updated), overheating, and network activity, and system-specific test scripts or programs may also be run.[5]</p>
<p>Upon discovery of a failed test, the Linux watchdog daemon may attempt to perform a software-initiated restart, which can be preferable to a hardware reset as the file systems will be safely unmounted and fault information will be logged. However it is essential to have the insurance of the hardware timer as a software restart can fail under a number of fault conditions. In effect, this is a dual-stage watchdog with the software restart comprising the first stage and the hardware reset the second stage.</p>
</blockquote>
<p>from my understanding, <code>SMCWatchDogTimer</code> stopped kicking watchdog somehow (at <code>IOLockUnlock()</code>), then watchdog realizes <code>AppleSMC</code> might be dead, it initiates a panic, reboot and throw the panic report to user</p>
            </div></div>]]>
            </description>
            <link>https://jm33.me/digging-into-a-macos-kernel-panic.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605451</guid>
            <pubDate>Sun, 27 Sep 2020 09:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SimulIDE 0.4.13]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24605357">thread link</a>) | @app4soft
<br/>
September 27, 2020 | https://www.simulide.com/2020/09/simulide0413-released.html | <a href="https://web.archive.org/web/*/https://www.simulide.com/2020/09/simulide0413-released.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-3720224599007737153">
<p>&nbsp;Hi guys SimulIDE 0.4.13 is available in the download section: https://www.simulide.com/p/downloads.html</p><h3>List of changes since 0.3.12:</h3><div><p><b>Changes:</b><br>&nbsp; RC1:<br>&nbsp;&nbsp;&nbsp; - Dissapear support for toggleSwitch.<br>&nbsp;&nbsp;&nbsp; - Full Adder carry pins at bottom.<br>&nbsp;&nbsp;&nbsp; - Led shape to original, but displaced to Cathode.<br>&nbsp;&nbsp;&nbsp; - Subcircuit default to Logic Symbol.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC2:<br>&nbsp;&nbsp;&nbsp; - 100 MHz max. circuit speed.<br>&nbsp;&nbsp;&nbsp; - Editor: Move "Control Circuit" from Editor to Debugger Properties.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR5:<br>&nbsp;&nbsp;&nbsp; - Delete key working again to remove Components.</p></div><div><p>&nbsp;&nbsp; &nbsp;<b>New Features:</b><br>&nbsp; RC1:<br>&nbsp;&nbsp;&nbsp; - Text Component opacity.<br>&nbsp;&nbsp;&nbsp; - Text Componext double-click to edit text.<br>&nbsp;&nbsp;&nbsp; - Allow positioning at 1/2 grid.<br>&nbsp;&nbsp;&nbsp; - Even smaller gates.<br>&nbsp;&nbsp;&nbsp; - New Buses: smaller footprint, connectable at both sides, nº Bit.<br>&nbsp;&nbsp;&nbsp; - 16 bit Encoder/Decoder<br>&nbsp;&nbsp;&nbsp; - Easier Auto-Connect pins.<br>&nbsp;&nbsp;&nbsp; - Drag and drop circuit files and open it.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC2:<br>&nbsp;&nbsp;&nbsp; - Labels in switches buttons, keyboard accesible.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC3:<br>&nbsp;&nbsp;&nbsp; - Multypole Push Switch.<br>&nbsp;&nbsp;&nbsp; - Circuit Zoom with key sequence: Ctrl+ Ctrl-<br>&nbsp;&nbsp;&nbsp; - AVR remote debugging.<br>&nbsp;&nbsp;&nbsp; - Serial Terminal: "Clear" and "CR" buttons.<br>&nbsp;&nbsp;&nbsp; - Make new Subcircuit pin naming compatible with old circuits.<br>&nbsp;&nbsp;&nbsp; - New Dialog: create and edit Package Pins<br>&nbsp;&nbsp;&nbsp; - Create Subcircuit and Package files in one shot.<br>&nbsp;&nbsp;&nbsp; - Inverted Pin Labels rendered with overline.<br>&nbsp;&nbsp;&nbsp; - WaveGen: Random waveform.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC4:<br>&nbsp;&nbsp;&nbsp; - Serial Monitor: Choose Usart to use.<br>&nbsp;&nbsp;&nbsp; - I2C module: Master Mode implemented.<br>&nbsp;&nbsp;&nbsp; - AVR Hardware I2C finally working!!<br>&nbsp;&nbsp;&nbsp; - Editor: Document reload.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC5:<br>&nbsp;&nbsp;&nbsp; - RAM/ROM load-save binary files.<br>&nbsp;&nbsp;&nbsp; - Buzzer option in Audio Out Component.<br>&nbsp;&nbsp;&nbsp; - Mcu: auto-load firmware at circuit power on (optional).</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC6:<br>&nbsp;&nbsp;&nbsp; - Move Settings file to user folder: accessible to Win OS.<br>&nbsp;&nbsp;&nbsp; - Add Compile date to About Dialog.<br>&nbsp;&nbsp;&nbsp; - Select Mcu Uart in Serial Port.<br>&nbsp;&nbsp;&nbsp; - Open several Serial Ports at once.<br>&nbsp;&nbsp;&nbsp; - PcLink: Auto-Connect Mcu to Serial Port<br>&nbsp;&nbsp;&nbsp; - Simulation Pause Button.<br>&nbsp;&nbsp;&nbsp; - SSD1306: Addressing completed, invert Display, Disp. Fully On.<br>&nbsp;&nbsp;&nbsp; - Relay Impedance and release current properties.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; Final:<br>&nbsp;&nbsp;&nbsp; - Open several Serial Monitors at once.<br>&nbsp;&nbsp;&nbsp; - Bipolar Stepper Motor.<br>&nbsp;&nbsp;&nbsp; - Probe: Ternary Logic indicator.<br>&nbsp;&nbsp;&nbsp; - Probe: Threshold property.<br>&nbsp;&nbsp;&nbsp; - SSD1306: Basic Hardware Horizontal Scrolling.<br>&nbsp;&nbsp;&nbsp; - Help files: Russian translation ( Sergey Roenko ).<br>&nbsp;&nbsp;&nbsp; - Help files: Spanish translation ( Kike_Gl ).<br>&nbsp;&nbsp;&nbsp; - Help files: Spanish help for 74 Series ( Kike_Gl ).<br>&nbsp;&nbsp;&nbsp; - PcLink Feature deleted.<br>&nbsp;&nbsp;&nbsp; - Serial Port: Auto Open property.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR1:<br>&nbsp;&nbsp;&nbsp; - Mcu Logic Symbol enabled.<br>&nbsp;&nbsp;&nbsp; - Some AVR Logic Symbols (Sergey Roenko)<br>&nbsp;&nbsp;&nbsp; - Mcu Help Files enabled.<br>&nbsp;&nbsp;&nbsp; - Some AVR Help files (Sergey Roenko)<br>&nbsp;&nbsp;&nbsp; - Gui French translation (Pascal Cotret)<br>&nbsp;&nbsp;&nbsp; - Change Language: Circuit-&gt;Properties.</p><p>&nbsp; &nbsp; SR3:<br>&nbsp;&nbsp;&nbsp; - Gui Brazilian Portuguese Translation ( Maico Smaniotto ).</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR4:<br>&nbsp;&nbsp;&nbsp; - Several AVR Logic Symbol Packages (Sergey Roenko).<br>&nbsp;&nbsp;&nbsp; - Several AVR help files (Sergey Roenko).</p></div><div><p>&nbsp;&nbsp; &nbsp;<b>Bug Fixes:</b><br>&nbsp; RC1:<br>&nbsp;&nbsp;&nbsp; - Crash hovering some external object over circuit canvas.<br>&nbsp;&nbsp;&nbsp; - Circuit not updating properly when animated( 0.3.12-SR1 ).<br>&nbsp;&nbsp;&nbsp; - Changes in Logic Devices properties while simulation running not updated.<br>&nbsp;&nbsp;&nbsp; - Load Circuit: avoid connect to already connected pins.<br>&nbsp;&nbsp;&nbsp; - Make 74HC and 74XX interchangeable.<br>&nbsp;&nbsp;&nbsp; - BJT animation not updated.<br>&nbsp;&nbsp;&nbsp; - BJT not working in vco example (0.3.12-RC2).<br>&nbsp;&nbsp;&nbsp; - Fix some memory leaks.<br>&nbsp;&nbsp;&nbsp; - Plotterwidget wrong scale in some cases.<br>&nbsp;&nbsp;&nbsp; - 74HC4022 Logic Symbol not working.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC2:<br>&nbsp;&nbsp;&nbsp; - Pic asm Compiler: gpasm does not find includes in project folder.<br>&nbsp;&nbsp;&nbsp; - Time widget scrollBars shown in some systems.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC3:<br>&nbsp;&nbsp;&nbsp; - Executable detected as shared lib in some builds.<br>&nbsp;&nbsp;&nbsp; - Push Switch broken (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - Keypad broken (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - debugger broken (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - AVR timer mode 14: Fast PWM, Top=ICR1, doesn't update in OCRX changes.<br>&nbsp;&nbsp;&nbsp; - Capacitor and Inductor not ok at simulation &gt; 1MHz (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - Send Text in Serial monitor limited to 50 characters.<br>&nbsp;&nbsp;&nbsp; - ATtinyX4 wrong Pin assignation in Timer0,1.<br>&nbsp;&nbsp;&nbsp; - ATtinyX4 wrong ADC definition.<br>&nbsp;&nbsp;&nbsp; - Package not initialized if Logic Symbol file not found.<br>&nbsp;&nbsp;&nbsp; - Package should save file relative path, not absolute.<br>&nbsp;&nbsp;&nbsp; - Create Subcircuit taking Component Circuit Id instead of unique Id.<br>&nbsp;&nbsp;&nbsp; - Avoid dash "-" in Subcircuits Pin Ids.<br>&nbsp;&nbsp;&nbsp; - Avoid save Backup in read only filesystems.<br>&nbsp;&nbsp;&nbsp; - SR04 not OK at simulation &gt; 1MHz (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - Clock and WaveGen not OK at simulation &gt; 1MHz (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - Servo Motor not OK at simulation &gt; 1MHz (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - Subcircuits fixed (thanks to Sergey Roenko):<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 74HC42, 74HC74, 74HC75, 74HC151, 74HC155, 74HC192, 74HC93<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 74HC393, 74HC592, 74HC4017, 74HC4026, 74HC4033</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC4:<br>&nbsp;&nbsp;&nbsp; - I2C module: wrong output impedance when transmiting.<br>&nbsp;&nbsp;&nbsp; - Editor: closing unsaved doc + cancel not working.<br>&nbsp;&nbsp;&nbsp; - Editor: close unsaved doc whith no focus, editor takes the focused one.<br>&nbsp;&nbsp;&nbsp; - PIC with OSCCAL Reg. not working if call 0x3FF is made.<br>&nbsp;&nbsp;&nbsp; - Crash: Debug session + Close doc. + RamTable-&gt;LoadVAriables.<br>&nbsp;&nbsp;&nbsp; - Debugger: some operations taking too long in some cases.<br>&nbsp;&nbsp;&nbsp; - Serial Monitor: some characters missing randomly.<br>&nbsp;&nbsp;&nbsp; - AVR SPI: MOSI pin should be high when idle.<br>&nbsp;&nbsp;&nbsp; - Wrong extension Creating subcircuits in some cases.<br>&nbsp;&nbsp;&nbsp; - Ground not working in Subcircuits.<br>&nbsp;&nbsp;&nbsp; - Crash creating Subcircuit with 2 Package Pins connected together.<br>&nbsp;&nbsp;&nbsp; - Subcircuits fixed (Sergey Roenko strikes again)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 74HC73, 74HC76, 74HC107, 74HC109, 74HC112,74HC113, 74HC173<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 74HC175, 74HC259, 74HC279, 74HC373, 74HC374, 74HC375, 74HC377</p><p>&nbsp;&nbsp; &nbsp;&nbsp; RC5:<br>&nbsp;&nbsp;&nbsp; - Crash closing file with debugger when no mcu ( 0.4.13-RC4 ).<br>&nbsp;&nbsp;&nbsp; - Program hangs removing components in some cases.<br>&nbsp;&nbsp;&nbsp; - Debugger: Simulation keeps running after Stop when not driving Circuit( 0.4.13-RC4 ).<br>&nbsp;&nbsp;&nbsp; - PIC: if PIC goes to sleep fail to exit sleep afther reset.<br>&nbsp;&nbsp;&nbsp; - Crash setting MCU to logic Symbol (No LS available for MCU yet).<br>&nbsp;&nbsp;&nbsp; - Subcircuit: place inversion sign only after the symbol «!» <br>&nbsp;&nbsp;&nbsp; - Crash on some actions while creating connector.<br>&nbsp;&nbsp;&nbsp; - Audio Out wrong at simulation speed &gt; 1e6 (0.4.13-RC2).<br>&nbsp;&nbsp;&nbsp; - Audio Out latency too high.<br>&nbsp;&nbsp;&nbsp; - LatchD randomly not properly initialized.<br>&nbsp;&nbsp;&nbsp; - Drop simu file to canvas should not save state.</p><p>&nbsp; RC6:<br>&nbsp;&nbsp;&nbsp; - Editor: Sintax highlight error parsing some rules.<br>&nbsp;&nbsp;&nbsp; - MCU: Auto-Load not working in Arduino Boards.<br>&nbsp;&nbsp;&nbsp; - Crash: Mcu in circuit + Run + delete Mcu + Run;<br>&nbsp;&nbsp;&nbsp; - Oscope not updating when signal dissapears.<br>&nbsp;&nbsp;&nbsp; - Relays not working randomly.<br>&nbsp;&nbsp;&nbsp; - Fixed 74HC194_LS.package (Sergey Roenko)</p><p>&nbsp;&nbsp; &nbsp;&nbsp; Final:<br>&nbsp;&nbsp;&nbsp; - Stepper: bounding box overlaping pins.<br>&nbsp;&nbsp;&nbsp; - Stepper not updating after change steps number.<br>&nbsp;&nbsp;&nbsp; - Arduino 1.8.10 issue solved.<br>&nbsp;&nbsp;&nbsp; - AppImage tries to backup in Readonly FS.<br>&nbsp;&nbsp;&nbsp; - Some Help Files not Found.<br>&nbsp;&nbsp;&nbsp; - Help files for each subcircuit not possible.<br>&nbsp;&nbsp;&nbsp; - Some wrong error strings higlighted in Arduino Compile.<br>&nbsp;&nbsp;&nbsp; - Memory: Error saving data in read only FS.<br>&nbsp;&nbsp;&nbsp; - Ram/Rom: Error saving and loading binary files.<br>&nbsp;&nbsp;&nbsp; - Text Encoding errors.<br>&nbsp;&nbsp;&nbsp; - Missing file extension filters in Ram/Rom.<br>&nbsp;&nbsp;&nbsp; - Missing file extension filters in Editor-&gt;SaveAs.<br>&nbsp;&nbsp;&nbsp; - Bad Led visualisation when cpu can not keep speed.<br>&nbsp;&nbsp;&nbsp; - Atmega 1280,1281, 2560, wrong package file.<br>&nbsp;&nbsp;&nbsp; - Crash if mcu can't be created + new circuit.<br>&nbsp;&nbsp;&nbsp; - Pic18F4420 missing data file.<br>&nbsp;&nbsp;&nbsp; - Servo: Redraw probrems.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR1:<br>&nbsp;&nbsp;&nbsp; - Mosfet animation not updating after Power-Off.<br>&nbsp;&nbsp;&nbsp; - Editor: SaveAs should take current file instead of last file.<br>&nbsp;&nbsp;&nbsp; - Editor: SaveAs+Modify+Compile takes old fileName.<br>&nbsp;&nbsp;&nbsp; - Crash Setting values &lt; 1 pico <br>&nbsp;&nbsp;&nbsp; - Passive Components: should not accept value = 0.<br>&nbsp;&nbsp;&nbsp; - Atmega32u4: Pwm not working.<br>&nbsp;&nbsp;&nbsp; - Atmega32u4: Duplicated Pin D4. (Sergey Roenko)<br>&nbsp;&nbsp;&nbsp; - Atmega64: Wrong Pin20, should be reset. (Sergey Roenko)<br>&nbsp;&nbsp;&nbsp; - Mcu eeprom: error loading data files.<br>&nbsp;&nbsp;&nbsp; - Pic mcu: error reading opencollector pins as input.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR2:<br>&nbsp;&nbsp;&nbsp; - Atmega32u4: Fast PWM on pin OC1C doesn't work for timer 1.<br>&nbsp;&nbsp;&nbsp; - Audio Output: cracking sounds.<br>&nbsp;&nbsp;&nbsp; - Volt. Regulator not working in some cases.<br>&nbsp;&nbsp;&nbsp; - PIC16F505 wrong package.<br>&nbsp;&nbsp;&nbsp; - Counter not working in Subcircuits.<br>&nbsp;&nbsp;&nbsp; - Crash deleting a subcircuit that fails to load .subcircuit file.<br>&nbsp;&nbsp;&nbsp; - Gates sometimes fail to restart after power-off (inverter oscillator example).<br>&nbsp;&nbsp;&nbsp; - SubPackage-&gt;LoadPackage fails to set proper default path in some cases.<br>&nbsp;&nbsp;&nbsp; - Logic Devices: Input HighV &amp; LowV not working in Subcircuits.<br>&nbsp;&nbsp;&nbsp; - Windows can only reach 80% simulation speed.<br>&nbsp;&nbsp;&nbsp; - Windows cancel wire by right-click shows context menu.<br>&nbsp;&nbsp;&nbsp; - Drag &amp; drop files not workingin windows.<br>&nbsp;&nbsp;&nbsp; - Editor: some grammatical errors.<br>&nbsp;&nbsp;&nbsp; - Frequencimeter: Wrong value at Circuit speed &gt; 1 MHz.<br>&nbsp;&nbsp;&nbsp; - Plotter not showing small signals properly ( &lt; 0.1 V ).<br>&nbsp;&nbsp;&nbsp; - Mcu: Setting Pin direction can miss previous Pin state.<br>&nbsp;&nbsp;&nbsp; - Mcu: Pullups not working depending on Pin direction set order.<br>&nbsp;&nbsp;&nbsp; - BcdToDec not working in subcircuits.<br>&nbsp;&nbsp;&nbsp; - Editor: asm type not recognized after modify and save.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR3:<br>&nbsp;&nbsp;&nbsp; - Clock &amp; WaveGen: Wrong frequency after circuit speed change &gt; 1 MHz while running.<br>&nbsp;&nbsp;&nbsp; - New Circuit when Simulation is paused = Power button dissabled.<br>&nbsp;&nbsp;&nbsp; - Serial Monitor not properly deleted.<br>&nbsp;&nbsp;&nbsp; - Remove waveGen max frequency limit.<br>&nbsp;&nbsp;&nbsp; - AVR Adc not working for channels &gt; 8.<br>&nbsp;&nbsp;&nbsp; - Avr asm Copmiler: error in mega16 &amp; mega 32 .inc files.<br>&nbsp;&nbsp;&nbsp; - Arduino Uno should have a buffer lo drive builtin led.<br>&nbsp;&nbsp;&nbsp; - Locale variants not working (eg. pt_BR).<br>&nbsp;&nbsp;&nbsp; - AVR i2c not working properly.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR4:<br>&nbsp;&nbsp;&nbsp; - Drag&amp;Drop files not working as it should (item created at Drag enter).<br>&nbsp;&nbsp;&nbsp; - Crash: Arduino Uno led buffer not properly removed (0.4.13-SR3).<br>&nbsp;&nbsp;&nbsp; - LedMatrix not cleanly removed.<br>&nbsp;&nbsp;&nbsp; - Serial Monitor Windows always on top.<br>&nbsp;&nbsp;&nbsp; - Missing files: TC4560, TC4561 (Sergey Roenko).<br>&nbsp;&nbsp;&nbsp; - 74HC148 not working properly (Sergey Roenko).<br>&nbsp;&nbsp;&nbsp; - Fix Windows version number.</p><p>&nbsp;&nbsp; &nbsp;&nbsp; SR5:<br>&nbsp;&nbsp;&nbsp; - Text Component: Delete Key not working.<br>&nbsp;&nbsp;&nbsp; - PIC Comparator: Output Vref to Pin doesn't work.<br>&nbsp;&nbsp;&nbsp; - Image Component: Animated Gifs not working.<br>&nbsp;&nbsp;&nbsp; - RamTable: Load varset brokes RamTable (addr = 0).<br>&nbsp;&nbsp;&nbsp; - Pic Uart sends extra character after reset (0.4.13.SR2).<br>&nbsp;&nbsp;&nbsp; - Serial Monitor doesn't keep on top of main window …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.simulide.com/2020/09/simulide0413-released.html">https://www.simulide.com/2020/09/simulide0413-released.html</a></em></p>]]>
            </description>
            <link>https://www.simulide.com/2020/09/simulide0413-released.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605357</guid>
            <pubDate>Sun, 27 Sep 2020 09:24:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Something funny is about to happen to some prices]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24605191">thread link</a>) | @solresol
<br/>
September 27, 2020 | http://blog.ifost.org.au/2020/09/something-funny-is-about-to-happen-to.html | <a href="https://web.archive.org/web/*/http://blog.ifost.org.au/2020/09/something-funny-is-about-to-happen-to.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4681556334331762709" itemprop="description articleBody">
<p>Landfill is an interesting product. The price fluctuates far enough that it can fluctuate from positive to negative and back again. If someone is building a tunnel, you can probably get paid to <i>take</i> landfill. If someone is building an island, you can probably get paid for <i>supplying</i> landfill. There are projects that can only go ahead at certain times: the Hornsby quarry remediation project was only viable because the north connex was being built.</p><p>That's slightly obscure, and there's not much you can do with landfill other than, well, fill land. But we are about to hit a very unusual combination of circumstances which will create some head-scratching economics.</p><p>Solar panels are getting cheaper. The learning rate for solar energy is (probably) the steepest of any energy technology yet deployed. So we can be pretty much assured that within the next decade we'll have enough solar power to power anything we want (as long as it is day time). We'll overprovision our houses and factories (and offices if they still exist) with generation capacity so that in the morning or evening when the sun is hitting at an oblique angle, we still have enough for our needs.</p><p>That means that at peak times, we'll have <i>more</i> than enough solar energy. What do we do with that surplus energy?</p><p>Actually, it's slightly worse than that, because there are some (non-renewable) power plants that can't fully idle. A nuclear reactor can't fully turn off for a few minutes in the middle of the day. Neither can a coal power plant. So they will be running at a time when nobody has a need for power. That may be OK -- if you make a lot of money generating power overnight, you might be prepared to pay some small penalties during the day for overproduction if that's what it takes to keep the system running.</p><p>Which means that someone, somewhere is going to get paid to create a dummy electrical load. We've never (as far as I can tell) seen "grid stability" <i>payments</i> <i>for</i> <i>using</i>&nbsp;electricity before. But it's the inevitable conclusion of where we are the moment: discounted rates for consumers who can change their requirements to help with grid stability exist already; there's no reason that this wouldn't still be necessary when the price of electricity hits zero.</p><p>Therfore, there will be times of the day (in certain weather conditions) when some companies will get <i>paid</i> to use electricity.</p><p>The kinds of consumers that will get paid are likely to be doing something that is energy inefficient (obviously), and not particularly capital intensive (since their equipment will be idle a lot of the time), and making something that can be stored indefinitely (because you definitely can't do just-in-time manufacturing if you are waiting for times when the price for electricity goes negative). But quite a lot of products could be made to fit that.</p><p>A possible product that I think is likely to play out this way is water desalination. Desalinated water is very expensive because of the embedded energy cost: it's often described as "bottled electricity". Currently we tend to use reverse osmosis because it's more energy efficient; but if you don't have to worry about energy costs, you might choose instead to boil water and distil it: since the capital costs are cheaper.</p><p>Now things get even weirder. Let's say you are getting paid 0.5c per kWH (a not unreasonable price) that you use. You might find that you can sell the water for -0.01c per kL. Yes, you can make a profit: not just giving it away, but you could still be profitable while paying someone to consume it.</p><p>If this all plays out, we might have water and electricity (at times) having a negative price. These are common inputs to other processes, so it doesn't end there: there might be a business that requires water and electricity occasionally, but the input costs normally make the business unviable. They in turn might be able to make some money selling the end product at a negative price if their inputs have a negative price.</p><p>If this sounds all a bit unbelievable, remember that up until very recently, many economists thought that it was impossible to have negative interest rates... right up until the moment when they started happening. We already have examples of products that oscillate between positive and negative prices, it's just that they were never fundamental inputs to other processes. My prediction is that by 2030 we will have a small part of the economy ticking away profitably making negative price products.</p><p>(Post scriptum: now for the completely weird: how do negative price products interact with negative interest rates?)</p>

</div></div>]]>
            </description>
            <link>http://blog.ifost.org.au/2020/09/something-funny-is-about-to-happen-to.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605191</guid>
            <pubDate>Sun, 27 Sep 2020 08:46:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PilBox – Building Android Apps in PicoLisp (2019)]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24605014">thread link</a>) | @bwidlar
<br/>
September 27, 2020 | https://picolisp.com/wiki/?PilBox | <a href="https://web.archive.org/web/*/https://picolisp.com/wiki/?PilBox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><h2>PilBox - Building Android Apps in PicoLisp</h2>
<p><b>Build your Apps in PicoLisp without an Android SDK</b></p><p>
PilBox ("PicoLisp Box") is a generic Android App which allows to write Apps in
pure PicoLisp, without touching Java, and without the need of an Android SDK.</p><p>
You do not need to root your device. And - if you prefer - you do not need a
separate development machine (PC or laptop): All can be done in a terminal on
the device, and even in a Lisp REPL while the App is running.</p><p>
Note: <b>PilBox needs Android &gt;= 5.0!</b></p><p>
It comes with PicoLisp binaries for Arm64 pre-installed. If your device has an
Arm32 CPU, you can - after installing the PilBox App but before starting it -
download and install the emulator version <a href="https://software-lab.de/arm32.zip">https://software-lab.de/arm32.zip</a>.
If this was done by mistake, you can revert to Arm64 binaries with
<a href="https://software-lab.de/arm64.zip">https://software-lab.de/arm64.zip</a>.</p><h3>How does it work?</h3><p>
The PilBox App itself (called the "PilBox kernel") is written in Java, the
normal Android way. It displays a WebView GUI, and starts a PicoLisp <b>binary</b>
compiled for Arm64 CPUs. This binary may now run any PicoLisp program, by
setting up a local web server where the WebView component connects to, possibly
opening a database, and doing whatever is desired.</p><p>
The PilBox kernel provides an interface to the Android Java runtime environment.
To the PicoLisp code it looks like a remote database, where Java objects are
mapped to PicoLisp DB objects, and Java functions and methods are executed via
remote procedure calls.</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/457.d" alt="PilBox.png"></p><p>
If a ZIP file is passed to the PilBox kernel upon start-up, it is unpacked, and
may override or extend whatever is installed already. This is done typically by
clicking on a downloaded ZIP, or by "sharing" it from some other App.</p><p>
Then it looks for a file "App.l" in the App's working directory, <span>load</span>s it,
and listens at the port number found in a file "Port". Out of the box, "Port" is
8081, and "App.l" is a meta-App which provides a convenient runtime environment
for managing Apps installed via the ZIP mechanism.</p><h3>Getting started</h3><p>
You can download the PilBox App from Google Play store, or get it directly from
<a href="https://software-lab.de/pilBox.apk">https://software-lab.de/pilBox.apk</a>. In the latter case, you may need to
enable "Unknown Sources" in your settings.</p><p>
To try the examples in this article, download these files:
</p><ul>
   <li><a href="https://software-lab.de/hello.zip">https://software-lab.de/hello.zip</a></li>
   <li><a href="https://software-lab.de/calc.zip">https://software-lab.de/calc.zip</a></li>
   <li><a href="https://software-lab.de/demo.zip">https://software-lab.de/demo.zip</a></li>
   <li><a href="https://software-lab.de/crash.zip">https://software-lab.de/crash.zip</a></li>
   <li><a href="https://software-lab.de/radio.zip">https://software-lab.de/radio.zip</a></li>
   <li><a href="https://software-lab.de/browser.zip">https://software-lab.de/browser.zip</a></li>
</ul><p>
<span>pilBox.apk</span> contains the PilBox kernel App as an APK ("Android Package"), and
the ZIP files are small demo applications.</p><p>
Then go to Apps -&gt; PilBox -&gt; Permissions and enable "Location" and "Storage".</p><h3>The pre-installed generic App</h3><p>
Initially, when started without any ZIP file, the PilBox kernel shows an empty
white screen with a PicoLisp logo on the top-left and a settings icon on the
top-right (the screenshots were taken on a tablet, so on a phone the proportions
may differ):</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/426.d" alt="emptyPilBox.png"></p><h4>The REPL</h4><p>
If you tap on the PicoLisp logo on the left, it opens a REPL (Read-Eval-Print
Loop) - a kind of terminal window into the App:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/430.d" alt="repl1.png"></p><p>
The REPL gives you control over many aspects of the App. It has a large text
field for displaying results and editing text, a single-line text field at the
bottom for command input, and the three buttons "Eval", "Edit" and "Clear
Cache".</p><p>
The main purpose is to enter commands, and look at their results in the text
area. As the "Eval" button is the first on the page, it is implicitly activated
if you hit <span>Enter</span> when typing a command.</p><p>
As a special case, if a command starts with a dollar-sign:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/431.d" alt="repl2.png"></p><p>
it is taken as a Shell command, here <span>ls -l</span>, and shows the listing in the text
area:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/432.d" alt="repl3.png"></p><p>
Otherwise (not starting with a dollar-sign), the command line is evaluated as a
Lisp expression. For example, after typing <span>(pp 'gps)</span>, we get:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/433.d" alt="repl4.png"></p><p>
If you type a file or path name like <span>App.l</span> in the command line,</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/434.d" alt="repl5.png"></p><p>
and press the "Edit" button, the file is opened in the text area and may be
edited:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/435.d" alt="repl6.png"></p><p>
Press the "Done" button to close the file again.</p><p>
The "Clear Cache" button invalidates the <span>WebView</span> cache, and is useful after
changing an App's CSS file.</p><p>
Tapping on the PicoLisp logo takes you back to the start screen.</p><p>
Normally, you won't edit your App's sources in the REPL, but instead edit them
in a terminal program like <span>Termux</span> with <span>vim</span> or <span>emacs</span>, and pass them as a
ZIP file to PilBox as described below.</p><h4>Settings</h4><p>
If you tap on the settings icon on the right of the start screen, it opens a
default settings page. Initially it shows two tabs, one with all standard
PicoLisp localizations</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/436.d" alt="settings1.png"></p><p>
and one listing the installed PILs (PicoLisp Apps):</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/437.d" alt="settings2.png"></p><p>
Initially the list is empty.</p><p>
The REPL behavior and the default settings page are normally overridden by
installed Apps, and are available only on the start screen.</p><h3>Installing your own App(s)</h3><p>
The empty PilBox kernel is not very useful, except for perhaps exploring the App
environment in the REPL.</p><p>
To install your own App, prepare a ZIP file with a directory containing
</p><ul>
   <li>One or more <span>*.l</span> Lisp files, where one of them must be named <span>App.l</span></li>
   <li>Optionally a CSS file named <span>lib.css</span></li>
   <li>Optionally an icon in a file named <span>logo.png</span></li>
   <li>Optionally a directory called <span>loc/</span> with localizations</li>
</ul><p>
The file <span>App.l</span> is mandatory, and is <span>load</span>ed to start the App. If one of the
<span>*.l</span> files is named <span>settings.l</span>, then it overrides the behavior of the
settings icon while this App is active.</p><p>
The first Lisp expression in <span>App.l</span> is <span>read</span> in, and should be a string
giving the App's name.</p><p>
You pass your ZIP file to the PilBox kernel by "sharing" it from another App
(e.g. the "Downloads" App). As I use the <span>Termux</span> App for local development, I
usually generate the ZIP file directly on the device, pass it to the
<span>termux-share</span> utility, using the world-readable <span>storage</span> area:
</p><pre>   $ zip -rFS ~/storage/downloads/myApp.zip myApp/
   $ termux-share ~/storage/downloads/myApp.zip
</pre><p>

When the PilBox kernel starts, it scans all top-level directories for other
files named "App.l". Each of those directories is taken as a PIL App. If only a
single one is found, it is started immediately, otherwise a list of buttons with
the App names is displayed.</p><h3>Hello World</h3><p>
For a minimal example for a PIL App, look at
<a href="https://software-lab.de/hello.zip">https://software-lab.de/hello.zip</a>. It consists of a directory <span>hello/</span> with
a single file <span>App.l</span>. This file contains:
</p><pre>   "Hello World"

   (menu "Hello World!"
      (&lt;h1&gt; "center blue" "Hello World!") )
</pre><p>

The first line gives the App's name, and the <span>menu</span> expression displays a
header line in blue with "Hello World!".</p><p>
If you pass this ZIP to the PilBox kernel, it immediately shows this screen
(because it is the first and only App installed so far):</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/440.d" alt="helloApp.png"></p><p>
A tap on the PicoLisp icon has no effect now (we are no longer on the PilBox
kernel start screen), but the settings page is still the default one. If we open
the "PILs" tab, we see that there is a single package "PIL-hello" installed:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/441.d" alt="helloSettings.png"></p><h3>Calculator</h3><p>
Let's move on to something more interesting than the obligatory "Hello World".
The package </p><li><a href="https://software-lab.de/calc.zip">https://software-lab.de/calc.zip</a></li><p> contains a calculator App.</p><p>
After we pass it to the PilBox, the start screen now shows <i>two</i> Apps:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/443.d" alt="calcPilBox.png"></p><p>
The calculator can be started by hitting the topmost button:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/445.d" alt="calculator.png"></p><p>
Play with it around a little. It employs PicoLisp's big numbers, so it can only
handle integers (of unlimited size though).</p><p>
If we go to the "PILs" tab in the settings, we see that now there are two
packages,</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/447.d" alt="settings3.png"></p><p>
and clicking on the "PIL-calc" link lists the package's contents:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/450.d" alt="pil-calc.png"></p><p>
The back-arrow brings you back to the "PILs" tab.</p><p>
Enabling the checkboxes in the "PILs" tab allows for the removal of the selected
packages. It removes <i>all</i> files in the package, so it must be handled with
care!</p><p>
The PilBox kernel start screen can be reached by clicking on the PicoLisp icon.
There we can also get to the REPL again.</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/451.d" alt="repl7.png"></p><h3>The Demo App</h3><p>
Finally, there is <a href="https://software-lab.de/demo.zip">https://software-lab.de/demo.zip</a>, an extensive but rather
silly Demo App. It contains examples for conventional GUI components, as they
are needed in database applications,</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/452.d" alt="demoFields.png"></p><p>
but also or accessing the Android toolbox, like taking pictures or scanning
QR-Codes, reading GPS coordinates, and posting notifications:</p><p>
<img src="https://picolisp.com/wiki/db/wiki/blob/A/454.d" alt="demoNotify.png"></p><p>
Feel free to install it, play around, and study the code.</p><h3>Using the Android API</h3><p>
PilBox is only useful if it can communicate with the Android API on the device.
Therefore, it loads the Android library "lib/android.l" in the PicoLisp
distribution (which in turn is built upon the Java reflection API).</p><p>
The central function in "lib/android.l" is <span>java</span>. It maps Lisp function calls
to the Java virtual machine, supporting eight types of calls:
</p><pre>   (java "cls" 'T ['any ..]) -&gt; obj       New object
   (java 'obj 'msg ['any ..]) -&gt; any      Send message to object
   (java 'obj "fld" ["fld" ..]) -&gt; any    Value of object field
   (java "cls" 'msg ['any ..]) -&gt; any     Call method in class
   (java "cls" "fld" ["fld" ..]) -&gt; any   Value of class field
   (java T "cls" ["cls" ..]) -&gt; obj       Define interface
   (java 'obj) -&gt; [lst ..]                Reflect object
   (java "cls") -&gt; cls                    Get class
</pre><p>

Depending on the type of the first one or two arguments (transient symbol,
internal symbol, or <span>T</span>) it behaves differently.</p><p>
This is not trivial, and requires some understanding of the Java side. For
example, to aquire a <span>WakeLock</span>, Java code samples do
</p><pre>   PowerManager powerManager = (PowerManager)getSystemService(POWER_SERVICE);
   WakeLock wakeLock = powerManager.newWakeLock(PowerManager.PARTIAL_WAKE_LOCK, "MyWakelockTag");
   wakeLock.acquire();
</pre><p>

To implement the same in PicoLisp, we must first look up the constant values
<span>POWER_SERVICE</span> and <span>PARTIAL_WAKE_LOCK</span>. They are found in
<a href="https://developer.android.com/reference/android/content/Context.html#POWER_SERVICE">https://developer.android.com/reference/android/content/Context.html#POWER_SERVICE</a>
as "power" and in
<a href="https://developer.android.com/reference/android/os/PowerManager.html#PARTIAL_WAKE_LOCK">https://developer.android.com/reference/android/os/PowerManager.html#PARTIAL_WAKE_LOCK</a>
as 1. With that, the corresponding Lisp code is:
</p><pre>   (java
      (java (java CONTEXT 'getSystemService "power") 'newWakeLock 1 "MyWakelockTag")
      'acquire )
</pre><p>

The gobal constant <span>CONTEXT</span> is defined in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://picolisp.com/wiki/?PilBox">https://picolisp.com/wiki/?PilBox</a></em></p>]]>
            </description>
            <link>https://picolisp.com/wiki/?PilBox</link>
            <guid isPermaLink="false">hacker-news-small-sites-24605014</guid>
            <pubDate>Sun, 27 Sep 2020 07:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The State of the Modern American University]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24604878">thread link</a>) | @rustoo
<br/>
September 27, 2020 | https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88</link>
            <guid isPermaLink="false">hacker-news-small-sites-24604878</guid>
            <pubDate>Sun, 27 Sep 2020 07:19:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Obsession is a sprint, life is a marathon]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24604841">thread link</a>) | @grwthckrmstr
<br/>
September 27, 2020 | https://www.preetamnath.com/blog/life-sprint-marathon | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/life-sprint-marathon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I have a little quirk.</p><p>When I start working on something like a task, project, anything, I tend to get obsessed and completely immerse myself into it until the objective is met.</p><p>It could be as random as when I first discovered intermittent fasting and decided I should try it, I spent the next few days absorbing as much information out there in the form of blogs, podcasts, research papers until I felt like I knew enough about the subject.</p><p>If I start reading a book and I’m into it, I find it hard to put it down until I’ve read the entire thing and satisfied my curiosity. In a day.</p><p>The same thing happens when I watch a TV show that I start to get into. I have to finish all 7 seasons and find out the whole story (hence I stopped watching old TV shows that are more than 2 seasons). In a week if possible.</p><p>I started working on a new landing page for <a href="http://www.delight.chat/">DelightChat</a> (dropping next week), which I worked on obsessively until the page was ready.&nbsp;</p><p>I literally didn’t get up all day from my chair (okay I did get up, but you get the point) from 8am to 8pm one of the days. I couldn’t sleep that night because I kept thinking of variations to try.</p><h3>Marathon, not a sprint</h3><p>My obsession zone is a mix of <a href="https://www.preetamnath.com/blog/flow-state" target="_blank">flow state</a> and I-can’t-switch-my-brain-off-even-for-a-second state.</p><p>Over the years, I have discovered that while obsession is great and it’s totally how I get into something new that I’m excited about, my little quirk often pushes me towards burn out.&nbsp;</p><p>Completely plugged in throughout the day, no rest or break, incomplete sleep. The works.&nbsp;</p><p>I’m a fan of <a href="https://patwalls.com/hard-work" target="_blank">hard work</a>, but as I’ve grown older I’ve understood the importance of life being a marathon, not a sprint.</p><p>Younger me didn't understand the value of weekends. Older me knows that running at maximum speed is great and super useful to cover short distances quickly, but it’s not <a href="https://seths.blog/2017/09/optimized-or-maximized/" target="_blank">optimised</a> for crossing long distances.&nbsp;</p><p>For me, I know I have to follow the approach that takes me furthest. Because I’m in it for the <a href="https://www.preetamnath.com/blog/the-long-haul" target="_blank">long haul</a>.</p><figure id="w-node-fdb6b7e5c445-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f6ffa904dc9a65e7061687f_long%20haul%20sprint%20marathon%20yoda%20preetam%20nath.gif" loading="lazy" alt=""></p></figure><p>Just as rest days are important for an athlete to recover, it’s important for all humans in all every other profession as well.</p><p>Even though I want to work today (Sunday) and complete another small aspect of DelightChat’s big plans, I won’t.</p><p>I'm gonna take the rest of the day off (after finishing this post, ha).</p><p>Because I'm running a marathon. And today is my rest day.</p></div></div>]]>
            </description>
            <link>https://www.preetamnath.com/blog/life-sprint-marathon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24604841</guid>
            <pubDate>Sun, 27 Sep 2020 07:10:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parametric lamp design using circle packings]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24604746">thread link</a>) | @stuffmatic
<br/>
September 26, 2020 | https://stuffmatic.com/blog/parametric-lamp-design-using-circle-packings/ | <a href="https://web.archive.org/web/*/https://stuffmatic.com/blog/parametric-lamp-design-using-circle-packings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>
      
      <div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/cover_2.jpg" alt="">
    </p>
    
  
</div>
      
      <p>If you like circles, spheres and shapes that fit nicely together, you’ll probably like spherical circle packings. In this post, I’ll describe how I turned one into a lamp.</p>

<!--more-->

<p>A circle packing is an arrangement of circles that fit tightly together, so that no circle can be enlarged without causing overlaps. Circle packing is a nice mathematical rabbit hole<sup id="fnref:circle_packing" role="doc-noteref"><a href="#fn:circle_packing">1</a></sup>, but this post focuses on Steiner chains, which is the type of packing I used for building the lamp (more pictures of which can be found <a href="https://stuffmatic.com/projects/circle-lamp">here</a>).</p>

<h2 id="steiner-chains">Steiner chains</h2>

<p>A Steiner chain<sup id="fnref:steiner_chain" role="doc-noteref"><a href="#fn:steiner_chain">2</a></sup> is constructed by surrounding a circle with a ring of additional circles that are all also tangent to a larger circle. In other words, a Steiner chain consists of circles packed in a circle (a concept I’ve previously explored in <a href="https://stuffmatic.com/projects/copper-circles">this project</a>).</p>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/steiner.png" alt="A simple Steiner chain.">
    </p>
    
  
  <p>A simple Steiner chain with a center circle surrounded by a ring of 9 smaller circles, all tangent to the bounding circle (dashed).</p>
  
</div>

<p>The fact that a Steiner chain fits tightly in a circle can be used to construct nested packings by repeatedly replacing the center circle with a smaller Steiner chain. Here’s an animation illustrating the idea.</p>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/steiner.gif" alt="Nesting Steiner chains">
    </p>
    
  
  <p>Nesting Steiner chains.</p>
  
</div>

<p>The lamp is built from a total of 13 circles, forming a nested Steiner chain with two rings, each containing 6 circles.</p>

<h2 id="deforming-a-circle-packing">Deforming a circle packing</h2>

<p>It’s intuitively clear that a circle packing can’t be arbitrarily deformed without “ruining” it. For example, stretching a packing in one direction turns the circles into ellipses. Luckily, there is a class of circle preserving planar deformations, so called Möbius transformations<sup id="fnref:mobius_transformation" role="doc-noteref"><a href="#fn:mobius_transformation">3</a></sup>, that can be used to parametrically control the shape of a circle packing. This is really useful for parametric design purposes.</p>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/mobius.gif" alt="Möbius transformations applied to a circle packing.">
    </p>
    
  
  <p>Möbius transformations applied to a circle packing.</p>
  
</div>

<h2 id="going-spherical">Going spherical</h2>

<p>The Möbius transformations described in the previous section turn out to be the only options for transforming a circle packing in the plane. However, if we venture into three dimensional space, there is another option: <em>inverse stereographic projection</em><sup id="fnref:stereographic" role="doc-noteref"><a href="#fn:stereographic">4</a></sup>. Loosely speaking, this transformation can be used to wrap a circle packing around a sphere.</p>

<p>For this project, I put together a parametric design tool to explore interesting spherical circle packings. This tool generates packings in three steps:</p>

<ol>
  <li>Create a nested Steiner chain</li>
  <li>Apply a Möbius transformation</li>
  <li>Wrap the packing around a sphere using inverse stereographic projection</li>
</ol>

<p>Here’s an animation showing the tool in action.</p>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/spherical_packing.gif" alt="Parametric exploration of spherical circle packings">
    </p>
    
  
  <p>Parametric exploration of spherical circle packings. The red dot indicates the circle packing's center of mass.</p>
  
</div>

<h2 id="generating-the-blueprint">Generating the blueprint</h2>

<p>The previous sections outline a method for creating nice spherical circle packings. In order to create physical objects from these packings, I wrote some code for procedural generation of laser cutter blueprints. One cruical thing to keep in mind when making a pendant lamp is the center of mass. To ensure the lamp is hanging properly, the center of mass and the wire hole need to lie on the same vertical line. The center of mass calculation is simplified by the fact that it only has to deal with circles (the contribution from the joints is negligible).</p>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/parametric_blueprint.gif" alt="Circle packing blueprint">
    </p>
    
  
  <p>An example of how changes in circle packing parameters affect the blueprint. Note how the wire hole (contained in a green rectangle) moves as the packing's center of mass changes.</p>
  
</div>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/prototype.jpg" alt="A simple prototype">
    </p>
    
  
  <p>A simple prototype for testing the strength of the joints and verifying the center of mass calculation.</p>
  
</div>

<h2 id="building-the-lamp">Building the lamp</h2>

<p>Once I had generated a blueprint and manufactured the parts, assembling the lamp went pretty smoothly. All circles, joints and joint holes were numbered so I would not have to think too much during assembly.</p>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/parts.jpg" alt="The laser cut parts">
    </p>
    
  
  <p>The laser cut MDF parts. No two parts are interchangeable, so they are all numbered to ensure smooth assembly.</p>
  
</div>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/painting.jpg" alt="Spray painting the outward facing parts">
    </p>
    
  
  <p>Spray painting the outward facing parts.</p>
  
</div>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/assembly.jpg" alt="Assembling">
    </p>
    
  
  <p>Assembling.</p>
  
</div>

<div>
  
    <p><img src="https://stuffmatic.com/assets/posts/circle_packing_lamp/cover.jpg" alt="The final result">
    </p>
    
  
  <p>The final result seen from below.</p>
  
</div>

<p>Some more pictures of the lamp can be found <a href="https://stuffmatic.com/projects/circle-lamp">here</a>.</p>

<h2 id="links">Links</h2>



    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://stuffmatic.com/blog/parametric-lamp-design-using-circle-packings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24604746</guid>
            <pubDate>Sun, 27 Sep 2020 06:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Build AWS ECS external deployments graphically]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24604601">thread link</a>) | @c-py
<br/>
September 26, 2020 | https://craftydeploy.com/editor | <a href="https://web.archive.org/web/*/https://craftydeploy.com/editor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://craftydeploy.com/editor</link>
            <guid isPermaLink="false">hacker-news-small-sites-24604601</guid>
            <pubDate>Sun, 27 Sep 2020 06:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facts to know about Google on its 21st birthday]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24604564">thread link</a>) | @xxlcloudinc
<br/>
September 26, 2020 | https://codecoda.com/en/blog/entry/21-facts-you-need-to-know-about-google-on-its-21st-birthday | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/21-facts-you-need-to-know-about-google-on-its-21st-birthday">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>Google is the biggest internet company in the world today.&nbsp; And it seems that this giant, successful company is going to have a birthday. As a present, we came up with a few interesting facts in honor of the birthday <b>big boy</b> company.</p>
<h2>1. People do not seem to know Google’s exact birth date.</h2>
<p>Yes, it is true. People do not know the exact date of Google’s birthday. It has been reported that Google has been given six different dates for their official birthday. Eventually they decided they need a fixed date, so that people know when to celebrate. Google later determined that <b>September 27th</b> will be the day.</p>
<h2>2. Google may even happen to be 25 years old.</h2>
<p>There are some indications that the real birth date might come even earlier than ’98. Google could be in fact, over the age needed to purchase alcohol in the US, legally. Although Google already has encoded their official starting date with the cryptic “98 9 27” doodle, it all must have started even earlier. In 1995, in the dormitory of Standford, the two main Google guys initiated the miracle power behind the most popular search engine in the world. Some say that during the infant years of Google development, the two founding men were frequently in disagreement with each other. However, we have the search engine today as proof they eventually shook hands and decided to put aside their differences and get to work.</p>
<h2>3. Google has a T-rex dinosaur on-site as a special reminder.</h2>
<div><p>Indeed, there is a T-rex on-site at Google’s headquarters. The dyno structure features a bone from a real Tyrannosaurus. When an amateur paleontologist initially discovered the bone by accident, they thought it comes from a different type of dinosaur. Stan, the name of the bone construction, is a vivid reminder that adaptation is key to survival.</p><p>Apart from being a preferred gathering <a href="https://www.demilked.com/google-campus-dinosaur-stan-flamingos/" target="_blank">spot for flamingos meeting</a>, Stan is there to remind Google employees they need to give their best all the time. Or risk having their company become extinct, just like a dinosaur.</p></div>
<h2>4. A T-rex game likes to hide in Google Chrome.</h2>
<div><p>Google is fond of dinosaurs, we noticed. Apart from the giant structure at their HQ, they also made a digital dyno version. When you browse the net on Google Chrome, a warning will appear about Google not being able to connect.</p><p>When the dinosaur is visible, if you push the space bar on your keyboard, a game will begin where you are a running dinosaur jumping over obstacles. The game length is theoretically infinite and has been an arena for peculiar competition for the highest score.</p></div>
<h2>5. Many things are hiding in Google’s products.</h2>
<p>You can find many Google easter eggs by doing a simple search. These hidden gems become quite apparent once you begin to understand what they are.&nbsp; For example, searching with the word “askew” will return search results in a tilted view. You can also try “zerg rush,” “blink HTML” or the classic “Google in the 1998”.</p>
<h2>6. Google was not at all pleased that the name of the company became a generic search term.</h2>
<p>“Google” and “just Google it” are common words, but the company thought that could undermine all their efforts. There is, however, no way to stop such a trend. We have little control over how language use evolves. Marketing departments would say they want the brand name should circulate as much as possible. Still, Google has reached a level where the term becomes forever embedded in our culture. At this point, the process of “genericization” becomes unstoppable and out of control, even Google’s.</p>
<h2>7. Google devours more businesses than people genuinely think.</h2>
<p>Some estimate that Google purchases more than one company per week. Most of the companies tend to be small, but some can be rather large. Most of the acquired products get blended in with others that are already part of an applied marketing strategy.&nbsp; However, Android resides firmly within Google’s realm on its own accord and is very well known.<br>Google does not usually sell the companies that it buys. </p>
<h2>8. The “I’m Feeling Lucky” Google button cost more than tens of millions of dollars per year.</h2>
<p>This button is really fun. But for Google, it is an expensive add-on. The simple task of taking a person directly to the top result page without the advertising makes Google miss a lot of potential revenue. That lost income estimates put it at around $110 million. When addressed directly, Google officials responded that without the feeling lucky button Google will look like a corporate beast with an exclusive focus on money. The fact that the button remains on the main google page is a true testament that Google understands the search engine is for the real people out there.</p>
<h2>9. The first Google storage building blocks come from Lego.</h2>
<p>Google, one of the largest companies in the world today, has many demands, most of them understandably also pretty big. For example, all the countless public photos, videos and emails needs a place to stay, and there are building-size structures that come to the rescue. But back in 1996, things were different for the Google founders, when they had to find a solution for their first storage device need. The hard drives they found were too bulky, so they produced unique server boxes made out of Lego parts.</p>
<h2>10. Google proves to be very generous to the spouses of employees who die while working for the company.</h2>
<p>Losing a loved one on the job is always tough. Dying while working in a comfortable, air-conditioned office is not the same as, say, a coal mine accident. However, one thing is sure: death comes unexpectedly, and it is a hard stone to all sides involved. Google understands that and pays the husband or wife of the decreased fifty percent of their salary for the next ten years! Even the children of those unfortunate enough to perish on the job have benefits too – they are set with compensatory payments till they reach adulthood.</p>
<h2>11. One search on Google requires more computing power than it took to send astronauts of Apollo 11 to the moon. </h2>
<div><p>Isn’t that a funny statistic? Searching with Google is made so simple now. Most people don’t believe when they hear the actual computing and networking power behind every simple search querry.</p><p>Searching the internet today takes more resources than were necessary to put people on the moon. Even your smartphone has better capabilities than the equipment NASA had when they attempted the first moonwalk. </p></div>
<h2>12. One time Google experienced a crash for five minutes, and almost half of the whole internet went down too.</h2>
<div><p>What if you can’t use your computer for five minutes? No bid deal, right? You can take a walk and come back again. Five minutes for Google is too much.</p><p>It was on August 19, 2013, when the famed Google stopped operating for a total of five minutes. This short interruption sufficed for Google to take down around 40% of all internet traffic.</p><p>While it is true that many companies have risen to the occasion and provide search opportunities for people, Google still dominates the more substantial part of the internet. Google has grown to the point where it almost became a synonym for the internet itself. When Google has a problem, the chances are that so does most of the world wide web.</p></div>
<h2>13. Google employs goats.</h2>
<div><p>There is a lot of beautiful green space around Google offices. And that could require a lot of mowing for sure. So they come up with the ingenious idea to have some goats to take care of the grass for them.</p><p>According to Google employees, they love goats because for a score of reasons. Goats are not as noisy, don’t cause any pollution, and, most of all, are more cure and cuddly than lawnmowers.</p></div>
<h2>14. Google has lots of dogs on site.</h2>
<div><p>Speaking of goats, Google also loves all kinds of animals and lets people bring their pets to work. Having your best friend around you is a huge booster for morale and productivity.</p><p>Note that cats are not banned from Google. It’s just that cats don’t usually get along with dogs, so there are fewer of them on-site. But there are still quite a few.</p></div>
<h2>15. Google has given a dog the title of Top Dog.</h2>
<p>According to Google’s official history, the dog of the owner of Google, whose name is Yoshka, is the first and only dog to be given the name Top Dog back in 1999. A post appeared on Google by Yoshka, stating that all dogs are welcome to come to Google. Yoshka is not the only dog in the company, but it was the first. The dog owner was non-other than Urs Hölzle. He was the person responsible for reducing the power needed for Google data centers by half!</p>
<h2>16. Google centered their logo on the main search page in 2001.</h2>
<div><p>Google’s homepage is simple, a much-needed requirement when millions around the world visit it on a daily. Any changes to that page, even the tiniest ones, will be indeed significantly noticed.</p><p>In the early days of the search engine, the Google logo resided to the left side of the page. But in 2001, they moved it to the center and has been there ever since. This seemingly slight change is pretty significant. It changed how the main page is perceived forever.</p></div>
<h2>17. Google continues to make small changes.</h2>
<div><p>There have been some rather small adjustments to the Google logo, in time. Those changes include the layout of the letters of the word “Google.”</p><p>Small changes are the general approach, but Google also goes big. They came up with different ways to arrange the words, which included a new font too.</p></div>
<h2>18. Changes include the name.</h2>
<p>In recent years, the most significant and notable change occurred when the company changed its name from Google to Alphabet. That change was prompted by the fact the company was dominating most of the search, information, internet and other aspects of the business.</p>
<h2>19. Google Instant.</h2>
<p>Google Instant means that you will see results immediately as soon as you start typing if your connection allows it.&nbsp; Google can then collect ample information on you about your browsing patterns to get you where you want to go even faster. Google Instant changes the autocomplete options, and the suggested search results in an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/21-facts-you-need-to-know-about-google-on-its-21st-birthday">https://codecoda.com/en/blog/entry/21-facts-you-need-to-know-about-google-on-its-21st-birthday</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/21-facts-you-need-to-know-about-google-on-its-21st-birthday</link>
            <guid isPermaLink="false">hacker-news-small-sites-24604564</guid>
            <pubDate>Sun, 27 Sep 2020 06:02:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using SPF on HELO/EHLO hostnames is repurposing SPF to validate a different thi]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24604086">thread link</a>) | @todsacerdoti
<br/>
September 26, 2020 | https://utcc.utoronto.ca/~cks/space/blog/spam/SPFForHELOsII | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/spam/SPFForHELOsII">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Using SPF on HELO/EHLO hostnames is repurposing SPF to validate a different thing</h2>

	<p><small>September 26, 2020</small></p>
</div><div><p>Back in June I discovered that <a href="https://utcc.utoronto.ca/~cks/space/blog/spam/SPFForHELOs">in theory we should have SPF records
for EHLO hostnames too</a>. The conventional explanation
for this (apart from 'big email providers say so', the usual reason
to do anything in modern SMTP) comes from, for example, <a href="https://bridge.grumpy-troll.org/2020/07/small-mailserver-bcp/">this
writeup of small mailserver best current practices</a>,
and goes like this (I'm paraphrasing):</p>

<p>People use <a href="https://en.wikipedia.org/wiki/Sender_Policy_Framework">SPF</a>
to validate the envelope sender domain (the SMTP MAIL FROM). However,
when you send a bounce, it has a null sender and thus no sender
domain to use for SPF checks. So the sender domain is taken from
the EHLO hostname, for lack of a better place to get it from (since
there is no SMTP level 'the bounce claims to have been sent by X
domain' information to be had, although this is commonly in the
message headers).</p>

<p>This is of course kind of bogus. What is really happening here is that
receiving mail servers are attempting to validate that the EHLO/HELO
hostname itself is not forged and are using SPF for this purpose. This
is a complete repurposing of SPF, which we can see since 'Sender' is
right in the name 'Sender Policy Framework' and there's no 'sender' of
the bounce that is visible at the SMTP level (and no entirely standard
way that it's visible in the mail headers, either).</p>

<p>There are some lessons here for email related 'standards' and in general
any Internet standards, which I can summarize this way: if there's a
hole that people think needs filling, any nearby peg will get hammered
into it regardless of what the peg was originally designed for.</p>

<p>PS: This elaborates on <a href="https://twitter.com/thatcks/status/1307064512302940161">a recent tweet of mine</a> that was
sparked by adding SPF DNS records for our EHLO hostnames (and writing
the official explanation of the change for our records).</p>

<h3>Sidebar: This explanation and <a href="https://tools.ietf.org/html/rfc7208">RFC 7208</a></h3>

<p>RFC 7208 says two things in <a href="https://tools.ietf.org/html/rfc7208#section-2.3">section 2.3, <em>The "HELO" Identity</em></a>:</p>

<ul><li>it's RECOMMENDED that you check the HELO identity (but carefully)
all the time, and do so before checking MAIL FROM.</li>
<li>if the envelope sender is the null sender, the message is presumed
to come from 'postmaster@&lt;HELO name&gt;' and this is used as the
MAIL FROM to check (even if you already checked the HELO identity).</li>
</ul>

<p>I haven't gone through RFC 7208's section on doing SPF checks to see
if it treats HELO and MAIL FROM checks somewhat differently in its
algorithm, because frankly I'm not interested enough.</p>

<p>This means that RFC 7208 itself is a superset of the conventional
explanation I summarized above. In RFC 7208, you have SPF records
for your EHLO hostnames both because of bounces and because receivers
are recommended to check them all the time. This implies that all
of your mail sending machines should have SPF records, not just the
ones that can send bounces.</p>

<p>(Now that I've looked that up, I may need to update some of our
DNS records. Again.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/spam/SPFForHELOsII</link>
            <guid isPermaLink="false">hacker-news-small-sites-24604086</guid>
            <pubDate>Sun, 27 Sep 2020 03:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a command line tool to manipulate CSV files]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24603897">thread link</a>) | @kaunta
<br/>
September 26, 2020 | https://johnlekberg.com/blog/2020-09-26-cli-csv.html | <a href="https://web.archive.org/web/*/https://johnlekberg.com/blog/2020-09-26-cli-csv.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://johnlekberg.com/blog.html">Return to Blog
</a></p><p>By John Lekberg on September 26, 2020.
</p><hr>
<p>In this week's post, you will learn how to build a command line tool that
manipulates <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV files</a>.</p>

<blockquote>
<p><strong>csv-proc</strong></p>
</blockquote>
<pre><code>#!/usr/bin/env python3

from collections import OrderedDict
import csv
import logging
import sys

logging.basicConfig(format="%(levelname)s: %(message)s")


def MAIN():
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument(
        "file", help="CSV file. E.g. 'data.csv'."
    )
    parser.add_argument(
        "command",
        help="Python code to run on each row of the file.",
    )
    parser.add_argument(
        "--init",
        default="",
        metavar="CODE",
        help="Python code to run before processing begins.",
    )
    args = parser.parse_args()

    code_command = compile_or_exit(args.command)
    code_init = compile_or_exit(args.init)

    env_global = {}
    exec(code_init, env_global)

    with open(args.file, "rt") as file:
        dialect = guess_dialect(file)
        reader = csv.DictReader(file, dialect=dialect)

        results = []
        for row in reader:
            env_global["row"] = RowProxy(row)
            env_local = OrderedDict()
            exec(code_command, env_global, env_local)
            result = row.copy()
            result.update(
                (k, v)
                for k, v in env_local.items()
                if not k.startswith("_")
            )
            results.append(result)

    fieldnames = tuple(results[0].keys())
    writer = csv.DictWriter(
        sys.stdout, fieldnames=fieldnames, dialect=dialect
    )
    writer.writeheader()
    for row in results:
        writer.writerow(row)


def compile_or_exit(text):
    """Return a compiled statement or call sys.exit on failure."""
    try:
        return compile(text, "&lt;string&gt;", "exec")
    except SyntaxError as error:
        logging.error(f"Unable to parse {text!r}")
        sys.exit(1)


def guess_dialect(file):
    """Guess the CSV dialect of a file by examining a sample."""
    sample = file.read(2048)
    file.seek(0)
    dialect = csv.Sniffer().sniff(sample)
    return dialect


class RowProxy:
    """Read-only proxy to dict object.

    Allows element access like `d["x"]` and `d.x`.
    """

    def __init__(self, row):
        self._row = row

    def __getitem__(self, key):
        return self._row[key]

    def __getattr__(self, key):
        return self._row[key]


if __name__ == "__main__":
    MAIN()
</code></pre>
<blockquote>
<pre><code>$ csv-proc --help
</code></pre>
</blockquote>
<pre><code>usage: csv-proc [-h] [--init CODE] file command

positional arguments:
  file         CSV file. E.g. 'data.csv'.
  command      Python code to run on each row of the file.

optional arguments:
  -h, --help   show this help message and exit
  --init CODE  Python code to run before processing begins.
</code></pre>

<p>In this example, I have medical data on some hospital patients:</p>
<blockquote>
<p><strong>data.csv</strong></p>
</blockquote>
<pre><code>id,height_ft,weight_lb,glucose_mgdL
PT-9357,5.96,189,124
PT-5315,5.53,180,106
PT-7733,6.15,222,126
PT-9667,6.10,174,104
PT-8893,6.00,232,98
PT-1125,5.97,187,85
PT-1222,5.82,237,104
PT-7681,6.00,198,134
PT-7043,5.98,227,78
PT-2623,5.55,204,125
PT-7031,5.50,216,107
PT-4947,5.91,199,105
PT-9711,6.13,237,107
PT-3737,6.03,179,111
PT-2931,5.78,187,87
</code></pre>
<p>Here's what the columns mean:</p>
<ul>
<li><code>id</code> - the patient's id number.</li>
<li><code>height_ft</code> - the patient's height (units <a href="https://en.wikipedia.org/wiki/Foot_(unit)">ft</a>).</li>
<li><code>weight_lb</code> - the patient's weight in (units <a href="https://en.wikipedia.org/wiki/Pound_(mass)">lb</a>).</li>
<li><code>glucose_mgdL</code> - the patient's fasting <a href="https://en.wikipedia.org/wiki/Blood_sugar_level">blood glucose</a> levels (units <a href="https://en.wikipedia.org/wiki/Kilogram#SI_multiples">mg</a>/<a href="https://en.wikipedia.org/wiki/Litre#SI_prefixes_applied_to_the_litre">dL</a>).</li>
</ul>
<p>From this data, I want to make several calculations:</p>
<ul>
<li>I want to calculation the patients' <a href="https://en.wikipedia.org/wiki/Body_mass_index">body mass index</a> (BMI) from their
height and weight.</li>
<li>I want to classify the patients' weight based on <a href="https://en.wikipedia.org/wiki/Body_mass_index">BMI</a>, e.g. "obese",
"underweight".</li>
<li>I want to classify the patients' <a href="https://en.wikipedia.org/wiki/Diabetes">diabetic status</a> based on <a href="https://en.wikipedia.org/wiki/Blood_sugar_level">blood
glucose</a>, e.g. "diabetic", "prediabetic".</li>
</ul>
<p>Here's how I can use <code>csv-proc</code> to accomplish this:</p>
<blockquote>
<pre><code>$ ./csv-proc data.csv '
_height_m = float(row.height_ft) * 0.3048
_weight_kg = float(row.weight_lb) * 0.453592
bmi = _weight_kg / _height_m ** 2
bmi = round(bmi, 1)
if bmi &lt; 18.5:
    bmi_cat = "underweight"
elif 18.5 &lt;= bmi &lt; 25:
    bmi_cat = "normal"
elif 25 &lt;= bmi &lt; 30:
    bmi_cat = "overweight"
elif 30 &lt;= bmi:
    bmi_cat = "obese"

_glucose_mgdL = float(row.glucose_mgdL)
if _glucose_mgdL &lt; 100:
    glucose_cat = "normal"
elif 100 &lt;= _glucose_mgdL &lt; 126:
    glucose_cat = "prediabetic"
elif 126 &lt;= _glucose_mgdL:
    glucose_cat = "diabetic"
'
</code></pre>
</blockquote>
<pre><code>id,height_ft,weight_lb,glucose_mgdL,bmi,bmi_cat,glucose_cat
PT-9357,5.96,189,124,26.0,overweight,prediabetic
PT-5315,5.53,180,106,28.7,overweight,prediabetic
PT-7733,6.15,222,126,28.7,overweight,diabetic
PT-9667,6.10,174,104,22.8,normal,prediabetic
PT-8893,6.00,232,98,31.5,obese,normal
PT-1125,5.97,187,85,25.6,overweight,normal
PT-1222,5.82,237,104,34.2,obese,prediabetic
PT-7681,6.00,198,134,26.9,overweight,diabetic
PT-7043,5.98,227,78,31.0,obese,normal
PT-2623,5.55,204,125,32.3,obese,prediabetic
PT-7031,5.50,216,107,34.9,obese,prediabetic
PT-4947,5.91,199,105,27.8,overweight,prediabetic
PT-9711,6.13,237,107,30.8,obese,prediabetic
PT-3737,6.03,179,111,24.0,normal,prediabetic
PT-2931,5.78,187,87,27.3,overweight,normal
</code></pre>
<p>(This uses the functions <a href="https://docs.python.org/3/library/functions.html#float">float</a> and <a href="https://docs.python.org/3/library/functions.html#round">round</a>.)</p>
<p>I could also accomplish this by defining some helper functions using the
<code>--init</code> flag:</p>
<blockquote>
<pre><code>$ ./csv-proc data.csv '

_height_m = N(row.height_ft) * 0.3048
_weight_kg = N(row.weight_lb) * 0.453592
bmi = round(_weight_kg / _height_m ** 2, 1)
bmi_cat = classify_bmi(bmi)
_glucose_mgdL = N(row.glucose_mgdL)
glucose_cat = classify_glucose(_glucose_mgdL)

' --init '

from bisect import bisect_right
from functools import partial

N = float

def classify(x, *, cutoff, label):
    return label[bisect_right(cutoff, x)]

classify_bmi = partial(
    classify,
    cutoff=[18.5, 25, 30],
    label="underweight normal overweight obese".split(),
)

classify_glucose = partial(
    classify,
    cutoff=[100, 126],
    label="normal prediabetic diabetic".split(),
)

'
</code></pre>
</blockquote>
<pre><code>id,height_ft,weight_lb,glucose_mgdL,bmi,bmi_cat,glucose_cat
PT-9357,5.96,189,124,26.0,overweight,prediabetic
PT-5315,5.53,180,106,28.7,overweight,prediabetic
PT-7733,6.15,222,126,28.7,overweight,diabetic
PT-9667,6.10,174,104,22.8,normal,prediabetic
PT-8893,6.00,232,98,31.5,obese,normal
PT-1125,5.97,187,85,25.6,overweight,normal
PT-1222,5.82,237,104,34.2,obese,prediabetic
PT-7681,6.00,198,134,26.9,overweight,diabetic
PT-7043,5.98,227,78,31.0,obese,normal
PT-2623,5.55,204,125,32.3,obese,prediabetic
PT-7031,5.50,216,107,34.9,obese,prediabetic
PT-4947,5.91,199,105,27.8,overweight,prediabetic
PT-9711,6.13,237,107,30.8,obese,prediabetic
PT-3737,6.03,179,111,24.0,normal,prediabetic
PT-2931,5.78,187,87,27.3,overweight,normal
</code></pre>
<p>(This uses functions <a href="https://docs.python.org/3/library/functions.html#float">float</a>, <a href="https://docs.python.org/3/library/functools.html#functools.partial">functools.partial</a>, and <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect_right">bisect.bisect_right</a>.)</p>

<p>I use the <a href="https://docs.python.org/3/library/csv.html">csv</a> module to read and write <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV files</a>.
The method <a href="https://docs.python.org/3/library/csv.html#csv.Sniffer.sniff">csv.Sniffer.sniff</a> analyzes a sample of a <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV file</a> and guesses the "dialect" (delimiter, quoting, etc.).
I use <a href="https://docs.python.org/3/library/csv.html#csv.DictReader">csv.DictReader</a> and <a href="https://docs.python.org/3/library/csv.html#csv.DictWriter">csv.DictWriter</a> instead of <a href="https://docs.python.org/3/library/csv.html#csv.reader">csv.reader</a> and
<a href="https://docs.python.org/3/library/csv.html#csv.writer">csv.writer</a> because I want to expose the rows as <a href="https://docs.python.org/3/library/stdtypes.html#dict">dictionaries</a> instead</p>
<p>I use <a href="https://docs.python.org/3/library/functions.html#compile">compile</a> to prepare text to be executed as code by <a href="https://docs.python.org/3/library/functions.html#exec">exec</a>.
To determine the new columns to add to the output, I examine how
<a href="https://docs.python.org/3/library/collections.html#collections.OrderedDict">collections.OrderedDict</a> <code>env_local</code> changes after processing a row.
I ignore local variables that start with <code>_</code> because I wanted an easy way to
create "temporary variables" that won't show up in the output.</p>
<p>When I process each row of the input <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV file</a>, I create a <code>RowProxy</code> object
that allows accessing <a href="https://docs.python.org/3/library/stdtypes.html#dict">dictionary</a> entries as attributes. E.g.</p>
<blockquote>
<pre><code>rp = RowProxy({"cat": 3})
rp["cat"]
</code></pre>
</blockquote>
<pre><code>3
</code></pre>
<blockquote>
<pre><code>rp.cat
</code></pre>
</blockquote>
<pre><code>3
</code></pre>

<p>In this week's post you learned how to a command line tool that manipulates
<a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV files</a>.
You learned how to use the <a href="https://docs.python.org/3/library/csv.html">csv</a> module to read and write <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV files</a>, as well as how to use <a href="https://docs.python.org/3/library/csv.html#csv.Sniffer">csv.Sniffer</a> to automatically deduce the
"dialect" of a <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV file</a>.
You also learned how to use <a href="https://docs.python.org/3/library/functions.html#compile">compile</a> and <a href="https://docs.python.org/3/library/functions.html#exec">exec</a> to run text as Python code.</p>
<p>My challenge to you:</p>
<blockquote>
<p>Build a tool like <code>csv-proc</code> that allows you to filter <a href="https://en.wikipedia.org/wiki/Comma-separated_values">CSV files</a>
based on some criteria.
For example, if you only want to view prediabetic patients from <strong>data.csv</strong>,
you could call your program like this:</p>
<pre><code>$ csv-filter data.csv '100 &lt;= float(row.glucose_mgdL) &lt; 126'
</code></pre>
</blockquote>
<p>If you enjoyed this week's post, share it with your friends and stay tuned for next week's post. See you then!</p>

<hr>
<p>(If you spot any errors or typos on this post, contact me via my
<a href="https://johnlekberg.com/contact.html">contact page</a>.)
</p></div></div>]]>
            </description>
            <link>https://johnlekberg.com/blog/2020-09-26-cli-csv.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24603897</guid>
            <pubDate>Sun, 27 Sep 2020 03:05:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AKL-PT1 2 GHz Passive Probe Operator Manual [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24603834">thread link</a>) | @app4soft
<br/>
September 26, 2020 | https://www.antikernel.net/downloads/AKL-PT1/doc/manual.pdf | <a href="https://web.archive.org/web/*/https://www.antikernel.net/downloads/AKL-PT1/doc/manual.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>¹\M¥–‰o·À:+«,ðÂÐ¡¦Éöì¶ƒô‰Õï¨é¸šáÕôFè=HuÇôÒ8¾*2ÎÄ¿º£—z&gt;¶³žqrh¦%¹˜­;&amp;f¤DèÞ-:ï¾ÈK¥ëI¹^ì/E9À£¯Û5íÓ©^v´¥¬Dçðvú]8ß:U3cZÒêlp#&gt;œ€
Ç[Nºî^,+GøÅÜðÝjúÒvŠñøpæá¿ây#?3®*¬¡áž¡!p*+9ÜùGf¥Ðós‡¾‰aÅ9÷iH1m�žþçl|ôhg±‹
endstream
endobj
142 0 obj
&lt;&lt;
/Length 1797      
/Filter /FlateDecode
&gt;&gt;
stream
xÚµXÝsÛ6Ï_áÛËä»ZõaIÝËÚ¥ûìÖäÖ‡u´D;¼R¢KJq²¿~¹vêv¹m½ÞÕ‚ ~%™mfÉìÅYÂ¿O¯ÎÎŸçÕLäq–/ÓÙÕzV-ã|Vfe\åbvÕÎþˆÄ|!D’D¯næ™ˆ”»Ñj7ÿóê‡óçår&amp;D\EØ™Ìi—`Ž¶ÅacZD?Ë~ž¥Ñl´ž‹H"Ñ1‘S@:²(Àb×I-&amp;‹I\ÔY|ÒÏÓ*ô»yZ‚=î3óE¶’+�p‹Èâ"¯iË¯¯hý©Å­·Èˆ(_.‹Cå‚N²¢ �_žÑ¶ßçUIcÔñ¯ÛS‡¼¶Æè~³’xÆnyDêoæBˆè	1u•,Å"á³‚d&amp;fq@âõ@¢,ïÝþð”ëaØúÇçç»Ý.–=D#`â^
çl�0=ÄC3^å¿•BYE{CŸ@5Oã²Ø£š2ªoæuIç\€¾û B&nbsp;ˆ�Úá"ÙFe–×š©­³«ù
ðŠ¥ßNÁ%Hc\í¯UK¬ß’z£ß&amp;YÞÈAÛžmµ£ðˆ¶®ÕàO/Ý	ŒÄs*X�‹)3Ø&nbsp;X”Ñè²Ç#ØÂGºp-®­£EIü¤¢m8¥%©]“Ò®\;¥ˆ{›Iÿ	RºÈIçiuí@ÙvÄ´rP‡¦ÊÈ_ëm§(šìAÏ§í´1D9µ•Ú�Êpt;ÏÔ0²Q�Þy	àc	ãÂ2ÒˆjxkQv‹÷ªPC="zG+­Z«fÐ7á$@)c3ÄóE	5tÐÆÅ*~È†KM(ëJ%ÖîHm\Ëf hO\(Ü&gt;i$=\Â«M¬šÅ”zÒ°½	5
n-«4º��Ü(Zj$Â."¶µ¢út¯6FoTOÁ‚é´åÀÀ©M£[†c„›³Å³ÐžDCÝ6Jµ”´Ùqªò®"K“ŠÑ]@ûP¨¡ŒK¢Ú—öec¸Ïõv %pRNµqpG,ã:[ûôQYCNåijúkOt'ouôØ‘Àh¹ÒFSÜ&nbsp;«Œ}KÏAà¨âQõ^G8Ø1i„;b�Á†@	8s÷5€÷X^„+úf^ˆ1 \…úÁßPŠ,ãæÁLMÄé»ƒ"õ3¤v°=”2!¸H°b0†éÐ&amp;rQ”
H[í +CfÔ‘î�Ø`JÃ"u»8™&lt;Âí_©¼
Å�…bê½z?r„À‰Û�ðžlBºoÌˆYéLÔÑjÄ|ÉsNPÜ£�Ì`ù¨©Ì›ÑØiñ~¼%ô*l!ãÊc¼õ0B;q…
±¡y¶àY
/‘¥¬AÒãŒÒ(,¢à1Ö�,œ€¿Tˆ¸�R2iy7øˆ1øoP¾dywôºW“)Mž+çÆ-¶A(ZêÍixµµÇšáw�%2”ÎœÅÁµq8Ùx×T‡!�±2é�Á2_“€ÅLäå#(jŒ!ÌTúlM¶7ÚS¿H?&gt;‚%š&gt;,ÎCU?6hùš8J�øS#a§I=
¯¶ø¾F
+‹è¥tíÇéÔfˆ«àj±Œ:ë¢Æíb°‹6<i¼Ø*¯7=Ñˆ¨ i="" ¿ÂË)v@="" hx2xÈ­¬íh="" 'd¡‡—ãŠý€þµ·Î[²ecÐ1ÄîÆo="" (¼g�fa~ºÏ¾mÒäbºì¹†k}Åðba¶”÷°de="" „ö÷ºú‡âÄ²�ïÍ�evû="">O€4.ò"Ég‡N «²†¥&nbsp;þ£þîÉ§eŽêàuj&gt;.ÛøŸæ9�cÀ£�jï�žÿÊ“çáKbåt3�ƒà¢ü!vaøÜ�Ä²AïÞ�[ÐÄ†xvÜí[è)˜1_&lt;Ž—¶ï'–’2œ&lt;0îñp@‹�qÊøã6Õ&nbsp;…f°¬7ÀCî5Má_:ô—“�—[˜È/<d$éø9�Ç›fƒ$Î²ò8j¡ï¤©À÷Ëí§i~×\…Ç&û6„ô¾ !#ý±"u#¤vnÓì†Œö�øÁ˜eœû{~0nôp="®âÆvçò/Û«~¥Üæœnš–i,êâÞgâ�ŸðÑà$" ªîþæ?tùœ»ü%uy�Ù:ÿ€¾~¡(c="">Vò4™Æõûô`Ãgï6	å4§ÕÓÀHšû¾�&lt;½¸¼ØÉ–ÅTI8!@¤y«q’ç±F«qË/¢coðoÎvÄ\sGŸÚrO»ßáŸ]à]øï8B=ÐÌ´&lt;…§¿ëè8èÕÏ×CQÅ¢J'CaPAýgWg‚OIù¾œÕIeÖtgïÏ0—à³×È°$’$‰¤¢ŠóiéüûNÌ.ìÙoðoòf:b1�±ØþþtìkJiUÍ ~™à¼ÈŽn^ÿ
wdÉ_
endstream
endobj
138 0 obj
&lt;&lt;
/Type /XObject
/Subtype /Image
/Width 4167
/Height 910
/BitsPerComponent 8
/ColorSpace /DeviceRGB
/SMask 148 0 R
/Length 50262     
/Filter /FlateDecode
&gt;&gt;
stream
xÚìÝk›TW�Æa^Ç†n&nbsp;Q?ÕÌuÆQc �˜!„œFG��¨qÆqfÔh4
9�htüf±º««®]Uû°ÖÚ»ŠªU÷}=Ÿ`×Þïêwý?û Cÿô«Ý½ýã¯þarÐ¹~ËP5uÐ¹/þz÷?�.0pðè€d_üõîÉ…7 ôìzäZé&lt;™R½½{¸Ò´!°qð$XfU9ƒº¡ÊCoï)l÷ØÂ]K+0gÐ5}éí=Å=T²ÐÆaX7xª,•Ø¢A×Ðóå·÷ŒíK«ijê/$K"­hXò®á+¿ÙóåÉ5eá�ƒ×€ìµ)–¶køÊoö”®1sˆ
¼œd¬}Ñ°„]Ã¿üvOoU]C]ã8xEÈRWEÃRE
ÿúÛ½ýõÓ†±%7�ƒ®€uX4,O×0,ª–Þ8”ÃºÁë
@6:/–!jøê;{‹k¢‡ÆºÁK@¦Q4d5Œ
¥‹j¢Î7ôÓ¯.mJECÞQÃ¿½³wr-3‡¸ÀaP7x�XPÓ+2Ž¾öÎÞÒ%dÉ�C±nð°p¦Z4ä5|íw{+×.shjê/3dÚEC–QÃ×·¯f�™CËÀ¡þ|ƒW€…0ƒ¢!¿¨áïîë­¾khÈâ‡¨ºÁ‹
Àœ›MÑ�YÔðð»ûúûFÅZ6i�ÃdÝàõ`n)‹†š%”!�ClÝ&nbsp;k`&gt;Í¬hÈ)jøæ»ûŠ{8fá�CZàPU7xÕ˜+³,²‰¾yußøÞ-_‡�Cià[7xá˜Š†�\Ý?¶’Æ¡:vˆjš‡²ó
õuƒ×€NÑ�àøÕý“{¤z-3‡ÆÀ!ªnÐ50
	Ž_Û_¾«•‹ÍB‡Àº¡þpƒO€BÑ�àÄµýU;^³¦Ì!!p¨?ß^7ø˜1EC‚š¢!:vob‡´ºÁçÀÌ(&lt;º±¿~­J‡êÆ!*p¯ÆÒ3&nbsp;hHprã@ãÚÄ5�CcàU7TnÐ50mŠ†!EClìÑ84uCàáS¢hHpjã@àÚd±�ClÝx¸A×À4(œº~ b-b‡èÀ¡ì|CuÃvÚàc&nbsp;CŠ†�]?¾¨Ø¡}àP¾¡±nhL|2tBÑ�àñë¢×;7��CTÝPu¸¡4mðáÐ’¢!Áã›¢Ó;¤5õ�CMÝ�v¸A×@Š†ßÚ\IXTïÞ84uuCäá†Ò´ÁG@EC‚´¢!:voš‡VuCÙá†É´Á§@EC‚'6W’×ªt¨nJ‡–uCHÚððhÚàƒ �¢!Á“7VÚ¬Mì8„Ÿo¨ªª7ì¤
WÒŸ�
	Z
Q±CZàP~¾!&nbsp;n¨&lt;ÜŸ6ø¸¨¡hHpúÆJû%gm‡Éº!ùpÃ#cuCEÚà&nbsp;”¢!Á™›+�,9vlJ‡„º¡þpCcÚ&nbsp;k`’¢!Í™›»XDìÞ8L£nh8Ü–6øÜR4¤9{ó`'‹êÂ‡ˆÀ¡©n&lt;Üž6øèøLÑ�êì{;[\ï�Ò8¤Õ
�‡ÒÒŸÀ’S4${ê½ƒ]-*v¨iB‡&nbsp;º!òpC`Ú°Ó5Ò_À2S4$;÷ÞÁ;Ô5å�ClÝx¸¡UÚ&nbsp;kXbŠ†6º�Âc‡úÆ!-p¯Æ7l”Ô
QiƒÏ`	)ZzúýC.9sˆ
Òê†é¥
¾D€e£hh©Û¢¡MìP×8”%çªê†ÊÃ
×Gê†¨´a¬kð1,EC{çß?ÔíºÊ‡¨º¡ápCGiƒO`I(:ñÌ‡º]rì8Ö
±‡vÒ†Í¶iƒ¯`(ºÒyÔ;$åçâë†ÒÃ
�iÃÉ¦´Á‡	�=EC‡.|p¨ÃµÉ’‡ðº¡ó´a¬kðmäMÑÐ­n£†6±CràP7nhŸ6ø&lt;2¦hèÜ³®v¸®2‡ÆÀ!¨n¨8Ü0½´Á
�+EÃ4&lt;÷áj‡KŽ’‡ö‡BÓ†B×P•6øH²¤h˜žn»†ÀØ!¡qh[7t�6Œu
&gt;R€,)¦êù�V»Zræ�8„×
c‡ÎŒÖ
íÓß)@~
ÓÖaÔ�;„-ë†ÒÃ
¦
&gt;U€Ì(fà…�V»Z'™CcàU7t’64v
&gt;U€Ì(fæÅ[«�,9vHÚnè*mðµäDÑ0K/ÞZëh¡±C›À¡MÝ0�´Á×
�EÃì½tk­å¢b‡ÀÆ¡«º!5mX©ID
ùQ4&lt;(í»†àØ!:phY7´OªN6xm²¡hx°^¾½–¼™Ceã8TÕ
¥iÃùîÒ/@6
óà•ÛkiKŽª‡ØºaÆiƒW Š†ù‘Ü5Æm‡®74¦
õ]ƒ— Š†yóê�µØ%gQ�CxÝu¸!*mðzdCÑ0Ÿ^½s8r‰±Cdà�X7tuµÁ‹�
EÃ&lt;{íÎáð…Çm‡ðºaiƒW Š†ù÷í;‡;Ä!uCTÚ0V7L¦
¥]ƒ— Š†EñíßZXìPÇ!¶nH;Ü��6x
²¡hX,ßùýáú…—µ�CguCxÚPìªÒ/@6
‹¨±k�ª‡ðÀ!&nbsp;n9Ü�œ6œW4dDÑ°¸¾û‡#UKÏb‡ðº¡}ÚÐ�üèÙP4,ºïýáHé’c‡ÆÀ!¤nhJÖÒÒ?7@6
y¨êc‡ØÀ¡¦n&lt;Ü�–6ø¡²¡hÈÉ¿|dlÉ™CsàPW7¤n(OŠ]ƒŸ Š†üLv
¥k8´¯bÓ?.@6
¹úþÇG†kß8tQ7t�6øY²¡hÈÛ&gt;&gt;Òß÷+–Ö8ÔcuCÕá†Æ´¡Ø5ôÓ?(@6
Ëà&lt;ºµAÝP\Tã[7TnHNü”Ù˜]Îp|kø´Ó5L®)sZnJüˆÙ˜YË&nbsp;h˜ÿñÇ£“kÌ‡ðº¡MÚàçÈÆÌZ†]Ç7zóÀçDi×Ð�9”ÝÔ
wFê†ª´áåÛŠ€|Ì$gØÎŸ+?¼{´¸´À¡þ|C·iƒŸ 3k
sëGw�÷Ã‰-ê†¨´Á���™µŠ†9Wìj‡æÀa¢nhŸ6¼6˜Ÿ	 ³Ìv�P4Ì»‹w�^¬HJ‡–uCiÚ0V7Ó?@6ºÎ6jrEÃ¢¸xo½Ÿ6—8¤Õ
UiƒŸ ³9Í0Øu|�lu
Å4QuCBÚàGÈÆtO3Z†þ&lt;ð…séÞúp5�C}àx¸¡1mðsdc–9ƒ¢aq]¾·Þ_eàÐ²nKüÙh×2\o
¸|}k÷ÖÃ‡äÃ
¥iƒŸ ³Ì
yx½ß5×8DÖ
5iƒ‡��éä×Ë÷¨¢!¯ß_®1ph¬7Ò� I9ÃFZÎ&nbsp;hÈÏ•ûëý•uCÕá†Ò´ÁÈF79Ã‰ÚœáÑá6=ð,]ùäØÖuÃ•¦ó
ãuCíá†b×àQdc–9ƒ¢!ooô»†ájê†ÈÃ
Ã´ÁCÈÆLr†Íá&lt;ðì½ñÉ±þÒê†ú´ÁãÈFpÎp­:gh&gt;Í&nbsp;hX6Ã®¡$phªÆ7Ò éâs†]'
ËåÍ‰®¡¾nhL<r����������€lÌ(g8¹3| ½ùÉ±þbê†ñÃ="" ÷fê����������="" -r†�êœa³4gp4,³ÿéxo5ucÃá†í®Ác����������ÈftÎp<="gP4ÐïBë†‰´Á����������ÈFê�†”œayŠ†ËƒËý¿â÷ÿ–ïe+*¦" 5ucñpƒ‡�����������“ns†ëõ9cÞeÃ¥{ë—‡›ÈúËû»þ›ŸóŽ¥="" Ãºaìyyp�����������™™eÎ°ëä�üàÅ{ë½]Ú^lÎÐßðŸüÞÆÉ´Á3����������ÈuhÑp•3œˆÈò+zæ="" càÿÉ`^k�����������²×Ñ�† œa×©¬Š†‹w�‹†s†Ÿüùs½ýt{Þo�����������ruv4l+gÈ©h(æ="" qec]Î°Ý2="" s†ÞÞÌ‹="" ����������@fš4t—3äz4l#gxkb?ût×�����������@="">r†¶EÃHÎ�UÑPv&nbsp;¡eÎðÓŠœágŸŽÌK@¦y&nbsp;a<gÈ²h<Ð˜3¼Õ”3üç`ÿõ—Ï{{����������x\)rs†lŠ†‹w�nh¸y ¡1g¨iŠó ¡§ß?Ôß¹÷ööÔöÎövóà™­­ôvúÆÊ“7v<+����������`nup ¡*gÈ¸hh¸t} a69co?ßž7y\øàÐ3ƒ�d="" Å®áìh×púÆn×ÐÛ›+ßÚ8�����������s¤p4lý@Ã®s7óxhÃ¢!ü@cûœ¡ªeØÚ_wæ}ÎÕs®="">»½*íúQÃ¹Â±†b×ðäh×ÐÛã›<u����������àÁj:Ð�˜3ät4\-:<Ðrša²eøïÁ~¡kÈÎó­ööÜ‡«Ï¢†…¨¡¦k83Ñ5<±9Ò5<~]Ú�����������<qecó�†ºœa×c9 ÷g‹†v"r†²–a°="" ôæÝÎÃ­¾°]4="" £†ª®áéÑ®á©ñ®a+j8="q¬aØ5<&amp;m�����������f«Óœa©‹†+eEÃØ�†–9ÃØi†ª–¡¿ÿùÿ­yÃÚK·Ö^ÜÚj}×ðLm×Ð�ÎNk(v" [qÃ k8%m�����������f"½hˆÏ2+.w="" á:Ífb†±yÏÑË·×^ºµ6ˆvº†çg»†gk»†~ÔpnüxÃh×ðÄæh×°5ô»†sÒ����������`Šjr†ãe9Ã‰°="" µ9c®eÃëÃ¢¡ö@Ã�#4”ä="" É~�3üoaÞöÅòÊíµ—·Ò5ô£†…¨áüÄ±†Ñ®a+j8="q¬¡Ø5ô£†“º����������`:fq&nbsp;á1ECô�†àœ¡¹eø¿¿�Ì;¿(^½³öÊíµ²®aµØ5ô£†ª®áé‰®áìD×ðäD×Ð�t" ����������ÀtÅ="" 5n„hÈ¦h¸4,î7="" ±:Éªz†þ~¹="oþœ{íÎáW·¶5¼Rˆ^*k¨éž™èúQÃ¹ñc" #]cÍ±†~×="" m�����������º2^4„h-Æs†Œ‹†+ƒ¢á�Š¢!í@ÃÏg‹†Éœ!¼eøåßÙ»oyÎò¾÷{ÙÆÆ¹^1°r�—Äœ="" Â½v®mc;›Ø="" �ÀhØ`fÍhéhžŽ$4ÒÑ,flhb32ö¿rnw×Þµ«Þz«ê­êêÞ]uŸïzvvâl="">ïó<ou×î ¿r½6+ó¿³|üÄ+="">¶ª¯áCe¯áƒ¯áÌûB¯áôÐkXJ
ï‰†5Ü†5ðBr@Ã�ë4ÌÊh¸¤ÆhèÐÐ[gˆº7|û°lÁò‰_ññEJ
q¯áo½†Ljø@%¬¡è5dRÃ{ca
§EÃ
^ÃÛïøM�Ð›d£a€€†¹

—×4¬©34F3„.Ã�å²;Å'|Å¾ÔPã5|$ôþuÑkÈ¤†³*a
E¯!“Î¨„5^Ã©Q¯¡ÖÀkÐ�˜Ñ0P@Ã;
q£¡C@Ã:CºË�×MÿÀkØ&gt;ùÐ+uè5œ(z
¿]ô2©áïÃ¯áÌûB¯a_j¸7ÖPôr©á�•°†¿þ¯@7Òî$&nbsp;anFCIgˆ
A@CÑhHhhÔ’\†›þ!,{qä|ê¡W~ª 5D½†LjH÷2©á•°†ÐkØ—~«GX¯@:iFÃ]MFCr@ÃÄ�†'þM«Ñpy�ÑÐ;&nbsp;!]gH²ºù&nbsp;lÇòé‡_™I
Q¯ác�^C&amp;5½†Lj8«ÖPô2©¡â54…5¼«&amp;¬�× …ŠÑ°Á€†½wÝ;�CÛ´ÑPÐÐYg¨‹fhuË?þ_yÙ‘#á3¿òÓ«jöþ¾ì5DÃ&gt;\	k¼††°†÷ÆÂNKkà5h†ÑÐƒó·e444$ê)ÑQ‘!(›²eÎ~ø•¹Ôõ&gt;z
‘°†¢×ð¡Š×Ð#¬á=ÝÃx
ê(ëQ£á®&amp;£¡‹ÎÀh(ê�Ñ�ëWö
hhÕººÇ+e_¶ÆÙ�¼jY1¯á“�×°’¼†Lj(z
™ÔpV,¬áÌhXÃ½ÝÂª^Ã_ñTè`4¬Ð0q£a%5Ô
_ý?/ëÐp¬K@CW�¡Áe8^_·~gY¶fœóÈ«Î9�ê¼†LjøDÖpè5t
kø@%¬!ô¤†Àk8”îj	kà5(Òd4¼½—ÑP¯3LÐhxlƒFÃUe£¡!&nbsp;¡ŸÎ�è2dC^·”ÝÙ(ç&gt;úªLj8§Öð™²Ôð© ¬¡ä5üvŠ×PÖPôr©áôš°†Ðkhkø«Ûy
–”�†;»

©FÃ7£a­€†”h†V—á¶š²Aâ¼G_µ¨¨×P
k(y
'J^C&amp;5½†Lj¨z
¬x
ma
¿µNX¯@›ÑpW�Ñpw£á@g˜˜ÑpAÁhøìfŒ†«Œ†Áu†‘aQ·?ùº¼ìÑð3¶2¯áìF¯!“&gt;†5¼"%¬¡è5l3¬áó€“j4¼#Íhx'£¡�ÑPÒbFC®3\SÐÐCghÈehµªe›†�±e¤†’×ðð+‹^C&amp;5|*kx0%¬á·«a
gm=¬�×Ì“‚Î°¦ÑpÏ¬Œ†óFÃ…)FÃJjH7®:4z4tÕ\†‹á•²SƒpájÀ2©áüJXÃ9…°†¯áDÄkøHè54…5|&nbsp;&amp;¬áŒ^a
ï¨kxÛí/×w`VÔ
oo3NI3
:ÃtŒ†G_Ug4\T0r©aFCJ@C«Î�è2
Ã±²Yk²œ«Õ€]Pk¨ó&gt;]ör©áaXCÉkÈ¤†¿ëÖpf¿°†;›ÂþŠ×ÌFCJFÃcÛ6r�áº.
]u†f—!T¾©;¿ËkèÏE«¡Ê¼†½†³+^C&lt;¬áÁHXÃGca
Þ�°†·ÝÆk¦O/£áî¸ÑðÎÙ
FÃJj¸¸ 5lÔh¸¾l4DÑâ‰!V¯_”-ëÁÒŽYÍUÑk8¿ì5œx
+©á3•°†’×°’&gt;¶Ëa
·ó€¹0�Ñ�Ð°wê¤Œ†óËFÃgë�†KFÃåÉFÃÕFCQgˆ
½ª:CR.C­ÈðújÝõ½ý²k�ÈF(÷.¼†ÅVÂÎ©„5½†LjøD%¬¡ê5dRCÕkX'¬á´»ZÂÞ~ÇoÖ…5ü%¯˜(�FCTg`4œÌ~O^4.&lt;2£áµ
FÃš:CƒËP'2äþB±î.”�Kä’ƒ)º(ð+y
çU¼†³+^C&amp;5|ªÖðñXXCà5äRCÕkHkø?ÂÞÙÖ°/5ð€‰ÒÓh8eÖFÃy�ÑðXÉh¸¨Þh¸¬`4äRÃ©¡·Ñpc‚ÑÐCghtâ"ÃÝ	eïZYÌÌ%«*†5½†*^Ã¹�×°’&gt;S	k¼†©á5a
¿=xXÃ©ma
™Ô
kà5S¢`4Ü¹–ÑðÎ9
Å˜†}£¡ÓpIAjØšÑ�ë7Õ4ôÓª.CW‘ážï—Êö5pÙ�sI!õ#k(z
™Ôp~%¬áœJXCÑk8”Œ„5|tëa
™ÔÐÖp 5ð€i°=£áÔÉ
Å˜†ƒß™�†‹£a%5¤
W5
×
7|;n4ôh(éa4C—!ð²º·Rv0ÊÒùÊaÆGÔk¸°â5œWñÎ®x
™Ôð©­„5œ&gt;DXC&amp;5T½†¿à5#gƒFC%&nbsp;aJFÃy�ÑPŒiˆ
—Ö
Ÿ/
WnÞhJgH±îM.›pùjTê¼†‹¯a5‡�×pnà54†5|bÐ°†÷5†5äRCCXÃ;ÒÂþâ¶—ÿ¯[y
ÀXén4Ü]1îI6î›Æ¡�† ¦á¢²Ô5.ß–Ñ�ë
FC³ÎpgYghÈeèd1Ü÷ýÿ;Zö1'›�}©¡à5\òDÙk8	ÂÎ¯„5œÓ%¬áckxo[XC&amp;5´†5äR¯;Œ†œwðsñRLÃÁoËëb2£á²4£áXÁhÈ¥†ÞFÃñ²ÑÐÐÐ�ÎÐÛeˆûOÕ–­\°˜Š&lt;Ë#k¸¬ÖpqÖPöÎ«x
¹Ôð™Q…5äRCsX¯[2N�”ÑpnÔh(Æ4Ô
1
Ÿ+K
[3z4ÔêÍ.C«¿ðÅÆšùb^q`»T½†K+^ÃE�×°šÉÀkØ­°†}©¡)¬!—ZÃ©�×ŒFC£!ˆi¸¨,5äFÃ¥�FC.5;�Ö1nîh4ôÖÒE†¨¶ð¥¶šíb.&amp;!—r¯áòŠ×pÉe¯á ($1¬áìAÃ2©¡!¬!“Âr©¡5¬!—ê¼†·Þú®w`Ç)
w09·ðñRLÃã‘˜†K‚˜†Õ/Ò//
Ÿo2^�
×Œ†ëú
·%
ýt†¨ËÐî/&lt;Ý^3\Ì&lt;³#ê5dRÃe•°†‹+a
ÆÂ¯!—ª^Ãúa
ïO
kXJ
­a
¹Ô�ÖðÖ[ã­Çy
ÀN³£¡¨3LÎh8ç‘W�[1Â˜†Â�ÌKFC}LCþ#öÜh¸j“FC®3ÜÞ1&nbsp;¡Eg¨¸­
Ã—ÓjV[¹€cóPôò±	ÂŠ^C&amp;5\k8?ÖPö¶ÖpzBXC.5´†5R¯
ïL1î›¤ÑP�iøl,¦!ÿÙyƒÑPŠiØ¢ÑÐ)&nbsp;¡Ighpz)sö­?–UAj¸¢Öx
Y H$¬áñHXÃyÃ‡5üëÖ°†3ïkkÈ¥†Ö°†¢ÔÐÖð^°{0º’ýüÜ¨Ñ�Ó°úúåe£áó£áXÁhÈ¥†ªÑ�I
Ã
±€†f�!ˆfhvZm…ûŸ~CkÍÄkX5ýÕWH
Ç*a
E¯!“.«„5„^C.5¼†õÃ&gt;ÒÖðÁ„°†‚ÔÐÖP”RÂ©áò€]‚ÑÐ•ˆÑP‰i¸(9¦¡j4c®.Ç4\[�º
·~'Ýh¨
hhHgu†6‘!*,&lt;ðL{åÿ‡'¼•‹^gRCÑk¸²â5äIAXCÑkÈ¥†Ïn1¬!—ÂŠRCsXÃ¡Ô�ÖP•x
À.s 50’È~û]Óðx$¦á’JLCn4äRCÔh¸ªl4\
¯‰
7u4î80ú4t† š¡UdHñZk’+™·»Öð�RXÃ•°†Àkhk¸`a
™ÔÐÖP”ÚÂ¥†Ö°†@jHkà5À°üÎïþ—-—3‡µ²b�Ó€ÑÐ‰³£FC4¦aõKò ¦!3šc2£áX£ÑpÝ&amp;�†Ö€†Z�¡&gt;š!]d8‘PÓöÍ½¶$5¼¦Öp¬ÖPôšÃ.:¬!“ZÃ2©¡5¬a_jh
k¨H
)a
Q©�×ƒp´?Šó»8Ø,Ëðˆ0jjŒ†;‡1N�¬ÑÐ5¦!ÿ‘y§˜†ÌhÈ¥†¨ÑpC‚Ñ�I
ýŒ† &nbsp;¡«ÎÐì2Ä�…gªòk2+™õ÷Úo^Ã«‹^Ã•¯!§jXÃ%GÖð·ia
¹ÔÐÖP’Âê¤†ª×ðç·ð`-váGq~›e¹1Æ£!�³~e§˜†‹kb.¯Ä4\Q‰i80^]4r©!3Š1
ý�†ïæFÃë£FCz@C¢ËÐê/&lt;˜PQÍa3¶êìkr¯áš²×pUÅkhk¸lÐ°†LjhkÈ¤†Ö°†\jh	k(H
‰a
U©!1¬áÏoá5@ü(˜ürÙ/ð|ñ|°Q’�†»
E£a¨˜†üçè�ÑPŒiÈÖ^6^S4r©a}£áî£a}�¡Nd¨
=ûo[«NsõŒ-ºrUó8¢^C&amp;5"¬áÂ5Â&gt;žÖp(5´†5äRCRXCEjHkˆJ
vË¯{"@ü.˜üfY.ðˆñˆ°QbRÃ]ñ˜†Àh8e^FÃÉ
Ç4\yðõrLÃkŠ1
ùÝŒ†\jXÓh¸çûMFC³Î�â2´(Ï%T½æ0Ò[ôñ†UÕy
™Ôpu,¬áŠhXCÙk8”Ê^Ãàa
¹ÔÐÖðþä°†ˆÔ�ÖP+5ð`ü(°\��ëÀhHg›1
WUb®
cöý^4nÚ¨Ñhèª3ÔŠaáá¶jÕF7`‹öeÝ&lt;�½†Ú°†oDÂB¯á+‡ãWÖpAsXÃbò›Ã¥†ö°†LjH	k¤†Ä°†:©!=¬áOoæ5@ü(°\��ëÀhHä3«ßuWcÎëÓð¹š˜†c•˜†ü§ì�ÑPŒi¨
·lÌhHh¢".C…!±ÁaD–u0ÏÝÈÃ®�‡5¼¦ÖPôr©áò¾a
ç¶…5äRCkXC&amp;5´†5T¥†¤°†z©!)¬¡Fjà5@:~X.€GŒG€Þ0É�†³7ÓpE,¦áêJLÃuß
cn,K
Q£áÖ:£áÉ&amp;£¡¤3´
‰:CÕehÖi«DÁavóª}u^Ãuq¯a?Îcka
¹ÔÐÖ°/5´†5RCJXC�Ô�Ö�"5ð&nbsp;+~X.€GŒG€Þ0Ù^LÃ7"1
×VbnøvÓpsAj8^‰iXÓhøbÙhêt†0š¡Ñeˆj�þ&nbsp;©ÒM‡Ÿ®¬k¹Ô�{
RÃk«a
E¯a­°†Õ¸6„5œóHRXC&amp;5´†5RCJXCTjHkh–ZÃÞÌk€ü(°\��ý(
wÆ�†ªÔ�f4LIjøôê·ÜQ©¡d4&lt;6lLÃkª1
×WbòŸÁ7
¹Ôð…\jèg4¤4DÓj\†t!±ší†­¬Sy¾F�°†«»‡5\òDSXC&amp;5´†5dRCkXCYjhk¨J
éa

RC×°RtÂ�âËðˆñˆÐ���†wÍÅh¨•
FÃEƒÆ4ä?hŒ†bLCþÃød£áu
Õ€†�!Ýexìÿ®¡‡�õ=ZT³×pCÅkÈb;¢a
Çú†5|6!¬áì´°†\jHk¤†ô°†f©!=¬¡UjxóM¼hÁ�âËðˆñˆÐƒrLÃ]©!ÁhˆÄ4LÍh8™Ó•Òc®&lt;ø!zÓpÍ7£1
¯­Æ4Ü\‰iÈ~-_4n_ÛhørÙhˆ4¤ë©
Ãó�•¦9Tí†#ªE;²îäRÃñŠÔPô2©áúxXÃkú…5\ÜÖp^ZXC.5¤…5„RCJXC³Ô�Ö�(5ð&nbsp;~X.€GŒG€4
w12�†z©!4bRCbLÃU]bòŸ¾FC1¦¡j4ÜQ0î*
÷ÄŒ†/UŒ†æ€†V�¡Ed¨h�7V³æPg7¹×�u$ÏÑh
k¸q&nbsp;°†ËÚÂ2©¡%¬¡ 5´†5Ä¤†ö°†F©¡CXC«Ô ¬†Â�âËðˆñˆÐ•Í
ó‰i¨•
FC�Ô�
U©¡9¦á†oGbòÃFC.5ì
OnÊhhhˆêQ‘¡ª-&lt;ÑX-šC�Ýp„jÃ«^|áÀ4É¥†ÀkÈ¢7ba
¯=’°†\jh
k¤†Ä°†:©!=¬¡]jèÖ•þ„×õøQ`¹11ºÒÍh8e¦FÃÉF©¡d4ÔH
�Ñpùæc²_ÈFÃÊFC&amp;5Ü]�ªFÃSŒ†gËFC'�!&amp;2&lt;±vÅ‡6µaÓvÃêÌ—‡¿LÊ(H
E¯!OÙÂ*^ÃáHôkX
dsXÃ¾Ô�ÖH
ia
©¡KXC›ÔÐ%¬¡“Ôð&amp;^ÔàGq€åxÄxÄèÊÊh¸sp£aï´‰Ç4ÔJ
£áâ¶˜†Ï÷Ši¸±&amp;¦áx%¦!ÿÙ|Ùhx]�Ñ°/5t7¢
U�!ˆfH¾òBS¥Ø</ou×î></u����������àáj:ð�˜3ät4\-:<ðrša²eøïá~¡kèîó­ööü‡«ï¢†…¨¡¦k83ñ5<±9ò5<~]ú�����������<qecó�†ºœa×c9></gè²h<ð˜3¼õ”3üç`ÿõ—ï{{����������x\)rs†lš†‹w�nh¸y ¡1g¨išó></r����������€lì(g8¹3|></d$éø9�ç›fƒ$î²ò8j¡ï¤©à÷ëí§i~×\…ç&û6„ô¾></i¼ø*¯7=ñˆ¨></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.antikernel.net/downloads/AKL-PT1/doc/manual.pdf">https://www.antikernel.net/downloads/AKL-PT1/doc/manual.pdf</a></em></p>]]>
            </description>
            <link>https://www.antikernel.net/downloads/AKL-PT1/doc/manual.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24603834</guid>
            <pubDate>Sun, 27 Sep 2020 02:51:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pac-Man Maze Generation]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24603618">thread link</a>) | @kanamekun
<br/>
September 26, 2020 | https://shaunlebron.github.io/pacman-mazegen/ | <a href="https://web.archive.org/web/*/https://shaunlebron.github.io/pacman-mazegen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">

<p>
by <a href="http://twitter.com/shaunlebron">Shaun LeBron</a>.
(<a href="https://github.com/shaunlebron/pacman-mazegen">code on GitHub</a>)
</p>


<canvas id="canvas"></canvas>

<h2><span>Work in Progress</span></h2>
<p>
<i>
Generating random Pac-Man mazes is a deceptively difficult problem that I spent some months working on.  It is not easy to describe clearly.  I hope you are patient.  This page is an effort to begin communicating how the algorithm works.  It will slowly be refined (your feedback appreciated) until it is all stated as clearly as possible.
</i>
</p>

<h2>Contraints</h2>
<p>
The mazes are built carefully to closely match design patterns deduced from the original maps found in Pac-Man and Ms. Pac-Man:
</p>

<ul>
<li>Map is 28x31 tiles.</li>
<li>Paths are only 1 tile thick</li>
<li>No sharp turns (i.e. intersections are separated by atleast 2 tiles).</li>
<li>There are 1 or 2 tunnels</li>
<li>No dead-ends.</li>
<li>Only I, L, T, or + wall shapes are allowed, including the occasional rectangular wall.</li>
<li>Any non-rectangular wall pieces must only be 2 tiles thick.</li>
</ul>

<h2>It's like Tetris</h2>

<p>
We start by stacking tetris pieces on a 5x9 grid. Gravity pulls the pieces in the left direction rather than down.  The edges of the resulting tetris pieces correspond to walkable paths in the maze.  This grid is then mirrored across the left vertical axis to create a symmetric map, then scaled by 3 to form an original-size 28x31 map.
</p>

<h2>Definitions</h2>

<p>
For clarity, I call the squares in the initial 5x9 grid, <b>cells</b>, and the squares in the final 28x31 grid, <b>tiles</b>.  So, this algorithm first creates the <b>cells</b> and transforms them into <b>tiles</b>
</p>

<h2>Simple Model</h2>

<p>
Shown in the above diagram titled "Simple Model" is the 5x9 grid of tetris pieces.  The pieces are created one cell at a time using some algorithm to limit the type of pieces at certain locations (they are numbered to show the order of creation).
</p>

<p>
The ghost pen and the edge between rows 7 and 8 at column 1 are present in every map, since the starting location of Pac-Man and the ghost pen location are constant.
</p>

<h2>Height and Width Adjustments</h2>

<p>
Cells are directly transformed into a 3x3 group of tiles. Unfortunately, this creates a resulting map that is too short by 1 tile and too wide by 1 tile.  So, we increase the height of one cell for every column, and decrease the width of one cell for every row, allowing the generated map to fit in the exact dimensions of the original game.
</p>

<p>
Shown in the above diagrams titled "Height Adjustments" and "Width Adjustments", the highlighted cells are the candidate cells whose size can be changed without creating ugly walls (i.e. walls that have non-uniform thickness).
</p>

<p>
Arrows occupy cells which have been chosen for size adjustment.  Care is taken to prevent discontinuities in the edges as a result of the shifting of cells from the size change.
</p>

<h2>Border Cells and Tunnels</h2>

<p>
I won't explain too much about this right now.  But the above diagram titled "Border Cells and Tunnels" has arrows to indicate the tunnel candidates.  The highlighted cells show the type of tunnel candidates by color.  Some cell edges are erased to create some variation in how walls connect with the boundary of the map (shown in green).  The tunnel creation algorithm is sophisticated in how it chooses different types of tunnels.
</p>

<h2>Final Paths</h2>

<p>
When the cells are finally transformed into tiles, what you are left with is shown in the diagram above titled "Final Paths".  Here you can directly map a cell to a 3x3 group of tiles.  You can even pick out the cells whose height are width have been adjusted by 1 tile in this map.
</p>

<h2>Final Tiles</h2>

<p>
See how the above diagram titled "Final Tiles" differs from "Final Paths".  The paths are shifted from the tile <em>edges</em> toward the tile <em>centers</em>.  Each tile with a path going through its center is turned into a path tile.  Finally, any tile that touches a path tile becomes a wall tile.  The map structure is now complete.
</p>

<h2>Results</h2>

<p>
<a href="https://shaunlebron.github.io/pacman-mazegen/tetris/many.htm">Click here to see many generated Pac-Man mazes together.</a>
</p>

<h2>Appendix</h2>

<h3>Original Maps</h3>
<p><img src="https://shaunlebron.github.io/pacman-mazegen/img/origmaps_2x.png" width="100%"></p><h3>Original Maps (plain)</h3>
<p><img src="https://shaunlebron.github.io/pacman-mazegen/img/origmaps_2x_print.png" width="100%"></p><h3>Original Maps (paths)</h3>
<p><img src="https://shaunlebron.github.io/pacman-mazegen/img/origmaps_path.png" width="100%">

</p></div></div>]]>
            </description>
            <link>https://shaunlebron.github.io/pacman-mazegen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24603618</guid>
            <pubDate>Sun, 27 Sep 2020 02:01:25 GMT</pubDate>
        </item>
    </channel>
</rss>
