<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 19 Dec 2020 08:38:11 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 19 Dec 2020 08:38:11 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Deprecating Excalidraw Electron in favor of the Web version]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454687">thread link</a>) | @markdog12
<br/>
December 17, 2020 | https://blog.excalidraw.com/deprecating-excalidraw-electron/ | <a href="https://web.archive.org/web/*/https://blog.excalidraw.com/deprecating-excalidraw-electron/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>On the <a href="https://github.com/excalidraw/">Excalidraw project</a>, we have decided to deprecate <a href="https://github.com/excalidraw/excalidraw-desktop">Excalidraw Desktop</a>, an <a href="https://www.electronjs.org/">Electron</a> wrapper for Excalidraw, in favor of the Web version that you can—and always could—find at <a href="https://excalidraw.com/">excalidraw.com</a>. After a careful analysis, we have decided that <a href="https://web.dev/pwa/">Progressive Web App</a> (PWA) is the future we want to build upon. Read on to learn more about our rationale.</p>
<!-- end -->
<h2>How Excalidraw Desktop came into being</h2>
<p>Soon after <a href="https://twitter.com/vjeux">@vjeux</a> had created the initial version of Excalidraw in January 2020 and <a href="https://blog.excalidraw.com/reflections-on-excalidraw/">blogged about it</a>, he proposed the following in <a href="https://github.com/excalidraw/excalidraw/issues/561#issue-555138343">Issue #561</a>:</p>
<blockquote>
<p>“Would be great to wrap Excalidraw within Electron (or equivalent) and publish it as a native application to the various app stores.”</p>
</blockquote>
<p>The immediate reaction by <a href="https://github.com/voluntadpear">@voluntadpear</a> was to suggest:</p>
<blockquote>
<p>“What about making it a PWA instead? Android currently supports adding them to the Play Store as Trusted Web Activities and hopefully iOS will do the same soon. On Desktop, Chrome lets you download a desktop shortcut to a PWA.”</p>
</blockquote>
<p>The decision that <a href="https://github.com/vjeux">@vjeux</a> took in the end was simple:</p>
<blockquote>
<p>“We should do both :)”</p>
</blockquote>
<p>While work on converting the version of Excalidraw into a PWA was started by <a href="https://github.com/voluntadpear">@voluntadpear</a> and later others, <a href="https://github.com/lipis">@lipis</a> independently <a href="https://github.com/excalidraw/excalidraw/issues/561#issuecomment-579573783">went ahead</a> and created a <a href="https://github.com/excalidraw/excalidraw-desktop">separate repo</a> for Excalidraw Desktop.</p>
<p>To this day, the initial goal set by <a href="https://github.com/vjeux">@vjeux</a>, that is, to submit Excalidraw to the various app stores, has not been reached yet. Honestly, no one has even started the submission process to any of the stores. But why is that? Before I try to provide an answer, let me quickly look at Electron, the platform.</p>
<h2>What is Electron?</h2>
<p>The unique selling point of <a href="https://www.electronjs.org/">Electron</a> is that it allows you to <em>“build cross-platform desktop apps with JavaScript, HTML, and CSS”</em>. Apps built with Electron are <em>“compatible with Mac, Windows, and Linux”</em>, that is, <em>“Electron apps build and run on three platforms”</em>. According to the homepage, the hard parts that Electron makes easy are <a href="https://www.electronjs.org/docs/api/auto-updater">automatic updates</a>, <a href="https://www.electronjs.org/docs/api/menu">native menus and notifications</a>, <a href="https://www.electronjs.org/docs/api/crash-reporter">crash reporting</a>, <a href="https://www.electronjs.org/docs/api/content-tracing">debugging and profiling</a>, and <a href="https://www.electronjs.org/docs/api/auto-updater#windows">Windows installers</a>. Turns out, some of the promised features need a detailed look at the small print.</p>
<ul>
<li>For example, automatic updates <em>“are [currently] only [supported] on macOS and Windows. There is no built-in support for auto-updater on Linux, so it is recommended to use the distribution’s package manager to update your app”</em>.</li>
<li>Developers can create native menus by calling <code>Menu.setApplicationMenu(menu)</code>. On Windows and Linux, the menu will be set as each window’s top menu, while on macOS there are many system-defined standard menus, like the <a href="https://developer.apple.com/documentation/appkit/nsapplication/1428608-servicesmenu?language=objc">Services</a> menu. To make one’s menus a standard menu, developers should set their menu’s <code>role</code> accordingly, and Electron will recognize them and make them become standard menus. This means that a lot of menu-related code will make use of the following platform check: <code>const isMac = process.platform === 'darwin'</code>.</li>
<li>Windows installers can be made with <a href="https://github.com/electron/windows-installer">windows-installer</a>. The README of the project highlights that <em>“for a production app you need to sign your application. Internet Explorer’s SmartScreen filter will block your app from being downloaded, and many anti-virus vendors will consider your app as malware unless you obtain a valid cert”</em>.</li>
</ul>
<p>Looking at just these three examples, it is clear that Electron is far from “write once, run everywhere”. Distributing an app on app stores requires <a href="https://www.electronjs.org/docs/tutorial/code-signing">code signing</a>, a security technology for certifying app ownership. Packaging an app requires using tools like <a href="https://github.com/electron-userland/electron-forge">electron-forge</a> and thinking about where to host packages for app updates. It gets complex relatively quickly, especially when the objective truly is cross platform support. I want to note that it is <em>abolutely</em> possible to create stunning Electron apps with enough effort and dedication. For Excalidraw Desktop, we were not there.</p>
<h2>Where Excalidraw Desktop left off</h2>
<p>Excalidraw Desktop so far is basically the Excalidraw Web app bundled as an <a href="https://github.com/electron/asar"><code>.asar</code></a> file with an added <strong>About Excalidraw</strong> window. The look and feel of the application is almost identical to the Web version.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/1d7f7/excalidraw-desktop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Excalidraw Desktop application running in an Electron wrapper." title="The Excalidraw Desktop application running in an Electron wrapper." src="https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/fcda8/excalidraw-desktop.png" srcset="https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/12f09/excalidraw-desktop.png 148w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/e4a3f/excalidraw-desktop.png 295w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/fcda8/excalidraw-desktop.png 590w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/efc66/excalidraw-desktop.png 885w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/c83ae/excalidraw-desktop.png 1180w,
https://blog.excalidraw.com/static/261833dc69ad2e3fc4027bf26fcfd62b/1d7f7/excalidraw-desktop.png 2038w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>Excalidraw Desktop is almost indistinguishable from the Web version</figcaption>
</figure>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/9cab2/about-excalidraw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Excalidraw Desktop 'About' window displaying the version of the Electron wrapper and the Web app." title="The Excalidraw Desktop 'About' window displaying the version of the Electron wrapper and the Web app." src="https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/fcda8/about-excalidraw.png" srcset="https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/12f09/about-excalidraw.png 148w,
https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/e4a3f/about-excalidraw.png 295w,
https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/fcda8/about-excalidraw.png 590w,
https://blog.excalidraw.com/static/a0a6ce646cf65a72e37db3347d329a88/9cab2/about-excalidraw.png 864w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The <strong>About Excalidraw</strong> menu providing insights into the versions</figcaption>
</figure>
<p>On macOS, there is now a native menu at the top of the application, but since none of the menu actions—apart from <strong>Close Window</strong> and <strong>About Excalidraw</strong>—are hooked up to to anything, the menu is, in its current state, pretty useless. Meanwhile, all actions can of course be performed via the regular Excalidraw toolbars and the context menu.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/f941f/menu.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Excalidraw Desktop menu bar on macOS with the 'File', 'Close Window' menu item selected." title="The Excalidraw Desktop menu bar on macOS with the 'File', 'Close Window' menu item selected." src="https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/fcda8/menu.png" srcset="https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/12f09/menu.png 148w,
https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/e4a3f/menu.png 295w,
https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/fcda8/menu.png 590w,
https://blog.excalidraw.com/static/ee571b3d7ed3e69a9d4f98eb59cb29ba/f941f/menu.png 736w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The menu bar of Excalidraw Desktop on macOS</figcaption>
</figure>
<p>We use <a href="https://github.com/electron-userland/electron-builder">electron-builder</a>, which supports <a href="https://www.electron.build/configuration/configuration#PlatformSpecificBuildOptions-fileAssociations">file type associations</a>. By double-clicking an <code>.excalidraw</code> file, ideally the Excalidraw Desktop app should open. The relevant excerpt of our <code>electron-builder.json</code> file looks like this:</p>
<div data-language="json"><pre><code><span>{</span>
  <span>"fileAssociations"</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>"ext"</span><span>:</span> <span>"excalidraw"</span><span>,</span>
      <span>"name"</span><span>:</span> <span>"Excalidraw"</span><span>,</span>
      <span>"description"</span><span>:</span> <span>"Excalidraw file"</span><span>,</span>
      <span>"role"</span><span>:</span> <span>"Editor"</span><span>,</span>
      <span>"mimeType"</span><span>:</span> <span>"application/json"</span>
    <span>}</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>Unfortunately, in practice, this does not always work as intended, since, depending on the installation type (for the current user, for all users), apps on Windows&nbsp;10 do not have the rights to associate a file type to themselves.</p>
<p>These shortcomings and the pending work to make the experience truly native-like on <em>all</em> platforms (which, again, with enough effort <em>is</em> possible) were a strong argument for us to reconsider our investment in Excalidraw Desktop. The way bigger argument for us, though, was that we foresee that for <em>our</em> use case, we do not need all the features Electron offers. The grown and still growing set of capabilities of the Web serves us equally well, if not better.</p>
<h2>How the Web serves us today and in the future</h2>
<p>Even in 2020, <a href="https://jquery.com/">jQuery</a> is still <a href="https://almanac.httparchive.org/en/2020/javascript#libraries">incredibly popular</a>. For many developers it has become a habit to use it, despite the fact that today they <a href="http://youmightnotneedjquery.com/">might not need jQuery</a>. There is a similar resource for Electron, aptly called <a href="https://youmightnotneedelectron.com/">You Might Not Need Electron</a>. Let me outline in the following why we think we do not need Electron.</p>
<h3>Installable Progressive Web App</h3>
<p>Excalidraw today is an <a href="https://web.dev/installable/">installable</a> Progressive Web App with a <a href="https://excalidraw.com/service-worker.js">service worker</a> and a <a href="https://excalidraw.com/manifest.json">Web App Manifest</a>. It caches all its resources in two caches, one for fonts and font-related CSS, and one for everything else.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/49ee2/excalidraw-cache.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Chrome DevTools Application tab showing the two Excalidraw caches." title="Chrome DevTools Application tab showing the two Excalidraw caches." src="https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/fcda8/excalidraw-cache.png" srcset="https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/12f09/excalidraw-cache.png 148w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/e4a3f/excalidraw-cache.png 295w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/fcda8/excalidraw-cache.png 590w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/efc66/excalidraw-cache.png 885w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/c83ae/excalidraw-cache.png 1180w,
https://blog.excalidraw.com/static/6de51f0361ad22fbbb52ebe4a2f48227/49ee2/excalidraw-cache.png 1618w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>Excalidraw's cache contents</figcaption>
</figure>
<p>This means the application is fully offline-capable and can run without a network connection. Chromium-based browsers on both desktop and mobile prompt the user if they want to install the app. You can see the installation prompt in the screenshot below.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/d67fd/install-excalidraw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw prompting the user to install the app in Chrome on macOS." title="Excalidraw prompting the user to install the app in Chrome on macOS." src="https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/fcda8/install-excalidraw.png" srcset="https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/12f09/install-excalidraw.png 148w,
https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/e4a3f/install-excalidraw.png 295w,
https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/fcda8/install-excalidraw.png 590w,
https://blog.excalidraw.com/static/16be4e620446e7da17481d3fd520d6b8/d67fd/install-excalidraw.png 670w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw install dialog in Chrome</figcaption>
</figure>
<p>Excalidraw is configured to run as a standalone application, so when you install it, you get an app that runs in its own window. It is fully integrated in the operating system’s multitasking UI and gets its own app icon on the home screen, Dock, or task bar; depending on what platform you install it.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/d8d63/excalidraw-pwa.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw running in its own window." title="Excalidraw running in its own window." src="https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/fcda8/excalidraw-pwa.png" srcset="https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/12f09/excalidraw-pwa.png 148w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/e4a3f/excalidraw-pwa.png 295w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/fcda8/excalidraw-pwa.png 590w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/efc66/excalidraw-pwa.png 885w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/c83ae/excalidraw-pwa.png 1180w,
https://blog.excalidraw.com/static/dd69b46d69578ef7d0a8020d1f649bf1/d8d63/excalidraw-pwa.png 2026w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw PWA in a standalone window</figcaption>
</figure>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/076ca/excalidraw-icon.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw icon on the macOS Dock." title="Excalidraw icon on the macOS Dock." src="https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/fcda8/excalidraw-icon.png" srcset="https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/12f09/excalidraw-icon.png 148w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/e4a3f/excalidraw-icon.png 295w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/fcda8/excalidraw-icon.png 590w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/efc66/excalidraw-icon.png 885w,
https://blog.excalidraw.com/static/1769e90d9bfd53401cf1590b5f8926d5/076ca/excalidraw-icon.png 914w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw icon on the macOS Dock</figcaption>
</figure>
<h3>File system access</h3>
<p>Excalidraw makes use of <a href="https://github.com/GoogleChromeLabs/browser-nativefs">browser-nativefs</a> for accessing the file system of the operating system. On supporting browsers, this allows for a true open→edit→save workflow and actual over-saving and “save as”, with a transparent fallback for other browsers. You can learn more about this feature in my blog post <a href="https://blog.excalidraw.com/browser-nativefs/">Reading and writing files and directories with the browser-nativefs library</a>.</p>
<h3>Drag and drop support</h3>
<p>Files can be dragged and dropped onto the Excalidraw window just as in native applications. On a browser that supports the <a href="https://web.dev/file-system-access/">File System Access API</a>, a dropped file can be immediately edited and the modifications be saved to the original file. This is so intuitive that you sometimes forget that you are dealing with a Web app.</p>
<h3>Clipboard access</h3>
<p>Excalidraw works well with the operating system’s clipboard. Entire Excalidraw drawings or also just individual objects can be copied and pasted in <code>image/png</code> and <code>image/svg+xml</code> formats, allowing for an easy integration with other native tools like <a href="https://inkscape.org/">Inkscape</a> or Web-based tools like <a href="https://jakearchibald.github.io/svgomg/">SVGOMG</a>.</p>
<figure>
  <span>
      <a href="https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/906b5/clipboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Excalidraw context menu showing the 'copy to clipboard as SVG' and 'copy to clipboard as PNG' menu items." title="Excalidraw context menu showing the 'copy to clipboard as SVG' and 'copy to clipboard as PNG' menu items." src="https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/fcda8/clipboard.png" srcset="https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/12f09/clipboard.png 148w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/e4a3f/clipboard.png 295w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/fcda8/clipboard.png 590w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/efc66/clipboard.png 885w,
https://blog.excalidraw.com/static/9fdb4575d0cdafbc5baa6cf8c9530117/906b5/clipboard.png 950w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
  <figcaption>The Excalidraw context menu offering clipboard actions</figcaption>
</figure>
<h3>File handling</h3>
<p>Excalidraw already supports the experimental <a href="https://web.dev/file-handling/">File Handling API</a>, which means <code>.excalidraw</code> files can be double-clicked in the operating system’s file manager and open directly in the Excalidraw app, since Excalidraw registers as a file handler for <code>.excalidraw</code> files in the operating system.</p>
<h3>Declarative link capturing</h3>
<p>Excalidraw drawings can be shared by link—here is an <a href="https://excalidraw.com/#json=4646308765761536,jwZJW8JsOM75vdhqG2nBgA">example</a>. In the future, if people have Excalidraw installed as a PWA, such links will not open in a browser tab, but launch a new standalone window. This will work thanks to <a href="https://github.com/WICG/sw-launch/blob/master/declarative_link_capturing.md">declarative link capturing</a>, an, at the time of writing, bleeding-edge proposal for a new Web platform feature.</p>
<h2>Conclusion</h2>
<p>The Web has come a long way, with more and more features landing in browsers that only a couple of years or even months ago were unthinkable on the Web and exclusive to native applications. Excalidraw is at the forefront of what is possible in the browser, all while acknowledging that not all browsers on all platforms support each feature we make use of. By betting on a progressive enhancement strategy, we enjoy the latest and greatest wherever possible, but without leaving anyone behind. Best viewed in <em>any</em> browser.</p>
<p>Electron has served us well, but in 2020 and beyond, we can live without it. Oh, and for that objective of <a href="https://github/com/vjeux">@vjeux</a>: since the Android Play Store now accepts PWAs in a container format called <a href="https://web.dev/using-a-pwa-in-your-android-app/">Trusted Web Activity</a> and since the <a href="https://docs.microsoft.com/en-us/microsoft-edge/progressive-web-apps-edgehtml/microsoft-store">Microsoft Store supports PWAs</a>, too, you can expect Excalidraw in these stores in the not too distant future. Meanwhile, you can always use and install <a href="https://excalidraw.com/">Excalidraw in and from the browser</a>.</p></div></div>]]>
            </description>
            <link>https://blog.excalidraw.com/deprecating-excalidraw-electron/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454687</guid>
            <pubDate>Thu, 17 Dec 2020 11:42:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React vs. Angular vs. Vue]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454595">thread link</a>) | @oczek
<br/>
December 17, 2020 | https://blog.graphqleditor.com/react-angular-vue/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/react-angular-vue/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>After looking at the features, components and libraries for Vue, React and Angular it’s time to do an actual comparison of the three. While in terms of popularity React is still top there are substantial differences in where each of the frameworks excels. So even if you’re already committed to one (or want to switch) it’s probably a good idea to check out exactly how they measure up against each other in a few key aspects.</p>
<h2>Basics</h2>
<p>Before we get to the meat it’s probably prudent to point out what these differences stem from. Each of the three frameworks has a different approach to development and aims at helping devs in a different way. <strong>React and Angular are developed by big companies</strong> namely Facebook and Google while <strong>Vue has started as a side project</strong> of a Google developer. While all are JavaScript based, each presents a slightly different syntax approach. React uses JavaScript and JSX (which combines HTML and JavaScript logic), Angular uses TypeScript (HTML and TypeScript logic is split) Vue uses JavaScript (HTML and JavaScript logic is split). All of them are component-driven, but they treat coding them differently along with a number of default features included.</p>
<ul>
<li><strong>React</strong> combines the UI and behavior of components, the same code is responsible for both creating a UI component and dictating its behavior. </li>
<li><strong>Vue</strong> takes the same approach and even lets you combine the UI and behavior of components from within a script. </li>
<li><strong>Angular</strong> completely separates the two, the UI parts of components are attributes of HTML tags while their behaviors are in the form of JavaScript code. </li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Components</th>
<th>Lang</th>
<th>Built-in features</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>React</strong></td>
<td><em>same code is responsible for UI &amp; logic</em></td>
<td><em>JavaScript/JSX</em></td>
<td><em>low amount</em></td>
</tr>
<tr>
<td><strong>Angular</strong></td>
<td><em>components’ UI &amp; logic are completely separated</em></td>
<td><em>TypeScript</em></td>
<td><em>high amount</em></td>
</tr>
<tr>
<td><strong>Vue</strong></td>
<td><em>same code is responsible for UI &amp; logic</em></td>
<td><em>JavaScript</em></td>
<td><em>fair amount</em></td>
</tr>
</tbody>
</table>
<h2>Learning curve</h2>
<p>Finally the main difference in approach is probably the learning curve. Vue is the easiest to learn and can even serve as a stepping stone for learning the two others, as there is some overlap especially in handling components. Simplicity and customizability obviously have their advantages, but there are also some drawbacks as it makes it somewhat difficult to debug and test. React is middle of the road, it is harder to get into but has great documentation and an easy to follow starting guide. The drawback is it does require use of third party libraries for more complex stuff. This makes the learning curve not so steep but highly dependent on what you actually want to do and what third party libraries you’ll need to learn to do it. Angular is the complete framework, but also has the steepest learning curve requiring learning TypeScript, RxJS and MVC. The investment of time and effort may prove well worth it as mastering it will make building your app a breeze.</p>
<p><span>
      <a href="https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/e3189/charts.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Popularity of React, Vue, Angular" title="Popularity of React, Vue, Angular" src="https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/fcda8/charts.png" srcset="https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/12f09/charts.png 148w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/e4a3f/charts.png 295w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/fcda8/charts.png 590w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/efc66/charts.png 885w,
https://blog.graphqleditor.com/static/256ae861e92cff3c9bed714f84a188e0/e3189/charts.png 1035w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h2>Minimalism vs all-in-one</h2>
<p>Approach and philosophy are important and all but that’s mostly just the pitch. For a clearer picture it’s better to look at the features. As mentioned above React takes a minimalistic approach here, it provides you with a library for rendering content to the DOM. It does provide some rudimentary built-in state management support but you’ll likely need to use a state management library like Redux (which is fortunately quite easy to learn). There aren’t any other special features and if you need some other functionalities you’ll need to check out community provided solutions. That does make it a lot slimmer than the other two, but can be a hassle if you’re working on a complex project and looking to get started from the get go. Vue is the middle ground, it provides some features, but isn’t the complete package Angular is. You get built in state management as well as a built-in router. Though for form validation you’ll need something like the Vuelidate library and a library for Http client functions (there’s quite a few to choose from) Angular gives you all these features out of the box and more, there’s an official CLI which helps building, managing, updating and deploying projects even easier.</p>
<table>
<thead>
<tr>
<th></th>
<th>React</th>
<th>Angular</th>
<th>Vue</th>
</tr>
</thead>
<tbody>
<tr>
<td>Backed by</td>
<td><em>Facebook</em></td>
<td><em>Google</em></td>
<td><em>Evan You</em></td>
</tr>
<tr>
<td>Release date</td>
<td><em>2013</em></td>
<td><em>2016</em></td>
<td><em>2014</em></td>
</tr>
<tr>
<td>Lang</td>
<td><em>JavaScript</em></td>
<td><em>TypeScript</em></td>
<td><em>JavaScript</em></td>
</tr>
<tr>
<td>Learning curve</td>
<td><em>medium</em></td>
<td><em>hard</em></td>
<td><em>easy</em></td>
</tr>
<tr>
<td>Documnation</td>
<td><em>good</em></td>
<td><em>good</em></td>
<td><em>good</em></td>
</tr>
<tr>
<td>Features</td>
<td><em>external libraries</em></td>
<td><em>all-in-one</em></td>
<td><em>most-in-one</em></td>
</tr>
<tr>
<td>Production-ready</td>
<td><em>yes</em></td>
<td><em>yes</em></td>
<td><em>yes</em></td>
</tr>
</tbody>
</table>
<h2>Less is more</h2>
<p>The thought that comes to mind is probably, why not go with Angular, after all it has the most features. Well more isn’t always better and as mentioned the steep learning curve can be a turnoff especially if you’re looking to get started right away or working on projects requiring less complex solutions out of the box. Oh and emphasis on ‘out-of-the-box’ here, it’s not like Vue and React are useless when it comes to features. Just the opposite, they’re freely available to you when you need them, you just need to reach out to the community instead of getting them built-in with the framework. As you can see it comes to personal preference and focusing on what fits you best now and what might fit you best in the future, hopefully this little piece helped with that at least a little bit.</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/react-angular-vue/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454595</guid>
            <pubDate>Thu, 17 Dec 2020 11:27:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Covid-19 Pandemic and the Art of Geo Time Series]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25454448">thread link</a>) | @MorganeR
<br/>
December 17, 2020 | https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
<p>As <a rel="noreferrer noopener" href="https://senx.io/" target="_blank">SenX</a> enters its second week of remote work, I thought it would be a good time to write about the importance of time and <a href="https://blog.senx.io/working-with-geo-data-in-warp-10/" target="_blank" rel="noreferrer noopener">geo time series</a> during a pandemic like the one we are experiencing with the coronavirus and the associated COVID-19.</p>



<p>For millions if not billions of people on Earth, <strong>some time series has become the most important thing to look at.</strong> Whether it is the #FlattenTheCurve graph or the Hammer and the dance illustration, or the various graphs showing the evolution of the number of cases, recovering patients, and unfortunately deaths, those are all-time series, i.e. graphs whose x-axis represents the time and the y-axis the evolution of tracked quantities.</p>



<figure><img src="https://media.wired.com/photos/5e6aac7295ff060008467cf9/master/w_1600%2Cc_limit/Science_Covid19-Infographic.jpg" alt="Coronavirus COVID-19 #FlattenTheCurve strategy"><figcaption>#FlattenTheCurve</figcaption></figure>



<h2>Contact Tracing</h2>



<p>But another trend about to begin will bring people exposed even more to time series. As the world learns how countries such as Singapore, South Korea, or Taiwan have dealt with the COVID-19 outbreak, the notion of <a href="https://en.wikipedia.org/wiki/Contact_tracing" target="_blank" rel="noreferrer noopener">Contact Tracing</a> has appeared in the media and will soon be in everybody's mouth.</p>



<p>The reaction to that notion, which is widely used in public health but may appear new to many, varies from country to country, and among countries varies with culture, political background, or religious belief. Some are considering it as the end of privacy and liberty. The others as a salvation technique or more moderate ones as a good temporary tactic for fighting the outbreak.</p>



<h3>But what exactly is contact tracing? </h3>



<p>The idea is very simple. It keeps a log of who you came close to so when someone gets tested positive with COVID-19 his or her log can be accessed. The people appearing in the log can be contacted to test them too. Logs used to be your memory, now with the advent of technology they can be tracked automatically.</p>



<p>By relying on those automated logs, the sphere of contagion of the newly discovered patient can easily be determined from the patient's own log and from those of the people that were in contact with that patient with the same process being extended as individuals are tested positive.</p>



<h3>How are the people you came in contact with identified? </h3>



<p>Well, that is rather simple, with the help of technology. Contact tracing relies on a mobile app which exploits the <strong>Bluetooth signal of the phone</strong> it is installed on. Bluetooth is a short-range radio system. It means that it cannot be transmitted more than a few meters. So technically if you can receive the Bluetooth signal from another phone, then this phone is in the vicinity of yours. </p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D9855&amp;text=Due%20to%20COVID-19%2C%20for%20millions%20of%20people%2C%20some%20time%20series%20has%20become%20the%20most%20important%20thing%20to%20look%20at.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Due to COVID-19, for millions of people, some time series has become the most important thing to look at. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D9855&amp;text=Due%20to%20COVID-19%2C%20for%20millions%20of%20people%2C%20some%20time%20series%20has%20become%20the%20most%20important%20thing%20to%20look%20at.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>When that happens, the mobile application adds an entry to its log, saying it saw a signal from another application. The id logged is a random id that is assigned to your phone at the time you installed the app. <strong>Only the organization responsible for the application can associate this random id with your phone number</strong>. So yes, you should trust this organization for willing to not do evil.</p>



<p>That is all there is to it, contact tracing in a few paragraphs. </p>



<h3>Back to our own topic now </h3>



<p>The log kept by the contact tracing application has one important component, <strong>the timestamping</strong> of the entries. Because if you came in contact with someone more than 21 days ago (roughly the longest incubation period for COVID-19), then there is no need to contact that person as you were probably not contagious when you two came close. So yes, the base of contact tracing is recording time series and later analyzing them to reconstruct a timed graph of interactions.</p>



<figure></figure>



<h2>What about Warp 10?</h2>



<p><a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10</a> is our advanced time series platform. It can be used to analyze those time series, even at a large scale, at the scale of a whole population if need be. So any agency willing to put contact tracing in place should contact us, we can help.</p>



<p>Note that beyond the contact tracing some countries have used in the case of the COVID-19 pandemic, there might be some other situations where more information may need to be collected, most notably actual location data when a pathogen agent is really contagious and can stay in the environment and spread without human to human contact. In that case, besides obvious debates about privacy or lack thereof that would be legitimate to have, the data collected are no longer simply time series but geo time series. And there again Warp 10 can help to analyze them.</p>



<p>The weeks to come will undoubtedly bring on the table the question of contact tracing. I hope this article helped you understand better how it works. The social implication of contact tracing will need to be balanced with the benefit that it can bring to fighting the ongoing pandemic. When those debates will have settled, remember that technology such as Warp 10 can help analyze those data fast.</p>



<p><strong>Keep safe, stay at home!</strong></p>



<p>The Ministry of Health of Singapore just announced it would be open-sourcing its own contact tracing application is used for fighting the COVID-19 outbreak.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/the-covid-19-pandemic-and-the-art-of-geo-time-series/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454448</guid>
            <pubDate>Thu, 17 Dec 2020 10:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[51% of 4M Docker images have critical vulnerabilities]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25454207">thread link</a>) | @AnnieNma
<br/>
December 17, 2020 | https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/ | <a href="https://web.archive.org/web/*/https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thechief.io/c/news/51-4-million-docker-images-have-critical-vulnerabilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454207</guid>
            <pubDate>Thu, 17 Dec 2020 10:09:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to debug Elixir/Erlang compiler performance]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25454147">thread link</a>) | @wojtekmach
<br/>
December 17, 2020 | https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> December 15th, 2020
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/compiler">compiler</a>, <a href="https://dashbit.co/blog/tags/performance">performance</a>
  </li>
</ul>
<p>
Recently someone opened up an <a href="https://github.com/elixir-gettext">issue on Gettext</a> saying compilation of Gettext modules got slower in Erlang/OTP 23. In this article, we are going to explore how I have debugged this problem and the three separate pull requests sent to the Erlang/OTP repository to improve compiler performance.</p>
<p>
For those not familar, the Gettext project converts <code>.po</code> files like this:</p>
<pre><code># pt
msgid "Hello world"
msgstr "Olá mundo"

# pl
msgid "Hello world"
msgstr "Witaj świecie"</code></pre>
<p>
Into a module with functions:</p>
<pre><code><span>def</span><span> </span><span>translate</span><span data-group-id="9576884584-1">(</span><span>"pt"</span><span>,</span><span> </span><span>"Hello world"</span><span data-group-id="9576884584-1">)</span><span>,</span><span> </span><span>do</span><span>:</span><span> </span><span>"Olá mundo"</span><span>
</span><span>def</span><span> </span><span>translate</span><span data-group-id="9576884584-2">(</span><span>"pl"</span><span>,</span><span> </span><span>"Hello world"</span><span data-group-id="9576884584-2">)</span><span>,</span><span> </span><span>do</span><span>:</span><span> </span><span>"Witaj świecie"</span></code></pre>
<p>
While we start with an Elixir application, we end-up doing most of the work with the Erlang compiler and tools, so most of the lessons here are applicable to the wider ecosystem. Be sure to read until the end for a welcome surprise.</p>
<h2>
Isolating the slow file</h2>
<p>
When project compilation is slow, the first step is to identify which files are slow. In Elixir v1.11, this can be done like this:</p>
<pre><code>$ mix compile --force --profile time</code></pre>
<p>
The command above will print:</p>
<pre><code>...
[profile] lib/ecto/query/planner.ex compiled in 1376ms (plus 596ms waiting)
[profile] lib/ecto/association.ex compiled in 904ms (plus 1168ms waiting)
[profile] lib/ecto/changeset.ex compiled in 869ms (plus 1301ms waiting)
[profile] Finished compilation cycle of 95 modules in 2579ms
[profile] Finished group pass check of 95 modules in 104ms</code></pre>
<p>
Compilation of each file in your project is done in parallel. The overall message is:</p>
<pre><code>[profile] FILE compiled in COMPILE_TIME (plus WAITING_TIME waiting)</code></pre>
<p>
<code>COMPILE_TIME</code> is the time we were effectively compiling code. However, since a file may depend on a module defined in another file, <code>WAITING_TIME</code> is the time we wait until the file we depend on becomes available. High waiting times are not usually a concern, so we focus on the files with high compilation times.</p>
<p>
At the end, we print two summaries:</p>
<pre><code>[profile] Finished compilation cycle of 95 modules in 2579ms
[profile] Finished group pass check of 95 modules in 104ms</code></pre>
<p>
The first includes the time to compile all files in parallel and includes how many modules have been defined. The second is the time to execute a group pass which looks at all modules at once, in order to find undefined functions, emit deprecations, etc.</p>
<p>
Unless the “group pass check” is the slow one - which would be a bug in the Elixir compiler - we are often looking at a single file being the root cause of slow compilation. With this file in hand, it is time to dig deeper.</p>
<h2>
Timing the slow file</h2>
<p>
Once we have identified the slow file, we need to understand why it is slow. When Elixir compiles a file, it executes code at three distinct stages. For example, let’s assume the slow down was in <code>lib/problematic_file.ex</code> that looks like this:</p>
<pre><code><span># FILE LEVEL</span><span>
</span><span>defmodule</span><span> </span><span>ProblematicModule</span><span> </span><span data-group-id="0623758596-1">do</span><span>
  </span><span># MODULE LEVEL</span><span>
  </span><span>def</span><span> </span><span>function</span><span> </span><span data-group-id="0623758596-2">do</span><span>
    </span><span># FUNCTION LEVEL</span><span>
  </span><span data-group-id="0623758596-2">end</span><span>
</span><span data-group-id="0623758596-1">end</span></code></pre>
<p>
When compiling the file above, Elixir will execute each level in order. If that file has multiple modules, then compilation will happen for each module in the file, first at MODULE LEVEL and then FUNCTION LEVEL.</p>
<blockquote>
  <p>
TIP: If a file with multiple modules is slow, I suggest breaking those modules into separate files and repeating the steps in the previous section.  </p>
</blockquote>
<p>
With this knowledge in hand, we want to compile the file once again, but now passing the <code>ERL_COMPILER_OPTIONS=time</code> flag to the underlying Erlang compiler, which will print time reports. One option is to do this:</p>
<pre><code>$ mix compile
$ touch lib/problematic_file.ex
$ ERL_COMPILER_OPTIONS=time mix compile</code></pre>
<p>
Then, for each module being compiled (which includes the one in your <code>mix.exs</code>), you will see a report like this:</p>
<pre><code>core             :  0.653 s   72136.4 kB
sys_core_fold    :  0.482 s   69055.3 kB
sys_core_alias   :  0.146 s   69055.3 kB
core_transforms  :  0.000 s   69055.3 kB
sys_core_bsm     :  0.098 s   69055.3 kB
v3_kernel        :  2.250 s  169439.0 kB</code></pre>
<p>
Most compilers work by doing multiple passes on your code. Above we can see how much time was spent on each pass and how much memory the code representation, also known as Abstract Syntax Tree (AST), takes after each pass.</p>
<p>
The <code>ERL_COMPILER_OPTIONS=time mix compile</code> command above has one issue though. If other files depend on the problematic file, they may be recompiled too, and that will add noise to your output. If that’s the case, you can also do this:</p>
<pre><code>$ ERL_COMPILER_OPTIONS=time mix run lib/problematic_file.ex</code></pre>
<p>
This is a rather neat trick: we are re-running a file that we have just compiled. You will get warnings about modules being redefined but they are safe to ignore.</p>
<p>
With the time reports in hand, there are two possible scenarios here:</p>
<ol>
  <li>
    <p>
One (or several) of the passes in the report are slow. This means the slow down happens when compiling at the FUNCTION LEVEL and it will be associated with the generation of the <code>.beam</code> file for <code>ProblematicModule</code>    </p>
  </li>
  <li>
    <p>
All passes are fast and the slow down happens before the reports emitted by <code>ERL_COMPILER_OPTIONS=time</code> are printed. If this is the case, the slowdown is actually happening at the MODULE LEVEL, before the generation of the <code>.beam</code> file    </p>
  </li>
</ol>
<p>
Most times, the slowdown is actually at the FUNCTION LEVEL, including the one reported as a Gettext issue, so that’s the one we will explore. Performance issues at the MODULE LEVEL may still happen though, especially in large module bodies as seen in Phoenix’s Router - but don’t worry, those have often already been optimized throughout the years!</p>
<h2>
Moving to Erlang</h2>
<p>
At this point, we have found a module that is slow to compile. Given the original Gettext issue pointed to a difference of performance between Erlang versions, my next step is to remove Elixir from the equation.</p>
<p>
Luckily, this is very easy to do with the <a href="https://github.com/michalmuskala/decompile">decompile</a> project:</p>
<pre><code>$ mix archive.install github michalmuskala/decompile
$ mix decompile ProblematicModule --to erl</code></pre>
<p>
This command will emit a <code>Elixir.ProblematicModule.erl</code> file, which is literally the compiled Elixir code, represented in Erlang. Now, let’s compile it again, but without involving Elixir at all:</p>
<pre><code>$ erlc +time Elixir.ProblematicModule.erl</code></pre>
<blockquote>
  <p>
TIP: the command above may not work out of the box. That’s because the <code>.erl</code> file generated by <code>decompile</code> may have invalid syntax. In those cases, you can manually fix those errors. They are often small nits.  </p>
</blockquote>
<p>
If you want to try it yourself, you can <a href="https://gist.github.com/josevalim/694c1799143fcf25e43aa27e3e11e4c1">find the <code>.erl</code> file for the Gettext report here</a>:</p>
<pre><code>$ erlc +time Elixir.GettextCompile.Gettext.erl</code></pre>
<p>
Here are the relevant snippets of the report I got on my machine:</p>
<pre><code>...
expand_records         :      0.065 s   19988.0 kB
core                   :      3.295 s  373293.3 kB
...
beam_ssa_bool          :      1.125 s   39252.7 kB
...
beam_ssa_bsm           :      2.432 s   39263.1 kB
   ...
beam_ssa_funs          :      0.119 s   39263.1 kB
beam_ssa_opt           :      6.242 s   39298.0 kB
   ...
...
beam_ssa_pre_codegen   :      3.426 s   48897.5 kB
   ...
...</code></pre>
<p>
Looking at the report you can start building an intuition about which passes are slow. Given we were also told the code compiled fast on Erlang/OTP 22.3, I compiled the same file with that Erlang version and compared the reports side by side. Here are my notes:</p>
<ol>
  <li>
    <p>
The <code>core</code> pass got considerably slower between Erlang/OTP versions (from 1.8s to 3.2s)    </p>
  </li>
  <li>
    <p>
Going from the <code>expand_records</code> pass to <code>core</code> increases the memory usage by almost 20 times (although this behaviour was also there on Erlang/OTP 22)    </p>
  </li>
  <li>
    <p>
The <code>beam_ssa_bool</code> did not exist on Erlang/OTP 22    </p>
  </li>
</ol>
<p>
In Erlang/OTP 22.3, the module takes 22 seconds to compile. On version 23.1, it takes 32 seconds. We have some notes and a reasonable target of 22 seconds to optimize towards. Let’s get to work.</p>
<blockquote>
  <p>
Note: it is worth saying that it is very natural for new passes to be added and others to be removed between Erlang/OTP versions, precisely because the compiler is getting smarter all the time! As part of this process, some passes get faster and others get slower. Such is life. :)  </p>
</blockquote>
<h2>
Pull request #1: the profiler option</h2>
<p>
The Erlang compiler also has a neat feature that alows us to profile any compiler pass. Since we have detected the slow down in the <code>core</code> file, let’s profile it:</p>
<pre><code>$ erlc +'{eprof, core}' Elixir.ProblematicModule.erl</code></pre>
<p>
It will print a report like this:</p>
<pre><code>core: Running eprof

****** Process &lt;0.111.0&gt;    -- 100.00 % of profiled time ***
FUNCTION                   CALLS        %      TIME  [uS / CALLS]
--------                   -----  -------      ----  [----------]
gen:do_for_proc/2              1     0.00         0  [      0.00]
gen:'-call/4-fun-0-'/4         1     0.00         0  [      0.00]
v3_core:unforce/2              2     0.00         0  [      0.00]
v3_core:make_bool_switch/5     2     0.00         0  [      0.00]
v3_core:expr_map/4             1     0.00         0  [      0.00]
v3_core:safe_map/2             1     0.00         0  [      0.00]</code></pre>
<p>
With the slowest entries coming at the bottom. In this Gettext module, the slowest entry was:</p>
<pre><code>cerl_trees:mapfold/4     3220377    19.14   2447684  [      0.76]</code></pre>
<p>
Jackpot! 20% of the compilation time was spent on a single function. This is a great opportunity for optimization.</p>
<p>
I usually like to say there are two types of performance improvements. You have semantic improvements, which you can only pull off by having a grasp of the domain. The more you understand, the more likely you are to be able to come up with an improved algorithm (or the more you will be certain you are already implementing the state of the art). There are also mechanical improvements, which are more about how the runtime and the data structures in the language work. Often you work with a mixture of both.</p>
<p>
In this case, the function <code>cerl_trees:mapfold/4</code> is a function that traverses all AST nodes recursively. You can also see it was called more than 3 million times. The <a href="https://github.com/erlang/otp/blob/db13f8883721c7a217a80cb2c73a1e419f462d83/lib/compiler/src/v3_core.erl#L3040">caller of this function in the <code>core</code> pass has the following goal</a>:</p>
<blockquote>
  <p></p></blockquote></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance">https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/how-to-debug-elixir-erlang-compiler-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25454147</guid>
            <pubDate>Thu, 17 Dec 2020 09:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crypto in Layman's Terms]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453703">thread link</a>) | @alex_portabella
<br/>
December 17, 2020 | https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/ | <a href="https://web.archive.org/web/*/https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This is a post I've been wanting to write for a while now. I want to put down in layman's terms what various cryptographic operations represent, and common use cases for them. When designing large systems we don't need to get bogged down in details of how a Diffie-Hellman handshake works, what we need are abstractions, patterns and black boxes we can effectively use together and reason about.</p><p>With this post I hope to present terms you may or may not have heard before, hopefully with a few examples, one for anyone to understand and at least one for developers to understand.</p><p>Before we go any further it's worth mentioning the old adage - never roll your own crypto. Always build on proven, audited libraries and preferably get the implementation looked at by someone who knows what they're doing. Cryptographic operations can fail (often silently) in unpredictable ways, leaving you stuck with the assumption that what you've built is secure, when it's really not.</p><div><h2 id="hashing">Hashing</h2><p>Hashing has many, many use cases in the digital world. For our purposes it can be easiest to explain hashing as a deep check for equality. Given two things (files, sentences, words, images) how do we ascertain that they are identical? This can be hard to reason about outside of computing because almost never are two items perfectly equal.</p><h5 id="in-a-system">In a system</h5><p>The most common use case almost all of us will be familiar with is password hashing. When users enter their password we don’t want to store that in plaintext, if a database of raw user passwords was leaked it’d be catastrophic. What we do instead is hash the password and store that. If the database is ever leaked the user passwords can’t be reversed from the hash.</p><p>I don’t need to provide another example for hashing because it’s so common, however let’s briefly look at how we might leverage hashing to build a custom image caching system. When we browse user profiles on a mobile application, the mobile application (hopefully) doesn’t fetch the images every time you see the image. What it <em>could</em> do, to save bandwidth, is just send the hash of the current image to the server. The server checks if this hash matches the hash of the latest upload, and only sends the new image if it doesn’t match, meaning the clients version is outdated.</p><h2 id="symmetric-encryption">Symmetric encryption</h2><p>Symmetric encryption is something most of us are probably familiar with, however if not, it’s simply the act of encrypting something with a key. If you don’t have the key, you can’t decrypt the data.</p><p>A good analogy can be to liken symmetric encryption with a safe. It’s big, heavy and you know whatever’s in there is going to be private. If you’ve got the combination - awesome - you’ve got full access to it. If not, you’re out of luck and you’re gonna have to try break it open.</p><h5 id="in-a-system-1">In a system</h5><p>As a practical example of symmetric encryption in a wider digital system, imagine you want to save data in the cloud. You’ve run out of space on your laptop and want to use Dropbox to store your data. Just sending your data to Dropbox is a recipe for disaster, anyone at Dropbox would be able to view your private information. However if you generate a symmetric key and encrypt your data with it before sending it to Dropbox, you know no one else is going to be able to see it.</p><h2 id="asymmetric-encryption">Asymmetric encryption</h2><p>Asymmetric encryption is a really powerful concept we can model entire systems around. It all boils down to there being a different key for encryption and decryption.</p><p>As a simple example, let’s liken asymmetric encryption to a letterbox. With a letterbox anyone can put mail in it, however only people with the key can read said mail. This is at odds with symmetric encryption from our previous example, where you need the key to put anything into the box.</p><h5 id="in-a-system-2">In a system</h5><p>I’ve struggled here to just pick one example to explore, but perhaps the most relevant is encrypted communication. With asymmetric encryption you have a public key (this is what others see, like the name on your letterbox) and you have a private key (like the name suggests, this one should be kept secret - otherwise anyone could open your letterbox). When two users want to communicate securely they simply encrypt their messages to the recipients public key. Now no one else other than those two can read their messages. To spell this out:</p><ul><li>User B (recipient) publishes their public key</li><li>User A (sender) encrypts a message to B’s public key</li><li>User A sends the encrypted message to B</li><li>User B receives the message and decrypts it with their private key.</li></ul><h2 id="signatures">Signatures</h2><p>Another great aspect of asymmetric cryptography is the ability to provide proof that a message came from someone in particular. To use the mail analogy again, this can be thought of as a stamp on the letter. You know that only Steve has the stamp “Steve’s stamp”, so you can trust any letter with this to be from him.</p><h5 id="in-a-system-3">In a system</h5><p>Digital signatures are used almost everywhere in the internet today. In the context of cryptocurrency and blockchains, every transaction you send it accompanied by a signature over the payload you’re sending - asserting that it came from you.</p><p>Let’s also take a moment to think about internal or external communication between various services you’ve written. How do you know when a request comes from your payments service that it’s really your payments service sending this message? When a user of your website does an action (buying an item, for example), how do you tie that action to the right user?</p><p>A common solution is signed payloads, <a href="https://jwt.io/">JSON Web Tokens</a> being a popular specification to follow. A session token is any many aspects just a signature over some payload you’ve provided, an assertion that at some point this user authenticated with you. A basic user authentication flow might go:</p><ul><li>User sends you their username and password</li><li>You verify that the password hash matches the saved hash for this username</li><li>You generate a signed payload that includes their unique ID and potentially anything else you don’t want to have to read from the database for every request.</li></ul><p>Now every request that comes to your server can just verify the signature provided, and you allow them access to the system based on that.</p><h2 id="blind-signatures">Blind Signatures</h2><p>A blind signature is one where the signer doesn’t need to about the contents of the message. This can be hard to reason about but one simple example is in an election voting situation. Alice comes in to vote and proves her identity to the officials at the location. After voting (her choice remains a secret) she hands the sealed envelope to the official, who signs and submits it. In this case the signer has no idea what choice Alice has made, however later at the vote counting station we can verify that this envelope is valid because it was signed by an official.</p><h5 id="in-a-system-4">In a system</h5><p>We could improve upon the above voting example and think about payments. Imagine we’re wanting to make a payment somewhere and not have the merchant know our identity, this is where we could leverage blind signatures to make transactions privately.</p><ol><li>We go to the bank and ask for a cheque for $100</li><li>We take this cheque and send our order to a shop (anonymously), asking for $100 worth of goods</li><li>The shop can verify this blind signature with the bank and send our goods to our specified address</li><li>We’ve successfully completed a purchase without either the bank knowing what we’re buying, or the merchant knowing who we are.</li></ol><h2 id="secret-sharing">Secret sharing</h2><p>I’ve wracked my brain for hours trying to think of a good analogy for secret sharing, but I wasn’t able to come up with one. Essentially it comes down to (what seems like) magic, you and another party are able to agree on something without ever communicating, it’s pretty cool.</p><p>What we’re talking about here are Diffie-Hellman key exchanges. They underpin almost all modern communication. Most of your browser traffic these days is secured via TLS (which implies some kind of key exchange between your browser and the server) however I’d like to explore another cool use case in the context of privacy preserving applications.</p><p>Before we dive into the example, at the highest level a Diffie-Hellman key exchange works as follows:</p><ul><li><code>DH(Alice's public key, Bob's private key) = shared_secret</code></li><li><code>DH(Bob's public key, Alice's private key) = shared_secret</code></li></ul><p>This <code>shared_secret</code> is only computable by Alice and Bob, no one else would be able to figure it out.</p><h5 id="a-use-case">A use case</h5><p>Let’s explore how we could build a privacy preserving messaging platform using a centralised database. At its most basic (and totally open) a message between two parties would look like this:</p><table><thead><tr><th>from</th><th>to</th><th>payload</th></tr></thead><tbody><tr><td>Alice</td><td>Bob</td><td>Hi!</td></tr><tr><td>Bob</td><td>Alice</td><td>Hey! What’s up?</td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr></tbody></table><p>This is how most applications have been built for the last twenty years. Maybe data is encrypted at rest, but in my experience working at software companies encryption at rest means nothing, every employee still has access to this data on demand, in the worst case it’s a Jira ticket away.</p><p>Step one in our privacy preserving journey is to encrypt the data swapped between parties, Alice encrypts messages to Bob’s public key and vice-versa. Now we as the providers of this service can’t see the data being swapped:</p><table><thead><tr><th>from</th><th>to</th><th>payload</th></tr></thead><tbody><tr><td>Alice</td><td>Bob</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>Bob</td><td>Alice</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr><tr><td>…</td><td>…</td><td></td></tr></tbody></table><p>However here we can unfortunately still tell that Alice and Bob are communicating. What could we do to hide the communication between these two?</p><p>One solution I’ll propose - which also has the benefit of sender privacy, so we’re killing two birds with one stone here - would be to generate a shared secret and hash it with the recipients identifier. Now messages just have a <code>payload</code> and a <code>to</code> property. The <code>to</code></p><table><thead><tr><th>to</th><th>payload</th></tr></thead><tbody><tr><td>HASH(alice_bob_shared_secret, Bob)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>HASH(alice_bob_shared_secret, Alice)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>HASH(alice_bob_shared_secret, Bob)</td><td>XXXXXXXXXXXXXX</td></tr><tr><td>…</td><td>…</td></tr><tr><td>…</td><td>…</td></tr><tr><td>…</td><td>…</td></tr></tbody></table><p>Remember only Alice and Bob can generate this shared secret, and the HASH function is some irreversible function that hides its content. Now whenever Bob wants to find messages from Alice he computes <code>HASH(alice_bob_shared_secret, Bob)</code> and queries all messages that match that <code>to</code> field.</p><p>As you can see now we only …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/">https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/</a></em></p>]]>
            </description>
            <link>https://portabella.io/blog/2020-11-16-crypto-in-laymans-terms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453703</guid>
            <pubDate>Thu, 17 Dec 2020 08:23:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling (organization) by bubbling the problems out]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453685">thread link</a>) | @liveweird
<br/>
December 17, 2020 | https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/ | <a href="https://web.archive.org/web/*/https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-post-id="5fda593d1605500039b287da">
	

	<section>
		<p>Working in many different environments provided me a good perspective on what scaling models are applied by different companies. Today I'd like to spend a bunch of keystrokes on one of the worst scaling models I've ever encountered.</p><p>I call it:</p><blockquote>Scaling by bubbling the problems out</blockquote><p>A <em>'busy person'</em>, usually a leader or manager, identifies a persistent problem within the organization: something that consumes focus and time, impacts the quality, slows down the value delivery, etc. This problem is either completely new (caused by the growth) or has evolved over time, but now its severity is more apparent.</p><p>Here are a few examples (of such problems) to make sure we're on the same page:</p><ul><li><strong>the number of quality defects</strong> (for the whole product) is increasing; until now, each team had been able to deal with their deliverables' quality</li><li><strong>the quality of internal communication</strong> deteriorates - people start complaining they don't know what's happening in the org, there are more and more misunderstandings and misalignments</li><li>the engineering unit needs to grow, and the <strong>recruitment takes more time increasingly</strong> - hereby hemorrhaging the last reserves of time of the unit's manager</li></ul><p>Initially, such a problem is dealt with in an ad-hoc way (through a one-off, point-directed action). But it keeps popping up back (as due to its nature, it can't be eliminated permanently). Apparently, that kind of a problem requires continuous effort and ownership (to make sure it doesn't get out of control).</p><p>Finally, the <em>'busy person'</em> (mentioned above) decides that burying her/his head in the sand won't work anymore, so why not do what all the handbooks advise?</p><p>That sounds like a tremendous idea, but the devil is in details. The <em>'busy person'</em> doesn't delegate responsibility, function, or role. (S)he <strong>outsources</strong> the problem by creating a new (formal or no) position (or even a sub-unit) to deal with that problem, so all the annoyances are out of the <em>'busy person's'</em> back.</p><p>This way the problem is contained within some sort of a <strong>bubble</strong>, but it's someone else's bubble! Problem-related black box our <em>'busy person'</em> doesn't have to worry about.</p><p>Got it?</p><ul><li>Problem <strong>X</strong> -&gt; <strong>X</strong> Manager / <strong>X</strong> Team</li><li><strong>Quality </strong>problem -&gt; <strong>Quality </strong>Manager / <strong>Quality </strong>(Assurance) Team</li><li><strong>Communication </strong>problem -&gt; <strong>Communication </strong>Manager / <strong>Communication</strong> Team</li><li><strong>Recruitment </strong>problem -&gt; <strong>Recruitment </strong>Manager / <strong>Recruitment </strong>Team</li></ul><p>Oh, how convenient is that! If the problem re-appears, it's clear who's guilt...^M^M^M to be asked to fix the situation.</p><p>As the crisis is prevented now, the <em>'busy person'</em> continues with her/his quest, smug and oblivious to the consequences of the change just made ...</p><p>Yes, it seems that short-term, we're all good here. Putting someone in charge of the crisis sounds like a decent plan. But it's not really what happened here. A new position has been spawned <strong>not to solve</strong> the actual problem (which may be hidden and unobvious) <strong>but to patch</strong> its visible symptoms, potentially making the organization more complex, inter-dependent, and bureaucratic.</p><p>Instead of well-thought-through systemic change, we're adding a sub-unit (usually with the manager in charge) with the responsibility of dealing with problem X. If you had any hopes for getting rid of problem X permanently - abandon any faith in that. If problem X is the sole reason for the sub-unit's existence, it will subliminally act <strong>to preserve and solidify</strong> that problem (under control, but still).</p><p>In more simple words:</p><ol><li>no wider context</li><li>no holistic view (to understand the flow of work and value, or the nature of the problem)</li><li>no systemic approach (System's Theory)</li></ol><p>While in fact the solutions to before-mentioned problems may be much more simple and straightforward:</p><ul><li><strong>the quality issues</strong> may be a result of reaching the critical capacity of manual regression testing (with test automation as a likely answer) or pushing quality checks towards the end of process (e.g. by not doing proper reviews)</li><li><strong>internal communication</strong> could deteriorate because of the increasing number of actors - a good idea is to check the component/area boundaries to verify the number &amp; validity of dependencies; other potential root cause may be an underlying conflict or misaligned priorities of two (or more) parties</li><li><strong>extensive recruitment</strong> will be a problem if you centralize the 'gating' too much - although acquiring talent is manager's/leader's duty, (s)he should get a lot of control over it directly to the teams (who are looking for more members) - it's their skin in the game of getting the most proper people on board</li></ul><hr><p>Just to make sure I'm clear - what I'm saying here is not against the popular principle of <em>'single-threaded teams'</em> (ones dedicated end-to-end, exclusively to well-defined narrow topic). I'm all for crystal-clear focus and unequivocal responsibility range, but the area covered by such a team should be <strong>defined by product/service vision</strong>, instead of what kind of piece of garbage has been thrown over the fence to save you some time ...</p>
	</section>

	
</article></div>]]>
            </description>
            <link>https://no-kill-switch.ghost.io/scaling-organization-by-bubbling-the-problems-out/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453685</guid>
            <pubDate>Thu, 17 Dec 2020 08:19:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453663">thread link</a>) | @ingve
<br/>
December 17, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453663</guid>
            <pubDate>Thu, 17 Dec 2020 08:13:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin price will hit $1M by the end of the decade: My prediction]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25453620">thread link</a>) | @kprimice
<br/>
December 17, 2020 | https://thenextwave.blog/bitcoin-future-price-prediction/ | <a href="https://web.archive.org/web/*/https://thenextwave.blog/bitcoin-future-price-prediction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thenextwave.blog/bitcoin-future-price-prediction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453620</guid>
            <pubDate>Thu, 17 Dec 2020 08:03:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Deep learning tool that repairs damaged/faded photos]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453481">thread link</a>) | @panabee
<br/>
December 16, 2020 | https://hotpot.ai/restore-picture?s=hn | <a href="https://web.archive.org/web/*/https://hotpot.ai/restore-picture?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="rootBody">

		


		<div id="rootYield">
			




<div id="pageBox">

	


	<div id="mainBox">

		<div id="controlBox">

			<div>
				<p><img src="https://hotpot.ai/images/site/transparent.gif">
				</p>
			</div>

			

			<p><span>Restore</span>
			</p>

		</div>

		

	</div>


	<article id="apiAccess">
		<h2>API Access</h2>

		<p>
			Add this service to your app, website, or company workflow with the <a href="https://hotpot.ai/docs/api">Hotpot API</a>.
		</p>
	</article>

	


	<article>
		<h2>Directions</h2>

		<p>
			Upload an image.
		</p>

		<p>
			Enable "Has Scratches" to explicitly remove scratches.
		</p>

		<p>
			To turn black &amp; white pictures to color, try our AI <a href="https://hotpot.ai/colorize-picture?s=restorer">Picture Colorizer</a> service.
		</p>
	</article>


	<article>
		<h2>Overview</h2>

		<p>
			This Hotpot AI service restores pictures by automatically performing scratch removal, face enhancement, and color sharpening. What used to require trained professionals hours can now be accomplished in seconds.
		</p>

		<p>
			The service can repair and restore both color and black &amp; white photographs.
		</p>

		<p>
			While this service automates photo restoration, it cannot replace experts for demanding restoration jobs. It is designed to help consumers with lightweight requirements while helping professionals save time on difficult restoration requests.
		</p>

		<p>
			For this service, pictures are not saved without user permission. For storage costs and user privacy, we only retain images for as long as necessary to run our machine learning models, and do not store photos beyond this.
		</p>

		<p>
			Note: the maximum image resolution we support is 1280x1280, but our new model supports larger images and is launching soon. Please contact us to try this newer model.
		</p>
	</article>


	<article>
	<h2>AI Tools</h2>

	<p>
		Explore other Hotpot <a href="https://hotpot.ai/tools">AI tools</a>, including ones for <a href="https://hotpot.ai/remove-background">background removal</a>, <a href="https://hotpot.ai/personalize-art">art personalization</a>, <a href="https://hotpot.ai/enlarge-picture">image upscaler</a> for photo prints, <a href="https://hotpot.ai/restore-picture">picture restoration</a>, <a href="https://hotpot.ai/colorize-picture">picture colorization</a>, and more.
	</p>
</article>


	<article>
		<h2>Research Credit</h2>

		<p>
			Our technology applies proprietary enhancements to the amazing Microsoft research project, <a href="https://github.com/microsoft/Bringing-Old-Photos-Back-to-Life" target="_blank">Bringing Old Photos Back to Life</a>.
		</p>
	</article>


	<article>
		<h2>Contribute</h2>

		<p>
			Help improve our AI by <a href="https://hotpot.ai/contact">sharing images</a> that convert poorly.
		</p>
	</article>


</div>








<!---------------------------- Hotjar BEGIN ---------------------------->



<!---------------------------- Hotjar END ----------------------------->
		</div>

	</div></div>]]>
            </description>
            <link>https://hotpot.ai/restore-picture?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453481</guid>
            <pubDate>Thu, 17 Dec 2020 07:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creative Code-Generated Art]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25453252">thread link</a>) | @dzink
<br/>
December 16, 2020 | https://www.editorx.com/shaping-design/article/creative-coding | <a href="https://web.archive.org/web/*/https://www.editorx.com/shaping-design/article/creative-coding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><p id="viewer-foo"><span><span>Have you ever experienced true novelty? Something so mind-altering that it questions your definition of what you’ve known to be true for so long. I imagine the first people to watch a film or see an airplane felt this. It’s an inexplicable energy that has the power to redefine. In many ways, artists have been at the center of challenging commonly held beliefs, and using entirely new mediums to express speculative ideas. </span></span></p><p id="viewer-fa7pc"><span><span>While never the first thing to come to mind when discussing art, creative coding is revolutionizing what art is and can be. As we enter a more digital world, creative coding may be the contemporary art movement we need in order to articulate major societal challenges we are facing as technology advances. </span></span></p><p id="viewer-gar4"><span><span>Put simply, creative coding is an emerging specialty that utilizes code and programming as a medium to create art. Programming’s versatility and ubiquitous nature makes it especially expressive, allowing it to manifest itself as digital paintings, data visualization, or even robotics. </span></span></p><p id="viewer-aesrq"><span><span>Unlike the functional focus of most uses of code - like the code lines of a navigation app - creative coding uses programming languages for a solely artistic purpose.</span></span></p><p id="viewer-bg2ev"><span><span>As artists, we generally hold a stigma regarding coding having high barriers to entry, and as engineers, we also hold a stigma surrounding the difficulties of creative expression. However, these fields no longer need to be separate entities, as they are more closely tied than people expect. </span></span></p><p id="viewer-80qt3"><span>With programming resources being incredibly open-source and <a href="https://www.editorx.com/shaping-design/article/drawing-inspiration-for-designers" target="_blank" rel="noopener"><u>creative inspiration</u></a> democratized across the internet, getting into this field is as easy as watching some coding tutorials on Youtube and making a Pinterest board. </span></p><p id="viewer-2vgh3"><span>If you haven’t already, you can <a href="https://www.editorx.com/shaping-design/article/should-designers-code" target="_blank" rel="noopener"><u>learn to code</u></a> by picking up a coding language such as HTML, CSS, and JavaScript. There are many online resources available, such as:</span></p><ul><li id="viewer-27t6d"><p><a href="https://www.w3schools.com/" target="_blank" rel="noopener"><u>W3Schools</u></a></p></li><li id="viewer-5oukm"><p><a href="https://www.youtube.com/watch?v=2qDywOS7VAc" target="_blank" rel="noopener"><u>Youtube Tutorials</u></a></p></li><li id="viewer-4rsku"><p><a href="https://www.linkedin.com/learning/" target="_blank" rel="noopener"><u>LinkedIn Learning</u></a></p></li><li id="viewer-a6fsj"><p><a href="https://www.learnpython.org/" target="_blank" rel="noopener"><u>Learnpython.org</u></a></p></li><li id="viewer-8el3i"><p><a href="https://www.codecademy.com/?g_network=g&amp;g_device=c&amp;g_adid=459321005730&amp;g_keyword=codecademy&amp;g_acctid=243-039-7011&amp;g_adtype=search&amp;g_adgroupid=70946090375&amp;g_keywordid=kwd-41065460761&amp;g_campaign=US_Brand_Core_Exact_Net+New+%28Auto+Tagging%29&amp;g_campaignid=1955172604&amp;utm_id=t_kwd-41065460761:ag_70946090375:cp_1955172604:n_g:d_c&amp;utm_term=codecademy&amp;utm_campaign=US_Brand_Core_Exact_Net%20New%20(Auto%20Tagging)&amp;utm_source=google&amp;utm_medium=paid-search&amp;utm_content=459321005730&amp;hsa_acc=2430397011&amp;hsa_cam=1955172604&amp;hsa_grp=70946090375&amp;hsa_ad=459321005730&amp;hsa_src=g&amp;hsa_tgt=kwd-41065460761&amp;hsa_kw=codecademy&amp;hsa_mt=e&amp;hsa_net=adwords&amp;hsa_ver=3&amp;gclid=CjwKCAiAzNj9BRBDEiwAPsL0d6bnyHp-tuJuJPB6ESAc8vQsGp2os6n9SvJ_fN73bAazebYH-FcctRoCuOMQAvD_BwE" target="_blank" rel="noopener"><u>The Code Academy</u></a> </p></li><li id="viewer-6638e"><p><a href="https://processing.org/" target="_blank" rel="noopener"><u>Processing</u></a></p></li></ul><p id="viewer-cbn64"><span>From there, finding inspiration can be as simple as reading the rest of this article or exploring dedicated art-technology spaces such as <a href="https://www.artechouse.com/" target="_blank" rel="noopener"><u>Artechouse</u></a>.</span></p><p id="viewer-erafq"><span>Here are some interesting fields within creative coding that you can experiment with once you get started:</span></p><ul><li id="viewer-ehb6t"><p><span><strong>Machine learning:</strong> The development of computer algorithms that automatically learn and improve their performance through experience and data.</span>


</p></li><li id="viewer-32vc4"><p><span><strong>Projection mapping:</strong> A technique to project video on irregularly shaped surfaces, such as sculptures or buildings. </span>


</p></li><li id="viewer-f009e"><p><span><strong>Generative design:</strong> An iterative design process in which a program, usually using algorithms, generates a certain number of outputs based on a set of constraints.</span>


</p></li><li id="viewer-5n77p"><p><span><strong>Live coding:</strong> A form of performance art in which coders program in real-time. It usually involves sound, image and light design.</span></p></li></ul><p id="viewer-ep6sm"><span><span>To get some ideas flowing and inspire your own creative coding pieces, here are some examples of how expansive, stunning, and novel creative coding can be.</span></span></p><ol><li id="viewer-eeo5c"><p><span>Audience by Random International</span></p></li><li id="viewer-fha9v"><p><span>New Nature Digital Petting Zoo by Marpi Studio</span></p></li><li id="viewer-a5o8e"><p><span>Everything in Existence by fuse*</span></p></li><li id="viewer-8gq1n"><p><span>Infinite Command Team by Casey Reas </span></p></li><li id="viewer-4eu7u"><p><span>Land Lines by Zach Lieberman </span></p></li><li id="viewer-3unh"><p><span>ALGOBABEZ by Shelly Knotts</span></p></li><li id="viewer-538vu"><p><span>XYZT: Abstract Landscapes by Adrien M &amp; Claire B</span></p></li><li id="viewer-b7vhn"><p><span>Tecnicontrol by Bradley G Munkowitz (GMUNK)</span></p></li><li id="viewer-bprm6"><p><span>PEmbroider created at Frank-Ratchye STUDIO for Creative Inquiry</span></p></li><li id="viewer-akhtn"><p><span>Learning to See by Memo Akten</span></p></li></ol><p id="viewer-bahbh"><span><span>Random International is a London-based experimental art studio that has been pioneering the creative coding space for well over a decade now. Their work touches on deep social themes and has been exhibited internationally in spaces like the MoMa. </span></span></p><p id="viewer-fduu8"><span><span><em>Audience</em>, one of their earlier pieces of work from 2008, uses motion tracking software and creative coding to create an almost uncomfortable, anthropomorphic experience. As a gallery visitor steps in front of rows of individually dancing mirrors, they instantly synchronize and lock onto the viewer. With 100 mirrors now looking right back at you, you then become the focal point of your own onlooking. </span></span></p><p id="viewer-8dmeo"><span><span>Created by Marpi Studio, New Nature is a digitally interactive petting zoo that relies on gesture-based technology and programming to create virtual organisms. </span></span></p><p id="viewer-65ego"><span><span>Through machine learning, Marpi has forged a virtual terrarium of creatures and plants that rely on the physical interactions of the viewers to come alive. As viewers engage with the digital creatures, the artwork responds with real-time computer-generated motions, simulating the movement of an organic creature being pet. </span></span></p><p id="viewer-60ee9"><span><span><em>Everything in Existence</em> questions our perceptions of reality. Using real-time data processing tools and algorithmic software, fuse* creates a living piece of art that constantly evolves and adapts depending on its interactions with onlookers. </span></span></p><p id="viewer-bna5m"><span><span>The artworks are constantly generating new visuals in response to the viewers, their social networks, sound and more. This solo exhibition by fuse*, which premiered in Washington DC in 2019, creates digitally interactive experiences independently of an artist. Its self-sufficient and generative nature suggests an entirely new form of artistic expression.</span></span></p><p id="viewer-274p6"><span><span>Casey Reas’ <em>Infinite Command Team</em> investigates the relationship between particles that are encoded to construct images, and the code that forges those particles. </span></span></p><p id="viewer-c3cum"><span><span>Using pixelation of different weights and sizes, the piece creates a digital mosaic of television signals that become abstract and collage-like, reminiscent of TV channel-surfing. The piece is a celebration of art and technology that showcases the potential of combining digital fragments into a holistic piece of work. </span></span></p><p id="viewer-fhi88"><span><span>One of the most exciting aspects of creative coding is that it’s so readily available. Regardless of where you go in the world, there will always be code present guiding new innovations or digital platforms. </span></span></p><p id="viewer-8344v"><span><span>Creative coder Zach Lieberman takes advantage of how constantly present code is in our lives by using Google Maps to create art. In his proj</span>ect <a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><em><u>Land Lines</u></em></a>, Lieberm<span>an uses machine learning, optimized algorithms, and card power to harness images from Google Maps and match them with viewers’ drawings. </span></span></p><p id="viewer-ab3mh"><span><span>Lieberman asks his viewers to draw shapes and lines on the screen, which in turn are converted into real spaces on earth that resemble the line they drew. </span></span></p><div id="viewer-6292q"><a href="https://lines.chromeexperiments.com/" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="Land Lines by Zach Lieberman website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_1000%2Ch_715%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_37a32651df7f41128188147e18c73b6c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Land Lines by Zach Lieberman website screenshot"></p></div></div></a></div><p id="viewer-8vtqk"><span><span>Shelly Knotts takes creative coding to an entirely new plane in her live-coding pop band, ALGOBABEZ. Based in the UK, Shelly collaborates with other musicians and programmers in her pseudo-improvised live-coded music performances. Her coded music has been played to international audiences and explores themes of data, music, networks, and code.</span></span></p><p id="viewer-5b9e7"><span><span>Created by the company Adrien M &amp; Claire B, <em>XYZT</em> explores the intersection of mathematics and imaginary landscapes. </span></span></p><p id="viewer-bstnp"><span><span>Leveraging technology, programming, and lighting design, <em>XYZT</em> allows visitors to explore the four primary planes of existence: horizontal (the X axis), vertical (Y), depth (Z), and time (T). The exhibit allows for unparalleled interactivity across each of the planes, responding to visitors’ motion and creating new visuals in real time. </span></span></p><p id="viewer-3jqso"><span><span>In his creative coding work <em>Technicontrol</em>, Bradley Munkowitz, also known as GMUNK in the art community, investigates the ways in which robotics, code and screen content can result in a choreographed piece of work. </span></span></p><p id="viewer-b6arv"><span><span>Rather than using typical projection-mapped canvases, he pushed for LED-screen-wielding robots and a motion-controlled camera. The end result is a whimsical, technology-driven video piece with a truly marvelous storyline tracing the steps of a television abduction.</span></span></p><p id="viewer-178s8"><span><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><em><u>PEmbroider</u></em></a> is a<span>n open-source computational embroidery library. The goal of the creative coding library is to empower artists and craftspeople to make generative embroidery work for free. </span></span></p><p id="viewer-2ua6k"><span><span>Usually, tools such as this would be costly, and oftentimes are inaccessible to most artists or hobbyists. By creating an open-source repository, PEmbroider allows anyone to forge new, generative embroidery work through code. </span></span></p><div id="viewer-ecl5u"><a href="https://github.com/CreativeInquiry/PEmbroider" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img" aria-label="PEmbroider creative coding website screenshot"><p><img data-pin-url="https://www.editorx.com/shaping-design/article/creative-coding" data-pin-media="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_1000%2Ch_661%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/5e5a34_20ee1567d5a340ab973279c47312232e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="PEmbroider creative coding website screenshot"></p></div></div></a></div><p id="viewer-18rug"><span><span>Memo Akten is an artist and researcher who examines the nature of vision and perception through computational creativity and artificial intelligence. In his series of works, <em>Learning To See</em>, Akten has developed an artificial neural network to view and make sense of the world around us. </span></span></p><p id="viewer-bnqsf"><span><span>By comparing everyday objects with their interpretations through the eyes of neural networks, Memo Akten is able to digitally emulate the way we humans observe the world and make sense of objects.</span></span></p><p id="viewer-1q52f"><span><span>As he states, “it can only see through the filter of what it already knows. Just like us. Because we too, see things not as they are, but as we are.”</span></span></p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.editorx.com/shaping-design/article/creative-coding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453252</guid>
            <pubDate>Thu, 17 Dec 2020 06:44:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell with Elm: How to Setup IHP with Elm]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25453058">thread link</a>) | @_query
<br/>
December 16, 2020 | https://driftercode.com/blog/ihp-with-elm/ | <a href="https://web.archive.org/web/*/https://driftercode.com/blog/ihp-with-elm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Get Elm with hot reloading on top of IHP, the new framework that makes Haskell a cool kid in web dev.</p><article><p><a target="_blank" rel="noreferrer noopener" href="https://elm-lang.org/">Elm</a> was my gateway drug into type-safe functional programming. It's such a good tool for making robust frontends. Writing big projects in React and TypeScript honestly bums me out because of it.</p><p>I have always wanted have to have the equivalent type-safe joy on the backend like I have with Elm.</p><p>Now I have it all, with SSR included and an amazing developer experience 😍</p><p><strong><a target="_blank" rel="noreferrer noopener" href="https://ihp.digitallyinduced.com/">IHP</a> is a new web framework that has opened a wide door for the web development community to get into Haskell.</strong> Like Rails and Laravel, it's great for quick prototyping, well documented and easy to use.</p><p>It even has the pipe operator (<code>|&gt;</code>) included making it even more similar to the Elm syntax.</p><p><strong>Disclaimer: This tutorial should work for Mac and Linux. If you develop on Windows, it might not work without some tweaks on your own</strong></p><h2>Create a new IHP Project</h2><p>If you haven't installed IHP already, make sure you do. <a target="_blank" rel="noreferrer noopener" href="https://ihp.digitallyinduced.com/Guide/installation.html">It's surprisingly easy to get going</a>.</p><p>Start a fresh IHP project for this tutorial. Luckily, it couldn't be easier as soon as IHP is properly installed.</p><code-editor language="bash"></code-editor><p>To verify the app is working, cd into the <code>ihp-with-elm</code> folder and run <code>./start</code>.</p><h2>Update .gitignore</h2><p>Let's update <code>.gitignore</code> as soon as possible to avoid pushing unwanted stuff into git.</p><code-editor language="bash"></code-editor><h2>Initialize node and elm</h2><p>In your <code>default.nix</code> file in the root folder, add <code>Node.js</code> and <code>elm</code> to <code>otherDeps</code>:</p><code-editor language="nix"></code-editor><p>To update your local environment, close the server <strong>(ctrl+c)</strong> and run</p><code-editor language="bash"></code-editor><p>Then initialize Node.js and elm at the project root.</p><code-editor language="bash"></code-editor><p>For this tutorial, we will rename the <code>src</code> folder that elm generated into <code>elm</code>.</p><code-editor language="bash"></code-editor><p>Set the source directories folder to <strong>"elm"</strong> in <code>elm.json</code>.</p><code-editor language="json"></code-editor><h2>Getting the Haskell template ready</h2><p>Let's start writing the Elm entrypoint into the Haskel template.</p><p>Go to <code>Web/View/Static/Welcome.hs</code> and replace all the html inside the HSX in <code>VelcomeView</code>:</p><code-editor language="hs"></code-editor><p>If your IHP app is not already running, run it with <code>./start</code> and see the output on <code>localhost:8000</code>.</p><p><img src="https://driftercode.com/images/archive/ihp-with-elm/elm-not-loaded.jpg" alt="Elm not running" loading="lazy"></p><p>As you see, Elm has not been loaded, because we naturally haven't written any Elm code yet. Let's close the server <strong>(ctrl+c)</strong> and do that now.</p><h2>Setting up Elm</h2><p>Install <code>node-elm-compiler</code> for compiling and <code>elm-hot</code> for hot reloading in development. <code>parcel-bundler</code> is a "zero config" JavaScript bundler.</p><code-editor language="bash"></code-editor><p>You could do it all without a bundler like Parcel. IHP discourages bundlers, and I agree that it's not always necessary.</p><p>Still, Parcel provides valuable niceties like tight production minification and good hot reloading in development, so I prefer to use Parcel when things get a bit more advanced.</p><p>Create <code>index.js</code> and <code>Main.elm</code> in the elm folder:</p><code-editor language="bash"></code-editor><p>The <code>elm/index.js</code> should look like this to initialize the Elm file.</p><code-editor language="javascript"></code-editor><p>Finally, lets' insert the code for <code>elm/Main.elm</code>!</p><code-editor language="elm"></code-editor><p>Add the <code>start</code> and <code>build</code> scripts into the <code>package.json</code>:</p><code-editor language="json"></code-editor><p>You should now be able to run <code>npm start</code> in one terminal and <code>./start</code> in another terminal.</p><p>There you should have it! Elm in Haskell with hot reloading and the Elm debugger is ready for you in the bottom right corner. Beautiful!</p><p><img src="https://driftercode.com/images/archive/ihp-with-elm/elm-loaded.jpg" alt="Elm running" loading="lazy"></p><h2>Build for production</h2><p>When pushing your IHP app to production, you need to make sure that it builds the Elm applications.</p><p>Go to the <code>Makefile</code> in the project root and append this line to the list of <code>JS_FILES</code>:</p><code-editor language="makefile"></code-editor><p>And put this at the bottom of the Makefile.</p><code-editor language="makefile"></code-editor><p>It should now be ready to ship to production for example to IHP Cloud.</p><p>For a complete overview of what has been done, see the <a target="_blank" rel="noreferrer noopener" href="https://github.com/kodeFant/ihp-with-elm/commit/485726d51b0c167e27e660d9696f0d289378314a">diff on my demo-repo</a>.</p><h2>Bonus: Run IHP and the frontend in one command</h2><p>Running two commands to start up the service can be difficult for a very lazy developer.</p><p><code>concurrently</code> is a tool that lets you spawn and kill multiple commands as one.</p><p>Install it as a developer dependency through npm:</p><code-editor language="bash"></code-editor><p>Then replace the <code>start</code> script in <code>package.json</code> and add accordingly:</p><code-editor language="json"></code-editor><p>With that you can now run both the IHP app and the JavaScript simultaneously with this single command.</p><code-editor language="bash"></code-editor><p>And quit with <strong>(ctrl+c)</strong> as always.</p><h2>Things I don't use Elm for in IHP</h2><p>IHP gives you HTML templating (HSX) with pure functions, very similar to Elm. In that regard it's partially overlapping with Elm.</p><p>It can be a blurry line for beginners, so here are my recommendations for how to set those lines.</p><ul><li>Use HSX for <strong>basic HTML</strong>, even if it requires a couple of lines of JavaScript. I would for example write a basic hamburger menu in HSX/HTML.</li><li>Use HSX for <strong>forms</strong>. Forms are pretty much always a bigger pain written in app code. If you have been living in the Single Page App world for a while, you will realize forms written in normal HTML is not that bad. IHP gives you a convenient way of writing forms with server-side validation.</li><li>Use Elm for the <strong>advanced UI stuff</strong> requiring heavy use of DOM manipulation. Elm shines in writing user interfaces with high complexity. If the lines of JavaScript are getting too many, turn to Elm!</li><li>Do you want the content to have <strong>SSR</strong> for search engine optimization? Use HSX.</li></ul><p>So unless you really want to write a full Single Page App, Elm should be used with restraint in IHP, for only specific supercharged parts of the site.</p><p><strong>Most sites are actually better off outputting just HTML and CSS.</strong></p><h2>Next up</h2><p>I want to take this application further in future posts showing you how to interact between IHP and Elm, and how use Elm within protected boundaries (requiring authentication). Stay tuned if these are topics that intrigue you 😊</p></article></div>]]>
            </description>
            <link>https://driftercode.com/blog/ihp-with-elm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25453058</guid>
            <pubDate>Thu, 17 Dec 2020 06:05:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[React's UseRef Deep Dive]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25452146">thread link</a>) | @giovannibenussi
<br/>
December 16, 2020 | https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1 | <a href="https://web.archive.org/web/*/https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header></header><p><code>useRef</code> allows you to keep a mutable value within a component, similar to <code>useState</code> or instance variables on a class, without triggering re-renders.</p><p>For example, this component stores the number of clicks for a button:</p><div data-language="jsx"><pre><code><span>function</span> <span>RefButton</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> clicks <span>=</span> <span>useRef</span><span>(</span><span>0</span><span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks<span>.</span>current <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>.</span>current<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>This is how this component looks like (I added a re-render button so you can
actually test it out 😄):</p><div><h2>Interactive Example</h2><p>The example below is completely interactive, try clicking the "Clicks" button and then click on "Re-render".</p></div><p>As you can see, if you click the "Clicks" button it doesn't do anything. However, after click on "Re-render", it gets updated with the number of clicks we did previously.</p><h2>Difference with a variable</h2><p>You might wonder why not just use a simple variable as the example below:</p><div data-language="jsx"><pre><code><span>let</span> clicks <span>=</span> <span>0</span><span>;</span>

<span>function</span> <span>OutsideVariableButton</span><span>(</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>clicks <span>+=</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
      Clicks: </span><span>{</span>clicks<span>}</span><span>
    </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>And here's an interactive example for it:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span></p></div><p>The button works the same way that our previous example. However, the problem arises when you have multiple instances of the same component like the example below. Try clicking just one of the buttons and then click on re-render to see the result.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>outside variable</span><span>outside variable</span><span>outside variable</span></p></div><p>As you were able to see, the clicks are not isolated. In fact, all the examples
from this article uses the same button component, so if you click the button
from the first example and then click on "re-render" on the second example, the count it is gonna be
incremented! What a bug 🐛.</p><p>On the other hand, <code>useRef</code> values are completely isolated between components:</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>ref</span><span>ref</span><span>ref</span></p></div><h2>Difference with&nbsp;useState</h2><blockquote><p>The main difference between useState and useRef, is that useState triggers a
re-render and useRef doesn't.</p></blockquote><p>In the following example I added two buttons: one that updates its count with <code>useRef</code> and the other one with <code>useState</code>. I added some labels so you can identify them easily.</p><div><h2>Interactive Example</h2><p><strong>Type</strong><strong>Result</strong><span>state</span><span>ref</span></p></div><p>You'll notice that clicking on the button with <code>useRef</code> doesn't trigger a re-render and thus, the view isn't updated. On the other side, when you click on the button that uses <code>useState</code>, it will update its clicks count immediately.</p><p>To perform imperative actions on DOM nodes, React provides a way to get a
reference to them via refs. All you have to do is to assign a <code>ref</code> property to
a node with a ref object like this:</p><div data-language="jsx"><pre><code><span>function</span> <span>CustomInput</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>The way to get a DOM reference using refs works (informally 😅) as follows:</p><div><p><span>Today</span></p><div><p>React</p><p>Hey, what's up?<span>12:00</span></p></div><div><p>Could you give me a reference to this dom node?<span>12:00<svg style="color:#34B7F1" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg><svg style="color:#34B7F1;margin-left:-12px" fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg></span></p></div><div><p>React</p><p>Sure, I assigned it to the 'current' property of your ref.<span>12:00</span></p></div></div><p>On the first render, <code>inputRef</code>'s value will be <code>{ current: null }</code> and in the
following renders it will have its <code>current</code> property assigned to the specified DOM
node:</p><p>However, if you only reference <code>inputRef</code> inside <code>useEffect</code> then it'll always
reference the DOM node so you don't need to worry about it being undefined.</p><p>Let's update our example to get an idea of how this works:</p><div data-language="jsx"><pre><code><span>function</span> <span>AttachingToDomExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> inputRef <span>=</span> <span>useRef</span><span>(</span><span>)</span>

  console<span>.</span><span>log</span><span>(</span><span>"Render inputRef value:"</span><span>,</span> inputRef<span>)</span>

  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"useEffect inputRef value:"</span><span>,</span> inputRef<span>)</span><span>)</span>

  <span>return</span> <span><span><span>&lt;</span>input</span> <span>ref</span><span><span>=</span><span>{</span>inputRef<span>}</span></span> <span>/&gt;</span></span>
<span>}</span></code></pre></div><p>Here's the console output when rendering this component:</p><table><thead><tr><th>Render</th><th>Location</th><th>Value</th></tr></thead><tbody><tr><td>1</td><td>Render</td><td>{ current: undefined }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>2</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td>3</td><td>Render</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr><tr><td></td><td>useEffect</td><td>{ current: &lt;input /<!-- -->&gt;<!-- --> }</td></tr></tbody></table><p>As you can see, if you access the <code>inputRef</code> inside <code>useEffect</code> then you don't
need to worry about it being <code>undefined</code> because React will assign it
automatically for you.</p><p>Let's start with a simple real-world application for refs: <code>usePrevious</code>. This
hook stores the previous value for a given state variable.
<a href="https://reactjs.org/docs/hooks-faq.html#how-to-get-the-previous-props-or-state" target="_blank" rel="nofollow">It is even referenced on React's docs</a> as a way to "get the previous props or state". Let's see it in
action first:</p><div data-language="jsx"><pre><code><span>function</span> <span>UsePreviousExample</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>clicks<span>,</span> setClicks<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>)</span>
  
  <span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span>clicks<span>)</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setClicks</span><span>(</span>clicks <span>+</span> <span>1</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>
        Clicks: </span><span>{</span>clicks<span>}</span><span> - Before: </span><span>{</span>previousClicks<span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span>
<span>}</span></code></pre></div><p>Here's the output so you can play with it:</p><p>You can notice that the <code>previousClicks</code> variable stores the value for the previous render
for a given variable. Here's its implementation:</p><div data-language="jsx"><pre><code><span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
    ref<span>.</span>current <span>=</span> value
  <span>}</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>Let's analyze how it works.</p><p>Let's simulate what happens on the first render. We can remove the call to
<code>useEffect</code> since it doesn't affect the return value on the first render:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current
<span>}</span></code></pre></div><p>On the first render it is called with a value of <code>0</code>:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>0</span><span>)</span></code></pre></div><p>In this case, <code>usePrevious</code> will return <code>undefined</code>:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>After increase the value for count, here's how the <code>usePrevious</code> call will look:</p><div data-language="jsx"><pre><code>
<span>const</span> previousClicks <span>=</span> <span>usePrevious</span><span>(</span><span>1</span><span>)</span></code></pre></div><p>Since <code>usePrevious</code> is called again, its effect needs to run:</p><div data-language="jsx"><pre><code><span>useEffect</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  ref<span>.</span>current <span>=</span> <span>0</span>
<span>}</span><span>)</span></code></pre></div><p>After this, the <code>usePrevious</code> function is called again:</p><div data-language="jsx"><pre><code>
<span>function</span> <span>usePrevious</span><span>(</span><span>value</span><span>)</span> <span>{</span>
  <span>const</span> ref <span>=</span> <span>useRef</span><span>(</span><span>)</span>
  <span>return</span> ref<span>.</span>current 
<span>}</span></code></pre></div><p>And so on. Here's the value for each render for both variables:</p><table><thead><tr><th>Render</th><th>clicks</th><th>previousClicks</th></tr></thead><tbody><tr><td>1</td><td>0</td><td>undefined</td></tr><tr><td>2</td><td>1</td><td>0</td></tr><tr><td>3</td><td>2</td><td>1</td></tr><tr><td>4</td><td>3</td><td>2</td></tr></tbody></table><p>Callback Refs are a different way to set refs. It gives you a fine-grain control
over when refs are attached and detached because you provide a function instead
of a ref variable. This function gets called every time the component mounts and
unmounts.</p><p><a href="https://codesandbox.io/s/callback-ref-example-lqe8w?file=/src/App.js" target="_blank" rel="nofollow">Here's an example</a> that shows/hides an emoji every time you click its button.
The important thing here is the <code>ref</code> prop that we added. We use a function to log
the provided ref:</p><div data-language="jsx"><pre><code><span>const</span> <span>callback</span> <span>=</span> <span>(</span><span>ref</span><span>)</span> <span>=&gt;</span> console<span>.</span><span>log</span><span>(</span><span>"callback:"</span><span>,</span> ref<span>)</span>

<span>function</span> <span>App</span> <span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>[</span>show<span>,</span> setShow<span>]</span> <span>=</span> <span>useState</span><span>(</span><span>true</span><span>)</span><span>;</span>

  <span>return</span> <span>(</span>
    <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>setShow</span><span>(</span><span>!</span>show<span>)</span><span>}</span></span><span>&gt;</span></span><span>
        </span><span>{</span>show <span>?</span> <span>"Hide"</span> <span>:</span> <span>"Show"</span><span>}</span><span>
      </span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span>{</span>show <span>&amp;&amp;</span> <span><span><span>&lt;</span>span</span> <span>ref</span><span><span>=</span><span>{</span>callback<span>}</span></span><span>&gt;</span></span><span>👋</span><span><span><span>&lt;/</span>span</span><span>&gt;</span></span><span>}</span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span>)</span><span>;</span>
<span>}</span></code></pre></div><p>Here's an interactive version of the previous code (you can check the output in
the console to see that I'm not lying 🙃):</p><p><em>Note: If you use callback refs as inline functions, it will be called
twice: one with <code>null</code> and another one with the DOM element.
This is because React needs to clear the previous ref every time the function is
created. A workaround for this is to use a class method.</em></p><div><h2>Warning</h2><p><a href="https://reactjs.org/docs/refs-and-the-dom.html#legacy-api-string-refs" target="_blank" rel="nofollow">String refs</a> are a legacy feature and they are likely to be removed in future React versions.</p></div><p>The way it works is that you provide a string as a ref value like <code>ref="exampleRef"</code> and it automatically gets assigned to <code>this.refs</code>.</p><p><em>Note: String refs can only be used with class components.</em></p><p>Here's an usage example:</p><div data-language="jsx"><pre><code><span>export</span> <span>default</span> <span>class</span> <span>App</span> <span>extends</span> <span>React<span>.</span>Component</span> <span>{</span>
  <span>render</span><span>(</span><span>)</span> <span>{</span>
    console<span>.</span><span>log</span><span>(</span><span>this</span><span>.</span>refs<span>)</span><span>;</span>

    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span> <span>ref</span><span><span>=</span><span>"</span>exampleRef<span>"</span></span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>setState</span><span>(</span><span>{</span> dummy<span>:</span> <span>0</span> <span>}</span><span>)</span><span>}</span></span><span>&gt;</span></span><span>Re-render</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
    <span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Here's the value for <code>this.refs</code> across renders:</p><table><thead><tr><th>Render</th><th>this.refs</th></tr></thead><tbody><tr><td>1</td><td><code>{}</code></td></tr><tr><td>2</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>3</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr><tr><td>4</td><td><code>{ exampleRef: &lt;div&gt;...&lt;/div&gt; }</code></td></tr></tbody></table><p>As you can see, on the first render <code>this.refs.exampleRef</code> will be undefined and
on the following renders it will point out to the specified DOM node.</p><p>We saw what <code>useRef</code> is, how it differentiates with a plain old variable and
state variables, and we saw real world examples that uses it. I hope that most
of the content makes sense to you!</p><p>I'd love to hear your feedback. You can <a href="https://twitter.com/giovannibenussi" target="_blank" rel="nofollow">reach out to me on
Twitter</a> at any time :-)</p><hr></article></div></div>]]>
            </description>
            <link>https://www.giovannibenussi.com/blog/a-complete-guide-to-useref/?id=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25452146</guid>
            <pubDate>Thu, 17 Dec 2020 03:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passing of a Great Mind (1957)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25451727">thread link</a>) | @unclefuzzy
<br/>
December 16, 2020 | https://qualiacomputing.com/2018/06/21/john-von-neumann/ | <a href="https://web.archive.org/web/*/https://qualiacomputing.com/2018/06/21/john-von-neumann/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2>Passing of a Great Mind</h2>
<h3>John von Neumann, a Brilliant, Jovial Mathematician, was a Prodigious Servant of Science and his Country</h3>
<p><em>by Clary Blair Jr</em>. –&nbsp;<em>Life Magazine</em>&nbsp;(February 25th, 1957)</p>
<p>The world lost one of its greatest scientists when Professor John von Neumann, 54, died this month of cancer in Washington, D.C. His death, like his life’s work, passed almost unnoticed by the public. But scientists throughout the free world regarded it as a tragic loss. They knew that Von Neumann’s brilliant mind had not only advanced his own special field, pure mathematics, but had also helped put the West in an immeasurably stronger position in the nuclear arms race. Before he was 30 he had established himself as one of the world’s foremost mathematicians. In World War II he was the principal discoverer of the implosion method, the secret of the atomic bomb.</p>
<p>The government officials and scientists who attended the requiem mass at the Walter Reed Hospital chapel last week were there not merely in recognition of his vast contributions to science, but also to pay personal tribute to a warm and delightful personality and a selfless servant of his country.</p>
<p>For more than a year Von Neumann had known he was going to die. But until the illness was far advanced he continued to devote himself to serving the government as a member of the Atomic Energy Commission, to which he was appointed in 1954. A telephone by his bed connected directly with his EAC office. On several occasions he was taken downtown in a limousine to attend commission meetings in a wheelchair. At Walter Reed, where he was moved early last spring, an Air Force officer, Lieut. Colonel Vincent Ford, worked full time assisting him. Eight airmen, all cleared for top secret material, were assigned to help on a 24-hour basis. His work for the Air Force and other government departments continued. Cabinet members and military officials continually came for his advice, and on one occasion Secretary of Defence Charles Wilson, Air Force Secretary Donald Quarles and most of the top Air Force brass gathered in Von Neumann’s suite to consult his judgement while there was still time. So relentlessly did Von Neumann pursue his official duties that he risked neglecting the treatise which was to form the capstone of his work on the scientific specialty, computing machines, to which he had devoted many recent years.</p>
<p><img data-attachment-id="26616" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_1_1/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1316%2C920&amp;ssl=1" data-orig-size="1316,920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_1_1" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=300%2C210&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?fit=1000%2C699&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;ssl=1" alt="von_neumann_1_1" width="1000" height="699" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_1_1.png?resize=1000%2C699&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>His fellow scientists, however, did not need any further evidence of Von Neumann’s rank as a scientist – or his assured place in history. They knew that during World War II at Los Alamos Von Neumann’s development of the idea of implosion speeded up the making of the atomic bomb by at least a full year. His later work with electronic computers quickened U.S. development of the H-bomb by months. The chief designer of the H-bomb, Edward Teller, once said with wry humor that Von Neumann was “one of those rare mathematicians who could descend to the level of the physicist.” Many theoretical physicists admit that they learned more from Von Neumann in methods of scientific thinking than from any of their colleagues. Hans Bethe, who was director of the theoretical physics division at Los Alamos, says, “I have sometimes wondered whether a brain like Von Neumann’s does not indicate a species superior to that of man.”</p>
<p><img data-attachment-id="26617" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_2/" data-orig-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" data-orig-size="226,304" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_2" data-image-description="" data-medium-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=223%2C300&amp;ssl=1" data-large-file="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?fit=226%2C304&amp;ssl=1" loading="lazy" src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;ssl=1" alt="von_neumann_2" width="226" height="304" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_2.png?resize=226%2C304&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>The foremost authority on computing machines in the U.S., Von Neumann was more than anyone else responsible for the increased use of the electronic “brains” in government and industry. The machine he called MANIAC (mathematical analyzer, numerical integrator and computer), which he built at the Institute for Advanced Study in Princeton, N.J., was the prototype for most of the advanced calculating machines now in use. Another machine, NORC, which he built for the Navy, can deliver a full day’s weather prediction in a few minutes. The principal adviser to the U.S. Air Force on nuclear weapons, Von Neumann was the most influential scientific force behind the U.S. decision to embark on accelerated production of intercontinental ballistic missiles. His “theory of games,” outlined in a book which he published in 1944 in collaboration with Economist Oskar Morgenstern, opened up an entirely new branch of mathematics. Analyzing the mathematical probabilities behind games of chance, Von Neumann went on to formulate a mathematical approach to such widespread fields as economics, sociology and even military strategy. His contributions to the quantum theory, the theory which explains the emission and absorption of energy in atoms and the one on which all atomic and nuclear physics are based, were set forth in a work entitled <em>Mathematical Foundations of Quantum Mechanics</em>&nbsp;which he wrote at the age of 23. It is today one of the cornerstones of this highly specialized branch of mathematical thought.</p>
<p>For Von Neumann the road to success was a many-laned highway with little traffic and no speed limit. He was born in 1903 in Budapest and was of the same generation of <a href="http://slatestarcodex.com/2017/05/26/the-atomic-bomb-considered-as-hungarian-high-school-science-fair-project/">Hungarian physicists</a> as Edward Teller, Leo Szilard and Eugene Wigner, all of whom later worked on atomic energy development for the U.S.</p>
<p>The eldest of three sons of a well-to-do Jewish financier who had been decorated by the Emperor Franz Josef, John von Neumann grew up in a society which placed a premium on intellectual achievement. At the age of 6 he was able to divide two eight-digit numbers in his head. By the age of 8 he had mastered college calculus and as a trick could memorize on sight a column in a telephone book and repeat back the names, addresses and numbers. History was only a “hobby,” but by the outbreak of World War I, when he was 10, his photographic mind had absorbed most of the contents of the 46-volume works edited by the German historian Oncken with a sophistication that startled his elders.</p>
<p>Despite his obvious technical ability, as a young man Von Neumann wanted to follow his father’s financial career, but he was soon dissuaded. Under a kind of supertutor, a first-rank mathematician at the University of Budapest named Leopold Fejer, Von Neumann was steered into the academic world. At 21 he received two degrees – one in chemical engineering at Zurich and a PhD in mathematics from the University of Budapest. The following year, 1926, as Admiral Horthy’s rightist regime had been repressing Hungarian Jews, he moved to Göttingen, Germany, then the mathematical center of the world. It was there that he published his major work on quantum mechanics.</p>
<h4>The young professor</h4>
<p>His fame now spreading, Von Neumann at 23 qualified as a <em>Privatdozent</em>&nbsp;(lecturer) at the University of Berlin, one of the youngest in the school’s history. But the Nazis had already begun their march to power. In 1929 Von Neumann accepted a visiting lectureship at Princeton University and in 1930, at the age of 26, he took a job there as professor of mathematical physics – after a quick trip to Budapest to marry a vivacious 18-year-old named Mariette Kovesi. Three years later, when the Institute for Advanced Study was founded at Princeton, Von Neumann was appointed – as was Albert Einstein – to be one of its first full professors. “He was so young,” a member of the institute recalls, “that most people who saw him in the halls mistook him for a graduate student.”</p>
<p><img data-attachment-id="26618" data-permalink="https://qualiacomputing.com/2018/06/21/john-von-neumann/von_neumann_3/" data-orig-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1210%2C1028&amp;ssl=1" data-orig-size="1210,1028" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="von_neumann_3" data-image-description="" data-medium-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=300%2C255&amp;ssl=1" data-large-file="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?fit=1000%2C850&amp;ssl=1" loading="lazy" src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;ssl=1" alt="von_neumann_3" width="1000" height="850" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/qualiacomputing.com/wp-content/uploads/2018/06/von_neumann_3.png?resize=1000%2C850&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Although they worked near each other in the same building, Einstein and Von Neumann were not intimate, and because their approach to scientific matters was different they never formally collaborated. A member of the institute who worked side by side with both men in the early days recalls, “Einstein’s mind was slow and contemplative. He would think about something for years. Johnny’s mind was just the opposite. It was lightning quick – stunningly fast. If you gave him a problem he either solved it right away or not at all. If he had to think about it a long time and it bored him, hist interest would begin to wander. And Johnny’s mind would not shine unless whatever he was working on had his undivided attention.” But the problems he did care about, such as his “theory of games,” absorbed him for much longer periods.</p>
<h4>‘Proof by erasure’</h4>
<p>Partly because of this quicksilver quality Von Neumann was not an outstanding teacher to many of his students. But for the advanced students who could ascend to his level he was inspirational. His lectures were brilliant, although at times difficult to follow because of his way of erasing and rewriting dozens of formulae on the blackboard. In explaining mathematical problems Von Neumann would write his equations hurriedly, starting at the top of the blackboard and working down. When he reached the bottom, if the problem was unfinished, he would erase the top equations and start down again. By the time he had done this two or three times most other mathematicians would find themselves unable to keep track. On one such occasion a colleague at Princeton waited until Von Neumann had finished and said, “I see. Proof by erasure.”</p>
<p>Von Neumann himself was perpetually interested in many fields unrelated to science. Several years ago his wife gave him a 21-volume Cambridge History set, and she is sure he memorized every name and fact in the books. “He is a major expert on all the royal family trees in Europe,” a friend said once. “He can tell you who fell in love with whom, and why, what obscure cousin this or that czar married, how many illegitimate children he had and so on.” One night during the Princeton days a world-famous expert on Byzantine history came to the Von Neumann house for a party. “Johnny and the professor got into a corner and began discussing some obscure facet,” recalls a friend who was there. “Then an argument arose over a date. Johnny insisted it was this, the professor that. So Johnny said, ‘Let’s get the book.’ They looked it up and Johnny was right. A few weeks later the professor was invited to the Von Neumann house again. He called Mrs. von Neumann and said jokingly, ‘I’ll come if Johnny promises not to discuss Byzantine history. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qualiacomputing.com/2018/06/21/john-von-neumann/">https://qualiacomputing.com/2018/06/21/john-von-neumann/</a></em></p>]]>
            </description>
            <link>https://qualiacomputing.com/2018/06/21/john-von-neumann/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451727</guid>
            <pubDate>Thu, 17 Dec 2020 02:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Graying of Gnome]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25451433">thread link</a>) | @pabs3
<br/>
December 16, 2020 | https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/ | <a href="https://web.archive.org/web/*/https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><section id="primary"><main id="main" role="main"><article id="post-622"><div><p><a href="https://gnome.org/">The GNOME project</a> turned 23 this year, and despite equally persistent rumors to the contrary, it’s still alive and kicking.</p><p>Just how alive, though? All I know is this: Where the topic of GNOME’s health goes, accurate data rarely follows. Of course, there <em>is</em> data — lots of it in fact, in public source code repositories. Though flawed in many ways, it allows us to make comparisons to the past — and maybe predictions for the future: Are a few organizations carrying most of the workload, making them critical points of failure? Are new contributors able to pick up the slack from those who leave? Is the project graying (i.e. increasingly dominated by veterans)?</p><p>In one of my occasional fits of hubris, I set out to process this data to see if I could shake out anything meaningful. I’m usually fine with just satisfying my own curiosity and leaving it at that, but it’s one of those times where the results seem interesting enough for a blog post. So here we are.</p><p>I’m going to lead with the nice graphs and follow on with a <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#methodology">section on methodology</a>. The latter is long, boring, and mandatory reading.</p><h2 id="contributors">Active contributors</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png" alt="Active GNOME authors per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>The stacked histogram above shows the number of contributors who touched the project on a yearly basis. Each contributor is assigned to a generational cohort based on the year of their first contribution. The cohorts tend to shrink over time as people leave.</p><p>There’s a special “drive-by” cohort (in a fetching shade of off-white) for contributors who were only briefly involved, meaning all their activity fits in a three-month window. It’s a big group. In a typical year, it numbers 200-400 persons who were not seen before or since. Most of them contribute a single commit.</p><p>According to this, GNOME peaked at slightly above 1,400 contributors in 2010 and went into decline with the GNOME 3.0 release the following year. However, 2020 saw the most contributors in a long time, even with preliminary data — there’s still two weeks to go. Who knows if it’s an anomaly or not. It’s been an atypical year across the board.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png" alt="Active GNOME authors per month, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>This is the same histogram, but with per-month bins. There’s a clear periodicity caused by the semiannual release cycle. The peak month was March 2011, right before the <a href="https://www.gnome.org/press/2011/04/gnome-3-0-released-better-for-users-developers-3/">GNOME 3.0 release</a>. About 450 contributors got involved that month.</p><p>The drive-by cohort is relatively smaller on a monthly basis. This makes sense, as it has little overlap from month to month, and the per-year bins tend to add them all up.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png" alt="Active GNOME authors per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Above, the top 15 affiliations of active contributors. I’ve excluded personal accounts. This is pretty flawed (details below), but interesting nonetheless. For what it’s worth, it mostly lines up with my memory of things.</p><p>The pattern tracks well with the total despite only capturing a minority portion of it. I think this means that paid and unpaid contributions are driven by the same underlying trends, or that there’s a lot of the former hiding in the latter.</p><h2 id="commitcount">Commit count</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png" alt="Number of GNOME commits per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Here I’m counting the number of commits per year in the various cohorts.</p><p>At first glance, this looks much less dire. However, note how newcomers are having a smaller impact, especially from 2014 on. And the 2018-2020 bounce is entirely due to a handful of veterans making a comeback.</p><p>Half the commits in 2020 were made by contributors who’ve been with the project for ten years or more. Also noteworthy, drive-by commits are a vanishingly small portion of the total.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png" alt="Number of GNOME commits per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Top 15 affiliations again, but now ordered by commit counts. It’s safe to say that GNOME is dependent on paid developers in a big way. Specifically, and to no one’s surprise, it leans heavily on Red Hat.</p><h2 id="observations">General observations</h2><p>A few observations can be made with confidence:</p><ul><li>By F/OSS standards, the project is not <em>un</em>healthy. It has hundreds of experienced and first-time contributors every year. It is well-organized and arguably well-funded compared to its peers. But:</li><li>Every metric has the project peaking around 2010.</li><li>A diminishing number of veterans is doing an increasing share of the work.</li><li>Although recruitment is stable, newcomers don’t seem to be hitting their stride in terms of commits.</li><li>Corporate sponsorship is probably necessary to keep the project going, but the field of sponsors has kept thinning.</li></ul><p>I think GNOME is addressing the risk factors competently by modernizing infrastructure (<a href="https://gitlab.gnome.org/">GitLab</a>, <a href="https://discourse.gnome.org/">Discourse</a>). This has obvious value even in the absence of quantifiable results, but it’ll be interesting to see if the effect can be measured over the next couple of years.</p><p>Diminished enthusiasm may also be due to there being fewer ways for a new contributor to make their mark or assume a role of responsibility. GNOME has become more conservative, certainly much more so than it was a decade ago in the run-up to GNOME 3. The rationale and phrasing in <a href="https://discourse.gnome.org/t/new-gnome-versioning-scheme/4235">the announcement of the new versioning scheme</a> (e.g. <em>“Radical technological and design changes are too disruptive for maintainers, users, and developers”</em>) seems indicative of this trend<sup>1</sup>.</p><h2 id="methodology">Notes on methodology</h2><p>So what’s wrong with this analysis? If you’re so inclined, you can find the details under the next couple of subheadings and pass harsh, harsh judgement.</p><p>I’ve set the unscientific rigor bar high enough to hopefully yield something useful, but low enough that I could do it in my spare time and not get stuck in the dreaded state commonly known as “90% done”.</p><h3>Module selection</h3><p>I aggregated data from <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-repos">189 Git repositories</a>. The vast majority of these are hosted on <code>gnome.org</code>, with a handful from <code>freedesktop.org</code> and <code>github.com</code>. Commits are uniquely identified by their commit hash, meaning trivial duplicates are counted only once.</p><p>GNOME has always been a decentralized, big-tent project, so it’s not obvious how to delineate it. I’ve tried to be fair by including most of the repositories from a full meta-gnome-desktop jhbuild, including fairly low-level dependencies like Cairo, Pango, and Pipewire, as well as past, present and would-be flagship applications under the GNOME umbrella. Documentation and infrastructure is represented, as are many archived projects (e.g. ORBit2, Bonobo, Sabayon, GAL).</p><p>I was a little uncertain about what to do with X.Org and Wayland. In the end I decided to include the latter, but not the former, since Wayland has close ties to GNOME (it even references GTK+ in its TODO file), while X.Org has its roots in the much older XFree86.</p><p>Mono is another project I resisted including; its development was tangential to GNOME proper, diverging completely in the most recent decade. However, I did include GtkSharp and several GNOME-hosted C# applications common on desktops in the 2005-2010 time frame.</p><p>Since I haven’t established hard criteria for module selection, it’s subject to various biases. Older code is probably underrepresented, since providers of important functionality were more loosely attached to the project early on (e.g. GNOME Online Accounts and Telepathy got pulled in, should I have included Gaim or Pidgin too? How about XChat?).</p><p>Anyway, the list isn’t terrible, but there’s room for improvement.</p><h3>Contributor identities</h3><p>Similar studies often identify contributors by their e-mail addresses. I used full author names instead, since there’s good reason to think they’re more stable over a 20-year time span. We’re fairly consistent in spelling our own names, and we change them rarely (often never). On the other hand, e-mail addresses come and go with different hosting arrangements, employers, etc.</p><p>An added challenge with this approach is that sometimes different people have the exact same name. In practice, I’m not aware of any instances of this happening in GNOME. It seems to be rare enough that I doubt it’d introduce significant error in most projects.</p><p>I should add here that the drive-by cohort depends on a fair amount of hindsight (you never know when someone might come back with more contributions, but the likelihood drops off quickly as time passes). This means the cohorts for 2020 are preliminary. They’ll be a lot more accurate with another run late next year.</p><h3>Domain names</h3><p>I’m using e-mail domain names as a proxy for organizations in some of the graphs. This is a notoriously unreliable approach for at least three reasons:</p><ol><li>Contributors often use personal e-mail addresses for paid work, leading to significant undercounting in general.</li><li>Specific companies may require their employees (or ask them nicely) to use company e-mail for collaboration. Out of the listed companies, I know of at least one that definitely did this. However, there are many that don’t, and these will be comparatively less well represented.</li><li>The mapping between DNS and organizations isn’t one-to-one. A company may operate under multiple names or TLDs (e.g. <code>.co.uk</code> and <code>.com</code>).</li></ol><p>Despite these weaknesses, it’s common to slice the data this way. It’s difficult to do better without access to semi-closed data troves, and depending on your views on privacy and ability to handle <a href="https://en.wikipedia.org/wiki/Personal_data">PII</a> safely, it might not be something you’d want to get into anyway. But I bet you’d be well-positioned for it if you were, say, the corporate owner of both LinkedIn and GitHub.</p><p>When grouping by organization, the goal is to get an idea of which outside entities are sponsoring contributions. Therefore, I’ve filtered out addresses from the biggest mass e-mail providers like <code>@gmail.com</code> and project-centric providers of personal accounts (e.g. <code>@gnome.org</code>, <code>@gtk.org</code>).</p><p>I took the liberty of reassigning the personal domains of a few extra prolific authors who would’ve otherwise showed up as individual organizations. Since there’s no way I’m doing it for everyone, this introduces some bias. The full details are in <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-meta.json">the project’s metadata file</a> (see: <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#code">code</a>).</p><h3>Version control systems</h3><p>Changeovers in version control systems divide GNOME’s VCS history into three eras with noticeable discontinuities between them.</p><h4>Before 1998: Dark ages</h4><p>In the Bad Old Days, Free Software would often use plain <a href="https://en.wikipedia.org/wiki/Revision_Control_System">RCS</a> or no version control at all. I have basically no data for this era: The GIMP, being the ur-project from which …</p></div></article></main></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</a></em></p>]]>
            </description>
            <link>https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451433</guid>
            <pubDate>Thu, 17 Dec 2020 01:57:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine learning could be fundamentally unexplainable]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25451334">thread link</a>) | @eindiran
<br/>
December 16, 2020 | https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable | <a href="https://web.archive.org/web/*/https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-12-16</p>
        
<p>I'm going to consider a fairly unpopular idea: most efforts towards "explainable AI" are essentially pointless. Useful as an academic pursuit and topic for philosophical debate, but not much else.</p>
<p>Consider this article a generator of interesting intuitions and viewpoints, rather than an authoritative take-down of explainability techniques.</p>
<p>That disclaimer aside:</p>
<hr>
<p>What if almost every problem for which it is desirable to use machine learning is unexplainable?</p>
<p>At least unexplainable in an efficient-enough way to be worth explaining. Whether it is an algorithm or a human that is doing the explanation.</p>
<p>Let's define "<a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">explainable AI</a>" in a semi-narrow sense, inspired by the DARPA definition, as an inference system that can answer the questions:</p>
<blockquote>
<p>Why was that prediction made as a function of our inputs and their interactions?</p>
</blockquote>
<blockquote>
<p>Under what conditions would the outcome differ?</p>
</blockquote>
<blockquote>
<p>How confident can we be in this prediction and why is the confidence such?</p>
</blockquote>
<p>Why might we be unable to answer the above questions in a satisfactory manner for most machine learning algorithms? I think I can name four chief reasons:</p>
<ol>
<li>Some problems are just too complex to explain. Often enough, these are perfect problems for machine learning, it's exactly their intractability to our brains that makes them ideal for equation-generating algorithms to solve.</li>
<li>Some problems, while not that complex, are really boring and no human wants or should be forced to understand them.</li>
<li>Some problems can be understood, but understanding in itself is different for every single one of us, and people's culture and background often influence what "understanding" means. So explainable for one person is not explainable for another.</li>
<li>Even given an explanation that everyone agrees on, this usually puts us no closer to most of what we want to achieve with said explanation, things like gathering better data or removing "biases" from our models.</li>
</ol>
<h2>I - Unexplainable due to complexity</h2>
<p>Let's say, physicists, take in 100 PetaBytes of experimental data, reduce them using equations, and claim with a high probability that there exists this thing called a "Higgs Boson" with implications for how gravity works, among other things.</p>
<p>The resulting Boson can probably be defined within a few pages of text via things such as mass, the things it decays into, its charge, its spin, the various interactions it can have with other particles, and so on.</p>
<p>But if a luddite like myself asks the physicists:</p>
<blockquote>
<p>Why did you predict this fundamental particle exists?</p>
</blockquote>
<p>I will either get a "press conference answer" which carries no meaning other than providing a "satisfying" feeling, but it doesn't answer any of the above questions.</p>
<p>It doesn't tell me why the data shows the existence of the Higgs Boson, it doesn't tell me how the data could have been different in order for this not to be the case, and it doesn't tell me how confident they are in this inference and why.</p>
<p>If I press for an answer that roughly satisfies the explainability criteria I mentioned above, I will at best get them to say:</p>
<blockquote>
<p>Look, the standard model is a fairly advanced concept in physics, so you first have to understand that and why it came to be. Then you have to understand the experimental statistics needed to interpret the kind of data we work with here. In the process, you'll obviously learn quantum mechanics, but to understands the significance of the Higgs boson specifically it's very important that you have an amazing grasp of general relativity, since part of the reason we defined it as is and why it's so relevant is because it might be a unifying link between the two theories. Depending on how smart you are this might take 6 to 20 years to wrap your head around, really you won't even be the same person by the time you're done with this. And oh, once you get your Ph.D. and work with us for half a decade there's a chance you'll disagree with your statistics and our model and might think that we are wrong, which is fine, but in that case, you will find the explanation unsatisfactory.</p>
</blockquote>
<p>We are fine with this, since physics is bound to be complex, it earns its keep by being useful and making predictions about very specific things with very tight error margins, its fundamental to all other areas of scientific inquiry.</p>
<p>When we say that we "understand" physics what we really mean is that there are a few dozen of thousands of blokes that spent half their lives turning their brains into hyper-optimized physics-thinking machines and they assure us that they "understand" it.</p>
<p>For the rest of us, the edges of physics are a black box, I know physics works because Nvidia sells me GPUs with more VRAM each year and I'm able to watch videos of nuclear reactors glowing on youtube while patients in the nearby oncology ward are getting treated with radiation therapy.</p>
<p>This is true for many complex areas, we "understand" them because a few specialists say they do, and the knowledge that trickles down from those specialists has results that are obvious to all. Or, more realistically, because a dozen-domain long chain of specialists combined, each relying on the other, is able to produce results that are obvious to all.</p>
<p>As long as there is a group of specialist that understands the field, as long as those specialists can prove to us that their discoveries can affect the real world (thus excluding groups of well-synchronized insane people) and as long as they can teach other people to understand the field... we claim that it's "understood".</p>
<hr>
<p>But what about a credit risk analysis "AI" making a prediction that we should loan Steve at most 14,200$?</p>
<p>The model making this prediction might be operating with TBs worth of data about Steve, his browsing history, his transaction history, his music preferences, a video of him walking into the bank... each time he walked into the bank for the last 20 years, various things data aggregators tell us about him, from his preference about clothing to the likelihood he wants to buy an SUV, and of course, the actual stated purpose Steve gave us for the credit, both in text and as a video recording.</p>
<p>Not only that, but the "AI" has been trained on previous data from millions of people similar to Steve and the outcomes of the loans handed to then, thus working with petabytes of data in order to draw the 1-line conclusion of "You should loan steve, at most, 14,200$, if you want to probabilistically make a profit".</p>
<p>If we ask the AI:</p>
<blockquote>
<p>Why is the maximum loan 14,200$? How did the various inputs and their interactions contribute to coming up with this number?</p>
</blockquote>
<p>Well, the real answer is probably something like:</p>
<blockquote>
<p>Look, I can explain this to you, but 314,667,344,401 parameters had a significant role in coming up with this number, and if you want to "truly" understand that then you'd have to understand my other 696,333,744,001 parameters and the ways they related to each other in the equation. In order to do this, you have to gain an understanding of human-gate analysis as well as how its progress over time relates to life-satisfaction, credit history analysis, shopping preference analysis, error theory behind the certainty of said shopping preferences, and about 100 other mini-models that end up coalescing into the broader model that gave this prediction. And the way they "coalesce" is even more complex than any of the individual models. You can probably do this given 10 or 20 years, but basically, you'd have to re-train your brain from scratch to be like an automated risk analyst, you'd only be able to explain this to another automated risk analysts, and the "you" "understanding" my decision will be quite different from the "you" that is currently asking.</p>
</blockquote>
<p>And even the above is an optimist take assuming the "AI" is made of multiple modules that are somewhat explainable.</p>
<p>So, is the "AI" unexplainable here?</p>
<p>Well, not more so than the physicists are. Both of them can, in theory, explain the reasoning behind their choice. But in both cases, the reasoning is not simple, there's no single data point that is crucial, if even a few inputs were to change slightly the outcome might be completely different, but the input space is so fast it's impossible to reason about all significant changes to it.</p>
<p>This is just the way things are in physics and it might be just the way things are in credit risk analysis. After all, there's no fundamental rule of the universe saying it should be easy to comprehend by the human mind. The reason this is more obvious in physics is simply because physicists have been gathering loads of data for a long time. But it might be equally true in all other fields of inquiry, based on current models, it probably is. It's just that those other fields didn't have enough data nor the intelligence required to grok through it until recently.</p>
<h2>II - Some problems are boring</h2>
<p>There is a class of problems that is complex, but not as complex as to be impenetrable to the vast majority of human minds.</p>
<p>To harken back to the physics example, think classical mechanics. Given the observations made by Galileo and some training in analysis, most of us could, in principle, understand classical mechanics.</p>
<p>But this is still difficult, it requires a lot of background knowledge, although fairly common and useful background knowledge and a significant amount of times. Ranging from, say, a day to several months depending on the person.</p>
<p>This is time well spent learning classical mechanics, but what if the problem domain was something else, say:</p>
<ul>
<li>Figuring out if a blotch on a dental CT scan is more likely to indicate a streptococcus or a lactobacillus infection.</li>
<li>Understanding what makes an image used to advertise a hiking pole attractive to middle-class Slovenians over the age of 54.</li>
<li>Figuring out, using l2 data, if the spread for the price of soybean oil is too wide, and whether the bias is towards the sell or buy.</li>
<li>Finding the optimal price at which to pre-sell a new brand of luxury sparkling water based on yet uncertain …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable">https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable</a></em></p>]]>
            </description>
            <link>https://cerebralab.com/Machine_learning_could_be_fundamentally_unexplainable</link>
            <guid isPermaLink="false">hacker-news-small-sites-25451334</guid>
            <pubDate>Thu, 17 Dec 2020 01:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Kakoune – The quest for a better code editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25450025">thread link</a>) | @psalminen
<br/>
December 16, 2020 | https://kakoune.org/why-kakoune/why-kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune.org/why-kakoune/why-kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Up to now, I have used vi as an example for modal text editor, mostly because
I expect most programmers have at least heard of it. However, I don’t believe
vi and clones are the best modal text editor out there.</p>
<p>I have been working, for the last 5 years, on a new modal editor called
Kakoune. It first started as a reimplementation of Vim (the most popular vi
clone) whose source code is quite dated. But, I soon realized that we could
improve a lot on vi editing model.</p>
<div>
<h3 id="_improving_on_the_editing_model">Improving on the editing model</h3>
<p>vi basic grammar is <strong>verb</strong> followed by <strong>object</strong>; it’s nice because it matches
well with the order we use in English, "delete word". On the other hand,
it does not match well with the nature of what we express: There is only
a handful of <strong>verbs</strong> in text editing (<strong>d</strong>elete, <strong>y</strong>ank, <strong>p</strong>aste,
<strong>i</strong>nsert…​), and they don’t compose, contrarily to <strong>objects</strong> which can be
arbitrarily complex, and difficult to express. That means that errors are
not handled well. If you express your object wrongly with a delete verb,
the wrong text will get deleted, you will need to undo, and try again.</p>
<p>Kakoune’s grammar is <strong>object</strong> followed by <strong>verb</strong>, combined with instantaneous
feedback, that means you always see the current object (In Kakoune we call
that the selection) before you apply your change, which allows you to correct
errors on the go.</p>
<p>Kakoune tries hard to fix one of the big problems with the vi model: its
lack of interactivity. Because of the <strong>verb</strong> followed by <strong>object</strong> grammar,
vi changes are made in the dark, we don’t see their effect until the whole
editing <strong>sentence</strong> is finished. <code>5dw</code> will delete to next five words, if
you then realize that was one word too many, you need to undo, go back to
your initial position, and try again with <code>4dw</code>. In Kakoune, you would do
<code>5W</code>, see immediately that one more word than expected was selected, type
<code>BH</code> to remove that word from the selection, then <code>d</code> to delete.  At each
step you get visual feedback, and have the opportunity to correct it.</p>
<p>At the lower level, the problem is that vi treats moving around and selecting
an object as two different things. Kakoune unifies that, moving <strong>is</strong> selecting.
<code>w</code> does not just go to the next word, it selects from current position to
the next word. By convention, capital commands tend to expand the selection,
so <code>W</code> would expand the current selection to the next word.</p>
</div>
<div>
<h3 id="_multiple_selections">Multiple selections</h3>
<p>Another particular feature of Kakoune is its support for, and emphasis
towards the use of multiple selections. Multiple selections in Kakoune
are not just one additional feature, it is the central way of interacting
with your text. For example there is no such thing as a "global replace" in
Kakoune. What you would do is select the whole buffer with the <code>%</code> command,
then select all matches for a regex in the current selections (that is the
whole buffer here) with the <code>s</code> command, which prompts for a regex. You would
end up with one selection for each match of your regex and use the insert
mode to do your change. Globally replacing foo with bar would be done with
<code>%sfoo&lt;ret&gt;cbar&lt;esc&gt;</code> which is just the combination of basic building blocks.</p>
<div>
<p>Global replace</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/global-replace.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Multiple selections provides us with a very powerful to express structural
selection: we can subselect matches inside the current selections, keep
selections containing/not containing a match, split selections on a regex,
swap selections contents…​</p>
<p>For example, convert from <code>snake_case_style</code> to <code>camelCaseStyle</code> can be done
by selecting the word (with <code>w</code> for example) then subselecting underscores
in the word with <code>s_&lt;ret&gt;</code>, deleting these with <code>d</code>, then upper casing the
selected characters with <code>~</code>. The inverse operation could be done by selecting
the word, then subselecting the upper case characters with <code>s[A-Z]&lt;ret&gt;</code>
lower casing them with ` and then inserting an underscore before them with
<code>i_&lt;esc&gt;</code> This operation could be put in a macro, and would be reusable
easily to convert any identifier.</p>
<div>
<p>Camel case to snake case</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/camel.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Another example would be parameter swapping, if you had <code>func(arg2, arg1);</code>
you could select the contents of the parenthesis with <code>&lt;a-i&gt;(</code>, split the
selection on comma with <code>S, &lt;ret&gt;</code>, and swap selection contents with <code>&lt;a-)&gt;</code>.</p>
<div>
<p>Swapping arguments</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/args-swap.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>It is as well easy to use multiple selections for alignment, as the <code>&amp;</code>
command will align all selection cursors by inserting blanks before
selection start</p>
<div>
<p>Aligning variables</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/align.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Or to use multiple selections as a way to gather some text from different
places and regroup it in another place, thanks to a special form of pasting
<code>&lt;a-p&gt;</code> that will paste every yanked selections instead of the first one.</p>
<div>
<p>Regrouping manager objects together</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/regroup.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
</div>
<div>
<h3 id="_interactive_predictable_and_fast">Interactive, predictable and fast</h3>
<p>A design goal of Kakoune is to beat vim at its own game, while providing a
cleaner editing model. The combination of multiple selections and cleaned up
grammar shows that it’s possible to have text edition that is interactive,
predictable, and fast at the same time.</p>
<p>Interactivity comes from providing feedback on every command, made possible by
the inverted <strong>object</strong> then <strong>verb</strong> grammar. Every selection modification
has direct visual feedback; regex-based selections incrementally show what
will get selected, including when the regular expression is invalid; and even
yanking some text displays a message notifying how many selections were yanked.</p>
<p>Predictability comes from the simple effect of most commands. Each command is
conceptually simple, doing one single thing. <code>d</code> deletes whatever is selected,
nothing more. <code>%</code> selects the whole buffer. <code>s</code> prompts for a regex and
selects matches in the previous selection. It is the combination of these
building blocks that allows for complex, but predictable, actions on the text.</p>
<p>Being fast, as in requiring fewer keystrokes, is provided by carefully designing
the set of editing commands so that they interact well together, and by sometimes
sacrificing beauty for useability. For example, <code>&lt;a-s&gt;</code> is equivalent to
<code>S^&lt;ret&gt;</code>: they both split on new lines, but this is such a common use case that
it deserves to have its own key shortcut. As shown in <a href="http://github.com/mawww/golf">http://github.com/mawww/golf</a>,
Kakoune manages to beat Vim at the keystroke count game in most cases,
using much more idiomatic commands.</p>
</div>
<div>
<h3 id="_discoverability">Discoverability</h3>
<p>Keyboard oriented programs tend to be at a disadvantage compared to GUI
applications because they are less discoverable; there is no menu bar on
which to click to see the available options, no tooltip appearing when you
hover above a button explaining what it does.</p>
<p>Kakoune solves this problem through the use of two mechanisms: extensive
completion support, and auto-information display.</p>
<p>When a command is written in a prompt, Kakoune will automatically open a menu
providing you with the available completions for the current parameter. It
will know if the parameter is supposed to be a word against a fixed set
of word, the name of a buffer, a filename, etc…​ Actually, as soon as <code>:</code>
is typed, entering command prompt mode, the list of existing commands will
be displayed in the completion menu.</p>
<p>Additionally, Kakoune will display an information box, describing what the
command does, what optional switches it can take, what they do…​</p>
<div>
<p>Command discoverability</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/discoverability.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>That information box gets displayed in other cases, for example if the <code>g</code>
key is hit, which then waits for another key (<code>g</code> is the <strong>goto</strong> commands
prefix), an information box will display all the recognized keys, informing
the user that Kakoune is waiting on a keystroke, and listing the available
options.</p>
<p>To go even further in discoverability, the auto information system can
be set to display an information box after each normal mode keystroke,
explaining what the key pressed just did.</p>
</div>
<div>
<h3 id="_extensive_completion_support">Extensive completion support</h3>
<p>Keyboard oriented programs are much easier to work with when they provide
extensive completion support. For a long time, completion has been prefix
based, and that has been working very well.</p>
<p>More recently, we started to see more and more programs using the so called
fuzzy completion. Fuzzy completion tends to be subsequence based, instead
of prefix based, which means the typed query needs to be a subsequence of
a candidate to be considered matching, instead of a prefix. That will generate
more candidates (all prefix matches are also subsequence matches), so it
needs a good ranking algorithm to sort the matches and put the best ones first.</p>
<p>Kakoune embraces fuzzy matching for its completion support, which kicks in both
during insert mode, and prompt mode.</p>
<div>
<p>Word completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Insert mode completion provides completion suggestions while inserting in the
buffer, it can complete words from the buffer, or from all buffers, lines,
filenames, or get completion candidates from an external source, making it
possible to implement intelligent code completion.</p>
<div>
<p>Language specific completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/cpp-completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Prompt completion is displayed whenever we enter command mode, and provides
completion candidates that are adapted to the command being entered, and to
the current argument being edited.</p>
</div>
<div>
<h3 id="_a_better_unix_citizen">A better unix citizen</h3>
<p>Easily making programs cooperate with each others is one of the main strength
of the Unix environment. Kakoune is designed to integrate nicely with a POSIX
system: various text editing commands give direct access to the power of POSIX
tools, like <code>|</code>, which prompts for a shell command and pipe selections through
it, replacing their contents with the command output, or <code>$</code> that prompts for
a command, and keeps selections for which the command returned success.</p>
<div>
<p>Using external commands as filters</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/filters.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>This is only the tip of the iceberg. Kakoune is very easily controllable from</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kakoune.org/why-kakoune/why-kakoune.html">https://kakoune.org/why-kakoune/why-kakoune.html</a></em></p>]]>
            </description>
            <link>https://kakoune.org/why-kakoune/why-kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25450025</guid>
            <pubDate>Wed, 16 Dec 2020 23:08:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Power of Lampshading]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25449934">thread link</a>) | @ducaale
<br/>
December 16, 2020 | https://www.swyx.io/lampshading/ | <a href="https://web.archive.org/web/*/https://www.swyx.io/lampshading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
  <p>Author's Note: The latest version of this essay is now a chapter in <a href="https://www.learninpublic.org/#learn-more">the Coding Career Handbook</a>.</p>
</blockquote>
<p>We are often told that <strong>Knowledge is Power</strong>. This is mostly true - except for at least two points in your career.</p>
<p>Have you thought about how <strong>Ignorance can be Power</strong> too? I can think of at least two stages in a career when you can wield lack of knowledge as a form of power (in the neutral, <em>ability to influence others to do what you need</em> sense, not in the petty <em>dominating over others</em> sense).</p>
<p>And we'll talk about how you can wield ignorance throughout the rest of your career too - with <strong>Lampshading</strong>!</p>
<section>
  <h2 id="when-youre-very-senior"><a href="#when-youre-very-senior">When you're very senior</a></h2>
  <p>First, when you're in <strong>senior management</strong>, typically at least a couple layers removed from individual contributors. Beyond a certain level you are not being paid to have the right answers - that's what your reports are for. It's your job to ask the right <em>questions</em>, and to enable your team to figure out how to get the answers.</p>
  <p>In my career so far I've often noticed that it is <em>senior management</em>, not middle or junior people, that are most likely to say "Whoa, whoa, whoa. I don't understand what's going on here. <a href="https://www.dictionary.com/e/slang/eli5/">Can you explain like I'm five?</a>" Done right, it can expose weak reasoning and bust bullshit, particularly when framed with the (mostly correct) belief that <a href="https://www.passiton.com/inspirational-quotes/3363-if-you-cant-explain-it-simply-you-dont">"If you can't explain it simply, you don't understand it well enough."</a>.</p>
  <p>Note I'm not absolving incompetent management of the need to know domain knowledge necessary to be an effective leader. I'm simply observing that at senior levels you are <em>not</em> expected to know everything, and that's an interesting violation of "Knowledge is Power" you have probably experienced.</p>
</section>
<section>
  <h2 id="when-youre-new"><a href="#when-youre-new">When you're new</a></h2>
  <p>Second, <strong>when you're new</strong>, typically entry level in a career or a new joiner to a community or company. At this level, again, nobody expects you to know <em>anything</em>. Sure, you needed to know <em>enough</em> to fool someone into hiring you. But so long as you never lied or lied-by-omission, nobody is going to turn around and fire you for having holes in your knowledge.</p>
  <p>Of course, there are cases where this doesn't apply. Junior talent are the most expendable, and some companies don't have a healthy attitude to mentorship and hiring. But in general, I find the tech industry a lot better for mentoring than, say, finance. Tech companies generally place explicit responsibility on seniors/team leads to mentor juniors, especially as part of their career progression goals.</p>
  <p>You might imagine, having restarted my career 2-4 times depending how you count it, that I have a good deal of personal experience with being a total newbie.</p>
</section>
<section>
  <h2 id="storytime"><a href="#storytime">Storytime!</a></h2>
  <p>Here I can tell you about my first day on my new dev job, fresh out of bootcamp.</p>
  <p>My team all joined on the same day - 3 new hires (me and 2 more experienced devs). My new boss, a confident senior dev who had had a long tenure with the firm, was walking us through our tech stack. All of a sudden he paused, and said, "oh by the way, we're going to use TypeScript. You all know TypeScript, right?". Coworker 1 nodded, Coworker 2 nodded. There was that unspoken sense of <em>duh, we're all professionals here, of course we use TypeScript</em>.</p>
  <p>And then all eyes were on me.</p>
  <p>I don't do well with peer pressure. In Gretchen Rubin's <a href="https://gretchenrubin.com/2015/01/ta-da-the-launch-of-my-quiz-on-the-four-tendencies-learn-about-yourself/">4 Tendencies</a> model, I'm an Obliger - I like to please people and put my own concerns aside. Of course my bootcamp hadn't taught TypeScript, we'd only had 3 months to learn fullstack JS! And of course I wanted to say yes!</p>
  <p>I had a probably visible moment of panic, before going with "no I don't know TypeScript." My boss simply nodded, saying, "you can learn on the job", and moved on.</p>
  <p>I think in my first few months I probably had a dozen little tests like that. Did I know how to do professional code reviews? (No) Did I know how to do BEM naming? (No, and I proudly still don't) Did I know what Clean Code was? (eh.. nope).</p>
  <p>Every time I confessed ignorance, they gave me what I needed to learn, and I caught up. If I made a mistake, they taught me what I did wrong. What were they gonna do, fire me? They knew what they were doing when they hired me out of bootcamp.</p>
</section>
<section>
  <h2 id="lampshading"><a href="#lampshading">Lampshading</a></h2>
  <p>So we see that confessing ignorance works at both the senior and junior stages of careers. But it also works in isolated situations as well, for example when you caveat what you don't know while <a href="https://www.swyx.io/writing/learn-in-public">learning in public</a>.</p>
  <p>Given my casual interest in creative writing, I often compare this technique with <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/LampshadeHanging">Lampshading</a>. To quote from TV Tropes:</p>
  <blockquote>
    <p>Lampshade Hanging (or, more informally, <strong>Lampshading</strong>) is the writers' trick of dealing with any element of the story that threatens the audience's Willing Suspension of Disbelief, whether a very implausible plot development, or a particularly blatant use of a trope, <strong>by calling attention to it and simply moving on</strong>.</p>
  </blockquote>
  <p>Applied to real life: You call out your own weakness, so that others can't.</p>
  <p>In fact, by most functional team dynamics, others are then obliged to help you fix your weakness. This is <a href="https://en.wikipedia.org/wiki/Soft_power">soft power</a>.</p>
  <p>Many Americans (of a certain age) immediately sympathize with this by linking it to <a href="https://www.youtube.com/watch?v=sHE0wmgljco">the final battle in 8 Mile</a>. In it, Eminem kicks off by naming every single weakness of his that his opponent Papa Doc was going to, literally stealing all the words from Papa Doc's mouth and turning himself into a sympathetic character. <strong>Weakness is strength</strong> here purely because of lampshading.</p>
</section>
<section>
  <h2 id="the-stupid-question-safe-harbor"><a href="#the-stupid-question-safe-harbor">The Stupid Question Safe Harbor</a></h2>
  <p>In real life, I often lampshade by invoking the "Stupid Question Safe Harbor" (SQSH).</p>
  <p>A "<a href="https://en.wikipedia.org/wiki/Safe_harbor_(law)">Safe Harbor</a>" is a legal idea that explicitly okays some behavior that may be in a grey zone due to unclear rules. So I use it as an analogy for how we act when someone says "I have a Stupid Question".</p>
  <p>When we invoke the "Stupid Question Safe Harbor", we are acknowledging the question is potentially stupid, AND that we all know that there's not really such a thing as a stupid question, but we'll just get it out of the way to ask something really basic - because getting mutual understanding is more important than saving face.</p>
  <p>The trick here is you actually are saving face - now you've invoked the SQSH, people understand you’re roleplaying, you're explicitly invoking a well understood mode of conversation, and you're not <em>ACTUALLY</em> that stupid. Right? Right?? <em>nervous laughter</em></p>
  <p>When you are in a group scenario, the SQSH has positive externalities. There may be multiple people wondering the same thing, but only one person has to "take the hit" of asking the "stupid question", and yet all benefit. I like performing this role of <a href="https://twitter.com/swyx/status/1096645037788618752">Stupid Questions as a Service</a>.</p>
</section>
<section>
  <h2 id="advanced-lampshading"><a href="#advanced-lampshading">Advanced Lampshading</a></h2>
  <p>Once you learn to look out for <strong>Lampshading</strong>, you may see powerful users of it out there in the wild who use it to Learn in Public:</p>
  <ul>
    <li>Kyle Simpson famously was told "You Don't Know JS" in an interview, and turned that into his <a href="https://github.com/getify/You-Dont-Know-JS">primary claim to fame</a>, controversial title and all.</li>
    <li>I eventually took my own TypeScript learnings, explicitly lampshaded that I was learning, and put them online and that became the <a href="https://github.com/typescript-cheatsheets/react-typescript-cheatsheet/">React TypeScript Cheatsheets</a></li>
    <li>I <em>frequently</em> lampshade my mistakes during my talks. Clicker not working? Call attention to it. Joke didn't land? Call myself out. Self aware, self deprecating humor is always appreciated by the audience, and fills dead air. But you can also use it to set up <a href="https://www.goodreads.com/quotes/91029-every-great-magic-trick-consists-of-three-parts-or-acts">a Pledge, in advance of a Turn and the final Prestige</a>, which is <a href="https://www.youtube.com/watch?v=KJP1E-Y-xyo">exactly how I set up my own livecoding talks</a>.</li>
    <li><a href="https://twitter.com/Nicolemens/status/1229610008167383040?s=20">This woman lampshading to ward off all trolls</a></li>
    <li><em>who else lampshades very well? let me know</em></li>
  </ul>
  <blockquote>
    <p>Dec 2020 Edit: <a href="https://css-tricks.com/the-power-of-lampshading/">Chris Coyier chimes in</a> with some very kind commentary of his own.</p>
  </blockquote>
</section>
</div></div>]]>
            </description>
            <link>https://www.swyx.io/lampshading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449934</guid>
            <pubDate>Wed, 16 Dec 2020 22:57:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New by AngelList: Recurring Transfers]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25449913">thread link</a>) | @siddg
<br/>
December 16, 2020 | https://angellist.com/blog/recurring-transfers | <a href="https://web.archive.org/web/*/https://angellist.com/blog/recurring-transfers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article><figure id="w-node-062ee8588b39-d1412f6c"><p><img src="https://assets-global.website-files.com/5f3e7f710351ee0491efb21b/5fd8e8a511c36679f08ad7a7_Article%20Image.png" loading="lazy" alt=""></p></figure><p>The lifeblood of any great technology company is their talent. Unfortunately, when it comes to competing for talent, private companies have always been at a disadvantage to public companies. Let’s imagine a scenario where an employee has two competing offers where the cash offer is the same.</p><ul role="list"><li><strong>Private Company:</strong> $100K worth of stock, 100% YoY Growth</li><li><strong>Public Company:</strong> $100K worth of stock, 35%YoY Growth</li></ul><p>On paper, the private company offer looks better. The company is doubling every year so the stock will grow much faster. In practice, however, people discount the stock because it’s illiquid. That puts the private company at a significant disadvantage.&nbsp;</p><p>We think there’s a better way. <a href="http://www.angellist.com/recurring-transfers">Recurring Transfers</a> enables private companies to offer recurring liquidity as a way to attract and retain great talent. We built the product to provide maximum control on who gets to sell how much and when. </p><ul role="list"><li><strong>Control the process while reducing overhead:</strong> set parameters for incoming LPs, percentages individuals can sell, and more, while AngelList manages the entire process end-to-end on a recurring basis</li><li><strong>Streamline the cap table, future voting, and signatures:</strong> the buying entity will vote with the majority of non-conflicted holders of the same class and only a single signature is needed from AngelList for all buyers</li><li><strong>Protect private information:</strong> information rights are held by the single block and not provided to the underlying investors</li><li><strong>Offer recurring liquidity</strong> as a benefit to employees to differentiate compensation offerings from competitors&nbsp;&nbsp;&nbsp;</li></ul><p><a href="http://www.pipe.com/">Pipe.com</a> uses Recurring Transfers to make sure their employees can get liquidity on a recurring annual basis - something private companies historically haven't actively promoted. </p><p><strong>Harry Hurst, co-founder and co-CEO said, </strong></p><blockquote>“At Pipe, we believe that our entire team should have the same access to liquidity usually only afforded to founders. Everyone at the company may go through life-changing events such as buying a house or starting a family, we want to make sure that our team can get access to liquidity along the way to provide the financial cushion they need and deserve. AngelList's reputation for being startup-friendly gave us the confidence to choose them as our trusted partner.” </blockquote><p>Furthermore, companies can attract investors and talent by offering liquidity as part of a compensation package, reducing pressure for early investors and employees. </p><p>Earlier this year, <a href="https://angellist.com/blog/introducing-transfers-the-company-friendly-liquidity-solution?_ga=2.224275995.1222680455.1608045226-1365692428.1604910835">we introduced Transfers</a>, which enabled companies to take control of their liquidity options, while reducing operations, time, and expenses. With Recurring Transfers, we've further streamlined the process allowing for end-to-end liquidity management on a recurring basis. This added flexibility permits companies to offer shareholders liquidity on a recurring basis without having to incur extra overhead.</p><p><a href="http://www.angellist.com/recurring-transfers">Recurring Transfers</a> allows companies to manage their liquidity without having to manage the process periodically. Interested companies that have a <strong>$100M+ valuation and notable VC investors</strong> should <a href="https://go.pardot.com/l/853403/2020-12-11/77jr6">contact us</a> to learn more.</p></article><div><p>Disclosures</p><p>This blog post and the information contained herein is provided for informational and discussion purposes only and is not intended to be a recommendation for any investment or other advice of any kind, and shall not constitute or imply any offer to purchase, sell or hold any security or to enter into or engage in any type of transaction. Any such offers will only be made pursuant to formal offering materials containing full details regarding risks, minimum investment, fees, and expenses of such transaction. The terms of any particular fund, including size, costs, and other characteristics, are set forth in the applicable constituent documents for such fund and may differ materially from those presented in this presentation. Quotes included in these materials related to AngelList's services and should not be construed in any way as an endorsement of AngelList's advice, analysis, or other service rendered to its clients. Illustrative examples are chosen on basis of their notability and the total amount invested on the AngelList platform. </p></div><div><p>Published: </p><p>December 16, 2020</p></div></div></div><div id="post_list"><div role="list"><div role="listitem"><p><a href="https://angellist.com/blog/disrupting-wall-street-with-a-rolling-fund-an-interview-with-alexander-pack">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/recurring-transfers" aria-current="page">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/gp-correlation">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/q3-2020-saw-a-rebound-in-early-stage-venture-activity">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/angellist-confidential-2020-highlights">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/introducing-transfers-the-company-friendly-liquidity-solution">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/super-angel-gp-launches-rolling-fund-with-global-lp-base">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/what-were-seeing-in-early-stage-vc-so-far-in-2020">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/apply-to-spearhead-2-for-a-fund-up-to-1m">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/congratulations-ubercab">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/q-a-with-angellist-co-founder-naval-ravikant">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/should-seed-investors-follow-on">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/for-seed-funding-safes-have-won-against-convertible-notes">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/what-angellist-data-says-about-power-law-returns-in-venture-capital">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/what-happens-after-you-make-a-seed-investment">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/how-portfolio-size-affects-early-stage-venture-returns">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/past-founders-and-funders-make-for-good-seed-investments">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/angellist-no-longer-charges-carry-on-your-own-lps">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/rolling-venture-fund-launch">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/venture-returns">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/world-positive-investing-1">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-state-of-women-in-venture-part-3">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/angellist-access-fund">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-w-fund-using-rolling-funds-to-close-the-48-gap">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-state-of-women-in-venture-part-2">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/easier-than-expected-gumroad-ceo-on-launching-his-first">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/the-state-of-women-in-venture-part-1">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/from-jakarta-to-silicon-valley-lp-uses-angellist-to-launch-syndicate-angellist-opened-the-world-to-me">Text Link</a></p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p><p>This is some text inside of a div block.</p></div><div role="listitem"><p><a href="https://angellist.com/blog/opportunistic-investing-an-interview-with-sriram-krishnan">Text Link</a></p><p>This is some …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://angellist.com/blog/recurring-transfers">https://angellist.com/blog/recurring-transfers</a></em></p>]]>
            </description>
            <link>https://angellist.com/blog/recurring-transfers</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449913</guid>
            <pubDate>Wed, 16 Dec 2020 22:55:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok Engagement Calculator and Earnings Estimator]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25449426">thread link</a>) | @youriykaplan
<br/>
December 16, 2020 | https://admass.io/tiktok-engagement-calculator | <a href="https://web.archive.org/web/*/https://admass.io/tiktok-engagement-calculator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <p>In 2020 PepsiCo-owned Doritos utilized TikTok and YouTube influencers for their ad camapign.</p>
              <p>One of their TikTok ads was a 60 second video of a comedic dance battle where Sam Elliott battled Lil
                Nas X over Cool Ranch tortilla chips while featuring his “Old Town Road” song.</p>
              <p>Doritos later expanded the ad campagin even further by encouraging viewers to show if their moves using the
                hashtag #CoolRanchDance in a dedicated TikTok challenge.</p>
              <p>Results?</p>
              <p>The video went viral on Doritos’ YouTube page, reaching over 16 million views.</p>
              <p>Almost 3,000 users have created dance videos using their hashtag on TikTok.</p>
            </div>
          </div>
        </div></div>]]>
            </description>
            <link>https://admass.io/tiktok-engagement-calculator</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449426</guid>
            <pubDate>Wed, 16 Dec 2020 22:05:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If everyone else on Earth disappeared, how would you spend your time?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25449176">thread link</a>) | @mcrittenden
<br/>
December 16, 2020 | https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-4393">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I found this thought exercise in the book <a href="https://smile.amazon.com/Happy-More-Less-Everything-Absolutely-ebook/dp/B01HE7TG7Y?sa-no-redirect=1">Happy</a> by Derren Brown.</p>



<p>Imagine <a href="https://critter.blog/2020/10/07/how-easily-our-lives-could-have-gone-differently/">suddenly everyone disappears</a>, but all of the world’s infrastructure and food supply magically continues to work. So you are the only person on Earth and you don’t have to worry about finding food/water/shelter. <a href="https://critter.blog/2020/10/21/non-fluffy-brainstorming-questions-for-long-term-career-planning/">What would you do all day</a>? </p>



<p>It’s a forcing function to make us realize how much of our behavior is driven by status seeking. It might be fun to drive a Ferrari and live in a mansion with no one around to stop you. You could sleep in the Oval Office! But without anyone else to see it, what’s the point? Once the novelty wore off, what would be left?</p>



<p>Would I still <a href="https://critter.blog/2020/09/09/running-advice-i-wish-id-gotten/">exercise</a> or eat well if I didn’t have anyone to look good for? Would I still want a nice house, or would I end up somewhere tiny and easy to clean? Would I even care about cleaning if nobody was around to think I’m a slob? Would I have <a href="https://critter.blog/2019/07/01/learning-to-crochet-as-a-32-year-old-man/">hobbies</a> with no one to try to impress or even talk to about them? Would I travel to beautiful places if I had no one to share them with? Would I bother taking pictures of those places if no one else could see them?</p>



<p>What could I <a href="https://critter.blog/2020/09/10/what-the-heck-do-i-even-want/">possibly care about</a>? I honestly have no idea. Does that mean everything I do is status seeking? Or just that without community, <a href="https://critter.blog/2020/11/04/what-we-have-left/">the human condition</a> does not exist? </p>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/12/16/if-everyone-else-on-earth-disappeared-how-would-you-spend-your-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25449176</guid>
            <pubDate>Wed, 16 Dec 2020 21:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C/C++ Compiler Cheatsheet]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25448573">thread link</a>) | @dmulholl
<br/>
December 16, 2020 | http://www.dmulholl.com/notes/c-compiler-cheatsheet.html | <a href="https://web.archive.org/web/*/http://www.dmulholl.com/notes/c-compiler-cheatsheet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-body">
            <ul>
<li>
<a href="#preprocessing">Preprocessing</a>
</li>
<li>
<a href="#compiling">Compiling</a>
</li>
<li>
<a href="#assembling">Assembling</a>
</li>
<li>
<a href="#linking">Linking</a>
</li>
<li>
<a href="#multiple-files">Multiple Files</a>
</li>
<li>
<a href="#warnings-standards">Warnings &amp; Standards</a>
</li>
<li>
<a href="#compiling-static-libraries">Compiling Static Libraries</a>
</li>
<li>
<a href="#compiling-dynamic-libraries">Compiling Dynamic Libraries</a>
</li>
</ul>
<hr>
<p>
There are four distinct steps involved in transforming a C or C++ source file into an executable binary: <i>preprocessing</i>, <i>compiling</i>, <i>assembling</i>, and <i>linking</i>.
</p>
<p>
In theory each step is the responsibility of a dedicated tool: the preprocessor <code>cpp</code>, the compiler <code>cc</code>, the assembler <code>as</code>, and the linker <code>ld</code>. In practice the compiler will happily orchestrate all four steps for us and we can build a simple C or C++ program using a single command:
</p>
<pre>$ cc source.c
</pre>
<p>
By default the resulting executable will be given the rather unappealing name of <code>a.out</code> — short for <i>assembler output</i> — but we can fix this by specifying a custom output name:
</p>
<pre>$ cc -o name source.c
</pre>
<p>
We'll look briefly below at each step of the compilation process and summarize some of the most useful options available.
</p>
<p>
The interface we'll describe was developed originally for <a href="https://en.wikipedia.org/wiki/GNU_Compiler_Collection">GCC</a>  — the GNU C Compiler —  and its supporting toolchain. This interface was later mimicked by <a href="https://en.wikipedia.org/wiki/Clang">Clang</a>, which aimed to be a drop-in replacement for GCC, and so now applies to both. It's a little crufty and inconsistent but the desire for backwards compatibility means we're stuck with it for the foreseeable future.
</p>
<p>
(To avoid repeating the awkward "C or C++" all the time we'll assume below that we're compiling a C program, but the steps and options are identical for both. Just substitute a <code>.cpp</code> extension in place of <code>.c</code> for C++ source files.)
</p>
<h3 id="preprocessing">
Preprocessing
</h3>
<p>
The C preprocessor <code>cpp</code> is responsible for executing <code>#</code> directives and expanding macros. It takes a <code>.c</code> source file as input and outputs an expanded source file, still written in C.
</p>
<p>
Preprocessed files typically aren't retained, but when they are the convention is to give them a <code>.i</code> extension. (I have no idea why.)
</p>
<p>
We can use the compiler's <code>-E</code> flag to view the preprocessed source. Output is printed to standard out by default unless we also use the <code>-o</code> flag to specify an output filename.
</p>
<pre>$ cc -E source.c
</pre>
<p>
The following preprocessor options are available (and can be passed directly to the compiler):
</p>
<table>
<tbody>
<tr>
<td>
<code>-C</code>
</td>
<td>
Retain source comments in the output.
</td>
</tr>
<tr>
<td>
<code>-D&lt;name&gt;=&lt;value&gt;</code>
</td>
<td>
Define the named symbol before preprocessing. If no value is specified the symbol will have a default value of 1.
</td>
</tr>
<tr>
<td>
<code>-I&lt;directory&gt;</code>
</td>
<td>
Add the specified directory to the search path for <code>#include</code> files.
</td>
</tr>
<tr>
<td>
<code>-P</code>
</td>
<td>
Omit debugging information from the output.
</td>
</tr>
<tr>
<td>
<code>-U&lt;name&gt;</code>
</td>
<td>
Undefine the named symbol before preprocessing.
</td>
</tr>
</tbody>
</table>
<h3 id="compiling">
Compiling
</h3>
<p>
The compiler <code>cc</code> translates a source file written in C into <a href="https://en.wikipedia.org/wiki/Assembly_language">assembly language</a>.
</p>
<p>
Assembly language is a human-readable representation of the binary machine code that actually runs on the computer's hardware; as such it's specific to the CPU architecture of the target system.
</p>
<p>
Assembly language files typically aren't retained but we can view them using the compiler's <code>-S</code> flag which halts the compilation process after they've been generated.
</p>
<pre>$ cc -S source.c
</pre>
<p>
This will generate a <code>.s</code> assembly file for each input file provided.
</p>
<h3 id="assembling">
Assembling
</h3>
<p>
The assembler <code>as</code> translates source files written in assembly language into executable binary code. It outputs a single <code>.o</code> object file for each input file provided.
</p>
<p>
The compiler defaults to automatically deleting these object files but we can retain them using the <code>-c</code> flag.
</p>
<pre>$ cc -c source.c
</pre>
<p>
This instructs the compiler to compile and assemble the object files but stop before linking them into an executable.
</p>
<h3 id="linking">
Linking
</h3>
<p>
Linking is the final stage of the compilation process. The linker <code>ld</code> combines multiple object files into a single executable file. It also links in code from the standard library and any other external libraries referenced by the files.
</p>
<p>
The C standard library is linked in automatically. To link in a static library <code>libfoo.a</code> located on the default library search path we use the <code>-l</code> flag:
</p>
<pre>$ cc source.c -lfoo
</pre>
<p>
Note that the standard <code>lib</code> prefix and <code>.a</code> (<i>archive</i>) extension are omitted. To link to a library that isn't on the default search path we have two options:
</p>
<ol>
<li>
<p>
We can specify the library's full filepath as if it were a source or object file:
</p>
</li>
</ol>
<pre>$ cc source.c /path/to/lib/libfoo.a
</pre>
<ol start="2">
<li>
<p>
We can add the containing directory to the search path using the <code>-L</code> flag:
</p>
</li>
</ol>
<pre>$ cc source.c -L/path/to/lib -lfoo
</pre>
<p>
Note that libraries must be specified <i>after</i> the source or object files that reference them.
</p>
<h3 id="multiple-files">
Multiple Files
</h3>
<p>
The compiler will happily accept multiple input files in varying stages of compilation:
</p>
<pre>$ cc src.c asm.s obj.o
</pre>
<p>
In this case <code>src.c</code> will be compiled and assembled, <code>asm.s</code> will be assembled, and the two resulting object files will be linked with <code>obj.o</code> into an executable.
</p>
<h3 id="warnings-standards">
Warnings &amp; Standards
</h3>
<p>
Turn on compiler warnings with the following flags:
</p>
<pre>-Wall -Wextra --std=c99 --pedantic
</pre>
<p>
The <code>-Wall</code> and <code>-Wextra</code> flags turn on most of the compiler's available warnings. The <code>--std=c99</code> flag instructs the compiler to use the C99 standard (available options include <code>c90</code> and <code>c11</code>). The final <code>--pedantic</code> flag turns on a number of additional warnings specific to the particular standard chosen.
</p>
<p>
Warnings can be turned off individually, e.g.
</p>
<pre>-Wno-unused-parameter
</pre>
<p>
will tell the compiler to stop bugging us about unused parameters.
</p>
<h3 id="compiling-static-libraries">
Compiling Static Libraries
</h3>
<p>
A static library is simply a collection or <i>archive</i> of object files. Static libraries are created using the <code>ar</code> (<i>archiver</i>) tool and by convention are given a <code>lib</code> prefix and <code>.a</code> extension.
</p>
<pre>$ ar -rv libfoo.a one.o two.o three.o
</pre>
<p>
Static libraries are built into the executable at compiletime — they do not have to be present on the system at runtime.
</p>
<h3 id="compiling-dynamic-libraries">
Compiling Dynamic Libraries
</h3>
<p>
A dynamic or <i>shared object</i> library is a special collection of object files that can be loaded by a program at runtime. Dynamic libraries are created using the compiler's <code>--shared</code> flag and by convention are given a <code>lib</code> prefix and <code>.so</code> extension.
</p>
<pre>$ cc --shared -o libfoo.so one.o two.o three.o
</pre>
<p>
Dynamic libraries can be used in two ways:
</p>
<ul>
<li>
<p>
An executable can be linked against a dynamic library at compiletime. Multiple executables can then share a single library instance, which must be available on the system at runtime.
</p>
</li>
<li>
<p>
An executable can dynamically load and unload library files at runtime using the system's dynamic linking functions. Libraries used in this way can form the basis of a plugin system for an application.
</p>
</li>
</ul>
        </div></div>]]>
            </description>
            <link>http://www.dmulholl.com/notes/c-compiler-cheatsheet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448573</guid>
            <pubDate>Wed, 16 Dec 2020 21:00:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sequoia PGP 1.0 Released: The Seedling Is a Sapling]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25448533">thread link</a>) | @dannyobrien
<br/>
December 16, 2020 | https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/ | <a href="https://web.archive.org/web/*/https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-content">
                          <p>Version 1.0.  It’s here.  After three and a half years of development,
we are happy to announce the release of version 1.0 of Sequoia!</p>
<p>The release includes the low-level crate <a href="https://crates.io/crates/sequoia-openpgp"><code>sequoia-openpgp</code></a>, and a
program to verify detached signatures geared towards software
distribution systems called <a href="https://crates.io/crates/sequoia-sqv"><code>sqv</code></a>.</p>
<p>We will support this API with security updates for at least one year.
In 9 months, we will announce whether we will extend this commitment.
The two main criteria will be our financial situation (please
<a href="https://pep.foundation/support-pep/index.html">donate</a>, or sponsor a developer or two), and the number of users.</p>

<p>We actually <a href="https://mastodon.social/@sequoiapgp/103364362621954545">almost released</a> version 1.0 about a year ago.  All of the
features that we had planned for version 1.0 were implemented, we had
good test coverage, and we even had a few users.  But, we decided to
wait.  We decided to wait not because we thought of another feature,
or because we became aware of a significant bug, but because <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/465">we</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/466">decided</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/467">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/468">take</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/469">some</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/470">time</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/471">to</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/472">improve</a>
<a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/473">our</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/474">documentation</a>.</p>
<p>Our goal was to make sure that every module had a helpful
introduction, and all public methods had a useful description, a link
to <a href="https://tools.ietf.org/html/rfc4880">the standard</a>, when appropriate, and a meaningful example.
Dividing the task between five people, we figured it would delay the
release by a month, perhaps two.  In the end, well, it took nearly a
year, and we had to scale our ambitions back a bit.  Nevertheless,
we’re quite happy with <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/index.html">the</a> <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html">result</a>.</p>
<p>First, the documentation is much better.  It’s of course hard to
quantify its quality.  But, we can distill a few numbers.  When we
started our documentation effort shortly after we released version
0.14, the Sequoia library had just over 11k lines of comments
including 53 documentation tests, and 37 kSLOC including 12 kSLOC of
unit tests.  The 1.0 release has over 33k lines of comments (190%
more) including 464 documentation tests (780% more), and 44 kSLOC (21%
or 7.5 kSLOC more) including 8k SLOC of additional unit tests.</p>
<p>Second, in the process of documenting our public API and writing
examples, we discovered many minor annoyances, some inconsistencies,
and more than a few bugs.  Since we hadn’t yet commited to a stable
API, we could and did fix them.</p>
<p>Finally, as the rate of change of the API had decreased, more projects
were willing to try out Sequoia.  They provided additional useful
feedback, which we integrated.</p>
<p>All in all, we feel that with version 1.0 we’ve not only checked the
<a href="https://www.tomsguide.com/news/cyberpunk-2077-is-a-disaster-on-ps4-and-xbox-one-and-it-gets-worse">right boxes</a>, but we also have a high-quality API and implementation
that we can be proud of.</p>

<p>Sequoia was started 3.5 years ago by Justus Winter, Kai Michaelis and
me, Neal Walfield.  Prior to working on Sequoia, the three of us had
worked together at <a href="http://www.g10code.de/">g10code</a> on <a href="https://gnupg.org/">GnuPG</a>.  The <a href="https://pep.foundation/">p≡p foundation</a> hired
us not only to create a new OpenPGP implementation using a new
architecture and programming language, but to improve the ecosystem
around privacy-preserving tools as a whole.</p>
<p>The Sequoia library is a first step in that direction.  But it is not
our end goal.  Indeed, over the past three years, we’ve helped other
OpenPGP implementations.  We’ve reported bugs that we’ve found (thanks
in particular to our <a href="https://tests.sequoia-pgp.org/">OpenPGP interoperability test suite</a>), and even
contributed some fixes to other OpenPGP implementations.</p>
<p>And, we’ve invested in tooling.  We developed <a href="https://gitlab.com/hagrid-keyserver/hagrid">Hagrid</a>, a new
verifying OpenPGP key server, which powers <a href="https://keys.openpgp.org/">keys.openpgp.org</a> and is
now maintained by Vincent Breitmoser.  We’ve helped <a href="https://openpgp-ca.gitlab.io/openpgp-ca/">OpenPGP CA</a>, a
tool written by Heiko Schaefer to create <em>federated</em> CAs for groups
like activists, lawyers, and journalists, but also companies, who
don’t want to trust centralized infrastructure whose primary
incentives are monetary.  OpenPGP CA significantly simplifies key
discovery and authentication for unsophisticated OpenPGP users.  We’ve
developed <a href="https://gitlab.com/koverto/koverto">Koverto</a>, an SMTP proxy, which makes it easy to sign and
encrypt mails sent by services that don’t support OpenPGP out of the
box, like most CMSes.  We developed a tool, <a href="https://gitlab.com/sequoia-pgp/keyring-linter"><code>sq-keyring-linter</code></a>
(<a href="https://packages.debian.org/sid/sq-keyring-linter">Debian</a>), to help users update their OpenPGP Certificates, so that
we can <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">finally get rid of SHA-1</a>.</p>
<p>We’re thinking big.  We’re thinking not only about mail encryption or
even encryption in general, but also about integrity and
authentication.  And, we’re thinking in particular, about <a href="https://en.wikipedia.org/wiki/Public_key_infrastructure">PKI</a>.  If
users can’t easily find the <strong>right</strong> certificate for a communication
partner, encryption and digital signatures are worthless, and possibly
even dangerous.</p>

<p>In designing Sequoia, we took a library-first approach.  Although we
have a command-line tool, <a href="https://docs.sequoia-pgp.org/sq/index.html"><code>sq</code></a>, which we are not yet releasing, we
intend for the library to always provide a richer, more expressive
interface.  We agree that there is value in process separation, but we
want to avoid the dangerous complexity of <em>safely</em> shelling out to
another program.</p>
<p>The sequoia-openpgp crate (Rust’s terminology for a library) is a
low-level, policy-free OpenPGP implementation.  Our goal was to
implement all of <a href="https://tools.ietf.org/html/rfc4880">RFC 4880</a>, and provide an API that can be used to
access and modify pretty much everything, but is simultaneously secure
by default.</p>
<p>We understand low-level to mean not only an API that provides getters
and setters, but an API that provides interfaces to parse and
serialize those fields, and can combine them in ways intended by the
standard, and needed by users.  For instance, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> data
structure encapsulates an OpenPGP certificate (casually referred to as
an OpenPGP key).  It canonicalizes the structure, and makes it easy to
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html#method.revocation_status">query its properties</a>.  But, it does so in such a way that it is
still possible for a user to inspect and modify the low-level bits
themselves without reimplementing the rest of the functionality.
Another example is the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>, which makes it easy to
parse and decrypt an OpenPGP message.</p>
<p>An example of how we make the API safe by default is that it is hard
to accidentally export secret key material.  In Sequoia, you have to
explicitly <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html#secret-keys">opt-in to export it</a>.  Similarly, when <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/packet/signature/struct.SignatureBuilder.html">updating a
signature</a>, the creation time, hash algorithm, and issuer are
automatically updated.  This is usually what the user wants, but is
easy to forget, and hard to debug when forgotten.  Critically, it is
easy to opt out when that behavior is not desired.</p>
<p>While developing Sequoia, we spent a lot of time thinking about
extremes and corner cases.  For instance, OpenPGP supports
notarizations (signatures over signatures), but as far as we know no
OpenPGP implementation supports them.  We implemented support for it
anyway, and it improved the ergonomics of the common case.</p>
<h2 id="notable-details">Notable Details</h2>
<p>The devel is in the details.  And while deviloping Sequoia, we paid
attention.  Here are a few noteworthy details:</p>
<p><a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a> has been broken since 2005.  And, in 2011 NIST deprecated its
use.  Initially, we decided to simply reject any signature that used
SHA-1.  However, we were recently forced to <a href="https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/">reevaluate</a> <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/595">that
decision</a>: 22% of Debian developers use a certificate that relies on
SHA-1 as do 63% of Arch developers.  Even the Fedora release keys use
SHA-1.</p>
<p>We decided that we couldn’t simply reenable SHA-1.  After some
consideration, we’ve opted to <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/enum.HashAlgoSecurity.html">permit it</a> in contexts where collision
attacks similar to the one presented in <a href="https://sha-mbles.github.io/">SHA-1 is a Shambles</a> are
harder.  We also use a variant of SHA-1 called <a href="https://gitlab.com/sequoia-pgp/sha1collisiondetection">SHA1CD</a> (SHA-1
Collision Detection), which detects and neutralizes the known attacks
against SHA-1.  Among others, <a href="https://github.blog/2017-03-20-sha-1-collision-detection-on-github-com/">GitHub uses it</a>.  And, we have also
decided to <strong><a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/struct.StandardPolicy.html#method.reject_hash_at">start rejecting SHA-1 by default</a> at the beginning of
2023</strong>, i.e., in a bit more than two years.  This will hopefully give
Debian developers and others sufficient time to <a href="https://gitlab.com/sequoia-pgp/keyring-linter">fix</a> or replace their
certificates.</p>
<p>When we create a signature, we include a <a href="https://gitlab.com/sequoia-pgp/sequoia/-/issues/597">salt</a>.  This makes it harder
for an attacker to predict what data a user will sign.  And, it foils
attacks where an attacker needs multiple signatures over the same
message.</p>
<p>Similar to <a href="https://www.undeadly.org/cgi?action=article;sid=20190621081455">OpenSSH</a>, we <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/mem/struct.Encrypted.html">encrypt secret key material</a> while it is in
memory.  This frustrates side-channel attacks.</p>
<p>Sequoia supports <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/serialize/stream/padding/index.html">padding messages</a> to obfuscate an encrypted
message’s length.  We include support for the <a href="https://bford.info/pub/sec/purb.pdf">padmé</a> scheme, but
other schemes can be plugged in.</p>
<p>To allow users to control the policy while still using higher-level
functionality, Sequoia uses a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/index.html">policy object</a>.  A policy object is
passed to any method that checks something for validity.  For
instance, when a method needs to determine whether a binding signature
should be used, it invokes the policy object’s <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/policy/trait.Policy.html#method.signature"><code>signature</code> callback</a>.
Our experience suggests that this approach greatly simplifies dealing
with this <a href="https://en.wikipedia.org/wiki/Cross-cutting_concern">cross-cutting concern</a> in a highly flexible manner.</p>
<p>Policy objects can also be embedded in other objects.  For instance, a
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/cert/struct.ValidCert.html"><code>ValidCert</code></a> encapsulates a <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/struct.Cert.html"><code>Cert</code></a> and a policy object.  This
ensures that the application of the policy is consistent, and hard to
forget to apply.</p>
<p>In Sequoia, we prefer the use of formal grammars rather than ad-hoc
parsing when doing any non-trivial parsing.  For instance, when
verifying the structure of <a href="https://tools.ietf.org/html/rfc4880#section-11.1">OpenPGP Certificates</a> and <a href="https://tools.ietf.org/html/rfc4880#section-11.3">OpenPGP
Messages</a>, we use <a href="https://github.com/lalrpop/lalrpop">LALRPOP</a>, a parser generator, to generate the
parser.</p>
<p>Sequoia implements a streaming API.  If not careful, this can lead to
a consumer processing unauthenticated data, which was exploited by
<a href="https://efail.de/">EFAIL</a>.  To mitigate this type of failure, the <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/trait.DecryptionHelper.html"><code>DecryptionHelper</code></a>
withholds the last <code>O(1)</code> bytes of data, and only releases it if the
message can be authenticated.  This makes it harder for an attacker to
control what is released.  And for short messages, nothing is released
since the whole message is buffered.</p>
<p>We’ve tried to ensure that data structures that may be used in a
side-channel sensitive context use constant time comparisons.</p>
<p>Where possible, we use a device driver-style API so that it is
straightforward to add new backends.  For instance, our <a href="https://docs.sequoia-pgp.org/sequoia_openpgp/crypto/trait.Signer.html"><code>Signer</code></a> and
<a href="https://docs.sequoia-pgp.org/sequoia_openpgp/parse/stream/struct.Decryptor.html"><code>Decryptor</code></a> traits make it easy to implement alternative signing and
decryption backends.  In addition to the in-memory implementations, we
already have implementations that use secret key material managed by
<a href="https://docs.sequoia-pgp.org/sequoia_ipc/gnupg/struct.KeyPair.html">gpg agent</a>.</p>
<p>We tried hard to provide helpful error messages.  This is particularly
difficult …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/">https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</a></em></p>]]>
            </description>
            <link>https://sequoia-pgp.org/blog/2020/12/16/202012-1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448533</guid>
            <pubDate>Wed, 16 Dec 2020 20:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Researchers Measured the Efficacy of Every Kind of Mask. Here's What They Found]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25448300">thread link</a>) | @hindsightbias
<br/>
December 16, 2020 | https://smosa.com/researchers-measured-the-efficacy-of-every-kind-of-mask-heres-what-they-found/ | <a href="https://web.archive.org/web/*/https://smosa.com/researchers-measured-the-efficacy-of-every-kind-of-mask-heres-what-they-found/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>In a <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2769443">study published in <em>JAMA Internal Medicine</em></a>, researchers studied 29 different face masks and used fit and use guidelines by the Occupational Safety and Health Administration to evaluate the FFEs in a variety of breathers worn by a male and female volunteers.</p><figure><img src="https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="A Couple wearing pink accented gas masks joins the Protests in Washington DC" srcset="https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1591034455539-0352f7ed55ee?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI3fHxmYWNlJTIwbWFza3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@thenewmalcolm?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Obi Onyeador</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>When two people wearing masks interact, chance of SARS-CoV-2 transmission is drastically reduced. Some masks were as much as 79 percent effective at blocking particles that could carry the virus. UNC scientists researched the protectiveness of various kinds of consumer-grade and modified masks. Researchers used an approach based on the OSHA Fit Test to determine the fitted filtration efficiency of facemasks. The top-of-the-line N-95 mask proved to be 98 percent effective.</p><p>Fitted filtration efficiency tests were conducted in a custom-built exposure chamber. Masks were fitted with sampling probes using a Fit Test Probe Kit for Disposable Facepieces 8025-N95 (TSI) to allow sampling of aerosol inside the face mask. Three respirator sterilization methods were tested on used masks: ethylene oxide (EtO), steam (121 °C, 15 minutes), and vaporized hydrogen peroxide (8 g/min, 260 PPM, 100-minute cycle) The FFE of these sterilized, used masks was measured after a single sterilization cycle as described above.</p><figure><img src="https://smosa.com/content/images/2020/12/251456_web.jpg" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/251456_web.jpg 600w, https://smosa.com/content/images/size/w1000/2020/12/251456_web.jpg 1000w, https://smosa.com/content/images/2020/12/251456_web.jpg 1440w" sizes="(min-width: 720px) 720px"><figcaption>CREDIT: UNC School of Medicine, Medical procedure mask and modifications designed to enhance mask fit or comfort for the wearer. A mask w/ear loops (A) modified by tying the ear loops and tucking in the side pleats (B), attaching ear loops to a 3D-printed "ear guard" (C), fastening ear loops with a 23mm claw-type hair clip placed behind the wearer's head (D), placing ring of three, ganged, rubber bands over the mask and around the wearer's ears (E), and sliding a 10-inch segment of nylon hosiery over the fitted mask (F).</figcaption></figure><p>N95 respirators fitted to the face are the preferred choice of protection from bioaerosols. However, availability of these items may be compromised during periods of high demand, such as in a pandemic. Recently, sterilization and decontamination of face masks has emerged as a novel method to prolong the limited supply of existing respirators. The study evaluated particle penetration for commonly available face masks and alternatives. The most effective face mask achieved only 79.7% FFE, and masks with elastic ear loops were the least effective when moving the head left and right (21.2% F FE) and bent at the waist and looked up and down.</p><p>The most penetrating particle size was found to be 30 to 60 nm, which is similar in size to those used for measurements in this study. A limitation of this study is the decision to test each mask on a single man (and woman for a few comparisons) rather than a large number of individuals with a full range of facial configurations.</p><figure><img src="https://smosa.com/content/images/2020/12/IMG_2187.jpeg" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/IMG_2187.jpeg 600w, https://smosa.com/content/images/size/w1000/2020/12/IMG_2187.jpeg 1000w, https://smosa.com/content/images/2020/12/IMG_2187.jpeg 1057w" sizes="(min-width: 720px) 720px"></figure><figure><img src="https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Man wearing a black mask" srcset="https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1598207951491-255eaf139751?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDJ8fGZhY2UlMjBtYXNrfGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@gmalhotra?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Gayatri Malhotra</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Even face masks with less than 95% FFE (eg, surgical masks) are effective in preventing acquisition of epidemic coronaviruses. N95 respirators had no increased prevention benefit over surgical masks. The CDC and Infectious Diseases Society of America has recommended the use of N94 respirators.</p><p><em>Cover Photo Credit: UNC School of Medicine</em></p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/researchers-measured-the-efficacy-of-every-kind-of-mask-heres-what-they-found/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448300</guid>
            <pubDate>Wed, 16 Dec 2020 20:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Old New Adventure]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25448248">thread link</a>) | @Ygg2
<br/>
December 16, 2020 | https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>After two and a half years of being independent, I am returning to Google.</p>

<p>The time off was really valuable. I was still feeling residual effects from burnout on the Android team in late 2015, and also drained by family and personal things that were happening and needed more time and energy. I got that, and return recharged and with some insights that I hope will be useful. I’ll touch on a few of those in this post. Each could probably be its own blog post, but today I want to briefly note the event.</p>

<p>I am now a research software engineer on the Google Fonts team, working on a number of topics in font technology, including font design tools, GPU-accelerated font rendering, and evolution of font file formats to be more efficient and capable.</p>

<h2 id="on-open-source-sustainability">On open source sustainability</h2>

<p>Much has been written on open source sustainability, notably <a href="https://nadiaeghbal.com/">Nadia Eghbal</a>’s <em>Working in Public.</em> I won’t speak to open source more broadly (except to note how impressed I am with Blender and Krita), but for the specific task of building an ecosystem for a library, I think there is one model that actually works: being hired by a company that depends on that ecosystem.</p>

<p>To some extent, that’s an indictment of our capitalist system. In an ideal universe, there would be strong institutions dedicated to the public interest where open source developers could develop, researchers could research, and spend an absolute minimum of time and energy hustling for support. For software, in any case, universities are not that (as demonstrated by <a href="https://blog.cocalc.com/2019/04/12/should-i-resign-from-my-full-professor-job-to-work-fulltime-on-cocalc.html">William Stein’s experience with Cocalc at University of Washington</a>), otherwise I’d be quite tempted. In the actual world, working for a company like Google is about as close as you can come.</p>

<p>I remain skeptical of patronage-style platforms such as Patreon or Github Sponsors. I think it’s possible to make them work, but only for a small number of fortunate people, and even then, the incentives for creating maximum value aren’t that well aligned with the incentive structure of hustling on social media.</p>

<p>So me (re-)joining Google full time is basically a statement of confidence in this model of being employed to work on open source. Other models can work, and people should definitely find what works for them, but particularly for the projects I’m interested in, it makes sense.</p>

<h2 id="on-rust">On Rust</h2>

<p>I continue to love Rust, and believe it offers a stronger foundation for building software. I feel like I started my Rust journey in the early ’90s, when I was working on retrofitting <a href="https://theory.stanford.edu/~aiken/publications/papers/pldi95.pdf">static memory management</a> to ML, using explicit lifetime regions.</p>

<p>Rust adoption is trending up, including at Google. The language is in good shape, but the library ecosystem is still fairly immature, missing a number of critical pieces. Building up that ecosystem is an incredibly rewarding project.</p>

<p>I am particularly excited about Rust for font technology and infrastructure. Today, Python rules on the font design and production side, partly to the connection of typeface designer <a href="https://medium.com/type-thursday/learning-python-makes-you-a-better-designer-an-interview-with-just-van-rossum-8d4758c192d8">Just van Rossum</a> being Guido’s brother. The flexibility and expressiveness of Python makes it a good fit, but we’ve also gotten to a place where the <em>production</em> of fonts is done in Python, and the <em>consumption</em> is in C++.</p>

<p>Rust lets us build reliable, performant code that can also be deployed in production, and can be the basis of fluidly interactive UI tools. I’m not the only one who sees this potential; YesLogic is building their next-generation font shaper <a href="https://github.com/yeslogic/allsorts">Allsorts</a> in Rust, for many of the same reasons.</p>

<p>The Google Fonts team has been interested in adopting more Rust for a while, and part of my role is to facilitate that. I’m really looking forward to it.</p>

<h2 id="on-research">On research</h2>

<p>I have rebranded myself somewhat as a researcher, but that doesn’t <em>quite</em> capture the whole story either. I have always loved research, and that love sustained the energy to complete my <a href="https://levien.com/phd/phd.html">PhD</a>, but I also love building real things, and actually feel that many of these practical problems are more interesting than many of the abstract topics fashionable in academia. Just as much as writing papers and so on, I’m trying to build open source software and community around that. There isn’t really a word for this role, but even without such a word I’m trying to consciously create it for myself, and am grateful that Google is allowing me to try.</p>

<h2 id="on-the-work">On the work</h2>

<p>This is the most exciting part for me. I have a very long-term interest in 2D graphics, font technology, and UI, and have been doing a bunch of interesting things on all these fronts. I expect to spend most of my time continuing to advance research on all these frontiers.</p>

<p>The scope of these projects is large, and more ambitious than one person could really do. That’s one reason I’ve been consciously developing an open source community around them. That will continue.</p>

<p>Most of the day-to-day work on <a href="https://github.com/linebender/druid">Druid</a> and <a href="https://github.com/linebender/runebender">Runebender</a> will be done by Colin Rofls, though I very much enjoy getting my elbows in the code too and will be doing some of that.</p>

<p>A major focus will be building out the <a href="https://github.com/linebender/piet-gpu/blob/master/doc/vision.md">piet-gpu vision</a>. I believe a high-performance 2D rendering engine will be a great thing for the Rust ecosystem and with potential for large impact. It feels like good research; whether it goes into production at scale or not, I expect the things we learn from doing it will help inform the next generation of UI technology. That’s equally true for research into fundamental UI principles, for example the <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">Crochet</a> architecture for Druid.</p>

<p>There are also really exciting advances in <a href="https://github.com/linebender/spline">spline</a> technology in the pipeline. I think these have the potential to be a more appealing and productive basis for drawing fonts than cubic Béziers. The next big step is to validate whether they actually work as well as I’m hoping. That involves polishing the UX and integrating them into Runebender. If that turns out really well, a longer term (but more speculative) aspiration is to get them into a font format, where they could reduce binary size while increasing quality. It’s obvious the Google Fonts team is the best home for this work.</p>

<p>I have a lot of work in front of me, but am more excited than ever. On to an old new adventure, and may 2021 be a time of healing and renewed energy for all.</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://raphlinus.github.io/personal/2020/12/16/an-old-new-adventure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448248</guid>
            <pubDate>Wed, 16 Dec 2020 20:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Encapsulate for Easy Refactors]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25448247">thread link</a>) | @jshah111
<br/>
December 16, 2020 | https://www.jshah.dev/ruby/rails/refactor/2020/12/14/encapsulate-for-easy-refactors/ | <a href="https://web.archive.org/web/*/https://www.jshah.dev/ruby/rails/refactor/2020/12/14/encapsulate-for-easy-refactors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  
  <p><span>14 Dec 2020</span></p><p>An application is a living, breathing code base that will continually change over time. As the application evolves, early decisions won’t scale, and shortcuts taken will reveal technical debt. When the time comes to address these problems, one thing you can start doing today to make refactoring tomorrow easier is using encapsulation.</p>



<p>Imagine your application has a <code>User</code> model, and the <code>User</code> can have a role. The role is stored as a column on the model.</p>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: users</span>
<span>#</span>
<span>#  id                     :bigint(8)        not null, primary key</span>
<span>#  email                  :string           default(""), not null</span>
<span>#  first_name             :string</span>
<span>#  last_name              :string</span>
<span>#  role                   :string</span>
<span>#  created_at             :datetime         not null</span>
<span>#  updated_at             :datetime         not null</span>
<span>#</span>
<span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
<span>end</span>
</code></pre></div></div>

<p>You might have actions in your controller where you check if a user has a specific role. You might decide to directly access the role attribute and compare it with the role you care about:</p>

<div><div><pre><code><span>class</span> <span>ItemController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>def</span> <span>update</span>
    <span>if</span> <span>user</span><span>.</span><span>role</span> <span>==</span> <span>'admin'</span> <span>||</span> <span>user</span><span>.</span><span>role</span> <span>==</span> <span>'operations'</span>
       <span>update_item</span><span>(</span><span>params</span><span>[</span><span>:item_id</span><span>])</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>While this seems harmless at first, it becomes painful to refactor when you have to extend the relationship so a user can have many roles.</p>

<h2 id="extending-role-to-its-own-model">Extending Role To Its Own Model</h2>

<p>Imagine your product manager asks you to support users having multiple roles. You will have to move the role attribute from the <code>User</code> model to its own model.</p>

<h3 id="models">Models</h3>

<p>The resulting model design might look like the following. The <code>User</code> model now has a <code>has_many</code> relationship through a joining class (<code>UserRole</code>) to a <code>Role</code> model.</p>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: users</span>
<span>#</span>
<span>#  id                     :bigint(8)        not null, primary key</span>
<span>#  email                  :string           default(""), not null</span>
<span>#  first_name             :string</span>
<span>#  last_name              :string</span>
<span>#  role                   :string</span>
<span>#  created_at             :datetime         not null</span>
<span>#  updated_at             :datetime         not null</span>
<span>#</span>
<span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_roles</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:roles</span><span>,</span> <span>through: :user_roles</span>
<span>end</span>
</code></pre></div></div>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: user_roles</span>
<span>#</span>
<span>#  id         :bigint(8)        not null, primary key</span>
<span>#  created_at :datetime         not null</span>
<span>#  updated_at :datetime         not null</span>
<span>#  role_id    :bigint(8)</span>
<span>#  user_id    :bigint(8)</span>
<span>#</span>
<span>class</span> <span>UserRole</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>belongs_to</span> <span>:user</span>
  <span>belongs_to</span> <span>:role</span>
<span>end</span>
</code></pre></div></div>

<div><div><pre><code><span># == Schema Information</span>
<span>#</span>
<span># Table name: users</span>
<span>#</span>
<span>#  id                     :bigint(8)        not null, primary key</span>
<span>#  name                   :string</span>
<span>#  created_at             :datetime         not null</span>
<span>#  updated_at             :datetime         not null</span>
<span>#</span>
<span>class</span> <span>Role</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_roles</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:users</span><span>,</span> <span>through: :user_roles</span>
<span>end</span>
</code></pre></div></div>

<h3 id="usage">Usage</h3>

<p>Instead of checking if a <code>user.role</code> is equal to a role, we’ll now check if a specific role is in the list of roles attached to a user.</p>

<div><div><pre><code><span>admin_role</span> <span>=</span> <span>Role</span><span>.</span><span>create</span><span>(</span><span>name: </span><span>'admin'</span><span>)</span>
<span>operations_role</span> <span>=</span> <span>Role</span><span>.</span><span>create</span><span>(</span><span>name</span> <span>:</span> <span>'operations'</span><span>)</span>
<span>user</span> <span>=</span> <span>User</span><span>.</span><span>find</span><span>(</span><span>1</span><span>)</span>

<span># add roles to user</span>
<span>user</span><span>.</span><span>roles</span> <span>&lt;&lt;</span> <span>admin_role</span>
<span>user</span><span>.</span><span>roles</span> <span>&lt;&lt;</span> <span>operations_role</span>
<span>user</span><span>.</span><span>roles</span> <span># [&lt;Role name: 'admin'&gt;, &lt;Role name: 'operations'&gt;]</span>

<span># check if a user is an admin</span>
<span>user</span><span>.</span><span>roles</span><span>.</span><span>exists?</span><span>(</span><span>name: </span><span>'admin'</span><span>)</span> <span># true</span>
</code></pre></div></div>

<h3 id="refactoring-usages">Refactoring Usages</h3>

<p>When we refactor the <code>ItemController</code> to use these new models and methods, we first want to bring all methods into the <code>User</code> class and then update usages.</p>

<div><div><pre><code><span># Encapsulate all User role related methods.</span>
<span># New feature is also gated behind a feature flag.</span>

<span>class</span> <span>User</span> <span>&lt;</span> <span>ApplicationRecord</span>
  <span>has_many</span> <span>:user_roles</span><span>,</span> <span>dependent: :destroy</span>
  <span>has_many</span> <span>:roles</span><span>,</span> <span>through: :user_roles</span>

  <span>def</span> <span>has_role?</span><span>(</span><span>role_name</span><span>)</span>
    <span>if</span> <span>feature_flag_on?</span>
      <span>roles</span><span>.</span><span>exists?</span><span>(</span><span>name: </span><span>role_name</span><span>)</span>
    <span>else</span>
      <span>role</span> <span>==</span> <span>role_name</span>
    <span>end</span>
  <span>end</span>

  <span>def</span> <span>admin?</span>
    <span>has_role?</span><span>(</span><span>'admin'</span><span>)</span>
  <span>end</span>

  <span>def</span> <span>operations?</span>
    <span>has_role?</span><span>(</span><span>'operations'</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>With these methods now encapsulated in the <code>User</code> class, checking if a user has a certain role becomes easy!</p>

<div><div><pre><code><span># No explicit feature flag check needed.</span>
<span># All logic is encapsulated inside the User methods.</span>

<span>class</span> <span>ItemController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>def</span> <span>update</span>
    <span>if</span> <span>user</span><span>.</span><span>admin?</span> <span>||</span> <span>user</span><span>.</span><span>operations?</span>
       <span>update_item</span><span>(</span><span>params</span><span>[</span><span>:item_id</span><span>])</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

</div>



    </div></div>]]>
            </description>
            <link>https://www.jshah.dev/ruby/rails/refactor/2020/12/14/encapsulate-for-easy-refactors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25448247</guid>
            <pubDate>Wed, 16 Dec 2020 20:36:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fight “Cancel Culture” on Campus]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447993">thread link</a>) | @Reedx
<br/>
December 16, 2020 | https://www.persuasion.community/p/fight-cancel-culture-on-campus | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/fight-cancel-culture-on-campus">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F904a2ea2-8235-4988-9603-e6489cfd4c13_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F904a2ea2-8235-4988-9603-e6489cfd4c13_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/904a2ea2-8235-4988-9603-e6489cfd4c13_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1567070,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>College leaders rarely get it right when it comes to campus free-speech controversies. Too often their responses are confused, slow, ambivalent, contradictory or downright illiberal.</p><p>Take, for example, St. John’s University in Queens, New York. It <a href="https://www.stjohns.edu/about/leadership-and-administration/administrative-offices/office-provost/policies-procedures-and-reports">advertises</a> “freedom of inquiry.” But earlier this fall, it found a professor <a href="https://www.thefire.org/teaching-history-not-permitted-st-johns-bulldozes-academic-freedom-punishes-professor-for-posing-question-about-columbian-exchange/">guilty</a> of “bias, discrimination, and harassment” for asking his introductory history class if the positives of expanding global trade in the 15th and 16th centuries justified the negatives. The slave trade was part of this phenomenon, so some people judged the question off-limits, and a <a href="https://www.instagram.com/p/CE9udVzpYkC/">group</a> of self-declared radicals petitioned to have him fired. Now, adjunct professor Richard Taylor, a former 9/11 first responder, cannot even serve as a guest lecturer about 9/11—<a href="https://www.thefire.org/update-st-johns-limits-academic-freedom-of-history-department-in-ongoing-effort-to-punish-professor-for-asking-question/">he’s barred from teaching</a>.</p><p>Then there’s the case from earlier this year at Babson College. Administrators demonstrated that they understood comedy as poorly as they understood free expression when it came to Professor Asheen Phansey, who made a private, satirical joke on Facebook. He was responding to President Donald Trump’s threat to bomb 52 Iranian locations, including cultural sites. “In retaliation,” Phansey quipped, “Ayatollah Khomenei should tweet a list of 52 sites of beloved American cultural heritage that he would bomb. Um… Mall of America? …Kardashian residence?” The administrators <a href="https://www.thefire.org/babson-college-abandons-freedom-of-expression-fires-professor-over-facebook-post-criticizing-trump-threat-to-bomb-iran-cultural-sites/">fired</a> him.</p><div><p>College leaders please nobody when they try to please everybody in a cancel campaign. So why try? Instead, why not defend the core enlightenment mission of a college, which the University of Chicago describes as the “discovery, improvement, and dissemination of knowledge”? That language appears in the <a href="http://www-news.uchicago.edu/releases/07/pdf/kalverpt.pdf">Kalven Report</a>, which the university commissioned in 1967 to address the tension between open inquiry and activism in a university environment. The report states that “a university must sustain an extraordinary environment of freedom of inquiry and maintain an independence from political fashions, passions, and pressures.”</p><p>Living up to these values may be hard but, with sufficient courage, it’s possible. Perhaps the best example of a college president with backbone when faced with an effort to banish a professor comes from 20 years ago, before “cancel culture” was part of our popular lexicon.</p></div><div><p>In December 2000, the renowned poet and University of Alaska Professor Linda McCarriston published a poem called “<a href="https://www.thefire.org/linda-mccarristons-indian-girls-2/">Indian Girls</a>,” about alcoholism and the sexual abuse of children in Native American communities. Students protested, including some in McCarriston’s class. They <a href="https://www.thefire.org/professors-poem-draws-fiery-conflict/">argued</a> that the poem was insulting and stereotyping of Native communities. Then came the investigation. That is, until the university president, Mark R. Hamilton, heard about it. </p><p>Hamilton was a <a href="https://www.alaska.edu/uajourney/presidents/1998-2010-mark-r.-hamilto/">retired U.S. Army major general</a> who brokered peace negotiations in El Salvador and Somalia. He was also an admirer of the First Amendment’s protection for freedom of speech, and knew it was his job as a government official leading a public university system to guarantee that protection. </p></div><p>Besides the “Indian Girls” imbroglio, there was also a controversy around an invited campus speaker, and an open letter from faculty members written to President Bill Clinton against a proposal to drill within the Arctic National Wildlife Refuge. The open letter prompted Alaska’s governor to call Hamilton to complain: What are you going to do about it?</p><p>Responding to all three matters at once, Hamilton wrote an <a href="https://www.thefire.org/president-hamiltons-memo/">open letter of his own</a>. “What I want to make clear and unambiguous is that responses to complaints or demands for action regarding constitutionally guaranteed freedoms of speech CANNOT BE QUALIFIED,” he wrote. </p><p>“Attempts to assuage anger or to demonstrate concern by qualifying our support for free speech serve to cloud what must be a clear message. Noting that, for example, ‘The University supports the right to free speech, but we intend to check into this matter,’ or ‘The University supports the right of free speech, but I have asked Dean X or Provost Y to investigate the circumstances,’ is unacceptable. There is nothing to ‘check into,’ nothing ‘to investigate.’ ” </p><p>Case closed.</p><p><strong>For years, we at the <a href="http://thefire.org/">Foundation for Individual Rights in Education</a> (FIRE) </strong>have worked to defend free speech and academic freedom on campus. Two observations we can make are: 1) colleges used to get in front of these controversies faster and more categorically than they do now; and 2) when they do remove the possibility of punishment and assert their values from the beginning, the demands tend to peter out, often quickly.&nbsp;</p><p>Qualifying free-speech defenses, we find, only prolongs the fight and emboldens would-be censors. What’s more, leaders at public colleges need to be careful: Investigating protected speech can result in legal liability. As the University of Alaska president Hamilton wrote, when it comes to speech protected by the First Amendment, “There is nothing to ‘check into,’ nothing ‘to investigate.’”</p><p>While rarer, we do see shades of Hamilton’s response from some of today’s more courageous college presidents.&nbsp;Last year, the president of University of the Arts in Philadelphia, David Yager, rejected calls to fire Professor Camille Paglia over her statements surrounding the #MeToo movement and transgender people: “Across our nation it is all too common that opinions expressed that differ from another’s—especially those that are controversial—can spark passion and even outrage, often resulting in calls to suppress that speech,” he wrote <a href="https://www.uarts.edu/node/43674">in a letter</a> to the university community. “That simply cannot be allowed to happen.”&nbsp;</p><p>The would-be censors called his letter “<a href="https://www.change.org/p/uarts-president-david-yager-uarts-support-transgender-students-and-survivors-of-sexual-assault">wildly ignorant</a>.” But the controversy soon fizzled and the demands stopped, much as they did at the University of Alaska. Yager’s letter, like Hamilton’s, left no room for compromise.</p><p>Most recently, the University of Chicago president, Robert Zimmer, wrote a community-wide email of his own, rejecting calls to punish a geophysical sciences professor, Dorian Abbot, for videos he had made critiquing diversity initiatives. A total of 129 students, alumni, and staff wrote <a href="https://docs.google.com/document/d/1fCOezNmxmaeVLSirrYp9y2nzy7m9Yr-rgPulwW-eNDw/edit">an open letter</a> to his faculty alleging that Abbot’s videos “threaten the safety and belonging of all underrepresented groups” and “represent an aggressive act towards the research and teaching communities of which Professor Abbot is a member.”&nbsp;</p><div><p>To this, Zimmer <a href="https://president.uchicago.edu/page/statement-faculty-free-expression-and-diversity">wrote</a> to the campus community: “The University does not limit the comments of faculty members, mandate apologies, or impose other disciplinary consequences for such comments, unless there has been a violation of University policy or the law.” (Under normal circumstances, that last clause about “University Policy” might worry us, but Chicago receives <a href="https://www.thefire.org/schools/university-of-chicago/">a “green-light” rating</a> from FIRE, which means it does not maintain any policies that threaten free expression.)</p><p>Sometimes, college leaders—or, more often, those at the center of the controversy—make matters worse by apologizing for hurt feelings. In a perfect world, a heartfelt, genuine apology would settle matters and placate the mob. But during a cancel campaign, apologies tend to be received as confessions that you <em>are</em> a witch deserving of further persecution.&nbsp;</p></div><p>Research backs this up. <a href="https://www.cambridge.org/core/journals/behavioural-public-policy/article/does-apologizing-work-an-empirical-test-of-the-conventional-wisdom/D34F1D89E6FF6A6E32C22C75F0C5FE24">A 2019 study</a> of whether apologizing works found that “when a prominent figure apologizes for a controversial statement, individuals are either unaffected or become more likely to desire that the individual be punished.” The scholar Cass Sunstein, of Harvard Law School, conducted a similar study and <a href="https://www.nytimes.com/2019/07/27/opinion/sunday/when-should-a-politician-apologize.html">found</a> that “an apology tended to decrease rather than to increase overall support for those who said or did things that many people consider offensive.”</p><p><strong>So what is the antidote to campus cancel campaigns? </strong>A strong, unequivocal defense of the right to free inquiry and expression <em>after</em> the campaign begins is important. But much of the groundwork for a successful defense begins <em>before</em> the campaign. Here are three vital practices.</p><ul><li><p><strong>Stop violating the law</strong>. Public colleges in the United States are bound by the First Amendment, yet <a href="https://www.thefire.org/resources/spotlight/reports/spotlight-on-speech-codes-2021/">85% of them maintain speech codes</a> that restrict speech protected by the Constitution. We have a group of lawyers whose full-time job it is to work collegially with campus administrators to help them fix restrictive speech codes. We are happy to help.</p></li><li><p><strong>Commit and recommit to free speech and inquiry</strong>. Faculty and administrators should seek out opportunities to enshrine protections for free speech and inquiry in campus policy. These policies should be adopted publicly and conspicuously. The <a href="https://www.thefire.org/get-involved/student-network/take-action/adopting-the-chicago-statement/">Chicago Statement</a>—a freedom-of-expression declaration from the University of Chicago in 2014—is one such policy that colleges can easily adopt and adapt, and <a href="https://www.thefire.org/chicago-statement-university-and-faculty-body-support/">78 have already done so</a>. Same goes for the aforementioned <a href="http://www-news.uchicago.edu/releases/07/pdf/kalverpt.pdf">Kalven Report</a>. (There’s a reason <a href="https://www.thefire.org/research/publications/student-surveys/2020-college-free-speech-rankings/2020-college-free-speech-rankings-view-rankings/">student survey data</a> finds the University of Chicago to be the number one school for free speech in the country.) </p></li><li><p><strong>Teach students about free speech from day one</strong>. Principles of free speech can run counter to our moral intuitions, and may be taken for granted. But the principles are essential if colleges are to fulfill their core missions. Sadly, few incoming students are aware of these principles and their role in the larger project of human knowledge. Only a handful of colleges teach them in their orientation programming. That is why we joined with New York University’s First Amendment Watch to create <a href="https://www.thefire.org/resources/free-speech-freshman-orientation/">a series of orientation modules and videos</a> that are ready for colleges to use right away.</p></li></ul><p>Fighting cancel culture isn’t easy for campus leaders. It’s a fight that seems to get more challenging every day. But, while the war might be neverending, individual battles can be won. Courageous leaders have shown us a way—it’s up to others to follow it.</p><p><strong>Greg Lukianoff is president and chief executive and Nico Perrino is vice president for the <a href="https://www.thefire.org/">Foundation for Individual Rights in Education</a> (FIRE). Both are producers of the recently released free-speech documentary, <a href="http://mightyira.com/">Mighty Ira: A Civil Liberties Story</a>.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/fight-cancel-culture-on-campus</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447993</guid>
            <pubDate>Wed, 16 Dec 2020 20:19:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Sorbet in Y Minutes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447883">thread link</a>) | @jdkaplan
<br/>
December 16, 2020 | https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/ | <a href="https://web.archive.org/web/*/https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>We’ve been increasing our adoption of <a href="https://sorbet.org/">Sorbet</a> at <a href="https://gusto.com/">Gusto</a>!
As I’ve been trying to type more and more complex bits of Ruby, I’ve found it helpful to have a single page of examples that I can search through easily.</p><p>I like learning new programming languages with <a href="https://learnxinyminutes.com/">Learn X in Y minutes</a>, so I tried to make this digestible in the same way.</p><p>If you use this, let me know what you think!
I’m open to improving this to work for more people, and I’m also interested in learning what your value of <code>Y</code> is.</p><p>The easiest way to see this in action is on <a href="https://sorbet.run/">sorbet.run</a>.
Here’s a link for each section below:</p><div><div>
<table><tbody><tr><td>
<pre><code><span>   1
</span><span>   2
</span><span>   3
</span><span>   4
</span><span>   5
</span><span>   6
</span><span>   7
</span><span>   8
</span><span>   9
</span><span>  10
</span><span>  11
</span><span>  12
</span><span>  13
</span><span>  14
</span><span>  15
</span><span>  16
</span><span>  17
</span><span>  18
</span><span>  19
</span><span>  20
</span><span>  21
</span><span>  22
</span><span>  23
</span><span>  24
</span><span>  25
</span><span>  26
</span><span>  27
</span><span>  28
</span><span>  29
</span><span>  30
</span><span>  31
</span><span>  32
</span><span>  33
</span><span>  34
</span><span>  35
</span><span>  36
</span><span>  37
</span><span>  38
</span><span>  39
</span><span>  40
</span><span>  41
</span><span>  42
</span><span>  43
</span><span>  44
</span><span>  45
</span><span>  46
</span><span>  47
</span><span>  48
</span><span>  49
</span><span>  50
</span><span>  51
</span><span>  52
</span><span>  53
</span><span>  54
</span><span>  55
</span><span>  56
</span><span>  57
</span><span>  58
</span><span>  59
</span><span>  60
</span><span>  61
</span><span>  62
</span><span>  63
</span><span>  64
</span><span>  65
</span><span>  66
</span><span>  67
</span><span>  68
</span><span>  69
</span><span>  70
</span><span>  71
</span><span>  72
</span><span>  73
</span><span>  74
</span><span>  75
</span><span>  76
</span><span>  77
</span><span>  78
</span><span>  79
</span><span>  80
</span><span>  81
</span><span>  82
</span><span>  83
</span><span>  84
</span><span>  85
</span><span>  86
</span><span>  87
</span><span>  88
</span><span>  89
</span><span>  90
</span><span>  91
</span><span>  92
</span><span>  93
</span><span>  94
</span><span>  95
</span><span>  96
</span><span>  97
</span><span>  98
</span><span>  99
</span><span> 100
</span><span> 101
</span><span> 102
</span><span> 103
</span><span> 104
</span><span> 105
</span><span> 106
</span><span> 107
</span><span> 108
</span><span> 109
</span><span> 110
</span><span> 111
</span><span> 112
</span><span> 113
</span><span> 114
</span><span> 115
</span><span> 116
</span><span> 117
</span><span> 118
</span><span> 119
</span><span> 120
</span><span> 121
</span><span> 122
</span><span> 123
</span><span> 124
</span><span> 125
</span><span> 126
</span><span> 127
</span><span> 128
</span><span> 129
</span><span> 130
</span><span> 131
</span><span> 132
</span><span> 133
</span><span> 134
</span><span> 135
</span><span> 136
</span><span> 137
</span><span> 138
</span><span> 139
</span><span> 140
</span><span> 141
</span><span> 142
</span><span> 143
</span><span> 144
</span><span> 145
</span><span> 146
</span><span> 147
</span><span> 148
</span><span> 149
</span><span> 150
</span><span> 151
</span><span> 152
</span><span> 153
</span><span> 154
</span><span> 155
</span><span> 156
</span><span> 157
</span><span> 158
</span><span> 159
</span><span> 160
</span><span> 161
</span><span> 162
</span><span> 163
</span><span> 164
</span><span> 165
</span><span> 166
</span><span> 167
</span><span> 168
</span><span> 169
</span><span> 170
</span><span> 171
</span><span> 172
</span><span> 173
</span><span> 174
</span><span> 175
</span><span> 176
</span><span> 177
</span><span> 178
</span><span> 179
</span><span> 180
</span><span> 181
</span><span> 182
</span><span> 183
</span><span> 184
</span><span> 185
</span><span> 186
</span><span> 187
</span><span> 188
</span><span> 189
</span><span> 190
</span><span> 191
</span><span> 192
</span><span> 193
</span><span> 194
</span><span> 195
</span><span> 196
</span><span> 197
</span><span> 198
</span><span> 199
</span><span> 200
</span><span> 201
</span><span> 202
</span><span> 203
</span><span> 204
</span><span> 205
</span><span> 206
</span><span> 207
</span><span> 208
</span><span> 209
</span><span> 210
</span><span> 211
</span><span> 212
</span><span> 213
</span><span> 214
</span><span> 215
</span><span> 216
</span><span> 217
</span><span> 218
</span><span> 219
</span><span> 220
</span><span> 221
</span><span> 222
</span><span> 223
</span><span> 224
</span><span> 225
</span><span> 226
</span><span> 227
</span><span> 228
</span><span> 229
</span><span> 230
</span><span> 231
</span><span> 232
</span><span> 233
</span><span> 234
</span><span> 235
</span><span> 236
</span><span> 237
</span><span> 238
</span><span> 239
</span><span> 240
</span><span> 241
</span><span> 242
</span><span> 243
</span><span> 244
</span><span> 245
</span><span> 246
</span><span> 247
</span><span> 248
</span><span> 249
</span><span> 250
</span><span> 251
</span><span> 252
</span><span> 253
</span><span> 254
</span><span> 255
</span><span> 256
</span><span> 257
</span><span> 258
</span><span> 259
</span><span> 260
</span><span> 261
</span><span> 262
</span><span> 263
</span><span> 264
</span><span> 265
</span><span> 266
</span><span> 267
</span><span> 268
</span><span> 269
</span><span> 270
</span><span> 271
</span><span> 272
</span><span> 273
</span><span> 274
</span><span> 275
</span><span> 276
</span><span> 277
</span><span> 278
</span><span> 279
</span><span> 280
</span><span> 281
</span><span> 282
</span><span> 283
</span><span> 284
</span><span> 285
</span><span> 286
</span><span> 287
</span><span> 288
</span><span> 289
</span><span> 290
</span><span> 291
</span><span> 292
</span><span> 293
</span><span> 294
</span><span> 295
</span><span> 296
</span><span> 297
</span><span> 298
</span><span> 299
</span><span> 300
</span><span> 301
</span><span> 302
</span><span> 303
</span><span> 304
</span><span> 305
</span><span> 306
</span><span> 307
</span><span> 308
</span><span> 309
</span><span> 310
</span><span> 311
</span><span> 312
</span><span> 313
</span><span> 314
</span><span> 315
</span><span> 316
</span><span> 317
</span><span> 318
</span><span> 319
</span><span> 320
</span><span> 321
</span><span> 322
</span><span> 323
</span><span> 324
</span><span> 325
</span><span> 326
</span><span> 327
</span><span> 328
</span><span> 329
</span><span> 330
</span><span> 331
</span><span> 332
</span><span> 333
</span><span> 334
</span><span> 335
</span><span> 336
</span><span> 337
</span><span> 338
</span><span> 339
</span><span> 340
</span><span> 341
</span><span> 342
</span><span> 343
</span><span> 344
</span><span> 345
</span><span> 346
</span><span> 347
</span><span> 348
</span><span> 349
</span><span> 350
</span><span> 351
</span><span> 352
</span><span> 353
</span><span> 354
</span><span> 355
</span><span> 356
</span><span> 357
</span><span> 358
</span><span> 359
</span><span> 360
</span><span> 361
</span><span> 362
</span><span> 363
</span><span> 364
</span><span> 365
</span><span> 366
</span><span> 367
</span><span> 368
</span><span> 369
</span><span> 370
</span><span> 371
</span><span> 372
</span><span> 373
</span><span> 374
</span><span> 375
</span><span> 376
</span><span> 377
</span><span> 378
</span><span> 379
</span><span> 380
</span><span> 381
</span><span> 382
</span><span> 383
</span><span> 384
</span><span> 385
</span><span> 386
</span><span> 387
</span><span> 388
</span><span> 389
</span><span> 390
</span><span> 391
</span><span> 392
</span><span> 393
</span><span> 394
</span><span> 395
</span><span> 396
</span><span> 397
</span><span> 398
</span><span> 399
</span><span> 400
</span><span> 401
</span><span> 402
</span><span> 403
</span><span> 404
</span><span> 405
</span><span> 406
</span><span> 407
</span><span> 408
</span><span> 409
</span><span> 410
</span><span> 411
</span><span> 412
</span><span> 413
</span><span> 414
</span><span> 415
</span><span> 416
</span><span> 417
</span><span> 418
</span><span> 419
</span><span> 420
</span><span> 421
</span><span> 422
</span><span> 423
</span><span> 424
</span><span> 425
</span><span> 426
</span><span> 427
</span><span> 428
</span><span> 429
</span><span> 430
</span><span> 431
</span><span> 432
</span><span> 433
</span><span> 434
</span><span> 435
</span><span> 436
</span><span> 437
</span><span> 438
</span><span> 439
</span><span> 440
</span><span> 441
</span><span> 442
</span><span> 443
</span><span> 444
</span><span> 445
</span><span> 446
</span><span> 447
</span><span> 448
</span><span> 449
</span><span> 450
</span><span> 451
</span><span> 452
</span><span> 453
</span><span> 454
</span><span> 455
</span><span> 456
</span><span> 457
</span><span> 458
</span><span> 459
</span><span> 460
</span><span> 461
</span><span> 462
</span><span> 463
</span><span> 464
</span><span> 465
</span><span> 466
</span><span> 467
</span><span> 468
</span><span> 469
</span><span> 470
</span><span> 471
</span><span> 472
</span><span> 473
</span><span> 474
</span><span> 475
</span><span> 476
</span><span> 477
</span><span> 478
</span><span> 479
</span><span> 480
</span><span> 481
</span><span> 482
</span><span> 483
</span><span> 484
</span><span> 485
</span><span> 486
</span><span> 487
</span><span> 488
</span><span> 489
</span><span> 490
</span><span> 491
</span><span> 492
</span><span> 493
</span><span> 494
</span><span> 495
</span><span> 496
</span><span> 497
</span><span> 498
</span><span> 499
</span><span> 500
</span><span> 501
</span><span> 502
</span><span> 503
</span><span> 504
</span><span> 505
</span><span> 506
</span><span> 507
</span><span> 508
</span><span> 509
</span><span> 510
</span><span> 511
</span><span> 512
</span><span> 513
</span><span> 514
</span><span> 515
</span><span> 516
</span><span> 517
</span><span> 518
</span><span> 519
</span><span> 520
</span><span> 521
</span><span> 522
</span><span> 523
</span><span> 524
</span><span> 525
</span><span> 526
</span><span> 527
</span><span> 528
</span><span> 529
</span><span> 530
</span><span> 531
</span><span> 532
</span><span> 533
</span><span> 534
</span><span> 535
</span><span> 536
</span><span> 537
</span><span> 538
</span><span> 539
</span><span> 540
</span><span> 541
</span><span> 542
</span><span> 543
</span><span> 544
</span><span> 545
</span><span> 546
</span><span> 547
</span><span> 548
</span><span> 549
</span><span> 550
</span><span> 551
</span><span> 552
</span><span> 553
</span><span> 554
</span><span> 555
</span><span> 556
</span><span> 557
</span><span> 558
</span><span> 559
</span><span> 560
</span><span> 561
</span><span> 562
</span><span> 563
</span><span> 564
</span><span> 565
</span><span> 566
</span><span> 567
</span><span> 568
</span><span> 569
</span><span> 570
</span><span> 571
</span><span> 572
</span><span> 573
</span><span> 574
</span><span> 575
</span><span> 576
</span><span> 577
</span><span> 578
</span><span> 579
</span><span> 580
</span><span> 581
</span><span> 582
</span><span> 583
</span><span> 584
</span><span> 585
</span><span> 586
</span><span> 587
</span><span> 588
</span><span> 589
</span><span> 590
</span><span> 591
</span><span> 592
</span><span> 593
</span><span> 594
</span><span> 595
</span><span> 596
</span><span> 597
</span><span> 598
</span><span> 599
</span><span> 600
</span><span> 601
</span><span> 602
</span><span> 603
</span><span> 604
</span><span> 605
</span><span> 606
</span><span> 607
</span><span> 608
</span><span> 609
</span><span> 610
</span><span> 611
</span><span> 612
</span><span> 613
</span><span> 614
</span><span> 615
</span><span> 616
</span><span> 617
</span><span> 618
</span><span> 619
</span><span> 620
</span><span> 621
</span><span> 622
</span><span> 623
</span><span> 624
</span><span> 625
</span><span> 626
</span><span> 627
</span><span> 628
</span><span> 629
</span><span> 630
</span><span> 631
</span><span> 632
</span><span> 633
</span><span> 634
</span><span> 635
</span><span> 636
</span><span> 637
</span><span> 638
</span><span> 639
</span><span> 640
</span><span> 641
</span><span> 642
</span><span> 643
</span><span> 644
</span><span> 645
</span><span> 646
</span><span> 647
</span><span> 648
</span><span> 649
</span><span> 650
</span><span> 651
</span><span> 652
</span><span> 653
</span><span> 654
</span><span> 655
</span><span> 656
</span><span> 657
</span><span> 658
</span><span> 659
</span><span> 660
</span><span> 661
</span><span> 662
</span><span> 663
</span><span> 664
</span><span> 665
</span><span> 666
</span><span> 667
</span><span> 668
</span><span> 669
</span><span> 670
</span><span> 671
</span><span> 672
</span><span> 673
</span><span> 674
</span><span> 675
</span><span> 676
</span><span> 677
</span><span> 678
</span><span> 679
</span><span> 680
</span><span> 681
</span><span> 682
</span><span> 683
</span><span> 684
</span><span> 685
</span><span> 686
</span><span> 687
</span><span> 688
</span><span> 689
</span><span> 690
</span><span> 691
</span><span> 692
</span><span> 693
</span><span> 694
</span><span> 695
</span><span> 696
</span><span> 697
</span><span> 698
</span><span> 699
</span><span> 700
</span><span> 701
</span><span> 702
</span><span> 703
</span><span> 704
</span><span> 705
</span><span> 706
</span><span> 707
</span><span> 708
</span><span> 709
</span><span> 710
</span><span> 711
</span><span> 712
</span><span> 713
</span><span> 714
</span><span> 715
</span><span> 716
</span><span> 717
</span><span> 718
</span><span> 719
</span><span> 720
</span><span> 721
</span><span> 722
</span><span> 723
</span><span> 724
</span><span> 725
</span><span> 726
</span><span> 727
</span><span> 728
</span><span> 729
</span><span> 730
</span><span> 731
</span><span> 732
</span><span> 733
</span><span> 734
</span><span> 735
</span><span> 736
</span><span> 737
</span><span> 738
</span><span> 739
</span><span> 740
</span><span> 741
</span><span> 742
</span><span> 743
</span><span> 744
</span><span> 745
</span><span> 746
</span><span> 747
</span><span> 748
</span><span> 749
</span><span> 750
</span><span> 751
</span><span> 752
</span><span> 753
</span><span> 754
</span><span> 755
</span><span> 756
</span><span> 757
</span><span> 758
</span><span> 759
</span><span> 760
</span><span> 761
</span><span> 762
</span><span> 763
</span><span> 764
</span><span> 765
</span><span> 766
</span><span> 767
</span><span> 768
</span><span> 769
</span><span> 770
</span><span> 771
</span><span> 772
</span><span> 773
</span><span> 774
</span><span> 775
</span><span> 776
</span><span> 777
</span><span> 778
</span><span> 779
</span><span> 780
</span><span> 781
</span><span> 782
</span><span> 783
</span><span> 784
</span><span> 785
</span><span> 786
</span><span> 787
</span><span> 788
</span><span> 789
</span><span> 790
</span><span> 791
</span><span> 792
</span><span> 793
</span><span> 794
</span><span> 795
</span><span> 796
</span><span> 797
</span><span> 798
</span><span> 799
</span><span> 800
</span><span> 801
</span><span> 802
</span><span> 803
</span><span> 804
</span><span> 805
</span><span> 806
</span><span> 807
</span><span> 808
</span><span> 809
</span><span> 810
</span><span> 811
</span><span> 812
</span><span> 813
</span><span> 814
</span><span> 815
</span><span> 816
</span><span> 817
</span><span> 818
</span><span> 819
</span><span> 820
</span><span> 821
</span><span> 822
</span><span> 823
</span><span> 824
</span><span> 825
</span><span> 826
</span><span> 827
</span><span> 828
</span><span> 829
</span><span> 830
</span><span> 831
</span><span> 832
</span><span> 833
</span><span> 834
</span><span> 835
</span><span> 836
</span><span> 837
</span><span> 838
</span><span> 839
</span><span> 840
</span><span> 841
</span><span> 842
</span><span> 843
</span><span> 844
</span><span> 845
</span><span> 846
</span><span> 847
</span><span> 848
</span><span> 849
</span><span> 850
</span><span> 851
</span><span> 852
</span><span> 853
</span><span> 854
</span><span> 855
</span><span> 856
</span><span> 857
</span><span> 858
</span><span> 859
</span><span> 860
</span><span> 861
</span><span> 862
</span><span> 863
</span><span> 864
</span><span> 865
</span><span> 866
</span><span> 867
</span><span> 868
</span><span> 869
</span><span> 870
</span><span> 871
</span><span> 872
</span><span> 873
</span><span> 874
</span><span> 875
</span><span> 876
</span><span> 877
</span><span> 878
</span><span> 879
</span><span> 880
</span><span> 881
</span><span> 882
</span><span> 883
</span><span> 884
</span><span> 885
</span><span> 886
</span><span> 887
</span><span> 888
</span><span> 889
</span><span> 890
</span><span> 891
</span><span> 892
</span><span> 893
</span><span> 894
</span><span> 895
</span><span> 896
</span><span> 897
</span><span> 898
</span><span> 899
</span><span> 900
</span><span> 901
</span><span> 902
</span><span> 903
</span><span> 904
</span><span> 905
</span><span> 906
</span><span> 907
</span><span> 908
</span><span> 909
</span><span> 910
</span><span> 911
</span><span> 912
</span><span> 913
</span><span> 914
</span><span> 915
</span><span> 916
</span><span> 917
</span><span> 918
</span><span> 919
</span><span> 920
</span><span> 921
</span><span> 922
</span><span> 923
</span><span> 924
</span><span> 925
</span><span> 926
</span><span> 927
</span><span> 928
</span><span> 929
</span><span> 930
</span><span> 931
</span><span> 932
</span><span> 933
</span><span> 934
</span><span> 935
</span><span> 936
</span><span> 937
</span><span> 938
</span><span> 939
</span><span> 940
</span><span> 941
</span><span> 942
</span><span> 943
</span><span> 944
</span><span> 945
</span><span> 946
</span><span> 947
</span><span> 948
</span><span> 949
</span><span> 950
</span><span> 951
</span><span> 952
</span><span> 953
</span><span> 954
</span><span> 955
</span><span> 956
</span><span> 957
</span><span> 958
</span><span> 959
</span><span> 960
</span><span> 961
</span><span> 962
</span><span> 963
</span><span> 964
</span><span> 965
</span><span> 966
</span><span> 967
</span><span> 968
</span><span> 969
</span><span> 970
</span><span> 971
</span><span> 972
</span><span> 973
</span><span> 974
</span><span> 975
</span><span> 976
</span><span> 977
</span><span> 978
</span><span> 979
</span><span> 980
</span><span> 981
</span><span> 982
</span><span> 983
</span><span> 984
</span><span> 985
</span><span> 986
</span><span> 987
</span><span> 988
</span><span> 989
</span><span> 990
</span><span> 991
</span><span> 992
</span><span> 993
</span><span> 994
</span><span> 995
</span><span> 996
</span><span> 997
</span><span> 998
</span><span> 999
</span><span>1000
</span><span>1001
</span><span>1002
</span><span>1003
</span><span>1004
</span><span>1005
</span><span>1006
</span><span>1007
</span><span>1008
</span><span>1009
</span><span>1010
</span></code></pre></td>
<td>
<pre><code data-lang="ruby"><span># Every file should have a "typed sigil" that tells Sorbet how strict to be</span>
<span># during static type checking.</span>
<span>#</span>
<span># Strictness levels (lax to strict):</span>
<span>#</span>
<span># ignore: Sorbet won't even read the file.  This means its contents are not</span>
<span># visible during type checking.  Avoid this.</span>
<span>#</span>
<span># false: Sorbet will only report errors related to constant resolution.  This</span>
<span># is the default if no sigil is included.</span>
<span>#</span>
<span># true: Sorbet will report all static type errors.  This is the sweet spot of</span>
<span># safety for effort.</span>
<span>#</span>
<span># strict: Sorbet will require that all methods, constants, and instance</span>
<span># variables have static types.</span>
<span>#</span>
<span># strong: Sorbet will no longer allow anything to be T.untyped, even</span>
<span># explicitly.  Almost nothing satisfies this.</span>

<span># typed: true</span>

<span># Include the runtime type-checking library.  This lets you write inline sigs</span>
<span># and have them checked at runtime (instead of running Sorbet as RBI-only).</span>
<span># These runtime checks happen even for files with `ignore` or `false` sigils.</span>
<span>require</span> <span>'sorbet-runtime'</span>

<span>class</span> <span>BasicSigs</span>
  <span># Bring in the type definition helpers.  You'll almost always need this.</span>
  <span>extend</span> <span>T</span><span>::</span><span>Sig</span>

  <span># Sigs are defined with `sig` and a block.  Define the return value type with</span>
  <span># `returns`.</span>
  <span>#</span>
  <span># This method returns a value whose class is `String`.  These are the most</span>
  <span># common types, and Sorbet calls them "class types".</span>
  <span>sig</span> <span>{</span> <span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>greet</span>
    <span>'Hello, World!'</span>
  <span>end</span>

  <span># Define parameter value types with `params`.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>n</span><span>:</span> <span>Integer</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>greet_repeat</span><span>(</span><span>n</span><span>)</span>
    <span>(</span><span>1</span><span>..</span><span>n</span><span>)</span><span>.</span><span>map</span> <span>{</span> <span>greet</span> <span>}</span><span>.</span><span>join</span><span>(</span><span>"</span><span>\n</span><span>"</span><span>)</span>
  <span>end</span>

  <span># Define keyword parameters the same way.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>n</span><span>:</span> <span>Integer</span><span>,</span> <span>sep</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>greet_repeat_2</span><span>(</span><span>n</span><span>,</span> <span>sep</span><span>:</span> <span>"</span><span>\n</span><span>"</span><span>)</span>
    <span>(</span><span>1</span><span>..</span><span>n</span><span>)</span><span>.</span><span>map</span> <span>{</span> <span>greet</span> <span>}</span><span>.</span><span>join</span><span>(</span><span>sep</span><span>)</span>
  <span>end</span>

  <span># Notice that positional/keyword and required/optional make no difference</span>
  <span># here.  They're all defined the same way in `params`.</span>

  <span># For lots of parameters, it's nicer to use do..end and a multiline block</span>
  <span># instead of curly braces.</span>
  <span>sig</span> <span>do</span>
    <span>params</span><span>(</span>
      <span>str</span><span>:</span> <span>String</span><span>,</span>
      <span>num</span><span>:</span> <span>Integer</span><span>,</span>
      <span>sym</span><span>:</span> <span>Symbol</span><span>,</span>
    <span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span>
  <span>end</span>
  <span>def</span> <span>uhh</span><span>(</span><span>str</span><span>:,</span> <span>num</span><span>:,</span> <span>sym</span><span>:)</span>
    <span>'What would you even do with these?'</span>
  <span>end</span>

  <span># For a method whose return value is useless, use `void`.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>name</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>void</span> <span>}</span>
  <span>def</span> <span>say_hello</span><span>(</span><span>name</span><span>)</span>
    <span>puts</span> <span>"Hello, </span><span>#{</span><span>name</span><span>}</span><span>!"</span>
  <span>end</span>

  <span># Splats! Also known as "rest parameters", "*args", "**kwargs", and others.</span>
  <span>#</span>
  <span># Type the value that a _member_ of `args` or `kwargs` will have, not `args`</span>
  <span># or `kwargs` itself.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>args</span><span>:</span> <span>Integer</span><span>,</span> <span>kwargs</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>void</span> <span>}</span>
  <span>def</span> <span>no_op</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>)</span>
    <span>if</span> <span>kwargs</span><span>[</span><span>:op</span><span>]</span> <span>==</span> <span>'minus'</span>
      <span>args</span><span>.</span><span>each</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span><span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span> <span>}</span>
    <span>else</span>
      <span>args</span><span>.</span><span>each</span> <span>{</span> <span>|</span><span>i</span><span>|</span> <span>puts</span><span>(</span><span>i</span> <span>+</span> <span>1</span><span>)</span> <span>}</span>
    <span>end</span>
  <span>end</span>

  <span># Most initializers should be `void`.</span>
  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>name</span><span>:</span> <span>String</span><span>)</span><span>.</span><span>void</span> <span>}</span>
  <span>def</span> <span>initialize</span><span>(</span><span>name</span><span>:)</span>
    <span># Instance variables must have annotated types to participate in static</span>
    <span># type checking.</span>

    <span># The value in `T.let` is checked statically and at runtime.</span>
    <span>@upname</span> <span>=</span> <span>T</span><span>.</span><span>let</span><span>(</span><span>name</span><span>.</span><span>upcase</span><span>,</span> <span>String</span><span>)</span>

    <span># Sorbet can infer this one!</span>
    <span>@name</span> <span>=</span> <span>name</span>
  <span>end</span>

  <span># Constants also need annotated types.</span>
  <span>SORBET</span> <span>=</span> <span>T</span><span>.</span><span>let</span><span>(</span><span>'A delicious frozen treat'</span><span>,</span> <span>String</span><span>)</span>

  <span># Class variables too.</span>
  <span>@@the_answer</span> <span>=</span> <span>T</span><span>.</span><span>let</span><span>(</span><span>42</span><span>,</span> <span>Integer</span><span>)</span>

  <span># Sorbet knows about the `attr_*` family.</span>
  <span>sig</span> <span>{</span> <span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>attr_reader</span> <span>:upname</span>

  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>write_only</span><span>:</span> <span>Integer</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>Integer</span><span>)</span> <span>}</span>
  <span>attr_writer</span> <span>:write_only</span>

  <span># You say the reader part and Sorbet will say the writer part.</span>
  <span>sig</span> <span>{</span> <span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>attr_accessor</span> <span>:name</span>
<span>end</span>

<span>module</span> <span>Debugging</span>
  <span>extend</span> <span>T</span><span>::</span><span>Sig</span>

  <span># Sometimes it's helpful to know what type Sorbet has inferred for an</span>
  <span># expression.  Use `T.reveal_type` to make type-checking show a special error</span>
  <span># with that information.</span>
  <span>#</span>
  <span># This is most useful if you have Sorbet integrated into your editor so you</span>
  <span># can see the result as soon as you save the file.</span>

  <span>sig</span> <span>{</span> <span>params</span><span>(</span><span>obj</span><span>:</span> <span>Object</span><span>)</span><span>.</span><span>returns</span><span>(</span><span>String</span><span>)</span> <span>}</span>
  <span>def</span> <span>debug</span><span>(</span><span>obj</span><span>)</span>
    <span>T</span><span>.</span><span>reveal_type</span><span>(</span><span>obj</span><span>)</span> <span># Revealed type: Object</span>
    <span>repr</span> <span>=</span> <span>obj</span><span>.</span><span>inspect</span>

    <span># Reminder that Ruby methods can be called without arguments, so you can</span>
    <span># save a couple characters!</span>
    <span>T</span><span>.</span><span>reveal_type</span> <span>repr</span> <span># Revealed type: String</span>

    <span>"DEBUG: "</span> <span>+</span> <span>repr</span>
  <span>end</span>
<span>end</span>

<span>module</span> <span>StandardLibrary</span>
  <span>extend</span> <span>T</span><span>::</span><span>Sig</span>
  <span># Sorbet provides some helpers for typing the Ruby standard library.</span>

  <span># Use T::Boolean to catch both `true` and `false`.</span>
  <span>#</span>
  <span># For the …</span></code></pre></td></tr></tbody></table></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/">https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/</a></em></p>]]>
            </description>
            <link>https://jdkaplan.dev/blog/learn-sorbet-in-y-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447883</guid>
            <pubDate>Wed, 16 Dec 2020 20:11:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Preview in macOS Big Sur is destroying PDFs]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 296 (<a href="https://news.ycombinator.com/item?id=25447830">thread link</a>) | @matrixagent
<br/>
December 16, 2020 | https://annoying.technology/posts/86f4ea27e4cd90d0/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/86f4ea27e4cd90d0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/35f98c21da204421e81bcfcb709f0b9a2563fde5/a3843/media/previeweatingpdfs.png"></p><p>This <a href="https://annoying.technology/media/previeweatingpdfs.png">image</a> has three components: On the left is an OCR’ed PDF from my ScanSnap iX500. I have selected most of the text, and on the right side you can see two copy&amp;paste results. In the upper half is the result directly after scanning, right after the bundled ABBYY FineReader that comes with the iX500 did its magic. In the lower half is the result <strong>after</strong> modifying (removed a blank page) and saving that same PDF in <em>Preview</em>.</p><p>Hard to believe, but that’s <a href="https://discourse.devontechnologies.com/t/odd-pdf-behavior/21400">not</a> <a href="http://www.documentsnap.com/ocr-text-macos-sierra-preview/">the</a> <a href="https://discussions.apple.com/thread/8010687">first</a> time Apple <a href="https://mjtsai.com/blog/2016/12/21/more-macos-preview-pdf-trouble/">messed this up</a>. Sure, even Apple can’t account for all use cases when changing complex stuff like internal PDF handling. But:</p><ul><li>The iX500 is an insanely popular and common scanner</li><li>I don’t know any OCR software that is more popular than ABBYY FineReader</li><li>macOS used to be the absolute best in class OS for dealing with PDFs by a <strong>long</strong> shot</li><li>IT HAPPENED BEFORE</li></ul><p>I wish Apple was still charging for OS updates, so I could at least refund it.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> This is such a nasty bug – if you don’t already know to expect it, you will only find out months or possibly years later. I almost missed it this time, because even after modifying and saving the file it’s still not happening. You have to completely close the file and reopen it, only then will you realize that it has been destroyed.</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Yes, I blame only Apple for this. I’ll repeat what I told Philipp (noted Apple apologist!) when we argued about this last week after I discovered the problem: ABBYY says they don’t support Big Sur yet, that’s fine. But Apple didn’t tell me that I can’t upgrade to Big Sur when I use ABBYY. I’d be a lot less angry if there was a changelog or release notes <em>from Apple</em> where it says there is a known problem with OCR’ed PDFs in Preview. <em>Their</em> software is broken, <em>they</em> need to tell me. I don’t care if it only worked because they had workarounds for super shitty PDFs that ABBYY possibly produces, I just need my OS to keep working for me. This bug could hit me without even owning a scanner at all – someone sending me a PDF that I then unknowingly break before archiving it. That’s the part I’m mad about. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li></ol></section></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/86f4ea27e4cd90d0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447830</guid>
            <pubDate>Wed, 16 Dec 2020 20:07:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Google’s Artificial Intelligence Goes Homophobic]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447655">thread link</a>) | @freshfruitmag
<br/>
December 16, 2020 | https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/ | <a href="https://web.archive.org/web/*/https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<p>Arjan Dijk, Google’s former VP of marketing and global executive sponsor of Gayglers (Google’s LGBTQ+ Employee Resource Group) said in a 2018 post on <a href="https://www.blog.google/outreach-initiatives/small-business/adding-lgbtq-friendly-and-transgender-safe-space-attributes-google-my-business/" data-type="URL" data-id="https://www.blog.google/outreach-initiatives/small-business/adding-lgbtq-friendly-and-transgender-safe-space-attributes-google-my-business/" target="_blank" rel="noreferrer noopener">Google’s blog</a>, announcing a feature allowing businesses to tag whether they were LGBTQ-friendly or provided an LGBTQ safe space, “There’s little that compares to the feeling of walking into a place and being immediately comfortable—your shoulders loosen, your breathing slows, you physically relax, knowing you can be yourself. Finding those spaces has often been hard for the LGBTQ+ community. We want to help celebrate those spaces of belonging and make them easier to find.”</p>



<p>The tech giant, whose mission it is “to organize the world’s information and make it universally accessible and useful” and whose tagline is “Do the right thing,” has fallen short of its professed ideals. Instead, it fiercely protects its advertising customer interests and threat to its advertising revenue, at the expense of its publishing clients, content creators and even <a href="https://www.theverge.com/2019/6/7/18656540/googles-youtube-lgbtq-employees-harassment-policies-pride-month" data-type="URL" data-id="https://www.theverge.com/2019/6/7/18656540/googles-youtube-lgbtq-employees-harassment-policies-pride-month" target="_blank" rel="noreferrer noopener">its own LGBTQ employees</a>. With changes to its advertising policies that have disenfranchised various LGBTQ media companies and content creators, in 2019 some of its employees demanded Google do better and stand firm behind its commitment to support the LGBTQ community.</p>



<p>With more than lip service, they wanted Google to show them that it, too, offered a “safe space” – not just when it’s convenient during Pride month. They also wanted Google to affirm that it wouldn’t unfairly silence, censor or discriminate against LGBTQ media companies and content creators and the safe spaces they create. This follows dismay by LGBTQ employees months prior on Google’s initial response to not penalize a right-wing YouTube commentator for his <a href="https://www.washingtonpost.com/technology/2019/06/05/right-wing-youtuber-hurled-racist-homophobic-taunts-gay-reporter-company-did-nothing/" data-type="URL" data-id="https://www.washingtonpost.com/technology/2019/06/05/right-wing-youtuber-hurled-racist-homophobic-taunts-gay-reporter-company-did-nothing/" target="_blank" rel="noreferrer noopener">continual homophobic harassment</a> of a gay Vox media journalist and other complaints about how Google handles <a href="https://www.nytimes.com/2018/11/01/technology/google-walkout-sexual-harassment.html" data-type="URL" data-id="https://www.nytimes.com/2018/11/01/technology/google-walkout-sexual-harassment.html" target="_blank" rel="noreferrer noopener">sexual harassment claims</a>. Some 20,000 of its employees internationally walked out in protest.</p>



<p>Admittedly, Google’s discriminatory algorithm and the black box application of its policies hit close to home. <em>Freshfruit</em> had been actively trying to sign up for both Google AdSense and Ad Manager (GAM) accounts for nearly two months, a process that can be approved in a matter of days or weeks. Google’s ad suite, including GAM (its ad serving technology), AdSense (a plug-and-play ad monetization solution) and Ad Exchange (a marketplace with greater publisher controls) are the favored ad products in the market for internet publishers to maintain and grow their advertising business. While previously all of these services operated as separate products on an opt-in basis, Google made the decision in 2018 to <a href="https://blog.google/technology/ads/new-advertising-brands/" data-type="URL" data-id="https://blog.google/technology/ads/new-advertising-brands/" target="_blank" rel="noreferrer noopener">rebrand</a> and bundle them. Therefore, in order to get a GAM account, you need to get AdSense first. While Ad Exchange is an add-on feature, it cannot be used without GAM. To partake in any of these services as a new publisher requires an application and meeting <a href="https://support.google.com/adsense/answer/9335564?hl=en" data-type="URL" data-id="https://support.google.com/adsense/answer/9335564?hl=en" target="_blank" rel="noreferrer noopener">Google’s strict publisher policies</a>.</p>



<p>Although hard to substantiate in the U.S., Google has roughly <a href="https://assets.publishing.service.gov.uk/media/5efc57ed3a6f4023d242ed56/Final_report_1_July_2020_.pdf" data-type="URL" data-id="https://assets.publishing.service.gov.uk/media/5efc57ed3a6f4023d242ed56/Final_report_1_July_2020_.pdf" target="_blank" rel="noreferrer noopener">90% percent</a> market share among ad serving technology companies in the United Kingdom, which should be roughly the same prevalence in the U.S. Google also has over <a href="https://www.datanyze.com/market-share/advertising-networks--9/google-ads-market-share" data-type="URL" data-id="https://www.datanyze.com/market-share/advertising-networks--9/google-ads-market-share" target="_blank" rel="noreferrer noopener">80 percent</a> market share among publisher ad networks between its AdSense and Ad Exchange products, which is how publishers make money outside of their direct advertising business. Given that online media companies primarily rely on ad spend to fund their operating costs, Google is in many ways a requisite partner to have, since over decades it has inserted itself as an intermediary between the publishing community and their direct advertisers with its offer of efficiency and yield management tools. Therefore, the vast majority of the publishing ecosystem, including LGBTQ media businesses, would find it incredibly hard to fund critical journalism without Google. Suffice to say, the inherent irony and ethical concerns shouldn’t be lost on anyone that Google both facilitates the potentiality of free speech and its censorship by acting as an arbiter via its technology and policies.</p>



<p>Over the past two months, <em>Freshfruit</em> had been back and forth with Google’s automated system and human reviewers that had flagged various policy “violations” that were not clear and were up to Google’s interpretation. As requested, we had removed any possible textual references and any images that could be deemed to be explicit, although it is our opinion that none of our content met that criteria or were unlike what you can find on other mainstream media websites. Yet, there were still issues.</p>



<p>Example of potentially flagged content includes “<a rel="noreferrer noopener" href="https://freshfruitmag.com/dirty-sex/" data-type="URL" data-id="https://freshfruitmag.com/dirty-sex/" target="_blank"><em>Dirty Sex</em></a>” about the stigmatization of HIV after the AIDS epidemic in contrast to current considerations of the coronavirus disease pandemic, or “<a rel="noreferrer noopener" href="https://freshfruitmag.com/blood-work/" data-type="URL" data-id="https://freshfruitmag.com/blood-work/" target="_blank"><em>Blood Work</em></a>” about an artist who uses human blood to protest the FDA ban against gay, bi and transgender men from blood donation. Google’s policy bans keywords that can be categorized as “explicit” and also “shocking content,” such as blood. The most suggestive images we used were of a <a href="https://www.instagram.com/p/CG6NY4eHPdm/?igshid=1dp03x47vyptm" data-type="URL" data-id="https://www.instagram.com/p/CG6NY4eHPdm/?igshid=1dp03x47vyptm" target="_blank" rel="noreferrer noopener">banana covered by a medical face mask</a> for a piece, where three subjects spoke in their words about dating during the pandemic, entitled “<em><a href="https://freshfruitmag.com/love-and-sex-in-the-time-of-corona/" data-type="URL" data-id="https://freshfruitmag.com/love-and-sex-in-the-time-of-corona/" target="_blank" rel="noreferrer noopener">Love and Sex in the Time of Corona</a></em>;” for the same story, an image of a <a rel="noreferrer noopener" href="https://www.istockphoto.com/photo/love-and-hugs-family-and-relationships-three-sexy-men-gm1015470990-273280528" data-type="URL" data-id="https://www.istockphoto.com/photo/love-and-hugs-family-and-relationships-three-sexy-men-gm1015470990-273280528" target="_blank">man’s torso</a> with two sets of hands hugging him; and an <a href="https://www.instagram.com/p/CG6Q4TlHzyZ/?igshid=1cy5nu59ppj8" data-type="URL" data-id="https://www.instagram.com/p/CG6Q4TlHzyZ/?igshid=1cy5nu59ppj8" target="_blank" rel="noreferrer noopener">illustration</a> of two gay men kissing for an advice column about the alarming number of straight women who watch gay porn—a topic also covered by <a rel="noreferrer noopener" href="https://www.cosmopolitan.com/sex-love/a44494/girls-who-like-boys-who-like-boys/" data-type="URL" data-id="https://www.cosmopolitan.com/sex-love/a44494/girls-who-like-boys-who-like-boys/" target="_blank"><em>Cosmopolitan</em> magazine</a>. Google’s response was to provide their policy for <em>Freshfruit</em> to review, which we combed through and found ourselves at an impasse. We didn’t see where we were not adhering to their policies and Google didn’t specify what needed to be fixed. Throughout this process, there is no human interaction. If rejected, they offer no appeals process or a way to escalate. Your only option is to post or sift through <a rel="noreferrer noopener" href="https://support.google.com/adsense/answer/2581949?hl=en" data-type="URL" data-id="https://support.google.com/adsense/answer/2581949?hl=en" target="_blank">community support boards</a> to see how others have dealt with a similar set of circumstances. However, when you are an advertiser, the opposite is true. There are ample resources, a call center, a support team, and dedicated account management if you generate considerable revenue. In fact, <a rel="noreferrer noopener" href="https://ads.google.com/intl/en_us/home/contact-us/" data-type="URL" data-id="https://ads.google.com/intl/en_us/home/contact-us/" target="_blank">they invite you to contact them</a> with your concern and they respond.</p>



<p><em>Freshfruit</em> encountered similar issues on Facebook’s platform as well; where their algorithm blocked our website on Facebook and Instagram (as well as the same torso image), resulting in all of our Facebook content being expunged. Much of this content was already reviewed and approved to run in Facebook Ads Manager, yet its algorithm codified <em>Freshfruit</em> as “spam.” It took nearly one month to address through a circuitous and nebulous process, where a human being was able to observe that there was no issue and restored our content in a matter of minutes. The reason given was that it was a “false positive” flag. Unlike Google, Facebook offered a human escalation point to resolve the matter.</p>



<p>There have been various reports of LGBTQ content creators on YouTube who have faced similar issues, having to do with its algorithm and policies. YouTube and Google are both owned by their parent company, Alphabet Inc. Led by married couple Celso Dulay and Chris Knight, co-founders of <em><a rel="noreferrer noopener" href="https://glitterbombtv.com/" data-type="URL" data-id="https://glitterbombtv.com/" target="_blank">GlitterBombTV</a></em>, 12 individual LGBTQ content creators have <a rel="noreferrer noopener" href="https://www.dropbox.com/s/g3t7ofhmg3asc9m/%231%20LGBTQ%2B%20v%20Google-YouTube%20complaint%20FILED%20%28case%20%235-19-cv-4749%20%29.pdf?dl=0" data-type="URL" data-id="https://www.dropbox.com/s/g3t7ofhmg3asc9m/%231%20LGBTQ%2B%20v%20Google-YouTube%20complaint%20FILED%20%28case%20%235-19-cv-4749%20%29.pdf?dl=0" target="_blank">sued</a> the technology company for discrimination, alleging that its machine learning algorithm inhibited, outright blocked, or demonetized their publishing or advertising content or caused them financial harm in their ability to generate advertising revenue. The lawsuit alleges that Google’s algorithm and its system of human reviewers discriminated against YouTube channels that incorporated words such as “gay,’ “trans” or “bisexual” in the title. For many this meant that their content was no longer showing up in YouTube’s Explore pages or were not being recommended alongside similar videos by YouTube’s recommendation engine.</p>



<p>The lead plaintiffs in the case had also sought to advertise <em><a rel="noreferrer noopener" href="http://www.youtube.com/glitternewsSF" data-type="URL" data-id="http://www.youtube.com/glitternewsSF" target="_blank">GNews</a></em>, their new YouTube show – a gay version of E! Network’s <em>Talk Soup</em>. After attempting to build an audience by running ads about their <a rel="noreferrer noopener" href="https://www.youtube.com/watch?v=ji6tJcYIYSo&amp;t=3s" data-type="URL" data-id="https://www.youtube.com/watch?v=ji6tJcYIYSo&amp;t=3s" target="_blank">Christmas ‘holigay’ show</a> and lineup via Google AdWords, their ads were flagged as problematic. After inquiring with Google AdWords’ call center for the fifth time on why their 9th ad had been rejected, which Knight recorded and <em>Freshfruit</em> has listened to, they were told that their content was flagged as “shocking” and violated Google’s policy. The supervisor on the call explained to them that the advertisement, which he himself had reviewed and saw no issue with, did not meet Google’s standards not because of its actual content but because the show was a gay show and considered “sexual,” despite the fact that it was not about sex and had no sexual references.</p>



<p>“Everywhere you went we were running into walls and we were running into these obstacles,” said Dulay. “More than frustrating, it was debilitating to people’s incomes. It was keeping us from reaching our audience. People were now saying they couldn’t find us any longer. Before that, we had a lot of correspondence with people who said that we were a touchstone to the community because they lived in a place where they didn’t have any. So, we were giving them access to information and all this other stuff. So, with that sort of dwindling, we did our own website because we still wanted to keep the show going even though we were having so many issues with YouTube.”</p>



<p>Stephanie Frosch, an LGBTQ+ YouTuber with about 370,000 subscribers who is also affiliated with the suit told <em>Freshfruit</em> that she’s barely making $100 per month down from a high of $23,000 annually in 2009.</p>



<p>“When this first happened,” said Frosch, “I was invited to the YouTube [offices] with several other creators from very niche-specific genres from gaming to parenting to food people from the different facets of YouTube. And we were all voicing our concerns about the new algorithm and how it was …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/">https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/</a></em></p>]]>
            </description>
            <link>https://freshfruitmag.com/when-googles-artificial-intelligence-goes-homophobic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447655</guid>
            <pubDate>Wed, 16 Dec 2020 19:53:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IoT Security at Home]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447481">thread link</a>) | @henrikwm
<br/>
December 16, 2020 | https://security.christmas/2020/16 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://i.ibb.co/KzGcFd9/yoonjae-baik-p7-Ms-AMLSbb-U-unsplash.jpg?w=1226&amp;h=400&amp;fit=crop&amp;crop=edges" alt=""><div><section><p>What is the state of your IoT (Internet of Things)-security in your home? Do you have any gadgets on your network that are vulnerable to exploitation? Maybe you have any devices you do not recognize? If you own an IoT-device then you should be curious about how it talks to the Internet and how security is taken care of.</p>
</section><article><section><p>We've all heard the horror stories. Whether it's <a href="https://www.nbcnews.com/news/us-news/stranger-hacks-baby-monitor-tells-child-i-love-you-n1090046">hacked baby monitors</a> or <a href="https://www.theguardian.com/technology/2017/nov/14/retailers-urged-to-withdraw-toys-that-allow-hackers-to-talk-to-children%20">talking toys</a>, <a href="https://auth0.com/blog/surprised-turns-out-consumers-dont-trust-iot-security/%20">consumers and developers seem to agree</a> on one thing; <em>don’t trust your IoT-devices</em>. This article tries to explain common security flaws with IoT-devices and includes a comprehensive "do-it-yourself" guide on how you can minimize the security threat.</p>
<p>Before we dive into the guide, what is an IoT-device and what security concerns should we be aware of?</p>
<h2>IoT-devices in your home</h2>
<p>The Internet of things promises us connected devices in your home talking to each other and the Internet. The connectivity enables your printer, fridge, vacuum cleaning robot or floor-heaters to be automated while you are on-the-go and not at home. Maybe even more efficient home-management. But should we put our trust into the vendor of our IoT coffe-machine that they won't leak our data, won't get hacked and has privacy and GDPR as their core focus? What priorities do these vendors have and how does that affect us?  </p>
<h2>Security concerns</h2>
<p><strong>Default / Weak passwords</strong></p>
<p>"Box fresh" devices often have a default password. If your device has a weak or easy to guess password then it will be susceptible to guessing attacks. Default passwords are <a href="https://www.routerpasswords.com/">easily obtained from the Internet</a></p>
<p><strong>Missing security updates</strong></p>
<p>IoT-devices are often built on pre-existing technologies such as the Linux operating system or using HTTP services such as Apache or NGINX. Over time, flaws are discovered in all software products which should be addressed. Failure to update against known vulnerabilities in supporting software will increase the chances of a remote attacker being able to compromise the device.</p>
<p><strong>Insecure web administration</strong></p>
<p>Some devices offer some form of web application to provision and administer the device. These interfaces are vulnerable to the same risks as enterprise applications or Internet sites. </p>
<p><strong>Use of insecure protocols</strong></p>
<p>An insecure protocol includes (but is not limited to): ftp, telnet, http or SNMP. The protocol is said to be insecure if it employs no transport layer encryption or has known security weaknesses. Those listed all fall into the first category. </p>
<p>It is common to offer administration functions over most of the listed protocols. The impact of using insecure protocols is that an attacker on the same network would be able to conduct a man-in-the-middle (MiTM) exploitation to compromise the device.</p>
<p><strong>Bad configuration</strong></p>
<p>All networked services are potential avenues for an attacker to target your device. A vulnerability assessment of these networked services would uncover known flaws. Most likely your device is powered by an embedded operating system. To gain defence in depth review the operating system for configuration weaknesses such as: processes with elevated privileges, file permissions etc. </p>
<p><strong>Insecure data storage</strong></p>
<p>If your device can store data locally then you need to be aware of the risks of doing so. Are your controls robust enough to prevent trivial retrieval of sensitive information? Do you use some form of encryption to protect data while the device is powered off?</p>
<h2>"Do-it-yourself" security checklist</h2>
<ul>
<li>
<p><strong>Change default passwords:</strong> </p>
<p>Refer to the manual, do an online search, or contact the manufacturer for advice.</p>
</li>
<li>
<p><strong>Check for firmware and system updates:</strong> </p>
<p>Even a brand new device could need a security update. Refer to the manual, do an online search, or contact the manufacturer for advice.</p>
</li>
<li>
<p><strong>Apply updates regularly:</strong></p>
<p>Manufacturers patch bugs and flaws on an ongoing basis – and so should you.Sign up for automatic updates or software update alerts when possible.</p>
</li>
<li>
<p><strong>Set up a guest WiFi network for IoT-devices to connect to:</strong></p>
<p>Isolate your IoT-devices from your home computers to reduce risk to important data. If you need advice, start with an online search for your WiFi router model. Many devices make it easy to set up a guest network.</p>
</li>
<li>
<p><strong>Disable Universal Plug-and-Play (UPnP) functionality:</strong></p>
<p>Some IoT-devices can leave your home firewall vulnerable to attack via UPnP. Unless you specifically need it for an IoT-device, turn off UPnP. An online search can help you find advice for your specific model.</p>
</li>
<li>
<p><strong>Google <em>{name of the device}</em> + CVE:</strong></p>
<p>You should see if there exists one or more <a href="https://www.cvedetails.com/">Common Vulnerabilities and Exposures (CVE) </a> for your device. If there is, see if the manufacturer of your device has patched the CVE in one of the software updates, or consider sending them an email letting them know. If the CVE is serious, you should consider turning your IoT off until there is a fix available. </p>
</li>
<li>
<p><strong>Check for open ports:</strong></p>
<p><a href="https://gist.github.com/rsperl/321aac3d529aa8f8c7924fd12d581b67">Nmap-cheatsheet</a></p>
<p>First obtain the IP-address of your device. This can be done by looking for "connected devices" on your router or do a network scan with <a href="https://nmap.org/">nmap</a>.</p>
<ul>
<li>Does your device expose any ports? </li>
<li>What does that port do? (google port + {port number})</li>
<li>Can you connect to your device through the port? For example through your web browser, ftp client, ssh?</li>
<li>Example of a generic scan for performing host discovery on your subnet:</li>
</ul>
<p><code>nmap -sP 192.168.1.0/24</code></p>
<p>Secondly do a full service scan on your device. Grab a cup of coffee, this usually takes some time.</p>
<ul>
<li>Example of a specific scan to find printer's open ports on your subnet:</li>
</ul>
<p><code>nmap -p 515,9100 192.168.1.0/24 -oG - | grep open</code></p>
</li>
</ul></section></article></div></article></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447481</guid>
            <pubDate>Wed, 16 Dec 2020 19:42:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Due to unusually high call volumes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25447367">thread link</a>) | @osmode
<br/>
December 16, 2020 | https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/ | <a href="https://web.archive.org/web/*/https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg"><img data-attachment-id="2690" data-permalink="https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/clinical_combat_vest/#main" data-orig-file="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1608121966&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="clinical_combat_vest_hi_res" data-image-description="" data-medium-file="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=225" data-large-file="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=720" src="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=768" alt="" srcset="https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=768 768w, https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=1536 1536w, https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=113 113w, https://omarmetwally.files.wordpress.com/2020/12/clinical_combat_vest.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></a></figure></div>



<p>The strain of the COVID-19 pandemic on society and healthcare systems turned fine fault lines into gaping canyons. Reflecting on <a href="https://omarmetwally.blog/2015/07/03/if-hospitals-were-run-like-startups/">my writings about U.S. hospitals 5 years ago</a>, I asked myself what had changed and what still must change to rebuild a healthcare system that can deliver medical care wherever and whenever it’s needed. What problems were prevalent in the healthcare system before the pandemic, and how did the pandemic highlight these deficiencies? In my day-to-day work as a doctor, what diverts my time and energy away from the most important and fulfilling aspect of doctoring – patient care?</p>



<p>Direct and effective communication with patients is the most important aspect of healthcare, in my view. A doctor working in the community who is licensed and certified has demonstrated a body of knowledge and skills to provide medical care within a certain scope of practice. Someone with a health concern is arguably not seeking the smartest doctor they can find; they want a doctor with whom they can communicate their concerns, understand their health issue, and make a mutually acceptable treatment plan. In daily practice, I feel that 95% of my time and energy are consumed by tasks that do not relate directly to patient care. Even more unfortunate is the fact that these 95% of tasks are the ones by which doctors are evaluated and compensated: clicking through electronic health records (EHR), wrestling with flawed communication systems (such as hospital phones, pagers, texting, and email) to receive and share information with other members of the healthcare team, answering “queries” from hospital administration for the purpose of billing patients and insurance companies, and wasting life-years trying to wrangle health information systems as mandated by hospital administrators and insurance companies.</p>







<p>1. The world wide web</p>



<p>The pandemic pushed the role of “telemedicine” (healthcare rendered by phone or digitally) into the foreground as a way to deliver healthcare efficiently while reducing the spread of the coronavirus. Regrettably the first and biggest problem with healthcare is internet connectivity and how EHR software sends and receives information between a doctor’s phone/computer and the hospital server. Even in the year 2020, reliable, high-speed internet is a scarce resource in the United States. Most Americans have no choice of internet service provider, if they are lucky to even have access to one.  In a time where human resources are stretched thin and inefficiently used, trying to reach a human in the event of a service interruption can easily waste hours if not days waiting on hold or confined to chatbot purgatory. Many doctors now work remotely to a large extent, if not entirely. Reliable, fast internet is prerequisite to being able to deliver good healthcare. This is especially true because of the nature of EHRs, which use “Virtual Machines” and “Remote Desktops” that require a reliable, low-latency, high-speed internet connection. A client that runs at a snail’s speed and frequently disconnects, requiring 10 minutes to repeat the authentication process before dropping the connection again, is severely detrimental to patient care.</p>



<p>2. Electronic Health Records</p>



<p>EHRs are essentially spreadsheets in fancy packaging. They’re not smart in the sense that a phone is smart; they don’t learn, predict, or automate tasks. In fact software that is slow, requires a lot of clicking and non-intuitive behavior, and which wastes a lot of time with authentication and logging in, is not much better than typing text into the simplest text editor and saving it in a rudimentary database. That is the core of a hospital or clinic’s information system: text and media files saved chronologically and accessible to the right people at the right time. I prefer to type or dictate notes freestyle rather than use templates because it’s faster for me, gives me more control over the document, and helps me communicate my assessment and treatment plan more effectively than relying on a template created by someonen else who may conceptualize a diagnostic process and treatment plan much differently than their peers. An ideal EHR to me would simply be typed into a Unix terminal (for a reader unfamiliar with Unix, imagine a black screen with a flashing white cursor) and piped into a hospital server, which would then use the text to help doctors appreciate the clinical Gestalt or “big picture”: what could harm or kill the patient in the next few hours? And beyond the first 12-24 hours, how to safely discharge the patient? As an EHR user, I don’t want a fancy front-end trickling through a lagging virtual machine; I want a simple, low-latency, text-focused interface and a smart backend, in other words, very simple software that looks dumb but is actually smart. </p>



<p>3. Communication</p>



<p>On top of the pressure of having to synthesize a huge amount of dynamic information to make fast and sound decisions about patient care, doctors are inundated and constantly interrupted by communications from other members of the care team. Doctors work closely with nurses, aids, phlebotomists, lab and radiology technicians, doctors from different specialties, clerks, social workers, insurance companies, and hospital administrators. There is a lot of information constantly moving back and forth in real-time between all parties. This flow of information is often like a waterfall rather than a water faucet – the communications are not prioritized and frequently fail to reach the right person at the right time. There are times when a doctor’s attention should be focused entirely on the task at hand, for example when assessing or speaking with a patient at bedside. This is no time to be interrupted with billing queries or non-urgent questions about other patients’ care. A constant stream of unprioritized and unfocused information can make it extremely difficult to focus on the critical 1% of information which can hurt patients if this information is not processed correctly at the right time. In order to hold people accountable for their decisions, they need to be given a fair chance, with tools that work without draining life out of the users. A page or phone call that may or may not find the intended recipient, and a note left in the EHR saying, “tried to call you but you didn’t answer your phone,” is subjective and not constructive without a way for all parties to track communications from their origin to their destination.</p>



<figure><a href="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg"><img data-attachment-id="2706" data-permalink="https://omarmetwally.blog/spam_calls/" data-orig-file="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg" data-orig-size="1242,2081" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1608127938&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="spam_calls" data-image-description="" data-medium-file="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=179" data-large-file="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=611" src="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=611" alt="" srcset="https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=611 611w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=1222 1222w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=90 90w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=179 179w, https://omarmetwally.files.wordpress.com/2020/12/spam_calls.jpg?w=768 768w" sizes="(max-width: 611px) 100vw, 611px"></a><figcaption>Automated spam calls, a nuisance in daily life, can be harmful to patient care by hindering timely and effective communication</figcaption></figure>



<p>In addition to the right tools, there is a need for sound systems. A doctor’s extensive education and training culminates in a highly specialized set of skills and knowledge. Doctors should take pride and joy in their work; they endured long, grueling training out of a desire to help humanity. Out of training, doctors traditionally became their own bosses, working in community hospitals or private clinics, practicing medicine the way they were taught in a style that becomes their own. Nowadays doctors are managed by administrators who are not doctors. There is a reason why healthcare systems look and function the way they do, an evolutionary end-product of decades of legislative, financial, operational, and societal forces exerting themselves on doctors and hospitals. Back in the day, doctors saw their own patients in their own clinic and treated their patients when they were hospitalized too. This is exceptional nowadays. There was no, “I’m your doctor for today,” or “I’m your doctor this shift, until 8pm.” The reality is that this mode of doctoring has become rare. Having experienced the modern-day flavor of corporate medicine in urban areas and the more traditional model in rural areas, I appreciate the pros and cons of both models. “I’m your doctor, period” can be spoken by a doctor lucky enough to escape corporate medicine, but also a doctor prepared to withstand the stress of not having any personal or protected time away from work. Too many talented doctors nowadays burn out after short-lived clinical careers, depriving patients of the care of great doctors who fell victim to the 95% non-clinical burden on top of the already stressful 5% clinical work.</p>



<p>4. More communication</p>



<p>There is a clear line between “outpatient” and “inpatient” medicine in most doctors’ minds, that is, healthcare delivered in a clinic, where a patient goes to an appointment and returns home, compared to a hospital, where a patient stays overnight. Patients don’t think in terms of “inpatient” and “outpatient.” A patient who wakes in the middle of the night with a fever and shortness of breath, or a patient with a growing breast lump, have concerns that needs to be addressed immediately by someone who actually cares. It sounds obvious, but I could not copy and paste this phrase too many times: by someone who actually cares. Not a voice menu, not a chatbot, not “Due to unusually high call volumes…,” and not a tired, under-paid clerk who is poorly equipped to do their job. A doctor has the knowledge to assess whether a problem is urgent or not urgent, concerning or likely harmless. It’s not fair or realistic to expect patients, lacking specialized knowledge, exposed to the vast informational waste littering cyberspace, biased by personal experience and anxiety about a health condition, to make those calls.</p>



<p>“Due to unusually high call volumes…” has become this year’s mantra. Nearly every call I attempt to place to an insurance company, hospital, or clinic is met with this phrase and indefinite wait times, now nine months since the start of the pandemic.  Most negative feedback about doctors and hospitals relates to what goes on beyond the few minutes a doctor spends interacting directly with the patient: a medical assistant having a bad day, a disorganized clinic, the insurance labyrinth, bills…human …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/">https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/</a></em></p>]]>
            </description>
            <link>https://omarmetwally.blog/2020/12/16/due-to-unusually-high-call-volumes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25447367</guid>
            <pubDate>Wed, 16 Dec 2020 19:33:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Killing Our Help Center Improved CSAT and Revenue over 11%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25446836">thread link</a>) | @tapneal
<br/>
December 16, 2020 | https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue | <a href="https://web.archive.org/web/*/https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/Helpcenter.png"></center>
<p>Being card game geeks, we run <a href="https://solitaired.com/">our solitaire site</a> as a fun hobby. As we gained some users though over the last year and launched a subscription service to generate some side income, we had to make sure we had reasonable customer support. </p>
<p>It was a no brainer to create a help center because we didnâ€™t want to spend time managing customer support tickets, and having a workflow where users could be self-directed and answer questions on their own was ideal. </p>
<h2 id="whenirealizedihatedhelpcenters">When I realized I hated help centers</h2>
<p>I had an issue with one of our service providers, and went to their site to figure out how to solve the problem. For 30 minutes, I hopped around their own help center with no luck finding the answer to my question. </p>
<p>I then started looking for a support line. After digging through various questions and hitting â€œNo, this did not answer my question,â€� I  found  that it was discontinued and the page redirected me back. </p>
<p>Needless to say, I wasnâ€™t happy. </p>
<p>It made me realize that instinctually, I always want to talk to someone. Whether it be over email, the phone, or chat, knowing that I was getting personalized attention would give me comfort and confidence that my issues will be resolved. </p>
<p>I decided then and there: We will get rid of our help center!</p>
<h2 id="removingourhelpcenterandimprovingourcustomersatisfactionscoreby12">Removing our help center and improving our customer satisfaction score by 12%</h2>
<p>We analyzed where users visited most in our help center. We found that three issues dominated 95% of requests:</p>
<ol>
<li>We had launched a subscription service and users wanted to understand how to cancel. Having run subscription businesses in the past, this wasnâ€™t too surprising. </li>
<li>How to report bugs in the game. Invariably, users came across some fringe bugs, especially for our <a href="https://solitaired.com/freecell">Freecell</a>, <a href="https://solitaired.com/klondike-solitaire">Klondike</a>, and <a href="https://solitaired.com/spider">Spider Solitaire</a> games, and wanted to report it. </li>
<li>Requests for more games. </li>
</ol>
<p>Addressing these questions were relatively simple, and we figured we can spend a few minutes a day responding to anything that came in. </p>
<p>We responded on average within two days and found that our customer satisfaction score (CSAT) improved from 65% to 73%. </p>
<h2 id="improvingcustomersatisfactionanother22">Improving customer satisfaction another 22%.</h2>
<p>We hypothesized that response time played a major role in improving customer satisfaction. </p>
<p>For the next week we decided to respond within 24 hours and we found that CSAT improved from 73% to 78%.</p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/24hours.png"></center>
<p>Realizing that response time makes a difference, we promised and communicated on our site that weâ€™d respond within 2 hours during business hours. CAST went up 82%. </p>
<p>We didnâ€™t want to stop, and we decided to add live chat and respond immediately during business hours. CSAT shot up to 89%!</p>
<h2 id="improvingrevenueby11">Improving revenue by 11%</h2>
<p>As we started responding and talking to our customers, we learned that many users would cancel their subscription because they didnâ€™t know how to access certain games, customization features, and due to some unknown bugs. </p>
<p>Operating a help center only gave users instructions on how to cancel, and did not give us an opportunity to understand why and course correct.</p>
<p>When we started understanding all the reasons our users were canceling, we were able to address this, improving our retention. In the first month, this improved our very modest subscription revenue by 11%. If you compound the impact of retention, it will likely be more over time. </p>
<center><img width="900" src="https://defbnszqe1hwm.cloudfront.net/images/Retention.png"></center>
<h2 id="ourcustomersupportsetuptodayandidealsolutions">Our customer support set up today, and ideal solutions</h2>
<p>Because we run the site for fun, itâ€™s difficult for us to commit to a SLA when someone responds. Today, we just have a simple contact us page. We try to get back within a day generally, but sometimes we miss that and sometimes weâ€™re able to respond earlier depending on competing priorities. </p>
<p>This has taught us though that many consumers want to talk to someone and want a response right away. With that said, some people are totally fine skipping the human interaction. We think an ideal set up is to:</p>
<ol>
<li>Have a help center that covers very simple questions, like how to use certain features. On those pages, there should be an option to quickly talk to a customer service agent. </li>
<li>Have a page on cancellation, but have a CTA talk to someone with a quick response. This will help you understand issues for paying customers and address it</li>
<li>Have a chatbot in lieu of a help center with similar works flow described above. However, set it up in a way where users understand they are talking to a bot, and at any point they can talk to someone</li>
</ol>
<p>Naturally, everyone has resource limitations. If you were to protoize KPIs like revenue, as I imagine you would, find a way to quickly talk to your paying customers or those most likely to pay to support your business goals.</p></div></div></div></div>]]>
            </description>
            <link>https://solitaired.com/killing-our-help-center-improved-customer-satisfaction-and-revenue</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446836</guid>
            <pubDate>Wed, 16 Dec 2020 19:00:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[O'Reilly book about Google Cloud Run released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25446614">thread link</a>) | @wietsevenema
<br/>
December 16, 2020 | https://wietsevenema.eu/cloud-run-book/ | <a href="https://web.archive.org/web/*/https://wietsevenema.eu/cloud-run-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <p><img src="https://wietsevenema.eu/cloud-run-book/lrg.jpg">
        </p>
        <p>
            Ebooks are available now and paperbacks are shipping (<a href="#availability">where to buy</a>)
        </p>
        <h2>Praise</h2>
        <blockquote>
            "I’ve been fortunate enough to be a part of the Google team that helped create Knative and bring Cloud Run
            to market. I’ve watched Cloud Run mature as a product over the years. I’ve onboarded thousands of customers
            and I wrote a framework to help Go developers build Cloud Run applications faster--and even I learned a
            thing or two from this book. What took me three years to learn, Wietse delivers in less than a dozen
            chapters."
            <br> <b>— Kelsey Hightower, Principal Engineer at Google Cloud</b>
        </blockquote>

        <h2 id="availability">Where to Buy</h2>
        <p>
            <em>Ebooks</em> are available here:
        </p><ul>            
            <li><a href="https://play.google.com/store/books/details/Wietse_Venema_Building_Serverless_Applications_wit?id=PV4MEAAAQBAJ">Google
                    Play</a> (DRM free epub)</li>
            <li><a href="https://www.amazon.com/Building-Serverless-Applications-Google-Cloud-ebook/dp/B08PHT7W5T/">amazon.com</a>,
                <a href="https://www.amazon.co.uk/Building-Serverless-Applications-Google-Cloud-ebook/dp/B08PHT7W5T">amazon.co.uk</a>,
                <a href="https://www.amazon.in/Building-Serverless-Applications-Google-Cloud-ebook/dp/B08PHT7W5T">amazon.in</a>
                (Kindle)
            </li>
            <li><a href="https://learning.oreilly.com/library/view/building-serverless-applications/9781492057086/">O'Reilly
                Online Learning</a> (needs subscription)</li>
        </ul>
        
        <p>The <em>paperbacks</em> are shipping, check your favourite (local) bookstore for a delivery estimate. You
            can <a href="https://shop.aer.io/oreilly/p/building-serverless-applications/9781492057093-9149">buy directly
                from
                O'Reilly</a> at a discount if you are in the US or Canada</p>

        <h2>About the Book</h2>
        <p>If you have experience building web applications on traditional infrastructure, this hands-on guide shows you
            how to get started with Cloud Run, a container-based serverless product on Google Cloud.

            Through the course of this book, you'll learn how to deploy several example applications that highlight
            different parts of the serverless stack on Google Cloud. Combining practical examples with fundamentals,
            this book will appeal to developers who are early in their learning journey as well as experienced
            practitioners (<a href="#review">learn what others say about the book</a>).</p>
        
        <h2>Who this Book is For</h2>
        <p>If you build, maintain or deploy web applications, this book is for you. You might go by the title of a
            software engineer, a developer, system administrator, solution architect, or a cloud engineer. I carefully
            balance hands-on demonstrations with deep dives into the fundamentals so that you’ll get value out of it
            whether you’re an aspiring, junior, or experienced developer. </p>

        <p>I tried to stay as programming language agnostic as possible and I use Go for the code listings, because it is easy to read if 
            you haven't worked with it before.</p>

        <h2>Full Chapter Outline</h2>
        <p>Chapter 1 gives a general overview of what a serverless application is, introduces you to Google Cloud and
            their serverless products without going too much in depth. If you are new to Google Cloud, this will be a
            great introduction.</p>
        <p><img src="https://wietsevenema.eu/cloud-run-book/pp1.png">
        </p>
        <p>Chapter 2 is a hands-on introduction to Cloud Run. I’ll show you how to get started with Google Cloud and
            deploy your first Cloud Run service. While the first part of the chapter focuses on using Cloud Run, in the
            second part I explain the runtime characteristics of Cloud Run and how they influence the way you build your
            application. I’ll also compare Cloud Run with the other serverless runtimes on Google Cloud: App Engine and
            Cloud Functions.</p>

        <p><img src="https://wietsevenema.eu/cloud-run-book/pp2.png">
        </p>

        <p>In Chapter 3 you’ll find a thorough introduction to application development with containers. In this chapter
            I show you how to run containers on your local machine with Docker, create your own container images (with
            and without Docker), and dive into the fundamentals of containers. </p>

        <p><img src="https://wietsevenema.eu/cloud-run-book/pp3.png">
        </p>
        <p>The containers on Cloud Run are disposable. This requires you to store data you need to persist beyond the
            lifetime of a single request in a database or another downstream system. In Chapter 4 I dive into the
            managed product Cloud SQL (managed relational databases such as MySQL and PostgreSQL), in Chapter 5 I follow
            up with MemoryStore (Redis). I discuss scalability and reliability, as Cloud Run can scale to 1,000
            containers very fast.</p>

        <p><img src="https://wietsevenema.eu/cloud-run-book/pp4.png">
        </p>

        <p>Especially if you are building a more serious application, you’ll want to make sure that every Cloud Run
            service in your system only has the permissions to do exactly what it needs to do. In information security,
            this is also known as the principle of least privilege: it helps to reduce the impact of a vulnerability in
            one part of the system. This is why I introduce you to Cloud Identity and Access Management (IAM) in Chapter
            6. </p>

        
        <p>Most applications have the need to schedule tasks to be executed later, either immediately after handling an
            HTTP request or at a scheduled time. In Chapter 7 I introduce you to Cloud Tasks when I cover patterns to
            use for task scheduling. </p>
        <p><img src="https://wietsevenema.eu/cloud-run-book/pp5.png">
        </p>

        <p>In Chapter 8 I’ll show you how to work with Terraform, an infrastructure as code (IaC) tool. Terraform lets
            you recreate your entire project using one command, which proves useful if your application grows beyond
            “Hello World”. If you are still getting started with building applications, you might want to skip this
            chapter and the last two chapters for now, to come back to them later.</p>

        <p>I want to make sure that you have proper visibility over what is going on in your system when you go live for
            end users. This is why I cover structured logging and tracing in Chapter 9. Doing this right is
            fundamentally important when you run a system in production. </p>

        <p>Finally, I move beyond the day-to-day concerns and think about the future in Chapter 10. If you build your
            application on top of a vendor-controlled platform, you should consider portability.</p>

        <h2 id="review">Review</h2>
        <blockquote>This is the most comprehensive, yet approachable guide to getting started with Cloud Run (and its
            vast array of accompanying tools and technologies) that currently exists - no small feat for a technology
            that's seen rapid evolution over the past 12 months. From introducing the concept of containers, to
            discussing the real-world considerations when deploying Cloud Run as part of a microservices-based
            architecture, Wietse has written a book that will appeal to both newcomers to Google Cloud and veteran
            developers alike.
            <br><b>Chris Tippett - Principal Consultant at Servian (UK)</b>
        </blockquote>

        <blockquote>Wietse Venema's book goes into significant technical depth while also keeping the reader grounded
            with realistic scenarios. I had the opportunity to review it, and look forward to purchasing a copy of my
            own so that I can read it again. Google Cloud Run may be the most interesting compute platform you'll use in
            the years ahead, and this book will help you build up the knowledge you need to successfully use it.
            <br><b>Richard Seroter, Director of Outbound Product Management at Google Cloud</b>
        </blockquote>

        <blockquote>What can I say... this guy definitely knows what he's talking about. He is as enthusiastic about the
            subject as most people are about little puppies, and manages to explain it in a way that anyone can
            understand it.
            His diagrams are a strong part of the book. They help you understand topics that can be daunting and
            difficult to comprehend, especially for junior backend developers like myself. Go buy this book, it will
            make your life running in the cloud a whole lot easier!
            <br>
            <b>Femke Buijs - Software Engineer at Mollie</b>
        </blockquote>

        <blockquote>Get ready for what I believe is going to be the de facto reference book for Google Cloud Run. Wietse
            Venema explores and explains every facet of the product and goes into details of building production-grade
            serverless apps. As a Cloud Run Product Manager, I helped review every chapter for accuracy.
            <br><b>Steren Giannini, Cloud Run Product Manager at Google Cloud</b>
        </blockquote>

        <blockquote>Wietse has an engaging and personal style that makes this book a pleasure to read. What I like
            especially, is that apart from essential knowledge about Cloud Run, it also contains plenty of anecdotes,
            best practices and useful advice to make you a better application developer. Highly recommended!
            <br><b>Robbert Brak - Principal Software Engineer at 4me</b>
        </blockquote>

        <blockquote>Developers looking to future proof their career for the next decade will love this book because: #1
            It is a practical, easy to read and concise guide on Cloud Run (the technology that finally closes the gap
            between Serverless and Containers). #2 The author covers a broad set of managed services on Google Cloud
            Platform to help you become productive quickly (even if you're new to GCP). #3 If you're skeptical about
            vendor lock-in, you will appreciate the section on how to take your serverless containers and "move out" of
            the Google Cloud.
            <br><b>Daniel Zivkovic, Solution Architect and Organizer of Serverless Toronto User Group</b>
        </blockquote>

        <h2>About the Author</h2>

        <p>Wietse Venema is a software engineer. If he's not training teams to build scalable and reliable software,
            he's figuring out how thing work so he can be a better engineer and teacher. He works at Binx.io to help
            companies build what's next in the public cloud. </p>

        <p>He's proud to be the name twin (not family) of the <a href="http://www.porcupine.org/wietse/">famous</a>
            Wietse Venema, who created Postfix.</p>

        <p>Follow me on <a href="https://www.twitter.com/wietsevenema">twitter.com</a> and connect with me on <a href="https://www.linkedin.com/in/wietse-venema/">linkedin.com</a></p>

    </article></div>]]>
            </description>
            <link>https://wietsevenema.eu/cloud-run-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446614</guid>
            <pubDate>Wed, 16 Dec 2020 18:47:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New OpenNebula Managed Services for Corporate Users]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25446322">thread link</a>) | @amarti
<br/>
December 16, 2020 | https://opennebula.io/new-opennebula-managed-services-for-corporate-users/ | <a href="https://web.archive.org/web/*/https://opennebula.io/new-opennebula-managed-services-for-corporate-users/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-29462">

    <!-- .entry-header -->

    <div>

		
<p>We are very excited to be announcing that we will now be expanding the support that we make available to <strong>OpenNebula Systems customers </strong>by providing a complete <a href="https://support.opennebula.pro/hc/en-us/articles/360052934231-Managed-Services-Guide">Managed Services extension</a> to those Corporate Users with an active <a href="https://opennebula.io/subscriptions/">OpenNebula Subscription</a>. This comes at a time when many organizations want to have their own private Enterprise Cloud, but are seeking <strong>an alternative to having to manage and administer a cloud solution</strong> by themselves.</p>



<div>
<p>We are aware of the resources, expertise, and effort that are required to run a private or hybrid cloud infrastructure, and many organizations would plainly rather <strong>focus on their business</strong>. And that is OK! For that reason, we have expanded our offering to provide Corporate Users not only with a commercially-supported cloud platform and the underlying benefits of our Subscriptions, but also with the option of <strong>handing the ‘keys’ of your OpenNebula cloud environment to us</strong>, OpenNebula Systems, so that our team of experts can fully manage and administer it for you! 🤓</p>



<div>
<div><figure><img src="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel.png" alt="" width="175" height="180" srcset="https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel.png 908w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel-291x300.png 291w, https://opennebula.io/wp-content/uploads/2020/12/OpenNebula_SupportModel-768x793.png 768w" sizes="(max-width: 175px) 100vw, 175px"></figure></div>
</div>
</div>



<p>The Managed Services extension converts your OpenNebula Software Subscription into a <strong>Managed Cloud Subscription</strong> that:</p>



<ul><li>Lets you submit through our <a rel="noreferrer noopener" href="https://support.opennebula.pro/" target="_blank">Customer Portal</a> any incidents related to the managed infrastructure and not only with the software stack.</li><li>Includes periodic capacity planning, tuning, maintenance, update and upgrade actions for your OpenNebula cloud and all software components needed for your cloud infrastructure.</li><li>Implements continuous monitoring for availability of your cloud services, and commits to an uptime service level.</li></ul>







<div><figure><a href="https://opennebula.io/true-hybrid/" target="_blank" rel="noopener noreferrer"><img src="https://opennebula.io/wp-content/uploads/2020/12/Consolidated-Infra-Cluster.png" alt="" width="661" height="398"></a></figure></div>







<p>This Managed Services extension goes hand-in-hand with our <a href="https://opennebula.io/true-hybrid">True Hybrid Cloud Architecture</a>, a streamlined platform for running <strong>any workload</strong>, on <strong>any resource</strong>, <strong>anywhere</strong>. And the elastic approach to pricing for this Managed Services extension comes with the flexibility of annual, quarterly, or monthly billing features. This new subscription extension rounds out the recent addition that we announced with our <a href="https://opennebula.io/opennebula-managed-service-provider-partnership/">Managed Service Provider Program</a>, which provides managed services through our <strong>certified partners</strong> for other combinations of storage and networking technologies.</p>



<p>Have a look at our <a href="https://support.opennebula.pro/hc/en-us/articles/360052934231-Managed-Services-Guide" target="_blank" rel="noreferrer noopener">Managed Services Guide</a> and don’t hesitate to <a href="https://opennebula.io/contact/">contact us</a> to discuss your specific needs; our consultants will help you <strong>find the most suitable Managed Services model</strong> for your OpenNebula Enterprise Cloud! 📡</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/new-opennebula-managed-services-for-corporate-users/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25446322</guid>
            <pubDate>Wed, 16 Dec 2020 18:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Bitcoin Is Called Digital Gold and Why Store of Value Is a Bullshit Argument]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25445705">thread link</a>) | @wiggumspiggums
<br/>
December 16, 2020 | https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/ | <a href="https://web.archive.org/web/*/https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
												
<p>There’s this narrative in the Bitcoin community that you may have heard: The government doesn’t care about you and is printing money with no conscience. Preserve your wealth with Bitcoin! Money printers go brrrr! </p>



<p>It makes Bitcoin sound virtuous. </p>



<p>But it’s a sales pitch.</p>



<p>In this post, we’ll talk about how Bitcoin stacks up to gold as a hedge against inflation and why we don’t think wealth preservation is what really motivates most Bitcoin investors.</p>



<p>Table of Contents:</p>



<ul><li><a href="#Why-Bitcoin-Is-Compared-to-Gold">Why Bitcoin Is Compared to Gold</a></li><li><a href="#Why-Bitcoin-Is-Better-Than-Gold">Why Bitcoin Is Better Than Gold</a></li><li><a href="#The-Store-of-Value-Argument">The “Store of Value” Argument</a></li><li><a href="#Is-Preserving-Wealth-What-People-Really-Care-About">Is Preserving Wealth What People Really Care About?</a></li></ul>



<h2 id="Why-Bitcoin-Is-Compared-to-Gold">Why Bitcoin Is Compared to Gold</h2>



<p>People call Bitcoin “digital gold” because both Bitcoin and gold have a limited supply. Unlike fiat/paper currency, which can be printed at the discretion of the government, Bitcoin will only ever have 21 millions coins unless +51% of its miners agree to change the protocol (which is highly unlikely). As for gold, there’s only so much that can be mined out of the earth.</p>



<h2 id="Why-Bitcoin-Is-Better-Than-Gold">Why Bitcoin Is Better Than Gold</h2>



<p>Many believe Bitcoin is superior to gold because:</p>



<ol><li>It’s digital so potentially harder to get seized by the government or stolen by a criminal. (Of course, if someone knows you own Bitcoin, they could still threaten you with force or violence to access it). </li><li>It’s easy to send. Anyone with a basic internet connection and some sort of computing device can send/receive Bitcoin. But gold is not because it’s a physical object and a heavy one at that.</li><li>It’s easily verifiable through cryptographic technology.</li><li>It’s infinitely divisible, which of course gold is not. There’s actual a unit of currency called a Satoshi, and 1 Bitcoin equals 100 million Satoshis.</li><li>It is somewhat programmable (though not nearly as advanced as a <a href="https://prudentlycrypto.com/why-invest-in-ethereum/" target="_blank" rel="noreferrer noopener">Ethereum</a>).</li></ol>



<p>But Bitcoin has some important disadvantages:</p>



<ol><li>It’s not fully private. Because the Bitcoin ledger aka blockchain is open to the public, Bitcoin transactions can reveal information about the senders and recipients. Authorities have taken advantage of this lack of complete anonymity to catch criminals.</li><li>It’s not as widely accepted or trusted: by society, financial institutions, governments, etc.</li><li>It’s very speculative &amp; volatile and has a much shorter a track record.</li></ol>



<h2 id="The-Store-of-Value-Argument">The “Store of Value” Argument</h2>



<p>Because both Bitcoin and gold are scarce, people think Bitcoin can serve the same purpose as gold: act as a better store of value over paper money and hedge against inflation.</p>



<p>You may have heard worries over inflation because of governments printing money to provide financial relief due to Covid-19. Some notable investors, like Raoul Pal and Ray Dalio, have said so, too.</p>



<p>So in the eyes of many Bitcoin enthusiasts, one of the most compelling arguments in support of Bitcoin is the fact that it can preserve wealth from being inflated away.</p>



<p>(NOTE: We know <a href="https://www.bloomberg.com/news/articles/2020-05-07/paul-tudor-jones-buys-bitcoin-says-he-s-reminded-of-gold-in-70s" target="_blank" rel="noreferrer noopener">Paul Tudor Jones</a> says that a store of value must have purchasing power, trustworthiness, liquidity and portability. But scarcity is what the majority of folks focus on).</p>



<h2 id="Is-Preserving-Wealth-What-People-Really-Care-About">Is Preserving Wealth What People Really Care About?</h2>



<p>Let’s rephrase this question a bit: Let’s say inflation was high at 10% per year. But a total stock market ETF gave a 15% return on the year. Would anyone give a rat’s ass about Bitcoin, if it kept up with inflation but <em>didn’t</em> beat the market?</p>



<p>We think not. Because, let’s be honest, the excitement around Bitcoin <em>as an “investment</em>” is its outstanding returns.&nbsp;</p>



<p>Many people promote Bitcoin, arguing that it is the best inflation hedge. But protecting against inflation is not as important to them as seeing the price of Bitcoin go up. Because Bitcoin is scarce, getting more people to adopt Bitcoin as an inflation hedge drives up the price. So the justification is your wealth preservation. But the motivation is their wealth accumulation.</p>



<p><em>Now, does this detract from Bitcoin as a financial innovation? </em>No.</p>



<p><em>Does this mean Bitcoin does NOT act as a hedge against inflation? </em>No, it can despite other people’s ulterior motives advocating for it.&nbsp;</p>



<p><em>Does this stop us <a href="https://prudentlycrypto.com/about/" target="_blank" rel="noreferrer noopener">Crypto Prudes</a> from buying and hodling Bitcoin? </em>Not at all.</p>



<p>We just think it’s important to have clear eyes when betting on Bitcoin because Bitcoin as a “store of value” is not what is truly motivating current investors. The truth is they wanna see Bitcoin beat the pants off all other investments. Otherwise, nobody would really give a shit (us included). </p>



<p><em>Disclaimer: this article should be treated as informational only and not as financial, investment or any other advice.&nbsp;</em></p>
											</div></div>]]>
            </description>
            <link>https://prudentlycrypto.com/why-bitcoin-is-called-digital-gold-and-why-store-of-value-is-a-bullshit-argument/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25445705</guid>
            <pubDate>Wed, 16 Dec 2020 17:48:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Observer Effect interview with Tobi Lütke]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25445474">thread link</a>) | @matallo
<br/>
December 16, 2020 | https://www.theobservereffect.org/tobi.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/tobi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the third interview on 'The Observer Effect'. We are lucky to have one
									of the most interesting founders in technology and commerce - Tobi Lütke, Founder
									and CEO of Shopify. This interview was published on December 16th, 2020.

							</em></p><p><em>Tobi is one of the most thoughtful and first principles oriented founders I've met and
								this was a fascinating conversation. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let’s start with the basics. Walk me through a typical day in the life of
										Tobi Lütke.</strong></em>
							</p><p>
								Here’s the honest answer: obviously I have a schedule and people helping me manage my
								time, however, I think a lot about where to devote my attention. In this way, there is
								no typical day.

							</p><p>My attention is the most liquid and valuable resource that I have. Even back in the day
								when Shopify went public, I spent a good deal of time pre-selling the various investors.
								During meetings, I would say, “Hey, I'm here, and we've been doing this roadshow, but I
								actually spend a lot of my time on the product.” This was to set expectations because I
								knew I wasn't going to attend very many investor conferences. Fundamentally, my
								attention belonged to the product, not to the sales and marketing of it. </p><p>A day in my life really depends on what's happening. That said, usually I have themes.
								For instance, I have a priority list, and I have decision logs that chronicle all the
								things I am trying to figure out. </p><p>
								These cover different questions. For example, if I had just taken the company over, how
								would I change it? How would I build a company to potentially disrupt Shopify? I try to
								make my calendar match these bigger topics and other urgent priorities. In a way, the
								calendar is nothing more than a strategy. Although it's incredibly easy—and it has
								happened to me quite a lot—to have circumstances dictate the calendar. Because of this,
								there’s this constant tug of war between the actual priorities of the company and the
								kind of things that have to be done.

							</p><p>So, I end up trying to insert themes into my days. Like today, for instance, I have a
								meeting with my small team to begin the week; I reserved my afternoon for product
								reviews—what we call “greenpathing exercises”—where, oddly, I'm trying to discern how
								everyone is thinking about the main things we're working on. I do this because
								oftentimes I feel as though I am the connective tissue combining operations, finance,
								and more formal business functions with the product itself. This connection helps me to
								make good decisions.</p><p>Lastly, on Wednesdays, Shopify doesn't do scheduled meetings. Usually, I have a list of
								memos to read or reactions to record to various mock-ups and so on. This is basically my
								very loosely defined schedule.</p><p>
								<b><i>How do you work with your so-called “expansion pack team” on reallocating your
										portfolio management on time? What does that loop look like?
									</i></b>
							</p><p>
								A lot of this is almost automatic by just having a good color coding system, which is
								really fun.
								<i>[laughs]</i>

							</p><p> At one point, I started complaining about blue weeks where every single time slot was
								taken. And someone said, “Well, if you don't like blue, I can make any color.” And I
								replied, “Well, how about we color based on leverage?” And that’s just what we did. </p><p>
								We ended up labeling my product-related things red, investor/Board of Director-related
								things some kind of teal color, et cetera. And the thing I’m looking for is a balanced
								week; a week where, ideally, I manage to devote about 30% of the time—at least—to the
								product and then as much as possible to things like recruiting, bigger picture projects,
								and one-on-ones.

							</p><p>
								And so, if my calendar becomes too external or too much of anything, it's the first
								thing we see when we sit down for our priorities meeting. This makes scheduling a lot
								easier.

							</p><p>
								<b><i>
										This is a very natural segue to my next question. One of the theories behind
										this whole set of interviews is diving into the atomic bits of how we spend our
										time in meetings. This time compounds over the long term and has a massive
										effect. What does a good meeting with Tobi look like? Alternatively, what does a
										bad meeting with you look like?
									</i>
							</b></p><div>
							<p>So actually, agendas are not terribly successful with me. I admire how other CEOs I’ve
								spoken with always have a strict agenda where everyone has a speaking slot. I find that
								absolutely fascinating. Even if I really set myself to an agenda and say, “Okay, great,
								this is going to happen,” I can't get through half of a meeting like this. Partly
								because a good meeting is, for me personally, when I learn something.</p>
								<blockquote>
									<p>..when I have my own ideas, the first thing I tend to do is
										just try to falsify them, to figure out why what I'm thinking about is probably
										incorrect...<em>
									</em></p>
								</blockquote>
							<p>
								I started a company because I love learning. I went into programming because I found it
								fascinating. During meetings, I just love to hear the things that teams have discovered.
								When you're discussing an idea or a decision, I want to know what has been considered.
								To be honest, I find myself more interested in the inputs of an idea than the actual
								decision. I say this because when I have my own ideas, the first thing I tend to do is
								just try to falsify them, to figure out why what I'm thinking about is probably
								incorrect. This is actually something that I have to explain to people that I work with.
								If I like someone's idea, I tend to do the same thing: I try to poke holes in it.
							</p>

							<p>I usually say, “Well, the implication of this choice means you've made the following
								assumptions. What inputs did you use to make these foundational assumptions?”
								Effectively, I'm trying to figure out if an idea is built on solid fundamentals. I find
								that shaky fundamentals tend to be where things often go wrong. The decision being
								discussed could be the perfect decision according to the various assumptions that
								everyone came into the room with. But if those assumptions are faulty, the seemingly
								perfect decision is faulty too. Interestingly, assumptions are rarely mentioned in the
								briefing docs or in the slide deck. Usually, I'm trying to make sure those are rock
								solid. Through this process, I invariably end up learning something completely new about
								a field. That gives me great confidence and comfort both in the decision and the
								direction.</p>

							
							<h2 id="enneagrams"><b>On Enneagrams and Comprehensivists</b></h2>
							<p>


								<b><i>Two words have come up a lot in preparatory conversations: comprehensivist and
										enneagrams. Could you talk about both?

									</i></b>

							</p>

							<p>Interesting.</p>
							<p>
								<i>[Laughs]</i>
								I feel like I'm becoming known for pointing people towards the enneagram. I actually
								don't think it's that valuable on its own. The valuable thing about any of these
								personality-type constructs is that they do a really good job of teaching people that
								other people are very different. That realization is probably one of the biggest growth
								moments for people in general. It tells you that different people play different roles.
								On that note, I do think that, ideally, people should play their own roles really,
								really well.

							</p>
							<p>
								I play the role of challenger, personally. I find that the enneagram helps me remind
								myself that with different people I have to talk about the same things in different
								ways. I think it allows you to skip some time which would otherwise be touch and go at
								the beginning of a relationship and helps build trust better. In short, it enables us to
								have fruitful and effective conversations.
								And comprehensivist, I mean, that's a fancy word.
							</p>
							<p>

								<i>[Laughs]</i> I don't think I've ever used it outside of putting it into my Twitter
								bio when I was reading Buckminster Fuller. That said, I do like range. I find that the
								first 80% of every field is pretty quick to learn—it’s equivalent to the Pareto
								principle—and I think that creativity generally is people using lessons from one field
								in another field in different ways. Because of this, I find learning fascinating.

								</p><blockquote>
									<p>..creativity generally is people using lessons from one field
										in another field in different ways...<em>
									</em></p>
								</blockquote>
							
						


							<h2 id="decisionmaking"><b>On Time and Attention on Shopify<br></b></h2>
							<p>
								<b><i>
										You try and design how your company spends time and attention. One particular
										incident came up recently which I found really fascinating. You wrote a script
										to delete every recurring meeting at Shopify. Talk about why you did that, and
										what you ended up learning from it.


									</i></b>
							</p>


							<p>
								<i>[Laughs]</i>
								So, going back a little bit further there—you know what, I should talk about books. One
								thing that is interesting is how people have accused Shopify of being a book club thinly
								veiled as a public company.

							</p>
							<p>We tend to read a lot and talk about a lot of books. We read Nassim Taleb’s books and one
								person on my team began talking about Antifragile and gave an outline. He said, “I think
								Nassim is putting a word to the thing that you keep talking about…” </p>

							<p>Now, I come from an engineering perspective. One of my biggest beefs with engineers, in
								general, is …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/tobi.html">https://www.theobservereffect.org/tobi.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/tobi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25445474</guid>
            <pubDate>Wed, 16 Dec 2020 17:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeskPi Pro and 8GB Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444965">thread link</a>) | @todsacerdoti
<br/>
December 16, 2020 | https://www.earth.li/~noodles/blog/2020/12/deskpi-pro-and-pi4.html | <a href="https://web.archive.org/web/*/https://www.earth.li/~noodles/blog/2020/12/deskpi-pro-and-pi4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p><img alt="DeskPi Pro Raspberry Pi case" src="https://www.earth.li/~noodles/blog/images/2020/deskpi.jpg"></p>

<p>Despite having worked on a <a href="https://www.earth.li/~noodles/blog/2006/03/more-amstrad-e3-joy.html">number</a> <a href="https://www.earth.li/~noodles/blog/2006/10/progress-with-the-balloon.html">of</a> <a href="https://www.earth.li/~noodles/blog/2019/01/mapleboard.html">ARM</a> <a href="https://www.earth.li/~noodles/blog/2020/09/rb3011-mainline.html">platforms</a> I’ve never actually had an ARM based development box at home. I have a Raspberry Pi B Classic (the original 256MB rev 0002 variant) a coworker gave me some years ago, but it’s not what you’d choose for a build machine and generally gets used as a self contained TFTP/console server for hooking up to devices under test. Mostly I’ve been able to do kernel development with the cross compilers already built as part of Debian, and either use pre-built images or Debian directly when I need userland pieces. At a previous job I had a <a href="http://macchiatobin.net/">Marvell MACCHIATObin</a> available to me, which works out as a nice platform - quad core A72 @ 2GHz with 16GB RAM, proper SATA and a PCIe slot. However they’re still a bit pricey for a casual home machine. I really like the look of the <a href="https://www.solid-run.com/arm-servers-networking-platforms/honeycomb-workstation/">HoneyComb LX2</a> - 16 A72 cores, up to 64GB RAM - but it’s even more expensive.</p>

<p>So when I saw the existence of the <a href="https://www.raspberrypi.org/blog/8gb-raspberry-pi-4-on-sale-now-at-75/">8GB Raspberry Pi 4</a> I was interested. Firstly, the Pi 4 is a proper 64 bit device (my existing Pi B is ARMv6 which means it needs to run Raspbian instead of native Debian armhf), capable of running an upstream kernel and unmodified Debian userspace. Secondly the Pi 4 has a USB 3 controller sitting on a PCIe bus rather than just the limited SoC USB 2 controller. It’s not SATA, but it’s still a fairly decent method of attaching some storage that’s faster/more reliable than an SD card. Finally 8GB RAM is starting to get to a decent amount - for a headless build box 4GB is probably generally enough, but I wanted some headroom.</p>

<p>The Pi comes as a bare board, so I needed a case. Ideally I wanted something self contained that could take the Pi, provide a USB/SATA adaptor and take the drive too. I came across the pre-order for the <a href="https://deskpi.com/products/deskpi-pro-for-raspberry-pi-4">DeskPi Pro</a>, decided it was the sort of thing I was after, and ordered one towards the end of September. It finally arrived at the start of December, at which point I got round to ordering a Pi 4 from <a href="https://cpc.farnell.com/">CPC</a>.</p>

<p>Total cost ~ £120 for the case + Pi.</p>

<h2 id="the-bad">The Bad</h2>

<p>First, let’s get the bad parts out of the way.</p>

<p><img alt="Broken USB port (right)" src="https://www.earth.li/~noodles/blog/images/2020/deskpi-broken-usb.jpg"></p>

<p>I managed to break a USB port on the Desk Pi. It has a pair of forward facing ports, I plugged my wireless keyboard dongle into it and when trying to remove it the solid spacer bit in the socket broke off. I’ve never had this happen to me before and I’ve been using USB devices for 20 years, so I’m putting the blame on a shoddy socket.</p>

<p>The first drive I tried was an old Crucial M500 mSATA device. I have an adaptor that makes it look like a normal 2.5” drive so I used that. Unfortunately it resulted in a boot loop; the Pi would boot its initial firmware, try to talk to the drive and then reboot before even loading Linux. The DeskPi Pro comes with an m2 adaptor and I had a spare m2 drive, so I tried that and it all worked fine. This might just be power issues, but it was an unfortunate experience especially after the USB port had broken off.</p>

<p>(Given I ended up using an M.2 drive another case option would have been the <a href="https://www.argon40.com/argon-one-m-2-case-for-raspberry-pi-4.html">Argon ONE M.2</a>, which is a bit more compact.)</p>

<h2 id="the-annoying">The Annoying</h2>

<p><img alt="DeskPi Pro without rear bezel" src="https://www.earth.li/~noodles/blog/images/2020/deskpi-open.jpg"></p>

<p>The case is a little snug; I was worried I was going to damage things as I slid it in. Additionally the construction process is a little involved. There’s a good set of instructions, but there are a lot of pieces and screws involved. This includes a couple of <a href="https://en.wikipedia.org/wiki/Flexible_flat_cable">FFC cables</a> to join things up. I think this is because they’ve attempted to make a compact case rather than allowing a little extra room, and it does have the advantage that once assembled it feels robust without anything loose in it.</p>

<p><img alt="DeskPi Pro with rear bezel and USB3 dongle" src="https://www.earth.li/~noodles/blog/images/2020/deskpi-rear.jpg"></p>

<p>I hate the need for an external USB3 dongle to bridge from the Pi to the USB/SATA adaptor. All the cases I’ve seen with an internal drive bay have to do this, because the USB3 isn’t brought out internally by the Pi, but it just looks ugly to me. It’s hidden at the back, but meh.</p>

<p>Fan control is via a USB/serial device, which is fine, but it attaches to the USB C power port which defaults to being a USB peripheral. Raspbian based kernels support device tree overlays which allows easy reconfiguration to host mode, but for a Debian based system I ended up rolling my own dtb file. I changed</p>

<div><div><pre><code>#include "bcm283x-rpi-usb-peripheral.dtsi"
</code></pre></div></div>

<p>to</p>

<div><div><pre><code>#include "bcm283x-rpi-usb-host.dtsi"
</code></pre></div></div>

<p>in <code>arch/arm/boot/dts/bcm2711-rpi-4-b.dts</code> and then I did:</p>

<div><div><pre><code>cpp -nostdinc -I include -I arch -undef -x assembler-with-cpp \
    arch/arm/boot/dts/bcm2711-rpi-4-b.dts &gt; rpi4.preprocessed
dtc -I dts -O dtb rpi4.preprocessed -o bcm2711-rpi-4-b.dtb
</code></pre></div></div>

<p>and the resulting <code>bcm2711-rpi-4-b.dtb</code> file replaced the one in <code>/boot/firmware</code>. This isn’t a necessary step if you don’t want to use the cooling fan in the case, or the front USB ports, and it’s not really anyone’s fault, but it was an annoying extra step to have to figure out.</p>

<p>The DeskPi came with a microSD card that was supposed to have RaspiOS already on it. It didn’t, it was blank. In my case that was fine, because I wanted to use Debian, but it was a minor niggle.</p>

<h2 id="the-good">The Good</h2>

<p>I used Gunnar’s <a href="https://raspi.debian.net/">pre-built Pi Debian image</a> and it Just Worked; I dd’d it to the microSD as instructed and the Pi 4 came up with working wifi, video and USB enabling me to get it configured for my network. I did an <code>apt upgrade</code> and got updated to the Buster 10.7 release, as well as the latest 5.9 backport kernel, and everything came back without effort after a reboot. It’s lovely to be able to run Debian on this device without having to futz around with self-compiled kernels.</p>

<p>The DeskPi makes a lot of effort to route things externally. The SD slot is brought out to the front, making it easy to fiddle with the card contents without having to open the case to replace it. All the important ports are brought out to the back either through orientation of the Pi, or extenders in the case. That means the built in Pi USB ports, the HDMI sockets (conveniently converted to full size internally), an audio jack and a USB-C power port. The aforementioned USB3 dongle for the bridge to the drive is the only external thing that’s annoying.</p>

<p>Thermally things seem good too. I haven’t done a full torture test yet, but with the fan off the system is sitting at about 40°C while fairly idle. Some loops in bash that push load up to above 2 get the temperature up to 46°C or so, and turning the fan on brings it down to 40°C again. It’s audible, but quieter than my laptop and not annoying.</p>

<p>I liked the way the case came with everything I needed other than the Pi 4 and a suitable disk drive. There was an included PSU (a proper USB-C PD device, UK plug), the heatsink/fan is there, the USB/SATA converter is there and even an SD card is provided (though that’s just because I had a pre-order).</p>

<p>Speaking of the SD, I only needed it for initial setup. Recent Pi 4 bootloaders are capable of booting directly from USB mass storage devices. So I upgraded using the <a href="https://github.com/raspberrypi/rpi-eeprom/releases/tag/v2020.09.03-138a1">RPi EEPROM Recovery image</a> (which just needs extracted to the SD FAT partition, no need for anything complicated - boot with it and the screen goes all green and you know it’s ok), then created a FAT partition at the start of the drive for the kernel / bootloader config and a regular EXT4 partition for root. Copies everything over, updated paths, took out the SD and it all just works happily.</p>

<h2 id="summary">Summary</h2>

<p>My main complaint is the broken USB port, which feels like the result of a cheap connector. For a front facing port expected to see more use than the rear ports I think there’s a reasonable expectation of robustness. However I’m an early adopter and maybe future runs will be better.</p>

<p>Other than that I’m pretty happy. The case is exactly the sort of thing I wanted; I was looking for something that would turn the Pi into a box that can sit on my desk on the network and that I don’t have to worry about knocking wires out of or lots of cables hooking bits up. Everything being included made it very convenient to get up and running. I still haven’t poked the Pi that hard, but first impressions are looking good for it being a trouble free ARM64 dev box in the corner, until I can justify a HoneyComb.</p>

  </article></div>]]>
            </description>
            <link>https://www.earth.li/~noodles/blog/2020/12/deskpi-pro-and-pi4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444965</guid>
            <pubDate>Wed, 16 Dec 2020 17:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Risk8s Business: Risk Analysis of Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444866">thread link</a>) | @clintgibler
<br/>
December 16, 2020 | https://tldrsec.com/guides/kubernetes/ | <a href="https://web.archive.org/web/*/https://tldrsec.com/guides/kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><strong>On this page</strong>: A zero-to-hero guide for assessing the security risk of your Kubernetes cluster and hardening it.</p>

<p>Kubernetes is a container orchestrator that has seen year-after-year exponential growth in adoption.</p>

<p>While many organizations have adopted Kubernetes because of its hyped ability to
scale, extensibility, and multi-cloud support, many security teams have been
left playing catch-up.</p>

<blockquote>
  <p>This guide will help you rapidly ramp on what Kubernetes is and what it does
(and doesn’t do).</p>

  <p>You’ll learn how to understand the current state of your
Kubernetes deployment, hone in on what’s most risky, and how to mitigate that
risk.</p>

  <p>We’ll link to the best tools and other resources to learn more, and
include plenty of handy CLI one-liners to get the job done.</p>
</blockquote>

<h2 id="guide-structure">Guide Structure</h2>

<p>The structure of this guide, which you can also quickly navigate by the navbar
links on the left hand side, is the following:</p>

<h3 id="introduction">Introduction</h3>

<p>First we’ll give you an <a href="https://tldrsec.com/guides/kubernetes/overview">overview</a> of Kubernetes, discuss what it means to <a href="https://tldrsec.com/guides/kubernetes/secure-cluster-looks-like">secure a
cluster</a>, and talk about the end
goal here.</p>

<p>We’ll list a number of <a href="https://tldrsec.com/guides/kubernetes/tooling-up">solid tools</a> to get you
started, which will be used throughout this guide.</p>

<h3 id="understanding-your-environment">Understanding Your Environment</h3>

<p>You need to <a href="https://tldrsec.com/guides/kubernetes/understanding-your-environment">understand your environment</a> before you can secure it, so we start
there. We’ll quickly dive in to ways that you can collect information, and which information is relevant in the big picture.</p>

<p>We want to see what your cluster looks like, how you’re <a href="https://tldrsec.com/guides/kubernetes/how-deploying">deploying it</a> (managed vs self-hosted), what’s running
<a href="https://tldrsec.com/guides/kubernetes/whats-running-in-cluster">inside</a> and <a href="https://tldrsec.com/guides/kubernetes/whats-running-nearby-cluster">nearby</a>, and what services are at risk of being compromised throughout the cluster’s lifetime.</p>

<h3 id="understanding-your-risk">Understanding Your Risk</h3>

<p>With all this information we will run through a simple risk analysis that helps us determine how likely an exploit would occur and determine how your cluster will hold up. Finally building
an overall risk baseline for the environment.</p>

<p>We’ll examine:</p>
<ul>
  <li><a href="https://tldrsec.com/guides/kubernetes/understanding-your-risk">Access controls</a>: who can deploy and how are workloads being deployed?</li>
  <li>Which <a href="https://tldrsec.com/guides/kubernetes/services-exposed">services are exposed</a> publicly or internally?</li>
  <li>Do we have visibility into the cluster, and is our <a href="https://tldrsec.com/guides/kubernetes/how-vulnerable-is-cluster">cluster vulnerable</a> due to configuration mistakes or networking-related vulnerabilities?</li>
</ul>

<p>We’ll conclude by discussing <a href="https://tldrsec.com/guides/kubernetes/common-compromise-scenarios">common compromise
scenarios</a>: a pod being
compromised, a developer compromising a cluster, and a developer being
compromised by an attacker. And some stories of what I’ve seen in the real world
during my consulting work, for good measure 😎</p>

<h3 id="wrapping-up">Wrapping Up</h3>
<p>In the end, we’ll <a href="https://tldrsec.com/guides/kubernetes/putting-it-together">put it all together</a>,
and you will hopefully have enough information to get started reviewing your
cluster environment to identify gaps, vulnerabilities, and just questionable
areas that will need further inspection.</p>

<p>Once you have a risk assessment complete, it’ll be your job to continue onto the
risk management phase and find out what mitigations will best fit in to address
all the issues you found.</p>

<p>And of course, we conclude with a variety of <a href="https://tldrsec.com/guides/kubernetes/further-reading">further
resources</a> on Kubernetes threat modeling,
additional tools, and some of our favorite conference talks.</p>



<p>My name is Mark Manning and I’m currently a security architect at <a href="https://www.snowflake.com/">Snowflake</a>. I’ve spent years as a security consultant for a global security consulting firm where I assessed, reviewed, attacked, and sometimes, helped fix problems on a wide range of Kubernetes projects (among other types of projects). I was excited for the opportunity to collaborate with <em>tl;dr sec</em> and write about a topic I’ve dealt with repeatedly over the last 4 years, Kubernetes risk.</p>

<p>I’ve worked with customers just getting started with Kubernetes, cloud providers deploying their own Kubernetes platforms, and large organizations that have invested much of their business into embracing the “digital transformation.”</p>

<p>Today I’m working with Snowflake by focusing some of my experiences and offensive skills towards helping solve some really interesting security challenges. Part of that is Risk Management of Kubernetes clusters at scale.</p>

<p>I’ve seen how things can go right, and wrong, in the real world, in a vast variety of companies. While I don’t have all the answers, I enjoy sharing what I do know with the public, and <a href="https://www.twitter.com/antitree">on Twitter</a> or at <a href="https://www.shmoocon.org/speakers/#kubectl">hacker conferences</a>.</p>

<p>My hope is that some of us will continue to work heavily on Kubernetes security so that even if we don’t fix everything, the rest of the infosec industry can level-up to meet the challenges of securing these modern platforms.</p>










<!-- Begin MailChimp Signup Form -->



<!--End mc_embed_signup-->
        
      </section></div>]]>
            </description>
            <link>https://tldrsec.com/guides/kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444866</guid>
            <pubDate>Wed, 16 Dec 2020 16:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Running Federated Learning Applications on Embedded Devices]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444353">thread link</a>) | @tanto
<br/>
December 16, 2020 | https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower?s=hn | <a href="https://web.archive.org/web/*/https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Federated Learning (FL) is catching traction and it is now being used in several commercial applications and services. For example, Google uses it for mobile <a href="https://arxiv.org/pdf/1812.02903.pdf">keyboard prediction</a>, while Apple uses FL to <a href="https://www.technologyreview.com/2019/12/11/131629/apple-ai-personalizes-siri-federated-learning/">improve Siri</a>. In this blog post, I will first give a primer on FL by comparing it against a standard datacenter setup. Then, I'll motivate the use of Federated Learning on embedded devices and, end this blog post by providing a walk-through on how you can set up and run FL applications on embedded devices using Flower.</p><p>By the end of this post, you will understand the key difference between distributed and federated learning as well as how to apply federated learning to a real problem.</p><h2>What is Federated Learning?</h2><p>We will start by giving a brief overview of what are the unique aspects of Federated Learning (FL) and how it differs from other forms of learning such as datacenter-based distributed learning.</p><ul><li><p><strong>Distributed learning:</strong> Under this setting clients are compute nodes (e.g. a server with a few GPUs) and the dataset is controller by whoever manages the datacenter, thus it can be shuffled and balanced across clients. All clients are almost always available and typically there are 1-1000 of them. The learning process is centrally orchestrated by another server in the datacenter.</p></li><li><p><strong>Federated learning:</strong> By contrast in an FL setting, the clients are independent and often much more constrained compute nodes (e.g your smartphone) that <strong>own</strong> the data and never send it to the central server. In this way, learning happens locally in each node using their own data and, once the on-device learning stage is completed, the nodes send their updates to the central server, where the results get aggregated. Finally, the central server generates a new <em>global model</em>. The number of clients in FL can reach millions of nodes, but only a fraction of them might be available for a given round of training. The amount and quality of data might vastly differ from client to client. Because clients own the data, FL can offer privacy guarantees that aren't possible in datacenter-based learning approach where privacy is mostly based on a trust agreement.</p></li></ul><p>The diagram bellow illustrates the key differences (left: federated learning, right: classical distributed training in datacenter):</p><div><div data-rmiz-wrap="visible"><picture><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-b7d6672412df666c1cc1d865dcbeb644.webp" media="(max-width: 400px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-3717f1fd49de4f57238436b6834188a6.webp" media="(min-width: 401px) and (max-width: 800px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-a369975bc78b7ba6d4f503b3d8e10cb0.webp" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-7742c1738e0b8935883cb64f9de350ea.webp" media="(min-width: 1201px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-682846e2e914876775cc51a6d7971561.png" media="(max-width: 400px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-45202bd75244e2af964f56d786bf6834.png" media="(min-width: 401px) and (max-width: 800px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-83386a049a9605e0a6a543d8d4822645.png" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/intro_diagram-dae913420dfe5e5ec3e868d9287fa636.png" media="(min-width: 1201px)"><img src="https://flower.dev/_next/static/chunks/images/intro_diagram-dae913420dfe5e5ec3e868d9287fa636.png" alt="Intro Diagram"></picture></div></div><blockquote><p>For a more in-depth analysis of different training setups please check <a href="https://arxiv.org/pdf/1912.04977.pdf">Advances and Open Problems in Federated Learning, Kairouz et al. (2019)</a></p></blockquote><h2>Motivating FL on Embedded Devices</h2><p>Here I present a hypothetical example showing how Federated Learning brings value in privacy sensible contexts such as smart appliances using computer vision. I'll use this example to motivate the use of Federated Learning on embedded devices.</p><p>Let's assume there is a company out there that offers a service by which you can easily keep track of what's in your fridge. Such service only requires you to (1) install a small camera with an embedded computer inside your fridge (we'll refer to this device as a "FridgeCam") and (2) connect the device to your WiFi network. Upon installation, the FridgeCam will download a pretrained model from the server offering the service of detecting and classifying the items in your fridge.</p><p>However, this initial classification model isn't very good. The main reason being that there are not publicly available datasets that capture the wide variety of items that can be found inside a fridge as well as the different levels of occlusion, viewing angles and, illumination conditions. Because of this, the service provider offers an opt-in program for users to collaborate with the images captured by their FridgeCams and use them to build a better classification model.</p><div><div data-rmiz-wrap="visible"><picture><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-3e4885cd589d501ac7a08cd83f782911.webp" media="(max-width: 400px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-c437da742eac9221e9c23455edfb0113.webp" media="(min-width: 401px) and (max-width: 800px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-3581e47721403c07542c3039b03b26e4.webp" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-3fb3cfc661b335b882c9e83c811bf100.webp" media="(min-width: 1201px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-50459349e7715d687e896e0b58deb2ba.png" media="(max-width: 400px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-de054442d7f2ee9a0cb2e1dbb549edab.png" media="(min-width: 401px) and (max-width: 800px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-6bfab7c98cb8e339fe6099181c14f9fe.png" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-7d66966788856236c27a8003121310d1.png" media="(min-width: 1201px)"><img src="https://flower.dev/_next/static/chunks/images/fridgecam_diagram-7d66966788856236c27a8003121310d1.png" alt="FridgeCam Diagram"></picture></div></div><p>Privacy is an obvious concern here. As a result, many users might not want to share the content of their fridge. For example, some might not want to share images showing alcoholic drinks, others would be worried about sharing some medication that needs to be stored in the fridge. Whatever the reason is, Federated Learning with its privacy guarantees is currently the best way of training a better global model without sharing any data with the service provider.</p><p>If a sufficiently large pool of users with their FridgeCams joins the service and, if they are willing to contribute towards the FL learning process (which will also involve some regular image annotation effort from their side), this long-awaited service of keeping track of what's on your fridge could become a reality :relieved:.</p><h2>Using Flower on Embedded Devices</h2><p>Using embedded devices as FL clients could be cumbersome as it might require substantial configuration to get the machine learning framework (e.g. PyTorch or Tensorflow) running efficiently on these devices. How can I automate this process as well as setting up the communication with the server?</p><p>With Flower you can <a href="https://github.com/adap/flower/tree/main/examples/embedded_devices">run FL on embedded devices</a> after a minimal setting up process. We have dockerized the Flower clients to make the process of adding them to the FL pool of clients as seamless as possible. This means that the only requirement to use Flower clients is to install Docker in your embedded device (e.g. a Raspberry Pi). We provide a step-by-step guide on how to do this <a href="https://github.com/adap/flower/tree/main/examples/embedded_devices">here</a>. Once Docker is up and running, everything is ready to launch an FL training pipeline that trains on-device an image classification model. The following diagram illustrates the setup for this example.</p><div><div data-rmiz-wrap="visible"><picture><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-3ae27e7892c0bbcbbe3b93a3105b2881.webp" media="(max-width: 400px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-035688095262cea6c213a03ea8520013.webp" media="(min-width: 401px) and (max-width: 800px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-625fba5beee330cebada9a0610fbe9ac.webp" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/webp" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-b3383612702a6119acde5f4640bdacd3.webp" media="(min-width: 1201px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-0fad80335f0842adfd9fbd3ec8897e2e.png" media="(max-width: 400px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-9814f1da2d7e15c2522882f7c63f6e9c.png" media="(min-width: 401px) and (max-width: 800px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-536fd0cf9c552493921f8c656c31311b.png" media="(min-width: 801px) and (max-width: 1200px)"><source type="image/png" srcset="https://flower.dev/_next/static/chunks/images/demo_diagram-aa32a501ac7d3a407b4e1ade63e08363.png" media="(min-width: 1201px)"><img src="https://flower.dev/_next/static/chunks/images/demo_diagram-aa32a501ac7d3a407b4e1ade63e08363.png" alt="Demo Diagram"></picture></div></div><p>In the example we provide, we present a simpler scenario from what was described in the previous section using FridgeCams. Instead, we will show how to train an image classifier for <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10 dataset</a> in a Federated Learning fashion. An equivalent setup could be used to make FridgeCams a reality so, if this idea sounds exciting to you, feel free to <a href="https://flower.dev/join-slack">join our Slack channel</a> to discuss it! In the meantime, you can run our CIFAR-10 example by:</p><p>First, launch the server in your machine (i.e. your laptop) by specifying your machine's IP address, the number of FL rounds and, the model to use: </p><div><article><p>Copy</p><pre><code><span># launch your server. It will be waiting until two clients connect</span><span>
</span>$ python server.py --server_address &lt;YOUR_SERVER_IP:PORT&gt; --rounds 3 --model Net
</code></pre></article></div><blockquote><p>If you have just one device around to act as a client you can still run this demo by supplying <code>--min_num_clients=1</code> and <code>--min_sample_size=1</code> when you launch the server. Please refer to this example's repository for additional details.</p></blockquote><p>Then, launch the Raspberry Pi client:</p><div><article><p>Copy</p><pre><code><span># where `cid` is your unique client id, and `model` is the architecture to use</span><span>
</span>$ ./run_pi.sh --server_address=&lt;SERVER_ADDRESS&gt; --cid=0 --model=Net
</code></pre></article></div><p>Then, launch the Jetson client:</p><div><article><p>Copy</p><pre><code><span># make sure the --cid is unique</span><span>
</span>$ ./run_jetson.sh --server_address=&lt;SERVER_ADDRESS&gt; --cid=1 --model=Net
</code></pre></article></div><p>Internally, <code>run_pi.sh</code> and <code>run_jetson.sh</code> are identical with the exception that the former pulls a Docker image with PyTorch compiled for Arm CPUs and the latter pulls another with GPU support for NVIDIA-Jetson devices. Then, the Dockerfile recipe (see below) downloads the CIFAR-10 dataset. The last stage in the Docker build process copies the two scripts needed to run the Flower Client: <code>client.py</code> and <code>utils.py</code>. </p><div><article><p>Copy</p><pre><code><span>ARG</span><span> BASE_IMAGE_TYPE=cpu
</span><span></span><span># these images have been pushed to Dockerhub but you can find</span><span>
</span><span></span><span># each Dockerfile used in the `base_images` directory </span><span>
</span><span></span><span>FROM</span><span> jafermarq/jetsonfederated_$BASE_IMAGE_TYPE:latest
</span>
<span></span><span>RUN</span><span> apt-get install wget -y</span><span>
</span>
<span></span><span># Download and extract CIFAR-10</span><span>
</span><span></span><span>ENV</span><span> DATA_DIR=/app/data/cifar-</span><span>10</span><span>
</span><span></span><span>RUN</span><span> mkdir -p </span><span>$DATA_DIR</span><span>
</span><span></span><span>WORKDIR</span><span> </span><span>$DATA_DIR</span><span>
</span><span></span><span>RUN</span><span> wget https://www.cs.toronto.edu/\~kriz/cifar-10-python.tar.gz </span><span>
</span><span></span><span>RUN</span><span> tar -zxvf cifar-10-python.tar.gz</span><span>
</span>
<span></span><span>WORKDIR</span><span> /app</span><span>
</span>
<span></span><span># Scripts needed for Flower client</span><span>
</span><span></span><span>ADD</span><span> client.py /app</span><span>
</span><span></span><span>ADD</span><span> utils.py /app</span><span>
</span>
<span></span><span>ENTRYPOINT</span><span> [</span><span>"python3"</span><span>,</span><span>"-u"</span><span>,</span><span>"./client.py"</span><span>]</span></code></pre></article></div><p>The client will print various messages throughout the process. For this particular example, you should expect to see that a successful connection with the server was established and the duration of each of the three training rounds:</p><div><article><p>Copy</p><pre><code><span>#</span><span> [Docker build output -- omitted]</span><span>
</span>DEBUG flower 2020-12-12 11:52:54,264 | connection.py:36 | ChannelConnectivity.IDLE
<!-- -->DEBUG flower 2020-12-12 11:52:54,267 | connection.py:36 | ChannelConnectivity.CONNECTING
<!-- -->INFO flower 2020-12-12 11:52:54,267 | app.py:60 | Opened (insecure) gRPC connection
<!-- -->DEBUG flower 2020-12-12 11:52:54,337 | connection.py:36 | ChannelConnectivity.READY
<!-- -->Client 0: get_parameters
<!-- -->Client 0: fit
<!-- -->Training 1 epoch(s) w/ 781 batches each
<!-- -->Epoch took: 204.97 seconds
<!-- -->Client 0: fit
<!-- -->Training 1 epoch(s) w/ 781 batches each
<!-- -->Epoch took: 202.48 seconds
<!-- -->Client 0: fit
<!-- -->Training 1 epoch(s) w/ 781 batches each
<!-- -->Epoch took: 197.53 seconds
<!-- -->DEBUG flower 2020-12-12 12:03:19,797 | connection.py:68 | Insecure gRPC channel closed
<!-- -->INFO flower 2020-12-12 12:03:19,798 | app.py:71 | Disconnect and shut down
</code></pre></article></div><p>And that’s how easy it is to deploy and run Federated Learning applications with Flower and PyTorch. If you want to use another image classification model you can do so by editing <code>utils.py</code>. If you want to further customize your FL setup or design it from the grouds up, check <a href="https://flower.dev/blog/2020-12-11-federated-learning-in-less-than-20-lines-of-code">our previous blog</a> where we showed how to do FL in less than 20 lines of code using Flower and Tensorflow.</p></div></div></div>]]>
            </description>
            <link>https://flower.dev/blog/2020-12-16-running_federated_learning_applications_on_embedded_devices_with_flower?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444353</guid>
            <pubDate>Wed, 16 Dec 2020 16:19:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaSy Math: A Resource of SaaS Metrics for Your Startup]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25444277">thread link</a>) | @randrews543
<br/>
December 16, 2020 | https://www.talkinsaasy.com/saasy-math | <a href="https://web.archive.org/web/*/https://www.talkinsaasy.com/saasy-math">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><h2 data-ix="fade-in-on-scroll-2">A collection of simple, easy to use SaaS metrics with formulas, sample calculations, and examples of how to find this data in your own tech stack</h2></p><div><div><p>Net Revenue Retention (NRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4ad78fde0b0a238a1870_Net%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Net Revenue Retention represents how well you are <strong>retaining</strong> and <strong>expanding</strong> your existing recurring revenue. NRR is most typically measured either annually or month-to-month, but you are always comparing a cohort (a group of customers acquired at the same time) to see how their subscription revenue fares over the given time period. Think about your Netflix subscription, when you first signed up, are you still subscribed? And are you paying the same about as before?</p><p>‍<strong>Quick and SaaSy Way To Calculate:</strong> Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month, then just divide that number by previous years MRR number and you have your annual net revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Net Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-revenue-retention" target="_blank">Net Revenue Retention</a></p></div></div></div><div><div><p>Gross Revenue Retention (GRR)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fbe4aa6b26ad627a4efeb0f_Gross%20Revenue%20Retention.png" loading="lazy" alt=""></p></div><div><div><p>Gross Revenue Retention represents how well you are <strong>retaining</strong> your revenue and DOES NOT include how well you are expanding them. Similar to NRR, GRR measures customer cohorts aver a given time period to see how much of the initial MRR still remains over the given time period.</p><p><strong>Quick and SaaSy Way To Calculate:</strong> Similar to NRR, go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>. Go back twelve months and find all of the customers you acquired in that month, total their MRR and save their Subscription ID (Look for all subscriptions with a created date in that month). Then, go to the most recent full month of billing data and pull all of the invoices the match the Subscription ID for all the new customers 12 months ago (the subscription ID lives on the invoice object and you can join the data using these IDs to only get the invoices tied to those subscriptions). Once you have them all you can calculate the total MRR in the most recent month but in the case of GRR, any customers who’s revenue expanded, you need to take out the additional revenue and just keep their original MRR. Then just divide that number by previous years MRR number and you have your annual gross revenue retention. If you want to take this analysis to the next level shoot me an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how Gross Revenue Retention can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank">Net vs Gross Revenue Retention</a></p></div></div></div><div><div><p>Customer Churn</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca548eec3a202105d82b1e_Customer%20Churn.png" loading="lazy" alt=""></p></div><div><div><p>Customer Churn is the measure of how many customers cancel over time from a given cohort. While the goal is to always minimize churn as best possible, SaaS/Subscription will have some churn and tracking it is crucial for success. Similar to Revenue Retention</p><p><strong>Quick and SaaSy Way To Calculate: </strong>Go into your billing/subscription management system such as <a href="https://stripe.com/" target="_blank">Stripe</a> or <a href="https://www.zuora.com/" target="_blank">Zuora</a>, or go into your CRM such as <a href="https://www.salesforce.com/" target="_blank">Salesforce</a> or <a href="https://www.hubspot.com/" target="_blank">HubSpot</a>. From either system you want to look for the Customer/Account table from the systems API. From that table you want to look up and count all of the unique customer ID’s that where created in a given month. Then month-to-month you want to run a check on those same ID’s to see how many of them are still active customers and then divide that number by the initial number in their first month. Typically, startups will look at churn on a monthly and annual basis and we highly recommend you track the changes in churn over time (ie. If the rate of churn is decreasing or increasing over time). If you want to take this analysis to the next level shoot me us <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer churn can differ throughout your customer base.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/churn-isnt-always-bad" target="_blank">Churn Isn’t Always Bad</a>, <a href="#https://www.talkinsaasy.com/blog/revenue-churn-vs-customer-churn">Revenue Churn vs Customer Churn</a><br><a href="https://www.talkinsaasy.com/blog/net-vs-gross-revenue-retention" target="_blank"></a></p></div></div></div><div><div><p>Customer Acquisition Cost (CAC)</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fca549a64abc2d9c6dfb094_Customer%20Acquisition%20Cost.png" loading="lazy" alt=""></p></div><div><div><p>Customer Acquisition Cost, or CAC, is the measure of how much a company must spend in order to acquire a new customer. Typically you look at CAC over a period of time (annually and/or month-to-month) to understand how it is trending for your business.<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>To get your expenses you will need to go into your accounting/financial system such as Quickbooks or Xero, and track down your sales and marketing expenses for a time frame. This will include salaries, tech spend, marketing spend and any other expenses that go into your customer acquisition funnel. You then want to go into your CRM or billing and subscription management system and run a count of all the unique customer ID’s that have a created date in the same time period. You then divide the cost by your new customer count and you have your average CAC. If you want to take this analysis to the next level shoot us an <a href="https://www.talkinsaasy.com/contact">email</a> and we can discuss how to segment and find how customer acquisition cost can differ throughout your customer base.</p><p>Related Blog&nbsp;Posts:<a href="https://www.talkinsaasy.com/blog/dont-get-fooled-by-cac"> Don't Get Fooled By CAC</a></p></div></div></div><div><div><p>Retention Margin</p><p><img src="https://uploads-ssl.webflow.com/5fac0bd027bf86766ba40837/5fd6a337e1ad8f8787d82e4d_Retention%20Margins.png" loading="lazy" alt=""></p></div><div><div><p>Retention Margins is a measurement of the % of top-line revenue that is left over each month once you have taken out the cost of revenue (Gross Margins) and the cost of keeping (retaining) your recurring revenue customers. Think of retention margins as the the home profit on a per customer basis after you have retained them month-over-month<br>‍<br><strong>Quick and SaaSy Way To Calculate: </strong>First you need to calculate your Gross Margin (Revenue-Cost of Revenue/Revenue). Then go into your accounting system like Quickbooks or Xero. You want to total up the amount of spend (payroll, overhead, etc.) for your customer service and success teams. You then want to add that number to your Cost of Revenue number and subtract that from your top-line revenue. That number is your retention profit (Take home $$$) after retaining your customers. Take your retention profit and divide it by your top-line revenue number and that will give you your retention margin.</p><p>Related Blog Posts: <a href="https://www.talkinsaasy.com/blog/why-net-and-gross-revenue-retention-matter">Why Net AND&nbsp;Gross Revenue Retention Matter</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.talkinsaasy.com/saasy-math</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444277</guid>
            <pubDate>Wed, 16 Dec 2020 16:14:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Alt-Cities: Why Tech, Finance, and Music Chose Austin, Miami, and Nashville]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444176">thread link</a>) | @jseliger
<br/>
December 16, 2020 | http://www.yared.com/2020/12/the-alt-cities-why-tech-finance-and.html | <a href="https://web.archive.org/web/*/http://www.yared.com/2020/12/the-alt-cities-why-tech-finance-and.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-1263537399197749957">
<div><p><a href="https://1.bp.blogspot.com/-QZ-6Vs0QrWE/X9j2BGe5B0I/AAAAAAAAnSg/Cj7V2U8ZjQAVBAvjQGNDdQVPpz3I4pfuACLcBGAsYHQ/s1600/alt-cities.jpg"><img data-original-height="900" data-original-width="1600" height="316" src="https://1.bp.blogspot.com/-QZ-6Vs0QrWE/X9j2BGe5B0I/AAAAAAAAnSg/Cj7V2U8ZjQAVBAvjQGNDdQVPpz3I4pfuACLcBGAsYHQ/w563-h316/alt-cities.jpg" width="563"></a></p></div><p><span>Three months ago, my wife and I moved from San Francisco to Miami. I previously lived in San Francisco for over 23 years, where I started multiple companies and worked at companies like Sun Microsystems. Given the spate of people now moving, I thought it would be useful to aggregate the unique characteristics that have turned Austin, Miami, and Nashville into such hot destinations.</span></p><p><span>Globalization and network effects have produced centers of industry in mega-cities, such as finance in New York and technology in San Francisco. It takes a monumental event to displace an industry from a mega-city; the only such event in the modern era is the handover of Hong Kong to China, which shifted Asian finance to Singapore.</span></p><p><span>The coronavirus is now as significant an event as the handover of Hong Kong. Three alt-cities (alternative cities) for key industries are quickly emerging: finance from New York to Miami, technology from San Francisco to Austin, and music from Los Angeles to Nashville. There is also cross-pollination in these emerging centers. Much like New York started to have a tech scene, Miami has a rapidly burgeoning tech scene with </span><a href="https://twitter.com/FrancisSuarez/status/1338605468894244865?s=20"><span>great support from its mayor</span></a><span> Francis Suarez.</span></p><p><span>Alt-cities require multi-faceted kindling to become viable competitors:</span></p><h2><span>Key people</span></h2><p><span>It's all about the key people. You can't move the center of an industry without moving key players. Years of attempts to kindle homegrown Silicon Valleys everywhere from the Silicon Prairie to Silicon Beach have fallen flat as a replacement to Silicon Valley because </span><a href="https://www.statista.com/statistics/424167/venture-capital-investments-usa-by-state/"><span>the key people stayed put</span></a><span>.&nbsp;</span></p><p><span>Rather than going fully remote, key people are aggregating in cities where they will be able to network post-COVID. Austin has attracted well-known technology figures such as </span><a href="https://www.bbc.com/news/technology-55246148"><span>Elon Musk</span></a><span>, </span><a href="https://www.businessinsider.com/dropbox-drew-houston-moving-to-austin-report-2020-11"><span>Drew Houston</span></a><span>, and </span><a href="https://www.cnbc.com/2020/11/06/palantir-co-founder-joe-lonsdale-leaving-silicon-valley.html"><span>Joe Lonsdale</span></a><span>. Miami and South Florida have landed finance billionaires </span><a href="https://www.miamiherald.com/news/business/real-estate-news/article244933672.html"><span>Carl Icahn</span></a><span> and </span><a href="https://www.bloomberg.com/news/articles/2020-10-21/singer-s-41-billion-hedge-fund-moving-headquarters-to-florida"><span>Paul Singer</span></a><span>, as well as prominent technology investors </span><a href="https://fortune.com/2020/11/17/keith-rabois-investor-silicon-valley-loses-another-tech-icon/"><span>Keith Rabois</span></a><span>, </span><a href="https://www.bizjournals.com/sanfrancisco/news/2020/12/01/prominent-venture-capitalist-joins-bay-area-exodus.html"><span>David Blumberg</span></a><span>, and </span><a href="https://www.bizjournals.com/southflorida/news/2018/07/03/shervin-pishevar-buys-miami-beach-home.html"><span>Sherwin Pishevar</span></a><span>. Nashville hosts well-known artists including </span><a href="https://virtualglobetrotting.com/map/jack-whites-house/view/google/"><span>Jack White</span></a><span>, </span><a href="https://www.velvetropes.com/backstage/miley-cyrus-house"><span>Miley Cyrus</span></a><span>, and </span><a href="https://www.velvetropes.com/backstage/taylor-swift-nashville-house"><span>Taylor Swift</span></a><span>, who rejected Los Angeles and helped shift Nashville from country to other forms of music. These cities are attracting free thinkers known to lead the way, leaving the impression that those left behind in the origin cities are clock-punchers at Google.</span></p><h2><span>Prestigious companies</span></h2><p><span>Alt-cities need well-known and prestigious companies to relocate or create significant outposts to help create an ecosystem. These companies help attract new talent to the area as well as transfers from other locations.</span></p><p><span>The Miami area has attracted numerous hedge funds, including </span><a href="https://www.bloomberg.com/news/articles/2020-10-21/singer-s-41-billion-hedge-fund-moving-headquarters-to-florida"><span>Elliott Management</span></a><span>, and even top-tier Wall Street firms such as </span><a href="https://www.bloomberg.com/news/articles/2020-10-08/blackstone-joins-rush-to-miami-with-office-for-technology-staff"><span>Blackstone</span></a><span> and </span><a href="https://therealdeal.com/national/2020/12/07/goldman-sachs-plans-move-to-south-florida/"><span>Goldman Sachs</span></a><span> are relocating key divisions to Miami. In Austin, </span><a href="https://austonia.com/tesla-austin-factory-2021"><span>Tesla is building its largest facility on the outskirts</span></a><span> and </span><a href="https://www.cnbc.com/2020/12/11/oracle-is-moving-its-headquarters-from-silicon-valley-to-austin-texas.html"><span>Oracle is moving its&nbsp; headquarters</span></a><span> there, joining outposts from Amazon, Apple, Facebook, Dell, and many other top-tier technology companies. Brand name Silicon Valley VC firms are closing their </span><a href="https://www.vox.com/2015/4/13/11561376/has-south-park-finally-become-the-new-sand-hill-road"><span>San Francisco South Park outposts</span></a><span> and </span><a href="https://www.theinformation.com/articles/austin-emerges-as-a-hot-spot-for-silicon-valley-investors"><span>setting up shop in Austin</span></a><span>. Nashville has sprung from its country music roots, with Warner, RCA, Sony, Universal, and other top-tier music labels expanding in the city.</span></p><h2><span>Business-friendly</span></h2><p><span>While New York City and San Francisco are mulling converting their emptied </span><a href="https://www.nytimes.com/2020/12/11/nyregion/nyc-commercial-real-estate.html"><span>office buildings into residences</span></a><span>, the alt-cities have seen an increase in </span><a href="https://www.miamiherald.com/news/business/article247261699.html"><span>office space demand</span></a><span> and are quickly green-lighting </span><a href="https://www.cpexecutive.com/post/top-10-office-projects-under-construction-in-miami/"><span>new office space projects</span></a><span>. Tesla's new facility in the outskirts of Austin was fast-tracked and is nearing completion.</span></p><p><span>The coronavirus highlighted how business-friendly a jurisdiction was in terms of using data and science to set rational re-opening parameters. With pandemic protocols in place, Tesla's factory was open in China, Boeing’s factories were open in Washington, and auto factories were open in Detroit, Alabama, and South Carolina. Tesla's San Francisco-area factory was one of the only auto factories in the world that was still closed, forcing Elon Musk to play a </span><a href="https://www.theverge.com/2020/5/11/21255149/elon-musk-tesla-fremont-factory-reopen-order-arrest-alameda"><span>game of brinksmanship</span></a><span> with local authorities, with the county’s assemblywoman </span><a href="https://www.marketwatch.com/story/california-assemblywoman-hits-elon-musk-with-an-f-bomb-after-he-says-will-move-teslas-hq-out-of-state-2020-05-10"><span>sending Musk a vulgar missive</span></a><span>.</span></p><p><span>Escaping increasingly bizarre </span><a href="https://calmatters.org/california-divide/2020/11/san-francisco-ceo-tax-income-gap/"><span>taxes</span></a><span> and </span><a href="https://www.businessinsider.com/california-labor-jobs-law-bad-confusing-freelance-workers-2019-11"><span>regulations</span></a><span>, it’s now no surprise for innovators to start a new </span><a href="https://www.miamitodaynews.com/2020/03/17/sophisticated-professionals-flood-into-miami-with-hedge-funds/"><span>hedge fund in Miami</span></a><span>, a new </span><a href="https://www.bizjournals.com/austin/inno/stories/roundups/2020/11/02/austin-startup-funding-october-2020.html"><span>tech startup in Austin</span></a><span>, or a new </span><a href="https://webcache.googleusercontent.com/search?q=cache:nHBB8x0E5zkJ:https://www.tennessean.com/story/news/2020/12/10/state-music-industry-2020-not-great-nashville-leading/3885391001/+&amp;cd=1&amp;hl=en&amp;ct=clnk&amp;gl=us"><span>record label in Nashville</span></a><span>. Access to people and capital will be equivalent to the previous centers of industry.</span></p><h2><span>Affordable suburban living</span></h2><p><span>From the 1980s to the mid-1990s, cities suffered from high crime rates and numerous quality of life issues. New York City, San Francisco, Los Angeles, and some other major cities have recreated the environment of that era, with </span><a href="https://twitter.com/RMB/status/1337629864329961477?s=20"><span>non-scientific pandemic restrictions</span></a><span> that devastated local businesses and a penchant for placing the </span><a href="https://www.nytimes.com/2020/08/18/nyregion/uws-homeless-hotels-nyc.html"><span>mentally ill directly in family-oriented, residential neighborhoods</span></a><span>. These cities have </span><a href="https://sfist.com/2019/11/16/boudin-will-not-prosecute-prostitution-public-camping-and-other-quality-of-life-crimes-once-sworn-in/"><span>stopped prosecuting</span></a><span> many property and quality of life crimes, inevitably leading to </span><a href="https://abc7news.com/society/majority-of-bay-area-residents-say-quality-of-life-is-getting-worse/5963390/"><span>bad quality of life</span></a><span> and </span><a href="https://www.thecity.nyc/2020/9/14/21437309/nypd-crime-response-time-still-lags-three-months-post-protest"><span>apathetic enforcement</span></a><span> of more serious crimes.</span></p><p><span>The coronavirus has reset consumer expectations back to suburban living with the mental health benefits of living in greenspace. There has been an exodus from major industry centers to their suburbs and to the alt-cities. The alt-cities of Miami, Austin, and Nashville all offer car-friendly, suburban living, relatively cheap housing, and continual housing construction. With the acceleration of sustainable building materials and </span><a href="https://www.fastcompany.com/90583426/the-price-of-solar-electricity-has-dropped-89-in-10-years"><span>clean and cheap energy</span></a><span>, the urban planning rationale to pack people into urban cores with mass transportation was already beginning to fray, and the coronavirus has sealed its fate.</span></p><h2><span>Culture and openness</span></h2><p dir="ltr"><span>Miami is incredibly diverse, a nightlife capital of the world, has a booming art scene centered around Art Basel, and is almost as LGBTQ friendly as San Francisco. Austin and Nashville are both well known for live music and vibrant nightlife. All three offer farm-to-table restaurants and craft breweries, as artisans follow their clientele to new locations where they are unlikely to be </span><a href="https://signalscv.com/2020/12/judge-orders-l-a-county-to-provide-evidence-on-outdoor-dining-ban-lawsuit/"><span>arbitrarily shut down</span></a><span> or face inordinately high </span><a href="https://www.nytimes.com/2020/11/09/business/small-business-insurance-unrest-kenosha.html"><span>insurance premiums</span></a><span>.</span></p><p><span>New York City, San Francisco, and Los Angeles are increasingly recognized for only accepting a single, maximalist viewpoint with a </span><a href="https://brokeassstuart.com/2016/02/18/open-letter-to-justin-keller-tech-bro/"><span>rapidly shrinking Overton window</span></a><span> that even excludes working with </span><a href="https://www.cnbc.com/2020/08/26/palantir-makes-denver-the-city-to-watch-amid-silicon-valleys-exodus.html"><span>the defense industry</span></a><span>. In Miami, </span><a href="https://www.miamiherald.com/news/politics-government/article247212794.html"><span>half the people you meet are conservative and half are&nbsp; liberal</span></a><span>, and there is an acceptance that there are alternative viewpoints. A diversity of thought -- rather than a single yet constantly shifting viewpoint -- is attracting "</span><a href="https://www.youtube.com/watch?v=mtftHaK9tYY"><span>the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes</span></a><span>" to the alt-cities.</span></p><h2><span>Low taxes and quality government</span></h2><p><span>People are not moving solely for tax purposes. New York and California’s tax rates are only a few points higher than they were twenty years ago. However, once people decide to move, of course tax rate is a factor in choosing a destination. Florida, Texas, and Tennessee seemingly offer everything that California and New York offer: highways, streets, schools, police departments, fire departments, and such. All the government services one would expect are there, and none of the capital gains taxes that entrepreneurs and venture capitalists typically pay.</span></p><p><span>As comedian and political commentator Bill Maher recently noted, California is </span><a href="https://www.foxnews.com/entertainment/bill-maher-california-super-high-taxes"><span>reminiscent of a 1970s Italy</span></a><span>, with high taxes and terrible government services. In return for high taxes, one would expect to go to Hunter's Point, East Palo Alto, or East San Jose and see excellent schools and services for disadvantaged people. A </span><a href="https://www.fox5vegas.com/news/virgin-hyperloop-completes-first-test-with-actual-passengers-in-las-vegas/article_d17d8d68-418a-5d8e-bf9b-9a28f906c324.html"><span>hyperloop</span></a><span> instead of a </span><a href="https://www.cagw.org/thewastewatcher/californias-100-billion-nightmare-high-speed-rail-project"><span>failed high-speed train</span></a><span>. </span><a href="https://www.sfchronicle.com/bayarea/article/Bay-Area-awakes-to-foreboding-smoke-choked-15553731.php"><span>Fire mitigation</span></a><span> and </span><a href="https://www.sfchronicle.com/bayarea/article/Bay-Area-blackouts-What-you-need-to-know-about-15488351.php"><span>stable power</span></a><span> to complement </span><a href="https://www.wsj.com/articles/california-to-ban-sales-of-new-gas-powered-cars-starting-in-2035-11600882738"><span>long term climate change goals</span></a><span>. A boom in middle-class housing rather than a </span><a href="https://www.nytimes.com/2020/11/30/realestate/california-housing-market-price.html"><span>$700K median house price</span></a><span>. California and New York are becoming bad versions of Singapore, with a wealthy technocratic elite, an immigrant servant class, and a </span><a href="https://www.cnbc.com/2018/03/19/californians-fed-up-with-housing-costs-and-taxes-are-fleeing-state.html"><span>collapsed middle class</span></a><span>.</span></p><h2><span>What’s next for alt-cities?</span></h2><p><span>The alt-city trend has only just begun as legacy cities seem ideologically unwilling to waver on these characteristics. Other industries are starting to relocate, including the Los Angeles entertainment industry to </span><a href="https://www.productionhub.com/directory/profiles/studios-soundstages-production-television-film/us/nevada/las-vegas"><span>Las Vegas by piggybacking on the porn industry</span></a><span>, Seattle aerospace industry to </span><a href="https://abcnews4.com/news/local/boeing-moving-all-787-dreamliner-production-to-north-charleston"><span>Charleston by piggybacking on Boeing</span></a><span>, New York art industry to </span><a href="https://www.nytimes.com/2019/03/04/arts/design/artcenter-south-florida-miami-millions.html"><span>Miami by piggybacking on Art Basel</span></a><span>, Denver building a bigger technology sector by </span><a href="http://www.metrodenver.org/d/m/3T4"><span>piggybacking on it broadcast/telecommunications base</span></a><span>, and the New York retail fashion industry to </span><a href="https://fashion2fiber.osu.edu/exhibits/show/columbus-fashion-story/the-limited"><span>Columbus by piggybacking on L Brands</span></a><span>.</span></p><p><span>We are at a momentous intersection where numerous Hong Kongs are becoming Singapores.</span></p>
</div></div>]]>
            </description>
            <link>http://www.yared.com/2020/12/the-alt-cities-why-tech-finance-and.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444176</guid>
            <pubDate>Wed, 16 Dec 2020 16:05:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Performance 500: Websites of the Fortune 500 Ranked by Page Speed]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25444128">thread link</a>) | @tomhanlon
<br/>
December 16, 2020 | https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/ | <a href="https://web.archive.org/web/*/https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>The Performance 500</h2><p>Google <a href="https://developers.google.com/search/blog/2020/11/timing-for-page-experience">recently announced</a> that Page Rank changes are coming: performance metrics (Core Web Vitals like Largest Contentful Paint, Cumulative Layout Shift and First Input Delay) will soon be taken into account for prioritizing search listings.</p><p>We wanted to see how some of America's top companies —The Fortune 500— would stack up against each other when viewed in a different light: website performance. Is there a correlation between business performance and Page Speed performance? What else might we find?</p><p>Using Google’s <a href="https://developers.google.com/speed/pagespeed/insights/">PageSpeed Insights API</a> and 2020 Fortune 500 data, we compiled what we’re calling “The Performance 500”.</p><p><a href="https://docs.google.com/spreadsheets/d/17qQh1zKpa5qwNBzXcCgkVbsy-YMHV0DB_doNgktcp8M/edit?usp=sharing"><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-chart.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-chart.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-performance-500-chart.jpg" width="768" loading="lazy" alt="The Performance 500 (Google Sheets)"></picture></a></p><p><a href="https://docs.google.com/spreadsheets/d/17qQh1zKpa5qwNBzXcCgkVbsy-YMHV0DB_doNgktcp8M/edit?usp=sharing">The Performance 500</a></p><h3>And the Winner Is</h3><p>You’ll notice a recognizable name in first place for the Performance 500: <a href="https://www.berkshirehathaway.com/">Berkshire Hathaway</a>. Its Chairman and CEO, Warren Buffet, famous for continuing to live in the same house he purchased in 1958, bested even Google’s parent company in page speed performance using a simple HTML site with minimal resources to deliver content. Hats off to you, Warren and team.</p><h3>Other Interesting Findings</h3><ul><li>Only 4 sites out of the 500 (.8%) scored above a 90% or above on their PageSpeed Insights Performance Score</li><li>~85% (424/500) of sites have a Performance Score of less than 50</li><li>The average Performance Score is ~29</li><li>The average Largest Contentful Paint (LCP) metric is 13.5 seconds(!)</li><li>Less than half of the Fortune 500 had a Cumulative Layout Shift (CLS) Score of better than .1</li><li>Only 11 of the 500 have "Good" First Input Delay (FID) scores</li></ul><h3>Understanding Core Web Vitals (LCP, CLS &amp; FID)</h3><p>A quick reference:</p><ul><li>LCP: Largest Contentful Paint - How long does it take to render the largest element within the viewport (measured in seconds)</li><li>CLS: Cumulative Layout Shift - How often things move around as the page loads (presented as a score value)</li><li>FID: First Input Delay - How soon after a user input does the browser process the event (measured in milliseconds)</li></ul><p>We’ve included <a href="#understanding-core-web-vitals">a section below</a> that explains these in further detail in the language used on <a href="https://web.dev/">web.dev</a>.</p><h3>How We Tested</h3><p>We ran 5 tests at different times of day over a period of two weeks. Those results have been averaged into the scores presented in the table above. PageSpeed Insights never returned a Performance Score for ViacomCBS so we ranked it last.</p><h3>Ranking Methodology</h3><p>We chose to rank these companies “Performance 500” rank first by Google’s PageSpeed Insights Performance Score, then by Largest Contentful Paint (LCP), then by Cumulative Layout Shift (CLS), then First Input Delay (FID). We preferred this ranking order as FID is not assigned a weight in <a href="https://web.dev/performance-scoring/#lighthouse-6">Google’s weighting of the performance score</a>.</p><h3>Color Coding</h3><p>We chose to use the green, yellow and red labels using the same color coding scheme used by Page Speed Insights. These vary by metric and can be found in the <a href="https://developers.google.com/speed/docs/insights/v5/about#categories">PageSpeed Insights documentation</a>.</p><h3>Device Type</h3><p>We also chose to only show the mobile rankings of these sites. A prior version of this table existed with desktop scores as well but we felt it was too cluttered to meaningfully show desktop and mobile metrics in the same table.</p><h2 id="understanding-core-web-vitals">Understanding Core Web Vitals (Loading, Visual Stability, and Interactivity Metrics)</h2><p>Starting next May, as Google Search Results start to take into account Loading (Largest Contentful Paint), Interactivity (First Input Delay) and Visual Stability (Cumulative Layout Shift) metrics, sites that have not focused on improving these metrics will be penalized against sites that are faster to load. Let’s take a look at each of these categories.</p><h3>Loading: Largest Contentful Paint (LCP)</h3><p>Google's Definition: The Largest Contentful Paint (LCP) metric reports the render time of the largest image or text block visible within the viewport. <a href="https://web.dev/lcp/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-lcp-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-lcp-lg.svg" width="768" loading="lazy" alt="Largest Contentful Paint (LCP)"></picture><h3>Visual Stability: Cumulative Layout Shift (CLS)</h3><p>Google's Definition: CLS measures the sum total of all individual layout shift scores for every unexpected layout shift that occurs during the entire lifespan of the page.</p><p>A layout shift occurs any time a visible element changes its position from one rendered frame to the next. <a href="https://web.dev/cls/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-cls-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-cls-lg.svg" width="768" loading="lazy" alt="Cumulative Layout Shift (CLS)"></picture><h3>Interactivity: First Input Delay (FID)</h3><p>Google's Definition: FID measures the time from when a user first interacts with a page (i.e. when they click a link, tap on a button, or use a custom, JavaScript-powered control) to the time when the browser is actually able to begin processing event handlers in response to that interaction. <a href="https://web.dev/fid/">web.dev</a></p><picture><source srcset="https://reachlightspeed.com/img/blog/post-performance-500-fid-sm.svg" media="(max-width: 640px)"><img src="https://reachlightspeed.com/img/blog/post-performance-500-fid-lg.svg" width="768" loading="lazy" alt="First Input Delay (FID)"></picture><h2>Incentivizing A Faster Web</h2><p>We think these Page Rank changes from Google will have a positive impact, incentivizing companies to focus on improving page speed performance and ultimately the user experience.</p><p>Special thanks to Lekshmi Nair’s <a href="https://github.com/lekshmicnair/Fortune500_Financial_Analysis">repo</a> as a starter for most of the 2020 Fortune 500 company data in this table.</p></section></div>]]>
            </description>
            <link>https://reachlightspeed.com/blog/the-performance-500-websites-of-the-fortune-500-ranked-by-page-speed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444128</guid>
            <pubDate>Wed, 16 Dec 2020 16:01:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Regret Quitting Astrophysics]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 124 (<a href="https://news.ycombinator.com/item?id=25444069">thread link</a>) | @petschge
<br/>
December 16, 2020 | http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/ | <a href="https://web.archive.org/web/*/http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-223">
	
	<!-- .entry-header -->

	<div>
		
<p>In 2013 I decided to quit my career in astrophysics, move back “home” and become a data scientist. The <a href="http://www.marcelhaas.com/index.php/2018/03/30/leaving-the-field-becoming-an-extronomer/">blog post</a> I wrote about my decision was probably my best read publication as a professional astronomer and it was moving to read all the reactions from people who were struggling with similar decisions. I meant every word in that blog post and I still agree with most of what I said. Now, 7 years after the fact, it is time to confess: I deeply regret quitting.</p>



<p>This post is meant to give my point of view. Many people who left academia are very happy that they did. Here I present some arguments why one might not want to leave, which I hope will be of help for people facing decisions like these.</p>



<p><span>I miss being motivated.</span> In the first few years after jumping ship many people asked me why I would ever wanted to <em>not</em> be a professional astronomer. I have always said that my day-to-day work wasn’t too different, except that what I did with data was about financial services or some other business I was in, rather than about galaxies and the Universe, but that the “core activities” of work were quite similar. That is kind of true. On an hour by hour basis, often I’m just writing (Python) code to figure things out or build a useful software product. The motivation to do what you do, though, is very <em>very</em> different. The duty cycle and technical depth of projects are short and shallow and the emphasis of projects is much more on getting working products than on understanding. I am doing quite well (in my own humble opinion), but it is hard to get satisfaction out of my current job.</p>



<p><img loading="lazy" width="546" height="340" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png" alt="" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat.png 546w, http://www.marcelhaas.com/wp-content/uploads/2020/12/academic_hat-300x187.png 300w" sizes="(max-width: 546px) 100vw, 546px"></p>



<p><span>I miss academic research.</span> The seeds of astronomy were planted at very young age (8, if I remember correctly). The fascination for the wonders of the cosmos has changed somewhat in nature while growing up but hasn’t faded. Being at the forefront of figuring things out about the workings of the Universe is amazing, and unparalleled in any business setting. Having the freedom to pick up new techniques that may be useful for your research is something that happened to me only sporadically after the academic years. The freedom to learn and explore are valuable for creative and investigative minds and it doesn’t fit as well in most business settings that I have seen.</p>



<p><span>I miss working at academic institutions.</span> The vibe of being at a large research institute, surrounded by people who are intrinsically motivated to do what they do was of great value to me. Having visitors over from around the globe with interesting, perhaps related work was a big motivator. That journal clubs, coffee discussions, lunch talks, colloquiums etc. are all “part of the job” is something that even most scientists don’t always seem to fully appreciate. Teaching, at the depth of university level classes, as a part of the job is greatly rewarding (I do teach nowadays!).</p>



<p><span>I miss passion and being proud of what I do.</span> The <a href="https://www.google.nl/search?hl=nl&amp;q=sexiest+job+of+the+21st+century">internet </a>says I have ”the sexiest job of the 21<sup>st</sup> century”, but I think my previous job was more enjoyable to brag about at birthday parties. I can do astro as a hobby, but that simply doesn’t give you enough time to do something substantial enough.</p>



<p><span>I don’t miss …</span> Indeed, the academic career also had its downsides. There is strong competition and people typically experience quite some pressure to achieve. The culture wasn’t always very healthy and diversity and equality are in bad shape in academia. Success criteria of your projects and of you as a person are typically better motivated in business. The obligatory nomadic lifestyle that you are bound to have as an early career scientist were a very enjoyable and educational experience, but it can easily become a burden on your personal life. The drawbacks and benefits of any career path will balance out differently for everybody. If you get to such a point, don’t take the decision lightly.</p>



<div><figure><img loading="lazy" src="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png" alt="" width="89" height="89" srcset="http://www.marcelhaas.com/wp-content/uploads/2020/12/decision.png 200w, http://www.marcelhaas.com/wp-content/uploads/2020/12/decision-150x150.png 150w" sizes="(max-width: 89px) 100vw, 89px"></figure></div>



<p>The people who questioned my decision to become an extronomer were right. I was wrong. It seems too late to get back in. I think I have gained skills and experience that can be very valuable to the astronomical community, but I know that that is simply not what candidates for academic positions are selected on. On top of that, being geographically bound doesn’t help. At least I will try to stay close to the field and who knows what might once cross my path.</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>http://www.marcelhaas.com/index.php/2020/12/16/i-regret-quitting-astrophysics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25444069</guid>
            <pubDate>Wed, 16 Dec 2020 15:56:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A year's worth of learnings from adopting Mob programming]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443874">thread link</a>) | @dinispeixoto
<br/>
December 16, 2020 | https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/ | <a href="https://web.archive.org/web/*/https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At FARFETCH, teams are encouraged to try new development methodologies so that they can deliver even better results while also improving productivity. As a fairly new team, we have continuously been looking for different methodologies that best fit our needs, such as avoiding knowledge silos or a slow-paced reviewing process. Although not every approach that we have tried has worked, the ones that did are now part of our daily development workflow and play a key role in the outcome of the tasks that we deliver.</p><p>A year ago, our team was first introduced to <a href="https://mobprogramming.org/" target="_blank">Mob Programming</a>, and we have been using it since then. The concept that was once hard to fathom is now the go-to approach when dealing with most of our sprint tasks. Although being able to use Mob Programming daily has come with many different types of challenges, the results have been surprisingly good.&nbsp;</p><p>When using Mob Programming, instead of having each team element working on its own task, the whole team gathers together to tackle the same task. It includes using a single workstation and only one person typing - <span>the Driver</span> - while the remaining people are describing the path that should be taken.</p><blockquote><p><span>Itâ€™s a software development approach where the whole team works on the same thing, at the same time, in the same space, and at the same computer. - Woody Zuill (2014)</span></p></blockquote><p>Mob Programming is somewhat similar to Pair Programming. While the latter consists of having two team members sharing the same workstation, Mob Programming goes a bit further and implies having the entire team focused on a single task. Even though Pair Programming is a great tool to share knowledge, improve communication and even bring better outcomes (as a consequence of having multiple people thinking about the same problem), it confines these advantages to only two elements on a team. On the other hand, Mob Programming can amplify these benefits to the whole team.</p><p>Yet, having an entire team working on the same problem brings its own challenges. It's imperative that the team establishes a set of well-defined procedures and rules. Furthermore, Mob Programming may not be suitable for all kinds of tasks or teams. Depending on the task the team is tackling, it should first be established whether Mob, Pair or Solo Programming is the appropriate methodology. None of the three is suitable for all situations. It's up to the teams to give them a try and figure out when to use them.</p><p>A typical Mob Programming setup consists of moving the team to an isolated space (e.g. a meeting room) and bringing one computer that should be connected to either a large monitor or a projector. Having a whiteboard to write down possible solutions and describe the next steps is great to empower collaborative brainstorming. Seats and tables for everyone is a must, as everyone should be comfortable during the session, this is particularly relevant as these sessions tend to be time-consuming. Since the beginning of the Covid-19 pandemic, we have adapted our ways of working to facilitate Remote Mob Programming sessions - but more to come on that later.&nbsp;</p><p><img src="https://www.farfetchtechblog.com/fotos/editor2/Dinis_Peixoto/Image_01.png" alt=""></p><p>Two key roles must be considered when using Mob Programming: the Driver and the Navigator. The Driver is the person at the keyboard, responsible for moving the codebase forward. The Navigator understands what the group has decided to aim for and provides instructions to the Driver. The Navigator shouldn't dictate the actual code that the Driver has to write down, only the expected solution. Sometimes, the Navigator role may not be needed. It is up to the Driver to opt-in or out. Nonetheless, when there's no Navigator, the Driver may get lost by having multiple people explaining what to do. These roles should rotate between all team members at regular intervals (usually monitored by a timer).</p><p>The session should be held continuously until the task is done. Quick breaks, like coffee or bathroom, are allowed and shouldn't require the session to stop. Some longer breaks like lunch must be agreed between the team so that everyone does it at the same time to prevent distractions and absences.</p><div><p>The first thing that may come to one's mind is that Mob Programming jeopardizes the team's overall productivity. After all, having an entire team working on the same task certainly means that both the team's velocity and throughput will be compromised, right?</p></div><div><p>More often than not, people tend to forget that delivering a task includes a lot more than just writing code. It's common that most of the time spent on a particular task is on coming up with the right solution or waiting for the team to review what was done. In our case, each task requires approval from 3 different people, which implies that they stop what they are doing, get up to speed, and finally review the result.</p></div><div><p>When using a development workflow like Solo Programming, once a developer puts the task up for review, the team has to understand all the requirements and review what was done, while also trying to identify what was the problem-solving process that the author took. The fact that the team has to go through someone elseâ€™s work without being completely aware of the decisions behind the proposed solution might take longer and prevent some mistakes from being identified.</p></div><p>Whereas when using Mob Programming, taking advantage of insights and knowledge from the whole team may lead to the task being delivered quicker while also with a better solution. When it comes to the review process, it will also be straightforward as everyone owns the decisions that were made and the solution path that was taken.&nbsp;</p><p>We have been using Mob Programming for over a year. Over this period, we have been trying to refine our methodology so that we can make the most out of our sessions. Some of the phases that have improved our workflow are described below.</p><ol><li><span>Task scouting:</span> each team member should, individually, check the task details prior to the session. Investing time on exploring the task beforehand will considerably shorten the time required on the next phase.</li><li><span>Purpose clarification: </span>at the beginning of the session, someone should present the problem at hand and make sure that everyone has a clear grasp of what the team is trying to achieve. Any questions about the purpose of the task should be raised at this time.</li><li><span>Work breakdown:</span> with the purpose of clarified, it's now time to identify the work blocks that have to be monitored during the session. The different tasks that result from this analysis should be prioritized and can be split into even smaller tasks if needed.</li><li><span>Execution:</span> based on the tasks identified previously, the team must try to work on each task by following the agreed order. The team should expect new tasks to surface throughout the session. If it happens, the order of the tasks can be adjusted.</li><li><span>Debriefing:</span> at the end of the session, the team will need to look at the initially defined tasks and check if everything was tackled. The solution should be carefully reviewed together before submitting it for team review. It's highly recommended to provide some time for an individual review to address groupthink problems.</li></ol><p>Equally important are the rules that our team has defined so far. Periodically, we revisit them and discuss whether or not some updates are required. Trying to make this an iterative process is extremely important to enhance the overall experience of our Mob Programming sessions over time.</p><ol><li><span>Driving/navigation time:</span> each team member will be in the Driver/Navigator role for 15 minutes. If a discussion comes up, the timer should stop so that both the Driver and Navigator can participate.</li><li><span>Complete focus on the session:</span> everyone in the room has to be focused on the session. If someone needs to work on something else, they must leave the room to avoid distracting the team.</li><li><span>Mandatory and optional breaks:</span> there are three mandatory breaks where the session must be stopped: morning coffee, lunch and afternoon coffee. Additional breaks are allowed but should be minimized to reduce the impact on focus. These sessions are very demanding on every team member so, if one cannot focus on the current tasks, taking a break is completely acceptable.</li><li><span>Research time:</span> whenever research is required, it should be done primarily by the Driver with the help of the team. Parallel research streams are allowed, as long as the team is aware of them.</li><li><span>Identify Mob Programming tasks ahead of time:</span> we always try to decide upon whether a specific task is going to be tackled through Mob Programming or not. It facilitates any coordination required during our sprint.</li></ol><p>Due to the COVID-19 global pandemic, we had a new challenge ahead of us: <a href="https://www.remotemobprogramming.org/" target="_blank">Remote Mob Programming</a>. As a consequence, we had to go through the rules above and update them as a means to adapt to the reality of having the whole team working remotely.</p><ol><li><span>Driving/navigation time:</span> this should be increased, in our case, we adjusted it to 45 minutes, due to the extra work required when changing the Driver (e.g. setting up the environment, sync with git's remote repository). It might take up to 5 minutes and wouldn't be worth it to do it every 15 minutes.</li><li><span>Video sharing:</span> everyone should keep the camera on during the session and, when possible, look directly at it. Itâ€™s as close as we can get to face-to-face interaction.</li><li><span>Driver handover:</span> every time a Driver handover is required, the current Driver has to ensure that changes made during their turn are properly committed and pushed to the remote repository. To have a better sense of the changes and their history, usually, the Driver's name is kept on the commit description.</li></ol><p>When it comes to the tools that we use during our mob sessions, it depends on if we are doing it in-person or remotely. When having in-person sessions, the only tool that we make use of is <a href="https://github.com/dillonkearns/mobster" target="_blank">Mobster</a>, which allows us to keep track of the Driver timer, the active and next up Drivers. Whereas when having remote sessions, on top of Mobster we also benefit from <a href="https://slack.com/" target="_blank">Slack</a> for video/screen sharing and live annotations (i.e. being able to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/">https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/</a></em></p>]]>
            </description>
            <link>https://www.farfetchtechblog.com/en/blog/post/a-year-s-worth-of-learnings-from-adopting-mob-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443874</guid>
            <pubDate>Wed, 16 Dec 2020 15:42:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New GitLab Virtual Appliance for KVM now available from OpenNebula Marketplace]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443719">thread link</a>) | @amarti
<br/>
December 16, 2020 | https://marketplace.opennebula.io/appliance/6b54a412-03a5-11e9-8652-f0def1753696 | <a href="https://web.archive.org/web/*/https://marketplace.opennebula.io/appliance/6b54a412-03a5-11e9-8652-f0def1753696">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marketplace.opennebula.io/appliance/6b54a412-03a5-11e9-8652-f0def1753696</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443719</guid>
            <pubDate>Wed, 16 Dec 2020 15:29:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to grow and level up as a software engineer]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443599">thread link</a>) | @hoanhan101
<br/>
December 16, 2020 | https://hoanhan.co/circleci-engineering-competency-matrix | <a href="https://web.archive.org/web/*/https://hoanhan.co/circleci-engineering-competency-matrix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Based on CircleCI Engineering Competency Matrix, let's learn more about different growth opportunities as well as how we can level up our career.</p><time datetime="2020-12-15T00:00:00-05:00"> December 15, 2020 · 7 mins read · <a href="https://hoanhan.co/category/Key-takeaways-from-important-reading">Key takeaways from important reading</a><hr> </time><h2> Table of Contents</h2><ul id="markdown-toc"><li><a href="#guidelines" id="markdown-toc-guidelines">Guidelines</a></li><li><a href="#technical-skills" id="markdown-toc-technical-skills">Technical skills</a><ul><li><a href="#writing-code" id="markdown-toc-writing-code">Writing code</a></li><li><a href="#testing" id="markdown-toc-testing">Testing</a></li><li><a href="#debugging" id="markdown-toc-debugging">Debugging</a></li><li><a href="#observability" id="markdown-toc-observability">Observability</a></li><li><a href="#understanding-code" id="markdown-toc-understanding-code">Understanding code</a></li><li><a href="#software-architecture" id="markdown-toc-software-architecture">Software architecture</a></li><li><a href="#security" id="markdown-toc-security">Security</a></li></ul></li><li><a href="#delivery" id="markdown-toc-delivery">Delivery</a><ul><li><a href="#work-breakdown" id="markdown-toc-work-breakdown">Work breakdown</a></li><li><a href="#prioritisation" id="markdown-toc-prioritisation">Prioritisation</a></li><li><a href="#dealing-with-ambiguity" id="markdown-toc-dealing-with-ambiguity">Dealing with ambiguity</a></li><li><a href="#reliability" id="markdown-toc-reliability">Reliability</a></li><li><a href="#economic-thinking" id="markdown-toc-economic-thinking">Economic thinking</a></li></ul></li><li><a href="#feedback-communication-collaboration" id="markdown-toc-feedback-communication-collaboration">Feedback, communication, collaboration</a><ul><li><a href="#deliveringseeking-feedback" id="markdown-toc-deliveringseeking-feedback">Delivering/seeking feedback</a></li><li><a href="#effective-communication" id="markdown-toc-effective-communication">Effective communication</a></li><li><a href="#knowledge-sharing" id="markdown-toc-knowledge-sharing">Knowledge sharing</a></li><li><a href="#team-work" id="markdown-toc-team-work">Team work</a></li><li><a href="#relationship-building" id="markdown-toc-relationship-building">Relationship building</a></li><li><a href="#handling-disagreement" id="markdown-toc-handling-disagreement">Handling disagreement</a></li></ul></li><li><a href="#leadership" id="markdown-toc-leadership">Leadership</a><ul><li><a href="#decision-making" id="markdown-toc-decision-making">Decision making</a></li><li><a href="#driving-alignment" id="markdown-toc-driving-alignment">Driving alignment</a></li><li><a href="#process-thinking" id="markdown-toc-process-thinking">Process thinking</a></li><li><a href="#facilitation" id="markdown-toc-facilitation">Facilitation</a></li><li><a href="#mentoring" id="markdown-toc-mentoring">Mentoring</a></li></ul></li><li><a href="#strategic-impact" id="markdown-toc-strategic-impact">Strategic impact</a><ul><li><a href="#business-acumen" id="markdown-toc-business-acumen">Business acumen</a></li><li><a href="#strategic-work" id="markdown-toc-strategic-work">Strategic work</a></li><li><a href="#product-thinking" id="markdown-toc-product-thinking">Product thinking</a></li></ul></li></ul><hr><h2 id="guidelines">Guidelines</h2><ul><li>A numbered list is used for each theme, where the higher the number is, the higher seniority level one has. Usually, each is built on top of the previous one.</li><li>Junior-Senior levels generally focus on engineers executing works (number 1 and 2) while Staff-Principal levels focus on mentoring and guiding others in their work (number 3 and above).</li><li>Competencies scale through impact: task → project → milestone → team → across teams → organization.</li><li>Competencies also scale through increased frequency: sometimes → usually → always.</li></ul><h2 id="technical-skills">Technical skills</h2><h3 id="writing-code">Writing code</h3><ol><li>Consistently writes code that are testable, easily understood by other developers.</li><li>Document effectively.</li></ol><h3 id="testing">Testing</h3><ol><li>Understands the testing pyramid (unit test, integration test, end-to-end test) and ensures that they are in good places.</li><li>Understands the team testing approach, works to recommend solutions accordingly.</li><li>Works with other teams to recommend solutions</li><li>Drives the company wide testing strategy.</li></ol><h3 id="debugging">Debugging</h3><ol><li>Uses a systematic approach to debug issues located within a single device.</li><li>Proficient at using systematic debugging to diagnose cross services issues.</li><li>Leads incident response across the organization.</li></ol><h3 id="observability">Observability</h3><ol><li>Is aware of the team monitoring philosophy.</li><li>Uses it as a basis for suggesting stability and performance improvements.</li><li>Drives monitoring works</li><li>Fosters a culture of observability across several teams and organization.</li></ol><h3 id="understanding-code">Understanding code</h3><ol><li>Understands a portion of the team domain, knows how to work productively within it.</li><li>Understands the team’s domain at a high level, has expertise in a portion.</li><li>Has expertise in the team’s domain, including the breadth of services, how they interact, and data flows between systems.</li><li>Has expertise in a set of related teams’ domains and organization’s architecture.</li></ol><h3 id="software-architecture">Software architecture</h3><ol><li>Designs functions what are aligned with the overall architecture.</li><li>Utilizes abstractions and code isolation effectively.</li><li>Architects scalable services and systems, makes design decisions, weights trade-offs.</li><li>Guides several teams to foster a culture of scalable architecture.</li></ol><h3 id="security">Security</h3><ol><li>Approaches all engineering work with a security lens, actively looks for vulnerabilities both in code and peer reviews.</li><li>Fosters a security first mindset across the teams/organization.</li></ol><h2 id="delivery">Delivery</h2><h3 id="work-breakdown">Work breakdown</h3><ol><li>Review tasks critically and ensures that they’re appropriately scoped for continuous integration and incremental delivery.</li><li>Reviews epics and projects and ensures that they’re broken down, prioritized properly and well understood by the team.</li><li>Reviews cross-team works and ensures that they’re well understood by all teams.</li></ol><h3 id="prioritisation">Prioritisation</h3><ol><li>Ensures that tasks are prioritised and dependencies are noted correctly.</li><li>Works within team to foster a culture of priority setting and urgency in alignment with organizational strategy.</li><li>Identifies dependencies across organization and work with individual team to resolve them before they become an issue.</li></ol><h3 id="dealing-with-ambiguity">Dealing with ambiguity</h3><ol><li>Handles risk and uncertainty within your personal scope responsibly and effectively.</li><li>Effectively handles risk within the team.</li><li>Effectively handles risk within the across several teams and organization.</li></ol><h3 id="reliability">Reliability</h3><ol><li>Understands the priorities and deliver upon them accordingly.</li><li>Anticipates and communicates blockers, delays before they require escalation.</li><li>Ensures expectations with the team and external stakeholders are clarified.</li><li>Successfully manages cross-team commitments, progress, and roadmap to delivery.</li></ol><h3 id="economic-thinking">Economic thinking</h3><ol><li>When taking action, weighs cost and value in order to make the most economic action.</li><li>Uses this well and make suggestion to teammates.</li><li>Fosters a culture within their team where people apply economic thinking to make timely decisions.</li><li>Fosters a culture across several teams and within the organization.</li></ol><h2 id="feedback-communication-collaboration">Feedback, communication, collaboration</h2><h3 id="deliveringseeking-feedback">Delivering/seeking feedback</h3><ol><li>Delivers praise and constructive feedback to their team, teammates, and manager in a useful manner.</li><li>Delivers feedback to their team’s business stakeholders when opportunities arise.</li><li>Fosters a culture of delivering praise and constructive feedback within the team, across several teams and organization.</li></ol><h3 id="effective-communication">Effective communication</h3><ol><li>Communicates effectively, clearly, concisely in written and verbal form both technical and non technical subjects.</li><li>Is able to communicate effectively with a diverse team, set of team, across the organization.</li></ol><h3 id="knowledge-sharing">Knowledge sharing</h3><ol><li>Understand your domain, share your knowledge and contribute to the team’s documentation frequently.</li><li>Fosters a culture of documentation and knowledge sharing within the team, across team and organization.</li></ol><h3 id="team-work">Team work</h3><ol><li>Consistently helps their teammates overcome obstacles, resolve blockers, and complete work tasks.</li><li>Consistently works across the organization to enable teams to support each other.</li></ol><h3 id="relationship-building">Relationship building</h3><ol><li>Works to build strong relationships with teammates, manager, and senior engineers across the organization.</li><li>Works to build strong relationships across the organization and leverage those to better plan for the engineering organization.</li></ol><h3 id="handling-disagreement">Handling disagreement</h3><ol><li>Approaches disagreement with teammates non-defensively and uses contradictory opinions as a basis for constructive, productive conversations.</li><li>Encourages teammates to do the same.</li><li>Foster a culture where people are encouraged to share opinions and contribute to discussions in a respectful manner.</li></ol><h2 id="leadership">Leadership</h2><h3 id="decision-making">Decision making</h3><ol><li>Strives to be objective, reflects on your own biases, and holds yourself accountable for decision and outcomes.</li><li>Takes ownership of decisions made in their team by helping teammates make clear decisions in alignment with organizational goals, backing decisions made, and taking responsibility for their success.</li><li>Takes ownership of decisions made across teams and organization.</li></ol><h3 id="driving-alignment">Driving alignment</h3><ol><li>Strongly oriented towards goals and ensures the team is continuously working towards shared goals.</li><li>Fosters a culture within the team of having conversations based on organizational strategy and principles to create alignment.</li><li>Fosters a culture across several teams and organization.</li></ol><h3 id="process-thinking">Process thinking</h3><ol><li>Regularly thinks about team practices and processes and discusses improvements with team.</li><li>Thinks about practices and processes that affect several teams, discusses improvements with appropriate parties, and drives implementation.</li><li>Takes ownership and responsibility for organizational practices and processes and their continuous improvement.</li></ol><h3 id="facilitation">Facilitation</h3><ol><li>Facilitates discussions within the team, ensuring that everyone has an opportunity to share their opinion and be heard, and no one person dominates the conversation.</li><li>Facilitates discussions across teams, guides discussions toward decisions, clarifies and gets buy-in.</li><li>Facilitates organization-wide discussions.</li></ol><h3 id="mentoring">Mentoring</h3><ol><li>Seeks out mentorship to grow their own experience.</li><li>Seeks out mentoring opportunities specifically to create team redundancy and backfill ability.</li><li>Mentors across teams and organization in an open, respectful, flexible, empathetic manner.</li></ol><h2 id="strategic-impact">Strategic impact</h2><h3 id="business-acumen">Business acumen</h3><ol><li>Has a thorough understanding of their team’s domain, and how it contributes to overall business strategy.</li><li>Has a thorough understanding of adjacent teams’ strategies and how they map to their team and interaction points.</li><li>Has a thorough understanding of the entire business, including individual domains, and how they contribute to overall business strategy.</li></ol><h3 id="strategic-work">Strategic work</h3><ol><li>Understands the organization’s engineering strategy.</li><li>Collaborates and decides on their team’s engineering work based on organization’s engineering strategy.</li><li>Leads cross-team and organization strategic efforts, influencing decisions to achieve cross-team alignment on major goals.</li></ol><h3 id="product-thinking">Product thinking</h3><ol><li>Understands product area of focus, how it fits into the overall business.</li><li>Looks for opportunities to simplify product &amp; technical design.</li><li>Evaluates and creates new product features in collaboration with the product team.</li><li>Recognizes product opportunities and differentiators in relation to the competition.</li><li>Actively seeks to create or redefine roadmaps across the organization with product &amp; business counterparts.</li></ol><hr><p><strong>References:</strong></p><ul><li><a href="https://docs.google.com/spreadsheets/d/1mtn4QTvqCiS_sf6uxtCiexTo03FVjSbnwbZXE46NdQE/edit?usp=sharing">https://docs.google.com/spreadsheets/d/1mtn4QTvqCiS_sf6uxtCiexTo03FVjSbnwbZXE46NdQE/edit?usp=sharing</a></li></ul><hr><hr><p> Tagged: <a href="https://hoanhan.co/tag/blog">#blog</a>, <a href="https://hoanhan.co/tag/outlier">#outlier</a>, <a href="https://hoanhan.co/tag/success">#success</a></p><br> </article></div></div>]]>
            </description>
            <link>https://hoanhan.co/circleci-engineering-competency-matrix</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443599</guid>
            <pubDate>Wed, 16 Dec 2020 15:22:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Linux and Bash for Data Scientists]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25443415">thread link</a>) | @tolstoyevsky
<br/>
December 16, 2020 | http://dagshub.com/blog/effective-linux-bash-data-scientists/ | <a href="https://web.archive.org/web/*/http://dagshub.com/blog/effective-linux-bash-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>In November 2020, DAGsHub gave a series of guest lectures to the excellent <a href="https://yandexdataschool.com/israel/">Y-DATA</a> course for aspiring data scientists, which we would now like to share with whoever finds it useful, in blog form!</p><h2 id="cut-to-the-chase-">Cut to the chase!</h2><ul><li><a href="#basics">Shell basics</a></li><li><a href="#the-shell">Background on shells</a></li><li><a href="#shell-variables">Shell variables</a></li><li><a href="#pipes">Pipes</a></li><li><a href="#redirects">Redirects</a></li><li><a href="#filesystem">Filesystem</a></li><li><a href="#runnable-files">Runnable files</a></li><li><a href="#package-managers">Package managers</a> (e.g. brew and apt)</li><li><a href="#shell-commands-inside-jupyter-notebooks">Shell commands inside Jupyter notebooks</a></li><li><a href="#text-editors-in-the-terminal">Text editors in the terminal</a></li><li><a href="#other-useful-commands">Other useful commands</a></li><li><a href="#ssh">SSH</a></li><li><a href="#tmux">tmux</a></li><li><a href="#running-commands-in-the-background">Running commands in the background</a></li><li><a href="#symbolic-links">Symbolic links</a></li><li><a href="#zsh-oh-my-zsh-powerlevel10k">Oh-my-zsh</a></li></ul><h2 id="intro">Intro</h2><p>The topic - system, IT, DevOps, MLOps, whatever other name you want to call it - how do you make the computer do what you want, outside the context of Python (or R or Matlab etc., we don't discriminate)? How do you get that beautiful neural network of yours to run on an actual server in the cloud, so that it can serve actual users?</p><blockquote>What to do when the bubble bursts, and you have to step outside the Jupyter notebook to fix things?</blockquote><p>Of course, this is a wide open question which requires a lot of previous knowledge to answer. In our lectures, we wanted to start by building a solid foundation for the students to stand on. So, we went to the classics - what is Linux? Why do people use it? What is Bash? How to use the terminal? How to exit vim?!</p><figure><img src="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="It's all about that base, no trouble!" srcset="https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1507245921392-e902673ca772?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDZ8fHxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>It's all about that base, no trouble! Photo by <a href="https://unsplash.com/@arstyy?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Austin Neill</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Instead of creating yet-another-tutorial on how to move and copy files in terminals, we wanted to bring perspective: </p><ul><li>Why would you use Linux, Bash, and other system tools?</li><li>What's the smart way to do it, based on our subjective experience? </li><li>What common problems will you come across, and how to solve them?</li><li>What's the mental framework for working with these tools, to gain understanding and learn more by playing?</li></ul><p>So, this guide/cheatsheet is more about our tips and tricks, and is definitely not exhaustive. On the contrary - we wanted to make the most of students' time, and only talk about what's interesting. Other things can be learned on an as-needed basis.</p><h3 id="who-is-this-for">Who is this for?</h3><p>The curriculum and some of the tips are aimed at data scientists who want an introduction to the topics of Linux &amp; Bash. However, the data science orientation mainly comes into play in a few domain specific tips, and in the stated motivations to learn these things - if you're an aspiring web developer, there's no reason not to benefit from this guide as well!</p><h2 id="linux">Linux</h2><h3 id="what-is-linux">What is linux?</h3><ul><li>A family of open source operating systems.</li><li>Developed by Linus Torvalds, who also invented Git to manage the source code for Linux.</li><li>An operating system is a program that takes over a bit after your computer turns on.</li><li>For the first few seconds after your computer switches on, the motherboard runs a small hard-coded operating system called the BIOS, but it quickly hands control over to some operating system<em> kernel</em>, which is installed on one of the hard drives, a USB stick or CD.</li><li>From that point on, the kernel decides which programs to run when, and how to control physical devices (via drivers).</li><li>An <em>operating system</em> is a bundle of programs that come packaged together. The kernel is the most important part, but it comes with more programs which help the users communicate with the kernel.</li><li>e.g. File explorers are part of the OS, but not the kernel - they're just graphical interfaces which sit between the user and the kernel.</li><li>Operating systems normally also handle file systems, user permissions, memory management, and many other things.</li><li>The thing that unites all the different operating systems in the Linux family is they all use the same Linux kernel - other parts differ. More on that later in the section about distributions.</li></ul><figure><img src="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Penguins" srcset="https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1573480813647-552e9b7b5394?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDM3fHx8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@topcools?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">topcools tee</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><h3 id="what-is-linux-good-for">What is Linux good for?</h3><p>An operating system is, surprisingly, just a type of system. Systems are designed by humans, and better designs lead to better performance, stability, and flexibility. <strong>Linux is simply a better designed operating system</strong>. It's super flexible and stable - "blue screens of death" are exceedingly rare in production Linux servers, and their performance is very reliable. <strong>Which is why a vast majority of production systems run on Linux</strong>, and that's also why it's good for anyone working in tech to be Linux literate. That includes you, dear reader.</p><p>Being open source leads to high quality, as bugs have fewer dark places to hide in. Developers can peer under the covers to make sure their Linux applications will work well, rather than guessing and relying on questionable documentation from closed source operating system developers.</p><p>But with great power and flexibility comes a great ability to shoot yourself in the foot. Linux makes that easy as well.</p><h3 id="what-do-the-different-types-of-linux-mean">What do the different types of Linux mean?</h3><p>One of the confusing things when entering the Linux world is the giant jargon which is thrown in your face. It feels like the explanations expect you to already know and understand a bunch of other terms, without building understanding step by step. So, I'd like to give you a very brief summary of terms you might come across and what they mean.</p><h3 id="linux-like-systems">Linux-like systems</h3><p>Mac and Unix are very similar to, but are not Linux technically. You will have a hard time telling the difference, unless you dive deep.</p><p>Unix is older than Linux and extremely similar - In fact, Linux is an open source re-implementation of Unix (which was closed source, but very good). This is pretty much historic trivia, as Unix is rarely seen nowadays, but know that some people use the words Unix and Linux interchangeably.</p><p>In general, there’s a name for operating systems that look and feel like Unix – POSIX compliant, or *nix. When you see these words, translate them as “follows the conventions of Linux, such as basic commands for file manipulation (ls, cd, mkdir) and "/" as the root of the file system etc.”</p><p>GNU is a large set of free software which is the foundation for much of Linux – compilers, C libraries, programs to zip files, and many others. It's also the name of an independent POSIX operating system, with more hardcore ideology around free software than Linux.</p><p>All of the above systems, as well as Linux itself, are examples of POSIX compliant or *nix systems.</p><h3 id="linux-distributions-distros">Linux Distributions / Distros</h3><p>There are (too?) many flavours of “real Linux”, called distros or distributions. It can be a headache to differentiate them.</p><p>A distribution is like a "company", which invents a new operating system. They wrap the Linux Kernel with a new bundle of peripheral programs - i.e. they may use a different mix of GUI programs, support different hardware by default, etc. They release new versions occasionally.</p><p><strong>The bottom line – unless you know what you’re doing, <a href="https://ubuntu.com/download/desktop">just use Ubuntu</a></strong>. It’s the most user friendly, widely supported, and easy to install.</p><p><a href="https://www.redhat.com/en/technologies/linux-platforms/enterprise-linux">Red Hat Enterprise Linux</a>, or RHEL, is a different distro which is used sometimes in heavy duty production servers. <a href="https://getfedora.org/">Fedora</a> is the desktop equivalent of RHEL - usually, developers aiming to run their applications on RHEL servers will use Fedora for their development computers, to avoid compatibility issues.</p><p><a href="https://alpinelinux.org/">Alpine</a> is a super minimal distro which is used for many Docker images. <a href="https://dagshub.com/blog/setting-up-data-science-workspace-with-docker/">Read our blog post about Docker for more information</a>.</p><h2 id="interfaces">Interfaces</h2><p>When people think of Linux, they usually associate it with a scary terminal (plus attached Anonymous hacker with a hoodie 👩‍💻).</p><p>Don't Panic – it’s not so scary! Today, it’s really easy to install Linux on a computer, with a regular GUI wizard, if you pick a distro that cares about that sort of thing (for example, Ubuntu).</p><p>We'll focus on terminals / shells in this lecture, since that is always available, and generally where "real work" is done. Production servers will rarely have GUIs. Don't let that discourage you - after you get used to it, using the shell can become much more convenient than GUIs!</p><figure><img src="https://dagshub.com/blog/content/images/2020/12/image.png" alt="The Wizard will now install your software."><figcaption>The Wizard will now install your software.</figcaption></figure><h2 id="basics">Basics</h2><p>The following actions are very basic file manipulation commands - moving, copying, deleting, viewing, etc.<br>I think there are enough sources online to learn these basic commands, and so I won't be re-explaining them here. Below the list, I provide my recommended way to learn about them, so don't worry!</p><ul><li>ls</li><li>mv</li><li>cp</li><li>rm</li><li>pwd</li><li>cd</li><li>mkdir</li><li>echo</li><li>cat</li></ul><p><strong>The most convenient way I found to learn about these commands, even if you don't have a Linux terminal available, is to follow these tutorials:</strong></p><ol><li><a href="https://www.webminal.org/terminal/">https://www.webminal.org/terminal/</a><br><strong>Do up to and including lesson 3.</strong><br>Webminal includes an interactive terminal in the browser, which you can play with and use for the next tutorial (which doesn't have an interactive shell, only text and quizzes).</li><li><a href="https://linuxjourney.com/lesson/the-shell">https://linuxjourney.com/lesson/the-shell</a></li></ol><h2 id="the-shell">The Shell</h2><p>The shell (AKA terminal) is itself a program! It's in charge of things like: </p><ul><li>Taking keystrokes from the user</li><li>Displaying text output to the user.</li><li>Remembering what directory you're in currently (changed using <code>cd</code>, shown using <code>pwd</code>)</li><li>Turning your commands into <strong>new</strong> <strong>running programs &nbsp;- processes,</strong> by sending appropriate messages to the kernel</li></ul><p>For example, what does the shell do when I type <code>python hello_world.py</code> and press enter?</p><ul><li>It's in charge of knowing where the actual program called "python" is located in the file system - probably something like <code>/usr/bin/python</code>. In the end, the kernel is the only thing that can run new programs, and it expects absolute paths to files.</li><li>I can check where the shell is actually finding "python" by running <code>which python</code>. &nbsp;The <code>which</code> command outputs the full path found by the shell. How does it know? More on that later, in the section on runnable scripts.</li><li><code>which</code> is a useful command! Maybe you have several conflicting versions of python installed, and you're not sure which one is actually running and giving you problems. <code>which python</code> to the rescue!</li><li>Or maybe I have some runnable script, and I want to edit, delete or rename it, but I forgot where it's located. <code>which</code> to the rescue!</li><li>So, what actually happens is that the shell tells the kernel program: "Please take the program file located at <code>/usr/bin/python</code>, and turn that into a new running process with a single argument <code>/absolute/path/to/hello_world.py</code> , running inside the current …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://dagshub.com/blog/effective-linux-bash-data-scientists/">http://dagshub.com/blog/effective-linux-bash-data-scientists/</a></em></p>]]>
            </description>
            <link>http://dagshub.com/blog/effective-linux-bash-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443415</guid>
            <pubDate>Wed, 16 Dec 2020 15:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matrix: One Chat Protocol to Rule Them All]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25443050">thread link</a>) | @djsumdog
<br/>
December 16, 2020 | https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/ | <a href="https://web.archive.org/web/*/https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

  

  <article>
    

    <figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/matrix.png" alt="Matrix Logo Surrounded by Logos for Hangouts, Telegram, Messenger and Signal pointing to it">
  
  
</figure>

<p>Once upon a time, there were many chat services. AOL Instant Messenger, Yahoo Messenger, ICQ and others. These messengers had their own desktop clients, and developers reverse engineered their protocol to build custom applications, both open and closed source. Trillian, Audium and Pidgin were applications that let people communicate across all these messengers with one program. Over time the old protocols died, and newer chat services like Facebook Messenger and Google Hangouts started storing your entire history on their servers. People started using the web interfaces and mobile apps, no longer caring about desktop programs.</p>

<p>Matrix is an open source communication protocol. It’s similar to XMPP (formerly Jabber) in the sense that anyone can set up a Matrix server and communicate to people on other Matrix servers. It’s a federated protocol, just like e-mail. Google Hangouts used to support XMPP federation, but silently removed support in 2014. Matrix supports bridging other chat services, so they can appear in a unified view. With my current setup of Matrix and appropriate bridges, I’ve combined my view of Facebook Messenger, Google Hangouts, Telegram and native Matrix chats into one convenient user interface. The path to get to that integration was not as simple.</p>

<!--more-->

<p>The dedicated server I use for <a href="https://battlepenguin.com/tech/a-history-of-personal-and-professional-websites/">this website</a> and other self-hosted web applications, is located in Germany. Logging in to Facebook or Google’s chat system from a country I’m not currently in, can raise all sorts of security flags and lock me out of my account. For those bridges, I purchased a small virtual machine in a Chicago data center. I installed a proxy on that server, accessible only via VPN, to view both Google and Facebook, so they record the IP address I’m connecting from with my web browser. This helps minimize security lockouts. Telegram isn’t hostile to third party developers, and has an official API. It doesn’t care my bridge is connecting to it from Germany, so I host it on the dedicated server.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/server-diagram.png" alt="Server Diagram of Matrix Homeserver and Bridges">
  
  
  <figcaption>
      

      Server Diagram of Matrix Homeserver and Bridges

      
  </figcaption>
  
</figure>

<p>The reference Matrix server is called Synapse. It, as well as the <a href="https://github.com/tulir/mautrix-telegram">mautrix-telegram</a>, <a href="https://github.com/tulir/mautrix-hangouts">mautrix-hangouts</a> and <a href="https://github.com/tulir/mautrix-facebook">mautrix-facebook</a> bridges all have official Docker containers built by their developers. Each bridge must be able to communicate with the Synapse homeserver. Their instructions go through generating configuration and key pairs that are copied over to Synapse in order to form their authentication bridge. The bridges provide chat robots that guide you through getting OAuth tokens or cookies for those respective services.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/element-screenshot.png" alt="Facebook and Hangouts Chats in Element">
  
  
  <figcaption>
      

      Facebook and Hangouts Chats in Element

      
  </figcaption>
  
</figure>

<p>The wiki for each bridge also has instructions for enabling double-puppeting, making each chat look seamless between myself and the accounts on the other side of each respective bridge. Without double-puppeting, each conversation will be in a three person group with the Matrix user, the bridge user (e.g my Google Hangouts user) and the person I’m talking to.</p>

<figure>
  
  <img src="https://battlepenguin.com/images/tech/matrix/no-double-puppet.png" alt="Chat Without Double-Puppeting Enabled">
  
  
  <figcaption>
      

      Chat Without Double-Puppeting Enabled

      
  </figcaption>
  
</figure>

<p>Enabling double-puppeting via the <code>curl</code> command in the bridge documentation and calling <code>login-matrix</code> on the bot, removes the creation of three person rooms. The bridged accounts will now show up as regular, two-person conversations.</p>

<p>I use the Element desktop app to connect to my matrix server, but I also have a web version of Element running from its own official Docker container in case I need to access chat from another computer. There are other clients, such as <a href="https://github.com/mirukana/mirage">Mirage</a> which is built using Qt and <a href="https://fluffychat.im/">Fluffychat</a> for mobile. Although I use Synapse for my homeserver, there are other servers that support the Matrix protocol that are in use and under active development.</p>

<p>Setting up all the Matrix components wasn’t too difficult, but it does require knowledge or experience with running services. It took a considerable amount of work and debugging to get each bridge operational, compounded slightly by my complex networking setup. Most people would probably just run all of this on a Raspberry Pi at home. I feel that using Matrix with bridges is still somewhat inaccessible to people who aren’t interested in development or server administration. Still, the satisfaction of having unified chat, plus one more layer of abstraction between myself and Google or Facebook, feels like it was wroth the overall effort.</p>


    

  </article>

</section>



    </div></div>]]>
            </description>
            <link>https://battlepenguin.com/tech/matrix-one-chat-protocol-to-rule-them-all/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25443050</guid>
            <pubDate>Wed, 16 Dec 2020 14:44:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Static Calls in Linux 5.10]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442991">thread link</a>) | @woodruffw
<br/>
December 16, 2020 | https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10 | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Dec 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#c">c</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#curiosity">curiosity</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#security">security</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#x86">x86</a>
    
  
  </p>


<p>I was reading the
<a href="https://kernelnewbies.org/Linux_5.10">Linux 5.10 release summary on KernelNewbies</a>, and a
section stood out to me:</p>

<blockquote>
  <p>1.6. Static calls for improved post-Spectre performance</p>

  <p>Static calls are a replacement for global function pointers. They use code patching to allow
direct calls to be used instead of indirect calls. They give the flexibility of function pointers,
but with improved performance. This is especially important for cases where retpolines would
otherwise be used, as retpolines can significantly impact performance.</p>
</blockquote>

<p>I’ve spent a lot of time looking at the Linux kernel, but never directly at its indirect call
setup or post-<a href="https://spectreattack.com/">Spectre</a> mitigations. These changes sound very cool,
so I’m going to use this post to try and explain and understand them (both to myself and others).</p>

<p><strong>Update</strong>: One of the original authors of the patchset has emailed me with some corrections
and answers to the questions that I ask below. I’ve marked each with either “Correction” or
“Update.” Thanks, Peter!</p>

<h2 id="background-indirect-calls-spectre-and-retpolines">Background: indirect calls, Spectre, and retpolines</h2>

<h3 id="indirect-calls">Indirect calls</h3>

<p>Indirect calls are one of C’s most powerful language features, and are critical for writing
higher-order code without a supplementary object or function/method dispatch system.</p>

<p>Most C programmers are familiar with the basics of indirect calls, thanks to standard and POSIX
functions like <code>qsort</code> and <code>pthread_create</code>: each takes a <em>function pointer</em>, which it then
calls internally to complete the functionality of the surrounding call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;stdio.h&gt;
</span>
<span>/* qsort_strcmp is just the normal stdlib strcmp, with a bit of extra parameter
 * munging to match qsort's API.
 */</span>
<span>static</span> <span>int</span> <span>qsort_strcmp</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>a</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>b</span><span>)</span> <span>{</span>
    <span>return</span> <span>strcmp</span><span>(</span><span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>a</span><span>,</span> <span>*</span><span>(</span><span>const</span> <span>char</span> <span>**</span><span>)</span><span>b</span><span>);</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>strings</span><span>[]</span> <span>=</span> <span>{</span><span>"foo"</span><span>,</span> <span>"bar"</span><span>,</span> <span>"baz"</span><span>};</span>

    <span>/* qsort is a generic sorting function:
     * you give it the a pointer to the base address of things to sort,
     * their number and individual sizes, and a *function* that can compare
     * any two members and provide an ordering between them.
     *
     * in this case, we tell qsort to sort an array of strings, using
     * `qsort_strcmp` for the ordering.
     */</span>
    <span>qsort</span><span>(</span><span>&amp;</span><span>strings</span><span>,</span> <span>3</span><span>,</span> <span>sizeof</span><span>(</span><span>char</span> <span>*</span><span>),</span> <span>qsort_strcmp</span><span>);</span>

    <span>printf</span><span>(</span><span>"%s %s %s</span><span>\n</span><span>"</span><span>,</span> <span>strings</span><span>[</span><span>0</span><span>],</span> <span>strings</span><span>[</span><span>1</span><span>],</span> <span>strings</span><span>[</span><span>2</span><span>]);</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/vbn7zW">Godbolt</a>).</em></p>

<p>In this case, the indirect call occurs within <code>qsort</code>. But we can see it directly if
we implement our own function that does an indirect call:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>static</span> <span>uint32_t</span> <span>good_rand</span><span>()</span> <span>{</span>
    <span>uint32_t</span> <span>x</span><span>;</span>
    <span>getrandom</span><span>(</span><span>&amp;</span><span>x</span><span>,</span> <span>sizeof</span><span>(</span><span>x</span><span>),</span> <span>GRND_NONBLOCK</span><span>);</span>
    <span>return</span> <span>x</span><span>;</span>
<span>}</span>

<span>static</span> <span>uint32_t</span> <span>bad_rand</span><span>()</span> <span>{</span>
    <span>return</span> <span>rand</span><span>();</span>
<span>}</span>

<span>/* munge takes a function pointer, rand_func, which it calls
 * as part of its returned result.
 */</span>
<span>static</span> <span>uint32_t</span> <span>munge</span><span>(</span><span>uint32_t</span> <span>(</span><span>*</span><span>rand_func</span><span>)(</span><span>void</span><span>))</span> <span>{</span>
    <span>return</span> <span>rand_func</span><span>()</span> <span>&amp;</span> <span>0xFF</span><span>;</span>
<span>}</span>

<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
    <span>uint32_t</span> <span>x</span> <span>=</span> <span>munge</span><span>(</span><span>good_rand</span><span>);</span>
    <span>uint32_t</span> <span>y</span> <span>=</span> <span>munge</span><span>(</span><span>bad_rand</span><span>);</span>

    <span>printf</span><span>(</span><span>"%ul, %ul</span><span>\n</span><span>"</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>);</span>

    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>where <code>munge</code> boils down to:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
</pre></td><td><pre><span>munge:</span>
  <span>push</span>    <span>rbp</span>
  <span>mov</span>     <span>rbp</span><span>,</span> <span>rsp</span>
  <span>sub</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>mov</span>     <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>],</span> <span>rdi</span>  <span>; load rand_func</span>
  <span>call</span>    <span>qword</span> <span>ptr</span> <span>[</span><span>rbp</span> <span>-</span> <span>8</span><span>]</span>       <span>; call rand_func</span>
  <span>and</span>     <span>eax</span><span>,</span> <span>255</span>
  <span>add</span>     <span>rsp</span><span>,</span> <span>16</span>
  <span>pop</span>     <span>rbp</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/P44Ghq">Godbolt</a>).</em></p>

<p>Observe: our <code>call</code> goes through a memory or register operand (<code>[rbp - 8]</code>)<sup id="fnref:opt" role="doc-noteref"><a href="#fn:opt">1</a></sup> to get the target,
instead of a direct target specified by the operand value itself (like, say,
<code>call 0xacabacab ; @good_rand</code>). That’s what makes it indirect.</p>

<p>But we can go even further than this! Indeed, a common pattern in C is to declare
entire <em>structures</em> of operations, using each to parametrize a lower level set of behaviors
(for example, the core POSIX I/O APIs) over independent implementations.</p>

<p>This is exactly how <a href="https://github.com/libfuse/libfuse">FUSE</a> works: every FUSE client
creates its own <a href="https://github.com/libfuse/libfuse/blob/cd4aae2de6aacad31a15791bbb52adf173561a6d/include/fuse.h#L299-L790"><code>fuse_operations</code></a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td><td><pre><span>struct</span> <span>fuse_operations</span> <span>{</span>
  <span>int</span> <span>(</span><span>*</span><span>getattr</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>stat</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>fi</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>readlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mknod</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>,</span> <span>dev_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>mkdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>mode_t</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>unlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rmdir</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>symlink</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>rename</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>unsigned</span> <span>int</span> <span>flags</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>link</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
  <span>int</span> <span>(</span><span>*</span><span>open</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>read</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
         <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>write</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>,</span> <span>size_t</span><span>,</span> <span>off_t</span><span>,</span>
          <span>struct</span> <span>fuse_file_info</span> <span>*</span><span>);</span>
  <span>int</span> <span>(</span><span>*</span><span>statfs</span><span>)</span> <span>(</span><span>const</span> <span>char</span> <span>*</span><span>,</span> <span>struct</span> <span>statvfs</span> <span>*</span><span>);</span>
  <span>/* ... */</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Unsurprisingly, this technique isn’t limited to userspace: the Linux kernel itself makes
aggressive use of indirect calls, particularly in architecture-agnostic interfaces
(like the <a href="https://www.kernel.org/doc/html/latest/filesystems/vfs.html">VFS</a> and sub-specializations
like <code>procfs</code>) and the architecture-specific internals of subsystems like
<a href="https://perf.wiki.kernel.org/index.php/Main_Page"><code>perf_events</code></a>.</p>

<p>So that’s neat. It’s so neat that CPU engineers got all
<a href="https://en.wikipedia.org/wiki/Branch_predictor#Indirect_branch_predictor">hot in the pants</a> trying
to squeeze extra performance out of them<sup id="fnref:perf" role="doc-noteref"><a href="#fn:perf">2</a></sup>, and we ended up with
<a href="https://spectreattack.com/spectre.pdf">Spectre v2</a>.</p>

<h3 id="spectre-v2">Spectre (v2)</h3>

<p><img src="https://blog.yossarian.net/assets/spectre.png" alt="The Spectre logo"></p>

<p>The exact mechanism that Spectre v2 (also known as
<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-5715">CVE-2017-5715</a>) exploits is
<em>slightly</em> out of scope of this post, but at a high level:</p>

<ol>
  <li>
    <p>Modern (x86) CPUs contain an <em>indirect branch predictor</em>, which attempts to guess the target
of an indirect call or jump.</p>

    <p>To actually speed things up, the CPU <strong>speculatively executes</strong> the
 predicted branch:</p>

    <ul>
      <li>
        <p>A correct prediction means that the indirect call completes significantly faster
 (since it’s already executing or has finished executing speculatively);</p>
      </li>
      <li>
        <p>A misprediction <strong>should</strong> result in a slower (but still
 successful) indirect call with <strong>no side effects from the incorrect speculation.</strong></p>
      </li>
    </ul>

    <p>In other words: the CPU is responsible for <strong>rolling back</strong> any side effects associated
 with any misprediction and subsequent speculation. Mis-speculation is a <em>microarchitectural</em>
 detail that should not manifest in <em>architectural</em> changes, like modified registers.</p>
  </li>
  <li>
    <p><strong>Rolling back</strong> any mis-speculated state is a relatively expensive operation, with a lot of
microarchitectural implications: cache lines and other bits of state need to be fixed up so that
the <em>actual</em> program control flow isn’t tainted by failed speculations.</p>

    <p>In practice, rolling back the entire speculated state would undo most of the advantages
 of speculating in the first place. Instead of doing that, x86 and other ISAs will just mark
 (many) of the bits of speculated state (like cache lines) as stale.</p>
  </li>
  <li>
    <p>This fixup behavior (either reverting or marking speculated state) results in a
<a href="https://en.wikipedia.org/wiki/Side-channel_attack"><em>side-channel</em></a>: an attacker can
<em>train</em> the branch predictor to speculatively execute a bit of code
(not unlike a <a href="https://en.wikipedia.org/wiki/Return-oriented_programming">ROP gadget</a>) that modifies
a piece of microarchitectural state in a data-dependent manner, such as a cache entry
whose address is dependent on a secret value that was speculatively fetched.</p>

    <p>The attacker can then <em>probe</em> that microarchitectural state by <strong>timing</strong> access to it:
 fast accesses indicate a speculatively modified state, disclosing the secret.</p>
  </li>
</ol>

<p>The original Spectre v2 attack focused on cache lines since they’re relatively easy to time, even
from high level (and sandboxed!) languages that don’t have access to
<a href="https://c9x.me/x86/html/file_module_x86_id_30.html"><code>clflush</code></a> or other cache-line
primitives on x86. But the concept is a general one: it’s difficult to execute speculatively without
leaking <em>some</em> information, and subsequent vulnerabilities (like <a href="https://mdsattacks.com/">MDS</a> and
<a href="https://zombieloadattack.com/">ZombieLoad</a>) have exposed information leaks in other
microarchitectural features.</p>

<p>This is bad news: an attacker running one of the <strong>safest</strong> contexts (JavaScript or other managed
code, in a sandbox, in userspace) can conceivably train the indirect branch predictor to
speculatively execute a gadget in kernelspace, potentially
<a href="https://cyber.wtf/2017/07/28/negative-result-reading-kernel-memory-from-user-mode/">disclosing kernel memory</a>.</p>

<p>So, the kernel needed a new mitigation. That mitigation is <em>retpolines</em>.</p>

<h3 id="retpolines">Retpolines</h3>

<p>To mitigate Spectre v2, the kernel needs to prevent the CPU from speculating on an attacker
controlled indirect branch.</p>

<p>A retpoline (short for <em>ret</em>urn
<a href="https://en.wikipedia.org/wiki/Trampoline_(computing)"><em>trampoline</em></a>) does exactly that: indirect
jumps and calls are surrounded by a little <a href="https://en.wikipedia.org/wiki/Thunk">thunk</a> that
effectively traps the speculated execution in an infinite loop, spinning it until the misprediction
is resolved.</p>

<p>Intel’s
<a href="https://software.intel.com/security-software-guidance/api-app/sites/default/files/Retpoline-A-Branch-Target-Injection-Mitigation.pdf">Retpoline whitepaper</a>
has some helpful illustrations:</p>

<p><img src="https://blog.yossarian.net/assets/retpoline.png" alt="A visualization of speculative execution with and without a retpoline."></p>

<p>This works by converting the indirect control flow from an <em>indirect branch</em> to an
<em>indirect return</em><sup id="fnref:allreturns" role="doc-noteref"><a href="#fn:allreturns">3</a></sup>, hence the “ret” in retpoline. Returns are <em>also</em> predicted,
but with an additional mechanism given priority: the
<a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/">Return Stack Buffer</a><sup id="fnref:rsb" role="doc-noteref"><a href="#fn:rsb">4</a></sup>. To ensure that
the RSB can’t be maliciously trained away from the infinite loop, the retpoline begins with a
direct <code>CALL</code> that primes the RSB to always<sup id="fnref:notalways" role="doc-noteref"><a href="#fn:notalways">5</a></sup> predict the infinite loop.</p>

<p>Here’s what an indirect call retpoline <em>actually</em> looks like<sup id="fnref:ool" role="doc-noteref"><a href="#fn:ool">6</a></sup>, simplified significantly from
the <a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/lib/retpoline.S">kernel</a>
<a href="https://elixir.bootlin.com/linux/v5.9.14/source/arch/x86/include/asm/nospec-branch.h">source</a>:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre><span>__x86_retpoline_rax:</span>
  <span>call</span> <span>.Ldo_rop_0</span>
<span>.Lspec_trap_0:</span>
  <span>pause</span>
  <span>lfence</span>
  <span>jmp</span> <span>.Lspec_trap_0</span>
<span>.Ldo_rop_0:</span>
  <span>mov</span> <span>[</span><span>rsp</span><span>],</span> <span>rax</span>
  <span>ret</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>…all of that to replace a simple <code>call [rax]</code>!</p>

<h3 id="consequences">Consequences</h3>

<p>There are repercussions for this kind of trickery:</p>

<ul>
  <li>
    <p>It’s slow when correctly predicted: we’ve replaced a single indirect <code>CALL</code> with at least two
direct <code>CALL</code>s, plus a <code>RET</code>.</p>
  </li>
  <li>
    <p>It’s <em>really</em> slow when mispredicted: we <em>literally</em> spin in place using <code>PAUSE</code> and <code>LFENCE</code>.</p>
  </li>
  <li>
    <p>It’s a ROP gadget, so it <em>looks</em> like an exploit primitive. That means it screws with Intel’s
<a href="https://software.intel.com/sites/default/files/managed/4d/2a/control-flow-enforcement-technology-preview.pdf">CET</a>
and similar protections on other platforms. Intel claims that newer hardware will support “enhanced
IBRS”<sup id="fnref:ibrs" role="doc-noteref"><a href="#fn:ibrs">7</a></sup> that will replace the …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10">https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/12/16/Static-calls-in-Linux-5-10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442991</guid>
            <pubDate>Wed, 16 Dec 2020 14:38:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gloo Mesh Enterprise Beta Release – Solo.io Service Mesh Management Plane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442825">thread link</a>) | @ilackarms
<br/>
December 16, 2020 | https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/ | <a href="https://web.archive.org/web/*/https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png" data-src="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png" alt="" width="1781" height="397" data-srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png 1781w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1024x228.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-768x171.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1536x342.png 1536w" data-sizes="(max-width: 1781px) 100vw, 1781px" srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B.png 1781w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-300x67.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1024x228.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-768x171.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo-Mesh-Enterprise-B-1536x342.png 1536w"></p><p><span>From day one, our mission with Gloo Mesh has been to provide a service mesh command center that will give users indispensable features to manage a “glooed” together mix of environments, and today I am excited to announce that Gloo Mesh Enterprise is now available in Beta. We are asking the Gloo community and customers to <a href="https://lp.solo.io/request-trial">request a trial</a>, <a href="https://docs.solo.io/gloo-mesh/latest/">get started</a> and provide <a href="https://slack.solo.io/">feedback</a> via Slack on this latest Gloo Mesh Enterprise Beta so that our teams can continue to improve the features for its upcoming general availability. In addition, Gloo Mesh Enterprise has released its accompanying long term support for Istio, Istio on ARM and FIPS compliant Istio in general availability today with a license.&nbsp;</span></p><p><span>Originally launched in early 2019, Gloo Mesh (previously Service Mesh Hub) aims to provide organizations with a command center for all their service mesh needs, from a single cluster with Istio to stitching together and providing consistency for multiple clusters running different service meshes.&nbsp;</span></p><p><img src="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png" data-src="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png" alt="" width="7272" height="3440" data-srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png 7272w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-300x142.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1024x484.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-768x363.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1536x727.png 1536w" data-sizes="(max-width: 7272px) 100vw, 7272px" srcset="https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2.png 7272w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-300x142.png 300w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1024x484.png 1024w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-768x363.png 768w, https://www.solo.io/wp-content/uploads/2020/11/Gloo_Mesh_Diagram-Flat_110320-V2-1536x727.png 1536w"></p><p><span>Some of the exciting features you will find in the Enterprise Beta release includes:</span></p><ul><li><b>A Single Pane of Glass for Every Service Mesh On Every Cluster – </b><span>Gloo Mesh helps users manage similar or mixed service meshes such as Istio and Open Service Mesh (originally from Microsoft) over multiple clusters.&nbsp;&nbsp;</span></li><li><b>Ability to Create a Virtual Mesh that Connects Multiple Clusters </b><span>–&nbsp; Join similar meshes, such as Istio, together in a virtual mesh that makes services discoverable and policies easy to manage anywhere, even across clusters. With Gloo Mesh Enterprise the promise of federated workloads is finally here!&nbsp;</span></li><li><b>Enhanced Security Across Your Mesh – </b><span>Gloo Mesh includes end-to-end security across clusters and meshes and forms a virtual, zero trust, mesh.&nbsp;</span></li><li><b>WebAssembly Modules to Increase Engineer Productivity </b><span>– Extend your service mesh control plane to allow developers to declaratively initialize, build, push, and deploy Wasm filters to Istio workloads over multiple clusters.&nbsp;</span></li><li><b>Easy User Management </b><span>– No more wrangling of users with complex RBAC permissions across clusters and meshes. With Gloo Mesh Enterprise you can now define a single user policy for your service mesh or virtual mesh, and propagate that policy to all your environments.&nbsp;</span></li><li><b>Simplified Failover and Traffic Polices</b><span> – Easy to define policies for service failover and traffic limits that are effortless to migrate throughout your service mesh environments.&nbsp;</span></li></ul><p><span>Istio Support Features:</span></p><ul><li><b>Long Term Enterprise Support for Istio</b><span> – Gloo Mesh enterprise license includes support for N-3 versions of Istio. This long term support aligns Istio support with the underlying Kubernetes cluster and gives organizations the peace of mind that break fixes, security patches, and other Istio issues will be fixed with the type of enterprise support they require.&nbsp;</span></li><li><b>Istio for ARM</b><span> – With new cloud providers releasing ARM instances that boost performance while decreasing cost, organizations’ ARM portfolio has become increasingly important and Solo.io has listened with ARM build.&nbsp;</span></li><li><b>Istio with FIPS – </b><span>&nbsp;Federal government agencies and those organizations serving them often need to comply with the Federal Information Processing Standard (FIPS-2) to maintain a minimum level of security. Solo.io has the option for FIPS-2 compliant build of Istio’s data plane.&nbsp;</span></li></ul><p><span>What’s Next for Gloo Mesh? The </span><span>Gloo Mesh team is working tirelessly on the new set of features based on what our customers and the community require in an Enterprise service mesh.&nbsp;</span></p><ul><li><span>Routing locality rules for cross cluster service failover and ability to access closest geographical workload – e.g. one housed on east coast cluster vs. Asia.</span></li><li><span>Upstream enhancements for Istio</span></li><li><span>Full AWS App Mesh Support</span></li><li><span>Metrics for a single or multiple clusters</span></li><li><span>Virtual Mesh that includes AppMesh and Istio in a single logical mesh.&nbsp;</span></li><li><span>Istio lifecycle management&nbsp;</span></li></ul><p><span>To learn more about the features in the Beta release of Gloo Mesh please see the</span> <a href="https://www.solo.io/products/gloo-mesh/"><span>website</span></a><span>, </span><a href="https://docs.solo.io/gloo-mesh/main/"><span>documentation</span></a><span> and the public </span><a href="https://github.com/solo-io/gloo-mesh"><span>Github</span></a><span>.&nbsp;&nbsp;&nbsp;</span></p><p>You can also read about Making Web Assembly a first-class citizen on Gloo Mesh Enterprise Beta <span><a href="https://www.solo.io/blog/making-web-assem%E2%80%A6-enterprise-beta/">blog.</a></span></p><p><span>You can request a free trial of Gloo Mesh today <a href="https://lp.solo.io/request-trial">here</a>. To connect, join the </span><a href="https://solo-io.slack.com/archives/CJQGK5TQ8"><span>#gloo-mesh</span></a><span> channel in the Solo.io Slack.</span></p></div></div></div>]]>
            </description>
            <link>https://www.solo.io/blog/gloo-mesh-enterprise-beta-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442825</guid>
            <pubDate>Wed, 16 Dec 2020 14:26:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiments in Model Simplification]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442786">thread link</a>) | @pete_b_condon
<br/>
December 16, 2020 | https://wagtaillabs.com/2020/12/16/experiments-in-model-simplification/ | <a href="https://web.archive.org/web/*/https://wagtaillabs.com/2020/12/16/experiments-in-model-simplification/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-178">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>We were recently challenged by&nbsp;Ali El-Sharif from <a href="https://ai.science/">Aggregate Intellect</a> to run some benchmarks on GRANT, and thought that one of the most interesting direct comparisons would be to compare <a href="https://wagtaillabs.com/2020/11/17/introducing-grant-pt-1/">Amalgamate</a> with Cost Complexity Pruning (CCP).</p>



<p>Cost Complexity Pruning applies a similar philosophy to Amalgamate, aiming to remove parts of each decision tree that don’t carry their weight. There are many descriptions of how CCP works on the web, but <a href="https://www.analyticsvidhya.com/blog/2020/10/cost-complexity-pruning-decision-trees/">this is a good, quick introduction</a>.</p>



<p>First up we tried pruning a Random Forest using Amalgamate with increasing&nbsp;<em>threshold</em> values&nbsp;and compared that to pruning with increasing CCP <em>alpha</em> values. Here’s the result plot comparing Validation Root Mean Squared Error (RMSE) against the number of rules in the model (as found by <a href="https://www.analyticsvidhya.com/blog/2020/10/cost-complexity-pruning-decision-trees/">Graft</a>):</p>



<figure><img loading="lazy" width="735" height="425" src="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-1-1.png" alt="" srcset="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-1-1.png 735w, https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-1-1-300x173.png 300w" sizes="(max-width: 735px) 100vw, 735px"></figure>



<p>What’s interesting here is that Amalgamate has a significant early advantage, up to 20% fewer rules for the same Validation RMSE, but that eventually CCP finds a better, ultra-low complexity model. This suggests that CCP misses some easy simplifications because it only works on each decision tree individually, and that these can be found using Amalgamate.</p>



<p>To test this theory we tried running Amalgamate (with a fixed <em>threshold</em> for simplicity) on each CCP pruned model:</p>



<figure><img loading="lazy" width="723" height="428" src="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-2-1.png" alt="" srcset="https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-2-1.png 723w, https://wagtaillabs.com/wp-content/uploads/2020/12/EIMS-2-1-300x178.png 300w" sizes="(max-width: 723px) 100vw, 723px"></figure>



<p>These results show us that Amalgamate always found rules to eliminate, often (but not always) improving Validation RMSE. Overall our experiments showed that Amalgamate can be reduce the number of rules in a model by an average of 5% with no impact on Validation RMSE. This mightn’t sound like a lot, but anything that can be done to reduce the cognitive load required to understand the model without impacting on the results is useful.</p>



<p>By using both CCP and Amalgamate it is possible to find better simple models, and let stakeholders decide where the tradeoff between accuracy and complexity should be.</p>



<p>Check out <a href="http://github.com/wagtaillabs/GRANT">GitHub</a> if you would like to run your own experiments with GRANT.</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://wagtaillabs.com/2020/12/16/experiments-in-model-simplification/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442786</guid>
            <pubDate>Wed, 16 Dec 2020 14:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SolarWinds leaked FTP credentials through a public GitHub repo since 2018]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25442734">thread link</a>) | @hackerpain
<br/>
December 16, 2020 | https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/ | <a href="https://web.archive.org/web/*/https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.savebreach.com/content/images/size/w300/2020/12/ss_solar.png 300w,
                            https://www.savebreach.com/content/images/size/w600/2020/12/ss_solar.png 600w,
                            https://www.savebreach.com/content/images/size/w1000/2020/12/ss_solar.png 1000w,
                            https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.savebreach.com/content/images/size/w2000/2020/12/ss_solar.png" alt="SolarWinds Leaked FTP Credentials through a Public GitHub Repo &quot;mib-importer&quot; since 2018">
            </figure>

            <section>
                <div>
                    <h2 id="what-could-go-wrong-when-your-employees-commit-internal-information-to-public-github-repos">What could go wrong when your employees commit internal information to public GitHub repos? </h2><p>While <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">we were the first to report on the SolarWinds security vulnerability that possibly could have exposed their Downloads FTP server</a> credentials letting attackers to push malicious binaries and attack the US government and <a href="https://solarwinds.com/">SolarWinds</a>' other high profile clients, some more information has surfaced regarding the SolarWinds security vulnerability since then, that gives more insight into what possibly was exposed and whether it could have led to this massive breach of the US government. While majority of security researchers are of the opinion that this wasn't the main reason of the breach, and that there was a complex and sophisticated supply chain attack targeting <a href="https://solarwinds.com/">SolarWinds</a>, we believe<strong> these small security lapses could have given the attackers a larger attack surface to carry out their attacks</strong> and eventually might have helped strengthen their foothold into the SolarWinds infrastructure, to perform reconnaissance and evade detection.</p><h3 id="plain-old-ftp-to-the-blame">Plain old FTP to the blame?</h3><p>As per the screenshot posted by Vinoth, which we wrote about in our previous <a href="https://savebreach.com/solarwinds-credentials-exposure-led-to-us-government-fireye-breach/">post</a>, SolarWinds were possibly using unencrypted plain FTP server for their Downloads server in the age of global CDN technologies. However, not a direct attack vector its very likely that the FTP server had more vulnerabilities and unencrypted communication can always be intercepted, and modified. But we don't believe this maybe something as concerning as the FTP password leak.</p><h2 id="solarwinds-credentials-were-possibly-leaking-since-2018">SolarWinds Credentials were possibly leaking since 2018</h2><p>Security researcher Vinoth Kumar, told us that "SolarWinds had been possibly exposing the FTP credentials to the Download server since at least 2018". To corroborate his claim, Vinoth shared the the following link to the Configuration file exposed that was exposed in the mib-importer GitHub repo possibly belonging to a <a href="https://github.com/xkozus00">SolarWinds employee</a>, <a href="https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config">https://github.com/xkozus00/mib-importer/blob/master/Src/Lib/PurgeApp/PurgeApp.exe.config</a> and he further added that, upon supplying the <a href="https://github.com/xkozus00/mib-importer">repo base url</a> to the Web Archive, it shows Web Archive had first archived the page back in June 2018, and that was the last time the page was archived. So we concluded that the credentials to the FTP server and other potentially sensitive information in that exposed repository possibly existed for more than 1 year in the public domain until Vinoth reported it to the SolarWinds PSIRT.</p><figure><img src="https://savebreach.com/content/images/2020/12/image-3.png" alt="" srcset="https://savebreach.com/content/images/size/w600/2020/12/image-3.png 600w, https://savebreach.com/content/images/size/w1000/2020/12/image-3.png 1000w, https://savebreach.com/content/images/2020/12/image-3.png 1411w" sizes="(min-width: 720px) 720px"><figcaption>Screenshot of the SolarWinds GitHub repository archived by Web Archive</figcaption></figure><p>This shows that SolarWinds might have been exposing their sensitive internal credentials since a fairly long time before it was brought to their notice, which in turn might have given its attackers an opportunity to steal certificates and other valuable internal information about SolarWinds to carry out the large scale attack against US government and other top organizations using the backdoored SolarWinds Orion software.</p><h2 id="the-mib-importer-github-repository">The mib-importer GitHub repository</h2><p>A "mib-importer" public GitHub repository, possibly belonging to a SolarWinds employee with secrets (like FTP username and password) exposed, was found on GitHub by the security researcher in November 2019, which is said to have existed from around June 2018</p><p>Upon analyzing, the SaveBreach team found out that SolarWinds Orion lets users import MIB files into it. MIB files are used for monitoring network devices. Apparently, the mib-importer tool was developed by SolarWinds to import MIB files into Orion. We found the following data from the <strong><a href="https://support.solarwinds.com/SuccessCenter/s/article/Add-MIBs-to-the-SolarWinds-MIB-database">SolarWinds documentation pages</a> </strong>regarding importing &nbsp;MIB files (Reference – <a href="https://support.solarwinds.com/SuccessCenter/s/article/Upload-MIB-in-Orion-Universal-Device-Poller">1</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">2</a>, <a href="https://thwack.solarwinds.com/t5/NPM-Discussions/Adding-MIBs-to-Orion/m-p/113474">3</a>)</p><p><a href="https://documentation.solarwinds.com/en/Success_Center/orionplatform/Content/Core-Management-Information-Base--MIB--sw1730.htm">From SolarWinds website</a> – </p><blockquote>Management Information Base (MIB) is a structure that describes all objects a device can report on, such as CPU, fan, or temperature. MIB contains the name, datatype, and the object identifier (OID). MIB is a hierarchical structure, displayed as a navigation tree. Every entry in the MIB tree is a value for a specific component on a specific device.</blockquote><blockquote>SolarWinds maintains a MIB database that serves as a repository for the OIDs used to monitor a wide variety of network devices. The MIB database is updated regularly.</blockquote><h2 id="qa-with-cybersecurity-researcher-vinoth">Q&amp;A with cybersecurity researcher Vinoth</h2><p>From our most recent conversation with Vinoth, it appears that the credentials and possibly more sensitive data about SolarWinds was lying in public domain for a long time before finally being taken down. Vinoth doubts that the data might have also included certificates and not just FTP credentials, which was alone sufficient to sign the malicious binaries and upload them to the FTP server while passing off as legitimate software.</p><p><strong>Q: Since when do you think the GitHub repo might have been exposed? Do you think the attackers could have gained persistence into their infrastructure for almost 3 years to carry out the attack?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: I’m not sure, even on June 2018, 40 commits were there (in that repo). There was only one page available on archive couldn’t find anything else.</p><p><strong>Q: The Attackers had put signed binaries on the Download server. What was the process the attackers might have followed after getting access to the file upload server to sign the binaries?</strong></p><p><strong><a href="https://twitter.com/vinodsparrow">Vinoth</a></strong>: Not sure, but I could have missed checking the repo which could have had the certificate in it.</p><p><strong>Vinoth had tweeted that the GitHub repo was open to public since 17th June, 2018</strong></p><figure><blockquote data-width="550"><p lang="en" dir="ltr">That Github repo was open to the public since 17 Jun 2018 😱 <a href="https://t.co/SHUWaPXIeK">pic.twitter.com/SHUWaPXIeK</a></p>— Vinoth Kumar (@vinodsparrow) <a href="https://twitter.com/vinodsparrow/status/1338956534147993601?ref_src=twsrc%5Etfw">December 15, 2020</a></blockquote>

<figcaption>Tweet by Vinod about the web archived GitHub repository page</figcaption></figure><h2 id="certificates-used-to-sign-malicious-binaries-exposed-through-github-repo">Certificates used to sign malicious binaries exposed through GitHub repo?</h2><p>This raises many questions. Were the certificates used to sign the binaries obtained from that public GitHub repository or, from any other information leaked publicly? &nbsp;Exposed certificate could have allowed hackers to sign their malicious SolarWinds Orion binaries and pass them off as legitimate software developed by SolarWinds, subsequently uploading them to the Downloads server with the previously found leaked FTP credentials.</p><h2 id="was-this-how-solarwinds-got-hacked">Was this How SolarWinds got hacked?</h2><p>We can come to a partial conclusion that the internal information exposed on GitHub was there for a sufficiently long time for the attackers to have already exploited them to gain their initial foothold. Although unclear at this point, as there maybe a more sophisticated and complex attack chain with evasion techniques as being claimed by FireEye and security researchers, but we do feel this might have been a precursor to the SolarWinds breach and the widespread cyber attack against the US Government.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to SaveBreach | Cyber Security, Bug Hunting &amp; Domain Acquisitions</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.savebreach.com/solarwinds-exposed-ftp-credentials-back-in-2018-says-security-researcher-vinoth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442734</guid>
            <pubDate>Wed, 16 Dec 2020 14:19:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tig – Text-mode interface for Git]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25442510">thread link</a>) | @lemonspat
<br/>
December 16, 2020 | https://jonas.github.io/tig/ | <a href="https://web.archive.org/web/*/https://jonas.github.io/tig/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tig is an ncurses-based text-mode interface for git. It functions mainly
as a Git repository browser, but can also assist in staging changes for
commit at chunk level and act as a pager for output from various Git
commands.</p>
</div></div>]]>
            </description>
            <link>https://jonas.github.io/tig/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442510</guid>
            <pubDate>Wed, 16 Dec 2020 14:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Django Apps–Optimizing Templates Part 1]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25442290">thread link</a>) | @brauhaus
<br/>
December 16, 2020 | https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-1/ | <a href="https://web.archive.org/web/*/https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Slow websites are frustrating—and Google doesn’t like them either. In May 2021, Google is releasing a set of new ranking metrics known as <a href="https://moz.com/blog/core-web-vitals">Core Web Vitals</a>.&nbsp;</p>



<p>The core web vitals are a set of metrics used to determine how fast webpages load. The three metrics are:</p>



<ul><li><strong>Largest Contentful Paint:</strong>&nbsp;The time it takes the webpage’s main content to load—should ideally be below 2.5 seconds.</li><li><strong>First Input Delay:</strong>&nbsp;How long it takes before the page is interactive for the user. This should be less than 100 milliseconds.</li><li><strong>Cumulative Layout Shift:</strong>&nbsp;The time it takes for unexpected layout shifts in the page’s content; should be less than 0.1 milliseconds.</li></ul>



<p>Throughout this tutorial, you will learn how to optimize your Django templates for faster page load speeds to get your website ready for the new Google updates. Plus, it will make your visitors happy too! Let’s get started!</p>



<h2>Bundling and Minifying CSS with Django Compressor</h2>



<p>CSS is a render-blocking asset, meaning that it blocks the browser from rendering our webpage until the CSS has been completely downloaded and parsed.&nbsp;&nbsp;</p>



<p>We can optimize this process in our Django templates using <a href="https://django-compressor.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener">Django Compressor</a> to minify and bundle our stylesheets. Thus, reducing the CSS’s file size and the amount of network requests the browser has to make. Awesome, let’s see how we can do this.</p>



<p>First, let’s install and configure Django Compressor.</p>



<pre><code lang="python">pip install django_compressor</code></pre>



<p>After installing, add <code>"compressor"</code> to your <code>INSTALLED_APPS</code> in your project settings.</p>



<pre><code lang="python"># myproject/settings.py

INSTALLED_APPS = [
    # apps
    'compressor',
]</code></pre>



<p>Perfect, since we are using Django’s staticfiles contrib app, we have to add Django Compressor’s file finder to our <code>STATICFILES_FINDERS</code> setting. Inside your <code>settings.py</code> file, add:</p>



<pre><code lang="python"># myproject/settings.py 

STATICFILES_FINDERS = (
    'django.contrib.staticfiles.finders.FileSystemFinder',
    'django.contrib.staticfiles.finders.AppDirectoriesFinder',
    'compressor.finders.CompressorFinder',
)</code></pre>



<p>Now Django Compressor can find our static files. By default, Django Compressor will bundle our CSS files but not minify them. To minify the bundled CSS file, we need to pass the bundled file through a CSS filter. Let’s configure our CSS filters. Inside your <code>settings.py</code> file, add:</p>



<pre><code lang="python"># myproject/settings.py

COMPRESS_ENABLED = True
COMPRESS_FILTERS = {
        "css": [
            'compressor.filters.css_default.CssAbsoluteFilter',  
            'compressor.filters.cssmin.CSSMinFilter',
        ]
}</code></pre>



<p>Let’s break down what’s happening here. First, we set <code>COMPRESS_ENABLED</code> to <code>True</code>—this tells Django Compressor to compress our CSS files while in development mode.</p>



<p>Next, we define a list of filters to pass the bundled CSS through. The <code>CssAbsoluteFilter</code> normalizes the URLs in your CSS files to absolute URLs, like the URLs in the CSS <code>url()</code> function, and the <code>CSSMinFilter</code> minifies the bundled CSS.</p>



<p>Perfect, that takes care of the configuration. Let’s set up our templates and start using Django Compressor to minify and bundle our CSS files in the next section.</p>



<h3>Setting Up Templates</h3>



<p>Inside our Django app, let’s create our template folder structure.</p>



<pre><code lang="bash">+-- myapp
    +-- migrations
    +-- templates
        -- base.html
        +-- myapp
            -- mytemplate.html</code></pre>



<p>That takes care of the folder structure. Let’s create our <code>base.html</code> template now. Inside the <code>base.html</code> template, add:</p>



<pre><code lang="markup">{% <em>load</em> compress static %}
&lt;!DOCTYPE <em>html</em>&gt;
&lt;html <em>lang</em>="en"&gt;
    &lt;head&gt;
        &lt;!-- Global StyleSheets --&gt;
        {% <em>compress</em> css %}
           &lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/base.css' %}"&gt;
        {% <em>endcompress</em> %}

        {% <em>compress</em> css %}
        {% <em>block</em> styles %}
            &lt;!-- Child Template StyleSheets Go Here --&gt;
        {% <em>endblock</em> %}
        {% <em>endcompress</em> %}

        &lt;title&gt;Tutorial&lt;/title&gt;
    &lt;/head&gt;
   ....
&lt;/html&gt;</code></pre>



<p>We load in the compressor template tags and place the files we want to bundle and minify inside the <code>{% compress %}</code> template tag to use Django Compressor. The compress template tag takes one required argument: The filter key from the <code>COMPRESS_FILTERS </code>dictionary that tells Django Compressor which filters to use for these files. </p>



<p>Notice, I placed a style block inside the compressor template tag—this will put the child template stylesheets inside the compressor to be bundled and minified. </p>



<p>Lastly, let’s create a child template and add some stylesheets to it.</p>



<pre><code lang="markup">{% <em>extends</em> 'base.html' %}

{% <em>load</em> static %}

{% <em>block</em> styles %}
&lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/index.css' %}"&gt;
&lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/additional.css' %}"&gt;
{% <em>endblock</em> %}

{% <em>block</em> content %}
&lt;h1&gt;Index&lt;/h1&gt;
{% <em>endblock</em> %}</code></pre>



<p>Perfect, now we can test it out in the browser. Save your files and navigate over to <code>localhost:8000</code> in your browser. Inside your developer tools network tab, you should see something similar to this:</p>



<figure><img loading="lazy" width="1024" height="201" src="https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-1024x201.png" alt="Compressed CSS file shown in the network tab of the developer tools." srcset="https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-1024x201.png 1024w, https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-980x192.png 980w, https://engineertodeveloper.com/wp-content/uploads/2020/12/Screen-Shot-2020-12-14-at-9.07.23-PM-480x94.png 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1024px, 100vw"></figure>



<p>The bundled and minified CSS file <code>output.9a3d8d8fb748.css</code> is on line two. Awesome, Django compressor took our two child template CSS files, bundled them, and minified them—this will reduce network requests and speed up browser download and parsing times!</p>



<p>We can use Django Compressor to do the same with our JavaScript files too. In the next section, let’s learn how we can further optimize our template’s CSS files.</p>



<h2>Reducing Render-Blocking CSS with Media Attributes</h2>



<p>CSS files can quickly become bloated with a bunch of rules our page doesn’t need. For example, if someone accesses your site on a mobile device, they don’t need to parse the tablet and desktop styles before using the webpage. They only need the mobile styles.</p>



<p>Thankfully, we have a way around this with the <code>media</code> attribute. We can add a <code>media</code> attribute to the link tag to conditionally parse styles before rendering, depending on screen size. The other CSS files are still downloaded, but they are no longer render-blocking, meaning the browser doesn’t wait for them to load before rendering the webpage.</p>



<p>Let’s look at an example using our child template and base template. Inside the base template, define a new block called <code>mobile_styles</code>.</p>



<pre><code lang="markup">&lt;head&gt;
    {% <em>compress</em> css %}
    {% <em>block</em> mobile_styles %}

    {% <em>endblock</em> %}
    {% <em>endcompress</em> %}
&lt;/head&gt;</code></pre>



<p>Now, let’s add the mobile stylesheet in the child template.</p>



<pre><code lang="markup">{% <em>block</em> mobile_styles %}
&lt;link <em>rel</em>="stylesheet" <em>href</em>="{% static 'css/index-mobile.css' %}" <em>media</em>="(max-width: 520px)"&gt;
{% <em>endblock</em> %}</code></pre>



<p>If we test this out in the browser, we see that both mobile and desktop stylesheet are still downloaded, but only one was render-blocking depending on our screen size. If we resize the browser window, we will see the mobile stylesheet affect screen sizes below 520px.</p>



<p>Perfect, we are now loading less render-blocking CSS—this will improve our largest contentful paint and first input delay metrics.</p>



<h2>Conclusion</h2>



<p>Congrats on finishing the tutorial! You should now know how to optimize your Django template’s CSS and JavaScript using Django Compressor and reducing render-blocking CSS. </p>



<p>In the <a href="https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-2/">next tutorial</a>, we will look at optimizing images in our Django templates—images have a massive impact on page load speed performance.</p>



<p>I hope you found this tutorial helpful. If you have any questions leave a comment below and I will do my best to help out!</p>
</div></div>]]>
            </description>
            <link>https://engineertodeveloper.com/faster-django-apps-optimizing-templates-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442290</guid>
            <pubDate>Wed, 16 Dec 2020 13:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large tech company websites contain many spelling mistakes]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25442206">thread link</a>) | @petems
<br/>
December 16, 2020 | https://www.getsiteinspector.com/blog/spelling-errors-on-tech-company-websites/ | <a href="https://web.archive.org/web/*/https://www.getsiteinspector.com/blog/spelling-errors-on-tech-company-websites/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">
        <article>
  

  <div>
    <p>Scanning 5 tech company websites using <a href="https://github.com/siteinspector/siteinspector">SiteInspector</a> open-source tool shows that all of them contain a dozen of errors at the very least.</p>

<h3 id="apple">Apple</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/apl-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/apl-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/apl-3.png">
</p>

<ul>
  <li><strong>turn into turn into</strong> (duplicate)</li>
  <li><strong>acess</strong> (correct <em>access</em>)</li>
  <li><strong>to to</strong> (duplicate)</li>
</ul>

<h3 id="atlassian">Atlassian</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/atl-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/atl-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/atl-3.png">
</p>

<ul>
  <li><strong>responsibilites</strong> (correct <em>responsibilitis</em>)</li>
  <li><strong>the the</strong> (duplicate)</li>
  <li><strong>to get to get</strong> (duplicate)</li>
</ul>

<h3 id="gitlab">Gitlab</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/glb-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/glb-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/glb-3.png">
</p>

<ul>
  <li><strong>toolcahin</strong> (correct <em>toolchain</em>)</li>
  <li><strong>abiity</strong> (correct <em>ability</em>)</li>
  <li><strong>spport</strong> (correct <em>support</em>)</li>
</ul>

<h3 id="salesforce">Salesforce</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/sfs-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/sfs-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/sfs-3.png">
</p>

<ul>
  <li><strong>identites</strong> (correct <em>identities</em>)</li>
  <li><strong>an an</strong> (duplicate)</li>
  <li><strong>sharable</strong> (correct <em>shareable</em>)</li>
</ul>

<h3 id="shopify">Shopify</h3>

<p><img src="https://www.getsiteinspector.com/blog/images/spf-1.png">
  <img src="https://www.getsiteinspector.com/blog/images/spf-2.png">
  <img src="https://www.getsiteinspector.com/blog/images/spf-3.png">
</p>

<ul>
  <li><strong>langauge</strong> (correct <em>language</em>)</li>
  <li><strong>it’s own</strong> (correct <em>its own</em>)</li>
  <li><strong>availabilty</strong> (correct <em>availability</em>)</li>
</ul>

  </div>

  <p>
    Written on December  4, 2020
  </p>

  
<div>
	
	
	
</div>

</article>

      </div></div>]]>
            </description>
            <link>https://www.getsiteinspector.com/blog/spelling-errors-on-tech-company-websites/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442206</guid>
            <pubDate>Wed, 16 Dec 2020 13:26:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting started with C programming a lightning-fast start for absolute beginners]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 39 (<a href="https://news.ycombinator.com/item?id=25442165">thread link</a>) | @hdante
<br/>
December 16, 2020 | https://not.cafe/2020/10/12/getting-started-with-c-programming.html | <a href="https://web.archive.org/web/*/https://not.cafe/2020/10/12/getting-started-with-c-programming.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      <article>
    

  <h5>Posted at <time>2020-10-13 00:32+0000</time>
  
          , <em>last edit: <time>2020-12-14 18:47+0000</time></em>
  
  </h5>

  
  

  <p><span>!☕</span> This tutorial will guide you through writing the
“Hello World” program in the C programming language. You’ll use Unix-style terminal
emulators and command-line tools to execute commands, Linux-style package managers to
install programs and libraries, the GNU nano text editor to write C code, the meson build
system to build executable programs and the Gtk+ library to write portable, cross-platform
graphical programs.</p>

<figure>
  <a href="https://commons.wikimedia.org/wiki/File:Ken_Thompson_(sitting)_and_Dennis_Ritchie_at_PDP-11_(2876612463).jpg" target="_blank">
    <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg/599px-Ken_Thompson_%28sitting%29_and_Dennis_Ritchie_at_PDP-11_%282876612463%29.jpg" alt="Ken Thompson (sitting) and Dennis Ritchie at PDP-11">
  </a>
  <figcaption>
    <a href="https://en.wikipedia.org/wiki/Dennis_Ritchie" target="_blank">
    Dennis Ritchie
    </a> (standing), the creator of the C programming language, with
    <a href="https://en.wikipedia.org/wiki/Ken_Thompson" target="_blank">Ken Thompson</a>, the
    creator of Unix. Ken is using a
    <a href="https://en.wikipedia.org/wiki/Teleprinter" target="_blank">teletypewriter</a>
    (known as a tty on Unix) typewriter-style
    <a href="https://en.wikipedia.org/wiki/Computer_terminal" target="_blank">physical terminal</a>.
    Behind is the <a href="https://en.wikipedia.org/wiki/PDP-11" target="_blank">DEC PDP-11</a>
    minicomputer.
  </figcaption>
</figure>

<p>Instructions&nbsp;for&nbsp;three operating systems are provided: macOS, Ubuntu Linux and
Windows. The selected tools are personal favorites and were hand picked to allow the
fastest development and to allow identical development flows (and thus seamless
environment switching) on the three operating systems. All tools used in this tutorial are
<a href="https://en.wikipedia.org/wiki/Free_and_open-source_software" target="_blank">free, open source software</a>
and can be downloaded and used without any issues. No programming experience is required,
as this tutorial is for absolute beginners.</p>

<h3 id="before-we-start-terminals">Before we start: terminals</h3>

<p>There are a few notes for absolute beginners that will make our path easier and faster to
understand: to stay short, the tutorial will only guide through the setup process, but
will not teach the C language; references for next steps will be given at the end; some
program downloads may be large and take some time.</p>

<p>Programming languages and textual commands are very different from spoken languages:
programs must be written in a very strict way. Miss a comma and the program will stop
working. The most important rule for a beginner is that the C language, like most other
programming languages, is case sensitive, that is, upper case letters are considered
distinct from lower case letters and one can’t be swapped for the other. Keep this in mind
when typing the code and when in doubt copy and paste it to make sure all symbols are
correctly written.</p>

<figure>
  <a href="https://www.sydney.edu.au/science/psychology/pdp-11/terminals.html" target="_blank">
    <img src="https://not.cafe/assets/2020/terminals.jpeg" alt="PDP-11 terminals">
  </a>
  <figcaption>
    The <a href="https://en.wikipedia.org/wiki/VT52#VT55" target="_blank">DEC VT55</a>
    (display-style terminal, left side), the
    <a href="https://en.wikipedia.org/wiki/DECwriter" target="_blank">DECwriter</a>
    (dot-matrix printer-style terminal) and the
    <a href="https://en.wikipedia.org/wiki/Teletype_Model_33" target="_blank">Teletype ASR-33</a>
    (typewriter-style terminal).
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the terminal emulator application to type textual commands. I’ll
succintly explain what each command does and will show each command written after a dollar
sign. The dollar sign represents the terminal emulator’s prompt symbol, and that’s the
usual symbol that the command line input program, called the shell, displays when waiting
for a command. For example:</p>

<pre><code>$ ls -l
</code></pre>

<p>In the above example, we type after the prompt symbol: <code>ls[space][minus]l</code>, then press
<code>[enter]</code> to execute. In this example, we execute the <code>ls</code> program (list directory) with
the <code>-l</code> parameter (a specific parameter for the program, changes the output mode to long,
or more descriptive). Same example, but also showing the resulting output in my computer:</p>

<pre>$ ls -l
total 7344
-rw-r--r-- 1 hdante users    9999 set 19 19:12 coffee-34251.svg
-rw-r--r-- 1 hdante users     347 set 19 19:12 coffee-34251.svg.license
-rw-r--r-- 1 hdante users   16805 set 19 19:12 favicon.ico
-rw-r--r-- 1 hdante users    3253 set 19 19:12 favicon.svg
-rw-r--r-- 1 hdante users   11665 out  2 18:49 index.html
-rw-r--r-- 1 hdante users   17833 set 19 19:12 not-coffee.svg
-rw-r--r-- 1 hdante users 2372085 set 19 19:12 radio.caf
-rw-r--r-- 1 hdante users 2656465 set 19 19:12 radio.mka
-rw-r--r-- 1 hdante users 2401864 set 19 19:12 radio.opus
-rw-r--r-- 1 hdante users    3263 out  2 16:48 site.css
-rw-r--r-- 1 hdante users    2166 set 19 19:12 square.svg
$ </pre>

<p>So,&nbsp;after&nbsp;running the <code>ls</code> program with the <code>-l</code> parameter, it shows the long
description of current directory and another dollar symbol appears at the end, it’s
waiting for a new command. Don’t worry about understanding this example, I’ll also add
references at the end for learning more about using Unix-style command-line tools.</p>

<h3 id="installation">Installation</h3>

<figure>
  <a href="https://not.cafe/assets/2020/macos-terminal-app.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/macos-terminal-app.jpeg" alt="macOS Terminal App">
  </a>
  <figcaption>
    The
    <a href="https://en.wikipedia.org/wiki/Terminal_(macOS)" target="_blank">
    macOS Terminal.app
    </a> is a
    <a href="https://en.wikipedia.org/wiki/Terminal_emulator" target="_blank">terminal emulator</a>.
    Modern terminals are software that emulate physical terminals.
  </figcaption>
</figure>

<p>Different&nbsp;procedures&nbsp;are required for each operating system. Pick the best one
for you. After installing, writing and running code will work the same way. We’ll write a
single cross-platform program that works on all three systems and build it using the same
cross-platform build tools.</p>

<h4 id="macos">macOS</h4>

<p>For macOS, only the terminal emulator comes installed with the operating system. The Apple
provided C compiler is the
<a href="https://en.wikipedia.org/wiki/Clang" target="_blank">LLVM clang compiler</a>,
contained in the “Xcode command line tools” package. To install it, open the Terminal
application by opening the Spotlight search input, then typing Terminal (or find it in the
Utilities folder inside Applications). In the terminal emulator, type:</p>

<pre><code>$ xcode-select --install
</code></pre>

<p>The Xcode installation program will start. Follow the instructions that will appear and in
the end, the LLVM clang C compiler will be installed. You can check if it’s working by
executing it with the <code>--version</code> parameter:</p>

<pre><code>$ clang --version
</code></pre>

<p>For installing packages like build tools, text editors and libraries, we’ll install the
<a href="https://en.wikipedia.org/wiki/Homebrew_(package_manager)" target="_blank">Homebrew package manager</a>,
which is the main Linux-style package manager for macOS. The package manager allows
single-command installing, configuring, upgrading and removing of packages from the
command line. Go to <a href="https://brew.sh/" target="_blank">brew.sh</a> and access the
instructions there, or simply execute this command to download and install it:</p>

<pre><code>$ /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
</code></pre>

<p>Notice that this command is already more complex than the previous ones, downloading and
executing the install script from the Homebrew source code repository, and gives a hint on
the power and efficiency of the command line. Don’t worry trying to understand it, we’re
installing Homebrew exactly to make it easy to execute complex package installations.
[<strong>edit 20201214</strong>: It might be necessary to restart the Terminal App and configure the
search path after installing <code>brew</code> to be able to use it. When in doubt, check the
<a href="https://docs.brew.sh/">Homebrew documentation</a>.]</p>

<p>Now that Homebrew is installed, you may install packages with <code>brew install</code> and search
packages with <code>brew search</code>. Search and install the GNU nano text editor with:</p>

<pre><code>$ brew search nano
$ brew install nano
</code></pre>

<h4 id="linux">Linux</h4>

<figure>
  <a href="https://not.cafe/assets/2020/gcc-on-ubuntu.png" target="_blank">
    <img src="https://not.cafe/assets/2020/gcc-on-ubuntu.png" alt="gcc on Ubuntu">
  </a>
  <figcaption>
    Installing gcc on Ubuntu Linux.
  </figcaption>
</figure>

<p>We’ll&nbsp;use&nbsp;the apt package manager available in
<a href="https://ubuntu.com/" target="_blank">Ubuntu Linux</a> from the Debian family, but
other Linux distributions using, for example,
<a href="https://www.redhat.com/sysadmin/how-manage-packages" target="_blank">yum</a>,
<a href="https://docs.fedoraproject.org/en-US/quick-docs/dnf/" target="_blank">dnf</a>,
<a href="https://wiki.archlinux.org/index.php/Pacman" target="_blank">pacman</a>,
etc. will work in pretty much the same way. On Linux the
<a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a>
usually comes preinstalled, so we’ll use it instead of clang, but they work the same way.
Open a terminal by clicking the activities menu on the top left of the screen and writing
terminal in the search input (or click on the terminal icon in the favorites bar). In the
terminal emulator, write:</p>

<pre><code>$ sudo apt-get install gcc
</code></pre>

<p>Ubuntu Linux and most other distributions require switching to administrator (root) mode
to install programs, so we use the <code>sudo</code> program to execute <code>apt-get</code> in root mode (you
may also use the <code>su</code> program, if <code>sudo</code> is not installed). Type your password and follow
the instructions. In the end, check gcc:</p>

<pre><code>$ gcc --version
</code></pre>

<p>You may install packages with <code>sudo apt-get install</code> and search packages with <code>apt-cache
search</code>:</p>

<pre><code>$ apt-cache search nano
$ sudo apt-get install nano
</code></pre>

<p>For other Linux distributions, use the appropriate package manager:</p>

<pre><code>$ yum search nano         # for RedHat Linux/CentOS
$ sudo yum install nano   # for RedHat Linux/CentOS
</code></pre>

<h4 id="windows">Windows</h4>

<figure>
  <a href="https://www.msys2.org/" target="_blank">
    <img src="https://not.cafe/assets/2020/msys2-website.jpeg" alt="MSYS2 website">
  </a>
  <figcaption>
    <a href="https://www.msys2.org/" target="_blank">MSYS2 website</a>. MSYS2 is a
    toolkit for Windows development that contains Unix-style tools.
  </figcaption>
</figure>

<p>For Windows we’ll use the
<a href="https://en.wikipedia.org/wiki/Mingw-w64#MSYS2" target="_blank">MSYS2 toolkit</a>,
which provides a terminal emulator, the pacman package manager and a complete set of
Unix-style command line tools. Download the MSYS2 installer from
<a href="https://www.msys2.org/" target="_blank">www.msys2.org</a> and follow the
instructions to install the package. When installed, MSYS2 will provide three sets of
programs, which are selected whenever opening the terminal emulator. They are called the
MSYS2 shell, the MINGW64 shell (pronounced mingwee 64) and the MINGW32 shell. The MINGW64
shell is the appropriate one to develop Windows programs. The MSYS2 is appropriate for
managing MSYS2 itself and the MINGW32 is the 32-bit version that shouldn’t be used
anymore. After installing MSYS2 it’s necessary to immediatelly upgrade it. Open the MSYS2
shell and type:</p>

<pre><code>$ pacman -Syu
</code></pre>

<p>Follow the instructions and if requested restart the terminal emulator. On Windows we’ll
use the <a href="https://gcc.gnu.org/" target="_blank">GNU Compiler Collection</a> C
compiler (gcc):</p>

<pre><code>$ pacman -S mingw-w64-x86_64-toolchain
</code></pre>

<p>After installing, to test gcc, you must use a MINGW64 shell. If you’re running the MSYS2
shell for executing pacman, open another terminal running the MINGW64 shell and type:</p>

<pre><code>$ gcc --version
</code></pre>

<p>From now on, we’ll assume that the MINGW64 shell is being used. Notice that pacman runs
normally both on MSYS2 and MINGW64 shells. You may install packages with <code>pacman -S</code> and
search packages with <code>pacman -Ss</code>:</p>

<pre><code>$ pacman -Ss nano
$ pacman -S nano
</code></pre>

<h3 id="hello-world-">Hello, World !</h3>

<figure>
  <a href="https://not.cafe/assets/2020/nano-on-macos.jpeg" target="_blank">
    <img src="https://not.cafe/assets/2020/nano-on-macos.jpeg" alt="GNU nano on macOS">
  </a>
  <figcaption>
    Writing the Hello World program using GNU nano on macOS.
  </figcaption>
</figure>

<p>After installing the compilers, remember installing the
<a href="https://en.wikipedia.org/wiki/GNU_nano" target="_blank">GNU nano</a> text editor:</p>

<pre><code>$ brew install nano    # (or apt-get, or pacman)
</code></pre>

<p>Now, let’s create a new root directory to store this project and all future code:</p>

<pre><code>$ mkdir code
$ cd code
</code></pre>

<p>The first command above creates a new directory called <code>code</code>. If it already exists, it
will complain. Change the name if you prefer something else. The second command changes
the current directory to the <code>code</code> directory (the current directory is the directory used
when file operations specify file names without …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://not.cafe/2020/10/12/getting-started-with-c-programming.html">https://not.cafe/2020/10/12/getting-started-with-c-programming.html</a></em></p>]]>
            </description>
            <link>https://not.cafe/2020/10/12/getting-started-with-c-programming.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442165</guid>
            <pubDate>Wed, 16 Dec 2020 13:21:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiments on a $50 DIY air purifier that takes 30s to assemble]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25442097">thread link</a>) | @dyno-might
<br/>
December 16, 2020 | https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/ | <a href="https://web.archive.org/web/*/https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            
            <p><strong>Dec 15, 2020</strong></p>
            
            



<p>Bad air is bad for you. The air purifier market, though, is a mess. Every purifier uses incompatible proprietary filters, presumably to lock you into buying replacements. How do we know these actually work? Few seem to publish lab tests. And why does it cost $100-$300 for a big plastic box with a fan and a filter inside?</p>

<p>It’s common to build DIY air purifiers by basically strapping a filter to a fan. I like the idea of these, but again, it’s hard to be confident they really work. There’s a few experiments out there, but not enough to make me comfortable. So I decided to do some experimenting of my own. I made a purifier, generated smoke, and measured how well it removes tiny particles.</p>



<p>If you’re in a hurry, this post says that if you strap two HEPA filters to a box fan, it will clear the air of basically all the particles we can measure, and it will do it faster than a commercial filter that costs twice as much.</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="in a large room the DIY filter does slightly better than the commercial filter"></p>



<h3 id="diy-purifier">DIY purifier</h3>

<p>My DIY purifier was <em>very</em> simple. (I don’t want to promote any particular brands here. Contact me if you want the exact products.)</p>

<ul>
  <li>A standard box fan. (Cost: $19)</li>
  <li>Two HEPA air filters, each approximately 32 cm x 22 cm and 5cm thick. (Cost: $35 for both)</li>
  <li>A bungie cord. (Cost: Free)</li>
</ul>

<p>Assembly takes about 30s. You put the filters on the intake side of the fan and strap them on with the bungie cord. Here’s a picture:</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_notape.jpg" alt="DIY purifier" max-width="60%" min-width="35%"></p>

<p>Timeless elegance and grace, it is not. I get the shakes just looking at that bit of crinkled filter.</p>

<h3 id="commercial-purifier">Commercial purifier</h3>

<p>As a comparison, I got a $100 air purifier from a well-known brand that’s intended for small rooms. It uses uses a single HEPA filter that’s about 25cm x 12cm and 4cm thick. Replacement filters currently cost around $25.</p>

<h3 id="smoke">Smoke</h3>

<p>It’s surprisingly hard to repeatedly generate a consistent amount of smoke. I tried burning various things (paper, cardboard) and found that the number of particles generated can vary by an order of magnitude, depending on the burn pattern. This is difficult to control and effectively random.</p>

<p>Ideally, I’d have liked to burn some food product like oil, since the kitchen is usually the biggest source of indoor air pollution. I couldn’t figure out a good way of doing this, either: You’d need to have the same amount of oil distributed in the same way and heated to the same temperature.</p>

<p>I finally settled on using incense. I cut sticks to the length of a standard credit card and then attached the ends horizontal to the ground. This seemed to be pretty consistent. In retrospect, I bet that burning toast in a toaster would work well. (I didn’t have one on hand.)</p>

<h3 id="measurements">Measurements</h3>

<p>I borrowed a cheap-ish ($100) air quality monitor from a friend. I think it’s made by some company in China and then re-sold by various white-label brands. I can’t figure out who the original manufacturer is. Based on data I’ve seen for the reliability of other air quality monitors, I wouldn’t trust the absolute numbers, but the I think the <em>relative</em> measurements should still be OK.</p>

<p>The typical measurement for particulate pollution is “PM 2.5” which is in units of μg/m³. This is intended to measure what you’d get if you did the following:</p>
<ul>
  <li>Take a cubic meter of air.</li>
  <li>Filter all the solid particles out of the air.</li>
  <li>Keep only the solid particles that are are 2.5 micrometers (μm) or smaller.</li>
  <li>Weigh all the particles you kept in micrograms (μg).</li>
</ul>

<p>Here are some ways to interpret these numbers:</p>
<ul>
  <li>The EPA says yearly averages should be below 12 and daily averages below 35.</li>
  <li>The average outdoor level ranges from 6 in Finland to almost 100 in Nepal. Rich countries are typically under 15. The highest levels are typically found in Asia and Africa.</li>
  <li>Cooking can easily cause PM 2.5 measurements to spike into the hundreds. I’ve observed myself that this can happen with only a small amount of visible smoke.</li>
</ul>

<h3 id="logging">Logging</h3>

<p>Since the air quality monitor doesn’t log data, I used an ultra-hacky alternative: I set the monitor next to a laptop running a stopwatch. I then aimed a tabet at both of those screens and took a timelapse video. Finally, I manually transcribed the data by going to each minute marker in the data. (This was even more tedious than it sounds.)</p>



<p>I ran a first experiment in a tiny room of around 8 ㎥. Due to worries that wind from the purifiers might change the speed the incense burned, I placed it on the opposite side of a wall, with a gap of around 20 cm near the ceiling.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_tinyroom.jpg" alt="tiny room setup"></p>

<p>I repeated the experiment once with no filter, once with a commercial filter, and once with the DIY filter. Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_linear.jpg" alt="smallroom measurements in linear space"></p>

<p>Things are a bit random around the beginning, probably due to the drifting of the smoke before it’s equalized in the room. With no filter at all, this spikes all the way to 1000 μg/m³, the maximum the instrument can show.</p>

<p>If we make the y-axis logarithmic, it becomes quite clear that the DIY filter is cleaning the air at a better rate. (This is the picture from the top of this page.)</p>

<p><img src="https://dyno-might.github.io/img/purifier/smallroom_log.jpg" alt="smallroom measurements in log space"></p>

<p>If we take the EPA’s threshold of 12 μg/m³, the DIY filter gets there in around 15 minutes, while the commercial filter take around 25 minutes.</p>



<p>Thankfully, I don’t spend most of my time in an 8 ㎥ room. Thus, I repeated the experiment in a large room of around 100 ㎥. Here there was no wall between incense and purifier. Instead I left around a meter of distance between the incense and purifier and the purifier and the monitor.</p>

<p><img src="https://dyno-might.github.io/img/purifier/setup_largeroom.jpg" alt="large room setup"></p>

<p>Here are the results:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_linear.jpg" alt="large room measurements in linear space"></p>

<p>There’s even more randomness around the beginning, probably just due to how the smoke drifts around. Based on the room volume we’d expect a peak concentration with no filter of around 80 μg/m³ = 1000 μg/m³ * (8/100). Reassuringly, this is pretty close to what we see.</p>

<p>The DIY purifier looks a bit better. If we plot in log space, it’s more clear that it is indeed filtering at a better rate:</p>

<p><img src="https://dyno-might.github.io/img/purifier/largeroom_log.jpg" alt="large room measurements in log space"></p>



<p>It’s common advice for DIY purifiers like this to seal around the edges of the filter so that all air must pass through it.  I share the intuition that this would help, but it’s hard to be sure: If you block airflow, you slow down the fan. This could be counterproductive.</p>

<p>In this case at least, experiment is easier than theory. I took packing tape and carefully sealed around the intake side.</p>

<p><img src="https://dyno-might.github.io/img/purifier/filter_tape.jpg" alt="DIY purifier with tape" max-width="60%" min-width="35%"></p>

<p>And the results are…</p>

<p><img src="https://dyno-might.github.io/img/purifier/taping.jpg" alt="taping around the filter has no effect"></p>

<p>…nothing!?</p>

<p>This was unexpected. I thought the tape would help, but I wouldn’t have been surprised if it hurt instead. Instead, there’s basically no difference at all. I don’t know enough about fluid dynamics to even speculate about what’s happening here, so I won’t try.</p>

<p>There could be some weird quirk in how I ran this experiment. This doesn’t necessarily mean that all the advice to tape around the filter is <em>wrong</em>. However, I’ve never seen any experriments that show taping helps either.</p>



<p><strong>Cost.</strong> The DIY purifier isn’t dramatically cheaper than the commercial one, but I expect the filters would need to be replaced much less often. The commercial purifier uses a single filter with an area of 300 cm², whereas the DIY purifier uses two filters with a total area of around 1400 cm², and also slightly thicker. It’s reasonable to assume the DIY filters could remove ~4 times as many particles before replacement.</p>

<p><strong>Durability.</strong> One concern is that box fans aren’t meant to be used with filters attached and could wear out. This is reasonable. However, box fans are much cheaper than commercial purifiers, and I’ve been using this particular fan with various filters attached for several years now without issue.</p>

<p><strong>Electricity.</strong> The cost of electricity is another factor. Typical box fans seem to use around 55W, whereas commercial purifiers typically use 30-45W. If electricity costs $0.13 / kWh, the box fan would cost around $62 to operate 24 hours a day for a year, while a 30-watt purifier would cost around $34. Obviously, these numbers decrease if you run the purifier less. Some (more expensive) commercial purifiers have air quality sensors built in and automatically turn on only when needed.</p>

<p><strong>MERV or HEPA?</strong> Most people who build box-fan purifiers use <a href="https://en.wikipedia.org/wiki/Minimum_efficiency_reporting_value">MERV</a>-rated filters intended for furnaces. Commercial air purifiers use <a href="https://en.wikipedia.org/wiki/HEPA">HEPA</a>-rated filters. Roughly speaking, HEPA filters are “better” in that they are rated to remove a higher percentage of particles in one pass. It’s not clear that HEPA filter will actual perform better when attached to a fan, though: A filter that catches fewer particles in one pass might still be better if it allows for faster airflow.</p>

<p><strong>That one video.</strong> If you’re reading this article after it was linked from some forum, I’d bet you that someone in the comments links to <a href="https://www.youtube.com/watch?v=kH5APw_SLUU">this video</a> from the Michigan Sinus Center. I found this inspirational, but note a couple of things: First, while the description says they use HEPA filter, the video clearly indicates a MERV filter. Again, that’s not necessarily bad! They claim that around 90% of particles sized 0.3 microns are larger are eliminated in a single pass. That’s good, but not totally reassuring. The question is, does it remove 99% in two passes? If 90% of the particles in the ambient air were large and the filter only catches large particles, then additional passes would never get rid of the most dangerous small particles. This is why I trust HEPA filters a bit more: since they remove almost all particles in one pass, I’m confident they should remove almost all particles eventually. This is also why I strongly prefer experiments that actually measure particles removed from the air in a room, rather than just the air coming out of the purifier.</p>

<p><strong>Further questions.</strong> There’s a lot of things that further experiments could look at:</p>

<ol>
  <li>Does the fan speed make a huge difference?</li>
  <li>How does the purifier compare to larger commercial purifiers?</li>
  <li>How do MERV-rated furnace-type filters compare under the same conditions?</li>
  <li>How can it not matter if there’s tape around the filters!?</li>
  <li>Does fan speed matter? (I always ran the box fan at maximum speed.)</li>
  <li>Is it better to put the filters on the intake or outtake side of the …</li></ol></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/">https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</a></em></p>]]>
            </description>
            <link>https://dyno-might.github.io/2020/12/15/some-real-data-on-a-DIY-box-fan-air-purifier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25442097</guid>
            <pubDate>Wed, 16 Dec 2020 13:15:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[For e-mobility 2020 brought significant progress, this is an extensive overview]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25441956">thread link</a>) | @Pabloemm
<br/>
December 16, 2020 | https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html | <a href="https://web.archive.org/web/*/https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><a href="https://solidstudio.io/index.html">Solidstudio</a>
                    &gt;&gt;
                    <a href="https://solidstudio.io/blog/blog.html">Blog</a>
                    &gt;&gt;
                    &gt;The growing concept of e-Mobility as a Service
                </p>

                

                <h2 id="research-explanation">Research explanation of e-Mobility as a
                    Service</h2>

                <h3 id="emergence-of-emobility">Emergence of mobility concepts</h3>

                <p>
                    Before the digital revolution and user-centric approach, the concept of accessible, new forms of
                    transportation was the future vision of what life could be like. With the rapid growth of
                    technology, mobile devices, enhanced battery capacities, wide Internet connection, investments in
                    new unexplored forms of service delivery, and quick social adaptation in the last ten years we have
                    witnessed a great transformation.
                </p>
                <p>
                    Raising enthusiasm boosted consumption and proved that rapid adaptation is possible and widely
                    accepted. New economic models have begun to take into account sharing concepts and value the
                    tangible benefits of such solutions. In a sharing economy, not used assets such as parked cars and
                    extra bedrooms can be rented out. We transferred from owning to renting. And this concept widely
                    approved first by Uber users moved to other transport areas offering new possibilities. In the
                    Alternative Journal article,
                    <a href="https://www.alternativesjournal.ca/science-and-solutions/ours-better-yours" target="_blank" rel="nofollow">
                        ‘Ours is Better than Yours’
                    </a>
                    , Ray Tumulty (2014) the sharing economy is
                    described as a clearly urban phenomenon. To achieve economies of scale for shared economy services
                    satisfactory population density is required. Moreover, these services are seen as an extra option,
                    not a replacement for traditional sectors. Ridesharing is used along with public transportation in
                    cities.
                </p>
                <p>
                    With the growing success of rented items and services, new forms of transportation options come to
                    the market. The mobility concept grew to form a comprehensive ecosystem offering numerous moving
                    variants, such as city bikes, electric scooters, car rides, ticket purchasing options, city traffic
                    monitoring, planning the most convenient route, parking options, integrated payments, and available
                    charging options for ‘e’ users. All available in real-time from the mobile app on one’s phone. This
                    progress developed the term
                    <a href="https://solidstudio.io/blog/from-maas-to-emaas-how-e-is-taking-a-charge-over-the-markets.html" target="_blank" rel="nofollow">
                        Mobility as a service
                    </a>
                    , which covers a wide range of mobility services
                    available on the market, and its integral part becomes a shared economy providing extra value for
                    participants.
                </p>
                <p>
                    On a high-level, the MaaS ecosystem includes transport infrastructure, transportation services,
                    transport information, and payment services. Within the ecosystem, the common objective is the
                    delivery of a seamless mobility experience and transportation network improvement by utilizing the
                    benefits of each service - public and private. Besides, other participants such as local authorities
                    or data administration companies can collaborate to smooth the operation of the services and improve
                    their profitability.
                </p>
                <p>
                    MaaS as a definition is described as
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/6.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>
                <p>
                    One of the MaaS ecosystem examples was presented by the Siemens Mobility Division in 2016 for
                    Tampere City, Finland. The ecosystem is build of 4 main elements: service providers; a
                    business-to-business (B2B) platform; mobility retailers; and the users. The intention of the project
                    was to unite the existing and upcoming transport services with the operations of the local
                    paratransit services.
                </p>
                <p>
                    A similar approach on a high level was presented by König project ‘Mobility As A Service for Linking
                    Europe’. Four different levels define the public and regulatory level, the transport and logistics
                    service providers level, the mobility service level, and the end-user level. On the basis of similar
                    concepts and definitions, a framework for Mobility as a service was developed.
                </p>
                <p>
                    From a business perspective, MaaS is described by Kamargianni and Matyas in the paper ‘The Business
                    Ecosystem of Mobility-as-a-Service’[1](2017) as ‘the wider network of enterprises that influences how a
                    dominant company, in this case, the MaaS provider, creates and capture value’.
                </p>
                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/7.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    To support theoretical premises on shared mobility, a survey conducted by McKinsey&amp;Company (2017)
                    provides some insight into the consumer’s opinion on ride-hailing and car-sharing. Respondents were
                    asked how their usage of ride-hailing and car-sharing services will change within the next two
                    years. In both cases, over 60% responded that it will increase or increase significantly. Shared
                    mobility is mostly favored in urban areas, but seems to be less attractive for running errands or
                    multi-stop shopping trips.
                </p>

                <h3 id="what-is-e">What is ‘e’ all about?</h3>

                <p>
                    We are an integral part of the next global transformation, where alternative fuels and green energy
                    takes charge. The concept explained above has been extended with ‘e’ - a possibility to travel in an
                    eco-friendly way, where ‘e’ stands for electric solutions.
                </p>
                <p>
                    Electric Mobility as a service combines Mobility as a Service (MaaS), Electric Mobility Systems
                    (EMS), and Shared Electric Mobility Services (SEMS) [2]. As a concept eMaaS operates upon MaaS,
                    where the last one became one of the complementary components. With that defined, all MaaS
                    participants become, as a consequence, eMaaS attendees. Providing they offer electric mobility
                    solutions.
                </p>

                <p><img src="https://solidstudio.io/img/blog/emobility-ebook/8.jpg" alt="MaaS definition" width="100%" height="auto">
                </p>

                <p>
                    Electric Mobility System (EMS) covers technologies (batteries, charging technologies, drivetrains,
                    and EVs), infrastructure (physical and organizational of charging stations, electricity grid,
                    information and communication technology), and users (manufacturers, suppliers, end-users, service
                    providers, governments, and agents).
                </p>
                <p>
                    Shared Electric Mobility Services’ (SEMS) applies to a new economy implementation, where instead of
                    ownership there is an on-a-need basis share connected by the technology with users and providers.
                    SEMS replies to the environmental, social, financial, and transportation-related benefits that had
                    already been correlated to emobility and shared mobility practice connecting both. Five business
                    approaches are proposed:
                </p>
                <ul>
                    <li>
                        Membership-based (e.g. e-bike sharing, e-car sharing, e-ridesharing, e-ride hailing, e-scooter
                        sharing, e-bus sharing),
                    </li>
                    <li>
                        Peer-to-Peer(e.g. e-car sharing, e-bike sharing, e-scooter sharing),
                    </li>
                    <li>
                        Non-membership-based (e.g. e-car rental, elimousine rental),
                    </li>
                    <li>
                        For-hire (e.g. e-car/bike/scooter sharing, e-ridesharing e-carpooling),
                    </li>
                    <li>
                        Mass transit systems (e.g. e-Public Transport, airport autonomous shuttles).
                    </li>
                </ul>
                <p>
                    As a part of a wider concept, combined with two other components MaaS &amp; EMS, together provides
                    multiple eco-friendly transportation possibilities. Successful implementation of such a concept
                    requires multi-level support, well-designed system architecture, and an extensive network in public
                    structures.
                </p>

                <h3 id="user-centric">User-centric approach</h3>

                <p>
                    The user-centric approach will always be foreground. It applies to the development of the widely
                    recognized concept of e-mobility as a service. From accessible payment methods for single ticket
                    purchasing, subscriptions, to well-developed charging networks and various means of transport
                    access. At each stage of the proposition should be declared value.
                </p>
                <p>
                    We are still in the early stages of what could be called e-Mobility as a service. Most customer
                    journeys are under development, and achieving overall flow is still in its infancy. There is a lot
                    of research to be done, but there is room for the general necessary approaches. Each of the
                    participants, in order to achieve success and remain successful in this growing market, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html">https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</a></em></p>]]>
            </description>
            <link>https://solidstudio.io/blog/growing-concept-e-mobility-as-a-service.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441956</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PerceptiLabs – A simple tool to build machine learning models]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25441955">thread link</a>) | @Xubeqi
<br/>
December 16, 2020 | https://perceptilabs.com/product | <a href="https://web.archive.org/web/*/https://perceptilabs.com/product">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-b80770e6=""><div xs="12" data-v-b80770e6=""> <p data-v-b80770e6="">
          PerceptiLabs is a dataflow driven, visual API for TensorFlow,
          carefully designed to make machine learning (or deep learning)
          modeling as intuitive as possible.
        </p></div></div></div>]]>
            </description>
            <link>https://perceptilabs.com/product</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441955</guid>
            <pubDate>Wed, 16 Dec 2020 12:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a recipe for distributed, small-scale food production]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25441679">thread link</a>) | @roboben
<br/>
December 16, 2020 | https://permapeople.org/blog/2020/12/02/designing-and-optimizing-a-recipe-for-distributed-food-production.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/12/02/designing-and-optimizing-a-recipe-for-distributed-food-production.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="introduction">Introduction</h2>

<p>I’ve been considering these concepts for a few years, and after spending a few years living in a small, economically-challenged community - I started to develop some ideas on how to power food sovereignty alongside traditional food sources like foraging, hunting, and fishing.</p>

<h2 id="distributed-small-scale-food-production-a-potential-solution">Distributed small-scale food production: A potential solution</h2>

<p>I realize this may be an idealistic approach, assuming people will be willing to take on the burden of learning new skills like animal husbandry, the many aspects of gardening, and the inevitable food preparation skills that are required to manage the outputs of such a system.</p>

<p>This being said, I think this could work for a minority of interested folks, and allow a more refined approach to a more accessible, possibly larger and possibly communal systems.</p>

<p><img src="https://permapeople.org/blog/assets/veg-garden-stella-de-smit.jpg" alt="Vegetable garden by Stella de Smit"></p>

<h2 id="ingredients">Ingredients</h2>

<h3 id="requirements">Requirements</h3>

<p>This list will need to be specific to each region such a system would be rolled out in. For this system to work, we should define each required <em>_niche_</em> or <em>_zone_</em> (medicine, staple, protein, etc) as well as the <em>_method_</em> (intensive row-based or food-forest style) based on an amount of land/space available.</p>

<ul>
  <li><strong>The system should</strong> <strong><em>not</em>:</strong></li>
  <li>Be a replacement for the grocery store</li>
  <li>
    <p>Be expected to feed a whole family exclusively</p>
  </li>
  <li><strong>The system should:</strong></li>
  <li>Follow the principles of permaculture</li>
  <li>Be supplementary to regular food purchasing/foraging/consumption</li>
  <li>Be easy to set up and get rolling (beginner crops for beginners)</li>
  <li>Maintenance should decrease year-over-year</li>
  <li>Material inputs should be free and should utilize waste products (compost, greywater) whenever possible</li>
  <li>Output should increase year-over-year</li>
  <li>Be scalable and easy to replicate</li>
  <li>Be easy to substitute items based on personal preference/needs</li>
  <li>Should support a range of diets</li>
  <li>Each element should serve two or more functions</li>
</ul>

<h3 id="elements">Elements</h3>

<ol>
  <li>
    <p>Staples - Something that is substantial, and worthy of being a main course. At least 2 crops in case of failure, most often annuals</p>
  </li>
  <li>
    <p>Medicine - Teas, herbs, healthful foods. Can easily grow 3+, often perennials</p>
  </li>
  <li>
    <p>Fertilizer/Mulching - Beneficial to growth or maintenance of the entire system (preferably edible)</p>
  </li>
  <li>
    <p>Greens - Important for health, and fulfilling an important niche in western diets</p>
  </li>
  <li>
    <p>Supplementary - Snacking foods, processable foods for jams or sauces</p>
  </li>
  <li>
    <p>Protein - Most likely and accessible item is egg production, but not legal everywhere</p>
  </li>
  <li>
    <p>Surplus - For use in feeding animals, wildlife, crafting, or trading with neighbours</p>
  </li>
</ol>

<h3 id="example-system">Example system</h3>

<p>Based on my experiences living and growing in the temperate coastal rainforests (zone 7b), I’ve developed this example/conceptual list to complement the locally available forage:</p>

<ol>
  <li><strong>Staples (2+)</strong>
    <ul>
      <li>Spaghetti squash / Acorn / butternut - for its many benefits (groundcover, mulch, seed production, hardiness)</li>
      <li>Potatoes - would require creative integration if using <em>_food forest_</em> method</li>
    </ul>
  </li>
  <li><strong>Medicine (2+)</strong>
    <ul>
      <li>Mint / lemonbalm / lavender / rosemary</li>
      <li>Currants / Seabuckthorn</li>
    </ul>
  </li>
  <li><strong>Fertilizer/Mulching (1 per season)</strong>
    <ul>
      <li>Comfrey</li>
      <li>Clover / alfalfa</li>
      <li>Pigeon peas / siberian peas</li>
    </ul>
  </li>
  <li><strong>Greens (2+)</strong>
    <ul>
      <li>Arugula</li>
      <li>Kale</li>
      <li>Giant red mustard</li>
      <li>Bok choi</li>
    </ul>
  </li>
  <li><strong>Supplementary (2)</strong>
    <ul>
      <li>Cucumber</li>
      <li>Apple tree (on Pacific crab-apple stock) / currant / blueberries / strawberry / raspberry</li>
      <li>Tomatoes</li>
      <li>Chives</li>
    </ul>
  </li>
  <li><strong>Protein (either/or)</strong>
    <ul>
      <li>3x hens / ducks</li>
      <li>Chickpeas / beans</li>
    </ul>
  </li>
  <li><strong>Surplus</strong></li>
</ol>

<ul>
  <li>Double-up on at least 2 choices from above</li>
</ul>

<h2 id="other-considerations-to-be-developed-further">Other considerations (to be developed further)</h2>

<ol>
  <li>
    <p>How can we empower economically-challenged communities through the use of food sovereignty?</p>
  </li>
  <li>
    <p>What would it take to convert the average non-gardener to start growing a sufficient amount of food?</p>
  </li>
  <li>
    <p>What would it take for the average non-gardener to benefit (enough to support) from an intensive, cooperative, multi-cultured field-cropping or food forest system?</p>
  </li>
  <li>
    <p>How far can we scale such a system if it does exist?</p>
  </li>
  <li>
    <p>What are the required inputs —  like space, water, and fertilizer?</p>
  </li>
  <li>
    <p>What are the minimal outputs to make this a worthwhile endeavor?</p>
  </li>
</ol>

<h2 id="next-steps">Next steps</h2>

<p>Get creating! As they say:</p>
<blockquote>
  <p>The best time to plant a tree, is 10 years ago. The second best time is now.</p>
  <ul>
    <li>Unknown</li>
  </ul>
</blockquote>

<p>If you have any questions, or want to talk about <em>anything</em>, please reach out. And don’t forget to check out the <a href="https://permapeople.org/">plant database</a>, and create a list of your favourite candidates for your garden.</p>

<ul>
  <li>Simon 🌱✌️</li>
</ul>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/12/02/designing-and-optimizing-a-recipe-for-distributed-food-production.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441679</guid>
            <pubDate>Wed, 16 Dec 2020 12:16:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: ThinkType – Write and Search Notes at the Same Time]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25441662">thread link</a>) | @amadeuspagel
<br/>
December 16, 2020 | https://thinktype.app/resubmit | <a href="https://web.archive.org/web/*/https://thinktype.app/resubmit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thinktype.app/resubmit</link>
            <guid isPermaLink="false">hacker-news-small-sites-25441662</guid>
            <pubDate>Wed, 16 Dec 2020 12:13:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a crate for creating interactive chord diagrams in Rust]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25440590">thread link</a>) | @DataCrayon
<br/>
December 16, 2020 | https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://datacrayon.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440590</guid>
            <pubDate>Wed, 16 Dec 2020 09:31:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elderly patients 23% more likely to die if surgery is on the surgeon’s birthday]]>
            </title>
            <description>
<![CDATA[
Score 349 | Comments 204 (<a href="https://news.ycombinator.com/item?id=25440322">thread link</a>) | @whx23
<br/>
December 16, 2020 | https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-5563" role="main"><div><div><div><p>A <a href="https://www.bmj.com/content/371/bmj.m4381" target="_blank" rel="noreferrer noopener">new study has found</a> that elderly patients who underwent emergency surgery on their surgeon’s birthday had significantly higher 30-day mortality rates than patients whose surgery took place on any other day of the year. <span data-ez-name="psychnewsdaily_com-medrectangle-3"></span></p><p>The 30-day mortality rate (defined as death within 30 days after surgery)&nbsp;for the “surgeon’s birthday” group was 6.9%. This was 23% higher than the 5.6% rate for the “other day” group.</p><p>The study, which appears today in the <em>British Medical Journal</em> (<a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener">BMJ</a>),&nbsp;looked at 980,876 procedures performed in US hospitals by 47,489 surgeons.&nbsp;Of those procedures, 2,064 (0.2%) took place on a surgeon’s birthday.&nbsp;The patients were all Medicare beneficiaries aged 65 to 99. They had all undergone one of 17 common emergency surgical procedures between 2011 and 2014.</p><h2>Distractions during the most common emergency surgery types</h2><p>Examples of those 17 procedures included cardiovascular surgeries, hip and femur fracture, appendectomy, and small bowel resection. The study focused on&nbsp;emergency surgery, so as to&nbsp;minimize the potential selection bias. For example, surgeons might otherwise choose patients based on their illness severity, or patients might choose their surgeon.</p><p>As the authors write, “The effect size of surgeons’ birthday observed in our analysis (1.3 percentage point increase or a 23% increase in mortality), though substantial, is comparable to the impact of other events, including holidays (e.g., Christmas and New Year) and weekends.” <span data-ez-name="psychnewsdaily_com-medrectangle-4"></span></p><p>In fact, the <a href="https://amzn.to/3m5rimG" target="_blank" rel="noreferrer noopener">history of surgery</a> has often demonstrated that external factors can influence surgical outcomes. The authors refer to a 2014 study showing that <a href="https://pubmed.ncbi.nlm.nih.gov/23345314/" target="_blank" rel="noreferrer noopener">patients admitted to Scottish emergency rooms on&nbsp;public holidays had a 27% increase</a> in 30-day mortality.&nbsp;Other research has found, for example,&nbsp;that doctors are more likely to <a href="https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/1910546" target="_blank" rel="noreferrer noopener">prescribe antibiotics</a> and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2749268" target="_blank" rel="noreferrer noopener">opioids</a> — and <a href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2733171" target="_blank" rel="noreferrer noopener">less likely to order&nbsp;cancer screening tests</a> — as the workday progresses. This is most likely because the “cumulative cognitive demand” of such decisions gradually takes its toll.&nbsp;</p><p>Research on judges has yielded similar results. It has found, for example, that external factors as diverse as outdoor temperatures and sports results can influence judges’ decisions.&nbsp;</p><h2>A natural experiment: ER surgery on the doctor’s birthday</h2><p>But the authors say the “natural experiment” in the present study is more revealing than, for example, holiday-related mortality rates. That is because “those events not only affect physicians’ performance but also influence patients’ decision to seek care (i.e., patients seeking care on these special days might be sicker than those seeking care on other days), as well as hospital staffing.” Unless, of course, the patients know their surgeon’s birthday, which is unlikely (though that may change if this study becomes widely known).&nbsp;</p><p>The 1.3% effect size was the result after a very through series of controls. These included, for example, excluding those surgeons with the highest patient mortality rates. Other controls included assigning a random “pseudo-birthday” to surgeons to see whether the results still held up, or checking whether the surgeon did an above-average number of procedures on their birthday. <span data-ez-name="psychnewsdaily_com-box-4"></span></p><p>Likewise, the researchers controlled for “milestone” birthdays (such as 40 or 50). They also controlled for whether a birthday fell on a Friday, which might make after-work birthday festivities more likely.&nbsp;Their findings also held up when the analysis was restricted to procedures with the highest average mortality, or to only the most ill patients.&nbsp;In fact, without these adjustments, the 30-day mortality rate difference between the birthday and non-birthday groups (the unadjusted rate) was even higher (7.0% vs. 5.6%, or a 1.4% difference).</p><h2><strong>Why</strong> does emergency surgery suffer on surgeon’s birthday?</h2><p>The authors propose a few potential explanations for this “birthday effect.”&nbsp;</p><p>These include hurrying through an emergency surgery to be on time for after-work birthday events; <a href="https://www.psychnewsdaily.com/study-finds-users-not-notifications-initiate-89-of-smartphone-interactions/" target="_blank" rel="noreferrer noopener">distracting</a> birthday-related phone calls or text messages; more conversations with well-wishing staff members; and a decreased likelihood to go back to the hospital that evening if a patient’s condition deteriorates.</p><p>They also found that some surgeons did not work on their birthdays. While 2,144 surgeons in this study performed procedures one day before their birthday, and 2,027 did so one day after their birthday, only 1,805 surgeons carried out procedures on their actual birthday. This does not affect the results of the study’s analyses. But it does suggest “that birthdays are an important enough factor for some surgeons to choose not to operate on that day, which supports the credibility of our assumption that a birthday could be a distracting factor for those surgeons who choose to operate on that day,” the authors write.&nbsp;</p><h2><strong>Limitations</strong> <strong>and future directions</strong></h2><p>The researchers emphasized that this study focused on common procedures, and on older Medicare patients. This means that the findings may not apply to other types of patients, or to other surgical procedures.</p><p>Still, the authors write, these results may lead to “additional support for surgeons who have potentially distracting events,” such as birthdays, “to make sure that patients receive high quality surgical care regardless of when undergo surgery.”</p><hr><p><strong>Study: </strong>“<a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">Patient mortality after surgery on the surgeon’s birthday: observational study</a>“<br><strong>Authors:</strong> Hirotaka Kato, Anupam B. Jena, and Yusuke Tsugawa<br><strong>Published in:</strong> <a href="https://www.bmj.com/" target="_blank" rel="noreferrer noopener"><em>The BMJ</em></a><br><strong>Publication date: </strong>December 10, 2020<br><strong>DOI:</strong> <a href="https://dx.doi.org/10.1136/bmj.m4381" target="_blank" rel="noreferrer noopener">https://dx.doi.org/10.1136/bmj.m4381</a><br><strong>Photo: </strong>by&nbsp;<a href="https://pixabay.com/users/theshiv76-1022681/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Jason Shivers</a>&nbsp;from&nbsp;<a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=766166">Pixabay</a>&nbsp;</p><p>For a weekly summary of the latest psychology news, subscribe to our <a href="https://www.psychnewsdaily.com/the-psych-news-weekly-newsletter/" target="_blank" rel="noreferrer noopener">Psych News Weekly newsletter</a>.</p></div></div></div></article></div>]]>
            </description>
            <link>https://www.psychnewsdaily.com/elderly-emergency-surgery-patients-23-more-likely-to-die-if-operation-takes-place-on-surgeons-birthday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440322</guid>
            <pubDate>Wed, 16 Dec 2020 08:38:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2020-25695 Privilege Escalation in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25440088">thread link</a>) | @arkadiyt
<br/>
December 15, 2020 | https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/ | <a href="https://web.archive.org/web/*/https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<article>
  
  <div><p>It has been quite a year, I hope everyone is well and staying safe. This is my first and probably only post for the year, and covers a fun privilege escalation vulnerability I found in Postgresql. This affects all supported versions of Postgresql going back to 9.5, it is likely it affects most earlier versions as well.</p>
<p>The vulnerability is similar to a time-of-check to time-of-use (TOCTOU) issue, however in this case it relates to state not being fully cleared/reset before exiting a security restricted operation.</p>
<p>Tested versions:</p>
<ul>
<li>13.0 – PostgreSQL 13.0 (Debian 13.0-1.pgdg100+1)</li>
<li>12.4 – PostgreSQL 12.4 (Debian 12.4-1.pgdg100+1)</li>
<li>12.3 – PostgreSQL 12.3 (Debian 12.3-1.pgdg100+1)</li>
<li>11.9 – PostgreSQL 11.9 (Debian 11.9-1.pgdg90+1)</li>
</ul>
<p>Release notes and updates: <a href="https://www.postgresql.org/about/news/postgresql-131-125-1110-1015-9620-and-9524-released-2111/">https://www.postgresql.org/</a></p>

<p>I set out with the goal of finding a vulnerability which would allow an unprivileged user to elevate their privileges to that of <code>superuser</code>.</p>
<p>There are some legitimate ways to provide users with elevated persmissions in Postgresql, without giving those users full <code>superuser</code> rights. This is typically done using <code>SECURITY DEFINER</code> functions.</p>
<p>When misconfigured, a badly written <code>SECURITY DEFINER</code> function and controllable <code>search_path</code> can be used to elevate privileges (<a href="https://www.cybertec-postgresql.com/en/abusing-security-definer-functions/">Cybertec Blog</a>).</p>
<p>This functionality is explicitely called out in the Postgresql documentation in <a href="https://www.postgresql.org/docs/current/sql-createfunction.html#SQL-CREATEFUNCTION-SECURITY">how to safely write security definer functions</a>.</p>
<blockquote>
<p>Because a SECURITY DEFINER function is executed with the privileges of the user that owns it, care is needed to ensure that the function cannot be misused.</p>
</blockquote>
<p>Even though this is legitimate functionality, it still provided a good starting point, as it gave me an idea of where I should looking in the source code. Maybe there would be a way to use <code>SECURITY DEFINER</code> in another context.</p>

<p>I started off by looking into security definer functions and other locations where Postgresql switches user permissions, I noticed mention of <code>security-restricted operations</code>. This immediately triggered that spidey sense that there might be something to find in these. Out came grep and a search for locations where <code>security-restricted operations</code> are mentioned.</p>
<p>Two places where this term occurs are <code>src/backend/commands/analyze.c</code> (<code>ANALYZE</code> directive) and <code>src/backend/commands/vacuum.c</code> (<code>VACUUM</code> directive), with the same code comment in both:</p>
<pre><code>/*
* Switch to the table owner's userid, so that any index functions are run
* as that user.  Also lock down security-restricted operations and
* arrange to make GUC variable changes local to this command.
*/
</code></pre><p>This leads into the next section;</p>
<h2 id="indexes-and-functions">Indexes and Functions</h2>
<p>This seemed interesting, I didn’t know that an index could run functions. Now it was time to first figure out how to make indexes run user functions.</p>
<p>Turns out this is pretty easy to do, the <a href="https://www.postgresql.org/docs/current/sql-createindex.html">documentation</a> has a bunch of examples of indexes calling functions (even if these aren’t user defined, it shows the syntax on how to structure the sql query.)</p>
<p>For example:</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>INDEX</span> <span>ON</span> films ((<span>lower</span>(title)));
</code></pre></div><p>In this, an index is created on the <code>films</code> table, using the <code>title</code> column, cast to lowercase using the <code>lower</code> function. It should be pretty straight forward to simply supply a user created function instead of <code>lower</code>.</p>
<p>I’m skipping a few debugging steps I had to go through, but it boiled down to reading the error messages thrown when trying to use the function. The main thing to note at this point is that an <code>INDEX</code> requires an <code>IMMUTABLE</code> function, meaning the function will always return the same result for a given input. This makes sense, an <code>INDEX</code> is trying to optimise on uniqueness.</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>FUNCTION</span> sfunc(integer) 
  <span>RETURNS</span> integer
  <span>LANGUAGE</span> <span>sql</span> <span>IMMUTABLE</span> <span>AS</span>
  <span>'SELECT $1'</span>;
</code></pre></div><p>And now create a table, and an index on that table:</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>TABLE</span> blah (a int, b int);
<span>INSERT</span> <span>INTO</span> blah <span>VALUES</span> (<span>1</span>,<span>1</span>);

<span>CREATE</span> <span>INDEX</span> indy <span>ON</span> blah (sfunc(a));
</code></pre></div><p>This isn’t really helpful, I wanted a function that does something more useful, like inserting values into another table. The reason being that I wanted to retrieve the user which was executing to index function. The train of thought I had at this point was:</p>
<pre><code>create index as unpriv --&gt; privileged user executes ANALYZE/VACUUM --&gt; index function executes as privileged user 
</code></pre><p>In this scenario I was planning on using <code>SECURITY INVOKER</code> to trick Postgres into executing the function as the privileged user.</p>
<div><pre><code data-lang="sql"><span>-- create the table to insert the user into
</span><span></span><span>CREATE</span> <span>TABLE</span> t0 (s varchar);

<span>-- create the security invoker function
</span><span></span><span>CREATE</span> <span>FUNCTION</span> sfunc(integer) <span>RETURNS</span> integer
   <span>LANGUAGE</span> <span>sql</span> 
   <span>SECURITY</span> <span>INVOKER</span> <span>AS</span>
   <span>'INSERT INTO t0 VALUES (current_user); SELECT $1'</span>;
</code></pre></div><p>As mentioned earlier, the index requires an <code>IMMUTABLE</code> function. So trying to use the function in an index, would throw an error:</p>
<div><pre><code data-lang="sql">tmp<span>=#</span> <span>CREATE</span> <span>INDEX</span> indy <span>ON</span> blah (sfunc(a));
ERROR:  functions <span>in</span> <span>index</span> expression must be marked <span>IMMUTABLE</span>
</code></pre></div><p>This seemed like a dead-end. Then it occurred to me that functions can be recreated/redefined. As long as you use <code>CREATE OR REPLACE FUNCTION</code>, any existing function will be overridden. Maybe the <code>INDEX</code> doesn’t check if an assigned function has become mutable since it was initially defined (spoiler, it doesn’t!).</p>
<div><pre><code data-lang="sql"><span>CREATE</span> <span>FUNCTION</span> sfunc(integer) 
  <span>RETURNS</span> integer
  <span>LANGUAGE</span> <span>sql</span> <span>IMMUTABLE</span> <span>AS</span>
  <span>'SELECT $1'</span>;

<span>CREATE</span> <span>INDEX</span> indy <span>ON</span> blah (sfunc(a));

<span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> sfunc(integer) <span>RETURNS</span> integer
   <span>LANGUAGE</span> <span>sql</span> 
   <span>SECURITY</span> <span>INVOKER</span> <span>AS</span>
<span>'INSERT INTO t0 VALUES (current_user); SELECT $1'</span>;
</code></pre></div><p>Now when the index is run the <code>current_user</code> will be inserted into table <code>t0</code>. To check this, I switched to a privileged user (postgres) and executed the <code>ANALYZE</code> function.</p>
<div><pre><code data-lang="sql">tmp<span>=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> t0;
 s
<span>---
</span><span></span>(<span>0</span> <span>rows</span>)

tmp<span>=#</span> <span>ANALYZE</span>;
<span>ANALYZE</span>
tmp<span>=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> t0;
  s
<span>-----
</span><span></span> foo
(<span>1</span> <span>row</span>)

tmp<span>=#</span>

</code></pre></div><p>The triggering of the function worked, but we inserted the user <code>foo</code> instead of <code>postgres</code>. This means the <code>SECURITY INVOKER</code> didn’t have an effect. Looking back at the source-code comment from earlier, we can recall that a switch is done to the owner’s uid in security-restricted functions. Yay, we proven that this functionality works, sure we found a nice bypass for the <code>IMMUTABLE</code> check, but this isn’t really a security or world ender.</p>
<h2 id="ill-get-to-it-later---deferred">I’ll get to it later - deferred</h2>
<p>Diving back into the source-code, I had a look at how the security-restricted operation was entered, and subsequently exited.</p>
<p>In the <code>vacuum.c</code> file, there were some interesting comments. Maybe you can spot the bit that caught my eye immediately.</p>
<div><pre><code data-lang="c">
<span>/*
</span><span>  * Switch to the table owner's userid, so that any index functions are run
</span><span>  * as that user.  Also lock down security-restricted operations and
</span><span>  * arrange to make GUC variable changes local to this command. (This is
</span><span>  * unnecessary, but harmless, for lazy VACUUM.)
</span><span>  */</span>
GetUserIdAndSecContext(<span>&amp;</span>save_userid, <span>&amp;</span>save_sec_context);
SetUserIdAndSecContext(onerel<span>-&gt;</span>rd_rel<span>-&gt;</span>relowner,
                                            save_sec_context <span>|</span> SECURITY_RESTRICTED_OPERATION);
save_nestlevel <span>=</span> NewGUCNestLevel();

<span>// DO LOTS OF WORK
</span><span>// &lt;--- SNIP ---&gt;
</span><span></span>
<span>/* Restore userid and security context */</span>
SetUserIdAndSecContext(save_userid, save_sec_context);

<span>/* all done with this class, but hold lock until commit */</span>
<span>if</span> (onerel)
        relation_close(onerel, NoLock);

<span>/*
</span><span>  * Complete the transaction and free all temporary memory used.
</span><span>  */</span>
PopActiveSnapshot();
CommitTransactionCommand();
</code></pre></div><p>See that last comment and function calls? The <code>CommitTransactionCommand()</code> is executed after the <code>SetUserAndSecContext</code>, which resets the context userid to that of the executing user. In SQL you have transactions and a transaction isn’t final until the commit happens. This gives you room to execute some SQL, have part of it fail and then seamlessly rollback any changes to the state before the transaction was entered. The fact that in this code the user is restored before the transaction is committed made me wonder if it would be possible to sneak in some additional commands to execute before the commit is done.</p>
<p>Next ensued a long time of reading documentation and looking for ways to delay execution of SQL commands. I finally happened on <code>INITIALLY DEFERRED</code>, which held the key to unlocking this puzzle. This was part of the documentation for <a href="https://www.postgresql.org/docs/current/sql-createtrigger.html">TRIGGERS</a> which further set the spidey senses tingling.</p>
<p>What is <code>INITIALLY DEFERRED</code>?</p>
<blockquote>
<p>INITIALLY DEFERRED
The default timing of the trigger. See the CREATE TABLE documentation for details of these constraint options. This can only be specified for constraint triggers.</p>
</blockquote>
<p>Going into the <code>CREATE TABLE</code> reference you find:</p>
<blockquote>
<p>If a constraint is deferrable, this clause specifies the default time to check the constraint. If the constraint is INITIALLY IMMEDIATE, it is checked after each statement. This is the default. If the constraint is INITIALLY DEFERRED, it is checked only at the end of the transaction. The constraint check time can be altered with the SET CONSTRAINTS command.</p>
</blockquote>
<p>That sounds exactly like what we want! An initially deferred constraint is only checked at the “<em>end of the transaction</em>”. This indicated that it would happen just before the <code>commit</code> but after the security context switch.</p>
<h2 id="gymnastics">Gymnastics</h2>
<p>The next trick was to figure out how to use the constraint trigger and where this should be placed so that it triggers at the right moment.</p>
<p>Firstly, a <code>CONSTRAINT TRIGGER</code> needs a function to execute. This will be our “final” step, and should thus be executing in the privileged user context. Therefore we should insert our privileged actions into this function. The other trick is that the <code>CONSTRAINT TRIGGER</code> needs to be triggered somehow. Fortunately we’ve already got the initial bits ready. Since the index calls our custom function, which inserts into table <code>t0</code>, we have an action which will cause a constraint trigger to execute.</p>
<pre><code>Index runs --&gt; sfunc inserts into t0 --&gt; constraint trigger fires --&gt; strig function is executed
</code></pre><p>This leaves us with the following SQL:</p>
<div><pre><code data-lang="sql">
<span>CREATE</span> <span>TABLE</span> t1 (s varchar);

<span>-- create a function for inserting current user into another table
</span><span></span>
<span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> snfunc(integer) <span>RETURNS</span> integer
   <span>LANGUAGE</span> <span>sql</span> 
   <span>SECU…</span></code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/">https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/</a></em></p>]]>
            </description>
            <link>https://staaldraad.github.io/post/2020-12-15-cve-2020-25695-postgresql-privesc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25440088</guid>
            <pubDate>Wed, 16 Dec 2020 07:49:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote login is a lot like astral projection]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25439946">thread link</a>) | @samim
<br/>
December 15, 2020 | https://samim.io/p/2020-01-23-remote-login-is-a-lot-like-astral-projection/ | <a href="https://web.archive.org/web/*/https://samim.io/p/2020-01-23-remote-login-is-a-lot-like-astral-projection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <div>
        <p><b>"Remote login is a lot like astral projection."</b><br></p><div><figure>
    <img src="https://samim.io/static/upload/EOf3B6BW4AAqnZA.jpeg" alt="Remote login is a lot like astral projection">
        
</figure></div><p><a href="https://samim.io/tag/Art">#Art</a> <a href="https://samim.io/tag/Technology">#Technology</a> <a href="https://samim.io/tag/Magic">#Magic</a><br></p>
      </div>
    </div></div>]]>
            </description>
            <link>https://samim.io/p/2020-01-23-remote-login-is-a-lot-like-astral-projection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439946</guid>
            <pubDate>Wed, 16 Dec 2020 07:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research in Programming Languages (2012)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25439629">thread link</a>) | @swyx
<br/>
December 15, 2020 | http://tagide.com/blog/academia/research-in-programming-languages/ | <a href="https://web.archive.org/web/*/http://tagide.com/blog/academia/research-in-programming-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><strong>Is there still research to be done in Programming Languages?</strong> This essay touches both on the topic of programming languages and on the nature of research work. I am mostly concerned in analyzing this question in the context of Academia, i.e. within the expectations of academic programs and research funding agencies that support research work in the STEM disciplines (<span>Science, Technology, Engineering, and Mathematics</span>). This is not the only possible perspective, but it is the one I am taking here.</p>
<p><span id="more-416"></span>PLs are dear to my heart, and a considerable chunk of my career was made in that area. As a designer, there is something fundamentally interesting in designing a language of any kind. It’s even more interesting and gratifying when people actually start exercising those languages to create non-trivial software systems. As a user, I love to use programming languages that I haven’t used before, even when the languages in question make me curse every other line.</p>
<p>But the truth of the matter is that ever since I finished <a href="ftp://ftp.ccs.neu.edu/pub/people/crista/publications/thesis/index.html">my Ph.D.</a> in the late 90s, and especially since I joined the ranks of Academia, I have been having a hard time convincing myself that research in PLs is a worthy endeavor. I feel really bad about my rational arguments against it, though. Hence this essay. Perhaps by the time I am done with it I will have come to terms with this dilemma.</p>
<p>Back in the 50s, 60s and 70s, programming languages were a BigDeal, with large investments, upfront planning, and big drama on standardization committees (Ada was the epitome of that model). Things have changed dramatically during the 80s. Since the 90s, a considerable percentage of new languages that ended up being very popular were designed by lone programmers, some of them kids with no research inclination, some as a side hobby, and without any grand goal other than either making some routine activities easier or for plain hacking fun. Examples:</p>
<ul>
<li>PHP, by Rasmus Lerdorf circa 1994, “originally used for tracking visits to his online resume, he named the suite of scripts ‘Personal Home Page Tools,’ more frequently referenced as ‘PHP Tools.’ ” [<a href="http://www.php.net/manual/en/history.php.php">1</a>] PHP is a marvel of how a horrible language can become the foundation of large numbers of applications… for a second time! <a href="http://www.dreamsongs.com/RiseOfWorseIsBetter.html">Worse is Better</a> redux. According one <a href="http://langpop.com/">informal but interesting survey</a>, PHP is now the 4th most popular programming language out there, losing only to C, Java and C++.</li>
<li>JavaScript, by Brendan Eich circa 1995, “Plus, I had to be done in ten days or something worse than JS would have happened.” [<a href="http://www.jwz.org/blog/2010/10/every-day-i-learn-something-new-and-stupid/#comment-1021">2</a>] According to that same survey, JavaScript is the 5th most popular language, and I suspect it is climbing up that rank really fast. It may be #1 by now.</li>
<li>Python, by Guido van Rossum circa 1990, “I was looking for a ‘hobby’ programming project that would keep me occupied during the week around Christmas.” [<a href="http://www.python.org/doc/essays/foreword/">3</a>] Python comes at #6, and its strong adoption by scientific computing communities is well know.</li>
<li>Ruby, by Yukihiro “Matz” Matsumoto circa 1994, “I wanted a scripting language that was more powerful than Perl, and more object-oriented than Python. That’s why I decided to design my own language.” [<a href="http://linuxdevcenter.com/pub/a/linux/2001/11/29/ruby.html">4</a>] At #10 in that survey.</li>
</ul>
<p>Compare this mindset with the context in which the the older well-known programming languages emerged:</p>
<ul>
<li>Fortran, 50s, originally developed by IBM as part of their core business in computing machines.</li>
<li>Cobol, late 50s, designed by a large committee from the onset, sponsored by the DoD.</li>
<li>Lisp, late 50s, main project occupying 2 professors at MIT and their students, with the grand goal of producing an algebraic list processing language for artificial intelligence work, also funded by the DoD.</li>
<li>C, early 70s, part of the large investment that Bell Labs was doing in the development of Unix.</li>
<li>Smalltalk, early 70s, part of a large investment that Xerox did in “inventing the future” of computers.</li>
</ul>
<p>Back then, developing a language processor was, indeed, a very big deal. Computers were slow, didn’t have a lot of memory, the language processors had to be written in low-level assembly languages… it wasn’t something someone would do in their rooms as a hobby, to put it mildly. Since the 90s, however, with the emergence of PCs and of decent low-level languages like C, developing a language processor is no longer a BigDeal. Hence, languages like PHP and JavaScript.</p>
<p>There is a lot of fun in designing new languages, but this fun is not an exclusive right of researchers with, or working towards, Ph.Ds. Given all the knowledge about programming languages these days, anyone can do it. And many do. And here’s the first itchy point: <em>there appears to be no correlation between the success of a programming language and its emergence in the form of someone’s doctoral or post-doctoral work. </em>This bothers me a lot, as an academic. It appears that deep thoughts, consistency, rigor and all other things we value as scientists aren’t that important for mass adoption of programming languages. But then again, <a href="http://www.dreamsongs.com/RiseOfWorseIsBetter.html">I’m not the first to say it</a>. It’s just that this phenomenon is hard to digest, and if you really grasp it, it has tremendous consequences. If people (the potential users) don’t care about conceptual consistency, why do we keep on trying to achieve that?</p>
<p>To be fair, some of those languages designed in the 90s as side projects, as they became important, eventually became more rigorous and consistent, and attracted a fair amount of academic attention and industry investment. For example, the Netscape JavaScript hacks quickly fell on Guy Steele’s lap resulting in the <a href="http://en.wikipedia.org/wiki/ECMAScript">ECMAScript specification</a>. Python was never a hack even if it started as a Christmas hobby. Ruby is a fun language and quite elegant from the beginning. PHP… well… it’s fun for possibly the wrong reasons. But the core of the matter is that “the right thing” was not the goal. It seems that <span><em>a reliable implementation of a language that addresses an important practical need</em></span> is the key for the popularity of a programming language. But being opportunistic isn’t what research is supposed to be about… (or is it?)</p>
<p>Also to be fair, not all languages designed in the 90s and later started as side projects. For example, Java was a relatively large investment by Sun Microsystems. So was .NET later by Microsoft.</p>
<p>And, finally, all of these new languages, even when created over a week as someone’s pet project, sit on the shoulders of all things that existed before. This leads me to the second itch: <em>one striking commonality in all modern programming languages, especially the popular ones, is how little innovation there is in them</em>! Without exception, including the languages developed in research groups, they all feel like mashups of concepts that already existed in programming languages in 1979, wrapped up in their own idiosyncratic syntax. (I lied: exceptions go to aspects and monads both of which came in the 90s)</p>
<p><a href="http://tagide.com/blog/?attachment_id=544" rel="attachment wp-att-544"><img title="PLs" src="http://tagide.com/blog/wp-content/uploads/2011/09/PLs-300x225.jpg" alt="" width="300" height="225"></a>So one pertinent question is: given that not much seems to have emerged since 1979 (that’s 30+ years!), is there still anything to <em>innovate</em> in programming languages? Or have we reached the asymptotic plateau of innovation in this area?</p>
<p>I need to make an important detour here on the nature of research.</p>
<h3>&lt;Begin Detour&gt;</h3>
<p>Perhaps I’m completely off; perhaps <em>producing innovative new software</em> <em>is not a goal of [STEM] research</em>. Under this approach, any software work is dismissed from STEM pursuits, unless it is necessary for some specific goal — like if you want to study some far-off galaxy and you need an IT infrastructure to collect the data and make simulations (S for Science); or if you need some glue code for piecing existing systems together (T for Technology); or if you need to improve the performance of something that already exists (E for Engineering); or if you are a working on some Mathematical model of computation and want to make your ideas come to life in the form of a language (M for Mathematics). This is an extreme submissive view of software systems, one that places software in the back sit of STEM and that denies the existence of value in research in/by software itself. If we want to lead something on our own, let’s just… do empirical studies of technology or become biologists/physicists/chemists/mathematicians or make existing things perform better or do theoretical/statistical models of universes that already exist or that are created by others. Right?</p>
<p>I confess I have a dysfunctional relationship with this idea. Personally, I can’t be happy without creating software things, but I have been able to make my scientist-self function both as a cold-minded analyst and, at times, as an expert passenger in someone else’s research project. The design work, for me, has moved to sabbatical time, evenings and weekends; I don’t publish it [much] other than the code itself and some informal descriptions. And yet, I loathe this situation.</p>
<p>I loathe it because it’s is clear to me that software systems are something very, <em>very</em> special. Software revolutionized everything in unexpected ways, including the methods and practices that our esteemed colleagues in the “hard” sciences hold near and dear for a very long time. The evolution of information technology in the past 60 years has been _way_ off from what our colleagues thought they needed. Over and over again, software systems have been created that weren’t part of any scientific project, as such, and that ended up playing a central role in Science. Instead of trying to mimic our colleagues’ traditional practices, “computer scientists” ought to be showing the way to a new kind of science — maybe <em>that </em><a href="http://www.wolframscience.com/nksonline/page-1?firstview=1">new kind of science</a> or <a href="http://www.amazon.com/Sciences-Artificial-Herbert-Simon/dp/0262691914">that one</a> or maybe something else. I dare to suggest that the something else is related to the design of things that have software in them. It should not be called Science. It is a bit like Engineering, but it’s not it either because we’re not dealing [just] with physical things. Technology doesn’t cut it either. It needs a new name, something that denotes “the design of things with software in them.” I will call it Design for short, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://tagide.com/blog/academia/research-in-programming-languages/">http://tagide.com/blog/academia/research-in-programming-languages/</a></em></p>]]>
            </description>
            <link>http://tagide.com/blog/academia/research-in-programming-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439629</guid>
            <pubDate>Wed, 16 Dec 2020 06:10:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shell Competency and Prominent Anti-Patterns]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25439561">thread link</a>) | @jkoelndorfer
<br/>
December 15, 2020 | https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html | <a href="https://web.archive.org/web/*/https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    <p>Throughout my career, I’ve crossed paths with quite a few developers whose
chief expertise has run the gamut of programming languages: C, Python,
Java, Ruby, JavaScript, and so on. The programming language(s) in which you
build expertise undoubtedly influence the way you think about problems and
what solutions you’re likely to reach for, and they do so in a big way.
The common thread I’ve noticed, though, is that developers on average lack
competency in their operating system shell. That lack of competency often
manifests as an <em>aversion</em> to the shell.</p>
<p>You may see that a developer prefers to use point-and-click interfaces
when a shell can get the job done more quickly and with exponentially
more flexibility. You might find that they write scripts in their native
language rather than struggle with the intricacies of <code>bash</code>. At one of
my previous workplaces, I uncovered a 30 line Ruby script that could
have been replaced by one pipeline in <code>bash</code>. Yes, a single pipeline.</p>
<p>This shell aversion is a real shame, because the shell can be a very powerful
tool in one’s technical arsenal. The shell is <em>the</em> textual interface to your
computer.  Regardless of familiarity, every developer will be forced to use a
shell in some ongoing capacity. That use may be to invoke <code>git</code>, grab a quick
snapshot of what is happening in the cloud with <code>aws</code>, or start a container
with <code>docker</code> or <code>docker-compose</code>. The uses are there, and they are many.</p>
<p>Because my experience has largely been infrastructure focused, the shell is more
often a sensible tool for me to reach for than it is for other developers.
Consequently, I learned many hard lessons about shell, best practices,
patterns, and anti-patterns.</p>
<p>And that brings us to the topic at hand today. A friend sent me a blog post
claiming to implement a “safe” template for bash. Just insert your shell
into the provided blank. It’s a fairly hefty template too, weighing in at
just under 100 lines.</p>
<p>Complements of <a href="https://betterdev.blog/minimal-safe-bash-script-template/">Better Dev.blog</a>,
the template follows (note: this is the template as originally published, before any edits):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span><span>46
</span><span>47
</span><span>48
</span><span>49
</span><span>50
</span><span>51
</span><span>52
</span><span>53
</span><span>54
</span><span>55
</span><span>56
</span><span>57
</span><span>58
</span><span>59
</span><span>60
</span><span>61
</span><span>62
</span><span>63
</span><span>64
</span><span>65
</span><span>66
</span><span>67
</span><span>68
</span><span>69
</span><span>70
</span><span>71
</span><span>72
</span><span>73
</span><span>74
</span><span>75
</span><span>76
</span><span>77
</span><span>78
</span><span>79
</span><span>80
</span><span>81
</span><span>82
</span><span>83
</span><span>84
</span><span>85
</span><span>86
</span><span>87
</span><span>88
</span><span>89
</span><span>90
</span><span>91
</span><span>92
</span><span>93
</span><span>94
</span><span>95
</span><span>96
</span><span>97
</span><span>98
</span><span>99
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span>
<span>set</span> -Eeuo pipefail

<span>cd</span> <span>"</span><span>$(</span>dirname <span>"</span><span>${</span><span>BASH_SOURCE</span><span>[0]</span><span>}</span><span>"</span><span>)</span><span>"</span> &gt;/dev/null 2&gt;<span>&amp;</span><span>1</span>

<span>trap</span> cleanup SIGINT SIGTERM ERR EXIT

usage<span>()</span> <span>{</span>
  cat <span>&lt;&lt;EOF
</span><span>Usage: $(basename "$0") [-h] [-v] [-f] -p param_value arg1 [arg2...]
</span><span>
</span><span>Script description here.
</span><span>
</span><span>Available options:
</span><span>
</span><span>-h, --help      Print this help and exit
</span><span>-v, --verbose   Print script debug info
</span><span>-f, --flag      Some flag description
</span><span>-p, --param     Some param description
</span><span>EOF</span>
  <span>exit</span>
<span>}</span>

cleanup<span>()</span> <span>{</span>
  <span>trap</span> - SIGINT SIGTERM ERR EXIT
  <span># script cleanup here</span>
<span>}</span>

setup_colors<span>()</span> <span>{</span>
  <span>if</span> <span>[[</span> -t <span>2</span> <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> -z <span>"</span><span>${</span><span>NO_COLOR</span><span>-</span><span>}</span><span>"</span> <span>]]</span> <span>&amp;&amp;</span> <span>[[</span> <span>"</span><span>${</span><span>TERM</span><span>-</span><span>}</span><span>"</span> !<span>=</span> <span>"dumb"</span> <span>]]</span><span>;</span> <span>then</span>
    <span>NOCOLOR</span><span>=</span><span>'\033[0m'</span> <span>RED</span><span>=</span><span>'\033[0;31m'</span> <span>GREEN</span><span>=</span><span>'\033[0;32m'</span> <span>ORANGE</span><span>=</span><span>'\033[0;33m'</span> <span>BLUE</span><span>=</span><span>'\033[0;34m'</span> <span>PURPLE</span><span>=</span><span>'\033[0;35m'</span> <span>CYAN</span><span>=</span><span>'\033[0;36m'</span> <span>YELLOW</span><span>=</span><span>'\033[1;33m'</span>
  <span>else</span>
    <span>NOCOLOR</span><span>=</span><span>''</span> <span>RED</span><span>=</span><span>''</span> <span>GREEN</span><span>=</span><span>''</span> <span>ORANGE</span><span>=</span><span>''</span> <span>BLUE</span><span>=</span><span>''</span> <span>PURPLE</span><span>=</span><span>''</span> <span>CYAN</span><span>=</span><span>''</span> <span>YELLOW</span><span>=</span><span>''</span>
  <span>fi</span>
<span>}</span>

msg<span>()</span> <span>{</span>
  <span>echo</span> &gt;<span>&amp;</span><span>2</span> -e <span>"</span><span>${</span><span>1</span><span>-</span><span>}</span><span>"</span>
<span>}</span>

die<span>()</span> <span>{</span>
  <span>local</span> <span>msg</span><span>=</span><span>$1</span>
  <span>local</span> <span>code</span><span>=</span><span>${</span><span>2</span><span>-1</span><span>}</span> <span># default exit status 1</span>
  msg <span>"</span><span>$msg</span><span>"</span>
  <span>exit</span> <span>"</span><span>$code</span><span>"</span>
<span>}</span>

parse_params<span>()</span> <span>{</span>
  <span># default values of variables set from params</span>
  <span>flag</span><span>=</span><span>0</span>
  <span>param</span><span>=</span><span>''</span>

  <span>while</span> :<span>;</span> <span>do</span>
    <span>case</span> <span>"</span><span>${</span><span>1</span><span>-</span><span>}</span><span>"</span> in
    -h <span>|</span> --help<span>)</span>
      usage
      <span>;;</span>
    -v <span>|</span> --verbose<span>)</span>
      <span>set</span> -x
      <span>;;</span>
    --no-color<span>)</span>
      <span>NO_COLOR</span><span>=</span><span>1</span>
      <span>;;</span>
    -f <span>|</span> --flag<span>)</span> <span># example flag</span>
      <span>flag</span><span>=</span><span>1</span>
      <span>;;</span>
    -p <span>|</span> --param<span>)</span> <span># example named parameter</span>
      <span>param</span><span>=</span><span>"</span><span>${</span><span>2</span><span>-</span><span>}</span><span>"</span>
      <span>shift</span>
      <span>;;</span>
    -?*<span>)</span>
      die <span>"Unknown option: </span><span>$1</span><span>"</span>
      <span>;;</span>
    *<span>)</span>
      <span>break</span>
      <span>;;</span>
    <span>esac</span>
    <span>shift</span>
  <span>done</span>

  <span>args</span><span>=(</span><span>"</span><span>$@</span><span>"</span><span>)</span>

  <span># check required params and arguments</span>
  <span>[[</span> -z <span>"</span><span>${</span><span>param</span><span>-</span><span>}</span><span>"</span> <span>]]</span> <span>&amp;&amp;</span> die <span>"Missing required parameter: param"</span>
  <span>[[</span> <span>${#</span><span>args</span><span>[@]</span><span>}</span> -eq <span>0</span> <span>]]</span> <span>&amp;&amp;</span> die <span>"Missing script arguments"</span>

  <span>return</span> <span>0</span>
<span>}</span>

parse_params <span>"</span><span>$@</span><span>"</span>
setup_colors

<span># script logic here</span>

msg <span>"</span><span>${</span><span>RED</span><span>}</span><span>Read parameters:</span><span>${</span><span>NOCOLOR</span><span>}</span><span>"</span>
msg <span>"- flag: </span><span>${</span><span>flag</span><span>}</span><span>"</span>
msg <span>"- param: </span><span>${</span><span>param</span><span>}</span><span>"</span>
msg <span>"- arguments: </span><span>${</span><span>args</span><span>[*]-</span><span>}</span><span>"</span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>I won’t sugar coat it. There’s a <em>lot</em> wrong with this. Let’s start
from the top.</p>
<h2 id="the-airing-of-grievances">The Airing of Grievances</h2>
<h3 id="the-shebang">The Shebang</h3>
<pre><code>#!/usr/bin/env bash
</code></pre><p>In case you don’t know what a shebang is for, here’s the quick
rundown: generally, when you execute a file on your computer, it’s a raw
binary that your operating system understands and can execute natively.
Being that scripts aren’t binaries, a file starting with <code>#!</code> signals
that instead, the command that follows should be executed and the the
file path passed to the interpreter.</p>
<p>In this case, we’ve got <code>env</code> searching a user’s <code>PATH</code> and executing
<code>bash</code>. Proponents of this method would tell you that it smooths over
file system hierarchy differences between machines. That’s technically
true.</p>
<p>But there’s a big problem here: if you’re at the level of experience
where you’re copy/pasting a template, your <code>bash</code> script isn’t
going to run on any machine other than the one you wrote it on (or
other very similar systems where <code>bash</code> can be found at the same
place). Using <code>#!/usr/bin/env bash</code> as the shebang gives the
<em>misleading</em> impression that you can just take the script and
run it somewhere else. And that’s just not true unless your script does
almost nothing of interest, or you actually understand the differences
between various platforms and can account for them when writing
your script. Furthermore, as the author, you probably originally
wrote the script with the system-wide <code>bash</code> in mind - so why
shouldn’t you just use that one?</p>
<p>“But John,” you say. “When I use <code>python</code> and <code>ruby</code> and other scripting
languages, I always use <code>#!/usr/bin/env</code>.” You sure do. The difference
between <code>bash</code> and those other languages is that those other ones
have tooling built around them, like <code>pyenv</code>, <code>poetry</code>, <code>rbenv</code> and <code>bundler</code>,
to facilitate running at a non-standard location with a particular
interpreter version and collection of libraries.</p>
<p>Don’t misrepresent your script from the outset. Just use <code>#!/bin/bash</code>
unless you can actually handle running in another environment.</p>
<h3 id="the-set-smorgasbord">The <code>set</code> Smorgasbord</h3>
<pre><code>set -Eeuo pipefail
</code></pre><p>Here we’ve got a smattering of shell options that are commonly used, but
are not universal. Here’s what <code>bash</code> has to say about those options,
with irrelevant options removed for brevity:</p>
<pre><code>$ help set
      -e  Exit immediately if a command exits with a non-zero status.
      -u  Treat unset variables as an error when substituting.
      -o option-name
          Set the variable corresponding to option-name:
              pipefail     the return value of a pipeline is the status of
                           the last command to exit with a non-zero status,
                           or zero if no command exited with a non-zero status
      -E  If set, the ERR trap is inherited by shell functions.
</code></pre><p>Right off the bat, <code>set -e</code> is a giant landmine. What happens when you pipe
some text to <code>grep</code> and nothing matches? Well, <code>grep</code> exits with a non-zero
status. Oops!</p>
<p>You can work around this with an <code>if</code> statement, or slapping an <code>|| true</code>
on the end, but it creates an entirely new problem. It’s still something you
have to remember to do everywhere, but only for very few binaries.</p>
<p><code>grep</code> is not the only binary that uses its exit code informatively.
<code>terraform plan -detailed-exitcode</code>, for example, will let you know whether
the plan showed a diff or not, or if there was an error during the plan
process. In this sort of case, you’d probably want to capture the exit code
with something like <code>rc="$?"</code> immediately after so that you can deal with it
as appropriate.</p>
<p><code>set -u</code> is fine, and I would recommend it generally. That said, you’ve got to
be responsible and initialize anything you’re going expecting to get via the
environment. If you don’t, your program will bomb with a canned error message
and exit code. Your users (or future you) will appreciate a reminder regarding
expected environment variables and what their values ought to be. For example,
you might write something like:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span>
<span>set</span> -uo pipefail

<span>MY_SECRET_PASSWORD</span><span>=</span><span>${</span><span>MY_SECRET_PASSWORD</span><span>:-</span><span>}</span>

<span>if</span> <span>[[</span> -z <span>"</span><span>$MY_SECRET_PASSWORD</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>'you forgot to provide your secret password'</span> &gt;<span>&amp;</span><span>2</span>
    <span>exit</span> <span>1</span>
<span>fi</span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>I don’t take any exceptions with <code>set -o pipefail</code>.</p>
<p>The biggest problem I have with <code>set -E</code> is that its only usefulness comes
from catching unhandled errors in your script. Unhandled errors are
a deficiency with the script as written, and should be corrected. And, like
<code>set -e</code>, you run into the same sort of problem where executables
might use the exit code to communicate some information that is not
necessarily a fatal error.</p>
<h3 id="an-immediate-directory-change">An Immediate Directory Change</h3>
<p>On line 5, before any script logic has been executed, this template will
change the current directory:</p>
<pre><code>cd "$(dirname "${BASH_SOURCE[0]}")" &gt;/dev/null 2&gt;&amp;1
</code></pre><p>Want to pass the script a relative file path? Not on my watch.</p>
<p>Don’t change directories in your script unless you are ready to deal with
the consequences of that.</p>
<p>Additionally, this displays another anti-pattern: the use of <code>$BASH_SOURCE</code>.
It only works in <code>bash</code>, not in any other shell. The manual says that:</p>
<pre><code>BASH_SOURCE
    An array variable whose members are the source filenames where the
    corresponding shell function names in the FUNCNAME array variable are
    defined.  The shell function ${FUNCNAME[$i]} is defined in the file
    ${BASH_SOURCE[$i]} and called from ${BASH_SOURCE[$i+1]}.
</code></pre><p>Proponents of the use of <code>$BASH_SOURCE</code> would argue that <code>$BASH_SOURCE</code> works
both when a script is sourced and when it is executed. That is true,
but also only useful in the rarest of circumstances.</p>
<p>Sourcing functions like an include or import in other programming languages.
The sourced script is effectively inlined. Unless both the sourcing script
and sourced script are built with that in mind, you’re signing up for chaos.</p>
<p>I have been writing bash …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html">https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html</a></em></p>]]>
            </description>
            <link>https://www.johnk.io/blog/shell-competency-and-prominent-anti-patterns.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25439561</guid>
            <pubDate>Wed, 16 Dec 2020 06:00:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Being So Polarized All the Time]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25438822">thread link</a>) | @aswinmohanme
<br/>
December 15, 2020 | https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/ | <a href="https://web.archive.org/web/*/https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Remember when we used to joke around, debate about politics, have a drink afterwards and hug your  friend with a  different political view. Remember when we would switch on the news and just casually criticize whatever dumb shit both the  political parties were doing. Ahh those were the days.</p>
<p>Remember when we used to hug our friends with a slightly different political view than us. Remember when we switch on the news and make fun of whatever dumb shit those politicians were pulling of. Remember when opinions were objective and not personal.</p>
<p>Now everyone and their grandmother has a political opinion that is so well formed, so true,  that neither of them is going to entertain any counter argument. I have seen decade old friendships end, careers destroyed, families torn apart because of differing political opinions.</p>
<p>We do have faint memories  of  a time before this, where everyone didn’t make everything a part of their identity. Where you could have a reasonable discussion with someone without it ending in a fist fight. Those times are long gone, but how the hell did we arrive here.</p>

<p>There is point on the slope where shit goes downhill, and for us it was that point when Social Media appeared. Social Media in all it’s glorious forms aren’t  inherently bad, it’s when you add big data magic and billions of dollars of advertisement budget to the mix that messes everything up. Suddenly  the thing  that you use to keep tabs of your friends and family, start to keep tabs on you.</p>
<p>Advertisement has always been about attention, that’s why big billboards are lit up in the middle of the  night showing scantily clad women with legs pointing to some shit your won’t need. The sole purpose is to turn your head and to make you take notice. They don’t care who sees it, they just care a lot of us do.</p>
<p>A lot of advertisement on the early days of the internet were similar, they would put banner ads on the  most busiest sites hoping to gather the most eyeballs. It worked  like that for some time  until they  realized rather than billboards  on the side of the  road,  you could target your users. Rather than  advertising on a generic forum about the world, you could advertise on a blog about cars for your new useless engine oil. The people who would be visiting the car blog would probably be the ones who would be most interested in buying your shitty snake oil. Hence targeting was born. The ROI of Internet advertisement skyrocketed, and everyone wanted a piece of the pie.</p>
<p>Then Social Media came along with a totally different game. They started  to  track your each and every move  building up intricate profiles of you neatly kept on an offshore data-center, opening up an even better gold mine for those sleazy salesmen. Rather than waiting for someone to show up for that stupid  blog post  about that broken down car, they could put the ad for the snake oil right in the feed of a person who loves clicking on car pictures. It was all christmas  in ad town from  then on, and the companies  who had the best  tracking profiles  started swimming in money, and the ones who didn’t started dying out. (Too far ? yeah too far)</p>
<p>After spending a couple of billions and tracking every sneeze and every turn of everyone  who ever set foot in their world,  they started to  realize some thing else. The people who bought the snake oil on the first impression was not the normal person who kind  of loved cars, but the obsessed ones who believed that snake oil was the best oil in the  world and that the best way to save the world was to buy more snake oil. Those were the people that had the most ROI ever, and  the people who wore nice suits in big office buildings decided they wanted more of these obsessed fanatics, and Big Social gladly served them up on a plate.</p>
<p>But even in a large  enough population pool  the people who are obsessed about a lot of shit is really hard to find, and to keep the money flowing they needed more of them. So they did what anyone with a degree in Operations would do, they started manufacturing them.</p>
<p>Big Social realized that the people who  engage  most, who  drive the most revenue are the ones obsessed with the content. They are the most  revenue generating cattle of the ranch, and since everything is a numbers game they started to maximize obsessiveness. Well how do you manufacture people who would die for their views ? How do you manufacture obsessiveness ? Bubbles.</p>
<h2 id="enter-bubbles">Enter Bubbles</h2>
<p>The more the number of positive reinforcement that a person receives about their already existing viewpoints and the more number  of negative reinforcements they see around the opposing ones, the more likely they are to believe their beliefs are true. The more they are engrossed in their bubbles the more they are susceptible to being obsessed.</p>
<p>The  first  time we sign-up for it, they don’t know anything about us. So they ask us for our interests and to add our closest friends. Based on that they show us some generic content  based on our and  our friends interests. Then we start interacting with them, each and every interaction, each and  every pause is recorded and measured and converted  to a  data point. Initially the content is neutral, leaning just to the side  of our interests and our beliefs. The more we interact with it, the more the virtual  profile of ourselves get optimized. With our likes and shares and comments  we build an echo chamber around ourselves, with help from a  black box algorithm designed to optimize  for obsessiveness.</p>
<p>But an echo chamber doesn’t make you and obsessed radical, what makes you one is shock.</p>
<h2 id="enter-shock">Enter Shock</h2>
<p>Shock is what pushes your towards the edge of obsessiveness. Content that has high shock value are borderline impossible to believe. They rock your belief system and lingers on the edge of possibility. It’s purpose is not to make you believe the content right away, but to expand and reinforce your viewpoint so much so that you believe a little more polarized content than what you are used to. That is how you manufacture obsessiveness, that’s how your manufacture  polarization. The cycle is repeated indefinitely nudging you little by little to the edge, until you fall  o ver. Is  it  intentional or  a  byproduct  of an algorithm optimized for profit and engagement maximization is up for debate.</p>
<p>Consider me and Youtube. Like every teenager I had trouble with the ladies and like any other teenager I turned  to the internet for help. I started with dating videos, content which I  was looking for. Then slowly my recommended feed stared to show just one or two videos on how women were the problem of modern society, not enough to turn me to a believer but just enough to shock me. Having been exposed to that I started to normalize videos that bash feminism, SJW’s being owned and rants about how women are the problem. Then my feed started to get populated with  even more  anti-women and videos around red-pill and the manosphere. I am not saying these viewpoints are right or  wrong, but they were shocking  and normalized  a lot  of stuff that I would never have accepted if I was shown then from the start. After a while I started believing a lot of the what was being said, I was starting to suffocate in my own bubble. Luckily I used to read a lot outside the internet and hence had access to contrasting view points. That’s when I realized how deep in the rabbit hole I was. This prompted me to seek out alternate viewpoints and form my own opinions.  If I had kept going I would most probably have turned  into an angry fanatic thirsty for blood on the internet, shouting on some obscure forum on the edge of the internet.</p>
<p>That’s what  the algorithms are designed to do. They have the maximum engagement and attention from how obsessed their users  are. For being obsessed it’s not only vital that you  push the view point forward but also to demean and dehumanize the opposing one, so much so to the point that you believe the views that they hold are clearly wrong.  It pushes us into an us vs them mentality, where we are on right ones  and they are the wrong ones.</p>
<p>After a while we start to internalize what we interact with, it becomes a part of your identity.You start to believe the extreme content that you are exposed to as your own, you start to defend it with all your might.  You can’t entertain an  argument  because it is no  longer an argument  against your opinion,but one against  your identity. To entertain any argument is to acknowledge you are wrong and to prove everything you have interacted with for a long time to be wrong. This is  what  polarizes  us, this is what makes having a friendly conversation about opposing  views impossible in this  day and age. This is what is being done to us. We are divided  by opinions cocooned in our own bubbles, our own  echo chambers which enforce our beliefs and makes us immune to any counter  argument no matter how right or wrong.</p>
<h2 id="breaking-out">Breaking Out</h2>
<p>It’s not easy and fun getting out once you are inside. It’s like the matrix you see and hear and interact with an artificial world designed to hook you in, and like Neo it’s one hell of a ride to unplug. It’s hard but it’s possible, this is how I  did it.</p>
<ul>
<li>Clear the data that they have on you, take away the data and take away the power.</li>
<li>Humanize the opposing view points and the people who make  them. Realize they too have a valid point and that they believe it enough to defend it with all their heart.</li>
<li>Seek out alternate view points, it’s kind of a fun exercise. When you start everything looks stupid and dumb, persist and after a while you will feel a switch inside your brain, when you realize they also have a valid point.</li>
<li>Take some time off and  think deeply about everything and put together a version of the reality and form your own opinions based on them.</li>
<li>Refine those opinions  as you learn more about reality.</li>
</ul>
<p>OR</p>
<ul>
<li>Logout of all your Social Media, it’s not that useful anyway</li>
<li>Get a Flip Phone,  looks cooler than  a dumb phone</li>
<li>Life life  as  nature …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/">https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/</a></em></p>]]>
            </description>
            <link>https://aswinmohan.me/posts/stop-being-so-polarized-all-the-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438822</guid>
            <pubDate>Wed, 16 Dec 2020 03:47:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg: How my Twitter hijacks happened]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25438660">thread link</a>) | @sohkamyung
<br/>
December 15, 2020 | https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>You might recall that my Twitter account was <a href="https://daniel.haxx.se/blog/2020/11/16/i-lost-my-twitter-account/" data-type="post" data-id="15196">hijacked</a> and then <a href="https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/" data-type="post" data-id="15287">again</a> just two weeks later.</p>



<h2>The first: brute-force</h2>



<p>The  first take-over was most likely a case of brute-forcing my weak password while not having 2FA enabled. I have no excuse for either of those lapses. I had convinced myself I had 2fa enabled which made me take a (too) lax attitude to my short 8-character password that was possible to remember. Clearly, 2fa was not enabled and then the only remaining wall against the evil world was that weak password.</p>



<h2>The second time</h2>



<p>After that first hijack, I immediately changed password to a strong many-character one and I made really sure I enabled 2fa with an authenticator app and I felt safe again. Yet it would only take seventeen days until I <em><strong>again</strong></em> was locked out from my account. This second time, I could see how <em>someone had managed to change the email address</em> associated with my account (displayed when I wanted to reset my password). With the password not working and the account not having the correct email address anymore, I could not reset the password, and my 2fa status had no effect. I was locked out. Again.</p>



<p>It felt related to the first case because I’ve had my Twitter account since May 2008. I had never lost it before and then suddenly after 12+ years, within a period of three weeks, it happens twice?</p>



<h2>Why and how</h2>



<p>How this happened was a complete mystery to me. The account was restored fairly swiftly but I learned nothing from that.</p>



<p>Then someone at Twitter contacted me. After they investigated what had happened and how, I had a chat with a responsible person there and he explained for me exactly how this went down.</p>



<p>Had Twitter been hacked? Is there a way to circumvent 2FA? Were my local computer or phone compromised? No, no and no.</p>



<p>Apparently, an agent at Twitter who were going through the backlog of issues, where my previous hijack issue was still present, accidentally changed the email on my account by mistake, probably confusing it with another account in another browser tab.</p>



<p><strong>There was no outside intruder, it was just a user error.</strong></p>



<p>Okay, the cynics will say, this is what he <em>told</em> me and there is no evidence to back it up. That’s right, I’m taking his words as truth here but I also think the description matches my observations. There’s just no way for me or any outsider to verify or fact-check this.</p>



<h2>A brighter future</h2>



<p>They seem to already have identified things to improve to reduce the risk of this happening again and Michael also mentioned a few other items on their agenda that should make hijacks harder to do and help them detect suspicious behavior earlier and faster going forward. I was also happy to provide my feedback on how I think they could’ve made my lost-account experience a little better.</p>



<p>I’m relieved that the second time at least wasn’t my fault and neither of my systems are breached  or hacked (as far as I know).</p>



<p>I’ve also now properly and thoroughly gone over all my accounts on practically all online services I use and made really sure that I have 2fa enabled on them. On some of them I’ve also changed my registered email address to one with 30 random letters to make it truly impossible for any outsider to guess what I use.</p>



<p>(I’m also positively surprised by this extra level of customer care Twitter showed for me and my case.)</p>



<h2>Am I a target?</h2>



<p>I don’t think I am. I think maybe my Twitter account could be interesting to scammers since I have almost 25K followers and I have a verified account. Me personally, I work primarily with open source and most of my works is already made public. I don’t deal in business secrets. I don’t think my personal stuff attracts attackers more than anyone else does.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor.jpg" alt="" width="184" height="183" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor.jpg 471w, https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor-200x200.jpg 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/08/please-use-backdoor-450x448.jpg 450w" sizes="(max-width: 184px) 100vw, 184px"></figure></div>



<p>What about the risk or the temptation for bad guys in trying to backdoor curl? It is after all installed in some 10 <em>billion</em> systems world-wide. I’ve <a href="https://daniel.haxx.se/blog/2017/09/12/the-backdoor-threat/">elaborated on that before</a>. Summary: I think it is terribly hard for someone to actually manage to do it. Not because of the security of my personal systems perhaps, but because of the entire setup and all processes, signings, reviews, testing and scanning that are involved.</p>



<p>So no. I don’t think my personal systems are a valued singled out target to attackers.</p>



<p>Now, back to work!</p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/geralt-9301/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3319619">Gerd Altmann</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3319619">Pixabay</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/15/how-my-twitter-hijacks-happened/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438660</guid>
            <pubDate>Wed, 16 Dec 2020 03:19:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Empirical Estimates of Golden Handcuffs]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25438546">thread link</a>) | @lemonspat
<br/>
December 15, 2020 | https://applieddivinitystudies.com/handcuffs-empirical/ | <a href="https://web.archive.org/web/*/https://applieddivinitystudies.com/handcuffs-empirical/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
       <p><a href="https://applieddivinitystudies.com/handcuffs/">Last post</a>, I argued against common explanations for Golden Handcuffs.</p>
<p>Before we dive deeper, it’s worth asking, are they even real? Are employees of elite companies actually pathologically unable to leave? Is it just a stereotype with no grounding in reality?</p>
<p>Here are a variety of attempts to estimate the Golden Handcuffs effect empirically.</p>
<h3 id="YC-Founders-Join-Elite-Universities-but-Not-Elite-Companies"><a href="#YC-Founders-Join-Elite-Universities-but-Not-Elite-Companies" title="YC Founders Join Elite Universities, but Not Elite Companies"></a>YC Founders Join Elite Universities, but Not Elite Companies</h3><p>Rather than examining the psychology of employees, let’s just work backwards and count how many founders have big company experience.</p>
<p><a href="https://applieddivinitystudies.com/wilbin-rationalists/">A while back</a>, I published a dataset of the top Y Combinator founders and noticed something odd.</p>
<p>Of the 26 founders, only 1 had held a full-time role at a FAANG company. [2] Two others had worked at Facebook, but only as interns. Outside of FAANG, only 3 founders had worked at companies I recognized at all. [3]</p>
<p>One explanation is the founder-as-monomaniacal-hero. Founders are totally single minded in their devotion, and would never do something as stupid as get sidetracked by prestige or status.</p>
<p>Except that they absolutely do. Of the 26 founders, 21 attended elite universities, mostly MIT and Stanford [1]. So maybe those universities are just incredibly good at fostering entrepreneurs, but more likely, they’re just good at attracting and selecting them. I take this as evidence that founders are not allergic to jumping through conventional hoops, pursuing instrumental goods, sitting down to take the SAT and so on.</p>
<p>It gets weirder when you consider population sizes. Google has around 100,000 employees, whereas MIT and Stanford undergrad programs are just 11,500 combined! And since average tenure at Google is under 4 years, each unit of headcount produces more alumni than a full degree program. [4]</p>
<p>All else equal, we should expect to sample many more founders from Google than from elite universities, but this doesn’t seem to be the case.</p>
<p>What’s going on?</p>
<h3 id="Golden-Handcuffs-as-Selection-Effects"><a href="#Golden-Handcuffs-as-Selection-Effects" title="Golden Handcuffs as Selection Effects"></a>Golden Handcuffs as Selection Effects</h3><p>One explanation is that there are no golden handcuffs and it’s all selection effects. The kinds of people who work for Google are the ones who never intended to leave in the first place. The kinds of people who want to start great companies don’t have any interest in working for somebody else.</p>
<p>This is a reasonable explanation, but applies to less than half of the founders I looked at.</p>
<p>Only 11 of the 26 founders started a company right out of school. 14 have confirmed work experience, and another 2 have scrubbed the employment history, but have long gaps between graduating from school and founding their company.</p>
<p>Maybe working for a small startup shows that you’re less risk averse than a Google employee, but I don’t totally buy this. Brandon Leonardo (Instacart) worked at <a target="_blank" rel="noopener" href="https://www.linkedin.com/company/webs/">Webs</a>, a company I’ve never heard of that claims to make “small business marketing simple”. Dan Kan (Cruise) worked at <a target="_blank" rel="noopener" href="https://www.linkedin.com/company/uservoice/">UserVoice</a>, “the leading product feedback management software”. What exactly do these experiences select for?</p>
<p>In contrast, if you do want to start a company, working at Google seems like a great first step! You can meet co-founders and potential early employees, save money to fund yourself, gain legitimacy for investors and so on.</p>
<p>Of course, it’s possible the kinds of people who think about “gaining legitimacy for investors” are not going to start great companies. Maybe “real founders” don’t pursue instrumental goods.</p>
<h3 id="A-Third-Perspective-Ex-Google-Founded-Companies"><a href="#A-Third-Perspective-Ex-Google-Founded-Companies" title="A Third Perspective: Ex-Google Founded Companies"></a>A Third Perspective: Ex-Google Founded Companies</h3><p>We’ve been dancing around the issue, but why not just go straight to the source and look at outcomes for the population we care about?</p>
<p>Are Google employees actually bad at starting companies?</p>
<p>Looking directly at startups founded by ex-Google employees valued over a billion dollars, we get:</p>
<ul>
<li>Nutanix $5.8B</li>
<li>Cohesity $2.5B</li>
<li>Asana $4.3B</li>
<li>Lucidchart $1B+</li>
<li>Rubrik $3.3B</li>
<li>Instagram (sold for $1B, valued at $100B in 2018)</li>
<li>Pinterest $43B</li>
<li>Flatiron Health $1.9B</li>
<li>Xiaomi $46B</li>
<li>Affirm $2.9B</li>
</ul>
<p>That’s a super impressive list! It doesn’t seem like ex-Google employees are bad at starting companies and pathologically incapable of quitting their jobs. Instead, the oddity is merely that they don’t attend Y Combinator.</p>
<p>That’s a different skew, and much easier to explain. Unlike regular YC founders, ex-Google employees may just be:</p>
<ul>
<li>So wealthy that they self-fund until they can raise a Series A and aren’t willing to sell 7% of their company for $125k.</li>
<li>So tired of bureaucracy that they refuse to join an accelerator.</li>
<li>So credentialed that they don’t feel a need to go through Y Combinator to gain further credibility.</li>
<li>So well connected that they raise a Series A without going through Y Combinator.</li>
</ul>
<p>Whatever the explanation, the fact remains that ex-Google employees do in fact leave to start companies.</p>
<h3 id="Adjustments-and-Proportionality"><a href="#Adjustments-and-Proportionality" title="Adjustments and Proportionality"></a>Adjustments and Proportionality</h3><p>Of course, we now have to ask if they do so proportionally. Even if Google has produced the founders of nearly a dozen billion dollar companies, we shouldn’t be impressed until we’re confident that they’re actually hitting above their weight.</p>
<p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/List_of_unicorn_startup_companies">Wikipedia lists</a> 495 startups worth over a billion dollars, putting Google at 2%. But if you only include US based startups, Google is at 9 out of 122, or 7%.</p>
<p>To figure out the appropriate reference class, we’ll start with the number of software engineers in the US (4 million), then identify how many ex-Google employees there were 10 years ago when most of these founders started their companies.</p>
<p><a target="_blank" rel="noopener" href="https://medium.com/gabor/timeline-employee-count-growth-for-microsoft-yahoo-google-and-facebook-9ede22a37824">A partner at google</a> has compiled and released <a target="_blank" rel="noopener" href="https://docs.google.com/spreadsheets/d/1L0M0u0-C_LoFrGLw0H-9nkgN9wqUhl4bUTcVI0fDZuU/edit#gid=793191479">historical headcount data</a>. This is a good starting point, but remember that we’re actually interested in the total alumni population rathern than point-in-time headcount.</p>
<p>To make this estimate, I assume 3 year average tenure and run a simplified simulation where 33% of the workforce quits at the end of each year, then Google rehires up to next year’s headcount. </p>
<p>Running this simulation from 2000 to 2010, we get that there were 50,000 ex-Google employees in 2010. They’ve <a target="_blank" rel="noopener" href="https://www.quora.com/How-many-software-engineers-does-Google-have">previously said the workforce is 40% technical</a>, so that’s equivalent to 20,000 engineers. [5]</p>
<p>Pitting that against the 4 million software engineers in the US [6], we get that ex-Google engineers were around 0.5% of the relevant population, but started 7% of the US based billion dollar startups. That’s a mulitple of 14x, and fairly good evidence that Google employees are not particularly bad at starting companies. [7]</p>
<h3 id="Conclusion"><a href="#Conclusion" title="Conclusion"></a>Conclusion</h3><p>Taking a step back, recall that what we’re actually curious about is not whether Google engineers are disproportionately successful at starting companies, but whether they even try in the first place. In other words, do they appear irrationally bound by Golden Handcuffs?</p>
<p>Compared to a randomly selected US based engineer, Google engineers have all sorts of benefits. They’re well credentialed, well connected, largely based in Silicon Valley, and supposedly smarter than average.</p>
<p>It’s entirely possible that their success rate is 140x that of a typical engineer, but they only try one tenth as often. The fact that Google engineers start successful companies doesn’t preclude the possibility that Golden Handcuffs are holding them back.</p>
<p>Further, consider that “rationality” in this case is really a function of both odds of success and opportunity cost. Even if Google engineers are less likely to start companies, it could be a perfectly reasonable choice given their relatively high opportunity cost.</p>
<p>So at the end of the day, the empirical data tells us a few interesting things, but can’t present a decisive conclusion.</p>
<hr>
<p>[1] The other universities I count as “elite” are:</p>
<ul>
<li>RISD</li>
<li>Joint RISD/MIT</li>
<li>2 x Harvard</li>
<li>University of Waterloo</li>
<li>Berkeley, Columbia MBA</li>
</ul>
<p>The ones I don’t include are:</p>
<ul>
<li>USD</li>
<li>San Jose State University</li>
<li>Rice</li>
<li>Duke</li>
<li>Claremont McKenna College</li>
</ul>
<p>I do include 4 founders who attended Stanford for grad school, but did not attend an elite undergraduate institution.</p>
<p>[2] Apoorva Mehta of Instacart spent 2 years at Amazon.</p>
<p>[3] Tony Xu of DoorDash was an intern at Square, and worked full time at McKinsey for 2 years, and eBay for another 2. Fred Ehrsam of Coinbase had spent 2 years at Goldman Sachs. Brian Armstrong of same had interned at IBM and Deloitte, then spent a year at Airbnb. Though notably, this was in May 2011, back when Airbnb was a small Series A startup with under $10 million in total funding.</p>
<p>[4] This ends up being a bit complicated. Reportedly, Google has an average tenure of 3.2 years with a median of 1.1. This is possible, but odd, and I’m not sure how they got these numbers. It’s tricky because at any given time, some population of employees has not left and you don’t know how long they’ll stay. If you count their tenure as their tenure-to-date, you’re undercounting how long they’ll actually end up staying. If you only count employees who have left, you’re skewed toward employees with short tenure. Also, Google has grown over the years, and we’re looking at founders who are successful now but started out 10 years ago when Google was around 25,000 employees.</p>
<p>[5] Data <a target="_blank" rel="noopener" href="https://docs.google.com/spreadsheets/d/1FeDDGo_SWeDMMZlTrJ_P2TifyJoOqAuOD8klBKQpUdA/edit?usp=sharing">here</a>. And yes, it’s possible the proportion of engineers has changed over time and this analysis is off.</p>
<p>This also helps explain why there are relatively so many founders from top universities. In the same 10 year time span, Stanford and MIT undergrad graduated around 115,000 alumni.</p>
<p>[6] Maybe we should be looking at the number of people who have been software engineers from 2000 to 2010 including retirements, and this number is actually higher. Assuming 40 year careers, and a constantly total number of engineers, it should be something like 25% higher, and Google is proportionately 25% better than it appears in the main text.</p>
<p>[7] There are lots of over corrections you could apply here, so don’t take this too literally. Maybe the relevant population is all people, not just engineers. In that case, Google ends up looking way better since the general population is much less than 40% engineers. </p>
 
    </div></div>]]>
            </description>
            <link>https://applieddivinitystudies.com/handcuffs-empirical/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438546</guid>
            <pubDate>Wed, 16 Dec 2020 03:01:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minesweeper in 3D]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25438365">thread link</a>) | @cow9
<br/>
December 15, 2020 | http://egraether.com/mine3d/ | <a href="https://web.archive.org/web/*/http://egraether.com/mine3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://egraether.com/mine3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438365</guid>
            <pubDate>Wed, 16 Dec 2020 02:37:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Tale of Static Devirtualization Vol. I: The Lift]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25438149">thread link</a>) | @from
<br/>
December 15, 2020 | https://0xnobody.github.io/devirtualization-intro/ | <a href="https://web.archive.org/web/*/https://0xnobody.github.io/devirtualization-intro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
  
  <time datetime="2020-05-20T00:00:00+00:00">May 20, 2020</time>
</header>

  <blockquote>
  <p>This article is the result of my latest obsession with software virtualization. After years of just skipping virtualized routines, I was finally inspired by <a href="https://blog.can.ac/" target="_blank">Can</a> and started work on this complex topic. What ensued was months of reverse engineering, functional programming, and a LOT of learning. Now that I finally feel comfortable publishing some information on the things I learned in the process, I present unto you the first installment in my devirtualization series, focusing on how virtualization works and the methodology of how we can lift a VM. The aim of this series is to tear down the curtains behind virtualization and hopefully inspire more reverse engineers to research this interesting topic!</p>
</blockquote>

<h2 id="preface">Preface</h2>

<p>Over the last 10 years or so, virtualization based obfuscation has become the de-facto standard in defensive and offensive software alike. As the complexity and power of disassembling tools has improved, software security solutions have kept up rather well. Packers and code mutation tools, being easily defeated by even newbie attackers, have been replaced by these virtual machine based protectors. Today, the two main ‘pioneers’ in this field, controlling the vast majority of the market are <a href="https://vmpsoft.com/" target="_blank">VMProtect</a> and <a href="https://www.oreans.com/" target="_blank">Themida</a>. While we will be looking into analyzing (and breaking) them specifically in some future articles, today we’ll just be looking into how we can lift <em>any</em> VM into <a href="https://blog.can.ac/" target="_blank">Can</a>’s promising <a href="https://vtil.io/" target="_blank">VTIL</a>.</p>

<h2 id="but-first-what-actually-is-virtualization">But first, what actually is virtualization?</h2>
<p>Virtualization is the <strong>recompilation</strong> of instructions to a <strong>custom proprietary architecture</strong>, and the generation of <strong>handler routines</strong> to emulate said architecture. Let’s look at an example of the life of just one simple instruction, <code>push rcx</code>:</p>

<table>
  <thead>
    <tr>
      <th><img src="https://0xnobody.github.io/assets/virtualization-1/vm-flowchart.png" alt="alt text" title="Life of a push rcx instruction"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>The mystical adventure <code>push rcx</code> undertakes when you press ‘Protect’</em></td>
    </tr>
  </tbody>
</table>

<p>The <code>push rcx</code> instruction is decoded, and interpreted by the virtualizer. A handler is generated (or fetched, if it has already been generated and is being reused), which is responsible for executing this instruction in a way that the CPU understands. In our example, I called this handler <code>VPUSH</code> just for explanation’s sake, but obviously they don’t come with names attached to them.</p>

<p>Following this, a ‘virtual instruction’ is then assembled, which contains bytes to identify its handler (in this case, just a table offset) and any operands that are needed for execution. You can see in the diagram above, that the bytes corresponding to the instruction’s <strong>handler offset</strong> are in <strong>green</strong>, whereas the ones corresponding to the <strong>operand</strong> (ie. the <strong>target register</strong>) are in <strong>blue</strong>. This is also reflected in the handler with the corresponding colours.</p>

<p>It’s worth noting, that on handler execution, the virtual instruction pointer (VIP) actually points to the beginning of the <strong>blue</strong> operand bytes. This is because the previous handler has to read (and consume) the next handler’s offset in order to pass control over to it.</p>

<p>Anyways, let’s take a closer look at this <code>VPUSH</code> handler:</p>

<div><div><pre><code><span>movzx</span> <span>rax</span><span>,</span> <span>word</span> <span>ptr</span> <span>[rbp]</span> 
<span>; - rbp is the virtual instruction pointer (VIP) in this case, which contains the pushed register (blue)</span>
<span>; - the pushed register is fetched and stored in ax. In our case this is 0x30</span>

<span>mov</span> <span>rax</span><span>,</span> <span>[</span><span>rsi</span> <span>+</span> <span>rax</span><span>]</span> 
<span>; - rsi is the virtual context; it holds each of the virtual registers. Think of a CONTEXT structure on </span>
<span>; windows.</span>
<span>; - the lower word in rax holds the register offset in the context. The register is fetched from the</span>
<span>; context and stored in rax.</span>

<span>push</span> <span>rax</span>
<span>; - the stored register is pushed to the stack.</span>

<span>movzx</span> <span>rdx</span><span>,</span> <span>word</span> <span>ptr</span> <span>[</span><span>rbp</span><span>+</span><span>0x2</span><span>]</span>
<span>mov</span> <span>rdx</span><span>,</span> <span>[</span><span>rdi</span><span>+</span><span>rdx</span><span>]</span>
<span>; - VIP + 0x2 contains the next handler's offset (green). It is fetched and stored in rdx</span>
<span>; - rdi is the handler table base. The next handler is fetched by offseting it by rdx and storing the</span>
<span>; handler address</span>

<span>add</span> <span>rbp</span><span>,</span> <span>0x4</span>
<span>; - the instruction pointer is incremented by the size of bytes consumed</span>

<span>jmp</span> <span>rdx</span>
<span>; - jump to the next handler, held by rdx, to execute the next instruction's handler</span>
<span>; - the execution loop continues...</span>
</code></pre></div></div>

<p>Virtual machines are basically just very <strong>very</strong> long chains of these handlers, each doing quite rudimentary operations.
It must be said, however, that the example I gave above is an extremely simple one. Modern virtualizers have integrated encryption and obfuscation techniques, and some feature quite advanced custom architectures. Many stray far away from the x86 instruction set to make the analyst’s life harder.</p>

<p>Well, how does this impact analysis, you ask? Well, since you’re reading this article, you must already know ;)
But to name a few:</p>
<ul>
  <li>The original instructions are lost, forever. Only the behaviour is retained, in a proprietary, usually randomized architecture. For example, even after full devirtualization, we can’t for 100% say that the original register used for the push is <code>rcx</code>.</li>
  <li>The VM’s architecture can differ significantly from the original. For example, a single VM instruction could push 3 registers, exchange 2 registers, and write to one register. All in a <em>single</em> virtual instruction!</li>
  <li>Other obfuscation techniques (such as mutation) can now be applied on both the host level (real x86 instructions executing on the PC) and on the guest level (the virtual instructions represented by the handlers).</li>
  <li>Control flow is in most cases highly obscured. Often conditional jumps are manually emulated. This makes tracking basic blocks difficult.</li>
  <li>The VM cannot be statically analyzed in tools like IDA, as it does not function like a conventional program.</li>
</ul>

<p>Needless to say, virtualization is an extremely powerful and effective software protection method.</p>

<h2 id="lets-break-it">Let’s break it!</h2>
<p>In order to break and reverse this protection, we really just need to do three things: gather information in order to determine exactly what each handler does in which order, somehow convert this information into a language that the CPU and disassemblers understand (in our case, x86), and then finally repackage the binary.
This is called <em>lifting</em>, <em>translation</em>, and <em>repackaging</em> respectively, and it is what needs to be done to devirtualize any VM.
Today, we’re just gonna be looking at <em>lifting</em> in particular.</p>

<h2 id="lifting">Lifting</h2>
<p>The dictionary definition for lifting is “raise to a higher position or level”. This is entirely true. We are performing analyis on the virtual routines, in order to determine what each handler does on the instruction level, and then converting this information into a higher level, easy-to-understand representation. This is done in a few steps.</p>

<h3 id="navigation">Navigation</h3>

<table>
  <thead>
    <tr>
      <th><img src="https://0xnobody.github.io/assets/virtualization-1/virt-starter-pack.png" alt="alt text" title="Ha ha xd"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>After analyzing VMs for a few hours (or days), you do begin to notice certain things.</em></td>
    </tr>
  </tbody>
</table>

<p>Before we can perform any handler analysis, we must first be able to navigate our way around the VM. Although this step varies greatly for each VM, certain parts always remain the same.</p>
<ul>
  <li>Every VM routine must begin by saving the value of each register, usually by pushing them to the stack. This is done because the VM needs to use the registers to run its handlers, and it must restore the registers after exiting the VM.</li>
  <li>Each VM must also have some sort of context structure. This is where current executing information about the VM is held, such as register values. It can easily be identified as it is accessed very often in every handler.</li>
  <li>Each VM must have an instruction pointer (VIP) used to determine which handler to execute next and to provide that handler with operands. It is also easy to identify, as it much be adjusted after each handler.</li>
  <li>Many VMs have some sort of stack representation. For example, VMProtect uses a nominated register to access the stack, whereas Themida just uses RSP.</li>
  <li>Code flow must somehow be passed from one handler to the next. This can just be an index in a handler table, an offset to some point in the code, or something entirely different. It is worth noting that the next handler <em>must</em> be computed from the VIP.</li>
</ul>

<p>In order to properly analyze and decode each handler, we must be able to follow the VM’s execution. We must follow the VM’s <em>fetch-&gt;decode-&gt;execute</em> loop, so we are able to determine which handler will be executed next. Once the basics of the VM are reversed and we can step through the handler instructions, the next step is to identify these handlers.</p>

<h3 id="identification">Identification</h3>
<p>Now we need to determine what each handler does. We can achieve this via <em>pattern matching</em> the instructions. Of course, we must remember to keep these patterns balanced, ensuring we match all the relevant instructions but make them generic enough so that we can match with all instances of the handler.</p>

<p><em>Pattern matching</em> is quite a generic method, and can be used in various different flavours alongside many other algorithms depending on the complexity of the VM. But in this example we’re gonna take it easy, and just look at a simple forward matching algorithm. This allows us to specify the patterns we want to match, and the order we want to match them in.</p>

<p>Let’s use the above <code>push</code> handler as an example:</p>

<div><div><pre><code><span>// this class contains templates to pattern match against</span>
<span>//</span>
<span>auto</span> <span>matcher</span> <span>=</span> <span>new</span> <span>pattern_matcher</span><span>(</span><span>stream</span><span>);</span>

<span>// these are the constant registers</span>
<span>// they are hardcoded here for simplicity's sake</span>
<span>//</span>
<span>x86_reg</span> <span>vip_reg</span> <span>=</span> <span>X86_REG_RBP</span><span>;</span>
<span>x86_reg</span> <span>vcontext_reg</span> <span>=</span> <span>X86_REG_RSI</span><span>;</span>

<span>// these values will be set as the patterns are found</span>
<span>// they allow us to ensure that the same register is used for more than one pattern</span>
<span>// they also allow us to retrieve specific information about the handler eg. operand sizes</span>
<span>//</span>
<span>x86_reg</span> <span>pushed_reg_idx_reg</span> <span>=</span> <span>X86_REG_INVALID</span><span>;</span>
<span>uint64_t</span> <span>pushed_reg_idx_offs</span> <span>=</span> <span>-</span><span>1</span><span>;</span>

<span>x86_reg</span> <span>pushed_reg</span> <span>=</span> <span>X86_REG_INVALID</span><span>;</span>
 
<span>auto</span> <span>result</span> <span>=</span> <span>matcher</span>
    <span>// match for `mov %0, [%vip + %1]`</span>
    <span>// %0 is written to pushed_reg_idx_reg, %1 is written to pushed_reg_idx_offs</span>
    <span>//</span>
    <span>-&gt;</span><span>mov_reg_mem</span><span>(</span><span>&amp;</span><span>pushed_reg_idx_reg</span><span>,</span> <span>&amp;</span><span>vip_reg</span><span>,</span> <span>&amp;</span><span>pushed_reg_idx_offs</span><span>)</span>

    <span>// match for `mov %2, [%ctx + %0]`</span>
    <span>// %2 is written to pushed_reg</span>
    <span>//</span>
    <span>-&gt;</span><span>mov_reg_mem_idx</span><span>(</span><span>&amp;</span><span>pushed_reg</span><span>,</span> <span>&amp;</span><span>vcontext_reg</span><span>,</span> <span>&amp;</span><span>pushed_reg_idx</span><span>)</span>
    
    <span>// match for `push %2`</span>
    <span>//</span>
    <span>-&gt;</span><span>push_reg</span><span>(</span><span>&amp;</span><span>pushed_reg</span><span>)</span>

<span>if</span> <span>(</span><span>result</span><span>)</span>
    <span>// matched - the handler is `push`</span>
<span>else</span>
    <span>// not matched - …</span></code></pre></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0xnobody.github.io/devirtualization-intro/">https://0xnobody.github.io/devirtualization-intro/</a></em></p>]]>
            </description>
            <link>https://0xnobody.github.io/devirtualization-intro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25438149</guid>
            <pubDate>Wed, 16 Dec 2020 02:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyTorch Quantization Aware Training]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25437855">thread link</a>) | @keyboardman
<br/>
December 15, 2020 | https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Static quantization allows the user to generate quantized integer model that is highly efficient during inference. However, sometimes, even with careful post-training calibration, the model accuracies might be sacrificed to some extent that is not acceptable. If this is the case, post-training calibration is not sufficient to generate a quantized integer model. We would have train the model in a way so that the quantization effect has been taken into account. Quantization aware training is capable of modeling the quantization effect during training.</p>



<p>The mechanism of quantization aware training is simple, it places fake quantization modules, i.e., quantization and dequantization modules, at the places where quantization happens during floating-point model to quantized integer model conversion, to simulate the effects of clamping and rounding brought by integer quantization. The fake quantization modules will also monitor scales and zero points of the weights and activations. Once the quantization aware training is finished, the floating point model could be converted to quantized integer model immediately using the information stored in the fake quantization modules.</p>



<p>In this blog post, I would like to show how to use PyTorch to do quantization aware training. More details about the mathematical foundations of quantization for neural networks could be found in my article <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">â€œQuantization for Neural Networksâ€�</a>.</p>

<h3 id="pytorch-quantization-aware-training">PyTorch Quantization Aware Training</h3>

<p>Unlike TensorFlow 2.3.0 which supports integer quantization using arbitrary bitwidth from 2 to 16, PyTorch 1.7.0 only supports 8-bit integer quantization. The workflow could be as easy as loading a pre-trained floating point model and apply a quantization aware training wrapper. However, without doing layer fusion, sometimes such kind of easy manipulation would not result in good model performances.</p>



<p>In this case, I will also use the ResNet18 from <a href="https://pytorch.org/docs/stable/torchvision/models.html">TorchVision models</a> as an example. All the steps prior, to the quantization aware training steps, including layer fusion and skip connections replacement, are exactly the same as to the ones used in <a href="https://leimao.github.io/blog/PyTorch-Static-Quantization/">â€œPyTorch Static Quantizationâ€�</a>. The source code could also be downloaded from <a href="https://github.com/leimao/PyTorch-Quantization-Aware-Training">GitHub</a>.</p>



<p>The quantization aware training steps are also very similar to post-training calibration:</p>

<ol>
  <li>Train a floating point model or load a pre-trained floating point model.</li>
  <li>Move the model to CPU and switch model to training mode.</li>
  <li>Apply layer fusion.</li>
  <li>Switch model to evaluation mode, check if the layer fusion results in correct model, and switch back to training mode.</li>
  <li>Apply <code>torch.quantization.QuantStub()</code> and <code>torch.quantization.QuantStub()</code> to the inputs and outputs, respectively.</li>
  <li>Specify quantization configurations, such as symmetric quantization or asymmetric quantization, etc.</li>
  <li>Prepare quantization model for quantization aware training.</li>
  <li>Move the model to CUDA and run quantization aware training using CUDA.</li>
  <li>Move the model to CPU and convert the quantization aware trained floating point model to quantized integer model.</li>
  <li>[Optional] Verify accuracies and inference performance gain.</li>
  <li>Save the quantized integer model.</li>
</ol>

<p>The quantization aware training script is very similar to the one used in <a href="https://leimao.github.io/blog/PyTorch-Static-Quantization/">â€œPyTorch Static Quantizationâ€�</a>:</p>

<div><div><pre><code><span># cifar.py
</span>
<span>import</span> <span>os</span>
<span>import</span> <span>random</span>

<span>import</span> <span>torch</span>
<span>import</span> <span>torch.nn</span> <span>as</span> <span>nn</span>
<span>import</span> <span>torch.optim</span> <span>as</span> <span>optim</span>
<span>import</span> <span>torchvision</span>
<span>from</span> <span>torchvision</span> <span>import</span> <span>datasets</span><span>,</span> <span>transforms</span>

<span>import</span> <span>time</span>
<span>import</span> <span>copy</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>from</span> <span>resnet</span> <span>import</span> <span>resnet18</span>

<span>def</span> <span>set_random_seeds</span><span>(</span><span>random_seed</span><span>=</span><span>0</span><span>):</span>

    <span>torch</span><span>.</span><span>manual_seed</span><span>(</span><span>random_seed</span><span>)</span>
    <span>torch</span><span>.</span><span>backends</span><span>.</span><span>cudnn</span><span>.</span><span>deterministic</span> <span>=</span> <span>True</span>
    <span>torch</span><span>.</span><span>backends</span><span>.</span><span>cudnn</span><span>.</span><span>benchmark</span> <span>=</span> <span>False</span>
    <span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>random_seed</span><span>)</span>
    <span>random</span><span>.</span><span>seed</span><span>(</span><span>random_seed</span><span>)</span>

<span>def</span> <span>prepare_dataloader</span><span>(</span><span>num_workers</span><span>=</span><span>8</span><span>,</span> <span>train_batch_size</span><span>=</span><span>128</span><span>,</span> <span>eval_batch_size</span><span>=</span><span>256</span><span>):</span>

    <span>train_transform</span> <span>=</span> <span>transforms</span><span>.</span><span>Compose</span><span>([</span>
        <span>transforms</span><span>.</span><span>RandomCrop</span><span>(</span><span>32</span><span>,</span> <span>padding</span><span>=</span><span>4</span><span>),</span>
        <span>transforms</span><span>.</span><span>RandomHorizontalFlip</span><span>(),</span>
        <span>transforms</span><span>.</span><span>ToTensor</span><span>(),</span>
        <span># transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
</span>        <span>transforms</span><span>.</span><span>Normalize</span><span>(</span><span>mean</span><span>=</span><span>(</span><span>0.485</span><span>,</span> <span>0.456</span><span>,</span> <span>0.406</span><span>),</span> <span>std</span><span>=</span><span>(</span><span>0.229</span><span>,</span> <span>0.224</span><span>,</span> <span>0.225</span><span>))</span>
    <span>])</span>

    <span>test_transform</span> <span>=</span> <span>transforms</span><span>.</span><span>Compose</span><span>([</span>
        <span>transforms</span><span>.</span><span>ToTensor</span><span>(),</span>
        <span># transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
</span>        <span>transforms</span><span>.</span><span>Normalize</span><span>(</span><span>mean</span><span>=</span><span>(</span><span>0.485</span><span>,</span> <span>0.456</span><span>,</span> <span>0.406</span><span>),</span> <span>std</span><span>=</span><span>(</span><span>0.229</span><span>,</span> <span>0.224</span><span>,</span> <span>0.225</span><span>))</span>
    <span>])</span>

    <span>train_set</span> <span>=</span> <span>torchvision</span><span>.</span><span>datasets</span><span>.</span><span>CIFAR10</span><span>(</span><span>root</span><span>=</span><span>"data"</span><span>,</span> <span>train</span><span>=</span><span>True</span><span>,</span> <span>download</span><span>=</span><span>True</span><span>,</span> <span>transform</span><span>=</span><span>train_transform</span><span>)</span> 
    <span># We will use test set for validation and test in this project.
</span>    <span># Do not use test set for validation in practice!
</span>    <span>test_set</span> <span>=</span> <span>torchvision</span><span>.</span><span>datasets</span><span>.</span><span>CIFAR10</span><span>(</span><span>root</span><span>=</span><span>"data"</span><span>,</span> <span>train</span><span>=</span><span>False</span><span>,</span> <span>download</span><span>=</span><span>True</span><span>,</span> <span>transform</span><span>=</span><span>test_transform</span><span>)</span>

    <span>train_sampler</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>RandomSampler</span><span>(</span><span>train_set</span><span>)</span>
    <span>test_sampler</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>SequentialSampler</span><span>(</span><span>test_set</span><span>)</span>

    <span>train_loader</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>DataLoader</span><span>(</span>
        <span>dataset</span><span>=</span><span>train_set</span><span>,</span> <span>batch_size</span><span>=</span><span>train_batch_size</span><span>,</span>
        <span>sampler</span><span>=</span><span>train_sampler</span><span>,</span> <span>num_workers</span><span>=</span><span>num_workers</span><span>)</span>

    <span>test_loader</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>DataLoader</span><span>(</span>
        <span>dataset</span><span>=</span><span>test_set</span><span>,</span> <span>batch_size</span><span>=</span><span>eval_batch_size</span><span>,</span>
        <span>sampler</span><span>=</span><span>test_sampler</span><span>,</span> <span>num_workers</span><span>=</span><span>num_workers</span><span>)</span>

    <span>return</span> <span>train_loader</span><span>,</span> <span>test_loader</span>

<span>def</span> <span>evaluate_model</span><span>(</span><span>model</span><span>,</span> <span>test_loader</span><span>,</span> <span>device</span><span>,</span> <span>criterion</span><span>=</span><span>None</span><span>):</span>

    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>running_loss</span> <span>=</span> <span>0</span>
    <span>running_corrects</span> <span>=</span> <span>0</span>

    <span>for</span> <span>inputs</span><span>,</span> <span>labels</span> <span>in</span> <span>test_loader</span><span>:</span>

        <span>inputs</span> <span>=</span> <span>inputs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>labels</span> <span>=</span> <span>labels</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

        <span>outputs</span> <span>=</span> <span>model</span><span>(</span><span>inputs</span><span>)</span>
        <span>_</span><span>,</span> <span>preds</span> <span>=</span> <span>torch</span><span>.</span><span>max</span><span>(</span><span>outputs</span><span>,</span> <span>1</span><span>)</span>

        <span>if</span> <span>criterion</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>criterion</span><span>(</span><span>outputs</span><span>,</span> <span>labels</span><span>).</span><span>item</span><span>()</span>
        <span>else</span><span>:</span>
            <span>loss</span> <span>=</span> <span>0</span>

        <span># statistics
</span>        <span>running_loss</span> <span>+=</span> <span>loss</span> <span>*</span> <span>inputs</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
        <span>running_corrects</span> <span>+=</span> <span>torch</span><span>.</span><span>sum</span><span>(</span><span>preds</span> <span>==</span> <span>labels</span><span>.</span><span>data</span><span>)</span>

    <span>eval_loss</span> <span>=</span> <span>running_loss</span> <span>/</span> <span>len</span><span>(</span><span>test_loader</span><span>.</span><span>dataset</span><span>)</span>
    <span>eval_accuracy</span> <span>=</span> <span>running_corrects</span> <span>/</span> <span>len</span><span>(</span><span>test_loader</span><span>.</span><span>dataset</span><span>)</span>

    <span>return</span> <span>eval_loss</span><span>,</span> <span>eval_accuracy</span>

<span>def</span> <span>train_model</span><span>(</span><span>model</span><span>,</span> <span>train_loader</span><span>,</span> <span>test_loader</span><span>,</span> <span>device</span><span>,</span> <span>learning_rate</span><span>=</span><span>1e-1</span><span>,</span> <span>num_epochs</span><span>=</span><span>200</span><span>):</span>

    <span># The training configurations were not carefully selected.
</span>
    <span>criterion</span> <span>=</span> <span>nn</span><span>.</span><span>CrossEntropyLoss</span><span>()</span>

    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span># It seems that SGD optimizer is better than Adam optimizer for ResNet18 training on CIFAR10.
</span>    <span>optimizer</span> <span>=</span> <span>optim</span><span>.</span><span>SGD</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>learning_rate</span><span>,</span> <span>momentum</span><span>=</span><span>0.9</span><span>,</span> <span>weight_decay</span><span>=</span><span>1e-4</span><span>)</span>
    <span># scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=500)
</span>    <span>scheduler</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>lr_scheduler</span><span>.</span><span>MultiStepLR</span><span>(</span><span>optimizer</span><span>,</span> <span>milestones</span><span>=</span><span>[</span><span>100</span><span>,</span> <span>150</span><span>],</span> <span>gamma</span><span>=</span><span>0.1</span><span>,</span> <span>last_epoch</span><span>=-</span><span>1</span><span>)</span>
    <span># optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)
</span>
    <span># Evaluation
</span>    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span>eval_loss</span><span>,</span> <span>eval_accuracy</span> <span>=</span> <span>evaluate_model</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>test_loader</span><span>=</span><span>test_loader</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>,</span> <span>criterion</span><span>=</span><span>criterion</span><span>)</span>
    <span>print</span><span>(</span><span>"Epoch: {:02d} Eval Loss: {:.3f} Eval Acc: {:.3f}"</span><span>.</span><span>format</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>eval_loss</span><span>,</span> <span>eval_accuracy</span><span>))</span>

    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>num_epochs</span><span>):</span>

        <span># Training
</span>        <span>model</span><span>.</span><span>train</span><span>()</span>

        <span>running_loss</span> <span>=</span> <span>0</span>
        <span>running_corrects</span> <span>=</span> <span>0</span>

        <span>for</span> <span>inputs</span><span>,</span> <span>labels</span> <span>in</span> <span>train_loader</span><span>:</span>

            <span>inputs</span> <span>=</span> <span>inputs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
            <span>labels</span> <span>=</span> <span>labels</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>

            <span># zero the parameter gradients
</span>            <span>optimizer</span><span>.</span><span>zero_grad</span><span>()</span>

            <span># forward + backward + optimize
</span>            <span>outputs</span> <span>=</span> <span>model</span><span>(</span><span>inputs</span><span>)</span>
            <span>_</span><span>,</span> <span>preds</span> <span>=</span> <span>torch</span><span>.</span><span>max</span><span>(</span><span>outputs</span><span>,</span> <span>1</span><span>)</span>
            <span>loss</span> <span>=</span> <span>criterion</span><span>(</span><span>outputs</span><span>,</span> <span>labels</span><span>)</span>
            <span>loss</span><span>.</span><span>backward</span><span>()</span>
            <span>optimizer</span><span>.</span><span>step</span><span>()</span>

            <span># statistics
</span>            <span>running_loss</span> <span>+=</span> <span>loss</span><span>.</span><span>item</span><span>()</span> <span>*</span> <span>inputs</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
            <span>running_corrects</span> <span>+=</span> <span>torch</span><span>.</span><span>sum</span><span>(</span><span>preds</span> <span>==</span> <span>labels</span><span>.</span><span>data</span><span>)</span>

        <span>train_loss</span> <span>=</span> <span>running_loss</span> <span>/</span> <span>len</span><span>(</span><span>train_loader</span><span>.</span><span>dataset</span><span>)</span>
        <span>train_accuracy</span> <span>=</span> <span>running_corrects</span> <span>/</span> <span>len</span><span>(</span><span>train_loader</span><span>.</span><span>dataset</span><span>)</span>

        <span># Evaluation
</span>        <span>model</span><span>.</span><span>eval</span><span>()</span>
        <span>eval_loss</span><span>,</span> <span>eval_accuracy</span> <span>=</span> <span>evaluate_model</span><span>(</span><span>model</span><span>=</span><span>model</span><span>,</span> <span>test_loader</span><span>=</span><span>test_loader</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>,</span> <span>criterion</span><span>=</span><span>criterion</span><span>)</span>

        <span># Set learning rate scheduler
</span>        <span>scheduler</span><span>.</span><span>step</span><span>()</span>

        <span>print</span><span>(</span><span>"Epoch: {:03d} Train Loss: {:.3f} Train Acc: {:.3f} Eval Loss: {:.3f} Eval Acc: {:.3f}"</span><span>.</span><span>format</span><span>(</span><span>epoch</span><span>,</span> <span>train_loss</span><span>,</span> <span>train_accuracy</span><span>,</span> <span>eval_loss</span><span>,</span> <span>eval_accuracy</span><span>))</span>

    <span>return</span> <span>model</span>

<span>def</span> <span>calibrate_model</span><span>(</span><span>model</span><span>,</span> <span>loader</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu:0"</span><span>)):</span>

    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>

    <span>for</span> <span>inputs</span><span>,</span> <span>labels</span> <span>in</span> <span>loader</span><span>:</span>
        <span>inputs</span> <span>=</span> <span>inputs</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>labels</span> <span>=</span> <span>labels</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
        <span>_</span> <span>=</span> <span>model</span><span>(</span><span>inputs</span><span>)</span>

<span>def</span> <span>measure_inference_latency</span><span>(</span><span>model</span><span>,</span> <span>device</span><span>,</span> <span>input_size</span><span>=</span><span>(</span><span>1</span><span>,</span><span>3</span><span>,</span><span>32</span><span>,</span><span>32</span><span>),</span> <span>num_samples</span><span>=</span><span>100</span><span>):</span>

    <span>model</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>

    <span>x</span> <span>=</span> <span>torch</span><span>.</span><span>rand</span><span>(</span><span>size</span><span>=</span><span>input_size</span><span>).</span><span>to</span><span>(</span><span>device</span><span>)</span>

    <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>num_samples</span><span>):</span>
        <span>_</span> <span>=</span> <span>model</span><span>(</span><span>x</span><span>)</span>
    <span>end_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>elapsed_time</span> <span>=</span> <span>end_time</span> <span>-</span> <span>start_time</span>
    <span>elapsed_time_ave</span> <span>=</span> <span>elapsed_time</span> <span>/</span> <span>num_samples</span>

    <span>return</span> <span>elapsed_time_ave</span>

<span>def</span> <span>save_model</span><span>(</span><span>model</span><span>,</span> <span>model_dir</span><span>,</span> <span>model_filename</span><span>):</span>

    <span>if</span> <span>not</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>exists</span><span>(</span><span>model_dir</span><span>):</span>
        <span>os</span><span>.</span><span>makedirs</span><span>(</span><span>model_dir</span><span>)</span>
    <span>model_filepath</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>model_dir</span><span>,</span> <span>model_filename</span><span>)</span>
    <span>torch</span><span>.</span><span>save</span><span>(</span><span>model</span><span>.</span><span>state_dict</span><span>(),</span> <span>model_filepath</span><span>)</span>

<span>def</span> <span>load_model</span><span>(</span><span>model</span><span>,</span> <span>model_filepath</span><span>,</span> <span>device</span><span>):</span>

    <span>model</span><span>.</span><span>load_state_dict</span><span>(</span><span>torch</span><span>.</span><span>load</span><span>(</span><span>model_filepath</span><span>,</span> <span>map_location</span><span>=</span><span>device</span><span>))</span>

    <span>return</span> <span>model</span>

<span>def</span> <span>save_torchscript_model</span><span>(</span><span>model</span><span>,</span> <span>model_dir</span><span>,</span> <span>model_filename</span><span>):</span>

    <span>if</span> <span>not</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>exists</span><span>(</span><span>model_dir</span><span>):</span>
        <span>os</span><span>.</span><span>makedirs</span><span>(</span><span>model_dir</span><span>)</span>
    <span>model_filepath</span> <span>=</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>model_dir</span><span>,</span> <span>model_filename</span><span>)</span>
    <span>torch</span><span>.</span><span>jit</span><span>.</span><span>save</span><span>(</span><span>torch</span><span>.</span><span>jit</span><span>.</span><span>script</span><span>(</span><span>model</span><span>),</span> <span>model_filepath</span><span>)</span>

<span>def</span> <span>load_torchscript_model</span><span>(</span><span>model_filepath</span><span>,</span> <span>device</span><span>):</span>

    <span>model</span> <span>=</span> <span>torch</span><span>.</span><span>jit</span><span>.</span><span>load</span><span>(</span><span>model_filepath</span><span>,</span> <span>map_location</span><span>=</span><span>device</span><span>)</span>

    <span>return</span> <span>model</span>

<span>def</span> <span>create_model</span><span>(</span><span>num_classes</span><span>=</span><span>10</span><span>):</span>

    <span># The number of channels in ResNet18 is divisible by 8.
</span>    <span># This is required for fast GEMM integer matrix multiplication.
</span>    <span># model = torchvision.models.resnet18(pretrained=False)
</span>    <span>model</span> <span>=</span> <span>resnet18</span><span>(</span><span>num_classes</span><span>=</span><span>num_classes</span><span>,</span> <span>pretrained</span><span>=</span><span>False</span><span>)</span>

    <span># We would use the pretrained ResNet18 as a feature extractor.
</span>    <span># for …</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/">https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/PyTorch-Quantization-Aware-Training/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437855</guid>
            <pubDate>Wed, 16 Dec 2020 01:21:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Far Cry: How the Fire Burns and Spreads (2012)]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25437800">thread link</a>) | @fctorial
<br/>
December 15, 2020 | https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/ | <a href="https://web.archive.org/web/*/https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
			
<h2>INTRO</h2>



<p>A few years ago, I got the opportunity to architect and code the fire propagation system in Far Cry 2. &nbsp;At that time, &nbsp;it was a gigantic task and it scared the hell out of me. Luckily, it turned out well enough.</p>



<p>With the upcoming Far Cry 3, several people recently asked me how the system worked. I realized that I never took the time to write it down. So, before I forget and also because it might be useful to somebody out there, here’s a high level overview of its inner workings. &nbsp;Pretty programmer art included as a bonus.</p>



<p><em>Disclaimer: Although Far Cry 3 uses the same system I wrote, I was not involved in the project. They may or may not have changed / adapted or modified the algorithms. What I describe below is accurate for Far Cry 2.</em></p>



<figure><p>
<iframe title="Far Cry 3 incredible fire demo video" width="640" height="360" src="https://www.youtube.com/embed/zcmbWqJjCN4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>BASE STRUCTURE</h2>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACell1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACell1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>A 2D Grid good for grass fire. &nbsp;Here, a fire cell has 50 hitpoints</figcaption></figure></div>



<p>At the core, the fire propagation system is quite simple. Since gameplay is what’s important, we&nbsp;sacrifice some of the realism for fun. The fire propagation in&nbsp;Far Cry 2 &nbsp;(and Far Cry 3) has just enough realism to maintain the player’s&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Suspension_of_disbelief">suspension of disbelief</a>,&nbsp;but certainly not enough to get published anytime soon. Because I like to&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/KISS_principle">keep things simple</a>, it doesn’t involve any complicated mathematics, physics or fluid dynamics. That has the additional advantage to be fast to simulate and easy to understand.</p>



<p>The secret sauce is an&nbsp;equally spaced grid. It is true for grass, for objects as well as for trees. The only difference is that we use a 2D grid for grass and a 3D grid for objects and trees.</p>



<p>Each cell of the grid has a position in the world, a radius and&nbsp;<strong>hitpoints</strong>. The cells have a plethora of&nbsp;properties, but these three are the bare minimum to propagate fire.</p>



<h2>LIGHT MY FIRE! HOW TO START ONE?</h2>



<p>The game engine tracks all damage done in the game, might it be bullet shots, impacts or fire damage. When a game entity is damaged, it is notified by an event. The damage event includes how much damage was done, what kind it was and what caused it.&nbsp;&nbsp;If the kind of damage was fire based and the entity is flammable, then at least two things happen:</p>



<ul><li>Firstly, the fire grid is dynamically created for the damaged entity. We create them dynamically because we don’t want those grids&nbsp;to exist in the wild for no reasons. That would take memory, disk space, etc, so we create them as we go. But, once created, it remains as long as the game entity exists.</li></ul>



<ul><li>Secondly, we figure out which cell in the grid is closest to the damage source. That cell then takes the damage and its hitpoints are reduced accordingly.</li></ul>



<p>That’s where things get interesting – When a cell has been damaged by fire and has lost all its hitpoints;&nbsp;<strong>it catches fire</strong>.</p>



<p>While burning, the cell becomes a damager itself. It deals damage to its neighbour cells on the grid; cells that share an edge with it. By doing so, it reduces their hitpoints and when in turns these cells have lost all their hitpoints, they catch fire. That’s how the propagation is created.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1.jpg 700w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridBiggerFire1-300x220.jpg 300w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Fire propagating from left to right. The cells on the fire front are being damaged.</figcaption></figure></div>



<p>Lastly, a cell from the grid as a finite lifetime. Otherwise, it would burn forever. It can be seen as the amount of energy given by the material that is burning. &nbsp;For instance,&nbsp;a piece of paper would most likely burn faster than a wood log, so it would be given a shorter lifetime value.</p>



<p>That’s it. A fully functional fire propagation system good enough for a AAA game!</p>



<h2>TECHNICALITIES</h2>



<p><strong>Simulate wet jungle VS dry patch of grass</strong><br>How to simulate a wet jungle versus a dry patch of grass? They behave differently. Quite easily!<br>Increase the fire cell’s hitpoints and it’s difficult to set it on fire and it’s slow to propagate.&nbsp;Decrease its burning lifetime and the fire dies out quickly. There, you just simulated a wet jungle environment.</p>



<p><strong>How to create the propagation grids</strong></p>



<p><strong><em>Grass / Land</em></strong><br>For grass wildfire, &nbsp;an axis-aligned 2D grid is built in realtime and projected on a 3D terrain. For each of the cell, we take care to determine if the cell position is underwater, or under an object such as a rock or a building. In which case, we disable that cell and it can no longer catch fire. We wouldn’t want to have fire propagating under rock, would we?<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled.jpg 512w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDisabled-300x220.jpg 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>2D grid projected on a terrain. The cells under the rock are disabled.</figcaption></figure></div>



<p><strong><em>Objects</em></strong><br>For objects, it’s a little bit more complicated. First, we create an&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Bounding_volume">AABB</a>&nbsp;that entirely surrounds the object. &nbsp;Second, we somehow&nbsp;need to detect the shape of that object. After all, it could be a chair, an oil barrel or a whole house for all we know. To accomplish that, the &nbsp;bounding box is divided in equally spaced cubes.&nbsp;The size of each cube depends of the object size, the number of fire emitter we want to have, performance, memory, etc.</p>



<p>An iterative algorithm then go through all those cubes and test their location against the collision shape of the object.&nbsp;If the test return a positive result, this cube is kept, otherwise it is discarded. At the end, we have a collection of cubes that approximately&nbsp;represent the shape of the object to be burned. That’s our propagation grid.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/3DGrid.jpg 800w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-300x183.jpg 300w, https://jflevesque.com/wp-content/uploads/2020/01/3DGrid-768x469.jpg 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption>Detection of the shape of an object</figcaption></figure></div>



<h2><strong>WIND EFFECT</strong></h2>



<p>The wind is an important disruptive factor for a wildfire and it adds a great layer of realism for the player. &nbsp;Here it could be tempting to&nbsp;over-think&nbsp;the design and go with a very complicated system. After all, it’s an active area of research and&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S1540748912001988">several</a>&nbsp;<a href="http://web.archive.org/web/20160114121147/http://www.sciencedirect.com/science/article/pii/S0378475407002030">papers</a>&nbsp;on the subject are available online.</p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S0378475407002030-gr3-300x235-1.jpg" alt=""></figure></div>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/1-s2.0-S1540748912001988-gr3.jpg" alt=""></figure></div>



<p>Luckily, with what have been explained thus far, it’s quite easy to simulate if we accept to cut corners a bit.</p>



<p>In our system, the fire propagates by damaging the&nbsp;neighbor&nbsp;cells on a grid. And it is generally accepted that a fire should spread faster in the direction of the wind than against&nbsp;the wind? Then, with that in mind, we can create a rule where a burning cell deals more damage to its&nbsp;neighbor&nbsp;cells if that neighbor is in the direction of the wind.</p>



<p>We do that by getting the&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Dot_product">dot product</a>&nbsp;between the wind direction&nbsp;vector and the direction of the&nbsp;neighbor&nbsp;cell to damage.&nbsp;If the result is greater than zero, then that node is dealt greater damage. &nbsp;Likewise, if the result is negative, &nbsp;the node is against the wind and should be dealt less damage. To be fancy, the amount of damage is interpolated with the dot product result as shown in the picture below.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/ACellWindEffect1-300x206.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>The cell on fire causes more damage to its neighbor cells if they are in the direction of the wind.</figcaption></figure></div>



<p>With that rule alone, you will get a nice bell shaped fire front that propagates in the direction of the wind. Simple, yet believable&nbsp;enough to get the player’s stamp of approval.</p>



<p>It’s worth noting that we simulate gravity the exact same way.</p>



<h2>PROPAGATING TO THINGS AROUND AND CHAIN REACTIONS</h2>



<p>When a cell burns, it sends a “I’m on fire and I burn this much in this radius” message down&nbsp;the game event pipeline. This event is caught by objects, AI and other game systems that are in that area. They react&nbsp;to this message their own specific ways. The AI freaks out, the flammable objects get damaged and eventually catch fire. And, &nbsp;it is also true for dynamic objects. &nbsp;For example, if a burning oil barrel goes flying through the map, every step of the way, &nbsp;it will send that “i’m burning” message and a lot of things around might hear it.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone.jpg 719w, https://jflevesque.com/wp-content/uploads/2020/01/2DGridDmgZone-300x284.jpg 300w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>In the absence of wind, a cell on fire damages equally all its neighbors.</figcaption></figure></div>







<p>This causes a chain reaction effect where trees, explosive items, &nbsp;objects and patches of grass set each others on fire. &nbsp;It’s completely&nbsp;systemic and it makes it much more believable. It &nbsp;also scores pretty high on the&nbsp;player’s&nbsp;fun meter because it behaves as one would expect, yet as real fire, it sometimes gets totally out of control.</p>



<h2>OPTIMISATION</h2>



<p><strong>The Hair Transplant Strategy</strong></p>



<p>In an ideal world, we would have access to enough memory to hold&nbsp;an infinite number of particle emitters and we could display an infinite number of particles on screen.&nbsp;Unfortunately, the reality is that those numbers are actually pretty low.</p>



<p>To do more with less, we have to put our emitters where it really counts. Enters the hair transplant strategy! &nbsp;In Far Cry 2, the fire emitters are constantly being teleported around, most importantly, from the back of the camera to the front. The player’s point of view is monitored at all time and emitters that are burning out of sight are moved to a better location where they are also needed.</p>



<p>In addition, the emitters’s density is higher in close proximity of the player and lower as the distance increases. A kind of fire&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Level_of_detail">LOD&nbsp;</a>if you will.&nbsp;If things are getting bad and we still need more emitters but none are available, we increase the particle sizes to give them more volume and fill more space on screen.</p>



<p>With this strategy, and some others, we can simulate a wildfire that is several meters wide with a relatively low number of particle emitters.<br></p>



<div><figure><img src="http://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg" alt="" srcset="https://jflevesque.com/wp-content/uploads/2020/01/farc2.jpg 600w, https://jflevesque.com/wp-content/uploads/2020/01/farc2-300x169.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"><figcaption>Credits: http://www.rockpapershotgun.com</figcaption></figure></div>



<p><strong>Event Pipeline</strong><br>Since the described system tried to avoid all complicated maths, generally speaking we will be GPU bound before being&nbsp;CPU bound.</p>



<p>That being said, the event pipeline could be a bottleneck. It works well when you have just a few cells on fire. But, it’s another story when you have thousands of them burning and&nbsp;advertising&nbsp;their state to the world. That will likely clog your CPU’s arteries.</p>



<p>The trick for me was to regroup the cells that were burning into&nbsp;<a href="http://web.archive.org/web/20160114121147/http://en.wikipedia.org/wiki/Axis-aligned_bounding_box#Axis-aligned_minimum_bounding_box" target="_blank" rel="noreferrer noopener">AABB</a>&nbsp;groups. These groups would constantly merge, split and&nbsp;change shape to follow the evolution of the fire. The events would then be sent per AABB instead of per cell, which saves&nbsp;a significant amount of processing power. Additionally, the events would be spread out across several frames in order to distribute the load and avoid framerate spikes.</p>



<p><strong>Keeping things under control.</strong><br>In your game, if you don’t constrain the propagation somehow, it will either</p>



<ul><li>Burn the entire map and kill all the NPCs</li><li>Fill out the …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/">https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</a></em></p>]]>
            </description>
            <link>https://jflevesque.com/2012/12/06/far-cry-how-the-fire-burns-and-spreads/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437800</guid>
            <pubDate>Wed, 16 Dec 2020 01:13:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Statistical Analysis of Speedrunner's RNG proves game “was modified” [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25437663">thread link</a>) | @linksbro
<br/>
December 15, 2020 | https://mcspeedrun.com/dream.pdf | <a href="https://web.archive.org/web/*/https://mcspeedrun.com/dream.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>] &gt;&gt;
stream
xœcbdàg`b`8	$¸ÚA¬| ÁùH0½ŒE0BÁHˆ±	ö !U$\k˜ý8@ÚG‰!K°-hŒt$ç
´F	ºé¸
endstream
endobj
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
323 0 obj
&lt;&lt; /Names 320 0 R /OpenAction 334 0 R /PageMode /UseOutlines /Pages 610 0 R /Type /Catalog &gt;&gt;
endobj
324 0 obj
&lt;&lt; /Type /ObjStm /Length 2183 /Filter /FlateDecode /N 90 /First 801 &gt;&gt;
stream
xœÕZÛnÇ}ÏWô£ý�Þ®êª¾Ž],Y€á(¤8ò@Ñ›˜‰Ä%¨¥%ý}ÎrWKj%îî1Ý³55gª«OUuwÎRÈÙÿç¤ñZƒjÃµ-×L f)¸\%Ô$¸jhÆ~½u\-ˆP‘ym”€FSC£ñJ-H&gt;Ôñ2j÷4	^çT
ô¸ÍBL9¨&lt;î$ÃZíÂÇñ—Š¢*lt~J¹$*ÅãPJÁã”kÔÃŸ;5ãßøÙÔy§³D™Ì©¾´`uÐC´
eøO4:.ÊªÏü
tÜ¨¾Zð’xÇƒWB¨%xK€P+0I®
�Íµï4TƒæN¨0_InŠ† ·ŒFeÃB~;Vá�ŠrHZEcnhp00%+?7¡AÍš-ñ4›ñ4{çh®|¼Cs§ýzÁXSs¯6à�†5÷ªâŽ¥ªÁ)rÕ€×€»ºÂ�xM¥é,Î;jK†æ&gt;&lt;Í}xª…&amp;
§šÂHôº†QACBs˜Ö0À­r@$‡ÖáHí]Õ0®=ãÍ†»�®g°QçW¦;ß%=ôš9Ô)Ì�*l
Ã¯h	^e¸/I½ÿá›oÂìIø&lt;«`¢…ÙÓ³eøg˜‡Ù³ÅËExð`y¼x½¸&lt;¾89�ãÙÉoß/Ÿ/O–¼e7/Î—�òO3Üe­nåxãu‡®µ–ïó¡óàA˜½8Y.ç—çtÔk�—‹Óãùg/ž&lt;
³—ó÷„wƒêðŸþþs&nbsp;£W•Ø0Î¯^¿þ¢(Žv[ìa¸þêâäråëMC„Ù£Åå/óKhJø'4Óctdè¢ó]˜=³£ù)ñŠ•·†K¶HwÐl‘þZ¬GÇøÓÆW¯–.æaöýÙùñmCûáùùbù	œ·Pz¶8Ÿ‘”Ø0¡T$ªsb•˜ŠˆH'@äÝ"¦ŸJŽàN�€EÁ´=PžP•(˜S&nbsp;ÛX€Ä›F8ð~€šÄ<p¡š“^£ f¹µh="">9Ì&gt;6"±ØE³GE,ÀŽÝujŸ‘u�ü¦&amp;1�:&gt;”ü²)È¼E†zÌ~p!Âkdü:Ì@e
DWÄ0Õ3C€ÕX}_Ÿ^!ªS µbrR+�þàT{"ºzµ5Ž‹DG¦‡H+â=I�0sl}oCmÂE7°�ÞÄ!³3�L‘‹Ä2k”£¯`Õ3ÓËêpøk˜ª‡rw›À­�9ƒ‹|à&amp;òÝÂÜÁ†j“¸Š‡8ˆ¶m)²7…o‚šÄ©rX2çS¿‰2f¬Iœ
)ÜP–ð~Ó(k�Šz+X©GAêªZ‡3+|Ýö¶Ö
¦&gt;�¯k¹ ™$"Bí€vê“¸º‚Èœ9Á»®•ÈÒpª)|yJ„}p-`(¢´ÈÚh¬)|]]"²€®PjA4,£¬5…¯£ÆŽ¬±5ÓÇ¤=E—QÖ•æ­`ÁÑ-ó
6%Jð`Ý;ïÜD5*·Z¡âØUÜŽÚ]ÁñûŽà�zN‘›KÃ¬3¦ž†~AÕ�cÝ?þ­
Î4$±°ÀS�\“š�4ŒÈ]$MBT‚Z\8n¸xÈÚˆèXS0•°ªb�³¥Þ3ÚþKÀuÚ8›5Ð¥keÉG›¡àB=�ø&lt;¤Y£Á�²Ü
œ°¸!×£&gt;E8œõ	,7ŠéWà�±s5W{‰ž`Ó0ÜNÌ)–‚*üžä.0“´ÐZ,²¯ÿŸ\\ÌÏ9{N²ð]a¢Ô"W‹ªQ·
èÑÕDŽ¥rËI˜ùqmz&lt;—
ØìÎ¡c6£‘ö;Ú{—Šk»¹-\VA†²êYðœnzË½®ãJØqwSÐà.˜Þ¥+ˆ²l[ò
÷,øný6¿_.'Ø¾M¡ïòÖz€J]¶EvÑvW*;½{IrVÞ&gt;;}Ç])Œ8pÛˆÝ•ÌH_È–ŸJjº-i\z�mÖQÝã])GÁÀ³Ïì|÷¯Åb‰Ù5V³&nbsp;6Å,auR¸á†Ä¶°�ê¤ú¾ùöGLc¢©»¥I©,Q@2vU/ªqî6®{=]÷:z«Ý$n§y®«žq—rµít{Štå«ÚººÅŸ£«ÑVØüîñë;a†×&lt;™ÿvv:?zöˆ^±¼¼š¾ôòòäü-Ê”ùùé‡Õ&nbsp;?»\\]üîƒ~�)fÏßœü{þ˜þûÓ__ý‡®NÏßHh+UŸcÞ/Å£MAÔ]Ë°Sï’ÛhëlÆÛÛ¶šÖÌñ·Dv�Ð’gî·Ç‚„|´InaÚù!;M�-d;¦:ÈM‡2ÝÝbâé$á0”�<jr(ÿ�yiÈÜõdä(ñÏ‡Êä"dkû–z1�z�bŠçÎÃ(- kul1ãÁeb^ö­ð="">b³ü“+â¤b5â#Ïì4‰Ò»Jä¾—�áÇ£çk�¡Ä»¾õÕ¯ËåÅÛ?ÍfïÞ½‹WË«Wóxºx3{w²&lt;ýõ/¿ýùoßêÕQùù�?œþøõ&gt;�Mù4Ô#Í�ÎcM%*O”8˜¹�(·uö]IþhÖ1ûƒf0#—½GƒâN¥sçfî}GL×:‡% b&lt;+µÖÉSQ¶þ�¡lý\‡kçõû:Ÿ[Ó\¦âºG-«·k¢–UZóù„‡Ï¬&gt;™dOî7%yÜÄÀ&amp;Vz¼/ñWÔÙ™§ÅPŠeø^³q|Œbãê­#ótk”V÷ZŸ1�ßŸÚâû‡}Þ#¦1OÎð\¦1÷…†i�wü„¦Ì&amp;ÉîÓâÿÉõo×œ_rýMIžýŽ‚"@pa÷^w³7Èã5ó¦!bÚ°G8œåu×…ÚOëámßú?Æ¾nT
endstream
endobj
325 0 obj
&lt;&lt; /Filter /FlateDecode /S 384 /Length 407 &gt;&gt;
stream
xœc```b`ÞÏÀÌÀÀbÇ È`6+™XXfnhsa9´ìcÜáiÜ,™~6ïQ8˜ÀÀ&nbsp;&gt;EtWØ2¶”fÇkD/ðµPœÀpá÷KÖmEŽI&amp;P\Á8-xÆæf¥£;u[¢%=–ežjPôÍ~ÐÚ’j%-y“›9¡µÅ·gÂ²mFN®)†l³üÐ³Ü9^êy�ÓÊœU+©_ÏkšDý[€b@YÓS^dÇÏsäZºñ‚éï'«b–;GŸPyáUbúqí‚ÖVßâ·,Ú5/-Û××$ê�¼PóÂõë50Ö5&nbsp;Ž
S^G=¿åªÛ×r6û±ÍûIN+{K”5/\ÛoýdÂªhYŽS%¦[ÏýTÑÜ0IäP�UðÂµ}?U´d«´®ÜP$¶Ì’;X†² †¯«J%�æbypà10002ÈŸ�ÄÆ%ÅäÂ={{
›®h€¨¼®°t›æFõ�¬A2*qÚ§,Ó´“çD}«×�îŸZ›ÉÑË÷L$d¢L³
endstream
endobj
326 0 obj
&lt;&lt; /Contents 327 0 R /MediaBox [ 0 0 612 792 ] /Parent 527 0 R /Resources 335 0 R /Type /Page &gt;&gt;
endobj
327 0 obj
&lt;&lt; /Filter /FlateDecode /Length 296 &gt;&gt;
stream
xœ…‘OK1ÅïýsLÀ¤™ÉŸM<j­(ˆ¢ëi=l»i»ÐnËîvðÛ›mŠp ^f&Ã¼ïkpp7qÿô›r2�»�xhbk \!jã-8mc€²†w6ëbµãb£f÷íwì‡f]="" Í¾w†½Äþ¸zþy="">Lç…‚DÖÒHZK¯ä¥÷&gt;Óž&gt;”vË¦Ú&amp;9¹$?pAÛóTºa\lÁÉ³ï&lt;›˜/›6.»j5äçkÖÅXwÇ¶mÚu&gt;/¹'6ú=ù	^çNáœ’ˆ”Ü(ðœíù¸Ø6ý&amp;Ö×\&nbsp;2�Íâ2î±ãÂ’eˆWy EjD‚‘…r rÊÌx;ÔÕp&amp;X•ÙÄþ�üþÀt®	B2Hîd¥2„	$5�éx¡¸-'?&gt;ÃsÌ
endstream
endobj
328 0 obj
&lt;&lt; /Filter /FlateDecode /Length1 726 /Length2 7542 /Length3 0 /Length 8143 &gt;&gt;
stream
xœmuePœY´-<xp§qohÜ‚[cÁ‚5ÐhãÜ!¸kwîÁ!ÜÝ%ì23wæÖ«zõýÙ²v�µ×yu>zjY˜«¦—#Är
4d54@\œœN 7:=½”3ÄÔê“6u…t 
ˆ#Äx�€ÐéRŽ^ÎP+kW“9óßE€¶�©ÔêÐv°sp‡š[DÜÝÝÅÝ]Ü€În¢À—!
àj
XBí ©wªz`9“œŠ@ƒ8›ÚTÝÌì&nbsp;æ%¨9æaX:8ìþIæ0è_œ\€€¹Cœ]_ˆY:;Ø”e4%dß©hd¤84¥¦0€’üË8ÌÕEè
1wqùk;6€ë‘�é‘ÙÑ]gÏ" :°€š»Ì VP:Ç_º�a–¾ÊnŽÿ¶^¹¼ð0½hÈ°€X¾&nbsp;ÝììTLí!&amp;){G7Wˆ3@ÙÁâh˜Â\^q†Zþ5µ‡ÚyýÁÿ‹»š¾ˆ!³z‘�óŸÔEê	±P…º¾èmij÷¢ÓßuÈ?—£±€ºÙÿ3yååZ-`v^ÿ{äË.È¡"%¥#­ÉúŸþnËÀÌ,&nbsp;0+€†ë‹&nbsp;¦Îÿþn«šBÿ±Ð¿dþµô¹²©«3Ô`À	üË#œ}ÿFFÿ‡’”tðôf	òØ¹¹@//@@�×÷ÿ¡kîæì�¹þ­úË.ÿæ»	ñ„˜£/Ì9˜‡Ø¤5„•øÉL”"±NŒ™h±Î�àþè85xíµ¶x¿uLz¡Išë�A1hövíh|QOcÁØ�¦Ž0š#½ýB[jåW±üG-ï®:ÂøQ›ÄÞ\ñ4òÜ5ã×B�*Ë(OVÎA…‚Ó×·oä@Ñ&amp;Å-]H8+ñóÓW09f#FÜLý'Èk9Î„uhþ‰™ØíúBxnðÆ)=É{ëü’@Ç­p½K^¦&amp;Áy·=-†×'ï¦Nd{Ç±ëí~“ÌàV�g¨BQ¦ãéñGž?©Cb#ffJ¯a5Ê­ê¾#ÅW\§Kxîò´íˆöË8çA^ß´xá„ÆŠ~ŸÜž{¿6í®t\Å	"ñÒÿ)HÜ1**Ò;™Ø»|6¤Â.çÇÏ?¿pNGïw:Éÿ.‘Ë¸ÑÓ*‰]Iàq·Î4ò~‡³¿Ì&gt;\{V½&amp;wœç²Óäö�í±‹paŠ�ˆ˜óÙÁu�¾æðJºnÅlÔIeÞ’_&nbsp;‹ÉÛ"?9H¸Fö&gt;fÿü,îÔñ«&amp;¨¾Á¶GÄž_‘”“�x—±YÆù­?VìÓÓCÐG¯;ÿg°×�xy vÇá­¤¥^««/’ýVÔ@„Ú¨¬h¶y?7-1¯ÅªQßsœ$#bq˜XÍÇ¬‹I<cøØÁ»š5Èx‹(ÝÄ>µòa„õÏ­¤Ì¸Ö[â��û
#J}©ö.+5#ùô¥»”&gt;vÎ<tÊºveûÞ“ž;í^bÊ±“àçb©aÄý;Üñv›…_súÞiîbÚ_7Õ§[Ÿ· 0¸öÇf="" %“aŠ˜ô}üa¸ž˜6wgÇ¿%?×ÅÁ="">Þù»·_.vŽU‡"6%îú7ª‘ñšÄ¹-N*ÅÆ¢ÇØ£'ÅCZ‘�;¤Ó¤Øu)=r¬öðŽ�ã�GÔÍB€v&lt;¡„Q�&nbsp;LÖ¦þx¶Í6C„Ö1¥€)ASºQˆA˜±»Õuˆ¥«Hü�·&amp;i¼T®Ù¸È!+˜êVÎäöWÞ» Ø…Ê.ÐšßÛ\ïL+º05³n®X×ìÛœ•=Võ¨­±Ö1ÐPSKjY².Ôëj™‚H)2žïgŒ£�Šá;\íFÿw_?LÇ�ôKÙËè¤’Ø2‘Žmtíý„„ô°8êí-àŽÊU$­�gxí¸µü„Mšóü²ý$�•cÄ¾ÓÕ½‘h®AÚŸpžº»kÛ\À)æn¾(º:BK oÏ4�½H@�É?OO-÷ójtUÂîN{Ü4¶Ê�t?”L}´’¬L@@j`è¨¤Û¨#–q®CJÊË=¼z-0³˜^g\HR•¦¤Oü+:*æFå=Z«õ6�MÅÌÒÓfîƒŒ6ê¹.aw&amp;c‡aÔŠcâëvò6cñ©P`ôÂ·Vþ_6N1c†&amp;sy¯ÜßxŽÞª
-²ÝSª3�t8Áq0$w©­|²Þþ%§ì)æ{&amp;¸×Ò_ò÷\Ï&nbsp;!»RÎlHf
loIs‹Œ´áfìÝv]µoçêÀ$èä´	Zõé•(+o,¤ŸYâ&nbsp;«äò§·×Þ³¡�üa7é6÷oM&lt;ô:Â–ah›/ÓûÖ&lt;å˜*&nbsp;nK²uDÄ'd·F•F&gt;›“�,fM”¿y šßL;Aìì›€›öîO´Õcb&nbsp;ã‘Í’ÿî£ÛÅ#–´Ü™¹©µe/uªaYÁÅah³ŸŸ÷ô$Èb”}]"Äã&nbsp;1M?]HÿDÌdO}…€€124—R‡ÔÂMP¹"°?W¾UÚüEƒ×à²êC~ÃC3µ�È^›åžêþz(˜u:àü´`M&lt;ÐÖ¥œQäÜ‰çŠCŒ:ÛCæ[àÉ®ªV‘Å5ÕL
î�y:ž2\?X´0oJ€_Ö„�«º”þNæk¹;\
Ý¼êTûèGî°�¢&amp;·Šf•¿6ŸÜmUC]�¥ÀN´Á°~H¤Ç\`òç”/Ç^
T&amp;
n@Á5ó«i#I8&nbsp;k˜È½vk£ôÞlx¯•âÞ¡ä�O€+µ�:l¨Y~³	ŽøY	½À²ðä…›Jøúv¶E¶¤—æ¼�Rô€ô\ûHý|šíž ©üÀ#e?âT„†Z38¬–ª"•¡i²AÍðÉH£¶m©Sc�@y«£iŠ®|•FiöIè'tk¸úFËæ*ðêCüÇëþÈ?°ny±€"›/þ8QˆºUÀ•ÁÉ±š6MñÜ*Ê£ður,
ŠÂ¥‰¶�é“H®w5KÃ#'MhGÈ–zÒÝx´ƒ3�eê[æoçÂýÅ±Í€L#âOáZ¨ì£+õŒ`™7Éi£™í%›»}Ÿøº×ø½–,1Ÿ£°�+ê@qË™„òÂ‡pÔ~Œð£½™OM?â„ŽìÛ\^™�AÇÆgZï4¦kTl6m•ar=]GlHá‹"NKä˜„8dRI
’áwFkâß‘·é³'Ž~T_QLÓu-í}l—úárAÍ›P°)H”»&nbsp;ö�›Q8ªp*þÝ%è.&amp;_/õÄgÙzå1áý*~â&amp;¼ˆƒJå0ù¢&amp;÷{$uÚ×¯O¥Þ‚t›D0mcQßx:8ª3s;)r"R›2[ÔÂS‡d]Hš~1anÌ¦Z|'77&amp;_6ÿó&gt;ãœIý&gt;ãƒÉšjLÚîx”·ë#�èë{‘rz/Å•„g¹yÆPèLŠæ¨Ò—�n3ìAoÅ‘n³­‹¿·�•ÃÐTþö&lt;Ùˆ9ÛØ"R¸Í¤óp¦~|®È&gt;#»qÜûå®ôIiB°&lt;tvŠ
åòK&nbsp;aû²ÐDH3ã¿
±¥—ãŒóÏÖå¬Â²q‡û¶²·&gt;?¼·úyt?i­!Çÿ¦Ðwÿ“uŒ¶Ã¬ÕýU%ïÛˆ.hæòÎg¸4ñ1\º	ŸnºÕS£?xMª%Š\7öTeOÁð±õxÕêxZa³à1ø&amp;7gƒ
Ê•¹é&gt;Òãÿ×ãÛ½é§fê0&gt;¤ýíínÑ;«{n&gt;•—y¸é»�B|E
çg·îïä®A\Á…&amp;i~”Ó¿@Ôù®,Lþ­´6�ÂA_kš��wRSþö€M«&lt;‘êaÚž¦1	@^Üôƒª£$WÐú#zzÝ!»…5Ö§ˆS^&nbsp;u°Azù\ö$%–ì¿,ÊåéZ_Ö¶lc(ûÆÀ1i‡zWº)Ú^�Ì¼ÅOwÁvLð‰š:67€~¯ì=BÄ	�Àv[5
r&nbsp;OÎ(ø¢'`$û-XÌXprX·µÑÃ¸!_Fé¸è¡Æt¶øàçþÑ†áàj|uÇD[9��÷x™Ã[]P±ÿ”ˆÉÝ÷ ¡°="=·Œ©„”Ž*S¬©‡-7=ÂCR¬B±_ÃÇ
{)	}d1¨©r�¥:£­¡(cB:è§Vûh3,KŒ·É"¶{ôúõ¯�Íj‹$Óƒ &lt;Žõçåá_�Lñ„K¹&amp;ì²ŽúÙõ4*ÈèïÃã÷Þ#€Š=&gt;EUy¹±r¿·)÷ßûy¬On§³Ya×n]ý“à4ä•qyD±‡5_5Tµ2Iß…/x*&nbsp;øO
¨ÅÚŠ²nn‡ãÕ¾~‰ïÖà&amp;Âÿ!Ãÿ&nbsp;´b…°`.ófH#�bêÌ
ä¼ë`°ðFøYðö¶¬gÕ€¸5Œ™è³Wãà ³¦&gt;¤5ÇÞ¬‘zïû£ÈW˜&gt;ËwmÅ¤
Z‡wœþÐ_íFŒYîb«m¼&amp;D!é…ÂÊ¯Ÿy&gt;›l5Õr6#ïÈW¼
ìc¡´÷;©âû-X:'CØ47Có¼Ï;m6"ÿØàõÝÃõ‘�kÇ‘ûìÄô'_ïaî,ªYô½˜?§•í’ç#ø‘Ù”wÌï£ª0o"ûsC²äR!Ä
1'ä2%�Øëzºt&nbsp;MI&lt;¥³*�ø
=%Ñt‹â{*¤8¦‹%Y«Ë¶¸€«€%¯&nbsp;Ä:®²˜êfQ–[‰ÑöË¸~žÑæ­A0»
YQˆzh�‚{õÔí%�ÌþšuåÈ«øêçæ:9›¥*Ñøšˆæºº.ª±™LÉ†ŽÍ\¸{í(ú¼ÔN!~V3²÷q¦ð­E™)ïB¹†Ñ2}½0Y�§sò*|â•uzU�Mô5WÉ(¸¿i’þ²‡6úZÎµÞN[ì�|Hz-™AôEÝ_DoÐrŠ·¶uºXl€NªÖ„›®ˆ
Ì1Åxl‰­K€ÿ±aÛ5£·{Ÿ[e+ÆpOð“GSåBñA6C¹ÝÑ„Å�9÷oaŽ•*|°{!]Á´áOÕQ*“A’¥#ÊQÝËê{ƒÀ¼ŸW+�^f~ƒÉ–+{á›vkaâêV"çèŒ™QÛzäÛÞì™a3A�5ÛºA‡\«gJ¹�ñ'Ys²ÌŠ%#w3‘È”L–	L½í_pÕEÉóMßÁ]JÆ�ÙùyÔN±|)FæƒÏì|§H�r)®Tý°^…¥:x¦]ƒÀ�ßEë˜Ý#qÇ÷v|?ö•`Êýþ…«åU¦ò¾¤L]r'
€*CQuì¥\U½àw§µ/­¥xÅÞ"n›&gt;ëMîX|úŽ™�ˆ¯‚Ï~\UÁõÑ
c3ôFÍ°^V°á5eN¶#/µ�!¯\FÀô¦uýVú°&nbsp;§å­3(`–I$Òð&nbsp;&amp;ÛÜ®òlj©ÌVúõç§³B­p¨�§™ŸßìÖØ™§p³÷†£‚%ë\»p�¸©î;\3!´Ú¾é
^£»~µR®Á•‹c°ÿò•@¡W&lt;5—nÿå45Þ„+×¯rg‰Aû1èý³J,¯aoÑ"ëAõŽ—óñä²;11eœfa=)¸÷�"kÝäñØ¹;¸pÄEÊÛ5·ÔŒ(ü¥BxÌ+_·¯K±LÀëÙhov)pòF��ÝË?*RvœŸÙ4in��î&amp;]…­\ÍÒÄ"˜í2s»¿ÿb	Lw,,p_"Å&nbsp;±ttà¬ðÍxÑ¬k)Ù�VÿìrÐT‹¬AÅ- ¥‰-yšäl–"½©ËýÛ,�’;åêtoÿ�WÖ¸Ô¶³µøõ%&amp;gIêôï™W÷3ö
IÌNY¥»3.»Zß•¼z.c’bt^ëûÕq$4+Ö¹¸ãî‚&amp;'Ñ
òbZ'lÔeWÑDà˜592V°ýœÑãtB_âšÉñrºùžØŸ:­À¤sñÎ†Ð¹~Ô/®ñà•pËêÝ“ÅŽ¢E—r¨£#VÛ
HfËW7ðOvçØõrk–µ¡a6.h§Šó´m‚Xð‹7â#úþi^+`{iÇ‚Ëur7
Î+µúÍ¯!ONeìåÀß+äˆ`m!7“ ë{1Þ²ž»‘-Ý�îûë§™»2Áî£lîê$äs†�ÇÄsù6ÏBÚiã�Î´C¶oOÒÀà/zà]Á¤½gÌ
ð1d[®
Û×D©If…ºŽ§ÇRèu7êv8_!ªS¯D(ªÌÉ.z×ìëÈUjñÚª30Ÿ&nbsp;¥¥©ÈaZˆ]V:C3bu¿ùìûÞ�|�Åsb­"úÓBÜÉ|&amp;7ì4äUBÑ€eŸ‚Ÿ…“ËÒ¬*ð‰@I�…</têºveûþ“ž;í^bê±“àçb©aäý;üñv›…_súþiîbú_7õ§[ÿ·></cøøá»š5èx‹(ýä></xp§qohü‚[cá‚5ðhãü!¸kwîá!üý%ì23wæö«zõýù²v�µ×yu></j­(ˆ¢ëi=l»i»ðnëîvðû›mšp></jr(ÿ�yièüõdä(ñï‡êä"dkû–z1�z�bšçîã(-></p¡š“^£></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcspeedrun.com/dream.pdf">https://mcspeedrun.com/dream.pdf</a></em></p>]]>
            </description>
            <link>https://mcspeedrun.com/dream.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437663</guid>
            <pubDate>Wed, 16 Dec 2020 00:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write code. Not too much. Mostly functions.]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25437527">thread link</a>) | @brundolf
<br/>
December 15, 2020 | https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>There's a well-known quote by author <a href="https://en.wikipedia.org/wiki/Michael_Pollan">Michael Pollan</a>:
        "Eat food. Not too much. Mostly plants." I like it because it doesn't
        attempt to be dogmatic: it encapsulates some basic guiding principles that get
        you 90% of the way there 90% of the time. Wikipedia describes the book the quote
        is from (emphasis mine):</p>
      <blockquote>
        <p>He explains...the notion that nutritionism and, therefore, the whole Western
          framework through which we intellectualize the value of food <strong>is more a religious
and faddish devotion to the mythology of simple solutions than a convincing and
reliable conclusion of incontrovertible scientific research</strong>.</p>
      </blockquote>
      <p>That...sounds familiar.</p>
      <h2 id="write-code">Write code </h2>
      <p>Code, like food, has value. I think those of us who write it can (hopefully)
        agree on that. Some, though, are so afraid of writing/eating
        <em>too much</em> that they avoid writing/eating what they should.</p>
      <p>In the context of programming, I think this translates to an unhealthy fear
        (again, for some) of duplication. A little bit of duplication - writing
        something in a way that doesn't completely maximize conciseness - isn't the end
        of the world. Sometimes it's the best path forward. Sometimes it's okay to
        copy-and-modify here and there, especially when you're still figuring out what
        your application will end up being.</p>
      <h2 id="not-too-much">Not too much </h2>
      <p>Of course too much code, like too much food, can also be a bad thing. This is
        a well-trodden topic so I don't feel the need to go too far into it here.</p>
      <p>Just be aware of your project's "appetite": write what needs to be written,
        and then try not to over-indulge.</p>
      <h2 id="mostly-functions">Mostly functions </h2>
      <p>By "functions" here I mean "pure functions". You could make a case that pure
        functions aren't the "plants" of code, though I feel
        that they are. In my experience most codebases have a pure functional
        subset, and I believe writing that subset in a pure-functional style is nearly
        always a win for the long-term health of the project.</p>
      <p>Of course the qualifier is "mostly": this isn't a dogma. Writing a 100%
        functional system ("going vegan", if you will) often requires you to jump
        through a bunch of extra hoops to get all the functionality you need. Looking
        at it solely from the perspective of health, those extra complications may not
        be worth it.</p>
      <p>And then different projects have different needs: just as an athlete may need
        a larger percentage of protein, or individuals may have certain nutrient
        deficiencies, a project may only have a very small functional subset, or may not
        be able to afford to return new values each time due to data size or
        performance-sensitivity. There's nothing wrong with that.</p>
      <h2 id="%22real-code%22">"Real code" </h2>
      <p>Pollan later qualifies his snappy statement a bit further:</p>
      <blockquote>
        <p>He contends that most of what Americans now buy in supermarkets, fast food
          stores, and restaurants is not in fact food, and that a practical tip is to eat
          only those things that people of his grandmother's generation would have
          recognized as food.</p>
      </blockquote>
      <p>At the risk of stretching the analogy, maybe the equivalent is
        "code only those things that people at a junior level would recognize for what
        they do". Code in simple, straightforward terms. Don't get too clever,
        "manufacturing artificial ingredients". Use the primitives that are there, when
        possible. Write what is simple, and natural, and human.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/write-code-not-too-much-mostly-functions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25437527</guid>
            <pubDate>Wed, 16 Dec 2020 00:42:26 GMT</pubDate>
        </item>
    </channel>
</rss>
