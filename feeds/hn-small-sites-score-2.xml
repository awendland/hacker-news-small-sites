<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 27 Nov 2020 08:29:26 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 27 Nov 2020 08:29:26 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Asking a Tech Recruiter]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207447">thread link</a>) | @lawik
<br/>
November 25, 2020 | https://underjord.io/asking-a-tech-recruiter.html | <a href="https://web.archive.org/web/*/https://underjord.io/asking-a-tech-recruiter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-25</small>
        <p>Since I left my comfy job as the tech lead for a SaaS product and went into running my own business I took a closer look at my relationship with recruiters. While working I mostly found the attention of recruiters slightly reassuring but often annoying. I think that annoyance is fairly common, usually built up from countless LinkedIn drive-by attempts from unreading keyword-hunting recruiters. I thought that now, out on my own, maybe this legion of recruiters can be my sales department. And they have been, to an extent.</p>
<p>During my first few days as a free agent I did reach out to one recruiter in particular. This was the one that had been closest to dislodging me from my previous position and I had a feeling he was a sharp one. I had also thrown my cousin at him and he had helped him land his first real ops gig. When I got in touch this recruiter quite swiftly landed me my first client. In parallel I started to accept more recruiter connections and had a lot more conversations with assorted recruitment agencies. It has netted a fair bit of work. But I dare say the hit-rate is mostly low.</p>
<p>The recruiters that I’ve found to give the best results also give recurring results. They are the people that follow up, consider your needs, balance them with client needs and make things happen. It is my feeling that there remains a large cultural gap between the majority of recruiters and developers. I’ve been thinking about how to usefully bridge that. I don’t particularly need it right now but I want to help junior developers find their way into work and more experienced developers find their way to what they actually want. I think recruiters could help there. But I think we’re still quite far off from that.</p>
<p>I reached out  about this to my network on LinkedIn (where the recruiters live). I got a response from Emy Wennerberg Kristoffersson who was willing to take a chance and reach some new developers. Emy works mostly in Sweden around Gothenburg and Helsingborg, so while she might not work in your particular area I think the information and exchange is widely applicable. We figured a good first step is to tackle some of the common skepticisms that developers tend to have around recruiters and recruitment. I hope this will be helpful. The post is not sponsored, I asked her to answer a bunch of uncomfortable and nuanced questions which I think she does gracefully. Let’s get into it.</p>
<p><strong>For some background, can you introduce yourself and tell us a little bit about your professional experience?</strong></p>
<p>Emy: My name is Emy Wennerberg Kristoffersson. I was born and raised in Helsingborg (south of Sweden), but moved to Gothenburg back in 2016. I am passionate about tech, human beings and business development. I settled on tech-recruitment because it gives me the opportunity to combine all of these areas. For the last three years, I have been working in the recruitment industry. I work for Bonsai Consulting, a Gothenburg-based company that specializes in tech recruitment.</p>
<p>I have always had a huge tech-interest. Though, this wasn’t something that I seized back in my younger years, at least not to a greater extent (apart from when loved ones encountered technical problems and I wanted to impress – hah!). My father has always been in the IT sector so I’m quite sure that his tech skills have influenced me. I am a people-person at heart, so I eventually decided to study Human Resources in Gothenburg. In time, I got in touch with Bonsai Consulting whereupon I started to work as a researcher, and my main task was to build a network of candidates who were open to new opportunities. After a couple of months, I leveled up to a position as a recruiter and got a bigger responsibility within the company. Back then we worked broadly in recruitment and recruited to many different industries, but due to my tech-interest, the positions that related to IT and tech always ended up on my desk. One and a half years ago, we decided to work exclusively with tech recruitment due to the enormous demand within the industry.</p>
<p>One of the most interesting things in my profession is the potential for improvement in the recruitment industry. Today, I am aware that there is a lot of frustration against the recruitment profession and I do think that this is a misconception. Many jobseekers consider recruiters as an annoying part of the job search. Generally speaking, we have a pretty bad reputation (let’s talk more about this later). But the thing is, in fact, that we are an asset in a candidate’s job search and in a company’s recruiting process. My vision is to get fewer people out there to see us as an annoying piece of the puzzle, and instead see the value of taking our help as a job coach.</p>
<p><strong>Finding and hiring experienced developers has been a challenging proposition for a while due simply to enormous demand, how does this affect your job?</strong></p>
<p>Emy: The first thing that comes to my mind, is the challenge of getting the companies to understand the market and the developers’ situation. It is a bitter pill to swallow for many recruiters and companies, but today many developers have at least 4-5 opportunities available for him or her. Unfortunately, not all companies understand how coveted many developers are, and therefore they don’t understand the necessity of offering a great deal to potential employees. Not just the salary has been rising during the last years, other requirements have changed considerably as well. Today, many developers expect to be able to work remotely, having flexibility in their working day, good opportunities to develop within the company and to be able to develop their own skills (and so on…). Outstanding developers know their value on the market, and if a company’s position doesn’t sound interesting or profitable, they will go on to their next available opportunity. Many companies lack the understanding of how many offers a developer can have on their table and are therefore unable (or even unwilling) to match their needs. This is a tough nut to crack.</p>
<p>Another thing that comes top of mind is the art of standing out as a recruiter. Due to the enormous demand, many developers are likely to get contacted by a countless number of recruiters every day. The old-fashioned way of sending an email to a developer saying “Hi, here’s a job I’d like you to consider” doesn’t work today. Why? Because that developer has probably received multiple requests from other recruiters already, and my message is likely to disappear somewhere in all that noise. Over the years that I have worked as a recruiter, I have come to understand the importance of understanding the developers needs and desires before sending them multiple job descriptions, preferably even before I contact him or her. It is my duty, as a recruiter, to do my research before I expect a developer to take his or her time to talk with me. For example, If I check their Github I may find out that this developer prefers back-end development in C#/.Net, then I know that it won’t be necessary for me to contact him or her in order to talk about a front-end position where your main focus is in React and Typescript. If I don’t do my research, I’m likely to waste the person’s time. If I don’t find anything on Github or similar, then I think it is pure decency of me to first of all ask if they are interested in having a conversation with me and if they are, I can’t just throw a job description in their face without first understanding what this person is interested in.</p>
<p><strong>Has everything changed with the pandemic? Is development work hard to find now?</strong></p>
<p>Emy: A lot has changed with the pandemic. From my experience, I think that the biggest challenge for recruiters right now is that developers in general are unwilling to take on a new job, even though they might know that their current position isn’t exactly what they want. I think it’s a result of the uncertainty with the pandemic, that no one knows how it will develop and what will happen next. Since the pandemic seriously shook the market during spring and summer, many developers are worried that it will put them in a situation where they’ve left a permanent employment and the safety that it entails, to be the “last man/woman in, first out”.</p>
<p>In the beginning of the pandemic the market was disastrous, from March until September it was clear that even the IT-industry (despite the great demand) suffered from the pandemic. Many start-ups had to end their businesses and bigger companies were prohibited from hiring, many were even forced to dismiss employees in order to survive. Since August until today it has eased, and more companies dare to hire today. With that said though, companies take precautions when hiring and the processes might include more steps than normally in order to be really sure that it’s a good fit for the position.</p>
<p>I’d say that there are many opportunities on the market by now, but of course we are far from “normal”. Unfortunately, many companies demand more senior developers today, in order to fill the positions that they dismissed during spring. So, for junior developers it may still be a challenge to find their first or next position. Many companies can hire junior developers as a short-term consultant-assignment, so it is advantageous to be open to these opportunities as a junior developer.</p>
<p><strong>Is the poor reputation of the recruitment profession in tech among developers deserved or overstated?</strong></p>
<p>Emy: Sadly, I do think that it is deserved. I think that many recruiters have the wrong approach when recruiting for developer-positions. I have talked to many, many, many developers about this, and my understanding of the situation is that developers experience that recruiters don’t understand them nor their industry. And above all, many developers think that recruiters are a bit ignorant and uninterested in understanding it.</p>
<p>Recruiters and developers communicate differently, which is natural due to very different professions. …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/asking-a-tech-recruiter.html">https://underjord.io/asking-a-tech-recruiter.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/asking-a-tech-recruiter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207447</guid>
            <pubDate>Wed, 25 Nov 2020 09:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207055">thread link</a>) | @dijit
<br/>
November 25, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207055</guid>
            <pubDate>Wed, 25 Nov 2020 08:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get lots of ideas for side projects and writing]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25206661">thread link</a>) | @thesephist
<br/>
November 24, 2020 | https://linus.coffee/note/having-ideas/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/having-ideas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>People ask me how I get so many <a href="https://thesephist.com/projects/">ideas for interesting side projects</a> and <a href="https://thesephist/posts/">blog posts</a>.</p>
<p>I think the best way to describe my growth as a writer/maker over time is that I’ve become more efficient at discovering and refining my own ideas.</p>
<p>There are always ideas floating around in your brain. Sometimes, it comes to you out of the blue in the shower. Sometimes, you’re reading the news over dinner and a particular combination of words sets off a lightbulb. Sometimes, you’re reading and a metaphor resonates with you, so you contemplate on it in the hopes that it leads to an interesting perspective on something else. The key is to <strong>pay attention to your own wandering mind</strong>, notice when good ideas pass by in your mind for a split second, and grab a hold of it and pin it down on your mental desk and don’t let go, until you can expand that idea into something more interesting or valuable.</p>
<hr>
<p>There are fundamentally two knobs you can turn in the imaginary faucet of ideas.</p>
<p>The first is your <strong>creative input</strong>. This is a measure of the diversity and volume of interesting stories, knowledge, music, ideas, and advice you hear regularly. More and more, interesting ideas come to me as a combination of something I read or learned before, and an interesting metaphor or perspective I hear in the moment. The more quality, creative content you consume, the more source material you have from which your brain can synthesize new creative ideas. The diversity of content matters here. You’re going to have much better luck producing creative ideas when you combine knowledge or stories about completely different, unrelated topics, than by combining related existing ideas with each other.</p>
<p>The second knob is your <strong>creative efficiency</strong>, which I define as the fraction of interesting ideas that may occur to you, that you capitalize on. The human mind has tens of thousands of thoughts a day. Because of that staggering volume, most of the time, we’re trained to tune things out and dismiss internal mental side-conversations. But I think prolific creatives are able to counteract that urge to stay focused and hook onto an interesting ideas whenever it passes them by, and then learn to develop it into an insight or a piece of work. Lots of writers I talk to who are starting out tell me that they have ideas that are “mildly interesting” – not completely obvious, but not insightful. The best writers and artists and storytellers have a <em>skill</em> of developing these mildly-interesting ideas and stories into something more profound or valuable, and I think this is a skill that comes only with practice.</p>

        <hr>
        <p>
            
            ←
            <a href="https://linus.coffee/note/writing-growth/"><em>Growth as a writer</em></a>
            
        </p>
        
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/having-ideas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206661</guid>
            <pubDate>Wed, 25 Nov 2020 07:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Banned for Security Research]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206462">thread link</a>) | @arkadiyt
<br/>
November 24, 2020 | https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html | <a href="https://web.archive.org/web/*/https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Note that this post does not reflect the opinions of my employer nor my colleagues, and I conducted this research on my own time.</em></p>

<p>About a week ago, Activision banned me from Call of Duty: Modern Warfare/Warzone (2019) for attempting to study the security of its networking code.</p>

<p>As a user, I think I ought to be able to research vulnerabilities when I may be at risk. Multiplayer games do a great deal of networked communication, both between the user and the vendor (e.g., for fetching stats or user configuration) and between users (when hosting a private game or communicating over the microphone). A user should be able to trust that playing the game in a typical manner should not lead to a compromise. Some initial background research revealed that other security researchers, like me, have reverse engineered previous iterations of the game to discover and report vulnerabilities. There is already a precedent for both the validity of the security risk and Activision’s demonstrated openness to vulnerability reports [<a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-20817">1</a>, <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2018-10718">2</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/huffman">3</a>, <a href="https://github.com/momo5502/cod-exploits/tree/master/steam-auth">4</a>].</p>

<p>To do this research, I needed to reverse engineer the networking code in the game’s executable, as this would allow me to review the code for memory corruption vulnerabilities. Unfortunately, the executable was heavily obfuscated, and IDA was unable to analyze it. Therefore, I had to dump the unobfuscated code from the memory of a running game process. I believe it was at this point where the developers flagged me as a suspected cheater. I did two things to try to read memory from the process while I was in the main menu to avoid affecting any players. First, I attached WinDbg, and the game exited (probably the flagging event). Next, I tried pausing the process before dumping memory from it. I simply dumped an image of the game from memory in the main menu and then exited normally.</p>

<p>After spending a few days reviewing the binary, I decided that the binary was so large and unwieldy to deal with that I would table the project for a later date. But unfortunately, I was banned about a month later, losing over a year of progress on my account. The ban saddens me on a personal level as I’ve reconnected with family and friends from throughout my life playing this game during the pandemic. But more importantly, this sends a clear signal: this research is not welcome. I believe I had a reasonable expectation that it would be. I had done similar work during a CTF, where I reverse engineered and fuzzed CS:GO without ever risking a ban. Valve regularly accepts bug reports, and in one case, they paid a researcher $18000 for <a href="https://hackerone.com/reports/470520">reporting a vulnerability</a>.</p>

<p>Cheating is one of the biggest threats to the experience of gamers online. I understand that the developers shoulder an impressive burden in preventing cheat development and use. They need to leverage a variety of signals to detect cheat development and use. I’m guessing that because they may not have seen security researchers reviewing their platform before, they interpret any attempt to reverse engineer as a sign of malicious behavior. No typical player would attach a debugger to the game, and therefore they probably assume they don’t need much more evidence beyond this to issue a ban. Let me be clear: at no point did I intend to develop or use a cheat, and at no point did I manipulate any aspect of the game for another player or even myself. To this day, I don’t know what exactly caused the ban, and there’s no process to appeal it. What if using a reversing tool as part of my job gets me flagged? This fear is in the back of my mind for all games with anti-cheat, not just Warzone.</p>

<p>Where do we go from here? Obviously, I’d appreciate it if Activision unbanned my account. More importantly, I think they should provide a way for security researchers to have a place in the ecosystem by carving out exemptions for security research and establishing a point of contact (even a bug bounty) for vulnerability reports. The task of managing cheaters on the PC platform is growing both in difficulty and <a href="https://www.pcgamer.com/the-controversy-over-riots-vanguard-anti-cheat-software-explained/">controversy</a> - and I believe that Activision should join Valve and other publishers in fostering a symbiotic relationship with security researchers rather than an adversarial one. Together we can make games safer from cheaters and malicious users alike.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nedwill.github.io/blog/jekyll/update/2020/11/25/banned-for-research.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206462</guid>
            <pubDate>Wed, 25 Nov 2020 06:23:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Overengineering. Predicting the future does not work]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206269">thread link</a>) | @DevTalker
<br/>
November 24, 2020 | https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/ | <a href="https://web.archive.org/web/*/https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>This one will be short.</p>



<p>Yesterday, while I was browsing a programming forum, I came across a statement like this:</p>



<p>â€œâ€¦ and currently, I am creating some neat abstractions if I need something more in the futureâ€¦â€�.</p>



<p>This is so wrong! And let me tell you why.</p>



<h2>Overengineering</h2>



<p>Overengineering in software development means creating something that is not needed. Something that brings overhead to the development process and inefficiency to the end product.</p>



<p>An elementary example of overengineering is if all your applications data can be saved in a 10 line XML file, but you use a SQL database.</p>



<h2>Predicting the future</h2>



<p>One of the reasons overengineering happens is because of a lack of information.</p>



<p>Often developers want to predict the future, so they are ready when new requirements come, or requirements change.</p>



<p>The practice and statistics show that they are tragically bad at that.</p>



<p>In fact, even business people donâ€™t know how requirements will change.</p>



<p>Thatâ€™s why <a href="https://en.wikipedia.org/wiki/Agile_software_development">agile methodologies</a> were born.</p>



<p>In the modern world of software development, it often happens during one sprint to create functionality, and in the next one, to change it so drastically that it is better to start all over again.</p>



<p>Do you believe that you will have the right estimate and create the right thing from the first time with all this uncertainty and change? I believe not.</p>



<p>Predicting the future is a waste of <a href="https://ddimitrov.dev/2020/06/29/software-development-is-about-being-effective-and-efficient/">resources</a>, so donâ€™t do it.</p>



<h2>Inexperienced developers</h2>



<p>Inexperienced developers tend to create overengineered things by default ðŸ˜Š. And thatâ€™s is normal for their level.</p>



<p>They do it mainly because of two reasons.<br>1) They want to create something complicated and â€œcoolâ€�, trying new practices, patterns, and technologies.</p>



<p>2) They donâ€™t see a simple way of doing it.</p>



<p>Only gaining experience can solve the second one, but inexperienced developers should intentionally avoid the first one.</p>



<p>Donâ€™t get me wrong. <a href="https://ddimitrov.dev/2020/10/18/how-to-learn-to-become-a-good-software-developer/">New things should be tested</a>, but not directly on paying customerâ€™s projects.</p>
				
		</div></div>]]>
            </description>
            <link>https://ddimitrov.dev/2020/11/24/overengineering-predicting-the-future-does-not-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206269</guid>
            <pubDate>Wed, 25 Nov 2020 05:29:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206221">thread link</a>) | @azhenley
<br/>
November 24, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206221</guid>
            <pubDate>Wed, 25 Nov 2020 05:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatic Content Recognition (ACR) – How Does It Work?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25206054">thread link</a>) | @ponderingfish
<br/>
November 24, 2020 | https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/ | <a href="https://web.archive.org/web/*/https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Automatic Content Recognition (ACR) refers to technology embedded into OTT applications or SmartTVs that recognizes the content that you are watching by sampling small portions of the video/audio and comparing it with a large database. </strong></p>



<p>ACR is prevalent in SmartTVs and hand-held devices and plays a major role in the audience measurement and ad-tracking industry. </p>



<p>In this article, let’s take a look at how Automatic Content Recognition or ACR works and some use-cases for this technology. </p>



<hr>



<h2>Firstly, how is Data Gathered from OTT Applications?</h2>



<p>Before we look at ACR, let’s first take a quick look into the field of analytics and data gathering in OTT. </p>



<p>Typically, an SDK or library is integrated into an OTT application (HTML5, Android, iOS, SmartTV app, etc.) and then released to the public. Once it’s installed on a phone, or TV, the application can track the user’s actions, the content being watched, etc. at a very granular level. </p>



<p>Each time the user presses play/pause/stop/etc., the SDK records the action and reports it back to a server. Similarly, data points from millions of users are gathered, cleaned, and then presented in a useable format in dashboards back to the OTT content provider. </p>



<p>In most cases, it’s usually the publisher (aka content provider) who is the consumer of this information and the publisher uses it to improve their QoE, content offering, advertising strategies, etc. </p>



<p>You may think that this level of data-gathering is intrusive, but, the fact of the matter is that you agreed to this by pressing “Yes” on the consent form when you installed the app which in all likelihood, you didn’t read! </p>



<p>With that introduction to data-gathering (which is rather common in today’s world), let’s switch over to another form of intelligence-gathering – Automatic Content Recognition (ACR).</p>



<hr>



<h2>What is Automatic Content Recognition?</h2>



<p>Automatic Content Recognition refers to technology that samples the audio or video that a user is consuming, creates a fingerprint from that sample, and compares this against an extensive database of fingerprints to automatically recognize what was being watched or listened to. In some instances of ACR, the recorded sample might be directly transmitted to a server for processing and further information extraction.</p>



<hr>



<h2>How Does Automatic Content Recognition Work?</h2>



<p>As we’ve already seen, ACR works by sampling the video and/or audio and using that information to determine the content being consumed. This leads us to <strong>Acoustic (or Audio) Fingerprinting</strong> and <strong>Video Fingerprinting.</strong></p>



<p>Here’s a visual explanation of ACR works. Simply put, </p>



<ul><li>fingerprints are generated for the media that needs to be recognized (using either audio or video fingerprinting techniques). These fingerprints are stored in a database. </li><li>ACR-enabled SmartTVs, phones, or other devices generate similar fingerprints and transmit them to a server that compares these device-generated fingerprints with the main database to find a match. </li><li>Based on database-match, metrics or data are generated that provide insights into media consumption. </li></ul>







<div><figure><img loading="lazy" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" alt="ACR Automatic Content Recognition
" width="622" height="370" srcset="https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=240x143&amp;lossy=1&amp;strip=1&amp;webp=1 240w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=300%2C178&amp;ssl=1 300w, https://889329.smushcdn.com/2063466/wp-content/uploads/2020/11/image-3.png?size=480x286&amp;lossy=1&amp;strip=1&amp;webp=1 480w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=768%2C457&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1024%2C609&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=1200%2C713&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?w=1396&amp;ssl=1 1396w" sizes="(max-width: 622px) 100vw, 622px" data-recalc-dims="1" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/11/image-3.png?resize=622%2C370&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>







<p>That’s fundamentally how fingerprinting and ACR works. Now, let’s take a look at the different techniques used in ACR.</p>



<h3>Acoustic Fingerprinting</h3>



<p>Quoting from Wikipedia, <strong><em>an acoustic fingerprint is a condensed digital summary, a fingerprint, deterministically generated from an audio signal, that can be used to identify an audio sample or quickly locate similar items in an audio database.</em></strong></p>



<p>Certain metrics such as frequency, amplitude, tempo, spectrum (i.e., characteristics in the frequency domain), etc. are used in building a fingerprint or signature of the audio signal. </p>



<p>Another reason why this is important is that audio is generally compressed before transmission. And compression algorithms generally remove characteristics of an audio signal that are not perceptible to humans. Hence, the acoustic fingerprinting algorithm that are you building should also take these sources of distortion and noise into account. </p>



<h3>Video Fingerprinting</h3>



<p>Similar to Audio Fingerprinting, in Video Fingerprinting, small video clips are made from the original video, and certain characteristics are extracted from it. These techniques take care to ensure that image manipulation technologies like compression, or resizing do not affect these fingerprints and the content can be recognized nonetheless. </p>



<h3>Digital Watermarking</h3>



<p>Watermarking is the process of embedding data into video/audio <strong>covertly </strong>such that the embedded information is not ordinarily or easily detected. The watermark can be detected only by specialized and authorized <strong>watermark&nbsp;detecting software</strong>. Watermarking allows publishers to track piracy and establish authenticity.  In the case of Automatic Content Recognition, one can use Watermarking as a method of detecting if someone has engaged with or watched a content. </p>



<hr>



<h2>Uses of ACR</h2>



<p>There are several uses of ACR technology. Some of the more prominent ones are – </p>



<ol><li><strong>Detection of copyright infringement: </strong>Copyrighted material such as video and audio are often used indiscriminately without attributing or paying royalties to the original content creators. If a database of copyrighted content exists, then large UGC platforms such as YouTube, TikTok, Vimeo, etc. could check to see if user-uploaded content contains copyrighted material or not. </li><li><strong>Ad-tracking</strong>: ACR has found a lot of use in the advertising industry and for good reason. Here’s why –<ol><li>Unless you have the <strong>ability to determine if an ad was played and watched by the end-user </strong>(instead of being buried at the end of a long landing page), then your metrics don’t make a lot of sense and it could lead to inflated data with respect to ad impressions, plays, and completion rates. This requires SDKs and changes to the players that can consume a lot of effort and development cycles. </li><li>However, ACR has the ability to recognize the content that is being played by sampling certain pixels of video, or by recognizing the audio. This enables ACR to provide a better picture to the advertisers and publishers on the ad delivery and engagement. </li></ol></li><li><strong>Collating information from different sources</strong>: This is a very interesting use-case of ACR. In most homes, there is one big TV in the living room where people gather to watch movies. However, the content streaming to the TV could come from an STB, Chromecast, Roku, FireStick, or an Xbox. Instead of embedding code inside all these devices, SmartTVs with ACR can recognize the content being played (from the “glass”) and report on it. This allows for content attribution and normalization across a variety of sources. </li><li><strong>Understanding Audiences and their preferences</strong>: Similar to other methods of gathering usage analytics, ACR allows broadcasters and content providers to know how their audience is responding to their content, marketing, strategies, etc. By having fine-grained information about their audience and their usage patterns, broadcasters can better invest their dollars and get a much higher ROI. </li><li><strong>Ad Retargeting by OEMs</strong>: Samsung includes ACR technology in their SmartTVs and sells ad inventory and provides<a href="https://www.samsung.com/us/business/samsungads/resources/tv-ad-retargeting/" target="_blank" rel="noopener"> ad-retargeting services</a>. According to their website, “<em>Samsung Ads offers TV Ad Retargeting that empowers brands to identify audiences who saw or missed their TV spots and reconnect with them via mobile, tablet, desktop or OTT</em>.” And, <em>“Samsung Smart TVs have built-in Automated Content Recognition (ACR) technology that can understand viewing behavior and usage including programs, movies, ads, gaming content and OTT apps in real-time”</em>. You can read more about Samsung’s Privacy Policy <a href="https://www.samsung.com/sg/info/privacy/" target="_blank" rel="noopener">here</a> where they are pretty open about recording your video and audio to understand “you” better! </li></ol>











<hr>



<h2>Controversies Surrounding ACR</h2>



<p>The bone of contention around ACR is due to the fact that audio and/or video are recorded, fingerprinted, and often stored for future use. Some devices might be able to generate the fingerprints on-device, but some might send the audio recordings to the cloud for further processing. </p>



<p>So what happens if your private conversations are in those recordings? Who is listening on the other end?</p>



<p>Samsung got into one of these sticky situations and had to clarify in a <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">press release</a>. Their initial privacy policy stated –</p>



<p><em>“Please be aware that if your spoken words include personal or other sensitive information, that information will be among the data captured and transmitted to a third party through your use of Voice Recognition.”</em></p>



<p>This spooked a lot of people and Samsung had to backtrack and <a href="https://news.samsung.com/global/samsung-smart-tvs-do-not-monitor-living-room-conversations" target="_blank" rel="noopener">release a clarifying note</a> that said – </p>



<p><em>If you enable Voice Recognition, you can interact with your Smart TV using your voice. To provide you the Voice Recognition feature,&nbsp;some interactive voice commands may be transmitted (along with information about your device, including device identifiers) to a third-party service provider (currently, Nuance Communications, Inc.) that converts your interactive voice commands to text and to the extent necessary to provide the Voice Recognition features to you. In addition, Samsung may collect and your device may capture voice commands and associated texts so that we can provide you with Voice Recognition features and evaluate and improve the features. Samsung will collect your interactive voice commands only when you make a specific search request to the Smart TV by clicking the activation button either on the remote control or on your screen and speaking into the microphone on the remote control.</em></p>



<p>And, please don’t think that I am picking on Samsung. Another TV manufacturer, Vizio was fined by the FTC for not being forthright with its data-tracking policies. (<a href="https://www.ftc.gov/news-events/press-releases/2017/02/vizio-pay-22-million-ftc-state-new-jersey-settle-charges-it" target="_blank" rel="noopener">link to the notice on the FTC website</a>). </p>



<p>And, here’s an interesting <a href="https://www.consumerreports.org/privacy/how-to-turn-off-smart-tv-snooping-features/" target="_blank" rel="noopener">article from consumerreports.org</a> on how to turn off “snooping” features on Android TVs,&nbsp;Amazon Fire TV Edition,&nbsp;LG,&nbsp;Roku,&nbsp;Samsung,&nbsp;Sony, and&nbsp;Vizio.</p>



<p>All of this constitutes a weird situation, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/">https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/acr-automatic-content-recognition-how-does-it-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206054</guid>
            <pubDate>Wed, 25 Nov 2020 04:30:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Great software engineers are never actively looking for a job on job boards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205830">thread link</a>) | @karlhughes
<br/>
November 24, 2020 | https://www.karllhughes.com/posts/hiring-process | <a href="https://web.archive.org/web/*/https://www.karllhughes.com/posts/hiring-process">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>
<div>
<p><img src="https://www.karllhughes.com/assets/img/hiring.png" alt="Recruiting and Hiring Software Engineers">
</p> 

<p>
2020, Nov 13&nbsp;&nbsp;&nbsp;—&nbsp;
13 minute read
</p>
<section id="mc_embed_signup">

</section>
<p>When I took my first real management role as <a href="https://www.karllhughes.com/posts/packback-engineering">Packback’s Head of Engineering back in 2015</a>, I inherited a great team of engineers who were hired before my promotion. Later that year, when the time came for me to do some of my own hiring, I had to quickly adopt a process for finding and onboarding new software engineers.</p>
<p>I started with the framework my predecessor used and brought in some heavy influences from <em><a href="https://www.karllhughes.com/posts/peopleware">Peopleware</a></em> and Josh Tyler’s <em><a href="https://amzn.to/1XQAfT7">Building Great Software Engineering Teams</a></em>. Over the years, I’ve refined my hiring process - mostly through trial and error - to come up with the iteration described here.</p>
<p>My approach is a little unconventional, but I hope it inspires you to think outside the box. This is going to be a long read, so I’ve broken it down into five sections:</p>
<ol>
<li><a href="#the-problem-with-hiring-software-engineers">The Problem with Hiring</a></li>
<li><a href="#skills-i-look-for-in-software-engineers">Skills I Look For</a></li>
<li><a href="#how-i-find-software-engineers">How I Find Candidates</a></li>
<li><a href="#how-i-hire-software-engineers">How I Hire Engineers</a></li>
<li><a href="#mistakes-ive-made-when-hiring-software-engineers">The Mistakes I’ve Made</a></li>
</ol>
<p><em>Note: If you’re looking for some books to help you on your journey as a software engineering manager, <a href="https://www.karllhughes.com/posts/reading-for-engineering-managers">here are some of my favorites</a>.</em></p>
<h2 id="the-problem-with-hiring-software-engineers">The Problem with Hiring Software Engineers</h2>
<p>Any <a href="https://www.karllhughes.com/posts/engineering-manager">engineering manager</a> who’s hired people in the past will tell you that it’s hard.</p>
<p>There are lots of constraints, no way to fairly compare two candidates, and suitable candidates for one team may be horrible for another. Because it’s so hard, the process has evolved to favor people who think like the interviewers, who know someone at the company, or who perform well in high-pressure interviews. It leaves people with non-traditional backgrounds struggling, often works against diverse candidates, and is nothing like the day-to-day work that most engineers do.</p>
<p>For example, a typical interview may require a phone screen with a recruiter who tests for “soft skills.” Next, an engineering manager may screen for baseline technical skills, and then the candidate may be asked to complete an independent project or come into the office for a whiteboarding session. In either case, <strong>the interview is nothing like a typical day working as an engineer</strong> (although the “take-home” project may be the closest in some environments).</p>
<p>Soft skills are important, but “tell me about a time when…” questions favor people who are quick to make things up, and they <a href="https://www.forbes.com/sites/lizryan/2014/03/04/why-i-hate-behavioral-interviewing/#7229c954693c">don’t demonstrate real judgment or problem-solving skills</a>. It’s impossible to assess someone’s character in a 30-minute phone screen, so at best, you can weed people out who are completely unreliable or have poor verbal communication skills.</p>
<p>Similarly, it’s very hard to judge a person’s technical ability in all things during a 1-hour tech screening. The field of web development (and software engineering in general) is so vast that nobody is going to match your requirements perfectly. You can ask them what technologies they’re familiar with and see if they can have a coherent conversation about technical topics, but you probably can’t bump up against the edges of all of their knowledge, especially if it doesn’t overlap with your own.</p>
<p>Finally, I’ve never done whiteboarding or live coding sessions with candidates, but <a href="https://theoutline.com/post/1166/programmers-are-confessing-their-coding-sins-to-protest-a-broken-job-interview-process">a lot of people really hate them</a>, and I think there’s a good reason for that. In the real world, programmers pushed in front of an audience to solve a problem with an obscure algorithm, no time for independent research, and no access to resources. I would never do this job if that were my day-to-day.</p>
<p>Testing programmers at something they don’t need to be good at and expecting to learn something about how they would work at your company is delusional. These kinds of interviews only serve to make the hiring team feel superior and ensure better outcomes for engineers with traditional CS backgrounds.</p>
<h2 id="skills-i-look-for-in-software-engineers">Skills I Look for in Software Engineers</h2>
<p><img src="https://i.imgur.com/FfOzjCZ.jpg" alt="Software Engineering Skills"></p>
<p>In an effort to redesign our hiring process around the skills that actually matter in software engineering, I took the problem down to <a href="https://fpt.guide/">first principles</a>. What skills do I need in a team of software engineers?</p>
<h3 id="initiative">Initiative</h3>
<p>I have never liked micromanaging people. I remember being a team lead at a restaurant in college and getting irrationally annoyed with people who would stand around while customers were lining up at the register. “Go, take an order or something!”</p>
<p>I digress.</p>
<p>Most software engineers who are looking for a job have a certain level of initiative, but great software engineering candidates go the extra mile all the time. For example, I worked with a guy at Packback who had built a website and extremely popular Twitter account to follow the chatter on police scanners. He did all this to learn new things for fun.</p>
<p>Software engineers who take initiative don’t wait for the hiring manager to email them back, they ask about next steps, and they read about the company before they show up for an interview. It’s not really that hard, but it does take time, and very few candidates do it.</p>
<h3 id="reliability">Reliability</h3>
<p>Initiative is a start, but <a href="https://www.karllhughes.com/posts/hero-myth">I don’t want a hero</a>. I want to build a team of consistently reliable engineers who improve over time.</p>
<p>Candidates with a history of staying in jobs for a long time, strong references, and commitment to projects usually make it to the top of my list when hiring.</p>
<h3 id="competency">Competency</h3>
<p>When I was a new engineering manager, I over-indexed on technical skills. It’s easy to fall into the trap of grading engineers based purely on their technical knowledge (whole companies like <a href="https://www.toptal.com/">Toptal</a> and <a href="https://triplebyte.com/">Triplebyte</a> are built on this fallacy), but arcane trivia does not make a sound engineer.</p>
<p>I’ll talk more about how I gauge a candidate’s competency later in this post, but the key question I ask is, <strong>do I think this engineer can learn to solve the problems we are facing?</strong></p>
<p>It’s not about whether they know all the answers on day one, but instead, I look for curious people who are lifelong learners with a drive to improve themselves. If they have that, I’ll find a way to get them the information they need to succeed in this role.</p>
<h3 id="interest-in-the-mission">Interest in the Mission</h3>
<p>I used to call this “passion,” but after a <a href="https://www.listennotes.com/podcasts/exceptions-welcome/building-a-resilient-career-dea4tx69g32/">lively conversation on the Exceptions Welcome podcast</a> I decided to rebrand this skill.</p>
<p>Ultimately, I only want to hire software engineers who care about our industry, the problems we’re solving, and the method we’re using to get there. If we aren’t pointing in the same direction before they join, I don’t want to spend the first six weeks convincing them.</p>
<p>While I don’t want unquestioning loyalty or people who live at the office, I do think it’s important that software engineers are actually interested in the work they will be doing. It’ll make them happier, and that positivity rubs off on everyone.</p>
<h2 id="how-i-find-software-engineers">How I Find Software Engineers</h2>
<p><img src="https://i.imgur.com/bTlxNvy.jpg" alt="Finding Software Engineers"></p>
<p>I’ve used several methods for finding and recruiting software engineers over the years. While I don’t have a ton of data to back up these methods, here’s what I’ve found works for me.</p>
<h3 id="job-listings">Job Listings</h3>
<p>Job listings are the <em><a href="https://unbounce.com/landing-page-articles/what-is-a-landing-page/">landing page</a></em> for job hunters.</p>
<p>A compelling job listing should outline the tools and languages the candidate should know, the projects the candidate will work on, and as much information about day-to-day expectations as is reasonable. I try to make job listings interesting and creative, so I typically use a GitHub repository with lots of information about our team, our company, and the job interview process (<a href="https://github.com/thegraidenetwork/job-openings">here’s an example of the repo I set up for The Graide Network</a>).</p>
<p>Remember that you won’t just share this listing with candidates. You’ll also be emailing it out to everyone in your network, sharing it on social media, and linking to it from your website. It’s a public-facing document that should be good looking and functional.</p>
<h3 id="networking">Networking</h3>
<p>I’ve never paid money to promote a job listing, but I doubt it’s worth it, and here’s why:</p>
<p><strong>The best software engineers are never <em>actively</em> looking for a job on job boards.</strong></p>
<p>They’re locked away behind gatekeepers called “their network,” which includes former managers and coworkers, friends, and people who know them from professional organizations. They jump ship when someone they trust tells them about a great opportunity or when they decide to ask around. Senior software engineers often laugh about how many Linkedin messages we get from naive recruiters.</p>
<p>So, what’s the trick to building a network full of software engineers?</p>
<p>Time.</p>
<p>People are surprised when I tell them that <a href="https://www.karllhughes.com/posts/the-key-to-networking-keeping-in-touch">I spend 4-8 hours per week building and maintaining my network</a>, but the dividends on that investment have been enormous. Whenever I have a new job opening, I write up a job listing and start passing it around. I keep a huge list of people I’d like to work with someday, so I go through it and find an excuse to get lunch.</p>
<p>If you’re not actively building your network right now, start <a href="https://ctocraft.com/blog/how-to-use-writing-to-build-a-solid-talent-pipeline/">writing</a>, <a href="https://www.karllhughes.com/posts/speaking-guide">speaking</a>, and taking meetings with interesting people. It’s the best investment you can make in your career.</p>
<h3 id="cold-outreach">Cold Outreach</h3>
<p>Another unpopular recruiting tool for finding software engineers is cold outreach. I’ve found that it can work, but you have to be careful. It’s easy to come off as spammy or annoying.</p>
<p>Treat cold outreach as an excuse to grow your network rather than jumping straight to “the ask.” Reach out to people, ask them genuine questions; do some research on their background; get to know them. You’re just having a conversation, and eventually, you might slide in a mention that you’re keeping an eye out for software engineers.</p>
<p>End each call by asking if you can follow up in a few months and (shocker!) actually do it. I’ve met some outstanding people this way, even if we never ended up working together.</p>
<h3 id="recruiters">Recruiters</h3>
<p>Recruiters get a bad name in the software engineering world because they can be pretty annoying. I’ve had junior recruiters cold call me at work or send job requests to my company email. Not a good look.</p>
<p>On the flip side, there are a few well-networked and honest tech recruiters out there. Just be ready to pay big bucks as the best likely work on a <a href="https://theundercoverrecruiter.com/contingency-vs-retained-recruiters-what-difference/">retainer rather than contingency</a>.</p>
<p>Even if you do get a recruiter, you need to keep recruiting too. If your recruiter doesn’t have any luck, you don’t want all your leads to dry up with them.</p>
<h2 id="how-i-hire-software-engineers">H…</h2></div></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.karllhughes.com/posts/hiring-process">https://www.karllhughes.com/posts/hiring-process</a></em></p>]]>
            </description>
            <link>https://www.karllhughes.com/posts/hiring-process</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205830</guid>
            <pubDate>Wed, 25 Nov 2020 03:42:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[4 V's of Good Data Engineering]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205610">thread link</a>) | @apex-consulting
<br/>
November 24, 2020 | https://theapex.io/4-vs-big-data | <a href="https://web.archive.org/web/*/https://theapex.io/4-vs-big-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <p>When talking about scalable data engineering there are four broad categories of questions that we like to start with. I like to call these the four V’s of Good Data Engineering: Volume, Velocity, Variety and Veracity.</p>

<h3 id="overview">Overview</h3>
<ol>
  <li><a href="#volume">Volume</a>
    <ul>
      <li><a href="#current">Current</a></li>
      <li><a href="#desired">Desired</a></li>
      <li><a href="#anticipated">Anticipated</a></li>
    </ul>
  </li>
  <li><a href="#velocity">Velocity</a>
    <ul>
      <li><a href="#input">Input Velocity</a></li>
      <li><a href="#output">Output Velocity</a></li>
      <li><a href="#intra">Intra Velocity</a></li>
      <li><a href="#pressure">Pressure</a></li>
    </ul>
  </li>
  <li><a href="#variety">Variety</a>
    <ul>
      <li><a href="#flexibility">Flexibility</a></li>
      <li><a href="#discoverability">Discoverability</a></li>
      <li><a href="#useability">Useability</a></li>
    </ul>
  </li>
  <li><a href="#veracity">Veracity</a>
    <ul>
      <li><a href="#traceability">Traceability</a></li>
      <li><a href="#expl">Explainability</a></li>
      <li><a href="#expl">Auditability</a></li>
      <li><a href="#security">Security</a></li>
    </ul>
  </li>
</ol>


<p><img src="https://theapex.io/assets/images/volume.png" width="600"></p>
<p>Volume is simply a measure of how much data you wish to process. This is usually a discussion of gross numbers and timelines associated with them, and gives a rough idea of some architecture constraints and guidelines. For volume the discussion is a straightforward one about business goals and aspirations. Usually the discussion breaks down as follows:</p>
<h3 id="-current-volume"><a name="current"></a> Current Volume:</h3>
<p>What is the current volume of data that a particular data pipeline or system is processing. You can also discuss the current architecture and any bottlenecks it may be facing. When looking at current volume of data some considerations that may matter are:</p>
<ol>
  <li><strong><em>Volumes per access level</em></strong>: What volumes of data currently in terms of access patterns. In other words, there may be 10 PB worth of data, but 9 PB of that may be “cold data” or archive data and only 1 PB is regularly accessed or used for any analytics. Further than that it could be that only 1 TB is “hot data” or data that is frequently accessed. This will also impact how data estimates could be affected, for example archive data may be compressed or stored in columnar or analytical formats which would not give an accurate comparison to row based serial data.</li>
  <li><strong><em>Data Retention</em></strong> Companies may not be keeping all the data they wish to currently keep and have imposed retention policies which they may choose to remove if they have a more scalable data strategy in place. Data Retention can also be used to estimate the amount of data flowing through a system regardless of persistence for data processing purposes.</li>
  <li><strong><em>Record/Message size</em></strong> For each current dataset, how big is a record, and at a static point in time how many records of that size are there? In a streaming context this can impose hard limitations on what technologies can be used (Kafka vs. Kinesis for example), in a static data warehousing context it may give ideas about current suboptimal data model design or heavy denormalization patterns along low latency paths in the data pipeline.</li>
  <li><strong><em>Data Footprint</em></strong>  The amount of data a company stores may not be reflective of the total data footprint the company has especially when taking into consideration data retention policies, data that is ephemeral or not stored anywhere, or query patterns which adopt patterns of heavy denormalization. In well-designed systems some denormalization will lend itself towards better separation between write and read latencies, but will result in a lot of duplicate data. Another example of necessary duplicate data is in RAID configurations or replication such as with HDFS, and backups. In other cases there may be unnecessary duplicate data. Its important to suss out instances of heavy data duplication, necessary or not, in order to get a sense for the total data footprint and distinguish between “raw” system data and derived data that the company has synthesized for various reasons.</li>
  <li><strong><em>Key Datasets</em></strong>  It may also be helpful to get a sense for what are the largest datasets a company deals with and the most frequently changing. Sometimes you can infer key elements about how that dataset may change over time, and thus the right strategy for designing around that dataset. For example if they say their largest dataset is “users” and they are a B2C retail company then you can infer that table is most likely to see heavy growth as the business grows, and will have higher demands for read and write latency.</li>
</ol>

<h3 id="desired-volume"><a name="desired"></a>Desired Volume:</h3>
<p>What is the volume of data the company “wishes” to be able to process in the system. “As much as possible” is not an option, it must be finite and realistic. Over provisioning data processing capacity can get expensive really quickly, especially on the higher ends. More open-ended needs and requirements around scaling can be approached using autoscaling or adaptive scheduling. If the answer is “we dont know” an effort should at least be made to help the company try to estimate.</p>
<h3 id="-anticipated-volume"><a name="anticipated"></a> Anticipated Volume:</h3>
<p>This is meant to bookend the previous point. Whereas as the desired volume is where the company wants to be in X years, the anticipated volume is where the company is most likely going to be within that time. This serves as a lower bound where the desired volume forms a rough upper bound. A less jarring way to discuss desired and anticipated volume (because after all what business is going to admit they aren’t going to grow as fast as they want, even though for most businesses the amount of data being handled is a bad vanity metric) is to simply discuss upper and lower bounds of needed capacity.</p>


<p><img src="https://theapex.io/assets/images/velocity.png" width="800"></p>
<p>Velocity is a measure of how quickly the data is moving over time regardless of the volume of data. Normally it’s hard to talk about data velocity without talking about its desired latencies or limits of time that you have in order to process the data which is usually imposed by external technical or business requirements. You can talk about roughly 3 types of velocity:</p>
<h3 id="input-velocity"><a name="input"></a>Input Velocity:</h3>
<p>How quickly is data coming into the system and how does the system need to accommodate that. This can be as simple as knowing that you only have batch access to the data (daily data dumps) vs stream access to a particular subset of the data, thus can only in best case scenario provide batch analytics on it. Or it can be as complex as planning very tailored distributed stream systems to get a specific input consumption rate.</p>
<h3 id="output-velocity"><a name="output"></a>Output Velocity:</h3>
<p>How quickly does the data need to be accessed or read. Typically this is tied to the front end of the process and the business use cases of how the data is being used. Limits on the associated output latency may vary for different subsets of the data, and may also make exchanges between consistency and availability (in the spirit of the <a href="https://en.wikipedia.org/wiki/CAP_theorem">CAP theorem</a>).  In plain terms, you may be willing to sacrifice accuracy of the data for getting it quicker, or you may opt to scale out further in order to get tighter control over both speed and accuracy.</p>
<h3 id="intra-velocity"><a name="intra"></a>Intra Velocity</h3>
<p>Intra latency is the amount of latency that is permissible between input and output velocity, or you can think of it between the various components of a data pipeline. Intra velocity in a data pipeline is a little harder to tack down. Usually this is either an operational metric, or something that is observed and optimized post-hoc. However, this doesn’t mean it isn’t important as it can have cascading effects on other parts of a data pipeline, sometimes in unexpected ways. In streaming systems back pressure engineering is one way to observe and respond dynamically to changes and levels of intra velocity.</p>

<p><img src="https://theapex.io/assets/images/cascading.gif" width="400"></p>
<p>Cascading failures are familiar to those that have designed tightly coupled stream systems</p>
<h4 id="end-to-end-latency">End to End Latency</h4>
<p>Putting together the three latencies associated with each of these and you arrive at what people typically refer to as “end to end” latency requirements, ie once a piece of data hits your system, how much time do you have before your analytics or end users will see the impact of that data. Keep in mind that varying business use cases may have varying requirements around end to end latency. It is not a universal metric. However, multiple data pipelines may end up affecting one particular end to end latency and may require you to more carefully engineer a particular pipeline to “keep pace” with other parts of the pipeline.</p>



<p>Before going onto Variety, I want to make a quick note about the relationship between Volume and Velocity as they don’t exist in isolation but in terms of planning are heavily dependent on one another. In order to do so I want to introduce the idea of “data pressure”.</p>

<p>You can think of Data Pressure as follows:</p>

<div><div><pre><code>Data Pressure = Data Volume x Data Velocity 
</code></pre></div></div>

<p><img src="https://theapex.io/assets/images/pressure.png" width="300"></p>

<p>In other words a relatively low desired data velocity might be offset by higher data volume and vice versa. This basically expresses the data volume in terms of total amount of data needed to be processed per unit time. It is interesting to look at the limits of data pressure. For example, a really low data volume but high input velocity may lend itself towards stream processing. However, if the needed output velocity on the opposite end of the process velocity is very low, say daily, then it may lend itself towards buffering and then batch processing. In short, the pressure expresses how much strain is put on particular parts of a system and what extra parts of the system may need to be designed intermediately in order to marry front and backend pressure demands gracefully. Those parts that feel more pressure than may need to be given special attention, for example, horizontal scaling, or other strategies such as breaking up the data pipeline stages differently.</p>

<p><img src="https://theapex.io/assets/images/dataflow.png" width="800"></p>
<p>Thinking in terms of total data volume per unit time</p>

<p>In some instances certain processes may not decrease the total data pressure but simply exchange one type of pressure for another. For example, batch processing may be slower, but will allow for processing much higher volumes efficiently, whereas you can avoid processing larger volumes by simply micro batch or stream processing at lower frequencies. One is not better than the other, one may simply be more strategically convenient than the other when you take the whole picture into account.</p>

<p><img src="https://theapex.io/assets/images/pressure2.png" width="800"></p>
<p>You can think of a query over larger dataset but same latency similarly to higher pressure demand on a physical system</p>

<p>The other useful aspect of thinking in terms of pressure is that you can also think in terms of pressure differentials, for example, suppose that you have a very large dataset which you need to query with low latency. In …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theapex.io/4-vs-big-data">https://theapex.io/4-vs-big-data</a></em></p>]]>
            </description>
            <link>https://theapex.io/4-vs-big-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205610</guid>
            <pubDate>Wed, 25 Nov 2020 03:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Letters from Alaska]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205393">thread link</a>) | @DoreenMichele
<br/>
November 24, 2020 | https://www.gabrielzzarate.com/blog/alaska | <a href="https://web.archive.org/web/*/https://www.gabrielzzarate.com/blog/alaska">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><section><article><p><em>The following are selections from letters I wrote to my fiancé in the summer of 2014 while working for a commercial salmon fishing company in Kodiak, Alaska.</em></p><h3 id="14-May-2014---Kodiak-Harbor"><a href="#14-May-2014---Kodiak-Harbor" aria-label="14 May 2014   Kodiak Harbor permalink"></a>14 May 2014 - Kodiak Harbor</h3><p>Here in the harbor, there are probably about a hundred large commercial fishing boats docked. Just about every evening, we have seen sea lions come swim amongst the boats! They will surface from time to time. They're huge and entertaining to watch.</p><p>I was a little frustrated while we were working today. James and I have been helping another guy named Jeff. I'm frustrated because both of them have more experience with construction work. Sometimes I'll show my inexperience, and become the joke on the job site. It doesn't bother me too much, but being on the bottom of the totem pole isn't where I like to be. It just gives me the incentive to learn the fishing knots quickly.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/f3a60/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/08b4d/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/2b317/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.webp 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/bf173/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/acb04/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg 1074w" sizes="(max-width: 1074px) 100vw, 1074px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/7ac0ee8fb1779975df4997c9e927bb9e/edd00/4778D69B-63AB-4EE9-9F65-DE23C81EE62D_1_105_c.jpg" alt="Kodiak Harbor" title="Kodiak Harbor" loading="lazy">
      </picture>
    </span>
  <figcaption>Kodiak Harbor, Kodiak AK</figcaption></figure><h3 id="26-May-2014---Arriving-on-the-Island"><a href="#26-May-2014---Arriving-on-the-Island" aria-label="26 May 2014   Arriving on the Island permalink"></a>26 May 2014 - Arriving on the Island</h3><p>We arrived on Bear Island today. We took a flight from Kodiak to Larsen Bay, then hopped in the skiff to Bear. The scenery is beautiful, but our Island itself isn't much to look at. We got here and immediately started mending nets. A guy named Peter showed me how to tie the knots to mend the nets, and I'm getting the hang of it. Also, it turns out that our cook is great <!-- -->—<!-- --> what fantastic news! James and I were able to get a room together, just the two of us, which is nice.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/f3a60/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/08b4d/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/a9a89/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.webp 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/bf173/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/acb04/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg 1024w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/f89410ff96af6f091d8634e81884f97b/72e01/BF8E47A7-EB6F-42F0-9EF8-00FE9E405794_1_105_c.jpg" alt="Bear Island" title="Bear Island" loading="lazy">
      </picture>
    </span>
  <figcaption>Bear Island</figcaption></figure><h3 id="28-May-2014---Hiking"><a href="#28-May-2014---Hiking" aria-label="28 May 2014   Hiking permalink"></a>28 May 2014 - Hiking</h3><p>Because the season doesn't begin till the 9th, we can't send out mail every day like we will be able to. Today was my second full day on the Island. I mend nets most of the day. The nice thing is I get a break after lunch, and I have been reading and napping. Maybe this summer I can learn to sleep so I can enjoy many long naps next to you. </p><p>I think a big part of passing the time and not going crazy will be the friendships. Tonight after dinner James, Luke, Micah, and I hiked up to the highest point on the Island. It's not that far, but there is a good view up there. Luke challenged us to sprint to the top, but we only got 3/4 of the way before we almost passed out breathless.</p><h3 id="31-May-2014---The-Bana"><a href="#31-May-2014---The-Bana" aria-label="31 May 2014   The Bana permalink"></a>31 May 2014 - The Bana</h3><p>The last two days have been challenging as far as work goes. The weather has been pretty bad, a gale came in yesterday (when the wind blows hard), and it was cold and rainy. But even though it hasn't been the best working conditions, we've kept our spirits up.</p><p>Last night was my first shower here. But they don't just shower; they use what they call a Bana. It's a giant sauna. We sit in there and sweat out all the nasty stuff, then rinse off. It is super relaxing, and I haven't felt so clean in my entire time here.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/f3a60/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/08b4d/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/293e0/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/9a8a1/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/e72c3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c67aa/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bf173/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/acb04/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/bd53b/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/12609/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/93719/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/63dee56c867163ef1457bc38b838eb85/c58a3/956435E4-28BB-45DD-88FC-6CC15CF8092C_1_201_a.jpg" alt="Mike Falcochio" title="Mike Falcochio" loading="lazy">
      </picture>
    </span>
  <figcaption>Mike Falcochio</figcaption></figure><h3 id="6-June-2014---The-Season-Begins"><a href="#6-June-2014---The-Season-Begins" aria-label="6 June 2014   The Season Begins permalink"></a>6 June 2014 - The Season Begins</h3><p>Today is the second day of the season. Yesterday we got the nets out, and our first pick was pretty big. We only picked the nets once and brought in around 8,000 lbs, equal to like $16,000. Not bad for the first day. </p><p>When we put the nets out, I didn't take any medicine for sea-sickness, and we were out there in 36 mph winds with some pretty rocky seas. I threw up on three different occasions several times and now have those lovely broken blood vessel spots on my face. Now I've been taking Dramamine, and I've been fine. Unfortunately, a few guys are still getting sick even though they are taking medicine, including James.</p><p>This morning I was picking with Calvin, a 6' 5" guy with long curly blond hair that goes past his shoulders. He's super chill, goofy, and a prankster. Anyway, we had a great time. We were picking in one of the roughest nets, and I was in the front reaching to grab a rope over the side. A big wave came, pulling the rope away from me, and I didn't let go. I fell right over the side into the ocean. In a flash, Calvin ran to the front of the skiff to pull me back in. Haha, what a fun, cold dip in the ocean.</p><p>Being out amongst the weather and rough seas has reminded me of a fair bit of the boating accident, but not necessarily in a negative way. I think about it and thank God for using that experience to make me stronger and for allowing me to be back out there without fear. On the back of my orange rain jacket I wrote in Sharpie: "Joy follows suffering and life follows death" with Dad's and Earl's initials underneath. It's a proclamation to the ocean and the waves that even though that day on the Gulf was hard, God has made me stronger and brought me joy. The joy that comes from being in a love relationship with the King of the Universe, who calmed the seas and gives me hope that I will see both my Dads again.</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/f3a60/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/08b4d/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/293e0/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/9a8a1/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/e72c3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c67aa/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bf173/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/acb04/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/bd53b/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/12609/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/93719/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/310ec54e15d123748fa624e6287b092e/c58a3/49A141FF-08C4-4277-9695-E3266E73284B_1_201_a.jpg" alt="Calvin" title="Calvin" loading="lazy">
      </picture>
    </span>
  <figcaption>Calvin Bulthuis</figcaption></figure><h3 id="10-June-2014"><a href="#10-June-2014" aria-label="10 June 2014 permalink"></a>10 June 2014</h3><p>We had an extended break today because of the weather, so I've been getting extra rest. My back and hands are very sore, so much so that I have to take breaks as I write this letter. They say that the soreness goes away after a few more weeks.</p><h3 id="11-June-2014---Heads-or-Tails"><a href="#11-June-2014---Heads-or-Tails" aria-label="11 June 2014   Heads or Tails permalink"></a>11 June 2014 - Heads or Tails</h3><p>Yesterday I was picking with Luke when we caught a herring in the net (a herring is a small salmon, a little longer than my hand). He picked it up and said, "Heads or tails, Gabe?" I didn't understand what he meant but replied, "tails." He bit off the head, spit it out, and handed me the rest! So I bit off the tail. Nasty stuff! Guys on the crew said the tail is worse because it's where...well, I'll let you imagine what comes out near the tail.</p><h3 id="12-June-2014"><a href="#12-June-2014" aria-label="12 June 2014 permalink"></a>12 June 2014</h3><p>How long is it taking my letters to arive in Greenville? If the weather is good, your letters have been getting here in five to six days, which is quicker than I expected.</p><figure>
  <img src="https://www.gabrielzzarate.com/4e23b322945544755406648171c24d28/low_quality_day_on_the_job-3.gif" alt="A Nice Day on the Job">
  <figcaption>A day on the job. Heavy on the sunshine, light on the fish.</figcaption></figure><h3 id="14-June-2014"><a href="#14-June-2014" aria-label="14 June 2014 permalink"></a>14 June 2014</h3><p>There's not much new to tell here. We've done well as far as the amount of fish we've caught. I think we are close to me the 100,000 lbs mark.</p><p>Can you send me an update on the World Cup? You can probably print out what the scores have been and who scored during the games. That would be awesome.</p><h3 id="17-June-2014"><a href="#17-June-2014" aria-label="17 June 2014 permalink"></a>17 June 2014</h3><p>It's been storming here for the past few days, so we haven't been able to pick the nets three times a day. It seems like we've been fishing for a long time, but we are just getting started in reality. It can be too overwhelming to dwell on how much time I still have to be on this Island. I prefer to take the days one at a time.</p><p>You asked about who I am close to up here. I get along decently well with everyone. Luke is from Charleston. He's a loner and a wild one; he's hiked the Appalachian Trail by himself. In the off-season, he lives in Hawaii and surfs every day. Calvin is also another guy I like. I can't say I am close to anyone yet, though.</p><p>I was so glad to receive your letters today. I love you, Caitlyn. There's a guy named Mike who has a pretty pessimistic view of marriage. He has made a few jokes about getting married to the first girl I started dating, saying that I don't know if there is something else out there better. My response is that I know plenty of girls, and they all represent confirmation after confirmation that what I have is far better. xo :)</p><h3 id="21-June-2014---Summer-Solistice"><a href="#21-June-2014---Summer-Solistice" aria-label="21 June 2014   Summer Solistice permalink"></a>21 June 2014 - Summer Solistice</h3><p>Today is the summer solstice, and they say that the sun won't set until 1 am. The closure was two days long and was a nice break from fishing. The sun has been out for the last two days as well. We haven't seen the sunshine very much.</p><p>I want to hear from you. How did the wedding dress shopping go?</p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/f3a60/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/08b4d/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/8b983/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.webp 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/bf173/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 375w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/acb04/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 750w,https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg 768w" sizes="(max-width: 768px) 100vw, 768px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/531ac5d8181fcf31e455f32509daf307/212bf/9C2D88F8-2EBA-4ADE-AFBC-CD8F4507161D_1_105_c.jpg" alt="The Crew" title="The Crew" loading="lazy">
      </picture>
    </span>
  <figcaption>The Crew (left to right): Luke Yarborough, Josh Krohn, Evan Dundas, Adam Wilson, Calvin Bulthus, James Peery, Micah Glassman, Gabriel Zarate, Casey Furnish, Mike Falcochio, Moreno, Mark Barnes</figcaption></figure><h3 id="24-June-2014---The-Crew"><a href="#24-June-2014---The-Crew" aria-label="24 June 2014   The Crew permalink"></a>24 June 2014 - The Crew</h3><p>There are 12 crewmen in total. Mike is from Louisiana and has been coming up to work for the Fields for the last seven years! He is given a lot of responsibility for the crew and is a nice guy. Adam, Casey, and Mark are all from Florida. Adam is a big guy with lots of tattoos and is a big, fat southern teddy bear. Casey annoys me the most probably. He likes to talk a lot and try to tell me what to do when he doesn't know what he's doing himself. Mark is interesting. He has done some pretty hard drugs and tells some wild stories. Micah and Evan are the young guys from Idaho. They are both eighteen and are farm boys. Peter is from California but lives in Tennessee. He's a climber, and we have some great conversations. He wants to go to seminary and seems to love people. Luke is a surfer from Charleston and is a relaxed but funny guy. Then there's Calvin, who is the long, curly-haired giant who has the most infectious smile. What a goofball. Josh is also from California and is not my favorite.</p><p>Kelsey is the cook. She makes delicious food and has a no-nonsense attitude that is good for a girl in her position. Overall it is a great group. We laugh a lot.</p><p>So you found the dress! I could feel your excitement even through the letter, so I know it must be the right one. I'm so curious about it now!</p><p>The sun has been shining here for the past few days. It's been so great to have better weather. I got stung by some jellyfish this afternoon. It's no big deal, just an irritating stinging sensation. </p><figure>
  <span>
      <span></span>
  <picture>
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/f3a60/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/08b4d/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/293e0/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/9a8a1/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/e72c3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c67aa/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.webp 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/webp">
        <source srcset="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bf173/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 375w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/acb04/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 750w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 1500w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/bd53b/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 2250w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/12609/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 3000w,https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/93719/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg 4000w" sizes="(max-width: 1500px) 100vw, 1500px" type="image/jpeg">
        <img src="https://www.gabrielzzarate.com/static/07ba47a76ff4173a574b2e4f02d65d09/c58a3/63A2ABC4-E622-4C44-B73A-4E108A321BB9_1_201_a.jpg" alt="Bear Island at Sunset" title="Bear Island at Sunset" loading="lazy">
      </picture>
    </span>
  <figcaption>Backside of Bear at Sunset</figcaption></figure><h3 id="26-June-2014"><a href="#26-June-2014" aria-label="26 June 2014 permalink"></a>26 June 2014</h3><p>I keep coming back to the concept of contentment. Sometimes I try to count the days, and I can get discouraged. Not just a little down, like really discouraged. I can't wait to return.</p><h3 id="27-June-2014"><a href="#27-June-2014" aria-label="27 June 2014 permalink"></a>27 June 2014</h3><p>I think the most significant prayer request would be endurance to keep going. It's long hours and long days here, and there's a long way to go. Some mornings it's tough to get up and get going. Once I get up and eat breakfast, things get better.</p><h3 id="3-July-2014"><a href="#3-July-2014" aria-label="3 July 2014 permalink"></a>3 July 2014</h3><p>After every morning pick, there is usually a couple of hours for shore work before lunch (depending on how long the pick takes). For the last two days, I've been working in the …</p></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gabrielzzarate.com/blog/alaska">https://www.gabrielzzarate.com/blog/alaska</a></em></p>]]>
            </description>
            <link>https://www.gabrielzzarate.com/blog/alaska</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205393</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Origin of the Name Posix]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205384">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://stallman.org/articles/posix.html | <a href="https://web.archive.org/web/*/https://stallman.org/articles/posix.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><a href="https://stallman.org/">https://stallman.org</a></h2>
<p>
For current political commentary, see
the <a href="https://stallman.org/archives/polnotes.html">daily
political notes</a>.
</p>
<p>
<a href="https://stallman.org/biographies.html#serious">RMS's Bio</a> |
<a href="http://gnu.org/">The GNU Project</a>
</p>

<hr>



<h2>2011-05-11</h2>

<p>
In the 1980s I was in the IEEE committee that wrote the standard that
ultimately became known as POSIX.  The committee set itself the task
of standardizing interface specs for a Unix-like system, but had no
short name for its work.  When the first part of the specification was
ready, someone gave it the name "IEEEIX", with a subtitle that
included "Portable Operating System" — perhaps "Specifications
for a Portable Operating System".
</p>
<p>
It seemed to me that nobody would ever say "IEEEIX", since the
pronunciation would sound like a shriek of terror; rather, everyone
would call it "Unix".  That would have boosted AT&amp;T, the GNU
Project's rival, an outcome I did not want.  So I looked for another
name, but nothing natural suggested itself to me.
</p>
So I put the initials of "Portable Operating System" together with the
same suffix "ix", and came up with "POSIX".  It sounded good and I saw
no reason not to use it, so I suggested it.  Although it was just
barely in time, the committee adopted it.

<p>
I think the administrators of the committee were as relieved as I was
to give the standard a pronounceable name.
</p>
<p>
Copyright (c) 2011 Richard Stallman
Verbatim copying and redistribution of this entire page are
permitted provided this notice is preserved.
</p>


</div>]]>
            </description>
            <link>https://stallman.org/articles/posix.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205384</guid>
            <pubDate>Wed, 25 Nov 2020 02:33:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[C is not a subset of C++: A simple program to show differences in the standards]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25205170">thread link</a>) | @abqexpert
<br/>
November 24, 2020 | https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/ | <a href="https://web.archive.org/web/*/https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-883">

    

	<div>

		
<p>The following is a bit of a write up of a program I wrote for a presentation to a bunch of Java programmers(really this was part of a workshop on Qt for Android Programmers) to illustrate that C and C++ are very different languages, and the differences between standards can be large even if the program compiles.  So I tried making this as straightforward as possible.  A ton of people have written up similar things. Hopefully the value here is in the simplicity of the presentation(I tried making it accessible to people with only Java programming experience). I was heavily inspired by <a href="http://ioccc.org/2015/yang/prog.c">Don Yang’s 2015 IOCC entry</a>(Some commentary <a href="http://ioccc.org/2015/yang/hint.html">here</a>, and a fun video of him making it <a href="http://ioccc.org/2015/yang/spoiler.html">here</a>).</p>



<p>Imagine we would like to create a single program which when compiled would tell us how which standard of C or C++ it was compiled with.  Obviously we cannot use any features not common to both C and C++, so no template magic, and so we won’t be able to distinguish between C++98 and C++03 or between C++11,C++14, C++17, or C++20. Obviously we won’t try to tell the difference between C89 and C90 as well. And we will only consider C after C89 since it was not always implemented consistently prior, and K &amp; R function signatures are ugly.   We will try to not use the C preprocessor as much as possible, but in order to tell post-C11 from pre-C11 we need to introduce some macros.</p>



<p>One of the first and simplest differences is between C and C++. In C a character literal like ‘a’ is the same size as an int.  In C++ it is the same size as a char.  Now if you are on a platform where an int and char are the same size, then you will need a different test(In this day and age Fall 2020, even most embedded chips are moving to 32bit ARM/RISC-V/whatever else(I believe most 16bit chips in common use have an int with distinct size from char), where we wouldn’t expect this to be the case). So our first function is:</p>


<pre title="">static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); /*bail out early on unusual archs.*/
    return (sizeof ('\0') == sizeof(a));
}
</pre>


<p>The next major difference is between C before C99 and C after C99.  The big change was that C++ style inline comments were allowed.  So instead of just ‘/* whatever */’ you could use ‘// whatever’. This leads us to:</p>


<pre title="">static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
</pre>


<p>So if we have C++ style inline comments we return 1 since the rest of the line is a comment.  If we don’t then we have a ‘/’ followed by a comment followed by 2, so after comment and whitespace removal we get ‘return 1/2;’ which we know by the rules of integer division is 0.</p>



<p>Next in-order to differentiate versions of C and C++ after 2011, and ones before we will need to use a C Preprocessor macro.  After the C11 and C++11 revisions the language changed somewhat dramatically by adding some new prefixes for string literals to allow for the use of Unicode in strings(see <a href="https://en.cppreference.com/w/cpp/language/string_literal">this page</a> for a good reference to what the various prefixes mean, in general cppreference.com is a good source of information on either C or C++).  Here is our macro and function:</p>


<pre title="">#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
</pre>


<p>This uses a trick from Don Yang’s entry, in that in prior versions of the standard the preprocessor would view the ‘U’ in the definition as the value of the argument given to the ‘test’ function-type macro.  In the return statement we pass in no argument so the ‘U’ is replaced by nothing, and we just get ‘sizeof(“1″[0]) &gt;1’ which is just ‘sizeof(char) &gt;1’ which is always false.  In later editions of the standards the ‘U’ is parsed as a prefix to a string literal, in this case a 32bit wide unicode string, so each element in the string that follows the ‘U’ character must be at least 32 bits wide.  As long as we aren’t on an architecture with &gt;=32 bit chars this will lead to ‘sizeof(something at least 32bit) &gt;1’ which will be true for this case.</p>



<p>If proposal N2231 for the C2x standard goes through then both C++20 and C2x will have a char8_t datatype which will be the type of ‘u8’ prefixed string literal which would be another test we could do.</p>







<p>The final program is here:</p>


<pre title="">#include &lt;stdio.h&gt;
#include &lt;assert.h&gt;
 
static int is_post_ANSI_C(void){
    return 1//**/2
            ;
}
 
static int is_C(void){
    int a=0; char b='\0';
    assert(sizeof(a)!=sizeof(b)); 
    return (sizeof ('\0') == sizeof(a));
}
 
#define test(U) U"1"
static int is_post_11(void){
    return (sizeof(test()[0]) &gt;1);
}
 
int main(int argc, char *argv[])
{
    int C = is_C();
    int post_11 = is_post_11();
    int post_ANSI_C = is_post_ANSI_C();
 
    if(C &amp;&amp; post_ANSI_C &amp;&amp; post_11){
        printf("This is C11 or later!\n");
    }
    if(C &amp;&amp; post_ANSI_C &amp;&amp; !post_11){
        printf("This is C99!\n");
    }
    if(C &amp;&amp; !post_ANSI_C &amp;&amp; !post_11){
        printf("This is C89 or C90\n");
    }
    if(!C &amp;&amp; post_11){
        printf("This is C++11 or later\n");
    }
    if(!C &amp;&amp; !post_11){
        printf("This is C++98 or C++03\n");
    }
 
    return 0;
}
</pre>


<p>Which can be compiled with:</p>


<pre title="">gcc -std=c89 main.c
</pre>


<p>Or</p>


<pre title="">g++ -std=c++98 main.c
</pre>


<p>Then it can be run as:</p>


<pre title="">./a.out
</pre>


<p>valid values of the ‘std’ option to try are ‘c90’, ‘c99’, ‘c11’, ‘c++03’, ‘c++11’, etc. More given <a href="https://gcc.gnu.org/onlinedocs/gcc/C-Dialect-Options.html#C-Dialect-Options">here</a>.</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://abqexpert.com/2020/11/24/c-is-not-a-subset-of-c-a-simple-program-to-show-differences-in-the-c-and-c-standards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205170</guid>
            <pubDate>Wed, 25 Nov 2020 01:56:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I’m not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BIT joins OpenNebula's Managed Service Provider (MSP) Program]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203765">thread link</a>) | @amarti
<br/>
November 24, 2020 | https://opennebula.io/bit-joins-opennebula-msp-program/ | <a href="https://web.archive.org/web/*/https://opennebula.io/bit-joins-opennebula-msp-program/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
			    <!-- .entry-header -->

				
					
<article id="post-28713">

    <!-- .entry-header -->

    <div>

		
<p>Managed Service Providers are out to meet the needs of many organizations, and Managed Private Clouds offer a suitable alternative for those looking to reap the benefits of a private cloud environment without the hassle of managing and administering it on their own. And <a href="https://opennebula.io/opennebula-managed-service-provider-partnership/">OpenNebula announced</a> that it is opening the doors to its Solution Provider Partner Program, making way for qualified MSP’s. Our <a href="https://support.opennebula.pro/hc/en-us/articles/115005959343-Solution-Provider-Partner-Program-Guide">Partner Program</a> makes it easy for MSP’s not only to offer private clouds to their customers that are backed by official OpenNebula Systems support, but also having the security and comfort to deploy these clouds with the OpenNebula Enterprise Edition.&nbsp;</p>



<p><a href="https://www.bit.nl/opennebula" target="_blank" rel="noreferrer noopener">BIT</a> has been a long time user of OpenNebula, as well as an avid contributor to its development and evolution over the years. Now, they have joined our Partner Program as an official OpenNebula MSP, offering a comprehensive private cloud service to their customers that reaps the benefits of an OpenNebula subscription and the official backing and support of the OpenNebula Systems team.</p>







<blockquote><p>“<em><em>With OpenNebula’s feature-rich and stable software, along with its extensibility, flexibility, and integration of third-party tools, we have a platform and a partner which allows us to create a dependable platform for BIT and our customers.</em></em>”&nbsp;</p><cite>– Stefan Kooman, System Administrator, BIT</cite></blockquote>







<p>If you are an MSP using OpenNebula, and you would like to ensure that you are equipped to offer the best managed private cloud and support to your customers, reach out to our <a href="mailto:partners@opennebula.io">Partners Manager</a>, and inquire about how you can partner with us as an OpenNebula MSP Solution Provider Partner.&nbsp;&nbsp;</p>
		
		


        <div>
            <p><img alt="" src="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a1737e9efc6920480d8a1abc8d21fd64?s=192&amp;d=mm&amp;r=g 2x" height="96" width="96">            </p>
            <div>
                <p><span id="autorblog">Michael Abdou</span></p><p>Customer Success Manager at OpenNebula</p>
            </div>
        </div>
	</div><!-- .entry-content -->

</article><!-- #post-## -->

					
<!-- #comments -->

				
			</div></div>]]>
            </description>
            <link>https://opennebula.io/bit-joins-opennebula-msp-program/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203765</guid>
            <pubDate>Tue, 24 Nov 2020 22:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vim Sessions]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203660">thread link</a>) | @RMPR
<br/>
November 24, 2020 | https://rmpr.xyz/Vim-Session/ | <a href="https://web.archive.org/web/*/https://rmpr.xyz/Vim-Session/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Even though I prefer to use one buffer at a time to be more focused. I sometimes needed to have multiple buffers 
open in splits (Terminal, Netrw, …). And when for whatever reason, I needed to close them or shutdown my computer. I didn’t like loosing my context. Enter Vim sessions.</p>

<p>They are quite simple, if you want to save your layout as it is, just type <code>:mksession</code>  or for short <code>:mks</code> 
(yay! 6 strokes saved) and a file named Session.vim will be created. All you have to do the next time you open 
your project folder is <code>vim -S</code>.</p>

<p>P.S.</p>
<ul>
  <li>If there’s already a session file you will need to append ! at the end of the command to overwrite</li>
  <li>You can eventually specify the session filename, for more info <code>:help :mks</code></li>
</ul>

<p>In almost one year of Vim usage, I always wanted to do this, but somehow tutorials address mostly plugins installation and usage. No, I want the real, rough Vim, please.</p>

<p><a href="https://www.youtube.com/watch?v=jPPozzOCyIw"><img src="https://rmpr.xyz/images/sessions.gif" alt="Vim sessions"></a></p>


  </div></div>]]>
            </description>
            <link>https://rmpr.xyz/Vim-Session/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203660</guid>
            <pubDate>Tue, 24 Nov 2020 22:19:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Production Grade Workflow with SQL Modelling]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203365">thread link</a>) | @oedmarap
<br/>
November 24, 2020 | https://shopify.engineering/build-production-grade-workflow-sql-modelling | <a href="https://web.archive.org/web/*/https://shopify.engineering/build-production-grade-workflow-sql-modelling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By Michelle Ark and Chris Wu</strong></p>
<p>In January of 2014, Shopify built a data pipeline platform for the data science team called Starscream. Back then, we were a smaller team and needed a tool that could deal with everything from ad hoc explorations to machine learning models. We chose to build with PySpark to get the power of a generalized distributed computer platform, the backing of the industry standard, and the ability to tap into the Python talent market.&nbsp;</p>
<p>Fast forward six years and our data needs have changed. Starscream now runs 76,000 jobs and writes 300 terabytes a day! As we grew, some types of work went away, but others (like simple reports) became so commonplace we do them every day. While our Python tool based on PySpark was computationally powerful, it wasn’t optimized for these commonplace tasks. If a product manager needed a simple rollup for a new feature by country, pulling it, and modeling it wasn’t a fast task.</p>
<p>We’ll show you how we moved to a SQL modelling workflow by leveraging <a href="https://www.getdbt.com/" target="_blank" title="Analytics engineering is the data transformation work that happens between loading data into your warehouse and analyzing it. dbt allows anyone comfortable with SQL to own that workflow." rel="nofollow noopener noreferrer">dbt</a> (data build tool) and created tooling for testing and documentation on top of it. All together, these features provide Shopify’s data scientists with a robust, production-ready workflow to quickly build straightforward pipelines.</p>

<p>When we interviewed our users to understand their workflow on Starscream, there were two issues we discovered: <em>development time</em> and <em>thinking</em>.</p>
<p><em>Development time</em> encompasses the time data scientists use to prototype the data model they’d like to build, run it, see the outcome,and iterate. The PySpark platform isn’t ideal for running straightforward reporting tasks, often forcing data scientists to write boilerplate and it yields long runtimes. This led to long iteration cycles when trying to build models on unfamiliar data.</p>
<p>The second issue, <em>thinking</em>, is more subtle and deals with the way the programming language forces you to look at the data. Many of our data scientists prefer SQL to python because its structure forces consistency in business metrics. When interviewing users, we found a majority would write out a query in SQL then translate it to Python when prototyping. Unfortunately, query translation is time consuming and doesn’t add value to the pipeline.</p>
<p>To understand how widespread these problems were, we audited the jobs run and surveyed our data science team for the use cases. We found that 70% or so of the PySpark jobs on Starscream were full batch queries that didn’t require generalized computing. We viewed this as an opportunity to make a kickass optimization for a painful workflow.&nbsp;</p>

<p>Our goal was to create a SQL pipeline for reporting that enables data scientists to create simple reporting data faster, while still being production ready. After exploring a few alternatives, we felt that the dbt library came closest to our needs. Their tagline “deploy analytics code faster with software engineering practices” was <em>exactly</em> what we were looking for in a workflow. We opted to pair it with Google BigQuery as our data store and dubbed the system and its tools, Seamster.</p>
<p>We knew that any off-the-shelf system wouldn’t be one size fits all. In moving to dbt, we had to implement our own:</p>
<ul>
<li>source and model structure to modularize data model development</li>
<li>unit testing to increase the types of testable errors</li>
<li>continuous integration (CI) pipelines to provide safety and consistency guarantees.</li>
</ul>
<h2>Source Independence and Safety</h2>
<p>With dozens of data scientists making data models in a shared repository, a great user experience would</p>
<ul>
<li>maximize focus on work&nbsp;</li>
<li>minimize the impact of model changes by other data scientists.</li>
</ul>
<p>By default, dbt declares raw sources in a central <code>sources.yml</code>. This quickly became a very large file as it included the schema for each source, in addition to the source name. It creates a huge bottleneck for teams editing the same file across multiple PRs.&nbsp;</p>

<p>To mitigate the bottleneck, we leveraged the flexibility of dbt and created a top-level ‘sources’ directory to represent each raw source with its own source-formatted yaml file. This way, data scientists can parse only the source documentation that’s relevant for them and contribute to the <code>sources.yml</code> file without stepping on each other’s toes.</p>

<p><em>Base models are one-to-one interfaces to raw sources.</em></p>
<p>We also created a Base layer of models using the <a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" rel="nofollow noopener noreferrer">‘</a><a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" title="How we structure our dbt projects" rel="nofollow noopener noreferrer">staging’ concept from dbt</a> to implement their best practice of <a href="https://docs.getdbt.com/docs/guides/best-practices/#limit-references-to-raw-data" target="_blank" title="Limit references to raw data - dbt" rel="nofollow noopener noreferrer">limiting references to raw data</a>. Our Base models serve as a one-to-one interface to raw sources. They don’t change the grain of the raw source, but do apply renaming, recasting, or any other cleaning operation that relates to the source data collection system.&nbsp;</p>
<p>The Base layer serves to protect users from breaking changes in raw sources. Raw external sources are by definition out of the control of Seamster and can introduce breaking changes for any number of reasons at any point in time. If and when this happens, you only need to apply the fix to the Base model representing the raw source, as opposed to every individual downstream model that depends on the raw source.&nbsp;</p>
<h2>Model Ownership for Teams</h2>
<p>We knew that the tooling improvements of Seamster would be only one part of a greater data platform at Shopify. We wanted to make sure we’re providing mechanisms to support good dimensional modelling practices and support data discovery.</p>
<p>In dbt, a model is simply a .sql file. We’ve extended this definition in Seamster to define a model as a directory consisting of four files:&nbsp;</p>
<ul>
<li><code>model_name.sql</code></li>
<li><code>schema.yml</code></li>
<li><code>README.md</code></li>
<li><code>test_model_name.py</code></li>
</ul>
<p>You can further organize models into directories that indicate a data science team at Shopify like ‘finance’ or ‘marketing’.&nbsp;</p>
<p>To support a clean data warehouse we’ve also organized data models into these rough layers that differentiate between:</p>
<ul>
<li>
<strong>base</strong>: data models that are one-to-one with raw data, but cleaned, recast and renamed</li>
<li>
<strong>application-ready</strong>: data that isn’t dimensionally modelled but still transformed and clean for consumption by another tool (for example,&nbsp; training data for a machine learning algorithm)</li>
<li>
<strong>presentation</strong>: shareable and reliable data models that follow dimensional modelling best practices and can be used by data scientists across different domains.</li>
</ul>
<p>With these two changes, a data consumer can quickly understand the data quality they can expect from a model and find the owner in case there is an issue. We also pass this metadata upstream to <a href="https://shopify.engineering/solving-data-discovery-challenges-shopify" target="_blank" title="How We’re Solving Data Discovery Challenges at Shopify" rel="nofollow noopener noreferrer">other tools</a> to help with the data discovery workflow.</p>
<h2>More Tests</h2>
<p>dbt has native support for ‘schema tests’, which are encoded in a model’s schema.yml file. These tests run against production data to validate data invariants, such as the presence of null values or the uniqueness of a particular key. This feature in dbt serves its purpose well, but we also want to enable data scientists to write unit tests for models that run against fixed input data (as opposed to production data).</p>
<p>Testing on fixed inputs allows the user to test edge cases that may not be in production yet. In larger organizations, there can and will be frequent updates and many collaborators for a single model. Unit tests give users confidence that the changes they’re making won’t break existing behaviour or introduce regressions.&nbsp;</p>
<p>Seamster provides a Python-based unit testing framework. Data scientists write their unit tests in the <code>test_model_name.py</code> file in the model directory. The framework enables constructing ‘mock’ input models from fixed data. The central object in this framework is a ‘mock’ data model, which has an underlying representation of a Pandas dataframe. You can pass fixed data to the mock constructor as either a csv-style string, Pandas dataframe, or a list of dictionaries to specify input data.&nbsp;</p>
<p><img alt="Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967" src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967"><br><em>Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation.</em></p>
<p>A constructor creates a test query where a common table expression (CTE) represents each input mock data model, and any references to production models (identified using dbt’s ‘ref’ macro) are replaced by references to the corresponding CTE. Once you execute a query, you can compare the output to an expected result. In addition to an equality assertion, we extended our framework to support all expectations from the open-source <a href="https://github.com/great-expectations/great_expectations" target="_blank" title="Great Expectations - Always know what to expect from your data." rel="nofollow noopener noreferrer">Great Expectations</a> library to provide more granular assertions and error messaging.&nbsp;</p>
<p>The main downside to this framework is that it requires a roundtrip to the query engine to construct the test data model given a set of inputs. Even though the query itself is lightweight and processes only a handful of rows, these roundtrips to the engine add up. It becomes costly to run an entire test suite on each local or CI run. To solve this, we introduced tooling both in development and CI to run the minimal set of tests that could potentially break given the change. This was straightforward to implement with accuracy because of dbt’s lineage tracking support; we simply had to find all downstream models (direct and indirect) for each changed model and run their tests.&nbsp;</p>
<h2>Schema and Directed Acyclic Graph Validation on the Cheap</h2>
<p>Our objective in Seamster’s CI is to give data scientists peace of mind that their changes won’t introduce production errors the next time the warehouse is built. They shouldn’t have to wonder whether removing a column will cause downstream dependencies to break, or whether they made a small typo in their SQL model definition.</p>
<p>To achieve this accurately, we would need to build and tear down the entire warehouse on every commit. This isn’t feasible from both a time and cost perspective. Instead, on every commit we materialize every model as a view in a temporary BigQuery dataset which is created at the start of the validation process and removed as soon as the validation finishes. If we can’t build a view because its upstream model doesn’t provide a certain column, or if the SQL is invalid for any reason, BigQuery fails to build the view and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling">https://shopify.engineering/build-production-grade-workflow-sql-modelling</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/build-production-grade-workflow-sql-modelling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203365</guid>
            <pubDate>Tue, 24 Nov 2020 21:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Conducto – Use Python to write, run, view and debug DevOps pipelines]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25203326">thread link</a>) | @jonsolo
<br/>
November 24, 2020 | https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py | <a href="https://web.archive.org/web/*/https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&preview_file=pipeline.py">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.conducto.com/app/sandbox/github/conducto/examples?dir=cicd%2Fflask_microservice&amp;preview_file=pipeline.py</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203326</guid>
            <pubDate>Tue, 24 Nov 2020 21:48:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 203 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019–2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A 10x better way to manage your job search]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203150">thread link</a>) | @jacobdpeters
<br/>
November 24, 2020 | https://www.tealhq.com/job-tracker | <a href="https://web.archive.org/web/*/https://www.tealhq.com/job-tracker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="w-node-c72cce9215f1-2656f85e"><div><h2>Save any job listing <br>on the internet.</h2><p>Teal's Chrome Extension will scrape job descriptions from all the most popular listing sites — from LinkedIn to Glassdoor. If it doesn’t recognize a site, you can also add the job posting manually.<br></p></div></div></div>]]>
            </description>
            <link>https://www.tealhq.com/job-tracker</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203150</guid>
            <pubDate>Tue, 24 Nov 2020 21:24:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Speed Up 1000%]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202942">thread link</a>) | @tartoran
<br/>
November 24, 2020 | https://blog.binchen.org/posts/emacs-speed-up-1000.html | <a href="https://web.archive.org/web/*/https://blog.binchen.org/posts/emacs-speed-up-1000.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
<p>
I'm still <b>NOT</b> satisfied with my Emacs performance after applying below tricks:
</p>

<ul>
<li>autoload packages</li>
<li>idle-load packages</li>
<li>compiling *.el to  *.elc</li>
</ul>
<p>
After some research, I found I could make my Emacs 1000% fast <b>in 1 minute</b>.
</p>

<p>
Please note I'm talking about the <b>general performance</b> not just startup time.
</p>

<p>
The solution is really simple.
</p>

<p>
Since I'm a Linux guy and my computer got enough (24G) memory. I can place my setup into <a href="http://en.wikipedia.org/wiki/Tmpfs">memory</a>.
</p>

<p>
<b>Step 1</b>, insert below line into /etc/fstab and restart computer:
</p>

<div>

<pre><code>tmpfs       /tmp        tmpfs       nodev,nosuid,size=8G    0   0
</code></pre>

</div>

<p>
<b>Step 2</b>, run the script "emacs2ram":
</p>

<div>

<pre><code>#!/bin/sh

if [ -z "$1" ];then
    echo "Usage:"
    echo "  emacs2ram start"
    echo "  emacs2ram restore"
    exit 1
fi

if [ "$1" == "start" ];then
    backup=emacs.d-backup
    link=.emacs.d
    volatile=/tmp/.emacs.d-$USER

    IFS=
    set -efu

    cd ~/

    if [ ! -r $volatile ]; then
        mkdir -m0700 $volatile
    fi

    # link -&gt; volatie does not exist
    if [ "$(readlink $link)" != "$volatile" ]; then
        # backup project at first
        mv $link $backup
        # create the link
        ln -s $volatile $link
    fi

    if [ -e $link/.unpacked ]; then
        echo "Sync .emacs.d from memory to backup ..."
        rsync -avq --delete --exclude .unpacked ./$link/ ./$backup/
        echo "DONE!"
    else
        echo "Sync .emacs.d from disk to memory ..."
        rsync -avq ./$backup/ ./$link/
        touch $link/.unpacked
        echo "DONE!"
    fi
else
    echo "Moving .emacs.d back to disk ..."
    backup=$2-backup
    link=$2
    volatile=/tmp/$2-$USER
    cd ~/projs
    rm $link &amp;&amp; mv $backup $link &amp;&amp; rm -rf $volatile
    echo "DONE!"
fi
</code></pre>

</div>

<p>
That's all! Please enjoy Emacs as usual.
</p>

<p>
The original script is from ArchLinux Wiki. I learned this technique eight years ago. I'm just wondering why I need eight years to apply it?
</p>

<p>
BTW, I've also moved <b>all my projects into memory</b>, using similar scripts.
</p>

<p>
<b>UPDATE 1:</b>
I also publicize my project-managing script at <a href="https://gist.github.com/redguardtoo/596b1a9fd3eac1cedd13#file-proj2ram">gist</a>. It's almost same as emacs2ram. 
</p>

<p>
<b>UPDATE 2:</b>
Now I use <a href="https://hoytech.com/vmtouch/">vmtouch</a> which is easier to use and more light weight. Run <code>vmtouch -vt ~/.emacs.d</code> to place the directory into memory.
</p>

<p>
Unfortunately, <code>vmtouch</code> doesn't support Windows. You can convert my bash script to DOS batch script. Basically the script copies the directory into ram disk and create a link to the directory in memory. You can use <a href="https://sourceforge.net/projects/imdisk-toolkit/">ImDisk Toolkit</a> to create ram disk.</p>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.binchen.org/posts/emacs-speed-up-1000.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202942</guid>
            <pubDate>Tue, 24 Nov 2020 20:58:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If other engineers in your team are more productive]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202907">thread link</a>) | @_elergy_
<br/>
November 24, 2020 | https://evgenii.info/faster-pacers/ | <a href="https://web.archive.org/web/*/https://evgenii.info/faster-pacers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://evgenii.info/content/images/size/w300/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 300w,
                            https://evgenii.info/content/images/size/w600/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 600w,
                            https://evgenii.info/content/images/size/w1000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 1000w,
                            https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://evgenii.info/content/images/size/w2000/2020/11/wolfgang-hasselmann-mBccivEQvlk-unsplash--1-.jpg" alt="Not as Productive as Others?">
            </figure>

            <section>
                <div>
                    <blockquote>This is another article about pacers – people whom we use as an example to adjust our behaviour, mostly unconsciously.</blockquote><h2 id="surrounded-by-faster-pacers">Surrounded by faster pacers</h2><p>In this part, we will talk about problems that may occur when <em>you feel </em>that a lot of people in your team are much more productive than you. <br>In many cases, it doesn't lead to any problems – people happily work together and achieve great results. But sometimes their mutual influence can be destructive, and people would feel demotivated and discouraged.</p><p>Several symptoms are indicating that you're affected by faster pacers:</p><ul><li>You feel guilty seeing that colleagues have achieved more than you</li><li>You are afraid of taking challenging tasks which can make you stuck for a while</li><li>You feel like you have to work longer hours to keep up with others</li></ul><p>Daily standups or any other form of sync with colleagues is the perfect time to diagnose this problem:</p><ul><li>Are you nervous about sharing your progress?</li><li>Do those meetings make you feel like you have not done enough? </li><li>Do you find it challenging to describe your results and plans?</li></ul><p>If any of these describes you, a closer look is needed.</p><h2 id="five-actions-to-solve-the-problem">Five actions to solve the problem</h2><p>The most popular advice I heard in this situation is to take it easy. It is normal to have somebody more productive than you, left alone the fact that nobody can be a top performer in all situations.</p><p>Even though I fully understand the reasoning behind this suggestion, I do not think it is helpful. If somebody is nervous about attending standups, you cannot fix it by suggesting not to worry.</p><p>Instead, you can face this problem, find out the reasons and prepare an improvement plan, even if the problem exists only in your imagination. Then, it's going to be up to you whether to follow this plan or not, but at least you will take matters into your own hands – that alone can be sufficient to address most of the symptoms.</p><p>Let's talk about the five things which you can do to get out of this unpleasant situation. </p><h3 id="action-one-demystify-top-performers">Action one: demystify top performers<br></h3><blockquote>no two writers are the same, like snowflakes and fingerprints. No one will ever write in just the way that you do, or in just the way that anyone else does. Because of this fact, there is no real competition between writers. &lt;...&gt; Writing is a matter strictly of developing oneself. You compete only with yourself. You develop yourself by writing.<p>– John McPhee</p></blockquote><p>In time, everyone develops their areas of expertise. No matter how broad or narrow they are, one is the same — people are much more productive when their job overlaps with those areas.</p><p>Before bringing up your own expertise, I would recommend you you to think about your more productive colleagues. <strong>Every time they do something great, ask yourself what helped them to achieve those results.</strong></p><p>Something that could sound self-deprecating at first:</p><blockquote>Mark finished this giant feature for a week. That one would take more than a month for me!</blockquote><p>Can be rephrased and cleansed of magic:</p><blockquote>Mark finished this giant feature in a week because he's been building similar ones for the past three years.<br>He did more than ten last year – now he's extremely good at it.</blockquote><p>Now you can see that Mark's fast pace didn't appear overnight – it required years of deliberate practice. Moreover, you know that doing more things in this area can help you to close this gap.</p><p>That is not the only way of reframing achievements. It could be something like this:</p><blockquote>Mark finished it in a week because he wrote the whole system since the beginning and he knows every line of code by heart.</blockquote><p>or even this:</p><blockquote>... because he did not have the internet at home and spent all his free time working in the office.</blockquote><p>No matter the situation, your goal should be to stop seeing people as <em>just productive</em> and start noticed the reasons behind their results. Most of the time, those reasons are ordinary and achievable by anybody.</p><h3 id="action-two-find-your-comfort-zone">Action two: find your comfort zone</h3><p>Simply put, there are three types of activities:</p><ul><li>Something you enjoy the most</li><li>Something you are good at</li><li>Most important things for the company at the moment</li></ul><figure><img src="https://evgenii.info/content/images/2020/11/Three-types-niche.png" alt=""><figcaption>Three types of activities at work</figcaption></figure><p>The intersection of all three circles is your <em>niche </em>in the team, but finding and expanding your niche deserves a separate article. For this topic, I will focus only on the comfort zone (highlighted in green).</p><p>Everybody has ups and downs, and you will have many periods of not being at your best.<br>One of the smartest things you can do is to prepare something that can give you a little boost when needed — a type of work you like to be doing or an area where you can be very productive.</p><p>If you do not have a comfort zone right now — build one:</p><ul><li>Familiarize yourself with plans of your team.</li><li>Pick an area which will require work in the future.</li><li>Start building expertise there to capitalize on it when the time comes.</li></ul><h3 id="action-three-define-expectations-and-track-achievements">Action three: define expectations and track achievements</h3><p>The easiest way to not meet expectations is is to have no expectations at all. No matter what you achieve, you can always find a room for improvement.</p><p>The simplest way of coping with that is to formulate your goals before you start working towards them. I find daily plans most precise and helpful for this purpose; here is one of my recent ones:</p><figure><img src="https://evgenii.info/content/images/2020/11/image.png" alt=""></figure><p>The expectations were clear and realistic, but I ended up not finishing half of what I planned to do.</p><p>Was it a problem? No, because I knew that I had done more important things instead, and there was absolutely no reason to feel sad about my initial plan.</p><h3 id="action-four-keep-expectations-reasonable">Action four: keep expectations reasonable</h3><p>Sometimes results are noticeably small in comparison to goals:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-1.png" alt=""><figcaption>planned: 7; finished: 1</figcaption></figure><p>While this is a call to think about what can be improved, I would recommend checking your expectations for feasibility first.</p><p>There is a simple exercise to figure out if you are unrealistic in your estimations:</p><ul><li>Take some tasks your team plans to work on and imagine how much time each of them would take for you. Can you complete a particular task one day? In a week? Or maybe you can do five of those in an hour?</li><li>Write it somewhere.</li><li>When <em>other people</em> complete those tasks, check how their results match your estimations. <br>Were they working within their niches or tried something new? How did it impact them?</li></ul><p>This exercise is also helpful when your plans are unambitious and require correction:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-2.png" alt=""><figcaption>100% done!</figcaption></figure><h3 id="action-five-analyse-and-improve">Action five: analyse and improve</h3><p>Detailed plans can be beneficial even when everything looks good:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-3.png" alt=""><figcaption>Perfect plan and execution</figcaption></figure><p>Even though the result matched your expectation, a picky perfectionist can find some food for reflection:</p><figure><img src="https://evgenii.info/content/images/2020/11/image-4.png" alt=""><figcaption>Digging deeper</figcaption></figure><p>I rarely use this method – maybe once every two or three months, but it always helps to take control and find something I can change.</p><h2 id="prove-it-works">Prove it works</h2><p>At the beginning of this article, I mentioned that the best way of noticing this problem is to pay attention to your behaviour when you need to share your progress and describe the plans.</p><p>Feeling that you have not done enough can contribute to the demotivation, which will prevent you from working at your best, which will cause dissatisfaction of not achieving enough, which will incur even more demotivation, which will further decrease your productivity, which will make it even harder to get out of this loop.</p><p>The good news is that the actions above can help you to</p><ul><li>Understand if your expectations are realistic and how to adjust them if they are not</li><li>Find the quick way to get back on track after a period of dissatisfaction</li><li>Figure out what is the exact reason for dissatisfaction and how to improve it</li></ul><p>If anything, it doesn't leave too many reasons to worry.</p><hr><p>As always, you can <a href="https://evgenii.info/faster-pacers#subscribe">subscribe to Resilient Systems</a> and receive new articles by email if you haven't done it yet. <br>You also can <a href="https://twitter.com/_elergy_">find me on Twitter</a> or somewhere else – I am always happy to chat :-) &nbsp;</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Resilient Systems</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://evgenii.info/faster-pacers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202907</guid>
            <pubDate>Tue, 24 Nov 2020 20:54:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The war we forgot in our embrace of streaming]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202726">thread link</a>) | @mattbierner
<br/>
November 24, 2020 | https://blog.mattbierner.com/the-war-we-forgot/ | <a href="https://web.archive.org/web/*/https://blog.mattbierner.com/the-war-we-forgot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
    

    <p>I listened to Spotify for somewhere around 650 hours in 2019. That works out to a little over 27 solid days. That’s a lot of music!</p>

<p>I’m from the iPod generation, so the novelty of millions of songs in my pocket for $10 a month hasn’t entirely worn off. Spotify has changed my life. That’s only a minor exaggeration. In the old world of record stores and $0.99 iTunes singles, I never would have discovered artists like <a href="https://jeremiahkane.bandcamp.com/">Jeremiah Kane</a> or subgenres like <a href="https://giallodiscorecords.bandcamp.com/album/apocalypse-domani">Italian Horror Disco</a> which have had big impacts on both my day-to-day life and my creative work. The other great thing about streaming services like Spotify is that they let me focus on what I actually care about: the music! No more hours spent ripping CDs or scouring Limewire, no more nights wasted managing a media library and transferring songs between devices. It’s been so freeing.</p>

<p>Those 650 hours were on just one streaming service too. For a few bucks more a month, I can also stream tens of thousands of movies and shows through services such as Amazon or Netflix. And that’s all without even touching on services such as YouTube! If anything, the biggest problem facing consumers today is that there’s far too much content to choose from.</p>

<p>I’ve been happy gorging myself at this media buffet for years, until a recent project got me thinking about what shifting to a streaming only world means. Because while services such as Spotify or Netflix are in many ways better than what came before, it’s still worth trying to understand what we risk losing in this transition.</p>

<p>I have rarely seen this topic discussed in terms that I connect with. In this post, I want to go beyond typical concerns such as losing access to your library when your subscription lapses, to instead focus on how streaming can effect culture, and specifically remix culture. For, despite the flashy apps and all the billions and billions of dollars spent on new content, I’ve come to believe that streaming services take user control away and are actually quite regressive in many respects.</p>

<p>Ultimately, I feel that the biggest threat of streaming is its view that media is meant only for consumption. This view would be dangerous enough if it were restricted to the domain of streaming, but with streaming currently busy eating the world, I fear it will also come to dominate how we think about our media more broadly. This won’t happen overnight. In fact, we may not even realize that it is happening. The convenience and selection that streaming media promises has blinded us and made us forget a war that we (or at least the most nerdy ones among us) used to care deeply about: the war on DRM. By abandoning this war, we risk losing not only practical control over our media, but also our ability to imagine what our media could be and imagine how we could relate to it differently.</p>



<p>Before we continue though, a word about me: I’m not a musician, I’m not a video producer, and I’m certainly not a copyright lawyer. I’m just a nerd who likes music.</p>

<p>So what inspired this post? Well, to be perfectly honest, it was born from self interest. Streaming and DRM weren’t subjects I had ever given much thought to, let alone wanted to spend a weekend writing about. I was pretty happy with the status quo. That starting changing when I ran into a problem a few months back while building a new app.</p>

<p>You see, for the longest time I’ve wanted to use technology to somehow make the world dance along to my music. This year I finally figured out how to pull this off well. So for the past few months, I’ve been working off and on to create an augmented reality music visualizer iOS app. The app uses music to distort your walls/floors, creating wave patterns and other fun visualizations that look like they are distorting the real world’s geometry. It’s pretty neat!</p>

<p>During prototyping, I used a hardcoded audio file which let me focus on building the basic AR effects. To actually ship the app though, I wanted to let users select their own music. It sounded simple. However, I quickly hit a number of roadblocks.</p>

<p>Here’s an abridged version of my quest to add a music selector to my iOS app. Again my goal was simple: let users play their music with my app’s visualizer. On the technical side, the only important note is that the visualizer is driven by raw audio data.</p>

<ol>
  <li>
    <p>Try adding a media selector to the app using Apple’s built-in media picker UI: <a href="https://developer.apple.com/documentation/mediaplayer/mpmediapickercontroller"><code>MPMediaPickerController</code></a>.</p>

    <p>Discover that <code>MPMediaPickerController</code> shows nothing because I don’t actually have any songs in my phone’s music library.</p>
  </li>
  <li>
    <p>Remember that all of “my music” is actually in Spotify. Remember that Spotify has <a href="https://developer.spotify.com/documentation/">an API</a>!</p>

    <p>Discover that Spotify’s API is really more for remote control style apps. There is no way to access the raw audio data I needed for the visualizer.</p>
  </li>
  <li>
    <p>Check if Apple Music has an API I can use.</p>

    <p><a href="https://developer.apple.com/musickit/">Same issue</a>.</p>
  </li>
  <li>
    <p>Try downloading a song that I purchased on iTunes 10+ years ago.</p>

    <p>Discover that while the song now shows up in <code>MPMediaPickerController</code>, my app can’t access the raw audio data because the old song still has DRM.</p>
  </li>
  <li>
    <p>Go to Bandcamp, download a DRM free song, copy it over to my phone.</p>

    <p>Finally <code>MPMediaPickerController</code> works! Except I don’t own many of the songs I’d like to try in the app. Plus, now I have to manually copy music around like it’s 2003?</p>
  </li>
  <li>
    <p>Suspect that many users will be in the same boat, so see if my app can use a low level audio API to access the currently playing audio on the device.</p>

    <p>Discover that this also does not seem possible, likely for content protection reasons. (Although I won’t go so far as to say it is completely impossible. It may be possible if the music app your app tries to listen to consents or if you are some sort of iOS audio wizard.)</p>
  </li>
</ol>

<p>The only way I’ve found to let users easily visualize their music is by recording from the microphone while music plays over the speaker. Existing music visualizer apps that I’ve found on the App Store seem to have similar limitations. This just seems crazy to me!</p>

<p>So that’s where this post came from: I wanted to build a silly app about making walls dance, and streaming/DRM got in my way. The motivation is not exactly noble sounding when I put it in those terms.</p>

<p>But the app development problems I ran into aren’t nearly as interesting as the thinking they inspired. These problems got me thinking about big concepts like ownership and remixing. And this helped me realize that streaming takes away user control. Understanding all this got me wondering not only about the consequences of this loss of control, but why we mostly all have been just fine with this.</p>



<p>To watch Netflix, you have to use the Netflix app. To watch HBO, you have to use the HBO Max app. To watch Disney, you have to use the Disney Plus app.</p>

<p>Seems obvious enough. But why?</p>

<p>Why do I need apps from these providers at all? It’s not like using the Netflix app is some magical experience. 95% of the time, it’s just a fullscreen video. Any html <code>&lt;video&gt;</code> tag can do that!</p>

<p>So as long as my Netflix subscription is valid, shouldn’t I be able to load up Netflix content in any number of third party apps? Who knows, some of these third party apps might work on older or more niche devices that the official app doesn’t support. They may even have some neat UI ideas or unique features. After all, if anyone could develop a Netflix viewing app, then developers would have to work to make their app stand out from the pack. Having a vibrant app ecosystem seems like it would be a plus for these streaming providers, right?</p>

<p>But this gets to one of the fundamental misunderstandings that I had about streaming services. This misunderstanding explains why I just kind of assumed that it would be simple to hook my AR music visualizer up to a service like Spotify or Apple music.</p>

<p>Let’s take Netflix for example. When I first subscribed, I imagined that my $12 a month was buying me unlimited access to a huge library of Netflix content. However that’s not strictly accurate. Instead, my subscription lets me use sanctioned Netflix apps to view Netflix content. And while this distinction may seem like splitting hairs—especially when Netflix sanctioned apps exist for just about every modern device—I believe understanding it is a key first step in seeing the limitations of our current crop of streaming services.</p>

<p>Stepping back, I can sort of understand why streaming providers do this. If I were feeling particularly generous—or, if I were in marketing—I could probably even BS together justifications about how this setup actually benefits consumers too. Something about how the Disney app is specially designed and optimized for Disney content, and how all this vertical integration provides customers with the best end-to-end user experience. After all, we’re not just talking about apps here, but entertainment experiences! On the technical side, I also know that if you control both the frontend and backend, development and maintenance are simpler.</p>

<p>But seeing as my generosity reserves are now thoroughly depleted, I must also bring up three little letters: DRM. For controlling the entire pipeline also lets streaming providers control how their content can be shared and interacted with. That sounds a whole lot like DRM to me, even if it’s not explicitly called such. The fact that the streamed media itself is also encrypted is more of an implementation detail.</p>

<hr>

<p>So what’s the impact of linking content to an app? Well, simply put, it limits user control. Any control users have must be granted by streaming providers, who currently have little incentive to grant users anything meaningful.</p>

<p>The best analogy I can think of for this setup is that of a jukebox. A jukebox lets you play a large library of songs on demand, however browsing and selecting a song is basically all the control a jukebox grants to you. You certainly aren’t allowed to take some of the records out of the machine and play them on your own record player. Nor …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.mattbierner.com/the-war-we-forgot/">https://blog.mattbierner.com/the-war-we-forgot/</a></em></p>]]>
            </description>
            <link>https://blog.mattbierner.com/the-war-we-forgot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202726</guid>
            <pubDate>Tue, 24 Nov 2020 20:34:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Torture – VCard/vcf to CSV Converter for Address Labels]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25202644">thread link</a>) | @semireg
<br/>
November 24, 2020 | https://label.live/post/print-address-labels-using-vcard-vcf | <a href="https://web.archive.org/web/*/https://label.live/post/print-address-labels-using-vcard-vcf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://label.live/post/print-address-labels-using-vcard-vcf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202644</guid>
            <pubDate>Tue, 24 Nov 2020 20:27:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being-in-the-Room Privilege: Elite Capture and Epistemic Deference]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202553">thread link</a>) | @Reedx
<br/>
November 24, 2020 | https://www.thephilosopher1923.org/essay-taiwo | <a href="https://web.archive.org/web/*/https://www.thephilosopher1923.org/essay-taiwo">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="PAGES_CONTAINER"><div id="SITE_PAGES"><div id="r36i2"><div><div id="Containerr36i2"><div data-mesh-id="Containerr36i2inlineContent" data-testid="inline-content"><div data-mesh-id="Containerr36i2inlineContent-gridContainer" data-testid="mesh-container-content"><section id="comp-khunkqfk"><div data-testid="columns"><div id="comp-khunkqgo1"><div data-mesh-id="comp-khunkqgo1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqgo1inlineContent-gridContainer" data-testid="mesh-container-content"><div id="comp-khunkqgq2" data-testid="richTextElement"><p><span><span>Original Article:</span></span></p>

<p><span><span><span><span><span>Being-in-the-Room Privilege:</span></span></span></span></span></p>

<p><span><span><span><span><span>Elite Capture and Epistemic Deference </span></span></span></span></span></p>

<p><br>
<span><span><span>Olúfémi O. Táíwò </span></span></span></p></div></div></div></div></div></section><p><span><span><span><span><span>© Melody Overstreet</span></span></span></span></span></p><div id="comp-khunkqh71" data-testid="richTextElement"><div><p>“I abandoned the pitch because I don’t think I’m the right person to write this story – I have no idea what it’s like to be Black... I can send you the Google doc with my notes, too?”</p><p>

I flinched inwardly. It was an innocent and properly motivated offer: Helen, a freelance journalist, was offering to give up something for me, stemming from her concern to live out an ethos of racial justice. But I worried that it was also a trap.</p></div>



<p>Even setting aside the mistake about the power dynamics of the conversation (I am Black, but also a tenure-track professor), there was a problem here that I had seen many times before. Behind the assumption that I had experiential insight she lacked was the recognizable cultural imprint of a much discussed, polarizing perspective on knowledge and politics: standpoint epistemology.</p>



<p>If you consider a textbook definition of standpoint epistemology, it may be hard to see the controversy around this idea. The <span>International Encyclopedia of Philosophy</span> boils it down to three innocuous-sounding contentions:</p>



<p>1)&nbsp;&nbsp;&nbsp;&nbsp; Knowledge is socially situated</p>

<p>2)&nbsp;&nbsp;&nbsp;&nbsp; Marginalized people have some positional advantages in gaining some forms of knowledge</p>

<p>3)&nbsp;&nbsp;&nbsp;&nbsp; Research programs ought to reflect these facts.</p>



<p>Liam Kofi Bright argues persuasively that these contentions are derivable from a combination of 1) basic empiricist commitments, and 2) a minimally plausible account of how the social world affects what knowledge groups of people are likely to seek and find.</p>



<p>So, if the problem isn’t the basic idea, what is it?</p>



<p>I think it’s less about the core ideas and more about the prevailing norms that convert them into practice. The call to “listen to the most affected” or “centre the most marginalized” is ubiquitous in many academic and activist circles. But it’s never sat well with me. In my experience, when people say they need to “listen to the most affected”, it isn’t because they intend to set up Skype calls to refugee camps or to collaborate with houseless people. Instead, it has more often meant handing conversational authority and attentional goods to those who most snugly fit into the social categories associated with these ills – regardless of what they actually do or do not know, or what they have or have not personally experienced. In the case of my conversation with Helen, my racial category tied me more “authentically” to an experience that neither of us had had. She was called to defer to me by the rules of the game as we understood it. Even where stakes are high – where potential researchers are discussing how to understand a social phenomenon, where activists are deciding what to target – these rules often prevail.</p></div><section id="comp-khunkqh91"><div data-testid="columns"><div id="comp-khunkqhc1"><div data-mesh-id="comp-khunkqhc1inlineContent" data-testid="inline-content"><div data-mesh-id="comp-khunkqhc1inlineContent-gridContainer" data-testid="mesh-container-content"><p id="comp-khunkqhe2" data-testid="richTextElement"><h2><span>THE NORMS OF PUTTING STANDPOINT EPISTEMOLOGY INTO PRACTICE CALL FOR PRACTICES OF DEFERENCE: GIVING OFFERINGS, PASSING THE MIC, BELIEVING</span></h2></p></div></div></div></div></section><div id="comp-khunkqhg" data-testid="richTextElement"><p>The trap wasn’t <span>that</span> standpoint epistemology was affecting the conversation, but <span>how</span>. Broadly, the norms of putting standpoint epistemology into practice call for practices of deference: giving offerings, passing the mic, believing. These are good ideas in many cases, and the norms that ask us to be ready to do them stem from admirable motivations: a desire to increase the social power of marginalized people identified as sources of knowledge and rightful targets of deferential behaviour. But deferring in this way as a rule or default political orientation can actually work counter to marginalized groups’ interests, especially in elite spaces.</p>



<p>Some rooms have outsize power and influence: the Situation Room, the newsroom, the bargaining table, the conference room. Being in these rooms means being in a position to affect institutions and broader social dynamics by way of deciding what one is to say and do. Access to these rooms is itself a kind of social advantage, and one often gained through some prior social advantage. From a societal standpoint, the “most affected” by the social injustices we associate with politically important identities like gender, class, race, and nationality are disproportionately likely to be incarcerated, underemployed, or part of the 44 percent of the world’s population without internet access – and thus both left out of the rooms of power and largely ignored by the people in the rooms of power. Individuals who make it past the various social selection pressures that filter out those social identities associated with these negative outcomes are most likely to be in the room. That is, they are most likely to be in the room precisely because of ways in which they are systematically <span>different from</span> (and thus potentially unrepresentative of) the very people they are then asked to represent in the room.</p>



<p>I suspected that Helen’s offer was a trap. She was not the one who set it, but it threatened to ensnare us both all the same. Broader cultural norms – the sort set in motion by prefacing statements with “As a Black man…” – cued up a set of standpoint-respecting practices that many of us know consciously or unconsciously by rote. However, the forms of deference that often follow are ultimately self-undermining and only reliably serve “elite capture”: the control over political agendas and resources by a group’s most advantaged people. If we want to use standpoint epistemology to challenge unjust power arrangements, it’s hard to imagine how we could do worse.</p>

<p><br>
***</p></div><div id="comp-khunkqhr" data-testid="richTextElement"><p>To say what’s wrong with the popular, deferential applications of standpoint epistemology, we need to understand what makes it popular. A number of cynical answers present themselves: some (especially the more socially advantaged) don’t genuinely want social change – they just want the <span>appearance</span> of it. Alternatively, deference to figures from oppressed communities is a performance that sanitizes, apologizes for, or simply distracts from the fact that the deferrer has enough “in the room” privilege for their “lifting up” of a perspective to be of consequence.</p>



<p>I suspect there is some truth to these views, but I am unsatisfied. Many of the people who support and enact these deferential norms are rather like Helen: motivated by the right reasons, but trusting people they share such rooms with to help them find the proper practical expression of their joint moral commitments. We don’t need to attribute bad faith to all or even most of those who interpret standpoint epistemology deferentially to explain the phenomenon, and it’s not even clear it would help. Bad “roommates” aren’t the problem for the same reason that Helen being a good roommate wasn’t the solution: the problem emerges from how the rooms themselves are constructed and managed.</p>



<p>To return to the initial example with Helen, the issue wasn’t merely that I hadn’t grown up in the kind of low-income, redlined community she was imagining. The epistemic situation was much worse than this. Many of the facts about me that made my life chances different from those of the people she was imagining were the very same facts that made me likely to be offered things on their behalf. If I<span> had</span> grown up in such a community, we probably wouldn’t have been on the phone together.</p>



<p>***</p></div><div id="comp-khunkqhs" data-testid="richTextElement"><p>Many aspects of our social system serve as filtering mechanisms, determining which interactions happen and between whom, and thus which social patterns people are in a position to observe. For the majority of the 20th century, the U.S. quota system of immigration made legal immigration with a path to citizenship almost exclusively available to Europeans (earning Hitler’s regard as the obvious “leader in developing explicitly racist policies of nationality and immigration”). But the 1965 Immigration and Nationality Act opened up immigration possibilities, with a preference for “skilled labour”.</p>



<p>My parents’ qualification as skilled labourers does much to explain their entry into the country and the subsequent class advantages and monetary resources (such as wealth) that I was born into. We are not atypical: the Nigerian-American population is one of the country’s most successful immigrant populations (what no one mentions, of course, is that the 112,000 or so Nigerian-Americans with advanced degrees is utterly dwarfed by the 82 million Nigerians who live on less than a dollar a day, or how the former fact intersects with the latter). The selectivity of immigration law helps explain the rates of educational attainment of the Nigerian diasporic community that raised me, which in turn helps explain my entry into the exclusive Advanced Placement and Honours classes in high school, which in turn helps explain my access to higher education...and so on, and so on.</p>

<p><span>​</span></p>

<p>It is easy, then, to see how this deferential form of standpoint epistemology contributes to elite capture at scale. The rooms of power and influence are at the end of causal chains that have selection effects. As you get higher and higher forms of education, social experiences narrow – some students are pipelined to PhDs and others to prisons. Deferential ways of dealing with identity can inherit the distortions caused by these selection processes.&nbsp;</p>

<p><span>​</span></p>

<p><span>​</span>But it’s equally easy to see locally – in this room, in this academic literature or field, in this conversation – why this deference seems to make sense. It is often an improvement on the epistemic procedure that preceded it: the person deferred to may well be better epistemically positioned than the others in the room. It may well be the best we can do while holding fixed most of the facts about the rooms themselves: what power resides in them, who is admitted.</p></div><div id="comp-khunkqht1" title=""><div data-testid="linkElement"><wix-image id="img_comp-khunkqht1" data-image-info="{&quot;containerId&quot;:&quot;comp-khunkqht1&quot;,&quot;displayMode&quot;:&quot;fill&quot;,&quot;imageData&quot;:{&quot;width&quot;:500,&quot;height&quot;:692,&quot;uri&quot;:&quot;53a28d_d7a507c6115d4060a217e2377ff9c717~mv2.jpg&quot;,&quot;name&quot;:&quot;Vessel I.jpg&quot;,&quot;displayMode&quot;:&quot;fill&quot;}}" data-bg-effect-name="" data-is-svg="false" data-is-svg-mask="false" data-image-zoomed=""><img alt="Vessel I.jpg"></wix-image></div></div><p id="comp-khunkqhu2" data-testid="richTextElement"><h6><span>© Melody Overstreet</span></h6></p><div id="comp-khunkqhw" data-testid="richTextElement"><p>But these are the last facts we should want to hold fixed. Doing better than the epistemic norms we’ve inherited from a history of explicit global apartheid is an awfully low bar to set. The facts that explain who ends up in which room shape our world much more powerfully than the squabbles for comparative prestige …</p></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thephilosopher1923.org/essay-taiwo">https://www.thephilosopher1923.org/essay-taiwo</a></em></p>]]>
            </description>
            <link>https://www.thephilosopher1923.org/essay-taiwo</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202553</guid>
            <pubDate>Tue, 24 Nov 2020 20:16:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating a Terraform Provider for Plausible]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202260">thread link</a>) | @kurtmc
<br/>
November 24, 2020 | https://mcalpinefree.co.nz/blog/Technical/terraform-plausible | <a href="https://web.archive.org/web/*/https://mcalpinefree.co.nz/blog/Technical/terraform-plausible">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://mcalpinefree.co.nz/blog/Technical/terraform-plausible</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202260</guid>
            <pubDate>Tue, 24 Nov 2020 19:45:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 714 | Comments 669 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system’s internals very excited like we saw with Zen 3’s launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been “perfectly fine” for the last decade. We’ve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call “revolutionary”.</p>
<p>Before we proceed, it’s essential to set the context that I’ve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a “PC/Android Guy”, I have to admit what I saw this week is something special. I believe it’ll go down as a significant milestone in computing history on par with some industry-defining chips like Intel’s 8086, 386, 486, Pentium, Conroe or AMD’s K8, Zen, etc. I hope for the return of Moore’s law and awakening of the x86 manufacturers from their slumber as this will be the “<em>slowest</em>” CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year’s Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year’s Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft’s struggles in emulating x86 Windows apps on ARM CPUs. Apple’s answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That’s what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That’s on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they’re not currently, and so on, x86_64 performance should be very very decent. I’m going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it’s all said and done, it doesn’t take much working backwards to figure where they’d need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple’s new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who’s spending their money on them. There have been plenty of real-world experiences that I’ve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards 👏</p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens — even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. 👍</p></div>— JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>— Blake Scholl 🛫 (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don’t get near one! I have the 12.9” iPad Pro, new Max iPhone, older 13”MBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it’s eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn’t even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It’s honestly the best purchase I’ve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I’m holding a magical device that shouldn’t exist. Haven’t felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15” MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it’s been painful to say the least. It’s quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I’ve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor’s resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I’m impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I’ve ever owned. First computer that hasn’t had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I’m mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June… fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven’t plugged in this M1 Mac in almost 2 days. It’s only half dead. lol. What is this sorcery? 🔋 </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>— Computer Clan (📌M1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% 🤯🤯🤯</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>— William Lex Ham ✊🏽🧢 #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information – shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways –&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult –&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 920 | Comments 249 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does it mean to “reconcile to cash”?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201471">thread link</a>) | @qin
<br/>
November 24, 2020 | https://www.moderntreasury.com/journal/what-is-automatic-reconciliation | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/what-is-automatic-reconciliation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Businesses that manage payments at scale face the complex challenge of reliably monitoring cash. Most of us have experienced the time delays inherent to ACH, wires, and checks. These delays make it difficult to tie a payment you’ve made or expect to receive to the actual transaction that posts to your bank account. This process is called reconciliation and it is essential for a business to understand how completed and in-progress transactions add up to the cash balance in its bank account.&nbsp;<br></p><p>Most finance teams try to solve the reconciliation problem with spreadsheets, email and manual examination of bank statements — processes that are inefficient and error-prone. At Modern Treasury, we’ve built a better solution that helps finance teams save time and minimize errors. We call it Automatic Reconciliation.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury automatically matches your payments and returns to transactions as they are made available by your bank. Reconciled transactions are reflected in the previous day and intra-day balances available through the API and dashboard, allowing you to reliably monitor cash across all your business bank accounts.&nbsp;</p><p>‍<br></p><h4>How Does Reconciliation Help With Monitoring Cash?<br></h4><p>Let’s say you run a marketplace for artisanal coffee that lets coffee aficionados buy coffee from artisanal coffee roasters anywhere in the country. You collect payments from the buyer, deduct your platform fee and pay the seller. You also need to handle other types of transactions, like refunds and bonus payments to your top performing sellers. Business is going well so you’re processing thousands of orders a week.&nbsp;<br></p><p>To reliably monitor cash, you need to be able to match every single payment you’ve made or received to the corresponding transaction in your bank statement. At scale, this quickly gets very complicated for three reasons.&nbsp;</p><p>‍</p><h4>1. Banks Don’t Move Money as Fast as Your Business <br></h4><p>The time it takes for your transaction to settle depends on which payment method you use. Here’s a list of business payment methods used in the US and their typical settlement times. Because of these settlement timeframes, the rate at which you move money is slower than your business activities.&nbsp;<br></p><figure id="w-node-260693cab140-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc098771bac937c487c98a_AutomaticReconciliationTable.png" loading="lazy" alt=""></p></figure><p><br>Let’s say you pay coffee sellers on a daily basis. If you initiate a number of ACH credits on Monday, they are likely to settle by Tuesday. But by the time they settle, you have already initiated a new batch of payments on Tuesday that will settle on Wednesday.&nbsp;<br></p><p>Without reconciliation, it’s hard to keep track of the cash available in your bank account, what transactions are processing versus complete, and when different sets of transactions are likely to settle.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h4>2. Banks Process Transactions in Batches</h4><p>Let’s say you need to pay 10 coffee roasters $1000 each at the end of the week. You initiate 10 ACH credit transactions, each for $1000 on Friday before the day’s cut-off. These transactions will likely post to your bank statement Monday evening or Tuesday morning next week.&nbsp;<br></p><p>When you ask your bank to make a payment, it’s placed into a queue that’s sent to the network for processing after a certain cut-off time for the day. Any transactions submitted after the cut-off time are queued up to be processed the next business day. Different banks have different <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">cut-off times</a> for processing transactions.<br></p><p>The next day, instead of seeing 10 separate transactions next week, you’ll see one transaction for $10,000 on your statement. Because ACH transactions take place in batches, your bank directly debits your account for the total amount even though it represents 10 separate payments. Reconciliation helps you tie each payment to the appropriate transaction on your bank statement.&nbsp;</p><h4>3. Monitoring Incoming Payments and Returns is Difficult</h4><p>Let’s say you’re also expecting 100 payments of $20 each from your buyers. You need to know when they hit your bank account to predict cash accurately. You also need to tie each payment to an order. Similar to when you make bulk payments, your bank may record all or some of those payments as a single transaction on your statement.&nbsp;<br></p><p><a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">Payment returns</a> also complicate monitoring cash flow. For example, ACH credits will fail due to incorrect account or routing numbers and ACH debits will fail if the counterparty doesn’t have sufficient funds in their account. In both scenarios, your bank will post a return transaction to your bank statement that needs to be reconciled with the original payment.</p><h4>Automatic Reconciliation<br></h4><p>Until now, many companies have relied on manual reconciliation processes that typically involve exporting transactions from the bank portal to a spreadsheet and manually matching them with payments. In addition to being time consuming, the need to email multiple spreadsheets back and forth makes collaboration painful.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury instantly reconciles every single payment with transactions in your bank statement. We <a href="https://www.moderntreasury.com/journal/tentative-reconciliation" target="_blank">tentatively reconcile</a> the transaction when it’s pending and complete the process when it posts. Because ACH processes transactions in batches, a large number of transactions on your bank statement are likely to represent multiple distinct payments. If the transaction aggregates multiple Payment Orders, we automatically create matching <a href="https://docs.moderntreasury.com/reference#transaction-line-item-object" target="_blank">Transaction Line Items</a>.&nbsp;<br></p><p>When you see a Payment Order marked as completed, you can click into it in the web application to see the matching transaction.&nbsp;<br>‍<br></p><figure id="w-node-bb5fd7410dc0-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08ea82af2f7050239826_Payment%20Orders%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Expected Payments feature allows you to monitor your bank account for payments you do not initiate. When the transaction is made available by your bank, it is automatically reconciled with the Expected Payment. You can choose to be notified by <a href="https://docs.moderntreasury.com/reference#expected-payments">webhook</a> or email about its status.&nbsp;&nbsp;&nbsp;<br></p><figure id="w-node-6bf8f8776d0d-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08fdea9cc07dcb14b23c_Expected%20Payments%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Returns feature automatically matches returned payments to transactions and the original Payment Order, making identifying, correcting and redrafting returns a breeze.&nbsp;<br></p><figure id="w-node-2fa9dd183a06-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc0910f4c807451c4b685e_Returns%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>All the data you see in the app is also available through the API, allowing you to further automate and streamline reconciliation by integrating Modern Treasury directly into your business systems or platform.&nbsp;<br></p><p>We also have direct integrations with QuickBooks and NetSuite through our <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">Continuous Accounting</a> product. It syncs Modern Treasury directly with your general ledger, allowing you to tag payments with accounting categories. When you’re closing out the books, all you need to do is click a few buttons in the web app to transfer payments that have been Automatically Reconciled to your accounting software.<br></p><p>Finally, because we connect to <a href="https://docs.moderntreasury.com/docs/banks" target="_blank">multiple banks</a>, you can use Modern Treasury to reconcile transactions and monitor cash across all your business bank accounts.&nbsp;</p><h4>Get Started With Automatic Reconciliation</h4><p><a href="https://www.moderntreasury.com/product-demo" target="_blank">Get in touch</a> if you’re interested in exploring Automatic Reconciliation for your business. We’d love to discuss your use case in detail.</p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/what-is-automatic-reconciliation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201471</guid>
            <pubDate>Tue, 24 Nov 2020 18:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to stream your data in Apache Kafka with SQL]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201407">thread link</a>) | @Natasha_Fll
<br/>
November 24, 2020 | https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img alt="SELECT ApacheKafka WITH StreamingSQL FROM RealTimeData" src="https://images.ctfassets.net/tnuaj0t7r912/14MI0c1G0o6YM0jWb68az7/2623be6f9a8c8b47f72e878b351b604f/Mattero-KOH-Blog-v02.jpg?w=800&amp;q=100"></p><div><p>In another life, I taught the <i>Book of</i> <i>Genesis</i> to high school students, including The Tower of Babel excerpt. It struck me ironic that God’s wrath strikes down the tower, cofounds the universal language and scatters humans around the globe to teach King Nimrod a lesson in hubris; meanwhile, the boys in my class were texting their girlfriends across the country and playing video games with friends in Europe and Asia.&nbsp;</p><p>Technology allows us to form a new Tower; in particular, the ability to stream real-time events. For this technology to be built and managed, a common language is necessary, and more often than not, SQL is the common tongue of developers, architects and analysts. Recently, Matteo De Martino, Senior Scala Engineer at Lenses.io&nbsp; presented on the benefits of streaming SQL to react to real-time data for business critical decisions.&nbsp;</p><p>Anyone competent enough to build a pivot table on Excel understands how to act on data. You take a snapshot or data table and make an active query to parse out distribution and trends. While this is an important retrospective task, it does not allow for you to make business critical decisions in real-time.&nbsp;</p><p>The streaming SQL processors that Matteo explored in his <i>Kafka Office Hours </i>allow for users to process real-time data. As infinite amounts of data stream through an Apache Kafka cluster, users can model the transformations of data and write back to Kafka.</p><p>Lenses SQL Engine takes it a step further with SQL Processors. Not only can you model transformations, you can execute them as well. Users are able to scale, manage and govern their data with <a href="https://lenses.io/dataops/">DataOps</a>. </p><p>This activates data, allowing <a href="https://lenses.io/customers/">Lenses.io customers</a> to process data as it arrives and update the running state automatically.</p><p>Streaming SQL focuses on future data, so businesses can make time critical decisions. Matteo’s presentation outlines the advantages of Lenses Streaming SQL &amp; SQL processors. Watch his video below and then try SQL for yourself using <a href="https://lenses.io/box/">the Lenses Box, a self contained Apache Kafka environment.&nbsp;&nbsp;&nbsp;</a></p><p><iframe src="https://player.vimeo.com/video/483029806" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p>


</div></div></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/11/apache-kafka-with-streaming-sql-from-real-time-data/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201407</guid>
            <pubDate>Tue, 24 Nov 2020 18:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018–2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let’s take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity — it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn’t get to users’ credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice — it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it’s essential to <strong>notify users as fast as possible</strong> — keeping silent will simply destroy your company’s reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world’s most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users’ locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app’s users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn’t even found by the company — it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can’t tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users’ data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn’t run any security tests — <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn’t even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn’t delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn’t available to everyone anymore — to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn’t want to provide data for the heat map anymore, their data won’t be included in the next month’s map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren’t shown on the map until they’re used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals — the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn’t pay enough attention to the potential outcome, and that was their main mistake — they didn’t anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn’t have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it’s also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‍<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable’s size is or is expected to be tightly constrained by the platform’s limitations. A questionable reason not to use them is performance, as it’s unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it’s often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder – where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn’t apply. In software, that means something isn’t going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors…</p>



<p>In many of these cases, the program shouldn’t just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn’t its use case.</p>



<p>Examples of incorrect use of exceptions is when they’re thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise…</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 – XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It’s definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 – filling classes with the parsed XML</h2>



<p>For this test, I’ve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 – Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it’s not possible to exactly determine whether all of the message’s length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly – so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests – the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller’s caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that’s in the <code>catch</code> block.</p>



<p>If the errors …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Back DevOps]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201166">thread link</a>) | @semicolon
<br/>
November 24, 2020 | https://www.opslevel.com/2020/11/18/taking-back-devops/ | <a href="https://web.archive.org/web/*/https://www.opslevel.com/2020/11/18/taking-back-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <h2 id="lets-get-devops-to-mean-service-ownership-again">Let’s get DevOps to mean Service Ownership again.</h2>
<h3 id="we-broke-devops-and-its-preventing-us-from-building">We broke DevOps. And it’s preventing us from building.</h3>
<p>When the first cloud providers emerged in the mid-2000s, they unlocked a new superpower: the ability to near-instantly provision hardware. Service-oriented architecture and microservices developed as a new architectural pattern. As a result, DevOps emerged as a practice to organize engineering teams around those new services - combining development and operations responsibilities onto the same team.</p>

<p>In 2006, Werner Vogels, CTO at Amazon, described DevOps as: “You build it, you run it.” Fast forward to today and DevOps is a far cry from these origins. Code is no longer deployed efficiently, and the practice of DevOps has weakened. Here’s how this happened:</p>

<h4 id="1-we-rendered-the-term-devops-meaningless">1. We rendered the term DevOps meaningless.</h4>

<p>Over the last several years, DevOps has become simultaneously a practice, a culture, a team, a job title, and a vendor product. You can hire some DevOps, buy some DevOps, adopt DevOps, and sprinkle a little bit of DevOps on top for good measure.</p>
<ul>
  <li><strong>‘DevOps’ is a team</strong>, responsible for horizontal engineering concerns like standardized CI/CD and observability.</li>
  <li><strong>‘DevOps’ is a trendy job title</strong>, merely renamed from “Operations”.</li>
  <li><strong>‘DevOps’ is a vendor product</strong>, like “Azure DevOps”, “ServiceNow Enterprise DevOps”, and “IBM DevOps”.</li>
</ul>

<h4 id="2-we-spent-way-too-much-time-debating-microservices-vs-monolith">2. We spent way too much time debating microservices vs monolith.</h4>

<p>This is the wrong debate. And it’s distracted teams from focusing on how to own and operate code efficiently. For some companies, a monolith works just fine. For others, microservices is the way to go. For many, it’s a hybrid of fat services or serverless or applications or some other mix. The more important question is: <em>How do you get your team to a place where engineers own the code they write so everyone can ship faster and safer?</em></p>

<h4 id="3-we-built-some-devops-tools-but-for-crucial-needs-were-stuck-in-spreadsheets">3. We built some DevOps tools, but for crucial needs we’re stuck in spreadsheets.</h4>

<p>DevOps tools are siloed around monitoring, logging, tracing, incident management, CI/CD, etc. But there is nothing that unifies the information from those tools to answer broad questions about production architecture. Companies with the best DevOps cultures use this set of siloed tools, but they have also spent millions of dollars to <em>build their own</em> tools and systems–everything from lists of owners to full-fledged internal tools. We’ve seen teams with:</p>
<ul>
  <li><strong>Giant wikis of services</strong> that answer basic questions about architecture, including simply who owns what.</li>
  <li><strong>Spreadsheets of services</strong> that are painstakingly created (and later tossed away) during engineering initiatives like upgrades or security improvements across a large and complex architecture.</li>
  <li>Eventually spreadsheets and wikis are thrown away and <strong>complex internal tools</strong> are created that require a lot of engineering resources to build and maintain.</li>
</ul>

<p>Building these stop-gap solutions are a huge barrier to entry; there needs to be a way for <em>all</em> teams to adopt DevOps culture.</p>

<h3 id="lets-take-back-devops">Let’s take back DevOps.</h3>
<p><strong>If we want to get back to shipping code even faster, more securely, and with less risk, we need to reset DevOps so that it’s synonymous with <em>Service Ownership</em>.</strong></p>

<p>When DevOps = Service ownership, teams get:</p>
<ul>
  <li><strong>Autonomy:</strong> Teams fully control how their systems are built and run in production. Architecture becomes less prescriptive.</li>
  <li><strong>Speed:</strong> As long as your team’s SLOs are being met, there should be nothing stopping you from shipping quickly.</li>
  <li><strong>Resiliency:</strong> Shifting reliability and security concerns to dev teams naturally increases risk, but ownership involves educating/measuring teams against critical practices so that they can still deploy with low risk.</li>
  <li><strong>Accountability:</strong> People are no longer paged because a service goes haywire - or, worse yet, has a security breach - and learn that nobody owns the service, wants to touch it, or even knows anything about it.</li>
</ul>

<p>We’ve underinvested in tools to make DevOps actually work. There’s a lot we still need to build to help engineering teams adopt service ownership and unlock the full power of DevOps.</p>

<hr>

<h3 id="opslevel-enables-service-ownership-its-the-future-of-devops">OpsLevel enables Service Ownership. It’s the future of DevOps.</h3>

<p>OpsLevel helps DevOps teams own, operate, and understand their entire production infrastructure. You can easily catalog all your services, tools, ownership, and changes, while you continuously measure and improve how you build and operate your software. Teams ship faster, with confidence.</p>

<p>Forward-thinking engineering teams at Segment, Zapier, Auth0, Convoy, Under Armour, Chegg, and more use OpsLevel to drive service ownership. <strong>We’re proud to announce we’ve raised $5M in funding led by Vertex Ventures, with participation from S28 Capital, Webb Investment Network, Union Capital, and a number of angels</strong> including:</p>
<ul>
  <li>Alex Solomon, Andrew Miklas, and Baskar Puvanathasan (founders of PagerDuty)</li>
  <li>Anne Raimondi (CCO of Guru, Board member Asana, Gusto, Patreon)</li>
  <li>Frederic Kerrest (Executive Vice Chairman, COO, and co-founder of Okta)</li>
  <li>Jean-Michel Lemieux (CTO of Shopify)</li>
  <li>Maynard Webb (ex-COO of eBay)</li>
  <li>Yuri Sagalov (co-founder of AeroFS)</li>
  <li>Evan Weaver (CTO and co-founder of Fauna)</li>
  <li>Paul Judge (co-founder of Pindrop Security)</li>
  <li>Bill Clerico (co-founder of WePay)</li>
</ul>

<p>If you’re interested in joining our mission to take back DevOps and empower cultures of service ownership, <a href="https://www.opslevel.com/careers/">check out our open roles</a>.</p>

<p><em><a href="https://www.linkedin.com/in/john-laban/">John Laban</a> and <a href="https://www.linkedin.com/in/klprose/">Ken Rose</a> are co-founders of OpsLevel. John was previously PagerDuty’s first engineer and the pair of them bring senior technical expertise from Shopify, Amazon, and more.  They’ve spent the last decade scaling engineering teams and helping them transition to DevOps and service ownership.</em></p>

                </div></div>]]>
            </description>
            <link>https://www.opslevel.com/2020/11/18/taking-back-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201166</guid>
            <pubDate>Tue, 24 Nov 2020 18:11:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P² quantile estimator – estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its “average” duration.
It’s not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It’s much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it’s a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it’s usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P² quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P² quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let’s say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nꞌ</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qꞌ</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qꞌ</span> <span>&amp;&amp;</span> <span>qꞌ</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qꞌ</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qꞌ</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P²) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It’s time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P² quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It’s the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it “Type 7” according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It’s my favorite option in real life for non-sequential cases because
it’s more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P² quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I’m pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P² quantile estimator allows estimating quantile values on a stream of numbers without storing individual …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to layer sales onto a bottom-up self-serve product]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200913">thread link</a>) | @jcs87
<br/>
November 24, 2020 | https://www.lennyrachitsky.com/p/sales-bottom-up | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/sales-bottom-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>👋 Hello, I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>&nbsp;and welcome to a ✨&nbsp;<strong>once-a-month-free-edition&nbsp;</strong>✨ of my newsletter. Each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing them out at the office.</em></p><p><em>If you’re not a paid subscriber, here’s what you missed this month:</em></p><ol><li><p><a href="https://www.lennyrachitsky.com/p/magical-growth-loops">Magical growth loops</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/managing-up">How to manage up</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/product-management-startup-big-company">Startup PM vs. big company PM</a></p></li></ol><blockquote><h2>Q: I have a self-serve bottom-up SaaS product, and I'm trying to decide if, when, and how I should hire my first full-time salesperson.</h2></blockquote><p>One of the most surprising takeaways from <a href="https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-businesses-b11">my research into early B2B growth</a> was that <strong>100% of the bottom-up B2B companies ended up layering on a sales team</strong>. It’s rarely a question of if — it’s a question of when, and how.</p><p>Since I don’t have a lot of depth in sales myself, I went straight to my go-to person for all things sales: <a href="https://twitter.com/Kazanjy">Pete Kazanjy</a>. If you don’t know of Pete, he wrote <a href="https://www.foundingsales.com/">THE book on startup sales</a>, which he recently released as a physical book. This tweet was not an exaggeration:</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/7c5ce225-1f4f-47eb-afe6-1da59ed276f5_1190x756.png&quot;,&quot;height&quot;:756,&quot;width&quot;:1190,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1236090,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Pete generously agreed to write a guest post, and unsurprisingly, <strong>below you’ll find the most in-depth and tactical guide for adding sales into your org. </strong>Including<strong>:</strong></p><ol><li><p>Should I start with a self-serve product?</p></li><li><p>Should I ever involve salespeople?</p></li><li><p>When should I add a salesperson to the mix?</p></li><li><p>How do I set myself up for success during The Transition?</p></li><li><p>Common pitfalls to avoid</p></li></ol><p>Let’s dive in!</p><p><em>A bit more about Pete: In addition to authoring <a href="https://www.foundingsales.com/">Founding Sales</a>, Pete Kazanjy is also the founder of <a href="https://www.atriumhq.com/">Atrium</a>, makers of <a href="https://www.atriumhq.com/">data-driven management software for sales teams</a>, and founder of <a href="https://modernsaleshq.com/">Modern Sales</a> (the world’s largest peer-education community for sales operations and leadership professionals). He previously started and sold TalentBin (a recruiting software startup) to Monster Worldwide. You can find him on <a href="https://twitter.com/Kazanjy">Twitter</a> and <a href="https://www.linkedin.com/in/kazanjy/">LinkedIn</a>.</em></p><h2><strong>The Transition: </strong>Layering Sales onto a Bottom-Up Self-Serve Product</h2><p><em>By Pete Kazanjy</em></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/91b85976-c55f-4f8a-9d16-2b3807f40e6a_2150x1171.png&quot;,&quot;height&quot;:793,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:180377,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>“Bottom-up” (or “product-led”) B2B growth is a hot topic in early-stage circles these days, and it makes sense why. A self-serve (“easy-in”) entry motion, that’s later combined with a strong direct sales motion, can make for explosive revenue growth as shown by IPO’d exemplars Zoom, Slack, Datadog, and private market dynamos like Airtable, Figma, and others. The combination of bottom-up self-serve plus direct sales can simultaneously lower CACs and power larger contract values (with expansion into enterprise contracts). This would never be possible in a pure self-serve model.</p><p><strong>The crux of this article is that waiting too long to add sales-involvement often leads to a large opportunity cost.</strong> Many successful self-serve applications saw their market position usurped by competitors who adopted a sales-assisted motion and effectively firewalled the self-serve-only products out of lucrative enterprise segments (e.g. Dropbox).</p><p>Below, I’ll help you understand if layering in sales is right for your business, when to take the leap, and how to navigate this critical transition successfully:</p><h2>First of all, should I even start with a self-serve product?</h2><p>Self-serve has a lot going for it, but it’s not necessarily a slam dunk decision for every product. Below are four questions to take into consideration before building a self-serve product (many of which can be answered before you launch):</p><h4><strong>1. Is the product simple enough for self-serve?&nbsp;</strong></h4><p>Successful self-service is about allowing a user to get to success and have that “aha” activation moment on their own. So the question that follows from this is how easy is it for users to get to that <em>aha</em> moment? Zoom is not complicated. Send someone a link or join someone’s link, and boom, you’re talking to them. Dropbox is pretty straight forward – download this client, and tell it what folders to sync. Airtable is a bit more advanced, but you can start simple, and they’ve invested heavily in a content catalog of templates and recipes to allow for self-served advancement.</p><p>Note, “complexity” is audience contingent. Tableau is not an easy product to use by any stretch of the imagination, but it’s self-serviceable by the technical data analysts for whom it was designed, and as such started self-serve with a desktop client download. Similarly, Stripe, Datadog, Twilio, New Relic, and other developer tools have all started self-serve, in that their technical audience has the capacity to self-serve even these more involved products. Some offerings are really just too complex to start self-serve, such as enterprise-grade marketing automation platforms like <a href="https://www.marketo.com/">Marketo</a>,&nbsp; and software targeting massive financial enterprises like <a href="https://blend.com/">Blend</a>.</p><h4><strong>2. Is this truly new and differentiated?&nbsp;</strong></h4><p>If your offering is truly new and differentiated, self-serve can be fantastic. When <a href="https://www.yesware.com/">Yesware</a> and <a href="https://www.mixmax.com/">Mixmax</a> first launched, most organizations didn’t have any sort of sales engagement email offerings for their salespeople. The notion of sending someone a link to a public calendar with which to book time was crazy talk when <a href="https://calendly.com/">Calendly</a> first launched. Software that proactively monitors your revenue stack’s automations and linkages for errors has never existed, which is why <a href="https://seesonar.com/">Sonar</a> can be self-serviced by sales and marketing operations staff. Personal business cloud app search has never existed before, and thus there’s no reason for a given user in an organization to not download and give <a href="https://getcommande.com/">Command E</a> a try.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/8bdaeb77-d849-4833-aeb9-3add8098b57c_1017x574.png&quot;,&quot;height&quot;:574,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><h4><strong>3. Can this co-exist with a (less good) incumbent in a given company’s stack?</strong></h4><p>Conversely, if your offering can coexist alongside inferior incumbents, self-serve can also work. Most organizations where Slack was adopted early-on already had Gmail and thus GChat. Organizations that start using <a href="https://www.getguru.com/">Guru</a> may have antiquated knowledge bases in Sharepoint or in Confluence wikis. This is where my company, <a href="https://www.atriumhq.com/">Atrium</a> lives. Customers will frequently have legacy analytics infrastructure, like Tableau or Looker, in place, but its complexity underserves the needs of the sales organization, leaving open an opportunity for Atrium to enable data-driven management for sales managers and sales operations staff in a way they’re currently not doing. Tableau and Looker still end up existing in the organization, but for more advanced analytics run by a data or analytics team.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fa4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/a4948801-3ec0-4078-9e3e-ef583adfe8d8_1017x575.png&quot;,&quot;height&quot;:575,&quot;width&quot;:1017,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p>By contrast, an “end to end” offering like a Human Resource Information System (e.g. Workday) or email sending platforms (e.g. Iterable) are not something you have “two of” in an organization. As such, even though <a href="https://www.saplinghr.com/">Sapling</a> makes delightful modern HRIS software, they don’t have a self-serve offering. <a href="https://iterable.com/">Iterable</a> makes great, modern customer engagement software, but it’s highly unlikely an organization would run a legacy system like <a href="https://www.oracle.com/cx/marketing/campaign-management/">Responsys</a> and Iterable side by side. Self-serve would likely not work for them.&nbsp;</p><h4><strong>4. Will you focus on small organizations?</strong></h4><p>If none of the above apply, you can still target smaller orgs that have not yet adopted a legacy provider with a self-service offering. <a href="https://stripe.com/">Stripe</a> is a great example here. Payments providers already existed when Stripe first came on the scene, so it was less likely for a mature e-commerce provider with an existing payments provider to switch to a new upstart. But because legacy providers were clunky with poorly documented APIs, Stripe was the obvious choice for new internet businesses who didn’t yet have a payments provider.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F57067d98-1583-4066-9827-5d27fffba73e_1012x569.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/57067d98-1583-4066-9827-5d27fffba73e_1012x569.png&quot;,&quot;height&quot;:569,&quot;width&quot;:1012,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null}" alt=""></a></figure></div><p><a href="https://www.revops.io/">RevOps</a> makes fantastic quoting software for sales organizations that can be self-setup, but there’s no way anyone who already has Salesforce CPQ or Apttus is going to switch over to them. But for a 10 person sales organization that wants to systemize the creation of quotes and sending proposals, the idea of solving that problem in less than 5 minutes (rather than 3 months, like a standard Salesforce CPQ deployment) is really attractive. Which is why self-serve works for RevOps, specifically targeting this down-market segment.</p><h2><strong>Should I</strong> ever involve salespeople?&nbsp;</h2><p>Once you’ve determined whether self-serve is right for you, growth is going well, and you’re on your merry way (i.e. people are self-serving, getting to “aha”, transacting, and retaining), the next question would be “OK, well, should we get some salespeople involved here?” Well, that depends.</p><p>There are two primary reasons to add salespeople to a self-serve commercial motion:</p><ol><li><p>To facilitate the <strong>penetration or expansion</strong> of your solution into an organization where it has an initial foothold, and/or&nbsp;</p></li><li><p>To help <strong>raise conversion</strong> rates of your self-serve offer&nbsp;</p></li></ol><p>It turns out, humans are <em>really<strong> </strong></em>helpful when it comes to smoothing over weird edge cases, communicating complicated concepts, and persuading other people to surmount their inertia and try a new thing. They’re good at, you know, selling! But there’s a downside. Humans are expensive, and can only do so many tasks in a given amount of time - as compared to software which, once written, is really cheap to run, and can be scaled up to do as many tasks as you like. </p><p>So the question of “should I add sales to the mix?” is one of “will it help?” and “will the juice be worth the squeeze?”</p><h4><strong>1. Facilitating the penetration or expansion into an organization</strong></h4><p>This is the approach Slack and Zoom’s early sales motions helped with. It <em>wasn’t</em> about a salesperson showing up to an organization and saying “Hi, you need intra-organizational communication assistance, you should check out Slack.” Rather, teams within organizations might start using Slack to communicate amongst themselves, and the addition of an “Account Manager” (psssst...it’s a salesperson) helped unify those various pods into a single contract, while potentially adding more pods, was powerful. Similarly, in a more “single-player” offering, like <a href="https://getcommande.com/">Command E</a>, a handful of sales people in a 200 person sales organization might start using it to search their Salesforce opportunities, their Google Docs, and their Gmail, but a “Customer Success Specialist” (psssst...it’s a salesperson) offering to “give a personalized tour to the rest of the sales organization” could also be quite powerful (for expansion).</p><h4><strong>2. Helping with conversion</strong></h4><p>Sometimes even supposedly simplistic offerings …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lennyrachitsky.com/p/sales-bottom-up">https://www.lennyrachitsky.com/p/sales-bottom-up</a></em></p>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/sales-bottom-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200913</guid>
            <pubDate>Tue, 24 Nov 2020 17:50:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can’t find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I’ve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement”. I like that sentence, although one can point out that these traits are closely linked--you can’t have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call “plaintext awareness.” Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‘provably-secure schemes’ sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA’s Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it’s slow, it’s not flexible (if you change the protocol, good job changing the proof), and it’s limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint’s secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP’s WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don’t want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components — handshake and encryption protocol —&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I’m pretty sure there’s an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it’s a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we’re just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don’t further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I’d be interested…</p>
<p>In any case, what’s left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn’t been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we’ve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I’m now the CTO. I
could’ve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I’ve worked on web apps that used libraries only—no frameworks—and all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team’s composition changed, managing these decisions was a constant tax.</p>

<p>…managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we’d hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don’t have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn’t matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don’t matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can’t
be used for “serious” problems.  Those of us <em>with</em> Rails experience know this isn’t true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it’s obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails—and its ecosystem—tend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it’s still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That’s why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here – On the absence of information in today’s media]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today’s press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" —Martin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparison of Email Hosting Possibilities]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25200588">thread link</a>) | @Wronnay
<br/>
November 24, 2020 | https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/ | <a href="https://web.archive.org/web/*/https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>I’ve hosted my own Mailserver in various configurations since more than 6 years now. Since then I’ve taken multiple breaks from hosting it myself and explored other solutions for hosting emails with your own domain names.</p>
<p>Because my own Mailserver has lately problems (downtimes) I wanna explore other possibilities of hosting my email addresses.</p>
<p>So let’s take a look…</p>

<p>You simply setup a Mailserver with software like Mailcow, Mailu or Mail-in-a-Box on a virtual Server and manage it yourself.</p>
<p>Pros:</p>
<ul>
<li>You have the control</li>
<li>Unlimited domains</li>
<li>Unlimited mailboxes</li>
<li>Cheaper than most alternatives if you don’t look at the time you need for setup and maintenance</li>
</ul>
<p>Cons:</p>
<ul>
<li>Most cheap VPS don’t offer a lot of space and if you subtract the OS and installed software, then your space for mail is very limited</li>
<li>You need to invest a lot of time</li>
<li>You need a good spec VPS because Mailserver software and SPAM protection are performance intensive</li>
<li>Small VPS are often targeted by criminals and protection isn’t very easy</li>
</ul>
<p>This is what I’ve done the most of the time.</p>
<p>In the past this was very straightforward if you know how to setup and secure a mailserver but I’ve lately problems with things like DDoS and Brute Force Attacks.</p>
<p>A <a href="https://news.ycombinator.com/item?id=24154524">question</a> from me on Hacker News was even so heavily voted that it was for a short time on the front page of HN - so this seems to be a problem for other people too.</p>
<h2 id="pawnmail">Pawnmail<a href="#pawnmail" arialabel="Anchor">⌗</a> </h2>
<p>This service doesn’t exist anymore but I wanna mention it because it was one of the few free providers where you can get mailboxes for your own domains.</p>
<p>AFAIK that service doesn’t exist anymore because it was targeted by spammers and had problems with attacks.</p>
<h2 id="zoho-mail">Zoho Mail<a href="#zoho-mail" arialabel="Anchor">⌗</a> </h2>
<p>The free plan supports one domain with up to five users and has a 5GB/User and 25MB attachment limit.</p>
<p>Unusable for me because IMAP/ POP/ Active Sync are not included in the free plan.</p>
<p>Indian company, the CEO seems to support Hindu nationalism.</p>
<h2 id="yandex-mail">Yandex Mail<a href="#yandex-mail" arialabel="Anchor">⌗</a> </h2>
<p>The biggest player in my comparison. Offers 10 GB of storage, up to 1000 users and support for custom domains for free.</p>
<p>It seems like the only problem is that you have to trust a Russian company.</p>
<h2 id="mxroute">MXroute<a href="#mxroute" arialabel="Anchor">⌗</a> </h2>
<p>Has various plans for custom Domain Email Hosting. All plans include support for unlimited Domains and unlimited Email Accounts.</p>
<p>Especially the Black Friday deals seem to be pretty good every year.</p>
<p>US company, interestingly the Founder has worked for Christian Institutions - so both - the CEOs of Zoho and MXroute seem to be religious persons.</p>
<h2 id="mailcheapco">Mailcheap.co<a href="#mailcheapco" arialabel="Anchor">⌗</a> </h2>
<p>Cheap Hosting Provider for custom Domain Email, comparable to MXroute but it has more bad reviews than MXroute.</p>
<h2 id="migadu">Migadu<a href="#migadu" arialabel="Anchor">⌗</a> </h2>
<p>On the HN Post to this Article <a href="https://news.ycombinator.com/item?id=25201493">someone mentioned</a> Migadu.</p>
<p>Migadu is the only provider on this comparison from Switzerland and the pricing is more expensive compared to the US providers…</p>
<p>So you pay more but your data is probably also more secure.</p>
<h2 id="postaleio">postale.io<a href="#postaleio" arialabel="Anchor">⌗</a> </h2>
<p>French provider, offers a free plan which includes one domain, 2 mailboxes, 3 aliases and 1 GB per mailbox.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor">⌗</a> </h2>
<p>Unfortunately it seems like the cheapest hosting possibilities are either trusting a Russian company which government maybe spies on you, trusting a US company which is also obliged to let the government spy on you or to go to an Indian company which is run by a Hindu nationalism supporter…</p>
<p>Hosting your own server isn’t the cheapest option but you are more in control.</p>
<p>I know there are privacy focused providers like ProtonMail or Fastmail out there but the cost of those services are way higher than the providers I mentioned at the time of this writing. (Especially if you want more than one mailbox. Most popular services are on a pay per-user basis, but MXroute, Mailcheap, Yandex and your own VPS are more on a pay per-storage / resources plan)</p>
<p>So I think I will split my domains to various services - in that way no government has all of my information and I am more immune to downtimes.</p>

      </div></div></div>]]>
            </description>
            <link>https://blog.m5e.de/post/comparison-of-email-hosting-possibilities/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200588</guid>
            <pubDate>Tue, 24 Nov 2020 17:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitcoin 2021 Probabilistic Forecast]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25200220">thread link</a>) | @refrigerator
<br/>
November 24, 2020 | https://my.causal.app/models/21522 | <a href="https://web.archive.org/web/*/https://my.causal.app/models/21522">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://my.causal.app/models/21522</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200220</guid>
            <pubDate>Tue, 24 Nov 2020 16:52:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Neural Networks for Option Pricing]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199972">thread link</a>) | @jptitus
<br/>
November 24, 2020 | https://samuellee19.github.io/CSCI145_Option_Pricing/ | <a href="https://web.archive.org/web/*/https://samuellee19.github.io/CSCI145_Option_Pricing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h2 id="project-overview">Project Overview</h2>
<h3 id="background">Background</h3>
<p><strong>The Black Scholes model</strong> is used to price put and call options by estimating the variation over time said financial instruments. The model is based on the assumption that the markets are highly efficient (i.e., Efficient Market Hypothesis), which suggests that stock prices are uncorrelated to one another across time. As a result, Geometric Brownian Motion (GBM) also has been assumed. However, the assumption is often violated in practice, leading to numerous variations of the Black-Scholes model.</p>
<p>The <strong>Black-Scholes formula for European call and put options</strong> are:</p>
<p><span>\[C(S_0,t)=S_0N(d_1)-Ke^{-r(T-t)}N(d_2)\]</span> <span>\[P(S_0,t)=Ke^{-r(T-t)}N(-d_2)-S_0N(-d_1)\]</span> where<br>
- <span>\(S_0\)</span>: Stock Price<br>
- <span>\(C(S_0,t)\)</span>: Price of the Call Option<br>
- <span>\(K\)</span>: Exercise Price<br>
- <span>\((T-t)\)</span>: Time to Maturity, where T is Exercise Date<br>
- <span>\(\sigma\)</span>: Underlying Volatility (a standard deviation of log returns)<br>
- <span>\(r\)</span>: Risk-free Interest Rate (i.e., T-bill Rate)<br>
</p>
<p>The <span>\(d_i\)</span> variables are defined as: <span>\[d_1=\frac{\ln\frac{S_0}{K}+(r+\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span> <span>\[d_2=d_1-\sigma\sqrt{T-t}=\frac{\ln\frac{S_0}{K}+(r-\frac{\sigma^2}{2})(T-t)}{\sigma\sqrt{T-t}}\]</span></p>
<p>Finally, <span>\(N(x)\)</span> is cumulative distribution function for the standard normal distribution.</p>
<h3 id="project-objectives">Project Objectives</h3>
<p>In this project, we aim to do the following:<br>
1. Recreate Culkin and Das’ work<br>
2. See whether fitted simulated model performs well on actual data<br>
3. Observe if the model can perform better based on different datasets</p>
<h2 id="methodologies">Methodologies</h2>
<h3 id="data">Data</h3>
<p>To recreate Culkin and Das’ work we utilized the same simulated data used in the paper to train and validate the neural network.</p>
<p>Aditionally, we queried UKX options data and the options’ underlying stock infromation from Bloomberg (see Bloomberg Query File). We also created another dataset by <a href="https://github.com/jknaudt21/Option-Scraper-BlackScholes">scraping</a> information for S&amp;P500 companies from Yahoo Finance and AlphaQuery.</p>
<h4 id="culkin-and-das-2017">1. Culkin and Das (2017)</h4>
<p>To train a neural network to learn the call option pricing equation, Culkin and Das (2017) simulated a range of call option prices with ranges of different parameters<span data-cites="Culkin_Das_2017">(Culkin and Das <a href="#ref-Culkin_Das_2017">2017</a>)</span>:</p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Stock Price <span>\((S)\)</span></td>
<td>$10 — $50</td>
</tr>
<tr>
<td>Strike Price <span>\((K)\)</span></td>
<td>$7 — $650</td>
</tr>
<tr>
<td>Maturity <span>\((T-t)\)</span></td>
<td>1 day to 3 years</td>
</tr>
<tr>
<td>Dividend Rate <span>\((q)\)</span></td>
<td>0% — 3%</td>
</tr>
<tr>
<td>Risk Free Rate <span>\((r)\)</span></td>
<td>1% — 3%</td>
</tr>
<tr>
<td>Volatility <span>\((\sigma)\)</span></td>
<td>5% — 90%</td>
</tr>
<tr>
<td>Call Price <span>\((C)\)</span></td>
<td>$0 — $328</td>
</tr>
</tbody>
</table>
<p>In total, the dataset contains 300,000 observations.</p>
<h4 id="ukx-bloomberg-data">2. UKX Bloomberg Data</h4>
<p>This data is consisted of call options for stocks in the UKX 100 from Bloomberg Terminal. As Bloomberg Terminal has an upper bound for queries, this data only consists of 1600+ observations.</p>
<h4 id="sp-500-scraped-data">3. S&amp;P 500 Scraped Data</h4>
<p>To address a limited number of observations on the above data, we collected additional data through web scraping. Although web data may be imperfect, it can still hold useful information. For this dataset there are 57,000+ observations and we evaluate it separately from the addendum of UKX data.</p>
<h2 id="code">Code</h2>
<p>We used following dependencies and <code>scikit-learn</code>’s prebuilt models to train and visualize our results:</p>
<div data-layout="l-body">
<pre><code>
import numpy as np
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd
import matplotlib.pyplot as plt
import pickle
from scipy import stats
import matplotlib
matplotlib.rcParams['figure.dpi'] = 300</code></pre>
</div>
<h3 id="importing-and-preparing-training-data">Importing and Preparing Training Data</h3>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>206.484</td>
<td>194.386</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>79.434</td>
</tr>
<tr>
<td>1</td>
<td>79.582</td>
<td>73.926</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>24.976</td>
</tr>
<tr>
<td>2</td>
<td>130.957</td>
<td>154.101</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>28.928</td>
</tr>
<tr>
<td>3</td>
<td>53.021</td>
<td>58.598</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>8.574</td>
</tr>
<tr>
<td>4</td>
<td>455.191</td>
<td>529.570</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.210</td>
</tr>
</tbody>
</table>
<p>The original dataset contains an unnecessary index column, so we dropped it from the data frame.</p>
<h4 id="normalizing-the-data-as-done-in-culkin-and-das">Normalizing the data (as done in Culkin and Das)</h4>
<p>As we know that the Black-Scholes formula is linear homogeneous in <span>\(C(S,K)\)</span>, we can normalize our data as: <span>\(C(S,K)/K=C(S/K,1)\)</span></p>
<p>Hence, the results are shown below:</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Index</th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1.062</td>
<td>1.0</td>
<td>1.093</td>
<td>0.006</td>
<td>0.863</td>
<td>0.059</td>
<td>0.409</td>
</tr>
<tr>
<td>1</td>
<td>1.077</td>
<td>1.0</td>
<td>0.844</td>
<td>0.020</td>
<td>0.760</td>
<td>0.081</td>
<td>0.338</td>
</tr>
<tr>
<td>2</td>
<td>0.850</td>
<td>1.0</td>
<td>1.326</td>
<td>0.019</td>
<td>0.606</td>
<td>0.042</td>
<td>0.188</td>
</tr>
<tr>
<td>3</td>
<td>0.905</td>
<td>1.0</td>
<td>0.792</td>
<td>0.028</td>
<td>0.573</td>
<td>0.037</td>
<td>0.146</td>
</tr>
<tr>
<td>4</td>
<td>0.860</td>
<td>1.0</td>
<td>0.501</td>
<td>0.009</td>
<td>0.091</td>
<td>0.044</td>
<td>0.000</td>
</tr>
</tbody>
</table>
<h3 id="training-the-model">Training the model</h3>
<p>To remain as faithful to Culkin and Das, we trained the neural network with the following parameters:<br>
- 4 hidden fully connected layers, each with 100 neurons<br>
- Batch size of 64<br>
- 10 training epochs<br>
- 80-20 train-validation split<br>
- Mean Squared error as loss function</p>
<p>The main difference between our model and the paper’s model is that our network uses ReLU as the activation function for every layer, instead of using LeakyReLU, ELU, ReLU, and ELU for the four layers respectively. We also did not employ dropout regularization. Lastly, we opted to use “Adam” as our optimizer rather than stochastic gradient descent.</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train, X_test, y_train, y_test = train_test_split(df.drop('Call Price', axis=1), 
                                                    df['Call Price'], test_size=0.2)

mlp = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 10
                    ) </code></pre>
</div>
<h2 id="analysis-and-visualization">Analysis and Visualization</h2>
<p>We started by exploring the most basic performance metric for every regression problem: <span>\(R^2\)</span></p>
<div data-layout="l-body">
<pre><code>
print("Training set score: %f" % mlp.score(X_train, y_train))
print("Test set score: %f" % mlp.score(X_test, y_test))</code></pre>
</div>
<p>We received <span>\(R^2\)</span> values (training and test) of 0.999476 and 0.999474.</p>
<p>We can see that the model produced very promising results from the simulated data. While the results show that the algorithm is able to learn option pricing mechanism, we cannot draw any significant conclusion that it can produce meaningful results in real life situation.</p>
<p>We can visualize the succes of the model in the graph below:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_27_0.png" width="257"></p>
<p>We can also explore the distribution of both the in-sample and out of sample error:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_29_0.png" width="268"></p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_30_0.png" width="268"></p>
<div data-layout="l-body">
<pre><code>
rmse = mean_squared_error(preds_test, y_test)**0.5; rmse # root mean squared error
print("RMSE: %.4f" % rmse)</code></pre>
</div>
<p>Root Mean Square Error of the prediction is 0.0041. Hence, the pricing error in the training set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>240,000</td>
<td>(-0.045, 0.039)</td>
<td>-0.003</td>
<td>0.000007</td>
<td>-0.400</td>
<td>12.084</td>
</tr>
</tbody>
</table>
<p>The pricing error in the test set can be summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>11,841</td>
<td>(-1.407,204.185)</td>
<td>0.091</td>
<td>10.957</td>
<td>54.036</td>
<td>3,074.578</td>
</tr>
</tbody>
</table>
<h2 id="validating-with-real-data">Validating with real data</h2>
<p>So far, we have observed the behavior of the model using the synthetic data. Though the use of synthetic data has allowed us to learn the Black-Scholes model quite accurately, we have yet to see how the model performs using real data. Plus, we could also gauge whether models trained in real data are able to better price options in the market.</p>
<p>Nonetheless, it is worth noting that a common option trading strategy is to determine whether an option is undervalued or fairly valued with respect to the market’s price and the price outputed by Black-Scholes. With this in mind, if our model misprices an option with a higher price, it could be an indicator that said option is undervalued.</p>
<p><strong>Important</strong>: by the time the data for this article was collected, the current risk-free rate was 0.88%.</p>
<h3 id="ukx-bloomberg-data-1">UKX Bloomberg Data</h3>
<p>To start the validation, we pulled options data using a Bloomberg terminal. To limit the size of query, we extracted the data for around ~1600 calls on stocks in the UKX100.</p>
<table>
<thead>
<tr>
<th></th>
<th>Stock Price</th>
<th>Strike Price</th>
<th>Maturity</th>
<th>Dividends</th>
<th>Volatility</th>
<th>Risk-free</th>
<th>Call Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>1</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.34</td>
<td>11.949099</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>2</td>
<td>4,732.0</td>
<td>1.0</td>
<td>0.02</td>
<td>0.000000</td>
<td>0.392</td>
<td>0.0088</td>
<td>4,731.0</td>
</tr>
<tr>
<td>3</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.09</td>
<td>0.000000</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
<tr>
<td>4</td>
<td>2,094.0</td>
<td>1.0</td>
<td>0.34</td>
<td>4.424667</td>
<td>0.530</td>
<td>0.0088</td>
<td>2,093.0</td>
</tr>
</tbody>
</table>
<p>Though it might seem that this data is normalized already, such is not the case. Therfore, we normalize the data by dividing by the strike.</p>
<p>We proceeded with dropping <code>Call Price</code> column on the data and predicted to see how the model performs.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_40_0.png" width="263"></p>
<p>From a quick glance, there seems to be some minor deviations. In fact, we got <span>\(R^2\)</span> value of 0.8699. We can also see the distribution of the errors. Since the simulated data were not generated under a normal distribution, it would not be surprising to observe a skewed distribution:</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_44_0.png" width="263"></p>
<p>While the model performed worse relative to previous sample, it still achieved a high R-squared value considering that the training data and the test data came from different sources. Hence, the above graph is summarized as below:</p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>1,685</td>
<td>(-3,088.616,0.352)</td>
<td>-28.828</td>
<td>44,608.131</td>
<td>-10.457</td>
<td>123.588</td>
</tr>
</tbody>
</table>
<p>It makes sense that a model trained from the simulated data would perform relatively bad. However, a real question is whether neural network can perform well given real data that is not normally distributed.</p>
<p>To mitigate the effect of having less data, we increased the number of epochs:</p>
<div data-layout="l-body">
<pre><code>
np.random.seed(32)
X_train_ukx, X_test_ukx, y_train_ukx, y_test_ukx = train_test_split(ukx.drop('Call Price', axis=1), 
                                                    ukx['Call Price'], test_size=0.2)

mlp_u = MLPRegressor(hidden_layer_sizes=(100,100,100,100), 
                   solver='adam', shuffle = False, batch_size=64, verbose=True,
                   max_iter= 20
                    )

mlp_u.fit(X_train_ukx, y_train_ukx)</code></pre>
</div>
<p>Hence, the model achieved <span>\(R^2\)</span> values of 0.999998 and 0.999998 for training and testing sets.</p>
<p><img src="https://samuellee19.github.io/CSCI145_Option_Pricing/BS_Model_draft/output_51_0.png" width="259"></p>
<table>
<thead>
<tr>
<th>Number of Observations</th>
<th>minmax</th>
<th>mean</th>
<th>variance</th>
<th>skewness</th>
<th>kurtosis</th>
</tr>
</thead>
<tbody>
<tr>
<td>337</td>
<td>(-0.316,9.836)</td>
<td>0.164</td>
<td>0.804</td>
<td>7.901</td>
<td>69.226</td>
</tr>
</tbody>
</table>
<p>From the above, we can see that the model was able to perform very well, given that there were only 1,685 observations used for training the model. However, one thing to note is that the result exhibits a very <strong>high kurtosis</strong>: while the model is consistent in most cases, it could lead to a severe gain/loss (long tails) from time to time. In real-life application, such model will not be preferred by the practitioners as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samuellee19.github.io/CSCI145_Option_Pricing/">https://samuellee19.github.io/CSCI145_Option_Pricing/</a></em></p>]]>
            </description>
            <link>https://samuellee19.github.io/CSCI145_Option_Pricing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199972</guid>
            <pubDate>Tue, 24 Nov 2020 16:33:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Quicklang.net – A Simple Programming Language That Runs in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199865">thread link</a>) | @chkas
<br/>
November 24, 2020 | https://quicklang.net/ide/ | <a href="https://web.archive.org/web/*/https://quicklang.net/ide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quicklang.net/ide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199865</guid>
            <pubDate>Tue, 24 Nov 2020 16:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I’m fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harmful Biases in Performance Reviews]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199752">thread link</a>) | @ochronus
<br/>
November 24, 2020 | https://ochronus.online/biases-in-performance-reviews/ | <a href="https://web.archive.org/web/*/https://ochronus.online/biases-in-performance-reviews/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<div itemprop="text">

<p>We are all prone to biases. We cannot help but evaluate and assess people and situations through the lens of our own prejudices. When it comes to performance reviews this can have a huge unwanted impact as it influences compensation, promotion decisions, and even firing.</p>
<p>When you give a performance review for a colleague, you’re very directly impacting their career trajectory. Even so, if you’re their manager. Given the weight of this kind of influence, it’s our responsibility to make sure the reviews are as fair and objective as possible.&nbsp;</p>
<p>Not all is lost, though. Once you’re aware of the existence of these biases and the way they work, you can utilize certain strategies (and a good amount of self-awareness) to minimize their effect.</p>
<p>Below, I break down the most common performance review biases and share advice on how to deal with them both as the giver and the recipient of performance reviews.&nbsp;</p>

<h4 id="0-general-advice-for-managers-"><strong>General advice for managers</strong></h4>
<p>One of the best ways to counter bias in reviews is to come up with a great review format that guides people and doesn’t magnify bias effects. Phrasing matters a lot. Setting the tone, being clear about the purpose and scope of the feedback form is key.</p>
<p>Another very important point is to understand that giving quality feedback takes time, a certain kind of focus, and is a considerable effort. Make sure you proactively prepare your engineers for the feedback season and plan for it – one thing that worked pretty well for me is to represent feedback tasks as cards on the team board and even set them as sprint goals. Nothing makes feedback quality deteriorate more than rushing and feeling that you don’t have enough time for it. You can organize feedback training, too, with our without your HR peers.</p>
<h4 id="1-general-advice-for-everyone-"><strong>General advice for everyone</strong></h4>
<p>On the flip side of the above – expect that giving feedback is not a trivial task. Take your time, make sure you have a quiet corner, don’t do it in one go, take notes, work on your wording, look at email/slack/pull request history too and treat your peers as customers of your feedback.</p>
<p><a href="https://ochronus.online/thoughts-on-feedback/">My article on feedback</a> might help in that.</p>
<hr>
<h2 id="2-recency-bias">Recency bias</h2>
<p>Alice had a very strong year, she had great contributions to the projects her team was working on, achieved most of her goals, mastered a new language, and a framework. In the past month though, due to personal issues, she kept her involvement to the bare minimum. In his feedback to Alice, Bob highlights that he expects more from her and that she feels distant from the team. Bob completely fails to call out the amazing job Alice did earlier and the growth she had had.</p>
<p>Recency bias is when recent events weigh much more heavily in your performance review than older, possibly even more significant events. This is partly due to how our memory works and is a completely natural thing, yet its impact can be really bad and can bias your review in either direction depending on what people remember about you recently.&nbsp;</p>
<h3 id="3-how-to-deal-with-recency-bias">How to deal with recency bias</h3>
<p>The best way is to collect feedback more frequently – for example, do a 360 each quarter even if you only have the performance review once a year. Project-level retrospectives can be helpful as well. Some managers keep ‘files’ on their engineers to counter this bias, but honestly, that can easily backfire – it can feel like a shady practice to their teams. Prefer transparent and open frequent feedback instead.</p>
<p>Some people find it useful to keep a personal achievement log, which helps with their self-assessment or calling out things missing from their feedback. If you feel there are important bits missing from the feedback you’ve been given, call those out. If your manager doesn’t encourage more frequent feedback you can still ask for informal ones from your peers at any time.</p>
<hr>
<h2 id="4-similarity-bias-and-affinity-bias">Similarity bias and Affinity bias</h2>
<p>Alice and Bob graduated from the same university and are both huge Star Trek fans – they talk about it all the time, they get along really well and connect outside work, too. Bob’s feedback to Alice is always overly positive and he’s prone to overlooking seemingly obvious gaps in her performance.&nbsp;</p>
<p>We subconsciously tend to rate people similar to us higher. Similarity can mean many things – personality, looks, way of thinking, etc. Affinity bias occurs when we work with someone we feel we have an affinity with; maybe we attended the same college, we grew up in the same town, or they remind us of someone we know and like.</p>
<h3 id="5-how-to-deal-with-similarity-and-affinity-bias">How to deal with similarity and affinity bias</h3>
<p>A clear, and transparent performance evaluation system helps a lot here. Such a system is clear and well-understood level definitions, which can guide your focus while thinking about others’ performance. That said, levels are usually not public information in companies, so this won’t help too much with peer review.</p>
<p>Getting feedback from multiple peers can help mitigate the effect of this bias.</p>
<hr>
<h2 id="6-halo-effect-and-horn-effect">Halo effect and horn effect</h2>
<p>Alice is really great at debugging and fixing notoriously tricky bugs others usually struggle with. Because of this, she saved the day multiple times. That said, she barely meets her level’s expectations if we look at the wider spectrum. Alice gets really positive feedback from her team highlighting how grateful they are for her being the ‘bug hunter’ and omitting any gaps she might have elsewhere.</p>
<p>Bob meets his level’s expectations in general and is great to work with. That said, he has the tendency to be impatient and cut discussions short because of that, which really hurts his ability to effectively work with others in these situations. Bob gets negative feedback highlighting that he should really work on his temper and communication – not mentioning any of the amazing work he’s done otherwise.</p>
<p>In the halo effect, a single positive event or attribute lifts your review up, and in the horn effect similarly a single negatively perceived action or trait ‘poisons’ your whole review.</p>
<p>This gets even worse if your manager is biased. A classic example of the manager having a halo bias is when they see one of their engineers as the “hero” or the “10x engineer”, being blind about any gaps they might have (btw. check out my older post about <a href="https://ochronus.online/kill-your-heroes/">hero engineers</a>). An example of a manager having the horn bias is when they stigmatize an engineer as e.g. “unreliable” or “not smart enough” based on a one-off event.</p>
<h3 id="7-how-to-counter-the-halo-or-horn-effects">How to counter the halo or horn effects</h3>
<p>You might ask “why would I want to counter the halo effect if it results in positive reviews about me?”. True, it might momentarily be even helpful for you, but not having a clear picture of your gaps ultimately does more damage than good to your career. It hinders your potential to grow and if you change teams, managers, or companies you might be suddenly underperforming and you won’t necessarily understand what happened.</p>
<p>To counter the effect of these biases you first need to understand what the main positive or negative thing is in your feedback and have a heart-to-heart about it with yourself. Again, a proper level definition system helps a lot. If you feel that people are generalizing a one-off negative event, ask them to provide more examples of that behavior. You can actually call out that you feel stigmatized by that single event or trait. If you can, highlight counterexamples.</p>
<p>Sometimes phrasing of rating scale points helps mitigate these biases, e.g. if you call the two extremes of the scales “consistently underperforming” and “top performer”.</p>
<hr>
<h2 id="8-idiosyncratic-rater-bias">Idiosyncratic rater bias</h2>
<p>Bob is an engineering manager leading a mobile developer team. Bob has deep experience in project management but almost none in mobile development. Bob seems to consistently rate the development skills of his engineers much higher than they really are, while he rates the project management performance of the lead developer lower than it is.</p>
<p>Idiosyncratic rater bias happens when people evaluate skills they’re not good at, higher. Sometimes they rate others lower in things they’re great at. This is rooted in lower standards we have for things we don’t have deep knowledge about and higher standards for things we’re experienced at. In other words, our feedback reflects more on our own skills than the person’s we’re reviewing.</p>
<h3 id="9-how-to-counter-the-idiosyncratic-rater-bias">How to counter the idiosyncratic rater bias</h3>
<p>To overcome this bias as a manager, try rephrasing your performance evaluation questions for yourself from a different perspective, e.g.:</p>
<p>If this engineer wanted to resign I would try to retain them.</p>
<p>I would want this engineer on my team at any time.</p>
<p>I would hire this engineer again at any time.&nbsp;</p>
<p>Research shows that people are much more accurate when rating their own intentions compared to rating other people.</p>
<p>Also, having a diverse set of feedback from peers can mitigate this (there’s a low probability for every reviewer to be biased the same way).</p>
<hr>
<h2 id="10-centrality-bias">Centrality bias</h2>
<p>Alice is the manager of a team. She hands in her annual performance evaluations, and you notice that almost everyone on her team scored near the middle of the scale. Now you wonder if that’s actually a realistic image or not.</p>
<p>Many managers don’t like being extreme and tend to be moderate in their reviews. When everyone is receiving a rating of 3 out of 5 across the board, there’s no distinguishing the low-performing and high-performing employees. This will result in unfair reviews and people being pissed by lack of recognition and that nothing happens to low performers.&nbsp;</p>
<h3 id="11-how-to-counter-the-centrality-bias">How to counter the centrality bias</h3>
<p>Well, an easy hack is to remove the middle of the rating scale, the ‘neutral’ option, e.g. have a scale of 4 instead of 5 to force managers to decide. If you received one of the ‘meh’ reviews, have a heart-to-heart with your manager and highlight where you disagree. For example, if you feel you’ve been doing better in a certain area ask for explicit examples of how you could do better and cross-check it with your data points. Rating on multiple skills and axes can help, too, compared to a single, unified rating.&nbsp;</p>
<h2 id="12-contrast-bias">Contrast bias</h2>
<p>Alice is really good at project management. Bob is …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ochronus.online/biases-in-performance-reviews/">https://ochronus.online/biases-in-performance-reviews/</a></em></p>]]>
            </description>
            <link>https://ochronus.online/biases-in-performance-reviews/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199752</guid>
            <pubDate>Tue, 24 Nov 2020 16:14:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>“Ham Radio is dying!” A phrase all to often uttered that it’s become cliché, but it’s partly true. You can’t deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won’t be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren’t interested in pushing the limits of RF technology. To be blunt I’m talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word’s meaning. When I use the word hacker, I’m talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio’s role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that’s currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn’t be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink’s 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It’s been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I’ve collected has suggested this is a common occurrence around the United States. This type of focus doesn’t foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who’s going provide communications “support” on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can’t do that locally in person or over the air, then it’s time to turn to the digital voice modes. That’s right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one’s hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That’s what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I’m fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I’d love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype – 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Don't Work With Startups (Or FAANGs)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25199374">thread link</a>) | @elliotbnvl
<br/>
November 24, 2020 | https://devcareer.elliotbonneville.com/no-startups-or-faangs | <a href="https://web.archive.org/web/*/https://devcareer.elliotbonneville.com/no-startups-or-faangs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-no-startups-or-faangs"><p><span><span>This chapter is not a hard and fast set of rules you should always abide by, but is some reasoning and facts that I’ve found to be true about picking a company to work for, while optimizing for a high rate, freedom, and flexibility.</span></span></p><p><span><span>The tl;dr version is that you shouldn’t work with startups, because they are high pressure and don’t pay well, and you shouldn’t work with household names (Facebook, Amazon, Google, Netflix, and their ilk) because they don’t provide as much flexibility.</span></span></p><p><span><span>Instead, you should target a sweet spot right in the middle, working with companies who have enough money to pay you well, but aren’t large enough and well-run enough that they can afford to be extremely exclusive and demanding of their employees.</span></span></p><p><span><span>As a side effect of their size, these companies often have pressing technical issues that are growing pains which haven’t been resolved yet that you can be of real value in solving. Working with them leads to doing high-value, satisfying work that pays well and affords you freedoms you wouldn’t otherwise find.</span></span></p><p><span><span>We’ll clear up some common misunderstandings and establish our reasoning by tackling this topic from first principles, as per usual.
</span></span></p><p><span><span><em>This post is an early release chapter of </em></span><span><em><a href="https://devcareer.elliotbonneville.com/">a book I'm writing in public</a></em></span><span><em>, working title of </em></span><span>Refactor Your Career</span><span><em>. If you're interested in following along for more prerelease chapters and other info, you can sign up for the newsletter below:</em></span></span></p><h2 id="block-b97dcd7b406e467b87a25fbcb87546ba"><span id="b97dcd7b406e467b87a25fbcb87546ba"></span><span><span>Don’t work with startups</span></span></h2><p><span><span>The definition of a startup is “a company prioritizing fast growth over everything else.”</span></span></p><p><span><span>Given the current economic incentive structure of the venture capital model, startups often take outside investment to grow more quickly.</span></span></p><p><span><span>As a result, startups typically optimize to get as much done with as little money and in as little time as possible, because they are not cash-flow positive and have limited financial runway.</span></span></p><p><span><span>Therefore, they are incentivized to find extremely high return-on-investment employees who will work long hours for little money. To find these employees, they will use a number of strategies:</span></span></p><ul><li id="block-53700a214aaf4831be4625f6876e0ed7"><span><span>Offer equity instead of cash compensation</span></span></li><li id="block-2b21919a7bb64e3e962a21fd7d352e42"><span><span>Offer “fun” benefits (beer, ping pong table, catered lunches, free movie tickets, etc.)</span></span></li><li id="block-bb36db0b8db44966b9505bbb5ec4ea1a"><span><span>Target young, talented, and hardworking engineers who are new to the industry and don’t have connections</span></span></li></ul><p><span><span>An extremely high return-on-investment employee is always getting the short end of the stick. The money has to come from somewhere, and in this case the money is coming from the employees’ pockets.</span></span></p><p><span><span>As an aside, your employer wins when they get the most bang for their buck, but the more bang they get for their buck, the less bang you get in return for the most valuable resource you possess -- your time.</span></span></p><p><span><span>At its core, hourly billing is a profoundly adversarial relationship, and you need to understand the rules by which it operates in order to not be taken advantage of. If you don’t know the rules of the game, you will lose. If you know the rules of the game and don’t play to them, you will lose. If you want to win, you must play intelligently, intentionally, and aggressively.</span></span></p><p><span><span>Hourly billing is just the beginning. As you grow in skill and “career capital” (c.f. </span><span><a href="https://www.amazon.com/Good-They-Cant-Ignore-You-ebook/dp/B0076DDBJ6" target="_blank" rel="noopener noreferrer"><em>So Good They Can’t Ignore You</em></a></span><span>, Cal Newport), you’ll want to explore ways to move away from hourly billing to a better way of billing, i.e. separating time worked from results delivered. Big benefits to you and your clients all the way around. Jonathan Stark writes eloquently on the issues with hourly billing </span><span><a href="https://jonathanstark.com/the-moral-dilemma-of-hourly-billing" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><p><span><span>Let’s take a deeper look at the strategies startups use to find employees, and why that means working for one is usually a bad strategy.</span></span></p><h3 id="block-5b675128f52f4bc7ae0ffadf51c842d9"><span id="5b675128f52f4bc7ae0ffadf51c842d9"></span><span><span>Taking equity is becoming a micro venture capitalist</span></span></h3><p><span><span>Venture capitalism is a bet on the future. Even the best venture capitalists lose money on most of their investments. They only turn a profit because they invest at scale and need just a couple of big wins per batch of investments in order to make up for that extremely high percentage of losses. They also study investing all day, every day, and are surrounded by people all doing the exact same thing.</span></span></p><p><span><span>Second, time is fungible. If you want, you can trade time for money directly (that’s what hourly billing is, after all). Therefore, an investment of time is an investment of your personal funds.</span></span></p><p><span><span>As a result, if you take equity compensation instead of cash when working at a startup, you are investing your money directly into that startup.</span></span></p><p><span><span>Given all of the above and bearing in mind that venture capitalism is a high risk bet that only works at scale for people who exclusively study how to invest, the odds that you are going to make a return on your investment with the limited amount of resources that you have to invest is vanishingly low.</span></span></p><p><span><span>Don’t try to play venture capitalist with the most valuable thing you have -- your time.</span></span></p><p><span><span><a href="https://www.jwz.org/about.html" target="_blank" rel="noopener noreferrer">Jamie Zawinski</a></span><span> (OG programmer, one of the founders of Netscape and Mozilla.org, the guy who probably wrote your screensaver, and now a dance club proprietor [yes, really]) has this to say about working for startups:</span></span></p><blockquote id="block-bf5cc1f488d24661902d79343aefc830"><span><span>Follow the... money. When a VC tells you what's good for you, check your wallet, then count your fingers.

He's telling you the story of, "If you bust your ass and don't sleep, you'll get rich" because the only way that people in his line of work get richer is if young, poorly-socialized, naive geniuses believe that story! Without those coat-tails to ride, VCs might have to work for a living. Once that kid burns out, they'll just slot a new one in.</span></span></blockquote><p><span><span>You can read the full post from 2011 </span><span><a href="https://www.jwz.org/blog/2011/11/watch-a-vc-use-my-name-to-sell-a-con/" target="_blank" rel="noopener noreferrer">here</a></span><span> and I highly encourage you to do so. It’s a zinger.</span></span></p><h3 id="block-ffa7baffd6a6461a9f9db8658d9237c6"><span id="ffa7baffd6a6461a9f9db8658d9237c6"></span><span><span>Empirically, equity is not as valuable as it seems</span></span></h3><p><span><span>Backing up the logic above, loose empirical analysis shows that if you look at total startup compensation as income combined with equity </span><span><em>adjusted for likelihood of realizing that equity’s value</em></span><span>, statistically you end up making less money in the end.</span></span></p><p><span><span>Patrick McKenzie, a well-known entrepreneur and prolific writer, and currently working at Stripe to “increase the GDP of the internet,” has this to say on the topic of valuing equity grants:</span></span></p><blockquote id="block-f861c0e363034719a6aa4cf4032f0005"><span><span>Roll d100. (Not the right kind of geek? Sorry. rand(100) then.)

0~70: Your equity grant is worth nothing.

71~94: Your equity grant is worth a lump sum of money which makes you about as much money as you gave up working for the startup, instead of working for a megacorp at a higher salary with better benefits.

95~99: Your equity grant is a lifechanging amount of money. You won’t feel rich — you’re not the richest person you know, because many of the people you spent the last several years with are now richer than you by definition — but your family will never again give you grief for not having gone into $FAVORED_FIELD like a proper $YOUR_INGROUP.

100: You worked at the next Google, and are rich beyond the dreams of avarice. Congratulations.

Perceptive readers will note that 100 does not actually show up on a d100 or rand(100).</span></span></blockquote><p><span><span>Dan Luu, another well-known developer and blogger, has this to say on the subject:</span></span></p><blockquote id="block-841b5199ddf14a02af23c89b2adf0131"><span><span>For a more serious take that gives approximately the same results, 80000 hours finds that the average value of a YC founder after 5-9 years is $18M. That sounds great! But there are a few things to keep in mind here. First, YC companies are unusually successful compared to the average startup. Second, in their analysis, 80000 hours notes that 80% of the money belongs to 0.5% of companies. Another 22% are worth enough that founder equity beats working for a big company, but that leaves 77.5% where that's not true.

If you're an employee and not a founder, the numbers look a lot worse. If you're a very early employee you'd be quite lucky to get 1/10th as much equity as a founder. If we guess that 30% of YC startups fail before hiring their first employee, that puts the mean equity offering at $1.8M / .7 = $2.6M. That's low enough that for 5-9 years of work, you really need to be in the 0.5% for the payoff to be substantially better than working at a big company unless the startup is paying a very generous salary.</span></span></blockquote><p><span><span>You can read the rest of Patrick’s post </span><span><a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/" target="_blank" rel="noopener noreferrer">here</a></span><span>, and the rest of Dan’s post </span><span><a href="https://danluu.com/startup-tradeoffs/" target="_blank" rel="noopener noreferrer">here</a></span><span>. I highly recommend that you do so; they are erudite writers with a lot of insight into the industry.</span></span></p><h3 id="block-886c6f74b682471f90e8c002e01f09c9"><span id="886c6f74b682471f90e8c002e01f09c9"></span><span><span>Startup benefits are the cheese in the mousetrap</span></span></h3><p><span><span>While it might seem rather cynical, the benefits at a startup are just the cheese in the mousetrap. If you calculate the actual cash value of the benefits that many startups offer, you’ll find that they’re laughably low. Free beer, access to the company ping pong table (that never gets used), free movie tickets and a two hundred dollar per month business learning stipend actually work out to a relatively low amount of cold, </span><span><del>hard</del></span><span> mildly wrinkled Franklins.</span></span></p><p><span><span>Even things that are seemingly inherent to the unpurchasable, intangible benefits of startup culture like an open desk plan, brilliant and intense coworkers, and technically cutting-edge work can all be had elsewhere for a fraction of the time-cost of working at a startup if you’re willing to think outside the box.</span></span></p><p><span><span>Given that remaining within this particular box is so expensive, I highly encourage you not to do so without full understanding of what you’re doing.</span></span></p><p><span><span>If you can make $80/hr at a startup and $130/hr at a regular company, you are paying the startup $50/hr for the privilege of working there. For $50/hr, you can figure out a way to get most of the same benefits and come out way, way ahead.</span></span></p><p><span><span>Do what makes you happy, but do it with your eyes open. Also, if you really want to work at a startup, you might be better served by starting one.</span></span></p><h2 id="block-aebdc986fc9a4a39917e802441860771"><span id="aebdc986fc9a4a39917e802441860771"></span><span><span>Don’t work with household names</span></span></h2><p><span><span>There’s a word that gets tossed around a lot in the communities where developers that talk about their careers hang out (Hacker News, Reddit, et. al.) -- FAANG. It’s an acronym that refers to Facebook, Apple, Amazon, Netflix, and Google.</span></span></p><p><span><span>People talk about these companies (which pretty much are all out in Silicon Valley or in Seattle) so much that an acronym evolved as a catchall to refer to them. When I say “household name,” these are the companies …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcareer.elliotbonneville.com/no-startups-or-faangs">https://devcareer.elliotbonneville.com/no-startups-or-faangs</a></em></p>]]>
            </description>
            <link>https://devcareer.elliotbonneville.com/no-startups-or-faangs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199374</guid>
            <pubDate>Tue, 24 Nov 2020 15:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Disc as Dongle]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25199286">thread link</a>) | @mortenjorck
<br/>
November 24, 2020 | https://interuserface.net/2020/11/the-disc-as-dongle/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2020/11/the-disc-as-dongle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>November 23, 2020</h3>
      
      <p>One possible future of digital distribution is already here – in the guise of an existing format.</p>
      
<p><span>The industrial design</span> of the just-released Playstation 5 may be <a href="http://interuserface.net/2020/06/the-regressive-design-of-the-playstation-5/" data-type="post" data-id="633">regressive</a>, but it looks to the future in one critical way: Judging by the ungainly grafting-on of its disc drive, its original conception as a digital-only console is unmistakable.</p>



<p>For many, digital-only is a conflicting proposition. It curtails long-established freedoms of lending and resale, yet most would agree that it is also inevitably the future. But it doesn’t have to be the former. There is a solution – and it already exists.</p>



<p>The physical discs included with the retail versions of console games have served an increasingly marginal utility over the past console generation. Ever-larger day-one patches weigh in in the gigabytes. Triple-A games already require tens of gigabytes of data to be copied from the disc to the hard drive in order to manage load times, and the Playstation 5’s reliance on a super-fast SSD architecture only formalizes this. </p>



<hr>



<p><span>This leaves the disc</span> with precious little to actually do – it’s too slow to be played from, its data is often outdated by the time it’s installed, and as broadband speeds continue to inch upward, the read speed of even a modern Blu-ray drive is already slower than some fiber connections. Yet despite all this, the lowly disc still has one ace in the hole.</p>



<p>Even stripped of its value as a storage mechanism for game data, the disc serves a critical purpose: It is the physical manifestation of a license, an unencumbered and freely transferable token with which ownership of a game is immutably entangled. Future games could well ship with an essentially empty disc, relying on the network for everything else, yet the advantage of the disc-anchored license would remain undisputed. The disc allows one to, as memorably demonstrated in Sony’s 2013 response to Microsoft’s aborted digital-only Xbox play, simply <a href="https://www.polygon.com/2013/6/10/4417490/playstations-one-step-tutorial-on-sharing-used-games">hand that license to someone else.</a></p>



<hr>



<p><span>All this then invites the question:</span> Why does it have to be a <em>disc?</em> Why does a console need a noisy, mechanically complex, and expensive optical drive just to read a license? Professional software has long used USB peripherals, or dongles as they are semi-affectionately known, as the physical manifestation of licenses. The disc has become a dongle, so why not just use a dongle?</p>



<p>A few kilobytes and an encryption scheme are all that’s required to tie licenses to a physical device today. A tiny, inexpensive USB device could serve as the retail form factor for future games, ushering in an all-download future that retains nearly all the benefits of physical legacy formats. It could perhaps even, via firmware update, add “physical media” support to both the digital-only Playstation 5 and Xbox Series S.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2020/11/the-disc-as-dongle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199286</guid>
            <pubDate>Tue, 24 Nov 2020 15:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interim analysis shows 91.4% efficacy for the Russian Sputnik vaccine]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199213">thread link</a>) | @yread
<br/>
November 24, 2020 | https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li>
<p>
<b><i>The efficacy of the Sputnik V vaccine is 91.4%, based on the second interim analysis of data obtained 28 days after administering the first dose</i></b> (7 days after the second dose).
</p>
<ul>
<li>
<p>
<b><i>Calculation was based on the analysis of data on volunteers (n = 18,794) who received both the first and second doses</i></b><i> of the Sputnik V vaccine or placebo at the second control point (39 confirmed cases as of November 23, 2020) in accordance with the clinical trial protocol. </i>
</p>
</li>
</ul>
</li>
<li>
<p>
<b><i>Preliminary data from volunteers obtained 42 days after the first dose</i></b><i> (corresponds with 21 days after the second dose) <b>indicates an efficacy of the vaccine above 95%.</b> </i>
</p>
</li>
<li>
<p>
<i>The <b>interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals.</b> Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.</i>
</p>
</li>
  
<li>
<p>
<i>Currently, 40,000 volunteers are taking part in the Phase III double-blind, randomized, placebo-controlled clinical post-registration study of the Sputnik V vaccine in Russia, of whom more than <b>22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and second doses</b>.</i>
</p>
</li>
<li>
<p>
<i>There were <b>no unexpected adverse events during the trials</b>. Monitoring of the participants is ongoing.</i>
</p>
</li>
<li>
<p>
<b><i>The Sputnik V vaccine is based on a well-studied human adenoviral vector platform that has proven safe and effective with no long-term side effects </i></b><i>in more than 250 clinical trials globally conducted during the past two decades - while the history of the use of human adenoviruses in vaccine development began in 1953. More than 100,000 people have received approved and registered drugs based on human adenoviral vectors.</i>
</p>
</li>
<li>
<p>
<b><i>The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors</i></b><i> which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.</i>
</p>
</li>
</ul>
<p>
<b>Moscow, November 24, 2020 –</b><b> </b>The National Research Center for Epidemiology and Microbiology named after N.F. Gamaleya of the Ministry of Health of the Russian Federation (Gamaleya Center) and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund), announce positive results obtained during the second interim data analysis of the largest double-blind, randomized, placebo-controlled Phase III clinical trials in Russia’s history involving 40,000 volunteers. Gamaleya Center experts have once again confirmed the high efficacy of the Sputnik V vaccine, the world’s first registered vaccine against coronavirus based on a well-studied platform of human adenoviral vectors. <b>Evaluation of efficacy was carried out among volunteers (n = 18,794) 28 days after receiving the first dose (7 days after the second dose) of the vaccine or placebo upon reaching the second check point of the trial in compliance with the clinical trial protocol. The analysis demonstrated a 91.4% efficacy rate for the Sputnik V vaccine. </b>
</p>
<div>
<center><img width="90%" alt="table_eng_spu.jpg" data-src="/upload/medialibrary/70b/70bc3db939ed55ad755e935e8ae26df3.jpg" data-crc="5b1b93c0b54d98c83dc2e94e48f68aad" height="auto" title="table_eng_spu.jpg" src="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/table_eng_spu.jpg"></center>
</div>
<p>
According to the protocol of Phase III clinical trials of the Sputnik V vaccine, its interim efficacy is calculated at three statistically significant representative check points - upon reaching 20, 39 and 78 cases of novel coronavirus infection among volunteers both in the placebo group and in the group that received the vaccine. The second interim analysis of the Sputnik V vaccine efficacy was carried out on the basis of 39 confirmed cases identified in the placebo group (31 cases) and in the vaccine group (8 cases). The ratio of the placebo group to the vaccinated group is 1 to 3.
</p>
<p>
The uniqueness of the Russian vaccine lies in the use of two different vectors based on the human adenovirus, which allows for a stronger and longer-term immune response as compared to vaccines using one and same vector for two doses. <b>So, preliminary data on volunteers on the 42nd day after the first dose (equivalent to 21 days after the second dose), when they have already formed a stable immune response, indicates the efficacy rate of the vaccine is above 95%.</b>
</p>
<p>
The next interim data analysis will be conducted upon reaching the third check point of 78 confirmed coronavirus cases among the study participants. Final data analysis will be available by the end of Phase III clinical trials.
</p>
<p>
The interim research data will be published by the Gamaleya Center team in one of the leading international peer-reviewed medical journals. Following the completion of Phase III clinical trials of the Sputnik V vaccine, Gamaleya Center will provide access to the full clinical trial report.
</p>
  
<p>
As of November 24 more than 22,000 volunteers were vaccinated with the first dose and more than 19,000 volunteers with the first and the second dose of the vaccine at 29 medical centers in Russia as part of the ongoing clinical trials. Currently Phase III clinical trials are approved and are ongoing in Belarus, the UAE, Venezuela and other countries, as well as Phase II-III in India.
</p>
<p>
As of November 24, no unexpected adverse events were identified as part of the research. Some of those vaccinated had short-term minor adverse events such as pain at the injection point and flu-like symptoms including fever, weakness, fatigue, and headache.
</p>
<p>
During the clinical trials, the safety of the vaccine is constantly being monitored; information is analyzed by the Independent Monitoring Committee comprising leading Russian scientists. Collection, quality control and data processing is conducted in line with ICH GCP standards and involves the active participation of Moscow’s Health Department and Crocus Medical, the contract research organization (CRO).
</p>
<p>
<b>Mikhail Murashko, Minister of Health of the Russian Federation,</b> said:
</p>
<p>
“The data demonstrating high efficacy of the Sputnik V vaccine give us hope that we will soon obtain the most important tool in the fight against the pandemic of the novel coronavirus infection”.
</p>
<p>
<b>Alexander Gintsburg, Gamaleya Center Director,</b> said:
</p>
<p>
“It is very important that the second interim efficacy analysis of Sputnik V has confirmed our findings from the first stage and shown its efficacy at 91-92%. Let me stress that the second analysis was conducted a week after volunteers got the second dose, meaning that their bodies have partially reacted to both doses. We expect the efficacy rate to be even higher based on the data three weeks after the second immunization when the body’s strongest and most stable response is achieved. We plan to conduct the third interim data analysis after 78 confirmed coronavirus cases among volunteers and we have every reason to believe that the results will exceed our initial expectations. The drug’s final efficacy assessment will be made available after Phase III clinical trials are concluded.”
</p>
<p>
<b>Denis Logunov, Gamaleya Center Deputy Director,</b> commented:
</p>
<p>
“Results from the second interim analysis of the Sputnik V vaccine are in line with our expectations and predictions. The vaccine’s high efficacy rate is an important indication that a stable immune response to the coronavirus infection is formed among the study’s participants. We expect that the next interim results will demonstrate Sputnik V’s positive traits, moving us closer to the study’s completion and the beginning of a mass vaccination of our fellow citizens.”
</p>
<p>
<b>Kirill Dmitriev, CEO, Russian Direct Investment Fund,</b> said:
</p>
<p>
“Gamaleya Center has developed one of the most efficient vaccines against coronavirus in the world with an efficacy rate of more than 90% and a price that is two times lower than that of other vaccines with similar efficacy rate. The uniqueness of the Russian vaccine lies in the use of two different human adenoviral vectors which allows for a stronger and longer-term immune response as compared to the vaccines using one and the same vector for two doses.”
</p>
<p>
***
</p>
<p>
The safety of vaccines based on human adenoviruses has been confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades - while the history of use of human adenoviruses in vaccine development started in 1953. Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When the Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body's stable immune response.
</p>
<p>
On September 4, The Lancet, one of world’s leading medical journals, published a research paper on the results of Phase I and Phase II clinical trials of the vaccine that showed no serious adverse events and an effective immune response of those vaccinated.
</p>
<p>
Requests for more than 1.2 billion doses of Sputnik V vaccine came from more than 50 countries. The vaccine supplies for the global market will be produced by RDIF’s international partners in India, Brazil, China, South Korea and other countries.
</p>
<p>
On August 11, the Sputnik V vaccine developed by the Gamaleya Center was registered by Russia’s Health Ministry and became the world’s first registered vaccine against COVID-19. Detailed information on the Sputnik V vaccine, its human adenoviral vectors technological platform, and other details are available at&nbsp;<a href="https://sputnikvaccine.com/" target="_blank">sputnikvaccine.com</a>
</p>
<p>
<b>Be the first to learn about Sputnik V on social networks:</b>
</p>
<p>
<a href="https://twitter.com/sputnikvaccine" target="_blank">Twitter</a>
</p>
<p>
<a href="https://www.facebook.com/sputnikvaccine" target="_blank">Facebook</a>
</p>
<p>
<a href="https://www.instagram.com/sputnik_vaccine/" target="_blank">Instagram</a>
</p>
<p>
<a href="https://www.youtube.com/channel/UCLvQuKL3Nn7NnT9Jyi_dlgQ" target="_blank">Youtube</a>
</p>
<p>
***
</p>
<p>
<b>Russian Direct Investment Fund (RDIF)</b> is Russia's sovereign wealth fund established in 2011 to make equity co-investments, primarily in Russia, alongside reputable international financial and strategic investors. RDIF acts as a catalyst for direct investment in the Russian economy. RDIF’s management company is based in Moscow. Currently, RDIF has experience of the successful joint implementation of more than 80 projects …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/">https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/second-interim-analysis-of-clinical-trial-data-showed-a-91-4-efficacy-for-the-sputnik-v-vaccine-on-d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199213</guid>
            <pubDate>Tue, 24 Nov 2020 15:20:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A lesson in creating and using niche business DSLs at scale]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198991">thread link</a>) | @rhnvrm
<br/>
November 24, 2020 | https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/ | <a href="https://web.archive.org/web/*/https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At Zerodha, we process millions of trades in real-time, where each trade comes
into the system as concurrent high throughput HTTP requests. Each trade
increases the latency for subsequent orders in the queue that are under
processing at the same time at our OMS (Order Management System). When a single
order comes through to the OMS, it goes through a bunch of computationally
intensive validations and adds to the latency. To reduce the latency of orders,
we decided to offload some of these business validations from the OMS into an
external component called Veto, which pre-validates incoming orders based on
custom dynamic rules set by our Risk Management team. Rejected orders never go
through to the OMS thereby reducing significant load on the OMS. This is the
story of how we incrementally built this engine to keep up with the changing
business and regulatory environment starting with a custom DSL (Domain Specific
Language) and ending up with writing a framework to manage rules written in Go
and embedded inside Go plugins.</p><h2 id="overview">Overview</h2><p>Our goal with Veto was to build a dynamic evaluation engine framework capable of
hot-reloads. This framework would provide a generic environment to manage, track
and audit rules and filters on an easily accessible dashboard. The engine should
have support for custom data-stores related to the orders. Rules in this
framework are business validations on orders placed by our clients. These
validations range from simple checks like validating the limit prices to be
within circuit limits, to complex beasts, which <a href="https://support.zerodha.com/category/trading-and-markets/kite-web-and-mobile/articles/why-did-my-bank-nifty-option-order-get-rejected">validate fresh buy
orders</a>
in Nifty/BankNifty strikes due to exchange OI restrictions.</p><p><img src="https://zerodha.tech/static/images/bnf-veto-rejection.png" alt="banknifty-rejection-example"></p><p>Our first solution utilized our research from the
<a href="https://sentinel.zerodha.com/">Sentinel</a> project. We combined
<a href="https://github.com/Knetic/govaluate">knetic/govaluate</a>, which is an expression
evaluation engine, along with a filter manager and a hot reload mechanism with
an HTTP server which would either respond with an appropriate rejection to
the incoming order or proxy to the upstream OMS, thereby acting as a reverse
proxy with validations. The expression language was similar to Excel formulas,
which was familiar to our RMS Team that managed and operated it through custom
management dashboard built using <a href="https://frappe.io/">Frappe/ERPNext</a>.</p><h2 id="problems-with-dsls">Problems with DSLs</h2><p>After taking it live, we realized a bunch of issues that
cropped up and became pain points for us over time. These were not really technical,
but more or less, human usability issues.</p><ul><li><p>Since the underlying engine was a simple expression evaluator, the operators
would end up spending hours trying to write complex rules, and similarly the
developers, who are supposed to approve the rule to be production ready, spent
time reviewing it.</p><ul><li><p>This was due to how unreadable the expressions would become beyond a certain
complexity. Simple rules were indeed faster to write, but anything beyond
it would be beyond human capability to comprehend, which would cause
unnecessary and difficult debugging sessions in the office.</p></li><li><p>Unlike a regular language with branching, the operator writing the
rule would be stuck on writing logic defined with bracket matching
and <code>AND/OR</code> statements. Also, missing support for variables would not
allow us to reuse values.</p></li><li><p>To write a single complex rule, operators would depend on writing the rules
into manageable chunks. For example, a single spread (shown below) the rule would be broken
into <code>spread_ce_buy</code>, <code>spread_ce_sell</code>, <code>spread_pe_buy</code>, <code>spread_pe_sell</code>
rules.</p><p><img src="https://zerodha.tech/static/images/veto-govaluate-example.png" alt="Veto Govaluate Sample"></p></li></ul></li><li><p>Custom error messages and any non-boolean behaviour were not possible, as the
expression can only evaluate to a boolean. Switching to a proper language, we
could use early returns in the rule and return custom messages alongside the
evaluation result.</p></li><li><p>Implementing new functions and adding new variables was a pain.</p><ul><li>This meant that if you were to add a new function, you would have to bundle
it within the engine, defeating the purpose of the rules being dynamic.</li><li>This also meant the developer had to always be involved in writing the rules, defying the whole purpose of having a DSL for business folks.</li></ul></li></ul><h2 id="new-beginnings">New beginnings</h2><p>Our learnings from these issues made us reflect if it would be worth it for the
operators to keep using a simple expression language. The way we were going, we were
essentially building a DSL (Domain Specific Language) on top of <code>govaluate</code>,
that would keep getting more complex with time.</p><p>We finally decided that a solution to the problem was to use Go-like language as
the DSL instead of <code>govalute</code> and distribute the dynamic rules as Go plugins, as
Veto was written in Go in the first place, just like the rest of the Kite stack.
It is simple, easy to learn, and has good tooling around it.</p><p>We debated heavily on the best approach to solve the problems that we were
facing with veto rules and shortlisted a few candidates. We picked a complex rule in production written using govaluate and wrote that in the following to benchmark the performance of the rules in the alternatives.</p><ul><li><a href="https://github.com/Knetic/govaluate">Govaluate</a> - evaluates arbitrary C-like expressions</li><li><a href="https://github.com/containous/yaegi">Yaegi</a> - embedded go interpreter</li><li><a href="https://www.openpolicyagent.org/docs/latest/policy-language/">Rego</a> - open-policy-agent DSL</li><li><a href="https://github.com/hashicorp/go-plugin">Hashicorp Plugins</a> - plugin system over RPC.</li><li><a href="https://golang.org/pkg/plugin/">go-plugins</a> - native go plugins</li></ul><p>Benchmark Results:</p><div><pre><code data-lang="fallback">govaluate:
1319773 907 ns/op
go-plugins:
2745398 503 ns/op
yaegi:
202173 11091 ns/op
rego:
83476 13796 ns/op
</code></pre></div><p>We considered govaluate to be the baseline for our experiments. In our
benchmarks, native plugins outperformed other solutions and brought the power of
the entire Go runtime into independent plugins. We discarded Hashicorp plugins,
as they were slower. Yaegi was nice, but not as fast as govaluate. Govaluate and
Yaegi provide a simpler way to distribute rules, when compared to native plugins
which need a bit of orchestration.</p><h2 id="veto-v2">Veto v2</h2><p>Considering all the facts, we decided to go ahead with native Go plugins. They
are as fast as native code once loaded, and given enough tooling, act just like
regular Go code, along with all its niceties like type safety and none of the
baggage of other alternatives.</p><p>Veto v2 would be a web server which loads rules from native Go plugins on boot
and behave like a reverse proxy accepting incoming orders as HTTP requests,
either rejecting them in place or proxying them to the upstream OMS.</p><p>Since there are
<a href="#overcoming-go-plugin-caveats">problems</a> associated with building and
distributing plugins due to dependency issues, requiring in-tree building and
compilation, we decided to first work on writing a framework to abstract the
caveats associated with go plugins.</p><h3 id="a-framework-for-writing-rules">A framework for writing rules</h3><p>Rules in Veto v2 are now written in plain Go by the operators. A rule looks similar
to the following sample rule.</p><p>Each rule is expected to provide three functions.</p><p>Rules are contained in the <code>Validate</code> functions that are expected to accept an
interface and return a <code>rule.Result</code>. The contexts contain the controllers and
data needed for validating the rule, and are passed by the host to the rule
manager which iterates over all the rules. The host can then interpret the result
and do what it needs to, in our case render a response to the user with a custom
message, or proxy to the upstream.</p><p>Another added benefit of having written a custom go plugin based framework for
rules, is that we can implement our own testing framework for validation of the
rules. Every rule is expected to return its own testcases as a
<code>map[interface{}]e.Result</code> where the interface is the context. This way if a
rule implements all the testcases, we are sure that any minor refactor will be
also correct in the future. This reduces the need for constant developer
oversight and the testing needed for the rules. Also, the testcases provide
extra documentation for the future.</p><p>The following rule contains a sample circuit limit rule for illustration.</p><div><pre><code data-lang="go"><span>package</span> main

<span>import</span> (
    <span>...</span>
)

<span>// Slug is the identifier for the rule. Used in statistics and logging.
</span><span></span><span>func</span> <span>Slug</span>() <span>string</span> {
    <span>return</span> <span>"a_sample_ckt_limit_rule"</span>
}

<span>// Validate, is where the validation logic resides.
</span><span></span><span>func</span> <span>Validate</span>(data <span>interface</span>{}) (e.Result, <span>error</span>) {
    d, err <span>:=</span> m.<span>SetupOrderData</span>(data)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

    <span>// Get the market for the incoming order
</span><span></span>    s, err <span>:=</span> d.Ticker.<span>GetSnapForOrder</span>(d.OrderData.Order)
	<span>if</span> err <span>!=</span> <span>nil</span> {
		<span>return</span> e.Result{}, err
	}

    <span>...</span>

	<span>// Check limits
</span><span></span>	<span>if</span> d.Order.Price &gt; s.UpperCircuitLimit {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is higher than the current [upper circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.UpperCircuitLimit),
		}, <span>nil</span>
	}

	<span>if</span> s.LowerCircuitLimit &gt; d.Order.Price {
		<span>return</span> e.Result{
			Result: <span>true</span>,
			Message: fmt.<span>Sprintf</span>(
				<span>"Your order price is lower than the current [lower circuit limit](https://support.zerodha.com/category/trading-and-markets/trading-faqs/articles/what-does-circuit-limits-i-e-price-bands-mean) of %g. You can place an order within the range or [use GTT](https://support.zerodha.com/category/trading-and-markets/gtt/articles/what-is-the-good-till-triggered-gtt-feature) for long-standing orders."</span>,
				s.LowerCircuitLimit),
		}, <span>nil</span>
	}

    <span>return</span> e.Result{}, <span>nil</span>
}

<span>// TestData is expected to be provided by the rule,
</span><span>// so it can be validated before it is allowed to be published.
</span><span></span><span>func</span> <span>TestData</span>() <span>map</span>[<span>interface</span>{}]e.Result {
	tckr <span>:=</span> <span>&amp;</span>ticker.Ticker{
		Data: <span>map</span>[<span>string</span>]<span>interface</span>{}{
			<span>"NSE:INFY"</span>: snaps.Snap{
				LastPrice:         <span>12.34</span>,
				UpperCircuitLimit: <span>15.0</span>,
				LowerCircuitLimit: <span>10.0</span>,
			},
		},
	}

	<span>return</span> <span>map</span>[<span>interface</span>{}]e.Result{
		<span>&amp;</span>m.OrderContext{
			Controllers: m.Controllers{
				Ticker:      tckr,
			},
			OrderData: m.OrderData{
				Order: oms.OrderParams{
					Exchange:      <span>"NSE"</span>,
					Tradingsymbol: <span>"INFY"</span>,
					Price:         <span>20.34</span>,
					OrderType:     <span>"LIMIT"</span>,
				},
			},
		}: e.Result{
			Result:  <span>true</span>,
			Message: <span>"Your order price is higher than the …</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/">https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</a></em></p>]]>
            </description>
            <link>https://zerodha.tech/blog/a-lesson-in-niche-business-dsls-at-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198991</guid>
            <pubDate>Tue, 24 Nov 2020 14:58:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade recycling rig turns plastic waste into new products]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198780">thread link</a>) | @lysp
<br/>
November 24, 2020 | https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/ | <a href="https://web.archive.org/web/*/https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-26604">
<h3>Homemade recycling rig turns plastic waste into new products</h3>
<p> — <span>November 24th, 2020</span>
</p>
<div>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-300x225.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-385x289.jpg 385w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-768x576.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>While that plastic cup, bag, dish, or other item may have served its purpose, more than likely it could be formed into something new. With this in mind, the SOTOP-Recycling team of Manuel Maeder, Benjamin Krause, and Nadina Maeder developed <a href="https://www.instructables.com/Automated-Injection-Molding-Machine-for-Plastic-Re/">an automated injection molding machine</a> that can be built at home and is small enough to allow you to run your own recycling operation!</p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-300x218.png 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-768x558.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>The “Smart Injector” receives shredded pieces of plastic in a small hopper, then transports them down an extrusion pipe where heat is applied. This material is clamped together via a pair of stepper motors, with screws and timing belts implemented to apply sufficient pressure. Everything is controlled by an <a href="https://store.arduino.cc/mega-2560-r3">Arduino Mega</a>. </p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-300x200.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>As shown in the video, the plastic waste is converted into phone covers in just minutes, though other things could also be made depending on the form tooling used.</p>
<figure><p>
<iframe title="Injection molding machine for recycling plastic" width="500" height="281" src="https://www.youtube.com/embed/Eq9IbetsLB4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<section>


<p>
<small>

You can follow any responses to this entry through the <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/feed/">RSS 2.0</a> feed.
You can <a href="#respond">leave a response</a>, or <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/trackback/" rel="trackback">trackback</a> from your own site.
</small>
</p>
</section>
</div>
</div></div>]]>
            </description>
            <link>https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198780</guid>
            <pubDate>Tue, 24 Nov 2020 14:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making 8500 plants available to you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25198771">thread link</a>) | @roboben
<br/>
November 24, 2020 | https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/making-8500-plants-available-on-permapeople.jpg" alt="8500 plants available on Permapeople"></p>

<p><strong>tl;dr We made ~8500 plants available to you by importing the Plant For a Future dataset. You can use it now to create lists, guilds and help improving that data.</strong></p>

<p>The first thing I did when I started Permapeople was to look at other plant databases and platforms with a similar focus. If you ever were in the situation to try to get some information about specific plants, especially attributes which are important for a Permaculture style of gardening, there is a high chance you found <a href="https://pfaf.org/">Plants for a Future</a> (PFAF). It is a database started by Addy and Ken Fern, later turned into a not for profit organization operated by a handful of trustees. In recent years, they refocused their work on plants’ role in fighting climate change through carbon sequestration. If you don’t know them, you should definitely check them out.</p>

<p>I put a lot of consideration into importing the PFAF database into Permapeople, but decided against it in the beginning. The more I talked to people and our first users, I figured that using existing datasets saves contributors a lot of time and provides an immediate value. Most people I talked to are beginners or people running larger gardening operations, and I wanted to create something that could help them immediately in their projects. I think the PFAF database is one of the best resources available, but I found some problems with it, limiting its usefulness.</p>

<h2 id="data-quality">Data Quality</h2>

<p>While the PFAF dataset is probably the biggest by numbers and completeness, it has a few problems: Many things are outdated, incorrect, ambiguous, or incoherent. Some might think that plant data and its field, <em><a href="https://en.wikipedia.org/wiki/Botany">botany</a></em> is a static field. Actually, it is really the opposite: New discoveries, nomenclature changes, and fresh scientific research comes in weekly. Keeping track of this with a tiny circle of paid workers is a tough job to do. Even if you could contribute a fix, there is no way of doing that. Crowdsourcing this problem by letting anyone change the data could be very helpful. This is one of the main reasons I started Permapeople: I wanted to have one place to find up-to-date, correct, peer-reviewed information on the plants I want to grow. If I miss some info or find something incorrect, I can easily edit it and help everyone who needs this information after me. Think Wikipedia, but specifically for plants.</p>

<h2 id="no-clear-roadmap">No clear roadmap</h2>

<p>What makes working with PFAF data more challenging is that there is no information on if and when data gets corrected, updated, or added to PFAF. We do not know if and when new features will be added and if the organization will shift its focus to other projects in the future.</p>

<h2 id="unstructured-data">Unstructured Data</h2>

<p>While this is related to the data quality, the PFAF data is not structured and rather a full-text description of the plant. This makes it hard to find or sort through specific info because many attributes are not filterable and searchable. For example, while PFAF has great information on <em>companion planting</em>, it’s impossible to search based on these connections. You are left with searching through many plant profiles, reading long paragraphs, and scanning for the required information.</p>

<h2 id="missing-features">Missing features</h2>

<p>Having a database is great, but information seekers and contributors need some functionality to work with it. PFAF doesn’t provide any of that, and this is why we already added some of these missing features to Permapeople.</p>

<h3 id="see-the-editing-history-and-sources">See the editing history and sources</h3>

<p>A huge factor of why Wikipedia is so trustworthy is that every change is public and can be easily reviewed by anyone. This lets a user easily gauge any meta-information about a plant: Is this info credible or just a myth created by the hive-mind of the internet? Do many people agree with that info? Are there sources proving the correctness of the information? If yes, how many? Or how are people working within a similar climate to you faring with that plant?</p>

<h3 id="create-plant-connections-and-guilds">Create plant connections and guilds</h3>

<p>Companion planting and the more advanced <a href="http://www.neverendingfood.org/b-what-is-permaculture/permaculture-guilds/">concept of guilds</a> are a huge part of the success of Permaculture. At Permapeople, you can create explicit plant connections (may they be beneficial or adversary) and organize plants into guilds. This info can be fed back to the database and give users even better information: If two plants are used in many user-generated guilds, there is a high chance that these plants go well together.</p>

<p>Much of this functionality is in a very early stage, and we need your help and feedback to improve these features and the data itself. I hope this post helped you understand why I imported the PFAF dataset into Permapeople and how we plan to improve on the hard work PFAF and its contributors have already accomplished. In the best case, we can contribute our changes back to PFAF.</p>

<p>If you are interested, I suggest you try to <a href="https://permapeople.org/search">search for some plants</a> and <a href="https://permapeople.org/users/sign_up">sign up</a> to create your first list or guild.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

<p>PS: If you work for PFAF (or know someone who does), please reach out to us at hello at permapeople org - we’d love to talk about the future!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198771</guid>
            <pubDate>Tue, 24 Nov 2020 14:38:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A heat map and a new styling for Indoor= (Openstreetmap indoor mapping)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198621">thread link</a>) | @liotier
<br/>
November 24, 2020 | https://2metz.fr/blog/indoorequal-style-heatmap/ | <a href="https://web.archive.org/web/*/https://2metz.fr/blog/indoorequal-style-heatmap/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article lang="en">
  
  <p><time datetime="2020-11-24 00:00:00 +0000">24 November 2020</time> - François</p>

  <p><em>For those who are not familiar with <a href="https://indoorequal.org/">indoor=</a>, I recommend consulting the <a href="https://2metz.fr/blog/indoorequal-openstreetmap-indoor-viewer/">introductory post</a>. In short, it’s a map that displays the interior spaces of OpenStreetmap with a level selector.</em></p>

<p>A new version is available with improvements such as the heat map and a new styling.</p>

<h2 id="heat-map">Heat map</h2>

<p>To rapidly visualize locations that are indoor mapped, <a href="https://indoorequal.org/">indoor=</a> can now display a low zoom heat map.</p>

<figure>
<img alt="A heat map to locate indoor mapped locations in OpenStreetMap" src="https://2metz.fr/assets/blog/indoorequal-heatmap-2adfe009e4cc18dda707f9c67f30822aaa9214b5c70c5bfcf4138a891d099a2e.png" integrity="sha256-Kt/gCeTMGN2nB/nGfzCCKqqSFLXHDFv89BOKiR0Jmi4=" crossorigin="anonymous">
<figcaption>A heat map to locate indoor mapped locations in OpenStreetMap</figcaption>
</figure>

<p>It will therefore be much easier to locate indoor mapped locations. Here are a few places that I discovered:</p>

<ul>
  <li><a href="https://indoorequal.org/#map=17.29/41.97637/-87.905125&amp;level=1">Chicago Airport, IL, USA</a></li>
  <li><a href="https://indoorequal.org/#map=17/1.360945/103.990497&amp;level=1">Singapore Airport, Singapor</a></li>
  <li><a href="https://indoorequal.org/#map=17.39/51.499368/-0.12456&amp;level=1">House of Commons, London, UK</a></li>
  <li><a href="https://indoorequal.org/#map=18.77/38.8977124/-77.0365066">The White House, Washington D.C., USA</a></li>
</ul>

<p>This work was carried out by <a href="https://pavie.info/">Adrien Pavie</a>.</p>

<h2 id="new-styling">New styling</h2>

<p>In order to clearly distinguish the different interior spaces, the styling has been largely revised.</p>

<ul>
  <li>Rooms with interest points are in blue</li>
  <li>The other rooms are in yellow</li>
  <li>Traffic areas are in white</li>
  <li>A specific icon set to make the click more explicit has been added</li>
</ul>

<p><img alt="" src="https://2metz.fr/assets/blog/indoorequal-style-15cf917174f4ade9112135a4eba075741fa9f425d2773012ee4f2b99425bbc02.png" integrity="sha256-Fc+RcXT0rekRITWk66B1dB+p9CXSdzAS7k8rmUJbvAI=" crossorigin="anonymous"></p>

<p>In addition to the indispensable vending machines for drinks and other delicacies, you will also be able to see the ping-pong and foosball tables.</p>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-tennis-ffbf484050c0f460f56fbc6b970e06ccff738699c48a81a081d003dcc66eee08.png" integrity="sha256-/79IQFDA9GD1b7xrlw4GzP9zhpnEioGggdAD3MZu7gg=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.38/48.8520471/2.2868159&amp;level=1&amp;poi=node:2741751144">A ping-pong table at the École Centrale d'Électronique, Paris, France</a></figcaption>
</figure>

<figure>
<img alt="" src="https://2metz.fr/assets/blog/indoorequal-table-soccer-3b34b8ab0cda0ff16fc9d67d2656656f7bc4a8e053bf50a1988002ef4caa6d5e.png" integrity="sha256-OzS4qwzaD/FvydZ9JlZlb3vEqOBTv1ChmIAC70yqbV4=" crossorigin="anonymous">
<figcaption><a href="https://indoorequal.org/#map=20.03/48.9024495/2.4005376&amp;level=0">A foosball table in Arkose, Pantin, France</a></figcaption>
</figure>

<p>This work was carried out by <a href="https://www.jawg.io/">Jawg</a>.</p>

<h2 id="other-improvements">Other improvements</h2>

<ul>
  <li>Multiple interest points have been added</li>
  <li>The display of the interior doors has been corrected</li>
</ul>

<h2 id="integrate-indoor-in-your-map">Integrate indoor= in your map</h2>

<p>Do you want to add interior spaces to your map? Use the <a href="https://github.com/indoorequal/mapbox-gl-indoorequal">mapbox-gl-indoorequal</a> library and create your free API key on <a href="https://indoorequal.com/">indoorequal.com</a>.</p>

<p>If you are not using mapbox-gl, the schema has been updated so you can make your own integration: <a href="https://indoorequal.com/schema">indoorequal.com/schema</a>.</p>

<hr>

<p>Thanks to everyone who contributed to this version.</p>

<p>To have a look at all of this, you can go on <a href="https://indoorequal.org/">indoor=</a>.</p>

<p>And to learn more about mapping indoor spaces, please visit the <a href="https://wiki.openstreetmap.org/wiki/Simple_Indoor_Tagging">wiki page Simple Indoor Tagging</a>.</p>


</article>

    </div></div>]]>
            </description>
            <link>https://2metz.fr/blog/indoorequal-style-heatmap/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198621</guid>
            <pubDate>Tue, 24 Nov 2020 14:19:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25198597">thread link</a>) | @mooreds
<br/>
November 24, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198597</guid>
            <pubDate>Tue, 24 Nov 2020 14:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Lisp Iteration]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198573">thread link</a>) | @wooby
<br/>
November 24, 2020 | https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html | <a href="https://web.archive.org/web/*/https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>
Created Monday 23 November 2020
</p>

<p>
Each of the following definitions of a <a href="https://en.wikipedia.org/wiki/Factorial" title="factorial">factorial</a> function demonstrate a way to <a href="https://en.wikipedia.org/wiki/Iteration#Computing" title="iterate">iterate</a> in <a href="https://en.wikipedia.org/wiki/Common_Lisp" title="Common Lisp">Common Lisp</a>, with brief notes. I hope that by demonstrating many different ways that the same thing can be written, you can develop a sense for the character of the constructs afforded by the language, and of the variety of possible styles. Common Lisp is famously syntactically extensible via <a href="https://en.wikipedia.org/wiki/Common_Lisp#Macros" title="macros">macros</a>, so keep in mind that my examples are by no means the <i>only</i> ways to iterate.
</p>

<p>
For further reading on the iteration and control structures of Common Lisp, I heartily recommend:
</p>

<ul>
<li><a href="http://www.gigamonkeys.com/book/macros-standard-control-constructs.html" title="Chapter 7">Chapter 7</a> and <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> by Peter Siebel.</li>
<li>A reasonably-priced used copy of <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a> by Paul Graham.</li>
</ul>


<p>
<i>Note: several of the examples return nonsensical results for negative inputs. The addition of <tt>(assert (not (minusp n)) </tt>or similar is a good idea, but I have omitted it here for clarity.</i>
</p>

<h2>DOTIMES</h2>

<pre>(defun factorial-dotimes (n &amp;aux (prod 1))
  (dotimes (i n prod)
    (setq prod (* prod (1+ i)))))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names a local variable <tt>prod</tt>. <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_let_l.htm" title="LET"><tt>LET</tt></a> could also be used for this purpose, but at the cost of more indentation.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_dotime.htm" title="DOTIMES"><tt>DOTIMES</tt></a> binds <tt>i</tt> successively from 0 to 1-n and finally evaluates to <tt>prod</tt>.</li>
</ul>


<h2>DO</h2>

<pre>(defun factorial-do (n)
  (do ((i 1 (1+ i))
       (prod 1 (* prod i)))
      ((&gt; i n) prod)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_do_do.htm" title="DO"><tt>DO</tt></a> binds <tt>i</tt> to 1 and then to (1+ i) in subsequent iterations. <tt>prod</tt> is bound first to 1 and then to <tt>(* prod i)</tt> in subsequent iterations.</li>
<li>When the test clause <tt>(&gt; i n)</tt> becomes true, <tt>prod</tt> is returned. Contrast with the test clause of <tt>for</tt> loops in other languages, which terminate the loop when they become <i>false</i>.</li>
<li>I like the way Paul Graham explains <tt>DO </tt>and<tt> DO*</tt> in <a href="https://amzn.to/2UUTfm3" title="ANSI Common Lisp">ANSI Common Lisp</a>.</li>
</ul>


<h2>LOOP</h2>

<pre>(defun factorial-loop (n)
  (loop
     for i from 1 to n
     for prod = 1 then (* prod i)
     finally (return prod)))
</pre>

<ul>
<li><tt>i</tt> is bound from 1 to <tt>n</tt> inclusive.</li>
<li><tt>prod</tt> is bound to 1 and then <tt>(* prod i)</tt> in subsequent iterations in a manner similar to <tt>DO</tt>.</li>
<li>In the <tt>finally</tt> clause, <tt>prod</tt> is returned by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_return.htm#return" title="RETURN"><tt>RETURN</tt></a> once iteration is complete. The <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named NIL established by <tt>LOOP</tt> is the point of return.</li>
<li><a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/m_loop.htm" title="LOOP"><tt>LOOP</tt></a> supports a comprehensive iteration and accumulation <a href="https://en.wikipedia.org/wiki/Domain-specific_language" title="DSL">DSL</a>. <a href="http://www.gigamonkeys.com/book/loop-for-black-belts.html" title="Chapter 22">Chapter 22</a> of <a href="https://amzn.to/3nOWKa2" title="Practical Common Lisp">Practical Common Lisp</a> offers a great introduction.</li>
</ul>


<h2>Recursion</h2>

<pre>(defun factorial-recursive (n)
  (if (zerop n)
      1
      (* n (factorial-recursive (1- n)))))
</pre>

<ul>
<li><tt>FACTORIAL-RECURSIVE</tt> calls itself, but when <tt>n</tt> exceeds the maximum stack size supported by the implementation, an error is signaled.</li>
</ul>


<pre>(defun factorial-tail-recursive (n)
  (labels ((recur (n prod)
             (if (zerop n)
                 prod
                 (recur (1- n) (* n prod)))))
    (recur n 1)))
</pre>

<ul>
<li><tt>FACTORIAL-TAIL-RECURSIVE </tt>does not call itself directly.</li>
<li>Instead, it defines with <a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_flet_.htm" title="LABELS"><tt>LABELS</tt></a> an internal and recursive helper function, <tt>recur</tt>.</li>
<li>recur <a href="https://en.wikipedia.org/wiki/Tail_call" title="calls itself in tail position">calls itself in tail position</a> and the stack never overflows in implementations that implement tail-call elimination.</li>
</ul>


<h2>TAGBODY</h2>

<pre>(defun factorial-tagbody (n &amp;aux (i 0) (prod 1))
  (tagbody
     begin
     (when (eql i n)
       (return-from factorial-tagbody prod))
     (setq prod (* prod (incf i)))
     (go begin)))
</pre>

<ul>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_tagbod.htm" title="TAGBODY"><tt>TAGBODY</tt></a> is the most general but also the lowest-level and most verbose iteration construct.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/03_dae.htm" title="&amp;aux lambda list keyword"><tt>&amp;aux</tt> lambda list keyword</a> names local variables <tt>i</tt> and <tt>prod</tt>, initializing them to 0 and 1, respectively.</li>
<li><tt>begin</tt> names a label within the <tt>TAGBODY</tt> that may be jumped to.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/m_when_.htm" title="WHEN"><tt>WHEN</tt></a> <tt>i</tt> is <a href="http://www.lispworks.com/documentation/HyperSpec/Body/f_eql.htm" title="EQL"><tt>EQL</tt></a> to <tt>n</tt>, <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_ret_fr.htm" title="RETURN-FROM"><tt>RETURN-FROM</tt></a> returns <tt>prod</tt> from the <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/s_block.htm#block" title="BLOCK"><tt>BLOCK</tt></a> named after the function by <a href="http://www.lispworks.com/documentation/lw60/CLHS/Body/m_defun.htm" title="DEFUN"><tt>DEFUN</tt></a>.</li>
<li><a href="http://www.lispworks.com/documentation/HyperSpec/Body/s_go.htm" title="GO"><tt>GO</tt></a> jumps to <tt>begin</tt>.</li>
</ul>


</div></div>]]>
            </description>
            <link>https://tailrecursion.com/~alan/Lisp/CommonLispIteration.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198573</guid>
            <pubDate>Tue, 24 Nov 2020 14:14:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digitizing Old 8mm Tapes]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198435">thread link</a>) | @todsacerdoti
<br/>
November 24, 2020 | https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ | <a href="https://web.archive.org/web/*/https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-660">
	<!-- .entry-header -->

	<div>
		
		<p>It’s astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing software—<a href="https://www.blackmagicdesign.com/products/davinciresolve/" rel="noopener noreferrer" target="_blank">some of which comes at no cost at all</a>—and far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p>
<p>My personal experience with photography began around age 7 shooting on <a href="https://en.wikipedia.org/wiki/110_film" rel="noopener noreferrer" target="_blank">110 film</a> using a small “spy” camera I got as a gift. My dad’s <a href="https://www.sony.com/electronics/support/product/ccd-v5" rel="noopener noreferrer" target="_blank">Sony CCD-V5</a> was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapes—we produced an episodic “radio show” starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed. <a href="https://en.wikipedia.org/wiki/8_mm_video_format#Video8" rel="noopener noreferrer" target="_blank">Video8</a> tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p>
<figure id="attachment_706" aria-describedby="caption-attachment-706"><img data-attachment-id="706" data-permalink="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ccd-v5/" data-orig-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" data-orig-size="528,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ccd-v5" data-image-description="" data-medium-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=300%2C222&amp;ssl=1" data-large-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" loading="lazy" src="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=528%2C390&amp;ssl=1" alt="Sony CCD-V5 camcorder" width="528" height="390" srcset="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?w=528&amp;ssl=1 528w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=300%2C222&amp;ssl=1 300w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=210%2C155&amp;ssl=1 210w" sizes="(max-width: 528px) 100vw, 528px" data-recalc-dims="1"><figcaption id="caption-attachment-706">I remember it being a lot bigger.</figcaption></figure>
<p>I went off to college and spent a <em>lot</em> of time lurking the <a href="https://originaltrilogy.com/" rel="noopener noreferrer" target="_blank">originaltrilogy.com forums</a>. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the <a href="https://starwarsviscomp.wordpress.com/" rel="noopener noreferrer" target="_blank">unreleased “original unaltered” versions</a> of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best “fan preservations” of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p>
<p>I bought my dad a <a href="https://www.sony.com/electronics/support/product/hdr-cx100" rel="noopener noreferrer" target="_blank">Sony HDR-CX100</a> camcorder some years ago to supplement his by that time affinity for digital still cameras—he took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my family’s milestones over the first 25 years of my life continued to sit, undisturbed, in my folks’ cool, dry basement. My dad has recordings on them going as far back as 1988 that I’ve found so far. These recordings are over 30 years old, so the tapes must be at least that age. </p>
<p>8mm video tape <a href="https://fstoppers.com/diy/unlocking-memories-8mm-tapes-324466" rel="noopener noreferrer" target="_blank">does not last forever</a>, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad bought—a <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a>—still has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p>
<hr>
<p>Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant it’s written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dad’s aforementioned <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a> camcorder attached directly to the S-video and stereo audio inputs of a <a href="https://web.archive.org/web/20150128124027/https://www.blackmagicdesign.com/products/intensity/models" rel="noopener noreferrer" target="_blank">Blackmagic Intensity Pro</a> PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p>
<p>Since my Debian box is headless, I’m not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based <a href="https://github.com/lu-zero/bmdtools" rel="noopener noreferrer" target="_blank">bmdtools</a> suite—specifically bmdcapture—to do the raw captures from my Intensity Pro card. I do have to pull down the <a href="https://www.blackmagicdesign.com/developer/product/capture-and-playback" rel="noopener noreferrer" target="_blank">DeckLink SDK</a> in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p>
<p><code>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</code></p>
<p>The options passed to bmdcapture configure the capture as follows:</p>
<ul>
<li><code>-C 0</code>: Use the one Intensity Pro card I have installed (ID 0)</li>
<li><code>-m 0</code>: Capture using mode 0; that is, 525i59.94 NTSC, or 720×486 pixels at 29.97 FPS</li>
<li><code>-M 4</code>: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</li>
<li><code>-A 1</code>: Use the “Analog (RCA or XLR)” audio input. In my case, stereo RCA.</li>
<li><code>-V 6</code>: Use the “S-Video” video input. The S-video input on the Intensity Pro is provided as <a href="https://web.archive.org/web/20150122212738im_/https://images.blackmagicdesign.com/media/products/intensity/models/connections-intensitypro.png" rel="noopener noreferrer" target="_blank">an RCA pair</a> for chroma (“B-Y In”) and luma/sync (“Y In”); <a href="https://www.amazon.com/dp/B07K768YD1/" rel="noopener noreferrer" target="_blank">an adapter cable</a> is necessary to convert to the standard miniDIN-4 connector.</li>
<li><code>-d 0</code>: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in <a href="https://en.wikipedia.org/wiki/Time_base_correction" rel="noopener noreferrer" target="_blank">TBC</a> (which I leave enabled since I don’t own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</li>
<li><code>-n 230000</code>: Capture 230000 frames. At 29.97 FPS, that’s almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</li>
<li><code>-f &lt;output&gt;.nut</code>: Write to <code>&lt;output&gt;.nut</code> in the <a href="https://wiki.multimedia.cx/index.php/NUT" rel="noopener noreferrer" target="_blank">NUT container format</a> by default, substituting the tape’s label for <code>&lt;output&gt;</code>. The <a href="https://github.com/lu-zero/bmdtools/blob/master/README.md" rel="noopener noreferrer" target="_blank">README.md provided with bmdtools</a> suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and I’ve had no trouble capturing to that format, I leave the output file format alone.</li>
</ul>
<p>Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive <a href="https://en.wikipedia.org/wiki/Parchive" rel="noopener noreferrer" target="_blank">using the par2 utility</a>, and put my compressed capture and parity files somewhere safe for long-term archival storage. 🙂</p>
<p>My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I can’t capture there, but that’s fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p>
<p><code>$ ffmpeg.exe -i &lt;output&gt;.nut -vcodec copy -acodec copy &lt;output&gt;.avi</code></p>
<p>The options passed to FFmpeg are order-dependent and direct it to do the following:</p>
<ul>
<li><code>-i &lt;output&gt;.nut</code>: Use <code>&lt;output&gt;.nut</code> as the input file. FFmpeg is smart and will auto-detect its file format when opened.</li>
<li><code>-vcodec copy</code>: Copy the video stream from the input file’s container to the output file’s container; do not re-encode.</li>
<li><code>-acodec copy</code>: Likewise for the audio stream, copy from the input file’s container to the output file; do not re-encode.</li>
<li><code>&lt;output&gt;.avi</code>: Write to <code>&lt;output&gt;.avi</code>, again substituting my tape’s label for <code>&lt;output&gt;</code> in both the input and output filenames.</li>
</ul>
<div id=""><div>
<h2>A note about video containers vs. video formats</h2>
<p>Pop quiz! Given a file with the .mov extension, do you know for sure whether it will play in your media player?</p>
<p>Files ending with .mov, .avi, .mkv, and even the .nut format mentioned above are “container” files. When you save a digital video as a QuickTime .mov file, the .mov file is just a wrapper around your media, which must be encoded using one or more “codecs.” Codecs are small programs that can en<strong>co</strong>de and/or <strong>dec</strong>ode audio or video. These codecs must be specified at the same time as when you save your movie. QuickTime files can wrap among a great many codecs: Motion JPEG, MPEG, H.264, and Cinepak just to name a few. They’re a bit like Zip files, except that instead of files inside you have audio and/or video tracks, and there’s no compression other than what’s already done by the tracks’ codecs. Though Apple provides support in QuickTime for a number of modern codecs, older formats have been dropped over time and so any particular .mov file may or may not play… even using Apple’s own QuickTime software! Asking for a “QuickTime movie” is terribly vague—a QuickTime .mov file may not play properly on a given piece of hardware if support for a containing <em>codec</em> is missing.</p>
<p>AVI, MKV, and MP4 are containers, too—MP4 is in fact based on Apple’s own QuickTime format. But these are still just <em>containers</em>, and a movie file is nothing without some media inside that can be decoded. Put another way, when I buy a book I’m often offered the option of PDF, hardcover, or paperback form. But if the words contained therein are in Klingon, I still won’t be able to read it. When asked to provide a movie in QuickTime or AVI “format,” get the specifics—what codecs should be inside?</p></div></div>
<p>Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDub’s interface is reminiscent of a dual cassette deck ready to “dub” from one container to another. It isn’t as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more “filters,” encoding to one of several output codecs available at …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></em></p>]]>
            </description>
            <link>https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198435</guid>
            <pubDate>Tue, 24 Nov 2020 13:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam and Static Types with Louis Pilfold]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198388">thread link</a>) | @crowdhailer
<br/>
November 24, 2020 | https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main">

		
<div>
	<div>

		
		<div>
			<article id="fl-post-6124" itemscope="" itemtype="https://schema.org/BlogPosting">

	
	<header role="banner">
		
		<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="datePublished" content="2020-11-24"><meta itemprop="dateModified" content="2020-11-24"><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><meta itemprop="name" content="Thinking Elixir"></div>	</header><!-- .fl-post-header -->

	
	
	<div itemprop="text">
		<p>
We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!
</p>

<p>
  Show Notes online – <a href="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold">https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="http://devonestes.com/announcing_muzak" target="_blank" rel="noopener noreferrer">http://devonestes.com/announcing_muzak</a> – Devon Estes’ Muzak mutation testing library</li>
<li><a href="https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html" target="_blank" rel="noopener noreferrer">https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html</a> – AppSignal released 2.0 of their reporting tool</li>
<li><a href="https://github.com/phoenixframework/phoenix_live_view/pull/1223" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix_live_view/pull/1223</a> – Phoenix LiveView file upload fix for components</li>
<li><a href="https://github.com/rrrene/credo" target="_blank" rel="noopener noreferrer">https://github.com/rrrene/credo</a> – Happy 5th birthday Credo!</li>
<li><a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/" target="_blank" rel="noopener noreferrer">https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/</a> – New Elixir case-study looks at the collaborative wiki product Slab</li>
<li><a href="https://github.com/teamon/tesla/releases/tag/v1.4.0" target="_blank" rel="noopener noreferrer">https://github.com/teamon/tesla/releases/tag/v1.4.0</a> – Tesla v1.4.0 released – an Elixir HTTP client</li>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119</a> – ElixirLS version 0.6.2 released.</li>
<li><a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir" target="_blank" rel="noopener noreferrer">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a> – Jose Valim wrote a blog post addressing the idea of people saying “you don’t need Redis when you use Elixir”.</li>
<li><a href="https://baremessages.org/" target="_blank" rel="noopener noreferrer">https://baremessages.org/</a> – A new “binary serialization library” called “bare”. Aims to make Erlang data structures serialize easier in <em>other</em> languages</li>
<li><a href="https://sr.ht/~hauleth/BARE-Erlang/" target="_blank" rel="noopener noreferrer">https://sr.ht/~hauleth/BARE-Erlang/</a></li>
</ul>
<p>Do you know some Elixir news we don’t? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li><a href="https://github.com/gleam-lang/gleam" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam</a></li>
<li><a href="https://gleam.run/" target="_blank" rel="noopener noreferrer">https://gleam.run/</a></li>
<li><a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/" target="_blank" rel="noopener noreferrer">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></li>
<li><a href="https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/" target="_blank" rel="noopener noreferrer">https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/</a></li>
<li><a href="https://github.com/gleam-lang/gleam/graphs/contributors" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam/graphs/contributors</a></li>
<li><a href="https://www.embark-studios.com/" target="_blank" rel="noopener noreferrer">https://www.embark-studios.com/</a></li>
<li><a href="https://racket-lang.org/" target="_blank" rel="noopener noreferrer">https://racket-lang.org/</a></li>
<li><a href="https://akka.io/" target="_blank" rel="noopener noreferrer">https://akka.io/</a></li>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers/</a></li>
<li><a href="https://github.com/lalrpop/lalrpop" target="_blank" rel="noopener noreferrer">https://github.com/lalrpop/lalrpop</a></li>
<li><a href="http://www.elixir.london/2016/louis-pilfold" target="_blank" rel="noopener noreferrer">http://www.elixir.london/2016/louis-pilfold</a></li>
<li><a href="https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0</a></li>
<li><a href="https://gleam.run/community/" target="_blank" rel="noopener noreferrer">https://gleam.run/community/</a> – Join the Gleam Discord server</li>
<li><a href="https://twitter.com/louispilfold" target="_blank" rel="noopener noreferrer">https://twitter.com/louispilfold</a> – on Twitter</li>
<li><a href="https://github.com/lpil/" target="_blank" rel="noopener noreferrer">https://github.com/lpil/</a> – on Github</li>
<li><a href="https://lpil.uk/" target="_blank" rel="noopener noreferrer">https://lpil.uk</a> – Blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show – <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen – <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel – <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward – <a href="https://github.com/cadebward" target="_blank" rel="noopener noreferrer">Github</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="uploadDate" content="2020-11-24T04:15:45-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT48M57S"><meta itemprop="description" content="We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!



Show Notes online - https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3"><meta itemprop="contentSize" content="67.4"><div id="powerpress_player_9920"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6124-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3" title="Download" rel="nofollow" download="023-gleam-louis-pilfold.mp3">Download</a></p>	</div><!-- .fl-post-content -->

	
	<div></div>		
</article>


<!-- .fl-post -->
		</div>

		
	</div>
</div>


	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198388</guid>
            <pubDate>Tue, 24 Nov 2020 13:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198287">thread link</a>) | @crbelaus
<br/>
November 24, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198287</guid>
            <pubDate>Tue, 24 Nov 2020 13:38:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it’s a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it’s free to use!</p><p>We sometimes see it as an intimidating platform, but it’s not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don’t want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas’ feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let’s say you create a tool for developers then I’d post to /r/webdev. You don’t need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don’t be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you’ll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you’re ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I’d go with a small subreddit, and a super targeted one. Let’s say you created a no-code tool for startups, I’ll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It’s a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of “incremental launches” is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc… It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it’s totally repeatable. As long as you can provide value you’ll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I’ll be happy to help → <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EC2 Origin]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198157">thread link</a>) | @ashishsheth
<br/>
November 24, 2020 | http://blog.b3k.us/2009/01/25/ec2-origins.html | <a href="https://web.archive.org/web/*/http://blog.b3k.us/2009/01/25/ec2-origins.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>I was trying to avoid writing this post and had succeeded at that goal for almost 2 years. After some recent exchanges, I see the wisest move is the opposite. so, here goes.</p>
<p>In 2003 I was working at Amazon for the best manager I’ve ever had, Chris Pinkham. Chris had hired me the previous year as a network engineer, quickly promoting me to manager for the (ridiculously awesome) team. Chris was always pushing me to change the infrastructure, especially driving better abstraction and uniformity, essential for efficiently scaling. He wanted an all IP network instead of the mess of VLANs Amazon had at the time, so we designed it, built it, and worked with developers so their applications would work with it. He wanted anycast <span>DNS</span>, so we hacked up some routing software and put it out there (great idea at the time, but in hindsight we probably should’ve taken a different approach). Chris asked for something, we figured out how, and did it.</p>
<p>Sorry for the digression, back to what I was saying about 2003: Chris and I wrote a short paper describing a vision for Amazon infrastructure that was completely standardized, completely automated, and relied extensively on web services for things like storage. We drew on the work of a number of other folks internally who had been thinking and writing (and sometimes even coding) in the storage services space, and we combined it with our own thinking and experience in infrastructure. Near the end of it, we mentioned the possibility of selling virtual servers as a service.</p>
<p>We presented the paper to Bezos (he doesn’t do slides), he liked a lot of it, and we went back to work.</p>
<p>A few months later, in early 2004, I was told Jeff was interested in the virtual server as a service idea and asked for a more detailed write up of it. This I did, also incorporating a couple of requests Jeff had, like the idea of a “universe” of virtuals, which I translated into network-speak as a distributed firewall to isolate groups of servers. This first cut at it looked almost nothing like the production EC2 service, and, in my view, every change made by the team who built EC2 was for the better. As just one example, that first paper called for a system manifest from which a server would be built. This is similar to how much systems automation works, but is actually terrible for the sort of dynamism desired for EC2.</p>
<p>After presenting the “executive brief” paper to Jeff, the realities of turning this hare-brained scheme into a real service meant involving the smartest folks around (i.e., not me). In the Amazon style of “starting from the customer and working backwards”, we produced a “press release” and a <span>FAQ</span> to further detail the how and why of what would become EC2. At this point attention turned from these paper pushing exercises to specifics of getting it built. Most importantly, who would lead the effort?</p>
<p>Everyone seemed to leap at once to the same conclusion: Pinkham. And so it was that Pinkham returned to South Africa, taking a stellar lead developer with him, and they built the EC2 team, then built EC2. That last part seems awfully compressed, doesn’t it? Well, that’s because I had almost no interaction with the EC2 team. They went off and kicked a lot of ass and the rest is history.</p>
<p>The end.</p>
<p>Want more data? Here’s Jeff in a 2008 interview with Om Malik…</p>

<time datetime="2009-01-25">
  —Jan 25, 2009
</time>
</article></div>]]>
            </description>
            <link>http://blog.b3k.us/2009/01/25/ec2-origins.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198157</guid>
            <pubDate>Tue, 24 Nov 2020 13:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197950">thread link</a>) | @kkoncevicius
<br/>
November 24, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a “living document” that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody’s going to ditch the Web and switch to Gemini or Gopher today
(that’ll take, like, a month at the longest). Until that happens, here’s a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts–local or remote–besides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It’s a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most “dark mode”
browser addons. More on this below.</li>
<li>A good score on Mozilla’s <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I’d like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen’s DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn’t evil! It isn’t
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn’t dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user’s system.</p>
<p>A personal example: I set my preferred fonts in my computer’s fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don’t change their fonts…</h3>
<p>The “users don’t know better and need us to make decisions for them” mindset isn’t
without merits; however, in my opinion, it’s overused. Using system fonts doesn’t
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn’t
about making software easier for non-technical users; it’s about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can’t users globally override stylesheets instead?</h3>
<p>It’s not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn’t have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there’s
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn’t
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article’s advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn’t that allow a website to fingerprint with fonts?</h3>
<p>I don’t know much about fingerprinting, except that you can’t do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don’t
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don’t need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user’s system, the user’s canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox’s <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of “dead zones” with
abysmal download speeds, and my home’s Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don’t finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn’t expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn’t this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don’t decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don’t have reason to trust that
linked content doesn’t practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn’t
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can’t users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn’t essential, you shouldn’t include it inline.</li>
<li>Yes, users could disable images. That’s <em>their</em> choice. If your page uses lazy
loading, you’ve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren’t black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here’s
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I’ve found that it’s the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197950</guid>
            <pubDate>Tue, 24 Nov 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Elon of the 70s]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197941">thread link</a>) | @revolucien
<br/>
November 24, 2020 | https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s | <a href="https://web.archive.org/web/*/https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f18775b30d9fd6c1ed21e6a" data-item-id="5f18775b30d9fd6c1ed21e6a">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1595439165510" id="item-5f18775b30d9fd6c1ed21e6a"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1595439201816_6409"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG  (Source:    OTRAG   )" data-load="false" data-image-id="5f18789af192c5616c553b96" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG<em> (Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a><em>)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-1f175e5db5ee82782e37"><div><p>It’s 1977 and you’re standing on a rocky plateau overlooking the dense jungle of Zaire in what is now modern-day Congo. You and a group of maverick engineers work for OTRAG, a West German rocket startup that is sponsored by Zaire’s dictator, Mobutu Sese Seko. After many months of toil in the African bushland, you’re ready to launch the world’s first privately developed rocket booster––a 9-meter (30 ft) tall juggernaut which, from a distance, looks like a bundle of aluminum pencils with a nose cone. The countdown proceeds smoothly. Then finally, there’s liftoff: The rocket leaves the launch pad with a deafening roar and climbs to an altitude of 12 km (7.5 miles) before plummeting back to Earth. The plateau erupts in jubilation.</p><p>Wait, what? This unlikely scene from the jungle might sound crazy to you. A private rocket company from West Germany that is attempting to make it into space in the late seventies? That’s more than three decades before Elon Musk’s <a href="https://en.wikipedia.org/wiki/SpaceX" target="_blank">SpaceX</a> successfully launched its first rocket, the <a href="https://www.youtube.com/watch?v=dLQ2tZEH6G0" target="_blank">Falcon 1</a>, into orbit. But this incredible and long-forgotten tale is entirely true and forms the plot of the documentary<em> </em><a href="https://vimeo.com/300738920" target="_blank"><em>Fly Rocket Fly</em></a><em>, </em>which premiered at the Munich Film Festival in 2018. The film is now available to stream on <a href="https://www.amazon.com/Fly-Rocket-Lutz-Keyser/dp/B082H4WJJG" target="_blank">Amazon Prime</a> and <a href="https://vimeo.com/ondemand/flyrocketfly" target="_blank">Vimeo</a>.</p><p>The rise and fall of OTRAG is one of the strangest, and most remarkable, startup tales I’ve encountered to date. It’s an almost surreal story of entrepreneurial adventure and ambition that bears an astonishing resemblance to Werner Herzog’s<em> </em><a href="https://en.wikipedia.org/wiki/Fitzcarraldo" target="_blank"><em>Fitzcarraldo</em></a><em>. </em>In Herzog’s 1982 movie, Klaus Kinski plays an obsessive dreamer who manually drags his massive steamship over a steep hill in the Amazon jungle. Unfortunately for Fitzcarraldo, this astonishing engineering feat doesn’t translate into his mission’s overall success (Herzog later went so far as to call it a “<a href="https://www.nytimes.com/2009/08/02/books/review/Harris-t.html" target="_blank">conquest of the useless</a>”). The same could be said about OTRAG. Despite a number of successful test launches, OTRAG was a spectacular failure. The company burned through massive amounts of funding and eventually ran afoul of Cold War politics. Its demise is a case study in what happens to startups when their timing is wrong, their technology speculative, and their market unwilling to embrace disruptive innovation.</p><h3><strong>The Emperor of OTRAG</strong></h3><p>All startups are a reflection of their founders. The man behind the rocket-building adventure in the jungle was Lutz Kayser, a German aerospace engineer who was something of a 20th-century Elon Musk. Kayser began pursuing his dream of a low-cost rocket launcher in the 1960s. As a student of rocket pioneer <a href="https://en.wikipedia.org/wiki/Eugen_S%C3%A4nger" target="_blank">Eugen Sänger</a>, he experimented with new propulsion systems using industrially available components and low-cost fuels. The initial work with Sänger carried over into Kayser’s first startup, Technology Research Ltd., which he founded in 1970. The company received several million Deutschmark in research grants and was hired by the West German government to explore a low-cost alternative to the ailing <a href="https://en.wikipedia.org/wiki/Europa_(rocket)" target="_blank">Europa II</a> rocket program.&nbsp;</p><p>It was during this time that Kayser developed his vision for a low-cost, modular rocket system that could transport satellites into orbit<em>.</em> The idea was as simple as it was revolutionary: it involved the parallel clustering of many standard fuel tank and engine modules <em>(Bündelrakete)</em>. The smallest flight-worthy rocket module consisted of four clustered tank units and four identical engines. Bigger, more powerful boosters could be constructed by bundling together larger quantities of these tank-and-engine modules. The largest configuration on paper had as many as 600 individual engines! And there was another idiosyncrasy to the design: instead of being stacked <em>atop</em> one another, the stages would be nested <em>inside</em> one another and shed like layers of an onion as they burned out. This arrangement didn’t make for a particularly handsome vehicle and the rocket’s design was frequently compared to a<em> </em>bundle of asparagus. But aesthetics weren’t the point; “low cost, not high tech” was the North Star.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_13600"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image-dimensions="1988x966" data-image-focal-point="0.5,0.5" alt="Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right).  Source:    OTRAG" data-load="false" data-image-id="5fba982f2b4bfe31fd69b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Lutz Kayser with a prototype of his “cluster rocket” (left), next to a design sketch by Klaus Bürgle (right). <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_15492"><div><p>The key to holding down the rocket’s cost lay in three simple design principles, some of which have been rediscovered by the current crop of “<a href="https://en.wikipedia.org/wiki/Private_spaceflight#NewSpace_terminology" target="_blank">NewSpace</a>” companies. The first principle was rooted in the modular platform architecture itself. Building a whole family of launch vehicles around the same tank-and-engine modules simplified the vehicle configuration and saved millions in development costs. It also meant lots of tanks and engines in production, generating both economies of scale and lower prices. SpaceX applies the same design philosophy today: its main rocket, the <a href="https://en.wikipedia.org/wiki/Falcon_9" target="_blank">Falcon 9</a>, employs nine identical engines (plus another one to power the second stage), while the <a href="https://en.wikipedia.org/wiki/Falcon_Heavy" target="_blank">Falcon Heavy</a> uses 27 units of the same engine. This creates a virtuous cycle whereby the operating model helps drive the business model: being the cheapest launch provider in the market translates into a greater number of launch contracts, which in turn drives higher volumes and scale efficiencies. Once this flywheel is in motion, it becomes easier to run the business as it continues to operate.</p><p>The second design principle was to use mass produced, commercially available components instead of expensive “space grade” equipment from government contractors. The tank units, for example, were made of long pipeline tubes that were manufactured by the German steelmaker Krupp. Amusingly, a Volkswagen windshield-wiper motor was used to open and close the valves that controlled the propellant flow to the engines. Complex and trouble-prone components, like <a href="https://en.wikipedia.org/wiki/Turbopump" target="_blank">turbopumps</a> or <a href="https://en.wikipedia.org/wiki/Gimbaled_thrust" target="_blank">gimbals</a>, were avoided altogether. Instead, the fuel tanks were partially filled with compressed air that forced the propellant into the engines, and the rocket was steered by throttling back individual engines on the side where less thrust was desired. SpaceX would later use components from existing supply chains as well: The Falcon 1 used readily available car wash valves with modified seals to feed propellant into the engine, while the first <a href="https://en.wikipedia.org/wiki/SpaceX_Dragon" target="_blank">Dragon</a> spacecraft utilized a modified bathroom stall latch for securing the cargo lockers.</p><p>The third design principle was a simplified rocket engine that could run on extremely low-cost fuels. The<em> </em>basic job of rocket fuel is to burn steadily and intensely when combined with an oxidizer. Once the fuel and oxidizer are fed through an injector into the combustion chamber, they produce a hot gas that shoots out of the bell-shaped exhaust nozzle at the bottom. This creates the necessary thrust to launch the rocket upwards. The most common rocket propellant in use today is a mix of ultra-refined kerosene (RP-1) and liquid oxygen (LOX). SpaceX, <a href="https://en.wikipedia.org/wiki/Rocket_Lab" target="_blank">Rocket Lab</a>, and many other launch providers work with this fuel mix. Kayser, in contrast, opted for a much cheaper propellant combination: regular diesel oil as fuel and nitric acid as oxidizer. Though providing less thrust per pound than RP-1/LOX and being extremely toxic, this combination cost only 5% as much and was readily available.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_27594"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image-dimensions="1986x962" data-image-focal-point="0.5,0.5" alt="Kayser in the control center at the German Aerospace Center in Lampoldshausen.  Source:    OTRAG" data-load="false" data-image-id="5fba9899317ba5146213cb17" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Kayser in the control center at the German Aerospace Center in Lampoldshausen. <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_29089"><div><p>Much of the early work on this novel rocket concept was done at a test stand rented from the German Aerospace Center in <a href="https://www.dlr.de/content/en/articles/sites/lampholdshausen/about-lampoldhausen.html" target="_blank">Lampoldshausen</a>, north of Stuttgart. Over a period of four years, Kayser’s team went through hundreds of test firings to perfect the diesel oil/nitric acid cocktail. The biggest challenge around getting the engine to work was the “<a href="https://en.wikipedia.org/wiki/Hypergolic_propellant" target="_blank">hypergolic</a>” nature of the fuel mix: diesel oil and nitric acid ignite immediately upon contact and are subject to <a href="https://en.wikipedia.org/wiki/Combustion_instability" target="_blank">unstable burning</a>. Just getting the engine started was difficult: if ignition happened too late, a pool of almost-ready to burn propellant had already accumulated in the combustion chamber, triggering an explosion that would demolish the engine and its immediate surroundings. The group eventually achieved a breakthrough by inventing a radial fuel injection system that provided the right vapor mixture of fuel and oxidizer.</p><p>Then came an unexpected setback. By 1974, the West German government had lost interest in the project and decided to concentrate its rocket research efforts on a new, pan-European launch vehicle, the <a href="https://en.wikipedia.org/wiki/Ariane_1" target="_blank">Ariane 1</a>. Technology Research Ltd.’s fiscal tap<em> </em>was shut off. Kayser was undeterred. He began looking for private funding to bring his rocket to market but it was difficult. Venture capital as we know it today didn’t exist in 1974. Venerable firms like <a href="https://www.kleinerperkins.com/our-history/" target="_blank">Kleiner Perkins</a> and <a href="https://www.sequoiacap.com/article/remembering-don-valentine/" target="_blank">Sequoia</a>, both founded in 1972, were still in their infancy and unavailable to a little-known entrepreneur from West Germany. Kayser’s only option was a highly unorthodox crowdfunding strategy: he decided to raise money from wealthy individuals who wrote off their investment through tax deductions <em>(Abschreibungsgesellschaft). </em>Few investors believed that Kayser’s company would actually succeed, but that …</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</a></em></p>]]>
            </description>
            <link>https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197941</guid>
            <pubDate>Tue, 24 Nov 2020 12:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ask Your Coworkers What They Make. You’ll Earn More]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197935">thread link</a>) | @Fiveplus
<br/>
November 24, 2020 | https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e | <a href="https://web.archive.org/web/*/https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="1842">Lack of wage transparency is a real factor in suppressing American wages.</h2><div><div><div><p><a href="https://medium.com/@Nick_Cassella?source=post_page-----46efb2daf63e--------------------------------" rel="noopener"><img alt="Nick Cassella" src="https://miro.medium.com/fit/c/96/96/0*1ojfl3YBepASbp5C.jpg" width="48" height="48"></a></p></div></div></div><p id="1bb9">I remember the uneasiness of asking for my first raise—only to have my boss tell me the number I had in mind would make me the “highest paid employee.” It was a startling admission. I was asking for $44,000 a year, which seemed reasonable to me. But I didn’t know how my pay compared to the business’ other five employees. So I didn’t call my boss’ bluff. I settled for $42,000.</p><p id="b7d1">You probably don’t know how much your coworkers make either. I get it. It’s an awkward conversation to have. It’s taboo. Plus, do you really want to discover that Stephen makes $20,000 more than you? No. So you don’t ask. You skirt around the issue, only talking about your pay in the privacy of your own home.</p><p id="4ac1">There is a serious price to pay for keeping your salary secret, though: it benefits your boss. Their asymmetric knowledge of who earns what enables them to pay you “<a href="http://www.hamiltonproject.org/people/benjamin_harris" rel="noopener">less than [your] economic value</a>” demands, as my experience illustrates.</p><p id="208c">Now, standard economic theory suggests that this shouldn’t happen. In a competitive labor market, a worker’s pay is determined by the economic value of their labor. If a business underpays its employees, then they should expect to have their workforce leave for better jobs. But one of the features of a competitive market is “<a href="http://www.economicsdiscussion.net/market/features-of-a-perfectly-competitive-market/7108" rel="noopener">perfect knowledge</a>”; that is, both businesses and employees possess the same information.</p><p id="7b27">However, that’s not the case in America today. While websites like Glassdoor supply people with greater awareness of salaries and benefits, these “<a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">data sources all have considerable weaknesses when it comes to gaining a precise understanding of prevailing wages</a>.” To get a leg up over their employees, more than half of employers <a href="http://www.hamiltonproject.org/papers/information_is_power_fostering_labor_market_competition_through_transparent" rel="noopener">conduct their own salary surveys</a>. These employers generally don’t share their findings with the employees. Instead, they say, “Trust us, we offer competitive compensation.”</p><p id="0e4e">Is it any wonder America suffers from decades of stagnant wages?</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2432/1*uVgy2c4ZV8MuzgXQM1xcoQ.png" width="1216" height="1149" srcset="https://miro.medium.com/max/552/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 276w, https://miro.medium.com/max/1104/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 552w, https://miro.medium.com/max/1280/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 640w, https://miro.medium.com/max/1400/1*uVgy2c4ZV8MuzgXQM1xcoQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*uVgy2c4ZV8MuzgXQM1xcoQ.png?q=20"></p></div></div></div></figure><p id="53b6">This feature of the modern workplace is totally avoidable, too. When <a href="https://www.npr.org/sections/money/2015/02/23/385843576/50-years-of-shrinking-union-membership-in-one-map" rel="noopener">unions represented the majority of American workers</a>, there was greater “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">familiarity with the distribution of wages in a given market</a>.” In turn, this put “<a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">workers in a stronger position during negotiations</a>”—which could help explain why wage growth was stronger when more people belonged to a union.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1600/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg" width="800" height="459" srcset="https://miro.medium.com/max/552/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 276w, https://miro.medium.com/max/1104/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 552w, https://miro.medium.com/max/1280/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 640w, https://miro.medium.com/max/1400/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*NZWJ934hjczCSDt0Wx1Qvg.jpeg?q=20"></p></div></div></div></figure><p id="a62f"><a href="https://www.nytimes.com/2018/02/22/us/politics/supreme-court-unions.html" rel="noopener">Unions aren’t coming back</a>, though. So in a post-union economy, how do we empower workers to negotiate for higher wages?</p><p id="939b">Benjamin Harris of Northwestern University has compiled <a href="https://www.brookings.edu/research/information-is-power-fostering-labor-market-competition-through-transparent-wages/" rel="noopener">a report</a> enumerating five remedies to improving wage transparency. Quickly, Harris’ points are:</p><ul><li id="ad8d">Enact state laws to protect workers who discuss pay</li><li id="1dd6">Require large firms to disclose pay trends to the Equal Employment Opportunity Commission</li><li id="ec04">Amend the safe harbor for compensation surveys</li><li id="f822">Change state law to facilitate reciprocal pre-hiring wage disclosure</li><li id="9ce6">Allocate funds for the Department of Labor to study transparency</li></ul><p id="141b">The logic behind these wonky prescriptions is compelling. If businesses are forced to be transparent about wages, they will have a harder time suppressing them. You’d think whether you’re conservative or progressive, that is an outcome worth working towards.</p><p id="05c4">Alas, Republicans have blocked legislation that aims to provide workers with more information on compensation. They have filibustered and condemned the Paycheck Fairness Act—a labor law that, among other provisions, would punish “<a href="http://thehill.com/blogs/floor-action/senate/203064-senate-gop-blocks-paycheck-fairness-bill" rel="noopener">employers for retaliating against workers who share wage information</a>.”</p><p id="7c09">Their arguments against the Act are ridiculous. Ever the critical thinker, Marco Rubio summed up his party’s attitude towards greater wage transparency when he claimed that “<a href="https://thinkprogress.org/marco-rubio-explains-his-opposition-to-equal-pay-law-3c3924506778/" rel="noopener">all [the Paycheck Fairness Act] really did is just help lawyers sue</a>.” Ah, yes. Astute point, Marco.</p><p id="9f61">If history has taught us anything, it is that businesses will not pay people what they are worth until they are forced to. That’s why some employers <a href="https://www.classaction.org/blog/can-i-be-fired-for-discussing-wages-at-work" rel="noopener">retaliate against workers for even <em>discussing</em> wages</a> with each other. So while <a href="https://www.inman.com/2018/03/09/the-week-in-financial-markets-why-arent-wages-growing-faster-in-this-booming-economy/" rel="noopener">everyone</a> <a href="https://www.washingtonpost.com/news/posteverything/wp/2017/10/09/why-arent-wages-growing-more-quickly-a-graphical-analysis/" rel="noopener">keeps</a> <a href="https://www.nationalreview.com/2017/09/growth-stagnant-economists-disagree-reasons-automation-offshoring-demographic-change/" rel="noopener">asking</a> “<a href="http://theweek.com/articles/760002/why-arent-wages-growing-faster" rel="noopener">why aren’t wages growing</a>?,” keep in mind that there is a <em>very simple fix</em> which could improve workers’ bargaining position.</p><p id="1f13">Enforcing greater wage transparency is not a silver bullet. It’s not going to completely erase all wage stagnation. But it is a powerful remedy to a labor market that favors the employer. If Americans want to see bigger paychecks, they should start by figuring out what their coworkers are making.</p><p id="64c2">Think about <em>that</em> the next time you ask for a raise.</p></div></div></div>]]>
            </description>
            <link>https://civicskunk.works/ask-your-coworkers-what-they-make-youll-earn-more-46efb2daf63e</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197935</guid>
            <pubDate>Tue, 24 Nov 2020 12:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything Curl – Trace Options]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197836">thread link</a>) | @kristianpaul
<br/>
November 24, 2020 | https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace | <a href="https://web.archive.org/web/*/https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="a6ef002b560e4352b590a3456afb72f4" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="19ab964dd5104d0e96746d1e9325ab76"><span><span data-key="c47a63eb63b94ec497e15ed367a3313b"><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:0">There are times when </span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="c47a63eb63b94ec497e15ed367a3313b:2"> is not enough. In particular, when you want to store the complete stream including the actual transferred data.</span></span></span></p><p data-key="ebacf752bc4a4890967ec23222938013"><span><span data-key="79f7332dd6bf466aacd76677ded40423"><span data-offset-key="79f7332dd6bf466aacd76677ded40423:0">For situations when curl does encrypted file transfers with protocols such as HTTPS, FTPS or SFTP, other network monitoring tools (like Wireshark or tcpdump) will not be able to do this job as easily for you.</span></span></span></p><p data-key="58ba64ab45d8412da695e15d71709c8a"><span><span data-key="388656d103e64ea080c159503ff14673"><span data-offset-key="388656d103e64ea080c159503ff14673:0">For this, curl offers two other options that you use instead of </span><span data-offset-key="388656d103e64ea080c159503ff14673:1"><code spellcheck="false" data-slate-leaf="true">-v</code></span><span data-offset-key="388656d103e64ea080c159503ff14673:2">.</span></span></span></p><p data-key="da7a8717ac1c470eae69cbe4790ce6ce"><span><span data-key="971b082de53d4f43b1fbd479951ad5dd"><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:0"><code spellcheck="false" data-slate-leaf="true">--trace [filename]</code></span><span data-offset-key="971b082de53d4f43b1fbd479951ad5dd:1"> will save a full trace in the given file name. You can also use '-' (a single minus) instead of a file name to get it passed to stdout. You would use it like this:</span></span></span></p><div><pre data-key="4cbf6e9356b64ff484fb8d13de5929bc" spellcheck="false"><p><span data-key="b9ee5fdba4e84b738b41fa1c7f15fff2"><span data-offset-key="b9ee5fdba4e84b738b41fa1c7f15fff2:0">$ curl --trace dump http://example.com</span></span></p></pre></div><p data-key="405e863d115f431dadbf90deed491cf9"><span><span data-key="005bd2da5cdc4f1485025d85c8f20bf3"><span data-offset-key="005bd2da5cdc4f1485025d85c8f20bf3:0">When completed, there's a 'dump' file that can turn out pretty sizable. In this case, the 15 first lines of the dump file looks like:</span></span></span></p><div><pre data-key="0e0c49cd57b2442fac8b95477d19da3f" spellcheck="false"><p><span data-key="44ae1b41de7f46f991bf292597d73863"><span data-offset-key="44ae1b41de7f46f991bf292597d73863:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="6fed896d67624b529a0fdd3edf7203d2"><span data-offset-key="6fed896d67624b529a0fdd3edf7203d2:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="4404aae5e0284eca86045739a019584a"><span data-offset-key="4404aae5e0284eca86045739a019584a:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="a91c13b6fb19420899f0ba554ad791c0"><span data-offset-key="a91c13b6fb19420899f0ba554ad791c0:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="c6f46dbe7f4f488f92bb4a297ef5052a"><span data-offset-key="c6f46dbe7f4f488f92bb4a297ef5052a:0">0000: 47 45 54 20 2f 20 48 54 54 50 2f 31 2e 31 0d 0a GET / HTTP/1.1..</span></span></p><p><span data-key="3c91a889a2fe43a0a667319325baa522"><span data-offset-key="3c91a889a2fe43a0a667319325baa522:0">0010: 48 6f 73 74 3a 20 65 78 61 6d 70 6c 65 2e 63 6f Host: example.co</span></span></p><p><span data-key="2e97d4ff01da467d85992911f65474a3"><span data-offset-key="2e97d4ff01da467d85992911f65474a3:0">0020: 6d 0d 0a 55 73 65 72 2d 41 67 65 6e 74 3a 20 63 m..User-Agent: c</span></span></p><p><span data-key="5ef52f20d4114d228d1bf5d3c67708a1"><span data-offset-key="5ef52f20d4114d228d1bf5d3c67708a1:0">0030: 75 72 6c 2f 37 2e 34 35 2e 30 0d 0a 41 63 63 65 url/7.45.0..Acce</span></span></p><p><span data-key="3984e066f33645678f4330fce9d9658b"><span data-offset-key="3984e066f33645678f4330fce9d9658b:0">0040: 70 74 3a 20 2a 2f 2a 0d 0a 0d 0a                pt: */*....</span></span></p><p><span data-key="393ecd26a68e4a88998c7e654e2b8fdb"><span data-offset-key="393ecd26a68e4a88998c7e654e2b8fdb:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="8b97f7554ac14ffa92725f4d1ce50791"><span data-offset-key="8b97f7554ac14ffa92725f4d1ce50791:0">0000: 48 54 54 50 2f 31 2e 31 20 32 30 30 20 4f 4b 0d HTTP/1.1 200 OK.</span></span></p><p><span data-key="48514fc4c23648779fcbd53d72ae53df"><span data-offset-key="48514fc4c23648779fcbd53d72ae53df:0">0010: 0a                                              .</span></span></p><p><span data-key="7118cb05b71540edbdd422769bb1d41c"><span data-offset-key="7118cb05b71540edbdd422769bb1d41c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="eedfedbbe314499f904e81cad9e260c6"><span data-offset-key="eedfedbbe314499f904e81cad9e260c6:0">0000: 41 63 63 65 70 74 2d 52 61 6e 67 65 73 3a 20 62 Accept-Ranges: b</span></span></p><p><span data-key="7a13f50dcfd74da5aff6f4598e00f943"><span data-offset-key="7a13f50dcfd74da5aff6f4598e00f943:0">0010: 79 74 65 73 0d 0a                               ytes..</span></span></p></pre></div><p data-key="e1381af0207e449a94931cb2b99773da"><span><span data-key="40a899c38f7b4a98a7387c1526a19730"><span data-offset-key="40a899c38f7b4a98a7387c1526a19730:0">Every single sent and received byte get displayed individually in hexadecimal numbers.</span></span></span></p><p data-key="3be1a1fe222a45b39a27341b6371848c"><span><span data-key="aa4dc13ee63040aab0c0303f6f7e5650"><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:0">If you think the hexadecimals are not helping, you can try </span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:1"><code spellcheck="false" data-slate-leaf="true">--trace-ascii [filename]</code></span><span data-offset-key="aa4dc13ee63040aab0c0303f6f7e5650:2"> instead, also this accepting '-' for stdout and that makes the 15 first lines of tracing look like:</span></span></span></p><div><pre data-key="22868136a84e4e15810fefe740495ec8" spellcheck="false"><p><span data-key="9e299d2991d6426ba442339ee9e9f139"><span data-offset-key="9e299d2991d6426ba442339ee9e9f139:0">== Info: Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="80b9bc8a91c2435bb40fba6cb5dfa9ff"><span data-offset-key="80b9bc8a91c2435bb40fba6cb5dfa9ff:0">== Info:   Trying 93.184.216.34...</span></span></p><p><span data-key="149c766c24ed40f386d75b401156ae33"><span data-offset-key="149c766c24ed40f386d75b401156ae33:0">== Info: Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="2eb4b3433be241cf9d8eb7187f2f7e0b"><span data-offset-key="2eb4b3433be241cf9d8eb7187f2f7e0b:0">=&gt; Send header, 75 bytes (0x4b)</span></span></p><p><span data-key="19e16419fc4a4a18967d864bd04c66c0"><span data-offset-key="19e16419fc4a4a18967d864bd04c66c0:0">0000: GET / HTTP/1.1</span></span></p><p><span data-key="e1bda71508224e9fb07f75c1910e48ab"><span data-offset-key="e1bda71508224e9fb07f75c1910e48ab:0">0010: Host: example.com</span></span></p><p><span data-key="b2b1088640fd4ae5ab0cc1b6ca6483be"><span data-offset-key="b2b1088640fd4ae5ab0cc1b6ca6483be:0">0023: User-Agent: curl/7.45.0</span></span></p><p><span data-key="d6d0ce807724460789e6ebb6f6e892ec"><span data-offset-key="d6d0ce807724460789e6ebb6f6e892ec:0">003c: Accept: */*</span></span></p><p><span data-key="a78aa7be8d554fa6a96f7c9d6ffbfa23"><span data-offset-key="a78aa7be8d554fa6a96f7c9d6ffbfa23:0">0049:</span></span></p><p><span data-key="39c0feb1902f44e1a5510b833f89f811"><span data-offset-key="39c0feb1902f44e1a5510b833f89f811:0">&lt;= Recv header, 17 bytes (0x11)</span></span></p><p><span data-key="872de778b8e54a4ca78408bb59ad8477"><span data-offset-key="872de778b8e54a4ca78408bb59ad8477:0">0000: HTTP/1.1 200 OK</span></span></p><p><span data-key="7219088e0db041a686b8de990b9ce04c"><span data-offset-key="7219088e0db041a686b8de990b9ce04c:0">&lt;= Recv header, 22 bytes (0x16)</span></span></p><p><span data-key="fb7b2cac706844fabd0b49ed2853a9b4"><span data-offset-key="fb7b2cac706844fabd0b49ed2853a9b4:0">0000: Accept-Ranges: bytes</span></span></p><p><span data-key="73d1394550f4418c8c83309c8fe64c6c"><span data-offset-key="73d1394550f4418c8c83309c8fe64c6c:0">&lt;= Recv header, 31 bytes (0x1f)</span></span></p><p><span data-key="f69380f0d894401199a175232fb1082d"><span data-offset-key="f69380f0d894401199a175232fb1082d:0">0000: Cache-Control: max-age=604800</span></span></p></pre></div><p data-key="21a030a4b3934ff086e961b01bacf8c5"><span><span data-key="45a9708d34fa4752b596d88b6c328371"><span data-offset-key="45a9708d34fa4752b596d88b6c328371:0">This options prefixes all verbose/trace outputs with a high resolution timer for when the line is printed. It works with the regular </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:1"><code spellcheck="false" data-slate-leaf="true">-v / --verbose</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:2"> option as well as with </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:3"><code spellcheck="false" data-slate-leaf="true">--trace</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:4"> and </span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:5"><code spellcheck="false" data-slate-leaf="true">--trace-ascii</code></span><span data-offset-key="45a9708d34fa4752b596d88b6c328371:6">.</span></span></span></p><p data-key="7dbd3d9e6be64569ae4ebfea8bdc44bf"><span><span data-key="d1a95ff5f69a4df297db6d12ca769d30"><span data-offset-key="d1a95ff5f69a4df297db6d12ca769d30:0">An example could look like this:</span></span></span></p><div><pre data-key="f3da03e1fe2f4e2dac6c9f1e40521e40" spellcheck="false"><p><span data-key="cacf73c781794099a94f5b902e53b860"><span data-offset-key="cacf73c781794099a94f5b902e53b860:0">$ curl -v --trace-time http://example.com</span></span></p><p><span data-key="1276cd54ea564f18b7a06b52900c17c6"><span data-offset-key="1276cd54ea564f18b7a06b52900c17c6:0">23:38:56.837164 * Rebuilt URL to: http://example.com/</span></span></p><p><span data-key="b13c21a8314e458baeee201b73f970e2"><span data-offset-key="b13c21a8314e458baeee201b73f970e2:0">23:38:56.841456 *   Trying 93.184.216.34...</span></span></p><p><span data-key="5ef410ea4c8a4361bf582f6d3a529375"><span data-offset-key="5ef410ea4c8a4361bf582f6d3a529375:0">23:38:56.935155 * Connected to example.com (93.184.216.34) port 80 (#0)</span></span></p><p><span data-key="0217c735977049c1a784a28bf069dfce"><span data-offset-key="0217c735977049c1a784a28bf069dfce:0">23:38:56.935296 &gt; GET / HTTP/1.1</span></span></p><p><span data-key="3e04d627753b4d09a993df6cffa6957f"><span data-offset-key="3e04d627753b4d09a993df6cffa6957f:0">23:38:56.935296 &gt; Host: example.com</span></span></p><p><span data-key="4bcff79e2b814cce8580b3e7b6bdd83b"><span data-offset-key="4bcff79e2b814cce8580b3e7b6bdd83b:0">23:38:56.935296 &gt; User-Agent: curl/7.45.0</span></span></p><p><span data-key="a36dc28f81b44594bb976f8fcccf8f88"><span data-offset-key="a36dc28f81b44594bb976f8fcccf8f88:0">23:38:56.935296 &gt; Accept: */*</span></span></p><p><span data-key="fe46ebea85294730aa0343db560b267e"><span data-offset-key="fe46ebea85294730aa0343db560b267e:0">23:38:56.935296 &gt;</span></span></p><p><span data-key="84569ebfbf29412baf4978628e7be2ce"><span data-offset-key="84569ebfbf29412baf4978628e7be2ce:0">23:38:57.029570 &lt; HTTP/1.1 200 OK</span></span></p><p><span data-key="4fea7818e129445397f0d80923b92786"><span data-offset-key="4fea7818e129445397f0d80923b92786:0">23:38:57.029699 &lt; Accept-Ranges: bytes</span></span></p><p><span data-key="924e7f8c5f434d6288a907642f83342b"><span data-offset-key="924e7f8c5f434d6288a907642f83342b:0">23:38:57.029803 &lt; Cache-Control: max-age=604800</span></span></p><p><span data-key="c05e4aa2dae740dc955924488c78a2f0"><span data-offset-key="c05e4aa2dae740dc955924488c78a2f0:0">23:38:57.029903 &lt; Content-Type: text/html</span></span></p><p><span data-key="479f1288467c414a92097deb991b5fa5"><span data-offset-key="479f1288467c414a92097deb991b5fa5:0">---- snip ----</span></span></p></pre></div><p data-key="6fa17657da7c4b9fb344c095331193e5"><span><span data-key="4c19bbee96c14e618d2e5b80ae437f5b"><span data-offset-key="4c19bbee96c14e618d2e5b80ae437f5b:0">The lines are all the local time as hours:minutes:seconds and then number of microseconds in that second.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://ec.haxx.se/usingcurl/usingcurl-verbose/usingcurl-trace</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197836</guid>
            <pubDate>Tue, 24 Nov 2020 12:31:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Serverless Cloud Platform for Building Chat Apps with Node.js]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197365">thread link</a>) | @aaronnwabuoku
<br/>
November 24, 2020 | https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/ | <a href="https://web.archive.org/web/*/https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>In <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">this tutorial series</a>
, I'll be showing you how to build a functional and secure chat app using 
the latest React Native libraries, the Expo framework, and Firebase, powered by the ChatKitty platform.</p><div>
          <p>This is the first article of this series. After reading this article, you will be able to:</p>
<ol>
<li><p>Create an Expo React Native application</p>
</li>
<li><p>Create a Firebase project for user authentication</p>
</li>
<li><p>Create a ChatKitty project and connect to ChatKitty to provide real-time chat functionality</p>
</li>
<li><p>Use Firebase Authentication and ChatKitty Chat Functions to securely implement user login</p>
</li>
</ol>
<h2 id="what-is-react-native">What is React Native?</h2>
<p><a href="https://reactnative.dev/">React Native</a> is a great way to develop both web and mobile applications very 
quickly, while sharing a lot of code when targeting multiple platforms. With a mature ecosystem of libraries 
and tooling, using React Native is not only fast but also reliable. Trusted by organizations like Facebook, 
Shopify, and Tesla - React Native is a stable framework for building both iOS and Android apps.</p>
<h2 id="what-is-expo">What is Expo?</h2>
<p>The <a href="https://expo.io/">Expo</a> framework builds on top of React Native to allow developers to build universal 
React applications in minutes. With Expo, you can develop, build, deploy and quickly iterate on iOS, Android and web 
apps from the same JavaScript code. Expo has made creating both web and mobile applications very accessible, 
handling would-be complex workflows like multi-platform deployment and advanced features like push notifications.</p>
<h2 id="what-is-firebase">What is Firebase?</h2>
<p><a href="https://firebase.google.com/">Firebase</a> is a <a href="https://www.cloudflare.com/learning/serverless/glossary/backend-as-a-service-baas/">Backend-as-a-Service</a> 
offering by Google. It provides developers a wide array of tools and services to develop quality apps 
without having to manage servers. Firebase provides key features like authentication, a real-time database, and hosting.</p>
<h2 id="what-are-chatkitty-chat-functions">What are ChatKitty Chat Functions?</h2>
<p>ChatKitty provides <strong>Chat Functions</strong>, <a href="https://www.cloudflare.com/learning/serverless/what-is-serverless/">serverless</a> 
cloud functions that allow you to define custom logic for complex tasks like user authentication, and respond 
to chat events that happen within your application. With ChatKitty Chat Functions, there's no need for you 
to build a backend to develop chat apps. ChatKitty Chat Functions auto-scale for you, and only cost you when they run.
Chat Functions lower the total cost of maintaining your chat app, enabling you to build more logic, faster.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>To develop apps with Expo and React Native, you should be able to write and understand JavaScript or 
TypeScript code. To define ChatKitty Chat Functions, you'll need to be familiar with basic JavaScript.</p>
<p>You'll need a version of <a href="https://nodejs.org/en/download/">Node.js</a> above <code>10.x.x</code> installed on your local machine 
to build this React Native app.</p>
<p>You'll need to install the <a href="https://docs.expo.io/workflow/expo-cli/">Expo CLI tool</a> through npm or npx.</p>
<p>For a complete walk-through on how to set up a development environment for Expo, you can go through 
<a href="https://docs.expo.io/get-started/installation/">the official documentation here</a>.</p>
<p>You can checkout our Expo React Native sample code any time <a href="https://github.com/ChatKitty/chatkitty-example-react-native/">on GitHub</a>.</p>
<h2 id="creating-project-and-installing-libraries">Creating project and installing libraries</h2>
<p>First, initialize a new Expo project with the <strong>blank managed</strong> workflow. To do so, you're going to 
need to open a terminal window and execute:</p>
<pre><code>expo init chatkitty-example-react-native</code></pre>


<p>After creating the initial application. You can enter the app root directory and run the app:</p>
<pre><code># navigate inside the project directory
cd chatkitty-example-react-native

# for android
expo start --android

# for ios
expo start --ios

# for web 
expo start --web</code></pre>


<p>If you run your newly created React Native application using Expo, you should see:</p>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-created-project.png" alt="Screenshot: Created Project">  </p>
<p>Now we have our blank project, we can install the React Native libraries we'll need:</p>
<pre><code># install following libraries for React Native and Firebase
yarn add @react-navigation/native @react-navigation/stack react-native-reanimated react-native-gesture-handler react-native-screens react-native-safe-area-context @react-native-community/masked-view react-native-paper react-native-vector-icons firebase</code></pre>
<h2 id="creating-reusable-form-elements">Creating reusable form elements</h2>
<p>We'll be creating Login and Signup screens soon which share similar logic. To prevent us from violating 
the <a href="https://thevaluable.dev/dry-principle-cost-benefit-example/">DRY principle</a>, let's create some 
reusable form components that we can share across these two screens. We'll also create a loading spinner 
component to provide a good user experience whenever a user waits for a long screen transition.</p>
<p>We'll create reusable <code>FormInput</code>, <code>FormButton</code>, and <code>Loading</code> UI components. At the root of this Expo
React Native app, create a <code>src/</code> directory and inside it create another new <code>components/</code> directory.</p>
<p>Inside the <code>src/components/</code> directory, create a new JavaScript file <code>FormInput.js</code>. In this file, we'll 
define a <a href="https://reactjs.org/docs/react-component.html">React component</a> to provide a text input field 
for our Login and Signup screens to use for the user to enter their credentials.</p>
<p>The <code>FormInput.js</code> file should contain the following code snippet:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { TextInput } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormInput({ labelName, ...rest }) {
  return (
    &lt;TextInput
      label={labelName}
      style={styles.input}
      numberOfLines={1}
      {...rest}
    /&gt;
  );
}

const styles = StyleSheet.create({
  input: {
    marginTop: 10,
    marginBottom: 10,
    width: width / 1.5,
    height: height / 15,
  },
});</code></pre>


<p>Our next reusable component is going to be in another file <code>FormButton.js</code>. We use it to display a button 
for a user to confirm their credentials.</p>
<p>The <code>FormButton.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { StyleSheet, Dimensions } from 'react-native';
import { Button } from 'react-native-paper';

const { width, height } = Dimensions.get('screen');

export default function FormButton({ title, modeValue, ...rest }) {
  return (
    &lt;Button
      mode={modeValue}
      {...rest}
      style={styles.button}
      contentStyle={styles.buttonContainer}
    &gt;
      {title}
    &lt;/Button&gt;
  );
}

const styles = StyleSheet.create({
  button: {
    marginTop: 10,
  },
  buttonContainer: {
    width: width / 2,
    height: height / 15,
  },
});</code></pre>


<p>Finally, create a <code>Loading.js</code> file. We'll use it to display a loading spinner when a user waits for a 
screen transition.</p>
<p>The <code>Loading.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { View, ActivityIndicator, StyleSheet } from 'react-native';

export default function Loading() {
  return (
    &lt;View style={styles.loadingContainer}&gt;
      &lt;ActivityIndicator size="large" color="#5b3a70" /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  loadingContainer: {
    flex: 1,
    alignItems: 'center',
    justifyContent: 'center',
  },
});</code></pre>


<p>Now we have our reusable form components, we can create a Login screen for users to enter our chat app.</p>
<h2 id="creating-a-login-screen">Creating a login screen</h2>
<div><p>The first screen we'll be creating is the login screen. We'll ask an existing user for their email and 
password to authenticate and provide a link to a future sign up form for new users to register with our app.
</p><p>
The login screen should look like this after you're done:</p></div>
<p><img src="https://www.chatkitty.com/images/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/screenshot-login-screen.png" alt="Screenshot: Login screen">  </p>
<p>Inside the <code>src/</code>, create a <code>screens/</code> directory, inside this directory create a <code>LoginScreen.js</code> file.</p>
<p>The <code>LoginScreen.js</code> file should contain:</p>
<pre><code>import React, { useState } from 'react';
import { View, StyleSheet } from 'react-native';
import { Title } from 'react-native-paper';
import FormInput from '../components/FormInput';
import FormButton from '../components/FormButton';

export default function LoginScreen({ navigation }) {
  const [email, setEmail] = useState('');
  const [password, setPassword] = useState('');

  return (
    &lt;View style={styles.container}&gt;
      &lt;Title style={styles.titleText}&gt;Welcome!&lt;/Title&gt;
      &lt;FormInput
        labelName="Email"
        value={email}
        autoCapitalize="none"
        onChangeText={(userEmail) =&gt; setEmail(userEmail)}
      /&gt;
      &lt;FormInput
        labelName="Password"
        value={password}
        secureTextEntry={true}
        onChangeText={(userPassword) =&gt; setPassword(userPassword)}
      /&gt;
      &lt;FormButton
        title="Login"
        modeValue="contained"
        labelStyle={styles.loginButtonLabel}
        onPress={() =&gt; {
          // TODO
        }}
      /&gt;
      &lt;FormButton
        title="Sign up here"
        modeValue="text"
        uppercase={false}
        labelStyle={styles.navButtonText}
        onPress={() =&gt; navigation.navigate('Signup')}
      /&gt;
    &lt;/View&gt;
  );
}

const styles = StyleSheet.create({
  container: {
    backgroundColor: '#f5f5f5',
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
  },
  titleText: {
    fontSize: 24,
    marginBottom: 10,
  },
  loginButtonLabel: {
    fontSize: 22,
  },
  navButtonText: {
    fontSize: 16,
  },
});</code></pre>


<p>Later, you'll hook up this login screen to ChatKitty to log in users into your app. We've also configured 
the <code>navigation</code> prop to navigate the user to the Signup screen you'll soon be creating. For now, 
let's add a stack navigator to direct users to the initial login route.</p>
<p>Create a new directory <code>src/navigation/</code>. This will contain all the routes and components needed to build 
the app's navigation. Inside this directory, create a <code>AuthStack.js</code> file.</p>
<p>The <code>AuthStack.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { createStackNavigator } from '@react-navigation/stack';
import LoginScreen from '../screens/LoginScreen';

const Stack = createStackNavigator();

export default function AuthStack() {
  return (
    &lt;Stack.Navigator initialRouteName="Login" headerMode="none"&gt;
      &lt;Stack.Screen name="Login" component={LoginScreen} /&gt;
    &lt;/Stack.Navigator&gt;
  );
}</code></pre>


<p>Later, you'll be adding another route for the Signup screen to our navigator.</p>
<p>Next, you'll need a navigation container to hold the app's stacks, starting with the auth stack. 
Create a <code>Routes.js</code> file inside the <code>src/navigation/</code> directory.</p>
<p>The <code>Routes.js</code> file should contain:</p>
<pre><code>import React from 'react';
import { NavigationContainer } from '@react-navigation/native';
import AuthStack from './AuthStack';

export default function Routes() {
  return (
    &lt;NavigationContainer&gt;
      &lt;AuthStack /&gt;
    &lt;/NavigationConta…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/">https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</a></em></p>]]>
            </description>
            <link>https://www.chatkitty.com/blog/posts/building-a-chat-app-with-react-native-and-firebase-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197365</guid>
            <pubDate>Tue, 24 Nov 2020 11:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Virtual Experiences for Teams]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197289">thread link</a>) | @joalavedra
<br/>
November 24, 2020 | https://onsite.fun/activities | <a href="https://web.archive.org/web/*/https://onsite.fun/activities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div mb="2"><div><div><p>Connecting teams through personalized and curated virtual activities.</p></div></div><div><div><ul><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96c0c35e980c07219862d7"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAyLnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAzLkpQRyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA0LnBuZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJhcmNoZW9sb2d5X29mX2xlYXZlczAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Archaeology of Leaves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Serbian</span></p><p><span> English</span></p><p><span> Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96e639d43a3b033484d677"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMS5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMi5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMy5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ2aXJ0dWFsX3N0cmVldF9hcnRfYWR2ZW50dXJlMC5qcGciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Lisbon Street Art Adventure</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96eab3d43a3b033484d678"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMi5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMy5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwNC5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJkaXNjb3Zlcl92aXN1YWxfdGhpbmtpbmcwMS5qcGVnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Discover Visual Thinking</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Greek</span></p><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f96f32bd43a3b033484d679"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDQuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJtYWdpY19zaG93MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Magic Show with a Professional Magician</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>French</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970a2ed43a3b033484d67a"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAyLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczA0LmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJjb2NrdGFpbF9tYXN0ZXJjbGFzczAxLmpwZWciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Cocktail Workshop and Masterclass</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Portuguese</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f970dc8d43a3b033484d67b"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDIuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDQuSlBHIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ0aGVfc2VjcmV0c19zY2FuZGFsMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>The Secrets and Scandal of art at the Borghese</h6></p><div><p>From 75€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f989d667c1a08065afb4615"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJlc3BhZHJpbGxhMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Create Your Own Espadrilles Workshop</h6></p><div><p>From 350€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p><p><span>French</span></p></div></div></div><div><div><div><div><p><span>Material included</span></p></div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5f9e8c9d758ef0033ec1c532"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJvbmxpbmVfc2NhcGVfcm9vbTAxLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Online Live Escape Room</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa47a42ccb5fb037cbcc1e6"><div><div><div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAyLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAzLmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA0LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="4" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczA1LmpwZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJsYXRpbl9hbWVyaWNhbl9kYW5jZV9jbGFzczAxLlBORyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unlock your body with some dance moves</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Russian</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fa482163f481803d20dd8f7"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDIuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDMuanBlZyIsImVkaXRzIjp7InJlc2l6ZSI6eyJ3aWR0aCI6MzAwLCJoZWlnaHQiOjM0NSwiZml0IjoiY292ZXIifSwibm9ybWFsaXNlIjp0cnVlfX0=" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJnbm9jY2hpX3BhcnR5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Have a Gnocchi Party with your team</h6></p><div><p>From 125€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Italian</span></p><p><span>Portuguese</span></p><p><span>Spanish</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fad1a07687d9703518bcd6c"><div><div><div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMi5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMy5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJ5b2dhX2Zsb3cwMS5wbmciLCJlZGl0cyI6eyJyZXNpemUiOnsid2lkdGgiOjMwMCwiaGVpZ2h0IjozNDUsImZpdCI6ImNvdmVyIn0sIm5vcm1hbGlzZSI6dHJ1ZX19" width="100%" height="345"></p></div></div></div></div><div><p><h6>Unwind your body with yoga flow </h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fb548072af9a4030c9e0969"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJibHVlX21lbW9yaWVzMDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Drawing Memories With Blue Ink</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>Spanish</span></p><p><span>English</span></p><p><span>Greek</span></p></div></div></div><div><div><div></div></div></div><span></span></a></div></div></div></li><li><div><div><div><a tabindex="0" role="button" aria-disabled="false" href="https://onsite.fun/activities/5fbae89ecd4d220339f54148"><div><div><div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="1" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDIuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="2" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDMuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="3" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDQuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div><div width="0"><p><img alt="0" src="https://dqqexa40r7vzg.cloudfront.net//eyJidWNrZXQiOiJvbnNpdGVmdW4iLCJrZXkiOiJmcmVuY2hfcGFzdHJ5MDEuanBnIiwiZWRpdHMiOnsicmVzaXplIjp7IndpZHRoIjozMDAsImhlaWdodCI6MzQ1LCJmaXQiOiJjb3ZlciJ9LCJub3JtYWxpc2UiOnRydWV9fQ==" width="100%" height="345"></p></div></div></div></div><div><p><h6>Sweet French Pastry</h6></p><div><p>From 100€</p><p> / 5 people</p></div><div><div><p><span>English</span></p><p><span>Spanish</span></p></div></div></div><div><p><span>NEW</span></p></div><div><div><div></div></div></div><span></span></a></div></div></div></li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://onsite.fun/activities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197289</guid>
            <pubDate>Tue, 24 Nov 2020 10:54:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye breakfast: 6 months of Intermittent Fasting]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25197199">thread link</a>) | @beatlevic
<br/>
November 24, 2020 | https://beatletech.com/2020/11/24/goodbye-breakfast | <a href="https://web.archive.org/web/*/https://beatletech.com/2020/11/24/goodbye-breakfast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            
            

            <p>Tuesday, 24 November 2020.</p>

            <p><img src="https://s3-eu-west-1.amazonaws.com/eu-west-1.beatletech.com/images/intermittent-fasting-mogwai-16-8-blue.png" alt="Intermittent Fasting 16/8" width="70%" title="Intermittent Fasting 16/8"></p>

<p><em><strong>DISCLAIMER:</strong> I’m not an MD, so please read this blog post only as an interesting starting point for your own research and always check with your own doctor or dietician if you want to try this at home. You are responsible for your own health.</em></p>

<hr>

<p>For the past 6 months I have been doing <code>intermittent fasting</code> (IF) by eating daily only during an 8 hour window: between noon and 8pm. On top of that I had three water-only fasts where I didn’t eat anything for multiple days (4-5) in a row.</p>

<p>That’s madness you might say! Why would you starve yourself? Breakfast is the most important meal of the day and you are skipping it!</p>

<p>Well, I currently believe that it would be madness NOT to fast, and have both scientific and 6 months of anecdotal evidence to back that up. When I was just a few weeks into intermittent fasting, I was already so positively surprised by the initial results that I wanted to tell everybody about my “discovery”, especially because I believed I could also explain why and how it works after reading into the physiology and research behind it. I decided to first see if I could stick with it for a couple of months and then write about my experiences. So here I am, 6 months later, ready to tell you all about my journey and “why” intermittent fasting is so interesting.</p>

<h3 id="benefits">Benefits</h3>

<p>Before we dive in, what’s in it for you? What kind of benefits are we talking about? There are the following immediate known and lasting benefits that I experienced:</p>
<ul>
  <li>Weight loss</li>
  <li>Higher levels of energy</li>
  <li>Feeling stronger (due to increase in human growth hormone)</li>
  <li>Better focus</li>
  <li>Decrease in hay fever symptoms (to be fair, I could have been lucky with a mild season)</li>
</ul>

<p>And there are (potential) long term benefits (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>, <a href="https://www.healthline.com/nutrition/10-health-benefits-of-intermittent-fasting">3</a>):</p>
<ul>
  <li>Cellular repair (Autopaghy)</li>
  <li>Decreased <a href="https://www.webmd.com/diabetes/insulin-resistance-syndrome">insulin resistance</a></li>
  <li>Decreased incidence of diseases, including cancers, obesity, neurological disorders and cardiovascular disease.</li>
  <li>Increased stress resistance</li>
  <li>Increased longevity and quality of life</li>
</ul>

<p>Fasting sounds like a miracle drug doesn’t it? You don’t even have to pay money for it! That’s also probably why you won’t see any fasting ads on your timeline or tv commercials (e.g., “Stop buying our cornflakes and just skip breakfast now!”). It is essentially free and available for you to try out.</p>

<p>Without further ado, let’s explore intermittent fasting and why it works.</p>

<h3 id="intermittent-fasting">Intermittent Fasting</h3>

<p>People have been actively fasting, i.e., periods of consciously not eating, since ancient times (<a href="https://thefastingmethod.com/fasting-a-history-part-i/">4</a>) and it has, unwillingly, been part of the eating pattern of our ancestors when food wasn’t always around (e.g. hunting on an empty stomach), although strictly speaking you would call it starvation if you don’t know when you will get your next meal. It just shows, that our bodies have been evolutionary adapted to handle feast and famine. It’s being exposed to stress, variability, volatility and randomness (up to a point and not continuously), that makes us stronger (i.e., <a href="https://en.wikipedia.org/wiki/Antifragile">antifragile</a>).</p>

<p>Recently intermittent fasting has become a more popular form of fasting, which can be defined as <strong>an eating pattern in which you cycle between periods of eating and fasting</strong>, where you stretch each fasting period long enough to force your body into switching from burning glucose (sugar) and glycogen (stored sugar) to fat burning. This is what is called <code>metabolic flexibility</code>, where your body makes use of whatever fuel is available. As a bonus, it seems that ketosis (i.e., the metabolic state running on fat for fuel) is the main driver for fat burning in the abdomen region, belly fat!</p>

<p><strong>So how long do you have to NOT eat to switch to fat burning?</strong> Apparently, energy intake restriction for 10 to 14 hours results in depletion of liver glycogen stores (<a href="https://www.nejm.org/doi/full/10.1056/nejmra1905136">1</a>, <a href="https://www.semanticscholar.org/paper/Fuel-metabolism-in-starvation.-Cahill/a8bb8327226d35259e68ecd8edcc17a3a1380f4a">5</a>) after which fat, fatty acids, are freed to form <code>ketones</code> that are used to fuel your body (as opposed to glucose). The more <code>fat adapted</code> you are, the quicker your body will switch to fat burning, something you get more adapted to as a result of prolonged intermittent fasting.</p>

<p>Given the required minimum of 10 to 14 hours of fasting to start producing ketones, you have different patterns for intermittent fasting you could follow:</p>
<ul>
  <li><strong>16/8</strong>: A daily window of 8 hours, often from noon to 8pm (so no breakfast), for eating and 16 hours of fasting (during the night and morning).</li>
  <li><strong>5:2</strong>: 5 days eating, 2 days fasting.</li>
  <li><strong>Alternate day</strong>: Alternate days of eating and fasting</li>
  <li><strong>One Meal a Day (OMAD)</strong>: Sticking to one meal a day, often dinner, and fast the rest of the day.</li>
</ul>

<p>I chose <strong>16/8</strong>, because it fits nicely with having kids that are not on a fasting schedule (nor should they ever be when they are young and still growing), having lunch and dinner together. I also like the consistency of following the same schedule every day, apart from sporadic multi-day periods of water-only fasts (more on that later).</p>

<p><strong>Aren’t you also burning up your muscles during fasting?</strong> Nope. Your body is naturally preserving your muscles by increasing <code>human growth hormone</code> (HGH), which also helps building muscles after the fasting period as HGH levels remain high.</p>

<p><strong>So all the benefits come from fat burning and the increase in human growth hormone?</strong> Actually those account for only part of the benefits. The third and arguable the most interesting process during fasting is called <code>autophagy</code>, which literally translates to “self eating”, an apt description for the cellular repair and rejuvenation that will happen in your body.</p>

<h4 id="autophagy">Autophagy</h4>

<p>Your body continuously needs amino acids, the building blocks for new cells, and when you are not eating you are not taking in new amino acids (proteins). The body already recycles your old and damaged cells to harvest these building blocks, but during fasting has to work harder to get enough of this material. It does this by increasing your immune system in order to “scavenge” in all the nooks and crannies of your body for cells to break down. Cells that otherwise would be “good enough yet mediocre” are now also recycled.</p>

<p>This is the only process known to rejuvenate neural pathways when you are getting older, and you will be safeguarding and protecting yourself against neurological and auto-immune disorders (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3106288/">2</a>).</p>

<p>The importance of autophagy has also been clearly demonstrated by Japanese cell biologist Yoshinori Ohsumi, who won, in 2016, the Nobel Prize in Medicine for his research on this very topic, showing how autophagy helps slow down the aging process (<a href="https://www.nobelprize.org/prizes/medicine/2016/press-release/">6</a>).</p>

<h4 id="key-concepts">Key concepts</h4>

<p>Now that we covered what intermittent fasting is, how it works and benefits you, by going over some of the key concepts: the metabolic switch to fat burning, the increase in human growth hormone and autophagy. I like to move on to sharing my experience of putting intermittent fasting into practice.</p>

<h3 id="my-6-month-journey">My 6 Month Journey</h3>

<p>During the first Coronavirus lockdown in April (in the Netherlands), I spent most of my time homeschooling my three kids and working for <a href="https://rekall.ai/">rekall.ai</a>, while neglecting sporting activities and not eating healthy consistently (e.g., more snacks). So when the kids were allowed to go back to school again in May, I stepped on the scale and found myself nearing 100 kg. This for me, being 1.98m tall (6’6”), meant I was being borderline overweight according to my <a href="https://www.nhlbi.nih.gov/health/educational/lose_wt/BMI/bmicalc.htm">BMI</a> calculation (&gt;25). I have never seen myself weigh more than 100 kg (220 lb) and didn’t want to see that happen, so it was time for action!</p>

<p>I set a weight goal to lose 8 kg in 6 weeks and weigh no more than 90 kg (200 lb) on my birthday (June 26th). In order to get there I wanted to follow a low-carb Paleo diet (<a href="https://www.mayoclinic.org/healthy-lifestyle/nutrition-and-healthy-eating/in-depth/paleo-diet/art-20111182">Caveman diet</a>), which I had followed 10 years prior with great <a href="https://about.me/beatlevic">results</a>. Doing some online research and catching up on Youtube with low-carb and Keto diets, is when I stumbled upon intermittent fasting videos (<a href="https://youtu.be/thZFIPOAGNQ">7</a>, <a href="https://youtu.be/thgVz3837l0">8</a>, <a href="https://youtu.be/LLVf3d0rqqY">9</a>). As you know by reading this far, the benefits of IF sounded amazing, so I decided, under the medical supervision of my wife, who is an actual MD, to go all in.</p>

<h4 id="weight-loss-results">Weight loss results</h4>

<p>In the following annotated graph you can view my weight over the course of the past 6 months. I’ll provide you with more context in the next sections.</p>







<h4 id="first-2-weeks">First 2 weeks</h4>

<p>I started May 13th weighing <strong>97.9 kg</strong> (A). To keep track of my eating window I set two alarms, one at 12.30pm labeled ‘lunch’ and the other at 8pm ‘no more eating’. For my exercise routine I started to play tennis on Monday mornings, and I tried to run 6-7 km twice a week.</p>

<p>I switched to a low-carb diet (Paleo): eating more meat, salads, fruits (primarily berries), vegetables and nuts. No longer eating bread, pasta, rice and oatmeal.</p>

<p>After one week I already lost 2 kg, and another 1 kg after the second week. I found it very easy to stick to the 8 hour eating window and I was not experiencing hunger sensations in the morning or late evenings. Probably because I was already used to skipping breakfast quite often, and because a low-carb diet also helps lowering your insulin spikes and cravings for more sugar. With lower insulin levels, as a result of lower overall blood sugar, you are also quicker in switching to fat burning!</p>

<h4 id="water-only-fasting">Water-only Fasting</h4>

<p>With this great start, I was feeling bullish about the changes and progression I had made, but I wanted to push fasting a bit harder. So I decided to try water-only fasting, i.e., eating nothing for a couple of days and only consuming water and some minerals (salt for electrolytes). In theory, your body should just switch to fat burning after 12 hours, increase your level of human growth hormone and increase your adrenaline and metabolism.</p>

<p><strong>So what about water-only fasting in practise?</strong> If you would have asked me a year ago, I would have guessed you would continuously feel very hungry and tired. Now I can tell you from experience that it is nothing like that, and that I continued to have plenty of energy throughout the 5 days that I fasted (B-C). Yes, you will feel a bit hungry around the times you would normally eat, but that feeling passes quickly. I believe being on IF together …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beatletech.com/2020/11/24/goodbye-breakfast">https://beatletech.com/2020/11/24/goodbye-breakfast</a></em></p>]]>
            </description>
            <link>https://beatletech.com/2020/11/24/goodbye-breakfast</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197199</guid>
            <pubDate>Tue, 24 Nov 2020 10:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn’t
include any sort of CSRF token and didn’t seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a “poor man’s CSRF token”, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski’s <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let’s examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let’s explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker’s site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn’t supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren’t there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn’t get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you’ll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Web Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197053">thread link</a>) | @virde
<br/>
November 24, 2020 | https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The purpose of the <a href="https://curl.se/">curl web site</a> is to inform the world about what curl and libcurl are and provide as much information as possible about the project, the products and everything related to that.</p>



<p>The web site has existed in some form for as long as the project has, but it has of course developed and changed over time.</p>



<h2>Independent</h2>



<p>The curl project is completely independent and stands free from influence from any parent or umbrella organization or company. It is not even a legal entity,  just a bunch of random people  cooperating over the Internet. And a bunch of <a href="https://curl.se/sponsors.html">awesome sponsors</a> to help us.</p>



<p>This means that we have no one that provides the infrastructure or marketing for us. We need to provide, run and care for our own servers and anything else we think we should offer our users.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="187" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 187px) 100vw, 187px"></a></figure></div>



<p>I still do a lot of the work in curl and the curl web site and I work full time on curl, for <a href="https://www.wolfssl.com/">wolfSSL</a>. This might of course “taint” my opinions and views on matters, but doesn’t imply ownership or control. I’m sure we’re all colored by where we work and where we are in our lives right now.</p>



<h2>Contents</h2>



<p>Most of the web site is static content: generated HTML pages. They are served super-fast and very lightweight by any web server software.</p>



<p>The web site source exists in the <a href="https://github.com/curl/curl-www/">curl-www</a> repository (hosted on GitHub) and the web site syncs itself with the latest repository changes several times per hour. The parts of the site that aren’t static are mostly consisting of smaller scripts that run either on demand at the time of a request or on an interval in a cronjob in the background. That is part of the reason why pushing an update to the web site’s repository can take a little while until it shows up on the live site.</p>



<p>There’s a deliberate effort at not duplicating information so a lot of the web pages you can find on the web site are files that are converted and “HTMLified” from the source code git repository.</p>



<h2>“Design”</h2>



<p>Some people say the curl web site is “retro”, others that it is plain ugly. My main focus with the site is to provide and offer all the info, and have it be accurate and accessible. The look and the design of the web site is a constant battle, as nobody who’s involved in editing or polishing the web site is really interested in or particularly good at design, looks or UX. I personally have done most of the editing of it, including CSS etc and I can tell you that I’m not good at it and I don’t enjoy it. I do it because I feel I have to.</p>



<p>I get occasional offers to “redesign” the web site, but the general problem is that those offers almost always involve rebuilding the entire thing using some current web framework, not just fixing the looks, layout or hierarchy. By replacing everything like that we’d get a lot of problems to get the existing information in there – and again, the information is more important than the looks.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png" alt="" width="379" height="145" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-200x76.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-450x172.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-768x294.png 768w" sizes="(max-width: 379px) 100vw, 379px"></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2016/05/27/a-new-curl-logo/" data-type="post" data-id="8817">curl logo</a> is designed by a proper designer however (Adrian Burcea).</p>



<p>If you want to help out designing and improving the web site, you’d be most welcome!</p>



<h2>Who</h2>



<p>I’ve already touched on it: the web site is mostly available in git so “anyone” can submit issues and pull-requests to improve it, and we are around twenty persons who have push rights that can then make a change on the live site. In reality of course we are not that many who work on the site any ordinary month, or even year.  During the last twelve month period, 10 persons authored commits in the web repository and I did 90% of those.</p>



<h2>How</h2>



<p>Technically, we build the site with traditional makefiles and we generate the web contents mostly by preprocessing files using a C-like preprocessor called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a>. This is an old and rather crude setup that we’ve used for over twenty years but it’s functional and it allows us to have a mostly static web site that is also fairly easy to build locally so that we can work out and check improvements before we push them to the git repository and then out to the world.</p>



<p>The web site is of course only available over HTTPS.</p>



<h2>Hosting</h2>



<div><figure><a href="https://www.haxx.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png" alt="" width="288" height="97" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png 1046w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-200x68.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-450x152.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-768x260.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-1038x354.png 1038w" sizes="(max-width: 288px) 100vw, 288px"></a></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2020/10/23/a-server-transition/" data-type="post" data-id="14836">curl web site is hosted</a> on an origin VPS server in Sweden. The machine is maintained by primarily by me and is paid for by <a href="https://www.haxx.se/">Haxx</a>. The exact hosting is not terribly important because users don’t really interact with our server directly… (Also, as they’re not sponsors we’re just ordinary customers so I won’t mention their name here.)</p>



<h2>CDN</h2>



<p>A few years ago we experienced repeated server outages simply because our own infrastructure did not handle the load very well, and in particular not the traffic spikes that could occur when I would post a blog post that would suddenly reach a wide audience.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="242" height="127" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 242px) 100vw, 242px"></figure></div>



<p>Enter <a href="https://www.fastly.com/">Fastly</a>. Now, when you go to <a href="https://curl.se/">curl.se</a> (or <a href="https://daniel.haxx.se/">daniel.haxx.se</a>) you don’t actually reach the origin server we admin, you will instead  reach one of Fastly’s servers that are distributed across the world. They then fetch the web contents from our origin, cache it on their edge servers and send it to you when you browse the site. This way, your client speaks to a server that is likely (much) closer to you than the origin server is and you’ll get the content faster and experience a “snappier” web site. And our server only gets a tiny fraction of the load.</p>



<p>Technically, this is achieved by the name <strong>curl.se</strong> resolving to a number of IP addresses that are <a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a>. Right now, that’s 4 IPv4 addresses and 4 IPv6 addresses.</p>



<p>The fact that the CDN servers cache content “a while” is another explanation to why updated contents take a little while to “take effect” for all visitors.</p>



<h2>DNS</h2>



<p>When we just recently switched the site over to <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se</a>, we also adjusted how we handle DNS.</p>



<div><figure><a href="https://www.kirei.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/kirei.png" alt="" width="265" height="117"></a></figure></div>



<p>I run our own main DNS server where I control and admin the zone and the contents of it.  We then have four secondary servers to help us really up our reliability. Out of those four secondaries, three are sponsored by <a href="https://www.kirei.se/">Kirei</a> and are anycasted. They should be both fast and reliable for most of the world.</p>



<p>With the help of fabulous friends like Fastly and Kirei, we hope that the curl web site and services shall remain stable and available.</p>



<p>DNS enthusiasts have remarked that we don’t do DNSSEC or registry-lock on the curl.se domain. I think we have reason to consider and possibly remedy that going forward.</p>



<h2>Traffic</h2>



<p>The curl web site is just the home of our little open source project. Most users out there in the world who run and use curl or libcurl will not download it from us. Most curl users get their software installation from their Linux distribution or operating system provider. The git repository and all issues and pull-requests are done on GitHub.</p>



<p>Relevant here is that we have no logging and we run no ads or any analytics. We do this for maximum user privacy and partly because of laziness, since handling logging from the CDN system is work. Therefore, I only have aggregated statistics.</p>



<p>In this autumn of 2020, over a normal 30 day period, the web site serves almost 11 TB of data to 360 million HTTP requests. The traffic volume is up from 3.5 TB the same time last year. 11 terabytes per 30 days equals about 4 megabytes per second on average.</p>



<p>Without logs we cannot know what people are downloading – but we can guess! We know that the <a href="https://curl.haxx.se/docs/caextract.html">CA cert bundle</a> is popular and we also know that in today’s world of containers and CI systems, a lot of things out there will download the same packages repeatedly. Otherwise the web site is mostly consisting of text and very small images.</p>



<p>One interesting specific pattern on the server load that’s been going on for months: every morning at 05:30 UTC, the site gets over 50,000 requests within that single minute, during which 10 gigabytes of data is downloaded. The clients are distributed world wide as I see the same pattern on access points all over. The minute before and the minute after, the average traffic rate remains at 200MB/minute. It makes for a fun graph:</p>



<figure><img loading="lazy" width="1525" height="471" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-24-Fastly-Stats-curl.png" alt=""><figcaption>An eight hour zoomed in window of bytes transferred from the web site. UTC times.</figcaption></figure>



<p>Our servers suffer somewhat from being the target of weird clients like <a href="https://daniel.haxx.se/blog/2020/04/09/a-qqgamehall-storm/" data-type="post" data-id="13880">qqgamehall</a> that continuously “hammer” the site with requests at a high frequency many months after we started always returning error to them. An effect they have is that they make the admin dashboard to constantly show a very high error rate.</p>



<h2>Software</h2>



<p>The origin server runs Debian Linux and Apache httpd. It has a reverse proxy based on nginx. The DNS server is bind. The entire web site is built with free and open source. Primarily: fcpp, make, roffit, perl, curl, hypermail and enscript.</p>



<p>If you curl the curl site, you can see in response headers that <a href="https://www.fastly.com/blog/benefits-using-varnish">Fastly uses Varnish</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197053</guid>
            <pubDate>Tue, 24 Nov 2020 10:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>“Don’t make me think” is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today’s article, we’d like to look into enterprise design and its peculiarities. It’s essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug’s principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren’t inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn’t necessarily true of enterprise products.</p><p>Enterprise users are power users — and it’s imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn’t inherently wrong. It allows users to work more efficiently once they’ve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software — most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they’ll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We’re very well aware of the importance of keeping interfaces simple and obvious. However, it’s essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let’s envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren’t really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but…</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it’s not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be… well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product — it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They’ve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don’t fix it if it’s not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn’t quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, “reinventing the wheel” isn’t always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let’s go back to Excel once more — imagine <a href="https://adamfard.com/blog/website-redesign">you’re trying to reinvent</a> a complex, spreadsheet-based product. You’re looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is — why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we’ve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of “don’t make me think” will most likely outlive us, it’s crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the “Don’t make me think” principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Any hope of keeping Earth habitable requires sucking CO2 out of the atmosphere]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197019">thread link</a>) | @jeremylevy
<br/>
November 24, 2020 | https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11 | <a href="https://web.archive.org/web/*/https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
                                <h2>Even if greenhouse-gas emissions stop now, global warming will continue for centuries, a study shows. The solution: removing carbon from the air.</h2>
                            </p><div>
                                <ul><li>Even if the world were to stop emitting greenhouse gases right now, the Earth would keep warming for centuries, a new study shows.</li>
<li>The researchers suggest <a href="https://www.businessinsider.com.au/how-to-stop-gobal-warming-plan-carbon-capture-2018-10">sucking carbon dioxide out of the atmosphere</a> and storing it underground — a solution known as carbon capture and storage.</li>
<li>That's considered a type of <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">geoengineering</a>. Other <a href="https://www.businessinsider.com/geoengineering-how-to-reverse-climate-change-2019-4">climate-hacking</a> proposals in the same category are far riskier.</li>
<li><a href="https://www.businessinsider.com/?hprecirc-bullet">Visit Business Insider's homepage for more stories</a>.</li></ul><p>Even if we stopped emitting greenhouse gas today, the Earth would continue warming for centuries. Arctic ice and permafrost are already on an irreversible path of melting.</p><p><a href="https://www.nature.com/articles/s41598-020-75481-z">That's the finding of new research</a> published Thursday in the journal Scientific Reports. The model suggests that even if emissions were to drop to zero this year, global temperatures would ultimately rise to be 5.4 degrees Fahrenheit higher in 2500 than they were in 1850 (that's 3 degrees Celsius).</p><p>"The tundra will continue to melt over the next 500 years — irrespective of how quickly humanity cuts its greenhouse-gas emissions," Jørgen Randers, the lead author of the new study, told Business Insider.</p><p>That's because climate change is a vicious, self-sustaining cycle: As permafrost thaws, it releases more greenhouse gases, like methane and carbon dioxide, which sustains warming over time. To stop that cycle, Randers said, we'll need to suck carbon dioxide back out of the atmosphere.</p><h2>8 feet of sea-level rise</h2><p>Randers' study modeled the effect of various emissions-reductions scenarios on Earth's climate between 1850 and 2500.</p><p>The data showed that if emissions stopped for good in 2020, sea levels in 2500 would still be more than 8 feet (2.5 meters) higher than in 1850.</p><figure><img src="https://i.insider.com/5fac2eb9b09abb0018626059?format=jpeg" alt="FILE - In this Aug. 16, 2019, photo, large Icebergs float away as the sun rises near Kulusuk, Greenland. The Trump administration is poised to announce an expanded diplomatic presence in Greenland and a new assistance package for the vast island aimed at thwarting growing Chinese and Russian influence in the Arctic. The announcement, expected Thursday, April 23, 2020, will come less than a year after President Donald Trump drew derision for expressing an interest in buying Greenland. (AP Photo/Felipe Dana, File)" height="2665" width="3557" charset=""><figcaption>Large icebergs float away as the sun rises near Kulusuk, Greenland, August 16, 2019.
<span>Felipe Dana/AP</span>
</figcaption></figure><p>To prevent the projected 3-degree-Celsius temperature increase, greenhouse-gas emissions would need to have ceased entirely between 1960 and 1970, the model found. In that sense, Earth blew by a climactic point of no return 50 years ago — before much of the public understood the realities of climate change.</p><p>"Yes, that is an irony," Randers said. "But of course the scientific community knew about global warming already in the 1960s."</p><h2>We need to suck carbon out of the atmosphere</h2><p>The Paris climate agreement was created with the intention to cut greenhouse-gas emissions enough to keep the world's temperature from rising more than 2 degrees Celsius by 2100. But even if all emissions stopped by 2100, according to Randers' model, sea levels in 2500 would be nearly 10 feet (3 meters) higher than they were in 1850.</p><p>Earth's temperatures are already on track to blow past the Paris agreement's goals. Last year was the <a href="https://www.ncei.noaa.gov/news/projected-ranks#:~:text=The%20warmest%20years%20globally%20have,Courtesy%20of%20NOAA%20NCEI.">second warmest on record</a> for surface temperatures and <a href="https://time.com/5765489/ocean-temperatures-warmest-ever/">the hottest ever for oceans</a>. Polar melting is <a href="https://www.businessinsider.com/sea-level-rise-3-feet-in-80-years-un-report-2019-9" data-analytics-module="body_link" data-analytics-post-depth="40">on track to raise seas 3 feet by 2100</a> and threatens to displace hundreds of millions of people.</p><p>What's needed, Randers said, is for companies and governments to "start developing the technologies for large-scale removal of greenhouse gases from the atmosphere."</p><p>In technical terms, that strategy is known as carbon capture and storage (CCS). To prevent further warming after emissions have stopped, the new study found, at least 33 gigatonnes (36.5 billion tons) of carbon dioxide would need to be sucked out of the atmosphere each year. That's roughly the total amount of carbon dioxide the global fossil-fuel industry emitted in 2018 (<a href="https://www.wri.org/blog/2018/12/new-global-co2-emissions-numbers-are-they-re-not-good#:~:text=Record%20Carbon%20Dioxide%20Emissions%20in%202018&amp;text=This%20year's%20numbers%20confirm%20their,2017%20to%2036.2%20gigatonnes%20CO20CO2">36 gigatonnes</a>).</p><p>Power plants in the US, Canada, and Switzerland have already started utilizing CCS to lower their emissions. In 2014, the Boundary Dam Power Station in Saskatchewan became one of the first in the world to successfully use the technology.</p><p>In total, 21 commercial-scale carbon-capture projects are operating around the world, and 22 more are in development, <a href="https://www.c2es.org/content/carbon-capture/">according to the Center for Climate and Energy Solutions</a>. These projects typically store carbon deep underground in depleted oil and gas fields or in bioreactor containers filled with algae that eats carbon dioxide.</p><figure><img src="https://i.insider.com/5fac4783b09abb001862611c?format=jpeg" alt="bioreactor" height="3744" width="4992" charset=""><figcaption>Bioreactors filled with green algae that eats carbon dioxide in Costa de la Luz, Spain.
<span>Santiago Urquijo/Getty Images</span>
</figcaption></figure><p>Two US carbon-capture completed in 2017 — <a href="https://www.c2es.org/content/carbon-capture/">one in Illinois, one in Texas</a> — can capture 1.1 million and 1.6 million tons of carbon dioxide, respectively, per year. But the amount of CO2 that needs to be removed from the atmosphere requires far more plants than any current plans call for.</p><p>"In other words, building 33,000 big CCS plants and keep them running for ever," the study authors wrote.</p><h2>The pros and cons of geoengineering</h2><p>Carbon capture is becoming widely accepted as a safe and potentially effective form of geoengineering. This and other climate interventions are increasingly being floated <a href="https://www.nature.com/articles/d41586-018-03036-4">by scientists</a> and politicians alike; Andrew Yang, a 2020 Democratic presidential candidate, suggested <a href="https://www.businessinsider.com/andrew-yang-thinks-geoengineering-could-lead-to-war-2019-4">budgeting $800 million</a> for further geoengineering research in the US.</p><p>But most climate-hacking proposals would be far riskier than CCS. Take solar geoengineering, for example, which involves injecting aerosols into the sky to reflect sunlight back into space. Critics of this idea point out that <a href="https://www.nature.com/articles/s41467-017-01606-0">most models predict</a> the effects of solar geoengineering wouldn't stay localized. If a country decided to independently deploy such measures, varying and unpredictable effects would likely be seen in other spots around the globe.</p><p>Aerosol injections deployed in the southern hemisphere, for instance, could impact ocean temperatures and wind speeds, leading to more hurricanes in the northern hemisphere.&nbsp;</p><figure><img src="https://i.insider.com/5c76a74726289812e8235523?format=jpeg" alt="Clouds above earth" height="2848" width="3797" charset=""><figcaption>Subtropical stratocumulus clouds above Earth.
<span>Aleksandar Georgiev/Getty Images</span>
</figcaption></figure><p>"Solar geoengineering has geopolitical ramifications, unlike carbon capture," Juan Moreno-Cruz, an associate professor at the University of Waterloo who studies geoengineering, previously told Business Insider.</p><p>Randers said his study advocates just for carbon capture, not other more experimental forms of geoengineering.&nbsp;</p><p>"I am generally against geoengineering because of its unintended side effects. But if the world continues to delay meaningful and feasible action to phase out fossil fuels, we may have to resort to geoengineering," Randers said.&nbsp;</p><p>As an immediate priority, he added, countries should invest equally in efforts to cut emissions and build more CCS plants.</p><p>"This would be a wonderful task for a government-financed <a href="https://www.businessinsider.com/alexandria-ocasio-cortez-green-new-deal-2019-1">Green New Deal</a>," he said.</p>
                            </div></div>]]>
            </description>
            <link>https://www.businessinsider.fr/us/climate-change-too-late-carbon-capture-needed-2020-11</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197019</guid>
            <pubDate>Tue, 24 Nov 2020 10:03:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies… that got me thinking about what you would see if you could pass iOS under X-Rays…</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>…</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, … are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, …</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, …</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, …</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji 🤟, News, iWork, Wallet, Shortcuts, ARKit, …</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 326 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2﻿<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>﻿ could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it’s injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️ </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world’s single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>📱 </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ♻️</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I went from $2k in a year to $2k in a week]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25196434">thread link</a>) | @jakeprins
<br/>
November 24, 2020 | https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week | <a href="https://web.archive.org/web/*/https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>After many hours of work, it was finally time to give people access to my new project, a SaaS boilerplate. In the first 5 days of early access, I almost made $2k in sales ($1,901.40 to be exact).</p><p>I have made and sold a React boilerplate before, <a href="https://www.reactmilkshake.com/">React Milkshake</a>. In the week after launching React Milkshake I made just 29 dollars. I, later on, created upgraded versions of the boilerplate. Every new version sold a bit better than the previous one, but with my completely new project <a href="https://serverless.page/">Serverless SaaS</a> I have made more in one week than with all the previous projects combined in a year.</p><p>This didn’t just happen because I just got luckier this time. Here is what I did differently.</p><h3>Landing page before product building</h3><p>The first mistake I made in the previous projects was working by myself until it was time to launch. This meant I didn’t have an audience.</p><p>Inspired by the #BuildInPublic movement, I decided for my new project to first build <a href="https://serverless.page/">the landing page</a> and open up a mailing list so people could subscribe and follow the progress of me building the product. Every now and then I shared some updates and slowly grew the mailing list to over 100 people that were sincerely interested in what I was making.</p><h3>Blogging</h3><p>In the past, I had written some articles on Medium before, but I decided to at least write one or two new blog posts every month. In total, I have at least 10 new blog posts that are related to some of the technologies that are being used in <a href="https://serverless.page/">Serverless SaaS</a>. Most of them are tutorials like <a href="https://medium.com/better-programming/how-to-set-up-next-js-with-tailwind-css-b93ccd2d4164">How to setup Next.js with Tailwind</a> or <a href="https://medium.com/better-programming/how-to-implement-netlify-cms-with-next-js-4b8721bdec45">How to implement Netlify CMS with Next.js</a>, but also a series called <em>stack choices</em> in which I compare different frameworks or technologies with each other as <a href="https://codeburst.io/stack-choices-react-vs-vue-vs-angular-vs-svelte-49aa0170c634">Angular vs React vs Vue vs Svelte</a>.</p><p>Writing these blog posts had multiple purposes and ended up with benefits:</p><ul><li>Learned a lot about these subjects</li><li>Provided value for other people learning about these subject</li><li>Earned some money with the <a href="https://help.medium.com/hc/en-us/articles/115011694187-Getting-started-with-the-Medium-Partner-Program#h_01EECWD3WWHZTJMF5PTK7AAM2C">Medium Partner Program</a></li><li>Gave me the ability to drop a link to my new project</li><li>Gave me the ability to drop a link to my personal site and Twitter</li><li>Increased my followings on Medium</li></ul><p>The people who read my blog posts could also be future customers because the starter-kit is mainly for developers (or people who work with developers).</p><h3>Mailing list</h3><p>This time I had built up a mailing list with around 100 subscribers, all with people who were interested in the boilerplate. Around 50% opened the emails I had to send and around 30% clicked the links to the site. This list is still growing because I still allow people to sign up to get regular updates.</p><p>Besides that, I already had a personal mailing list of people who had signed up for previous products I have to build like <a href="https://codestash.co/">codestash</a>, <a href="https://www.makermove.com/">makermove</a>, and <a href="https://www.raterfox.com/">raterfox</a>.</p><p>Because I started blogging more I updated <a href="https://jakeprins.com/">my personal site</a> and also added a signup field for this personal mailing list to stay informed about blog posts or product updates. In total, I had around 1000 people on this list to send out an announcement, but just 20% of that list opened the email and only 2.5% clicked the link. Those numbers are not great, but most of these subscribers come from <a href="http://raterfox.com/">raterfox.com</a>, a social platform for entertainment, which is clearly not my target audience.</p><h3>Twitter</h3><p>Twitter is a great platform for talking in public about the process and updates on your products. I wasn’t very active on Twitter and mainly used it to stay informed about tech-related stuff. I decided to be more active and did manage to gain some more Twitter followers. I think the slow growth is caused mostly by being more active on not just Twitter, but also on Indie Hackers and mentioning <a href="https://twitter.com/jakeprins_nl">my handle</a> in blog posts.</p><p>With the current 581 followers, I do not believe this had a very big impact on my launch. Twitter seems great for people with a couple of thousands of followers, but with &lt; 1k followers it sometimes feels like you are talking to a black hole of nothing.</p><p>I still think it’s a great way to share your work and be reachable by others. Some people started to DM me with questions about the boilerplate. This was already a good sign. Also, people told me they were excited about the upcoming launch, even better! Besides that, someone reached out to say my guides online were really helpful, which is always great to hear.</p><h3>Building a better product</h3><p>The first boilerplate I had build, <a href="https://www.reactmilkshake.com/">React Milkshake</a>, was a bit of an experiment. I was using it myself and wasn’t sure if other people were going to pay for it. It was very basic and doesn’t have a lot of features when it launched, but the fact that people started to buy it was super exciting for me. It proved that people are willing to pay money for a starter-kit that helped them save time.</p><p>For my next project, <a href="https://serverless.page/">Serverless SaaS</a>, I decided to spend more time on it and take it to the next level. I had some proof of the market, but the product needed to provide more value.</p><p>Most Indiehackers and developers I met online were building SaaS apps. I also had some ideas for building a SaaS, so a boilerplate that could help me build new SaaS apps faster was very helpful. If the boilerplate wouldn’t sell, I could still use it myself. So I decided to implement multiple SaaS features, like a billing integration with Stripe, and market the product as a way to build SaaS apps faster.</p><p>This would be more aligned with the need for most of my target audience and also allows me to ask for a higher price. It provides much more value than my other boilerplates and people are also more willing to pay for products that help them save time or make money. This project could potentially do both.</p><p>Instead of rushing to market and going with a full-on MVP approach, I figured I should take my time and craft a product to be proud of. After that, I could soft launch it as “Early Access”, so I could ask my first customers for feedback and improve the product while it’s being used by actual paying customers. In this soft launch period, I made more money than I did in the last year of my old project, so I guess I’m doing something right.</p><h2>Conclusion</h2><p>After years of indie hacking, I have learned a lot of valuable lessons. Looking back at the months leading to the “soft” launch of my new product, I can tell that certain activities will highly increase your chances of a successful launch.</p><p>Building in public, by sharing your progress and thoughts on social platforms, could definitely help a lot.</p><p>Taking time to write articles and provide value to others helps you in building an audience and to connect with people that might end up being a customer.</p><p>Also, don’t rush the process of building a product. It can be helpful to launch fast and validate your idea as quickly as possible, but if you want to provide real value that could mean you need to put in some extra time. Once you have seen some proof of evidence that people are willing to pay for your product I think it’s good to not rush your project. Don’t put too much pressure on yourself. But, when you think that MVP is ready, just ship it.</p><p>Thanks for reading! You can find me on Twitter (<a href="https://twitter.com/jakeprins_nl">@jakeprins_nl</a>) or read more at <a href="https://jakeprins.com/blog">jakeprins.com/blog</a>.</p></article></div></div>]]>
            </description>
            <link>https://jakeprins.com/blog/how-i-went-from-2k-in-a-year-to-2k-in-a-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196434</guid>
            <pubDate>Tue, 24 Nov 2020 08:26:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5th UberEats cyclist killed in Sydney in 3 months: Analysis and photos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25196375">thread link</a>) | @jakecopp
<br/>
November 24, 2020 | https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/ | <a href="https://web.archive.org/web/*/https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: November 24th, 2020. Please leave comments on <a href="https://news.ycombinator.com/item?id=25196375">Hacker News</a> (&gt;6 comments).</p>

<p><strong>Content warning</strong>: Description of a death, and photos of the cleaned site of death.</p>
<p>After <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">four cyclists were killed by car drivers in Sydney in the last 2 months</a>, a <a href="https://www.abc.net.au/news/2020-11-24/uber-eats-vows-to-improve-safety-cyclist-killed-in-inner-sydney/12913840">37-year-old man from Malaysia</a> was killed at ~6:40pm last night - on my street, 200 metres from my front door, at an intersection I cycle through 2-4 times a day. I would have gone through that intersection within 15 minutes of that time if I didn’t skip a class. If you know me, I’m usually quite outspoken about the dangers cyclists face, but this was absolutely brutal to hear.</p>
<p>They cleaned up the body, but didn’t completely clean up the UberEats meal the man was delivering. The man likely died while earning less than minimum wage - A survey conducted by the Transport Workers’ Union in September <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">found</a> that food deliverers earned an average of just $10.42 an hour after costs. 73% said they were worried about being “seriously hurt or killed” at work.</p>
<p><em>Content warning: Image of scattered food on road, blue glove likely from police investigation.</em></p>
</div><div>
<p>An <a href="https://www.reddit.com/r/sydney/comments/jzewgi/fifth_food_delivery_rider_dies_following_truck/gdbm0s4/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">eyewitness account on Reddit</a>:</p>
<blockquote>
<p>…I was driving along Cleveland st, and only had a glimpse of what happened: for those of you arguing about PPE - I think there was a helmet - and a crushed head and body, and a twisted bicycle, and, yes, one of those grey food delivery bags all in the middle of Chalmers st. I am crying tonight, because that was someone’s child, friend … a person - who is no more… .</p>
</blockquote>
<p><em>Content warning: Image of fragment of the helmet of the cyclist in the road gutter.</em></p>
</div><div>
<h2 id="contributing-causes">Contributing causes</h2>
<p>This is a tragedy in itself, but there are also a number of contributing causes at play here:</p>
<ul>
<li><p>In NSW, cycling on a footpath <a href="https://bicyclensw.org.au/who-can-ride-on-a-footpath-in-nsw/">is illegal and carries a fine of $114</a> for those above 15 years of age. Footpath cycling is <a href="https://www.bykbikes.com.au/blogs/bike-riding-tips/riding-bikes-on-the-footpath-the-laws-for-kids-and-adults-in-australia">legal in</a> Queensland, Tasmania, the ACT, the Northern Territory and South Australia.</p>
<ul>
<li>In the UK in 2017, there is a cyclist/pedestrian collision every <a href="https://www.cyclingweekly.com/news/rise-pedestrians-hit-cyclists-not-cause-leap-conclusions-396047">~9.9 million kilometres walked by a pedestrian</a>, or 531 in total. Of these 531 collisions 3 people were killed.</li>
</ul></li>
<li><p>Gig economy workers have little training and often no insurance. California recently proposed a law to force Uber and other platforms to treat their workers like employees. It narrowly failed to pass after <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/Uber,%20Lyft,%20and%20DoorDash%20poured%20over%20$200%20million%20into">Uber, Lyft and Doordash spent &gt; US$200m</a> campaigning against the law.</p></li>
<li><p>Dedicated infrastructure for cyclists is rare in Sydney. Not only are separated bicycle lanes hard to come by, a state government <a href="https://concreteplayground.com/sydney/design-style/sustainability/state-goverment-moves-to-rip-up-college-street-cycleway">actively removed</a> a cycleway in 2015 (which <a href="https://www.dailytelegraph.com.au/newslocal/central-sydney/college-st-syclists-four-times-as-likely-to-be-involved-in-a-crash-since-cycleway-removed/news-story/98ebe30e5c649407e45fd1aa7f023049">increased accidents by 400%</a>) <a href="https://www.bicyclenetwork.com.au/newsroom/2019/03/12/planned-removal-of-alexandra-canal-cycleway/">and in 2019</a>. Walking and cycling infrastructure typically receives <a href="https://theconversation.com/cycling-and-walking-can-help-drive-australias-recovery-but-not-with-less-than-2-of-transport-budgets-142176">0.1-2% of transport budgets</a>. Clover Moore is pushing hard on adding new dedicated cycle infrastructure in the City of Sydney - <a href="https://www.cityofsydney.nsw.gov.au/building-new-infrastructure/creating-pop-up-cycleways-in-sydney">Six pop-up cycleways</a> have been added, which may remain if their is popular support.</p></li>
<li><p>Australian car drivers have a <a href="https://www.abc.net.au/triplej/programs/hack/mythbusting-the-reasons-why-people-hate-cyclists/8689058">unique hatred of cyclists</a>. Cyclists <a href="https://www.smh.com.au/lifestyle/youre-a-cyclist-so-its-your-fault-20140205-321np.html">attract a level of vitriol</a>, if not outright malice, reserved for few subjects in the laid back Aussie’s mind. Even Tour de France winner Cadel Evans, a self described “car guy” who has a number of classic and sports cars, said <a href="https://www.smh.com.au/entertainment/books/even-tour-de-france-winner-cadel-evans-finds-cycling-in-sydney-too-intimidating-20161118-gss316.html">he doesn’t cycle in Sydney</a> due to the culture. Cyclists want to be on the road even less than car drivers want them there, but as stated earlier it is illegal to cycle on the footpath.</p></li>
</ul>
<p><em>Content warning: Image of the street where event took place, recognisable to those who live in Sydney.</em></p>
</div><div>
<h2 id="reasons-for-change">Reasons for change</h2>
<h3 id="public-safety">Public safety</h3>
<p>Car crashes are one of the <a href="https://www.seattletimes.com/life/lifestyle/the-most-dangerous-activity-driving/">leading causes of death in western countries</a>, and air pollution due to cars killed <a href="https://www.smh.com.au/politics/federal/road-death-toll-should-include-victims-of-vehicle-emissions-report-20190628-p522a8.html">two times</a> as many people as <a href="https://roadsafety.transport.nsw.gov.au/statistics/index.html">crashes do</a> in NSW each year - and they didn’t even have a choice. <a href="http://publications.jrc.ec.europa.eu/repository/bitstream/JRC89231/jrc89231-online%20final%20version%202.pdf">Half of PM10 particle emissions come from tire wear, suspended road dust and brake wear</a>- electric cars (even with regen braking) won’t fix this. In the US, drivers of cars <a href="http://vpc.org/regulating-the-gun-industry/gun-deaths-compared-to-motor-vehicle-deaths/">kill more people</a> than guns each year.</p>
<p>NSW has a program called <a href="https://towardszero.nsw.gov.au/">Towards Zero</a>, with the aim of reducing road fatalities to zero. One of the few cities to achieve this goal is Oslo, which <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the <em>city centre</em> <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches, increasing business.</p>
<p><em>Content warning: Image of food on the tarmac, and diffracted reflection from fluid likely used to clean the road.</em></p>
</div><div>
<h3 id="cars-are-heavily-subsidised-in-australia">Cars are heavily subsidised in Australia</h3>
<p>By the most generous measure, drivers only contribute <a href="https://www.ptua.org.au/myths/petroltax/">two-thirds of the cost of the road system</a> through rego and petrol taxes. The damage to a road is proportional to the <em>fourth power</em> of axle weight. Many cyclists also own a car and already pay rego. Contrary to popular belief, cyclists are likely subsidising car users.</p>
<h3 id="investing-in-cycle-infrastructurereducing-car-usage-makes-economic-sense">Investing in cycle infrastructure/reducing car usage makes economic sense</h3>
<p>In one study, for each dollar of investment in cycle focused infrastructure, the best practice policy returns 24 dollars in health, congestion, and air and noise pollution related benefits (<a href="https://ec.europa.eu/environment/integration/research/newsalert/pdf/378na1_en.pdf">Macmillan, A., Connor, J., Witten, K., et al.&nbsp;(2014). The Societal Costs and Benefits of Commuter Bicycling: Simulating the Effects of Specific Policies Using System Dynamics Modeling</a>)</p>
<p>A paper submitted to Infrastructure Australia estimated the value of commuter cycling in Australian capital cities as worth approximately <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">$0.76 per kilometre travelled</a>, equating to $2,667 for each regular commuter. Another paper <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">estimated</a> that converting drivers to cycling in Sydney &amp; Brisbane is worth $0.74 per kilometre, $1,920 per person annually in inner Sydney.</p>
<p>Banning cars on a street in Rome led to <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/www.theguardian.com/cities/2015/mar/13/pedestrianisation-rome-italy-car-parking-ban">30% increase</a> in retail spending in that street.</p>
<p>There are <a href="https://cityobservatory.org/ten-things-more-inequitable-that-road-pricing/">a lot of things</a> in our current system more inequitable than road pricing in urban areas.</p>
<h3 id="a-lot-of-other-cities-are-reducing-car-usage">A lot of other cities are reducing car usage</h3>
<p>I know this argumentum ad populum, but hey.</p>
<p>The following cities have a <a href="https://en.wikipedia.org/wiki/Congestion_pricing">congestion tax</a> in their urban core:</p>
<ul>
<li><a href="https://theconversation.com/london-congestion-charge-what-worked-what-didnt-what-next-92478">London</a></li>
<li><a href="https://en.wikipedia.org/wiki/Congestion_pricing_in_New_York_City">New York</a> (soon)</li>
<li>Stockholm</li>
<li>Singapore</li>
<li>Milan</li>
<li>Gothenburg</li>
</ul>
<p>Other efforts to reduce car usage:</p>
<ul>
<li><p>Oslo (population 673k) <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the city centre <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches. Amsterdam, New York, and San Francisco are <a href="https://www.citylab.com/perspective/2019/12/car-free-streets-plans-sf-market-street-new-york-europe-us/603391/">banning cars from their major streets</a>.</p></li>
<li><p>Madrid banned cars from its city centre during the 2018 Christmas period, <a href="https://copenhagenize.eu/news-archive/2019/3/14/the-benefits-of-car-free-streets">increasing retail profit by 9.5%</a>, and they are planning to ban cars from <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">500 acres of the city centre this year</a>.</p></li>
<li><p>In <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">Paris</a>, the first Sunday of every month is free of cars.</p></li>
</ul>
<p><em>Content warning: Image of food in the gutter of the road.</em></p>
</div><div>







<div><p>Disagree with my argument? Have I missed something or is there a mistake? I'd love to hear, please
contact me at <a href="https://jakecoppinger.blog/cdn-cgi/l/email-protection#97fdf6fcf2d7fdf6fcf2f4f8e7e7fef9f0f2e5b9f4f8fa"><span data-cfemail="0e646f656b4e646f656b6d617e7e6760696b7c206d6163">[email&nbsp;protected]</span></a>. I'm open changing my views if presented with new evidence.
</p></div></div></div>]]>
            </description>
            <link>https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196375</guid>
            <pubDate>Tue, 24 Nov 2020 08:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India's WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195938">thread link</a>) | @mihir6692
<br/>
November 23, 2020 | https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell | <a href="https://web.archive.org/web/*/https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p><strong><span>S</span>haarif Ansari got the call on 11 November</strong> at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p> <p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p> <p>Once he reached the station, Ansari found two people waiting for him</p></div></div></div></div></div>]]>
            </description>
            <link>https://themorningcontext.com/internet/indias-whitehatjr-is-startup-hell</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195938</guid>
            <pubDate>Tue, 24 Nov 2020 06:41:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Kakoune – The quest for a better code editor]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25195467">thread link</a>) | @imran3740
<br/>
November 23, 2020 | https://kakoune.org/why-kakoune/why-kakoune.html | <a href="https://web.archive.org/web/*/https://kakoune.org/why-kakoune/why-kakoune.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Up to now, I have used vi as an example for modal text editor, mostly because
I expect most programmers have at least heard of it. However, I don’t believe
vi and clones are the best modal text editor out there.</p>
<p>I have been working, for the last 5 years, on a new modal editor called
Kakoune. It first started as a reimplementation of Vim (the most popular vi
clone) whose source code is quite dated. But, I soon realized that we could
improve a lot on vi editing model.</p>
<div>
<h3 id="_improving_on_the_editing_model">Improving on the editing model</h3>
<p>vi basic grammar is <strong>verb</strong> followed by <strong>object</strong>; it’s nice because it matches
well with the order we use in English, "delete word". On the other hand,
it does not match well with the nature of what we express: There is only
a handful of <strong>verbs</strong> in text editing (<strong>d</strong>elete, <strong>y</strong>ank, <strong>p</strong>aste,
<strong>i</strong>nsert…​), and they don’t compose, contrarily to <strong>objects</strong> which can be
arbitrarily complex, and difficult to express. That means that errors are
not handled well. If you express your object wrongly with a delete verb,
the wrong text will get deleted, you will need to undo, and try again.</p>
<p>Kakoune’s grammar is <strong>object</strong> followed by <strong>verb</strong>, combined with instantaneous
feedback, that means you always see the current object (In Kakoune we call
that the selection) before you apply your change, which allows you to correct
errors on the go.</p>
<p>Kakoune tries hard to fix one of the big problems with the vi model: its
lack of interactivity. Because of the <strong>verb</strong> followed by <strong>object</strong> grammar,
vi changes are made in the dark, we don’t see their effect until the whole
editing <strong>sentence</strong> is finished. <code>5dw</code> will delete to next five words, if
you then realize that was one word too many, you need to undo, go back to
your initial position, and try again with <code>4dw</code>. In Kakoune, you would do
<code>5W</code>, see immediately that one more word than expected was selected, type
<code>BH</code> to remove that word from the selection, then <code>d</code> to delete.  At each
step you get visual feedback, and have the opportunity to correct it.</p>
<p>At the lower level, the problem is that vi treats moving around and selecting
an object as two different things. Kakoune unifies that, moving <strong>is</strong> selecting.
<code>w</code> does not just go to the next word, it selects from current position to
the next word. By convention, capital commands tend to expand the selection,
so <code>W</code> would expand the current selection to the next word.</p>
</div>
<div>
<h3 id="_multiple_selections">Multiple selections</h3>
<p>Another particular feature of Kakoune is its support for, and emphasis
towards the use of multiple selections. Multiple selections in Kakoune
are not just one additional feature, it is the central way of interacting
with your text. For example there is no such thing as a "global replace" in
Kakoune. What you would do is select the whole buffer with the <code>%</code> command,
then select all matches for a regex in the current selections (that is the
whole buffer here) with the <code>s</code> command, which prompts for a regex. You would
end up with one selection for each match of your regex and use the insert
mode to do your change. Globally replacing foo with bar would be done with
<code>%sfoo&lt;ret&gt;cbar&lt;esc&gt;</code> which is just the combination of basic building blocks.</p>
<div>
<p>Global replace</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/global-replace.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Multiple selections provides us with a very powerful to express structural
selection: we can subselect matches inside the current selections, keep
selections containing/not containing a match, split selections on a regex,
swap selections contents…​</p>
<p>For example, convert from <code>snake_case_style</code> to <code>camelCaseStyle</code> can be done
by selecting the word (with <code>w</code> for example) then subselecting underscores
in the word with <code>s_&lt;ret&gt;</code>, deleting these with <code>d</code>, then upper casing the
selected characters with <code>~</code>. The inverse operation could be done by selecting
the word, then subselecting the upper case characters with <code>s[A-Z]&lt;ret&gt;</code>
lower casing them with ` and then inserting an underscore before them with
<code>i_&lt;esc&gt;</code> This operation could be put in a macro, and would be reusable
easily to convert any identifier.</p>
<div>
<p>Camel case to snake case</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/camel.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Another example would be parameter swapping, if you had <code>func(arg2, arg1);</code>
you could select the contents of the parenthesis with <code>&lt;a-i&gt;(</code>, split the
selection on comma with <code>S, &lt;ret&gt;</code>, and swap selection contents with <code>&lt;a-)&gt;</code>.</p>
<div>
<p>Swapping arguments</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/args-swap.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>It is as well easy to use multiple selections for alignment, as the <code>&amp;</code>
command will align all selection cursors by inserting blanks before
selection start</p>
<div>
<p>Aligning variables</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/align.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Or to use multiple selections as a way to gather some text from different
places and regroup it in another place, thanks to a special form of pasting
<code>&lt;a-p&gt;</code> that will paste every yanked selections instead of the first one.</p>
<div>
<p>Regrouping manager objects together</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/regroup.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
</div>
<div>
<h3 id="_interactive_predictable_and_fast">Interactive, predictable and fast</h3>
<p>A design goal of Kakoune is to beat vim at its own game, while providing a
cleaner editing model. The combination of multiple selections and cleaned up
grammar shows that it’s possible to have text edition that is interactive,
predictable, and fast at the same time.</p>
<p>Interactivity comes from providing feedback on every command, made possible by
the inverted <strong>object</strong> then <strong>verb</strong> grammar. Every selection modification
has direct visual feedback; regex-based selections incrementally show what
will get selected, including when the regular expression is invalid; and even
yanking some text displays a message notifying how many selections were yanked.</p>
<p>Predictability comes from the simple effect of most commands. Each command is
conceptually simple, doing one single thing. <code>d</code> deletes whatever is selected,
nothing more. <code>%</code> selects the whole buffer. <code>s</code> prompts for a regex and
selects matches in the previous selection. It is the combination of these
building blocks that allows for complex, but predictable, actions on the text.</p>
<p>Being fast, as in requiring fewer keystrokes, is provided by carefully designing
the set of editing commands so that they interact well together, and by sometimes
sacrificing beauty for useability. For example, <code>&lt;a-s&gt;</code> is equivalent to
<code>S^&lt;ret&gt;</code>: they both split on new lines, but this is such a common use case that
it deserves to have its own key shortcut. As shown in <a href="http://github.com/mawww/golf">http://github.com/mawww/golf</a>,
Kakoune manages to beat Vim at the keystroke count game in most cases,
using much more idiomatic commands.</p>
</div>
<div>
<h3 id="_discoverability">Discoverability</h3>
<p>Keyboard oriented programs tend to be at a disadvantage compared to GUI
applications because they are less discoverable; there is no menu bar on
which to click to see the available options, no tooltip appearing when you
hover above a button explaining what it does.</p>
<p>Kakoune solves this problem through the use of two mechanisms: extensive
completion support, and auto-information display.</p>
<p>When a command is written in a prompt, Kakoune will automatically open a menu
providing you with the available completions for the current parameter. It
will know if the parameter is supposed to be a word against a fixed set
of word, the name of a buffer, a filename, etc…​ Actually, as soon as <code>:</code>
is typed, entering command prompt mode, the list of existing commands will
be displayed in the completion menu.</p>
<p>Additionally, Kakoune will display an information box, describing what the
command does, what optional switches it can take, what they do…​</p>
<div>
<p>Command discoverability</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/discoverability.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>That information box gets displayed in other cases, for example if the <code>g</code>
key is hit, which then waits for another key (<code>g</code> is the <strong>goto</strong> commands
prefix), an information box will display all the recognized keys, informing
the user that Kakoune is waiting on a keystroke, and listing the available
options.</p>
<p>To go even further in discoverability, the auto information system can
be set to display an information box after each normal mode keystroke,
explaining what the key pressed just did.</p>
</div>
<div>
<h3 id="_extensive_completion_support">Extensive completion support</h3>
<p>Keyboard oriented programs are much easier to work with when they provide
extensive completion support. For a long time, completion has been prefix
based, and that has been working very well.</p>
<p>More recently, we started to see more and more programs using the so called
fuzzy completion. Fuzzy completion tends to be subsequence based, instead
of prefix based, which means the typed query needs to be a subsequence of
a candidate to be considered matching, instead of a prefix. That will generate
more candidates (all prefix matches are also subsequence matches), so it
needs a good ranking algorithm to sort the matches and put the best ones first.</p>
<p>Kakoune embraces fuzzy matching for its completion support, which kicks in both
during insert mode, and prompt mode.</p>
<div>
<p>Word completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Insert mode completion provides completion suggestions while inserting in the
buffer, it can complete words from the buffer, or from all buffers, lines,
filenames, or get completion candidates from an external source, making it
possible to implement intelligent code completion.</p>
<div>
<p>Language specific completion support</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/cpp-completion.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>Prompt completion is displayed whenever we enter command mode, and provides
completion candidates that are adapted to the command being entered, and to
the current argument being edited.</p>
</div>
<div>
<h3 id="_a_better_unix_citizen">A better unix citizen</h3>
<p>Easily making programs cooperate with each others is one of the main strength
of the Unix environment. Kakoune is designed to integrate nicely with a POSIX
system: various text editing commands give direct access to the power of POSIX
tools, like <code>|</code>, which prompts for a shell command and pipe selections through
it, replacing their contents with the command output, or <code>$</code> that prompts for
a command, and keeps selections for which the command returned success.</p>
<div>
<p>Using external commands as filters</p>
<p>
<video src="https://kakoune.org/why-kakoune/video/filters.webm" autoplay="" controls="" loop="">
Your browser does not support the video tag.
</video>
</p>
</div>
<p>This is only the tip of the iceberg. Kakoune is very easily controllable from</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kakoune.org/why-kakoune/why-kakoune.html">https://kakoune.org/why-kakoune/why-kakoune.html</a></em></p>]]>
            </description>
            <link>https://kakoune.org/why-kakoune/why-kakoune.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195467</guid>
            <pubDate>Tue, 24 Nov 2020 05:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love Ed on CP/M]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25195420">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://techtinkering.com/articles/i-love-ed-on-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/i-love-ed-on-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>I love ED on CP/M.  It's often derided but I think it's just misunderstood and with a little practise its true value can shine through.  It's elegant, easy to learn and only has about 25 commands but these can be combined.  Once you get used to it most editing tasks are pretty quick.  If I'm editing text that is made up of separate lines, ideally not more than the width of the terminal, I find it excellent.  It does have a line limit of 128 characters so for continuous prose I will switch to something like Wordstar, but for editing source code and config files on CP/M, it's my first choice.</p>
<p>ED came as standard with CP/M and is only 7k for CP/M 2.2 and 10k for CP/M Plus.  One advantage of ED is that it will work both with teleprinters and video terminals without having to be configured for each device.  It is also good at manipulating large files even when the system is short of memory.</p>
<p><img src="https://techtinkering.com/img/articles/cpm_ed_copy_paste.png" title="Copying and Pasting with ED"></p><p>Like many early editors, ED is a modal editor which you start in command mode and while in this mode you can view existing text, move between lines and points in the line.  It allows you to do standard operations such as copy and paste, inserting text from other files, searching for and replacing text, etc.  When we want to enter input mode, we can use the 'I' command.  This is much like VI, except that you can only enter text in the non-command mode but not edit it.  To exit data input mode and return to command mode you use ^Z (CTRL-Z).  These commands can be combined together and one of the most powerful facilities that ED has is the 'M' Macro command to repeat sequences of commands.</p>
<p>Upon executing ED it creates a temporary output file and as you write out from ED it goes to this temporary file.  When editing a file we append text from it into the memory buffer and save to the temporary output file as we go or at the end.</p>
<p>ED keeps track of a number of values such as where it is in the source file,  the line number in the memory buffer and the character pointer (CP) on the line.  These are altered as you move around the file and memory buffer.</p>
<p>I'm not going to give a fuller explanation of how to use ED here because the CP/M 2.2 Operating Manual has a good section on the <a href="http://www.gaby.de/cpm/manuals/archive/cpm22htm/ch2.htm">CP/M Editor</a>.  I do, however, want to show it being used properly in the video below.  Further down in this article I have highlighted some useful command sequences.</p>
<h2>An Example Macro</h2>
<p>ED has a macro facility which allows you to repeat a sequence of commands as many times as you like.  This makes it a good example of the power of ED and the following is a typical macro which searches through the memory buffer and displays any occurrences of the text 'CPM', pauses in case you want to stop the macro and then replaces it with 'CP/M'.</p>
<pre><code>MFCPM^Z0TT6Z-3CSCPM^ZCP/M^Z
</code></pre>
<p>The 'M' command will run the sequences of commands that follows it until an error is raised, such as end of file.  If we wanted to we could prepend 'M' with a number to indicate the number of times we want it to run.  I'll break down each command in the sequence below:</p>
<table>
  <tbody><tr><td><code>M</code></td><td>Run the following command sequence until an error</td></tr>
  <tr><td><code>FCPM^Z</code></td><td>Find 'CPM' and leave Character Pointer (CP) after it</td></tr>
  <tr><td><code>0T</code></td><td>Display the line up to CP</td></tr>
  <tr><td><code>T</code></td><td>Display the rest of the line from CP to end </td></tr>
  <tr><td><code>6Z</code></td><td>Pause</td></tr>
  <tr><td><code>-3C</code></td><td>Move CP back 3 characters</td></tr>
  <tr><td><code>SCPM^ZCP/M^</code></td><td>Substitute 'CPM' for 'CP/M'</td></tr>
</tbody></table>
<p><code>^Z</code> in the above is CTRL-Z and indicates the end of an argument for a command.</p>
<p>The above macro could also be written:</p>
<pre><code>MFCPM^Z0TT6Z-3DICP/M^Z
</code></pre>
<p>In which case:</p>
<table>
  <tbody><tr><td><code>-3D</code></td><td>Delete the 3 previous characters</td></tr>
  <tr><td><code>ICPM^Z</code></td><td>Insert the text 'CP/M'</td></tr>
</tbody></table>
<h2>Video</h2>
<p>The video below shows ED being used properly and some of the things that make it great, including searching and replacing text, copying and pasting, macros and handling files bigger than the available memory.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7pqaj050X7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Common Command Sequences</h2>
<p>Below are some useful command command sequences which may be overlooked when reading the manual for ED.</p>
<div><table>
  <tbody><tr><th>Sequence</th><th>Explanation</th></tr>
  <tr><td>#A</td><td>Load whole file into buffer</td></tr>
  <tr><td>0A</td><td>Load enough of the file to fill half the buffer.  This is great for large files</td></tr>
  <tr><td>#W0A</td><td>Save entire buffer and load more of the source file, enough to fill half of the buffer.  Useful to move through large files.</td></tr>
  <tr><td>0W</td><td>Write half of the buffer to the new file.  Useful to make room of the buffer is full.</td></tr>
  <tr><td>-B</td><td>Move to end of the last line in the buffer</td></tr>
  <tr><td>0L</td><td>Move CP to beginning of line</td></tr>
  <tr><td>L-2C</td><td>Move to end of line before the &lt;cr&gt;&lt;lf&gt; sequence</td></tr>
  <tr><td>0P</td><td>Display page from CP without moving CP</td></tr>
  <tr><td>0LT</td><td>Move CP to beginning of line and display line (Should this be +/-n ??)</td></tr>
  <tr><td>0T</td><td>Type line up to but not including CP</td></tr>
  <tr><td>0TT</td><td>Type whole line without moving CP</td></tr>
  <tr><td>0T&lt;cr&gt;T</td><td>Type whole line without moving CP.  Display up to CP on first list and from CP on next line.  This is useful to see where CP is on line.</td></tr>
  <tr><td>B#T</td><td>Display the whole buffer</td></tr>
  <tr><td>KI</td><td>Replace a line</td></tr>
  <tr><td>0K</td><td>Delete up to CP on current line</td></tr>
  <tr><td>S^L^Z</td><td>Join current line with next</td></tr>
  <tr><td>I^L^Z</td><td>To split a line at CP</td></tr>
  <tr><td>0V</td><td>Print free/total memory buffer stats</td></tr>
  <tr><td>0X</td><td>Empties the temporary default exchange file: X$$$$$$$.LIB, used by the <em>X</em> command</td></tr>
</tbody></table></div>
<p>In the table above the following holds true:</p>
<dl>
  <dt>#</dt><dd>Represents the highest value for n</dd>
  <dt>^L</dt><dd>CTRL-L - Stands for carriage return sequence &lt;cr&gt;&lt;lf&gt;</dd>
  <dt>^Z</dt><dd>CTRL-Z - Indicates the end of a command's argument</dd>
  <dt>&lt;cr&gt;</dt><dd>Carriage Return - Actually pressing the <em>Return</em> key</dd>
</dl>
<br>
<h2>Do You Like ED Too?</h2>
<p>I know that I'm in the minority, but I'm sure there must be other people who also like ED.  I'd love to hear if I'm not alone in this.  You can leave comments via the links below or via the YouTube video above.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/i-love-ed-on-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195420</guid>
            <pubDate>Tue, 24 Nov 2020 04:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quest to Disable LAN LEDs of an Intel NUC]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25194316">thread link</a>) | @hiq
<br/>
November 23, 2020 | https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/ | <a href="https://web.archive.org/web/*/https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<h2>Introduction</h2>
<p>The Intel NUC <a href="http://ark.intel.com/products/76978/">D34010WYK</a> has a LAN port with two integrated LEDs. Both are permanently on when a connection is established, with one LED blinking on network activity. This can be rather distracting, particularly at night. So I went on to figure out how to disable the LEDs. It's a general solution that should work with every OS, every NUC, and every somewhat recent Intel NIC (Network Interface Card). Perhaps most devices with an Intel Ethernet controller.</p>
<p>The most obvious and low-tech solution is to tape the LEDs. I haven't tried as an observation led me on a different path. I noticed that a few seconds into booting Ubuntu, the LEDs are briefly switched off. I concluded this must be done through software somehow. This didn't turn out to be entirely correct or useful, as the driver (kernel module) merely resets the controller when it loads, but made me curious enough to proceed.</p>
<p>First, a step back to know the controller used in the NUC.</p>
<p>$ lspci | grep Ethernet
00:19.0 Ethernet controller: Intel Corporation Ethernet Connection I218-V (rev 04)</p>
<p>Intel ARK has <a href="http://ark.intel.com/products/71305/">more information</a>, including a very detailed 262-pages datasheet, which will prove essential.</p>
<h2>Kernel</h2>
<p>I wondered if the option to disable LEDs is perhaps provided through a kernel module parameter. I already knew the  module name for recent Intel Ethernet devices: <i>e1000e</i>. If I hadn't, <a href="https://downloadcenter.intel.com/search?keyword=I218">searching</a> the Intel Download Center for <i>I218</i> and filtering for <i>Linux</i> tells the same. And sure enough, the module is loaded.</p>
<p>$ lsmod | grep e1000e
e1000e                226396  0
ptp                    19395  1 e1000e</p>
<p>Many parameters, but none to change the behavior of LEDs. As confirmed by the <a href="https://www.kernel.org/doc/Documentation/networking/e1000e.txt">documentation</a>.</p>
<p>$ modinfo -p e1000e
debug:Debug level (0=none,...,16=all) (int)
copybreak:Maximum size of packet that is copied to a new buffer on receive (uint)
TxIntDelay:Transmit Interrupt Delay (array of int)
TxAbsIntDelay:Transmit Absolute Interrupt Delay (array of int)
RxIntDelay:Receive Interrupt Delay (array of int)
RxAbsIntDelay:Receive Absolute Interrupt Delay (array of int)
InterruptThrottleRate:Interrupt Throttling Rate (array of int)
IntMode:Interrupt Mode (array of int)
SmartPowerDownEnable:Enable PHY smart power down (array of int)
KumeranLockLoss:Enable Kumeran lock loss workaround (array of int)
WriteProtectNVM:Write-protect NVM [WARNING: disabling this can lead to corrupted NVM] (array of int)
CrcStripping:Enable CRC Stripping, disable if your BMC needs the CRC (array of int)</p>
<p>It turns out such a parameter was <a href="https://sourceforge.net/p/e1000/feature-requests/2/">requested</a> years ago, but denied by Intel with the following explanation.</p>
<p><span></span><span>I'm sorry, but this feature request was evaluated and denied because the majority of our customers require the LEDs to function as-is, and module parameters of this type are unacceptable.</span><span></span></p>
<p>So I downloaded the kernel model <a href="https://downloadcenter.intel.com/download/15817">source</a>, hoping to modify it, and eventually noticed a promising function.</p>
<p>
static s32 e1000_led_off_pchlan(struct e1000_hw *hw)
{
    u16 data = (u16)hw-&gt;mac.ledctl_mode1;
    u32 i, led;

    
    if (!(er32(STATUS) &amp; E1000_STATUS_LU)) {
        for (i = 0; i &lt; 3; i++) {
            led = (data &gt;&gt; (i * 5)) &amp; E1000_PHY_LED0_MASK; 
            if ((led &amp; E1000_PHY_LED0_MODE_MASK) !=
                E1000_LEDCTL_MODE_LINK_UP)
                continue;
            if (led &amp; E1000_PHY_LED0_IVRT)
                data &amp;= ~(E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
            else
                data |= (E1000_PHY_LED0_IVRT &lt;&lt; (i * 5));
        }
    }

    return e1e_wphy(hw, HV_LED_CONFIG, data);
}</p><p>Perhaps more complex than you'd expect such a simple task to be. Many constants and bit operations. Lots more in related functions. I figured this must be documented, presumably in the <a href="http://www.intel.com/content/dam/www/public/us/en/documents/datasheets/i218-ethernet-connection-datasheet.pdf">datasheet</a>. Browsing it cut my plans to modify the kernel module short, as it spells out a better alternative: NVM (Non-Volatile Memory).</p>
<p><span></span><span>The PHY has three LED outputs that can be configured via the NVM. The default values for the PHY (based on the LED NVM word 0x18 of the LAN region) are listed in the table below.</span><span></span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/182.x2.png?201706071857 2x">
</picture>
<p>If you're wondering why the table mentions 3 LEDs when the LAN port only has 2: the second LED is bi-colored and can switch state to either green (LED2) or amber (LED1).</p>
<p>As a closing note on the kernel module: the code does not do what it appears to. Its only purpose is to provide an interface for blinking a single LED on request, in order to identify a NIC or LAN port. It's unrelated to LEDs blinking on network activity or otherwise, which is done in hardware.</p>
<h2>NVM</h2>
<p>Writeable flash memory, which holds configuration, like the MAC address or power management settings, detailed in the table below. The LED configuration is stored in the previously mentioned word <span>0x18</span>.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/143+144.x2.png?201706071857 2x">
</picture>
<p>A minor detour first to explain the term <i>word</i>. It refers to a 2-byte (16-bit) value in little-endian order, meaning in reverse byte order. So value <span>0x1c10</span> is written <span>0x101c</span> to NVM. Very simple to do manually, by just swapping bytes, but can be done programmatically too. (These will be useful later.)</p>
<p>
def swap(value):
    return hex(value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)

&gt;&gt;&gt; swap(0x1c10)
'0x101c'</p>
<p>
function swap(value) {
    return '0x' + ((value &gt;&gt; 8 | (value &amp; 0xFF) &lt;&lt; 8)).toString(16);
};

&gt; swap(0x1c10)
"0x101c"</p>
<p>Word <span>0x18</span> is encoded as follows.</p>
<picture>
<source type="image/webp" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.webp?201707100332, https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x1.png?201706071857" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/149.x2.png?201706071857 2x">
</picture>
<p>It's a bit sequence with 5 bits each per LED. The first 3 bits on each LED set the mode, detailed in the second table. The remaining 2 bits invert and blink the LED. Below is a visual explanation on how to read this, using the default values.</p>
<p><img src="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/f418.x2.png?201706071858 2x"></p><p>Such a sequence can be used directly with the <span>swap</span> function defined earlier, with <span>0b</span> prefix to indicate bits.</p>
<p>&gt; swap(0b0001100011110100)
"0xf418"</p>
<p>Now to construct a bit sequence to turn LEDs off permanently. As you notice, there is no mode to just flat disable an LED. It's still possible to get effectively the same result. There are two solutions.</p>
<p><span>1</span><span>Set the mode of each LED to <span>010</span>, so LEDs are on on any connection, and set the invert bit on each LED. Ergo, LEDs are off on any connection. With a minor side effect: in case of no connection, LEDs are on. (When the network cable is pulled, or when the opposite side is off.)</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.webp?201707100332 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/4a29.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0010100101001010)
"0x4a29"</p>
<p><span>2</span><span>Set the mode of each LED to <span>101</span>, so LEDs are on <b>only</b> on a 10Mbps connection. Ergo, LEDs are off for either a 100Mbps or 1Gbps connection. Without side effect, as LEDs stay off in case of no connection.</span></p>
<picture>
<source type="image/webp" media="(min-resolution:2dppx)" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.webp?201707100333 2x">
<img src="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x1.png?201706071858" srcset="https://storage.googleapis.com/cdn.pwmon.org/1900/a514.x2.png?201706071858 2x">
</picture>
<p>&gt; swap(0b0001010010100101)
"0xa514"</p>
<p>There are two additional variants to the second solution, which exclude the other link speed combinations each. I'll leave constructing the bit sequence for both as an exercise to the reader. Of both solutions I prefer the second due to lack of side effect when a link speed can be excluded. Usually either 10Mbps or 1Gbps definitely can be. A way to get the negotiated link speed is to use <i>dmesg</i>.</p>
<p>$ dmesg -t | grep e1000e
...
e1000e: eth0 NIC Link is Up 100 Mbps Full Duplex, Flow Control: Rx/Tx</p>
<p>So <span>0xa514</span> it is. Ready to write to NVM. The datasheet tells how.</p>
<p><span></span><span>Intel has an MS-DOS* software utility called EEupdate that is used to program the SPI Flash images in development or production line environments. A copy of this program can be obtained through your Intel Field Service representative.</span><span></span></p>
<p>That's no good. <i>EEupdate</i> is not publicly available. A bit of research reveals another Intel tool named <i>LANConf</i>, available for DOS, Linux, and Windows, which can also write to NVM, but can only be obtained by applying for a <a href="https://www-ssl.intel.com/content/www/us/en/my-intel/design-center-privileged-access-required.html">privileged account</a> and signing a Non-Disclosure Agreement. Fortunately, <i><a href="https://www.kernel.org/pub/software/network/ethtool/">ethtool</a></i> can handle NVM too.</p>
<p>To read from NVM, use as follows. (EEPROM and NVM are used interchangeably from here on.)</p>
<p>% ethtool -e|--eeprom-dump devname [raw on|off] [offset N] [length N]</p>
<p>As per the NVM Address Map, word <span>0x18</span> is at NVM byte offset <span>0x30</span>.</p>
<p>$ sudo ethtool -e eth0 offset 0x30 length 2
Offset      Values
------      ------
0x0030:     f4 18</p>
<p>It matches the default value constructed earlier. Now to the important part: writing to NVM.</p>
<p>% ethtool -E|--change-eeprom devname [magic N] [offset N] [length N] [value N]</p>
<p>So <i>offset</i>, <i>length</i>, and <i>value</i> are obvious, but what does <i>magic</i> refer to? The manual knows.</p>
<p><span></span><span>Because of the persistent nature of writing to the EEPROM, a device-specific magic key must be specified to prevent the accidental writing to the EEPROM.</span><span></span></p>
<p>Where the device-specific magic key can be obtained from isn't documented anywhere. It appears to be kept somewhat secret on purpose. Only the file <i>ethtool.c</i> in the kernel module source code explains it.</p>
<p>eeprom-&gt;magic = adapter-&gt;pdev-&gt;vendor | (adapter-&gt;pdev-&gt;device &lt;&lt; 16);</p>
<p>Here <i>vendor</i> and <i>device</i> refer to <a href="https://pcisig.com/membership">PCI IDs</a>. There are numerous ways to get them, with the easiest perhaps being <i>lspci</i>.</p>
<p>$ lspci -nnq | grep Ethernet
00:19.0 Ethernet controller [0200]: Intel Corporation Ethernet Connection I218-V [<b>8086</b>:<b>1559</b>] (rev 04)</p>
<p>The bold numbers are the <i>vendor</i> and <i>device</i> ID respectively, in hex. So this should give the magic key.</p>
<p>
&gt; '0x' + (0x8086 | (0x1559 &lt;&lt; 16)).toString(16)
"0x15598086"</p>
<p>Very simple. Alright, commence writing.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 length 2 value 0xa514
ethtool: bad command line argument(s)</p>
<p>The value of <i>value</i> can only be a single byte. The <i>length</i> parameter repeats that byte. (This isn't documented.) Both bytes must hence be written separately. </p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
Cannot set EEPROM data: Invalid argument</p>
<p>This rather non-descriptive error took me quite a while to figure out. The <i>e1000e</i> kernel module included with the default kernel of Ubuntu 14.04.2 does not support writing to NVM, in this case at least. Intel has <a href="http://www.intel.com/content/www/us/en/support/network-and-i-o/ethernet-products/000005480.html">instructions</a> for compiling and installing the latest kernel module from source. Now it should work.</p>
<p>$ sudo ethtool -E eth0 magic 0x15598086 offset 0x30 value 0xa5
$ sudo ethtool -E eth0 magic 0x15598086 offset 0x31 value 0x14</p>
<p>And it does. Note: the LEDs remain unchanged until either the NUC is reset or the kernel module is reloaded.</p>
<h2>Windows / Mac</h2>
<p>I have not verified, but modifying NVM should also work for other OSes, unless the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/">https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</a></em></p>]]>
            </description>
            <link>https://pwmon.org/p/1900/quest-disable-lan-leds-intel-nuc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194316</guid>
            <pubDate>Tue, 24 Nov 2020 01:44:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Quantization for Neural Networks]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25194218">thread link</a>) | @keyboardman
<br/>
November 23, 2020 | https://leimao.github.io/article/Neural-Networks-Quantization/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Neural-Networks-Quantization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Quantization refers to techniques for performing computations and storing tensors at lower bitwidths than floating point precision. A quantized model executes some or all of the operations on tensors with integers rather than floating point values. This allows for a more compact model representation and the use of high performance vectorized operations on many hardware platforms. This technique is in particular useful at the inference time since it saves a lot of inference computation cost without sacrificing too much inference accuracies.</p>



<p>So far, major deep learning frameworks, such as TensorFlow and PyTorch, have supported quantization natively. The users have been using the built-in quantization modules successfully without knowing how it works exactly. In this article, I would like to elucidate the mathematics of quantization for neural networks so that the developers would have some ideas about the quantization mechanisms.</p>

<h3 id="quantization">Quantization</h3>

<h4 id="quantization-mapping">Quantization Mapping</h4>

<p>Quantization maps a floating point value $x \in [\alpha, \beta]$ to a $b$-bit integer $x_q \in [\alpha_q, \beta_q]$.</p>



<p>Mathematically, the de-quantization process is defined as</p><p>

\[x = c (x_q + d)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{c} x - d\big)\]

</p><p>where $c$ and $d$ are variables.</p>



<p>In order to derive $c$ and $d$, we have to make sure that $\alpha$ maps to $\alpha_q$ and $\beta$ maps to $\beta_q$. So we would just have to solve the linear system</p><p>

\[\begin{align}
\beta &amp;= c (\beta_q + d) \\
\alpha &amp;= c (\alpha_q + d) \\
\end{align}\]

</p><p>The solutions is</p><p>

\[\begin{align}
c &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
d &amp;= \frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha} \\
\end{align}\]

</p><p>In practice, we would have to ensure that $0$ in floating point is represented exactly with no error after quantization.</p>



<p>Mathematically, we need to ensure</p><p>

\[\begin{align}
x_q &amp;= \text{round}\big(\frac{1}{c} 0 - d\big) \\
&amp;= \text{round}(- d) \\
&amp;= - \text{round}(d) \\
&amp;= - d \\
\end{align}\]

</p><p>This means that</p><p>

\[\begin{align}
d &amp;= \text{round}(d) \\
&amp;= \text{round}\big(\frac{\alpha \beta_q - \beta \alpha_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>By convention, we denote $c$ as the scale $s$ and $-d$ as the zero point $z$.</p>



<p>To summarize, the de-quantization process is defined as</p><p>

\[x = s (x_q - z)\]

</p><p>and the quantization process is defined as</p><p>

\[x_q = \text{round}\big(\frac{1}{s} x + z\big)\]

</p><p>The value of scale $s$ and zero point $z$ are</p><p>

\[\begin{align}
s &amp;= \frac{\beta - \alpha}{\beta_q - \alpha_q} \\
z &amp;= \text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) \\
\end{align}\]

</p><p>Note that $z$ is an integer and $s$ is a <em>positive</em> floating point number.</p>

<h4 id="value-clipping">Value Clipping</h4>

<p>In practice, the quantization process will have chance to have $x$ that is outside the range of $[\alpha, \beta]$, thus the quantized value $x_q$ will also be outside the range of $[\alpha_q, \beta_q]$. If the integer type is signed <code>INTb</code> and $(\alpha_q, \beta_q) = (-2^{b-1}, 2^{b-1}-1)$, or unsigned <code>UINTb</code> and $(\alpha_q, \beta_q) = (0, 2^{b}-1)$, programming languages that have fixed type-precisions will clip the values that are outside the range.</p>



<p>More concretely, the quantization process will have an additional clip step.</p><p>

\[x_q = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>where $\text{clip}(x, l, u)$ function is defined as</p><p>

\[\begin{align}
\text{clip}(x, l, u) &amp;= 
    \begin{cases}
      l &amp; \text{if $x &lt; l$}\\
      x &amp; \text{if $l \leq x \leq u$}\\
      u &amp; \text{if $x &gt; u$}\\
    \end{cases} 
\end{align}\]

</p><h4 id="affine-quantization-mapping">Affine Quantization Mapping</h4>

<p>The quantization mapping we discussed above is also called affine quantization mapping.</p>

<h4 id="scale-quantization-mapping">Scale Quantization Mapping</h4>

<p>If the integer type is signed <code>INTb</code>, $(\alpha_q, \beta_q) = (-2^{b-1} + 1, 2^{b-1}-1)$ and we force $z = 0$.</p>



<p>Mathematically, we have</p><p>

\[\begin{gather}
\alpha_q = -\beta_q \\
\text{round}\big(\frac{\beta \alpha_q - \alpha \beta_q}{\beta - \alpha}\big) = 0 \\
\end{gather}\]

</p><p>This results in $\alpha = -\beta$. Therefore, we are mapping between the floating point range $[\alpha, -\alpha]$ and the integer range $[\alpha_q, -\alpha_q]$. Because it is exactly symmetric around $0$, we also call it symmetric quantization mapping.</p>



<p>Note that scale quantization mapping is just a special case of the affine quantization mapping, and we have an unused bit in the integer range.</p>

<h4 id="summary">Summary</h4>

<p>The quantization function is defined as</p><p>

\[f_q(x, s, z) = \text{clip}\Big( \text{round}\big(\frac{1}{s} x + z\big), \alpha_q, \beta_q \Big)\]

</p><p>and the de-quantization function is defined as</p><p>

\[f_d(x_q, s, z) = s (x_q - z)\]

</p><h3 id="quantized-matrix-multiplication">Quantized Matrix Multiplication</h3>

<h4 id="quantized-matrix-multiplication-mathematics">Quantized Matrix Multiplication Mathematics</h4>

<p>Suppose we have to perform the matrix multiplication $Y = XW + b$, where $X \in \mathbb{R}^{m \times p}$, $W \in \mathbb{R}^{p \times n}$, and $b \in \mathbb{R}^{n}$ resulting in $Y \in \mathbb{R}^{m \times n}$.</p><p>

\[\begin{align}
Y_{i, j} = b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j}
\end{align}\]

</p><p>We would need to do $p$ floating number multiplications and $p$ floating number additions to compute one single entry in $Y$. To complete the full matrix multiplication, given there are $mn$ entries in $Y$, we would need to do $mpn$ floating number multiplications and $mpn$ floating number additions.</p>



<p>Depending on the floating number precision, such the speed of such floating point matrix multiplication might not be favored. So the question becomes can we complete the same matrix multiplication using quantized values.</p>



<p>Here we apply the de-quantization equation.</p><p>

\[\begin{align}
Y_{i, j} &amp;= b_j + \sum_{k=1}^{p} X_{i,k} W_{k,j} \\
&amp;= s_b (b_{q, j} - z_b) + \sum_{k=1}^{p} s_X(X_{q,i,k} - z_X) s_W(W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \sum_{k=1}^{p} (X_{q,i,k} - z_X) (W_{q, k,j} - z_W)\\
&amp;= s_b (b_{q, j} - z_b) + s_X s_W \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\\
&amp;= s_Y(Y_{q,i,j} - z_Y)\\
\end{align}\]

</p><p>where $X_q$, $W_q$, $b_q$ and $Y_q$ are the quantized matrix for $X$, $W$, $b$ and $Y$, respectively, $s_X$, $s_W$, $s_b$, and $s_Y$ are the scales for $X$, $W$, $b$ and $Y$, respectively, and $z_X$, $z_W$, $z_b$ and $z_Y$ are the zero points for $X$, $W$, $b$ and $Y$, respectively.</p>



<p>Therefore,</p><p>

\[Y_{q,i,j} = z_Y + \frac{s_b}{s_Y} (b_{q, j} - z_b) + \frac{s_X s_W}{s_Y} \Bigg[ \bigg( \sum_{k=1}^{p} X_{q,i,k} W_{q, k,j} \bigg) - \bigg( z_W \sum_{k=1}^{p} X_{q,i,k} \bigg) - \bigg( z_X \sum_{k=1}^{p} W_{q, k,j} \bigg) + p z_X z_W\Bigg]\]

</p><p>Note that in the above equation the following terms are constants during inference and therefore could be computed offline before inference.</p>

<ul>
  <li>$z_Y$</li>
  <li>$\frac{s_b}{s_Y} (b_{q, j} - z_b)$</li>
  <li>$z_X \sum_{k=1}^{p} W_{q, k,j}$</li>
  <li>$p z_X z_W$</li>
</ul>

<p>Term $\sum_{k=1}^{p} X_{q,i,k} W_{q, k,j}$ suggests that we could just do the integer matrix multiplication for $X_q$ and $W_q$. Such integer matrix multiplication could employ special hardware and algorithms, such as <a href="https://www.nvidia.com/en-us/data-center/tensor-cores/">NVIDIA Tensor Core</a> and <a href="https://docs.nvidia.com/cuda/ampere-tuning-guide/index.html#tensor-operations">Tensor Core IMMA operations</a>, and runs much faster than conventional integer matrix multiplication.</p>

<div>
<figure>
    <img src="https://leimao.github.io/images/article/2020-11-01-Neural-Networks-Quantization/tensor-core.png">
    <figcaption>NVIDIA Tensor Core Operations</figcaption>
</figure>
</div>

<p>One additional thing to note is that $s_X$, $s_W$, $s_Y$, $z_X$, $z_W$, and $z_Y$ are floating point and integer constants, instead of variables. So there could be some special compile-time optimizations for those multiplications.</p>



<p>This could be retrieved from the resulting integer matrix from $X_q$ and $W_q$ multiplication, which is much faster than the floating number matrix multiplication for the same sizes.</p>



<p>The significance of such quantized matrix multiplication is that the product integer matrix could be converted back to floating point matrix using the scale and the zero point of the product integer matrix and it is almost numerically equivalent. If we have to do a sequence of matrix multiplications whose inputs and outputs are floating point numbers, for example</p><p>

\[\begin{align}
X_1 &amp;= X_0 W_0 + b_0\\
X_2 &amp;= X_1 W_1 + b_1\\
&amp;\vdots \\
X_n &amp;= X_n W_n + b_n\\
\end{align}\]

</p><p>We could convert the math to the followings using quantized matrices.</p><p>

\[\begin{align}
X_{0, q} &amp;= f_q(X_0, s_{X_0}, z_{X_0})\\
X_{1, q} &amp;= f_m(X_{0, q}, W_{0, q}, b_{0, q}, s_{X_0}, z_{X_0}, s_{W_0}, z_{W_0}, s_{b_0}, z_{b_0}, s_{X_1}, z_{X_1}) \\
X_{2, q} &amp;= f_m(X_{1, q}, W_{1, q}, b_{1, q}, s_{X_1}, z_{X_1}, s_{W_1}, z_{W_1}, s_{b_1}, z_{b_1}, s_{X_2}, z_{X_2}) \\
&amp;\vdots \\
X_{n, q} &amp;= f_m(X_{n-1, q}, W_{n-1, q}, b_{n-1, q}, s_{X_{n-1}}, z_{X_{n-1}}, s_{W_{n-1}}, z_{W_{n-1}}, s_{b_{n-1}}, z_{b_{n-1}}, s_{X_n}, z_{X_n}) \\
X_n &amp;= f_d(X_{n, q}, s_{X_n}, z_{X_n})
\end{align}\]

</p><p>where $f_q$ is the quantization function, $f_m$ is the quantized matrix multiplication function, and $f_d$ is the de-quantization function.</p>

<h4 id="examples">Examples</h4>

<p>In the following example, we simulated the quantization matrix multiplication of $Y = XW + b$ using random matrix $X$, $W$ and $b$.</p>

<div><div><pre><code><span># gemm.py
</span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>round</span><span>(</span><span>1</span> <span>/</span> <span>s</span> <span>*</span> <span>x</span> <span>+</span> <span>z</span><span>,</span> <span>decimals</span><span>=</span><span>0</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>np</span><span>.</span><span>clip</span><span>(</span><span>x_q</span><span>,</span> <span>a_min</span><span>=</span><span>alpha_q</span><span>,</span> <span>a_max</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>quantization_int8</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x_q</span> <span>=</span> <span>quantization</span><span>(</span><span>x</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>,</span> <span>alpha_q</span><span>=-</span><span>128</span><span>,</span> <span>beta_q</span><span>=</span><span>127</span><span>)</span>
    <span>x_q</span> <span>=</span> <span>x_q</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>int8</span><span>)</span>

    <span>return</span> <span>x_q</span>

<span>def</span> <span>dequantization</span><span>(</span><span>x_q</span><span>,</span> <span>s</span><span>,</span> <span>z</span><span>):</span>

    <span>x</span> <span>=</span> <span>s</span> <span>*</span> <span>(</span><span>x_q</span> <span>-</span> <span>z</span><span>)</span>
    <span>x</span> <span>=</span> <span>x</span><span>.</span><span>astype</span><span>(</span><span>np</span><span>.</span><span>float32</span><span>)</span>

    <span>return</span> <span>x</span>

<span>def</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>,</span> <span>alpha_q</span><span>,</span> <span>beta_q</span><span>):</span>

    <span># Affine quantization mapping
</span>    <span>s</span> <span>=</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>)</span> <span>/</span> <span>(</span><span>beta_q</span> <span>-</span> <span>alpha_q</span><span>)</span>
    <span>z</span> <span>=</span> <span>int</span><span>((</span><span>beta</span> <span>*</span> <span>alpha_q</span> <span>-</span> <span>alpha</span> <span>*</span> <span>beta_q</span><span>)</span> <span>/</span> <span>(</span><span>beta</span> <span>-</span> <span>alpha</span><span>))</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>generate_quantization_int8_constants</span><span>(</span><span>alpha</span><span>,</span> <span>beta</span><span>):</span>

    <span>b</span> <span>=</span> <span>8</span>
    <span>alpha_q</span> <span>=</span> <span>-</span><span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span>
    <span>beta_q</span> <span>=</span> <span>2</span> <span>**</span> <span>(</span><span>b</span><span>-</span><span>1</span><span>)</span> <span>-</span> <span>1</span>

    <span>s</span><span>,</span> <span>z</span> <span>=</span> <span>generate_quantization_constants</span><span>(</span><span>alpha</span><span>=</span><span>alpha</span><span>,</span> <span>beta</span><span>=</span><span>beta</span><span>,</span> <span>alpha_q</span><span>=</span><span>alpha_q</span><span>,</span> <span>beta_q</span><span>=</span><span>beta_q</span><span>)</span>

    <span>return</span> <span>s</span><span>,</span> <span>z</span>

<span>def</span> <span>quantization_matrix_multiplication_int8</span><span>(</span><span>X_q</span><span>,</span> <span>W_q</span><span>,</span> <span>b_q</span><span>,</span> <span>s_X</span><span>,</span> <span>z_…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Neural-Networks-Quantization/">https://leimao.github.io/article/Neural-Networks-Quantization/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Neural-Networks-Quantization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25194218</guid>
            <pubDate>Tue, 24 Nov 2020 01:30:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
    </channel>
</rss>
