<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 2]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 2. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 29 Jun 2020 20:16:37 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-2.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 29 Jun 2020 20:16:37 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Kindness for Mean Girls]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23667675">thread link</a>) | @tenslisi
<br/>
June 28, 2020 | https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html | <a href="https://web.archive.org/web/*/https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<h4 id="a-primer-on-the-cruel-tacit-laws-of-type-level-programming-in-haskell"><em>A primer on the cruel, tacit laws of type-level programming in Haskell</em></h4>

<p>Haskell programs are constructed at the junction of two worlds: one of types, and the other of values. Values are operational run-time entities that are denoted syntactically by <em>terms</em> in the code. To this end, types classify terms. They provide a powerful abstraction to organize data, determine how it should be stored in memory, passed through various operations, and more. On a superficial level, the difference between these worlds is simple: <em>types</em> refer to datatypes, which are either built-in (such as <code>Integer</code> and <code>String</code>), or user-declared, for example:</p>

<pre><code>data SpringFlingQueen = Cady | Regina
</code></pre>

<p>By comparison, <em>values</em> are denoted by <em>terms</em> those types categorize (such as <code>1</code> and <code>"abc"</code> described by the standard library’s <code>Integer</code> and <code>String</code> types, or <code>Cady</code> and <code>Regina</code> in the case of our user-declared type, <code>SpringFlingQueen</code>). Thus, the term <code>1</code> denotes a value that exists in memory only when the program is run.</p>

<p>In addition to these two worlds, a third, darker, and more elusive underworld of <em>kinds</em> also lurks in the shadows of Haskell programs. Haskell kinds can be as unpredictable and insidious as the soulless alpha-female of an elite high school clique. While daunting, understanding the coaction between these three worlds lays the foundation for type-level programming, a topic worth learning as it strengthens overall Haskell intuition.</p>

<p><img src="https://user-images.githubusercontent.com/875834/81239044-afe24580-8fd1-11ea-96b0-274cf839e834.png" alt="the haskell type system: a machine of constant, unforgiving judgement and rigid classification"></p>

<h3 id="kindness-is-a-virtue">Kindness is a virtue</h3>

<p>Much like counter-intuitive adolescent social dynamics, mastery of Haskell bears a steep learning curve because of its underlying complexity. It is difficult to wrap one’s head around the language’s typeclass hierarchies, category-theoretic roots, or the intricacies of compiler behavior. However, an intimate understanding of the type system lets programmers look beyond the chaos of code and apply a recognizable template by which to understand it.</p>

<h3 id="kindness-takes-patience">Kindness takes patience</h3>

<p>This topic is also difficult to master because it is both vast and subtle. Ideas underlying type-level programming are scattered across many disconnected resources focused on several corners of the Haskell ecosystem. Authoritative references on the topic (such as relevant library documentation) tend to assume familiarity with domain-specific terminology that may be unknown to non-experts. Due to the paucity of approachable materials on the subject, I’ve attempted to break down type-level programming into explanations of its constituent parts. While I don’t go into extensive depth on any individual section below, I hope to provide a valuable starting point with which readers can explore ideas in greater detail.</p>

<table>
  <thead>
    <tr>
      <th>Table of contents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#Types-vs-Values">Types vs. Values</a></td>
    </tr>
    <tr>
      <td><a href="#Kinds">Kinds</a></td>
    </tr>
    <tr>
      <td><a href="#higher-kinded-types">Higher-kinded types</a></td>
    </tr>
    <tr>
      <td><a href="#constraint-kinds">Constraint kinds</a></td>
    </tr>
    <tr>
      <td><a href="#PolyKinds">Kind polymorphism</a></td>
    </tr>
    <tr>
      <td><a href="#DataKinds">DataKinds and type-level literals</a></td>
    </tr>
    <tr>
      <td><a href="#Datatype-promotion">Datatype promotion</a></td>
    </tr>
    <tr>
      <td><a href="#Relationship-between-values-terms-types-and-kinds">Relationship between values, terms, types, and kinds</a></td>
    </tr>
    <tr>
      <td><a href="#The-difference-between-type-and-type-level">The difference between “type” and “type-level”</a></td>
    </tr>
    <tr>
      <td><a href="#type-families">Type families</a></td>
    </tr>
    <tr>
      <td><a href="#associated-types">Associated types</a></td>
    </tr>
    <tr>
      <td><a href="#TypeLits">GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#Distinguishing-between-DataKinds-and-TypeLits">Distinguishing between DataKinds and GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#use-case-Marshaling-ASTs">Use-case: Marshaling ASTs</a></td>
    </tr>
    <tr>
      <td><a href="#The-hype-of-dependently-typed-langs">The hype of dependently-typed languages</a></td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="types-vs-values">Types vs. Values</h3>

<p>As mentioned above, Haskell programs are divided into two worlds: the <em>type-level</em> and the <em>value-level</em>. The <em>type-level</em> refers to the part of a program analyzed by the static type-checking phase during compilation. Since every expression is assigned a type, code is checked against Haskell’s type system to ensure it fits <a href="https://www.haskell.org/ghc/">GHC</a>’s specified correctness criteria.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704534-fce9fd80-af27-11ea-9544-13961a56c444.png" alt="types classify terms, just like hostile teens with identity crises classify one another"></p>

<p>If the program is well-typed, the program will compile. However, this type-information evaporates once the compilation process terminates, leaving only <em>values</em> behind at run-time. In this way, types and values can be better distinguished by the phasing distinction, with types being compile-time entities and values being run-time entities.</p>

<p>For example, if a function takes a <code>String</code>, the type-checker doesn’t care if the <code>String</code> has a value denoted by <code>"abc"</code> or <code>"123"</code> or <code>"get in loser"</code>—so long as it’s a <code>String</code>. Type information gets discarded at run-time, leaving only the string’s value (ex.,<code>"get in loser"</code>). In some cases, however, we want the type system to care about what those values are and distinguish between them. The <code>DataKinds</code> extension, which we’ll explore below, lets us do that by allowing us to shove more information about our program into the type system. This lets us add meaning to the value of a <code>String</code> at the type-level, moving them from their usual, strictly run-time existence, into the compile-time phase. The technique allows us to use more information statically in the logical development and abstraction of the program’s behavior. We’re also able to add consequences that can halt compilation if the specific value of <code>String</code> doesn’t conform to the rules we’ve specified, or define classes over them.</p>

<h4 id="distinguishing-types-and-values-in-ghci">Distinguishing types and values in GHCi</h4>

<p>Let’s examine our aforementioned <code>SpringFlingQueen</code> datatype in GHCi. When we query the type of one of its constructors using <code>:t</code> (a handy shorthand for <code>:type</code>), we see that it is indeed of type <code>SpringFlingQueen</code>:</p>

<div><div><pre><code>λ data SpringFlingQueen = Cady | Regina
λ :t Cady
Cady :: SpringFlingQueen
</code></pre></div></div>

<p>Now consider literals <code>1</code>, <code>2</code>, <code>3</code>. These are <em>values</em> of a type that parameterizes the <code>Num</code> class:</p>



<p>Typing <code>:t 1</code> into GHCi gives us <code>Num p =&gt; p</code>, indicating that a literal such as <code>1</code> can be of any polymorphic type <code>p</code> as long as the <code>Num</code> type class has instances for that type (for example, <code>Integer</code> and <code>Float</code> both have <code>Num</code> instances and therefore are valid types that <code>p</code> could be instantiated with). This is possible due to <a href="https://wiki.haskell.org/Type_inference">type inference</a>.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704346-ae3c6380-af27-11ea-8078-6f1ddfc7b238.png" alt="type inference can be used to deduce concrete types wherever they're obvious. If a type looks like a mouse, it's a mouse—duh!"></p>

<h3 id="kinds">Kinds</h3>

<p>Just like types classify terms, <a href="https://www.haskell.org/onlinereport/decls.html#sect4.1.1">kinds</a> classify types, and therefore are frequently described as “types of types”, or referred to be “one level up.” The “star” syntax (i.e., <code>*</code>) denotes kinds. It is defiantly used in this post despite <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0143-remove-star-kind.rst">recent syntactic changes</a>. A prerequisite for understanding the kind system necessitates comprehending the differences between three pairs of ideas:</p>

<ol>
  <li>
    <p><strong>Data constructors vs. type constructors:</strong> data constructors create values, whereas type constructors create types. Type constructors take one or more type arguments and produce a datatype when enough arguments are provided. This means that through <a href="https://wiki.haskell.org/Currying">currying</a>, a type constructor can be <a href="https://wiki.haskell.org/Partial_application">partially applied</a>. For example, the list type constructor <code>[]</code> may take a single type argument (ex. <code>String</code>) to denote the elements of the list (i.e., <code>[String]</code>). <code>[String]</code> is simply syntactic sugar for <code>[] String</code>, where the type <code>[]</code> is applied to <code>String</code>.</p>
  </li>
  <li>
    <p><strong>Full vs. partial application</strong> A partially-applied type, like a <a href="https://wiki.haskell.org/Partial_application">partially-applied function</a>, is one that is missing some of its data constructors. For instance, consider the list type <code>[]</code>. The kind of <code>[]</code> is <code>* -&gt; *</code>. A fully-applied list has data constructors, such as <code>[Int]</code>, and its kind is <code>*</code>.</p>
  </li>
  <li>
    <p><strong>Inhabited types vs. uninhabited types:</strong> An inhabitant of a type is precisely a value of that type. This means that <em>inhabited</em> types refer to the types that contain concrete values, such as the value denoted by the term <code>1 :: Int</code>. This suggests that the type <code>Int</code> is inhabited by value denoted by <code>1</code>. By contrast, <em>uninhabited</em> types refer to type constructors to which no values are abstracted. For instance, <code>Void</code> is uninhabited because it has no data constructors, and thus can not be used to construct a valid term. While <code>Void</code> may seem pointless at first, it can be a useful way to represent that a container is empty (ex., <code>[Void]</code>, which <em>is</em> inhabited by the term <code>[]</code> and the value this term denotes).</p>
  </li>
</ol>

<p>How do these ideas relate to the kind system? Well, all fully-applied runtime values are of kind <code>*</code> <em>and</em> they are inhabited. You can confirm this by typing <code>:k Int</code> and <code>:k String</code> in GHCi. However, this doesn’t work the other way around—just because a type is inhabited, doesn’t necessarily mean it’s fully-applied (ex., <code>[]</code> is not fully-applied but it <em>is</em> inhabited, and its kind signature is <code>* -&gt; *</code>). Conversely, all partially-applied types are uninhabited (since they don’t correspond to a value), but not all uninhabited types are partially applied. <code>Void</code> for instance is not partially-applied, but it is uninhabited.</p>

<p>To get the hang of this idea, consider the following examples:</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Inhabited?</th>
      <th>Fully-applied?</th>
      <th>Kind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Int</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>String</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>[]</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>[Int]</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>(,)</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Either</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Void</code></td>
      <td>No</td>
      <td>N/A</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>Either Void Void</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
  </tbody>
</table>

<p>Kind signatures can be specified manually in GHCi using the <a href="https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures"><code>XKindSignatures</code></a> extension. Try extending the above table by investigating the kind signatures of various types.</p>

<h3 id="higher-kinded-types">Higher-kinded types</h3>

<p>Just like there are higher-order functions (functions that take other functions as arguments), there are higher-kinded types (types constructors that take other type constructors as arguments). Type constructors such as <code>[]</code> are a first-class type, but also a higher-kinded type, given they take another type constructor to be reified:</p>



<p>Let’s consider <code>Functor</code>:</p>

<div><div><pre><code>λ :k Functor
Functor :: (* -&gt; *) -&gt; Constraint
</code></pre></div></div>

<p>We see that <code>Functor</code> takes a type constructor <code>* -&gt; *</code> and returns a <code>Constraint</code>. Let’s use <code>:info</code> to examine <code>Functor</code> a bit more closely:</p>

<div><div><pre><code>λ :info Functor
class Functor (f :: * -&gt; *) where
  fmap :: (a -&gt; b) -&gt; f a -&gt; f b
  (&lt;$) :: a -&gt; f b -&gt; f a
  {-# MINIMAL fmap #-}
  	-- Defined in ‘GHC.Base’
instance Functor (Either a) -- Defined in ‘Data.Either’
instance Functor ((,,,) a b c) -- Defined in ‘Data.Orphans’
instance Functor ((,,) a b) -- Defined in ‘Data.Orphans’
instance Functor [] -- Defined in ‘GHC.Base’
instance Functor Maybe -- Defined in ‘GHC.Base’
instance Functor IO -- Defined in ‘GHC.Base’
instance Functor ((-&gt;) r) -- Defined in ‘GHC.Base’
instance Functor ((,) a) -- Defined in ‘GHC.Base’
</code></pre></div></div>

<p>We see that <code>Functor</code> allows type constructors like <code>Maybe</code> and <code>[]</code> to have <code>Functor</code> instances, but not <code>Int</code> or <code>String</code>. This is because <code>Maybe</code> and <code>[]</code> are <code>* -&gt; *</code>, while <code>Int</code> has kind <code>*</code>. Similarly, <code>Either</code> has <code>* -&gt; * -&gt; *</code>, which is why its instance above is parameterized with a type parameter denoting something of kind <code>* -&gt; *</code>: <code>Either a</code>.</p>

<h3 id="constraint-kinds">Constraint kinds</h3>

<p>We got a glimpse of constraint kinds …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</a></em></p>]]>
            </description>
            <link>https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667675</guid>
            <pubDate>Sun, 28 Jun 2020 09:34:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twister OS for Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23667310">thread link</a>) | @jordybg
<br/>
June 28, 2020 | https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/ | <a href="https://web.archive.org/web/*/https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
		<div>
		<div id="content-area">
			<div id="left-area">
											<article id="post-814">
											 <!-- .et_post_meta_wrapper -->
				
					<div>
					<p>In this video, we take alike at Twister Os for the Raspberry Pi 4!</p>
<p>This is a new Linux distro from the creators of iRaspbian and RaspbianX and it allows you to swap between the Windows 10 look of Raspbian X nighthawk or the OSX look of iRaspbian!</p>
<p>This version does support Box86, Steam, Android mirroring on the desktop, Box86, Chromium Media edition for watching Netflix, HULU, and Disney Plus!</p>
<p>This Project is Mind-Blowing and works amazingly on The Raspberry Pi4!</p>
<p>Download it here: <a href="https://raspbian-x.com/" target="_blank" rel="noopener noreferrer">https://raspbian-x.com/</a><br>Pilabs YouTube channel: PiLabs Channel: <a href="https://www.youtube.com/channel/UCgfQjdc5RceRlTGfuthBs7g" target="_blank" rel="noopener noreferrer">https://www.youtube.com/channel/UCgfQjdc5RceRlTGfuthBs7g</a><br>PiLabs Discord: <a href="https://discord.com/invite/Fh8sjmu" target="_blank" rel="noopener noreferrer">https://discord.com/invite/Fh8sjmu</a></p>
<p><strong>Need a Pi4?</strong><br><a href="https://geni.us/jTs6jg">Raspberry Pi 4</a><br><a href="https://geni.us/sWKS">SD Cards</a><br><a href="https://geni.us/rPFYi">Ice Tower cooler</a></p>
<p><a href="https://twitter.com/ProjectsPi">Follow Me On Twitter</a></p>
<p><strong>Equipment I Use:</strong><br><a href="https://geni.us/JkNt">Screen Capture Device</a><br><a href="https://geni.us/BQ5nyKn">Tool Kit</a><br><a href="https://geni.us/wOtA">Soldering Station</a><br><a href="https://geni.us/vxAxn">Camera</a><br><a href="https://geni.us/Utll">Tripod</a><br><a href="https://geni.us/jTs6jg">Raspberry Pi 4</a><br><a href="https://geni.us/xqMj">Flirc Case</a></p>
<p>DISCLAIMER: This video and description contains affiliate links, which means that if you click on one of the product links, I’ll receive a small commission at no extra cost to you!</p>
<p>This video and Channel and Video are for viewers 14 years older and up. This video is not made for viewers under the age of 14. If you are under 14 years of age, you do not have permission to view this video.</p>
<p>THIS VIDEO IS FOR EDUCATIONAL PURPOSES ONLY!</p>
<p>#RaspberryPi #Pi4 #TwisterOS</p>


<figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/TX7tArVdf80?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure><figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/x4dX7mc9zI4?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure><figure><p><span><iframe width="1080" height="608" src="https://www.youtube.com/embed/La67o7aodJY?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
<!-- AI CONTENT END 1 -->
					</div> <!-- .entry-content -->
					 <!-- .et_post_meta_wrapper -->
				</article> <!-- .et_pb_post -->

						</div> <!-- #left-area -->

				 <!-- end #sidebar -->
		</div> <!-- #content-area -->
	</div> <!-- .container -->
	</div></div>]]>
            </description>
            <link>https://raspberrypiprojects.com/twister-os-raspberry-pi-4-get-that-osx-and-windows-10-look/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667310</guid>
            <pubDate>Sun, 28 Jun 2020 07:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Half of Canadians would support 30-hour work week: poll]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23667134">thread link</a>) | @chewdatgenie
<br/>
June 27, 2020 | https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/ | <a href="https://web.archive.org/web/*/https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Workers get set to pour cement from a truck at the GO train station in Oakville, Ont., Tuesday, Jan.28, 2020. A new report by the Angus Reid Institute suggests the majority of Canadians support the idea of a shorter work week. (Richard Buchan/THE CANADIAN PRESS)</p><div>
                    <p>Support for the idea of a shorter work week is growing in popularity in Canada as the COVID-19 pandemic continues to upend the working lives of Canadians, according to a <a href="http://angusreid.org/four-day-work-week/" target="_blank" rel="noopener noreferrer">new study by the Angus Reid Institute</a>.</p>
<p>More than half of Canadians (53 per cent) surveyed by the non-profit research centre said it would be a good idea to make a new 30-hour work week standard in Canada, the study found.</p>
<p>That’s a six-point increase compared to 2018 and more than twice the number of people who feel the present 40-hour workweek is just fine, the survey said.</p>
<p>Researchers at the institute speculate that the increase in support for a shorter workweek is perhaps driven in part by the COVID-19 pandemic and difficulties it has presented for many out of work Canadians.</p>
<p>The proportion of supporters of a 30-hour workweek rises to 58 per cent among those who have applied for the Canada Emergency Response Benefit. This is eight-points higher than those who have not applied for the program, the study found.</p>
<p>Support for a shorter workweek is highest at the lowest levels of household income (64 per cent) and lowest among those with incomes over $150,000 per year (47 per cent).</p>
<p>Past Conservative voters are the most fervent in their opposition to the idea of a shorter workweek.</p>
<p>This group is most likely to say that shortening the work week is an ill-conceived idea, 40 per cent feel this way, while two-thirds of past Liberal and New Democratic Party voters voice support for the measure.</p>
<h5>‘An interesting notion’</h5>
<p>Ricardo Tranjan, senior researcher at the Canadian Centre for Policy Alternatives, said “30 for 40”, thirty hours work for forty hours pay, is an interesting notion, and one that should be widely discussed, even beyond the COVID-19 context.</p>
<p>Shorter working weeks would allow workers to participate more actively in their children’s education, spend more time caring for their own parents and engage in leisure and physical activities that would have a positive impact on their health, Tranjan said.</p>
<p>Ten additional hours at home could go a long way in alleviating “double shifts,” which burden women disproportionately more than men, he said.</p>
<p>“But I have two critical concerns,” Tranjan said. “First, this can’t happen unless wages are adequate. We would absolutely need to maintain the same wage levels for shorter weeks, but for some workers, that wouldn’t be enough.”</p>
<p>People who work 40 hours a week at the minimum wage are very likely to have household incomes close to the poverty line, he said.</p>
<p>“If we reduce hours for these workers, they’re likely to pick up extra shifts, hoping that will allow them to afford things like new winter jackets for the kids or more and healthier food for the family,” Tranjan said.</p>
<p>“Meantime, higher-wage workers will be enjoying all the benefits of shorter weeks, so we’ll be just exacerbating social inequalities.”</p>
<p>Tranjan said his second concern has to do with eligibility for income supports, which is often tied to working hours.</p>
<p>“For example, will employment insurance eligibility be reduced if weeks are reduced? Or will we end up with even fewer people qualifying for EI benefits?” Tranjan said. “We need to tackle these questions heads on, but we should continue to have this conversation.”</p>
<h5>Business owners not buying it</h5>
<p>Dan Kelly, president of the Canadian Federation of Independent Business (CFIB), which has more than 100,000 members, said it should surprise no one that the majority of Canadians like the idea of a four-day work week.</p>
<p>“The only people who would say no to such an idea are those that immediately recognize that this would likely require a 20 per cent reduction in their weekly pay or the massive unemployment that would occur if businesses were required to pay the same for fewer working hours,” Kelly said. “I would like six months of vacation and double my salary – that doesn’t mean it would be a reasonable request.”</p>
<p>Half of small Canadian businesses remain fully or partially closed due to the pandemic and most of those open now will be losing money every week they are open for months and months ahead, Kelly said.</p>
<p>Businesses have been hit with multiple months of lost productivity, rising debt and the costs of the personal protective equipment they now have to procure, Kelly said.</p>
<p>“Shorter work weeks at the same rate of pay for their staff would be an impossibility for nearly every business at this time,” Kelly said.</p>
<p>Twelve per cent of independent businesses report they are considering winding down or going bankrupt, he added.</p>
<p>“There could be 100,000 fewer small businesses before this is over,” Kelly said. “Let’s not push that number even higher.”</p>
                    
                                        
                                    </div></div>]]>
            </description>
            <link>https://www.rcinet.ca/en/2020/06/26/half-of-canadians-would-support-30-hour-work-week-poll/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23667134</guid>
            <pubDate>Sun, 28 Jun 2020 06:44:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we got our AWS bill to around 2% of revenue]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 115 (<a href="https://news.ycombinator.com/item?id=23666999">thread link</a>) | @grwthckrmstr
<br/>
June 27, 2020 | https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it | <a href="https://web.archive.org/web/*/https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Server cost is usually not a concern for most funded startups, but for a boot strapped SaaS product like ours,&nbsp; it was important to have an AWS bill that is easy on the pocket and a little more proportional to the MRR.</p><p>‍</p><p>To that end when we started<a href="http://superlemon.xyz/" target="_blank"> superlemon.xyz</a> one of the first things I did was to find ways to consume the least amount of resources on the cloud. We currently serve a traffic of ~ 250 requests per second with our AWS setup.</p><p>‍<br></p><p>Most applications require certain common cloud resources and these include</p><p>‍<br></p><ul role="list"><li>Compute instances</li><li>Database instances</li><li>Caching instances</li><li>CDN&nbsp;</li><li>A web server that acts as a reverse proxy and load balancer</li></ul><p>‍<br></p><div><p>I will now go through each of these resources and talk about both the expensive way and the cheap way to implement them</p></div><p><strong>Compute instances</strong></p><p><strong>‍</strong><br></p><p>When it comes to compute instances, most people go with AWS EC2 instances. EC2 instances are the safest choice to make for running server applications as they are highly configurable, scalable and you can change the configuration on demand according to your needs. However, sometimes you do not really need this level of control on your compute instances and that brings us to <a href="https://aws.amazon.com/free/compute/lightsail/" target="_blank">AWS Lightsail</a>.</p><p>‍<br></p><p>Lightsail as the name suggests is a lightweight version of EC2. Under the hood Lightsail instances are actually EC2 instances, but this is not apparent to the user and unlike the highly configurable EC2, Lightsail comes with a fixed configuration that once you provision cannot be changed. The billing is also a fixed amount per month as opposed to EC2 which is billed by the hour.&nbsp;</p><p>‍<br></p><p>To give you a sense of how much less complicated Lightsail is, please take a look at these screenshots of the EC2 dashboard and Lightsail dashboard.</p><figure id="w-node-7afe1c2bdee3-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef82a451ea3cd05dfd4c146_x93boOZlEeQGL9kcVSXPZyGOX3SNQJfDNyRC0qG3jNDCYeySdZpIgBzYgkVDZqq3DhR92f_Eqdp8sG-vIgkwltIW9ExWhshfDSsb-gd2qCah6E5VjydVhGxO4QFRA5qCR2KXqhP5.png" alt=""></p></figure><p>‍</p><p>‍</p><p>‍</p><figure id="w-node-2074947a61a8-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef737f4a33047deb1c0a4a6_ZMr0t2QqxGgPZ-Grg-TIHjpok_ujhoYzyHLQnsGzlSfLJj0wRrKWFMKNnVDwCoOorYJHs6j4aqKz_NgztOFGNSNc9Fw4nKGrwSRVK7E4hQtDkzE7OXIVaQp0lDjXxwjiKkHN1e3c.png" alt=""></p><figcaption>EC2 dashboard</figcaption></figure><p>‍</p><p>‍</p><p>But we are not here to debate the complexity of EC2 vs Lightsail, so let’s let us talk about the cost.</p><p>An EC2 instance with 2 virtual cores, 4GB RAM and a storage of 80GB costs roughly 37$ a month and a Lightsail instance with the exact same configuration costs 20$ a month which is almost half the cost!</p><p>‍<br></p><p>The only drawback here as previously mentioned is that the instance is fixed and neither the storage nor the compute power can be tweaked later according to spikes in traffic and usage.&nbsp;</p><p>‍<br></p><p>In our case we do not have a need for too much storage on the compute instance, and as for the computing power it was easy for us to simply provision another Lightsail instance when there is an increase in traffic and set it up behind a load balancer. This way our system is still scalable.</p><p><strong>Database instances</strong></p><p><strong>‍</strong><br></p><p>Choosing a database provider for your application can be a tricky decision, but on a high level there is just one thing that is absolutely required for any database provider - the ability to take regular backups of the DB automatically and the ability to restore the database from one of the backups.</p><p>‍<br></p><p>All of this functionality is provided by AWS RDS along with an array of other capabilities like autoscaling of storage, multiple availability zones, etc. However we did not not really need this level of control over the DB for our simple SaaS product, not to mention the fact that RDS would cost us a minimum of 200$ a month with the lowest acceptable configuration.&nbsp;</p><p>‍<br></p><p>Once again our saviour was Lightsail which provides managed Databases with a fixed storage at very cheap prices. Only MySQL and PostgreSQL are available though which was fine with us since I am quite comfortable with MySQL. We have currently provisioned one MySQL DB with 2 vCPUS, 4GB RAM and 120GB SSD and it costs us 60$ a month.</p><p>‍<br></p><p>And as mentioned before Lightsail provides the basic capabilities of backups and restoration.</p><figure id="w-node-e1f43dee380f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef731c812136072299e133c_Q2n6wprxbcqgh5vI97YqjWYkOYV52HGzRtHXIQFfpgxwlHkGaO8YDv3aO3V-PwM2SI4qxPty6ZMlK0siv1-lAizSl9hf_6RASDqzNrSfEmIeMdu8UeSTsRhu4Sk1Ofg6Uw8CPPuK.png" alt=""></p><figcaption>Database restoration from recent backup</figcaption></figure><p>‍</p><div><p>The drawback here is that the DB will not scale automatically so your will have to make sure that your application does not use storage beyond what is available in the instance you select. We do this by regularly purging our Database of data that is older than X days and data that belongs to users who churned from our app more than X days ago and haven’t come back since.&nbsp;</p></div><p><strong>Caching instances</strong></p><p><strong>‍</strong><br></p><p>For our application we needed a Caching layer as well as the ability to queue up jobs that can be executed asynchronously. The seasoned folks here might have realised that the best tool to use for this is Redis and AWS has a service called ElastiCache which is Redis under the hood.&nbsp;</p><p>‍<br></p><p>Once again this would be a very safe choice to make because it is completely managed and scalable. Our need was a Redis instance with at least 6GB of memory and 2vCPUs and if we went with ElastiCache our cost would roughly come out to be 112$ a month, not to mention the additional cost of running our async workers somewhere else.</p><p>‍<br></p><p>I might sound like a broken record at this point but what we ended up doing was to provision a Lightsail instance with 2vCPUs and 8GB of memory for the cost of 40$ a month and installed an open source version of Redis on this instance. We also use the same instance to run our asynchronous workers which read from the Redis queue and execute jobs.&nbsp;</p><p>‍<br></p><p>So what is the drawback? Well since it is not a managed service, you would have to monitor the Redis server yourself. There are many tools out there that help you do this and the one I would recommend is<a href="http://prometheus.io/" target="_blank"> prometheus.io</a>.</p><p>‍<br></p><p>This means that you have to do a little bit of extra work to setup metrics collection from your Redis instance and use a grafana dashboard where you can view these metrics, but this extra work saves a lot of money in the long run and you get to look at a super cool dashboard like this one</p><figure id="w-node-ed9ef23d383f-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b6832df460f9189c1ef_8fAYGJqB0CXvglSTkg-wXPXqpKi2e3fusNyMcOaiepfnZ-dC1kjn2Do44sILw5lbKOSISB1CMTEdCzyqBcyggDwK4tJcDEA17xkWXb2J1tUjLHBJgtMa_t3ekfIUfOiImx5IaZd6.png" alt=""></p><figcaption>Grafana dashboard for monitoring redis instance</figcaption></figure><p><strong>CDN</strong></p><p><strong>‍</strong><br></p><p>Our application requires a javascript file to be loaded into the websites of our customers. This JS file gets a ton of traffic because this traffic scales according to how many visitors our customers get. Now this can be scary because it means we really had no idea how many requests the JS file might actually end up receiving so we hesitated to go with CloudFront which is the goto solution for a CDN on AWS.&nbsp;</p><p>‍<br></p><p>So we ended up taking an entirely different approach for this. Our application is a Shopify app and during the process of building the application we created a Shopify store. Every Shopify store gets its own personal CDN where you can manually upload anything and it will be served over the Shopify CDN. So we minified and uploaded our JS file to the CDN of our Shopify store and now we serve 20000 Shopify stores using this method at zero cost.</p><figure id="w-node-78b80f124ebd-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef71b68374cfd3932d127f5_z2vfALB6_5FJXMp4al-65PIczwKOE-wUb0TubqBXAFMiu0rnqPEKGAOl12Saf0Xn-Ay1DjWL7wIj7Vby1sNPfLHkpuXzHf17ytoJ5gQvql13DZl1BsIV2rJPeHgfnCnIdezWiddG.png" alt=""></p><figcaption>Shopify CDN&nbsp;that is free of cost</figcaption></figure><p>There is a glaring drawback to this approach. The Shopify store CDN does not provide an API that you can use to programmatically upload files and it has to be done manually. Also unlike CloudFront, there is no option of invalidating a file once it is uploaded. So If you have to make updates to your file you would have to upload a new file and migrate all of your existing users to this new file.&nbsp;<br></p><p>‍</p><p>This might sound like a big drawback, but it actually took me an hour to whip up a script that updates the JS file for all our existing 20000 stores to the updated JS file that I provide. So whenever I make a new release to this JS file, I simply upload a new file manually to the CDN, then take that file as the input and run this script and we re live! This approach works for us because we do not make too many releases to the JS&nbsp;file to begin with.</p><p><strong>Web server + load balancer</strong></p><p><strong>‍</strong><br></p><p>Every application requires the ability to route requests coming to their domain or subdomain to various applications running under the hood. The best way to do this is to use AWS ELB which can be used to automatically distribute incoming application traffic across multiple targets, such as Amazon EC2 instances, containers, IP addresses, and Lambda functions.&nbsp;</p><p>‍<br></p><p>This sounds quite fancy, but all we needed for our product was 4 things</p><p>‍</p><ul role="list"><li>Serving static files for our application dashboard</li><li>Distribute traffic among different Lightsail instances based on the path of the incoming URL</li><li>Load balance traffic that comes from our Merchants Shopify stores amongst N identical Lightsail instances.</li><li>Rate limiting of requests to prevent DDOS attacks.</li></ul><p>‍<br></p><p>All of this can be done using NGINX which is a great piece of software and is quite robust even with the default settings that it comes with.&nbsp;<br></p><p>So we simply installed a stable version of NGINX on one of our existing Lightsail instances which was already being used to host one of our server applications. We also use<a href="http://amplify.nginx.com/" target="_blank"> amplify.nginx.com</a> for monitoring it. This setup is pretty much equivalent to using a managed service at zero cost.</p><p>‍</p><figure id="w-node-26b2c44e15ee-87eecd11"><p><img src="https://uploads-ssl.webflow.com/5e0b01877436086c8beecd1a/5ef730c34b26677e785fa7ea_w67-tKkFsy_LekSEhO_PXqnHGxDiREqENBgMBaEAOqotyjEDJoKXRk6Wpd5K86OOv2z_S-ejGOnL37l6lj6MWqE_x2ZvrIZ4FCQraAC1uDWMne7yi0Fme4Jap2sp2uH2zrKdvpTz.png" alt=""></p><figcaption>Amplify dashboard for monitoring health of the NGINX server</figcaption></figure><p>‍</p><p><strong>Summary</strong></p><p>‍</p><ul role="list"><li>Use lightsail instances (20$ per instance) instead of EC2 instances (37$ per instance)</li><li>Use a lightsail database (60$ per DB) instead of RDS (200$ per DB)</li><li>Use a self hosted redis server on a compute instance (40$) instead of ElastiCache (112$)&nbsp;</li><li>If feasible, use a free CDN (cost savings depends on traffic size)</li><li>Use a self hosted NGINX server (20$ fixed cost) instead of ELB (cost depends on traffic and usage)</li></ul><p><strong>Closing notes</strong></p><p><strong>‍</strong><br></p><p>I would like to put emphasis on the fact that we are a micro-SaaS product that solves a small and specific use case and therefore this kind of AWS setup worked for us. This may not work for big organisations or products where the traffic is erratic.&nbsp;</p><p>This setup will also not work for folks who have a ton of stuff to do already and would prefer to use managed services and not take the additional headache of monitoring, maintaining and provisioning hardware resources on a regular basis because this has a time cost to it.</p><p>We are a team of 2 people with a product that is not computation heavy and has cloud requirements that are quite straightforward. We have been running this product for a little over 1 year with this AWS setup and so far we have not encountered any problems.</p></div></div>]]>
            </description>
            <link>https://www.sankalpjonna.com/posts/our-aws-bill-is-2-of-revenue-heres-how-we-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666999</guid>
            <pubDate>Sun, 28 Jun 2020 05:58:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Should I learn UIKit or SwiftUI?]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23666923">thread link</a>) | @sarunw
<br/>
June 27, 2020 | https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/ | <a href="https://web.archive.org/web/*/https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>            
      
<section>
<div>
    <div>        

      

      <hr>

      
        
        
      

      
            

      <p>SwiftUI feels very young when it first announced last year in WWDC19. It shows a promising future, but it has a rough edge here and there, and it quite hard to predict what it will be like in a year. The year has passed, and here is my thought on Apple's new declarative UI framework SwiftUI.</p>
<h2 id="the-gap-is-getting-closer">The gap is getting closer <a href="#the-gap-is-getting-closer">#</a></h2>
<p>My arguments around SwiftUI are always like, "You can't do x (UIKit features) in SwiftUI". This year, Apple show an incredible pace of SwiftUI development. The missing UI elements from last year already have a SwiftUI counterpart, e.g., <code>UIColelctionView</code> and <code>UITextField</code> already have a SwiftUI counterpart of <code>LazyH/VGrid</code> and <code>TextEditor</code>.</p>
<h2 id="first-class-citizen">First-class citizen <a href="#first-class-citizen">#</a></h2>
<p>It looks like SwiftUI doesn't want to be just a view for UIKit anymore. Now, you can write an entire app using pure SwiftUI.</p>
<p>The following is a working SwiftUI app code.</p>
<pre><code><span><span>import</span> <span>SwiftUI</span></span><br><span></span><br><span>@main</span><br><span><span>struct</span> <span>SwiftUIApp</span><span>:</span> <span>App</span> <span>{</span></span><br><span>    <span>var</span> body<span>:</span> some <span>Scene</span> <span>{</span></span><br><span>        <span>WindowGroup</span> <span>{</span></span><br><span>            <span>Text</span><span>(</span><span>"Hello! SwiftUI"</span><span>)</span></span><br><span>        <span>}</span></span><br><span>    <span>}</span></span><br><span><span>}</span></span></code></pre>
<p>And the code above not just works on iOS, but the same code can make an iPad and Mac app. You can write a multiplatform app entirely with SwiftUI. Seem like the concepts of SwiftUI are far more powerful than I first thought.</p>
<h2 id="exclusive-deal">Exclusive Deal <a href="#exclusive-deal">#</a></h2>
<p><a href="https://developer.apple.com/documentation/widgetkit" target="_blank" rel="nofollow noopener">WidgetKit</a>, a new framework in iOS 14 for writing a Widget can only write using SwiftUI. This means you can't run away from it, even you love UIKit, it seems like you have no choice, but to also learn SwiftUI.</p>
<figure>
  <img src="https://d33wubrfki0l68.cloudfront.net/29ba6373e9bf92bbbc301e0f6fb491f3cf51920a/819cd/images/swiftui-2-widget.png" alt="Widget">
  <figcaption>Widget</figcaption>
</figure>
<h2 id="is-uikit-going-to-die%3F">Is UIKit going to die? <a href="#is-uikit-going-to-die%3F">#</a></h2>
<p>Nope, it is far from over. I don't think Apple has a plan to drop UIKit in the foreseeable future. As working on UIKit for years, SwiftUI feels like magic to me. It can replicate UIKit function with a single line of code (or no line of code since it builds right into SwiftUI). The bad thing about magic is that when things are not going as you want, it is hard to figure out what's wrong, and it might not be possible to fix it. That's when you need to go back to UIKit. UIKit is a foundation of iOS, and Apple still keeps adding new features to it (UICollectionView and UISplitViewController got a lot of cool features this year, you should check it out).</p>
<p>I see UIKit as a secret sauce behind all SwiftUI magic. Both UIKit and SwiftUI have their strength, and Apple picks the right tool for the right job (they use SwiftUI for WidgetKit because it suits the constraint that Widget has right now). I think these two will coexist for a very long time.</p>
<p>Apple put years of experience in their UIKit and tools into SwiftUI. It is enjoyable to work with, and the outcome is phenomenal. Apple can do this because they set up a way to bridge SwiftUI to UIKit, so they know that even when SwiftUI fails to do some tasks, there will always have UIKit there.</p>
<h2 id="conclusion">Conclusion <a href="#conclusion">#</a></h2>
<p>Here comes the important question. Should you learn UIKit or SwiftUI?</p>
<p>My short answer would be <strong>SwiftUI</strong>.</p>
<p>And here is my long answer. From all the facts I point out in this article, SwiftUI is ready now. I think in the end you would end up learning both of them.</p>
<p>If you know UIKit, you are forced to learn SwiftUI since it is exclusive to a new framework like WidgetKit. Even not for that reason, I think you probably the one who appreciates SwiftUI the most. SwiftUI can do many great things right out of the box, things that we always want to do in UIKit, but don't have the opportunity and time to do it.</p>
<p>If you know SwiftUI, there would be a time that you want extra customization or hit some roadblock. When the time comes, UIKit will always there for you.</p>



      <hr>
      
      <p>Feel free to follow me on <a rel="nofollow noopener" href="https://twitter.com/sarunw" target="_blank">Twitter</a> and ask your questions related to this post. Thanks for reading and see you next time.</p>
      
      

      

      

      

      



      <p><a href="https://sarunw.com/">← Home</a></p>


      
  </div>
</div>
</section>            
    </div></div>]]>
            </description>
            <link>https://sarunw.com/posts/should-i-learn-uikit-or-swiftui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666923</guid>
            <pubDate>Sun, 28 Jun 2020 05:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adventures in booting Linux on Raspberry Pi 4]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23666564">thread link</a>) | @todsacerdoti
<br/>
June 27, 2020 | https://blog.mostlypointless.dev/posts/net-boot-rpi/ | <a href="https://web.archive.org/web/*/https://blog.mostlypointless.dev/posts/net-boot-rpi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <article>
        
        
            <span> Jun 26, 2020</span>
            
                <a href="https://blog.mostlypointless.dev/tags/linux">linux</a>
            
                <a href="https://blog.mostlypointless.dev/tags/raspberry-pi">raspberry pi</a>
            
        
        <p>Almost two months ago, I started building a four node Raspberry Pi 4 cluster for a project I’m working on. Figuring out the best way to get Linux on each node lead me down a rabbit hole and I spent the next four weeks <a href="http://www.catb.org/~esr/jargon/html/Y/yak-shaving.html">yak shaving</a>.</p>
<p>The most common way to boot a Pi is from an SD card. But they are slow and unreliable - I don’t like them. Certain models of Pi 2 and Pi 3 support <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/msd.md">booting from USB storage</a>, but Pi 4 cannot do that yet. So, I’m stuck with using an SD card for each Pi. Or so I thought.</p>
<h3 id="enter-pxe-boot">Enter PXE boot</h3>
<p>Turns out, Raspberry Pi 2 and 3 also <a href="https://www.raspberrypi.org/documentation/hardware/raspberrypi/bootmodes/net.md">support network booting</a>. A beta firmware was released late last year that enables <a href="https://en.wikipedia.org/wiki/Preboot_Execution_Environment">PXE</a> for Pi 4. I found <a href="https://linuxhit.com/raspberry-pi-pxe-boot-netbooting-a-pi-4-without-an-sd-card">an article on LinuxHit</a> detailing the process of installing the firmware and setting up network boot.</p>
<p>Just to test this out, I updated the firmware and configured PXE server on one of the Pis. I tried booting another Pi over the network and…it worked!
Here is the gist of PXE server setup process:</p>
<ol>
<li>Copy the contents of <code>/boot</code> and the rest of <code>/</code> into separate folders on your local filesystem. I copied mine to <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code> respectively.</li>
<li>Install and configure <code>dnsmasq</code> to enable TFTP and use <code>/tftp</code> as <code>tftp-root</code></li>
<li>Install and configure NFS server to share <code>/tftp/raspbian-boot</code> and <code>/nfs/raspbian-root</code></li>
<li>Edit the contents of <code>/nfs/raspbian-root/fstab</code> to mount the boot partition.</li>
<li>Edit <code>/nfs/raspbian-boot/cmdline.txt</code> to</li>
</ol>
<div><pre><code data-lang="bash">console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/raspbian-root,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><h3 id="pxe-booting-3-nodes-using-overlayfs">PXE booting 3 nodes using OverlayFS</h3>
<p>I cannot just boot all three nodes from the same boot and root filesystems since they are not read-only. And I don’t want to maintain a copy of these for each node. But this is a solved problem - Docker already lets you spin up multiple containers from a single base image. So I’ll just do <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/#how-the-overlay2-driver-works">what Docker does</a> - create <a href="https://www.kernel.org/doc/html/latest/filesystems/overlayfs.html">OverlayFS</a> for each node using raspbian-root and raspbian-boot as my lower directories. I’ll share them over NFS like before.</p>
<p>Configuration for one of the nodes is below. Other two nodes follow the same pattern. Note that I moved raspbian-root and raspbian-boot to a USB hard drive (mounted at <code>/mnt</code>) to get better r/w performance. dc-a6-32-XX-XX-XX is the MAC address of the node. I’m using <code>tftp-unique-root=mac</code> option in <code>dnsmasq</code> to maintain a separate boot environment for each node based on its MAC address.</p>
<div><pre><code data-lang="bash">$ mount -t overlay nog-boot -o lowerdir<span>=</span>/mnt/raspbian-boot,upperdir<span>=</span>/mnt/upper/nog-boot,workdir<span>=</span>/mnt/work/nog-boot -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /tftpboot/dc-a6-32-XX-XX-XX

$ mount -t overlay nog-root -o lowerdir<span>=</span>/mnt/raspbian-root,upperdir<span>=</span>/mnt/work/nog-root,workdir<span>=</span>/mnt/work/nog-root -o nfs_export<span>=</span>on -o index<span>=</span>on -o redirect_dir<span>=</span>nofollow /nfs/nog

$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>(In case you are wondering what <code>nog</code> is: I name my servers after planets from the Star Wars universe. Following this tradition, I’ve named the Pis Mandalore (PXE server), Nog, Ordo and Werda)</p>
<p>You are probably thinking that this worked. It did not.</p>
<p>NFS and OverlayFS did not play nice with each other. After a weekend trying to work around some weird issues, I gave up.</p>
<p>But OverlayFS is not the only copy-on-write filesystem in existence, is it? ZFS and BTRFS offer <a href="https://btrfs.wiki.kernel.org/index.php/Manpage/btrfs-subvolume">subvolumes and snapshots</a> that I can use instead. But not before I <del>procrastinate</del> spend 2 weeks deciding which one to use.</p>
<h3 id="moving-to-btrfs">Moving to BTRFS</h3>
<p>The plan is simple: I’ll create a subvolume each for raspbian-root and raspbian-boot. I’ll then create three snapshots of each subvolume - one for every node. I created a <a href="https://en.wikipedia.org/wiki/RAS_syndrome">btrfs file system</a> on my external drive and ran the following commands</p>
<div><pre><code data-lang="bash">$ btrfs subvolume create raspbian-root
$ btrfs subvolume create raspbian-boot

<span># Repeat the following for each node changing folder names as necessary</span>
$ btrfs subvolume snapshot raspbian-boot nog-boot
$ btrfs subvolume snapshot raspbian-root nog-root
$ mount --bind /mnt/nog-boot /tftpboot/dc-a6-32-XX-XX-XX
$ mount --bind /mnt/nog-root /nfs/nog

<span># Don’t forget to edit cmdline.txt for each node</span>
$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>/dev/nfs nfsroot<span>=</span>&lt;IP addr&gt;:/nfs/nog,vers<span>=</span>4.1,proto<span>=</span>tcp rw ip<span>=</span>dhcp rootwait elevator<span>=</span>deadline
</code></pre></div><p>Well, this worked! I have a Pi running without an SD card!! Now all I have to do is create systemd unit files to start all required services and mount snapshots. I can finally start working on my project.</p>
<p>Wait a minute. Take a closer look at the output of <code>cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.
If you are like me, you will realize for the first time that <code>root=</code> in this file defines where the root filesystem will be mounted from. Right now, we are telling it to mount from <code>/dev/nfs</code>. What if I attach an external drive and set <code>root=</code> to point to the external drive?</p>
<h3 id="network-booting-into-a-usb-hard-drive">Network booting into a USB hard drive</h3>
<p>RPi 4 cannot directly boot from a USB drive. As in - it cannot find <code>/boot</code> on a USB drive when powering on. But what if we provide <code>/boot</code> with network boot and mount <code>/</code> from a USB drive using <code>cmdline.txt</code>? Time to test.</p>
<p>I copied raspbian-root to a USB drive, edited <code>fstab</code> to mount <code>/</code> using the partition’s PARTUUID and connected it to Nog. I then updated the contents of <code>/tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt</code>.</p>
<div><pre><code data-lang="bash">$ cat /tftpboot/dc-a6-32-XX-XX-XX/cmdline.txt
 console<span>=</span>serial0,115200 console<span>=</span>tty1 root<span>=</span>PARTUUID<span>=</span>c1f95d14-01 rootfstype<span>=</span>ext4 elevator<span>=</span>deadline fsck.repair<span>=</span>yes rootwait
</code></pre></div><p>After a couple of reboots, it worked! I now have a RPi 4 running off a USB hard drive!</p>
<h3 id="what-did-i-gain">What did I gain?</h3>
<p>Let’s start with what I was looking for. All I wanted was to not deal with SD cards because they are slow and unreliable. Reliability is relative - everything fails at some point. But a decent quality USB hard drive will likely outlive an SD card. So let’s just look at some read/write performance numbers and see how they compare.</p>
<div><pre><code data-lang="bash">$ sync; dd <span>if</span><span>=</span>/dev/zero of<span>=</span>twogeefile bs<span>=</span>1M count<span>=</span>2048; sync  <span># Write performance</span>
$ sudo sh -c <span>"sync &amp;&amp; echo 3 &gt; /proc/sys/vm/drop_caches"</span>
$ dd <span>if</span><span>=</span>twogeefile of<span>=</span>/dev/null bs<span>=</span>1M count<span>=</span><span>2048</span>              <span># Read performance</span>
</code></pre></div><table>
<thead>
<tr>
<th>Storage</th>
<th>Read (MB/s)</th>
<th>Write (MB/s)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sandisk Ultra MicroSDXC Class 10</td>
<td>45.7</td>
<td>20.2</td>
</tr>
<tr>
<td>Network Boot with BTRFS</td>
<td>63.3</td>
<td>18.8</td>
</tr>
<tr>
<td>/ mounted from USB hard drive</td>
<td>113.0</td>
<td>92.7</td>
</tr>
</tbody>
</table>
<p>With network boot, I was able to get read and write speeds similar to a class 10 SD card. Note that the boot images are hosted on a USB hard drive connected to Mandalore (PXE server). NFS seems to be the bottleneck here - raw r/w speeds of the hard drive are much better than this. All Pis are connected to Netgear’s 8 port gigabit ethernet switch.</p>
<p>To no one’s surprise, things improve considerably when Pis are running off a USB hard disk. Note that the external drives I used are 5400RPM hard disks repurposed from very old MacBooks. I bought them on eBay for $10 a pop. YMMV.</p>
<h3 id="current-setup">Current setup</h3>
<p>Right now, I have Mandalore booting from an SD card and <code>/</code> mounted from a USB hard disk. Nog, Ordo and Werda fetch <code>/boot</code> from Mandalore over the network and <code>/</code> mounted from a USB hard disk.</p>
<p><img src="https://blog.mostlypointless.dev/img/pi-cluster.jpg" alt="from top to bottom - Mandalore, Nog, Ordo, Werda"></p>
<p>I can finally start working on my proj… wait, what?</p>
<p><a href="https://www.tomshardware.com/how-to/boot-raspberry-pi-4-usb">A new beta firmware is out for RPi 4 that lets you boot from USB drives directly.</a></p>
<p>Oh well…</p>
<p>¯\_(ツ)_/¯</p>
<p><em><strong>Update:</strong> This post was discussed on <a href="https://news.ycombinator.com/item?id=23666564">Hacker News</a>. As jordybg <a href="https://news.ycombinator.com/item?id=23667247">points out</a>, USB boot is no longer “beta” and is available in the latest (2020-06-15) “stable” firmware release.</em></p>

        
    </article>
</div></div>]]>
            </description>
            <link>https://blog.mostlypointless.dev/posts/net-boot-rpi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666564</guid>
            <pubDate>Sun, 28 Jun 2020 03:28:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebTransport API]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 43 (<a href="https://news.ycombinator.com/item?id=23666364">thread link</a>) | @Jarred
<br/>
June 27, 2020 | https://wicg.github.io/web-transport/ | <a href="https://web.archive.org/web/*/https://wicg.github.io/web-transport/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="introduction"><span>1. </span><span>Introduction</span><a href="#introduction"></a></h2>
   <p><em>This section is non-normative.</em></p>
   <p>This specification uses pluggable protocols, with QUIC <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a> as
one such protocol, to send data to and receive data from servers. It can be
used like WebSockets but with support for multiple streams, unidirectional
streams, out-of-order delivery, and reliable as well as unreliable transport.</p>
   <p role="note"><span>Note:</span> The API presented in this specification represents a preliminary proposal
based on work-in-progress within the IETF QUIC WG. Since the QUIC transport
specification is a work-in-progress, both the protocol and API are likely to
change significantly going forward.</p>
   <h2 data-level="2" id="conformance"><span>2. </span><span>Conformance</span><a href="#conformance"></a></h2>
   <p>As well as sections marked as non-normative, all authoring guidelines,
diagrams, examples, and notes in this specification are non-normative.
Everything else in this specification is normative.</p>
   <p>The key words <em>MUST</em> and <em>SHOULD</em> are to be interpreted as described in <a data-link-type="biblio" href="#biblio-rfc2119">[RFC2119]</a>.</p>
   <p>This specification defines conformance criteria that apply to a single product:
the user agent that implements the interfaces that it contains.</p>
   <p>Conformance requirements phrased as algorithms or specific steps may be
implemented in any manner, so long as the end result is equivalent. (In
particular, the algorithms defined in this specification are intended to be
easy to follow, and not intended to be performant.)</p>
   <p>Implementations that use ECMAScript to implement the APIs defined in this
specification MUST implement them in a manner consistent with the ECMAScript
Bindings defined in the Web IDL specification <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>, as this
specification uses that specification and terminology.</p>
   <h2 data-level="3" id="terminology"><span>3. </span><span>Terminology</span><a href="#terminology"></a></h2>
   <p>The <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#eventhandler" id="ref-for-eventhandler">EventHandler</a></code> interface, representing a callback used for event
handlers, and the <code><a data-link-type="idl" href="https://html.spec.whatwg.org/multipage/webappapis.html#errorevent" id="ref-for-errorevent">ErrorEvent</a></code> interface are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The concepts <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#queue-a-task" id="ref-for-queue-a-task">queue a task</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#networking-task-source" id="ref-for-networking-task-source">networking task source</a> are defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="https://dom.spec.whatwg.org/#concept-event" id="ref-for-concept-event">event</a>, <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handlers" id="ref-for-event-handlers">event handlers</a> and <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/webappapis.html#event-handler-event-type" id="ref-for-event-handler-event-type">event handler event types</a> are
defined in <a data-link-type="biblio" href="#biblio-html">[HTML]</a>.</p>
   <p>When referring to exceptions, the terms <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-throw" id="ref-for-dfn-throw">throw</a> and <a data-link-type="dfn" href="https://heycam.github.io/webidl/#dfn-create-exception" id="ref-for-dfn-create-exception">create</a> are defined in <a data-link-type="biblio" href="#biblio-webidl">[WEBIDL]</a>.</p>
   <p>The terms <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects">fulfilled</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①">rejected</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects②">resolved</a>, <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects③">pending</a> and <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects④">settled</a> used in the context of Promises are defined in <a data-link-type="biblio" href="#biblio-ecmascript-60">[ECMASCRIPT-6.0]</a>.</p>
   <p>The terms <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream">ReadableStream</a></code> and <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream">WritableStream</a></code> are defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.  Note that despite sharing the name "stream", these are
distinct from the IncomingStream, OutgoingStream, and BidirectionalStream
defined here. The IncomingStream, OutgoingStream, and BidirectionalStream
defined here correspend to a higher level of abstraction that contain and
depend on the lower-level concepts of "streams" defined in <a data-link-type="biblio" href="#biblio-whatwg-streams">[WHATWG-STREAMS]</a>.</p>
   <h2 data-level="4" id="unidirectional-streams-transport"><span>4. </span><span><code>UnidirectionalStreamsTransport</code> Mixin</span><a href="#unidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="unidirectionalstreamstransport"><code>UnidirectionalStreamsTransport</code></dfn> can send and receive
unidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order.  Data is generally sent
reliably, but retransmissions may be disabled or the stream may aborted to
produce a form of unreliability.  All stream data is encrypted and
congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#unidirectionalstreamstransport" id="ref-for-unidirectionalstreamstransport"><c- g="">UnidirectionalStreamsTransport</c-></a> {
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#sendstream" id="ref-for-sendstream"><c- n="">SendStream</c-></a>&gt; <a data-link-type="method" href="#dom-unidirectionalstreamstransport-createsendstream" id="ref-for-dom-unidirectionalstreamstransport-createsendstream"><c- g="">createSendStream</c-></a>(<c- b="">optional</c-> <a data-link-type="idl-name" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters"><c- n="">SendStreamParameters</c-></a> <dfn data-dfn-for="UnidirectionalStreamsTransport/createSendStream(parameters), UnidirectionalStreamsTransport/createSendStream()" data-dfn-type="argument" data-export="" id="dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"><code><c- g="">parameters</c-></code><a href="#dom-unidirectionalstreamstransport-createsendstream-parameters-parameters"></a></dfn> = {});
  <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream①"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-unidirectionalstreamstransport-receivestreams" id="ref-for-dom-unidirectionalstreamstransport-receivestreams"><c- g="">receiveStreams</c-></a>();
};
</pre>
   <h3 data-level="4.1" id="#unidirectional-streams-transport-methods"><span>4.1. </span><span>Methods</span><a href="#%23unidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" data-lt="createSendStream(parameters)|createSendStream()" id="dom-unidirectionalstreamstransport-createsendstream"><code>createSendStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream①">SendStream</a></code> object.</p>
     <p>When <code>createSendStream()</code> method is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>createSendStream</code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑤">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑥">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#sendstream" id="ref-for-sendstream②">SendStream</a></code> object and <a data-link-type="dfn" href="#add-the-sendstream" id="ref-for-add-the-sendstream">add the
  SendStream</a> to <var>transport</var> when all of the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state①">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint.  For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑦">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑧">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror①">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects⑨">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="UnidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-unidirectionalstreamstransport-receivestreams"><code>receiveStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream②">ReadableStream</a></code> of <code><a data-link-type="idl" href="#receivestream" id="ref-for-receivestream">ReceiveStream</a></code>s that have been received
 from the remote host.</p>
     <p>When <code>receiveStreams</code> is called, the user agent MUST run the following
 steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>UnidirectionalStreamsTransport</code> on which <code>receiveStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot">[[ReceivedStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each unidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#incomingstream" id="ref-for-incomingstream">IncomingStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedstreams-slot" id="ref-for-dom-quictransport-receivedstreams-slot①">[[ReceivedStreams]]</a></code>. As data
  is received over the unidirectional stream, insert that data into the
  corresponding <code>IncomingStream</code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code>IncomingStream</code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="4.2" id="#unidirectional-streams-transport-procedures"><span>4.2. </span><span>Procedures</span><a href="#%23unidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="4.2.1" id="add-sendstream"><span>4.2.1. </span><span>Add SendStream to UnidirectionalStreamsTransport</span><a href="#add-sendstream"></a></h4>
   
   <h3 data-level="4.3" id="send-stream-parameters"><span>4.3. </span><span>SendStreamParameters Dictionary</span><a href="#send-stream-parameters"></a></h3>
   <p>The <dfn data-dfn-type="dictionary" data-export="" id="dictdef-sendstreamparameters"><code>SendStreamParameters</code></dfn> dictionary includes information
relating to stream configuration.</p>
<pre><c- b="">dictionary</c-> <a data-link-type="dictionary" href="#dictdef-sendstreamparameters" id="ref-for-dictdef-sendstreamparameters①"><c- g="">SendStreamParameters</c-></a> {
};
</pre>
   <h2 data-level="5" id="bidirectional-streams-transport"><span>5. </span><span><code>BidirectionalStreamsTransport</code> Mixin</span><a href="#bidirectional-streams-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="bidirectionalstreamstransport"><code>BidirectionalStreamsTransport</code></dfn> can send and receive
bidirectional streams.  Data within a stream is delivered in order, but data
between streams may be delivered out of order. Data is generally sent reliably,
but retransmissions may be disabled or the stream may aborted to produce a form
of unreliability.  All stream data is encrypted and congestion-controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport"><c- g="">BidirectionalStreamsTransport</c-></a> {
    <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#bidirectionalstream" id="ref-for-bidirectionalstream"><c- n="">BidirectionalStream</c-></a>&gt; <a data-link-type="method" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream"><c- g="">createBidirectionalStream</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream③"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-bidirectionalstreamstransport-receivebidirectionalstreams" id="ref-for-dom-bidirectionalstreamstransport-receivebidirectionalstreams"><c- g="">receiveBidirectionalStreams</c-></a>();
};
</pre>
   <h3 data-level="5.1" id="#bidirectional-streams-transport-methods"><span>5.1. </span><span>Methods</span><a href="#%23bidirectional-streams-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-createbidirectionalstream"><code>createBidirectionalStream()</code></dfn>
    </dt><dd data-md="">
     <p>Creates a <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream①">BidirectionalStream</a></code> object.</p>
     <p>When <code>createBidirectionalStream</code> is called, the user agent MUST run the
 following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#bidirectionalstreamstransport" id="ref-for-bidirectionalstreamstransport①">BidirectionalStreamsTransport</a></code> on which <code><a data-link-type="idl" href="#dom-bidirectionalstreamstransport-createbidirectionalstream" id="ref-for-dom-bidirectionalstreamstransport-createbidirectionalstream①">createBidirectionalStream</a></code> is invoked.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state②">state</a></code> is <code>"closed"</code> or <code>"failed"</code>,
  immediately return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⓪">rejected</a> promise with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror②">InvalidStateError</a></code> and abort these steps.</p>
      </li><li data-md="">
       <p>If <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state③">state</a></code> is <code>"connected"</code>, immediately
  return a new <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①①">fulfilled</a> promise with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream②">BidirectionalStream</a></code> object, <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream">add the BidirectionalStream</a> to the
  transport and abort these steps.</p>
      </li><li data-md="">
       <p>Let <var>p</var> be a new promise.</p>
      </li><li data-md="">
       <p>Return <var>p</var> and continue the following steps in background.</p>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①②">Resolve</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream③">BidirectionalStream</a></code> object and <a data-link-type="dfn" href="#add-the-bidirectionalstream" id="ref-for-add-the-bidirectionalstream①">add the BidirectionalStream</a> to <var>transport</var> when all of the following
  conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s <code><a data-link-type="idl" href="#dom-webtransport-state" id="ref-for-dom-webtransport-state④">state</a></code> has transitioned to <code>"connected"</code>.</p>
        </li><li data-md="">
         <p>Stream creation flow control is not being violated by exceeding the
  max stream limit set by the remote endpoint. For QUIC, this is
  specified in <a data-link-type="biblio" href="#biblio-quic-transport">[QUIC-TRANSPORT]</a>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①③">settled</a>.</p>
       </li></ol>
      </li><li data-md="">
       <p><a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①④">Reject</a> <var>p</var> with a newly created <code><a data-link-type="idl" href="https://heycam.github.io/webidl/#invalidstateerror" id="ref-for-invalidstateerror③">InvalidStateError</a></code> when all of
  the following conditions are met:</p>
       <ol>
        <li data-md="">
         <p>The <var>transport</var>’s state transitions to <code>"closed"</code> or <code>"failed"</code>.</p>
        </li><li data-md="">
         <p><var>p</var> has not been <a data-link-type="dfn" href="http://www.ecma-international.org/ecma-262/6.0/index.html#sec-promise-objects" id="ref-for-sec-promise-objects①⑤">settled</a>.</p>
       </li></ol>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="BidirectionalStreamsTransport" data-dfn-type="method" data-export="" id="dom-bidirectionalstreamstransport-receivebidirectionalstreams"><code>receiveBidirectionalStreams()</code></dfn>
    </dt><dd data-md="">
     <p>Returns a <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream④">ReadableStream</a></code> of <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream④">BidirectionalStream</a></code>s that have been
 received from the remote host.</p>
     <p>When <code>receiveBidirectionalStreams</code> method is called, the user agent MUST run
 the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code>BidirectionalStreamsTransport</code> on which <code>receiveBidirectionalStreams</code> is invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot">[[ReceivedBidirectionalStreams]]</a></code> internal slot.</p>
      </li><li data-md="">
       <p>For each bidirectional stream received, create a corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑤">BidirectionalStream</a></code> and insert it into <code><a data-link-type="idl" href="#dom-quictransport-receivedbidirectionalstreams-slot" id="ref-for-dom-quictransport-receivedbidirectionalstreams-slot①">[[ReceivedBidirectionalStreams]]</a></code>.
  As data is received over the bidirectional stream, insert that data into the
  corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑥">BidirectionalStream</a></code>.  When the remote side closes or aborts
  the stream, close or abort the corresponding <code><a data-link-type="idl" href="#bidirectionalstream" id="ref-for-bidirectionalstream⑦">BidirectionalStream</a></code>.</p>
     </li></ol>
   </dd></dl>
   <h3 data-level="5.2" id="#bidirectional-streams-transport-procedures"><span>5.2. </span><span>Procedures</span><a href="#%23bidirectional-streams-transport-procedures"></a></h3>
   <h4 data-level="5.2.1" id="add-bidirectionalstream"><span>5.2.1. </span><span>Add BidirectionalStream to BidirectionalStreamsTransport</span><a href="#add-bidirectionalstream"></a></h4>
   
   <h2 data-level="6" id="datagram-transport"><span>6. </span><span><code>DatagramTransport</code> Mixin</span><a href="#datagram-transport"></a></h2>
   <p>A <dfn data-dfn-type="interface" data-export="" id="datagramtransport"><code>DatagramTransport</code></dfn> can send and receive datagrams.
Datagrams are sent out of order, unreliably, and have a limited maximum size.
Datagrams are encrypted and congestion controlled.</p>
<pre><c- b="">interface</c-> <c- b="">mixin</c-> <a data-link-type="interface" href="#datagramtransport" id="ref-for-datagramtransport"><c- g="">DatagramTransport</c-></a> {
    <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short"><c- b="">unsigned</c-> <c- b="">short</c-></a> <a data-link-type="attribute" data-readonly="" data-type="unsigned short" href="#dom-datagramtransport-maxdatagramsize" id="ref-for-dom-datagramtransport-maxdatagramsize"><c- g="">maxDatagramSize</c-></a>;
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream①"><c- n="">WritableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams"><c- g="">sendDatagrams</c-></a>();
    <a data-link-type="idl-name" href="https://streams.spec.whatwg.org/#readablestream" id="ref-for-readablestream⑤"><c- n="">ReadableStream</c-></a> <a data-link-type="method" href="#dom-datagramtransport-receivedatagrams" id="ref-for-dom-datagramtransport-receivedatagrams"><c- g="">receiveDatagrams</c-></a>();
};
</pre>
   <h3 data-level="6.1" id="datagram-transport-attributes"><span>6.1. </span><span>Attributes</span><a href="#datagram-transport-attributes"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="attribute" data-export="" id="dom-datagramtransport-maxdatagramsize"><code>maxDatagramSize</code></dfn>, <span> of type <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#idl-unsigned-short" id="ref-for-idl-unsigned-short①">unsigned short</a>, readonly</span>
    </dt><dd data-md="">
     <p>The maximum size data that may be passed to <code><a data-link-type="idl" href="#dom-datagramtransport-senddatagrams" id="ref-for-dom-datagramtransport-senddatagrams①">sendDatagrams</a></code>.</p>
   </dd></dl>
   <h3 data-level="6.2" id="datagram-transport-methods"><span>6.2. </span><span>Methods</span><a href="#datagram-transport-methods"></a></h3>
   <dl>
    <dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-senddatagrams"><code>sendDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Sends datagrams that are written to the returned <code><a data-link-type="idl" href="https://streams.spec.whatwg.org/#writablestream" id="ref-for-writablestream②">WritableStream</a></code>.</p>
     <p>When <code>sendDatagrams</code> is called, the user agent MUST run the following steps:</p>
     <ol>
      <li data-md="">
       <p>Let <var>transport</var> be the <code><a data-link-type="idl" href="#datagramtransport" id="ref-for-datagramtransport①">DatagramTransport</a></code> on which <code>sendDatagram</code> is
  invoked.</p>
      </li><li data-md="">
       <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-sentdatagrams-slot" id="ref-for-dom-quictransport-sentdatagrams-slot">[[SentDatagrams]]</a></code> internal slot.</p>
     </li></ol>
    </dd><dt data-md=""><dfn data-dfn-for="DatagramTransport" data-dfn-type="method" data-export="" id="dom-datagramtransport-receivedatagrams"><code>receiveDatagrams()</code></dfn>
    </dt><dd data-md="">
     <p>Return the value of the <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot">[[ReceivedDatagrams]]</a></code> internal slot.</p>
     <p>For each datagram received, insert it into <code><a data-link-type="idl" href="#dom-quictransport-receiveddatagrams-slot" id="ref-for-dom-quictransport-receiveddatagrams-slot①">[[ReceivedDatagrams]]</a></code>. If too
 many datagrams are queued because the stream is not being read quickly
 enough, drop datagrams to avoid queueing. Implementations should drop older
 datagrams in favor of newer datagrams. The number of datagrams to queue
 should be kept small enough to avoid adding significant latency to packet
 delivery when the stream is being read slowly (due to the reader being slow)
 but large enough to avoid dropping packets when for the stream is not read
 for short periods of time (due to the reader being paused).</p>
   </dd></dl>
   <h2 data-level="7" id="web-transport"><span>7…</span></h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wicg.github.io/web-transport/">https://wicg.github.io/web-transport/</a></em></p>]]>
            </description>
            <link>https://wicg.github.io/web-transport/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23666364</guid>
            <pubDate>Sun, 28 Jun 2020 02:26:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned about writing software in music school]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23665651">thread link</a>) | @while1malloc0
<br/>
June 27, 2020 | https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school | <a href="https://web.archive.org/web/*/https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5ef7bc76e6aaf04d0e009f94"><div><div><div data-block-type="44" id="block-af03afdb075005d5c151"><div><p>Like many software engineers in the industry, I don't have a Computer Science degree.
I spent my college years in music school, doing an undergraduate degree in jazz guitar performance and most of a graduate degree in music technology.
I've had the conversation about how music is like software a few times, and recently <a href="https://twitter.com/CatMcGeeCode/status/1272097365764300802?s=20">this tweet</a> got me reflecting about the things I apply in my technology career that I learned in music school.
While I might not have gone on to be a professional musician, it turns out that music school taught me many things that I still find valuable today.</p>
<p><strong>Focus on the (important) fundamentals</strong></p>
<p>Few classes in the traditional music school curriculum are as polarizing as the pair of music theory and ear training.
In a music theory class, you study the structural underpinnings of what most people refer to as Classical Music¹, and ear training is where you teach your brain to put names to the sounds that your ears hear.
I personally loved music theory and wasn't fond of ear training, and in hindsight I should have worked harder on the latter and less on the former.
Music theory tickled the same part of my brain that programming does because it's all about breaking down structures into understandable units, giving names to abstract concepts, categorization, and analysis.
In short, it's a puzzle, and it almost certainly didn't make me a better musician².
At no point when creating improvised music do you have time to think "haha, I know, I'll use an altered dominant chord here, that'll be great," and if you do you're likely not listening to the people you're playing with very closely.
Instead, you hear a sound in your head, and at the best of times your brain knows exactly how to translate that into notes on your instrument.
As you probably guessed, the class that teaches that is the one that I wasn't particularly fond of.</p>
<p>There's a similar split in usefulness when dealing with the fundamentals of programming and Compute Science.
Is it important that the average programmer can rattle off the finer points of Von Neumman architecture?
Probably not.
But it's infinitely useful to be able to pattern match problems against known-good patterns for solving them.
If I can see that a problem models well as a finite state machine in a funny hat, then a good portion of solving the problem is already done for me.
The useful fundamentals are the ones that build your ability to pattern match a problem against a solution.</p>
<p><strong>Practice what you don't know</strong></p>
<p>There's a not-so-fine line between practicing and playing what you already know is going to sound good on your instrument.
The former involves meticulously working on making new musical concepts familiar, and the latter generally sounds good.
"Noodling" on one's instrument is fun, but it's not likely to make you much better³.
In contrast, practicing new songs, scales, etc. will almost certainly make you a better musician overall.
It will just as certainly sound terrible until you've worked on it for far longer than is likely comfortable.
A little-known fact about being a professional musician is that you spend most of it sounding terrible in private so that you sound good in public.</p>
<p>There's a particular type of musician⁴ who spends all of their time running scales that they already know at faster and faster speeds.
When they play on stage you can tell what they've practiced, because their music consists of scales played really really fast.
There's a certain physicality to that that's impressive, but I've never particularly found it musically interesting.
Likewise, if I spend my career going company to company building the same application, I'm likely not to grow much as an engineer after a certain point.
It's totally reasonable to become a master at building a particular kind of thing, and I'd never begrudge anyone the economic security that can come with being able to build something that companies need really fast because you've done it a hundred times, but it's important to recognize that that's likely <em>not</em> a path towards building one's technical chops.
If you want to get better, sometimes you have to do something new.</p>
<p><strong>Listen to others</strong></p>
<p>One of the things I look back on most fondly about music school is its culture of sharing influences.
A frequent topic of conversation is what you and your friends are listening to, and what ideas you're taking from them.
The best musicians I know take in a wide variety of influences and find things to appreciate about music they don't necessarily like.
Most programmers--myself included--could stand to do more of that.
Explore outside of your own ecosystem, and if you find yourself less-than-enamored with a language or tool, try to find some good ideas in it.</p>
<p><strong>Learn your history</strong></p>
<p>From talking with people who have done them, one thing that music school does better than CS programs is the study of the history of the field⁵.
Every music school student is required to take a certain number of music history courses, and composition students--the Enterprise Architects of the music world--generally have a pretty firm understanding of when they're being imitative vs innovative.
And even in the most basic history classes--the kind that non-majors take when they think it's going to be an easy elective, not realizing that the tests are basically a game of music trivia where you've just heard all of the songs for the first time this week--there's at least an attempt to contextualize innovation even if it sounds old to us now.</p>
<p>I took a history of opera class as a sophomore, and at no point was Verdi referred to as "legacy" or "deprecated"⁶.
Contrast that with how history is viewed in tech, if it's learned at all.
Chapters in a history book written by the comments sections of popular tech industry sites would contain passages like "HTTP was originally developed by Tim Berners Lee at CERN in 1989, but no one uses that anymore because Google came out with gRPC and it's much more performant."
Taking the time to learn and contextualize the history of programming languages and tools will almost always make you better at assessing new technologies and techniques.</p>
<p><strong>There's no substitute for learning from an expert</strong></p>
<p>I was mostly a self taught guitar player until my first semester of music school, and I'm pretty sure that I improved more in those first few months than at any other point.
Experts who are good teachers will be able to watch you play and pick out the one thing that you need to do right now to improve, and then give you a bunch of other things to work on that will keep you improving for months.
You can teach yourself a lot of things, both in music and in programming, but there's no substitute for sitting down one on one with an expert and learning from them, even if you don't do it regularly.</p>
<p>If you have the chance to pair program with an expert, do it, and ask for feedback.
One of the best pairing experiences that I've ever had was with my former colleague <a href="https://twitter.com/jmileham">John Mileham</a>, who at the time was the head of architecture and interim lead of the security team at the company that we worked for.
He was working on some security code written in Go, and because I had a burgeoning interest in the language he was nice enough to invite me to pair on it together.
I was "driving", and after we implemented the feature I went through my normal process of interactively adding chunks to the git diff with <code>git add -p</code>.
After I added the second or third diff, he stopped me and said something to the effect of "Can I make an observation? You go way too fast when you code."
It was feedback that I'd never received before, and it was exactly what I needed to hear to get better.
I'd gotten to the point where I was a relatively competent programmer, but made mistakes often enough because I didn't slow down to consider code before committing it, and nobody had sat with me to watch me code so it just seemed like I was careless.
If I hadn't gotten that one on one time with an expert, I likely would have kept making the same mistakes.</p>
<p><strong>Teaching others makes you better</strong></p>
<p>One of the hardest things I've ever tried to do is teach the difference between major and minor to a child learning to play the guitar.
While programming as a career tends to be a fairly applied discipline, its foundations are largely mathematical, and that shows when you're able to explain things with relatively precise language without too many exceptions.
In contrast, major and minor are labels that were applied to patterns of sounds long after they were in common use, and as such basically every explanation has some sort of exception to it.
Major is happy, except that "happy" isn't really a universal reaction, and some "major modes" are more "floaty" or "bluesy," and the sound of a chord is all contextual anyway so major after minor might be interpreted as "triumphant" or "ironic" instead of happy, and so on.
Every explanation besides the technical one is squishy and filled with squishy exceptions, and the technical one is both likely to be uninteresting to a child--and most adults--and won't help them be a better musician.</p>
<p>Having to come up with these explanations gave me a much better understanding of the thing I was explaining, and the same is true of programming.
When you learn something, one of the barometers for how well you've learned it is how well you can teach it to others.
If you really want to learn something well, schedule a talk about it some number of weeks in the future.
It doesn't have to be a high-stakes speaking engagement; a lunch and learn with your team arguably works better.
During the course of practicing your talk, act out audience questions and regularly check in with yourself as to whether you're parroting phrases or really understand them.
By the time you give your talk, you'll either know the topic well, or be able to identify where you need more study.</p>
<p><strong>Know your audience</strong></p>
<p>Ask any working musician to play a "wedding gig," and they'll know exactly what you mean: show up early, dress nicely, …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school">https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school</a></em></p>]]>
            </description>
            <link>https://breaking.computer/blog/what-i-learned-about-writing-software-in-music-school</link>
            <guid isPermaLink="false">hacker-news-small-sites-23665651</guid>
            <pubDate>Sat, 27 Jun 2020 23:51:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Full Deno Tutorial]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23665348">thread link</a>) | @Software202
<br/>
June 27, 2020 | https://lyty.dev/deno/deno-tutorial.html | <a href="https://web.archive.org/web/*/https://lyty.dev/deno/deno-tutorial.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>Deno is a JavaScript/TypeScript runtime with security by default. Deno tends to substitute Node.js with a simpler, modern, and more secure runtime.</p>
<p>Deno is built on V8, Rust, and <a href="https://tokio.rs/" rel="noopener" target="_blank" title="Tokio homepage">Tokio</a>, a Rust asynchronous runtime environment. It aims to be a productive and secure scripting environment for the modern world of programming, Deno is for you!</p>
<p>If you want to learn Deno you are in the right section.</p>
<p>Our Deno tutorial is designed for simplicity. We also have tons of examples to get you in the game.</p>
<h2>Deno Example Code</h2>
<pre><code>function generateRandom(max_number) {
  return Math.ceil(Math.random() * max_number);
}

console.log(generateRandom(5));</code></pre>
<p><a href="https://lyty.dev/diy/deno-typescript-random-number-example.html" target="_blank"><i>launch</i>&nbsp; Do It Yourself</a></p>
<h2>What Can Deno Do?</h2>
<p>Deno is a JavaScript/TypeScript runtime environment, this means that you can use Deno to process server-side actions by writing JavaScript or TypeScript. Think of anything that other server-side programming languages can do.</p>
<ul>
<li>Deno can <strong>serve</strong> web pages dynamically (like PHP, NodeJS, ASP, and other server-side languages).</li>
<li>Deno can <strong>create</strong>, <strong>open</strong>, <strong>read</strong>, <strong>write</strong>, <strong>delete</strong>, and <strong>close</strong> files on the server</li>
<li>Deno can be used to <strong>build</strong> command-line based applications</li>
<li>Deno can <strong>interact</strong> with any kind of database</li>
</ul>
<h2>Why Use Deno?</h2>
<p>Think of anything other server-side programming languages can do, then think <strong>security</strong>, <strong>simplicity</strong>, and <strong>modernization </strong>with Deno.</p>
<ul>
<li>Security by default. No file, network, or environment access (unless explicitly enabled).</li>
<li>It is a TypeScript runtime, which means it supports TypeScript out of the box.</li>
<li>Comes with a single executable (<code>deno</code>).</li>
<li>Ships with built-in tools that make code inspection and formatting easy,&nbsp; the <code>deno info</code> and <code>deno fmt</code>.</li>
<li>You can bundle scripts into a single JavaScript file and more.</li>
</ul>
<h2>Who Can Learn Deno?</h2>
<p>Deno can be learned by anyone, provided that you have the basic knowledge of <strong>JavaScript </strong>especially about <code>async</code>/<code>await</code>.</p>
<h2>Comparisons to Node.js</h2>
<div><table>
<tbody>
<tr>
<td>Deno</td>
<td>NodeJS</td>
</tr>
<tr>
<td>No package manager. Uses modules referenced as URLs or file paths</td>
<td>Has a package manager called <code>npm</code></td>
</tr>
<tr>
<td>Deno does not use <code>package.json</code> in its module resolution algorithm</td>
<td>Uses <code>package.json</code></td>
</tr>
<tr>
<td>All async actions in Deno return a promise. Thus Deno provides different APIs than Node.</td>
<td>In Node.js, async can be promise or function-based</td>
</tr>
<tr>
<td>Deno requires explicit permissions for file, network, and environment access (for security purposes).</td>
<td>Node.js does not require this.</td>
</tr>
<tr>
<td>Deno always dies (exits) on uncaught errors</td>
<td>Node.js may not die.</td>
</tr>
<tr>
<td>Uses "ES Modules" and does not support <code>require()</code>. Third-party modules are imported via URLs: <code>import * as log from "https://deno.land/std/log/mod.ts";</code></td>
<td>Node.js uses both <code>require()</code> and the ES <code>import</code>.</td>
</tr>
</tbody>
</table></div>
<p>You can start our Deno Tutorial by clicking the 'Next Chapter' button below.</p>
<h2>What You Should Know at the End of This Lesson</h2>
<ul>
<li>You should understand when <strong>Deno</strong> is.</li>
<li>You should understand the core value of <strong>Deno </strong>(security, speed, and modern).</li>
<li>You should know that <strong>Deno </strong>is TypeScript-code and the standard file extensions are <code>.js</code> and&nbsp;<code>.ts</code></li>
</ul>
  
</div></div>]]>
            </description>
            <link>https://lyty.dev/deno/deno-tutorial.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23665348</guid>
            <pubDate>Sat, 27 Jun 2020 22:55:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“Fast Startup Growth” Is Killing Innovation Softly]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23664871">thread link</a>) | @utkarsh_apoorva
<br/>
June 27, 2020 | https://blog.lightcat.io/fast-startup-growth/ | <a href="https://web.archive.org/web/*/https://blog.lightcat.io/fast-startup-growth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It's a bit of a counterpoint.</p><p>I am a tech entrepreneur. I am supposed to dream Hypergrowth.</p><p>But lately, disturbed as I am with 2020 itself, I started to think - why are things the way they are. </p><h2 id="two-types-of-companies">Two Types of Companies</h2><p>There are two types of companies. Those that are designed to create wealth for founders and employees, and the others designed to create wealth for a Fund. Don't get me wrong - most companies end up doing neither - and some will do both. But every company is <em>designed</em> to do ONE and ONLY ONE of those things.</p><p>This is not just my opinion.</p><p>Paul Graham wrote in "Startup = Growth" that a startup is a company <em>designed</em> to grow very fast. One question to ask is - to what destination exactly? And why should a company <em>want</em> to grow so fast?</p><p>Let's try to unpack Hypergrowth. And let's borrow the framework from Daniel Kahneman, to do so.</p><h2 id="hypergrowth-tickles-the-market-s-fast-thinking-brain">Hypergrowth Tickles the Market's Fast Thinking Brain</h2><p>Hypergrowth is the business equivalent of your fast brain - the market reacts as if by instinct. Growing &nbsp;fast helps the company cover a good market share before competitors take note and 'copy-cats' come into the picture. Growing fast leads to a new behaviour (or a slight modification in the old one) getting adopted by a very large number of people, in a pretty short time. </p><h3 id="just-f-g-download-the-app-stop-thinking">Just F*****G Download The App, Stop Thinking</h3><p>The slow brain of the market would pause, think, analyse, and might decide NOT to adopt the new behaviour. It might ask questions about privacy, addiction, security, safety, life ... the fast brain of the market does not analyse. </p><p>It jumps instinctively to the shiny new app because it's trendy to do so. From a business perspective, you do not want the market to critique what you have built, you want them to adopt it.</p><p>What happens when the slow brain does kick in and start asking questions later? By that time, the behaviour is so well set, that it is hard to break. So it is likely to stick. Think about people criticising, and then using Facebook. As if they're addicted.</p><blockquote>Without hypergrowth and it's related behavioural sciences, we would still have Facebook, Instagram and Whatsapp, but probably with lesser adoption, and in slightly different avatars.</blockquote><h2 id="hypergrowth-leads-to-winner-take-all-markets">Hypergrowth Leads to Winner Take All Markets</h2><p>Another thing that hypergrowth helps do is make money. To understand what speed has got to do with capital, we need to understand <em>Extrapolation</em>.</p><p>We love to extrapolate. From debates about race, to forest fires to climate change - everywhere you can see this happening. An easy way to detect careless extrapolation is the phrase "at this rate ... X will happen" - assuming that "the rate" is a universal constant.</p><p>We love extrapolation so much, that with took this word and created a special symbol to represent it. And then we made it the most important symbol of modern times. That symbol, of course is "@" or "at the rate of.." . Yeah yeah. I know, it was meant for some other purpose - but even in the old definition, the rate is implied to be a constant - even if for a small duration. But I digress.</p><p>So extrapolation.</p><p>This is how it works - you grow fast - say 8x a year. That growth 'activates' a multiplier to your valuation in the private markets. That multiplier is super handy because as larger and larger funds get in on the action, smaller investors are able to exit at a profit.</p><p>And it's all great except for one thing - it creates Winner Take All markets.</p><h3 id="stop-minding-your-business-and-come-work-for-me">Stop Minding Your Business and Come Work For Me</h3><p>Hypergrowth, when adopted at large scale, creates 'Winner Take All' markets. In these markets, every small company that does something similar to the big guy, tends to die out. This leads to a large number of people, who were literally minding their own businesses, to crash, burn and work for the large corporations. </p><p>Do a few cycles of this, over a few decades, and you get an economy that is seriously debt ridden, afraid that even the remaining jobs will be taken away in the name of innovation. This society responds with mass scale knee-jerk reactions, even if for the right causes. This society gets divided into "Heroes" and "Zeroes". And when there are enough Zeroes and they are unhappy enough, it's easy for chaos to ensue. An incompetent leadership is just an icing on the cake.</p><blockquote><strong>This society responds with mass scale knee-jerk reactions, even if for the right causes. This society gets divided into "Heroes" and "Zeroes". And when there are enough Zeroes and they are unhappy enough, it's easy for chaos to ensue. An incompetent leadership is just the icing on the cake.</strong></blockquote><h2 id="hypergrowth-einstein-works-3-jobs">Hypergrowth = Einstein Works 3 Jobs</h2><p>Hypergrowth is a great concept, intellectually. But, if it is force fed to a society, it kills innovation. Because in these economies, Einstein does not work at a Patent Office. He works 3 jobs to pay his debts, and never has a moment to think about "light, energy and matter".</p><p>Other than large scale internet companies helping us take selfies, we haven't innovated much. The situation is so bad that it takes a crazy right wing billionaire (another one of my heroes) to build a battery powered car mainstream. Ford built his MVP in a f****ing garage.</p><h3 id="a-world-without-winner-take-all-markets">A World Without Winner Take All Markets</h3><p>There isn't a quick fix solution to this. But if fixed, here's what the world would look like.</p><p>There would be 10-15 Facebooks, for different niches. Most subreddits would be dedicated communities, and companies, of their own. Most markets won't be winner take all. There will be way way way more entrepreneurs than today - mostly small, and mostly "businesspeople" not innovative. Lesser debt, more healthcare. Less stress, more time. Less "me too" disruption, more real innovation. &nbsp;Less noise, more signal. But also, way lesser companies for VCs to invest in, way lesser organised Funds, way lesser ways for rich people to invest in and make even more money.</p><p>Consequently, many smart people will fill these gaps, start new funds. Invest in "me too disruptive" companies. And in a few decades, the world will be back to "let's grow fast".</p><p>But in those decades, Einstein would happen, again.</p>
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.lightcat.io/fast-startup-growth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664871</guid>
            <pubDate>Sat, 27 Jun 2020 21:36:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$8B tree wall to stop Sahara deserting]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23664331">thread link</a>) | @miohtama
<br/>
June 27, 2020 | https://kindling.xyz/good-news/21-african-countries-are-joining-together-to-build-a-4750-mile-wall-of-trees/ | <a href="https://web.archive.org/web/*/https://kindling.xyz/good-news/21-african-countries-are-joining-together-to-build-a-4750-mile-wall-of-trees/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Nearly two dozen African nations are now committed to build and maintain the “Great Green Wall,” a chain of forests and woodlands spreading across the entire continent at the southern edge of the Sahara Desert, in the region known as the Sahel. Initially launched in 2007 by 11 countries, the initiative has now been joined by ten more. It is considered the world’s largest ecosystem restoration project by the <a href="https://www.unenvironment.org/news-and-stories/story/worlds-biggest-ecosystem-restoration-project" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">UN Environment Programme<span></span></a>.</p>
<figure></figure>
<p>The project aims to address many of the continent’s core challenges at once. Most directly, it provides a physical barrier to ward off the spread of the Sahara. The Sahara has been moving gradually south for millennia, encroaching on and disrupting local livelihoods. However <a href="https://kindling.xyz/tag/climate-change/" data-wpel-link="internal">climate change</a> has accelerated this process, creating a major economic and environmental threat to the nations of the Sahel, many of which are already among the world’s poorest and least developed. </p>
<figure><img src="https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?lossy=0&amp;strip=1&amp;webp=1" alt="" srcset="https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations-150x84.jpg?lossy=0&amp;strip=1&amp;webp=1 150w, https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?size=234x132&amp;lossy=0&amp;strip=1&amp;webp=1 234w, https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?size=468x263&amp;lossy=0&amp;strip=1&amp;webp=1 468w, https://797230.smushcdn.com/1547441/wp-content/uploads/2020/05/Least-Developed-Nations.jpg?lossy=0&amp;strip=1&amp;webp=1 700w" sizes="(max-width: 700px) 100vw, 700px"><figcaption>Source: <a href="https://www.dw.com/en/to-prosper-poorest-countries-need-avenues-to-electricity/a-41472049" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">DW<span></span></a></figcaption></figure>
<p>The wall will reclaim 247 million acres of land by the year 2030, which can then be used for more economically productive purposes like agriculture and livestock. More trees will result in more rainfall being diverted back into the land, and therefore more water available to communities and ecosystems. The new trees will capture around <a href="https://time.com/5669033/great-green-wall-africa/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">250 million metric tons of carbon ever year<span></span></a>, roughly equivalent to removing all of California’s cars from the road for more than three year. The process of planting and maintaining the wall will also create hundreds of thousands of jobs over the course of the next several years.</p>
<p>It’s a win-win-win-win!</p>
<p>The effort is estimated to cost $8 billion USD and be completed by 2030. It is currently about 15% complete.</p>
<p>I love projects like these. They just make so much sense. They provide incredible economic bang for their buck, ensuring the <a href="https://kindling.xyz/tag/sustainability/" data-wpel-link="internal">sustainability</a> of livelihoods for decades, while also employing people in the process and offering a critical solution to the <a href="https://kindling.xyz/tag/climate-crisis/" data-wpel-link="internal">climate crisis</a>. But more than that, they demonstrate the importance and viability of international cooperation at a time when nearly all of humanity’s deepest challenges are trans-boundary, requiring us to collaborate with one another, even to re-envision ourselves as all part of the same team.</p>
<p>What other major development projects might we be able to make a reality if more countries acknowledged their shared challenges and pooled their resources together toward a common goal?</p>
<div><div><div><div>
<h2>
↯ NEWSLETTER
</h2>
<p><span>News of social progress from around the world. Once a week. It's free!</span></p>





</div></div></div></div><div><div><div><div>
<h2>♥ BECOME A PATRON
</h2>
<p>Get exclusive content. Help us grow the Kindling community and deepen our impact. </p><p>Your contribution makes Kindling possible!</p>

</div></div></div></div>
</div></div>]]>
            </description>
            <link>https://kindling.xyz/good-news/21-african-countries-are-joining-together-to-build-a-4750-mile-wall-of-trees/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664331</guid>
            <pubDate>Sat, 27 Jun 2020 20:16:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Mathematics in 106 Terms]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23664235">thread link</a>) | @R3G1R
<br/>
June 27, 2020 | https://mathvault.ca/math-glossary/ | <a href="https://web.archive.org/web/*/https://mathvault.ca/math-glossary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The language of mathematics is distinct from natural languages in that it aims to communicate abstract, logical ideas with precision and unambiguity. As a result, it is equipped with a system of specialized <strong><a aria-label="symbols (opens in a new tab)" href="https://mathvault.ca/hub/higher-math/math-symbols/" target="_blank" rel="noreferrer noopener">symbols</a></strong> and <strong>vocabularies</strong> — each with its own level of generality and formality.</p><p>Among these, there’s a particular subset of terms that is uniquely foundational and appropriate to our pursuit: the <strong>higher mathematical jargon</strong>. Loosely speaking, these are a set of specialized terms that fall into most — if not all — of the following categories:</p><ul><li>Specific to <strong>higher mathematics</strong></li><li><strong>English-looking</strong> (with a near-technical meaning)</li><li><strong>Frequently-occurring</strong></li><li><strong>Cross-disciplinary</strong> (i.e., not field-specific)</li></ul><p>In brief, these are terms that are generally accessible to most, yet still provide us with a glimpse of the world of non-miniaturized mathematics — and the way their practitioners act and think. In fact, in what follows, we’ve compiled a list of 106 such terms — along with some in-depth exploration of their <strong>definitions</strong>, <strong>examples</strong>, <strong>relevance</strong> and <strong>implications</strong>.</p><p>So if you’re ready to dive into this fascinating world that is known as mathematics, then let’s get started!</p><p>(and if you’re looking for a concise rendition of all the 106 terms featured in this glossary, then you might find the following <strong>higher math jargon mindmap</strong> both interesting and useful.)</p> <p><span><a href="#" target="_self"><span><strong>Download the 4-Page Higher Mathematical Jargon Mindmap</strong></span></a></span></p><p><img src="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png" alt="The Definitive Glossary of Higher Mathematical Jargons" width="1366" height="702" srcset="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png 1130w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-600x308.png 600w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-768x395.png 768w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-1024x526.png 1024w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-300x154.png 300w" sizes="(max-width: 1366px) 100vw, 1366px" title="Math Glossary Header Image" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201366%20702'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png 1130w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-600x308.png 600w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-768x395.png 768w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-1024x526.png 1024w, https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image-300x154.png 300w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Math-Glossary-Header-Image.png"></p><h2 id="toc">Higher Mathematical Jargon — The Definitive List (106 Terms)</h2><p><span> The definitive glossary of higher mathematical jargon — from abstract nonsense, elementary proof to singularity and 101+ more. </span> <span><span>Click to Tweet</span><i></i></span></p><h2 id="abstraction"><a href="#toc">Abstraction</a></h2><p>The process of extracting the underlying <strong>structures</strong>, <strong>patterns</strong>, or <strong>properties</strong> of some mathematical objects, with the intention of generalizing these findings to a broader class of objects. These include, for example:</p><ul><li>Finding the <strong>shared properties</strong> of similar polynomials</li><li>Formalizing the <strong>general pattern</strong> of a sequence</li><li>Establishing a <a href="#otoc"><strong>one-to-one correspondence</strong></a> between two sets</li><li>Constructing an alternate <a href="#axiom"><strong>axiomatic system</strong></a> for Euclidean geometry</li></ul><p>At first, abstraction can seem a bit unappealing due to its higher cognitive demand and lack of connection to real-world phenomena. However, it can often turn out to be an integral force in bringing about a <strong>broaden applicability</strong> to a field — along with some <strong>unification</strong> in between the fields.</p><div id=""><p>Did You Know?</p><p>While abstraction is involved in pretty much all subfields of mathematics, it is particularly well-represented in fields such as <strong>abstract algebra</strong>, <strong>model theory</strong>, <strong>axiomatic set theory</strong> and <a href="#nonsense"><strong>category theory</strong></a>.</p></div><h2 id="nonsense"><a href="#toc">Abstract Nonsense</a></h2><div id="attachment_18333"><p><img aria-describedby="caption-attachment-18333" src="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png" alt="Category Theory: A Category with Objects and Morphisms" width="325" height="325" srcset="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png 800w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-400x400.png 400w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-768x768.png 768w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-220x220.png 220w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-300x300.png 300w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-600x600.png 600w" sizes="(max-width: 325px) 100vw, 325px" title="Category Theory Diagram" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20325%20325'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png 800w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-400x400.png 400w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-768x768.png 768w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-220x220.png 220w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-300x300.png 300w, https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram-600x600.png 600w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Category-Theory-Diagram.png"></p><p id="caption-attachment-18333">A category with objects $A$, $B$, $C$ and a series of morphisms.</p></div><p>A colloquial term for <strong><a href="https://en.wikipedia.org/wiki/Category_theory" target="_blank" rel="noopener noreferrer">category theory</a></strong> (a mathematical subject dedicated to the notion of category and the formalization of <a href="#structure">mathematical structures</a>), or the methods and arguments that are related to it.</p><p><span>Since different branches of mathematics deal with different mathematical structures satisfying the definition of a category, category theory can be regarded as a <strong>unifying theory</strong> of mathematics — whose results are applicable to a wide range of disciplines.</span></p><p>In particular, if a proposition follows from abstract nonsense, then it means that its argument has more to do with the underlying categorical structure of its objects — rather than the field where it’s found. And since such arguments are often highly abstract and long-winded by nature, they are also alternatively referred to as “<strong>general abstract nonsense</strong>” or “<strong>generalized abstract nonsense</strong>“.</p><h2 id="aon"><a href="#toc">Abuse of notation</a></h2><p>The act of inadvertently or deliberately using notations in a way that’s not entirely<strong> syntactically correct</strong> — but which simplifies the exposition and makes the passage easier to understand. For example, one might say that:</p><ul><li>“$\mathbb{R}$ is distributive” — rather than “$(\mathbb{R}, +, \times)$ is distributive.”</li><li>“$3$ is differentiable” — rather than “the function defined by the rule $x \mapsto 3$ for all real $x$, is differentiable.”</li><li>“$a+b+c = c+b+a$” — rather than “$(a+b) + c = (c+b) + a$”.</li></ul><p>In the cases where the context and the assumptions are made clear and well understood, abuses of notation are usually harmless (if not actually desirable). In other cases, however, the same might not be true, and can amount to a <strong>misuse of notation</strong> — which is a faux-pas in mathematics (such as the case of $\frac{\mathrm{d}y}{\mathrm{d}x}=\frac{y}{x}$).</p><h2 id="algo"><a href="#toc">Algorithm</a></h2><p>A finite series of <a href="#welldefined">well-defined</a>, <strong>computer-implementable instructions</strong> to solve a specific set of computable problems. It takes a finite amount of initial input(s), processes them unambiguously at each operation, before returning its outputs within a finite amount of time. Some examples of algorithm in mathematics include:</p><ul><li>The <strong>Euclidean algorithm</strong> (for finding the greatest common factor of two natural numbers)</li><li><a href="https://mathvault.ca/long-division">The <strong>long division algorithm</strong> (and its variants)</a></li><li>The <strong>simplex algorithm</strong> (for finding the optimal solution under a set of linear constraints)</li></ul><p>In essence, algorithms are created to streamline the solution-finding process for a specific set of problems, though it can also remove the necessity of thinking and understanding in the process. For a a series of instructions that are quasi-algorithmic and broader in nature, the term “<strong>general procedure</strong>” is sometimes used (which, like an algorithm, could also involve some element of <a href="#heuristics">heuristics</a> or <a href="#recursion">recursion</a>).</p><h2 id="almost"><a href="#toc">Almost</a></h2><div id="attachment_18414"><p><img aria-describedby="caption-attachment-18414" src="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png" alt="Dart and Board" width="225" height="225" srcset="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png 225w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-220x220.png 220w" sizes="(max-width: 225px) 100vw, 225px" title="Dart and Board" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20225%20225'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png 225w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-150x150.png 150w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-100x100.png 100w, https://mathvault.ca/wp-content/uploads/Dart-and-Board-220x220.png 220w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Dart-and-Board.png"></p><p id="caption-attachment-18414">Since the actual circumference of the board has area 0, the probability of hitting it is also 0 as well (i.e., almost never).</p></div><p>A handy adverb similar to its usage in English, but can take on specific meanings depending on the context. For example:</p><ul><li>“<strong>Almost all</strong> elements in a set” usually means “all but a finite/countable amount of negligible elements in the set.”</li><li>“<strong>Almost no</strong> integer” usually means “only a finite subset of integers.”</li><li>“A property holds <strong>almost everywhere</strong> (in a measure space)” usually means “everywhere in a set except a subset of<a href="http://mathworld.wolfram.com/MeasureZero.html" target="_blank" rel="noopener noreferrer"> measure zero</a>.”</li><li>“An event occurs <strong>almost surely</strong>” usually means that “the event has a probability of 1, even though it does not include all of the possible outcomes.”</li><li>“An event occurs <strong>almost never</strong>” usually means that “the event has a probability of 0, even though it does contain some of the possible outcomes.”</li></ul><p>Here, notice that “almost” doesn’t necessarily mean that the <strong>exceptional cases</strong> are “small”, and hence one is perfectly well-justified in making claims such as “almost all real numbers are transcendental” — or that “the dart almost never lands on the circumference of the board.”</p><h2 id="ansatz"><a href="#toc">Ansatz</a></h2><p>A term of German origin meaning “initial placement of a tool at a work piece” (<a href="https://en.wikipedia.org/wiki/Ansatz" target="_blank" rel="noopener noreferrer">Wikipedia</a>), and is used in mathematics to refer to the initial, additional <strong>mathematical assumptions</strong> made to kick start the problem solving process — but which are later confirmed to be parts of the actual solution as well. Some examples of ansatz in mathematics include:</p><ul><li>The adoption of linear regression model to fit the data points (i.e., <strong>linear ansatz</strong>)</li><li>The assumption that the solutions to a differential/recurrent equation take an exponential form (<strong>exponential ansatz</strong>)</li><li>The assumption that the solution to a system of linear equations is expressible in terms of a particular vector (<strong>ansatz of particular solution</strong>).</li></ul><p>Metaphorically speaking, the use of ansatz can be liken to drawing a picture by first establishing a <strong>framework</strong>, in that if it succeeds, then the framework can be reused as an ansatz later on, but if it doesn’t, then it’s usually discarded and marked as an instance of failure.</p><h2 id="arbitrarily"><a href="#toc">Arbitrarily</a></h2><p>An adverb attached to a mathematical adjective X to make clear that something is “<strong>X with little limitation or restraint</strong>.” For example:</p><ul><li>An <strong>arbitrarily large</strong> function is a function capable of assuming values larger than any fixed choice of real number — regardless of the size of the latter.</li><li>An <strong>arbitrarily small</strong> positive sequence is a sequence capable of assuming values smaller than any fixed choice of positive real number — regardless of the “tininess” of the latter.</li><li>An <strong>arbitrarily long</strong> progression is a progression whose number of members can be made to exceed than any choice of natural number — regardless the size of the latter.</li></ul><p>In general, “arbitrarily” is a foundational term in number theory and mathematical analysis, and can also occur in other topics where some form of <strong>degree</strong> and <strong>ordering</strong> are involved (e.g., <a href="https://en.wikipedia.org/wiki/Polynomial_ring" target="_blank" rel="noopener noreferrer">polynomial ring</a>).</p><div><p><strong>Caution</strong></p><p>Don’t make the mistake in assuming that “arbitrarily” means “infinitely”! If anything, “arbitrarily” usually carries a sense of being “without bound within the finite realm.”</p></div><h2 id="arbitrary"><a href="#toc">Arbitrary</a></h2><p>An adjective used to refer to a choice made without any specific criterion or restraint (e.g., arbitrary integer, arbitrary division of a set, arbitrary permutation of a sequence). It corresponds to the term “<strong>any</strong>” and the <a href="https://mathvault.ca/hub/higher-math/math-symbols/logic-symbols/#Quantifiers" target="_blank" rel="noopener noreferrer">logical quantifier</a> $\forall$, and hints at an element of generality in the phrase where it’s found (e.g., statement $P$ holds for an arbitrary $n \in \mathbb{N}$).&nbsp;</p><div id=""><p>Arbitrary vs. Random</p><p>While “random” and “arbitrary” are often used interchangeably in informal discourses, in mathematics, “random” — unlike “arbitrary” — usually presupposes that the outcomes follow a <a href="https://mathvault.ca/hub/higher-math/math-symbols/probability-statistics-symbols/#Discrete_Probability_Distributions" target="_blank" rel="noopener noreferrer"><strong>probability distribution</strong></a>, and as such might have predictable probabilities even if the outcomes are subject to chance and unpredictability.</p></div><h2 id="axiom"><a href="#toc">Axiom</a></h2><div id="attachment_18546"><p><img aria-describedby="caption-attachment-18546" src="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png" alt="Illustration of Parallel Postulate" width="320" height="240" srcset="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png 320w, https://mathvault.ca/wp-content/uploads/Parallel-Postulate-300x225.png 300w" sizes="(max-width: 320px) 100vw, 320px" title="Parallel Postulate" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20320%20240'%3E%3C/svg%3E" data-lazy-srcset="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png 320w, https://mathvault.ca/wp-content/uploads/Parallel-Postulate-300x225.png 300w" data-lazy-src="https://mathvault.ca/wp-content/uploads/Parallel-Postulate.png"></p><p id="caption-attachment-18546">Pictorial representation of the parallel postulate</p></div><p>Axioms, also known as postulates, are mathematical premises which are assumed to be<strong>&nbsp;true</strong> and along with <a href="#def">definitions</a>, form the foundation of a <a href="#theory">mathematical <span>theory</span></a>.</p><p>In general, axioms can be divided into two types: <strong>logica</strong>l and <strong>non-logical</strong>. The logical axioms are the ones pertaining to the logical part of mathematics (e.g., $[A\rightarrow (B \wedge -B)] \rightarrow -A\,$), while the non-logical axioms are the ones pertaining to the <em>nature</em> of the theory itself (which might or might not be self-evident by nature).</p><p>For example, the <strong><a href="https://en.wikipedia.org/wiki/Parallel_postulate" target="_blank" rel="noopener noreferrer">parallel postulate</a></strong> — which stands as the most well-known (non-logical) axiom among the five in Euclidean geometry — states that:</p><blockquote><p>“If a line segment intersects two straight lines forming two interior angles on the same side that …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mathvault.ca/math-glossary/">https://mathvault.ca/math-glossary/</a></em></p>]]>
            </description>
            <link>https://mathvault.ca/math-glossary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664235</guid>
            <pubDate>Sat, 27 Jun 2020 20:01:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lemmy, an open-source federated Reddit alternative, gets funding for development]]>
            </title>
            <description>
<![CDATA[
Score 787 | Comments 493 (<a href="https://news.ycombinator.com/item?id=23664067">thread link</a>) | @jasonbourne1901
<br/>
June 27, 2020 | https://dev.lemmy.ml/post/35293 | <a href="https://web.archive.org/web/*/https://dev.lemmy.ml/post/35293">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dev.lemmy.ml/post/35293</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664067</guid>
            <pubDate>Sat, 27 Jun 2020 19:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A look into bias in AI and how to combat it]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23664059">thread link</a>) | @sidjain1412
<br/>
June 27, 2020 | https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/ | <a href="https://web.archive.org/web/*/https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
						
						
						<blockquote><p>
Human history has an unfortunate record of discrimination and biases against each other that follow us from ancient times. A conscious effort towards developing inclusive and equal social systems is a necessity. In the increasingly automated world, where computers interact with humans, Artificial Intelligence gives us another shot at making the world a fairer place with equal opportunities.</p>
<p>However, machines are built by people. We are obliged to put conscious effort into making sure the AI solutions won’t carry over our mistakes.
</p></blockquote>
<p>The appeal of AI is tremendous: it can search through millions of pieces of data and use it to make forecasts that are often more accurate than ours. Automating processes with AI also seems more objective than relying on subjective (and slower) human analysis. After all, the AI  algorithm will not “dislike” your picture or assume anything based on it, especially when it is taught to ignore it completely.</p>
<p>The problem is, AI algorithms are not necessarily human-bias free. AI is designed and trained on human data, and human thinking is characterized by bias. Therefore bias is also a built-in byproduct of human-designed systems. These AI biases can echo problematic perceptions, such as the perceived superiority of certain groups. Even well-designed AI systems can still end up with a bias, entirely by accident.</p>
<p>The question is: can we prevent AI from being racist and sexist? And if we can, then could machines help us create a fairer society?</p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.webp 780w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-300x167.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-768x428.webp 768w" sizes="(max-width: 780px) 100vw, 780px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.jpg 780w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-300x167.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-768x428.jpg 768w" sizes="(max-width: 780px) 100vw, 780px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20780%20435'%3E%3C/svg%3E" height="435" width="780" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.jpg 780w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-300x167.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination-768x428.jpg 768w" data-lazy-sizes="(max-width: 780px) 100vw, 780px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/SR_HousingDiscrimination.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<h2> People and biases </h2>
<p>Let’s start from the beginning: before the machines were biased, people were. Why is that? According to the <a href="https://dictionary.cambridge.org/dictionary/english/bias" target="_blank" rel="noopener noreferrer">Cambridge Dictionary</a>, bias is <em>“the action of supporting or opposing a particular person or thing in an unfair way, because of allowing personal opinions to influence your judgment.”</em></p>
<p>Biases can be innate or learned. People may develop biases for or against an individual, a group, or a belief. It does not have to be limited to ethnicity and race; it is also gender, religion, sexual orientation, and many other characteristics that are subject to bias. </p>
<h3>Are all biases conscious?</h3>
<p>There are two types of bias: conscious (also known as explicit bias) and unconscious (also known as implicit bias). The <a href="http://perception.org/wp-content/uploads/2014/11/Transforming-Perception.pdf" target="_blank" rel="noopener noreferrer">conscious bias</a> refers to the attitude we have on a conscious level, and most of the time, it arises as to the direct result of a perceived threat.</p>
<p>The <a href="https://diversity.ucsf.edu/resources/unconscious-bias#:~:text=Unconscious%20bias%20is%20far%20more,or%20working%20under%20time%20pressure." target="_blank" rel="noopener noreferrer">unconscious bias</a> is a social stereotype about certain groups of people that a person form outside their conscious awareness. It is automatic, unintentional, deeply ingrained, and able to influence behavior. Unconscious bias is more prevalent than the conscious one. </p>
<p>According to the <a href="https://www.apa.org/research/action/speaking-of-psychology/understanding-biases" target="_blank" rel="noopener noreferrer">American Psychological Association</a>, <b>only a small proportion of Americans today are explicitly racist</b> and feel hatred towards other ethnicities and races.</p>
<p>But the majority of Americans, because they have grown up in a culture that has been historically racist in many ways and because they’re exposed to the media that are biased, associate violence, drugs, and poverty with specific groups. </p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.webp 1537w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-300x200.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1024x682.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-768x512.webp 768w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1536x1023.webp 1536w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.jpg 1537w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-300x200.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1024x682.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-768x512.jpg 768w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1536x1023.jpg 1536w" sizes="(max-width: 1600px) 100vw, 1600px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201600%201066'%3E%3C/svg%3E" height="1066" width="1600" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.jpg 1537w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-300x200.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1024x682.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-768x512.jpg 768w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img-1536x1023.jpg 1536w" data-lazy-sizes="(max-width: 1600px) 100vw, 1600px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/shutterstock-img.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<p>People will always be biased to some extent because their opinions are subjective and what is worse – humans tend to generalize. This is partly the fault of the way we are programmed, and partly the failure of the way we programmed our society and culture. Does it mean machines have to be programmed like this as well? </p>
<h2>Want to build a racist AI solution? Just hand it a newspaper</h2>
<p>Obviously, AI solutions have no political agenda of their own, right? It’s not going to be intentionally racist unless it has <em>explicitly</em> been trained to be. It is also not (most of the time, at least) a political agenda of their creators that is the issue. The problem is that it is very easy to train machines to be racist by accident and without even trying. </p>
<p>Here are a few examples of how algorithms can discriminate on different fields based on race: </p>
<ul>
<li> <strong> Image Recognition: </strong> Researchers from Georgia Institute of Technology tested eight image-recognition systems used in self-driving cars, after observing higher error rates for specific demographics. They <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/self-driving-car-crash-racial-bias-black-people-study-a8810031.html" target="_blank" rel="noopener noreferrer">found their accuracy proving five percent less accurate</a> on average for people with darker skin. So a self-driving car is more likely to run over a black person than it is to run a white one. </li>
<li> <strong> Healthcare: </strong> An algorithm used in US hospitals to allocate healthcare for patients has been systematically discriminating against black people. A study concluded that the algorithm was <a href="https://www.nature.com/articles/d41586-019-03228-6#ref-CR1" target="_blank" rel="noopener noreferrer">less likely to refer black people than white people</a> who were equally sick to programs that aim to improve care for patients with complex medical needs. </li>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.webp 1200w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-300x175.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-1024x596.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-768x447.webp 768w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-300x175.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-1024x596.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-768x447.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20699'%3E%3C/svg%3E" alt="AI solutions" height="699" width="1200" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-300x175.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-1024x596.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314-768x447.jpg 768w" data-lazy-sizes="(max-width: 1200px) 100vw, 1200px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/iStock-971224314.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<li> <strong> Criminal Cases: </strong> In 2016, <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" target="_blank" rel="noopener noreferrer">ProPublica published</a> an investigation on an ML program that is used by courts to predict future criminals, and they found out that the system is biased against black people. The program learned about who is mostly to end up in jail from incarceration data. And historically, the criminal justice system has been unfair to black Americans. So when an AI program was fed with these historical data, it learned from biased decisions historically made by humans. </li>
<li> <strong> Natural Language Processing (<a href="https://sigmoidal.io/boosting-your-solutions-with-nlp/" target="_blank" rel="noopener noreferrer">NLP</a>): </strong> There is a broad spectrum of cases (for example, work/college admissions or even loan applications), where words can serve as an input – the so-called <em>word embeddings</em> represent words as inputs to machine learning. But there is a fairness problem when an algorithm learns the meaning of words from humans. Our opinions are often subjective and biased, so the meaning of the words (e.g., people names) is then biased. A <a href="http://science.sciencemag.org/content/356/6334/183.full" target="_blank" rel="noopener noreferrer"> paper in Science from 2017</a> found out that when a computer teaches itself English by crawling the internet, it becomes prejudiced against black Americans and women. For example, when <a href="http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/" target="_blank" rel="noopener noreferrer">the GloVe news dataset is used</a>, the sentiment (how positive a given sentence is) of simple text starting with ‘My name is…’ is significantly lower when it ends with common names of black people than common names for white people.
 </li>
</ul>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.webp 496w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2-300x133.webp 300w" sizes="(max-width: 496px) 100vw, 496px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.png 496w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2-300x133.png 300w" sizes="(max-width: 496px) 100vw, 496px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20496%20220'%3E%3C/svg%3E" height="220" width="496" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.png 496w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2-300x133.png 300w" data-lazy-sizes="(max-width: 496px) 100vw, 496px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-2.png"></picture><figcaption> This is just a glimpse of how sentiment works for different sentences. A machine understands the meaning of these words due to word embeddings. </figcaption></figure>
<figure>
<picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.webp" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.png"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20512%20429'%3E%3C/svg%3E" height="429" width="512" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.png" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/unnamed-karolina.png"></picture><br>
<picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.webp 364w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3-255x300.webp 255w" sizes="(max-width: 364px) 100vw, 364px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.png 364w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3-255x300.png 255w" sizes="(max-width: 364px) 100vw, 364px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20364%20429'%3E%3C/svg%3E" height="429" width="364" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.png 364w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3-255x300.png 255w" data-lazy-sizes="(max-width: 364px) 100vw, 364px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/pasted-image-0-3.png"></picture><figcaption> Sentiment values are more positive for stereotypically-white names, and more negative for stereotypically-black names. These examples show how word-embeddings can accidentally learn racist bias from us just by reading internet news. </figcaption></figure>
<h2> How can we fight it? </h2>
<blockquote>
<p>
Bias-free AI can soon be a powerful tool to tackle social issues – such as enhancing social mobility through fairer access to the financing/healthcare system, mitigating exclusion and poverty through making the judiciary systems more objective, bias-free testing in university admissions, and much more. We should expect fair AI solutions from both technology companies and authorities.
</p>
</blockquote>
<p>Military and tactics books say that weapons or tactics should always take into consideration the enemy strategy. That is also true for this particular fairness and human dignity fight. In the case of this war, there are also different ways to fight racial bias, depending on the domain (field) and the data used by the algorithm. </p>
<h3> Image Recognition </h3>
<p>In the case of image-recognition systems, the reason for bias is that training data that machines use for learning contain mostly samples gathered from white people. These AI solutions can have problems with recognizing people of different races because it simply did not see enough pictures of them. The effect is doubled when it comes to women of color.</p>
<p>Face recognition systems from the leading companies <a href="https://www.youtube.com/watch?v=QxuyfWoVV98" target="_blank" rel="noopener noreferrer">failed during the man/women classification</a> of Oprah Winfrey, Michelle Obama, and Serena Williams. </p>
<p>The biggest problem here is that face-recognition systems are widely used by law enforcement and border control. If the application has high false-positive rates for a specific group (and according to <a href="https://www.nist.gov/news-events/news/2019/12/nist-study-evaluates-effects-race-age-sex-face-recognition-software" target="_blank" rel="noopener noreferrer"> NIST study</a>, a majority of the face recognition algorithms used in the US had worse perform on nonwhite faces), it puts this population at the highest risk for being falsely accused of a crime. </p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-300x169.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-768x432.webp 768w" sizes="(max-width: 1024px) 100vw, 1024px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.jpeg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-300x169.jpeg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-768x432.jpeg 768w" sizes="(max-width: 1024px) 100vw, 1024px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20576'%3E%3C/svg%3E" height="576" width="1024" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.jpeg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-300x169.jpeg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw-768x432.jpeg 768w" data-lazy-sizes="(max-width: 1024px) 100vw, 1024px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/1_6xQOFmzai_8ALH9UP8sQvw.jpeg"></picture><figcaption><strong>Source:</strong> vpnsrus.com</figcaption></figure>
<p>The solution (our weapon) for this problem is quite simple. Still, it requires more attention during dataset preparation: the equal representation of people of color and gender in training datasets (e.g., face recognition) is crucial for algorithms (like face recognition ones) to work with the same precision regardless of race or gender.</p>
<p>Moreover, from the sociological point of view, those bias problems would be hard to overlook and natural to point out if minority representatives would be more encouraged to be a part of the artificial intelligence team.</p>
<h3> Biases in AI solutions for Healthcare </h3>
<p>The reason millions of black people were affected by racial bias in health-care algorithms? It was based on the historical cost of health care, where higher health-care costs are associated with greater needs. People who did have higher-cost treatment were assumed to need more extensive care, which seemed just about right – or did it?</p>
<figure> <picture><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.webp 1200w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-300x169.webp 300w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-1024x578.webp 1024w,https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-768x433.webp 768w" sizes="(max-width: 1200px) 100vw, 1200px" type="image/webp"><source data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-300x169.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-1024x578.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-768x433.jpg 768w" sizes="(max-width: 1200px) 100vw, 1200px"><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%20677'%3E%3C/svg%3E" height="677" width="1200" data-lazy-srcset="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.jpg 1200w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-300x169.jpg 300w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-1024x578.jpg 1024w, https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219-768x433.jpg 768w" data-lazy-sizes="(max-width: 1200px) 100vw, 1200px" data-lazy-src="https://mk0sigmoidalryb7krfc.kinstacdn.com/wp-content/uploads/2020/06/gettyimages-971253984_1200xx2116-1195-0-219.jpg"></picture><figcaption><strong>Source:</strong> Hyejin Kang, Shutterstock</figcaption></figure>
<p>The biggest problem with this approach was the fact that those less wealthy simply couldn’t afford more extensive treatment, so they chose less expensive options, while their actual needs remain the same as people in the same condition who could opt in the more expensive ones.</p>
<p>The approximation of the healthcare needs by the amount of money spent on treatment was actually an exclusive approach, biased towards more wealthy people. Finding other variables than the cost of treatment to estimate a person’s medical needs <a href="https://www.nature.com/articles/d41586-019-03228-6#ref-CR1" target="_blank" rel="noopener noreferrer">reduced bias by 84%</a>. </p>
<h3> College Admissions </h3>
<p>The problem here is often not testing actual skills but rather candidate background (e.g., childhood environment). If you have two candidates and one comes from the wealthy neighborhood and the other from a poor one, there is a possibility that the second one will …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/">https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/</a></em></p>]]>
            </description>
            <link>https://sigmoidal.io/how-to-build-inclusive-fair-ai-solutions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23664059</guid>
            <pubDate>Sat, 27 Jun 2020 19:35:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xi-Editor Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 436 | Comments 126 (<a href="https://news.ycombinator.com/item?id=23663878">thread link</a>) | @raphlinus
<br/>
June 27, 2020 | https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>A bit more than four years ago I started the <a href="https://github.com/xi-editor/xi-editor">xi-editor</a> project. Now I have placed it on the back burner (though there is still some activity from the open source community).</p>

<p>The original goal was to deliver a very high quality editing experience. To this end, the project spent a rather large number of “novelty points”:</p>

<ul>
  <li>Rust as the implementation language for the core.</li>
  <li>A rope data structure for text storage.</li>
  <li>A multiprocess architecture, with front-end and plug-ins each with their own process.</li>
  <li>Fully embracing async design.</li>
  <li><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type">CRDT</a> as a mechanism for concurrent modification.</li>
</ul>

<p>I still believe it would be possible to build a high quality editor based on the original design. But I <em>also</em> believe that this would be quite a complex system, and require significantly more work than necessary.</p>

<p>I’ve written the <a href="https://github.com/xi-editor/xi-editor/issues/1187#issuecomment-491473599">CRDT part of this retrospective</a> already, as a comment in response to a Github issue. That prompted good <a href="https://news.ycombinator.com/item?id=19886883">discussion</a> on Hacker News. In this post, I will touch again on CRDT but will focus on the other aspects of the system design.</p>

<h2 id="origins">Origins</h2>

<p>The original motivation for xi came from working on the Android text stack, and confronting two problems in particular. One, text editing would become very slow as the text buffer got bigger. Two, there were a number of concurrency bugs in the interface between the EditText widget and the keyboard (input method editor).</p>

<p>The culprit of the first problem turned out to be the <a href="https://developer.android.com/reference/android/text/SpanWatcher">SpanWatcher</a> interface, combined with the fact that modern keyboards like to put a spelling correction span on each word. When you insert a character, all the successive spans bump their locations up by one, and then you have to send onSpanChanged for each of those spans to all the watchers. Combined with the fact that the spans data structure had a naive O(n) implementation, and the whole thing was quadratic or worse.</p>

<p>The concurrency bugs boil down to synchronizing edits across two different processes, because the keyboard is a different process than the application hosting the EditText widget. Thus, when you send an update (to move the cursor, for example) and the text on the other side is changing concurrently, it’s ambiguous whether it refers to the old or new location. This was handled in an “almost correct” style, with timeouts for housekeeping updates to minimize the chance of a race. A nice manifestation of that is that swiping the cursor slowly through text containing complex emoji could cause flashes of the emoji breaking.</p>

<p>These problems have a unifying thread: in both cases there are small diffs to the text, but then the data structures and protocols handled these diffs in a less than optimal way, leading to both performance and correctness bugs.</p>

<p>To a large extent, xi started as an exploration into the “right way” to handle text editing operations. In the case of the concurrency bugs, I was hoping to find a general, powerful technique to facilitate concurrent text editing in a distributed-ish system. While most of the Operational Transformation literature is focused on multiple users collaboratively editing a document, I was hoping that other text manipulations (like an application enforcing credit card formatting on a text input field) could fit into the general framework.</p>

<p>That was also the time I was starting to get heavily into Rust, so it made natural sense to start prototyping a new green-field text editing engine. How would you “solve text” if you were free of backwards compatibility constraints (a huge problem in Android)?</p>

<p>When I started, I knew that Operational Transformation was a solution for collaborative editing, but had a reputation for being complex and finicky. I had no idea how deep the rabbithole would be of OT and then CRDT. Much of that story is told in the <a href="https://news.ycombinator.com/item?id=19886883">CRDT discussion</a> previously linked.</p>

<h2 id="the-lure-of-modular-software">The lure of modular software</h2>

<p>There is an extremely long history of people trying to build software as composable modules connected by some kind of inter-module communication fabric. Historical examples include <a href="https://en.wikipedia.org/wiki/DCE/RPC">DCE/RPC</a>, <a href="https://en.wikipedia.org/wiki/Common_Object_Request_Broker_Architecture">Corba</a>, <a href="https://en.wikipedia.org/wiki/Bonobo_(GNOME)">Bonobo</a>, and more recently things like <a href="https://sandstorm.io/">Sandstorm</a> and <a href="https://fuchsia.dev/fuchsia-src/concepts/modular/module">Fuchsia Modular</a>. There are some partial successes, including <a href="https://developer.android.com/reference/android/os/Binder">Binder</a> on Android, but this is still mostly an unrealized vision. (Regarding Binder, it evolved from a much more idealistic vision, and I strongly recommend reading this 2006 interview about <a href="https://www.osnews.com/story/13674/introduction-to-openbinder-and-interview-with-dianne-hackborn/">OpenBinder</a>).</p>

<p>When I started xi, there were signs we were getting there. Microservices were becoming popular in the Internet world, and of course all Web apps have a client/server boundary. Within Google, <a href="https://grpc.io/">gRPC</a> was working fairly well, as was the internal process separation within Chrome. In Unix land, there’s a long history of the terminal itself presenting a GUI (if primitive, though gaining features such as color and mouse). There’s also the tradition of <a href="https://en.wikipedia.org/wiki/Blit_(computer_terminal)">Blit</a> and then, of course, <a href="https://en.wikipedia.org/wiki/NeWS">NeWS</a> and X11.</p>

<p>I think one of the strongest positive models was the database / business logic split, which is arguably the most successful example of process separation. In this model, the database is responsible for performance and integrity, and the business logic is in a separate process, so it can safely do things like crash and hang. I very much thought of xi-core as a database-like engine, capable of handling concurrent text modification much like a database handles transactions.</p>

<p>Building software in such a modular way requires two things: first, infrastructure to support remote procedure calls (including serialization of the requests and data), and second, well-defined interfaces. Towards the end of 2017, I saw the goal of xi-editor as <em>primarily</em> being about defining the interfaces needed for large scale text editing, and that this work could endure over a long period of time even as details of the implementation changed.</p>

<p>For the infrastructure, we chose JSON (about which more below) and hand-rolled our own xi-rpc layer (based on JSON-RPC). It turns out there are a lot of details to get right, including dealing with error conditions, negotiating when two ends of the protocol aren’t exactly on the same version, etc.</p>

<p>One of the bolder design decisions in xi was to have a process separation between front-end and core. This was inspired in part by <a href="https://neovim.io/">Neovim</a>, in which everything is a plugin, even GUI. But the main motivation was to build GUI applications using Rust, even though at the time Rust was nowhere near capable of native GUI. The idea is that you use the best GUI technology of the platform, and communicate via async pipes.</p>

<p>One argument for process separation is to improve overall system reliability. For example, Chrome has a process per tab, and if the process crashes, all you get is an “Aw, snap” without bringing the whole browser down. I think it’s worth asking the question: is it useful to have the front-end continue after the core crashes, or the other way around? I think probably not; in the latter case it might be able to safely save the file, but you can also do that by frequently checkpointing.</p>

<p>Looking back, I see much of the promise of modular software as addressing goals related to project management, not technical excellence. Ideally, once you’ve defined an inter-module architecture, then smaller teams can be responsible for their own module, and the cost of coordination goes down. I think this type of project management structure is especially appealing to large companies, who otherwise find it difficult to manage larger projects. And the tax of greater overall complexity is often manageable, as these big companies tend to have more resources.</p>

<h3 id="json">JSON</h3>

<p>The choice of JSON was controversial from the start. It did end up being a source of friction, but for surprising reasons.</p>

<p>The original vision was to write plug-ins in any language, especially for things like language servers that would be best developed in the language of that ecosystem. This is the main reason I chose JSON, because I expected there would be high quality implementations in every viable language.</p>

<p>Many people complained about the fact that JSON escapes strings, and suggested alternatives such as <a href="https://msgpack.org/index.html">MessagePack</a>. But I knew that the speed of raw JSON parsing was a solved problem, with a number of extremely high performance implementations (<a href="https://github.com/simdjson/simdjson">simdjson</a> is a good example).</p>

<p>Even so, aside from the general problems of modular software as described above, JSON was the source of two additional problems. For one, <a href="https://github.com/xi-editor/xi-mac/issues/102">JSON in Swift is shockingly slow</a>. There are <a href="https://forums.swift.org/t/rearchitecting-jsonencoder-to-be-much-faster/28139">discussions on improving it</a> but it’s still a problem. This is surprising to me considering how important it is in many workloads, and the fact that it’s clearly possible to write a high performance JSON implementation.</p>

<p>Second, on the Rust side, while <a href="https://serde.rs/">serde</a> is quite fast and very convenient (thanks to proc macros), when serializing a large number of complex structures, it bloats code size considerably. The xi core is 9.3 megabytes in a Linux release build (debug is an eye-watering 88MB), and a great deal of that bloat is serialization. There is work to reduce this, including <a href="https://github.com/dtolnay/miniserde">miniserde</a> and <a href="https://github.com/not-fl3/nanoserde">nanoserde</a>, but serde is still by far the most mainstream.</p>

<p>I believe it’s possible to do performant, clean JSON across most languages, but people should know, we’re not there yet.</p>

<h2 id="the-rope">The rope</h2>

<p>There are only a few data structures suitable for representation of text in a text editor. I would enumerate them as: contiguous string, gapped buffer, array of lines, piece table, and rope. I would consider the first unsuitable for the goals of xi-editor as it doesn’t scale well to large documents, though its simplicity is appealing, and memcpy is fast these days; if you know your document is always under a megabyte or so, it’s probably the best choice.</p>

<p>Array of lines has performance failure modes, most notably very long lines. Similarly, many good editors have been written using piece tables, but I’m not a huge fan; performance is very good when first opening the file, but degrades over time.</p>

<p>My favorite aspect of the rope as a data structure is its excellent …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html">https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/xi/2020/06/27/xi-retrospective.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663878</guid>
            <pubDate>Sat, 27 Jun 2020 19:06:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Spreading of Threading (2019)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23663631">thread link</a>) | @jbarches
<br/>
June 27, 2020 | https://aaronzlewis.com/blog/2019/05/01/spreading-threading/ | <a href="https://web.archive.org/web/*/https://aaronzlewis.com/blog/2019/05/01/spreading-threading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="article">
    <!-- START OF _includes/article.html -->
<article>
	
	
	
	<p>Aaron Z. Lewis / <time>May 1, 2019</time></p>
	
	<!--more-->


<p>My Twitter feels like a local library. Each one of my Twitter friends is tending to their own little corner of the internet, sharing their best material, and responding to my random research questions. There are a lot of knowledgable folks out there, but <a href="https://aaronzlewis.com/blog/2019/05/01/spreading-threading/[@visakanv](https://twitter.com/visakanv">Visakan Veerasamy</a> is the ultimate librarian. I like to think of him as the crown prince of Nerd Twitter —&nbsp;a writer, creator, and curator who’s so prolific he doesn’t recognize himself. Visa is playing the Twitter game on a whole new level. He’s constructing a digital version of his brain, and his curation style feels like an early iteration of something that might one day go mainstream. It’s a knowledge creation and exploration ethos that feels more true to the original “web” and more fit for how we think.</p>

<p><img src="https://aaronzlewis.com/images/visa.png">
<em>Visa’s Twitter profile, complete with his personal web of values.</em></p>

<p>Inspired by his huge web of knowledge, I sent out a tweet three months ago that said: “I think I would legit pay for @visakanv as a service. $10/mo for him to respond to all of my random musings with his own thoughts, content recommendations, and links to relevant threads. This service would be like Mario racing turbo boost for the mind!”</p>

<p>To my surprise, Visa responded within a few minutes. “Happy to do this,” he said, and shared a link to his <a href="https://www.patreon.com/visakanv">Patreon</a>.</p>

<h3>A brief history of tweetstorms</h3>

<p>Visa’s digital brain is made up of Twitter threads. He didn’t invent the medium, but he’s pushed it to its limits.</p>

<p>When Marc Andreessen started tweeting in 2014, he didn’t let the 140-character limit stop him from posting his thoughts at length. Instead of shortening his tweets, he started stringing them together by replying to himself. Thus was born the tweetstorm. At first, tweetstorms were a hack. And they were mildly <a href="http://expletiveinserted.com/2014/07/02/taming-tweetstorms/">controversial</a>. Gawker once <a href="http://valleywag.gawker.com/uber-ceo-posts-13-tweet-apology-without-answering-a-sin-1660229634">slammed</a> Travis Kalanick’s use of a tweetstorm, calling it “a series of thoughts that give the illusion of substance and circumspection because they are presented in a numerical order.” Tech blogger/investor M.G. Siegler raged against them in 2014:</p>

<blockquote><p>1/ In theory, 2/ I love Tweetstorms 3/ and have long wanted a feature like this myself. 4/ But in practice, 5/ I f*cking hate them. 6/ They flow in the tweet stream about as nicely as vomit out of an esophagus. 7/ They ruin the experience of the stream by breaking what Twitter is, 8/ a service to share short thoughts quickly 9/ and let others reply to those in some semblance of order.</p></blockquote>

<p>At first, creating tweetstorms was a <a href="https://readwrite.com/2014/08/21/twitter-jargon-illustrated-rt-mt-canoes-darth/">very manual process</a>, and they weren’t very easy to read or share. Fast-forward three years: in 2017, Twitter officially productized tweestorms and rebranded them as “threads.” Suddenly, it was much simpler to string tweets together and share the resulting thread as a unit. This product change created the infrastructure on which Visa and others are currently spinning their webs.</p>

<h3>Resurrecting the Memex</h3>

<p>I found Visa’s threads sometime last year, and I’ve been crawling across them ever since. Whereas Marc Andressen’s threads were mostly self-contained, Visa’s are linked together. They form a giant web of interconnected thoughts. There’s no beginning or ending or map or wayfinding or sense of where you are in his tapestry. There are just threads of threads of threads that seem to extend into infinity —&nbsp;an ever-expanding network of Visa’s ideas and discoveries. At each node, there’s usually a full-on discussion taking place between his followers. Visa has constructed what feels like a whole new medium on top of the bedrock of Twitter. Here’s a representative thread for you to explore:</p>

<blockquote data-lang="en"><div lang="en" dir="ltr"><p>I’ve been stewing this theory for 1 year +:</p><p>Just as how the WWE isn’t a wrestling show, but a show ABOUT a wrestling show,</p><p>mainstream media is less about the news than a participatory interactive tv show ABOUT the news</p><p>Cable News Network is really Cable News Entertainment <a href="https://t.co/QZO2t8I9fI">https://t.co/QZO2t8I9fI</a></p></div>— Visa is in SF until May 8! 🌉 (@visakanv) <a href="https://twitter.com/visakanv/status/1004190525270851584?ref_src=twsrc%5Etfw">June 6, 2018</a></blockquote>





<p>Visa’s threads are doing to Twitter what hyperlinks did to dead-tree text. They link things together across time and space. Without thread-webs, most tweets get left behind in the past. A web of tweets allows people to rediscover older thoughts and connect them with newer ones.</p>

<p>These threads bear a family resemblance to the vision of an early 20th-century computer pioneer named Vannevar Bush. In 1945, he wrote a now-famous article called <a href="https://www.theatlantic.com/magazine/archive/1945/07/as-we-may-think/303881/">As We May Think</a>, which described a knowledge device he called the Memex:</p>

<blockquote><p>Man cannot hope fully to duplicate [his] mental process artificially, but he certainly ought to be able to learn from it. In minor ways, he may even improve, for his records have relative permanency. The first idea, however, to be drawn from the analogy concerns selection. Selection by association, rather than indexing, may be mechanized. One cannot hope thus to equal the speed of flexibility with which the mind follows an associative trail, but it should be possible to beat the mind decisively in regard to the permanence an clarity of the items resurrected from storage … <strong>Wholly new forms of encyclopedias will appear, ready made with a mesh of associative trails running through them, ready to be dropped into the memex and there amplified.</strong></p></blockquote>

<p><img src="https://aaronzlewis.com/images/memex.jpg"></p>

<p>Bush’s vision of associative trails has been realized in some corners of the web, like Wikipedia. But most content is organized in the reverse-chronological stream (also known as the feed or the timeline). Social media sites have made information consumption a very linear process. We scroll down infinitely long pages that are (roughly) organized from newest to oldest. Content that’s more than a week old is fossilized under the endless dump of new posts, links, pictures. On social media, time is the main ordering principle. Creating new content feels like throwing a leaf into a roaring river. It’s not attached to anything — it just floats on by, doomed to be forgotten within a matter of seconds. We don’t really “surf” the web anymore. Unless we’re <a href="https://en.wikipedia.org/wiki/Wikipedia:Wikirace">Wiki-racing</a>, we’re not hopping from hyperlink to hyperlink on a surprising journey across  human knowledge. We scroll, click, scroll click.</p>

<p>I see Visa’s Twitter threads as a response to this boring linearity&nbsp;— an attempt to make things hang together. We’re associative beings. We make sense of things by relating them to other things. As Joshua Foer wrote in his book <em>Moonwalking With Einstein:</em> “It takes knowledge to gain knowledge. Memory is like a spiderweb that catches information. The more it catches, the bigger it grows. And the bigger it grows, the more it catches.”</p>

<h3>The spread of threads</h3>

<p>I’ve noticed that the threading impulse is beginning to expand beyond Twitter. It’s popping up in more and more corners of the web. At Ribbonfarm, Venkatesh Rao is experimenting with a new genre called “<a href="https://www.ribbonfarm.com/2019/03/21/constructions-in-magical-thinking/">blogchains</a>,” in which a bunch of blog posts are linked together around a single theme. It’s different than a traditional series because it’s “improvised rather than planned, is responsive to salient events in the environment, evolves at a certain tempo, is structurally a way to <em>build over time</em>, is suitable for multi-author collaboration, is capable of supporting an inter-process messaging protocol with adjacent blogchains, has no necessary or scripted ‘ending.’” The blogchain seems like a direct descendant of the Twitter thread — an attempt to experiment with the medium outside the confines of Twitter’s more rigid platform.</p>

<p>At Epsilon Theory, Ben Hunt created what he calls a <a href="https://www.epsilontheory.com/discovery-map-december-31-2018/">Discovery Map</a>. It’s an interactive visualization that displays all 300 of his blog posts as a network graph. The nodes of the network are organized in thematic clusters. Instead of scrolling down a reverse-chronological feed, you can surf across related posts and see connections across time. This feels like a genuinely new way of interacting with blog content, and it serves as an interesting answer to the question “Where should I start?”</p>

<p><img src="https://aaronzlewis.com/images/discovery-map.png"></p>

<p>The most interesting non-linear threading product I’ve discovered is called <a href="http://are.na/">Are.na</a>. It’s like Pinterest, but for nerds. Are.na lets you organize “Blocks” (text, links, photos) into thematic “Channels”. For example, I’m currently collecting material for channels called “<a href="https://www.are.na/aaron-lewis/deep-history-8mjcwnu9nia">Deep history</a>” and “<a href="https://www.are.na/aaron-lewis/culture-wars-2-0">Culture wars 2.0</a>”. Other people can easily add blocks to your channels, and you can include their channels inside your own. Channels can be rearranged, renamed, connected in novel ways. On Are.na, you’re a spider spinning a knowledge web alongside a bunch of other curious spiders. You never know how your webs might connect. I’ve started searching for things on Are.na (instead of Google) because every block lives inside a channel that’s connected to a lot of related content. Whereas a Google search result feels like a dead-end, an Arena block feels like an unexpected beginning.</p>

<p>What’s frustrating about blogging is that each post feels static and final. It’s not very alive as a medium. I wish it were easier for posts to evolve over time, sprout offshoots, find collaborators. The hyperlink is a pretty crude technology for connecting things together. Visa’s threads, Ribbonfarm’s blogchains, Epsilon Theory’s Discovery Map, and Are.na’s channels are all pointing to a model of content creation and consumption that’s more fit for the way our minds actually work. Threads are a more fluid and malleable medium. Finding someone’s thread-web feels like the digital equivalent of perusing the bookshelves in their home. You don’t have to know what you’re looking for, but you’re usually pleasantly surprised by what you find.</p>

<p>For the last few months, Visa has been replying to my tweets with links to his relevant thread-webs. Each random thought I tweet becomes a new entry point into the collection he’s been curating for years. He’d probably do this if I weren’t supporting him on Patreon, but I believe his threading experiment is an extremely valuable service. As the internet grows more complex, we’re going to need people who can string things together across time and …</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aaronzlewis.com/blog/2019/05/01/spreading-threading/">https://aaronzlewis.com/blog/2019/05/01/spreading-threading/</a></em></p>]]>
            </description>
            <link>https://aaronzlewis.com/blog/2019/05/01/spreading-threading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663631</guid>
            <pubDate>Sat, 27 Jun 2020 18:30:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Build Magic Link]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23663211">thread link</a>) | @jbarches
<br/>
June 27, 2020 | https://snaphabit.app/blog/password-less-login/ | <a href="https://web.archive.org/web/*/https://snaphabit.app/blog/password-less-login/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://snaphabit.app/blog/content/images/size/w300/2020/06/MagicLink-3.png 300w,
                            https://snaphabit.app/blog/content/images/size/w600/2020/06/MagicLink-3.png 600w,
                            https://snaphabit.app/blog/content/images/size/w1000/2020/06/MagicLink-3.png 1000w,
                            https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://snaphabit.app/blog/content/images/size/w2000/2020/06/MagicLink-3.png" alt="Don't build password-less login">
            </figure>

            <section>
                <div>
                    <h3 id="a-metrics-driven-take-on-how-password-less-login-wasted-weeks-of-development-time-and-hurt-our-signup-funnel-">A metrics-driven take on how password-less login wasted weeks of development time and hurt our signup funnel.</h3><p>"Magic Link", also know as password-less login, enables users to sign in by clicking a link. With no need to remember a password or prove email ownership, <a href="https://medium.com/@kelvinvanamstel/should-we-embrace-magic-links-and-leave-passwords-alone-c73db7007fc4">many</a> <a href="https://techbeacon.com/security/your-passwordless-future-make-it-sooner-rather-later">people</a> have hailed "Magic Link" as the perfect authentication solution.</p><p>How it works on SnapHabit? After a user enters their enter email address, we direct them to their inbox to tap a link to sign in. Before diving into what went wrong, here's a snapshot of our authentication funnel:</p><ul><li><strong>11% of users</strong> required at least 4 magic-link emails before completing signing up.</li><li><strong>18% of users never finished signup (clicked the magic link)</strong>. On average, these users attempted signup twice, with several users submitting &gt; 10 times.</li></ul><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="-why-would-you-use-magic-link-anyways">... why would you use magic link, anyways?</h2><p>Friends are core to SnapHabit, so the functionality to send a friend request is critical. Phone number or email felt like the cheapest way to support a unique identifier — as it could be used for both authentication and finding a friend.</p><p>Like most services, we first looked at using "Sign in with Google/Facebook". However, Apple recently adjusted App Store Guidelines... starting June 30, <strong>"apps that use a social login service ... must also offer Sign in with Apple"</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/Screen-Shot-2020-06-17-at-3.47.00-PM-2.png"><figcaption>App Store Guidelines, June 17, 2020</figcaption></figure><p>Apple Sign In supports <a href="https://support.apple.com/en-us/HT210425">"Hide My Email"</a>, so many users who sign in with Apple would not have a meaningful email attached to their account. Asking for a user's email after they chose to "hide it" would be a poor user experience.</p><p>So in summary, we had 4 options for account creation:</p><ol><li><strong>Email + Password</strong> ... requires forgot password and users to prove email ownership</li><li><strong>Support all third-party (Apple, Google, Facebook)</strong> ... and add a new unique identifier to allow friends to find each other, given email will not be sufficient</li><li><strong>Phone number magic link</strong> ... we were relying on Expo (previously did not support phone-number auth), and we also felt emails would be a good/cheap tool for communication</li><li><strong>Email magic link</strong> </li></ol><p>Email magic link felt... perfect! &nbsp;We built the login flow, complete with a custom email, instructional webpage, and deep linking. <strong>Hurrah, we had cracked the authentication funnel!</strong></p><!--kg-card-begin: html--><iframe width="560" height="315" src="https://www.youtube.com/embed/QoS2-mIuOZw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><!--kg-card-end: html--><h2 id="what-went-wrong-and-how-we-tried-to-solve">What went wrong and how we tried to solve</h2><p><em>If you're interested in the technical details of how we implemented some of these fixes, let me know and we'll consider publishing.</em></p><h3 id="1-users-clicking-the-link-on-another-device-">1. Users clicking the link on another device.</h3><p>Of 10 users we chatted with who had issues, 4 tried to click the link on another device. There are two routes to solving this:</p><ul><li>technical solution to support this behavior (clicking the link on desktop will authenticate the user on mobile)</li><li>better instructional text</li></ul><p><strong>The latter was simpler, so we started with that:</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/firstattempt.png"></figure><p><strong>And again.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/email.png"></figure><p><strong>And more.</strong></p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/landingpage.png"></figure><h3 id="2-user-confusion-about-clicking-a-link-to-login">2. User confusion about clicking a link to login</h3><p>At least 2 people mentioned they simply did not understand that they needed to authenticate with email. &nbsp;To solve this, we added</p><ul><li>call-to-action to open Apple Mail or Gmail</li><li>disabled the "resend" button for 10 seconds, to encourage users to tap the mail CTA before attempting login again</li></ul><figure><img src="https://snaphabit.app/blog/content/images/2020/06/buttons.png"></figure><h3 id="3-users-entering-the-wrong-email">3. Users entering the wrong email</h3><p>Many users who did not finish finish signing up (eg. did not click email link) had accounts with a ".con" domain. &nbsp;We added an notice to alert users of a possibly unintended typo:</p><figure><img src="https://snaphabit.app/blog/content/images/2020/06/dotcon.png"></figure><h2 id="-what-s-next">... What's next</h2><div><p>Despite attempting to solve 1, 2 and 3, our funnel drop-off is still larger than we'd like (~15% of users do not open the email correctly).</p><p>So after two months of solution hackery, we're cutting our losses and adding sign in with Google, Facebook and Apple options. If we still see users opting for email sign-in and failing to complete, we'll consider making the full-circle shift back to an email/password model.<br><strong><br>I hope our sharing this painful journey can save you from taking a similar path!</strong> &nbsp;Let me know if you have any questions or feedback at <a href="https://snaphabit.app/cdn-cgi/l/email-protection" data-cfemail="f19b909a94b1829f90819990939885df908181df">[email&nbsp;protected]</a></p></div><hr><p><em>Don't have SnapHabit yet? You can download the app on iOS <a href="https://apps.apple.com/us/app/snaphabit-ai-healthy-habits/id1494552185" rel="noopener noreferrer">here</a> and Android <a href="https://play.google.com/store/apps/details?id=io.gravitech.habit.staging" rel="noopener noreferrer">here</a>.</em></p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://snaphabit.app/blog/password-less-login/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663211</guid>
            <pubDate>Sat, 27 Jun 2020 17:37:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon Changes Macs Forever]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23663200">thread link</a>) | @billyrobinson4
<br/>
June 27, 2020 | https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="cb2b">WWDC20</h2><h2 id="087c">Learn more about Apple’s ARM-based silicon chips for Mac, announced at WWDC20</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----d2682a9722df----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*3RTZkevqc5ZvJpivlnc1mg.jpeg?q=20" width="2500" height="1599" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*3RTZkevqc5ZvJpivlnc1mg.jpeg" width="2500" height="1599" srcset="https://miro.medium.com/max/552/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 276w, https://miro.medium.com/max/1104/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 552w, https://miro.medium.com/max/1280/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 640w, https://miro.medium.com/max/1456/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 728w, https://miro.medium.com/max/1632/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 816w, https://miro.medium.com/max/1808/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 904w, https://miro.medium.com/max/1984/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 992w, https://miro.medium.com/max/2160/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1080w, https://miro.medium.com/max/2700/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1350w, https://miro.medium.com/max/3240/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1620w, https://miro.medium.com/max/3780/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 1890w, https://miro.medium.com/max/4320/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2160w, https://miro.medium.com/max/4800/1*3RTZkevqc5ZvJpivlnc1mg.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="93b7">At the end of the WWDC20 Keynote, Apple announced that it’s switching from Intel processors to its own: Apple Silicon. The release of custom Apple chips, powered by ARM, comes after a long history of using Intel-based chips, for the greater part of the 21st century.</p><p id="0fc0">Modeled after Apple’s use of its own chips on the iPhone, iPad, and Apple Watch, the company is switching to its own chips to give the Mac more performance per watt and better GPU performance.</p><p id="ecaf">Though we won’t go in-depth into the specific implications for machine learning, there’s a lot to be excited about when it comes to the future of ML development on Mac. Inevitably, the enhanced GPU performance will be a boon to machine learning developers, with benefits ranging from faster model training to reduced reliance on transfer learning. It will be interesting to see how ML engineers capitalize on Apple Silicon over time.</p></div></div></section><hr><section><div><div><p id="10c8">The Mac, often considered Apple’s flagship lineup, has seen a couple changes in the past. Let’s look at what those changes were and how they’ve contributed to the evolution of the Mac.</p><h2 id="114e">Motorola 68K to PowerPC</h2><p id="d699">One of the earliest transitions in chip architecture was the transition from Motorola 68K chips to IBM and Motorola PowerPC chips. This was an incredible transition, which significantly improved the Mac and played an important role in understanding future transitions.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*gf2Y6U112riltsrAmT6VaA.png?q=20" width="780" height="439" role="presentation"></p><p><img src="https://miro.medium.com/max/1560/1*gf2Y6U112riltsrAmT6VaA.png" width="780" height="439" srcset="https://miro.medium.com/max/552/1*gf2Y6U112riltsrAmT6VaA.png 276w, https://miro.medium.com/max/1104/1*gf2Y6U112riltsrAmT6VaA.png 552w, https://miro.medium.com/max/1280/1*gf2Y6U112riltsrAmT6VaA.png 640w, https://miro.medium.com/max/1400/1*gf2Y6U112riltsrAmT6VaA.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>The original iMac with a PowerPC processor.</figcaption></figure><h2 id="ed43">PowerPC to Intel x86</h2><p id="6ac1">The most notable transition was the move from PowerPC chips to Intel processors, which have been used for almost half of the Mac’s history so far. With this transition, Apple announced a developer kit to help with the transition, similar to what they announced in the switch to Apple Silicon.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*YIIun0yR2job_s0MRzSINg.png?q=20" width="1200" height="675" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*YIIun0yR2job_s0MRzSINg.png" width="1200" height="675" srcset="https://miro.medium.com/max/552/1*YIIun0yR2job_s0MRzSINg.png 276w, https://miro.medium.com/max/1104/1*YIIun0yR2job_s0MRzSINg.png 552w, https://miro.medium.com/max/1280/1*YIIun0yR2job_s0MRzSINg.png 640w, https://miro.medium.com/max/1400/1*YIIun0yR2job_s0MRzSINg.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>A recent, Intel-based MacBook Pro.</figcaption></figure></div></div></section><hr><section></section><hr><section><div><div><p id="4c63">Undoubtedly, a switch to ARM-based Macs has a huge advantage for the performance and usability of Macs. Let’s look at how Apple Silicon will improve the Mac’s experience.</p><h2 id="71ef">Performance per Watt</h2><p id="e98c">Apple Silicon promises a stark improvement in performance per watt, meaning that the Mac could potentially promise desktop-level performance with the power consumption of a notebook computer, as exemplified by Apple’s diagram:</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*485W2PItyV9fz4UiWem0eQ.png?q=20" width="1720" height="953" role="presentation"></p><p><img src="https://miro.medium.com/max/3440/1*485W2PItyV9fz4UiWem0eQ.png" width="1720" height="953" srcset="https://miro.medium.com/max/552/1*485W2PItyV9fz4UiWem0eQ.png 276w, https://miro.medium.com/max/1104/1*485W2PItyV9fz4UiWem0eQ.png 552w, https://miro.medium.com/max/1280/1*485W2PItyV9fz4UiWem0eQ.png 640w, https://miro.medium.com/max/1400/1*485W2PItyV9fz4UiWem0eQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Performance per watt for Apple Silicon</figcaption></figure><h2 id="95f4">Native Apps</h2><p id="b37d">Apps that support Apple Silicon natively will perform best on the new ARM-based Macs. Out-of-the-box, Apple’s own apps, including pro apps like Final Cut Pro and Logic Pro, will have native support for Apple Silicon. In addition, through their collaboration with Adobe, the Creative Cloud Suite will also have native support from the get-go. Eventually, Microsoft Office and other widely used programs will be able to take advantage of Apple Silicon’s performance.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*AkSiIGraS55x_sZV5vt6_A.png?q=20" width="1080" height="607" role="presentation"></p><p><img src="https://miro.medium.com/max/2160/1*AkSiIGraS55x_sZV5vt6_A.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*AkSiIGraS55x_sZV5vt6_A.png 276w, https://miro.medium.com/max/1104/1*AkSiIGraS55x_sZV5vt6_A.png 552w, https://miro.medium.com/max/1280/1*AkSiIGraS55x_sZV5vt6_A.png 640w, https://miro.medium.com/max/1400/1*AkSiIGraS55x_sZV5vt6_A.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Photoshop running natively on an ARM-based Mac.</figcaption></figure><h2 id="2e35">iOS Apps on Mac</h2><p id="3611">Another incredible benefit of using the ARM architecture across iOS, macOS, and watchOS is the ability to run iOS apps natively on Apple Silicon Macs. Without any additional work from the developer, most iOS apps can be installed from the Mac App Store.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*SdaPx8Kn2Nw08JFB6XbDvw.png?q=20" width="3359" height="1891" role="presentation"></p><p><img src="https://miro.medium.com/max/6718/1*SdaPx8Kn2Nw08JFB6XbDvw.png" width="3359" height="1891" srcset="https://miro.medium.com/max/552/1*SdaPx8Kn2Nw08JFB6XbDvw.png 276w, https://miro.medium.com/max/1104/1*SdaPx8Kn2Nw08JFB6XbDvw.png 552w, https://miro.medium.com/max/1280/1*SdaPx8Kn2Nw08JFB6XbDvw.png 640w, https://miro.medium.com/max/1400/1*SdaPx8Kn2Nw08JFB6XbDvw.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Running Monument Valley and Fender Play, two popular iOS apps, on a Mac.</figcaption></figure><p id="4f66">To help developers transition their apps to support Apple Silicon, Apple has announced a whole host of tools to make native and simulated support for Apple Silicon as smooth as possible for users.</p><h2 id="0ebc">Universal 2</h2><p id="8277">As the name suggests, Universal 2 allows developers to quickly compile their apps for Apple Silicon while retaining support for Intel-based Macs. By using Universal 2 in Xcode, developers will be able to use the same binary for both Intel-based Macs, while providing a native experience for those who are using a Mac with Apple Silicon.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*4Krp5sFt3beXnXbpuenl9Q.png?q=20" width="3360" height="2100" role="presentation"></p><p><img src="https://miro.medium.com/max/6720/1*4Krp5sFt3beXnXbpuenl9Q.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*4Krp5sFt3beXnXbpuenl9Q.png 276w, https://miro.medium.com/max/1104/1*4Krp5sFt3beXnXbpuenl9Q.png 552w, https://miro.medium.com/max/1280/1*4Krp5sFt3beXnXbpuenl9Q.png 640w, https://miro.medium.com/max/1400/1*4Krp5sFt3beXnXbpuenl9Q.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Universal 2 for the same binary for Intel and ARM-based Macs.</figcaption></figure><h2 id="38e9">Rosetta 2</h2><p id="49cb">An upgrade from their previous version of Rosetta (for the Intel transition), Rosetta 2 provides similar capabilities as its previous counterpart — allowing Intel-based apps to run on Apple Silicon Macs. So if app developers haven’t yet recompiled their apps with Universal 2, their users can still access legacy versions of the app through Rosetta 2.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*2qVtb8FXZoJARJJa-Pq0IQ.png?q=20" width="3360" height="2100" role="presentation"></p><p><img src="https://miro.medium.com/max/6720/1*2qVtb8FXZoJARJJa-Pq0IQ.png" width="3360" height="2100" srcset="https://miro.medium.com/max/552/1*2qVtb8FXZoJARJJa-Pq0IQ.png 276w, https://miro.medium.com/max/1104/1*2qVtb8FXZoJARJJa-Pq0IQ.png 552w, https://miro.medium.com/max/1280/1*2qVtb8FXZoJARJJa-Pq0IQ.png 640w, https://miro.medium.com/max/1400/1*2qVtb8FXZoJARJJa-Pq0IQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Rosetta 2 for install-time translation for Intel-based apps.</figcaption></figure><h2 id="b5ed">Virtualization</h2><p id="d298">For developers who need to use Linux, Docker, or similar tools, Apple has also announced virtualization tools for ARM Macs. These tools are expected to provide a seamless transition to Apple Silicon for developers who need server-side development tools.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*z8L5KciHtXn7DOG5_HO8Ag.png?q=20" width="3359" height="1884" role="presentation"></p><p><img src="https://miro.medium.com/max/6718/1*z8L5KciHtXn7DOG5_HO8Ag.png" width="3359" height="1884" srcset="https://miro.medium.com/max/552/1*z8L5KciHtXn7DOG5_HO8Ag.png 276w, https://miro.medium.com/max/1104/1*z8L5KciHtXn7DOG5_HO8Ag.png 552w, https://miro.medium.com/max/1280/1*z8L5KciHtXn7DOG5_HO8Ag.png 640w, https://miro.medium.com/max/1400/1*z8L5KciHtXn7DOG5_HO8Ag.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Running an Apache server on an ARM-based Mac.</figcaption></figure><h2 id="f765">Developer Transition Kit</h2><p id="81af">Similar to the Intel transition, developers will be able to purchase a Developer Transition Kit, which comprises a Mac Mini enclosure fitted with the A12Z SoC — used on the latest iPad lineup. The Mac Mini will have 16GB of memory and a 512GB SSD — plenty for development needs. Also, macOS Big Sur and Xcode 12 will come pre-installed on the machine, which will be available for $500 (half the price of the Intel transition kit).</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*hpX5lvJahDiZXZxjGDDLMQ.png?q=20" width="1080" height="607" role="presentation"></p><p><img src="https://miro.medium.com/max/2160/1*hpX5lvJahDiZXZxjGDDLMQ.png" width="1080" height="607" srcset="https://miro.medium.com/max/552/1*hpX5lvJahDiZXZxjGDDLMQ.png 276w, https://miro.medium.com/max/1104/1*hpX5lvJahDiZXZxjGDDLMQ.png 552w, https://miro.medium.com/max/1280/1*hpX5lvJahDiZXZxjGDDLMQ.png 640w, https://miro.medium.com/max/1400/1*hpX5lvJahDiZXZxjGDDLMQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Apple’s Mac Mini Based Developer Transition Kit</figcaption></figure><p id="de05">While Apple isn’t completely transitioning to Apple Silicon just yet, the announcement of their ARM-based chip for Mac is a huge step in a two year process to change Mac for the better.</p><p id="04c2">Stay tuned for some great new tutorials on the latest frameworks this week, and get ahead of the crowd by taking use of them before they’re released to the public in the fall.</p><p id="3993">In case you missed it, here’s the Keynote in all its glory:</p><figure><div></div></figure><p id="6139">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this article</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="d325"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="cfac"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="5eba"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and</em><a href="https://www.fritz.ai/newsletter" target="_blank" rel="noopener"><em> </em></a><em>the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663200</guid>
            <pubDate>Sat, 27 Jun 2020 17:35:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook’s community standards censorship has far-reaching consequences]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 27 (<a href="https://news.ycombinator.com/item?id=23663155">thread link</a>) | @corywatilo
<br/>
June 27, 2020 | https://watilo.com/facebooks-community-standards-censorship-has-far-reaching-consequences | <a href="https://web.archive.org/web/*/https://watilo.com/facebooks-community-standards-censorship-has-far-reaching-consequences">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post_body_1565683">

    
      <div><p>Facebook censorship has effectively barred my business from their platform and is materially impacting the livelihood of my customers.</p>
<p>For the past decade, Iâ€™ve run an online portfolio business on the side called <a href="https://foliohd.com/" target="_blank">FolioHD</a>. (You get a subdomain on the platform to host your portfolio, like mine at <a href="http://watilo.foliohd.com/">watilo.foliohd.com</a>.)</p>
<p>Unfortunately I have no insight into the offending content, and the offending content can be anything from a nippleÂ&nbsp;to now apparently <a href="https://www.washingtontimes.com/news/2020/jun/23/project-veritas-facebook-sting-moderators-brag-abo/" target="_blank">even a MAGA hat</a>.</p>
<p>Now I am personally blocked on Instagram from liking photos or sending DMs. I canâ€™t sign into my company Instagram account. And Facebook has reached into my Pageâ€™s support inbox and removed private message between myself and customers.<br></p><p><b>How I noticed</b></p><p>A few weeks ago, I was scrolling through my personal Instagram and double-tapped a photo. Instead of seeing a red heart, I received this message.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3509ecd9-6aeb-4004-b042-0d782cec404c/Screenshot_20200620-0840172.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171501Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=534498c02cd6adf24abad8b4848915ab86e2fc90c2bc390e986a256de8d3e10f&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200620-0840172.png%22" title="Image: https://s3.us-west-2.amazonaws.com/secure.notion-static.com/3509ecd9-6aeb-4004-b042-0d782cec404c/Screenshot_20200620-0840172.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171501Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=534498c02cd6adf24abad8b4848915ab86e2fc90c2bc390e986a256de8d3e10f&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200620-0840172.png%22"><br></p><p>Tapping â€œTell usâ€� simply says, â€œThanks for reporting this issue.â€�</p>
<p>In my Instagram bio is a link to my personal portfolio, <a href="http://watilo.foliohd.com/">watilo.foliohd.com</a>. Because of this link, I effectively became completely blocked from interacting with anyone on Instagram.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/9db49566-898e-4743-a776-f38d5d97de0f/Screenshot_20200603-071310.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171521Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=fe284180ac384a5fcc2a2e80620b1591f6591c68f53de08d85c8379d579c0332&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200603-071310.png%22"><br></p><p>As the result of a single person sharing a link to a portfolio that Facebook deemed to have offensive content, they have now blocked the entire <a href="http://foliohd.com/">foliohd.com</a> domain.</p>
<p>It even prevented me from sending direct messages with ANY links.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e21b85f5-439c-4956-b8f1-5f3d7af98cc4/Screenshot_20200619-2203122.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171544Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=7871c844ed24cdd872248679c05a4d8f3839c5a86be8849fe1467fa70036467f&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%22Screenshot_20200619-2203122.png%22"><br></p><p>In order to restore my personal Instagram account, Iâ€™d have to remove the URL from my bio.</p>
<p>Using Facebookâ€™s Sharing Debugger confirms the URL was blocked on the entire Facebook ecosystem.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/ad2152fc-2508-4d44-af6b-6919b7aa6879/7474EA49-DE9C-431B-AA3B-2FCFCB41C0D6.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171615Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=b09b9fa953466ec52e76fe5e106c82fe45b016c76167b551bbc2ef98a7a6da40&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%227474EA49-DE9C-431B-AA3B-2FCFCB41C0D6.jpeg%22"><br></p><p>Of course Facebook has a way to report this issue on their developer site, but we know where those messages go. (A giant black hole.)<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/381da3b4-f1cc-43fa-9d47-8eac7fd20337/77F62DF6-5BFE-43BA-BC3D-5A21AC463B26.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171640Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=84831d9fcbca7433e84e476e3d8df870cbd7f76029a8940b60466264e883cfeb&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%2277F62DF6-5BFE-43BA-BC3D-5A21AC463B26.jpeg%22"><br></p><p>But the problems donâ€™t end there. Since Instagram has been seamlessly integrated into the Facebook ecosystem, any account containing a blocked URL on Facebook has related consequences on Instagram.</p>
<p>I canâ€™t sign into the FolioHD Instagram account, because Facebook wonâ€™t send a security code by email, presumably because it has <a href="http://foliohd.com/">foliohd.com</a> in the email.<br></p><p><img src="https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e202aab8-6473-434f-ae77-76d2d35af868/0AEC68F1-F197-4BE2-9DD7-2ECB093730AB.jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=AKIAT73L2G45O3KS52Y5%2F20200627%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20200627T171702Z&amp;X-Amz-Expires=86400&amp;X-Amz-Signature=604194c7fa9965b2b07f147e2f57aefa4f404cb93aa07187f1fae7bbf69e0f8c&amp;X-Amz-SignedHeaders=host&amp;response-content-disposition=filename%20%3D%220AEC68F1-F197-4BE2-9DD7-2ECB093730AB.jpeg%22"><br></p><p>But it gets worse: Visiting the FolioHD Facebook support inbox has led me to discover that Facebook is removing private messages between customers and myself, because they contain a link to <a href="http://foliohd.com/" target="_blank">foliohd.com</a> inside of them.<br></p><div id="posthaven_gallery[1591206]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/large_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/medium_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-medium-width="800" data-medium-height="638" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/large_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-large-width="1200" data-large-height="957" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/thumb_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/xlarge_1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-xlarge-width="1273" data-xlarge-height="1015" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2472433/StzACkbdfFfmQIBG7llsgKEseAE/1988198B-3D14-42A7-8911-326740A1C1F4.jpeg" data-orig-width="1273" data-orig-height="1015" data-posthaven-id="2472433">
        </p>
          
        </div>
<p>Iâ€™m thankful I donâ€™t rely on the Facebook support inbox, but I do have an auto-reply set up for anyone who sends a message there, directing them to contact support via <a href="http://foliohd.com/">foliohd.com</a>.</p>
<p>Since Facebook is blocking links, that auto-reply no longer gets sent.</p>
<p>Any social posts created through a Buffer-style service, even using a bitly link, gets posted briefly, then removed, with no notice.</p>
<p>And the worst part: there is no way to resolve this.</p>
<p>Now my customers can no longer share links to their websites within the Facebook ecosystem. They had nothing to do with this, and yet their businesses are being affected.<br></p><p><b>My ask</b></p><p>My request to Facebook would be to reconsider how they handle sites with user-generated content, in the same way Google handles it in their index. If a subdomain contains offending content, it shouldnâ€™t poison the root domain and every other subdomain.</p>
<p>And Facebook should probably never weasel their way into private company inboxes to remove content retroactively. You break the trust of any business by pulling these kind of moves. How can we rely on you for anything if your censorship is a moving target?</p>
<p>And if anyone knows how to get Facebook to fix this, please let me know. Short of filing a lawsuit, Iâ€™m not sure how to get this resolved.<br></p></div>
    
  </div></div>]]>
            </description>
            <link>https://watilo.com/facebooks-community-standards-censorship-has-far-reaching-consequences</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663155</guid>
            <pubDate>Sat, 27 Jun 2020 17:29:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MiniBoss – Pixel Art Tutorials for Video Games]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23663148">thread link</a>) | @anarchyrucks
<br/>
June 27, 2020 | https://blog.studiominiboss.com/pixelart | <a href="https://web.archive.org/web/*/https://blog.studiominiboss.com/pixelart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

      <!-- BEGIN POSTS -->
      
        <article id="post-">

          
            <div>
              <div>
                
                <p>Here are all the pixel art tutorials made by <strong>Pedro</strong> :D</p><div><p>More info on his <strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fsaint11&amp;t=ZGExZjUyNDc4Njk5MWU5ODIxODVhNjJmODQ4MTUwODExMmY1MmJjMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0">Patreon</a></strong> page!</p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2FbePatron%3Fu%3D2279992&amp;t=ZDI3OTAxZmNiNzI1N2VlOTJlMzU5YTVmYWIwNWZkZjczODM1NTljZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/acde232a22d6cb93bb34a149f8a0dd7e/tumblr_inline_ow8slwrGUs1qdiwz3_500.png"></a></p></div><p><strong>Article #8: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-8-eb218a4637dd&amp;t=MWEwZGYzNTQ1OWVkZjdmZGMzMjAxODMwM2Q0MDg2MjU2YjQ3ODc4NyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Saving and Exporting Pixel Art</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-8-eb218a4637dd&amp;t=MWEwZGYzNTQ1OWVkZjdmZGMzMjAxODMwM2Q0MDg2MjU2YjQ3ODc4NyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/f2daa6f4716afcc541fc01e24f155f31/tumblr_inline_pswg3uhLHV1qdiwz3_500.png"></a></strong></p><p><strong>Article #7: <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-7-e504bfa4ddf2&amp;t=NjVhNGI4ODNlMzY4OWQyZGE2Y2M0Mzc2ZTczNDUwZTA0ZjU2OGFhOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Working with Lines</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-7-e504bfa4ddf2&amp;t=NjVhNGI4ODNlMzY4OWQyZGE2Y2M0Mzc2ZTczNDUwZTA0ZjU2OGFhOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><strong><img src="https://66.media.tumblr.com/1ee38f820c573f34a2559e57745230f2/tumblr_inline_pr7haxEbfx1qdiwz3_500.png"></strong></a></p><p><strong>#79 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F79-jumping-25803471&amp;t=ODAzZWQ3MzRhNTg5MjBhYjIyYzI3MWZlNmYwYmFiODA2YWE0YTY4OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="jumping" target="_blank">Jumping</a></strong></p><p><strong><img src="https://66.media.tumblr.com/25529b9c829e9714231ebd716e020425/tumblr_inline_pqi15m2n8k1qdiwz3_1280.gif"></strong></p><p><strong>Article #6 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-6-a74f562a4056&amp;t=YjM5MTM2MDdmNzI2OTk3NDk5NjEyYTAwODdkZjAzYzIxMjY3NmEyMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Basic Color Theory</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-4-f57f51dcfa02&amp;t=YmRkMzJjZTBjODJlYzFiMmU0OWY4ZDkzOGY3NDA0Y2U2NzQ0MWRhMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><strong><img src="https://66.media.tumblr.com/9bbb85c753b861eaa63a7c0d39bb7236/tumblr_inline_pl3bsxXuy01qdiwz3_500.png"></strong></a></p><p><strong>#78 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fimpact-23417521&amp;t=ODZkODRlNzM0MzMzMGI5YmE4ZmU4ZDdjYzIxOTkxYzY4NGI4NmVjOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="impact" target="_blank">Impact</a></strong></p><p><strong><img src="https://66.media.tumblr.com/1ba8ce6801f7d6463f7c70252f58ff30/tumblr_inline_pjzse8KjHX1qdiwz3_1280.gif"></strong></p><p><strong>Article #5 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-4-f57f51dcfa02&amp;t=YmRkMzJjZTBjODJlYzFiMmU0OWY4ZDkzOGY3NDA0Y2U2NzQ0MWRhMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Basic Shading</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F79-jumping-25803471&amp;t=ODAzZWQ3MzRhNTg5MjBhYjIyYzI3MWZlNmYwYmFiODA2YWE0YTY4OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><strong><img src="https://66.media.tumblr.com/c47a895719717aa7b2a27c44d85ace6a/tumblr_inline_pimb83kJlG1qdiwz3_500.png"></strong></a></p><p><strong>Article #4 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-4-ff4bfcd2d085%3Ffbclid%3DIwAR1HjxwMVuR8lzLoserMAEmXSqtdLqRUDq_oXd084KTyv-FoIBtDOA5g8x4&amp;t=OWI3ZWE4MDI1MjUxNzc2NjdkNTk5MzliNTA5NzZkOGJmODU3MzJjOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Anti-alias and banding</a></strong></p><p><strong><img src="https://66.media.tumblr.com/ac1bf1b88440e61864410a0c3a3b97e2/tumblr_inline_phucif1mLB1qdiwz3_500.png"></strong></p><p><strong>#77 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-tricks-22246917&amp;t=Yjk5NDFkMzE0OWFkNmFlNDBhMTk4MDdlYzAxYmUzYzIyMGM3MjM5NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_tricks" target="_blank">Top down tricks</a></strong></p><p><strong><img src="https://66.media.tumblr.com/4e9f3c7c258e6569e26dbc3a23fcef51/tumblr_inline_ph4cqpw5xa1qdiwz3_1280.gif"></strong></p><p><strong>#76 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F21959820&amp;t=NTUxN2UwNTQ3MTQ3N2FjY2YxOGZiMzNjODY1MDMyZjM4ZDIyMTk0YixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_attack_animation" target="_blank">Top down attack animation</a></strong></p><p><strong><img src="https://66.media.tumblr.com/426290d81fb4dffad6f8e90358fe907d/tumblr_inline_pggo4tPVXv1qdiwz3_1280.gif"></strong></p><p><strong>#75 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fisometric-part-1-21638316&amp;t=NWUxZjliNDEyZDYxZmVlMDU2ZjY0OWQyZTY5YTU5NjZlYmVmN2UyNCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="isometric_part_1" target="_blank">Isometric - part 1</a><br></strong></p><p><strong><img src="https://66.media.tumblr.com/2e2ccd4e5e5601c8fbb907a39cb56448/tumblr_inline_pfor33qFKB1qdiwz3_1280.gif"></strong></p><p><strong>#74 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-walk-21353953&amp;t=ZTJiYjljNDQ4ODk1MDI2N2Q1MTZjZDQ3OWMwZjNkOTY4NmRiZjUxYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_walk_cycle" target="_blank">Top down walk cycle</a></strong></p><p><strong><img src="https://66.media.tumblr.com/09b50a78bbb170d52cd1d81b037d68a2/tumblr_inline_peywa8D48v1qdiwz3_1280.gif"></strong></p><p><strong>Article #3 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-3-c9eb70270fa1&amp;t=NzU2MmZlYzU1YzdlODU4ZGZmOGUzMmI2ZTE2Mzk5Y2E3MGVhYjNkZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">A basic Aseprite animation</a><br></strong></p><p><strong><img src="https://66.media.tumblr.com/2e4ed4f930c901c5151da05541b2620d/tumblr_inline_peaaqoqXgr1qdiwz3_500.gif"></strong></p><p><strong>Article #2 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-2-bcd705cb04d7&amp;t=MDM5YTFjYTU1MTQyYzE4ZDRkYTY4NjY1ODY4MzgzYTU5ODI5ZGU3ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">Cluster sketching and paiting</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2Fpixel-grimoire%2Fhow-to-start-making-pixel-art-2-bcd705cb04d7&amp;t=MDM5YTFjYTU1MTQyYzE4ZDRkYTY4NjY1ODY4MzgzYTU5ODI5ZGU3ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/ea1002e97dc39c1e15794c1ce1cc59c5/tumblr_inline_pd7jynCMjf1qdiwz3_500.png"></a></strong></p><p><strong>Article #1&nbsp;<a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2F%40saintjust%2Fhow-to-start-making-pixel-art-2d1e31a5ceab&amp;t=OTVkOTBhNDJmYjViMzlhZTk2ZjhjYjk1NDAwMzUxYWQ3OWFlZTFjMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank">How to start making pixel art</a></strong></p><p><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fmedium.com%2F%40saintjust%2Fhow-to-start-making-pixel-art-2d1e31a5ceab&amp;t=OTVkOTBhNDJmYjViMzlhZTk2ZjhjYjk1NDAwMzUxYWQ3OWFlZTFjMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://cdn-images-1.medium.com/max/600/1*8hOSIYTOWBg6ZZ5U9AkNcg.png"></a></p><p><strong>#73 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fswords-19905632&amp;t=NWNjMmMzNjVmOGNmZDE5M2Q3YWZjZmE2ZDVhNDVmYWQzZTcyNmM2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="swords" target="_blank">Swords<br></a><br><img src="https://66.media.tumblr.com/b1a0f06232943a7d373039321060a535/tumblr_inline_pbo31aS4eR1qdiwz3_1280.gif"></strong></p><p><strong>#72 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwood-textures-19566524&amp;t=NWUyZWVjMjdlYTcwY2FlYWU5NTFlMWU0NjRkYzA4NzhkMjc5Y2I2NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wood" target="_blank">Wood</a></strong></p><p><strong><img src="https://66.media.tumblr.com/c676c50bf84d3150940658ebedf33f7e/tumblr_inline_paour7pXDi1qdiwz3_1280.gif"></strong></p><p><strong>#71 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fresizing-pixel-19266474&amp;t=MzMwNzM3MWJlNzUxOTczMjI2YzMzYWQxZGQ1OTI3ZGZhMWJlODZmMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="resizing_pixel_art" target="_blank">Resizing Pixel Art</a></strong></p><p><strong><img src="https://66.media.tumblr.com/db58bece8b4bd868a158472f72a422a6/tumblr_inline_p9wpubzPrs1qdiwz3_1280.gif"></strong></p><p><strong>#70 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fillumination-18822379&amp;t=MTA3M2JiNDZkNGY0NjVmM2FjM2YxMTkyZGU2M2QzOTAxN2Y1ZDc3YSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="illumination_techniques" target="_blank">Illumination Techniques</a></strong></p><p><strong><img src="https://66.media.tumblr.com/4dac1bba410ed77d79107fa0e6bcff2b/tumblr_inline_p8u9cb3DfX1qdiwz3_1280.gif"></strong></p><p><strong>#69 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fgems-18529700&amp;t=ZjhmNGQwY2QxODMwOGFiZWZmN2VlNjAwZGI0MjU2NjZhNTZlOGIwNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="gems" target="_blank">Gems</a></strong></p><p><strong><img src="https://66.media.tumblr.com/185b9a56ca05956afc30e6adca78a7ae/tumblr_inline_p86aamjHgS1qdiwz3_1280.gif"></strong></p><p><strong>#68 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffirearm-design-18248148&amp;t=MGZhZjFmOTRiOGQ5NmYyNTBlMmIyODFiMDk3YzNmNDBjNzUyODlmNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="firearm design" target="_blank">Firearm Design</a></strong><strong></strong></p><p><strong><img src="https://66.media.tumblr.com/352bc588bcfbb25c2cffc4f57a42b302/tumblr_inline_p7e57s9VqK1qdiwz3_1280.gif"></strong></p><div><p><strong>#67 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fholograms-ghost-17955725&amp;t=ZGYzOGQyNWFkM2YxNWFiY2JhMDhjNWZhMjliNmFlMmZhZjRmY2MzMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="holograms_ghosts" target="_blank">Holograms/Ghosts</a></strong></p><p><img src="https://66.media.tumblr.com/7c9fd061bb05b75f0afdf4bf3a58b9d6/tumblr_inline_p6oy9pkPSh1qdiwz3_1280.gif"></p></div><p><strong>#66 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fholograms-ghost-17955725&amp;t=ZGYzOGQyNWFkM2YxNWFiY2JhMDhjNWZhMjliNmFlMmZhZjRmY2MzMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="defend_take hit" target="_blank">Defend/Take Hit</a></strong></p><p><strong><img src="https://66.media.tumblr.com/7e3c1dda61552bddce34cd271eca4bd7/tumblr_inline_p5z21ntJRV1qdiwz3_1280.gif"></strong></p><p><strong>#65 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-houses-17397188&amp;t=MGNkY2Y2ZjJhYzA0YjU4MDk5YjQ3ZmZhZTRjZTEyNDM2OTMwYWNmOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_houses" target="_blank">Top Down Houses</a></strong></p><p><strong><img src="https://66.media.tumblr.com/446bc1174a502f308ba129373d10d8e4/tumblr_inline_p5cf1kOWo31qdiwz3_1280.gif"></strong></p><p><strong>#64 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fice-and-snow-17113157&amp;t=OWJkZGNlY2FiM2ZlODAxY2Y4YTU1NzA4MGJmMmQ2YjZiMDY2MjI3OCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="ice" target="_blank">Ice</a></strong></p><p><strong><img src="https://66.media.tumblr.com/6717e8d14a5e39f02c7933835f9af992/tumblr_inline_p4ilt5P9Vl1qdiwz3_1280.gif"></strong></p><p><strong>#63 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fspaceship-design-16838125&amp;t=ODU0YTBkOGE3MmMxOTA2N2QwNTdmMDkwYmYxM2E0YWQzYjIyMjhlYyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="spaceships" target="_blank">Spaceships</a></strong></p><p><strong><img src="https://66.media.tumblr.com/58ab0bfc18e1ffeed0fab0bff95e32fe/tumblr_inline_p3szrphVi41qdiwz3_1280.gif"></strong></p><p><strong>#62 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fslide-roll-dash-16562907&amp;t=MzljOWQ5YjhkYjViNDIzNWQ2MmI1MzI2NjAyNzFlZWYwYzJkODExMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="slide_roll_dash" target="_blank">Slide/Roll/Dash</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fslide-roll-dash-16562907&amp;t=MzljOWQ5YjhkYjViNDIzNWQ2MmI1MzI2NjAyNzFlZWYwYzJkODExMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="slide_roll_dash" target="_blank"><img src="https://66.media.tumblr.com/158a10c2f4e97122281be2abfd631010/tumblr_inline_p336l6aiMT1qdiwz3_1280.gif"></a></strong></p><p><strong>#61 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwall-slide-wall-16310292&amp;t=ZWZiMGJhZWNjMDcyYjVjNzk4YjVmMDcwNGIzYTBiNDgzYzNjZjdjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wall_slide" target="_blank">Wall slide/kick</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwall-slide-wall-16310292&amp;t=ZWZiMGJhZWNjMDcyYjVjNzk4YjVmMDcwNGIzYTBiNDgzYzNjZjdjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wall_slide" target="_blank"><img src="https://66.media.tumblr.com/8b81155cc8cd14668d5a152887aad295/tumblr_inline_p2eoqrzfHA1qdiwz3_1280.gif"></a></strong></p><p><strong>#60 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmodern-indoors-16066669&amp;t=OWM3NzU3ZGQ1MDQ0ODgzMGM1Y2FlNmExMzliYjVmZDUxZmVkZjU2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="modern_indoors" target="_blank">Modern/indoors</a></strong></p><p><strong><img src="https://66.media.tumblr.com/ac73f2a15fd31defe34ac2f5d956b31d/tumblr_inline_p1orxgcJmD1qdiwz3_1280.gif"></strong></p><p><strong>#59 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdeath-take-hit-15846738&amp;t=YjY2NGJiNDk5YTNkNjE4NDkxYWRiYjUyMzQ2NjdiNTQ1NTE1ZDE2ZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="death_take_hit" target="_blank">Death/take hit</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdeath-take-hit-15846738&amp;t=YjY2NGJiNDk5YTNkNjE4NDkxYWRiYjUyMzQ2NjdiNTQ1NTE1ZDE2ZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="death_take_hit" target="_blank"><img src="https://66.media.tumblr.com/04f5810a3d0a53ed58c75c9ce6d82475/tumblr_inline_p0yqobOhwU1qdiwz3_1280.gif"></a></strong></p><p><strong>#58 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsand-15587559&amp;t=NjMwYzllNDA4OTFhZDgzZDIxMmFjMWVlMmJhMjdjZDlkNjkzMGViZCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="sand_desert" target="_blank">Sand/desert</a><br></strong><br><img src="https://66.media.tumblr.com/32aba2ba47850b9a6b85dcf5e19a99aa/tumblr_inline_p06zrg4DCB1qdiwz3_1280.gif"></p><p><strong>#57 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-15480982&amp;t=Y2Y3MzVjNTcwMjE4NWE1NDNjMTQwODhlMjI0YzBjMWRkOTAyMGM5NixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_part_3" target="_blank">Vegetation (part 3)</a></strong></p><p><strong><img src="https://66.media.tumblr.com/acd7dbec5acc6aa3635ede99314b8391/tumblr_inline_oztzxuuvxS1qdiwz3_1280.gif"></strong></p><p><strong>#56 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fcuteness-15259004&amp;t=Y2ExZDMzNTczM2Q2ZWI3MTgxMTI4ZmRjNjA4MWYwOWFiNzJkMzc5MSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="cuteness" target="_blank">Cuteness</a></strong></p><p><strong><img src="https://66.media.tumblr.com/fcf215f45da76769402971bd6d60a315/tumblr_inline_oz408xixEC1qdiwz3_1280.gif"></strong></p><p><strong>#55 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmodular-15160612&amp;t=YjcxNTE2ZTEwYjBjN2Q4Mzc0NDE5NzI3ZTZlODViMjBjNWQxZWUxOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="modular_animation" target="_blank">Modular animation</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmodular-15160612&amp;t=YjcxNTE2ZTEwYjBjN2Q4Mzc0NDE5NzI3ZTZlODViMjBjNWQxZWUxOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="modular_animation" target="_blank"><img src="https://66.media.tumblr.com/c33e906894e5f1de8a68715a2b1a0d37/tumblr_inline_oyt1js58Q61qdiwz3_1280.gif"></a></strong></p><p><strong>#54 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fbreaking-objects-15022934&amp;t=ZTY2YmMwODEwZTA0YTQzMzhiMzVkNDM1Njc5ZGNjNWIxYTM0MWI2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="breaking_objects" target="_blank">Breaking objects<br></a><br><img src="https://66.media.tumblr.com/6564f44187d76bbcfb536fd26302bd69/tumblr_inline_oydxyzvL4n1qdiwz3_1280.gif"></strong></p><p><strong>#53 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdarkness-14908368&amp;t=YzQ0NjVjMjI5OWE4MjUyMTE3MDQxZjM0NzQ1ZDExOGI5ZjE2NDFmOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="darkness" target="_blank">Darkness<br></a></strong><br><img src="https://66.media.tumblr.com/8f080ee4dca5a9df14cfb83cbb5ddd12/tumblr_inline_oy15kgYIxL1qdiwz3_1280.gif"></p><p><strong>#52 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fui-9-slice-14798512&amp;t=NGEwNWNjMDFlOGE0N2RiMWVmM2QyYzRmOTljMWY0NWE0MTA5ODZhNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="ui_the_9_slice" target="_blank">UI: the 9-slice</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fui-9-slice-14798512&amp;t=NGEwNWNjMDFlOGE0N2RiMWVmM2QyYzRmOTljMWY0NWE0MTA5ODZhNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" target="_blank"><img src="https://66.media.tumblr.com/1f3f84b2a0d216cc9a619591570af461/tumblr_inline_oxo0ss6cS51qdiwz3_1280.gif"></a></strong></p><p><strong>#51 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F1-bit-14560658&amp;t=MjZmYzdlY2Y5OWU1YjFmZmE4OWRhYTRjODg2OWJjN2UwNGI2ZTRjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="1_bit" target="_blank">1-Bit</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F1-bit-14560658&amp;t=MjZmYzdlY2Y5OWU1YjFmZmE4OWRhYTRjODg2OWJjN2UwNGI2ZTRjNixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="1_bit" target="_blank"><img src="https://66.media.tumblr.com/6f8116faee656165c4bb5e07c2d8b96f/tumblr_inline_owypd7zuGz1qdiwz3_1280.gif"></a></strong></p><p><strong>#50 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwind-tornado-50-14452186&amp;t=NWI0ZThkZTZjYjNhMzQ1M2EwOTE3ODA1OTQ5MmM4OTU0YTI1MTc1ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wind" target="_blank">Wind</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwind-tornado-50-14452186&amp;t=NWI0ZThkZTZjYjNhMzQ1M2EwOTE3ODA1OTQ5MmM4OTU0YTI1MTc1ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wind" target="_blank"><img src="https://66.media.tumblr.com/d457d93b485de7b10bd0b779a7a17160/tumblr_inline_owlmtk9ILF1qdiwz3_1280.gif"></a></strong></p><p><strong>#49 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2FbePatron%3Fu%3D2279992&amp;t=ZDI3OTAxZmNiNzI1N2VlOTJlMzU5YTVmYWIwNWZkZjczODM1NTljZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="space_stars" target="_blank">Space/stars</a></strong></p><p><strong><img src="https://66.media.tumblr.com/1e016fc3490e95f76fdb552072cd4c1d/tumblr_inline_ow8o0d0AFc1qdiwz3_1280.gif"></strong></p><p><strong>#48 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-walk-14234033&amp;t=MmY0M2IyZDQ4NTRjY2UwNGI5NjZhNGE1MjMwOGVlZWMzMTU3OTQzMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="walk_cycle" target="_blank">Walk cycle</a></strong></p><p><strong><img src="https://66.media.tumblr.com/6759dacdbc0f4dd6e69257629960713f/tumblr_inline_ovvd6rE4kC1qdiwz3_1280.gif"></strong></p><p><strong>#47 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Foutlines-14106192&amp;t=Y2VmZTZmZmFmZTRjMTcwOTg2ZjQxYWRkMzlhOTliZDhjMjM4ZGEyOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="outlines" target="_blank">Outlines<br></a><br><img src="https://66.media.tumblr.com/b1a3e5b4957aa2f44f5e8b27cdcee0e4/tumblr_inline_ovisyu8VPn1qdiwz3_1280.gif"></strong></p><p><strong>#46 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fquadruped-walk-14012170&amp;t=MjgyNTg4NWFmZDc2ZDZiZDQxYjk3M2ZjYWE0ZmFlOTRjMTFlNDQyYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="quadrupeds_walk" target="_blank">Quadrupeds walk/trot</a></strong></p><p><strong><img src="https://66.media.tumblr.com/1b921bdc088dd7c34a82aaa2b825b1ba/tumblr_inline_ov7mlgD0Xy1qdiwz3_1280.gif"></strong></p><p><strong>#45 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fshading-13869731&amp;t=ZDMyZGE3ZjQ5M2UwMWNmYWNhYWY4YTUxYTc0NDAxYzkzN2YzZTVhMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="shading" target="_blank">Shading</a></strong></p><p><strong><img src="https://66.media.tumblr.com/dd0829f69076cd6dbb4a634187d91f33/tumblr_inline_ouuq70nKac1qdiwz3_1280.gif"></strong></p><p><strong>#44 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fclouds-13744795&amp;t=ZTFhYmRiYzI2N2E3NzdlYjExMmQ1NmJmNTcxNWM1MDVkMDlmODliNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="clouds" target="_blank">Clouds</a></strong></p><p><strong><img src="https://66.media.tumblr.com/c5cc799376bd29e27e2428287e07f157/tumblr_inline_oug2m7pJuF1qdiwz3_1280.gif"></strong></p><div><p><strong>#43 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fenvironmental-13569268&amp;t=YWMwMDFjNGIxNzE4ZjUwNjI4ZDVlNTViZjZjYzVhMTI0ZDgyY2ZkYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="environmental_hazards" target="_blank">Environmental hazards</a></strong></p><p><img src="https://66.media.tumblr.com/0520c37e79b4cdeaefd44094ba9249ca/tumblr_inline_ou2cmw0eNy1qdiwz3_1280.gif"></p></div><p><strong>#42 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffabric-flags-13288135&amp;t=YmY3MTdjM2RjNzE4MDk0ZWZjNmRlYmJhYTAyMjJlZmEzYWEyMDg2NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fabric_flags" target="_blank">Fabric/Flags</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffabric-flags-13288135&amp;t=YmY3MTdjM2RjNzE4MDk0ZWZjNmRlYmJhYTAyMjJlZmEzYWEyMDg2NSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fabric_flags" target="_blank"><img src="https://66.media.tumblr.com/12bae334cfc713751d430b2be205d783/tumblr_inline_otpupsodce1qdiwz3_1280.gif"></a></strong></p><p><strong>#41 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fblood-and-guts-13092502&amp;t=NmJhMWVlZDU2ZDFlOWE2ZTFiMTU4ZjllYmVmMGYxM2Y2YjA1NGYyMCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="blood_and_guts" target="_blank">Blood and guts</a></strong></p><p><strong><img src="https://66.media.tumblr.com/16de890557bee9a6ddde41ecd7bff166/tumblr_inline_otchccuVi21qdiwz3_1280.gif"></strong></p><p><strong>#40 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmaking-tiles-12881715&amp;t=YTlhM2FjZGM2NmEwYzZiNzgwN2I0NTkyMzI2MWEzNjg4YmRlYjViMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="making_tiles" target="_blank">Making tiles</a></strong></p><p><strong><img src="https://66.media.tumblr.com/81e7da5a93664746b2ab7d2f8ab86c7a/tumblr_inline_oszpmzEqqA1qdiwz3_1280.gif"></strong></p><p><strong>#39 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fcharacter-idle-12464240&amp;t=MzQ4MzUxYmM1YWMyZmJkNTUwMzZmNWMyMzkzNTY0MjE0NzM5YTMzNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="character_idle" target="_blank">Character idle</a></strong></p><p><strong><img src="https://66.media.tumblr.com/ed4ce7ac0af70344aa71f6592dc52a1f/tumblr_inline_osoosucFqj1qdiwz3_1280.gif"></strong></p><p><strong>#38 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fbullets-12176568&amp;t=Y2UzYzE1NTk4ZDU4MzFmMmE4MTAyNWI5OTQyNTE2ZmRkYWQ4NThlNSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="bullets" target="_blank">Bullets</a></strong></p><p><strong><img src="https://66.media.tumblr.com/465c75a2dd8e00c8147ba8c34117a4a4/tumblr_inline_os9wwuenmW1qdiwz3_1280.gif"></strong></p><p><strong>#37 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmetals-11859263&amp;t=OTBiMjQ3NmI1MjM1NGEzYjIxZjI3NGI0YmJhZWNlNTAxMTI0NWU0OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="metals" target="_blank">Metals</a></strong></p><p><strong><img src="https://66.media.tumblr.com/4def0d40293de8e12e53eca02b9d856b/tumblr_inline_os0zezXKPr1qdiwz3_1280.gif"></strong></p><p><strong>#36 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsquash-and-11713421&amp;t=YjU2NTBkYTg1M2IzYTZiMGFhNDA1ZGNkNzljY2FiNmJkMmI1NGIwOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="squash_and_stretch" target="_blank">Squash and stretch</a></strong></p><p><img src="https://66.media.tumblr.com/febaa555f55d54b0116e758a5e6e33e9/tumblr_inline_orjleve9zU1qdiwz3_1280.gif"></p><p><strong>#35 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmotion-blur-11596285&amp;t=YjA5YjM3MmNlMTU1MDM4ODZiYTYzMDgxZWRlMTYyNGU3NjM5MTAxMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="motion_blur" target="_blank">Motion blur</a></strong></p><p><img src="http://i.imgur.com/WQ6WdOF.gif"></p><p><strong>#34 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmotion-blur-11596285&amp;t=YjA5YjM3MmNlMTU1MDM4ODZiYTYzMDgxZWRlMTYyNGU3NjM5MTAxMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="city_backgrounds" target="_blank">City backgrounds</a></strong></p><p><strong><img src="https://66.media.tumblr.com/b9a075aa4db065f5117e63e36f21b102/tumblr_inline_orlnm2ltXC1qdiwz3_1280.gif"></strong></p><p><strong>#33 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fpixel-art-part-2-11225146&amp;t=ZTYxMzRmZDhhODQ0NWQzZmNhYTE0MzE2MjMzYWUyNjYwNWE0YmM2OSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_art_fundamentals&quot;&quot;" target="_blank">Pixel art fundamentals - part 2</a></strong></p><p><img src="https://66.media.tumblr.com/07a35e4721111086107360f5dde30405/tumblr_inline_orlnp1zp5b1qdiwz3_1280.gif"></p><p><strong>#32 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-10886532&amp;t=YTRlNzFmMGE0NDgxMDU2MTBlZmM5NGQxYjVlNTY1ZGQxMGY2NzRkYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_tutorial_part_2" target="_blank">Vegetation tutorial - part 2</a></strong></p><p><strong><a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-10886532&amp;t=YTRlNzFmMGE0NDgxMDU2MTBlZmM5NGQxYjVlNTY1ZGQxMGY2NzRkYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_tutorial_part_2" target="_blank"><img src="https://66.media.tumblr.com/6eee0221675fe00e7ef022e6974a73b7/tumblr_inline_orlnpnNUR91qdiwz3_1280.gif"></a></strong></p><p><strong>#31 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Frock-formations-9856719&amp;t=YjIzYTFlYThhMzgzMmUzM2YyNGVhOThlYzZmMmQ0YzQzYzc4MTFhYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="rock_formations" target="_blank">Rock formations</a></strong></p><p><img src="https://66.media.tumblr.com/8ecbf0419be33eacf34e0254f015a9cc/tumblr_inline_orlnq6xMOH1qdiwz3_1280.gif"></p><p><strong>#30 <a href="https://t.umblr.com/redirect?z=denied%3A%2522https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffluids-slimes-929310&amp;t=ZjNiYzc3YTIxMGNkNGVhOWQxNTM5YjMwODVlMjQzMjU1MDc4NTc0YixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fluis_slime" target="_blank">Fluids/Slime</a></strong></p><p><img src="https://66.media.tumblr.com/bc2dae24ca515ded9e26742af77ae728/tumblr_inline_orlnrvmBLz1qdiwz3_1280.gif"></p><p><strong>#29 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwings-flying-8869136&amp;t=OGNlYTVhMTI5Y2UwMjhkZjZlZTdkNTVmM2ZkMDdmZmQ0Mzc5ODZhOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="wings_flying tutorial" target="_blank">Wings/Flying tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/021149062db027e39b5a5895f6489c4d/tumblr_inline_orlnshpN511qdiwz3_1280.gif"></p><div><p><strong>#28 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Flight-magic-8781428&amp;t=NTAwNjBkMjNiYWU5MDM5MTllZTRhZDg4N2JlNjFiZTQ0ZmRiOWY3YyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="light_magic_effects" target="_blank">Light Magic Effects</a></strong></p><p><img src="https://66.media.tumblr.com/4ec68347d9ca8883694db62edab08dab/tumblr_inline_orlnsytOD71qdiwz3_1280.gif"></p></div><div><p><strong>#27 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fportraits-8693396&amp;t=MmNkYzg0NjNmOWUxMTkwMmZhYmNiYmRiMWQxNWM4MzE4MTA2OWI1YyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="portraits" target="_blank">Portraits</a></strong></p><p><img src="https://66.media.tumblr.com/5a2c87747dadf61ce6411d6ce62f68be/tumblr_inline_orlntjXTDN1qdiwz3_1280.gif"></p></div><p><strong>#26 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fdark-magic-8600078&amp;t=NGFmYTllMmE1Y2I0ZDJiMTRhM2Y0MzU2YmI4NDFmY2VmYWFlZTk0NCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="dark_magic_effects" target="_blank">Dark Magic Effects</a></strong></p><p><img src="https://66.media.tumblr.com/c31c60c3a9bc6792dd6ae2f1a8417327/tumblr_inline_orlnu2Blmc1qdiwz3_1280.gif"></p><p><strong>#25 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fspaceship-8518887&amp;t=OGZjM2IzMGFiZGE1YTZkZWY3YTRmOWUyOTRiYzBmNjUyNzU1MmViZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="spaceship_propulsion_tutorial" target="_blank">Spaceship propulsion tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/00e6aad68c668d65b067f2af736a8a80/tumblr_inline_orlnvr6vA11qdiwz3_1280.gif"></p><p><strong>#24 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fruins-tutorial-8183989&amp;t=ZmI3ZTFhM2E1ZTNmZWMyNTlhZTFlNTViODkxYjIwNzdhNTdmOTViZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="ruins_tutorial" target="_blank">Ruins tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/205888769a88fae746d9c7b448afbd68/tumblr_inline_orlnw86N3e1qdiwz3_1280.gif"></p><p><strong>#23 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fpixel-art-8107774&amp;t=MGE4MzU2ZjFlNmYxNjUzODJlMTQ2ZGRhMmYwYTNmNDhlZjhlZDE3MCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_art_process" target="_blank">Pixel art process</a></strong></p><p><img src="https://66.media.tumblr.com/5946dc48dc257f65aa7e9f17a451df24/tumblr_inline_orlo18yAGa1qdiwz3_1280.gif"></p><p><em>Reading text with a timer is a bit stressful, so I added still frames of this tutorial:</em></p><p><img src="https://66.media.tumblr.com/62ba7558e5fedd68ef81cf347dde237e/tumblr_inline_ooxczkeRHC1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/b6c46fb3f9fb83f39d429e7ab094e622/tumblr_inline_ooxd08TEod1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/4e338c6a6207f15b3da9c6abb086b973/tumblr_inline_ooxd0cZmWm1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/830a2f6a3082b8b31ed2610decb0c14d/tumblr_inline_ooxd0fI4rX1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/ae28465631d7bd9768ad5471368110bf/tumblr_inline_ooxd0j6VT91qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/ffb990c7ca4a7b0b64c0817e04266cdb/tumblr_inline_ooxd0nVSNx1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/391f1da109ac109c6e75a5f84112c229/tumblr_inline_ooxd11rnmR1qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/38499d507673bf66b12de08d68467545/tumblr_inline_ooxd15Ds031qdiwz3_1280.png"></p><p><img src="https://66.media.tumblr.com/f686c03f4ae745f22f9aafa03766b92a/tumblr_inline_ooxd1aEUYz1qdiwz3_1280.png"></p><p><strong>#22 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fanimation-easing-8030922&amp;t=ZjA2MTk5NTlhOGI3ZDU1YWUyMDEyMDg1ZWE3ZjNiYzQ4YjA3MzM1MyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="animation_easings" target="_blank">Animation Easing</a></strong></p><p><img src="https://66.media.tumblr.com/aa1ee58decd2fb3100c47429ea61f31d/tumblr_inline_orlo2xZqfx1qdiwz3_1280.gif"></p><p><strong>#21 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Frender-tricks-7947098&amp;t=MDMxNjBkMmJhNDEyMTkwNWJjYjVhMDE5NGM1ZTMzMzhiNGQzNWVjMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="render_tricks" target="_blank">Render Tricks</a></strong></p><p><img src="https://66.media.tumblr.com/9a7eb190e3c573c45b5872632d47c524/tumblr_inline_orlo3psQ0i1qdiwz3_1280.gif"></p><p><strong>#20 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fparallax-and-7863658&amp;t=ODBlZTE1MDViZjM2NzI0MDMwMTk1MGUxOTY1MTBmNTAxNTUzMjZmMSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="parallax_and_depths" target="_blank"> Parallax and Depth</a></strong></p><p><img src="https://66.media.tumblr.com/f5b88aef57c0b3fbed9f050d29476c8e/tumblr_inline_orlo42MjMu1qdiwz3_1280.gif"></p><p><strong>#19 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fmachines-and-7800465&amp;t=ZWEyMjRiN2RkYjhiZTkyMDljZDc2NGE4ZWYxODc1MDQzYmUzNmIyOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="machines_and_weird_tech_tutorial" target="_blank">Machines and Weird Tech Tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/ee67155fe94fad79fe1edae446679f9e/tumblr_inline_orlo4tzTNU1qdiwz3_1280.gif"></p><div><p><strong>#18 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fexplosions-part-7719254&amp;t=ZjQyMWRjZWM2Yzc2ZjU4NjAwM2FjM2NlODVhNDVlYWQ2YjI0YTZmMyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="explosions_part_1" target="_blank">Explosions - part 1</a></strong></p><p><img src="https://66.media.tumblr.com/c108e82efee42056001fd1fcb415be5e/tumblr_inline_orlowlgPOa1qdiwz3_1280.gif"></p></div><p><strong>#17 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2F1-pixel-movement-7652033&amp;t=MTI5Yjk4MTMxZWMxMWJkOGVlOTIxYjZhODdjZWI5MTEwMTQ2NGJjOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_movement_tutorial" target="_blank">&lt;1 Pixel Movement Tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/518be4ef8ac9ecc55cbffb8fa39244c4/tumblr_inline_orlow6mIGN1qdiwz3_1280.gif"></p><div><p><strong>#16 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fanimation-7585006&amp;t=MmU2NThkODc2Yzk3OGMzNjFmZGVhMTY0MWVmMDgwNmQ3OTIzZjY2ZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="animation_planning" target="_blank">Animation planning</a></strong></p><p><img src="https://66.media.tumblr.com/f708006f5b8c3466797f53e097842831/tumblr_inline_orlot4Lxqp1qdiwz3_1280.gif"></p></div><div><p><strong>#15 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fcharacter-design-7530899&amp;t=ZTgxYWZmNzcwMzQ3MDBiYWRhMjAxM2M2MGFhNjk5ZDJkNmU0NjQ0NCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="character_desing" target="_blank">Character Desing 1</a></strong></p><p><img src="https://66.media.tumblr.com/1959e78c9b12d15931a3d64f3a82aeee/tumblr_inline_orlorl8LQ71qdiwz3_1280.gif"></p></div><div><p><strong>#14 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fskulls-and-bones-7475695&amp;t=M2IzYWNkMGVkZWU0YzUxZGVmMTRiMDI5MTFlMzNiMDRhN2FmNjcwNCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="skull_and_bones_tutorial" target="_blank">Skull and bones tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/12471723973d8df607799726db0cfaec/tumblr_inline_orlopmAovs1qdiwz3_1280.gif"></p></div><p><strong>#13 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fvegetation-part-7416630&amp;t=NzUxYmQwMDQ4ZjYxNzlhZmZmNTYzNzQxYmFiYTliN2QzYTc2YWRlYSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="vegetation_tutorial_part_1" target="_blank">Vegetation tutorial - part 1</a></strong></p><p><img src="https://66.media.tumblr.com/9ae1c51e0ff766a9ddb4fe32b1604a06/tumblr_inline_orlop1s4SE1qdiwz3_1280.gif"></p><p><strong>#12 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fseamless-7346998&amp;t=ZjliNDg4ZGM5OGQzNmFkODM5OWNhY2U5ZGQ0Y2ZmN2YxODcyYTdlNyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="seamless_animation_tutorial" target="_blank">Seamless animation tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/7c1606ece3701f0b31abc75c1fec3cf6/tumblr_inline_orlomdG0Dx1qdiwz3_1280.gif"></p><div><p><strong>#11 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ffire-tutorial-7293859&amp;t=Y2JkNTQyNDZkMDEzZTlkMjRlMzk1NjlhYWRiMTI3OWUyYTIzYzZhMixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="fire_tutorial" target="_blank">Fire tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/29476fe99b2e2eb0ed3504b5740ac40f/tumblr_inline_orlohdk66v1qdiwz3_1280.gif"></p></div><p><strong>#10 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fwater-tutorial-7242348&amp;t=NDUwZDdiNmE4ZWI1NjVmY2I3NDY4Mjg5ZTA3MjQ2ZTgzNDVlMTVmOSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="water_tutorial" target="_blank">Water tutorial<br></a></strong><br><img src="https://66.media.tumblr.com/dc4c9898545bf7a2381ed9a3516833ed/tumblr_inline_orlogobyc71qdiwz3_1280.gif"></p><div><p><strong>#9 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Flevel-design-7190330&amp;t=YzY2NGYyYzJmOTQyNmM0MGYyYTU2NWMwZTViZGM1OGJmZTcwYWNiOCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="level_design_progression" target="_blank">Level design progression</a></strong></p><p><img src="https://66.media.tumblr.com/8ba0dba7ef921d03ddc63d17f6f7cbab/tumblr_inline_orlog5ekZ11qdiwz3_1280.gif"></p></div><p><strong>#8 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fglitch-effect-7130333&amp;t=YWYwZTMyMzViZmRjOGY0YTAyMmVmMGVlMzYwZDNjNmE2YzhjNWM0OCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="glitch_effect_tutorial" target="_blank"> Glitch effect tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/ad5f9004f40554af1aa83f3d6d7513c6/tumblr_inline_orlof1K8R41qdiwz3_1280.gif"></p><p><strong>#7 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Felectricity-7075305&amp;t=MjViMzZkN2U0YmU5MDdlMmE2ODIyMDkyZGU3M2M2ODNkOTM3YjE5YixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="electricity_tutorial" target="_blank">Electricity tutorial</a></strong></p><p><img src="https://i.imgur.com/cxz6GRE.gif"></p><p><strong>#6 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Ftop-down-run-7023263&amp;t=OGI0NWQzOTk1YTc4NGJhNDQyNWI0MzA5NjQ1NzkyOWQ4ZDhkN2VhZixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="top_down_run_cycle" target="_blank">Top down run cycle</a></strong></p><p><img src="https://66.media.tumblr.com/68b72ba96ab4ea407320c56d43b6905a/tumblr_inline_orlp5ccduy1qdiwz3_1280.gif"></p><p><strong>#5</strong> <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fpixel-art-1-6971422&amp;t=OTc3YjBkNWFmOWEwYWE3OTljN2E1YWI1NzI1Mzk1N2JiNjUxYzI4MSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="pixel_art_fundamentals" target="_blank"><strong>Pixel art fundamentals</strong></a></p><p><img src="https://66.media.tumblr.com/b48321d1a3cd0a1b570dd2f696247353/tumblr_inline_orlo88y0i81qdiwz3_1280.gif"></p><p><strong>#4 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-run-6914055&amp;t=M2NhYmY2NGNiMzk1NDM3OTMyYTI4YjU5ZDhjY2MwN2MxYTYxODRmYixUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="simple_run_tutorial" target="_blank">Simple run tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/f2658a4754e27310eec0ab058dd5110a/tumblr_inline_orlo7sMewo1qdiwz3_1280.gif"></p><p><strong>#3 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsmoke-animation-6851636&amp;t=Y2I0NGVkNzk0MzI2ZDVhNTlkZDc0ZDIzNTgxMGI0NDk3Y2NhZDJmZCxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="smoke_animation" target="_blank">Smoke animation</a></strong></p><p><img src="https://66.media.tumblr.com/0a09c626ab6664aff9efaa399c279f9e/tumblr_inline_orlo74zaAn1qdiwz3_1280.gif"></p><p><strong>#2 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-attack-6837623&amp;t=MjJmZDY4M2ViNTY5NmI4NzE5ZDQ3OGRkOGJjNTNkNDZkYTM1ZjY3NyxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="simple_attack_animation" target="_blank">Simple attack animation</a></strong></p><p><img src="https://66.media.tumblr.com/f725cae9165d047c2f669ec4b204ccba/tumblr_inline_orlo6o5lyD1qdiwz3_1280.gif"></p><p><strong>#1 <a href="https://t.umblr.com/redirect?z=https%3A%2F%2Fwww.patreon.com%2Fposts%2Fsimple-shine-6837557&amp;t=NjkzMmNlYzU4NWVhMDM1Nzg1ZGU2NjdkYTBmMjcwNjc4MTQzMWY0ZSxUbU4zdWpESg%3D%3D&amp;p=&amp;m=0" id="simple_shine_tutorial" target="_blank">Simple shine Tutorial</a></strong></p><p><img src="https://66.media.tumblr.com/4fcef2a23bdcd59c03d432c7e3361b7e/tumblr_inline_orlo5uLdb71qdiwz3_1280.gif"></p>
              </div>
          

          

          

          

          

          

          

          

          

          

          

          
            

            
          

          </div><!-- /.post-panel -->
          
        </article><!-- /.post -->
      
      <!-- END POSTS -->

      

      

      

    </div></div>]]>
            </description>
            <link>https://blog.studiominiboss.com/pixelart</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663148</guid>
            <pubDate>Sat, 27 Jun 2020 17:28:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ultrasound Networking (2014)]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23663097">thread link</a>) | @funspectre
<br/>
June 27, 2020 | https://www.anfractuosity.com/projects/ultrasound-networking/ | <a href="https://web.archive.org/web/*/https://www.anfractuosity.com/projects/ultrasound-networking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                        




<p>We present a simple to use implementation of networking across ultrasonic frequencies, by making use of Gnuradio and a microphone and speakers. This allows you to use <strong>TCP/IP</strong>,<strong>UDP</strong> across an audio link.</p>



<p>In order to follow this tutorial we recommend you use the LiveDVD release of Gnuradio (which is basically a Ubuntu distribution, with gnuradio already installed). This is easily downloadable from <a href="https://gnuradio.org/redmine/news/31">http://gnuradio.org/redmine/news/31</a>. First of all you will need to download the patch we made to Gnuradio, to a USB stick. You can download the patch from <a href="https://github.com/anfractuosity/ultrasonicnetworking/archive/master.zip">https://github.com/anfractuosity/ultrasonicnetworking/archive/master.zip</a>. In order to use the patch, you need to be root, so type <strong>‘sudo bash’</strong>, then unzip the patch, and simply run setup.sh, by typing <strong>./setup.sh</strong>. The setup file simply patches the Gnuradio packet encoder and decoder, in order to support variable length packets.</p>



<p>After running <strong>setup.py</strong>, you can then initialise Gnuradio, which you need to run as root, so do <strong>sudo gnuradio-companion</strong>. And then load a.grc on your first laptop.</p>



<p><strong>Figure 1</strong> depicts our graph which enables us to perform the ultrasonic networking. We will now describe how the graph functions through each block. The first block in the top left, is the TUNTAP PDU, this allows you to create a virtual network interface, through which we can send and receive packets.</p>



<p>We use the “PDU to tagged Stream” block to convert the packets received from the virtual NIC, into a byte stream for the packet encoder to process. We can’t directly attach the output of the tagged stream to the GFSK modulator, as we need to add a checksum, through the use of CRC and also we need to add a preamble and header onto the packet – this is all achieved through the use of the packet encoder.</p>



<p>A preamble is essentially a series of bits, which can be detected at the receiver end, in order to correctly align bits, to the correct byte boundaries. The packet encoder, also adds a header after the preamble, which states how long the packet is, in bytes.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1-1024x558.png" alt="Screenshot" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1-1024x558.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1-300x163.png 300w, https://www.anfractuosity.com/wp-content/uploads/2014/02/screen1.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p><strong>Fig. 1</strong><br></p>



<p>The GFSK modulator essentially performs Frequency Shift Keying modulation. As you can see in <strong>Figure 2</strong>, the frequency of the modulated signal is lower, when a ‘0’ is being sent, than a ‘1’ being sent. We found that in the context of ultrasonic networking using laptops and microphones, that FSK performed better than PSK (Phase Shift Keying – which uses phase changes, to communicate bits), which is another modulation technique.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk.png" alt="fsk" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk.png 533w, https://www.anfractuosity.com/wp-content/uploads/2014/02/fsk-266x300.png 266w" sizes="(max-width: 533px) 100vw, 533px"></a></figure>



<p><strong>Fig. 2 (courtesy <a href="https://en.wikipedia.org/wiki/File:Fsk.svg">wikipedia</a>)</strong></p>



<p>A very important aspect of the GFSK block is the number of Samples/Symbol. We set this to a value of 9. This means that for each symbol received by the modulator, 9 samples are generated. The higher this number the more resilient the signal is to noise, but consequentially the lower the baud rate (which essentially means the longer it takes to send packets).<br>Baud rate refers to the number of symbols which are transferred per second.</p>



<p>We then use the rational resampler block, to make the signal further resilient. For every sample in, it generates 320 out.</p>



<p>We use a frequency-translating FIR filter, to translate the frequency of the incoming signal. We shift the signal by -carrier_tx, which is -19kHz in this example. This is so that the signal is just outside of the human range of hearing.</p>



<p>As we have been working with complex signals at this point, we need to convert the complex output into a floating point output for the audio card, we achieve this through the use of a ‘Complex to Real’ block.</p>



<p>The bottom part of the graph, depicts the receiver section of the program. It essentially performs the same functions, but in reverse.<br>However there are two additional blocks after the ‘Float to complex’ block. The multiply const block, allows you to multiply the output from the microphone by a fixed number. The block after this is a bandpass filter, to only allow a small range of frequencies to pass through to the demodulator, this helps remove a large amount of noise which is present from the microphone’s output.</p>



<p>In <strong>Figure 3</strong>, you will see that there are two graphs. The top graph, depicts the output sent to the transmitter and the bottom graph depicts the input received from the microphone (after a bandpass filter has mean applied to it). There is also a slider present at the top which allows you to multiply the signal from the microphone by a specific value. This is useful when using 2 laptops which are a greater distance away from each other.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/fft.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/fft.png" alt="fft" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/fft.png 762w, https://www.anfractuosity.com/wp-content/uploads/2014/02/fft-150x150.png 150w, https://www.anfractuosity.com/wp-content/uploads/2014/02/fft-300x298.png 300w" sizes="(max-width: 762px) 100vw, 762px"></a></figure>



<p><strong>Fig. 3</strong><br></p>







<p>Figure 4 depicts the full duplex signalling we use. You can see that we transmit in this example at two different frequencies, 19kHz and 18kHz. This allows both laptops to send their own signal simultaneously.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/clip.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/clip.png" alt="clip"></a></figure>



<p><strong>Fig. 4</strong><br></p>







<p>In Gnuradio-companion, you will need to go to Build &gt; Execute, in order to execute the graph. You then need to assign an IP address to the tap0 interface it creates for you. You need to do this through a terminal, typing <strong>sudo ifconfig tap0 192.168.1.10</strong> for instance.</p>



<p>You need to perform the same steps on your second laptop, B, but instead this time loading b.grc, and using <strong>sudo ifconfig tap0 192.168.1.20</strong>.</p>



<p>We found it was best to assign ARP entries manually to each laptop. In order to assign an ARP entry, on laptop A, <strong>arp -s 192.168.1.20 &lt;Laptop B’s MAC address for tap0&gt; -i tap0</strong></p>



<p>The setup script, which you have initialised on both laptops copied the patched files to Gnuradio, as well as modifying TCP options, in order to allow TCP/IP to work across a very laggy network.</p>


<pre title="">echo 100 &gt; /proc/sys/net/ipv4/tcp_syn_retries
echo 0 &gt; /proc/sys/net/ipv4/tcp_syncookies
echo 100 &gt; /proc/sys/net/ipv4/tcp_synack_retries
</pre>


<p>The first line is necessary in order to enable a client side TCP connection to stay open longer than the default of 20 seconds, before closing.</p>







<p>In order to test the network is functioning correctly we recommend using netcat. To test out TCP/IP connectivity Use <strong>netcat -vv -l 10000</strong> on Laptop A, and connect to it from Laptop B, using <strong>netcat -vv 192.168.1.10 10000</strong>. Because we are using the verbose options, netcat will inform you when a connection to Laptop A has been established, you can then send text from either laptop to the other one.</p>







<p>As the packet encoder and decoder provided by Gnuradio only work with fixed amounts of data, it was necessary to modify them to support the reading of stream tags. The “PDU to tagged stream” tags packets from the tap interface with their size. The packet encoder/decoder can’t process these tags normally, so we altered the packet encoder, to read these tags, and generate the appropriate sized packet from the tap0 frame. The packet decoder, then unencapsulates the packet, and tags the resulting data, with its size.</p>







<p>To give you an idea of the latencies involved please click on the image below, which shows you a wireshark screenshot, showing the server side of a TCP/IP connection. You’ll see it’s slow!</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap-300x163.png" alt="pcap" srcset="https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap-300x163.png 300w, https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap-1024x558.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2014/02/pcap.png 1920w" sizes="(max-width: 300px) 100vw, 300px"></a></figure>







<p><a href="https://github.com/anfractuosity/ultrasonicnetworking">https://github.com/anfractuosity/ultrasonicnetworking</a></p>



<p>If anyone’s got any suggestions for improvements to the Gnuradio patch I’d be most appreciative (the patch itself was done very quickly).</p>







<p>The following video is from a previous experiment I did to simply test whether we could send data at 23kHz .</p>



<figure><iframe src="//www.youtube.com/embed/H0DKRl8XIcU" allowfullscreen="allowfullscreen" width="560" height="315" frameborder="0"></iframe></figure>







<p>Minimodem looks like a great program, but as far as I’m aware it supports only FSK. I was keen to try different modulation schemes, which Gnuradio provides many of; I originally tried the setup with PSK.</p>



<p>Also this provided me with an introduction into how some of the techniques used for Software Defined Radio work.</p>



<p><strong>With thanks to the folks on #gnuradio for their help</strong></p>
                        <br>


			
                                
                
                                
                 <!-- END #comments -->    
                	                                
                
                
                                      
                 <!-- END #leave_comment -->
                
 
                </article></div>]]>
            </description>
            <link>https://www.anfractuosity.com/projects/ultrasound-networking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23663097</guid>
            <pubDate>Sat, 27 Jun 2020 17:20:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Take control over your feeds to regain mindfulness]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23662874">thread link</a>) | @hosolmaz
<br/>
June 27, 2020 | https://solmaz.io/thoughts/digital-hygiene-feeds/ | <a href="https://web.archive.org/web/*/https://solmaz.io/thoughts/digital-hygiene-feeds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>A digital feed is an online stream of content which gets updated as new content is pushed by the feed’s sources. Generally, content is created by users on the social media platform, to be consumed by their followers.</p>
<p>All popular social media platforms feature some type of feed: Twitter, Instagram, Reddit, Facebook. Operators of these platforms benefit from increased engagement by their users, so they employ techniques designed to achieve that end. Unfortunately, they often do so at the expense of their users’ well-being. Below are 7 rules to help you retain control over your screen time, without having to leave social media for good, ordered from most important to least important.</p>
<h2 id="rule-1-avoid-non-chronological-feeds">Rule #1: Avoid non-chronological feeds</h2>
<p>On most online platforms, the order of content is determined by an algorithm designed to maximize user engagement, i.e. addict you and keep you looking at ads for as long as possible. Examples: Facebook news feed, Twitter “top tweets”, Instagram explore tab, Tiktok.</p>

<p>Your phone is always within your reach. Access feeds only on your laptop, in order not to condition yourself to constantly check it. Don’t install social media or video apps on your phone.</p>
<h2 id="rule-3-follow-with-purpose">Rule #3: Follow with purpose</h2>
<p>Your digital experience changes with each new person/source you follow. Be mindful about the utility of the information you would obtain before following a new source.</p>
<h2 id="rule-4-limit-the-number-of-peoplethings-you-follow">Rule #4: Limit the number of people/things you follow</h2>
<p>The amount of content you will have to go through increases roughly linearly with the number of sources you follow. You probably won’t see everything your 500 followees share—maybe it’s time to unfollow some of them.</p>
<h2 id="rule-5-schedule-and-limit-your-exposure">Rule #5: Schedule and limit your exposure</h2>
<p>Your brain has a limited capacity to process and hold information. Schedule a certain hour of the day to receive it, and don’t surpass it. Example: No more than 30 minutes of social media, restricted to 10–11 am.</p>
<h2 id="rule-6-block-generously-and-ruthlessly">Rule #6: Block generously and ruthlessly</h2>
<p>If you don’t like what you’re seeing, block or unfollow <em>immediately</em>. This is the hardest when someone posts content that is sometimes useful, but otherwise annoying too. Generally, we put up with it for too long until we block someone.</p>
<h2 id="rule-7-mute-words">Rule #7: Mute words</h2>
<p>Avoid toxic memes by muting related words, e.g. Trump, ISIS. This will filter out any post that contains that word. Click <a href="https://twitter.com/settings/muted_keywords">here</a> to do it on Twitter now—it’s easy.</p>
<p>Follow these simple set of rules, and restore your control over social media and your digital experience in no time.</p>
<p><em>This post made it to the Hacker News <a href="https://news.ycombinator.com/item?id=23662874">front page</a>. Also posted as <a href="https://twitter.com/onurhsolmaz/status/1276858849446813696">a Twitter thread</a>.</em></p>
</article></div>]]>
            </description>
            <link>https://solmaz.io/thoughts/digital-hygiene-feeds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662874</guid>
            <pubDate>Sat, 27 Jun 2020 16:46:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FreeDVDBoot – Hacking the Playstation 2 through its DVD player]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23662443">thread link</a>) | @farmerbb
<br/>
June 27, 2020 | https://cturt.github.io/freedvdboot.html | <a href="https://web.archive.org/web/*/https://cturt.github.io/freedvdboot.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
			<div>
				


<p><span>Initial publication: June 27, 2020</span></p><hr>

<p>
	I've <a href="https://cturt.github.io/ps2-yabasic.html">previously discussed</a> how the PlayStation 2 doesn't have any good entry-point software exploits for launching homebrew. You need to either purchase a memory card with an exploit pre-installed (or a memory card to USB adapter), a HDD expansion bay (not available to slim consoles), open up the console to block the disc tray sensors, or install a modchip. For the best selling console of all time, it deserves better hacks.
</p>

<p>
	My initial attempt to solve this problem was to <a href="https://cturt.github.io/ps2-yabasic.html">exploit the BASIC interpreter</a> that came bundeld with early PAL region PS2s. Although I was successful at producing the first software based entry-point exploit that can be triggered using only hardware that came with the console, the attack was largely criticized due to the requirement of having to enter the payload manually through the controller or keyboard, and limitation of being PAL only. I decided to write-off that exploit as being impractical, and so the hunt continued for a better attack scenario for the PlayStation 2.
</p>

<p>
	The PlayStation 2 has other sources of untrusted input that we could attack; games which support online multiplayer or USB storage could almost definitely be exploited. But unlike say the Nintendo 64, where we don't really have any other choice but to resort to <a href="https://cturt.github.io/shogihax.html">exploiting games over interfaces like modems</a>, the PlayStation 2 has one key difference: its primary input is optical media (CD / DVD discs), a format which anyone can easily burn with readily available consumer hardware. This leaves an interesting question which I've wanted to solve since I was a child:
</p>

<p>
	Is it possible to just burn our own homebrew games and launch them on an unmodified console the same way we would launch official discs (without going through any user interaction like disc swapping or triggering a network exploit in a game)?
</p>



<p>
	Ultimately, I was successfully able to achieve my goal by exploiting the console's DVD player functionality. This blog post will describe the technical details and process of reversing and exploiting the DVD player. Loading <a href="#backup">backups of commercial games is also possible</a>. All of my code is <a href="https://github.com/CTurt/FreeDVDBoot">available on GitHub</a>.
</p>

<p>
	<iframe width="560" height="315" src="https://www.youtube.com/embed/ez0y-hz3VuM" frameborder="0" allowfullscreen=""></iframe>
</p>

<br>

<h2>DVD video player attack surface</h2>
<p>
	Obviously we can't just burn a disc containing an ELF file and expect the PS2 to boot it; we'll need to exploit some kind of software vulnerability related to parsing of controlled data. The console supports playing burned DVD video discs, which exposes significant attack surface we could potentially exploit to achieve our goal.
</p>

<p>
	If we think about what a DVD Video consists of there are quite a few main components, each with the potential for vulnerabilities:
</p>

<ul>
	<li>UDF filesystem</li>
	<li>DVD Video metadata / subtitles</li>
	<li>Audio and video decoding</li>
	<li>Interaction machine</li>
</ul>

<p>
	Whilst the complete DVD Video specification is unfortunately behind a paywall, it is comprised largely of <a href="https://en.wikipedia.org/wiki/DVD-Video#Video_data">open formats like MPEG</a>, just bundled together in a proprietary container format (VOB). For the proprietary aspects there are some freely accessible unofficial references.
</p>

<p>
	The <a href="http://dvd.sourceforge.net/dvdinfo/ifo.html">IFO</a> file format is probably the simplest format used, and is responsible for storing the metadata that links the video files together.
</p>

<p>
	The interaction machine is what allows for interactive menus and games in DVD Videos. It has <a href="https://en.wikibooks.org/wiki/Inside_DVD-Video/Instruction_Set_Details">32 groups of instructions</a>, and is interesting because it could potentially be used to dynamically manipulate internal memory state to prime an exploit, or it could be used to create a universal DVD with a menu which allows you to select your firmware version and trigger the appropriate exploit.
</p>

<br>

<h2>Setup</h2>
<p>
	Clearly it's not practical to do most of our testing on the real hardware since burning hundreds of test discs would be wasteful and time inefficient. We need an emulator with some debugger support, which is where we hit our first roadblock: the most popular emulator for PlayStation 2, PCSX2, <a href="https://github.com/PCSX2/pcsx2/issues/1981">does not support playing DVD Videos</a>, and no one is interested in adding support.
</p>

<p>
	I'd like to thank krHacken for helping me out with that first roadblock. It turns out that PCSX2 does support the DVD player; it just can't load it automatically since it's located in encrypted storage and PCSX2 does not support the decryption. There are public tools which can <a href="https://github.com/xfwcfw/kelftool">decrypt</a> and <a href="https://github.com/jimmikaelkael/eromdir">extract</a> the DVD player from EROM storage. It can then be repacked into an ELF for easy loading into PCSX2.
</p>

<p>
	Due to the large number of different PlayStation 2 models released, each with slightly different DVD player firmwares (&gt; 50...), I will focus on a single DVD player for the duration of this article: 3.10E (configured with English language in PS2 settings), as it happens to be the firmware for the console I own. Update: apparently the 3.10E exploit described here works on 3.10U console with no changes.
</p>

<p>
	I will continue to use Ghidra for decompilation as I've been using throughout my <a href="https://cturt.github.io/ps2-yabasic.html">previous</a> articles. The DVD player does not contain any symbols so all names in code snippets were assigned by me through reverse engineering.
</p>

<br>

<h2>Disc controlled data</h2>
<p>
	The first file a DVD player will attempt to read is <code>VIDEO_TS.IFO</code>. Searching memory for contents of the file and then setting memory write breakpoints there to track back where it was written we quickly locate the API that reads disc contents used by the IFO parsing code, <code>getDiscByte</code> at <code>0x25c920</code>. It's a stream reader which caches a number of sectors into a RAM buffer, and then automatically seeks more data once needed:
</p>

<pre><code>byte getDiscByte(void) {
	byte ret;
	
	if (currentDiscBytePointer &lt; endDiscBytePointer) {
		ret = *currentDiscBytePointer;
	}
	else {
		currentDiscBytePointer = &amp;buffer;
		setOffset = setOffset + numberOfSectorsRead;
		getDiscByteInternal();
		ret = *currentDiscBytePointer;
	}
	currentDiscBytePointer = currentDiscBytePointer + 1;
	return ret;
}
</code></pre>



<p>
	From searching calls to this, we can also quickly find wrappers that fetch data of larger sizes: <code>getDiscU16</code> (<code>0x25c980</code>), <code>getDiscU32</code> (<code>0x25c9b8</code>), and <code>getDiscData</code> (<code>0x25c9f0</code>), which is the most interesting as it reads an arbitrary length of data:
</p>

<pre><code>void getDiscData(uint size, byte *destination) {
	byte b;
	uint i;
	
	i = 0;
	if (size != 0) {
		do {
			i = i + 1;
			b = getDiscByte();
			*destination = b;
			destination = destination + 1;
		} while (i &lt; size);
	}
	return;
}
</code></pre>

<h2>Large reads</h2>
<p>
	The first thing I did was search for calls to <code>getDiscData</code> in the hope of finding one with controllable size, and no bounds checking.
</p>

<p>
	Sure enough, we very quickly identify about 4 blatant buffer overflow vulnerabilities of this nature. Relating back to the <a href="http://dvd.sourceforge.net/dvdinfo/ifo.html">IFO</a> file format, we can see that there are numerous 16-bit array lengths which are needed to parse the variably sized data structures in the file. The DVD player mistakenly only ever expects the maximum lengths allowed by the DVD specification, and so it is missing checks to reject discs with larger lengths. Since all of the copies are done on statically allocated memory buffers, specifying larger than allowed lengths will cause buffer overflows. For example, below is decompilation for the one at <code>0x25b3bc</code>:
</p>

<pre><code>		large1 = getDiscU16();
		large2 = getDiscU16();
		large3 = getDiscU16();
		ignored = getDiscU16();
		getDiscData(((uint)large1 + (uint)large2 + (uint)large3) * 8, &amp;DAT_0140bdd4);</code></pre>



<p>
	This one is the most interesting because it allows the largest possible copy size (<code>0xffff * 3 * 8 = 0x17FFE8</code> bytes) of all the <code>getDiscData</code> buffer overflows. It copies into the statically allocated buffer at <code>0x0140bdd4</code>, and so by specifying the maximum possible copy size we gain control over the address space from <code>0x140bdd4</code> to <code>0x158BDBC</code> (<code>0x140bdd4 + 0x17FFE8</code>).
</p>

<br>

<h2>Corruption from the large reads</h2>
<p>
	As you can see, we can control quite a large region of memory using the above vulnerability. However, scanning through that memory is initially very disappointing; there are very few pointers, and none of them look particularly interesting to corrupt!
</p>

<p>
	Although there are no interesting pointers in this region, there are some indexes, which if corrupted could lead to further out of bounds memory corruption.
</p>

<p>
	Note that large reads like this won't always copy contiguous data from the IFO file, as sectors will start repeating once we exceed the file size, but generally assume that all data written by a <code>getDiscData</code> call can be controlled as it originates from <i>somewhere</i> on the disc. Also, after writing a certain amount, we may overflow into internal state used by <code>getDiscByte</code> functions, but we will get to this later.
</p>

<br>

<h3>OOB call</h3>
<p>
	At <code>0x25e388</code> we have this call to an entry in a function pointer array, where we can control the 16-bit <code>fpIndex</code> at <code>0x141284a</code> from the overflow:
</p>

<pre><code>(*(code *)(&amp;PTR_LAB_005b9d40)[(uint)fpIndex])(puVar6 + ((uint)DAT_01412841 - 1) * 8);</code></pre>



<p>
	This allows us to jump to the address stored anywhere from <code>0x5b9d40</code> up to <code>0x5b9d40 + 0xffff * 4 = 0x5F9D3C</code>.
</p>

<br>

<h4>Exploiting OOB call</h4>
<p>
	This primitive is not quite ideal, as none of our overflow bugs allow us to control the memory where the jump targets are read from. Worse still, most of this memory region is mapped from a read-only section of the DVD Player, so it's unlikely that we can influence the contents of this memory region without another bug.
</p>

<p>
	After the function pointers, we do some see some addresses for <code>switch</code> <code>case</code> labels, which is slightly interesting because that allows us to jump into the middle of a function and execute its epilogue without having executed its prologue, allowing us to misalign the stack pointer and return to an unexpected value on the stack. I went through all of these and unfortunately I was only ever able to use that to jump to <code>0</code>.
</p>

<p>
	Finally after the code pointers, we see read only string data. Interestingly, this data can be changed by switching languages in the PS2 menu, which gives greater hope for finding at least 1 usable jump target in every firmware version, however it unfortunately comes at the cost of forcing the user to reconfigure their language.
</p>

<p>
	I decided to …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cturt.github.io/freedvdboot.html">https://cturt.github.io/freedvdboot.html</a></em></p>]]>
            </description>
            <link>https://cturt.github.io/freedvdboot.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662443</guid>
            <pubDate>Sat, 27 Jun 2020 15:32:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cache Oblivious Algorithms]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23662434">thread link</a>) | @tardygrade
<br/>
June 27, 2020 | https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/ | <a href="https://web.archive.org/web/*/https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

    

    
      

    

    
<p><a href="https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/" title="Cache Oblivious Algorithms">
        <img src="">
    </a>
</p>



    
<p>Cache-oblivious algorithms seemed incredible to me when I first heard about it in 6.854 (Advanced Algorithms). It’s relatively straightforward to imagine algorithms that utilizes information about page size $B$ and cache size $M$ to create efficient data structures. However, cache-oblivious algorithms are algorithms that achieve similar efficiencies <em>without knowing $B$ or $M$</em>. That means the same cache-oblivious algorithm can be ran on computers with different cache or page sizes and still achieve the same asymptotic efficiency as one that is tailored to that specific cache. The key to many of these algorithms is a recursive, fractal-like idea. I’ll describe a cache-oblivious algorithm for searching in a list of integers.</p>

<p>Here’s the set up. (TLDR at bottom) A program executes on the processor, but the input data resides on the disk. We can think of a disk as a really long linear array of data, but accessing it is really expensive. So, we instead invent this notion of a cache - a layer of memory of $M$ bits that is much smaller, but a lot faster to read/write to. For performance reasons, we will divide the disk and cache into blocks of $B$ bits, called pages, and we will transfer data between cache and disk a page at a time.</p>
<p>This cache sits between the processor and the disk, and the processor will never directly read or write to the disk. When the processor wants to read a piece of data that is not on the cache (this is called a cache miss), it will trigger some mechanism that copies the relevant page from the disk to the cache first, <em>evicting another page if the cache is full</em>, and then read from the cache.</p>
<p>How might this help? Well, trivially, if the entire set of data that the program needs fits in the cache, conceivably the processor could have fetched it all in the cache, paid the one-off cost, and then for the rest of the program the processor will never have to pay the expensive cost of reading from disk. Of course most programs require more data than that, and so we want to design algorithms that minimize cache misses.</p>
<h2 id="cache-management">Cache management</h2>
<p>However, the way computers are set up restricts the tools we have to achieve this. Programs executing on the processor have no explicit control over the cache. Instead, conceptually, programs continue to send read and write requests to the disk as though there is no cache. The processor intercepts these requests, and performs the necessary cache operations to serve the information. In other words, the cache is transparent to programs.  Thus, the task of reducing cache misses decomposes into two orthogonal components: writing efficient algorithms by cleverly ordering or specifying memory accesses, and efficient cache management.</p>
<p>For example, an efficient algorithm might try to shuffle memory accesses around so that memory accesses to a particular memory address are clumped together, increasing the likelihood that there will be a cache hit. In fact, because of the paging system, it would doubly help if memory accesses to the same <em>spatial region</em> are clumped together, because there’s a chance they’ll be on the same page.</p>
<p>On the other hand, efficient cache management entails trying to predict which piece of data to evict from the cache when there is a cache miss and we want to load more data into an already full cache. Since we’re focusing on the algorithm this article, we assume that the cache manager has magic oracle powers that lets it discard <em>optimally</em>, so from the algorithm design standpoint, if there exists a sequence of cache loads/writes that achieves our desired performance, we assume that the cache manager will do it. It turns out that this is not unreasonable, because simple techniques such as the Least Recently Used algorithm work <em>really</em> well. (An exposition on this deserves its own article.)</p>
<p>To summarize, the components of the external memory model are:</p>
<ul>
<li>Disk, effectively unbounded in size, stores data in pages of size $B$</li>
<li>Cache, stores $M/B$ pages, each page has size $B$</li>
<li>Processor executes algorithm, also manages cache.</li>
<li>Algorithm runs on the processor. When data is needed, the processor transparently loads the required page into the cache if there’s a cache miss, or serve the cached data if there isn’t</li>
</ul>
<p>There are efficient algorithms that require explicit knowledge of $B$ and $M$, and there cache-oblivous algorithms that are just as efficient, but some how do not. That is to say, the algorithm performs the same actions and requests the same sequence of memory accesses, that works efficiently no matter what size $B$ and $M$ really are. We’ll take a close look at the latter here.</p>

<p>Let’s say we want to scan through a list of $N$ integers, to do some task, say finding the maximum. If the list occupy a contiguous block of memory on the disk, this can be done efficiently by loading pages one at a time, and scanning through the page before loading the next page. This thus takes $O(N/B)$ disk accesses, and is quite clearly optimal.</p>
<p>Suppose the algorithm does not know $B$. It can achieve the same efficiency by simply reading the elements of the list in order. The CPU will then fetch the first page to the cache, containing elements $0$ to $B-1$ and pass it to the program, and then when the program requires element $B$, it’ll read in the next page, which contains elements $B$ to $2B-1$, possibly overwriting the earlier page. This will just continue until all $N/B$ pages are read. This is cache-oblivious, because the algorithm of sequentially reading the elements is the same regardless of what $B$ is.</p>
<p>Note that in this example, it is essential that the list is stored in a contiguous block of memory. Had the elements been scattered around like in a linked-list, each access could potentially trigger a cache miss, since there’s no guarantee that neighboring elements will be on the same page. This may seem obvious, but this is the main mechanism by which we can write efficient algorithms - coming up with efficient layouts of data.</p>

<p>Now, let’s consider the problem of searching for an integer in a list. We’ll examine three ways of doing this.</p>
<h2 id="inefficient-cache-oblivious-algorithm-binary-search">Inefficient cache-oblivious algorithm: Binary search</h2>
<p>Let’s assume the data is sorted in a list, and packed contiguously on the disk. A possible algorithm is then to perform binary search, which typically takes $O(\log N)$ reads. The binary search can be viewed a successively narrowing an interval in which the query value may reside in. However, once the interval that the binary search is narrowing is $O(B)$, the entire interval may reside in a page, and no further page accesses are required. Thus, we require only $O(\log N - \log B)$ page accesses. Notice that this is a cache-oblivious algorithm because the algorithm doesn’t know what $B$ is - to the algorithm, it’s just running a standard binary search.</p>
<h2 id="efficient-but-not-cache-oblivious-b-trees">Efficient, but not cache-oblivious: B-trees</h2>
<p>Suppose we know $B$ ahead of time. We can achieve $O(\log_B N)$ page accesses. We arrange the list in the format of a B-tree, a generalized BST. Similar to a BST, each subtree of a B-tree corresponds to a contiguous subset of the elements of the list when sorted by value. However, each node $V$ of the tree contains not one, but $B$ elements, which splits the interval corresponding to the subtree rooted at node $V$ into not 2, but $B+1$ intervals. Then, we can traverse down the BST, and each time we go down one level we reduce the interval by a factor of $B$. This thus requires only $O(\log_B N) = O(\log N / \log B)$ page accesses. In reality of course, we have to store pointers and possibly other metadata in each node, so we can’t have exactly $B$ elements in each node, but we can definitely split by $\Theta(B)$ each level.</p>
<h2 id="efficient-cache-oblivious-algorithm-van-emde-boas-layout">Efficient cache-oblivious algorithm: van Emde Boas layout</h2>
<p>Now we come to the exciting part. We claim that we can achieve $O(\log_B N)$ page accesses, but without having to know $B$ ahead of time. The data structure we’re using is a good old balanced Binary Search Tree. However, the order in which we store the nodes in memory matters. If we pack the the BST in a regular fashion, say in breadth-first order, we could potentially have a situation where almost every vertex in a BST search path, except for the first few, lies in a different page, and thus we’ll have to use $O(\log N - \log B)$ page accesses. The van Embde Boas layout is basically a clever way of ordering the vertices of a binary search tree in a recursive, fractal-like manner such that each page access will fetch the next few vertices that will be queried, so that the next few accesses will be contained within that page.</p>
<h3 id="concise-definition">Concise definition</h3>
<figure>
    <img src="https://jiahai-feng.github.io/images/van-embde-boas-layout-labelled.PNG" alt="One application of the recursive van Embde Boas layout"> <figcaption>
            <p>One application of the recursive van Embde Boas layout</p>
        </figcaption>
</figure>

<p>For convenience, suppose the binary tree is complete and has height $H=2^K$. The layout is a permutation of the vertices of the binary tree. Denote $T(x, k)$ as the subtree of height $2^k$, rooted at vertex $x$. If the subtree at $x$ is deeper than $2^k$, then $T(x,k)$ will be the subtree truncated to the required depth. Denote $L(x, k)$ as the layout for that subtree. Then, for some root vertex $x$, of a (sub-)tree with height $h=2^k$, $L(x, k)$ is defined recursively as:</p>
<p>$$L(x, k) = L(x, k-1) \circ L(l_1, k-1) \circ L(l_2, k-1) \circ \dots \circ L(l_{n}, k-1)$$</p>
<p>Where, $l_1, \dots, l_{n}$ are the $n=2^{h/2}$ children of the leaves of $T(x, k-1)$, and $\circ$ is just concatenation. One application of this recursion is shown above.</p>
<h3 id="visual-sketch">Visual sketch</h3>
<p>If you didn’t catch that, don’t worry about it. Here’s a walkthrough. Suppose we’re given a complete binary tree of height $h=2^k$, rooted at $x$. We want to compute $L(x, k)$, which is a permutation of the vertices in this binary tree. Here’s how it’s done:</p>
<figure>
    <img src="https://jiahai-feng.github.io/images/veb-step0.PNG" alt="Initial tree"> <figcaption>
            <p>Initial tree</p>
        </figcaption>
</figure>

<ol>
<li>Cut all the edges between the $2^{k-1}$-th and $2^{k-1}+1$-th layer. This gives us:
<ul>
<li>$2^{h/2}$ smaller BSTs with height $2^{k-1}$. These are the children subtrees now disconnected from the main subtree, …</li></ul></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/">https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/</a></em></p>]]>
            </description>
            <link>https://jiahai-feng.github.io/posts/cache-oblivious-algorithms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662434</guid>
            <pubDate>Sat, 27 Jun 2020 15:31:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New in iOS 14: Vision Contour Detection]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23662019">thread link</a>) | @austin_kodra
<br/>
June 27, 2020 | https://heartbeat.fritz.ai/new-in-ios-14-vision-contour-detection-68fd5849816e | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/new-in-ios-14-vision-contour-detection-68fd5849816e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="992e">WWDC20</h2><h2 id="667d">Apple boosts its computer vision ambitions with a bunch of new Vision requests</h2><div><div><div><div><a href="https://heartbeat.fritz.ai/@anupamchugh?source=post_page-----68fd5849816e----------------------" rel="noopener"><div><p><img alt="Anupam Chugh" src="https://miro.medium.com/fit/c/96/96/1*SdJ5BAJeHpGYxEoACvPnRQ@2x.jpeg" width="48" height="48"></p></div></a></div></div></div></div></div></div><div><div><p id="17ef">Apple’s WWDC 2020 (digital-only) event kickstarted with a bang. There were a lot of new surprises (read: <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/how-apple-silicon-changes-mac-forever-d2682a9722df">Apple’s own silicon chips for Macs</a>) from the world of SwiftUI, <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/arkit4-putting-the-reality-back-in-augmented-reality-cea4ab775b8">ARKit</a>, PencilKit, Create ML, and <a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/evolving-your-apps-intelligence-with-core-ml-model-deployment-165579ba0546">Core ML</a>. But the one that stood out for me was computer vision.</p><p id="bce9">Apple’s Vision framework got bolstered with a bunch of exciting new APIs that perform some complex and critical computer vision algorithms in a fairly straightforward way.</p><p id="718a">Starting with iOS 14, the Vision framework now supports Hand and Body Pose Estimation, Optical Flow, Trajectory Detection, and Contour Detection.</p><p id="078f">While we’ll provide an in-depth look at each of these some other time, right now, let’s dive deeper into one particularly interesting addition—the contour detection Vision request.</p><ul><li id="bcd1">Understanding Vision’s contour detection request.</li><li id="00c8">Running it in an iOS 14 SwiftUI application to detect contours along coins.</li><li id="63ab">Simplifying the contours by leveraging Core Image filters for pre-processing the images before passing them on to the Vision request. We’ll look to mask the images in order to reduce texture noise.</li></ul></div></div></section><hr><section><div><div><p id="d6a5">Contour detection detects outlines of the edges in an image. Essentially, it joins all the continuous points that have the same color or intensity.</p><p id="fb67">This computer vision task is useful for shape analysis, edge detection, and is helpful in scenarios where you need to find similar types of objects in an image.</p><p id="c5f4">Coin detection and segmentation is a fairly common use case in OpenCV, and now by using Vision’s new <code>VNDetectContoursRequest</code>, we can perform the same in our iOS applications easily (without the need for third-party libraries).</p><p id="3973">To process images or frames, the Vision framework requires a <code>VNRequest</code>, which is passed into an image request handler or a sequence request handler. What we get in return is a <code>VNObservation</code> class.</p><p id="4ad5">You can use the respective <code>VNObservation</code> subclass based on the type of request you’re running. In our case, we’ll use <code>VNContoursObservation</code>, which provides all the detected contours from the image.</p><p id="8298">We can inspect the following properties from the <code>VNContoursObservation</code>:</p><ul><li id="a70a"><code><a href="https://developer.apple.com/documentation/vision/vncontoursobservation/3548363-normalizedpath" target="_blank" rel="noopener">normalizedPath</a></code> — It returns the path of detected contours in normalized coordinates. We’d have to convert it into the UIKit coordinates, as we’ll see shortly.</li><li id="5ea7"><code>contourCount</code> — The number of detected contours returned by the Vision request.</li><li id="d7ad"><code>topLevelContours</code> — An array of <code>VNContours</code> that aren’t enclosed inside any contour.</li><li id="803a"><code>contour(at:)</code> — Using this function, we can access a child contour by passing its index or <code>IndexPath</code>.</li><li id="c47a"><code>confidence</code> — The level of confidence in the overall <code>VNContoursObservation</code>.</li></ul><blockquote><p id="b960">Note: Using <code>topLevelContours</code> and accessing child contours is handy when you need to modify/remove them from the final observation.</p></blockquote><p id="fcbd">Now that we’ve got an idea of Vision contour detection request, let’s explore how it might work it in an iOS 14 application.</p></div></div></section><hr><section></section><hr><section><div><div><p id="367c">To start off, you’ll need <a href="https://developer.apple.com/documentation/xcode-release-notes/xcode-12-beta-release-notes" target="_blank" rel="noopener">Xcode 12 beta</a> as the bare minimum. That’s about it, as you can directly run Vision image requests in your SwiftUI Previews.</p><p id="0bc8">Create a new SwiftUI application in the Xcode wizard and notice the new <code>SwiftUI App</code> lifecycle:</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*b-1INld9G6RyGdvKPBmlkg.png?q=20" width="719" height="519" role="presentation"></p><p><img src="https://miro.medium.com/max/1438/1*b-1INld9G6RyGdvKPBmlkg.png" width="719" height="519" srcset="https://miro.medium.com/max/552/1*b-1INld9G6RyGdvKPBmlkg.png 276w, https://miro.medium.com/max/1104/1*b-1INld9G6RyGdvKPBmlkg.png 552w, https://miro.medium.com/max/1280/1*b-1INld9G6RyGdvKPBmlkg.png 640w, https://miro.medium.com/max/1400/1*b-1INld9G6RyGdvKPBmlkg.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="f24c">You’ll be greeted with the following code once you complete the project setup:</p><pre><span id="d4e5">@main<br>struct iOS14VisionContourDetection: App {<br>    var body: some Scene {<br>        WindowGroup {<br>            ContentView()<br>        }<br>    }<br>}</span></pre><blockquote><p id="4fb4">Note: Starting in iOS 14, <code>SceneDelegate</code> has been deprecated in favor of the SwiftUI <code>App</code> protocol, specifically for SwiftUI-based applications. The <code>@main</code> annotation on the top of the <code>struct</code> indicates it’s the starting point of the application.</p></blockquote></div></div></section><hr><section><div><div><p id="fc40">In order to perform our Vision request, let’s quickly set up a SwiftUI view, as shown below:</p><figure><div></div></figure><p id="cb81">In the above code, we’ve used the <code>if let</code> syntax that’s released with SwiftUI for iOS 14. Ignore the <code>preprocessImage</code> state; for now, let’s directly jump onto the <code>detectVisionContours</code> function that’ll update the <code>outputImage</code> state upon the completion of Vision request:</p><figure><div></div></figure><p id="fdf1">In the above code, we’ve set the <code>contrastAdjustment</code> (to enhance the image) and <code>detectDarkOnLight</code> (for better contour detection as our image has light background) properties on the <code>VNDetectContoursRequest</code>.</p><p id="bef8">Upon running the <code>VNImageRequestHandler</code> with the input image (present in the Assets folder ), we get back the <code>VNContoursObservation</code>.</p><p id="b3b6">Eventually, we’ll draw the <code>normalizedPoints</code> as an overlay on our input image.</p><p id="96a9">The code for the <code>drawContours</code> function is given below:</p><figure><div></div></figure><p id="a926">The <code>UIImage</code> returned by the above function is set to the <code>contouredImage</code> SwiftUI state, and subsequently our view gets updated:</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*UEijelLTwx_uS_bC6J_Qgw.png?q=20" width="1011" height="625" role="presentation"></p><p><img src="https://miro.medium.com/max/2022/1*UEijelLTwx_uS_bC6J_Qgw.png" width="1011" height="625" srcset="https://miro.medium.com/max/552/1*UEijelLTwx_uS_bC6J_Qgw.png 276w, https://miro.medium.com/max/1104/1*UEijelLTwx_uS_bC6J_Qgw.png 552w, https://miro.medium.com/max/1280/1*UEijelLTwx_uS_bC6J_Qgw.png 640w, https://miro.medium.com/max/1400/1*UEijelLTwx_uS_bC6J_Qgw.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="a259">The results are pretty decent considering we ran this on a simulator, but they would certainly be better if we ran this on a device with iOS 14, with access to the Neural Engine.</p><p id="feb8">But still, there are far too many contours (mostly due to coin textures) for our liking. We can simplify (or rather reduce) them by pre-processing the image.</p></div></div></section><hr><section></section><hr><section><div><div><p id="066d"><a href="https://developer.apple.com/documentation/coreimage" target="_blank" rel="noopener">Core Image</a> is Apple’s image processing and analysis framework. Though it works fine for simple face and barcode detection tasks, it isn’t scalable for complex computer vision use cases.</p><p id="68da">The framework actually boasts of over 200 image filters and is handy in photography apps as well as for data augmentation in your machine learning model training.</p><p id="3f76">But more importantly, Core Image is a handy tool for pre-processing images that are then fed to the Vision framework for analysis.</p><p id="467b">Now, if you’ve watched the <a href="https://developer.apple.com/videos/play/wwdc2020/10673" target="_blank" rel="noopener">WWDC 2020 Computer Vision APIs</a> video, you’ve seen that Apple has leveraged Core Image’s monochrome filter for pre-processing, while demonstrating their punchcard contour detection example.</p><p id="49be">In our case, for coin masking, the monochrome effect would not give as good results. Specifically for coins that have a similar color intensity that’s different from the background, using the black and white color filter for masking coins is a better bet.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*oycNP8qYvVZbONbJGnsLWw.png?q=20" width="949" height="768" role="presentation"></p><p><img src="https://miro.medium.com/max/1898/1*oycNP8qYvVZbONbJGnsLWw.png" width="949" height="768" srcset="https://miro.medium.com/max/552/1*oycNP8qYvVZbONbJGnsLWw.png 276w, https://miro.medium.com/max/1104/1*oycNP8qYvVZbONbJGnsLWw.png 552w, https://miro.medium.com/max/1280/1*oycNP8qYvVZbONbJGnsLWw.png 640w, https://miro.medium.com/max/1400/1*oycNP8qYvVZbONbJGnsLWw.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="f4ed">For each of the above pre-processing types, we’ve also set a Gaussian filter to smoothen the image. Take note of how the monochrome pre-processing filter actually gives us significantly more contours.</p><p id="e3dc">Hence, it’s important to pay heed to the kinds of images you’re dealing with when doing pre-processing.</p><p id="c748">The <code>outputImage</code> obtained after the pre-processing is fed to the Vision image request. The block of code for creating and applying Core Image filters is available in this <a href="https://github.com/anupamchugh/iOS14VisionContourDetection" target="_blank" rel="noopener">GitHub Repository</a>, along with the full source code.</p></div></div></section><hr><section><div><div><p id="e6c5">By using the <code>VNGeometryUtils</code> class, we can observe properties like diameter, bounding circle, area perimeter, and aspect ratio of the contour. Simply pass the contour, as shown below:</p><pre><span id="994f">VNGeometryUtils.boundingCircle(for: VNContour)</span></pre><p id="2e4a">This can open up new computer vision possibilities in determining the different kinds of shapes available in an image.</p><p id="02b3">Additionally, by invoking the <code>polygonApproximation(withEpsilon:)</code> method on a <code>VNContour</code>, we can further simplify our contours by filtering out little noisy parts around an edge.</p></div></div></section><hr><section><div><div><p id="e09c">Computer vision plays a huge role in Apple’s mixed reality future. The introduction of hand and body Pose APIs, which were a part of the ARKit framework, will open up new kinds of opportunities for building intelligent computer vision applications.</p><p id="1e3a">There’s a lot of exciting stuff that came out of WWDC 2020. I’m excited about the new kinds of possibilities for machine learning on mobile. Stay tuned for more updates, and thanks for reading.</p></div></div></section><hr><section><div><div><p id="abb3"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="af09"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="6414"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/new-in-ios-14-vision-contour-detection-68fd5849816e</link>
            <guid isPermaLink="false">hacker-news-small-sites-23662019</guid>
            <pubDate>Sat, 27 Jun 2020 14:26:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Web Developer Interview Questions And Answers]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23661922">thread link</a>) | @spiderjako22
<br/>
June 27, 2020 | https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016 | <a href="https://web.archive.org/web/*/https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.codegiant.io/@codegiant?source=post_page-----3030b21ae016----------------------" rel="noopener"><img alt="Team Codegiant" src="https://miro.medium.com/fit/c/96/96/2*iU0oAI5CSMp5LPuEKOqNuQ.png" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*WnoJGHyKLF5tfS2cG5tavQ.png?q=20" width="1600" height="1200" role="presentation"></p><p><img src="https://miro.medium.com/max/3200/1*WnoJGHyKLF5tfS2cG5tavQ.png" width="1600" height="1200" srcset="https://miro.medium.com/max/552/1*WnoJGHyKLF5tfS2cG5tavQ.png 276w, https://miro.medium.com/max/1104/1*WnoJGHyKLF5tfS2cG5tavQ.png 552w, https://miro.medium.com/max/1280/1*WnoJGHyKLF5tfS2cG5tavQ.png 640w, https://miro.medium.com/max/1400/1*WnoJGHyKLF5tfS2cG5tavQ.png 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="4cc5">You’ve set the alarm for 2:45pm.</p><p id="d056">The web developer interview is scheduled for 3:00pm.</p><p id="8433">You are patiently and nervously waiting, tension digging deeper in your chest, hands trembling without any tangible reason, for your mobile phone to ring. You’re wondering what web development interview questions the interviewer is going to fire off at you. Your mind is playing on your nerves. Tension rising notch by notch. “Am I really ready for that coding interview?” — you start beating yourself up.</p><p id="dd5e">You check your phone — it’s 3:05 pm. No missed calls. Nothing.</p><p id="f93c">You anxiously recheck your phone — 3:15 pm… still nothing.</p><p id="4c5c">You are already 30 minutes under pressure, sweating and silently moaning — your heart races. The latent impostor syndrome arises from the depths. You start freaking out… wondering whether or not you’ve given the wrong phone number… or if they might have forgotten about you.</p><p id="5e62">Your mind is leading a furious battle to overcome your anxious trains of thought. You, filled with a desperate hope, grab your phone with your sweaty pawl and look at it for one last time… and then… it rings.</p><p id="845c">You pick up and say, “Hello,” trying to hide the trembling notes in your voice, the anxious quiver of your lips and fingers, while battling the excruciating jittery inside your mind. You introduce each other and then… kinds of interview questions for web developers thrown at you, catching you off guard, that you can barely give an adequate answer to.</p><p id="d227">You realize that you are completely f*cked up. The overwhelming anxiety is growing deeper and deeper in you. You feel like you have a 200-kg bench press on your chest that you can’t lift. Vertigo comes along, and you suddenly forget. You forget your location, the person you are talking to… everything. Hands so sweaty that you just can’t hold your phone without it slipping through your fingers.</p><p id="a240">You know that the chances of making a good impression are so damn low that you’d have more luck if you were to bet on racing cockroaches.</p><p id="262a">To avoid that, you need strong preparation for the next coding interview. You need to have a grasp of the interview questions for web developers you are being asked. That will boost your confidence and diminish the anxiety before the phone or onsite interview.</p><p id="ab34">In this article, I’ll talk about the principles behind the developer interview process — the most common web developer questions you can expect from interviewers and how to answer them in a fascinating way that will put a WOW expression on their faces (even if they want to rip your head off, rearrange your face, or just clean their shoes ;-) ).</p><p id="a90c">To start off, you need to realize that the web dev interviewing process is more like a negotiation. You’ve been probably taught as a kid that you need to be flawless during interviews and answer every question accurately to make a good impression and get hired.</p><p id="b625">This couldn’t be further from the truth (coming from someone who got hired by sending out a cold message directly to their employer — no official nor traditional interview process).</p><p id="e763">Yes, of course, you need to make a good impression. But if you think that making a good impression comes down to awkwardly staring at your interviewer, frozen, while answering every developer interview question like a robot… you’re highly mistaken my friend.</p><p id="804e">You need to be able to communicate with your future employer freely while at the same time exuding confidence, knowledge, curiosity, and most importantly, enthusiasm.</p><p id="e9be">Here are the main things employers look for when hiring people:</p><ol><li id="c9d8"><a href="https://www.wikihow.com/Have-a-Great-Personality" target="_blank" rel="noopener">Personality</a>.</li><li id="bc1a"><a target="_blank" rel="noopener" href="https://blog.codegiant.io/whats-the-difference-between-a-programmer-coder-developer-and-engineer-bd315404de7">Basic qualifications</a>.</li><li id="5b8b"><a href="http://breathehr.com/blog/what-is-cultural-fit-and-why-is-it-important" target="_blank" rel="noopener">Culture fit</a>.</li><li id="e3a7"><a target="_blank" rel="noopener" href="https://blog.codegiant.io/how-to-become-a-10x-engineer-492fa3f57101">Enthusiasm</a>.</li></ol><p id="c68d">You need to have a fitting personality, meaning, you need to be able to easily communicate with your team without any hassle whatsoever. You need to ask clear and concise questions while at the same time, giving thorough and detailed answers.</p><p id="51b8">Of course, you also need to possess basic qualifications for the job you are applying for. Yet, many people seem to put tons of attention to that one (which is perfectly fine), but it’s just ¼ of the whole equation.</p><p id="61d9">Culture fit — this ties back into your personality. You have to be able to sync with your team and develop a culture that everyone enjoys working in.</p><p id="147b">And finally, have a burning passion and enthusiasm for your job. You’ll be surprised how helpful enthusiasm can be.</p><p id="eee3">For example, you may not have as good a resume as the guy in the next room that’s also being interviewed… but if you display a burning enthusiasm and willingness to go out of your way, you can beat other candidates and win the job. Of course, that may not always be the case. Still, it’s much more likely for an employer to hire you as a hyper enthusiastic person than as an average employee.</p><p id="2cb1">Alright, let’s take a look at some of the most common web developer interview questions (and answers) you may encounter. We’ll first start with professional software engineer behavioral questions and then switch over to more technical questions.</p><p id="6540">Whether you are a front-end, back-end, or full-stack software developer, these common computer science interview questions will help you in your preparation for the next coding interview.</p><p id="0f2d">NOTE: Some of the behavioral questions can also be noticed in web design interviews. So if you are a web designer, this article will highly prepare you for the next web design interview.</p><p id="53af">Most interviewers start off with introductory questions. Just follow the common sense when answering these software engineer interview questions. Try to be as transparent as possible. Tell them what really sparked your interest in coding and why you applied for this job.</p><p id="9720">If you are applying for an entry-level web developer job, interviewers won’t expect years of experience (they may even skip that question) as you’ve probably just graduated or finished a coding boot camp. Yet, if you are applying for a senior software engineer position, you need to have years of experience to back up your application for that web development job.</p><p id="ed12">You need to get familiar with Agile frameworks such as Kanban and Scrum because nowadays companies are adopting Agile practices and moving away from Waterfall methodologies. Interviewers may also ask you questions about the <a target="_blank" rel="noopener" href="https://blog.codegiant.io/software-development-life-cycle-the-ultimate-guide-2020-153d17bb20fb">SDLC (Software Development Life Cycle) process</a>.</p><p id="3aa1">As simple as that. You might want to focus on the specific languages that your web development job will require you to use most frequently.</p><p id="b2b4">Lately, having experience with multiple languages like C++, Java, and Python will definitely widen your interviewer’s eyes in astonishment.</p><p id="588b"><em>Credits to Andrew Mallonee, CEO at </em><a href="https://malloneemedia.com/" target="_blank" rel="noopener"><em>Mallonee Media</em></a><em>.</em></p><p id="0286">Be transparent and give a thorough explanation.. Sometimes, the interviewer might follow up with, “Do you get excited by using these languages?” but rarely. Obviously, reply with Yes and explain why you feel excited.</p><p id="fb59">It’s more of a soft skill interview question. Software engineering is a job in which you need to always thrive and sharpen your skills. Employers need to know that their developers are on the cutting edge using the latest technologies and constantly honing their skills. So, the answer to that software developer interview question would obviously be “Yes” — but expand further by telling them what interests you the most when it comes to learning new coding skills.</p><p id="14d6">Talk about projects similar to the projects you are going to be working on in the position you are applying for. If not, be genuine (always) and tell them what really sparks your passion for software development.</p><p id="e2fd">Here, interviewers particularly want to hear about severe problems, not many people on your team were able to solve, yet you were. Something important to remember is not to try to impress the interviewer — the scales will fall from his eyes immediately. Instead of making a good impression, you’ll make a desperate one. Be casual when talking about the problem that no one was able to solve except you. You, thus, exude confidence and knowledge. Being humble in the answer of this web dev interview question is key.</p><p id="6399">Another soft skill interview question. Life is about learning from your mistakes. Be as transparent as possible and openly admit the mistakes you’ve made in the past. Talk about the lessons you’ve learned. Basically, explain how you coped with your worst failures and came out stronger.</p><p id="bf9b">Research a lot prior to the interview. Go through all of their social media profiles to find little nuggets of information that would impress your interviewer. Show passion and enthusiasm for the company. Enthusiasm plays a huge role in the interview process.</p><p id="7b49">Same as previous — conduct thorough research and analysis before the interview. Show passion and enthusiasm. Tell the interviewer why you would love to work on those particular projects. They can thus see the reason behind that enthusiasm and wind out the thoughts of all that being a mere fluff.</p><p id="b2c0">These web development interview questions can happen over the phone or onsite.</p><p id="e12a">The following technical interview questions typically happen onsite, but sometimes they can take place remotely. If it’s remotely, the interviewer will ask you to share your screen to watch over your shoulder while you are coding and at the same time answering software development interview questions.</p><p id="c6ea">Keep in mind that the technical questions you are being asked highly depend on the position you are applying for. We’ll try to cover some of the most common software developer interview questions and give you reasonable answers that you can adjust to your situation easily.</p><p id="699b"><em>Credits to Michael Miller, CEO at </em><a href="https://vpnonline.com/" target="_blank" rel="noopener"><em>VPN Online</em></a><em>.</em></p><p id="fc04">There are lots of ways you can write your code, and all of them are correct. The company you want to join probably has a set standard for writing code and will perhaps compare your answer to that standard. Usually, most companies look for developers who take the simplest approach to code and try to weep out those who praise the sophisticated way of coding. That’s because companies want to easily maintain and document their code.</p><p id="3b99">Java developer interview questions are quite common. When interviewers ask you …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016">https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016</a></em></p>]]>
            </description>
            <link>https://blog.codegiant.io/25-web-developer-interview-questions-and-answers-3030b21ae016</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661922</guid>
            <pubDate>Sat, 27 Jun 2020 14:09:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Rainbow – an attempt to display colour on a B&W monitor]]>
            </title>
            <description>
<![CDATA[
Score 368 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23661808">thread link</a>) | @anfractuosity
<br/>
June 27, 2020 | https://www.anfractuosity.com/projects/rainbow/ | <a href="https://web.archive.org/web/*/https://www.anfractuosity.com/projects/rainbow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">



 <!-- END header -->


<section id="main">
	<div>
    
     	

        
        <article>
                        
<p>The aim of this project was to display a colour image on a black and white monitor, by overlaying an acetate bayer filter over the monitor and mosaicing a colour image.</p>



<p>I obtained an Eizo B&amp;W monitor from ebay, which I was intending for use viewing B&amp;W photos and was curious if I could replicate an effect similar to <strong>Autochrome Lumière</strong> ( see <a href="https://en.wikipedia.org/wiki/Autochrome_Lumi%C3%A8re">wikipedia</a> ) where they overlay colour filters over a B&amp;W photographic plate, using starch grains, which creates a colour image.</p>



<p>The following image shows a 500x microscope image of the pixels that make up the B&amp;W LCD display, taken using a very cheap USB microscope.  It looks to me as if each pixel, is represented by 4 sub-pixel elements, please correct me if this appears not be the case.</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0007.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0007.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0007-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>A pdf was created of the bayer display, with the dimensions 433.1mm x 324.8mm.  The monitor has a resolution of 2048×1536 and I assumed the pixels had the same width as height.</p>



<p>You can see an example of the pdf I created below, where for example a blue element, should be represented by 2×2 pixels from the B&amp;W monitor. </p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-1024x540.png" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-1024x540.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-300x158.png 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-768x405.png 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf-1536x810.png 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/bayer_pdf.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I created 3 pdfs:</p>



<ul><li>bayer_1.pdf  –  each element, is represented by 1 pixel from the display</li><li>bayer_2.pdf  –  each element, is represented by 2×2 pixels from the display (this is the acetate used in the video)</li><li>bayer_4.pdf – each element is represented by 4×4 pixels from the display</li></ul>



<p>The following image shows the printed acetate with the bayer pattern:</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-1024x683.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-1024x683.jpg 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-300x200.jpg 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-768x512.jpg 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-1536x1024.jpg 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/IMG_7509-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The following, is a B&amp;W image with mosaicing applied from the colour image:</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2020/06/out.png"><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/out-1024x768.png" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/out-1024x768.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out-300x225.png 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out-768x576.png 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out-1536x1152.png 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/out.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>How it works</h2>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-1024x616.png" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-1024x616.png 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-300x180.png 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-768x462.png 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1-1536x923.png 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/fig-1.png 1898w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The monitor I am using seems to generally be used portrait, to make it landscape on linux:</p>


<pre title="">xrandr --output HDMI1 --rotate left
</pre>


<h2>Image of effect</h2>



<p>As you can see the effect of my attempt is quite slight, but you can see in the centre the different colours of the balloons.</p>



<figure><a href="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001.jpg"><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1024x576.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1024x576.jpg 1024w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-300x169.jpg 300w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-768x432.jpg 768w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1536x864.jpg 1536w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<h2>Video of effect</h2>



<p>The effect is also demonstrated in the following video, with the following parameters:</p>


<pre title=""> mpv out.mkv --fullscreen --loop --brightness=10 --contrast=20
</pre>


<figure><p>
<iframe title="Rainbow - using an acetate bayer filter over a B&amp;W monitor" width="940" height="529" src="https://www.youtube.com/embed/Sh2d9qAjYPo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>Microscope images of the bayer filter (2×2 scaling)</h2>



<p>2×2 bayer filter, I tried to design it so that for example the ‘red’ square covers 2×2 pixels on the monitor</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0001-1-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<h2>Chess board </h2>



<p>As suggested by Olivier, I’ve just created 2 chess board images.  Olivier was correct that a single pixel consists of 3 sub-pixels 🙂</p>



<p>1×1 (the white patch is 1 pixel), monitor in landscape, image in correct orientation from microscope (left, towards left monitor, top, towards top of monitor)</p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0020.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0020.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0020-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>2×2 </p>



<figure><img src="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0002.jpg" alt="" srcset="https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0002.jpg 640w, https://www.anfractuosity.com/wp-content/uploads/2020/06/mpv-shot0002-300x225.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<h2>Possible improvements</h2>



<p>I wonder if by measuring the exact pixel width/height under a microscope, if the effect could possibly be improved somewhat, as that information could be used when creating the acetate filter.</p>



<p>Alignment is also a key issue, I need to think of ways to improve that possibly using a microscope while aligning the acetate.</p>



<p>I’d be interested in other improvements I could make too!</p>



<h2>Source</h2>



<p>The sourcecode to generate the PDFs for the acetate and the mosaiced images and videos is at:</p>



<p><a href="https://www.github.com/anfractuosity/rainbow">https://www.github.com/anfractuosity/rainbow</a></p>
                        <br>


			
                                
                
                                
                 <!-- END #comments -->    
                	                                
                
                
                                      
                 <!-- END #leave_comment -->
                
 
                </article> <!-- END article -->




	</div> <!-- END #main_inner -->     
</section> <!-- END #main -->       

 <!-- END #footer -->

</div></div>]]>
            </description>
            <link>https://www.anfractuosity.com/projects/rainbow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661808</guid>
            <pubDate>Sat, 27 Jun 2020 13:43:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Our Own Version of Rust's Non-Lexical Lifetimes in Bolt]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23661557">thread link</a>) | @mrathi12
<br/>
June 27, 2020 | https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Creating the Bolt Compiler: Part 5</h3><p><h3>June 27, 2020</h3><h3>7 min read</h3></p><nav><h2>Series: Creating the Bolt Compiler</h2><ul><li></li><li></li><li></li><li></li><li><strong>Part 5: A tutorial on liveness and alias dataflow analysis</strong></li><li><em>Part 6: Desugaring - taking our high-level language and simplifying it!*</em></li><li><em>Part 7: Protobuf serialisation - converting from OCaml to C++*</em></li><li><em>Part 8: LLVM's C++ API for the Uninitiated*</em></li><li><em>Part 9: Adding Concurrency to Bolt*</em></li><li><em>Part 10: Adding function and method overloading*</em></li><li><em>Part 11: Inheritance and method overriding in Bolt*</em></li><li><em>Part 12: Generics - adding polymorphism to Bolt*</em></li><p>*coming soon! </p></ul></nav><hr><h2 id="dataflow-analysis---the-big-picture"><a href="#dataflow-analysis---the-big-picture" aria-label="dataflow analysis   the big picture permalink"></a>Dataflow Analysis - the big picture</h2><p>In the previous post in the series, we looked at how type-checking the core language worked. This analysis is <em>flow-insensitive</em> - it does not depend on the flow of the execution of the program. If an expression is of type <code>int</code> then it will have type <code>int</code> regardless of what was executed before or after it.</p><p>Some program properties do however depend on the execution path taken by a program. Dataflow analysis tracks how a particular value might propagate as the program executes.</p><p>For example, a value might <em>alias</em> - you could have multiple references pointing to that value. Whether two references <code>x</code> and <code>y</code> alias can’t be determined by looking at their assignments in isolation - we need to track the execution to determine if they have the same value assigned to them.</p><div><p><span>alias_example</span></p><div><pre><p><span>let</span><span> x </span><span>=</span><span> someObject</span></p><p><span></span><span>...</span><span></span></p><p><span></span><span>let</span><span> y </span><span>=</span><span> someObject </span></p></pre></div></div><p>Another example is <strong>liveness analysis</strong> - we say a value is <em>live</em> if some point later in the program it could be used, and <em>dead</em> otherwise.</p><div><p><span>liveness_example</span></p><div><pre><p><span>let</span><span> x </span><span>=</span><span> someValue </span><span></span></p><p><span></span><span>...</span><span></span></p><p><span></span><span>print</span><span>(</span><span>x</span><span>)</span><span> </span><span></span></p><p><span>x </span><span>=</span><span> someOtherValue </span></p></pre></div></div><p>Why do we care about alias analysis and liveness analysis? Well it turns out that Rust’s <em>borrow-checker</em> uses a combination of these to determine when a reference is borrowed. Bolt has a <em>linear</em> capability in its type system which acts the same.</p><p>Both Rust’s borrow checker and Bolt’s capabilities prevent data races - an explanation why is in <a href="https://github.com/mukul-rathi/bolt-dissertation/blob/master/dissertation.pdf">my dissertation</a>.</p><p>In a nutshell, Rust works on the principle of <strong>ownership</strong>: you either have one reference (owner) that can read/write (a <em>mutable</em> reference) or you can <em>borrow</em> (aka alias) the reference.</p><p>To enforce this we care about 2 things:</p><ol><li>When is a reference borrowed? (alias analysis)</li><li>For how long is it borrowed? (liveness analysis)</li></ol><p>Let’s elaborate on that second point. When is a reference borrowed? The first version of Rust’s borrow checker said this was whilst an alias was in scope.</p><div><p><span>borrow_example</span></p><div><pre><p><span>let</span><span> x </span><span>=</span><span> something </span><span></span></p><p><span></span><span>{</span><span></span></p><p><span>  </span><span>let</span><span> y </span><span>=</span><span> x</span></p><p><span>  </span><span>...</span><span> </span><span></span></p><p><span>  </span><span>print</span><span>(</span><span>y</span><span>)</span><span></span></p><p><span>  x </span><span>=</span><span> somethingElse</span></p><p><span></span><span>}</span><span></span></p></pre></div></div><p>That means we cannot reassign <code>x</code> in the example until <code>y</code> is out of scope. This is a “lexical lifetime” - <code>y</code>’s borrow lifetime is determined by its lexical scope. So that means <code>x</code> can’t be reassigned, since it is borrowed at that point. But <code>y</code> isn’t being used so surely <code>x</code> isn’t still borrowed?</p><p>That’s the idea behind <strong>non-lexical lifetimes</strong> - the borrow ends when the value of <code>y</code> is dead - i.e. it is not being used.</p><p>In Bolt, we’ll be tracking the lifetimes of references to <em>objects</em>.</p><p>Let’s get implementing it!</p><h2 id="alias-analysis"><a href="#alias-analysis" aria-label="alias analysis permalink"></a>Alias Analysis</h2><p>The first step is to determine when two values alias. How do we know two references will point to the same object without actually executing the program?</p><p>We use <strong>abstract interpretation</strong>.</p><h3 id="abstract-interpretation"><a href="#abstract-interpretation" aria-label="abstract interpretation permalink"></a>Abstract Interpretation</h3><p>Abstract interpretation is the process of simulating the execution of the program but only storing the program properties we care about. So in our case, we don’t care about what the actual result of the program execution is, we’re just tracking the <em>set of aliases</em>.</p><div><p>Implicit in this is a set of rules for how the program will execute, we call this its <strong>operational semantics</strong>. We will not go into details here, but it’s things like:</p><ul><li>Do we evaluate expressions left-to-right or right-to-left?</li><li>When calling a function, do we fully evaluate the argument expression and then call the function with the value of that argument, or do we just plug in the unevaluated argument expression directly into the function and only evaluate it at the point it is used in the function body? The former is called <strong>call-by-value</strong> and is used in most mainstream languages like Java and Python, the latter is called <strong>call-by-name</strong> and is used in Haskell and Lisp.</li></ul><p>There’s a lot more to say about this - perhaps it’s worthy of its own blog post? Send me a tweet if you would like one!</p></div><p>When do we have aliasing? When a new variable is declared or when it is reassigned. For simplicity (and also because we don’t want the lifetime of the alias to be larger than the original value) we will not allow aliasing via reassigning an existing variable (e.g. <code>x := y</code>).</p><p>So we care about expressions of this form:</p><p>The expression <code>e</code> can <em>reduce</em> to a value when executing e.g. <code>1+2</code> reduces to <code>3</code>.</p><p>If when executing <code>e</code> it reduces to a reference <code>y</code>, then the overall expression would look like:</p><p>And so <code>x</code> would alias <code>y</code>. So let’s write a function that, given an expression, will return the list of identifiers that it could possible reduce to. That’ll tell us what <code>x</code> could possibly alias.</p><p>We’ll store this helper function in an “environment” of helper functions used in the data-race type-checking stage of the Bolt compiler: <code>data_race_checker_env.mli</code></p><p>The type signature of this OCaml function is as we’d expect:</p><p>A reminder of the type of <code>expr</code> defined in the <a href="https://mukulrathi.co.uk/create-your-own-programming-language/intro-to-type-checking/#annotating-our-ast-with-types">previous post</a> - <code>loc</code> encodes the line number and position of the expression - used for error messages.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/simple-compiler-tutorial/src/frontend/typing/typed_ast.mli"> <!-- -->typed_ast.mli</a></span></p><div><pre><p><span>type</span><span> identifier </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Variable</span><span> </span><span>of</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t</span></p><p><span>  </span><span>|</span><span> </span><span>ObjField</span><span> </span><span>of</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Field_name</span><span>.</span><span>t</span></p><p><span></span><span>type</span><span> expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Integer</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> int</span></p><p><span>  </span><span>|</span><span> </span><span>Boolean</span><span>     </span><span>of</span><span> loc </span><span>*</span><span> bool</span></p><p><span>  </span><span>|</span><span> </span><span>Identifier</span><span>  </span><span>of</span><span> loc </span><span>*</span><span> identifier</span></p><p><span>  </span><span>|</span><span> </span><span>Constructor</span><span> </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Class_name</span><span>.</span><span>t </span><span>*</span><span> constructor</span><span>_</span><span>arg list</span></p><p><span>  </span><span>|</span><span> </span><span>Let</span><span>         </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> </span><span>Var_name</span><span>.</span><span>t </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>Assign</span><span>      </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> identifier </span><span>*</span><span> expr</span></p><p><span>  </span><span>|</span><span> </span><span>If</span><span>          </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> expr </span><span>*</span><span> block</span><span>_</span><span>expr </span><span>*</span><span> block</span><span>_</span><span>expr</span></p><p><span>  </span><span>.</span><span>.</span><span>.</span><span></span></p><p><span></span><span>and</span><span> block</span><span>_</span><span>expr </span><span>=</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Block</span><span> </span><span>of</span><span> loc </span><span>*</span><span> type</span><span>_</span><span>expr </span><span>*</span><span> expr list</span></p></pre></div></div><p>Starting off with the simple cases, it’s clear an integer or a boolean value doesn’t reduce to an identifier, and an identifier expression reduces to that identifier. A <code>new SomeClass()</code> constructor also doesn’t reduce to an identifier.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>let</span><span> </span><span>rec</span><span> reduce</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids expr </span><span>=</span><span></span></p><p><span>  </span><span>match</span><span> expr </span><span>with</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Integer</span><span> </span><span>_</span><span> </span><span>|</span><span> </span><span>Boolean</span><span> </span><span>_</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>]</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Identifier</span><span> </span><span>(</span><span>_</span><span>,</span><span> id</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>id</span><span>]</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Constructor</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>)</span><span> </span><span>-&gt;</span><span> </span><span>[</span><span>]</span></p></pre></div></div><p>If we have a let expression or assigning to an identifier, then it reduces to that identifier (e.g. <code>let x = ___</code> reduces to <code>x</code>, and <code>x.f:= __</code> reduces to <code>x.f</code>):</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>.</span><span>.</span><span>.</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>Let</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> bound</span><span>_</span><span>expr</span><span>)</span><span> </span><span>-&gt;</span><span> reduce</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids bound</span><span>_</span><span>expr</span></p><p><span>  </span><span>|</span><span> </span><span>Assign</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> assigned</span><span>_</span><span>expr</span><span>)</span><span> </span><span>-&gt;</span><span> reduce</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids assigned</span><span>_</span><span>expr</span></p></pre></div></div><p>We can continue doing this for other cases. But what about an <code>if</code> statement? Does this expression reduce to <code>x</code> or <code>y</code>?</p><div><div><pre><p><span>if</span><span> </span><span>(</span><span>someCondition</span><span>)</span><span> </span><span>{</span><span></span></p><p><span>  x</span></p><p><span></span><span>}</span><span> </span><span>else</span><span> </span><span>{</span><span></span></p><p><span>  y</span></p><p><span></span><span>}</span></p></pre></div></div><p>In general, without actually executing the expression, we don’t know. So we’ll have to approximate.</p><p>Let’s remind ourselves of our goal - to mark a value as borrowed/not linear (Rust / Bolt equiv. terminology) if it is aliased. We’re trying to eliminate data races, so we have to be <em>conservative</em> - assume it might be aliased even if it isn’t. The worst thing would be to let a data race slip through. Abstract interpretation <em>always</em> errs on the side of soundness.</p><p>So we’ll <em>overapproximate</em> the list of possible identifiers the expression could reduce to - we don’t know which branch so we’ll count the identifiers from <em>both</em> branches.</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>.</span><span>.</span><span>.</span><span></span></p><p><span>  </span><span>|</span><span> </span><span>If</span><span> </span><span>(</span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> </span><span>_</span><span>,</span><span> then</span><span>_</span><span>expr</span><span>,</span><span> else</span><span>_</span><span>expr</span><span>)</span><span> </span><span>-&gt;</span><span></span></p><p><span>      </span><span>let</span><span> then</span><span>_</span><span>ids </span><span>=</span><span> reduce</span><span>_</span><span>block</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids then</span><span>_</span><span>expr </span><span>in</span><span></span></p><p><span>      </span><span>let</span><span> else</span><span>_</span><span>ids </span><span>=</span><span> reduce</span><span>_</span><span>block</span><span>_</span><span>expr</span><span>_</span><span>to</span><span>_</span><span>obj</span><span>_</span><span>ids else</span><span>_</span><span>expr </span><span>in</span><span></span></p><p><span>      then</span><span>_</span><span>ids </span><span>@</span><span> else</span><span>_</span><span>ids</span></p></pre></div></div><p>So in the example above, we’d return a list <code>[x, y]</code>.</p><h3 id="computing-all-aliases"><a href="#computing-all-aliases" aria-label="computing all aliases permalink"></a>Computing all aliases</h3><p>So we know if we have an expression <code>let y = e</code> and <code>e</code> reduces to <code>x</code>, then we have <code>let y = x</code> and so <code>y</code> is an alias of <code>x</code>.</p><p>In the expression below, we would also run abstract interpretation (simple in this case) to find that <code>z</code> and <code>w</code> are aliases of <code>y</code>.</p><div><div><pre><p><span>let y = x</span></p><p><span>...</span></p><p><span>let z = y</span></p><p><span>if(y.f &gt; 1){</span></p><p><span>  ...</span></p><p><span>}</span></p><p><span>else {</span></p><p><span>}</span></p><p><span>...</span></p><p><span>let w = y</span></p></pre></div></div><p>By transitivity, <code>z</code> and <code>w</code> must also be aliases of <code>x</code>.</p><p>I like to think of this like a graph where each edge is a direct/immediate alias. We can find all aliases, by repeatedly applying abstract interpretation in a “breadth-first search” style - each iteration we’re expanding the frontier. And each iteration we try to find aliases of the aliases we’ve found - so the first iteration we find aliases of <code>x</code>, then the next iteration we find aliases of <code>x</code> and <code>y</code> and so on…</p><p><span>
      <a href="https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/191e2/alias-frontier.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Alias Frontier Diagram" title="Alias Frontier Diagram" src="https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/a6d36/alias-frontier.png" srcset="https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/222b7/alias-frontier.png 163w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/ff46a/alias-frontier.png 325w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/a6d36/alias-frontier.png 650w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/e548f/alias-frontier.png 975w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/3c492/alias-frontier.png 1300w,https://mukulrathi.co.uk/static/e996478c0eaa723fc8028caa72847284/191e2/alias-frontier.png 1836w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p><p>So we repeat, until we find no more aliases. The full code is linked in the repo, and includes an option of matching fields (i.e. should we consider aliases of <code>x.f</code> as well as <code>x</code>?) We won’t in this case, but other aspects of Bolt’s data-race type-checker do use this.</p><p>But the beauty of functional programming is that the function says what we’re doing with no boilerplate:</p><div><p><span><a href="https://github.com/mukul-rathi/bolt/blob/master/src/frontend/data_race_checker/data_race_checker_env.ml"> <!-- -->data_race_checker_env.ml</a></span></p><div><pre><p><span>let</span><span> </span><span>rec</span><span> get</span><span>_</span><span>all</span><span>_</span><span>obj</span><span>_</span><span>aliases should</span><span>_</span><span>match</span><span>_</span><span>fields curr</span><span>_</span><span>aliases block</span><span>_</span><span>expr </span><span>=</span><span></span></p><p><span>    find</span><span>_</span><span>immediate</span><span>_</span><span>aliases</span><span>_</span><span>in</span><span>_</span><span>block</span><span>_</span><span>expr should</span><span>_</span><span>match</span><span>_</span><span>fields name</span><span>_</span><span>to</span><span>_</span><span>match curr</span><span>_</span><span>aliases</span></p><p><span>      block</span><span>_</span><span>expr</span></p><p><span>    </span><span>|&gt;</span><span> </span><span>fun</span><span> updated</span><span>_</span><span>aliases </span><span>-&gt;</span><span></span></p><p><span>    </span><span>if</span><span> var</span><span>_</span><span>lists</span><span>_</span><span>are</span><span>_</span><span>equal updated</span><span>_</span><span>aliases curr</span><span>_</span><span>aliases</span></p><p><span>       </span><span>then</span><span> curr</span><span>_</span><span>aliases </span><span></span></p><p><span>    </span><span>else</span><span> get</span><span>_</span><span>all</span><span>_</span><span>obj</span><span>_</span><span>aliases should</span><span>_</span><span>match</span><span>_</span><span>fields updated</span><span>_</span><span>aliases block</span><span>_</span><span>expr</span></p></pre></div></div><h2 id="liveness-analysis"><a href="#liveness-analysis" aria-label="liveness analysis permalink"></a>Liveness Analysis</h2><p>Alright, so we’re halfway there - we’ve identified our aliases, now we need to find out when they’re live. Remember a value is <em>live</em> if there’s some program execution path in the future it will be used on.</p><h3 id="control-flow-graph"><a href="#control-flow-graph" aria-label="control flow graph permalink"></a>Control Flow Graph</h3><p>To do this, let’s formalise the notion of “execution paths” in a program. We’re going to be representing a program as a graph of instructions, with edges representing the steps in the execution. We call this the <strong>Control Flow Graph</strong> of the program.</p><figure>
    <span>
      <a href="https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/776d3/control-flow-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Control Flow Graph" title="Note how the control flow graph shows two different execution paths, corresponding to the if-else branch taken." src="https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/a6d36/control-flow-graph.png" srcset="https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/222b7/control-flow-graph.png 163w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/ff46a/control-flow-graph.png 325w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/a6d36/control-flow-graph.png 650w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/e548f/control-flow-graph.png 975w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/3c492/control-flow-graph.png 1300w,https://mukulrathi.co.uk/static/2f8d764b548afc2de1c14af61aee3c4e/776d3/control-flow-graph.png 1814w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span>
    <figcaption>Note how the control flow graph shows two different execution paths, corresponding to the if-else branch taken.</figcaption>
  </figure><p>We’ll be coming back to this Control Flow Graph when we talk about LLVM later in the series! There’ll be more terminology then, but for now this’ll do.</p><p>In our graph, we can pick any …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/">https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/</a></em></p>]]>
            </description>
            <link>https://mukulrathi.co.uk/create-your-own-programming-language/data-race-dataflow-analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661557</guid>
            <pubDate>Sat, 27 Jun 2020 12:58:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Global sailing navigation simulator using real weather/ocean data]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23661326">thread link</a>) | @ls65536
<br/>
June 27, 2020 | https://8bitbyte.ca/sailnavsim/ | <a href="https://web.archive.org/web/*/https://8bitbyte.ca/sailnavsim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><td>Position sharing interval:</td><td> - how often boat positions are shared among members in race</td></div></div>]]>
            </description>
            <link>https://8bitbyte.ca/sailnavsim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661326</guid>
            <pubDate>Sat, 27 Jun 2020 12:17:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Personal OKRs for Success]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 41 (<a href="https://news.ycombinator.com/item?id=23661067">thread link</a>) | @mkfeuhrer
<br/>
June 27, 2020 | https://mohitkhare.me/blog/personal-okrs/ | <a href="https://web.archive.org/web/*/https://mohitkhare.me/blog/personal-okrs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <!-- Toc if any -->
                
                <!-- End Toc -->
                <p>Last year as I kicked off my career entering the professional tech world, I came across the concept of <strong>Objective, Key and Results (OKRs)</strong> at work. I was quite intrigued by the whole concept of OKRs.</p>

<p>In very layman terms —</p>

<blockquote>
  <p>Main objective of OKR is to plan out qualitative goals with quantitative results for those with proper time tracking.</p>
</blockquote>

<p>People do use diary or todo apps for tracking there work. Todo apps usually work for tracking tasks over a shorter duration. You need a framework to plan out for your bigger goal and track your progress towards it.</p>

<p><img src="https://cdn-images-1.medium.com/max/1600/1*bX5Vy1OPJ3LImq9DHIgU5g.png" alt="Personal OKR Header Section"></p>

<p>In this blog, I will try to explain how you can plan and why it is important to have your Personal OKR. Let’s begin!</p>

<h2 id="what">What?</h2>

<p>OKRs is already a very popular term in business, most probably it is being used at your workplace too. It is a <strong>goal-setting framework</strong> that basically covers big and challenging goals with a set of defined measurable results for achieving these goals.</p>

<h3 id="objective">Objective — </h3>

<ul>
  <li>What do you want to achieve over a period of time?</li>
  <li>Objectives should be ambitious, more <strong>inspirational</strong> (which requires more effort of yours), bold and <strong>qualitative</strong></li>
  <li>Your targets should not be something very easily achievable.</li>
</ul>

<p><strong>Eg.</strong> Improve the financial condition, Get better at reading, etc</p>

<h3 id="key-results">Key Results</h3>

<ul>
  <li>KRs are steps you need to achieve the objective.</li>
  <li>KRs should be <strong>Quantitative</strong> i.e having defined metrics! This should not be vague. Add numbers, avoid terms like “more/less”.<br>
Google uses. a scale of 0–1 for tracking progress for each key result.</li>
  <li>Make KRs <strong>Time-bounded</strong>. This helps you tracking progress over the period and lets you recalibrate your tasks.</li>
  <li>KRs should be <strong>Binary</strong> i.e Complete / Incomplete</li>
</ul>

<p><strong>Eg.</strong> Read 3 books on investing, Read 1500 pages monthly, etc</p>

<hr>

<h3 id="personal-vs-work-okrs">Personal vs Work OKRs?</h3>

<p>OKRs are used by both teams and individuals, though mostly in work environments. The concept of OKR is simple and works pretty effectively for personal use as well. It is super important to have separate personal and work OKRs since your work goals are different from personal life and goals.</p>

<p>In personal OKRs, you would want to track things like —</p>

<ol>
  <li>Family time</li>
  <li>Personal finance</li>
  <li>Fitness</li>
  <li>Hobbies</li>
</ol>

<p>Personal OKRs are <strong>literally personal</strong>!<br>
It varies from person to person. It’s good to look for ideas on how people use OKRs, but you should align it for your goals and aspirations which you want to achieve.</p>

<hr>

<h2 id="why">Why?</h2>

<blockquote>
  <p>“Actions — and data — speak louder than words.”<br>
― <strong>John Doerr,</strong> <a href="https://www.goodreads.com/work/quotes/54960827"><strong>Measure What Matters</strong></a></p>
</blockquote>

<p>OKRs help you plan your goals in a structured and planned fashion, but there is more to it! Let me explain —</p>

<ul>
  <li>Better <strong>Focus</strong> and <strong>Alignment</strong> on what you want to achieve. Since OKRs are limited, you don’t want to waste time and do stuff that doesn’t really help you achieve what you want!</li>
  <li>These give the <strong>Motivation</strong> to work towards your objectives and a sense of urgency to finish them.</li>
  <li>OKRs help in building a <strong>Habit</strong> of planning things in general and following the path to achieving them. Eg. You have an objective of getting better at reading, you start reading 30 pages daily. Now, it slowly builds into your habit to read. Next year, even if you don’t have this objective, you’ll still read :)</li>
  <li><strong>Time Tracking</strong> is super useful and important since they give a timeline for you to work and align your tasks accordingly.</li>
  <li><strong>Metrics</strong> and Numbers help you visualize your progress. When you see 80% completion, you get a psychological motivation to make it 100%</li>
  <li>If you have a <strong>Public OKR</strong>, you get another source to actually work and complete your task.</li>
</ul>

<blockquote>
  <p>‘I’d rather have the objective be to go to Mars, and if we fall short, we’ll get to the moon. This is how you make moonshots. — Larry Page</p>
</blockquote>

<p><a href="https://www.whatmatters.com/faqs/benefits-of-okrs/">Measure what matters</a> brings a similar <strong>F.A.C.T.S</strong> showing the benefits of OKRs.</p>

<hr>

<h2 id="how">How?</h2>

<p>Now, that you understand the importance of Personal OKRs and are ready to create yours, I’ll show how I personally maintain my OKRs and share resources that might be useful for you!</p>

<h3 id="tools">Tools</h3>

<p>There are a lot of tools that you can use to start creating an OKR. I personally being a big fan of <a href="http://notion.so/">Notion</a>, use it to maintain my Personal OKRs. You can use anything from professional notes and trackers like <a href="https://evernote.com/">Evernote</a>, <a href="http://notion.so/">Notion</a>, <a href="https://todoist.com/">Todoist</a> to simple excel sheet template.</p>

<h3 id="process">Process</h3>

<p><img src="https://cdn-images-1.medium.com/max/2400/1*IOarq_FgPMWWVqohXAMvHg.png" alt="OKR Tracking with Notes"></p>

<p>I usually update my OKRs monthly since I maintain a yearly OKR tracker. You can adjust it according to the timeline you are planning for.</p>

<p>I maintain different tables for each of my Objectives. In the image below</p>

<p><strong>Objective</strong> — Boost Knowledge</p>

<p><strong>Key Results</strong> —</p>

<ol>
  <li>
    <p>Read 20 books</p>
  </li>
  <li>
    <p>Create 2 open source projects</p>
  </li>
</ol>

<p><strong>Time Tracking</strong> — <br>
I maintain time tracking based on which quarter of the year I want this to be completed. I do break these KRs into sub-tasks which are added to my Todolist with a specified timeline.<br>
I use <strong>EOY</strong> (End of Year) in cases when I want that KR to be worked on throughout the year.</p>

<p><strong>Status</strong>—</p>

<p>I set my KRs progress to one of the 5 stages. It helps me keep track of what to do next and what is already completed. I sometimes add <strong>At-Risk</strong> tag to denote that this KR is probably not happening. I already added <strong>At-Risk</strong> to my traveling KRs this year credits to corona :(</p>

<p><img src="https://cdn-images-1.medium.com/max/1600/1*HQJ56kvlk0-mDZiXBrptfw.png" alt="Quarter based timeframe and Status for tracking progress"></p>

<p><strong>Notes</strong>  — <br>
These are basically notes/links relevant to KR which I would want to revisit when I come back to this sometime later.</p>

<h2 id="tips-and-tricks">Tips and Tricks</h2>

<ul>
  <li><strong>Avoid changing OKRs</strong>! It is okay to update OKRs when you achieve something or want to divert. Do not remove OKRs just because you are doing something else now, at the end of the timeframe you should know that you failed at this due to XYZ reason, and was it worth it or not?</li>
  <li>You will fail in many Key results! <strong>It is okay to fail</strong>, now you get an idea on what did you miss, how can you improve and rework accordingly.</li>
  <li><strong>Regularly update your KRs status and notes</strong>, this gives you an idea of where you need to focus more in the next few days. A biweekly or monthly review is generally a good time to revisit OKRs. I set up a biweekly reminder in my calendar for this!</li>
  <li>You can <strong>add a score</strong> to each KR to make things more interesting. For the first time, I wanted to keep it simple. Do share if you use some interesting scoring :P</li>
  <li><strong>Avoid setting too many OKRs</strong> instead make the OKRs more challenging.</li>
  <li>Add links to your weekly tasks in notes sections. This helps you view how did you spend your week in the perspective of achieving your OKR results. Even add resources for specific KRs. This helps you increase your knowledge base over a period of time.</li>
  <li><strong>Keep it simple</strong>! Follow what you can maintain. Don’t overcomplicate :)</li>
</ul>

<h2 id="resources">Resources</h2>

<ul>
  <li>Wide-set of OKR examples — <a href="https://www.whatmatters.com/get-examples/">https://www.whatmatters.com/get-examples/</a></li>
  <li>Complete Guide — <a href="https://rework.withgoogle.com/guides/set-goals-with-okrs/steps/introduction/">https://rework.withgoogle.com/guides/set-goals-with-okrs/steps/introduction/</a></li>
  <li>How Google uses OKR — <a href="https://www.youtube.com/watch?v=mJB83EZtAjc">https://www.youtube.com/watch?v=mJB83EZtAjc</a></li>
  <li><a href="http://eleganthack.com/the-art-of-the-okr/">http://eleganthack.com/the-art-of-the-okr/</a></li>
  <li>Book — <a href="https://www.goodreads.com/book/show/39286958-measure-what-matters">Measure What Matters</a></li>
</ul>

<p>Do share how you maintain and keep track of your goals! But remember —</p>

<blockquote>
  <p>“Ideas are easy. Execution is everything.” — <strong>John Doerr</strong></p>
</blockquote>

<hr>

<p>I hope you learned something interesting and new. Don’t miss out on the latest blogs — <a href="https://mohitkhare.me/blog/personal-okrs/[http://eepurl.com/g2Mbc9](http://eepurl.com/g2Mbc9)">Subscribe now</a>. ✅</p>

<p>Interested in more technology, productivity and life stuff? I share updates/knowledge almost daily on <a href="https://twitter.com/mkfeuhrer">Twitter</a>.</p>

<p>Reach out to me at <a href="https://mohitkhare.me/">mohitkhare.me</a> ❤️️</p>

    
            </div></div>]]>
            </description>
            <link>https://mohitkhare.me/blog/personal-okrs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23661067</guid>
            <pubDate>Sat, 27 Jun 2020 11:15:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Treatise on Font Rasterisation (2010)]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23660701">thread link</a>) | @threeme3
<br/>
June 27, 2020 | https://freddie.witherden.org/pages/font-rasterisation/ | <a href="https://web.archive.org/web/*/https://freddie.witherden.org/pages/font-rasterisation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    
    
    <p>Font rasterisation is, in the author’s opinion, one of the most
    interesting fields of computer science. If music is the subjective
    application of physics, then font rasterisation is almost
    certainly the subjective application of computer science. The
    purpose of this article is threefold: firstly, to provide an
    introduction into the various methods available to aid in the
    rasterisation process; secondly, to provide a critical analysis of
    these methods against the needs of desktop applications; and
    finally, to relate this analysis to free software.</p>
    <p>Figures, in the form of bitmap images, are used extensively
    throughout. This is done to ensure consistent results across
    different platforms. Since some of the figures make use of
    sub-pixel rendering, this article is best viewed on an LCD
    screen.</p>
    <h2>Contents</h2>
    <ul>
      <li><a href="#introduction">Introduction</a></li>
      <li><a href="#font-hinting">Font Hinting</a></li>
      <li><a href="#anti-aliasing">Anti-aliasing</a></li>
      <li><a href="#anti-aliasing-with-hinting">Combining
      Anti-aliasing With Hinting</a></li>
      <li><a href="#sub-pixel-rendering">Sub-pixel Rendering</a></li>
      <li><a href="#sub-pixel-positioning">Sub-pixel
      Positioning</a></li>
      <li><a href="#application-requirements">Application
      Requirements</a></li>
      <li><a href="#windows-os-x">Windows &amp; Mac OS X</a></li>
      <li><a href="#summary-of-techniques">Summary of
      Techniques</a></li>
      <li><a href="#free-software">GNU/Linux &amp; Free
      Software</a></li>
      <li><a href="#advice-for-distributions">Advice For
      Distributions</a></li>
      <li><a href="#other-resources">Other Resources</a></li>
      <li><a href="#references">References</a></li>
      <li><a href="#figure-notes">Figure Notes</a></li>
      <li><a href="#revision-history">Revision History</a></li>
    </ul>
    <h2><a name="introduction">Introduction</a></h2>
    <p>Before we start exploring the various methods used in font
    rasterisation, it is important to first understand <em>why</em>
    rasterisation is so difficult. Why should rasterisation on a
    computer screen be any more complicated than on a printer? It all
    comes down to resolution. Or, more precisely, the number
    of <em>dots per inch</em> (DPI).</p>
    <p>Printers typically start at around 300 DPI, with 600 DPI not
    being uncommon. This means that for every inch (2.54cm), there are
    potentially 300+ individual dots. Fonts, however, are not measured
    in dots but instead in <em>points</em>: 1/72 of an inch. A direct
    consequence of this is that a specific font at 10pt will have the
    same <em>physical dimensions</em> irrespective of the DPI at which
    it is rasterised.</p>
    <p>Whereas printers have a relatively high DPI, computer screens
    are typically <em>assumed</em> to be at 96 DPI, over three times
    lower. Herein lies the difficulty with on-screen
    rasterisation. This is best illustrated with an example: Figure 1
    shows the letter ‘M’ in 10pt Times New Roman at 600, 300, and 96
    DPI, respectively. Looking at the figure, it is clear that 96 DPI
    is not sufficient to preserve the shape—or letter-form—of the
    glyph.</p>
    <div>
      <p><img width="137" height="55" alt="M at a low DPI" src="https://freddie.witherden.org/pages/font-rasterisation/images/m-various-dpi.png"></p><p>Figure 1: How 10pt Times Roman looks at 600, 300, and 96
      DPI.</p>
    </div>
    <p>This phenomenon can be explained using <em>information
    theory</em>. Since glyphs contain information it is possible to
    view them as a signal comprised of various frequencies. The
    Nyquist–Shannon sampling theorem states that in order to
    accurately reproduce a signal, the sampling rate needs to
    be <em>at least twice the maximum frequency of the
    signal</em>. Should the sampling rate be lower than this, then
    distortions—in the form of aliasing—will be introduced. In the
    case of rasterisation, the sampling rate corresponds directly to
    the DPI of the output device.</p>
    <p>An example of aliasing as a consequence of low DPI can be seen
    in Figure 2.</p>
    <div>
      <p><img width="249" height="12" alt="Aliasing at a low DPI" src="https://freddie.witherden.org/pages/font-rasterisation/images/aliasing.png"></p><p>Figure 2: 10pt Times New Roman at 96 DPI. Note how some stems
      are thicker than others, and how certain features are
      under-/over-emphasised.</p>
    </div>
    <p>Since it is clear that 96 DPI is insufficient for accurate
    rasterisation, we are left with two options. The first is to find
    a way of <em>increasing the effective sampling rate</em> of the
    device, while the second is to <em>reduce the frequency of the
    glyphs to allow the use of a lower sampling rate</em>. All of the
    methods presented in this article fall into one of these two
    categories.</p>
    <h2><a name="font-hinting">Font Hinting</a></h2>
    <p>One of the oldest and mostly widely used techniques for
    improving rasterisation quality is font hinting. Also known
    as <em>grid fitting</em>, hinting involves modifying the shape of
    glyphs in order to ensure they line up with the rasterisation
    grid. By distorting the glyph so that it is aligned with the pixel
    grid, the overall frequency is reduced. An example of font hinting
    can be seen in Figure 3.</p>
    <div>
      <p><img width="257" height="26" alt="Un-hinted vs hinted text" src="https://freddie.witherden.org/pages/font-rasterisation/images/hinting.png"></p><p>Figure 3: 10pt Times New Roman at 96 DPI with (bottom) and
      without (top) hinting. Also note the differing widths between
      the hinted and un-hinted text.</p>
    </div>
    <p>The hinted text is much more consistent than its un-hinted
    counterpart. However, this consistency comes at the price of
    accuracy. An unavoidable consequence of warping glyphs to the
    rasterisation grid is that their dimensions change slightly. These
    small differences quickly add up over a line of text resulting in
    a visible difference—such as that seen in Figure 3. The author
    refers to this phenomenon as <em>character drift</em>.</p>
    <p>The degree of hinting required to produce consistent output is
    dependent on the DPI of the output device; low resolution devices
    require more aggressive hinting than high resolution device. One
    of the consequences of aggressive hinting—necessary as it may
    be—is character drift. At resolutions in excess of 300 DPI, it is
    possible to forego font hinting entirely.</p>
    <h3>Implementation details</h3>
    <p>Font hinting is usually achieved through one of two
    approaches. The first of these puts the font designer in control
    of the hinting process. This is the approach taken by the TrueType
    font specification—without a doubt the most widespread font
    format. In the specification, a virtual machine is used to
    instruct the rasteriser on how to go about rendering a
    glyph. This, in theory, gives designers <em>pixel level</em>
    control over how glyphs are rasterised at various
    sizes <cite><a href="#tur01a">Tur01a</a></cite>. The second
    approach is to leave hinting up to the font rasteriser—so
    called <em>auto-hinting</em>. When rendering non-TrueType
    fonts—such as those in Adobe’s Type 1 format, or those that lack
    hinting instructions—this is often the only
    option <cite><a href="#tur01a">Tur01a</a></cite>.</p>
    <p>In order for a meaningful comparison to be made between these
    approaches, it is first necessary to have an understanding of some
    of the other techniques available for improving rasterisation
    quality.</p>
    <h2><a name="anti-aliasing">Anti-aliasing</a></h2>
    <p>So far, we have been assuming that pixels are bi-level, either
    on or off, black or white. However, modern computer screens are
    capable of displaying millions of colours, including shades of
    grey. Font rasterisers are able to take advantage of this by using
    a technique called <em>anti-aliasing</em>. As the name would
    suggest, anti-aliasing is a means of avoiding the unwanted effects
    of aliasing when sampling a high-frequency signal on a
    low-frequency device. This is done by blurring the signal; its
    effect is to reduce its maximal frequency.</p>
    <p>Pixels of anti-aliased text are multi-level. That is, they can
    be black, white, or a shade of grey. The shade of a pixel depends
    on the percentage of the pixel that is <em>masked</em> by the
    glyph. This concept is neatly demonstrated in Figure 4.</p>
    <div>
      <p><img width="92" height="63" alt="Primitive anti-aliasing" src="https://freddie.witherden.org/pages/font-rasterisation/images/g-anti-aliased.png"></p><p>Figure 4: The letter ‘g’ in 10pt Times New Roman at 672 DPI
      (left) and 96 DPI (right). The right glyph has been rendered
      with a (primitive) anti-aliasing algorithm and scaled by a
      factor of 7.</p>
    </div>
    <p>The effect of anti-aliasing on a line of text can be seen in
    Figure 5. Anti-aliasing does a very good job at preserving the
    shapes of glyphs. Moreover, the anti-aliased text does not suffer
    from character drift. However, this accuracy comes at the
    sacrifice of clarity—the anti-aliased text has a much lower
    contrast than its hinted counterpart.</p>
    <div>
      <p><img width="257" height="41" alt="A comparison of anti-aliased
      text" src="https://freddie.witherden.org/pages/font-rasterisation/images/anti-aliasing.png"></p><p>Figure 5: 10pt Times New Roman at 96 DPI; without
      anti-aliasing or hinting (top), with hinting (middle), with
      anti-aliasing (bottom).</p>
    </div>
    <h2><a name="anti-aliasing-with-hinting">Combining Anti-aliasing
    With Hinting</a></h2>
    <p>Both hinting and anti-aliasing improve the legibility of text
    at low resolutions by making it more consistent. Hinting does this
    at the cost of <em>accuracy</em>, while anti-aliasing does it at
    the cost of <em>contrast</em>. At this point, the logical question
    to ask is “can hinting and anti-aliasing be used in conjunction
    with each other?” The answer is yes—with the appropriate finesse,
    it is possible to hint anti-aliased text.</p>
    <p>In principle, hinting anti-aliased text is exactly the same as
    hinting monochromatic text. However, in practice, a different
    implementation is required in order to produce high-quality
    output <cite><a href="#tur01b">Tur01b</a></cite>. The practicality
    of this depends on the hinting approach taken; it is significantly
    easier when the hinting is performed by the font rasteriser
    instead of a virtual machine. Indeed, naïvely combining TrueType
    hinting with anti-aliasing can often result in a <em>reduction in
    overall consistency</em>! This is most readily observed when
    rendering sans-serif fonts, as can be seen in Figure 6.</p>
    <div>
      <p><img width="263" height="43" alt="Hinting and anti-aliasing
      combined" src="https://freddie.witherden.org/pages/font-rasterisation/images/bytecode-hinting-with-anti-aliasing.png"></p><p>Figure 6: 10pt Arial at 96 DPI; with TrueType hinting (top),
      with anti-aliasing (middle), with TrueType hinting and
      anti-aliasing (bottom).</p>
    </div>
    <p>While the output is legible, it lacks consistency—some
    characters, such as ‘w’ and ‘s’, are anti-aliased, while others,
    such as ‘l’, are not. This causes some characters to appear to be
    heavier than others. These heavier characters are often referred
    to as being <em>dirty</em>. The undesirable characteristics
    apparent in Figure 6 arise because the anti-aliased text is being
    hinted <em>as if it were regular monochromatic text</em>. (Which,
    incidentally, is why the application of anti-aliasing has no
    effect on the overall character drift.) But as was established in
    the previous section, anti-aliased text has a <em>lower
    frequency</em> than monochromatic text. The solution, therefore,
    is to use less aggressive hinting. This is quite difficult to
    accomplish when using TrueType hinting, as the virtual machine
    does not …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://freddie.witherden.org/pages/font-rasterisation/">https://freddie.witherden.org/pages/font-rasterisation/</a></em></p>]]>
            </description>
            <link>https://freddie.witherden.org/pages/font-rasterisation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23660701</guid>
            <pubDate>Sat, 27 Jun 2020 09:52:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Algorithmic View of Law]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23660114">thread link</a>) | @iciac
<br/>
June 27, 2020 | https://www.camerongordon.site/post/an-algorithmic-view-of-law | <a href="https://web.archive.org/web/*/https://www.camerongordon.site/post/an-algorithmic-view-of-law">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><p id="viewer-foo">In Western Australia it an offence to possess more than 50kg of potatoes, <a href="https://www.gotocourt.com.au/legal-news/weird-australian-laws/" target="_top" rel="noopener"><u>unless you are a member of the Potato Corporation</u></a>. Challenging someone to a duel in Tasmania carries a $6,000 fine. There's no law against <a href="http://www.gerties.com.au/weird-australian-laws-fact-or-fiction/" target="_top" rel="noopener"><u>wearing hot pink pants after midday</u></a> on a Sunday afternoon in Victoria, but flying a kite in public <a href="http://www8.austlii.edu.au/cgi-bin/viewdoc/au/legis/vic/consol_act/soa1966189/s4.html" target="_top" rel="noopener"><u>"to the annoyance of any person"</u></a> can put you back $800. Under the Rain-Making Control Act (1967) you are advised that it is an offence to <a href="http://www.legislation.vic.gov.au/Domino/Web_Notes/LDMS/LTObject_Store/ltobjst8.nsf/DDE300B846EED9C7CA257616000A3571/9D788B5BB4776F24CA257C3100008D44/$FILE/67-7637aa016%20authorised.pdf" target="_top" rel="noopener"><u>"carry out unauthorised rain-making operations"</u></a>. </p><p id="viewer-5hc95">Getting a measure of how many laws there are in Australia is not easy, but one practitioner's resource <a href="https://legal.thomsonreuters.com.au/products/the-laws-of-australia/" target="_top" rel="noopener"><em><u>The Laws of Australia</u></em></a> proudly lists over 40,000 legal propositions across 320 specific topics and 36 broad topic areas. Despite the legal maxim that ignorance of the law is no excuse, it is clear that it is impossible for even an interested reader to have a full and complete knowledge of the law - let alone a disinterested reader. </p><p id="viewer-eodrf">In the Design of Everyday Things, Donald Norman describes two crucial principles for a useful object: <em>Discoverability</em> and <em>Understanding</em>. It should be easy to learn how an object works, and clear to see how to use it. For the vast majority of laws, this is not the case: a typical Act may run for many hundreds of pages, define case-specific jargon, refer to rules set out in external pieces of legislation, involve ambiguities, internal inconsistencies, or simply poor writing (the 528 page <a href="https://www.legislation.qld.gov.au/view/html/inforce/current/act-2001-071" target="_top" rel="noopener"><u>Duties Act in Queensland</u></a> is a prime example).</p><p id="viewer-8n06i">In part, this is nature of the beast: the administrative structure for a law to be changed is a complicated and multi-staged affair, involving a parliament which will not seek to amend a law unless it serves for political capital. Repairing cracks in the sidewalk is necessary, but it's nothing you want to turn into a press statement. As a result law is updated only sporadically, and often in response to the most vocal and focal failures rather than being optimised. </p><p id="viewer-ekgl9">There are moves to improve this process. One of the more interesting is being led by the CSIRO <a href="https://data61.csiro.au/en/Our-Research/Our-Work/Future-Cities/Optimising-service-delivery/RaaP" target="_top" rel="noopener"><em><u>Regulation as a Platform</u></em></a><em> </em>project which recommends converting regulatory rules into machine readable logic which can be quickly checked for internal consistency, and clearer ways this may communicated to the public or automated for simple administrative tasks. Advances in natural language processing may additionally aid in users being able to ask for clarification for a legal rule, and receive general advice from a machine.</p><p id="viewer-ci8o1">The idea <a href="https://theconversation.com/csiro-wants-our-laws-turned-into-computer-code-heres-why-thats-a-bad-idea-130131" target="_top" rel="noopener"><u>has received pushback</u></a> due to concern that an algorithmic approach to law removes the human element and the role of discretion. Moreover the stink of Robodebt scandal makes some leery of outsourcing application of the law too far to machines. However the idea has some merit - not only in terms of directly using new tools for searching or interpreting the law; but also conceptually, using programming concepts to better understand how law may be better designed to run efficiently and user-friendly. </p><p id="viewer-dlmsk">In many ways a law is a program which runs on society rather than on circuits: wet, squishy humanware rather than hardware. It involves a system of logic and operation. Functions which are defined and acted upon in a systematic order, with constraints provided which restrict the operation of a system. The analogy is particularly clear for administrative law applied by rote. However, it also applies for laws which require the application of discretion or decision-making (the decision maker is simply a sub-operation requiring a person). </p><p id="viewer-6vdkf">In code, there is the concept of algorithmic efficiency - how resources (time and storage) vary with the size of an operation. This is measured by reference to the cost of a base operation (e.g. adding up two numbers, or plucking out an item from a list). The common measure is the worst case running time: a constant operation <em>O(1)</em> runs the same time no matter the size of the input; a linear operation <em>O(N) </em>runs as the sum of the base operations; and polynomial operations [e.g. <em>O(N^2)</em>],<em> </em>and exponential operations [e.g. <em>O(2^N)</em>] run increasingly less efficiently with the size of the input. Designing an efficient algorithm is understandably a goal for a good program that will run fast and easily with little overhead. </p><p id="viewer-dshb6">In principle the idea of algorithmic complexity also applies to law. Here we have additional forms of resources: costs of implementation (the cost of administrative public servants), costs of interpretation (the cost of understanding the law, e.g. employing external legal advice, reading legislation, or checking informal explainers), and costs in terms of error correction (the judicial system, including the many barriers to entry). While less tangible, these are similar to those borne by computers in algorithmic complexity: they represent the cost of resources required to run a particular process, which may be comprised of many smaller processes or required actions. </p><p id="viewer-4kiqo">As a result programming principles can be applied to make law more efficient and user-friendly. The aim is to minimise the total costs of operation while sufficiently achieving the desired legal aim. Looking at the regular individual operations involved in a procedure, including complex, expensive, or repeated operations, is the first step in improving the efficiency of a law. Beyond thinking about law in terms of algorithmic complexity, there are a number of core programming techniques that lend themselves to direct analogies in legal design. Many of the rules outlined in The Pragmatic Programmer (outline <a href="http://www.inf.fu-berlin.de/inst/ag-se/teaching/K-CCD-2014/Pragmatic-Programmer-summary.pdf" target="_top" rel="noopener"><u>here</u></a>) are directly applicable - particularly ideas around orthogonality (reducing cross-dependencies), maintaining single unambiguous definitions, and building in exception handling are all good concepts. </p><p id="viewer-1pb16">It's no coincidence that the authors of The Pragmatic Programmer turned to legal analogies when outlining concepts for programmers. As is often the case when two fields share conceptual links learnings from the two domains can flow in both directions, and legal professionals and policy designers would be advised to learn and take from design techniques in computer science where they can. </p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.camerongordon.site/post/an-algorithmic-view-of-law</link>
            <guid isPermaLink="false">hacker-news-small-sites-23660114</guid>
            <pubDate>Sat, 27 Jun 2020 07:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What IT Is]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23659998">thread link</a>) | @latchkey
<br/>
June 26, 2020 | https://xn--mp8hai.fm/statement | <a href="https://web.archive.org/web/*/https://xn--mp8hai.fm/statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="body"><h2>👁👄👁</h2><h2>WHAT IT REALLY IS</h2><p>JUNE 26TH, 2020</p><p>You’re probably wondering what this is. Well, it started off as just what it is.</p><p>A group of us changed our Twitter names to include <span>👁👄👁"</span> because we thought it was a funny trend from TikTok. People started noticing the change on their timelines, noting the creepiness of the emojis in particular. For a brief period of time, everyone who added the emojis to their name was added to a giant Twitter group conversation. From there, things unfolded.</p><p>What started out as a meme in our small group chat grew bigger than we ever imagined. So we thought about how to make use of the hype cycle we’d stumbled upon. But honestly, we didn’t have to think too hard: in this moment, there’s pretty much no greater issue to amplify than the systemic racism and anti-Blackness much of the world is only beginning to wake up to. We’re excited that we could use our newfound platform to drive action towards a few causes that are doing important work towards racial justice: <a href="https://thelovelandfoundation.org/loveland-therapy-fund/">Loveland Foundation Therapy Fund</a>,<a href="https://www.theokraproject.com/">The Okra Project</a>,<a href="https://www.innocenceproject.org/">The Innocence Project</a>, and others.</p><p>We’ve done pretty well for a non-existent product. <span>👁👄👁.fm</span> was the top product of the day on Product Hunt (Theranos who?). The website accumulated 20,000 email signups and thousands of tweets sharing the link. We were covered in <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/news/face-emoji-twitter-it-is-what-it-is-promo-a9587351.html">The Independent</a> and <a href="https://www.forbes.com/sites/paularmstrongtech/2020/06/26/what-is--oh-it-is-what-it-is/amp/?__twitter_impression=true">Forbes</a>. We got shoutouts from <a href="https://constine.substack.com/p/what-does-mean-well">Josh Constine</a> and <a href="https://wfh.substack.com/p/the-6-builders-who-will-thrive-in">Brianne Kimmel</a>. Some folks on <a href="https://www.reddit.com/r/OutOfTheLoop/comments/hg26ip/whats_the_deal_with_this_it_is_what_it_is_app/">Reddit</a> puzzled over who we were. <a href="https://twitter.com/andrewchen/status/1276585276626726913?s=20">Andrew Chen</a> of Andreessen Horowitz, <a href="https://twitter.com/shannonpurser/status/1276631647157235712">Shannon Purser</a> of Stranger Things, and <a href="https://twitter.com/elonmusk/status/1276418907968925696">Elon Musk</a> may have subtweeted us? The <a href="https://twitter.com/itiseyemoutheye">@itiseyemoutheye</a> Twitter and accounts of our teammates were inundated with invite requests. Most importantly, we raised over $65,000 in donations from people who signed up for our email list. Two anonymous donors have agreed to match the first $60,000 and $75,000, bringing the total to $200,000. We would love to work with anyone else who wants to match. Please DM us! </p>In a strange way, this sort of became an anti-statement against what we’d all seen on tech Twitter. We’re a <a href="https://xn--mp8hai.fm/demographics.png">diverse</a>, ragtag group of young technologists tired of the status quo tech industry, and thought that we could make the industry think a bit more about its actions. Despite calls-to-action like that “<a href="https://a16z.com/2020/04/18/its-time-to-build/">It’s Time to Build</a>” essay we’ve all read, most of the industry (from product teams to VC) still stays obsessed with exclusive social apps that regularly ignore — or even silence — real needs faced by marginalized people all over the world, and exclude these folks from the building process. As an industry, we need to do better.<p>We sincerely thank you for spreading the word and donating to these important causes. In conclusion, it is what it is: a meme that leveraged the relentless hype of exclusive apps and redirected it towards a critical social need. Thank you, and remember that unlike <span>👁👄👁</span>, #BlackLivesMatter and other social movements aren't trends or hype cycles. Let’s keep giving back as best as we can.</p><p>Signed,</p><p><a href="https://twitter.com/itiseyemoutheye/following">The 👁👄👁 Team</a></p><p><a href="https://shop.itiswhatitis.fm/">We do have merch though.</a><br>All proceeds are donated to organizations that support Black lives.</p></article></div></div>]]>
            </description>
            <link>https://xn--mp8hai.fm/statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659998</guid>
            <pubDate>Sat, 27 Jun 2020 06:52:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live code music in GLSL shaders (Chrome & FF only)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23659859">thread link</a>) | @mv9
<br/>
June 26, 2020 | https://fms-cat.com/wavenerd/ | <a href="https://web.archive.org/web/*/https://fms-cat.com/wavenerd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://fms-cat.com/wavenerd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659859</guid>
            <pubDate>Sat, 27 Jun 2020 06:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Indian railways gave time to India]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659821">thread link</a>) | @indianhistoryy
<br/>
June 26, 2020 | http://worldhistoryinchunks.com/2020/06/27/who-gave-india-time/ | <a href="https://web.archive.org/web/*/http://worldhistoryinchunks.com/2020/06/27/who-gave-india-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h2 id="783e">Railway time was the first joint element that united India. Madras/Chennai was the first place to transmit time to entire India.</h2>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/06/413ad-0wpivc8ss5r3ztwoj.jpg" alt=""><figcaption>Indian Railway.Source-Financial express</figcaption></figure></div>



<p>I’m always fascinated by the way my dad conveyed time. He prefers the 24 hours format. Many of his friends use the same, but in other walks of life in India, people stick to the 12hr time format. My dad worked in Indian railways, and in many parts of India, a 24 hours format came to be known as Railway Time. How did it the 24-hour format got the name railway time, and who gave India time? Let’s ponder on that question.</p>



<h2 id="c26f">Asia’s first-time zone:</h2>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/06/2fd24-0gbrmluypyr0km7jb.jpg" alt=""><figcaption>Madras Observatory.Source-Wikipedia</figcaption></figure></div>



<p>The need to have a standard time zone was the need due to Industrialisation. Prominent Astronomers across the world gathered in the USA for the World Meridian conference to conclude the center of the earth for timezone definition in 1884. The astronomers agreed that Greenwich, where British astronomical society is located will be the centerline for the time zone. Countries will calculate their time based on Greenwich meridian.</p>



<div><figure><img src="https://interestinghistoryforall.files.wordpress.com/2020/06/e08af-0h_a52u42pru5n1cy.jpg" alt=""><figcaption>John Goldingham working. Source-Wikipedia</figcaption></figure></div>



<p>British India set up a survey office in Nungambakkam, Madras to gather data on the landscape around Madras(Modern day Chennai). John Goldingham was the first Astronomer to land in Chennai and set up the first metrological station in Asia in Madras in 1742. He mapped the stars to set Madras at 80° 17’21 “E. He predicted India is 51/2 hours ahead of GMT. The time zone was fixed as Madras’s time probably the first Asian official timezone. His successor Thomas Glanville Taylor mapped 11,000 stars and published “Madras Catalog.”</p>



<p>As Industrialization gripped India, it was the need of the hour to keep uptime. Indian railways started to connect the nook and corner of India. Indian railways had three time zones, namely Bombay/Mumbai time zone, Calcutta/Kolkatta time zone, and Madras/Chennai time zone. After a few years, Madras’s time was adopted as Indian railways official time as Madras observatory had a telegraph office that can synchronize time across India. Also, Madras’s time was the closest to GMT. The Madras Merdian is marked by a granite pillar that stands to this day in the spot. The small telegraph office in Madras controlled the time of entire India until independence.</p>



<h2 id="b907">Railway time:</h2>



<p>Indian railways weaved across Indian culture and were part and parcel of everyday activity for millions of Indians. When Indian railways adopted standard time, it took the time with it throughout India. Divided by 567 princely states which even the British can’t penetrate, Indian railways brought them together at the same time. Most railway employees like my dad speak in 24 hours format as they are used to it. Madras’s time was the official time of India until independence.</p>



<p>Youtube:<a href="https://www.youtube.com/channel/UCu6Fe1D-UqBBSVcVk0O4n6g/featured?view_as=subscriber" target="_blank" rel="noreferrer noopener">https://www.youtube.com/channel/UCu6Fe1D-UqBBSVcVk0O4n6g/featured?view_as=subscriber</a></p>



<p>Twitter:<a href="https://twitter.com/indianhistoryyn" target="_blank" rel="noreferrer noopener">https://twitter.com/indianhistoryyn</a></p>



<p>Orginially published in <a href="https://medium.com/history-in-bytes/who-gave-india-time-90bd51f4b3d">https://medium.com/history-in-bytes/who-gave-india-time-90bd51f4b3d</a></p>
			
			
						</div></div>]]>
            </description>
            <link>http://worldhistoryinchunks.com/2020/06/27/who-gave-india-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659821</guid>
            <pubDate>Sat, 27 Jun 2020 05:59:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Myths about Patents and Trademarks in startups]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 32 (<a href="https://news.ycombinator.com/item?id=23659787">thread link</a>) | @samdung
<br/>
June 26, 2020 | https://hitstartup.com/myths-about-patents-and-trademarks-in-startups/ | <a href="https://web.archive.org/web/*/https://hitstartup.com/myths-about-patents-and-trademarks-in-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>These are some of the common myths about Patents and Trademarks in startups.</p><h3 id="i-have-a-startup-idea-i-need-to-protect-it-with-a-patent">I have a startup idea, I need to protect it with a patent</h3><p>It’s natural to feel defensive about our <a href="https://hitstartup.com/startup-ideas-vs-problems/" target="_blank">startup idea</a>, but patents are for invention/innovation and not for a startup idea; even if we get nightmares about <a href="https://hitstartup.com/faang-will-steal-my-idea/" target="_blank">FAANG stealing our startup idea</a>.</p><h3 id="i-have-an-innovative-app-idea-i-need-to-protect-it-with-a-patent">I have an innovative app idea, I need to protect it with a patent</h3><p>Most countries don’t allow <a href="https://web.archive.org/web/20200213051434/https://www.wipo.int/sme/en/documents/software_patents_fulltext.html" target="_blank">patent for a software</a>. Economic theories, methods of doing business, mathematical methods or computer programs&nbsp;as such&nbsp;are not patentable inventions in several countries.</p><h3 id="my-patent-attorney-said-they-are-patentable">My patent attorney said they are patentable</h3><p>Did you read all the clauses in the agreement you signed with your patent attorney? The decision to award a patent to an invention/innovation lies solely with the patent examiner of the country. By the time a patent application is filed, till it comes to examination, several years and thousands of dollars would have been spent.</p><p>Although ethically, a patent attorney should explicitly convey their doubts on patentability of an invention, few rarely do. Even when Prior Art Search(Searching for conflicting patents) is conducted by the patent attorney, they are not always successful in bringing up the conflicting patents because our patent application is not drafted yet.</p><p>But, when the Govt. patent examiner does the Prior Art Search while examining our patent application, they will likely find conflicting patents if it exists.</p><h3 id="i-have-paid-my-patent-attorney-explained-my-invention-now-all-i-have-to-do-is-just-sit-tight-for-a-patent">I have paid my patent attorney, explained my invention, now all I have to do is just sit tight for a patent</h3><p>An average patent attorney drafts patent for anything from innovation in a <a href="https://en.wikipedia.org/wiki/Bidet" target="_blank">bidet</a> to quantum computers, so they are experts in using language to define an invention but they are rarely an expert in any field of invention.</p><p>So, this requires utmost care from the inventor to work along with the patent drafter to articulate their invention with appropriate vocabulary.</p><p>Unfortunately, patent attorneys tend to force the inventor to not to be specific in describing their invention in the patent application in order to exploit the loop holes in patent examination; This may help in getting the patent, but it also enables someone else to exploit the same loop holes to file a patent for the copy of our invention by just changing the grammar/vocabulary because our patent was too generic.</p><h3 id="i-have-filed-for-a-patent-no-one-would-copy-my-innovation-invention">I have filed for a patent, no one would copy my innovation/invention</h3><p>Examination of patent takes several years, although in the meantime we could use ‘patent-pending’ tag if our patent application gets published, finding someone who is copying our invention takes proactive approach. If the copied invention is being applied for patent, we need to detect it from published journal of the patent office and raise a concern.</p><p>All these takes extraordinarily focused effort and budget.</p><h3 id="i-have-applied-for-a-patent-via-pct-i-will-receive-patent-for-all-countries">I have applied for a patent via PCT, I will receive patent for all countries</h3><p><a href="https://www.wipo.int/pct/en/" target="_blank">PCT - Patent Cooperation Treaty</a> simplifies the process of applying for a patent in several countries who are part of the PCT treaty, but the process of obtaining a patent depends upon the individual country’s patent laws.</p><p>Even during filing PCT, the second phase i.e. national phase involves filing documents for patent application in the respective individual countries requiring working with the patent attorney’s of those countries resulting in thousands of dollars of expense for each country we wish to apply for via PCT.</p><p>We can extrapolate the same process for patent examination in each of those countries.</p><p>Then there are certain countries which even while being part of the PCT, doesn’t enforce patent protection for inventions of other countries in order to protect their local businesses which copies our invention.</p><h3 id="i-have-received-my-patent-it-would-prevent-someone-from-copying-my-invention">I have received my patent, it would prevent someone from copying my invention</h3><p>Like any law, existence of a law doesn’t prevent someone from violating it; enforcement and judicial process should uphold that law. Similarly, existence of patent doesn’t prevent someone from copying our invention.</p><p>We need to find the violator, pursue an often lengthy and expensive judicial process to claim our right to the invention protected by the patent.</p><h3 id="i-m-the-inventor-in-the-patent-i-can-do-anything-with-it">I’m the inventor in the patent, I can do anything with it</h3><p>Unless the inventor in the patent is the owner of the patent, the inventor has no right to the patent. This is often the case when businesses file patents, where the business is the owner in the patent and the employee is the inventor in the patent.</p><h3 id="patents-are-only-for-protecting-my-invention">Patents are only for protecting my invention</h3><p>The main reason to protect the invention is to reap the value of the invention if needed. Patents offer commercial and strategic value to businesses.</p><p>So, patents are often used for trading them for money or for other patents in organizations apart from using it for protecting their inventions.</p><h3 id="patents-make-me-look-cool">Patents make me look cool</h3><p>Not necessarily, <a href="https://www.eff.org/deeplinks/2020/05/new-low-bad-patent-patent-troll-sues-ventilator-company" target="_blank">patent trolls</a> have left a bad taste in the inventor/innovator community; so much so that many are <a href="https://www.youtube.com/watch?v=OsIihrcqJYA" target="_blank">choosing not to file patent for their invention</a>.</p><p>Expenses, effort, lengthy unfair judicial trials has made several startups to not pursue patent for their invention in favor of capital efficiency.</p><h3 id="open-source-projects-doesn-t-need-patents">Open-source projects doesn’t need patents</h3><p>Open-source projects might need patents to <a href="https://golang.org/PATENTS" target="_blank">protect itself from getting sued for patent infringement</a>. Open-source projects protected by patents can prevent large organizations from stealing our project <a href="https://keivan.io/the-day-appget-died/" target="_blank">without due credit</a>.</p><h3 id="i-have-a-startup-product-name-i-need-to-trademark-it">I have a startup/product name, I need to trademark it</h3><p>Unless the startup/product has created value for its customers, so that a counterfeiter is using that startup/product name for forgery; trademarks for startup/product names are useless. Besides, in most countries just <a href="https://hitstartup.com/when-to-register-our-startup/" target="_blank">incorporating/registering our startup as a company</a> would prevent anyone else from using the same name for their company.</p><h3 id="trademark-automatically-applies-to-the-name-and-the-logo">Trademark automatically applies to the name and the logo</h3><p>Trademarking the name and logo are separate process namely wordmark and device mark respectively. Device mark might include text when it’s alongside the logo.</p></div></div>]]>
            </description>
            <link>https://hitstartup.com/myths-about-patents-and-trademarks-in-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659787</guid>
            <pubDate>Sat, 27 Jun 2020 05:44:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning Companies Revolutionizing Industries]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659486">thread link</a>) | @nutellalover
<br/>
June 26, 2020 | https://www.confetti.ai/post/50-machine-learning-and-data-science-companies | <a href="https://web.archive.org/web/*/https://www.confetti.ai/post/50-machine-learning-and-data-science-companies">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.10.5"><div dir="ltr"><div><div id="viewer-1m9gi"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.confetti.ai/post/50-machine-learning-and-data-science-companies" data-pin-media="https://static.wixstatic.com/media/4feadc_12fbac4a7cc34e54999ddbd5f621d7e5~mv2.jpg/v1/fit/w_5000,h_4000,al_c,q_80/file.png" src="https://static.wixstatic.com/media/4feadc_12fbac4a7cc34e54999ddbd5f621d7e5~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 01-.283 0l-.374-.374a.2.2 0 010-.283l4.356-4.355h-3.786a.2.2 0 01-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 01-.2.2h-.529a.2.2 0 01-.2-.2zm-6.5 6.9v.529a.2.2 0 01-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 01.283 0l.374.374a.2.2 0 010 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z"></path></svg></div></div></div></div><p id="viewer-agmh1">Nowadays it's hard to find a single industry where machine learning and data science aren't being used to improve productivity and deliver results. Indeed that is why people are so excited about the promise of artificial intelligence: it can be applied to so many diverse problem spaces effectively and it works!</p><p id="viewer-82q81">In this post, we'll go over some impactful companies doing data science and machine learning today across various industries. This list has been aggregated after analyzing over 200 company descriptions, and we've broadly organized them by the problem domain being tackled and have included a brief description of their mission. </p><h3 id="viewer-8moqe"><strong>Infrastructure and Hardware</strong></h3><p id="viewer-15jm3"><a href="https://booklet.ai/" target="_blank" rel="noopener"><u>Booklet AI</u></a></p><p id="viewer-39ima">	TLDR: A framework for providing data integrations and web interfaces for trained machine learning models.</p><p id="viewer-uv8g"><a href="https://neptune.ai/" target="_blank" rel="noopener"><u>Neptune AI</u></a></p><p id="viewer-98oic">	TLDR: A lightweight experiment management tool that integrates into existing machine learning workflows</p><p id="viewer-6fgfd"><a href="https://determined.ai/" target="_blank" rel="noopener"><u>Determined AI</u></a></p><p id="viewer-aqcc8">	TLDR: A deep learning platform to help scale up training jobs and track experiments easily</p><p id="viewer-ci845"><a href="https://www.streamlit.io/" target="_blank" rel="noopener"><u>Streamlit</u></a></p><p id="viewer-bq68m">	TLDR: A tool for easily building web interfaces for data science and machine learning experiments in Python</p><p id="viewer-foeaa"><a href="https://www.factored.ai/" target="_blank" rel="noopener"><u>Factored AI</u></a></p><p id="viewer-dtbq8">	TLDR: Helps organizations build out entire data science teams by handling screening and training</p><p id="viewer-3cunr"><a href="https://www.datarobot.com/" target="_blank" rel="noopener"><u>DataRobot</u></a></p><p id="viewer-5em2g">	TLDR: An enterprise platform for helping companies automate the full machine learning pipeline starting with raw data all the way to production-level predictions.</p><p id="viewer-etf4q"><a href="https://www.cognitivescale.com/" target="_blank" rel="noopener"><u>Cognitive Scale</u></a></p><p id="viewer-2vg3f">	TLDR: Provides tools to build end-to-end workflows for models, using visual interfaces and emphasizing explainability</p><p id="viewer-8k1bm"><a href="https://www.h2o.ai/" target="_blank" rel="noopener"><u>H20 AI</u></a></p><p id="viewer-2kpd">	TLDR: Builds a suite of problem-agnostic tools and libraries for machine learning and data science experiments</p><p id="viewer-2r9eq"><a href="https://www.graphcore.ai/" target="_blank" rel="noopener"><u>GraphCore AI</u></a></p><p id="viewer-9lbf4">	TLDR: Developing a machine-learning specific processor that promises faster training times and lower inference latency than existing offerings such as GPUs</p><p id="viewer-c5dor"><span><u>Petuum</u></span></p><p id="viewer-2n4bj"><span>	TLDR: Building a general purpose suite of artificial intelligence building blocks that enable enterprises to build their own vertical solutions relying on machine learning</span></p><p id="viewer-5f1g8"><a href="https://www.dataiku.com/" target="_blank" rel="noopener"><u>Dataiku</u></a></p><p id="viewer-5e1s1">	TLDR: A fully-integrated and collaborative data studio that enables organizations to iterates on and develop date-driven solutions through tools for various stakeholders</p><p id="viewer-1b3s">
<a href="https://scale.com/" target="_blank" rel="noopener"><u>Scale AI</u></a></p><p id="viewer-45doc">	TLDR: Building a data platform for AI that helps companies build high quality training and validation datasets for their applications</p><h3 id="viewer-a08hm"><strong>Natural Language Processing</strong></h3><p id="viewer-9h598"><a href="https://narrativescience.com/" target="_blank" rel="noopener"><u>Narrative Science</u></a></p><p id="viewer-e9in1">	TLDR: Employs data storytelling to convert data analytics from structured formats to natural language output that can be more easily interpreted</p><p id="viewer-5l7a4"><a href="https://www.alpha-sense.com/" target="_blank" rel="noopener"><u>Alpha Sense</u></a></p><p id="viewer-e2cqn">	TLDR: An enterprise search engine for analyzing and understanding business and financial data</p><p id="viewer-adn0g"><a href="https://www.persado.com/" target="_blank" rel="noopener"><u>Persado</u></a></p><p id="viewer-asphb">	TLDR: A platform employing natural language understanding and generation to create more relevant and impactful marketing campaigns</p><p id="viewer-3vp77"><a href="https://casetext.com/" target="_blank" rel="noopener"><u>Casetext</u></a></p><p id="viewer-bbspe">	TLDR: A search engine optimized for litigation and legal document research</p><p id="viewer-3modk">
<a href="https://www.soundhound.com/" target="_blank" rel="noopener"><u>Soundhound</u></a></p><p id="viewer-8rajt">	TLDR: Develops voice recognition and natural language understanding tools used by enterprises</p><p id="viewer-cfrm"><a href="https://sherpa.ai/" target="_blank" rel="noopener"><u>Sherpa AI</u></a></p><p id="viewer-4b5gh">	TLDR: Building a suite of natural language processing SDKs for integrating recommendation systems, conversational managers, and user profiling into applications</p><p id="viewer-qsr6"><a href="https://www.meetcleo.com/" target="_blank" rel="noopener"><u>Cleo</u></a></p><p id="viewer-e8uvq">	TLDR: Leverages data science and natural language processing to build a chatbot for helping users with their personal finances</p><p id="viewer-6c94t">
<a href="https://lilt.com/" target="_blank" rel="noopener"><u>Lilt</u></a> </p><p id="viewer-7f91t">	TLDR: Helps enterprises with product localization through their efficient, AI-powered machine translation platform</p><h3 id="viewer-4i7p4"><strong>Computer Vision</strong></h3><p id="viewer-5e4uv"><a href="https://www.clarifai.com/" target="_blank" rel="noopener"><u>Clarifai</u></a></p><p id="viewer-ciu80">	TLDR: Provides an enterprise API for performing various computer vision tasks</p><p id="viewer-31h4l"><a href="https://orbitalinsight.com/" target="_blank" rel="noopener"><u>Orbital Insight</u></a></p><p id="viewer-1uu0l">	TLDR: A geospatial enterprise data platform that enables deriving insights in problems such as GIS mapping frequency, supply chain monitoring, and real estate due diligence</p><h3 id="viewer-4grsr"><strong>Healthcare and Medicine</strong></h3><p id="viewer-3ouup"><a href="https://www.tempus.com/" target="_blank" rel="noopener"><u>Tempus</u></a></p><p id="viewer-7jqh1">	TLDR: Applying machine learning and big data to precision medicine, thereby helping physicians make data-driven decisions for personalized healthcare</p><p id="viewer-6ern9"><a href="https://www.freenome.com/" target="_blank" rel="noopener"><u>Freenome</u></a></p><p id="viewer-flbmc">	TLDR: Employs machine learning and computational biology for early detection and precision intervention in cancer</p><p id="viewer-19egm"><a href="https://insilico.com/" target="_blank" rel="noopener"><u>Insilico Medicine</u></a></p><p id="viewer-c8gcd">	TLDR: Employs big data and statistical analyses for drug discovery, biomarker development, and aging research</p><p id="viewer-c1eae"><a href="https://insitro.com/about" target="_blank" rel="noopener"><u>Insitro</u></a></p><p id="viewer-9e62t">	TLDR: Developing a platform for accelerated drug discovery that leverages machine learning and big data</p><p id="viewer-kfrd"><a href="https://www.zebra-med.com/" target="_blank" rel="noopener"><u>Zebra Medical Vision</u></a></p><p id="viewer-bkq54">	TLDR: Develops medical imaging tools powered by AI to help improve the efficacy of radiologists in detecting illnesses.</p><p id="viewer-69b3c"><a href="https://www.benevolent.com/" target="_blank" rel="noopener"><u>Benevolent AI</u></a></p><p id="viewer-62a83">	TLDR: Leveraging machine learning and data science for various tasks like precision medicine, drug discovery, and molecular design</p><p id="viewer-dqttl"><a href="https://roamanalytics.com/" target="_blank" rel="noopener"><u>Roam Analytics</u></a></p><p id="viewer-165ij">	TLDR: Building a platform to help healthcare companies derive insights from structured medical language data</p><p id="viewer-b7v5j">
<a href="https://ablacon.com/" target="_blank" rel="noopener"><u>Ablacon</u></a></p><p id="viewer-ddcle">	TLDR: Developing technology to monitor in real-time what is going on inside someone's heart via the use of electrographic flows</p><p id="viewer-3a7fo"><a href="https://www.viz.ai/" target="_blank" rel="noopener"><u>Viz AI</u></a></p><p id="viewer-ah983">	TLDR: Uses images of CT scans to automatically detect stroke threats in patients and alert relevant health teams</p><p id="viewer-c2a8i"><a href="https://deep6.ai/" target="_blank" rel="noopener"><u>Deep 6</u></a></p><p id="viewer-5cmbl">	TLDR: Helps companies find appropriate candidates for patient trials by scanning and analyzing clinical records</p><h3 id="viewer-edo9j"><strong>Robotics</strong></h3><p id="viewer-131d7"><a href="https://www.neurala.com/" target="_blank" rel="noopener"><u>Neurala</u></a></p><p id="viewer-fijjq">	TLDR: Provides a framework for quicker tagging and training of AI models for industrial and robotics applications</p><p id="viewer-3rso5"><a href="https://www.bossanova.com/" target="_blank" rel="noopener"><u>Bossa Nova</u></a></p><p id="viewer-dpfac">	TLDR: Leverages technology such as drones, robots, and fixed cameras to help large-scale retailers automatically answer questions about item supplies and out-of-stock products</p><h3 id="viewer-artuk"><strong>Autonomous Vehicles</strong></h3><p id="viewer-4tu8s"><a href="https://www.aeye.ai/" target="_blank" rel="noopener"><u>AEye</u></a></p><p id="viewer-1pm34">	TLDR: Provides a 2D/3D perception platform for use in sensors of autonomous vehicles</p><p id="viewer-bocqg">
<a href="https://www.nauto.com/" target="_blank" rel="noopener"><u>Nauto</u></a></p><p id="viewer-3rbf3">	TLDR: Uses machine learning to power an in-vehicle device that helps reduce traffic accidents due to distracted driving</p><p id="viewer-drh26"><a href="https://www.pony.ai/en/tech.html" target="_blank" rel="noopener"><u>Pony AI</u></a></p><p id="viewer-5cstf">	TLDR: Develops autonomous vehicle technology including perception, planning and control, and HD mapping</p><h3 id="viewer-8qi25"><strong>Agriculture</strong></h3><p id="viewer-dv2ke"><a href="http://www.bluerivertechnology.com/" target="_blank" rel="noopener"><u>Blue River Technology</u></a></p><p id="viewer-dof1e">	TLDR: Using computer vision to build more efficient crop weed control and agricultural herbicide resistance</p><p id="viewer-9nj1a"><a href="http://www.taranis.ag/" target="_blank" rel="noopener"><u>Taranis</u></a></p><p id="viewer-7fr8v">	TLDR: Leverages computer vision to detect, analyze, and treat early signs of agricultural crop threats</p><h3 id="viewer-51j8o"><strong>Company Operations </strong></h3><p id="viewer-2h3ur"><a href="https://x.ai/" target="_blank" rel="noopener"><u>X.ai</u></a></p><p id="viewer-38u2r">	TLDR: AI-powered meeting and email scheduling</p><p id="viewer-ertfj"><a href="https://vidado.ai/" target="_blank" rel="noopener"><u>Vidado</u></a></p><p id="viewer-5v3g8">	TLDR: Builds sophisticated optical character recognition technology to extract insights from paper documents and forms</p><p id="viewer-9adh5"><a href="https://www.anodot.com/" target="_blank" rel="noopener"><u>Anodot</u></a></p><p id="viewer-6s69r">	TLDR: Real-time monitoring of analyze and correlate company data for tasks like revenue monitoring, customer monitoring, and digital partners monitoring.</p><p id="viewer-96tu8"><a href="https://www.behavox.com/" target="_blank" rel="noopener"><u>Behavox</u></a></p><p id="viewer-77fgm">	TLDR: An end-to-end data platform for deriving insights from internal data within an enterprise, focusing in particular on the financial sector</p><p id="viewer-dcvqi"><a href="https://textio.com/" target="_blank" rel="noopener"><u>TextIO</u></a></p><p id="viewer-6j91d">	TLDR: Provides a platform for helping companies write more targeted and effective hiring content such as job postings, tailored toward building more diverse and inclusive work environments</p><h3 id="viewer-ai0n0"><strong>DevOps and Security</strong></h3><p id="viewer-2kmj"><a href="https://sift.com/" target="_blank" rel="noopener"><u>Sift</u></a></p><p id="viewer-31pdt">	TLDR: Develops a suite of fraud detection APIs to help businesses ensure the digital trust and safety of their products</p><p id="viewer-2ggm0"><a href="https://onfido.com/" target="_blank" rel="noopener"><u>Onfido</u></a></p><p id="viewer-6vv1k">	TLDR: Uses machine learning to power various document and identify verification offerings</p><p id="viewer-fps3j"><a href="https://hunters.ai/" target="_blank" rel="noopener"><u>Hunters AI</u></a></p><p id="viewer-2vckh">	TLDR: Uses machine learning to detect cyberattacks that bypass existing security controls</p><p id="viewer-cuglb"><a href="https://www.crowdstrike.com/" target="_blank" rel="noopener"><u>Crowdstrike</u></a></p><p id="viewer-f7e3o">	TLDR: Utilizes machine learning to battle cybersecurity threats via endpoint detection of network threats</p><p id="viewer-130tg"><a href="https://www.bigpanda.io/" target="_blank" rel="noopener"><u>BigPanda</u></a></p><p id="viewer-ehne">	TLDR: Uses AI to improve infrastructure and devops at companies helping to improve monitoring tools and root cause analysis. </p><h3 id="viewer-e2r23"><strong>Education</strong></h3><p id="viewer-ek7qm">
<a href="https://www.cerego.com/" target="_blank" rel="noopener"><u>Cerego</u></a></p><p id="viewer-17p5t">	TLDR: An adaptive platform that uses machine learning to help improve the learning experience and techniques around remote education curricula</p><p id="viewer-df6hh">While 50 seems like a lot of companies, this only scratches the surface of all the groups out there tackling challenging problems with machine learning and data science and all the companies that will be formed in the future. If these companies deliver on their goals, artificial intelligence promises to be one of the biggest technological paradigm shifts in human history. The future looks bright!</p><p id="viewer-1q3n6">If you're interested in preparing for a job in machine learning or data science, get in touch! Confetti AI's mission is to help empower the next generation of artificial intelligence talent. </p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.confetti.ai/post/50-machine-learning-and-data-science-companies</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659486</guid>
            <pubDate>Sat, 27 Jun 2020 04:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much is your online privacy worth? – About $3.50 according to a new study]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659315">thread link</a>) | @Oeck
<br/>
June 26, 2020 | https://www.oeck.com/o/how-much-is-your-online-privacy-worth-about-3-50-according-to-a-new-study-we%E2%80%99re-worth-far-more-than-that.57/ | <a href="https://web.archive.org/web/*/https://www.oeck.com/o/how-much-is-your-online-privacy-worth-about-3-50-according-to-a-new-study-we%E2%80%99re-worth-far-more-than-that.57/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

						
						
						

						<div data-lb-id="post-57" data-lb-caption-desc="Peter · Jun 20, 2020 at 1:58 AM">

							
								

	

							

							<article>
								
								<div><div title="1592614747501.png" data-xf-init="lightbox" data-lb-single-image="1" data-lb-container-zoom="1" data-lb-trigger=".js-lbImage-attachment129" data-lb-id="attachment129">
		
			
		
		<p><img src="https://www.oeck.com/attachments/1592614747501-png.129/" data-url="" data-zoom-target="1" alt="1592614747501.png">
	</p></div><p>
In an age where your personal data is being shared with far more companies than you can imagine, the folks at <a href="https://techpolicyinstitute.org/wp-content/uploads/2020/02/Prince_Wallsten_How-Much-is-Privacy-Worth-Around-the-World-and-Across-Platforms.pdf" target="_blank" data-proxy-href="/proxy.php?link=https%3A%2F%2Ftechpolicyinstitute.org%2Fwp-content%2Fuploads%2F2020%2F02%2FPrince_Wallsten_How-Much-is-Privacy-Worth-Around-the-World-and-Across-Platforms.pdf&amp;hash=493602e26ad60bf36acbdc1d6d52c624" rel="nofollow noopener">Tech Policy Institute</a> decided to take a poll. The general public was asked how much money they believe they should be paid by data amalgamators in exchange for their browsing habits, location history, etc. The answers from U.S. respondents ranged from caring almost not at all to just see ads, to demanding $10 for data collectors to see total bank account balances.</p><p>

Across all of the activities covered, Americans would only demand about $3.50/month on average to have each individual piece of personal data shared. A figure far too low when digital advertising revenue eclipsed $100 billion in 2019.</p><p>

As it stands now, the public is being paid $0 for all of the personal information which they choose to share, and for the information which they may not even know is being collected. That information is being used to build data profiles on an individual level which are then repackaged as “targeted advertisements” through ad networks. It’s why you can be searching for something on Google on your desktop and 6 hours later you see multiple ads on Facebook for the same thing for which you were searching on a different machine earlier.</p><p>

VPNs can help cut down on much of the data we unwittingly share, though you’re still going to end up sharing some information if you log into the same accounts across multiple networks or devices.</p><p>

Big Data has, unfortunately, creeped into our lives and is further entrenching itself as time goes on. What’s scary is that Americans, for the most part, do not seem to be concerned about it. Until legislation is passed limiting what can and cannot be collected, there isn’t a lot that can be done about data amalgamation on the macro level. On an individual level, taking care to opt-out of sharing whenever possible, using a VPN and limiting the number of apps on your phone can protect you to some degree.</p></div>
								
								
							</article>

							
								

	

							

							
								
	

							
						</div>

						

						
	

					</div></div>]]>
            </description>
            <link>https://www.oeck.com/o/how-much-is-your-online-privacy-worth-about-3-50-according-to-a-new-study-we%E2%80%99re-worth-far-more-than-that.57/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659315</guid>
            <pubDate>Sat, 27 Jun 2020 03:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NeXTSTEP on the HP 712 Part 2: Getting Software]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 34 (<a href="https://news.ycombinator.com/item?id=23659277">thread link</a>) | @luu
<br/>
June 26, 2020 | https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/ | <a href="https://web.archive.org/web/*/https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
  
  <p><time datetime="2020-06-09T09:45:00-0400">Tue, Jun 9, 2020</time></p><p>In the <a href="https://blog.pizzabox.computer/posts/hp712-nextstep-part-1">last post of this series</a>, I set up NeXTstep on an HP PA-RISC <a href="https://blog.pizzabox.computer/pizzaboxes/hp712">workstation</a>. Today, I’m going to get down to business: configure networking, install system patches, outfit it with developer tools, and install some useful software!</p>
<p>As with the previous post, I’ve also made a YouTube video that covers roughly the same topics! If video is your speed, I’d love for you to check it out!</p>
<p>
  <iframe src="https://www.youtube.com/embed/_4hs4K7AEvQ" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<!-- raw HTML omitted -->
<p>My goal is to end up with a capable machine that I can use like it might have been when new, and learn from the experience.</p>
<h2 id="foreshadowing-networking-woes">Foreshadowing networking woes</h2>
<p>While it is possible to transfer files from SCSI drives (or even floppies!), <strong>getting a pizzabox on my home network makes loading software much easier</strong>.
I first tried out NeXTstep on this workstation a couple years ago. The OS installed OK, but I ran in to trouble with networking. I was initially optimistic that I would figure it out:</p>
<blockquote><p lang="en" dir="ltr">I think I'm done for the day but soon if I can fight with NFS and NetInfo (lolololol) I can get screenshots off it and software on</p>— cron mom (@sophaskins) <a href="https://twitter.com/sophaskins/status/962427825608429568?ref_src=twsrc%5Etfw">February 10, 2018</a></blockquote>


<blockquote>
<p><strong>NARRATOR</strong>: she did not soon win the fight with NFS and NetInfo</p>
</blockquote>
<p>Hang on a second: NeXTstep is a workstation-focused Unix operating system from the 80s-90s - <strong>how could it be difficult to get it on a network</strong>? The answer is a thing called NetInfo.</p>
<p>In a surprise to exactly no one, NeXTstep, being from a company founded by Steve Jobs, had it’s own NeXT-only ecosystem of tools that fit together amazingly well. <strong>The cornerstone of NeXTstep networking was NetInfo</strong>. If you had a collection of NeXT computers on a network, NetInfo gave you a system to:</p>
<ul>
<li>manage user accounts that would work across all machines</li>
<li>configure file sharing</li>
<li>control permissions around access to network resources</li>
<li>assign IP addresses and hostnames</li>
<li>quickly bring new machines in to the network</li>
<li>serve this information in a highly-available manner</li>
</ul>
<p>which is to say: NetInfo is a “directory services” system. That’s all well and good - in the early 1990s that space had many competitors and a “right path” hadn’t yet been established, but…<strong>I don’t <em>want</em> my machine to be part of a directory</strong>, **I just want it to be on my existing TCP/IP network.</p>
<h2 id="starting-a-simple-network">Starting a “simple” network</h2>
<p>With that in mind, I (naively) attempted to use the “SimpleNetworkStarter” application.</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-1.png" alt="SimpleNetworkStarter">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-1.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>SimpleNetworkStarter</p>
      </figcaption>
  </figure>
</div>

<p>The SimpleNetworkStarter window has three “steps”:</p>
<ol>
<li>Select <strong>how we’ll integrate</strong> with an existing NetInfo network (since I don’t intend to interact with one at all, I have to choose “Provide the services specified below”, a sort of catch-all)</li>
<li>Specify <strong>my hostname and IP address</strong> - if I were connecting to an existing NetInfo network, I might not have to do this. “Network Options” lets me set more granular IP settings like netmask and gateway; “NetInfo Options” lets me choose how to integrate with existing domains (if relevant).</li>
<li>Setup <strong>network services</strong>: for my setup I don’t really want <em>any</em> of these things, but as a standalone NeXTstep system, I do have to “Maintain the master copy of network administrative data” (aka, the NetInfo database).</li>
</ol>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-2.png" alt="Network Options">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-2.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>Network Options</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-3.png" alt="NetInfo Options">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-3.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>NetInfo Options</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-4.png" alt="Configuration Successful">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/simple-network-starter-4.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>Configuration Successful</p>
      </figcaption>
  </figure>
</div>


</div>

<p>So far, this feels like a really good start, but will it let me fetch files from an NFS share?</p>
<h2 id="networking-woes">Networking woes</h2>
<p>I immediately tried connecting to my NAS over NFS - after all, the main point of setting up networking was making it easier to transfer files. Unfortunately, it didn’t work - I could set up the NFS mount with NFSMananger (more on how to do that later), but the mountpoint would always be empty. Here you can see me attempting to reach it by IP address:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/failing-nfs-mount.png" alt="a failing NFS mount">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/failing-nfs-mount.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>a failing NFS mount</p>
      </figcaption>
  </figure>
</div>

<p>So I had <em>some</em> sort of problem. To narrow down potential issues, I ran a few tests:</p>
<ul>
<li><strong>attempting to ping my NAS</strong> from the workstation - this turned out to not work because NeXTstep doesn’t seem to have any <code>ping</code> command. There are probably ways to accomplish something equivalent with the tools it <em>does</em> have, but I just moved on</li>
<li><strong>attempting to ping the workstation</strong> from elsewhere on my network. This worked - I was able to ping it from my laptop!</li>
<li><strong>attempting to connect to my NAS with FTP</strong> - one of the few network tools NeXTstep <em>does</em> seem to have is FTP, so I gave it a shot. To my surprise, this works!</li>
</ul>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-ip.png" alt="connecting to my NAS via FTP (successfully)">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-ip.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>connecting to my NAS via FTP (successfully)</p>
      </figcaption>
  </figure>
</div>

<p>It did not work via hostname, though, which points to at least some trouble with DNS. Taking a deeper look at the “NeXTstep 3.3 Network and
System Administration Manual” section on “<a href="http://www.nextcomputers.org/NeXTfiles/Docs/NeXTStep/3.3/nsa/11_MixedNet.htmld/index.html">NEXTSTEP Computers in a Mixed Network</a>” (which I probably should have done earlier) shows that <strong>I need to manually configure DNS</strong>. There’s no GUI options for it, you just have to write out an <code>/etc/resolv.conf</code>:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/resolv-conf.png" alt="editing /etc/resolv.conf in vi">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/resolv-conf.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>editing /etc/resolv.conf in vi</p>
      </figcaption>
  </figure>
</div>

<p>After rebooting, I was able to access the NAS via FTP by hostname:


</p><div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-hostname.png" alt="connecting to my NAS via FTP (successfully) by hostname">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/ftp-by-hostname.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>connecting to my NAS via FTP (successfully) by hostname</p>
      </figcaption>
  </figure>
</div>

<p>But still couldn’t use NFS. What gives? I have network connectivity in both directions, and DNS is also now working! I believe this is as far as I got a few years ago, and man I was FRUSTRATED.</p>
<p>Eventually I thought to look in the system log (<code>/usr/adm/messages</code>) for hints:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/dmesg.png" alt="an error from autonfsmount">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/dmesg.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>an error from autonfsmount</p>
      </figcaption>
  </figure>
</div>

<p>and there it was:</p>
<pre><code>autonfsmount: Can't get my address
</code></pre><p>Can’t get…<em>my</em> address? Doesn’t the computer know its own address? While I don’t know <em>why</em> it has to do this (googling has provided me a couple of <a href="https://rute.gerdesas.com/node31.html">quick asides</a> mentioning it, but not much detail), <strong>mounting an NFS server requires working <em>reverse</em> DNS for your IP</strong>.</p>
<p>I do have a real-ish DNS server for my home network, and it populates based on DHCP leases and IP reservations. This workstation, though, was just <strong>using an IP that I habitually hardcode for pizzaboxes (192.168.1.200)</strong>. I double-checked the DHCP server config, and it was indeed set up with a different host for that IP, and not set up at all for this hostname. I replaced that entry with one for <code>hp712</code> at <code>192.168.1.200</code> for the MAC address of my workstation, and crossed my fingers.</p>
<p>It worked! I could browse my NAS from the file-browser.</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/browse-nas.png" alt="browsing my NAS">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/browse-nas.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>browsing my NAS</p>
      </figcaption>
  </figure>
</div>

<h2 id="setting-up-an-nfs-mount">Setting up an NFS mount</h2>
<p>After all that rigamarole, the right way to configure a remote NFS mount goes through the NFSManager.app. While NFSManager lets you configure both “exports” (local directories I share with others) and “imports” (remote directories I want to mount locally).</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/empty-imports.png" alt="an empty list of nfs imports">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/empty-imports.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>an empty list of nfs imports</p>
      </figcaption>
  </figure>
</div>

<p>All I have to is click “Add” and fill in the details for my NAS:</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/new-import.png" alt="adding a new nfs import">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/new-import.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>adding a new nfs import</p>
      </figcaption>
  </figure>
</div>

<p>That’s it? A lot of struggle got me to this point, but <em>finally</em> I can transfer files.</p>
<h2 id="patch-tuesday">Patch Tuesday</h2>
<p>The first order of business is to <strong>run system updates</strong>. NeXTstep 3.3 was released in mid-1995, and it had three patch updates: the <a href="https://www.nextop.de/NeXTAnswers/2066.html">first</a> at the end of 1995, and the second and <a href="http://www.nextcomputers.org/NeXTfiles/Software/NEXTSTEP/Patches/NEXTSTEP_3.3_User_Patch_3/nextstep3.3_patch_3_overview.pdf">third</a> in late 1999. Since NeXT were acquired by Apple in 1997, this patch was made by Apple to address Y2k bugs and other longstanding issues. Thanks, Apple! <a href="https://youtu.be/gaI6kBVyu00?t=28"><em>Thapple</em></a>.</p>
<p>The third patch is a cumulative update, so that should be all I need. Nextcomputers.org generously <a href="http://www.nextcomputers.org/NeXTfiles/Software/NEXTSTEP/Patches/NEXTSTEP_3.3_User_Patch_3/">hosts</a> the patch for download. Because I’m using an HP PA-RISC machine, I need <code>NS33RISCUserPatch3.tar</code>. System updates need to be installed as the <code>root</code> user, and if you run them as <code>me</code> (the default user) NeXTstep doesn’t prompt to escalate privilges, it just gives an error. Thus, I need to log in as <code>root</code> directly. In order to do that, I need to give the <code>me</code> user a password so the system will stop automatically logging in at boot (giving me a chance to log in as <code>root</code>). To set a password, you go to Preferences.app and navigate to the lock icon.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-before.png" alt="no password!">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-before.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>no password!</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-set.png" alt="password set">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-set.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>password set</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-secure.png" alt="password secure">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/password-secure.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>password secure</p>
      </figcaption>
  </figure>
</div>


</div>

<p>After the next reboot, I then get the login screen (instead of automatically going to the desktop):</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/login-screen.png" alt="nextstep 3.3 login screen">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/login-screen.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>nextstep 3.3 login screen</p>
      </figcaption>
  </figure>
</div>

<p>By default, the <code>root</code> password is blank (you can of course fix this after login in the same way as setting a password for the <code>me</code> account). I navigated to where I had put the patch tarball on my NAS, copied it to the HP 712, and unarchived it.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-copy.png" alt="copying from NAS">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-copy.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>copying from NAS</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-untar.png" alt="untarring">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-untar.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>untarring</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-pkg.png" alt="the patch package">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-pkg.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>the patch package</p>
      </figcaption>
  </figure>
</div>


</div>

<p>Double-clicking the package brings up a familiar-feeling Installer.app</p>


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-installer.png" alt="installer.app for OS update">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-installer.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installer.app for OS update</p>
      </figcaption>
  </figure>
</div>

<p>Clicking “Install” prompts me to make sure I’m choosing the right architecture (in my case, PA-RISC), runs a program to determine compatibility, and runs the update.</p>



<div itemscope="" itemtype="http://schema.org/ImageGallery">
	  


<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-arch.png" alt="choose system arch">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-arch.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>choose system arch</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-install.png" alt="installation in progress">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-install.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installation in progress</p>
      </figcaption>
  </figure>
</div>



<div>
  <figure itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject">
    <p><img itemprop="thumbnail" src="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-complete.png" alt="installation complete">
    </p>
    <a href="https://blog.pizzabox.computer/img/hp712/nextstep-part-2/os-update-complete.png" itemprop="contentUrl"></a>
      <figcaption>
          <p>installation complete</p>
      </figcaption>
  </figure>
</div>


</div>

<p>After a reboot, I’m on the most recent version of NeXTstep for PA-RISC, and ready for the year 2000!</p>

<p>What’s next for making a usable system? Developer tools! <strong>NeXTstep came on two sets of discs - “User” for the main operating system, and the optional “Developer” disc</strong> with compilers, GUI building tools, libraries, and documentation. While there were separate versions of NeXTstep User for CISC (m68k and i386) and RISC (PA-RISC and SPARC) platforms, the Developer disc is “quad-fat” - it contains binaries for all four platforms. I …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/">https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/</a></em></p>]]>
            </description>
            <link>https://blog.pizzabox.computer/posts/hp712-nextstep-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659277</guid>
            <pubDate>Sat, 27 Jun 2020 03:22:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Schmidhuber: Critique of 2018 Turing Award for Drs. Bengio and Hinton and LeCun]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23659246">thread link</a>) | @tdhttt
<br/>
June 26, 2020 | http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html | <a href="https://web.archive.org/web/*/http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="arial">
<center>
.
<div>
<a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html"><img src="http://people.idsia.ch/~juergen/critique-turing754x288.png" alt="Critique of 2018 Turing Award for Bengio &amp; Hinton &amp; LeCun"></a>

<center>



<span size="4">
</span></center><span size="4">

<a name="abstract">
<hr>
</a><p><a name="abstract">
<b>Abstract.</b> ACM's 2018 A.M. Turing Award was about
<em>deep learning</em> in artificial neural networks.
ACM lauds the awardees for work based on algorithms
and conceptual foundations first published by other researchers 
whom the awardees failed to cite
(see </a><a href="#exec">Executive Summary</a>
and Sec. 
<a href="#I">I</a>,
<a href="#V">V</a>, 
<a href="#II">II</a>,
<a href="#XII">XII</a>,
<a href="#XIX">XIX</a>, 
<a href="#XXI">XXI</a>,
<a href="#XIII">XIII</a>, 
<a href="#XIV">XIV</a>,  
<a href="#XX">XX</a>, 
<a href="#XVII">XVII</a>).
ACM explicitly mentions "astonishing" deep learning breakthroughs in 4 fields:
<a href="#A"> (A) speech recognition</a>, 
<a href="#B">(B) natural language processing</a>, 
<a href="#C">(C) robotics</a>, 
<a href="#D">(D) computer vision</a>,
as well as "powerful" new deep learning tools in 3 fields: 
<a href="#VII">(VII) medicine, astronomy, materials science</a>.
Most of these breakthroughs and tools, however, were directly based on 
the results of my own labs in the past 3 decades 
 (e.g., Sec.  
<a href="#A">A</a>,
<a href="#B">B</a>,
<a href="#C">C</a>,
<a href="#D">D</a>,
<a href="#VII">VII</a>,
<a href="#XVII">XVII</a>,
<a href="#VI">VI</a>,
<a href="#XVI">XVI</a>). 
I correct ACM's distortions of deep learning history (e.g., Sec. 
<a href="#II">II</a>,  
<a href="#V">V</a>, 
<a href="#XX">XX</a>,
<a href="#XVIII">XVIII</a>) 
and also 
mention 8 of our direct priority disputes 
with Bengio &amp; Hinton (Sec.  <a href="#XVII">XVII</a>, <a href="#I">I</a>).


</p><hr>

<p>
<em>This document (~11,000 words)
reuses and expands some of the material in my <a href="http://people.idsia.ch/~juergen/critique-honda-prize-hinton.html">Critique of the 2019 Honda Prize</a> <a href="#HIN">[HIN]</a> (~3,000 words). 
It has several layers of hierarchical abstraction: 
<b><a href="#abstract">Abstract</a></b> (150 words), <b><a href="#exec">Executive Summary with links to details</a></b> (~1,000 words), <b><a href="#I">Body with 21 comments on 21 claims by ACM</a></b> (~7,700 words) and <b><a href="#conclusion">Conclusion</a></b> (~1,700 words). 
All backed up by  <a href="#References">over 200 references</a> (~6,500 words).
</em>

</p><hr>


<p>We must stop crediting the wrong people for inventions made by others.
Instead let's heed the recent call in the journal <em>Nature</em>:
<b>"Let 2020 be the year in which we value those who ensure that 
science is self-correcting"</b> <a href="#SV20">[SV20]</a>.
Like those who know me can testify, finding and citing original sources of scientific and technological innovations is important to me, whether they are mine or other people's <a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#HIN">[HIN]</a> <a href="#NASC1">[NASC1-9]</a>. The present page is offered as a resource for computer scientists who share this inclination. 
By grounding research in its true intellectual foundations and crediting the original inventors, 
I am not diminishing important contributions made by popularizers of those inventions. 
My goal is to encourage the entire community to be more scholarly in its efforts, to recognize the foundational work that sometimes gets lost in the frenzy of modern AI and machine learning,
and to fight plagiarism in all of its more or less subtle forms. 
I am also inviting others to contribute additional relevant 
references (send them to <em>juergen@idsia.ch</em>). 



</p><p> I will focus on 
contributions praised by
ACM's official justification <a href="#T19">[T19]</a> of the 
2018 A.M. Turing Award for Drs. Bengio &amp; Hinton &amp; LeCun  <a href="#R1">[R1]</a> 
 published in 2019.
After the <a href="#exec">Executive Summary</a>,
ACM's full text <a href="#T19">[T19]</a> is split into 21 parts  
labeled by "<b>ACM:</b>" 
<a href="#I">I</a>, 
<a href="#II">II</a>, 
<a href="#III">III</a>, 
<a href="#IV">IV</a>,
<a href="#V">V</a>,
<a href="#VI">VI</a>,
<a href="#VII">VII</a>,
<a href="#VIII">VIII</a>,
<a href="#IX">IX</a>,
<a href="#X">X</a>,
<a href="#XI">XI</a>,
<a href="#XII">XII</a>,
<a href="#XIII">XIII</a>,
<a href="#XIV">XIV</a>,
<a href="#XV">XV</a>,
<a href="#XVI">XVI</a>,
<a href="#XVII">XVII</a>,
<a href="#XVIII">XVIII</a>,
<a href="#XIX">XIX</a>,
<a href="#XX">XX</a>,
<a href="#XXI">XXI</a>.
Each part is followed by a critical "<b>Comment</b>." 
Most of the comments are based on references to original papers and other material from
 recent 
blog posts <a href="#MIR">[MIR]</a> <a href="#DEC">[DEC]</a>  <a href="#HIN">[HIN]</a>.
<b>I'll point out 
that  highly cited publications of the awardees ignored fundamental 
relevant prior work—this may be the reason for some of  ACM's misattributions.</b>
Since ACM's text is a bit repetitive and redundant, so are the partially overlapping
sections of  my critique. 



</p><h2><a name="exec">
<hr>
Executive Summary (~1000 words, with links to details)
<hr>
</a></h2><a name="exec">

</a><p><a name="exec">
While Drs. LeCun &amp; Bengio &amp; Hinton (<b>LBH for short</b>)  
have made  useful improvements of algorithms for 
artificial neural networks (<b>NNs</b>) 
and deep learning (e.g., </a><a href="#I">Sec.  I</a>), ACM lauds
them for more visible 
work based on fundamental methods whose inventors they did not cite,
not even in later surveys
(this may actually explain some of  ACM's misattributions). I correct ACM's distortions of deep learning history.
Numerous <a href="#References">references</a> can be found under the relevant section links I-XXI 
which adhere to the sequential order of ACM's text <a href="#T19">[T19]</a>
(while this summary groups related sections together).


</p><p>
<b>Sec. <a href="#II">II</a>:</b> 
In contrast to ACM's claims, 
NNs for pattern recognition etc. were introduced long before the 1980s. 
 <b>Deep learning with multilayer perceptrons started in 1965</b> through Ivakhnenko &amp; Lapa
long before LBH who have never cited them, not even in recent work.
<b>In the 1980s,</b> "modern" gradient-based learning 
worked only for rather shallow NNs,
<b>but it became really deep in 1991 in my lab,</b>
first through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training of NNs</a>, 
then through 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">supervised LSTM</a>.
<b>Sec.  <a href="#I">I</a></b> contains 4 subsections 
<b><a href="#A">A</a>, <a href="#B">B</a>, <a href="#C">C</a>, <a href="#D">D</a></b>
on <b>the  4 deep learning "breakthroughs" explicitly 
mentioned by ACM</b>. ACM does not mention that they were 
mostly based on deep learning techniques of my team:

</p><p>
<b>Sec.
<a href="#A">A: Speech Recognition</a></b> (see also <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp; <a href="#XV">XV</a>): The first superior end-to-end neural speech recognition 
combines two methods from my lab: <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a> (1990s-2005) and CTC (2006), applied to speech in 2007. 
Hinton (2012) and Bengio (<a href="#XV">XV</a>)
still used an old hybrid approach of the 1980s and 90s;
Hinton et al. (2012) did not compare it to 
our revolutionary CTC-LSTM (<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">which was soon on most smartphones</a>).

</p><p>
<b>Sec. <a href="#B">B: Natural Language Processing</a></b> (see also  <a href="#VI">VI</a> &amp; <a href="#XI">XI</a> &amp;  <a href="#XVI">XVI</a>): 
The first superior end-to-end neural machine translation  
(<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">soon used for several billions of
translations each day by the big platform companies</a>)
was also based on our <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%204">LSTM</a>.

</p><p>
<b>Sec. <a href="#C">C: Robotics</a></b>.
Our LSTM trained by <b>Reinforcement Learning</b> (RL) was also the core of the 
most visible breakthroughs in robotics and video games.

</p><p>
<b>Sec. <a href="#D">D: Computer Vision</a></b>
(see also   
<a href="#XVIII">XVIII</a> &amp; <a href="#XIV">XIV</a>  &amp; <a href="#XI">XI</a>  &amp;  <a href="#VI">VI</a>)
was revolutionized by <b>convolutional NNs</b> (CNNs).
The basic CNN architecture is due to Fukushima (1979). 
NNs with convolutions were later (1987) combined by Waibel with backpropagation and weight sharing, 
and applied to speech. <b>All before</b> LeCun's CNN work  (<a href="#XVIII">XVIII</a>).
We showed twice (1991-95 and 2006-10) that 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">deep NNs 
don't need unsupervised 
pre-training</a> (in contrast to Hinton's claims). Our team (Ciresan et al.)  
made CNNs fast &amp; deep enough for  
<a href="http://people.idsia.ch/~juergen/computer-vision-contests-won-by-gpu-cnns.html">superior computer vision  in 2011</a>,
<b>winning 4 image recognition contests in a row
before Hinton's team won one</b>. ResNet (ImageNet 2015 winner)
is a special case of our earlier <a href="http://people.idsia.ch/~juergen/highway-networks.html">Highway Nets</a>.

</p><p>
<b>Sec.  <a href="#XIV">XIV:</a></b>
Again ACM recognizes work that failed to cite the pioneers.
Long before Hinton (2012), Hanson (1990) had a variant of <b>dropout</b>, 
and v. d. Malsburg (1973) had <b>rectified linear neurons</b>; Hinton did not cite them.
Already in 2011,
our deep &amp; fast CNN  more than <b>"halved the error rate for object recognition"</b> (ACM's wording) 
in a computer vision contest 
(<a href="http://people.idsia.ch/~juergen/superhumanpatternrecognition.html">where LeCun participated</a>), 
long before Hinton's similar CNN (2012). 
<b>Sec. <a href="#XI">XI</a>:</b>  ACM mentions GPU-accelerated NNs  
pioneered by Jung &amp; Oh (2004). LBH
did not cite them.
Our deep GPU-NN of 2010 debunked <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%2019">unsupervised pre-training (introduced by myself in 1991 and later championed by Hinton)</a>, 
and our GPU-CNN of 2011 was the first  
to win contests in <b>computer 
vision</b> (explicitly mentioned by ACM).
 

</p><p>
<b>Sec.  
<a href="#XVIII">XVIII</a></b>:
ACM credits LeCun for developing CNNs. However, the foundations of CNNs were laid earlier by 
Fukushima and Waibel  (Sec. <a href="#D">D</a>).
 ACM also explicitly mentions <b>autonomous driving</b> and <b>medical image analysis</b>.
The first team to win relevant international contests in these fields 
through deep CNNs was ours (2011, 2012, 2013).
<b>Sec.  
<a href="#VII">VII</a>:</b> ACM explicitly mentions  <b>medicine</b> and
 <b>materials science</b>. Our deep NNs were the 
<a href="http://people.idsia.ch/~juergen/first-time-deep-learning-won-medical-imaging-contest-september-2012.html">first to win medical imaging competitions</a>
 in 2012 and 2013, and the first to apply deep NNs to material defect detection in industry (since 2010).


</p><p>
<b>Sec. <a href="#XII">XII</a> &amp; <a href="#XIX">XIX</a> &amp; <a href="#XXI">XXI</a>:</b> Modern 
<a href="http://people.idsia.ch/~juergen/who-invented-backpropagation.html">backpropagation</a>
was first published by Linnainmaa (1970), 
not by LeCun or Hinton or their collaborators (1985) who did not cite Linnainmaa, 
not even in later surveys. 
<b>Sec. 
<a href="#XIII">XIII</a>  &amp; 
<a href="#II">II</a> &amp; 
<a href="#V">V</a> 
</b>
(&amp; 
<a href="#III">III</a> &amp; 
<a href="#IX">IX</a> &amp;
<a href="#X">X</a> &amp;
<a href="#XX">XX</a>):
Ivakhnenko's deep feedforward nets (since 1965) <b>learned 
internal representations</b> long before Hinton's shallower ones (1980s).
Hinton has never cited him.
<b>Sec. <a href="#XX">XX</a>:</b> ACM credits LeCun for work on
<b>hierarchical feature representation</b> which did not cite Ivakhnenko's much earlier work
on this (since 1965).
<b>Sec. <a href="#XXI">XXI</a>:</b> ACM credits LeCun for work on
<b>automatic differentiation</b> which did not cite its inventor Linnainmaa (1970). 
And also for work on
<b>deep learning for graphs</b> that failed to cite 
the earlier work  by Sperduti &amp; Goller &amp; Küchler &amp; Pollack.



</p><p>
<b>Sec. 
<a href="#XV">XV</a>:</b> ACM credits Bengio for hybrids of NNs and  probabilistic models of sequences. 
His work
was not the first on this topic, and is 
not important for <b>modern deep learning speech recognition systems</b> (mentioned by ACM) based on our CTC-LSTM
 (Sec.  
<a href="#A">A</a> &amp; 
<a href="#B">B</a>).
<b>Sec.
<a href="#XVI">XVI</a>:</b> ACM 
credits Bengio for neural probabilistic language models.
Our 1995 neural probabilistic text model greatly predates Bengio's.
ACM mentions NNs that learn
 sequential <b>attention</b>. <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">We started this in 1990-93 long before LBH</a> who did not cite this.




</p><p>
<b>Sec.  <a href="#XVII">XVII</a>:</b>
ACM mentions
<b>Generative Adversarial Networks</b> (GANs, 2010-14) of Bengio's team, a special case of
my  Adversarial  
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%205"><b>Artificial Curiosity</b></a>
(1990) which he did not cite. 
I list 7 of 
our <b>additional priority disputes</b> with Bengio &amp; Hinton (more than can be explained by chance),  
on 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%203">vanishing gradients</a> (1991),
<a href="http://people.idsia.ch/~juergen/metalearner.html">meta-learning</a> (1987),
 <a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%201">unsupervised pre-training</a> (1991),
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%202">compressing or distilling one NN into another</a> (1991), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%208">fast weights  
through outer products</a> (1993), 
<a href="http://people.idsia.ch/~juergen/deep-learning-miraculous-year-1990-1991.html#Sec.%209">learning sequential attention with NNs</a> (1990),
and other topics <a href="#R2">[R2-R6]</a>.








</p><p>
<b>Sec. <a href="#IV">IV</a></b> is on <a href="http://people.idsia.ch/~juergen/turing.html">Turing</a> (1936) and his predecessors
<a href="http://people.idsia.ch/~juergen/goedel.html">Gödel</a> (1931) and Church (1935).

</p><p>
<b>Sec. <a href="#conclusion">Conclusion:</a></b>
 In the recent <a href="http://people.idsia.ch/~juergen/2010s-our-decade-of-deep-learning.html">decade of deep learning</a>,
most major AI applications mentioned by ACM 
<a href="http://people.idsia.ch/~juergen/impact-on-most-valuable-companies.html">(speech recognition, language translation, etc.) on billions of devices</a>  (also healthcare applications)
heavily depended on our deep learning techniques and conceptual foundations,
while LBH's most visible work ignored
 essential prior art since the 1960s—see, e.g., 
Sec. <a href="#II">II</a> &amp;  
<a href="#III">III</a> &amp; 
<a href="#V">V</a> &amp;
<a href="#XII">XII</a> &amp; 
<a href="#XIII">XIII</a> &amp; 
<a href="#XVII">XVII</a> &amp; 
<a href="#XIV">XIV</a> &amp; 
<a href="#XIX">XIX</a> &amp; 
<a href="#XX">XX</a> &amp; 
<a href="#XXI">XXI</a>, 
<a href="#DL1">[DL1]</a> <a href="#DL2">[DL2]</a> <a href="#DLC">[DLC]</a> <a href="#MIR">[MIR]</a> <a href="#HIN">[HIN]</a> <a href="#R4">[R2-R8]</a>.
But in science, by definition, the facts will always win in …</p></span></div></center></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html">http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</a></em></p>]]>
            </description>
            <link>http://people.idsia.ch/~juergen/critique-turing-award-bengio-hinton-lecun.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659246</guid>
            <pubDate>Sat, 27 Jun 2020 03:17:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Examining ARM vs. x86 Memory Models with Rust]]>
            </title>
            <description>
<![CDATA[
Score 232 | Comments 65 (<a href="https://news.ycombinator.com/item?id=23659037">thread link</a>) | @redbluemonkey
<br/>
June 26, 2020 | https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/ | <a href="https://web.archive.org/web/*/https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p>With Apple’s recent announcement that they are moving away from Intel X86 CPU’s to their own ARM CPU’s for future laptops and desktops I thought it would be a good time to take a look at the some differences that can affect systems programmers working in Rust.</p>

<p>One of the key areas where ARM CPU’s differ from X86 is their memory model. This article will take a look at what a memory model is and how it can cause code to be correct on one CPU but cause race conditions on another.</p>

<h2 id="memory-models">Memory Models</h2>

<p>The way loads and stores to memory interact between multiple threads on a specific CPU is called that architecture’s Memory Model.</p>

<p>Depending on the memory model of the CPU, multiple writes by one thread may become visible to another thread in a different order to the one they were issued in.</p>

<p>The same is true of a thread issuing multiple reads. A thread issuing multiple reads may receive “snapshots” of global state that represent points in time ordered differently to the order of issue.</p>

<p>Modern hardware needs this flexibility to be able to maximize the throughput of memory operations. While CPU clock rates and core counts have been increasing with each new CPU iteration, memory bandwidth has struggled to keep up. Moving data from memory to operate on is often the bottle neck in the performance of applications.</p>

<p>If you’ve never written multi-threaded code, or only done so using higher level synchronization primitives such as <code>std::sync::Mutex</code>, you’ve probably never been exposed to the details of the memory model. This is because the CPU, despite whatever reordering it’s memory model allows it to perform, always presents a consistent view of memory to the current thread.</p>

<p>If we look at the below snippet of code that writes to memory and then reads the same memory straight back, we will always get the expected value of <code>58</code> back when we read. There is never the case that we’d read some stale value from memory.</p>

<div><div><pre><code><span>pub</span> <span>unsafe</span> <span>fn</span> <span>read_after_write</span><span>(</span><span>u32_ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>u32_ptr</span><span>.write_volatile</span><span>(</span><span>58</span><span>);</span>
    <span>let</span> <span>u32_value</span> <span>=</span> <span>u32_ptr</span><span>.read_volatile</span><span>();</span>
    <span>println!</span><span>(</span><span>"the value is {}"</span><span>,</span> <span>u32_value</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p><em>I’m using volatile operations because if I used normal pointer operations the compiler is smart enough to skip the memory read and just prints the value <code>58</code>. 
Volatile operations stop the compiler from reordering or skipping our memory operation. However they have no affect on hardware (or the compiler re-ordering relative to non-volatile memory operations).</em></p>

<p>Once we introduce multiple threads, we’re now exposed to the fact that the CPU may be reordering our memory operations.</p>

<p>We can examine the snippet below in a multi-threaded context:</p>

<div><div><pre><code><span>pub</span> <span>unsafe</span> <span>fn</span> <span>writer</span><span>(</span><span>u32_ptr_1</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>,</span> <span>u32_ptr_2</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>u32_ptr_1</span><span>.write_volatile</span><span>(</span><span>58</span><span>);</span>
    <span>u32_ptr_2</span><span>.write_volatile</span><span>(</span><span>42</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>reader</span><span>(</span><span>u32_ptr_1</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>,</span> <span>u32_ptr_2</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>-&gt;</span> <span>(</span><span>u32</span><span>,</span> <span>u32</span><span>)</span> <span>{</span>
    <span>(</span><span>u32_ptr_1</span><span>.read_volatile</span><span>(),</span> <span>u32_ptr_2</span><span>.read_volatile</span><span>())</span>
<span>}</span>
</code></pre></div></div>

<p>If we initialize the contents of both pointers to <code>0</code>, and then run each function in a different thread, we can list the possible outcomes for the reader. We know that there is no synchronization, but based on our experience with single threaded code we think the possible return values are <code>(0, 0)</code>, <code>(58, 0)</code> or <code>(58, 42)</code>. But the possibility of hardware reordering of memory writes affecting multi-threads means that there is a fourth option <code>(0, 42)</code>.</p>

<p>You might think there are more possibilities due to the lack of synchronization. But all hardware memory models guarantee that aligned loads and store up to the native word size are atomic (u32 or a 32-bit CPU, u64 on a 64-bit CPU). If we changed one of our writes to <code>0xFFFF_FFFF</code>, the read will only ever see the old value or the new value. It will never see a partial value like <code>0xFFFF_0000</code>.</p>

<p>If the details of the CPU’s memory model are hidden away when using regular memory accesses, it seems like we would have no way to control it in multi-threaded programs where it affects program correctness.</p>

<p>Luckily Rust provides as with the <code>std::sync::atomic</code> module containing types that gives us the control we need. We use these types to specify exactly the memory ordering requirements our code needs. We trade performance for correctness. We place restrictions on what order the hardware can perform memory operations, taking away any bandwidth optimizations the hardware would want to perform.</p>

<p>When working with the <code>atomic</code> module, we don’t worry about the actual memory models of individual CPU architectures. Instead the operation of the <code>atomic</code> module works on an abstract memory model that’s CPU agnostic. Once we’ve expressed our requirements on the loads and stores using this Rust memory model, the compiler does the job of mapping to the memory model of the target CPU.</p>

<p>The requirements we specify on each operation takes the form of what reordering we want to allow (or deny) on the operation. The orderings form a hierarchy, with each level placing more restrictions the CPU. For example <code>Ordering::Relaxed</code> means the CPU is free to perform any reordering it wants. <code>Ordering::Release</code> means that a store can only complete after all proceeding stores have finished.</p>

<p>Let’s look at how atomic memory writes are actually compiled, compared to a regular write.</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>sync</span><span>::</span><span>atomic</span><span>::</span><span>*</span><span>;</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_write</span><span>(</span><span>shared_ptr</span><span>:</span> <span>*</span><span>mut</span> <span>u32</span><span>)</span> <span>{</span>
    <span>*</span><span>shared_ptr</span> <span>=</span> <span>58</span><span>;</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_relaxed</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>Relaxed</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_release</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>Release</span><span>);</span>
<span>}</span>

<span>pub</span> <span>unsafe</span> <span>fn</span> <span>test_atomic_consistent</span><span>(</span><span>shared_ptr</span><span>:</span> <span>&amp;</span><span>AtomicU32</span><span>)</span> <span>{</span>
    <span>shared_ptr</span><span>.store</span><span>(</span><span>58</span><span>,</span> <span>Ordering</span><span>::</span><span>SeqCst</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If we look at the <a href="https://godbolt.org/z/uVQM8T">X86 assembly</a> for the above code, we see the first three functions produce identical code. It’s not until the stricter <code>SeqCst</code> ordering that we get a different instruction being produced.</p>

<div><div><pre><code><span>example:</span><span>:</span><span>test_write:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_relaxed:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_release:</span>
        <span>mov</span>     <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>58</span>
        <span>ret</span>
        
<span>example:</span><span>:</span><span>test_atomic_consistent:</span>
        <span>mov</span>     <span>eax</span><span>,</span> <span>58</span>
        <span>xchg</span>    <span>dword</span> <span>ptr</span> <span>[</span><span>rdi</span><span>],</span> <span>eax</span>
        <span>ret</span>
</code></pre></div></div>
<p>The first two orderings use the <strong><code>MOV</code></strong> (<strong>MOV</strong>e) instruction to write the value to memory. Only the strictest ordering produces a different instruction, <strong><code>XCHG</code></strong> (atomic e<strong>XCH</strong>an<strong>G</strong>), to a raw pointer write.</p>

<p>We can compare that to the <a href="https://godbolt.org/z/wWQo8P">ARM assembly</a>.</p>

<div><div><pre><code><span>example:</span><span>:</span><span>test_write:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>str</span>     <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_relaxed:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>str</span>     <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>

<span>example:</span><span>:</span><span>test_atomic_release:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>stlr</span>    <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>
        
<span>example:</span><span>:</span><span>test_atomic_consistent:</span>
        <span>mov</span>     <span>w8</span><span>,</span> <span>#</span><span>58</span>
        <span>stlr</span>    <span>w8</span><span>,</span> <span>[</span><span>x0</span><span>]</span>
        <span>ret</span>
</code></pre></div></div>

<p>In contrast we can see there is a difference once we hit the release ordering requirement. The raw pointer and relaxed atomic store use <strong><code>STR</code></strong> (<strong>ST</strong>ore <strong>R</strong>egister) while the release and sequential ordering uses the instruction <strong><code>STLR</code></strong> (<strong>ST</strong>ore with re<strong>L</strong>ease <strong>R</strong>egister). <em>The <strong><code>MOV</code></strong> instruction in this disassembly is moving the constant <code>58</code> into a register, it’s not a memory operation.</em></p>

<p>We should be able to see the risk here. The mapping between the theoretical Rust memory model and the X86 memory model is more forgiving to programmer error. It’s possible for us to write code that is wrong with respect to the abstract memory model, but still have it produce the correct assembly code and work correctly on some CPU’s.</p>

<h2 id="writing-a-multi-threaded-program-using-atomic-operations">Writing a Multi-Threaded Program using Atomic Operations</h2>

<p>The program we’ll be exploring builds upon the concept of storing a pointer value being atomic across threads. One thread is going to perform some work using a mutable object it owns. Once it’s finished that work it’s going to publish that work as an immutable shared reference, using an atomic pointer write to both signal the work is complete and allow reading threads to use the data.</p>

<h2 id="the-x86-only-implementation">The X86 Only Implementation</h2>

<p>If we really want to test how forgiving the X86’s memory model is, we can write multi-threaded code that skips any use of the <code>std::sync::atomic</code> module. I want to stress this is not something you should ever actually consider doing. In fact this code has undefined behavior due to not guarding against possible compiler instruction re-ordering (however in Rust 1.44.1 the compiler doesn’t re-order so the code “works”). This is an learning exercise only.</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>SynchronisedSum</span> <span>{</span>
    <span>shared</span><span>:</span> <span>UnsafeCell</span><span>&lt;*</span><span>const</span> <span>u32</span><span>&gt;</span><span>,</span>
    <span>samples</span><span>:</span> <span>usize</span><span>,</span>
<span>}</span>

<span>impl</span> <span>SynchronisedSum</span> <span>{</span>
    <span>pub</span> <span>fn</span> <span>new</span><span>(</span><span>samples</span><span>:</span> <span>usize</span><span>)</span> <span>-&gt;</span> <span>Self</span> <span>{</span>
        <span>assert</span><span>!</span><span>(</span><span>samples</span> <span>&lt;</span> <span>(</span><span>u32</span><span>::</span><span>MAX</span> <span>as</span> <span>usize</span><span>));</span>
        <span>Self</span> <span>{</span>
            <span>shared</span><span>:</span> <span>UnsafeCell</span><span>::</span><span>new</span><span>(</span><span>std</span><span>::</span><span>ptr</span><span>::</span><span>null</span><span>()),</span>
            <span>samples</span><span>,</span>
        <span>}</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>generate</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{</span>
        <span>// do work on data this thread owns</span>
        <span>let</span> <span>data</span><span>:</span> <span>Box</span><span>&lt;</span><span>[</span><span>u32</span><span>]</span><span>&gt;</span> <span>=</span> <span>(</span><span>0</span><span>..</span><span>self</span><span>.samples</span> <span>as</span> <span>u32</span><span>)</span><span>.collect</span><span>();</span>

        <span>// publish to other threads</span>
        <span>let</span> <span>shared_ptr</span> <span>=</span> <span>self</span><span>.shared</span><span>.get</span><span>();</span>
        <span>unsafe</span> <span>{</span>
            <span>shared_ptr</span><span>.write_volatile</span><span>(</span><span>data</span><span>.as_ptr</span><span>());</span>
        <span>}</span>
        <span>std</span><span>::</span><span>mem</span><span>::</span><span>forget</span><span>(</span><span>data</span><span>);</span>
    <span>}</span>

    <span>pub</span> <span>fn</span> <span>calculate</span><span>(</span><span>&amp;</span><span>self</span><span>,</span> <span>expected_sum</span><span>:</span> <span>u32</span><span>)</span> <span>{</span>
        <span>loop</span> <span>{</span>            
            <span>// check if the work has been published yet</span>
            <span>let</span> <span>shared_ptr</span> <span>=</span> <span>self</span><span>.shared</span><span>.get</span><span>();</span>
            <span>let</span> <span>data_ptr</span> <span>=</span> <span>unsafe</span> <span>{</span> <span>shared_ptr</span><span>.read_volatile</span><span>()</span> <span>};</span>
            <span>if</span> <span>!</span><span>data_ptr</span><span>.is_null</span><span>()</span> <span>{</span>
                <span>// the data is now accessible by multiple threads, treat it as an immutable reference.</span>
                <span>let</span> <span>data</span> <span>=</span> <span>unsafe</span> <span>{</span> <span>std</span><span>::</span><span>slice</span><span>::</span><span>from_raw_parts</span><span>(</span><span>data_ptr</span><span>,</span> <span>self</span><span>.samples</span><span>)</span> <span>};</span>
                <span>let</span> <span>mut</span> <span>sum</span> <span>=</span> <span>0</span><span>;</span>
                <span>for</span> <span>i</span> <span>in</span> <span>(</span><span>0</span><span>..</span><span>self</span><span>.samples</span><span>)</span><span>.rev</span><span>()</span> <span>{</span>
                    <span>sum</span> <span>+=</span> <span>data</span><span>[</span><span>i</span><span>];</span>
                <span>}</span>

                <span>// did we access the data we expected?</span>
                <span>assert_eq!</span><span>(</span><span>sum</span><span>,</span> <span>expected_sum</span><span>);</span>
                <span>break</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The function that calculates the sum of the array starts by executing a loop that reads the …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/">https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/</a></em></p>]]>
            </description>
            <link>https://www.nickwilcox.com/blog/arm_vs_x86_memory_model/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23659037</guid>
            <pubDate>Sat, 27 Jun 2020 02:26:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coherent Unix Goes Open-Source (2015)]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23658893">thread link</a>) | @desiderantes
<br/>
June 26, 2020 | http://www.nesssoftware.com/home/mwc/source.php | <a href="https://web.archive.org/web/*/http://www.nesssoftware.com/home/mwc/source.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
			
			
			<div id="main">
				<h2>Mark Williams Company Sources</h2>
				<p><img src="http://opensource.org/files/osi_logo_100X133_90ppi.png" height="133" width="100" alt="OSI logo">
				</p>
				<p>
					This page contains links to Mark Williams Company (MWC)
					source code and documentation.
					This material was originally © Mark Williams Company.
					It is posted here as open source software
					by the current copyright holder Robert Swartz under a license
					complying with the <a href="http://opensource.org/">Open Source Initiative</a>.
					This site is not affiliated with
					or endorsed by the Open Source Initiative.
				</p>
				<p>
					Mark Williams Company closed in 1995.
					In 2001, Bob Swartz asked me to archive the
					hard drives containing the Mark Williams source repository;
					the command and system sources here are from that repository.
					I have long intended to catalog and organize these sources,
					but in the meantime they are posted here as is.
					MWC's documentation guru Fred Butzen
					provided the MWC documentation sources.
					The <b>.gtz</b> files in these archives
					are just compressed <b>tar</b> files,
					now commonly called <b>.tgz</b>.
				</p>
				<p><a href="http://www.nesssoftware.com/home/mwc/manpage.php?page=caveat_ut"><i>Caveat utilitor</i></a>, as Fred would say.</p>
				<h3>License</h3>
				<p>
					Copyright © 1977-1995 by Robert Swartz.<br>
					All rights reserved.
				</p>
				<p>Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</p>
				<p>1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.</p>
				<p>2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.</p>
				<p>3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.</p>
				<p>This software is provided by the copyright holders and contributors "as is" and any express or implied warranties, including, but not limited to, the implied warranties of merchantability and fitness for a particular purpose are disclaimed. In no event shall the copyright holder or contributors be liable for any direct, indirect, incidental, special, exemplary, or consequential damages (including, but not limited to, procurement of substitute goods or services; loss of use, data, or profits; or business interruption) however caused and on any theory of liability, whether in contract, strict liability, or tort (including negligence or otherwise) arising in any way out of the use of this software, even if advised of the possibility of such damage.</p>
				<br>
				
				
				<p>
					This page is dedicated to my incredibly talented colleagues at Mark Williams Company.
					They're listed in the <a href="http://www.nesssoftware.com/home/mwc/doc/coherent/manual/pdf/preface.pdf">Preface</a> to the <a href="http://www.nesssoftware.com/home/mwc/manual.php"><i>COHERENT</i> manual</a>.
				</p>
				<hr>
			</div>
			
			
		</div></div>]]>
            </description>
            <link>http://www.nesssoftware.com/home/mwc/source.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-23658893</guid>
            <pubDate>Sat, 27 Jun 2020 01:55:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scraping Websites: Python and Beautiful Soup and Ingesting into Elasticsearch]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23658382">thread link</a>) | @rbekker87
<br/>
June 26, 2020 | http://sysadmins.co.za/scraping-websites-with-python-and-beautiful-soup-and-ingesting-into-elasticsearch/ | <a href="https://web.archive.org/web/*/http://sysadmins.co.za/scraping-websites-with-python-and-beautiful-soup-and-ingesting-into-elasticsearch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		<!-- .post-header -->


		<div>
			<p><img src="http://obj-cache.cloud.ruanbekker.com/python-elasticsearch.png" alt=""></p>
<p>This will be a 2 post guide, where we will scrape this website on <code>Page Title</code>, <code>URL</code> and <code>Tags</code>, for blog posts, then we will ingest this data into Elasticsearch. - <a href="">This Post</a></p>
<p>Once we have our data in Elasticsearch, we will build a Search Engine to search for these posts, the frontend will consist of Python Flask, Elasticsearch Library and HTML, which will be coverend in <a href="https://sysadmins.co.za/building-a-search-engine-for-our-scraped-data-on-elasticsearch-part-2/">Part 2</a></p>
<p><strong>Notice:</strong></p>
<p>Always ensure that you are scraping for the right reasons, in this example, I will use my own blog site as the target, and I won't be scraping the websites data, but only Page Title, URL and Tags, so that we have enough data for our search engine.</p>
<p><strong>Requirements:</strong></p>
<p>For this example I am using Ubuntu 16.04, and we will need some dependencies to install for our Python Script:</p>
<pre><code>$ apt udpate &amp;&amp; apt upgrade -y
$ apt install python python-dev python-setuptools python-lxml openssl libssl-dev python-pip
$ pip install requests
$ pip install bs4
$ pip install elasticsearch
</code></pre>
<p><strong>Python Scraper:</strong></p>
<p>Here is our Python Scraper that will scrape the data from a <code>sitemap.xml</code> and ingest the data into Elasticsearch:</p>
<pre><code>import re
import time
import requests
from bs4 import BeautifulSoup
from elasticsearch import Elasticsearch

es_client = Elasticsearch(['http://10.0.1.10:9200'])

drop_index = es_client.indices.create(index='blog-sysadmins', ignore=400)
create_index = es_client.indices.delete(index='blog-sysadmins', ignore=[400, 404])

def urlparser(title, url):
    # scrape title
    p = {}
    post = title
    page = requests.get(post).content
    soup = BeautifulSoup(page, 'lxml')
    title_name = soup.title.string

    # scrape tags
    tag_names = []
    desc = soup.findAll(attrs={"property":"article:tag"})
    for x in xrange(len(desc)):
        tag_names.append(desc[x-1]['content'].encode('utf-8'))

    # payload for elasticsearch
    doc = {
        'date': time.strftime("%Y-%m-%d"),
        'title': title_name,
        'tags': tag_names,
        'url': url
    }

    # ingest payload into elasticsearch
    res = es_client.index(index="blog-sysadmins", doc_type="docs", body=doc)
    time.sleep(0.5)

sitemap_feed = 'https://sysadmins.co.za/sitemap-posts.xml'
page = requests.get(sitemap_feed)
sitemap_index = BeautifulSoup(page.content, 'html.parser')
urls = [element.text for element in sitemap_index.findAll('loc')]

for x in urls:
    urlparser(x, x)
</code></pre>
<p>This scraper will grab all the posts from the <code>sitemap.xml</code> then loop through each post, with the given logic, ingest the data into elasticsearch.</p>
<p><strong>Running the Python Scraper:</strong></p>
<pre><code>$ python scraper.py
</code></pre>
<p><strong>Verify Documents in Elasticsearch:</strong></p>
<p>After you have executed the python script, have a look at elasticsearch to confirm if the documents were ingested into Elasticsearch:</p>
<pre><code>$ curl http://10.0.1.10:9200/_cat/indices/scrape-sysadmins?v
health status index            uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   blogs-sysadmins gyHONBcwTmaVjZVRj6dYew   5   1         80            0    289.6kb        144.8kb
</code></pre>
<p>As you can see we have ingested 80 documents, having a look at one of our documents:</p>
<pre><code>$ curl http://10.0.1.10:9200/blogs-sysadmins/_search?pretty -d '{"size": 1}'
{
  "took" : 5,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 80,
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "blogs-sysadmins",
        "_type" : "docs",
        "_id" : "AV6j3bZEzCREvIW7N4yt",
        "_score" : 1.0,
        "_source" : {
          "date" : "2017-09-21",
          "url" : "https://sysadmins.co.za/bash-script-setup-a-3-node-hadoop-cluster-on-lxc-containers/",
          "tags" : [
            "LXC",
            "Hadoop",
            "Scripting",
            "LXD"
          ],
          "title" : "Bash Script setup a 3 Node Hadoop Cluster on LXC Containers"
        }
      }
    ]
  }
}
</code></pre>
<p><strong>Next Steps:</strong></p>
<p>In my <a href="https://sysadmins.co.za/building-a-search-engine-for-our-scraped-data-on-elasticsearch-part-2/">next post</a>, I will guide you through the steps on setting up a Search User Interface that will be our search engine to search from blog posts that is stored in Elasticsearch.</p>

		</div><!-- .post-content -->

		<!-- .post-footer -->

		<!-- .comments-area -->



	</article></div>]]>
            </description>
            <link>http://sysadmins.co.za/scraping-websites-with-python-and-beautiful-soup-and-ingesting-into-elasticsearch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23658382</guid>
            <pubDate>Sat, 27 Jun 2020 00:06:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Efficient and Safe Implementations of Dynamic Languages]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23658251">thread link</a>) | @matt_d
<br/>
June 26, 2020 | https://stefan-marr.de/2020/06/efficient-and-safe-implementations-of-dynamic-languages/ | <a href="https://web.archive.org/web/*/https://stefan-marr.de/2020/06/efficient-and-safe-implementations-of-dynamic-languages/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Last September, I had a lot of fun putting together a lecture on
language implementation techniques. It is something I wanted to do for a while,
but I had not had a good excuse before to actually do it.</p>

<p>When I got asked to give this lecture at a Dagstuhl summer school,
I posted an outline on Twitter, and as one might expect, some people raised
concerns about things that are missing. And, indeed, it’s far from complete,
and biased by my own experience, background, and research.
Though, perhaps it is still useful for others.</p>

<h3 id="abstract">Abstract</h3>

<blockquote>
<p>Dynamic languages leave all hard problems to the runtime system. Some argue
this allows programmers to focus on the application they implement, but it also
means that dynamic language implementations have to learn at run time what a
program does so that they can execute it efficiently.</p>

<p>This lecture will give a brief introduction into implementation techniques,
starting from abstract-syntax-tree and bytecode interpreters, and then going to
modern just-in-time compilation approaches based on partial evaluation or
meta-tracing. We will review ideas such as inline caching, hidden classes,
and storage strategies to understand better how dynamic languages can reach the
performance of less dynamic languages such as Java or C.</p>

<p>Optimizations such as storage strategies unfortunately have a major impact on
thread safety for dynamic languages such as Ruby and Python, which use shared
memory multi-threading. To ensure that we can implement such languages with
safe and efficient parallelism, we will also review variations for classic
storage strategies and object models for parallel virtual machines.</p>

<p>Last but not least, since the techniques are all about performance, we have to
discuss how to effectively assess optimizations. Modern virtual machines and
hardware systems are far from the deterministic machines we expect, which means
we have to take extra care when measuring and reporting performance numbers.</p>
</blockquote>

<p>The final agenda for the lecture included:</p>

<ul>
  <li>interpretation
    <ul>
      <li>abstract syntax trees</li>
      <li>bytecodes</li>
    </ul>
  </li>
  <li>optimizations at the interpreter level
    <ul>
      <li>caching, and lookup caching in particular</li>
      <li>bytecode quickening</li>
      <li>self-optimizing AST interpreters</li>
    </ul>
  </li>
  <li>just-in-time compilation
    <ul>
      <li>basic ideas of compilation at run time</li>
      <li>metacompilation techniques based on meta-tracing and partial evaluation</li>
    </ul>
  </li>
  <li>efficient data representation
    <ul>
      <li>maps, hidden classes, shapes</li>
      <li>storage strategies</li>
    </ul>
  </li>
  <li>data representations for multithreaded VMs
    <ul>
      <li>concurrent shapes</li>
      <li>concurrent strategies</li>
    </ul>
  </li>
  <li>benchmarking
    <ul>
      <li>pitfalls</li>
      <li>recommendations</li>
    </ul>
  </li>
</ul>

<p>This means there are indeed very many things, I haven’t been talking about.
This includes fundamental ideas such as garbage collection, compiler optimizations
and their intermediate representations, tiered compilation,
tooling for debugging &amp; profiling, and metacircularity.
Perhaps, I get to teach a full course at some point, and can include them.</p>

<p>Until then, the following slides might be useful to others.</p>



<p>If you have any questions, I am more than happy to answer, possibly on Twitter <a href="https://twitter.com/smarr/status/1276486069706506247">@smarr</a>.</p>

</div></div>]]>
            </description>
            <link>https://stefan-marr.de/2020/06/efficient-and-safe-implementations-of-dynamic-languages/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23658251</guid>
            <pubDate>Fri, 26 Jun 2020 23:45:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Xbox Architecture]]>
            </title>
            <description>
<![CDATA[
Score 217 | Comments 71 (<a href="https://news.ycombinator.com/item?id=23657231">thread link</a>) | @timeoperator
<br/>
June 26, 2020 | https://www.copetti.org/projects/consoles/xbox/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/xbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>It seems that Microsoft has decided to pick up where Sega left off. Their offer? A system with familiarities appreciated by developers and online services welcomed by users.</p><p>Please note that, due to consistency with other sources, this article separates storage units between the metric prefix (i.e. megabytes or ‘MB’) and the standardised binary prefix (i.e. mebibytes or ‘MiB’), thus:</p><ul><li>1 MB = 1000 KB</li><li>1 MiB = 1024 KiB</li></ul><p>… and so forth.</p><hr><h2 id="cpu">CPU</h2><p>The processor included in this console is a slightly customised version of the famous <strong>Intel Pentium III</strong> (an off-the-shelf CPU for computers) running at <strong>733 MHz</strong>. With this, one can assume this console is just a PC behind the scenes… I won’t tell you the answer, but I promise that at the end of the article you will be able to reach your own conclusion.</p><p>Anyhow, Pentiums, along with other lines of CPUs designed and manufactured by Intel, were incredibly popular in the computer market. Such was Intel’s market share that they became the de-facto reference point for quality: As a typical user, if you wanted a good computer and had the budget, you only had to look for <em>something</em> carrying an Intel CPU. We all know by now that there are more factors involved, but that’s what the marketing guys at Intel managed to project.</p><h4 id="technical-information">Technical information</h4><p>Now that we positioned Intel in the map, let’s go back to the topic of this console. During my research, I was expecting to find documentation with the level of depth as other CPUs (MIPS, SuperH, ARM, etc), but instead, I stumbled across an excessive amount of marketing terms that only diverted my search. So, for this article, I came up with a structure to organise all the necessary information which will help to understand how this CPU works. Furthermore, I will try to introduce some terminology that Intel used to brand this CPU.</p><p>Having said that, let us take a look:</p><div><ul><li id="tab-1-1-branding-link"><a href="#tab-1-1-branding">Branding</a></li><li id="tab-1-2-the-isa-link"><a href="#tab-1-2-the-isa">The ISA</a></li><li id="tab-1-3-the-microarchitecture-link"><a href="#tab-1-3-the-microarchitecture">The Microarchitecture</a></li><li id="tab-1-4-cisc-or-risc-link"><a href="#tab-1-4-cisc-or-risc">CISC or RISC</a></li><li id="tab-1-5-the-core-link"><a href="#tab-1-5-the-core">The Core</a></li></ul><div><div id="tab-1-1-branding"><h4>Branding</h4><div><a href="https://www.copetti.org/images/consoles/xbox/cpu/branding.113be6f183d200764d7cfc590548c60fe637af1411fccff6cb274c99c9a5fa28.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/xbox/cpu/branding.113be6f183d200764d7cfc590548c60fe637af1411fccff6cb274c99c9a5fa28.png" data-src="https://www.copetti.org/images/consoles/xbox/cpu/branding.113be6f183d200764d7cfc590548c60fe637af1411fccff6cb274c99c9a5fa28.png"></picture></a><figcaption>How is this study organised</figcaption></div><p>First things first, the Xbox’s CPU is identified as a <strong>Pentium III</strong>. So what does this mean? Back then (early 00s), the Pentium series represented the next-generation of CPUs. They were ‘new high-end’ that grouped all the fancy technology that made computers super-fast, plus it helped buyers decide which CPU they had to buy if they wanted <em>the best of the best</em>.</p><p>The Pentium III replaced Pentium II, which in turn replaced the original Pentium. Moreover, when the first Pentium came out, it replaced the 80486, which in turn replaced the 80386… You get the idea. What matters is that ‘Pentium’ is mainly a brand name, it’s not directly associated with its inner workings. Therefore, we must go deeper!</p><p>To dive further and not get lost in the way, I have catalogued the information into three sections which combined, make up the chip. The first the <strong>Instruction Set Architecture</strong> or ‘ISA’ (the group of instructions used to command the CPU), <strong>Microarchitecture</strong> (how is the ISA implemented in silicon) and the <strong>Core</strong> (what set of components are used to package the microarchitecture to form the specific CPU model).</p></div><div id="tab-1-2-the-isa"><h4>The ISA</h4><p>Indeed, after I mentioned the name Intel it was a matter of time before I introduce the famous <strong>x86</strong>, its instruction set.</p><p>Even though x86 first appeared with the release of the 16-bit CPU called <strong>Intel 8086</strong> in 1978, the ISA has been constantly expanded with more instructions as more Intel CPUs were released (80186, 80286 and so on). Consequently, x86 started to fragment as more ground-breaking features were added (i.e. ‘real mode’, vs ‘protected mode’ vs ‘long mode’). To tackle this, modern x86 applications commonly targeted the 80386 ISA (also referred as <strong>IA-32</strong> or <strong>i386</strong>) as a baseline, which among other things, operates in a 32-bit environment.</p><p>Subsequently, Intel presented enhancements of IA-32 in the form of <strong>extensions</strong>, meaning these may or may not be included in an IA-32 CPU. Programs can query the CPU to check if a specific enhancement is present. The Xbox’s CPU includes two extensions:</p><ul><li><strong>MMX</strong> (Multimedia Extension): Adds 57 SIMD instructions and 8 64-bit registers (integers only) that can speed up vector operations.</li><li><strong>SSE</strong> (Streaming SIMD extension): Another SIMD-type extension which addresses some of the limitations of MMX (lack of floating-point support and unable to use floating-point unit in parallel). It adds 8 128-bit registers (called ‘XMM’) that hold four 32-bit floats; and 56 new instructions.</li></ul><p>Good news is that since the console will always have the same CPU features, programmers can optimise their code to exploit these extensions as they will always be present.</p></div><div id="tab-1-3-the-microarchitecture"><h4>The Microarchitecture</h4><p>When it comes to building a circuit that can interpret x86 instructions, Intel has come up with so many different designs for their CPUs. Some designs were featured with the release of a new Pentium Series (i.e. Pentium 4) while others are featured when Intel releases an ‘enhanced’ version of a Pentium (such as the ‘Pentium Pro’). Nevertheless, since the release of the first Pentium, the microarchitecture is identified with a different name from the CPU model. For example, the original Pentium includes the ‘P5’ microarchitecture.</p><p>Now, the Xbox CPU, along with the rest of Pentium III processors, use the <strong>P6 Microarchitecture</strong> (also known as ‘i686’). This is the 6th generation (counting from the 8086) which features:</p><ul><li>A <em>massive</em> <strong>14-stage pipeline</strong>.</li><li><strong>Out-of-order execution</strong>: If possible, the CPU re-orders the sequence of instructions to increase efficiency and performance.</li><li><strong>Speculative prediction</strong>: Similar to <a href="https://www.copetti.org/projects/consoles/gamecube/#features">branch prediction</a>, but it also executes the branch that the CPU has predicted it will be chosen.</li></ul><p>Having said that, take a closer look at these features. It so happens they are very similar to <a href="https://www.copetti.org/projects/consoles/gamecube/#features">previous consoles</a>, however, the other CPUs are very different in terms of design compared to Intel ones. Historically, one could argue that Intel could have never been able to accomplish, let’s say, a pipelined CPU. Yet they managed to do so, so let us see why…</p></div><div id="tab-1-4-cisc-or-risc"><h4>CISC or RISC</h4><p>All of the competitor’s consoles previously analysed contain a <strong>RISC</strong> CPU whereas Intel’s x86 ones are <strong>CISC</strong>. RISC CPUs are known for having a simplified instruction set compared to CISC CPUs. This includes, for instance, not featuring instructions that operate values directly from memory (as opposed to registers).</p><p>One of the advantages of RISC processors is that their simplistic approach enables its CPUs to be designed with a modular sense, which in turn can be exploited to improve performance with parallelism techniques. This is why we have seen CPUs like MIPS and PowerPC debuting pipelining, superscalar, out-of-order, branch prediction, etc. On the other side, ‘CISC’ processors were design many years before the RISC processors appeared and aimed to solve different needs. Consequently, their designs are not as flexible as RISC ones.</p><p>Back to the original question, the P6 is an interesting design, because while the CPU only understands a CISC instruction set (x86), it interprets the ISA using <strong>microcode</strong> (called ‘micro-operations’) and the unit that executes that code is built around the guidelines of RISC. All in all, this allows Intel to apply the optimisations of RISC processors while keeping a ‘CISC layer’ for compatibility with x86.</p><p>Microcode is already embedded in the silicon but it can be patched, allowing Intel to fix its CPUs after production whenever a bug or a security vulnerability is discovered. If you have read previous articles (i.e. N64 or PS2), bear in mind that Intel’s microcode is <strong>not publicly accessible</strong> (let alone documented) and Intel is its solely ‘maintainer’.</p></div><div id="tab-1-5-the-core"><h4>The Core</h4><div><a href="https://www.copetti.org/images/consoles/xbox/cpu/core.63696b1d55e579495cbbb6e42a5ee66fe0ce7fee34e107f74c750a34546c309a.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/xbox/cpu/core.63696b1d55e579495cbbb6e42a5ee66fe0ce7fee34e107f74c750a34546c309a.png" data-src="https://www.copetti.org/images/consoles/xbox/cpu/core.63696b1d55e579495cbbb6e42a5ee66fe0ce7fee34e107f74c750a34546c309a.png"></picture></a><figcaption>Coppermine design</figcaption></div><p>There were numerous chips released using the P6 microarchitecture. Specifically, the Xbox includes one model called <strong>Coppermine</strong>. This was also released as the second revision of the Pentium III (replacing the ‘Katmai’ core) and includes the following components:</p><ul><li><strong>32 KiB L1</strong> cache: Divided between 16 KiB for instructions and 16 KiB for data.</li><li>Integrated <strong>128 KiB L2</strong> cache: This is <em>odd</em> since the off-the-shelf Coppermine has 256 KiB of L2. In fact, the Coppermine128 (found in the Intel ‘Celeron’ brand, the low-end Pentium alternative) has the same amount of L2. This is probably done to reduce manufacturing costs, and keep this console at a competitive price.</li><li>133 MHz <strong>Front-side bus</strong>: This is the bus that connects the L2 cache with the memory controller, we’ll see more about it later on.<ul><li>Intel names it ‘Front-side bus’ to distinguish it from another bus which connects the L2 (external cache) with the L1 (internal cache). The latter bus is called ‘Back-side bus’ and yes… It’s an unfortunate name to use from the UK.</li></ul></li></ul><p>Coppermine also features two ‘enhancements’ over their original implementation of L2 cache, these are the <strong>Advanced Transfer Cache</strong> and the <strong>Advanced System Buffering</strong>. To sum them up, L2 cache is on-chip and their buses are wider, which help to reduce possible bottlenecks found in the Front-side bus.</p><p>Finally, the chip uses the ‘Micro-PGA2’ socket to connect it to the motherboard, but like any other console, the Xbox has it soldered with a Ball Grid Array or ‘BGA’.</p></div></div></div><h4 id="p6-and-the-end-of-pentium-numbers">P6 and the end of Pentium numbers</h4><p>Here’s a bit more history: After the years of the P6, Intel planned to succeed it with the ‘Netburst’ microarchitecture (featured in the Pentium IV). However, the line of succession also ended there: The microarchitecture couldn’t be improved anymore. This prompted an Intel team in Israel to revisit the old P6 and develop a more efficient successor. The result was <strong>Pentium M</strong>, eventually extended to form the <strong>Core</strong> microarchitecture (and brand). ‘Core’ is the basis of present designs.</p><h4 id="motherboard-architecture">Motherboard architecture</h4><p>At some point in the history of the PC, motherboards grew so much in complexity that new designs had to be developed from the ground up to efficiently tackle new emerging needs.</p><div><div><a href="https://www.copetti.org/images/consoles/xbox/cpu/motherboard.8ddd164202ef59296b376029d383dac1a91e08eea715a6596e1eefe61af1a160.png"><picture>
<img name="image_cover" alt="Image" src="https://www.copetti.org/images/consoles/xbox/cpu/motherboard.8ddd164202ef59296b376029d383dac1a91e08eea715a6596e1eefe61af1a160.png" data-src="https://www.copetti.org/images/consoles/xbox/cpu/motherboard.8ddd164202ef59296b376029d383dac1a91e08eea715a6596e1eefe61af1a160.png"></picture></a><figcaption>Overview of Xbox Motherboard</figcaption></div><p>The new standard developed relied on two dedicated chips to handle most of the motherboard functions. These chips are:</p><ul><li>The <strong>Northbridge</strong>: Serves as a memory controller and interfaces the GPU.</li><li>Th…</li></ul></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/xbox/">https://www.copetti.org/projects/consoles/xbox/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/xbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23657231</guid>
            <pubDate>Fri, 26 Jun 2020 21:25:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of words text-to-speech engines can't say correctly]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23657205">thread link</a>) | @Mindless2112
<br/>
June 26, 2020 | https://wiki.therofl98.co/wiki/List_of_words_the_text-to-speech_engines_can%27t_say_correctly | <a href="https://web.archive.org/web/*/https://wiki.therofl98.co/wiki/List_of_words_the_text-to-speech_engines_can%27t_say_correctly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div><p>There are several glitches/word mispronunciations with SAPI 4 and SAPI 5 voices <a href="https://wiki.therofl98.co/wiki/Microsoft_Sam" title="Microsoft Sam">Microsoft Sam</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Mike" title="Microsoft Mike">Mike</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Mary" title="Microsoft Mary">Mary</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Anna" title="Microsoft Anna">Microsoft Anna</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_David" title="Microsoft David">David</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Hazel" title="Microsoft Hazel">Hazel</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Zira" title="Microsoft Zira">Zira</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Mark" title="Microsoft Mark">Mark</a>, <a href="https://wiki.therofl98.co/wiki/Microsoft_Eva" title="Microsoft Eva">Eva</a>, TruVoice Voices, LH British Voices, <a href="https://wiki.therofl98.co/wiki/MacinTalk_Voice_Alex" title="MacinTalk Voice Alex">MacinTalk Voice Alex</a>, and <a href="https://wiki.therofl98.co/wiki/MacinTalk_Voice_Zarvox" title="MacinTalk Voice Zarvox">MacinTalk Voice Zarvox</a>, some of which that cause them to pronounce words incorrectly. Following is a <b>list of mispronunciation glitches</b> that have been found so far. Please keep this list in alphabetical order.
</p><p>Note: Many of the mispronunciations from Sam are not in the <a href="https://wiki.therofl98.co/wiki/Microsoft_Sam_(SAPI_4)" title="Microsoft Sam (SAPI 4)">Speakonia (SAPI 4) version</a> originally in Windows 2000, although there are some <a href="https://wiki.therofl98.co/wiki/Speakonia" title="Speakonia">Speakonia</a>–only bugs.
</p>

<h2><span id="Word_Mispronunciations">Word Mispronunciations</span></h2>
<p>Most famously, regardless of version, Sam cannot pronounce the word "soy" (also the spelling "soi"), but instead will make a sound "swurghf", resembling a <a href="https://wiki.therofl98.co/wiki/ROFLcopter" title="ROFLcopter">helicopter</a> blade. In <a href="https://wiki.therofl98.co/wiki/Speakonia" title="Speakonia">Speakonia</a> (SAPI 4), one can aid this mispronunciation by typing "soei", "s'hoy" or "Swoi" instead, and SAPI 5: "soe" or "ssoy". It doesn't happen in Mary and Mike, meaning this issue seems to be specific to the voice itself. However, he can say it correctly if you type a z after the S. He also says it correctly if a word is placed after it that begins with L or W, such as "soy like" or "soy wheat". Sticky Keys XP has also found an accurate way to make him say it correctly in Windows XP (SAPI 5). To do this, type "sse loi" (s'e loi in SAPI4). However, he says "soil" correctly.
</p>
<h3><span id="#"></span><span id=".23">#</span></h3>
<ul><li>6ix9ine: Microsoft Sam says "six-ix-nine-ine" in the SAPI4 version. He says "six-ix-nine-in" in SAPI5.</li>
<li>8bit: If you type this in a lot of times, Sam will sound like he is saying "8 billit" or "Bill Gates".</li>
<li>.exe - SAPI4 Sam will say "point eggs". He will say it correctly if spelled out. However, on SAPI5, he will say "dot eggs ee".</li></ul>
<h3><span id="A">A</span></h3>
<ul><li>Activision: Sam will say "Act-tiv-vis-see-on" in the SAPI5 version, but not in SAPI4. In Anna, a brief "wuh" is heard before Activision.</li>
<li>Adblocker: Sam, Mike, and Mary will say "ad bloker" in SAPI 4, while the SAPI 5 version pronounces it almost correctly as "adplocker". (Sam only).</li>
<li>Aeroplane: Sam pronounces it as "air-ah plane" in the SAPI5 version. He says it correctly in the Speakonia version.</li>
<li>AFK: Sam will mispronounce this in a somewhat different fashion with APC and APK.</li>
<li>Aight: Sam, Mike, and Mary will say "eight" (Both versions).</li>
<li>Airbus: Sam says it as "Airbess", but will say it correctly as two words. The SAPI5 version of Sam will say "orbis"</li>
<li>Airmaster: Microsoft Sam will say "Airmister" in the SAPI5 version.</li>
<li>Alberto: Sam will say, "Albertoo" in SAPI5. Pronounced correctly in SAPI4.</li>
<li>Aleratec: Microsoft Sam will say "al-er-aw-teek" in the SAPI5 version.</li>
<li>Alex - Sam will say "awl-ex" in SAPI4.</li>
<li>Aliens: Sam will say "ull-yens" in both versions. If you put a word before it, he will say it correctly.</li>
<li>Alioramus: Sam will say "ull-ee-o-remus". Said correctly if typed as "Alley o ramus" SAPI4 Sam says "ully-are-oh-mus"</li>
<li>Alt: Sam will say "Allt" in the SAPI5 version, but the Speakonia version says it correctly.</li>
<li>Altirhinus: Sam will say "All-turnus". He will say it correctly if typed as "Al tee ry nus"</li>
<li>Altaïr (as in Assassin’s Creed): Anna and Sam will say "Al-tire" in the SAPI5 version, but the Speakonia version says "Alter".</li>
<li>Always: Anna and Sam will say "al-wez" in Speakonia, but the SAPI5 version says it right.</li>
<li>Amiibo: Sam will say "em-yuh-eye-bo" in the SAPI4 version.</li>
<li>Andre: Sam says it "in-drei', unless there is a word before it. This happens in both SAPI4 and SAPI5. In order to fix this, type "Andray"</li>
<li>Andrea: Sam says it "indrea" unless there is a word before it. He says it correctly in SAPI5. In order to fix this, type "Anddrea"</li>
<li>Ana: Sam says "inna" in the SAPI4 version. Typing "anna" will be said correctly.</li>
<li>Anna: Sam says "inna" in the SAPI5 version. Typing "ana" will be said correctly.</li>
<li>Animax: Microsoft Sam will say "Ah-knee-macks" (but not in the Speakonia version).</li>
<li>Anime: Sam will say "Ow-nyme" in the SAPI5 version. He will say "anim" in Speakonia.</li>
<li>Animoji: Sam will say "An-im-uh-jee" in SAPI4.</li>
<li>APC and APK: Sam, Mike, and Mary will say "ack" in SAPI4 no matter if it's capital or not. This can be corrected by typing "AP C", "AP K". Their SAPI5 Counterparts will say "ack" if it's in all lowercase letters.</li>
<li>Arabic: Microsoft Sam will say "Erarbic" (This happens with the other Speakonia voices) SAPI5 Sam will say "ah-ra-beak".</li>
<li>Arceus: Sam pronounces it as "Ar-seus". When he pronounces the r, it sounds like he's blowing a raspberry before saying "seus".</li>
<li>Are: Sam will say "war" Putting a second r makes him say "lar" in Speakonia.</li>
<li><a rel="nofollow" href="https://en.wikipedia.org/wiki/Ariana_Grande">Ariana Grande</a>: Sam, Mike, and Mary will say "Airiana Grand" in SAPI4. Their SAPI5 Counterparts pronounce the Grande right, but not the Ariana.</li>
<li>Armadillain - They will say "Armadillayn". Type "Armadillun" to make them pronounce it correctly. SAPI5 Sam will say it correctly.</li>
<li>Asakura: He will pronounce it "Asa kyura" sometimes. He pronounces it correctly on the SAPI5 version, however.</li>
<li>Asda: Sam will say "Azz Dah" in both versions.</li>
<li><a rel="nofollow" href="https://en.wikipedia.org/wiki/Autonomous_sensory_meridian_response">ASMR</a>: Sam will say "as murr" in SAPI4 no matter if it's capital or not. This can be corrected by typing "eh s m r". SAPI5 sam will say as murr if it's in all lowercase letters.</li>
<li>Asskiss: Sam will say "usskiss".</li>
<li>Asus: Sam will say "uh-sus (as in Gus)" in SAPI4.</li>
<li>Atherosclerosis: Sam will say "Atherosclero size" in SAPI5.</li>
<li>Auricom (as in the team of the PS1 game Wipeout): Sam can't pronounce it as one word. He'll say "or-ih-cum" in the SAPI5 version. To fix this problem, separate both Auri and com so it can be pronounced correctly.</li>
<li>Australia: Microsoft Sam will say "Orfstralia" in SAPI5 (and Speakonia?)</li>
<li>Avaya: Sam will say "Ah-vay-uh" in SAPI4.</li>
<li>Awesomeface: Sam will say "Osama face" in SAPI4. but he will say it correctly if it is typed as "awesome face" or "AwesomeFace". SAPI5 Sam will pronounce it correctly.</li>
<li><a rel="nofollow" href="https://www.youtube.com/channel/UCyKsgkMdgNjbGgyCNUlZtIQ">Aznguy.mp4:</a> All Voices Will Say "A-Zunn-guy.mp4" To Make them Pronounce it correctly, type "Asian Guy.mp4," Because according to Erich Nguyen (aznguy.mp4) says in <a rel="nofollow" href="https://www.youtube.com/watch?v=2YXDmrbT0NQ&amp;t=321s">this video (uploaded on aznguy.mp5 (his second channel),</a> That That's How you pronounce it, and then Shows you <a rel="nofollow" href="https://www.youtube.com/watch?v=qni8-apHe34&amp;t=2117s">a video</a> of <a rel="nofollow" href="https://www.youtube.com/channel/UCFUsBdbrNe2a8tnVsxBwoZw">King Liang (Plainrock124)</a> Pronouncing it "a z n guy.mp4."</li>
<li><a rel="nofollow" href="https://en.wikipedia.org/wiki/ASAP_Rocky">A$AP Rocky</a>: Sam will say "a-dollarsign-a-p rocky" in SAPI4, while in SAPI5, "a-dollars-a-p rocky".</li></ul>
<h3><span id="B">B</span></h3>
<ul><li>"Balance", as well as "Balanced", "Balancing", "Balancer", and "Balances": Microsoft Sam will say "Galance", "Galanced", "Galancing", "Galancer", and "Galances" in both SAPI4 and 5.</li>
<li><a href="https://wiki.therofl98.co/wiki/Scottyvich_Baloneykov" title="Scottyvich Baloneykov">Baloneykov</a>: Sam will say "Balaneekuv" in SAPI4, while in SAPI5, "Baloneykoff".</li>
<li>Ballpen: Sam will say "Gall-pen" in SAPI4.</li>
<li>Barack Obama - Sam will say "Bearack" and "Abama" (Says correctly if you put "Brock" and "O bomb ah"). Windows XP/SAPI 5 Sam, Mike, Mary and Anna say Obama as Oh bam uh. David, Hazel, Zira, Eva and Mark say it correctly. SAPI5 Sam says Barack as "Bah-rick"</li>
<li>Baryonyx - Microsoft Sam will pronounce it as "Beer-uh-nyx". Says correctly if you type it as "Barry-onyx"</li>
<li><a rel="nofollow" href="https://en.wikipedia.org/wiki/Billboard_Music_Award">BBMAs</a>: Sam will say "b'mas" in SAPI4.</li>
<li>Bear: Sam makes a slight tapping sound at the B in both SAPI4 and SAPI5</li>
<li>Beauregarde: Sam will say "Bow-ree-gurd" in the SAPI5 version.</li>
<li>Bedfordshire: Sam pronounces it as "Beet-ford-sheer". SAPI5 Sam will say "Bed-furd-sheer"</li>
<li>Betamax: Sam pronounces it as "bit-tah-max." (He says it correctly if you put a dash between the 'Beta' and 'Max'.) He pronounces it correctly in the SAPI5 version, however.</li>
<li>Billie Eilish: Sam will say "Billie E-lish" in SAPI4, as well as a sharp tapping sound at the B.</li>
<li>Bing: Microsoft Sam says "bin" in both versions.</li>
<li>Birdman: Same error as "Hammerman" example. Said as "Birdm'n", and in SAPI5, there is a low heartbeat-like sound at the M.</li>
<li>Bling: This only happens in the SAPI5 version, where Sam says it with the first two letters said individually (B L ing) (he pronounces it correctly in the SAPI4 version). Typing "blle ing" fixes it.</li>
<li>Bluetooth: Sam will say "Blue thooth" unless you type "Blue tooth". He says "Blue-tuth" in SAPI5</li>
<li>Booger - All speech engines will say it like "boo-jer". If you replace the "g" with a "k", all speech engines will say it correctly.</li>
<li>Booty: A tapping sound is heard from SAPI4 Sam, especially when typing "dat booty".</li>
<li>Boowana (As in Boowana Spirit from the <a rel="nofollow" href="https://sites.google.com/site/kenstertube/meet-phanto/comics">Phanto Comics</a>): SAPI4 Sam says Too-wanna (pronounced in a short A), while SAPI5 Sam says it like BooWowna, Anna says it like Bow na, David, Eva, Mark and Zira say it like Boowowina, Hazel says it like Bow oh inna, Mark, the way to pronounce it correctly is space "boo" and "wana" out</li>
<li>Bought - Sam will say something along the lines of "bsott"</li>
<li>Bournemouth: Sam will say "burn muth".</li>
<li>Bowser: Sam, Mike, and Mary will say "Boh-zer" in SAPI4. They say it correctly in the SAPI5 version.</li>
<li>Breanna: Sam will say "breena" in SAPI4.</li>
<li>Brianna: Sam will say "bry (as in Fry) anna" in SAPI4.</li>
<li>Bro: SAPI4 Sam, Mike, and Mary will say "bar o", while their SAPI5 versions say it correctly, but fast. to make SAPI4 versions say it correctly, type "brro" or "broe".</li>
<li>BSOD: SAPI4 voices will say it as one word (a brief b followed by sod). Putting spaces between the letters will make them say it correctly</li>
<li>Bu: Sam will say "<a rel="nofollow" href="https://en.wikipedia.org/wiki/Bushel">Bushels</a>" in the SAPI5 version, but the SAPI4 version just says the letters.</li>
<li>Buffaloaf: Sam will say "buff-low-ahf" in SAPI5. He says it correctly in SAPI4.</li>
<li>Butthurt - Sam will say "But-thurt" (both versions). If you type the two words, "butt" and "hurt" or typing in "ButtHurt", he will say it correctly.</li></ul>
<h3><span id="C">C</span></h3>
<ul><li>Calhoun: Sam will say "cal-hooned" in the SAPI5 version. He says "kihooned" in SAPI4.</li>
<li>Calaway Park: Sam will say "cal-uh-wah-ee purk" in the SAPI5 version. Said correctly in SAPI4.</li>
<li>Caillou - Sam will pronounce it as "Kay lao" in the both versions. To fix this, Type "kai u"</li>
<li><a rel="nofollow" href="https://en.wikipedia.org/wiki/Camila_Cabello">Camila Cabello</a>: Sam, Mike, and Mary will say "camila kay-bell-yaw" in SAPI5. SAPI4 Sam says "camilla ca-bello".</li>
<li>Canapé: Sam will say "can ape" in SAPI4. He says it correctly in SAPI5.</li>
<li>Candlehead: Sam will say "cand-leh-head" in the SAPI5 version. He says it correctly in SAPI4.</li>
<li>Capcom - SAPI4 Sam, Mike, Mary, Anna, Hazel, and Zira say Capc'm. The Natural voices (SAPI 5 Sam, Mike and Mary), David, Eva and Mark Say it correctly</li>
<li>CarPlay: Sam, Mike, and Mary will say "car-pluh-ee" in …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.therofl98.co/wiki/List_of_words_the_text-to-speech_engines_can%27t_say_correctly">https://wiki.therofl98.co/wiki/List_of_words_the_text-to-speech_engines_can%27t_say_correctly</a></em></p>]]>
            </description>
            <link>https://wiki.therofl98.co/wiki/List_of_words_the_text-to-speech_engines_can%27t_say_correctly</link>
            <guid isPermaLink="false">hacker-news-small-sites-23657205</guid>
            <pubDate>Fri, 26 Jun 2020 21:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker container and image – export and save]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23656606">thread link</a>) | @lukasbar
<br/>
June 26, 2020 | https://knowledgepill.it/posts/docker_save_load_export_import/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/docker_save_load_export_import/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>From time to time we want export filesystem from container and make image from it.<br>
Also sometimes there is need for giving someone our container image in single file without repository usage - on for example pendrive.</p>
<p>How to do this things?</p>

<h2 id="export">Export</h2>
<p>To export container filesystem we use command <code>docker export</code>.<br>
This command will create output file with whole container filesystem - if we manually uncompress it - we will get directory structure like in <code>/</code> on Linux OS.</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker image ls</span>
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              a187dde48cd2        <span>2</span> weeks ago         5.6MB
ubuntu              latest              4e5021d210f6        <span>3</span> weeks ago         64.2MB
</code></pre></div><p>In our example we have ubuntu image from which we will start container, there is no <code>testfolder</code> folder in <code>/</code> directory.<br>
So ubuntu official image not include such folder.</p>
<p>Let’s add it in our container, with some file in it:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker run -it ubuntu /bin/bash</span>
root@86b609d88376:/# pwd
/
root@86b609d88376:/# ls testfolder
ls: cannot access <span>'testfolder'</span>: No such file or directory
root@86b609d88376:/# mkdir testfolder
root@86b609d88376:/# touch testfolder/file
root@86b609d88376:/# ls testfolder/
file
root@86b609d88376:/# exit
exit
</code></pre></div><p>Now we can check name of container and perform export from it with <code>docker export</code> and <code>-o</code> parameter for output tar file location.</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker container ls -a</span>
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES
86b609d88376        ubuntu              <span>"/bin/bash"</span>         <span>56</span> seconds ago      Exited <span>(</span>0<span>)</span> <span>8</span> seconds ago                       sharp_mclaren

<span>[</span>lukas@docker-host ~<span>]</span><span># docker export -o ubuntu-export.tar 86b609d88376</span>

<span>[</span>lukas@docker-host ~<span>]</span><span># ll</span>
total <span>65024</span>
-rw-------. <span>1</span> lukas lukas <span>66584064</span> Apr <span>10</span> 20:59 ubuntu-export.tar
</code></pre></div><p>Now we have our container filesystem exported into file which we can give to someone!</p>
<h2 id="import">Import</h2>
<p>From tar file we can now create(import) new image by <code>docker import</code> command.</p>
<p>It is important to notice that we will create from container export file docker image, not container!<br>
Import command can take as input network directory also.</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker import ubuntu-export.tar ubuntu-testfolder:1.0</span>
sha256:c794b94e40a299a183af988fe6f6485bc065ac0fd95a0e190b2326c805e408f1

<span>[</span>lukas@docker-host ~<span>]</span><span># docker image ls</span>
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
ubuntu-testfolder   1.0                 c794b94e40a2        <span>5</span> seconds ago       64.2MB
alpine              latest              a187dde48cd2        <span>2</span> weeks ago         5.6MB
ubuntu              latest              4e5021d210f6        <span>3</span> weeks ago         64.2MB
</code></pre></div><p>We can see that our imported image named <code>ubuntu-testfolder:1.0</code> is on his place.</p>
<p>Let’s make container from it:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host  ~<span>]</span><span># docker run -it ubuntu-testfolder:1.0 /bin/bash</span>
root@8f2842c0158d:/# ls testfolder/
file
</code></pre></div><p>We have in our image previously created - folder and file.</p>
<p>Docker export never include files from volumes mounted to container!</p>
<p>If you want to add some instructions from Dockerfile before importing image - check in help <code>--change</code> parameter for <code>docker import</code> command.</p>
<hr>
<h5 id="important">Important!</h5>
<p><code>docker import</code> command always import image as single layer image, it ignores before export layer layout!</p>
<p>Compare ubuntu image from which we created container and made export and imported image:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker history ubuntu</span>
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
4e5021d210f6        <span>3</span> weeks ago         /bin/sh -c <span>#(nop)  CMD ["/bin/bash"]            0B</span>
&lt;missing&gt;           <span>3</span> weeks ago         /bin/sh -c mkdir -p /run/systemd <span>&amp;&amp;</span> echo <span>'do…   7B
</span><span>&lt;missing&gt;           3 weeks ago         /bin/sh -c set -xe   &amp;&amp; echo '</span><span>#!/bin/sh' &gt; /…   745B</span>
&lt;missing&gt;           <span>3</span> weeks ago         /bin/sh -c <span>[</span> -z <span>"</span><span>$(</span>apt-get indextargets<span>)</span><span>"</span> <span>]</span>     987kB
&lt;missing&gt;           <span>3</span> weeks ago         /bin/sh -c <span>#(nop) ADD file:594fa35cf803361e6…   63.2MB</span>
</code></pre></div><div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker history ubuntu-testfolder:1.0</span>
IMAGE               CREATED             CREATED BY          SIZE                COMMENT
c794b94e40a2        <span>31</span> seconds ago                          64.2MB              Imported from -
</code></pre></div><hr>

<p>Save and load operates only on images, it has nothing to do with containers.<br>
So we save image to file, give it to someone, he or she can load image into his repository.</p>
<h2 id="save-image">Save image</h2>
<p><code>docker save</code> will create file with layers and metadata about them instead of filesystem snapshot like in <code>docker export</code>.</p>
<p>Let’s save some image!</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker image ls</span>
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              a187dde48cd2        <span>2</span> weeks ago         5.6MB
ubuntu              latest              4e5021d210f6        <span>3</span> weeks ago         64.2MB

<span>[</span>lukas@docker-host ~<span>]</span><span># docker save -o ubuntu.tar ubuntu</span>

<span>[</span>lukas@docker-host ~<span>]</span><span># ll</span>
-rw-------. <span>1</span> lukas lukas <span>66612224</span> Apr <span>10</span> 21:44 ubuntu.tar
</code></pre></div><p>Additionally we can check what is inside output tar archive. As we mentioned earlier we should see files structure similar to <code>/var/lib/docker/&lt;storage_driver&gt;</code> location where docker stores images locally.</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># mkdir ubuntu</span>

<span>[</span>lukas@docker-host ~<span>]</span><span># tar xvf ubuntu.tar -C ubuntu</span>
4bea34c6cbddb48774fb9dea97758ae7148d309bb4f2b51ceda03904a8124b8b/
4bea34c6cbddb48774fb9dea97758ae7148d309bb4f2b51ceda03904a8124b8b/VERSION
4bea34c6cbddb48774fb9dea97758ae7148d309bb4f2b51ceda03904a8124b8b/json
4bea34c6cbddb48774fb9dea97758ae7148d309bb4f2b51ceda03904a8124b8b/layer.tar
4e5021d210f65ebe915670c7089120120bc0a303b90208592851708c1b8c04bd.json
a514b8e33bd194200e62e981fa0e9bb3c13c6cd04ff82e91f3e8f11bd4f3500c/
a514b8e33bd194200e62e981fa0e9bb3c13c6cd04ff82e91f3e8f11bd4f3500c/VERSION
a514b8e33bd194200e62e981fa0e9bb3c13c6cd04ff82e91f3e8f11bd4f3500c/json
a514b8e33bd194200e62e981fa0e9bb3c13c6cd04ff82e91f3e8f11bd4f3500c/layer.tar
ca00c330587678e46fabf95ff50e16d9cc64bc0de5fc684694ac5266c39f69e6/
ca00c330587678e46fabf95ff50e16d9cc64bc0de5fc684694ac5266c39f69e6/VERSION
ca00c330587678e46fabf95ff50e16d9cc64bc0de5fc684694ac5266c39f69e6/json
ca00c330587678e46fabf95ff50e16d9cc64bc0de5fc684694ac5266c39f69e6/layer.tar
d3bc4608f672143c84e7f1e0db9a00e5067213562f22fcd5b601a920d23859a2/
d3bc4608f672143c84e7f1e0db9a00e5067213562f22fcd5b601a920d23859a2/VERSION
d3bc4608f672143c84e7f1e0db9a00e5067213562f22fcd5b601a920d23859a2/json
d3bc4608f672143c84e7f1e0db9a00e5067213562f22fcd5b601a920d23859a2/layer.tar
manifest.json
repositories
</code></pre></div><p>In random matedata json file, we will see all metadata about layer:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># vi ubuntu/d3bc4608f672143c84e7f1e0db9a00e5067213562f22fcd5b601a920d23859a2/json</span>
<span>{</span><span>"id"</span>:<span>"d3bc4608f672143c84e7f1e0db9a00e5067213562f22fcd5b601a920d23859a2"</span>,<span>"parent"</span>:<span>"a514b8e33bd194200e62e981fa0e9bb3c13c6cd04ff82e91f3e8f11bd4f3500c"</span>,<span>"created"</span>:<span>"1970-01-01T01:00:00+01:00"</span>,<span>"container_config"</span>:<span>{</span><span>"Hostname"</span>:<span>""</span>,<span>"Domainname"</span>:<span>""</span>,<span>"User"</span>:<span>""</span>,<span>"AttachStdin"</span>:false,<span>"AttachStdout"</span>:false,<span>"AttachStderr"</span>:false,<span>"Tty"</span>:false,<span>"OpenStdin"</span>:false,<span>"StdinOnce"</span>:false,<span>"Env"</span>:null,<span>"Cmd"</span>:null,<span>"Image"</span>:<span>""</span>,<span>"Volumes"</span>:null,<span>"WorkingDir"</span>:<span>""</span>,<span>"Entrypoint"</span>:null,<span>"OnBuild"</span>:null,<span>"Labels"</span>:null<span>}</span>,<span>"os"</span>:<span>"linux"</span><span>}</span>
</code></pre></div><h2 id="load-image">Load image</h2>
<p>First, we remove ubuntu image from out local repository:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker image rm ubuntu</span>
Untagged: ubuntu:latest
Untagged: ubuntu@sha256:bec5a2727be7fff3d308193cfde3491f8fba1a2ba392b7546b43a051853a341d
Deleted: sha256:4e5021d210f65ebe915670c7089120120bc0a303b90208592851708c1b8c04bd
Deleted: sha256:1d9112746e9d86157c23e426ce87cc2d7bced0ba2ec8ddbdfbcc3093e0769472
Deleted: sha256:efcf4a93c18b5d01aa8e10a2e3b7e2b2eef0378336456d8653e2d123d6232c1e
Deleted: sha256:1e1aa31289fdca521c403edd6b37317bf0a349a941c7f19b6d9d311f59347502
Deleted: sha256:c8be1b8f4d60d99c281fc2db75e0f56df42a83ad2f0b091621ce19357e19d853

<span>[</span>lukas@docker-host ~<span>]</span><span># docker image ls</span>
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              a187dde48cd2        <span>2</span> weeks ago         5.6MB
</code></pre></div><p>Next we will perform load with <code>docker load</code> command:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker load -i ubuntu.tar</span>
c8be1b8f4d60: Loading layer <span>[</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>&gt;<span>]</span>  65.58MB/65.58MB
977183d4e999: Loading layer <span>[</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>&gt;<span>]</span>  991.2kB/991.2kB
6597da2e2e52: Loading layer <span>[</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>&gt;<span>]</span>  15.87kB/15.87kB
16542a8fc3be: Loading layer <span>[</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span><span>=</span>&gt;<span>]</span>  3.072kB/3.072kB
Loaded image: ubuntu:latest

<span>[</span>lukas@docker-host ~<span>]</span><span># docker image ls</span>
REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE
alpine              latest              a187dde48cd2        <span>2</span> weeks ago         5.6MB
ubuntu              latest              4e5021d210f6        <span>3</span> weeks ago         64.2MB
</code></pre></div><p>Other than import operation, loading adds all metadata and all layers of image as they were before load operation:</p>
<div><pre><code data-lang="bash"><span>[</span>lukas@docker-host ~<span>]</span><span># docker history ubuntu</span>
IMAGE               CREATED             CREATED BY                                      SIZE                COMMENT
4e5021d210f6        <span>3</span> weeks ago         /bin/sh -c <span>#(nop)  CMD ["/bin/bash"]            0B</span>
&lt;missing&gt;           <span>3</span> weeks ago         /bin/sh -c mkdir -p /run/systemd <span>&amp;&amp;</span> echo <span>'do…   7B
</span><span>&lt;missing&gt;           3 weeks ago         /bin/sh -c set -xe   &amp;&amp; echo '</span><span>#!/bin/sh' &gt; /…   745B</span>
&lt;missing&gt;           <span>3</span> weeks ago         /bin/sh -c <span>[</span> -z <span>"</span><span>$(</span>apt-get indextargets<span>)</span><span>"</span> <span>]</span>     987kB
&lt;missing&gt;           <span>3</span> weeks ago         /bin/sh -c <span>#(nop) ADD file:594fa35cf803361e6…   63.2MB</span>
</code></pre></div>
</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/docker_save_load_export_import/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23656606</guid>
            <pubDate>Fri, 26 Jun 2020 20:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building AI Trading Systems]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 103 (<a href="https://news.ycombinator.com/item?id=23656369">thread link</a>) | @dennybritz
<br/>
June 26, 2020 | https://dennybritz.com/blog/ai-trading/ | <a href="https://web.archive.org/web/*/https://dennybritz.com/blog/ai-trading/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Lessons learned building a profitable algorithmic trading system using Reinforcement Learning techniques.</p><div id="post-content"><p>About two years ago I wrote a <a href="http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/">little piece</a> about applying Reinforcement Learning to the markets. A few people asked me what became of it. So this post covers some high-level things I've learned. It's more of a rant than an organized post, really. If there is enough interest in this topic I'd be happy to go into more technical detail in future posts, but that's TBD. Please let me know in the comments or on <a href="https://twitter.com/dennybritz">Twitter</a>.</p> <p>Over the past few years I've built four and a half trading systems. The first one was crap. The second one I never finished because I realized early on that it could never work either. The third one was abandoned for personal and political reasons. The fourth one worked extremely well for 12-18 months, producing something on the order of a full-time salary with a tiny investment of a few thousands dollars. Then, profits started decreasing and I decided to move on to other things. I lacked the motivation to build yet another system. Some of the systems I worked on were for the financial markets, but the last one was applied to the crypto markets. So keep that in mind while reading.</p>  <p>If you've taken some economics classes your first thought is perhaps something like</p> <blockquote> <p>Ha, Efficient Market Hypothesis! You can't beat the market! It's all just luck!</p> </blockquote> <p>And I would say that most economic theories like the EMH are quite far removed from the real world. This doesn't necessarily mean they're wrong. They are interesting academic models that can be useful in certain contexts, like for writing papers or getting prizes. But they don't survive confrontations with a messy real world and emotional human beings. I won't get into it here because you can find <a href="https://www.youtube.com/watch?v=bM9bYOBuKF4">smarter people</a> arguing about this, but even the original author admits that the EMH is just a theoretical model. Suffice to say, I believe (and have seen myself) that you can build profitable systems that consistently beat the market. Will the market eventually adjust and take away that opportunity? Probably, but that's irrelevant, because the market may take months, years or decades to adjust (just look at HFT), and you are free to evolve your system over time, looking for new opportunities and adjusting to the adjusting market yourself. That was the case for me. The market may have adjusted to my system as profits started decreasing, but it took more than 12 months, and with the right motivation I probably could have adjusted and improved the system to work again.</p> <p>Rather than thinking about markets from an economics perspective, I prefer to think about them from a Game Theory or Reinforcement Learning perspective. <strong><strong>The market does not exist.</strong></strong> What people call the market is an emergent property of many agents acting in an environment trying to maximize their own objective. The objective may be slightly different for everyone. Some want to sell shares they obtained through a stock options plan at a good price. Some engage in arbitrage for quick profits. Some try to predict short-term movements based on news or charting patterns. Some engage long-term speculation based on fundamentals. Some are designated market makers providing liquidity for a specific asset or exchange in return for a fee. Each could be a human acting on gut feeling and emotion, a human following some kind of implicit fuzzy algorithm (e.g. charting), or an automated system acting on data. The combined behavior of all these agents gives rise to this illusive thing that people call <em>the market</em>. Your goal isn't to beat the market, it's to beat some of the other players in the market over a time horizon you care about. The time horizon part is important. Not every trade has a clear winner and loser, because agents are optimizing over different time horizons, ranging from microseconds to decades.</p>  <p>If you come from a tech or startup background, transitioning to trading may require a change in thinking. Products and engineering are often about <strong><strong>absolutes</strong></strong>. If your website takes 100ms to load that's pretty good. Making it load in 99ms provides negligible benefit to the end-user. It'd be a waste of engineering resources. The same is true for startups. Paul Graham likes to say that startups are rarely killed by competitors. Rather, they commit suicide. They fail because they cannot find customers, don't have a solid business model, or because of founder issues. Being killed by competition with a slightly better product is quite rare.</p> <p>Trading is different. It's about <strong><strong>relatives</strong></strong>. It's fine if your website takes a horrible 10 seconds to load if your competitor needs 11 seconds. Having crappy data is fine if everyone else's data is even crappier. Paying high trading fees is fine if everyone is paying the same. This is pretty obvious if you look at the market as a multiplayer game. Even if you're a bad player on an absolute scale, you can win if your competition is worse. This has direct effects on how you build software to trade in the markets.</p>  <p>What a focus on relative performance means for engineering can be quite counterintuitive.</p> <p>When building infrastructure for a product-based company you would prefer using battle-tested, robust frameworks that minimize risk. Why re-invent the wheel if someone else has already built it? It's safe to use something that has been adopted by thousands of people. This is where open source shines. Using AWS for hosting your server? Postgres for storing your data? JSON for serialization? Python or Node for data collection? An open source library for calling APIs? Download Keras and train a NN on your data? Reasonable ideas, but when you are building trading infrastructure, you should think twice about these.</p> <p>Widely adopted technologies are commodities. If you use the same technologies as everyone else, where will your advantage come from? When building a product this doesn't matter because it's about absolute SLAs. But trading is about relatives. <strong><strong>Each commoditized technology you can specialize and build yourself is an opportunity</strong></strong> to beat the competition. By being hybrid cloud you can reduce latencies. By storing data in an efficient binary format you can save serialization time, leading to faster iteration during development, and faster predictions in production. By creating custom integrations with exchanges instead of using off-the-shelf APIs you may be able to use specific order types that are not available to others, or gain an informational advantage by processing exchange-specific information. And so on. Building highly-specialized non-generic systems is what engineers hate. We love generalization and abstraction. But specialization is often where your advantage in trading comes from.</p> <p>You don't need to start from scratch and implement your own programming language to start trading. But you should be aware of the tradeoffs you are making when adopting commoditized technologies. Make conscious decisions about it. Some of the things above seem minor - but a large number of tiny advantages can add up to a significant edge.</p>  <p>You may say, well, this makes sense, but I really don't want to compete on the infrastructure side. Instead, I want to build a smarter model that makes better predictions. That's my edge! I've heard this a LOT, and I've never seen it work.</p> <p>AI is pretty commoditized. I would say it's more commoditized than excellent infrastructure engineering, data collection, or inductive biases from domain knowledge. These days, you can easily download state-of-the-art models and run them on your data. Unless you are at the forefront of some extremely relevant research, it's unlikely that you can gain a significant edge just from training a better model.</p> <p>When people realize that their fancy AI model built on crappy infrastructure trained with crappy data (that's also used by everyone else) doesn't work, they give up. AI can give you an edge, but not an edge so huge that it allows you to ignore other factors. You still need to build good infrastructure, get good data, have decent latencies, and so on. Few people seem to be willing to spend time on these unsexy things. Think of each as a multiplier. If one is close to zero, it doesn't matter how good your AI model is.</p> <p>So, what are some these other things?</p> <ul> <li><strong><strong>Market</strong></strong> - Pick the right market(s) to trade in. Don't go for the obvious choices that everyone is picking by default. The harder it is to get access to a market, both legally and technically, the more likely that you will find opportunities. Less liquid markets may be overlooked by sophisticated funds because they don't scale to their AUM. Again, this is often counterintuitive to engineers who go for "good APIs" - good APIs typically mean popular. Popular typically means commoditized.</li> <li><strong><strong>Data</strong></strong> - Think about data sources that others do not have access to, or are not willing to get. For example, there may be data that's difficult to crawl due to sophisticated rate restrictions IP bans. Most people will give up here. This is an opportunity for you. Be skeptical of popular APIs and open source software. It's the same data that everyone else uses.</li> <li><strong><strong>Latencies</strong></strong> - You're probably not planning to compete with HFT traders (bad idea), but that doesn't mean you can completely ignore latencies. Better latencies will probably lead to easier execution with less slippage. Be careful about where you host your systems, how you send data around, how you serialize data, and so on.</li> <li><strong><strong>Models</strong></strong> - In general, better data is more important than better models, but better models can also give you an edge. Note that you are often trading off model complexity with latencies.</li> <li><strong><strong>Execution</strong></strong> - A good model doesn't mean much if you can't execute. Historical data you collect may look quite different from what's actually happening on the exchange. You are not going to know until you start live trading.</li> </ul>  <p>More than two years after my <a href="http://www.wildml.com/2018/02/introduction-to-learning-to-trade-with-reinforcement-learning/">last post</a>, do I still believe that Reinforcement Learning is the right approach to trading in the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dennybritz.com/blog/ai-trading/">https://dennybritz.com/blog/ai-trading/</a></em></p>]]>
            </description>
            <link>https://dennybritz.com/blog/ai-trading/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23656369</guid>
            <pubDate>Fri, 26 Jun 2020 20:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Will tourist-based locales embrace high tech, with remote work more accepted?]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23655924">thread link</a>) | @ohjeez
<br/>
June 26, 2020 | https://avlwatchdog.org/how-tech-can-help-ashevilles-economy/ | <a href="https://web.archive.org/web/*/https://avlwatchdog.org/how-tech-can-help-ashevilles-economy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
		
		
<p>In 2019, if you were to ask anyone what drove Asheville’s economy, they’d tell you beer, arts and crafts, outdoor recreation, hotels and restaurants. In short, tourism.&nbsp;</p>



<p>Today, with those businesses only just beginning to ramp back up and tourists staying home, talk of diversifying Asheville’s economy is picking up. Local technology businesses and the rise of technology-based work-from-home jobs may be part of the solution.&nbsp;</p>



<p>Asheville already has a tech sector, albeit a small one with only 1% of the job market and approximately 1,900 jobs. But with an average salary of nearly $58,000 a year, according to ZipRecruiter, Western North Carolina tech jobs are good ones. And, more jobs are coming.</p>



<p><a href="https://charlesedwardind.com/about-us" target="_blank" rel="noreferrer noopener">Charles Edward Industries (CEI)</a>, a minority-owned electronics manufacturer, in concert with the Buncombe County Commission, Asheville City Council, and the Economic Development Coalition for Asheville-Buncombe County (EDC), has announced plans to move its headquarters to Asheville and invest $1.5 million over 3 years in a new manufacturing operation.&nbsp;</p>



<p>With this new factory, which will be next door to <a href="https://www.moogmusic.com/" target="_blank" rel="noreferrer noopener">Moog Music</a> on Broadway, will come 60 new assembly and production, engineering, management, and administration jobs.&nbsp; These jobs will have an average wage of $46,925–roughly 110% that of the Buncombe County average wage.&nbsp; Hiring is expected to start in Fall of 2020.</p>



<p>Why Asheville? Tim Harmon, CEI President “We see great promise for our company in Asheville and view the community’s workforce as a key competitive advantage as we seek to grow the business to new heights.”</p>



<p>As good as this news is, the infrastructure for more tech jobs is there.</p>



<p><a href="https://www.immedion.com/locations/asheville-data-center" target="_blank" rel="noreferrer noopener">Immedion Asheville</a>, a business data center in the Biltmore Park Town Square, has “helped many organizations transition to remote workforces” and bolster their computer-based systems since the pandemic, said Steve Newman, sales manager. “We see growth in our future for revenue or operations.”</p>



<p>Asheville is “fortunate to have several organizations like <a href="https://meetthegeeks.net/" target="_blank" rel="noreferrer noopener">Meet the Geeks</a>, <a href="http://www.hatchavl.org/" target="_blank" rel="noreferrer noopener">HATCH</a>, <a href="http://ventureasheville.com/" target="_blank" rel="noreferrer noopener">Venture Asheville</a>, <a href="https://www.abtech.edu/" target="_blank" rel="noreferrer noopener">A-B Tech</a>, and <a href="https://www.montreat.edu/" target="_blank" rel="noreferrer noopener">Montreat College</a> that are dedicated to helping promote and foster the technology industry in our area,” Newman said. “My hope is that those groups will continue to expand.”</p>



<p>For technology businesses to run anywhere requires broadband Internet. Thanks to the <a href="https://ercwnc.org/" target="_blank" rel="noreferrer noopener">Education &amp; Research Consortium of the Western Carolinas (ERC)</a>, Western North Carolina has access to up to extremely high-speed<em> </em>100 Gigabit per second broadband Internet access primarily to the education, healthcare, and government sectors.&nbsp;</p>



<p>The nonprofit ERC, which works with most broadband providers, has seen “a 10-15% overall increase in Internet traffic,” said CEO Hunter Goosmann.</p>



<p>“Some businesses have needed additional bandwidth, but the greater demand has been from homes,” Goosmann said. “You can imagine that whether it’s someone logging in for work or watching Netflix, Internet use has increased.”&nbsp;</p>



<p>Charter/Spectrum, the area’s biggest Internet Service Provider, has met the demand.&nbsp;</p>



<p>“We built our networks to exceed maximum capacity during peak evening usage, and even with the increased network activity we are seeing in the daytime, levels remain well below capacity and typical peak evening usage in most markets,” said Patti Braskie Michel, senior director of regional communications.</p>



<p>The ability of the Internet to hold up under the load opens other job possibilities for Asheville. The Society for Human Resources Management (SHRM) has found 17% of U.S. companies are adding permanent work-from-home policies for employees. This comes after major companies such as Google, Facebook, and Zillow announced their staff can work from home for the rest of 2020.&nbsp;</p>



<p>Companies that once dismissed the idea of employees working from Asheville out of hand are now much more open to the idea of remote workers.</p>



<p>Asheville also has its own home-grown technology businesses. They’re experiencing rough times but are doing much better than the companies relying on tourism.&nbsp;</p>



<p>Local company <a href="https://www.epsilon-inc.com/" target="_blank" rel="noreferrer noopener">Epsilon</a>, a Weaverville IT consultancy, is doing well and welcomes the telecommuting trend.</p>



<p>“We have been quite busy supporting customers that are getting used to working remotely,” said Matt Fraser, director of business development. “Over the years, Epsilon has stayed at the forefront of cloud technologies, which allow businesses to operate anywhere anytime, so many customers just needed a short learning curve to be able to work at home. In addition, we find that 70% to 80% of technical issues can be resolved remotely.”</p>



<p>Technology programs at AB-Tech and Montreat College as well as organizations like the Mountain Area Workforce Development Board, “continue to drive technology jobs in the area,” Fraser said.</p>



<p><a href="https://statusforward.com/" target="_blank" rel="noreferrer noopener">Status Forward</a>, a small Asheville-based web design, development, and marketing agency, has seen a rougher road.&nbsp;</p>



<p>“We have actually reduced our staff from 6 to 5 in the last two months,” said Leah Quintal, digital marketing strategist. “We have adapted by shifting the scope of our offerings…[We] developed and launched the <a href="https://supplyconnector.org/" target="_blank" rel="noreferrer noopener">Supply Connector</a>, a searchable directory site that connects manufacturers that have pivoted operations to provide PPE [Personal Protective Equipment] with the healthcare industry and essential providers that most need equipment. Should we get additional funding to support this effort, we will likely be able to hire additional staff.”&nbsp;&nbsp;</p>



<p>What’s ahead for Asheville’s tech businesses? Trevor Lohrbeer, a local tech entrepreneur who has launched several start-ups, sees potential.&nbsp;</p>



<figure><img src="https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-771x578.jpeg" alt="" srcset="https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-771x578.jpeg 771w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-336x252.jpeg 336w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-768x576.jpeg 768w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-1536x1152.jpeg 1536w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-2048x1536.jpeg 2048w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-1170x878.jpeg 1170w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-800x600.jpeg 800w, https://mk0ashevillewatlfby8.kinstacdn.com/wp-content/uploads/2020/06/Trevor-Lohrbeer-400x300.jpeg 400w" sizes="(max-width: 771px) 100vw, 771px"><figcaption><p>Trevor Lohrbeer</p>Tech entrepreneur Trevor Lohrbeer: “I don’t see Asheville becoming a major tech player, though I do think the tech industry could be built up to the point where it contributes significantly to the local economy.”
</figcaption></figure>



<p>“I don’t see Asheville becoming a major tech player, though I do think the tech industry could be built up to the point where it contributes significantly to the local economy,” said Lohrbeer, who’s also the founder of Meet the Geeks, the local technology networking nonprofit. “What I think we’ve seen over the past 20 years is that startups can now be started anywhere in the world.”</p>



<p>It helps to be in a startup hub like San Francisco or Boston.</p>



<p>But “it used to be almost impossible to build a significant tech company outside Silicon Valley,” Lohrbeer said. “Now, it’s possible in many more places around the world, including Asheville.”</p>



<p>Asheville now has tech-savvy angel investors and “as we continue to build our entrepreneurial ecosystem through initiatives like <a href="http://ventureasheville.com/" target="_blank" rel="noreferrer noopener">Venture Asheville</a>, I think we’ll see growth in the local tech industry,” Lohrbeer said.</p>



<p>Some Asheville-born tech start-ups, including <a href="https://www.homegauge.com/" target="_blank" rel="noreferrer noopener">Home Gauge</a>, <a href="https://www.flexera.com/more/acquisitions/flexera-risc.html" target="_blank" rel="noreferrer noopener">RISC Networks</a>, and <a href="http://ventureasheville.com/doctor-directory/" target="_blank" rel="noreferrer noopener">Doctor Directory</a>, have already grown and been acquired by national companies.&nbsp;</p>



<p>Jeffrey Kaplan, director of entrepreneurship at Venture Asheville, is optimistic “that entrepreneurs will lead our recovery.” Venture Asheville and its partners have raised $25,000 in support of the<a href="http://ventureasheville.com/microgrant/" target="_blank" rel="noreferrer noopener"> Asheville Impact Micro Grant</a>.</p>



<p>“We’re thrilled to help jumpstart five new companies,” Kaplan said.</p>



<p>With working from home more of an option now, Asheville is attracting more employees from bigger markets.</p>



<p>“Several startup founders have told me that a majority of applicants to open positions are coming from New York, Boston, and the Bay Area,” Kaplan said. “We’re seeing something of an urban exodus from major metros with people choosing locations that offer more balance, amenities, and a better lifestyle overall.”&nbsp;</p>



<p>Asheville will become “a regional health care innovation powerhouse,” Kaplan said. “Our unique ‘weirdness’ is an asset for startups to bootstrap and solve problems creatively.” What that means is that there will be more local competitive jobs.”</p>



<p>Don’t expect Asheville to become Boulder or Seattle, “which I think we all were aiming for 10-15 years ago,” Lohrbeer said.&nbsp;</p>



<p>“But since we’re starting to see the downsides of unplanned growth in the tourism industry, perhaps that’s a good thing,” he said. “Building a tech industry here that supports work-life balance and the ‘good living’ culture that Asheville is known for would be a success in my eyes, regardless of its size.”</p>



<p><a rel="noreferrer noopener" href="https://avlwatchdog.org/" target="_blank"><em>AVL Watchdog</em></a><em> is a nonprofit news team producing stories that matter to Asheville and Buncombe County. Steven Vaughan-Nichols is an Asheville-based freelance writer specializing in business and technology. Contact us at avlwatchdog@gmail.com.</em></p>
		
	</section></div>]]>
            </description>
            <link>https://avlwatchdog.org/how-tech-can-help-ashevilles-economy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23655924</guid>
            <pubDate>Fri, 26 Jun 2020 19:24:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming in Lambda Calculus]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23655390">thread link</a>) | @helmut_brandl
<br/>
June 26, 2020 | https://hbr.github.io/Lambda-Calculus/ | <a href="https://web.archive.org/web/*/https://hbr.github.io/Lambda-Calculus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <li>
            Untyped Lambda Calculus

            <ul>
            <li>
            <p><a href="https://hbr.github.io/Lambda-Calculus/lambda.html">Programming in Lambda Calculus</a>
            <a href="https://hbr.github.io/Lambda-Calculus/lambda.pdf">(pdf)</a></p>

            This text addresses programmers who are interested in looking at lambda
            calculus as a programming language.
            </li>

            <li>
            <p><a href="https://hbr.github.io/Lambda-Calculus/untyped_lambda.pdf">Step by Step Introduction into Lambda
                Calculus</a></p>

            This text gives a step by step introduction to the untyped lambda
            calculus from a mathematical point of view.
            </li>
            </ul>
        </li>
        </div></div>]]>
            </description>
            <link>https://hbr.github.io/Lambda-Calculus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23655390</guid>
            <pubDate>Fri, 26 Jun 2020 18:39:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom treats you like a child]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23655375">thread link</a>) | @dxchester
<br/>
June 26, 2020 | https://team.video/blog/zoom-child | <a href="https://web.archive.org/web/*/https://team.video/blog/zoom-child">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><img src="https://team.video/uploads/zoom-child.jpg" alt=""></p>

<section data-level="1" id="zoom-treats-you-like-a-child">
<p>Deeply ingrained in Zoom's defaults are choices that do not encourage us to expect the best from each other.  We spend such vast amounts of time in video meetings now that we should question what behaviors our platforms are driving us to, and how they affect our interactions with our friends, family, and colleagues at work.  </p>

<section data-level="3" id="-waiting-for-the-host-to-start-the-meeting-"><h3>"Waiting for the host to start the meeting"</h3>
<p>This message can be infuriating.  The host is on vacation, or they're in a car somewhere, or they're there but having trouble logging in.  Or worse, everyone wonders, who <em>is</em> the host of this meeting, anyway?  Is it me?  Am I holding us back at this moment?  For God's sake, when will we be able to get on with the actual work we have to do?</p>
<p>And really, why can't we just carry on without the host?  Of course if you go into all the right admin screens and click all the right buttons, you can turn this off, but since it is the default, this experience inevitably creeps in.</p>

</section>
<section data-level="3" id="may-i-please-share-my-screen-pretty-please-"><h3>May I please share my screen?  Pretty please?</h3>
<p>I have a thing on my screen that's relevant to our discussion right now.  Can I share my screen?  Oh, well, no because someone else is sharing <em>their</em> screen, and for some reason now I have to find a moment to interject and ask them if they would stop so that I could share my thing.  Or maybe it's not worth all of that so I'll just keep it to myself.  Yes, there is a setting again somewhere that can undo this constraint, but defaults are rarely changed.</p>

</section>
<section data-level="3" id="could-we-please-mute-this-person-making-a-ruckus-"><h3>Could we please mute this person making a ruckus?</h3>
<p>Try as we might to avoid it, we all at one point or another end up being this person making a ruckus.  If the host happens to be mid-sentence making a brilliant point, the last thing anybody wants is to derail the meeting so they can pause and find the right little mute button to click.  Shouldn't we all just be able to do it?</p>
<p>And really, why shouldn't it go the other way too -- if we see someone is muted and obviously meaning to speak to the group, do we all really need to figure out who is noticing this and who is going to yell "you're muted!" back at them?  And then they have to apologize, and figure out what they need to repeat, etc, etc.  More derailing.  What if anyone could just unmute anyone else and we all just trust each other to do the right thing?  That is the world I want to live in.</p>

</section>
<section data-level="3" id="-the-host-has-ended-the-call-"><h3>"The host has ended the call"</h3>
<p>In my younger days, at the bar, I used to get offended when last-call would come, and they'd kick everyone out.  Staff who had been friendly now changing course and telling everyone to please hurry up and GTFO.</p>
<p>These days, I can't help but see the parallel experience in leaving a zoom call.  I have to time my exit so that it's after the meeting is sure to be wrapping up, but before I get kicked out by the host.  Worst is when I'm reaching for that button to leave the call, but the host wins the race and I get booted before I can click.  Every time, I think, "Yeah, well, I was already leaving..."</p>

</section>
<section data-level="3" id="how-about-something-different-"><h3>How about something different?</h3>
<p>We built Team.Video over the last while with some of these frustrations in mind.  Anyone can come and go as they please.  The group can collaboratively manage mute states.  Everyone can share their screens if they like.</p>
<p>And in those first moments joining a call, instead of making everyone wait on their own, we have a little game people can play together while everyone is getting settled.  I suppose that is also treating you like a child in a way -- prompting you to play a game.  But I'll happily choose that version where we use play to spur our imagination and make a tiny little bit of a connection before getting into the hard work at hand.</p>
<p>Check out what we've put together at <a href="https://team.video/">https://team.video</a></p>

</section>
</section>
    </div></div>]]>
            </description>
            <link>https://team.video/blog/zoom-child</link>
            <guid isPermaLink="false">hacker-news-small-sites-23655375</guid>
            <pubDate>Fri, 26 Jun 2020 18:37:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Slack vs. Discord vs. Discourse]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23655253">thread link</a>) | @Elof
<br/>
June 26, 2020 | https://orbit.love/blog/slack-vs-discord-vs-discourse/ | <a href="https://web.archive.org/web/*/https://orbit.love/blog/slack-vs-discord-vs-discourse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>“What platform should I use for my startup’s community? Should I move from Slack to Discourse? Wait...there’s a Discourse <em>and</em> a Discord?”</p><p>Now is a great time to build a community online, and there’s no shortage of really great tools to help.</p><p>But despite the many options, there’s no single tool to rule them all. There are just too many variables, including community size, engagement model, the size and capabilities of the team building the community, and more.</p><p>While there’s no silver bullet for building and growing a community online, there <em>are</em> a few key questions to consider that will help guide your tooling decisions and your <a href="https://orbit.love/">Developer Relations </a>strategy.</p><p>In this article, we’ll discuss the key factors to consider when choosing a community platform, compare the three most popular options, and make recommendations based on a few different&nbsp;community scenarios.</p><p><strong>Here's what we'll cover:</strong></p><ul><li>The TL;DR recommendations</li><li>The 3 key factors to consider when choosing</li><li>In-depth feature comparison grid</li><li>Detailed recommendations</li></ul><h2>The TL;DR Recommendations</h2><p>We’ll discuss plenty of details, but here are the high-level recommendations.</p><h3>Use <a href="http://slack.com/">Slack</a> if…</h3><ul><li>You want to take advantage of Slack’s large library of integrations and bots (limited to 10 on free plans), or use their no-code workflow builder (only paid plans).</li><li>You want threaded conversations in your realtime chat.</li><li>You don’t care that only the last 10,000 messages are retained (on free plans).</li><li>You and your community members already use Slack for work.</li></ul><p><strong>But keep in mind:</strong></p><ul><li>On the free plan, Slack only retains the most recent 10,000 messages, which means they automatically archive messages above that threshold.</li><li>Slack paid plans start at $8 <em>per user</em> per month. <strong>Every community we’re aware of uses the free plan</strong>. <a href="https://slack.com/pricing">Compare Slack pricing plans here</a>.</li><li>Slack offers no real tooling for moderation. It’s specifically designed for workplaces, and they <a href="https://qz.com/1641708/slack-doesnt-care-that-you-cant-block-a-workplace-harasser/">don’t appear interested</a> in building features for moderation.</li></ul><h3>Use <a href="https://discord.com/">Discord</a> if…</h3><ul><li>You need realtime chat with advanced permissions and moderation.</li><li>You need unlimited message history.</li><li>Making users sign up for yet-another-Slack group is a concern.</li><li>Integrations and bots are less important.</li><li>Your community won’t mind the casual gamer-centric aesthetic.</li></ul><p><strong>But keep in mind…</strong></p><ul><li>With Discord, community members use a single account to login to multiple communities. This user model means you can join new communities with a single click (versus creating a new user account for every community). But it means it’s impossible to use different avatars for different communities, which could be a concern for folks who have used Discord primarily for gaming in the past. It’s possible that some might not want to use their stormtrooper headshot in a professional setting.</li><li><strong>Discord’s design and copy is playful and gamer-centric</strong>, which could be confusing for community members who aren't familiar with Discord’s gaming roots.</li></ul><h3>Use <a href="https://www.discourse.org/">Discourse</a> if…</h3><ul><li>Many community members will likely have similar questions or issues, and you’d like to point them to a library of common answers</li><li>You’d like community-generated content to be indexed (and thus findable in search engine results). This helps new members discover the community while reducing the core team’s support burden.</li><li>Moderation and fine-grained permissions are important.</li><li>You have enough community members for chat to be counterproductive.</li><li>Synchronous communication isn’t important, for example, if your community is distributed across many time zones.</li><li>You don’t mind paying to host the forum software, or are capable of hosting it yourself.</li><li>You want to use an open source platform.</li></ul><p><strong>But keep in mind…</strong></p><ul><li>There are many technical options for starting a community on Discourse, including deploying the open source code on your own servers, paying a third party for hosting, or paying Discourse.org for a fully hosted solution.</li><li><strong>For new members, starting a new thread in a forum can be perceived as a higher barrier of entry</strong>, versus simply saying “hello” in a chat channel.</li></ul><h3>Use <strong>both</strong> chat (Discord or Slack) + Discourse if…</h3><ul><li>You want indexed content (Discourse) along with realtime vibes (chat).</li><li>Have the bandwidth to manage multiple platforms.</li><li>Want separate spaces for distinct groups, for example a chat for your champions and a forum for everyone else.</li><li>Note: Discourse offers a <a href="https://meta.discourse.org/t/chatroom-integration-plugin-discourse-chat-integration/66522">plugin for integrating with chat platforms</a>.</li></ul><h2>Three key factors to consider when choosing a community platform</h2><p>When picking a platform, you’ll likely weigh some factors more heavily than others based on your situation. The factors here will provide you with a framework for assessing the options.</p><p><img src="https://cdn.sanity.io/images/cad8jutx/production/c8ec6b9dd94ccc54bc9ba7e8520fa1cd89f69758-2440x784.png" alt="Image of a comparison grid" title="Three Key Factors"></p><h3>The size of your community</h3><p><strong>Starting from scratch (or close to it)</strong></p><p>In the early stages of a community’s life, it’s important for the organizers to build strong connections with the first handful of members, since early adopters are more likely to join discussions, answer questions, and contribute in ways that make the community seem active and vibrant. Chat is good for this. Scalability and governance are less of a concern at this stage.</p><p><strong>Hundreds of community members</strong></p><p>At this point, chat platforms can start to feel unmanageable for a few reasons. First, moderation becomes an issue, since it’s hard for a small group of community managers to keep up with the volume of conversations happening (Discord beats Slack on this point).</p><p>Second, most community members complain that, on chat platforms, they often answer the same question or address the same concern many times over. The conversations just disappear too quickly for others to easily find, and since they’re not indexed or perma-linked, it’s difficult to reference previously answered questions.</p><p><strong>Many thousands of community members</strong></p><p>For large, well-established communities, forums are often the right choice, since live chat is difficult to manage and large scales.</p><p>Discourse provides fine-grained permissions and moderation that large communities will appreciate. Additionally, since large communities create lots of content, they especially benefit from indexed and shareable content.</p><h3>The size of your team</h3><p>Your choice of community platform should take into account your team’s ability to manage multiple channels, their timezone availability, and the number of folks available to interact on your chosen platform—all of which are a function of the team’s size.</p><p><strong>Small teams</strong></p><p>Small teams tend to start with a single platform, since that’s what they can manage given their bandwidth. In general, teams of three or smaller should commit to a single platform to focus their time and keep overhead low.</p><p><strong>Medium teams</strong></p><p>These teams are more self-sufficient compared to small teams and won’t need to depend as much on other teams for support. They <em>may</em> be able to handle multiple platforms, but often choose to go deeper with a single platform, such as more clearly defining roles and responsibilities within the team, and designating team members to focus on specific parts of the platform.</p><p><strong>Large teams</strong></p><p>Larger teams can handle multiple platforms and different sub-communities, such as a Slack for your MVPs and a Discourse forum for everyone else—but doing so introduces substantial overhead in terms of process management, identity resolution, and governance. That said, larger teams inside bigger companies tend to be better equipped to plan for and manage these situations.</p><h3>Your community’s engagement model</h3><p>What are the behaviors and norms you want your community members to model? Are you hoping for a casual vibe where members can congregate, discuss, and debate? Or are you more interested in cultivating deep knowledge sharing and collaboration? Once you decide, <strong>you should factor your engagement model into your tool choice</strong>.</p><p>In <a href="https://www.amazon.com/People-Powered-Communities-Supercharge-Business/dp/1400214882"><em>People Powered</em></a>, <a href="https://twitter.com/jonobacon">Jono Bacon</a> outlines three engagement models that we think are useful to consider when choosing a platform:</p><p><strong>Consumers</strong></p><p>These communities revolve around <strong>ephemeral and emergent discussions about common interests</strong>, and emphasize connection based on those topics. Examples include communities about art, gaming, or general technology trends.</p><p><strong>Champions</strong></p><p>In this engagement model, <strong>community members share knowledge and insights about a common tool or technology, with an emphasis on leveling-up one’s expertise and experience</strong>. Members often teach each other through demos and examples, driving further participation from other community members.</p><p>Examples include company-specific communities, like the <a href="https://roamresearch.com/">Roam Research</a> Slack group, where members share custom CSS and browser extensions as well as how-to videos to share their knowledge and help others excel.</p><p><strong>Collaborators</strong></p><p>In communities of collaborators, members work together on shared projects. <strong>The primary example is open source software</strong>, where diverse people from around the world work together to build and improve a common codebase.</p><h2>Comparing Slack, Discord, and Discourse</h2><p>In addition to the key factors above, it’s important to understand the actual feature set each platform offers. The grid below assumes features for the baseline plans for each platform, and includes call-outs when features are offered only on paid tiers.</p><p><strong><a href="https://cdn.sanity.io/images/cad8jutx/production/aff197588f79ad746695aefe4c436e90b1aa904b-1220x3044.png">›› View the full image</a><br><a href="https://res.cloudinary.com/dzello/image/upload/v1590534477/orbit/Slack-Discourse-Discord-Comparison-Primary-Orbit.pdf">›› Download the PDF</a></strong></p><p><a href="https://cdn.sanity.io/images/cad8jutx/production/aff197588f79ad746695aefe4c436e90b1aa904b-1220x3044.png"><img src="https://cdn.sanity.io/images/cad8jutx/production/f20e76ce60b8edd5151f05d8668c5df3e5efc971-1220x3044.png" title="Table Comparing Slack, Discord, and Discourse"></a></p><h2>Detailed Recommendations</h2><p>We’ll now look at detailed recommendations based on the key factors and the pros and cons of each platform.</p><p>Of all the factors to consider, <strong>we think a community’s engagement model should have the most influence over which platform is used</strong>, so we’ve organized this section along those lines with caveats for size of community and team.</p><h3>Consumer communities</h3><p><strong>Suggestion: </strong>Discord</p><p><strong>Rationale</strong></p><p>Casual communities should lower the barrier to involvement and focus on building close connections between users. For those reasons, we suggest using Discord. With Discord, new members can join with the click of a button (versus creating new accounts, as with Slack and Discord), which means they can get started quickly.</p><p>For servers managed by an official brand account, Discord also offers a <a href="https://discord.com/verification">verification program</a>, which unlocks additional features, like custom branding and short URLs, a verification check mark, and higher quality voice service.</p><p><strong>Tradeoffs</strong></p><p>Discord …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orbit.love/blog/slack-vs-discord-vs-discourse/">https://orbit.love/blog/slack-vs-discord-vs-discourse/</a></em></p>]]>
            </description>
            <link>https://orbit.love/blog/slack-vs-discord-vs-discourse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23655253</guid>
            <pubDate>Fri, 26 Jun 2020 18:26:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reduce Java Cold Starts in AWS Lambda Using GraalVM]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23654469">thread link</a>) | @formkiqmike
<br/>
June 26, 2020 | https://blog.formkiq.com/tutorials/aws-lambda-graalvm | <a href="https://web.archive.org/web/*/https://blog.formkiq.com/tutorials/aws-lambda-graalvm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Building <a href="https://aws.amazon.com/lambda/">Lambdas in AWS</a> is one of the central aspects for building <a href="https://aws.amazon.com/serverless/">serverless systems in AWS</a>. However, as AWS Lambda removes a lot of problems for developers when building systems, it also introduces a number of new problems developers have never had to deal with before.</p><p><span>The Number One Complaint developers have when building AWS Lambdas with Java are "cold starts".</span> A cold start occurs the very first time a AWS Lambda is asked to handle a request. Now, depending on the size of your Lambda function, it could take 10 seconds or more just for the Java process to start. For some applications, this may be an acceptable trade-off for the benefits AWS Lambda brings, but for most serverless applications, or for Lambdas that handle a large number of requests, this is unacceptable, and often makes developers abandon AWS Lambda and/or Java and go back to the technologies they are most familiar with.</p><p>AWS has tried to address cold starts by introducing features like <a href="https://aws.amazon.com/blogs/aws/new-provisioned-concurrency-for-lambda-functions/">Provisioned Concurrency</a>. However, this defeats the goal of "serverless" computing because you are no longer just paying for requests, you are also reserving compute capacity, and when you exceed this capacity you will incur the same cold starts you would have had otherwise.</p><p>The only way to fix cold starts is to get Java to start faster. Luckily, Oracle has created a new project called <a href="https://www.graalvm.org/">GraalVM</a>. GraalVM is a new Java VM that can be used to improve the performance and to reduce the startup time of applications.</p><h2>What You Need for this Tutorial</h2><h2>Full Source Code available on <a href="https://github.com/formkiq/tutorials/tree/master/java/graalvm-s3">GitHub</a></h2><h2>Create Project using SAM CLI</h2><p>AWS SAM CLI is a command line tool that makes it easy to create and deploy serverless applications. We are going to use the SAM CLI to first create a AWS Lambda function in Java, and then we will convert that Lambda function to use GraalVM. The last step will be to compare the performance of these two Lambda functions.</p><p>To create the project, run the following command in a terminal window (in a new) directory:</p><p>and answer the questions as follows:</p><p>You have now created a SAM project with a single Lambda function. In your current directory you should see a subdirectory called "graalvm-s3" that will contain the project generated by the SAM CLI.</p><h2>S3Java Lambda</h2><p>The Lambda function we will be creating is a simple function that writes a file to an S3 bucket. In the <span>graalvm-s3</span> directory, you will see a <span>HelloWorldFunction</span> subdirectory which is the default Lambda function that was generated from SAM. We are going to be creating our new Lambda function twice, once with Java and once with Java using GraalVM. The first one will be called <span>S3Java</span>, so our first step is to take over the sample function by renaming the <span>HelloWorldFunction</span> directory to <span>S3Java</span>.</p><p>We need to update the <span>template.yaml</span> to use the new Lambda name. We also need to add instructions into this template create the S3 bucket we will be writing our test file into, and to set the Lambda function permissions to allow read/write for this new bucket.</p><p>The Lambda function created by SAM comes with a few classes we will not need. You can delete the following files:</p><ul><li>S3Java/src/main/java/<span>helloworld/App.java</span></li><li>S3Java/src/main/java/<span>helloworld/GatewayResponse.java</span></li><li>S3Java/src/test/java/<span>helloworld/AppTest.java</span></li></ul><p>We will create a <strong>new Lambda function</strong> in this file:
<span>S3Java/src/main/java/<span>helloworld/S3Java.java</span></span></p><p>We need to add the official AWS S3 dependency to <span>S3Java/build.gradle</span> for the code to compile.</p><p>This Lambda function is very simple: it identifies an S3 Bucket by name from the environment, and then it creates a random file in that bucket with the message "This is a test".</p><p>To build and deploy this Lambda function by running the command in a terminal window, in the directory where the template.yaml file is:</p><p>Produces the following output:</p><p>To deploy this Lambda function by running the command in a terminal window, in the directory where the template.yaml file is:</p><p>Produces the following output:</p><p>SAM CLI will create and deploy a <a href="https://aws.amazon.com/cloudformation/">CloudFormation</a> Stack to your AWS Account. This will take a few minutes, but at the end you should see this message:</p><p>You can confirm the CloudFormation Stack was created by visiting the <a href="https://console.aws.amazon.com/cloudformation/home">CloudFormation Console</a> or by using AWS CLI command: "aws cloudformation describe-stacks --stack-name graalvm-s3 --region us-east-1"</p><p>A StackStatus "CREATE_COMPLETE" shows that the CloudFormation was successful. In the CloudFormation Outputs, you will see the ARN of the Lambda function we will use to run the Lambda function, as well as the S3 Bucket the files will be written to.</p><p>We can run the Lambda function by using AWS CLI with the command:</p><p>This will run the Lambda function and write the output of the function to a file called <span>output</span>. Viewing that file, you should see something similar to the following:</p><p>
<img src="https://blog.formkiq.com/img/graalvm-s3-newfile.png" alt="S3Java Created S3 File"></p><p>Now the last thing we need to know is how long this Lambda function takes to execute. The easiest way to see this is using the AWS CLI. Using the command <span>sam logs --name graalvm-s3-S3Java-XXXXXXXXXXXXXX --region us-east-1</span> will show the CloudWatch logs for the Lambda function. You can also visit the <a href="https://console.aws.amazon.com/cloudwatch/home">CloudWatch Console</a>. The output should be similar as below. We are looking for the <span>Duration</span> time.</p><p>We can see that it took 10400 ms, or 10.4 seconds, to execute this Lambda function. That is not very good, but we now have a time baseline. Once we convert this Lambda to GraalVM, we'll be able to see if anything changes.</p><h2>S3GraalVM Lambda</h2><p>We are going to create a new Lambda function called <span>S3GraalVM</span> based on the existing <span>S3Java</span>. So, you should copy the <span>S3Java</span> folder and call it <span>S3GraalVM</span></p><p>Delete the file
<span>S3GraalVM/src/main/java/<span>helloworld/S3Java.java</span></span>
and create
<span>S3GraalVM/src/main/java/<span>helloworld/S3GraalVM.java</span></span>
using the code below:</p><p><span>From a code perspective, the only change is setting the System Property
<span>software.amazon.awssdk.http.</span></span><span>service.impl</span>.
The AWS SDK by default uses Apache &amp; Netty for its HTTP service calls. This adds a ton of extra classes, and for AWS Lambda, this means slower startup times. Luckily, as of AWS SDK 2.0, we can change the SDK to use Java's built-in URLConnection class instead.</p><p>We then need to update our build.gradle to add url-connection-client, and exclude the apache-client and netty-nio-client so they are not included in our final build.</p><h2>"FAT" Jar File</h2><p>GraalVM needs to be run against a "FAT" jar file, IE: a single jar file that contains all code and dependencies. We will use the <span>com.github.johnrengelman.shadow</span> gradle plugin to easy accomplish this. Also, we will be using Lambda's custom runtime, so we need to use FormKiQ's open source <a href="https://github.com/formkiq/lambda-runtime-graalvm">GraalVM Lambda Runtime</a> library. Add the following to build.gradle.</p><h2>Build GraalVM Script</h2><p>GraalVM works by taking the "FAT" jar file and creating a Linux executable file that AWS Lambda can run. Unfortunately, GraalVM does not support all the features of Java. This is not generally a big deal, but one important feature it does not support without modification is Reflection. Because the FormKiQ GraalVM Lambda Runtime needs reflection to find the Lambda function to run, we need to use GraalVM's ReflectionConfigurationFiles. In this file we can define any classes we will be calling using reflection, and GraalVM will automatically add support for these classes.</p><p><span>Create the file
<span>S3GraalVM/src/main/</span></span><span>resources/reflect.json</span>,
defining our Lambda class inside.</p><p>Create file <span>S3GraalVM/build_graalvm.sh</span>, a shell script which will use Docker to convert the S3GraalVM-all.jar to an executable called <span>server</span>. (Make sure you give the build_graalvm.sh execute permission)</p><p>Add a task to <span>build.gradle</span> that will build the GraalVM image automatically when the project is built.</p><p>Once we have the GraalVM image, AWS requires a <span>bootstrap</span> file to be able to execute the Lambda function.</p><p>Create the file <span>S3GraalVM/bootstrap</span>, a script which will be bundled with the Lambda function and that AWS will call to execute the Lambda function. (Make sure you give the build_graalvm.sh execute permission)</p><p>We are almost done, the last thing we have to do is configure AWS SAM Cli to build our custom runtime. This is done though a <span>Makefile</span>. The Makefile is pretty simple, it just builds the gradle project and copies the <span>server</span> and <span>bootstrap</span> files to the SAM build directory.</p><p>Create file <span>S3GraalVM/Makefile</span> with the following code. (If you get the error Makefile:4: *** missing separator, it's because Makefile need to use TABS and not spaces to indent.)</p><p>Lastly, update the <span>template.yaml</span> file to include our new Lambda function.</p><p>Build the Lambda function by running the command in a terminal window, in the directory where the template.yaml file is (it will take a few minutes for GraalVM to build the project):</p><p>Produces the following output:</p><p>Deploy the Lambda function by running the command in a terminal window, in the directory where the template.yaml file is:</p><p>Produces the following output:</p></div><p>Just like above, we can use the AWS CLI to run the GraalVM Lambda function.</p><p>The output of the Lambda function will be written to a file called "output", with content similar to:</p><p>Running: "sam logs --name graalvm-s3-S3GraalVM-XXXXXXXXXXXX --region us-east-1", you should see the following:</p><p>As you can see, switching our Java Lambda function to use GraalVM has brought the duration from over 10 seconds cold start to less than 1/2 second.</p><p>We built two Lambda functions, one using standard Java 11 and a second using GraalVM. We saw that using GraalVM the runtime for our Lambda function went from over 10 seconds down to less than 1/2 a second.</p><p>If you want to learn more in detail about why AWS Lambda written in Java are slow, watch this video: <a href="https://www.youtube.com/watch?v=ddg1u5HLwg8">"Best practices for AWS Lambda and Java"</a>, which was a session from Reinvent 2019.</p></div>]]>
            </description>
            <link>https://blog.formkiq.com/tutorials/aws-lambda-graalvm</link>
            <guid isPermaLink="false">hacker-news-small-sites-23654469</guid>
            <pubDate>Fri, 26 Jun 2020 17:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why TikTok Snoofs Clipboard Contents]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23654345">thread link</a>) | @vecio
<br/>
June 26, 2020 | https://vec.io/posts/this-is-why-tiktok-snoofs-clipboard-contents | <a href="https://web.archive.org/web/*/https://vec.io/posts/this-is-why-tiktok-snoofs-clipboard-contents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://vec.io/posts/this-is-why-tiktok-snoofs-clipboard-contents</link>
            <guid isPermaLink="false">hacker-news-small-sites-23654345</guid>
            <pubDate>Fri, 26 Jun 2020 17:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origin-bound one-time codes delivered via SMS]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23654033">thread link</a>) | @yarapavan
<br/>
June 26, 2020 | https://wicg.github.io/sms-one-time-codes/ | <a href="https://web.archive.org/web/*/https://wicg.github.io/sms-one-time-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <div>
    <h2 id="intro"><span>Introduction</span></h2>
    <p><em>This section is non-normative.</em></p>
    <p>Many websites deliver one-time codes over SMS. <a data-link-type="biblio" href="#biblio-gsm-sms">[GSM-SMS]</a></p>
    <p>Without a standard format for such messages, programmatic extraction of codes from them has to rely on heuristics, which are often unreliable and error-prone. Additionally, without a mechanism for associating such codes with specific websites, users might be tricked into providing the code to malicious sites.</p>
    <p>This specification defines a format for the delivery of one-time codes over SMS. This format associates the one-time code with a specific <a data-link-type="dfn" href="https://url.spec.whatwg.org/#concept-url-origin" id="ref-for-concept-url-origin">origin</a>.</p>
   </div>
   <h2 data-level="1" id="infra"><span>1. </span><span>Infrastructure</span><a href="#infra"></a></h2>
   <p>This specification depends on the Infra Standard. <a data-link-type="biblio" href="#biblio-infra">[INFRA]</a></p>
   <h2 data-level="2" id="origin-bound-one-time-codes"><span>2. </span><span>Origin-bound one-time codes</span><a href="#origin-bound-one-time-codes"></a></h2>
   <p>An <dfn data-dfn-type="dfn" data-export="" id="origin-bound-one-time-code">origin-bound one-time code</dfn> is a <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#tuple" id="ref-for-tuple">tuple</a> consisting of an <a data-link-type="dfn" href="https://url.spec.whatwg.org/#concept-url-origin" id="ref-for-concept-url-origin①">origin</a> and a code (a <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#string" id="ref-for-string">string</a>).</p>
   <div id="example-7f98c637">
    <p>((<code>"https"</code>, <code>"example.com"</code>, <code>null</code>, <code>null</code>), <code>"747723"</code>) is an <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code">origin-bound one-time code</a> whose origin is (<code>"https"</code>, <code>"example.com"</code>, <code>null</code>, <code>null</code>) and whose code is <code>"747723"</code>.</p>
   </div>
   <h3 data-level="2.1" id="usage"><span>2.1. </span><span>Usage</span><a href="#usage"></a></h3>
   <p>Many User Agents help users fill out forms on websites. Sites can use features like <a href="https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#attr-fe-autocomplete-one-time-code"><code>autocomplete=one-time-code</code></a> to hint to User Agents that they could assist the user with providing a one-time code to the website. <a data-link-type="biblio" href="#biblio-html">[HTML]</a></p>
   <p>In this section, an <dfn data-dfn-type="dfn" data-noexport="" id="active-origin">active origin</dfn> is an <a data-link-type="dfn" href="https://url.spec.whatwg.org/#concept-url-origin" id="ref-for-concept-url-origin②">origin</a> of a <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#top-level-browsing-context" id="ref-for-top-level-browsing-context">top-level browsing context</a>'s <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/browsers.html#active-document" id="ref-for-active-document">active document</a>.</p>
   <p>When a User Agent is in possession of an <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①">origin-bound one-time code</a> and an <a data-link-type="dfn" href="#active-origin" id="ref-for-active-origin">active origin</a> is <strong><a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-origin" id="ref-for-same-origin">same origin</a></strong> with the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code②">origin-bound one-time code</a>'s origin, the User Agent may assist the user with providing the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code③">origin-bound one-time code</a>'s code to the website.</p>
   <p>When a User Agent is in possession of an <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code④">origin-bound one-time code</a> and an <a data-link-type="dfn" href="#active-origin" id="ref-for-active-origin①">active origin</a> is <strong><a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-site" id="ref-for-same-site">same site</a> but not <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-origin" id="ref-for-same-origin①">same origin</a></strong> with the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code⑤">origin-bound one-time code</a>'s origin, the User Agent may assist the user with providing the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code⑥">origin-bound one-time code</a>'s code to the website, and should indicate the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code⑦">origin-bound one-time code</a>'s origin to the user.</p>
   <p>When a User Agent is in possession of an <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code⑧">origin-bound one-time code</a> and an <a data-link-type="dfn" href="#active-origin" id="ref-for-active-origin②">active origin</a> is <strong>neither <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-site" id="ref-for-same-site①">same site</a> nor <a data-link-type="dfn" href="https://html.spec.whatwg.org/multipage/origin.html#same-origin" id="ref-for-same-origin②">same origin</a></strong> with the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code⑨">origin-bound one-time code</a>'s origin, the User Agent should not assist the user with providing the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①⓪">origin-bound one-time code</a>'s code to the website.</p>
   <p role="note"><span>Note:</span> because the <a data-link-type="dfn" href="https://url.spec.whatwg.org/#concept-url-scheme" id="ref-for-concept-url-scheme">scheme</a> of an <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①①">origin-bound one-time code</a>'s origin is always <code>"https"</code>, assisting the user with providing <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①②">origin-bound one-time codes</a> is only available in <a data-link-type="dfn" href="https://w3c.github.io/webappsec-secure-contexts/#secure-contexts" id="ref-for-secure-contexts">secure contexts</a>.</p>
   <p>This specification does not impose any requirements or restrictions on the use of one-time codes which are not <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①③">origin-bound one-time codes</a>.</p>
   <h2 data-level="3" id="format"><span>3. </span><span>Message format</span><a href="#format"></a></h2>
   <p>An <dfn data-dfn-type="dfn" data-export="" id="origin-bound-one-time-code-message">origin-bound one-time code message</dfn> is a <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#string" id="ref-for-string①">string</a> for which <a data-link-type="dfn" href="#parse-an-origin-bound-one-time-code-message" id="ref-for-parse-an-origin-bound-one-time-code-message">parsing an origin-bound one-time code message</a> successfully returns an <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①④">origin-bound one-time code</a>.</p>
   <div>
    <h3 data-level="3.1" id="authoring"><span>3.1. </span><span>Authoring</span><a href="#authoring"></a></h3>
    <p><em>This section is non-normative. <a href="#parsing">§ 3.2 Parsing</a> is the normative text.</em></p>
    <p><a data-link-type="dfn" href="#origin-bound-one-time-code-message" id="ref-for-origin-bound-one-time-code-message">Origin-bound one-time code messages</a> can optionally begin with human-readable <dfn data-dfn-for="origin-bound one-time code message" data-dfn-type="dfn" data-noexport="" id="origin-bound-one-time-code-message-explanatory-text">explanatory text</dfn>. This consists of all but the last line of the message. The last line of the message contains both a <dfn data-dfn-for="origin-bound one-time code message" data-dfn-type="dfn" data-noexport="" id="origin-bound-one-time-code-message-host">host</dfn> and a <dfn data-dfn-for="origin-bound one-time code message" data-dfn-type="dfn" data-noexport="" id="origin-bound-one-time-code-message-code">code</dfn>, each prefixed with a sigil: U+0040 (@) before the <a data-link-type="dfn" href="#origin-bound-one-time-code-message-host" id="ref-for-origin-bound-one-time-code-message-host">host</a>, and U+0023 (#) before the <a data-link-type="dfn" href="#origin-bound-one-time-code-message-code" id="ref-for-origin-bound-one-time-code-message-code">code</a>.</p>
    
    <p>The last line has to begin with U+0040 (@). (Which is to say, the <a data-link-type="dfn" href="#origin-bound-one-time-code-message-host" id="ref-for-origin-bound-one-time-code-message-host②">host</a> always comes before the <a data-link-type="dfn" href="#origin-bound-one-time-code-message-code" id="ref-for-origin-bound-one-time-code-message-code②">code</a> in the message.)</p>
    
    
    <p>Exactly one U+0020 (SPACE) separates the two values in the last line of the message.</p>
    <div id="example-c620376b">
     <p>The message <code>"@example.com code #747723"</code> is not an <a data-link-type="dfn" href="#origin-bound-one-time-code-message" id="ref-for-origin-bound-one-time-code-message④">origin-bound one-time code message</a>, because several characters appear between the two values on the last line of the message.</p>
    </div>
    <p>Trailing text in the last line is ignored. This is because we might identify additional information to include in <a data-link-type="dfn" href="#origin-bound-one-time-code-message" id="ref-for-origin-bound-one-time-code-message⑤">origin-bound one-time code messages</a> in the future. If we do, new syntax could be introduced after the existing syntax in the last line.</p>
    
   </div>
   <h3 data-level="3.2" id="parsing"><span>3.2. </span><span>Parsing</span><a href="#parsing"></a></h3>
   <p>To <dfn data-dfn-type="dfn" data-export="" id="parse-an-origin-bound-one-time-code-message" type="abstract-op">parse an origin-bound one-time code message</dfn> from <var>message</var>, run these steps:</p>
   <ol>
    <li data-md="">
     <p>Let <var>line</var> be the <a data-link-type="dfn" href="#last-line" id="ref-for-last-line">last line</a> of <var>message</var>, and <var>position</var> be 0.</p>
    </li><li data-md="">
     <p>If the code point at <var>position</var> within <var>line</var> is not U+0040 (@), return failure.</p>
    </li><li data-md="">
     <p>Advance <var>position</var> by 1.</p>
    </li><li data-md="">
     <p>Let <var>host</var> be the result of <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points" id="ref-for-collect-a-sequence-of-code-points">collecting a sequence of code points</a> which are not <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#ascii-whitespace" id="ref-for-ascii-whitespace">ASCII whitespace</a> from <var>line</var> with <var>position</var>.</p>
    </li><li data-md="">
     <p>If <var>host</var> is the empty string, return failure.</p>
    </li><li data-md="">
     <p>If <var>host</var> is not a <a data-link-type="dfn" href="https://url.spec.whatwg.org/#valid-domain-string" id="ref-for-valid-domain-string">valid domain string</a> or a <a data-link-type="dfn" href="https://url.spec.whatwg.org/#valid-ipv4-address-string" id="ref-for-valid-ipv4-address-string">valid IPv4-address string</a> or a <a data-link-type="dfn" href="https://url.spec.whatwg.org/#valid-ipv6-address-string" id="ref-for-valid-ipv6-address-string">valid IPv6-address string</a>, return failure.</p>
    </li><li data-md="">
     <p>If the code point at <var>position</var> within <var>line</var> is not U+0020 (SPACE), return failure.</p>
    </li><li data-md="">
     <p>Advance <var>position</var> by 1.</p>
    </li><li data-md="">
     <p>If the code point at <var>position</var> within <var>line</var> is not U+0023 (#), return failure.</p>
    </li><li data-md="">
     <p>Advance <var>position</var> by 1.</p>
    </li><li data-md="">
     <p>Let <var>code</var> be the result of <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points" id="ref-for-collect-a-sequence-of-code-points①">collecting a sequence of code points</a> which are not <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#ascii-whitespace" id="ref-for-ascii-whitespace①">ASCII whitespace</a> from <var>line</var> with <var>position</var>.</p>
    </li><li data-md="">
     <p>If <var>code</var> is the empty string, return failure.</p>
    </li><li data-md="">
     <p>Return the <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①⑤">origin-bound one-time code</a> ((<code>"https"</code>, <var>host</var>, <code>null</code>, <code>null</code>), <var>code</var>).</p>
   </li></ol>
   <p>The <dfn data-dfn-type="dfn" data-noexport="" id="last-line" type="abstract-op">last line</dfn> of <var>string</var> is the result of running these steps:</p>
   <ol>
    <li data-md="">
     <p><a data-link-type="dfn" href="https://infra.spec.whatwg.org/#normalize-newlines" id="ref-for-normalize-newlines">Normalize newlines</a> in <var>string</var>.</p>
    </li><li data-md="">
     <p>Let <var>lines</var> be the result of <a data-link-type="dfn" href="https://infra.spec.whatwg.org/#strictly-split" id="ref-for-strictly-split">strictly splitting</a> <var>string</var> on U+000A (LF).</p>
    </li><li data-md="">
     <p>Return the last item of <var>lines</var>.</p>
   </li></ol>
   <h2 data-level="4" id="security-considerations"><span>4. </span><span>Security considerations</span><a href="#security-considerations"></a></h2>
   <p>This specification attempts to mitigate the phishing risk associated with the delivery of one-time codes over SMS by enabling User Agents to know what website the one-time code is intended for.</p>
   <p>This specification does not attempt to mitigate other risks associated with the delivery of one-time codes over SMS, such as SMS spoofing, SIM swapping, SIM cloning, ISMI-catchers, or interception of the message by an untrusted party.</p>
   <p>Sites would do well to consider using non-SMS technologies such as <a data-link-type="biblio" href="#biblio-webauthn">[WEBAUTHN]</a> for authentication or verification.</p>
   <h2 data-level="5" id="privacy-considerations"><span>5. </span><span>Privacy considerations</span><a href="#privacy-considerations"></a></h2>
   <p>Any party which has access to a user’s SMS messages (such as the user’s cellular carrier, mobile operating system, or anyone who intercepted the message) can learn that the user has an account on the service identified in an <a data-link-type="dfn" href="#origin-bound-one-time-code-message" id="ref-for-origin-bound-one-time-code-message⑦">origin-bound one-time code message</a> delivered over SMS.</p>
   <p>On some platforms, User Agents might need access to all incoming SMS messages—even messages which are not <a data-link-type="dfn" href="#origin-bound-one-time-code-message" id="ref-for-origin-bound-one-time-code-message⑧">origin-bound one-time code messages</a>—in order to support the autofilling of <a data-link-type="dfn" href="#origin-bound-one-time-code" id="ref-for-origin-bound-one-time-code①⑥">origin-bound one-time codes</a> delivered over SMS in <a data-link-type="dfn" href="#origin-bound-one-time-code-message" id="ref-for-origin-bound-one-time-code-message⑨">origin-bound one-time code messages</a>.</p>
   <h2 id="acknowedgements"><span>Acknowledgements</span><a href="#acknowedgements"></a></h2>
   <p>Many thanks to
Aaron Parecki,
Eric Shepherd,
Eryn Wells,
Jay Mulani,
Paul Knight,
Ricky Mondello,
and
Steven Soneff
for their valuable feedback on this proposal.</p>
  </div><div data-fill-with="conformance">
   <h2 id="conformance"><span> Conformance</span><a href="#conformance"></a></h2>
   <p> Conformance requirements are expressed with a combination of descriptive assertions and RFC 2119 terminology.
            The key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “MAY”, and “OPTIONAL”
            in the normative parts of this document
            are to be interpreted as described in RFC 2119.
            However, for readability,
            these words do not appear in all uppercase letters in this specification. </p>
   <p> All of the text of this specification is normative
            except sections explicitly marked as non-normative, examples, and notes. <a data-link-type="biblio" href="#biblio-rfc2119">[RFC2119]</a> </p>
   <p> Examples in this specification are introduced with the words “for example”
            or are set apart from the normative text with <code>class="example"</code>, like this: </p>
   <p><a href="#example-example"></a> This is an example of an informative example. </p>
   <p> Informative notes begin with the word “Note”
            and are set apart from the normative text with <code>class="note"</code>, like this: </p>
   <p role="note"> Note, this is an informative note. </p>
  </div></div>]]>
            </description>
            <link>https://wicg.github.io/sms-one-time-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23654033</guid>
            <pubDate>Fri, 26 Jun 2020 16:45:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: No-code, AI/ML time-series predictions]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23653983">thread link</a>) | @reallymemorable
<br/>
June 26, 2020 | https://www.monument.ai/go/hackernews | <a href="https://web.archive.org/web/*/https://www.monument.ai/go/hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.monument.ai/go/hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653983</guid>
            <pubDate>Fri, 26 Jun 2020 16:41:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Timeleft – See how much time is left of the hour, week, year]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23653722">thread link</a>) | @raouls
<br/>
June 26, 2020 | https://aoueon.github.io/timeleft/ | <a href="https://web.archive.org/web/*/https://aoueon.github.io/timeleft/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        <div>
                            <div>
                                
                                <p>Don't waste your time.</p>
                                
                            </div>
                            <div>
                                <div><p>+ More info on <a href="https://github.com/aoueon/timeleft">GitHub</a></p></div>
                                <div><p>+ Built by <a href="mailto:raulsimionas@gmail.com">Raoul Simionas</a></p></div>
                                <div><p>+ Buy me a <a href="https://www.buymeacoffee.com/raoul">coffee</a></p></div>
                            </div>
                        </div>
                    </div></div>]]>
            </description>
            <link>https://aoueon.github.io/timeleft/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653722</guid>
            <pubDate>Fri, 26 Jun 2020 16:21:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Micronaut 2.0: a full stack Java framework for modular, testable applications]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 55 (<a href="https://news.ycombinator.com/item?id=23653601">thread link</a>) | @el_duderino
<br/>
June 26, 2020 | https://docs.micronaut.io/2.0.0/guide/index.html | <a href="https://web.archive.org/web/*/https://docs.micronaut.io/2.0.0/guide/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
        
        <p>Natively Cloud Native</p>
        <p><strong>Version:</strong> </p>
    </div>
    





<p>Micronaut is a modern, JVM-based, full stack Java framework designed for building modular, easily testable JVM applications with support for Java, Kotlin and the Groovy language.</p>
<p>Micronaut is developed by the creators of the Grails framework and takes inspiration from lessons learnt over the years building real-world applications from monoliths to microservices using Spring, Spring Boot and Grails.</p>
<p>Micronaut aims to provide all the tools necessary to build JVM applications including:</p>
<div>
<ul>
<li>
<p>Dependency Injection and Inversion of Control (IoC)</p>
</li>
<li>
<p>Aspect Oriented Programming (AOP)</p>
</li>
<li>
<p>Sensible Defaults and Auto-Configuration</p>
</li>
</ul>
</div>
<p>With Micronaut you can build Message-Driven Applications, Command Line Applications, HTTP Servers and more whilst for Microservices in particular Micronaut also provides:</p>
<div>
<ul>
<li>
<p>Distributed Configuration</p>
</li>
<li>
<p>Service Discovery</p>
</li>
<li>
<p>HTTP Routing</p>
</li>
<li>
<p>Client-Side Load Balancing</p>
</li>
</ul>
</div>
<p>At the same time Micronaut aims to avoid the downsides of frameworks like Spring, Spring Boot and Grails by providing:</p>
<div>
<ul>
<li>
<p>Fast startup time</p>
</li>
<li>
<p>Reduced memory footprint</p>
</li>
<li>
<p>Minimal use of reflection</p>
</li>
<li>
<p>Minimal use of proxies</p>
</li>
<li>
<p>No runtime bytecode generation</p>
</li>
<li>
<p>Easy Unit Testing</p>
</li>
</ul>
</div>
<p>Historically, frameworks such as Spring and Grails were not designed to run in scenarios such as server-less functions, Android apps, or low memory-footprint microservices. In contrast, Micronaut is designed to be suitable for all of these scenarios.</p>
<p>This goal is achieved through the use of Java’s <a href="https://docs.oracle.com/javase/8/docs/api/javax/annotation/processing/Processor.html">annotation processors</a>, which are usable on any JVM language that supports them, as well as an HTTP Server and Client built on <a href="https://netty.io/">Netty</a>. In order to provide a similar programming model to Spring and Grails, these annotation processors precompile the necessary metadata in order to perform DI, define AOP proxies and configure your application to run in a low-memory environment.</p>
<p>Many of the APIs within Micronaut are heavily inspired by Spring and Grails. This is by design, and aids in bringing developers up to speed quickly.</p>

<h2 id="whatsNew"><a href="#whatsNew"></a>1.1 What's New?</h2>




<p>Micronaut 2.0.0 includes the following changes:</p>
<div>
<h3 id="_core_features">Core Features</h3>
<div>
<h4 id="_support_for_jdk_14">Support for JDK 14</h4>
<p>Micronaut has been updated to support JDK 14.</p>
</div>
<div>
<h4 id="_groovy_3">Groovy 3</h4>
<p>Micronaut now supports applications written in Groovy 3.</p>
</div>
<div>
<h4 id="_startup_performance_improvements">Startup Performance Improvements</h4>
<p>Startup time has been further improved in this release with typical startup time for a new application around 20% faster.</p>
</div>
<div>
<h4 id="_improvements_to_bean_introspections">Improvements to Bean Introspections</h4>
<p>Bean introspections have been improved to support static creator methods, interfaces and enums. This means you can define a bean introspection on an interface with a private implementation such as:</p>
<div>
<p>Introspections on interfaces</p>
<div>
<pre><code data-lang="java">import io.micronaut.core.annotation.Creator;

@io.micronaut.core.annotation.Introspected
interface Example {
    String getName();

    @Creator
    static Example create(String name) {
        return () -&gt; name;
    }
}</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_support_for_analyzing_the_injection_point">Support for Analyzing the Injection Point</h4>
<p>Micronaut’s Dependency Injection implementation has been improved such that you can now receive an <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/inject/InjectionPoint.html">InjectionPoint</a> instance to any <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/context/annotation/Factory.html">@Factory</a> method. This makes it possible to customize how the bean is created based on the annotation metadata at the point at which the bean is injected.</p>
<p>For example consider the following definition:</p>
<div>
<div>
<pre><code data-lang="java">@Inject @Client("http://foo.com") RxHttpClient client;</code></pre>
</div>
</div>
<p>A factory method can receive the injection point and create a client based off of the value:</p>
<div>
<div>
<pre><code data-lang="java">@Bean
protected DefaultHttpClient httpClient(InjectionPoint&lt;?&gt; injectionPoint) {
    String url = metadata.stringValue(Client.class).orElse(null);
    if (url != null) {
        return new DefaultHttpClient(url);
    } else {
        return new DefaultHttpClient();
    }
}</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_support_for_eager_initialization_of_beans">Support for Eager Initialization of Beans</h4>
<p>Eager initialization of beans is useful in certain cases, such as on AWS Lambda where more CPU resources are assigned to Lamdba construction than execution. Therefore as for Micronaut 2.0, you can specify whether you want to eager initialization configuration or all singletons using the <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/context/ApplicationContextBuilder.html">ApplicationContextBuilder</a> interface:</p>
<div>
<p>Enabling Eager Initialization</p>
<div>
<pre><code data-lang="java">public class Application {

    public static void main(String[] args) {
        Micronaut.build(args)
            .eagerInitSingletons(true) <i data-value="1"></i><b>(1)</b>
            .mainClass(Application.class)
            .start();
    }
}</code></pre>
</div>
</div>
<div>
<table>
<tbody><tr>
<td><i data-value="1"></i><b>1</b></td>
<td>Setting eager init to true initializes all singletons</td>
</tr>
</tbody></table>
</div>
<p>It is also possible to just eager init configuration using <code>eagerInitConfiguration</code> which will initialize all <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/context/annotation/ConfigurationProperties.html">@ConfigurationProperties</a> beans.</p>
</div>
<div>
<h4 id="_spot_bugs_instead_of_jsr_305_nullable_nonnull_annotations">Spot Bugs Instead of JSR-305 Nullable/NonNull Annotations</h4>
<p>In Micronaut 1.x the Google distributed JSR-305 annotations library (<code>com.google.code.findbugs:jsr305</code>) was used to specify <code>@Nullable</code> and <code>@NonNull</code> on interfaces of the Micronaut API using the annotations contained within the <code>javax.annotation</code> package.</p>
<p>Due to the fact that JSR-305 has been cancelled and that this dependency has potential licensing issues (by using the <code>javax</code> namespace) as well as problems with the cross packages on Java 9+ with the module system Micronaut 2.x switches to the <code>spotbugs-annotations</code> module provided by the <a href="https://spotbugs.github.io/">SpotBugs project</a>.</p>
<p>It is recommended users of Micronaut use this API instead (although the <code>javax.annotation.Nullable</code> and <code>javax.annotation.NotNull</code> annotations continue to be supported).</p>
</div>
</div>
<div>
<h3 id="_cli_features">CLI Features</h3>

<div>
<h4 id="_micronaut_launch">Micronaut Launch</h4>
<p>Create Micronaut 2.0 applications without having the CLI installed using <code>curl</code>:</p>
<div>
<div>
<pre><code data-lang="bash">$ curl https://launch.micronaut.io/demo.zip -o demo.zip
$ unzip demo.zip -d demo</code></pre>
</div>
</div>


</div>
<div>
<h4 id="_diff_command">Diff Command</h4>
<p>Run <code>mn feature-diff --features=[FEATURE NAME]</code> from the root of another Micronaut project to create a diff of the changes that need to be applied to enable the feature. For example:</p>
<div>
<p>Using <code>feature-diff</code></p>
<div>
<pre><code data-lang="bash">$ mn feature-diff --features=azure-function
--- micronaut-cli.yml
+++ micronaut-cli.yml
@@ -3,4 +3,4 @@
 testFramework: junit
 sourceLanguage: java
 buildTool: gradle
-features: [app-name, application, gradle, http-client, java, junit, logback, netty-server, shade, yaml]
+features: [app-name, application, azure-function, azure-function-http, gradle, java, junit, logback, yaml]


--- host.json
+++ host.json
@@ -1,0 +1,7 @@
+{
+  "version": "2.0",
+  "extensionBundle": {
+    "id": "Microsoft.Azure.Functions.ExtensionBundle",
+    "version": "[1.*, 2.0.0)"
+  }
+}</code></pre>
</div>
</div>
</div>
</div>
<div>
<h3 id="_graalvm_improvements">GraalVM Improvements</h3>
<p>Micronaut’s support for GraalVM Native Image has been moved out of experimental status, which solidifies our commitment to continue improving support for native images.</p>
<div>
<h4 id="_automatic_static_resource_detection_for_native_image">Automatic Static Resource Detection for Native Image</h4>
<p>It is not longer necessary to configure static resources for your Native Immage builds. The <code>micronaut-graal</code> annotation processor will automatically do this for you for all resources found in <code>src/main/resources</code>.</p>
</div>
<div>
<h4 id="_improved_support_for_jdbc_hibernate_in_native_image">Improved support for JDBC / Hibernate in Native Image</h4>
<p>It is no longer necessary to provide additional GraalVM related configuration to connect to databases via JDBC or Hibernate/JPA. Micronaut includes automatic support for the following drivers with GraalVM Native Image:</p>
<div>
<ul>
<li>
<p>Oracle</p>
</li>
<li>
<p>MariaDB</p>
</li>
<li>
<p>Postgres</p>
</li>
<li>
<p>MS SQL</p>
</li>
<li>
<p>H2</p>
</li>
<li>
<p>MySQL</p>
</li>
</ul>
</div>
</div>
<div>
<h4 id="_support_for_flyway_migrations_in_native_image">Support for Flyway Migrations in Native Image</h4>

</div>
<div>
<h4 id="_support_for_native_image_in_aws_sdk_v2">Support for Native Image in AWS SDK v2</h4>
<p>Version 2.0 of the Micronaut AWS module <a href="https://micronaut-projects.github.io/micronaut-aws/2.0.x/guide/index.html#sdkv2">includes support for Native Image</a> for the majority of the v2 AWS APIs including S3, Dynamo DB, SES, SNS, and SQS which will be helpful for those developing native AWS Lambda functions with Micronaut + GraalVM.</p>
</div>
<div>
<h4 id="_support_for_jooq_in_native_image">Support for jOOQ in Native Image</h4>

</div>
<div>
<h4 id="_support_for_redis_in_native_image">Support for Redis in Native Image</h4>
<p>The Micronaut Redis module <a href="https://micronaut-projects.github.io/micronaut-redis/latest/guide/index.html#graalvm">includes support for Native Image</a>. There are still some pending uses cases that won’t work because of how Lettuce driver works. Make sure you read the documentation.</p>
</div>
<div>
<h4 id="_support_for_elasticsearch_in_native_image">Support for Elasticsearch in Native Image</h4>

</div>
</div>
<div>
<h3 id="_build_improvements">Build Improvements</h3>
<div>
<h4 id="_new_maven_parent_pom">New Maven Parent POM</h4>
<p>Micronaut now provides a new parent POM that can be used in Maven projects to get setup quickly:</p>
<div>
<p>Using the Maven Parent POM</p>
<div>
<pre><code data-lang="xml">&lt;parent&gt;
    &lt;groupId&gt;io.micronaut&lt;/groupId&gt;
    &lt;artifactId&gt;micronaut-parent&lt;/artifactId&gt;
    &lt;version&gt;${micronaut.version}&lt;/version&gt;
&lt;/parent&gt;</code></pre>
</div>
</div>
</div>
<div>
<h4 id="_new_maven_plugin">New Maven Plugin</h4>
<p>The parent POM mentioned above includes a new Micronaut Maven Plugin that enables automatic application restart during development. Just run the following:</p>

<p>Whenever you make a change to a class file the server will restart automatically.</p>
</div>
<div>
<h4 id="_gradle_6_5_update">Gradle 6.5 Update</h4>
<p>For Gradle users who create new applications Gradle 6.5 is used which is compatible with JDK 14.</p>
</div>
<div>
<h4 id="_better_gradle_incremental_annotation_processing_support">Better Gradle Incremental Annotation Processing Support</h4>

</div>
</div>
<div>
<h3 id="_http_features">HTTP Features</h3>
<div>
<h4 id="_support_for_http_2">Support for HTTP/2</h4>
<p>Micronaut’s Netty-based HTTP client and server have been updated to support HTTP/2.</p>
<p>See the <a href="#http2Server">HTTP/2 documentation</a> for more information on how to enable support for HTTP/2.</p>
</div>
<div>
<h4 id="_threading_model_and_event_loop_group_improvements">Threading Model and Event Loop Group Improvements</h4>
<p>Micronaut 2.0 uses a new shared default Netty <code>EventLoopGroup</code> for server worker threads and client request threads. This reduces context switching and improves resource utilization.</p>
<p>See the <a href="#clientConfiguration">HTTP Client Configuration</a> section for information on how to configure the default <code>EventLoopGroup</code> and add additional `EventLoopGroup’s that are configured per client.</p>
<p>In addition, as of Micronaut 2.0 all operations are by default executed on the <code>EventLoop</code> and users can optionally use the new <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/scheduling/annotation/ExecuteOn.html">@ExecuteOn</a> annotation to specify a named executor to execute an operation on if required (for example to offload blocking operations such as interactions with JPA/JDBC to a specific thread pool).</p>
</div>
<div>
<h4 id="_support_for_code_requestbean_code">Support for <code>@RequestBean</code></h4>
<p>It is now possible to bind the properties of a POJO argument to a <code>@Controller</code> to request parameters, headers and so on using the <a href="https://docs.micronaut.io/2.0.0/api/io/micronaut/http/annotation/RequestBean.html">@RequestBean</a> annotation.</p>
<p>Thanks to Github user <a href="https://github.com/asodja">asodja</a> for this contribution.</p>
</div>
<div>
<h4 id="_micronaut_servlet">Micronaut Servlet</h4>
<p>Micronaut now includes support for creating <a href="https://github.com/micronaut-projects/micronaut-servlet">Servlet applications</a> and users can use the command line to create an application that targets popular Servlet containers:</p>
<div>
<div>
<pre><code data-lang="bash">$ mn create-app myapp --features jetty-server    # for Jetty
$ mn create-app myapp --features tomcat-server   # for Tomcat
$ mn …</code></pre></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://docs.micronaut.io/2.0.0/guide/index.html">https://docs.micronaut.io/2.0.0/guide/index.html</a></em></p>]]>
            </description>
            <link>https://docs.micronaut.io/2.0.0/guide/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653601</guid>
            <pubDate>Fri, 26 Jun 2020 16:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serve your local website on HTTPS with mkcert]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23653455">thread link</a>) | @diamantidis_io
<br/>
June 26, 2020 | https://diamantidis.github.io/tips/2020/06/26/serve-localhost-website-on-https-with-mkcert | <a href="https://web.archive.org/web/*/https://diamantidis.github.io/tips/2020/06/26/serve-localhost-website-on-https-with-mkcert">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>When working on a website or a service, the development environment should imitate as much as possible the production one. And since most production websites and services are served on HTTPS, the same should happen for the development versions as well. This is exactly what <a href="https://github.com/FiloSottile/mkcert">mkcert</a> is trying to solve.</p> <p><a href="https://github.com/FiloSottile/mkcert">mkcert</a> is a tool that makes it easy to generate locally-trusted SSL certificates signed by a local CA (Certificate Authority).</p> <p>On macOS, you can use Homebrew to install the tool:</p> <div><div><pre><code><span># Install on macOS</span>
brew <span>install </span>mkcert
<span># Generate and install a local CA</span>
mkcert <span>-install</span>
<span># Create a new certificate</span>
mkcert <span>-key-file</span> key.pem <span>-cert-file</span> cert.pem localhost
</code></pre></div></div> <p>Now you can use the SSL key and cert for your local server. For instance, if you have a Jekyll blog, you can use the following command to serve on HTTPS</p> <div><div><pre><code>jekyll server <span>--ssl-cert</span> ./cert.pem <span>--ssl-key</span> ./key.pem
</code></pre></div></div> <p>Now, you can browse your local Jekyll site on <a href="https://localhost:4000/"><code>https://localhost:4000</code></a>! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p> </div></div>]]>
            </description>
            <link>https://diamantidis.github.io/tips/2020/06/26/serve-localhost-website-on-https-with-mkcert</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653455</guid>
            <pubDate>Fri, 26 Jun 2020 15:59:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s New in iOS 14]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23653418">thread link</a>) | @asdfasdfa2234
<br/>
June 26, 2020 | https://heartbeat.fritz.ai/whats-new-in-ios-14-c2ed9a7f67f?source=linkShare-ed6f13edc5f6-1593186947&_branch_match_id=805091344605560341 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/whats-new-in-ios-14-c2ed9a7f67f?source=linkShare-ed6f13edc5f6-1593186947&_branch_match_id=805091344605560341">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://heartbeat.fritz.ai/whats-new-in-ios-14-c2ed9a7f67f?source=linkShare-ed6f13edc5f6-1593186947&amp;_branch_match_id=805091344605560341</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653418</guid>
            <pubDate>Fri, 26 Jun 2020 15:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decarbonize Europe Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23653045">thread link</a>) | @martpie
<br/>
June 26, 2020 | https://decarbonizeurope.org/EN/ | <a href="https://web.archive.org/web/*/https://decarbonizeurope.org/EN/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				
				<div>
				<div><div><p><span><strong><span>We, the signatories of this Manifesto to decarbonize Europe, call upon all European States to immediately implement policies aiming to achieve a level of greenhouse gas emissions close to zero by 2050!</span></strong></span></p>
<p><span>The Paris Climate Agreement urges Europe to completely reinvent its economy. Much – if not all – remains to be done. This challenge involves all sectors which remain heavily dependent on fossil fuels: industry and electricity generation, transport, building and agriculture, as well as (albeit more indirectly) the finance and insurance sectors and public policies.</span></p>
<p><span>Europe saw the birth of the first industrial revolution, which relied on coal and hydrocarbon. In 150 years, humanity has consumed nearly half of the amount of oil Nature took half a billion years to create. It is now imperative to build a future free of depletable energy sources, which are irrevocably degrading the climate.</span></p>
<p><span>Europe must lead the way to the next industrial revolution, the one that will take us beyond the era of fossil fuels. Europe stands to reap massive benefits from such a revolution. Coal and steel were at the heart of the European project when it was built after the Second World War. It can now regenerate itself to create a new world – one that is prosperous and sustainable. A world of peace.</span></p>
<p><span>Together we can create a post-carbon Europe. This fresh impetus can be a driving force for Europe itself and for the world, to prevent the living conditions on our planet from being ravaged forever.</span></p>
<p><span><strong><span>We call upon all European actors – individuals, businesses and public authorities – to implement concrete and coherent strategies which can meet the challenge posed by climate change and the limits of natural resources. </span></strong><span>The European Union can and must take the necessary steps to align its actions with the ambitious and vital objective set out by the Paris Agreement. Success will only be achieved by working together towards this common goal, while respecting our differences which are a source of both solidarity and synergies. This historic endeavour will take shape thanks to Europe’s founding strengths: reason, freedom and boldness.</span></span></p>
<p><span>The technical and organizational solutions for this transition already exist; all that is now required is the European will to formulate political responses accordingly. These responses can quickly lead to a new economy, source of new profits, job opportunities and well-being. We acknowledge the fact that those answers require us to change our ways of producing, consuming but above all, thinking.</span></p>
<p><span>Are we going to give up because of the magnitude of this task?</span></p>
<p><span>We have the moral duty to act. We also have the necessary ambition.</span></p>
<p><span><strong><span>Once again, Europe has a rendezvous with History. The challenge is huge? Good. Anticipating the inevitable is a triumph over the future. The scale of the undertaking is equivalent to everything that Europe has done since its creation. This challenge is the path to modernity.&nbsp;</span></strong></span></p>
<p><a href="https://docs.google.com/forms/d/e/1FAIpQLSdI0kgv1GLU_6IwtJz-cPB8_PS97q8kpDXDICyUf9uxdP7S1A/viewform?c=0&amp;w=1"><img src="https://decarbonizeurope.org/wp-content/uploads/2017/03/I-SUPPORT-1.png" alt="" width="960" height="35" srcset="https://decarbonizeurope.org/wp-content/uploads/2017/03/I-SUPPORT-1.png 960w, https://decarbonizeurope.org/wp-content/uploads/2017/03/I-SUPPORT-1-300x11.png 300w, https://decarbonizeurope.org/wp-content/uploads/2017/03/I-SUPPORT-1-768x28.png 768w" sizes="(max-width: 960px) 100vw, 960px"></a></p>
</div></div></div></div></div>]]>
            </description>
            <link>https://decarbonizeurope.org/EN/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23653045</guid>
            <pubDate>Fri, 26 Jun 2020 15:25:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PHP 8.0: Alpha 1 released]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23652944">thread link</a>) | @zooboole
<br/>
June 26, 2020 | https://phpocean.com/blog/article/php-8-0-alpha-1-released/110 | <a href="https://web.archive.org/web/*/https://phpocean.com/blog/article/php-8-0-alpha-1-released/110">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
         <p>
          Our website is made possible by displaying online advertisements to our visitors.
          Please consider supporting us by disabling your ad blocker.
        </p>
                  
          <p><img src="https://phpocean.com/assets/images/pics-users/45fe0e23244a82128b2f73ab2a0b954b.jpg" alt="zooboole ">
                Published on <em>June 26th, 2020</em>
                By <em>zooboole </em>
                        </p>
          
          
              <p>Well, while others are using some of their time to hate, real developers continue to fix and improve. It's the custom in the software development ecosystem. You need to understand that no code wears out, It's eternal. but the man is not. That's why we need to decide well, focus, and be consistent in our decisions.</p>

<p>As a PHP developer for the past ten years, I know how it <a href="https://phpocean.com/blog/article/15-reasons-why-i-love-php/23">changed my life</a> and that of millions of others out there. That's why we keep on maintaining, using, and improving it to make sure it always satisfies the current market needs. This makes PHP to always be modern, I mean, the king.</p>

<p>So, the big news <s>today</s> yesterday is that the long-awaited <a href=""> PHP 8.0</a> is finally available in Alpha 1 with the freshest new feature — JIT(Just In Time) compilation. This is one of the newest features that the version 8 ships. It's promising to be a game-changer in terms of performance. Among other features you can also expect to have a support for union types, a new static return type, attributes,  str<em>contains(), str</em>starts<em>with, str</em>ends_with, and <a href="https://wiki.php.net/rfc/add-cms-support">Cryptographic Message Syntax (CMS)</a>. </p>

<p>Also, many more fixes have been applied to core features such as CURL, PDO, Date, FPM, GD, JSON, etc. And talking of JSON, the extension is now an integral part of PHP and cannot be disabled. This means you don't need to install the JSON extension manually after every installation of PHP like we use to do. It's particularly my favorite.</p>

<p>We can expect to have a final release by December this year. The next release, Alpha 2, is scheduled for Jul 09, 2020. Let's give it a try and have our own opinion.</p>

<hr>
<small>Cover image credit to phalcon.io</small>
        
        <hr>
        
           </div></div>]]>
            </description>
            <link>https://phpocean.com/blog/article/php-8-0-alpha-1-released/110</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652944</guid>
            <pubDate>Fri, 26 Jun 2020 15:17:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Six Levels of Reusability]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23652929">thread link</a>) | @michaelthiessen
<br/>
June 26, 2020 | https://michaelnthiessen.com/6-levels-of-reusability/ | <a href="https://web.archive.org/web/*/https://michaelnthiessen.com/6-levels-of-reusability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This is an excerpt from my upcoming course</em> <a href="https://michaelnthiessen.com/reusable-components">Reusable Components</a></p>
<!-- Put this wherever you would like your player to appear -->
<p><img src="https://play.vidyard.com/adQsnkrGv5DPwF3RSFy6Wi.jpg" data-uuid="adQsnkrGv5DPwF3RSFy6Wi" data-v="4" data-type="inline"></p>
<p>We all want to write less code, but get more done.</p>
<p>To make this happen, we build our components so they can be reused more than just once.</p>
<p>Some components only need basic reusability.</p>
<p>Others need far more complex techniques to get the most out of them.</p>
<p>I've identified 6 different levels of reusability, but there may be more that I've missed.</p>
<p>Here is a basic overview of the levels. My upcoming course, <em>Reusable Components</em>, explores each one and how to get the most out of them.</p>
<h2 id="1-templating">1. Templating</h2>
<p>Instead of copy + pasting code around everywhere, with this technique we wrap it up inside it's own component.</p>
<p>When we reuse the component —&nbsp;and not the code directly —&nbsp;it gives us two benefits:</p>
<ol>
<li>Making changes in the future is much easier to do, since we only have to do it one place</li>
<li>We don't have to remember the dozens (or hundreds) of places we've copied that code to</li>
</ol>
<p>This is the most basic, and most often talked about form of reusability.</p>
<p>But the higher levels get a lot more interesting...</p>
<h2 id="2-configuration">2. Configuration</h2>
<p>With some components we'll need to have variations on how they work.</p>
<p>A <code>Button</code> component might have a primary version, as well as an icon-only version. But instead of creating entirely new components for each of these versions, we use props to switch between the different types.</p>
<p>Adding in these props doesn't usually add much to a component, but gives us far more flexibility in how that component can be used. Neat-o.</p>
<p><em>Note: This is different than using props for state or data, such as a <code>loading</code> prop or a <code>disabled</code> prop.</em></p>
<h2 id="3-adaptability">3. Adaptability</h2>
<p>The biggest problem with configuration is lack of foresight. You need to anticipate future needs and build them into the component by putting in those props.</p>
<p>But if you make your component <em>adaptable</em>, it can allow for use cases that were never even thought of — without needing to change the component.</p>
<p>We do this by passing a chunk of markup from the parent to the component using a slot.</p>
<p>For example, instead of using a <code>text</code> prop in a <code>Button</code> component, we can use the <code>default</code> slot:</p>
<pre>
<span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>button</span>
    <span>class</span><span><span>=</span><span>"</span>btn btn--default<span>"</span></span>
    <span>@click</span><span><span>=</span><span>"</span>$emit('click')<span>"</span></span>
  <span>&gt;</span></span>
    <span><span><span>&lt;</span>slot</span> <span>/&gt;</span></span>
  <span><span><span>&lt;/</span>button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span></pre>
<p>Now we're not limited to just passing a <code>string</code> or <code>number</code> in.</p>
<p>If we wanted to add in a <code>loading</code> spinner without having to modify our <code>Button</code> component, we can do that:</p>
<pre><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>Button</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>img</span>
      <span>v-if</span><span><span>=</span><span>"</span>loading<span>"</span></span>
      <span>src</span><span><span>=</span><span>"</span>spinner.svg<span>"</span></span>
    <span>/&gt;</span></span>
    Click Me
  <span><span><span>&lt;/</span>Button</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span></pre>
<h2 id="4-inversion">4. Inversion</h2>
<p>Instead of passing a complete chunk of markup to our child component, we can pass a set of instructions for <em>how</em> to render.</p>
<p>This is like following a recipe instead of ordering takeout. When you follow a recipe it's a little more work, but you have total control over what you're making. You can tweak things as you go, or throw out the recipe altogether.</p>
<p>We use scoped slots to add even more flexibility to our components.</p>
<h2 id="5-extension">5. Extension</h2>
<p>With Adaptability and Inversion we have the necessary techniques to maximize the reusability of our components.</p>
<p>The next step is to apply these techniques all throughout our component so we can more easily extend it's behaviour.</p>
<p>We use named slots to add in one or more extension points in our component. Where Adaptability and Inversion on their own only give us one option to extend behaviour, having multiple extension points gives us many different options.</p>
<p>Here we have a <code>Modal</code> component with a <code>header</code>, <code>default</code>, and a <code>footer</code>:</p>
<pre><span><span><span>&lt;</span>template</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>modal<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>header<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>h2</span><span>&gt;</span></span>{{ title }}<span><span><span>&lt;/</span>h2</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>slot</span><span>&gt;</span></span>

    
    <span><span><span>&lt;</span>slot</span> <span>/&gt;</span></span>

    <span><span><span>&lt;</span>slot</span> <span>name</span><span><span>=</span><span>"</span>footer<span>"</span></span><span>&gt;</span></span>
      <span><span><span>&lt;</span>Button</span> <span>@click</span><span><span>=</span><span>"</span>closeModal<span>"</span></span><span>&gt;</span></span>
        Close
      <span><span><span>&lt;/</span>Button</span><span>&gt;</span></span>
    <span><span><span>&lt;/</span>slot</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>template</span><span>&gt;</span></span></pre>
<p>This is a fairly simple example of Extension, but we already have several options for extending this component:</p>
<ol>
<li>Just override the <code>default</code> slot to add in our content</li>
<li>Add in content but also override the <code>header</code> slot</li>
<li>Content and just the <code>footer</code> slot to add different buttons</li>
<li>Content and both <code>header</code> and <code>footer</code> slots for something more custom</li>
</ol>
<p>(We <em>could</em> add more if we didn't use the <code>default</code> slot, but that's unlikely here)</p>
<p>You don't have to extend the behaviour of this component, or you can extend parts of it. Either way, you get a lot of flexibility and a lot of code reuse.</p>
<h2 id="6-nesting">6. Nesting</h2>
<p>We'll take Extension to it's conclusion by passing these extension points through one or more layers of components.</p>
<p>It may sound crazy at first, but it's extremely useful, especially in medium to large applications.</p>
<p>You start with a base component that's fairly general in what it does. The next component is a little more specific, extending the base component in a few ways. Then on and on until you have the final component that does the real work.</p>
<p>It's exactly how we go from a very general <code>Animal</code> to a more specific <code>Mammal</code> and then <code>Dog</code> and eventually land on a <code>Poodle</code>. If all we need is a <code>Poodle</code> component, we're wasting our time here, but in large applications we need lots of variations on the same basic idea.</p>
<p>We can extend the <code>Dog</code> component to get a <code>Corgi</code> and a <code>Beagle</code> component. Or extend the <code>Mammal</code> component to get a <code>Cat</code> component, which lets us then add in <code>Tiger</code> and <code>Lion</code> components.</p>
<p>This is the most advanced application of reusability that I have come across. I use this technique <em>a lot</em> in my own work.</p>
<h2 id="conclusion">Conclusion</h2>
<p>These are the 6 levels of reusability that I've come across.</p>
<p>I might have missed some, and I certainly wouldn't say that this is an exhaustive list, but it's complete enough to be useful.</p>
<p>A short article like this doesn't do them justice, but I go into them in much more depth in my upcoming course, <a href="https://michaelnthiessen.com/reusable-components">Reusable Components</a>.</p>
<p>Subscribe to my email list in order to get weekly updates and previews of the course!</p>
</div></div>]]>
            </description>
            <link>https://michaelnthiessen.com/6-levels-of-reusability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652929</guid>
            <pubDate>Fri, 26 Jun 2020 15:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Celebrating Pride 2020: Stories of LGBTQ+ community members impacting tech]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23652872">thread link</a>) | @Dwolb
<br/>
June 26, 2020 | https://www.hologram.io/blog/celebrating-pride-2020 | <a href="https://web.archive.org/web/*/https://www.hologram.io/blog/celebrating-pride-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Hologram is proud to be part of the digital celebration of Pride this year!</p><p>We're taking this time to highlight the amazing members of the LGBTQ+ community who are part of the IoT, telecommunications, and technology industries. </p><p>As an out gay man, I always look forward to Pride month. This year, I'm excited to use the Hologram platform to highlight the incredible work done by members of the queer community. Hologram Operator editor Tricia Booker has profiled members of the queer community, including engineers, entrepreneurs, and founders who are tackling problems from equity and access to inclusion and trust around the world.<br></p><h2>Meet Ashleigh Wilson</h2><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-ashleigh-wilson-changed-directions-from-corporate-climbing-to-lifting-people-up">Ashleigh</a> founded&nbsp;<a target="_blank" href="https://auditmate.com/">AuditMate</a>&nbsp;— a platform designed to help commercial building owners advocate for themselves and simplify the complexity of elevator regulation. She's leading the charge in changing the way this legacy industry operates and treats people inside and outside their organizations.&nbsp;</p><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-ashleigh-wilson-changed-directions-from-corporate-climbing-to-lifting-people-up">Read about Ashleigh Wilson →</a><br></p><h2>Meet Johann Moonesinghe</h2><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-johann-moonesinghe-uses-a-love-for-food-tech-to-invest-in-new-culinary-ventures">Johann</a> is the founder of&nbsp;<a target="_blank" href="https://inkind.com/">inKind</a>. He's using technology to think beyond the credit score to invest in nontraditional culinary startups. He's leading a rethink of how restaurant financing works and helping underwrite award-winning eateries that would have never attained funding through traditional channels.&nbsp;</p><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-johann-moonesinghe-uses-a-love-for-food-tech-to-invest-in-new-culinary-ventures">Read about Johann Moonesinghe →</a></p><h2>Meet Brandy Jackson<br></h2><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-brandy-jackson-helps-underserved-paitenets-get-access-to-great-healthcare">Brandy</a> is a Navy veteran and engineering manager at&nbsp;<a target="_blank" href="https://www.caremessage.org/">CareMessage</a>. She's building a platform that helps underserved communities across the United States access vital health care service. Using servant leadership, she models a diverse culture that ensures employees can bring their whole selves to work each day.</p><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-brandy-jackson-helps-underserved-paitenets-get-access-to-great-healthcare">Read about Brandy Jackson →</a><br></p><h2>Meet Eugene Nadyrshin</h2><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-eugene-nadyrshin-is-designing-the-next-generation-of-ppe">Eugene</a> is a startup advisor for Y-Combinator's Startup School and founder of&nbsp;<a target="_blank" href="https://remaskd.com/">ReMaskD</a>. He's worked in a diverse set of fields, including IoT — building an air quality network across Europe. At ReMaskD, Eugene uses AI to construct custom-fitting personal protective equipment that limits the headaches and facial bruising medical professionals have endured. Eugene is also a member of&nbsp;<a target="_blank" href="https://startout.org/">StartOut</a>, helping increase the number of LGBTQ+ startup founders.&nbsp;<br></p><p><a href="https://www.hologram.io/blog/pride-spotlight-see-how-eugene-nadyrshin-is-designing-the-next-generation-of-ppe">Read about Eugene Nadyrshin →</a></p><p>‍</p><p>I'm incredibly proud of this fantastic, fabulous, and diverse LGBTQ+ community, and so grateful to be a part of it. I'm also grateful for the ongoing support and encouragement we've received both as a community and as individuals. Together, we are changing the way the world works.</p></div></div></div>]]>
            </description>
            <link>https://www.hologram.io/blog/celebrating-pride-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652872</guid>
            <pubDate>Fri, 26 Jun 2020 15:12:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardcoded secrets, unverified tokens, and other common JWT mistakes]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 81 (<a href="https://news.ycombinator.com/item?id=23652815">thread link</a>) | @todsacerdoti
<br/>
June 26, 2020 | https://r2c.dev/blog/2020/hardcoded-secrets-unverified-tokens-and-other-common-jwt-mistakes/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/hardcoded-secrets-unverified-tokens-and-other-common-jwt-mistakes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>JWT (JSON Web Token) is an open standard (<a href="https://tools.ietf.org/html/rfc7519" target="_blank" rel="noopener">RFC 7519)</a> that defines a way to provide information within a JSON object between two parties. This standard is intended to help transmit information securely, but no standard or technology will protect you when used improperly.</p>
<p>To identify what can go wrong when using JWT in Node.js, I performed a security review on <a href="https://www.npmjs.com/" target="_blank" rel="noopener">npm</a> modules that use the most popular JWT libraries. Using static analysis tooling, I examined 2,000 npm modules for security weaknesses and vulnerabilities. This post summarizes some common mistakes that were found during my research, including:</p>
<ul>
<li>Hardcoded secrets</li>
<li>Allowing the <code>none</code> algorithm for signing</li>
<li>Missing or incorrect token validation</li>
<li>Sensitive data exposure</li>
</ul>
<p>In addition to describing these issues so you can avoid them, this post includes open source rules that make it easier to either manually audit your code bases to detect them, or include in CI so these vulnerabilities never get merged into your code in the first place.</p>
<h2>Hardcoded secrets</h2>
<p>The most basic mistake is using hardcoded secrets for JWT generation/verification. This allows an attacker to forge the token if the source code (and JWT secret in it) is publicly exposed or leaked.</p>
<p>Not only does this introduce a vulnerability, it’s also considered a software anti-pattern. You should keep your JWT secrets apart from your code, for example, in separate configuration files or environment variables.</p>
<div data-language="javascript"><pre><code><span>const</span> jwt <span>=</span> <span>require</span><span>(</span><span>"jsonwebtoken"</span><span>)</span><span>;</span>
<span>const</span> secret <span>=</span> <span>"hardcoded-secret-here"</span><span>;</span> 

<span>class</span> <span>JwtAuthentication</span> <span>{</span>
  <span>static</span> <span>sign</span><span>(</span><span>obj</span><span>)</span> <span>{</span>
    <span>return</span> jwt<span>.</span><span>sign</span><span>(</span>obj<span>,</span> secret<span>,</span> <span>{</span><span>}</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span></code></pre></div>
<p>It’s worth mentioning that a popular way to use JWTs is within other libraries, e.g., through <a href="http://www.passportjs.org/packages/passport-jwt/" target="_blank" rel="noopener">Passport</a>, a popular authentication middleware for Node.js.</p>
<div data-language="javascript"><pre><code><span>var</span> JwtStrategy <span>=</span> <span>require</span><span>(</span><span>'passport-jwt'</span><span>)</span><span>.</span>Strategy<span>,</span>
    ExtractJwt <span>=</span> <span>require</span><span>(</span><span>'passport-jwt'</span><span>)</span><span>.</span>ExtractJwt<span>;</span>

<span>var</span> opts <span>=</span> <span>{</span>
    secretOrKey<span>:</span><span>'hardcoded-secret-here'</span><span>;</span> 
<span>}</span>

passport<span>.</span><span>use</span><span>(</span><span>new</span> <span>JwtStrategy</span><span>(</span>opts<span>,</span> <span>function</span><span>(</span><span>jwt_payload<span>,</span> done</span><span>)</span> <span>{</span>
    
<span>}</span><span>)</span><span>)</span><span>;</span></code></pre></div>
<p>Even though this is a known and quite obvious issue, it’s still common to use hardcoded secrets while developing and then accidentally leave it in your codebase. Fortunately, it’s also very easy to find hardcoded secrets with SAST tools, especially with <a href="https://semgrep.live/" target="_blank" rel="noopener">Semgrep</a>, which helps to find complex code patterns with rules that are very simple to write.
Rules for detecting hardcoded secrets:</p>
<p><a href="https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.jwt-hardcode" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.jwt-hardcode</a></p>
<p><a href="https://semgrep.live/editor?registry=javascript.passport-jwt.security.passport-hardcode" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.passport-jwt.security.passport-hardcode</a></p>
<p><a href="https://semgrep.live/editor?registry=javascript.express.security.express-jwt-hardcoded-secret" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.express.security.express-jwt-hardcoded-secret</a></p>
<h2>Allowing 'none' algorithm for signing</h2>
<p>Allowing tokens to have the 'none' algorithm was <a href="https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/#Meet-the%E2%80%94None%E2%80%94Algorithm" target="_blank" rel="noopener">a critical vulnerability</a> some years ago. Nowadays, most popular JWT libraries do not allow decoding or verifying tokens with the None algorithm without explicitly enabling it. The same as with hardcoded secrets, it’s easy to leave ‘'none'` in your codebase after testing or debugging.</p>
<div data-language="javascript"><pre><code><span>let</span> jwt <span>=</span> <span>require</span><span>(</span><span>"jsonwebtoken"</span><span>)</span><span>;</span>
<span>let</span> secret <span>=</span> <span>"some-secret"</span><span>;</span>
jwt<span>.</span><span>verify</span><span>(</span><span>"token-here"</span><span>,</span> secret<span>,</span> <span>{</span> algorithms<span>:</span> <span>[</span><span>"RS256"</span><span>,</span> <span>"none"</span><span>]</span> <span>}</span><span>)</span><span>;</span> </code></pre></div>
<p>Anyway, if you forget to remove it after messing with code, it’s also very easy to catch it with Semgrep.
Rules for detecting ‘none’ algorithm allowed in your code:</p>
<p><a href="https://semgrep.live/editor?registry=javascript.jose.security.jwt-none-alg" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jose.security.jwt-none-alg</a></p>
<p><a href="https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.jwt-none-alg" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.jwt-none-alg</a></p>
<h2>Not verifying tokens the right way</h2>
<p>Sometimes developers rely on their methods of token verification instead of using built-in API, or omit verification completely.
Small wonder that usually it introduces the opportunity for attackers to forge information inside the token.</p>
<div data-language="javascript"><pre><code><span>const</span> jwt <span>=</span> <span>require</span><span>(</span><span>"jsonwebtoken"</span><span>)</span><span>;</span>

<span>const</span> <span>checkToken</span> <span>=</span> <span>(</span><span>token<span>,</span> refreshToken<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span>jwt<span>.</span><span>verify</span><span>(</span>refreshToken<span>,</span> key<span>)</span><span>)</span> <span>{</span>
    
    <span>return</span> jwt<span>.</span><span>decode</span><span>(</span>token<span>)</span><span>.</span>param <span>===</span> jwt<span>.</span><span>decode</span><span>(</span>refreshToken<span>)</span><span>.</span>param<span>;</span>
  <span>}</span>
  <span>return</span> <span>false</span><span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>Note: only <code>refreshToken</code> is verified in the example above, which gives an opportunity to attacker to manipulate function results. By changing value of <code>param</code> property stored inside <code>token</code> an attacker can force the result of <code>checkToken</code> function to be <code>true</code> and pass the verification.</p>
<p>On top of that, it’s very typical to get certain data from tokens before verifying it (issue date, id, etc.) and then use it as a verification context. Usually it’s harmless, but only if this data does not go any further. If the information from an unverified token is passed to other parts of the code it may introduce a vulnerability.</p>
<div data-language="javascript"><pre><code>
<span>const</span> jwt <span>=</span> <span>require</span><span>(</span><span>"jsonwebtoken"</span><span>)</span><span>;</span>
<span>function</span> <span>checkToken</span><span>(</span><span>token</span><span>)</span> <span>{</span>
  <span>const</span> issuer <span>=</span> jwt<span>.</span><span>decode</span><span>(</span>token<span>)</span><span>.</span>issuer<span>;</span>
  <span>if</span> <span>(</span><span>findIssuer</span><span>(</span>issuer<span>)</span> <span>&amp;&amp;</span> jwt<span>.</span><span>verify</span><span>(</span>token<span>,</span> key<span>)</span><span>)</span> <span>{</span>
    
  <span>}</span> <span>else</span> <span>{</span>
    <span>throw</span> <span>new</span> <span>Error</span><span>(</span><span>"not valid token"</span><span>)</span><span>;</span>
  <span>}</span>
<span>}</span>


<span>function</span> <span>findIssuer</span><span>(</span><span>iss</span><span>)</span> <span>{</span>
  
  database<span>.</span><span>find</span><span>(</span>iss<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>(In the example above, the unverified <code>issuer</code> value is passed to another function before validating the token (<a href="https://owasp.org/www-project-top-ten/OWASP_Top_Ten_2017/Top_10-2017_A1-Injection" target="_blank" rel="noopener">https://owasp.org/www-project-top-ten/OWASP_Top_Ten_2017/Top_10-2017_A1-Injection</a>). If not used carefully it may end up in different kinds of injection vulnerabilities, especially if located in separate parts of the codebase.)</p>
<p>Also do not forget that even if a token is verified properly, the data stored in it should be treated as user input and be validated and sanitized according to the context.</p>
<p>Rule that helps identify lack of token verification:</p>
<p><a href="https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.audit.jwt-decode-without-verify" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.audit.jwt-decode-without-verify</a></p>
<h2>Sensitive data exposure</h2>
<p>When an object is converted to a JWT token without explicitly breaking it down into parts, it’s very easy to lose control of what is inside the object and disclose some sensitive information.</p>
<p>This is a very widespread mistake while using ORM libraries like Mongoose, Sequelize, etc. ORM models do not include any sensitive data at the moment of creation, but when the situation changes it is very easy to forget that the ORM object is also passed to JWT token.</p>
<div data-language="javascript"><pre><code>
<span>const</span> mongoose <span>=</span> <span>require</span><span>(</span><span>'mongoose'</span><span>)</span><span>,</span>
Schema <span>=</span> mongoose<span>.</span>Schema<span>;</span>

<span>const</span> schema <span>=</span> <span>new</span> <span>Schema</span><span>(</span><span>{</span>
    name<span>:</span> String<span>,</span>
    password<span>:</span> String<span>,</span>
    admin<span>:</span> Boolean
<span>}</span><span>)</span><span>;</span>

<span>const</span> User <span>=</span> mongoose<span>.</span><span>model</span><span>(</span><span>'LocalUser'</span><span>,</span> schema<span>)</span><span>;</span>


router<span>.</span><span>post</span><span>(</span><span>'/signin'</span><span>,</span> <span>(</span><span>req<span>,</span>res</span><span>)</span> <span>=&gt;</span> <span>{</span>

User<span>.</span><span>findOne</span><span>(</span><span>{</span>name<span>:</span> req<span>.</span>body<span>.</span>name<span>}</span><span>,</span> <span>function</span><span>(</span><span>err<span>,</span> user</span><span>)</span><span>{</span>
    <span>var</span> token <span>=</span> jwt<span>.</span><span>sign</span><span>(</span>user<span>,</span> key<span>,</span> <span>{</span>expiresIn<span>:</span> <span>60</span><span>*</span><span>60</span><span>*</span><span>10</span><span>}</span><span>)</span><span>;</span> 
    res<span>.</span><span>json</span><span>(</span><span>{</span>
        success<span>:</span> <span>true</span><span>,</span>
        message<span>:</span> <span>'Enjoy your token!'</span><span>,</span>
        token<span>:</span> token
    <span>}</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span>

<span>}</span></code></pre></div>
<p>Needless to say, you should not keep sensitive data in JWT token intentionally.</p>
<p>Helpful Semgrep rules:</p>
<p><a href="https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.audit.jwt-exposed-data" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.audit.jwt-exposed-data</a></p>
<p><a href="https://semgrep.live/editor?registry=javascript.jose.security.jwt-exposed-credentials" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jose.security.jwt-exposed-credentials</a></p>
<p><a href="https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.jwt-exposed-credentials" target="_blank" rel="noopener">https://semgrep.live/editor?registry=javascript.jsonwebtoken.security.jwt-exposed-credentials</a></p>
<p>These are the most common mistakes developers make when using JWT in their Node.js projects. Stay secure and don’t forget to automate security scans in your codebase.</p>
<h2>Resources</h2>
<ul>
<li>Publicly disclosed report that was found during research (more coming soon):
<a href="https://hackerone.com/reports/748214" target="_blank" rel="noopener">https://hackerone.com/reports/748214</a></li>
</ul>
<p>More insight on JWT security and best practices:</p>
<ul>
<li><a href="https://auth0.com/blog/critical-vulnerabilities-in-json-web-token-libraries/" target="_blank" rel="noopener">Autho0: Critical vulnerabilities in JSON Web Token libraries</a></li>
<li><a href="https://www.rfc-editor.org/rfc/rfc8725.html" target="_blank" rel="noopener">RFC 8725: JSON Web Token Best Current Practices</a></li>
<li><a href="https://github.com/ticarpi/jwt_tool" target="_blank" rel="noopener">jwt_tool</a></li>
<li><a href="https://www.slideshare.net/snyff/jwt-jku-x5u" target="_blank" rel="noopener">JWT: jku x5u</a> - NahamCon 2020 talk by <a href="https://twitter.com/snyff" target="_blank" rel="noopener">Louis Nyffenegger</a></li>
<li><a href="https://www.youtube.com/watch?v=zWVRHK3ykfo" target="_blank" rel="noopener">JWT Parkour</a> - AppSec California 2020 talk by <a href="https://twitter.com/snyff" target="_blank" rel="noopener">Louis Nyffenegger</a></li>
<li><a href="https://www.youtube.com/watch?v=M3jA0bGDCso" target="_blank" rel="noopener">Are You Properly Using JWTs? </a> - AppSec California 2020 talk by <a href="http://twitter.com/apisecurityio" target="_blank" rel="noopener">Dmitry Sotnikov</a></li>
<li>More Semgrep rules: <a href="https://semgrep.live/r" target="_blank" rel="noopener">https://semgrep.live/r</a></li>
</ul></div></div></div></section></div>]]>
            </description>
            <link>https://r2c.dev/blog/2020/hardcoded-secrets-unverified-tokens-and-other-common-jwt-mistakes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652815</guid>
            <pubDate>Fri, 26 Jun 2020 15:08:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Macs and Virtualization: It's going to be great]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 83 (<a href="https://news.ycombinator.com/item?id=23652643">thread link</a>) | @mlillustrated
<br/>
June 26, 2020 | http://www.ml-illustrated.com/2020/06/25/ARM-Macs-virtualization-different-take.html | <a href="https://web.archive.org/web/*/http://www.ml-illustrated.com/2020/06/25/ARM-Macs-virtualization-different-take.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The transition from Intel to Apple Silicon Macs is a huge deal, but some are
lamenting this shift as a loss to developers, especially those who rely on
virtualization such as Docker. The concern is that under x86 emulation instead
of hypervisor, the performance hit could be significant.</p>

<p>As the case may be, my take is the issue wouldn’t be that serious, while the
upside for developers is huge, especially for those who primarily develop
for Apple’s ecosystem. And if my hunch is correct, that ecosystem will expand
to server-side soon enough. Let me explain.</p>

<p>Just to be clear, I’m a huge fan of Docker, and I’m a ML practitioner working
primarily on server-side within Linux, so I’m very familiar with the importance
of the development machines being consistent as server-side. Funnily enough,
I’d say this is the biggest rationale for Apple going ARM for Macs, which is to make
the development environment <em>exactly the same</em> as their deployment targets, namely
iOS, iPadOS, Apple Watch, Apple TV, and soon, MacOS.</p>

<p>That is to say, the current situation is that Xcode development is done on x86,
emulated in x86 simulators, and re-built for ARM for device deployment.
This has been the
state since the first iPhone and Apple has done a superb job maintaining the
seamlessness of this process ever since (as far as I know),
but more edge cases are beginning to crop up.</p>

<h3 id="edge-case-or-tentpole">Edge Case or Tentpole?</h3>

<p>From my narrow view of ML, the one I experience is the lack of emulation of
Apple’s Neural Engine (ANE) for accelerating model inferencing. Once a model
is compiled to Core ML, the emulator would execute the model on CPU and possibly
GPU, but its behavior is different on device when offloaded
to ANE. It’s not only a performance difference, but also floating point
differences and possibly quantization nuances.</p>

<p>What this means is to truly test a ML model’s behavior on Apple devices, one
has to deploy to actual devices, likely via a cable to enable debugging. As you
guessed it, this also means that you’d have to have multiple physical devices
if one is to test against different models. Multiply this with different iOS
versions to test against, it quickly gets out of hand. If Apple wants to
(and likely plans to) add more custom hardware, the situation is untenable
for both Apple and its developers.</p>

<h3 id="virtualized-apples">Virtualized Apples?</h3>

<p>With ARM (and other custom silicon) on the development machines,
we already know iOS apps will run
natively so there’s no need for emulators. I wouldn’t be surprised if these
apps are running within individual virtualized instances, to as closely as
possible create the same behavior as actual devices. Apple could go as far
as virtualize the hardware resources and capabilities so performance would
be emulated faithfully also, greatly simplifying the
development, testing, and debugging process for developers.</p>

<p>For ANE, this switch will be huge. People have had to deal with “numerical
differences” when running ML models on CPU compared to ANE, a process that
is slow to debug via tethered devices.
With the Mac having the same hardware as the target devices,
there’s consistency and no hidden surprises.
Whenever the development cycle is shortened and
opaque differences removed, it’s a good thing.</p>

<p>What about the downside of Docker becoming 2 to 5x slower without hypervisor?
While that is indeed a downside, I’d argue that for local Docker instances,
they are better used for functional testing and not part of
the core development cycle.
Coming from the Python world, I have had no problems developing software in native OS
and only use local Docker for validation prior to deployment. The other main
use case for Docker of bringing up server clusters locally would be slower, but again, shouldn’t be core
part of the development cycle. There’s always the option for remote Docker or
even better, deploy to sandbox and integration environments for testing.</p>

<h3 id="armed-cloud">ARMed Cloud?</h3>

<p>That brings me to the last point about the ARM transition for Macs, which is
the aspect of developing for server-side, not an area of focus for Apple.
However, if Docker and virtualization needs are primarily for server-side
development, and to be consistent of being consistent, the problem of x86
emulation can be dealt with if Apple offers ARM-based cloud servers. Having this
uniformity would truly enable developers to write code on their ARM Macs,
test across devices locally, and deploy to iOS devices and server-side, all from one code base,
without translation, emulation, or hidden gotchas. Pretty sweet landscape for
Apple developers if you ask me.</p>

<h3 id="closing">Closing</h3>

<p>Ever since I bought my Titanium MacBook Pro many years ago, I have been a fan
of Apple’s combination of software and hardware, but more importantly, its
long term approach to their product developments. This ARM Mac transition
has been long in the making, and I, for one, am excited again to buy an
ARM MacBook and the future it’d usher in.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>http://www.ml-illustrated.com/2020/06/25/ARM-Macs-virtualization-different-take.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652643</guid>
            <pubDate>Fri, 26 Jun 2020 14:55:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why are CEOs failing software engineers?]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23652598">thread link</a>) | @elorant
<br/>
June 26, 2020 | https://iism.org/article/why-are-ceos-failing-software-engineers-56 | <a href="https://web.archive.org/web/*/https://iism.org/article/why-are-ceos-failing-software-engineers-56">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://iism.org/article/why-are-ceos-failing-software-engineers-56</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652598</guid>
            <pubDate>Fri, 26 Jun 2020 14:50:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Carving out a niche as a small artist on Spotify]]>
            </title>
            <description>
<![CDATA[
Score 380 | Comments 267 (<a href="https://news.ycombinator.com/item?id=23652545">thread link</a>) | @imartin2k
<br/>
June 26, 2020 | https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg | <a href="https://web.archive.org/web/*/https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5ef5dad9c1c000530253b9bf" data-item-id="5ef5dad9c1c000530253b9bf">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1593170960338" id="item-5ef5dad9c1c000530253b9bf"><div><div><div data-block-type="2" id="block-951a4eb12d4604fa593a"><div><p>I'm making over $800 per month with my music— almost exclusively through Spotify. This is up from <a href="https://www.stevebenjamins.com/blog/spotify-and-discover-weekly">$400 per month</a> last year.   </p><p>I don't tour, I don't sell merch and I'm not on a major label. I'm just a small indie artist making music in my evenings— and Spotify is making that possible. </p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1593170550434_54819"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593170748322-P5RY1O7VWJM9MIUCOI2F/ke17ZwdGBToddI8pDm48kMWB_b-n6a50YzIZsjMYkmt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nHIEvVYSINmwchg1DeZrsBIoPZ3Gfj_FVJugF-nGL6izxVTmLKDD-oSa7oHWTxBOw/Earnings+Chart.png" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593170748322-P5RY1O7VWJM9MIUCOI2F/ke17ZwdGBToddI8pDm48kMWB_b-n6a50YzIZsjMYkmt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nHIEvVYSINmwchg1DeZrsBIoPZ3Gfj_FVJugF-nGL6izxVTmLKDD-oSa7oHWTxBOw/Earnings+Chart.png" data-image-dimensions="2500x1085" data-image-focal-point="0.5,0.5" alt="Earnings Chart.png" data-load="false" data-image-id="5ef5db3b8575ee1ad665d981" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593170748322-P5RY1O7VWJM9MIUCOI2F/ke17ZwdGBToddI8pDm48kMWB_b-n6a50YzIZsjMYkmt7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0nHIEvVYSINmwchg1DeZrsBIoPZ3Gfj_FVJugF-nGL6izxVTmLKDD-oSa7oHWTxBOw/Earnings+Chart.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593170550434_55119"><div><p>I’ve been releasing music on the internet since 2013 and it’s crazy how much music has changed since then. Here’s what I’ve learned about where music is at in 2020 and how it’s possible to carve out a niche as a small artist.    </p><h3>1. Spotify Is The Streaming Service That Matters</h3><p>In terms of music streaming market share, Spotify is Google and Apple Music is Bing. At least, that’s what I see in my stats:</p><p>I get about 177,000 plays / month. <strong>Spotify is 96% of those plays. </strong></p><p>I earn around $800 / month from music streaming. <strong>Spotify is 93% of that income. </strong></p></div></div><div data-aspect-ratio="49.95918367346939" data-block-type="5" id="block-eb72151a66d662f8af68"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592916283663-0UYU3X1SDZU5IEDBVVRU/ke17ZwdGBToddI8pDm48kHP34hgIrqdksCH8TYvFigB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0jG2lbcDYBOeMi4OFSYem8C2mvP1fRqxz_kej_mjMmx3K3LA91PMAqEFB2wYydnw4g/Streaming-Bar-Graph.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592916283663-0UYU3X1SDZU5IEDBVVRU/ke17ZwdGBToddI8pDm48kHP34hgIrqdksCH8TYvFigB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0jG2lbcDYBOeMi4OFSYem8C2mvP1fRqxz_kej_mjMmx3K3LA91PMAqEFB2wYydnw4g/Streaming-Bar-Graph.jpg" data-image-dimensions="2500x1248" data-image-focal-point="0.5,0.5" alt="Streaming-Bar-Graph.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9ae" data-type="image" src="https://www.stevebenjamins.com/blog/Streaming-Bar-Graph.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1593170550434_61183"><div><h3>2. Algorithmic Playlists (Like <em>Discover Weekly</em>) Are Enormously Important</h3><p><strong>Every Monday my music gets a spike in streams on Spotify</strong>. You could set a watch to it— it’s that consistent: </p></div></div><div data-block-type="5" id="block-06dcac609bc1a10bb8d0"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592919512085-FCR4VZMBTDSZEIYU2GUK/ke17ZwdGBToddI8pDm48kIKogUPb2YHTlnaztcmfVcIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnPD4rrHbC4KeGHcLT21XLDVbdTUj-MuZl2cMhGeQFdSzaAYFqs-j32vOCypc5QMhBw/Daily-Spotify-Streams.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592919512085-FCR4VZMBTDSZEIYU2GUK/ke17ZwdGBToddI8pDm48kIKogUPb2YHTlnaztcmfVcIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnPD4rrHbC4KeGHcLT21XLDVbdTUj-MuZl2cMhGeQFdSzaAYFqs-j32vOCypc5QMhBw/Daily-Spotify-Streams.jpg" data-image-dimensions="2500x976" data-image-focal-point="0.5,0.5" alt="Daily-Spotify-Streams.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b99f" data-type="image" src="https://www.stevebenjamins.com/blog/Daily-Spotify-Streams.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-f845b5a6a792d5434442"><div><p>What makes Monday so special? </p><p>Well every Monday Spotify sends out a new <em>Discover Weekly</em> playlist. Discover Weekly is an <em>algorithmic</em> playlist— which means its personalized with songs <em>Spotify</em> thinks the user would like.</p><p>Discover Weekly is massively popular and it’s the reason for those Monday spikes in my streams.  </p></div></div><div data-block-type="5" id="block-4a776c4d7eb7e02d2365"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592999085261-APZRZMG2J7AOH4BO6B2E/ke17ZwdGBToddI8pDm48kJN0G_F3WP6my7lOVI5MswB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZp4hhut_HaIerbk5pFZ8oSyrnRibAambjs2gnBi-UefkvjJh3JJWsjdMZ66YIxKAg/discover-weekly.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592999085261-APZRZMG2J7AOH4BO6B2E/ke17ZwdGBToddI8pDm48kJN0G_F3WP6my7lOVI5MswB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZp4hhut_HaIerbk5pFZ8oSyrnRibAambjs2gnBi-UefkvjJh3JJWsjdMZ66YIxKAg/discover-weekly.jpg" data-image-dimensions="2362x1498" data-image-focal-point="0.5,0.5" alt="This is what Discover Weekly looks like" data-load="false" data-image-id="5ef5dad9c1c000530253b9a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592999085261-APZRZMG2J7AOH4BO6B2E/ke17ZwdGBToddI8pDm48kJN0G_F3WP6my7lOVI5MswB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UZp4hhut_HaIerbk5pFZ8oSyrnRibAambjs2gnBi-UefkvjJh3JJWsjdMZ66YIxKAg/discover-weekly.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>This is what Discover Weekly looks like</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-d485b2d78d765ad48976"><div><p>Discover Weekly might not seem like much— after all, it looks like just another playlist— but its effect on streaming numbers is <em>enormous</em>. </p><p>And the effect of Discover Weekly isn’t limited to small, obscure artists like me— the same spikes are  visible in famous artists too: </p></div></div><div data-block-type="5" id="block-ba6f929a7737ac5cf3aa"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920721420-SCE25GI5ZRSZD13FC5YU/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Coldplay.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920721420-SCE25GI5ZRSZD13FC5YU/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Coldplay.jpg" data-image-dimensions="2500x982" data-image-focal-point="0.5,0.5" alt="Coldplay.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9a5" data-type="image" src="https://www.stevebenjamins.com/blog/Coldplay.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-c576bcb5ad79ca58f7c2"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920734163-YDS79BET4FF7MXH3GTXY/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Beyonce.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920734163-YDS79BET4FF7MXH3GTXY/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Beyonce.jpg" data-image-dimensions="2500x982" data-image-focal-point="0.5,0.5" alt="Beyonce.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9a8" data-type="image" src="https://www.stevebenjamins.com/blog/Beyonce.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-2703bf19dcbad1ce9d12"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920755190-CMSVZPPO7TM4NHYONU59/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Rihanna.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1592920755190-CMSVZPPO7TM4NHYONU59/ke17ZwdGBToddI8pDm48kD3m4u8nI0SgVTwfGWCKndoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYwL8IeDg6_3B-BRuF4nNrNcQkVuAT7tdErd0wQFEGFSnO7bu0kpYlCm0fzLGoiwLJTCHsT-6enuziktTU2MNXtHVB6mY_V2xBKRzGpHlGMZGw/Rihanna.jpg" data-image-dimensions="2500x982" data-image-focal-point="0.5,0.5" alt="Rihanna.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9ab" data-type="image" src="https://www.stevebenjamins.com/blog/Rihanna.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-f9c72d34909bce94a17f"><div><p>This is <em>CRAZY</em>. </p><p>No other promotional tactic in music comes close to Discover Weekly in delivering new listeners in such a low-effort, high volume way. </p><p>Back in 2013 I would spend hours cold-emailing bloggers. I would be lucky if I got a hit and got 1,000 plays on one of my songs. It was labour intensive. </p><p>Now algorithmic playlists like Discover Weekly send 1,000 new listeners every week without any work on my part. This is amazing. Cold outreach sucks. It sucks for the artist and it sucks for the bloggers. Spotify deserves a lot of credit for here. </p><h3>3. Songs Matter, Not Albums</h3><p>Spotify's algorithmic playlists rank songs— not albums. It's just like in SEO: Google indexes pages, not websites. </p><p>This has elevated the importance of songs and made albums more irrelevant than ever— especially for small artists like me. (Of course famous artists like Drake and Billie Eilish can still get massive press from an album release— but most artists are not at that level of fame.)</p><p>These days it’s almost always better to release individual songs rather than albums. (Plus as an artist, you’re limited to pitching one song at a time to Spotify’s human editors— and I’ll explain why human editors still matter in the next section). </p></div></div><div data-block-type="5" id="block-3d45ff76650d47ec036b"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088518969-V2ZSGRTIPC70DQU6DTY2/ke17ZwdGBToddI8pDm48kO97cLu6upMnNovRR-E7bzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmbqkB0ZqjW5-e8O_uKcAuR8BQQi9T61LWwD7i0-QXfMoRwB-dUGsSquCnVTFQcaRg/stagger.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088518969-V2ZSGRTIPC70DQU6DTY2/ke17ZwdGBToddI8pDm48kO97cLu6upMnNovRR-E7bzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmbqkB0ZqjW5-e8O_uKcAuR8BQQi9T61LWwD7i0-QXfMoRwB-dUGsSquCnVTFQcaRg/stagger.jpg" data-image-dimensions="1574x639" data-image-focal-point="0.5,0.5" alt="A 12-song album is better off being released as 12 staggered singles throughout the year." data-load="false" data-image-id="5ef5dad9c1c000530253b9b1" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088518969-V2ZSGRTIPC70DQU6DTY2/ke17ZwdGBToddI8pDm48kO97cLu6upMnNovRR-E7bzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dmbqkB0ZqjW5-e8O_uKcAuR8BQQi9T61LWwD7i0-QXfMoRwB-dUGsSquCnVTFQcaRg/stagger.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>A 12-song album is better off being released as 12 staggered singles throughout the year.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-22e1940a7b25c119a57a"><div><p>I get why the growing irrelevance of albums bums some people out. Albums are big statements. Some of the most iconic releases in popular music have been albums. </p><p>… But things change and that’s okay. Plus I think asking listeners to listen to a full-length album don’t make sense in our attention-starved world. Asking listeners to listen to a single song might just be a more realistic ask. </p><h3>4. Human Editors Still Matter— Just Not How You Think</h3><p>The secret to getting your music on algorithmic playlists like Discover Weekly is to get on <em>human</em> playlists first. </p><p>It’s similar to SEO: playlists are like backlinks. When a song is added to a playlist it's a vote for the quality of the song. Not every playlist is equally authoritative though— just like how a link from The NY Times is more authoritative than other links in SEO.  </p><p>On Spotify, the most authoritative playlists are <em>editorial</em> playlists. These are  playlists curated by official Spotify editors. <strong>In my experience, it’s only when I get on an editorial playlist that my songs get heavily featured on algorithmic playlists like Discover Weekly.</strong></p></div></div><div data-block-type="5" id="block-d2618bdb9eb6fca6fb0b"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088707091-NCYBLFD641ENREFXBUZL/ke17ZwdGBToddI8pDm48kP049tvC-D_OFvuLSxtdDE0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds5RHc3yZvuk382KqaWk56FRKl7OH-Mh-dlRKY4AnQFFCjLISwBs8eEdxAxTptZAUg/editor-playlists.png" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088707091-NCYBLFD641ENREFXBUZL/ke17ZwdGBToddI8pDm48kP049tvC-D_OFvuLSxtdDE0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds5RHc3yZvuk382KqaWk56FRKl7OH-Mh-dlRKY4AnQFFCjLISwBs8eEdxAxTptZAUg/editor-playlists.png" data-image-dimensions="1884x738" data-image-focal-point="0.5,0.5" alt="Official Spotify editorial playlists have this icons in the top left." data-load="false" data-image-id="5ef5dad9c1c000530253b9b4" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593088707091-NCYBLFD641ENREFXBUZL/ke17ZwdGBToddI8pDm48kP049tvC-D_OFvuLSxtdDE0UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2ds5RHc3yZvuk382KqaWk56FRKl7OH-Mh-dlRKY4AnQFFCjLISwBs8eEdxAxTptZAUg/editor-playlists.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Official Spotify editorial playlists have this icons in the top left.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-811f68956e11c14d5a36"><div><p>So how do you get on editorial playlists? I sincerely have no clue. I've been on editorial playlists 16 times but I have no idea how to replicate that.  </p><p><em>Note: In my experience, major label artists have an easier time getting on editorial playlists. This is discouraging— if major label artists have an easier time getting on editorial playlists, they’ll also get better placement in algorithmic playlists… But major label artists also only typically get 13% - 20% of streaming royalties… so there are still plenty of reasons to stay indie! </em></p><h3>5. Algorithms Make For Looser Relationships Between Artists And Listeners</h3><blockquote><p><em>"Music itself is going to become like running water or electricity." - David Bowie</em></p></blockquote><p>My most popular song 'Circles' has been played 1,350,00 times. And every month about 65,000 people listen to my music on Spotify. </p><p>Guess how many people follow me <a href="https://www.instagram.com/stevebenjamins/">on Instagram</a>? 480. </p><p>Just because people listen to me on Spotify, doesn’t mean they want a deep relationship. Most listeners just add 'Circles' to their library and move on with their life.</p><p>I’m definitely okay with this. I’d rather listeners follow me on Spotify rather than Instagram anyways. Plus only good things can come out of de-coupling fame from music. Make music because it’s what you love to do— not because you want to get famous. If you want to get famous I think you’re better off as a Youtuber or Tiktok influencer anyways! </p><p><strong>I think this is just the nature of algorithmic playlists— they lead to a high volume of listeners with a very loose connection to you as an artist:</strong></p></div></div><div data-block-type="5" id="block-a901b06fafc5a15411fa"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089202461-97Q8C0YXC24AJXHWAZS9/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089202461-97Q8C0YXC24AJXHWAZS9/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-1.jpg" data-image-dimensions="2000x1106" data-image-focal-point="0.5,0.5" alt="discovery-1.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9b7" data-type="image" src="https://www.stevebenjamins.com/blog/discovery-1.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-a93c404fd14f000ea4f9"><div><h3>6. The Deepest Relationships Happen When Listeners Share Music With Friends</h3><p>Listeners sharing music among their friends leads to the deepest connections in my experience. </p><p>For example: last month I was interviewed on a college radio station by three guys. I was blown away by how closely these guys  listened to the music. They knew it so well and had spotted lyrical themes that I’ve repeated throughout songs that I thought I only noticed. It was clear there was a very deep connection.  </p><p>Hearing from listeners like that is nourishing in a way that a graph on Spotify just can't be.  It can be a very moving experience.</p><p>I’ve had similar experiences when high school students reach out to tell me everyone in their circle is listening to the music. Somehow they seem to just care about the music more— like their shared interest draws them deeper. </p><p>When you spend most of your time in an algorithmic world of music streaming, it can feel like magic when you meet listeners who found your music through friends. Sharing music between friends can’t much algorithms in sheer volume but it is by far the deepest way to build connections. </p></div></div><div data-block-type="5" id="block-9ce321c7732a79bf3e5a"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089242182-PUPZTVNS044OUUZMF106/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-2.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089242182-PUPZTVNS044OUUZMF106/ke17ZwdGBToddI8pDm48kE0dBl2NH3FZqnEQ36vQk7d7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1USktP1TqXhY4Tkzt8R3NIMXp3WxE2w03r4EM8893BLC6ItbcvNsfhsWVcDwbNYmf2w/discovery-2.jpg" data-image-dimensions="2000x1106" data-image-focal-point="0.5,0.5" alt="discovery-2.jpg" data-load="false" data-image-id="5ef5dad9c1c000530253b9ba" data-type="image" src="https://www.stevebenjamins.com/blog/discovery-2.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-47277ac585d98eee4d6a"><div><h3>7. Small And Obscure Is Wonderful </h3><p>I don’t tour, I don’t sell merch and I’m not on a major label. I just like making music. I'm an indie artist surfing the waves of the Spotify algorithm— and honestly… it’s been great. </p><p>Small and obscure is kind of wonderful: I get 3 or 4 people every week sending me an email or DM and it's all something sweet or kind— no one cares enough to troll or be a hater.</p></div></div><div data-block-type="5" id="block-33e58c22c9b6be9be03d"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089843440-HMK4D6UUZDPLG5KKJ34U/ke17ZwdGBToddI8pDm48kPnFvlbclLoR6gDHvfg1BsoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZ7nIHmprcfuov5dlvTnz74ZM4c50vsZUfNA6dMgd7y1l5gbUCHkpeEIHHwQ0bqKX/insta-love.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089843440-HMK4D6UUZDPLG5KKJ34U/ke17ZwdGBToddI8pDm48kPnFvlbclLoR6gDHvfg1BsoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZ7nIHmprcfuov5dlvTnz74ZM4c50vsZUfNA6dMgd7y1l5gbUCHkpeEIHHwQ0bqKX/insta-love.jpg" data-image-dimensions="1038x460" data-image-focal-point="0.5,0.5" alt="These kind of messages are really uplifting and mean a lot." data-load="false" data-image-id="5ef5dad9c1c000530253b9bd" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5c6b0db3da50d3614fd79e23/1593089843440-HMK4D6UUZDPLG5KKJ34U/ke17ZwdGBToddI8pDm48kPnFvlbclLoR6gDHvfg1BsoUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcZ7nIHmprcfuov5dlvTnz74ZM4c50vsZUfNA6dMgd7y1l5gbUCHkpeEIHHwQ0bqKX/insta-love.jpg">
          </p>
   …</figure></div></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg">https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg</a></em></p>]]>
            </description>
            <link>https://www.stevebenjamins.com/blog/music-in-the-age-of-algorithms-47syg</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652545</guid>
            <pubDate>Fri, 26 Jun 2020 14:46:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Supreme Court of Canada dismisses Uber appeal $400M class-action lawsuit]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23652450">thread link</a>) | @zoolander2
<br/>
June 26, 2020 | https://www.cbc.ca/news/politics/stefanovich-supreme-court-uber-class-action-decision-1.5626853 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/politics/stefanovich-supreme-court-uber-class-action-decision-1.5626853">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Canada's highest court opened the door to a proposed $400-million class-action lawsuit against Uber&nbsp;today after it sided with a driver in a case over whether workers can settle disputes with the ride-hailing company through a costly, foreign arbitration process or through Ontario courts.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5442916.1580225556!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/uber.jpg"></p></div><figcaption>A proposed $400 million class-action lawsuit against Uber seeks a minimum wage for drivers, vacation pay and other protections under Ontario’s Employment Standards Act.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure><p><span><p>Canada's highest court opened the door to a proposed $400-million class-action lawsuit against Uber&nbsp;today after it sided with a driver in a case over whether workers can settle disputes with the ride-hailing company through a costly, foreign arbitration process or through Ontario courts.</p>  <p>In an eight-to-one decision, the&nbsp;Supreme Court of Canada ruled that drivers can have labour issues resolved through Ontario courts, opening up&nbsp;the possibility of Uber drivers being seen as employees within the meaning of Ontario's Employment Standards Act.</p>  <p>Uber&nbsp;had challenged&nbsp;an Ontario Court of Appeal decision that found the company's contract clause, which relies on a costly arbitration process in the Netherlands to settle disputes, was "unconscionable" and "unenforceable."</p>  <p>In an email statement, a spokesperson for Uber said the company will amend its contracts to align with the court's principles.</p>  <p>"Going forward, dispute resolution will be more accessible to drivers, bringing Uber Canada closer in line with other jurisdictions," the statement said.</p>  <p>"We are proud to offer a flexible earning opportunity to tens of thousands of independent drivers throughout Ontario."</p>  <p>The lower court ruling came after David Heller, a driver for UberEATS, attempted to launch a class-action lawsuit in 2017 to force the company to recognize its drivers as employees rather than independent contractors.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.3880457.1480803361!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/david-heller.jpg 300w,https://i.cbc.ca/1.3880457.1480803361!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/david-heller.jpg 460w,https://i.cbc.ca/1.3880457.1480803361!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/david-heller.jpg 620w,https://i.cbc.ca/1.3880457.1480803361!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/david-heller.jpg 780w,https://i.cbc.ca/1.3880457.1480803361!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/david-heller.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.3880457.1480803361!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/david-heller.jpg"></p></div><figcaption>UberEATS driver David Heller triggered legal action against the ride-hailing company after he was asked to accept compensation changes on his phone in order to continue working for the company.<!-- --> <!-- -->(CBC)</figcaption></figure></span></p>  <p>Heller, who no longer works for Uber, started legal action after he received a message on his cellphone asking him to accept changes to the way he is compensated.</p>  <p>"There was clearly inequality of bargaining power between Uber and Mr. Heller," the Supreme Court's ruling said.</p>  <p>"The arbitration agreement was part of a standard form contract. Mr. Heller was powerless to negotiate any of its terms."</p>    <p>His lawyer, Lior Samfiru, said Heller agreed to the changes because he was out on a delivery in Toronto at the time — and wouldn't have been paid if he had declined.&nbsp;</p>  <p>"If the court agrees with Uber, then every company can have its workers sign a document that says the same thing," Samfiru said before the Supreme Court issued its decision.</p>  <p>"That would mean that companies can do whatever they want with impunity."</p>  <h2>Are individuals in the gig economy employees?</h2>  <p>Uber&nbsp;had won a stay of the proposed class action before Ontario Superior Court because of a clause in the contract that requires all disputes between drivers and the company to go through a mediation process in the Netherlands — at a personal cost of $14,500 US&nbsp;for drivers.</p>  <p>"Practically no one will do that," Samfiru said.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.4413209.1511319079!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/lior-samfiru.jpg 300w,https://i.cbc.ca/1.4413209.1511319079!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/lior-samfiru.jpg 460w,https://i.cbc.ca/1.4413209.1511319079!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/lior-samfiru.jpg 620w,https://i.cbc.ca/1.4413209.1511319079!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/lior-samfiru.jpg 780w,https://i.cbc.ca/1.4413209.1511319079!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/lior-samfiru.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4413209.1511319079!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/lior-samfiru.jpg"></p></div><figcaption>Toronto-based employment lawyer Lior Samfiru said the case involving Uber comes down to the company's accountability.<!-- --> <!-- -->(Andy Hincenberg/CBC)</figcaption></figure></span></p>  <p>Heller, who had been licensed to use the Uber Driver App since February 2016 in Toronto, earned between $20,800 and $31,200 per year before taxes and expenses.</p>  <p>In November 2018, Ontario's highest court ruled Uber's clause amounts to illegally outsourcing an employment standard.</p>  <p>Uber maintained&nbsp;that arbitration, not the courts, is the right forum for deciding&nbsp;the validity of an arbitration agreement.</p>  <p>The proposed class-action lawsuit, which has not yet been certified, aims&nbsp;to provide a minimum wage, vacation pay and other protections under Ontario's Employment Standards Act to anyone who works for Uber or&nbsp;has worked for the company&nbsp;in Ontario since 2012.</p>    <p>Samfiru said the high court's decision has wide implications for the gig economy, and starts the discussion about whether people in the free market are employees.</p>  <p>"We cannot have a system where companies can do whatever they want, whenever they want, without any repercussions," Samfiru said.</p>  <p>"The only way that we can even balance that inequality somehow is by giving individuals access to tribunals, like the labour relations board, or to our courts across the country."</p>  </span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/politics/stefanovich-supreme-court-uber-class-action-decision-1.5626853</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652450</guid>
            <pubDate>Fri, 26 Jun 2020 14:38:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don't need ElasticSearch, use ts_query]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23652091">thread link</a>) | @delirehberi
<br/>
June 26, 2020 | https://emre.xyz/searching-with-the-power-of-postgresql-in-symfony-applications | <a href="https://web.archive.org/web/*/https://emre.xyz/searching-with-the-power-of-postgresql-in-symfony-applications">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For instance, you need to write a search page for your last project, and it is not big enough to use an external search engine. Still, you want to use some powerful text searching features. You are brilliant if you preferred PostgreSQL as your database. Because PostgreSQL has very, very powerful search capabilities. I want to share some of them with you.</p>

<p>You can run the search queries on columns even if you don't index it. You need a <code>document</code> and a <code>query</code> for running on it. There is an operator for running your search query over the document. It is <code>@@</code>!</p>

<p>For instance; you have a content table like this:</p>

<pre><code>create table content( id INT, title TEXT, body TEXT);
</code></pre>

<p>And, it includes some data;</p>

<pre><code>insert into content values(1,'Demo content', 'Demo content body ');
insert into content values(2,'Demo content 2', 'Demo content body2 ');
insert into content values(3,'Verification title', 'Virtualization on cloud');
</code></pre>

<p>Let's run a search query on this table. Like I said, “We need a document and a query.” But we do not index anything yet, and we not have any query typed data. So, we can use the <code>to_tsvector</code> function for creating our document on the fly, and we can use the <code>to_tsquery</code> function for creating our query on the fly.</p>

<pre><code>select * from content where to_tsvector(title) @@ to_tsquery('demo');
</code></pre>

<p>And the result is;</p>

<pre><code> id |     title      |        body
----+----------------+---------------------
  1 | Demo content   | Demo content body
  2 | Demo content 2 | Demo content body2
(2 rows)
</code></pre>

<p>Meh, it was so easy. Let's try another thing. Did you see our last data? It includes <em>Verification</em> text inside. Can we search for it with any variant of the words? Yes, of course. For example, “Verify”.</p>

<pre><code>select * from content where to_tsvector(title) @@ to_tsquery('verify');
</code></pre>

<p>Get it? We can search for variants. PostgreSQL knows which word is matching with which words.</p>

<p>Also, there is a lot of special features here. You can read about it in the official documentation. This is not a documentation dude, this is a blog post. Just I've noted the amazing things not documenting. Anyway, this is the documentation URL: <a href="https://www.postgresql.org/docs/9.1/datatype-textsearch.html" rel="nofollow">postgresql/textsearch</a></p>

<p>OK. Let's continue.</p>

<p>I said you need to have a document and a query. So, you can create a document using different fields if you want. You can use <code>||</code> operator for concatenation.</p>

<pre><code>select * from content where to_tsvector(title || ' ' || body) @@ to_tsquery('cloud');
</code></pre>

<p>Also, you need a correct query for searching. So, you can't use this <code>to_tsquery('verification cloud')</code> because it is not valid. The query must not include spaces. It must be a logical operation. So? You can split your text and merge it via <em>and</em> or <em>or</em>. Like this: <code>to_tsquery('cloud&amp;verification')</code> or <code>to_tsquery('cloud|demo')</code></p>

<p>You like that, right?</p>

<p>—</p>

<p>OK. Let's jump the Symfony section. We have the Doctrine. Great ORM. But sometimes it can disable us. Like now...</p>

<p>We need to use a native query to make a profit about searching. I tired while writing. I'm adding the example here. This is a very basic snippet.</p>

<p>Note:I'm using <code>$rsm-&gt;generateSelectClause()</code> for prevent collisions happened when working with multiple tables.</p>

<p>Attention: This is an example code. Please filter your <code>$query</code> to prevent your application from an SQL injection vulnerability.</p>

<pre><code>  public function search(string $query,?string $role=null)
  {
   $query = (function($q){
       $pieces = explode(' ',$q);
       return join('&amp;',$pieces);
    })($query);
    $rsm = new ResultSetMappingBuilder($this-&gt;_em,ResultSetMappingBuilder::COLUMN_RENAMING_INCREMENT);
    $rsm-&gt;addRootEntityFromClassMetadata('App\\Entity\\User', 'm');
    $rsm-&gt;addJoinedEntityFromClassMetadata('App\\Entity\\Profile', 'p','m','profile');
    $sql ="select ".$rsm-&gt;generateSelectClause()." from member m 
      inner join profile p on m.profile_id=p.id
      where to_tsvector(m.email || ' ' || p.prename || ' ' || p.lastname || ' ' || p.company || ' ' || p.position) @@ to_tsquery('$query')";
    if($role) {
      $sql.=" AND '$role' = ANY (roles)";
    }
    $qb = $this-&gt;_em-&gt;createNativeQuery($sql,$rsm);
    return $qb-&gt;getResult();
  }
</code></pre>

<p>Keep safe...</p>

<p><a href="https://emre.xyz/tag:en" rel="nofollow"><span>#</span><span>en</span></a> <a href="https://emre.xyz/tag:php" rel="nofollow"><span>#</span><span>php</span></a> <a href="https://emre.xyz/tag:symfony" rel="nofollow"><span>#</span><span>symfony</span></a> <a href="https://emre.xyz/tag:postgresql" rel="nofollow"><span>#</span><span>postgresql</span></a></p>
</div></div>]]>
            </description>
            <link>https://emre.xyz/searching-with-the-power-of-postgresql-in-symfony-applications</link>
            <guid isPermaLink="false">hacker-news-small-sites-23652091</guid>
            <pubDate>Fri, 26 Jun 2020 14:06:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from writing for The Onion for a month (2015)]]>
            </title>
            <description>
<![CDATA[
Score 216 | Comments 113 (<a href="https://news.ycombinator.com/item?id=23651864">thread link</a>) | @bryanrasmussen
<br/>
June 26, 2020 | https://wordsbyevanporter.com/what-i-learned-from-writing-for-the-onion-for-a-month/ | <a href="https://web.archive.org/web/*/https://wordsbyevanporter.com/what-i-learned-from-writing-for-the-onion-for-a-month/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <!--kg-card-begin: markdown--><p><img src="https://wordsbyevanporter.com/content/images/2015/01/onionlogo.png" alt=""></p>
<p>In April/May of 2010, I spent four weeks as a freelance writer for The Onion News Network.</p>
<p>Besides looking great on a resume, it was an awesome gig and a huge learning experience. Not surprisingly, I get asked about it pretty often.</p>
<p>So here's everything I know about how to get a job writing for <a href="http://www.theonion.com/">The Onion</a>, and what I learned from my (short) time doing it.</p>
<hr>
<h2 id="howigotajobfreelancewritingfortheonion">How I Got a Job Freelance Writing for The Onion</h2>
<hr>
<p>Getting a job writing for The Onion is not easy. But there's no big secret to it, either.</p>
<p><a href="http://www.theonion.com/jobs">The Onion has a jobs page</a> on their website.</p>
<p>Yep. That's the big story behind how I got hired to write for The Onion: I went on their website and applied.</p>
<p>But here's the thing -- I did this at least twice with no luck before I got accepted.</p>
<p>Here's how it worked back then:</p>
<p>I would check the job listings frequently (obsessively), and every once in a blue moon, there'd be a position on there called Freelancer or Freelance Writer. You'd send in an email with your resume and samples, and they'd send back an application for you to complete. You had to return two things:</p>
<ol>
<li>
<p><strong>A list of 20 headlines</strong> and concepts for video sketches. (All the job listings I ever saw were for The Onion News Network -- their video leg. I never saw anything for editorial positions.)</p>
</li>
<li>
<p><strong>A completed script</strong> for one of their news segment sketches based on ideas or concepts they provided.</p>
</li>
</ol>
<p>Like I said, I went through this process (the final product is often known in the industry as a "packet") at least twice with no success. It doesn't sound like much, but it is TOUGH. I labored over those 20 headlines like you wouldn't believe. Even the best ideas start to look like shit after you've stared at them for a week.</p>
<p>And the scripts. Man, those were hard. They never gave you blockbuster concepts to work with, and I think that was on purpose. It was always some kind of dry, subtle joke -- they wanted to see what you could do and how far you would take it.</p>
<p>But the third time I applied was a charm. I'll never forget opening my email and seeing these words:</p>
<blockquote>
<p>The Onion News Network would like to congratulate you on being selected as a Contributor for the IFC series. We had a huge number of applicants, and we are thrilled with how strong this group is.</p>
</blockquote>
<p>I remember texting my wife -- girlfriend at the time. She was in class and stepped into the hall to call me. We both basically screamed on the phone for a couple of minutes.</p>
<p><strong>Side Note:</strong> I haven't seen any writing positions listed on The Onion's website in years. Granted, I don't check as frequently anymore, but I think the only way to get in with them these days is to be recruited, know someone there, or come up through the ranks as an intern or writer's assistant.</p>
<p>If you REALLY want to get a job writing for The Onion; email them. I've heard stories of people that have done this. They say they won't take anything unsolicited, and there's a 99% chance they won't, but who knows? Serendipity just might strike for you.</p>
<hr>
<h2 id="whatitwasliketowritefortheonion">What It Was Like to Write for The Onion</h2>
<hr>
<p>They put us to work right away. This was back in 2010, and The Onion was going into pre-production on its very first TV show -- The Onion News Network on IFC (The Independent Film Channel).</p>
<p>It would be a lot like the Onion video content we knew and loved, except in a half hour format and with recurring anchors as characters.</p>
<p>We were required to turn in 25 ideas a week; an "idea" being a headline or concept along with a short explanation of the joke and how the segment would play out.</p>
<p>Some weeks, we'd get really brief feedback on our lists. Other weeks, not. Then, by mid week, they'd compile all the ideas they liked. Some would be marked down as "one liners", or jokes that would be pulled in to scroll across the bottom of the screen during the show. Others were segmented by where in the show they might fit in, with some of them designated to move to the scripting stage (where the staff writers would take over).</p>
<p>The process moved fast. My job, along with the other freelancers, was to come up with ideas. We weren't really consulted or informed about anything else surrounding the show. No meetings to discuss casting. No phone calls to brainstorm around our jokes. It was our job to pump out creativity and let the full time staff filter everything out. Everything was done over email.</p>
<p>In the end, only one of my ideas actually made it into the show -- unless I missed a one-liner somewhere along the line, which would be easy to do.</p>
<p>Funny enough, the idea of mine that made it to production was one from my submission packet -- I'm pretty sure it's the reason they hired me. And they actually chose to open the entire series with it, which was pretty cool.</p>

<p>I recorded the pilot when it aired and probably watched it a dozen times with my family. One of the coolest moments I've ever had as a writer.</p>
<hr>
<h2 id="whatilearnedwritingfortheonion">What I Learned Writing for The Onion</h2>
<hr>
<p>This was a huge learning experience for me in a very short amount of time. I could probably talk for days about everything I learned working as a writer for The Onion for four weeks, but if I had to boil it down, here's what I'd say:</p>
<h3 id="ideasarecheap">Ideas are cheap.</h3>
<p>Or, in their case, jokes. They made us come up with so many sketch ideas and headlines. Huge lists of them. And once they were dead, they were dead. There was no reusing ideas that didn't quite make the cut in previous weeks. No iterating on almost-there jokes. When an idea was rejected, it was time to move on. Always bigger and better jokes, or ideas, out there to be found.</p>
<p>I also learned how to really dig into an idea to see if it had any potential. They were constantly pushing us to see past the headline. Is it just a funny sentence or is there room to explore and expand this into a 3 minute sketch? Is there substance?</p>
<h3 id="creativityisamuscle">Creativity is a muscle.</h3>
<p>What I loved about The Onion's writing process was the sheer volume of it. 25 ideas a week. No excuses. Often times, I'd turn in more than 25, along with a big list of one-liners I knew weren't big enough for full sketches. For one thing, it forced me to dig deep and get past those first initial ideas that came easily. It also helped me learn The Onion's editorial voice through repetition, which is something that can't be overstated.</p>
<h3 id="iamnotthatfunny">I am not that funny.</h3>
<p>I had one great idea and I used it up in my application to get the job. I wrote a few other funny jokes throughout, but nowhere near the level of The Onion's top writers. I wish I could show you these lists of approved ideas I got in my inbox each week. Reading through them was an absolute blast; these guys and girls are so freaking talented and funny.</p>
<p>At the end of the project, they opted to keep a few of the freelance writers on -- alas, I was not one of them. And I didn't expect to be. To be a professional humor writer, you have to be insanely funny and creative. I'm a good writer, and I got their voice, and I have a few good ideas, but I was never going to make it as a full-time writer for The Onion. And that's okay.</p>
<hr>
<h2 id="intheend">In The End</h2>
<hr>
<p>Writing for The Onion was one of the coolest experiences I've ever had, and I feel lucky to have gotten the opportunity.</p>
<p>I mean, I got to see an idea I had sitting in my living room acted out on TV with a real script, real actors, and real production value. That was awesome, and I'll never forget it. And to top it off, I actually got a paycheck. People paid me real money to come up with jokes. That was incredible.</p>
<p>And I'd like to think that, even though the gig was short lived, I learned a ton by being bold enough to jump into the deep end with pro comedy writers.</p>
<p>Even if I didn't really belong there.</p>
<hr>
<h2 id="nowreadthisworkingwithaneditorprotectingyourvoice">Now Read This: <a href="http://www.wordsbyevanporter.com/working-with-an-editor/">Working with an Editor &amp; Protecting Your Voice</a></h2>
<hr>
<!--kg-card-end: markdown-->
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://wordsbyevanporter.com/what-i-learned-from-writing-for-the-onion-for-a-month/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651864</guid>
            <pubDate>Fri, 26 Jun 2020 13:43:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asynchronous Podcast Recording]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23651606">thread link</a>) | @Khiwee
<br/>
June 26, 2020 | https://app.rumble.studio/quickstart | <a href="https://web.archive.org/web/*/https://app.rumble.studio/quickstart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    


    <div>
        <h5>Creation &amp; Recording (5mn)</h5>
        <div>
            <ol>
                <li>Creation &amp; Invitation (<a href="https://app.rumble.studio/editor/templates">"Create" tab</a>)
                    <ol>
                        <li>Click the <i>1-to-1 interview template</i> to create a new Botcast</li>
                        <li>Write a few example questions e.g. 'Please could you introduce yourself?'</li>
                        <li>Add the email you used to sign-up with as both the host and the guest (or invite a
                            colleague)</li>
                        <li>Save (<span>ctrl+s</span> or click on the <p><span>sd_card</span> </p>icon)
                        </li>
                        <li>Click 'Export &amp; invite' &gt; 'Create tasks'</li>
                        <li>Click 'Export &amp; invite' &gt; 'Invite new participants'</li>
                    </ol>
                    <iframe width="280" height="158" src="https://www.youtube.com/embed/LrucShIGZyc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </li><br>
                <li> Recording (<a href="https://app.rumble.studio/editor/tasks">"Record" tab</a>)
                    <ol>
                        <li>Record yourself asking the questions <strong>as the host</strong></li>
                        <li>Record yourself (or a colleague) answering the questions <strong>as the guest</strong></li>
                    </ol>
                    <iframe width="280" height="158" src="https://www.youtube.com/embed/hE53_3WdVM8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </li><br>
                <li>Add jingle &amp; export (<a href="https://app.rumble.studio/editor/templates">"Create" tab</a>)
                    <ol>
                        <li>Add jingle blocks to the start and end of the structure, using the left pop-out sidebar.
                            Select a jingle and save.</li>
                        <li>Download files</li>
                        <li>Have a listen!</li>
                    </ol>
                    <iframe width="280" height="158" src="https://www.youtube.com/embed/w-Uwj9uOnzY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </li>
            </ol>

            <p><a href="https://app.rumble.studio/editor/templates">Proceed</a>
            
        </p></div>
    </div>

    <br>
    <div>
        <h5>Distribution (2mn)</h5>
        <div><p>
            Once you have a recorded workflow:
            </p><ol>
                <li>Publish (<a href="https://app.rumble.studio/editor/shows">"Distribute" tab</a>)
                    <ol>
                        <li>Create a show</li>
                        <li>Create an episode</li>
                        <li>Share the show link or the RSS link</li>
                        <li><i>Coming soon:</i> automatic sharing on podcast directories</li>
                    </ol>
                    <iframe width="280" height="158" src="https://www.youtube.com/embed/bh9ARay1ihc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </li>
            </ol>
        </div>
    </div>
    <br>
    <div id="add-jingle">
        <h5>Add your own jingle/intro music (2mn)</h5>
        <div><p>
            You can upload your own audio files directly here: <a href="https://app.rumble.studio/upload-content">audio file upload</a></p><iframe width="280" height="158" src="https://www.youtube.com/embed/FH_a6D5LqYQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        </div>
    </div>






    </div></div>]]>
            </description>
            <link>https://app.rumble.studio/quickstart</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651606</guid>
            <pubDate>Fri, 26 Jun 2020 13:17:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prisma Raises $12M Series A]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 107 (<a href="https://news.ycombinator.com/item?id=23651605">thread link</a>) | @pimeys
<br/>
June 26, 2020 | https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6 | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><hr><h3 id="contents"><a href="#contents" aria-label="contents permalink"></a>Contents</h3><ul><li><a href="#our-mission-making-databases-easy">Our mission: Making databases easy</a></li><li><a href="#where-we-are-today">Where we are today</a></li><li><a href="#whats-next-for-prisma">What's next for Prisma</a></li><li><a href="#we--our-community">We 💚 our community</a></li></ul><hr><h3 id="tldr"><a href="#tldr" aria-label="tldr permalink"></a>TLDR</h3><p>At Prisma, our goal is to <strong>revolutionize how application developers work with databases</strong>. Considering the <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/intro/comparing-database-types">vast number of different databases</a> and <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/types/relational/comparing-sql-query-builders-and-orms">variety of tools</a> for working with them, this is an extremely ambitious goal!</p><p>We are thrilled to enter the next chapter of pursuing this goal with a <strong>$12M Series A</strong> funding round led by <a target="_blank" rel="noopener noreferrer" href="https://amplifypartners.com/">Amplify Partners</a>. We are especially excited about this partnership as Amplify is an experienced investor in the developer tooling ecosystem and has led investments for numerous companies, such as <a target="_blank" rel="noopener noreferrer" href="https://www.datadoghq.com/">Datadog</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.fastly.com/">Fastly</a>, and <a target="_blank" rel="noopener noreferrer" href="https://www.gremlin.com/">Gremlin</a>.</p><hr><h3 id="our-mission-making-databases-easy"><a href="#our-mission-making-databases-easy" aria-label="our mission making databases easy permalink"></a>Our mission: Making databases easy</h3><h4 id="database-tools-are-stuck-with-legacy-paradigms"><a href="#database-tools-are-stuck-with-legacy-paradigms" aria-label="database tools are stuck with legacy paradigms permalink"></a>Database tools are stuck with legacy paradigms</h4><p>Despite having been developed in the 1970s, relational <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/intro/what-are-databases">databases</a> are still the most commonly used databases today. While <a target="_blank" rel="noopener noreferrer" href="https://dataguide.prisma.io/intro/comparing-database-types">other database types have been developed in the meantime</a>, from <em>document</em>, to <em>graph</em> , to <em>key-value</em> databases, working with databases remains one of the biggest challenges in application development.</p><p>While almost any other part of the development stack has been modernized, database tools have been stuck with the same paradigms for the last decades.</p><p><span><img src="https://imgur.com/WwMdROo.png"></span></p><p>When working with relational databases, developers have the choice of working directly with SQL or using a higher-level abstraction called ORMs. <a href="https://www.prisma.io/docs/understand-prisma/why-prisma#problems-with-sql-orms-and-other-database-tools">None of these options is particularly compelling</a>.</p><p>Using SQL is very low-level resulting in reduced developer <em>productivity</em>. In contrast, ORMs are too high-level and developers sacrifice <em>control</em> over the executed database operations when using this approach. ORMs further suffer from a fundamentally misguided abstraction called the <a target="_blank" rel="noopener noreferrer" href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">object-relational impedance mismatch</a>.</p><h4 id="prisma-modernizes-how-developers-work-with-databases"><a href="#prisma-modernizes-how-developers-work-with-databases" aria-label="prisma modernizes how developers work with databases permalink"></a>Prisma modernizes how developers work with databases</h4><p>Similar to how React.js modernized frontend development or how Serverless invented a new model for compute infrastructure, <strong>Prisma is here to bring a new and modern approach for working with databases</strong>!</p><p>Prisma's unique approach to solving database access with a <em>generated</em> query builder that's fully type-safe and can be tailored to any database schema sets it apart from previous attempts of solving the same problem.</p><p>A big part of the modernization comes from our <strong>major focus on developer experience</strong>. Database tools are often associated with friction, uncertainty, painful hours of debugging and costly performance bottlenecks.</p><div><p><strong>Developer experience is part of our DNA at Prisma.</strong> Working with databases is too often associated with friction and uncertainty when it should be fun, delightful and productive!</p></div><p>We want to make working with databases <em>fun</em>, <em>delightful</em> and <em>productive</em> while guiding developers towards proper patterns and best practices in their daily work with databases!</p><h4 id="learning-from-our-past-from-graphql-to-databases"><a href="#learning-from-our-past-from-graphql-to-databases" aria-label="learning from our past from graphql to databases permalink"></a>Learning from our past: From GraphQL to databases</h4><p>As a company we've gone through a number of major product iterations and pivots over the last years.</p><p><span><img src="https://imgur.com/4YPWyaW.png"></span></p><p>Our initial products, Graphcool and Prisma 1 were focused on <a target="_blank" rel="noopener noreferrer" href="http://graphql.org/">GraphQL</a> as a technology. However, as we were running both tools in production, we realized they didn't address the <em>core</em> problems developers had.</p><p>We realized that a lot of the value we provided with both tools didn't necessarily lie in the quick provision of a GraphQL server, but rather in the fact that developers didn't need to manage their <em>database workflows</em> explicitly.</p><p>This realization led to a pivot which ultimately manifested in the rewrite to Prisma 2. With this new version of Prisma, we have found the right level of abstraction that ensures developers keep full control and flexibility about their development stack while not needing to worry about database workflows!</p><h4 id="inspired-by-the-data-layers-of-big-companies-twitter-facebook-"><a href="#inspired-by-the-data-layers-of-big-companies-twitter-facebook-" aria-label="inspired by the data layers of big companies twitter facebook  permalink"></a>Inspired by the data layers of big companies (Twitter, Facebook, ...)</h4><p>The approach Prisma takes for this modernization is inspired by big tech companies such as Twitter, Facebook, or Airbnb. </p><p>To ensure productivity of application developers, it is a common practice in these organizations to introduce a <em>unified data access layer</em> that abstracts away the database infrastructure and provides developers with a more familiar and convenient way of accessing data.</p><p>Facebook developed a system called <a target="_blank" rel="noopener noreferrer" href="https://medium.com/coinmonks/tao-facebooks-distributed-database-for-social-graph-c2b45f5346ea">TAO</a> that fulfills the data needs of application developers. Twitter has built a "virtual database" called <a target="_blank" rel="noopener noreferrer" href="https://about.sourcegraph.com/graphql/graphql-at-twitter#schema">Strato</a> which <em>brings together multiple data sources so that they can be queried and mutated uniformly</em>. Airbnb <a target="_blank" rel="noopener noreferrer" href="https://medium.com/airbnb-engineering/reconciling-graphql-and-thrift-at-airbnb-a97e8d290712">combines GraphQL and Thrift</a> to abstract away the implementation details of querying data.</p><p><span><img src="https://imgur.com/Hb9VOWN.png"></span></p><p>Building these custom data access layers requires <em>a lot</em> of time and resources (as these are typically implemented by dedicated <em>infrastructure teams</em>) and thus is not a realistic approach for most companies and development teams.</p><p>Being based on the same core ideas and principles as these systems, <strong>Prisma democratizes the pattern of a uniform data access layer</strong> and makes it accessible as an open-source technology for development teams of all sizes.</p><hr><h3 id="where-we-are-today"><a href="#where-we-are-today" aria-label="where we are today permalink"></a>Where we are today</h3><h4 id="prisma-20-is-ready-for-production"><a href="#prisma-20-is-ready-for-production" aria-label="prisma 20 is ready for production permalink"></a>Prisma 2.0 is ready for production</h4><p>After running Preview and Beta versions for more than a year, we've recently <a href="https://www.prisma.io/blog/announcing-prisma-2-n0v98rzc8br1">launched Prisma 2.0 for production</a>. Having rewritten the core of Prisma from Scala to Rust for the transition, we've built a strong foundation to expand the Prisma toolkit to cover various database workflows in the future.</p><p>Prisma's main feature is <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client">Prisma Client</a>, an auto-generated and type-safe query builder which can be used to access a database in Node.js and TypeScript. Thanks to <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/introspection">introspection</a>, Prisma Client can be used to work with any existing database!</p><blockquote><p><strong>Note</strong>: Prisma currently supports <strong>PostgreSQL</strong>, <strong>MySQL</strong> and <strong>SQLite</strong> databases –&nbsp;with more planned. Please create <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/new">new GitHub issues</a> or subscribe to existing ones (e.g. for <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues?q=is%3Aissue+is%3Aopen+mongo">MongoDB</a> or <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/1676">DynamoDB</a>) if you'd like to see support for specific databases.</p></blockquote><h4 id="next-generation-web-frameworks-are-built-on-prisma"><a href="#next-generation-web-frameworks-are-built-on-prisma" aria-label="next generation web frameworks are built on prisma permalink"></a>Next-generation web frameworks are built on Prisma</h4><p>The Node.js ecosystem is known for lots of different frameworks that try to streamline workflows and prescribe certain conventions. We are extremely humbled that many framework authors decide to use Prisma as their data layer of choice.</p><h5 id="redwoodjs-bringing-full-stack-to-the-jamstack"><a href="#redwoodjs-bringing-full-stack-to-the-jamstack" aria-label="redwoodjs bringing full stack to the jamstack permalink"></a>Redwood.js: Bringing full-stack to the Jamstack</h5><p>The new <a target="_blank" rel="noopener noreferrer" href="https://redwoodjs.com/">RedwoodJS</a> framework by GitHub co-founder <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/mojombo">Tom Preston-Werner</a> seeks to become the "Ruby on Rails" equivalent for Node.js. RedwoodJS is based on React and GraphQL and comes with a baked-in deployment model for serverless functions.</p><h5 id="blitzjs-the-fullstack-react-framework"><a href="#blitzjs-the-fullstack-react-framework" aria-label="blitzjs the fullstack react framework permalink"></a>Blitz.js: The Fullstack React Framework</h5><p>Another framework with increasing anticipation and excitement in the community is <a target="_blank" rel="noopener noreferrer" href="http://blitzjs.com/">Blitz.js</a>. Blitz is build on top of Next.js and takes a fundamentally different approach compared to Redwood. Its goal is to completely eliminate the API server and <a target="_blank" rel="noopener noreferrer" href="https://github.com/blitz-js/blitz/blob/canary/rfc-docs/01-architecture.md#introduction">"bring back the simplicity of server rendered frameworks"</a>.</p><h5 id="nexus-a-delightful-graphql-application-framework"><a href="#nexus-a-delightful-graphql-application-framework" aria-label="nexus a delightful graphql application framework permalink"></a>Nexus: A delightful GraphQL application framework</h5><p>At Prisma, we're huge fans of GraphQL and believe in its bright future. That's why we founded the <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma-labs/">Prisma Labs</a> team which dedicates its time to work on open source tools in the GraphQL ecosystem.</p><p>It is currently focused on building <a target="_blank" rel="noopener noreferrer" href="https://www.nexusjs.org/#/">Nexus</a>, a delightful application framework for developing GraphQL servers. As opposed to RedwoodJS, Nexus is a <em>backend-only</em> GraphQL framework and has no opinions on how you access the GraphQL API from the frontend.</p><h3 id="whats-next-for-prisma"><a href="#whats-next-for-prisma" aria-label="whats next for prisma permalink"></a>What's next for Prisma</h3><h4 id="database-migrations-with-prisma-migrate"><a href="#database-migrations-with-prisma-migrate" aria-label="database migrations with prisma migrate permalink"></a>Database migrations with Prisma Migrate</h4><p>Database migrations are a common pain point for many developers! Especially with applications running in production, it is often unclear what the best approach is to perform schema changes (e.g. in CI/CD environments). Many developers resort to manual migrations or custom scripts, making the process brittle and error-prone.</p><p><a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-migrate">Prisma Migrate</a> is our solution to this problem. Prisma Migrate lets developers map the declarative <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema">Prisma schema</a> to their database. Under the hood, Prisma Migrate generates the required SQL statements to perform the migration.</p><blockquote><p><strong>Note</strong>: Prisma Migrate is currently in an experimental state and should not be used in production environments.</p></blockquote><h4 id="prisma-studio-a-visual-editor-for-your-database-workflows"><a href="#prisma-studio-a-visual-editor-for-your-database-workflows" aria-label="prisma studio a visual editor for your database workflows permalink"></a>Prisma Studio: A visual editor for your database workflows</h4><p><a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-studio">Prisma Studio</a> is your visual companion for various database workflows. It provides a modern GUI that lets you view and edit the data in your database. You can switch between the <em>table</em> and the <em>tree</em> view, the latter is especially convenient to drill deeply into nested data (explore the two views using the tabs below or try out the <a target="_blank" rel="noopener noreferrer" href="https://prisma.studio/">online demo</a>).</p><div><p><span><img src="https://imgur.com/Fc7BweP.png"></span></p></div><blockquote><p><strong>Note</strong>: Prisma Studio is currently in an experimental state and should not be used in production environments. .</p></blockquote><h4 id="beyond-nodejs--typescript-prisma-client-in-other-languages"><a href="#beyond-nodejs--typescript-prisma-client-in-other-languages" aria-label="beyond nodejs  typescript prisma client in other languages permalink"></a>Beyond Node.js &amp; TypeScript: Prisma Client in other languages</h4><p>Prisma Client is a thin, language-specific layer that delegates the heavy-lifting of query planning and execution to Prisma's <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-client/query-engine">query engine</a>. The query engine is <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma-engines">written in Rust</a> and runs as a standalone process alongside your main application.</p><p>This architecture enables us to expand Prisma Client to other languages and bring its benefits to developers beyond the Node.js community. We are already working on <strong>Prisma Client in Go</strong> with a first <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma-client-go">alpha version</a> ready to try out!</p><h4 id="supporting-a-broad-spectrum-of-databases-and-other-data-sources"><a href="#supporting-a-broad-spectrum-of-databases-and-other-data-sources" aria-label="supporting a broad spectrum of databases and other data sources permalink"></a>Supporting a broad spectrum of databases and other data sources</h4><p>Prisma is designed in a way that it can potentially connect to <em>any</em> existing data source as long as there is the right <em>connector</em> for it!</p><p>As of today, we've built connectors for PostgreSQL, MySQL and SQLite. A <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/1277">connector for MongoDB</a> is already in the works and more are planned for the future.</p><p><span><img src="https://imgur.com/PQSljF7.png"></span></p><h4 id="building-commercial-services-to-sustain-the-oss-tools"><a href="#building-commercial-services-to-sustain-the-oss-tools" aria-label="building commercial services to sustain the oss tools permalink"></a>Building commercial services to sustain the OSS tools</h4><p>We are commited to building world-class open-source tools to solve common database problems of application developers. To be able to sustain our open-source work, we're planning to build commercial services that will enable development teams and organizations to collaborate better in projects that are using Prisma.</p><blockquote><p><strong>Note</strong>: The plans for commercial services do not affect the open-source tools we are building, those will remain free forever.</p></blockquote><hr><p>We are incredibly grateful for everyone who has accompanied us on our journey! It is fantastic to see our lively community on <a target="_blank" rel="noopener noreferrer" href="https://slack.prisma.io/">Slack</a>, <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma">GitHub</a>, <a target="_blank" rel="noopener noreferrer" href="https://twitter.com/search?q=%40prisma&amp;src=typed_query&amp;f=live">Twitter</a> and a lot of other channels where folks are chatting about Prisma and helping each other out!</p><h4 id="join-us-at-prisma-day"><a href="#join-us-at-prisma-day" aria-label="join us at prisma day permalink"></a>Join us at Prisma Day</h4><p>If you've become …</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6">https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6</a></em></p>]]>
            </description>
            <link>https://www.prisma.io/blog/prisma-raises-series-a-saks1zr7kip6</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651605</guid>
            <pubDate>Fri, 26 Jun 2020 13:17:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking Theatre Online with WebGL and WebRTC]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23651117">thread link</a>) | @seacaster
<br/>
June 26, 2020 | https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/ | <a href="https://web.archive.org/web/*/https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><em>[<strong>Ed. Note:</strong> This post contains a promotion! It basically *is* a promotion for my current online interactive show: Shattered Space.]</em></p>

<p><em>[But I’ve also got a lot of cool technical stuff to tell you about, so stick around and if this sounds interesting feel free to <a href="https://shatteredspace.live/" target="_blank">buy a ticket here</a>!]</em></p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#intro">Intro</a></li>
  <li><a href="#other-peoples-computers">Other People’s Computers</a></li>
  <li><a href="#basic-platform-overview">Basic Platform Overview</a></li>
  <li>WebRTC/Janus
    <ul>
      <li><a href="#webrtc-and-janus">WebRTC and Janus</a></li>
      <li><a href="#webrtc-and-redux">WebRTC and Redux</a></li>
      <li><a href="#acquiring-media-devices">Acquiring Media Devices</a></li>
    </ul>
  </li>
  <li>WebGL/three.js
    <ul>
      <li><a href="#threejs-and-offscreencanvas">three.js and OffscreenCanvas</a></li>
      <li><a href="#threejs-and-memory-management">three.js and Memory Management</a></li>
    </ul>
  </li>
  <li><a href="#detecting-and-solving-issues-remotely">Detecting and Solving Issues Remotely</a></li>
  <li><a href="#come-see-shattered-space">Come See Shattered Space!</a></li>
</ul>

<h2 id="intro">Intro</h2>

<p>Safe to say that the past couple months have gone a lot different than many of us were expecting. In early March, as quarantine was starting and all of my projection design gigs were being cancelled, I hit up a couple close friends about building a non-linear theatre experience entirely online. A lot of folks have been trying to perform plays on Zoom (and have found a lot of interesting and clever ways of working with that medium), but I felt like we could make something really unique if we built our own custom video conferencing app.</p>

<p><img src="https://chrisuehlinger.com/images/shattered/initial-google-doc.png">
<strong>The Google Doc that started it all</strong></p>

<p>Crazy? It definitely would’ve been 10 years ago. But advances in the web platform (as well as the quality of cameras and hardware in mobile devices) took this down into the realm of “possible-if-slightly-quixotic”.</p>

<p>Three months later, we’ve done it: Shattered Space is a piece of interactive theatre about a binary star system whose twin stars (“The Mothers”) have disappeared. You and your fellow audience members are Star Jockeys, and have been conscripted to fly around in spaceships to get to know the denizens of the Matra System and see what you can do to help.</p>

<p><iframe src="https://www.youtube.com/embed/iifZPEHJM6c" frameborder="0" allowfullscreen=""></iframe></p>
<p><strong>Here’s a trailer if you want a better idea of what’s going on</strong></p>

<p>If you watched that trailer, you’ve probably figured out that this show involved 3D graphics (WebGL), videoconferencing (WebRTC) and perhaps also some music and audio processing (Web Audio). These were all technologies that I’d worked with on some level in the past, but this show required me to think about them completely differently. All because of the following central problem:</p>

<h2 id="other-peoples-computers">Other People’s Computers</h2>

<p><iframe src="https://www.youtube.com/embed/nGt8w9RbhvY" frameborder="0" allowfullscreen=""></iframe></p>
<p><strong>This WebRTC-based monitoring system allowed the backstage band to see the stage in real time and take cues from actors. The onstage portal was rendered with WebGL. (<em>Welcome to Shakesville</em>, Baltimore Rock Opera Society 2019)</strong></p>

<p>I’ve used WebGL and WebRTC to build projection/video effects for a number of shows the past couple years, but in every case I was writing code that would only run on <strong>my</strong> computer. If I ran into a device-specific bug that affected my computer (or my iPhone, or my squad of Raspberry Pis) I had all the time and access I needed to either debug it or come up with a workaround. Not this time.</p>

<p>If someone pays us $15, receives the login link via email, tries to open it on a cheap 2014 laptop and it can’t load without crashing, that’s a refund. We weren’t just messing around with advanced web features, we needed to deploy them in the most battle-hardened and resilient way possible, while also capturing just enough data and logs to pinpoint who was having problems and ideally solve them before the show started.</p>

<p>This meant going beyond the kinds of code you see in introductory tutorials and really digging into how these APIs deal with memory management, how they respond to connection issues, how they can fail, and how to tweak things at runtime to ensure that framerates stay high and dropped packets are few. I learned a lot about productizing these features, and I’d like to share as much of that as I can, but first let’s talk basics.</p>

<h2 id="basic-platform-overview">Basic Platform Overview</h2>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/ship-in-flight.png">
<strong>A group of attendees interacting with a character in the show</strong></p>

<p>Attendees of Shattered Space are broken up into 6 groups of 5. Each group is assigned to a “ship” that flies around the system, and they interact with the characters in the show as a group. Attendees have the options to mute their microphone and turn off their camera if they wish (there is a text chat on the side they can use to communicate) although we encourage people to keep them on if they feel comfortable.</p>

<p>The Shattered Space platform consists of:</p>

<ul>
  <li>An ExpressJS service that keeps track of the overall state of the show.</li>
  <li>7 Janus WebRTC media servers. One for each ship and a extra for broadcasting a livestream of the ending scene.</li>
  <li>The Admin App, a React/Redux webapp that handles scheduling shows, keeping track of which actor is talking to which ship, and has real-time dashboards with logs of client-side errors and connectivity issues.</li>
  <li>The Actor App, a React/Redux webapp used by actors to interact with the audience via audio, video, text, and the giving/taking of items from a ship’s inventory.</li>
  <li>The Attendee App, a React/Redux webapp where attendees view the show and interact with the actors and each other via audio, video and text.</li>
  <li>The Host App, used by me to perform the motion-captured ending scene.</li>
</ul>

<p>When I say that the Show Service “keeps track of the overall state of the show”, I mean <em>all</em> of the state. Most of the Redux actions (across all 3 apps) don’t mutate the state of the reducers, but instead hit an endpoint on the Show Service that changes the state kept in the database, then fetches <em>all</em> of the state from the database and sends it to <em>all</em> of the users as a WebSocket message which then overwrites most of the reducers’ state. This way, no client can end up with “orphan state” as a result of optimistically updating their reducer before their API call returns, and fetching the updated state for <em>all</em> users can be done with a single database call (this refresh-all-state-for-everyone method is debounced and implements a queueing mechanism to ensure we don’t have too many database calls at once).</p>

<p><img src="https://chrisuehlinger.com/images/shattered/redux-oops.jpg">
<strong>I basically took Dan Abramov’s simple and elegant system and did this to it. <br> Sorry Dan.</strong></p>

<p>(I’d note that this architecture emerged sort of organicly and there are probably cleaner or more optimal ways of achieving this “Redux-but-the-server-is-the-reducer” architecture. I’m open to feedback on whether something like Relay or Meteor would be a better fit for a V2)</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/admin-show-online.png"></p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-screen.png">
<strong>The Admin app allows us to see who’s logged on and what’s happening in the show</strong></p>

<p>Of the 3 React/Redux apps, the Admin App uses the least of these shiny web technologies, and is pretty much just a dashboard for displaying what’s in the database. As admins, we can see which actors and attendees have logged on, which ships are currently visiting which actors, we can move attendees between ships if need be, and we can see a list of errors the actors and attendees have encountered (more on this later).</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-app-normal.png">
<strong>The actor app allows performers to engage with the audience and view information about the ship they’re talking to</strong></p>

<p>The Actor App is more sophisticated, since it needs to handle WebRTC and media device concerns. It also has 3 modes: Normal, Mobile (used automatically if the window has a dimension less than 500px) and Headless (used if the querystring variable <code>headless</code> is set to <code>true</code>. The Normal mode is used by about half of the actors, and has the ability for them to see themselves, configure their audio/video devices, change any info about their user, character or planet, and view information about the ships they’re talking to (their chat, inventory, history of previous places, etc.).</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-app-mobile.jpg">
<img src="https://chrisuehlinger.com/images/shattered/screenshots/actor-app-headless.png">
<strong>The mobile and headless modes of the actor app give our actors flexibility to use whatever devices they have available</strong></p>

<p>The Mobile mode uses a tab-based layout to try and accomplish all the same goals, but since only one tab can be on the screen at a time, it’s a bit of a pain to use on its own. We’ve got Headless mode, which doesn’t do any of the audio/video streaming, but shows all the information about the current ship and can run on any laptop. Many actors have opted for using the Mobile mode (since their phone has a good camera) but keeping Headless mode open on an old laptop to make it easier to use the other features.</p>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/ship-in-flight.png">
<strong>A group of attendees interacting with a character in the show</strong></p>

<p>The Attendee app is about as complex as the actor app, but doesn’t have a Headless mode (which is really just a power-user feature for actors). This app has multiple screens corresponding to the different phases of the show:</p>

<ul>
  <li>Preshow - A lobby screen where attendees can meet the shipmates they’ll be flying with</li>
  <li>Intro - A tutorial video</li>
  <li>Freeplay - The bulk of the show, where attendees alternate between interacting with characters and choosing their next destination from the Navigation Screen</li>
  <li>Ending - A livestreamed 3D ending scene</li>
  <li>Ended - This just redirects attendees out of the app to <a href="https://shatteredspace.live/program.html" target="_blank">a static page with our casts’ bios</a>.</li>
</ul>

<p><img src="https://chrisuehlinger.com/images/shattered/screenshots/host-app.jpg">
<strong>My setup for performing the motion capture at the end of the show</strong></p>

<p>At the end of the show, I perform a scene as Colonel Panic, the AI commander of the Star Jockeys. In this scene I go around to each ship and review the items they’ve managed to collect. Then a “resolution” happens that I won’t spoil here.</p>

<p>This performance is rendered on my desktop PC (Intel 8700K + RTX 2080TI) with a special version of the Actor app that I’ve built just for this purpose. The three.js scene here involves at least 7 huge models with MeshPhysicalMaterials and a dozen moving PointLights, so rather than rendering on attendees’ computers, I render it on mine and stream it to them using an <a href="https://www.elgato.com/en/gaming/cam-link-4k" target="_blank">Elgato Camlink 4K</a>, ffmpeg and the Janus (explained below) <a href="https://janus.conf.meetecho.com/docs/streaming.html" target="_blank">Streaming plugin</a>.</p>

<p>The motion capture work is done by taking a modified version of Apple’s <a href="https://developer.apple.com/documentation/arkit/tracking_and_visualizing_faces" target="_blank">TrackingAndVisualizingFaces</a> example from the ARKit docs and having it send each frame of mocap data over WebSockets to the server, which then forwards them to the Host app. It’s amazing that this works with sub-100ms latency, but it does.</p>

<p>I’m planning on open-sourcing all of this when the show is done, but I’d want to purge the git history in case there are any secrets lying around, and I’d warn any interested spelunkers that it will be more of an …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/">https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/</a></em></p>]]>
            </description>
            <link>https://chrisuehlinger.com/blog/2020/06/16/unshattering-the-audience-building-theatre-on-the-web-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23651117</guid>
            <pubDate>Fri, 26 Jun 2020 12:17:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bulding a Career in Aerodynamics]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650983">thread link</a>) | @seaghost
<br/>
June 26, 2020 | https://airshaper.com/blog/building-your-career-in-aerodynamics | <a href="https://web.archive.org/web/*/https://airshaper.com/blog/building-your-career-in-aerodynamics">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2><p>The top 3 question we receive from students are:</p><ul><li>How can I build a career in aerodynamics?</li><li>Do you have an open position at AirShaper / know of another company with open positions?</li><li>Can you support our Formula Student team?</li></ul><p>In this blog we'll zoom in on the first &amp; second question:
👣Which steps do you need to take to lang a job in the fascinating world of aerodynamics!</p><h2>Education 🎒</h2><p>Yes, this is important: if you're applying for a job, your education matters. Most (mechanical) engineering bachelor or master tracks will include at least an introduction to fluid mechanics, as it's crucial to many engineering problems (damper design, hydrodynamics, HVAC - heating, ventilation and air conditioning, ...). Or, you can follow a master really dedicated to the field of fluid dynamics, often with a choice between experimental (real-life testing) and/or computational (computer simulations). Of course, the choice of the institute is important: some, like the TUDelft in the Netherlands, have a superb reputation and that will help you shine on your CV. Finishing such a master is of course fantastic, but still, you will not be entirely unique (unless you were the only student to follow that course, in which case you may want to question the course itself 😎).</p><p><img alt="alt text" title="Courses on Aerodynamics at the TUDelft, Netherlands" src="https://airshaper.com/assets/images/tudelft.png"></p><p>There is something else which is, at least in my opinion, equally important:
self-study.
Companies will appreciate &amp; sometimes even demand the skills &amp; knowledge you gained through your studies, but they will in many cases look for something extra, something that sets you apart.
If you can talk at length about the go-kart you pimped aerodynamically in your backyard, or how you spent long evenings programming your own CFD (computational fluid dynamics) code, this can really set you apart.</p><h2>Exposure 🗣</h2><p>You can have plenty of skills, but you'll have to make them known to the world. Applying for open positions is an obvious way of doing so. But you could also build a network, even before you graduate, in the aerodynamics scene: write a blog, write stoties on Linkedin, post aero stuff on Twitter, ... let the world know you have a burning passion for aerodynamics.</p><p>It's not a straight path to success, and it's difficult to gauge the "return on investment", but you may be surprised by how you can sometimes end up talking to interesting people. And don't let anything hold you back: even if the people you want to talk to are senior people at respectable companies, just give it a try: add them on Linkedin, send them that interesting paper you did on your go-kart.</p><p><img alt="alt text" title="Willem Toet - Sauber" src="https://airshaper.com/assets/images/willem_toet.png"></p><p>Last but not least, don't underestimate the physical world:
Motorsport fairs for example (like the ones in Birmingham or Cologne) are a great place to find &amp; meet very interesting people. I've had multiple encounters with Willem Toet, for example. He's a legend in terms of aerodynamics, has worked at Sauber for years, but is one of the most charming &amp; accessible people in the entire racing scene. He &amp; others like him often give interesting (free) talks at such events. After the talk? Just walk up there and tell an interesting story that sticks! As to date, there is no app that will replace the quality of a face-to-face meeting 😇</p><h2>Dedicated channels⚡</h2><p>The first person ever to start working at AirShaper came to us via a job we had placed on <a href="https://www.cfd-online.com/Jobs/" target="_blank">CFD Online</a>, a specialist forum dedicated to computational fluid dynamics. In a similar way, but then dedicated to aerodynamics rather than CFD, we've created the <a href="https://www.airshaper.com/jobs/landing" target="_blank">AirShaper Job Board</a>. On this free &amp; open platform, people can create a profile to be discovered and companies can post vacancies.</p><h2>Indirect paths 🏎</h2><p>If you're dreaming of a job in Formula 1, don't over-focus on it.</p><p>First of all, being responsible for the aerodynamics of an entire car at a small company might be more rewarding than working on barge board number 3 on a Formula One car.</p><p>Second of all, an indirect path might actually be the more efficient &amp; interesting one. Even if you start out working on drones, you may still end up at a race team later on. They might even value your expertise from a different sector.</p><p>Just stay open to interesting things that cross your path, instead of focusing solely on that ultimate goal. For all you know, you may discover another domain you find even more interesting!</p><h2>Perspective 📷</h2><p>A cheesy one, but don't forget to live :)
Working on something you're passionate about is great, but please do balance work with other interesting things to do - it'll feed your creativy and keep you fresh!</p><h2>Conclusion 💡</h2><p>Besides proper education, applying your passion to private projects and talking about it to people around you and people in aerodynamics scene can really make a difference. Go beyond the text books that others have read as well and play around, experiment and enjoy aerodynamics - by doing so, you'll come across interesting people &amp; opportunities in life!</p></div></div>]]>
            </description>
            <link>https://airshaper.com/blog/building-your-career-in-aerodynamics</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650983</guid>
            <pubDate>Fri, 26 Jun 2020 11:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Financial Statements: A Beginner's Guide]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650823">thread link</a>) | @refrigerator
<br/>
June 26, 2020 | https://www.causal.app/blog/whats-a-financial-statement | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/whats-a-financial-statement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The finance world is quickly entering the mainstream —</p><p>Every month a notable company goes public. Every week a hot startup raises millions of dollars. And every day moms, pops, and teens check on their stocks. </p><p>Whether a company builds rocket engines or mobile apps, they tell their story using the same language —&nbsp;financial statements. Here's how they work.</p><p>Let's say you run a subscription t-shirt business.</p><p>It's going well — you have happy customers and healthy profit. You're thinking of buying your own factory to make more t-shirts, more quickly, and more cheaply.</p><p>There's just one problem — you can't afford a factory.</p><p>So, you ask the bank for a loan. Your company is profitable and the factory will pay for itself in 3 years, so you know you'll be able to pay it back. But while you know this, the bank doesn't — you'll need to convince them. The bank, however, doesn't know anything about the subscription clothing business.</p><p>To get on the same page, you need a shared language for talking about your business.</p><p><h4 id="heading-1">Double-entry Bookkeeping: The birth of accounting</h4></p><p>Double-entry bookkeeping was the first formalism in finance. The Middle East had it in the <a href="https://www.jstor.org/stable/40697986" target="_blank">first century AD</a>, Korea independently got it in the <a href="https://www.worldcat.org/issn/1598-2661" target="_blank">11th century</a>, and by the <a href="https://web.archive.org/web/20170627232023/http://130.74.92.202:82/record=b1000778" target="_blank">1500s</a>, it had been well-documented across Europe.</p><p>It's a simple concept designed to reduce errors when documenting transactions: every entry to an "account" requires an equal and opposite entry to another "account".</p><p>If you bought some cotton to turn into t-shirts, you might record the transaction like this:</p><p>‍</p><figure id="w-node-371c827e421c-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde0379b53032713cde77_bookkeeping.png" alt=""></p></figure><p>‍</p><p>When you spend $100 on cotton, your "Cash" account gets debited (loses) $100, and your "Materials" account gets credited (gains) $100. The underlying principle is that <em>you can't create something out of nothing</em>.</p><p>This might seem contrived, but with more and more transactions, it can help you spot errors. Since every entry has an equal and opposite entry, the sum of all the debits should always equal the sum of all the credits. If not, you know you made a mistake, and you can look back through your transactions to find it.</p><p>A list of transactions is pretty interesting — it tells a very detailed story about what your company's been up to. Certainly enough to answer the bank's questions when you ask for loan.</p><p>But just as the bank doesn't have time to learn about subscription t-shirts businesses, they don't have time to go through thousands of transactions. To understand what's going on, they need a shorter summary.</p><p><h4 id="heading-2">Financial Statement #1: The Balance Sheet</h4></p><p>If you went through all your transactions and worked out the net value of each account, you'd be able to see things like</p><ul role="list"><li>How much cash you have in the bank</li><li>The total value of the cotton in your inventory</li><li>How much money you owe to your cotton suppliers</li></ul><p>This will give you a snapshot of the current state of your company, split up into "everything you own" (<strong>Assets</strong>) and "everything you owe" (<strong>Liabilities</strong>) — a <strong>Balance Sheet</strong>. These generally won't be equal — ideally your assets will be worth more than your liabilities.</p><p>The difference between the assets and the liabilities is what you, the owner of the company, can rightfully stake a claim to. Crudely, if you sold all your assets today and used that money to pay off all your debts, you'd be left with a pile of cash all to yourself.</p><p>This idea is usually expressed by the "accounting equation":</p><p><strong>Assets - Liabilities = Shareholders Equity</strong></p><p>This is where the "balance" comes in: both sides of the equation are equal. Note that this equation is actually a definition — it asserts that the value of the <strong>Shareholders Equity</strong> is the difference between <strong>Assets</strong> and <strong>Liabilities</strong>. This is the same equation that underpins double-entry bookkeeping.</p><p>Here's what your balance sheet might look like:</p><p>‍</p><figure id="w-node-89b5b437bd58-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefde1a11602b68a068a079_balance-sheet.png" alt=""></p></figure><p>‍</p><p>The bank will be interested in seeing this before giving you a loan. It's a quick 'n' dirty way for them to understand the big picture:</p><ul role="list"><li>The orders of magnitude involved — does this company operate in the thousands, millions, or billions?</li><li>An estimate for how much the company is "worth", based on the shareholders equity</li><li>An indication of company health — is the company drowning in debt?</li></ul><p>Financiers often calculate metrics based on the balance sheet, to further summarise the information and to compare numbers across companies.</p><p>The <strong>Debt/Equity Ratio</strong> is a big one, telling you how much a company relies on borrowing money. If it's too high then the company might be too dependent on loans, but if it's too low, this might indicate an inefficiency, since borrowing money to spend on growth can be quicker than earning it the hard way.</p><p>So — the balance sheet summarises a lot about your company, in a way that the bank can understand.</p><p>Unfortunately, it doesn't answer a crucial question — "Do you make money?"</p><p><h4 id="heading-3">Financial Statement #2: The Income Statement (P&amp;L)</h4></p><p>The balance sheet is a snapshot of a single point in time. To understand whether a company makes money, you need see how things change over a period of time (e.g. every month).</p><p>The first thing you need to know is how much money you receive — your <strong>Revenue</strong>. You don't keep all of it — there are costs and expenses along the way — so you need to subtract these. The final number you end up with is your <strong>Profit</strong> — the money you've made at the end of the day.</p><p>Here's how you might do the calculation:</p><p>‍</p><figure id="w-node-a4e76259fbb4-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe0c6c8f0be2b6743533b_p%26l.png" alt=""></p></figure><p>‍</p><p>You start at Revenue (the top line), subtract your costs, and end up at Profit (the "bottom line" — get it?). This is a simple <strong>Profit &amp; Loss (P&amp;L)</strong>, or <strong>Income Statement</strong>. Most companies make one every month, to keep an eye on things. </p><p>‍</p><figure id="w-node-fec0fade16bf-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe17879b5309ce33ce18b_35274025-14536291245349646_origin.png" alt=""></p></figure><p>‍</p><p>With a P&amp;L, you and the bank can understand what's going in and out of your business. If your P&amp;L consistently shows a profit, then the bank will be happy, and so will you.</p><p>In theory, this is very simple. But in practice, each P&amp;L item has hidden nuances to address.</p><p>Let's take just the top line — what does <strong>Revenue</strong> actually mean?</p><p><strong>What is revenue?</strong></p><p>When you started selling shirts, it was a simpler time — you bought them in bulk from China and sold them at the local market.</p><p>Revenue, too, was simple — it was the cold hard cash in your hand.</p><p>But things changed. You started taking bulk orders from shops, who pay you 1 month after you deliver the shirts. And when you went online, your customers started paying you for 12 month subscriptions, all in one go.</p><p>It turns out that if you keep thinking of revenue as "cash in your hand", then things get a little weird —</p><ul role="list"><li>When you get a bulk order, your expenses shoot up. But since you don't get paid until next month, your profit goes way down this month.</li><li>When someone buys a 12-month subscription, your revenue spikes up. But for the next 11 months you have to keep delivering on the order (non-zero cost) without further payments (zero revenue) — your bottom line takes a hit.</li></ul><p>Bulk orders and upfront payments are great for your business, but if revenue means "cash in hand", then your P&amp;L might tell the opposite story.</p><p>A better way to think about revenue is as "the value of products delivered or service provided".</p><p>In each month of a subscription, you do 1 month of work. So even with 12 months' payment upfront, you only recognise 1/12th of that payment as revenue each month. The remaining 11/12th becomes <strong>Deferred Revenue.</strong> This is actually a liability on your balance sheet — your customers have essentially given you a loan which you must pay back each month, in the form of t-shirts.</p><p>The same principle applies for bulk orders — you recognise the revenue when you deliver the product, <em>not</em> when you get paid.</p><p>This is called <strong>Accrual Accounting</strong>, and it more accurately answers the question "Do you make money?".</p><p>So — you've got a balance sheet, showing your current financial state, and you've got a P&amp;L, showing how things change over time. The bank, however, remains unsatisfied.</p><p>Sadly, consistent profits, measured with accrual accounting, can still leave you penniless on payday.</p><p><h4 id="heading-4">Financial Statement #3: The Cashflow Statement</h4></p><p>In 1863, the Dowlais Iron Company had a dilemma.</p><p>On paper, things were great — they'd recovered from a downturn and were posting healthy profits. To smelt more iron, they set out to buy a new blast furnace. But despite their promising P&amp;L, it turned out that they had no cash to buy it.</p><p>What gives?</p><p>Their problem was in spending cash too quickly — as soon as they got some, they'd use it on inventory (iron ore, etc). The profits were rolling in, but the cash wasn't sticking around.</p><p>The company needed a way to understand how cash was coming in and out — the cashflow. Their solution was the origin of the modern <strong>Cashflow Statement</strong>.</p><p>Like the P&amp;L, the cashflow statement shows how things change over each month, but crucially, it only focuses on cash — how much you started with, what you spent it on, where you got more of it, and how much you ended up with. In short, the cashflow statement explains the difference between one balance sheet and the next.</p><figure id="w-node-508193268673-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5eefe644e9cf27ec56e99c29_Untitled-3.png" alt=""></p></figure><p>The bank should now have enough information to decide whether to give you a loan:</p><ul role="list"><li>Balance Sheet — shows everything that you own, and everything that you owe</li><li>P&amp;L/Income Statement — shows how your business operates</li><li>Cashflow Statement — shows how you spend and earn cash</li></ul><p>These financial statements are a shared language, letting businesses communicate across industries and borders. They also "flatten" a business' evolving operations — new business models, delivery methods, and products — to give a coherent view of a company through time.</p><p>Investors use financials to judge performance, lenders use them to assess credit-worthiness, and governments use them to make sure that taxes are correctly paid.</p><p>But the whole system only works if every company follows the same rules when compiling their financials. These rules require years of study to fully understand (this is why accountants exist) and include:</p><ul role="list"><li>How to recognise revenue —&nbsp;accrual accounting</li><li>How to "amortise" costs — spreading upfront expenses over time</li><li>How to "capitalise"&nbsp;costs —&nbsp;turning big purchases into assets on the balance sheet</li></ul><p>Who made these rules?</p><p><h4 id="heading-5">Accounting Standards: Mind the GAAP</h4></p><p>The Industrial Revolution …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.causal.app/blog/whats-a-financial-statement">https://www.causal.app/blog/whats-a-financial-statement</a></em></p>]]>
            </description>
            <link>https://www.causal.app/blog/whats-a-financial-statement</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650823</guid>
            <pubDate>Fri, 26 Jun 2020 11:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working on iPad]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 95 (<a href="https://news.ycombinator.com/item?id=23650763">thread link</a>) | @tosh
<br/>
June 26, 2020 | https://www.notion.so/vercel/Working-on-iPad-ccefea4f9e06455da169c97b3fe054c1 | <a href="https://web.archive.org/web/*/https://www.notion.so/vercel/Working-on-iPad-ccefea4f9e06455da169c97b3fe054c1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/vercel/Working-on-iPad-ccefea4f9e06455da169c97b3fe054c1</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650763</guid>
            <pubDate>Fri, 26 Jun 2020 11:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kindness for Mean Girls]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650749">thread link</a>) | @lelf
<br/>
June 26, 2020 | https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html | <a href="https://web.archive.org/web/*/https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<h4 id="a-primer-on-the-cruel-tacit-laws-of-type-level-programming-in-haskell"><em>A primer on the cruel, tacit laws of type-level programming in Haskell</em></h4>

<p>Haskell programs are constructed at the junction of two worlds: one of types, and the other of values. Values are operational run-time entities that are denoted syntactically by <em>terms</em> in the code. To this end, types classify terms. They provide a powerful abstraction to organize data, determine how it should be stored in memory, passed through various operations, and more. On a superficial level, the difference between these worlds is simple: <em>types</em> refer to datatypes, which are either built-in (such as <code>Integer</code> and <code>String</code>), or user-declared, for example:</p>

<pre><code>data SpringFlingQueen = Cady | Regina
</code></pre>

<p>By comparison, <em>values</em> are denoted by <em>terms</em> those types categorize (such as <code>1</code> and <code>"abc"</code> described by the standard library’s <code>Integer</code> and <code>String</code> types, or <code>Cady</code> and <code>Regina</code> in the case of our user-declared type, <code>SpringFlingQueen</code>). Thus, the term <code>1</code> denotes a value that exists in memory only when the program is run.</p>

<p>In addition to these two worlds, a third, darker, and more elusive underworld of <em>kinds</em> also lurks in the shadows of Haskell programs. Haskell kinds can be as unpredictable and insidious as the soulless alpha-female of an elite high school clique. While daunting, understanding the coaction between these three worlds lays the foundation for type-level programming, a topic worth learning as it strengthens overall Haskell intuition.</p>

<p><img src="https://user-images.githubusercontent.com/875834/81239044-afe24580-8fd1-11ea-96b0-274cf839e834.png" alt="the haskell type system: a machine of constant, unforgiving judgement and rigid classification"></p>

<h3 id="kindness-is-a-virtue">Kindness is a virtue</h3>

<p>Much like counter-intuitive adolescent social dynamics, mastery of Haskell bears a steep learning curve because of its underlying complexity. It is difficult to wrap one’s head around the language’s typeclass hierarchies, category-theoretic roots, or the intricacies of compiler behavior. However, an intimate understanding of the type system lets programmers look beyond the chaos of code and apply a recognizable template by which to understand it.</p>

<h3 id="kindness-takes-patience">Kindness takes patience</h3>

<p>This topic is also difficult to master because it is both vast and subtle. Ideas underlying type-level programming are scattered across many disconnected resources focused on several corners of the Haskell ecosystem. Authoritative references on the topic (such as relevant library documentation) tend to assume familiarity with domain-specific terminology that may be unknown to non-experts. Due to the paucity of approachable materials on the subject, I’ve attempted to break down type-level programming into explanations of its constituent parts. While I don’t go into extensive depth on any individual section below, I hope to provide a valuable starting point with which readers can explore ideas in greater detail.</p>

<table>
  <thead>
    <tr>
      <th>Table of contents</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="#Types-vs-Values">Types vs. Values</a></td>
    </tr>
    <tr>
      <td><a href="#Kinds">Kinds</a></td>
    </tr>
    <tr>
      <td><a href="#higher-kinded-types">Higher-kinded types</a></td>
    </tr>
    <tr>
      <td><a href="#constraint-kinds">Constraint kinds</a></td>
    </tr>
    <tr>
      <td><a href="#PolyKinds">Kind polymorphism</a></td>
    </tr>
    <tr>
      <td><a href="#DataKinds">DataKinds and type-level literals</a></td>
    </tr>
    <tr>
      <td><a href="#Datatype-promotion">Datatype promotion</a></td>
    </tr>
    <tr>
      <td><a href="#Relationship-between-values-terms-types-and-kinds">Relationship between values, terms, types, and kinds</a></td>
    </tr>
    <tr>
      <td><a href="#The-difference-between-type-and-type-level">The difference between “type” and “type-level”</a></td>
    </tr>
    <tr>
      <td><a href="#type-families">Type families</a></td>
    </tr>
    <tr>
      <td><a href="#associated-types">Associated types</a></td>
    </tr>
    <tr>
      <td><a href="#TypeLits">GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#Distinguishing-between-DataKinds-and-TypeLits">Distinguishing between DataKinds and GHC.TypeLits</a></td>
    </tr>
    <tr>
      <td><a href="#use-case-Marshaling-ASTs">Use-case: Marshaling ASTs</a></td>
    </tr>
    <tr>
      <td><a href="#The-hype-of-dependently-typed-langs">The hype of dependently-typed languages</a></td>
    </tr>
  </tbody>
</table>

<hr>

<h3 id="types-vs-values">Types vs. Values</h3>

<p>As mentioned above, Haskell programs are divided into two worlds: the <em>type-level</em> and the <em>value-level</em>. The <em>type-level</em> refers to the part of a program analyzed by the static type-checking phase during compilation. Since every expression is assigned a type, code is checked against Haskell’s type system to ensure it fits <a href="https://www.haskell.org/ghc/">GHC</a>’s specified correctness criteria.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704534-fce9fd80-af27-11ea-9544-13961a56c444.png" alt="types classify terms, just like hostile teens with identity crises classify one another"></p>

<p>If the program is well-typed, the program will compile. However, this type-information evaporates once the compilation process terminates, leaving only <em>values</em> behind at run-time. In this way, types and values can be better distinguished by the phasing distinction, with types being compile-time entities and values being run-time entities.</p>

<p>For example, if a function takes a <code>String</code>, the type-checker doesn’t care if the <code>String</code> has a value denoted by <code>"abc"</code> or <code>"123"</code> or <code>"get in loser"</code>—so long as it’s a <code>String</code>. Type information gets discarded at run-time, leaving only the string’s value (ex.,<code>"get in loser"</code>). In some cases, however, we want the type system to care about what those values are and distinguish between them. The <code>DataKinds</code> extension, which we’ll explore below, lets us do that by allowing us to shove more information about our program into the type system. This lets us add meaning to the value of a <code>String</code> at the type-level, moving them from their usual, strictly run-time existence, into the compile-time phase. The technique allows us to use more information statically in the logical development and abstraction of the program’s behavior. We’re also able to add consequences that can halt compilation if the specific value of <code>String</code> doesn’t conform to the rules we’ve specified, or define classes over them.</p>

<h4 id="distinguishing-types-and-values-in-ghci">Distinguishing types and values in GHCi</h4>

<p>Let’s examine our aforementioned <code>SpringFlingQueen</code> datatype in GHCi. When we query the type of one of its constructors using <code>:t</code> (a handy shorthand for <code>:type</code>), we see that it is indeed of type <code>SpringFlingQueen</code>:</p>

<div><div><pre><code>λ data SpringFlingQueen = Cady | Regina
λ :t Cady
Cady :: SpringFlingQueen
</code></pre></div></div>

<p>Now consider literals <code>1</code>, <code>2</code>, <code>3</code>. These are <em>values</em> of a type that parameterizes the <code>Num</code> class:</p>



<p>Typing <code>:t 1</code> into GHCi gives us <code>Num p =&gt; p</code>, indicating that a literal such as <code>1</code> can be of any polymorphic type <code>p</code> as long as the <code>Num</code> type class has instances for that type (for example, <code>Integer</code> and <code>Float</code> both have <code>Num</code> instances and therefore are valid types that <code>p</code> could be instantiated with). This is possible due to <a href="https://wiki.haskell.org/Type_inference">type inference</a>.</p>

<p><img src="https://user-images.githubusercontent.com/875834/84704346-ae3c6380-af27-11ea-8078-6f1ddfc7b238.png" alt="type inference can be used to deduce concrete types wherever they're obvious. If a type looks like a mouse, it's a mouse—duh!"></p>

<h3 id="kinds">Kinds</h3>

<p>Just like types classify terms, <a href="https://www.haskell.org/onlinereport/decls.html#sect4.1.1">kinds</a> classify types, and therefore are frequently described as “types of types”, or referred to be “one level up.” The “star” syntax (i.e., <code>*</code>) denotes kinds. It is defiantly used in this post despite <a href="https://github.com/ghc-proposals/ghc-proposals/blob/master/proposals/0143-remove-star-kind.rst">recent syntactic changes</a>. A prerequisite for understanding the kind system necessitates comprehending the differences between three pairs of ideas:</p>

<ol>
  <li>
    <p><strong>Data constructors vs. type constructors:</strong> data constructors create values, whereas type constructors create types. Type constructors take one or more type arguments and produce a datatype when enough arguments are provided. This means that through <a href="https://wiki.haskell.org/Currying">currying</a>, a type constructor can be <a href="https://wiki.haskell.org/Partial_application">partially applied</a>. For example, the list type constructor <code>[]</code> may take a single type argument (ex. <code>String</code>) to denote the elements of the list (i.e., <code>[String]</code>). <code>[String]</code> is simply syntactic sugar for <code>[] String</code>, where the type <code>[]</code> is applied to <code>String</code>.</p>
  </li>
  <li>
    <p><strong>Full vs. partial application</strong> A partially-applied type, like a <a href="https://wiki.haskell.org/Partial_application">partially-applied function</a>, is one that is missing some of its data constructors. For instance, consider the list type <code>[]</code>. The kind of <code>[]</code> is <code>* -&gt; *</code>. A fully-applied list has data constructors, such as <code>[Int]</code>, and its kind is <code>*</code>.</p>
  </li>
  <li>
    <p><strong>Inhabited types vs. uninhabited types:</strong> An inhabitant of a type is precisely a value of that type. This means that <em>inhabited</em> types refer to the types that contain concrete values, such as the value denoted by the term <code>1 :: Int</code>. This suggests that the type <code>Int</code> is inhabited by value denoted by <code>1</code>. By contrast, <em>uninhabited</em> types refer to type constructors to which no values are abstracted. For instance, <code>Void</code> is uninhabited because it has no data constructors, and thus can not be used to construct a valid term. While <code>Void</code> may seem pointless at first, it can be a useful way to represent that a container is empty (ex., <code>[Void]</code>, which <em>is</em> inhabited by the term <code>[]</code> and the value this term denotes).</p>
  </li>
</ol>

<p>How do these ideas relate to the kind system? Well, all fully-applied runtime values are of kind <code>*</code> <em>and</em> they are inhabited. You can confirm this by typing <code>:k Int</code> and <code>:k String</code> in GHCi. However, this doesn’t work the other way around—just because a type is inhabited, doesn’t necessarily mean it’s fully-applied (ex., <code>[]</code> is not fully-applied but it <em>is</em> inhabited, and its kind signature is <code>* -&gt; *</code>). Conversely, all partially-applied types are uninhabited (since they don’t correspond to a value), but not all uninhabited types are partially applied. <code>Void</code> for instance is not partially-applied, but it is uninhabited.</p>

<p>To get the hang of this idea, consider the following examples:</p>

<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Inhabited?</th>
      <th>Fully-applied?</th>
      <th>Kind</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Int</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>String</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>[]</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>[Int]</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>(,)</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Either</code></td>
      <td>Yes</td>
      <td>No</td>
      <td><code>* -&gt; * -&gt; *</code></td>
    </tr>
    <tr>
      <td><code>Void</code></td>
      <td>No</td>
      <td>N/A</td>
      <td><code>*</code></td>
    </tr>
    <tr>
      <td><code>Either Void Void</code></td>
      <td>Yes</td>
      <td>Yes</td>
      <td><code>*</code></td>
    </tr>
  </tbody>
</table>

<p>Kind signatures can be specified manually in GHCi using the <a href="https://downloads.haskell.org/~ghc/8.0.1/docs/html/users_guide/glasgow_exts.html#ghc-flag--XKindSignatures"><code>XKindSignatures</code></a> extension. Try extending the above table by investigating the kind signatures of various types.</p>

<h3 id="higher-kinded-types">Higher-kinded types</h3>

<p>Just like there are higher-order functions (functions that take other functions as arguments), there are higher-kinded types (types constructors that take other type constructors as arguments). Type constructors such as <code>[]</code> are a first-class type, but also a higher-kinded type, given they take another type constructor to be reified:</p>



<p>Let’s consider <code>Functor</code>:</p>

<div><div><pre><code>λ :k Functor
Functor :: (* -&gt; *) -&gt; Constraint
</code></pre></div></div>

<p>We see that <code>Functor</code> takes a type constructor <code>* -&gt; *</code> and returns a <code>Constraint</code>. Let’s use <code>:info</code> to examine <code>Functor</code> a bit more closely:</p>

<div><div><pre><code>λ :info Functor
class Functor (f :: * -&gt; *) where
  fmap :: (a -&gt; b) -&gt; f a -&gt; f b
  (&lt;$) :: a -&gt; f b -&gt; f a
  {-# MINIMAL fmap #-}
  	-- Defined in ‘GHC.Base’
instance Functor (Either a) -- Defined in ‘Data.Either’
instance Functor ((,,,) a b c) -- Defined in ‘Data.Orphans’
instance Functor ((,,) a b) -- Defined in ‘Data.Orphans’
instance Functor [] -- Defined in ‘GHC.Base’
instance Functor Maybe -- Defined in ‘GHC.Base’
instance Functor IO -- Defined in ‘GHC.Base’
instance Functor ((-&gt;) r) -- Defined in ‘GHC.Base’
instance Functor ((,) a) -- Defined in ‘GHC.Base’
</code></pre></div></div>

<p>We see that <code>Functor</code> allows type constructors like <code>Maybe</code> and <code>[]</code> to have <code>Functor</code> instances, but not <code>Int</code> or <code>String</code>. This is because <code>Maybe</code> and <code>[]</code> are <code>* -&gt; *</code>, while <code>Int</code> has kind <code>*</code>. Similarly, <code>Either</code> has <code>* -&gt; * -&gt; *</code>, which is why its instance above is parameterized with a type parameter denoting something of kind <code>* -&gt; *</code>: <code>Either a</code>.</p>

<h3 id="constraint-kinds">Constraint kinds</h3>

<p>We got a glimpse of constraint kinds …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html">https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</a></em></p>]]>
            </description>
            <link>https://www.aymannadeem.com/haskell/2020/05/15/Kindness-for-Mean-Girls.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650749</guid>
            <pubDate>Fri, 26 Jun 2020 11:19:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Numerical Linear Algebra for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 75 (<a href="https://news.ycombinator.com/item?id=23650640">thread link</a>) | @dragandj
<br/>
June 26, 2020 | https://aiprobook.com/numerical-linear-algebra-for-programmers?release=0.9.0 | <a href="https://web.archive.org/web/*/https://aiprobook.com/numerical-linear-algebra-for-programmers?release=0.9.0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="lafp-why">
        
        
        
        <p>
          <h4>basically…</h4>



<h4>interactive &amp; dynamic</h4>
<h4>a direct link from theory to implementation</h4>
<h4>incredible performance</h4>
<h4>Intel &amp; AMD CPUs (MKL)</h4>
<h4>Nvidia GPUs (CUDA and cuBLAS)</h4>
<h4>AMD GPUs (yes, OpenCL too!)</h4>
<h4>Clojure (it’s magic!)</h4>
<h4>Java Virtual Machine (without Java boilerplate!)</h4>
<h4>complete source code</h4>
<h4>beautiful typesetting (see the sample chapters below)</h4>

        </p>
      </div><div id="lafp-interactive">
        
        
        
        <p>
          

<h4>see the result of executing each line</h4>
<h4>experiment in a live environment</h4>

<h4>no C++ build hell</h4>

<h3>no C++ syntax hell!</h3>

<h4>Java Virtual Machine, but without Java boilerplate</h4>

<h4>Clojure, the nicest language on earth :-)</h4>



        </p>
      </div><div id="lafp-fast">
        
        
        
        <p>
          

<h3>yet, high-level (you don’t touch C++)</h3>

<h2>CPUs</h2>

<h4>learn Intel MKL</h4>

<h2>GPUs</h2>

<h4>learn CUDA &amp; cuBLAS</h4>
<h4>learn OpenCL</h4>
<h4>all hardware: Nvidia, AMD, Intel</h4>

<h3>you don’t touch C++!!!</h3>

        </p>
      </div><div id="lafp-contents">
        
        
        
        <div>
          <h2>Table of Contents</h2>

<h3>Part 1: Getting Started (SOON)</h3>

<h4>Hello world (SOON)</h4>

<h4>Vectors, matrices, and linear algebra API (SOON)</h4>

<h4>Polymorphic acceleration (SOON)</h4>

<h3>Part 2: Linear algebra refresher (<a href="https://www.patreon.com/linear_algebra?ref=20">AVAILABLE</a>)</h3>

<h4>Vector spaces (<a href="https://www.patreon.com/linear_algebra?ref=21">AVAILABLE</a>)</h4>

<h4>Eigenvalues and eigenvectors (<a href="https://www.patreon.com/linear_algebra?ref=22">AVAILABLE</a>)</h4>

<h4>Matrix transformations (<a href="https://www.patreon.com/linear_algebra?ref=23">AVAILABLE</a>)</h4>

<h4>Linear transformations (<a href="https://www.patreon.com/linear_algebra?ref=24">AVAILABLE</a>)</h4>

<h3>Part 3: High performance matrix computations (<a href="https://www.patreon.com/linear_algebra?ref=40">AVAILABLE</a>)</h3>

<h4>Using matrices efficiently (<a href="https://www.patreon.com/linear_algebra?ref=41">AVAILABLE</a>)</h4>

<h4>Linear systems and factorization (<a href="https://www.patreon.com/linear_algebra?ref=42">AVAILABLE</a>)</h4>

<h4>Singular value decomposition (SVD) (<a href="https://www.patreon.com/linear_algebra?ref=43">AVAILABLE</a>)</h4>

<h4>Orthogonalization and least squares (<a href="https://www.patreon.com/linear_algebra?ref=44">AVAILABLE</a>)</h4>

<h3>Part 4: GPU acceleration</h3>

<h4>GPU computing crash course</h4>

<h4>CUDA and cuBLAS on Nvidia GPUs</h4>

<h4>OpenCL and CLBlast on AMD GPUs</h4>

<h3>Part 5: In practice (<a href="https://www.patreon.com/linear_algebra?ref=50">IN PROGRESS</a>)</h3>

<h4>Generating random matrices (<a href="https://www.patreon.com/linear_algebra?ref=51">AVAILABLE</a>)</h4>

<h4>Broadcasting (<a href="https://www.patreon.com/linear_algebra?ref=52">AVAILABLE</a>)</h4>

<h4>Mean, variance, and correlation (<a href="https://www.patreon.com/linear_algebra?ref=53">AVAILABLE</a>)</h4>

<h4>Principal component analysis (PCA) (<a href="https://www.patreon.com/linear_algebra?ref=54">AVAILABLE</a>)</h4>

<h3>Appendix</h3>

<h4>Setting up the environment and the JVM</h4>

        </div>
      </div></div>]]>
            </description>
            <link>https://aiprobook.com/numerical-linear-algebra-for-programmers?release=0.9.0</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650640</guid>
            <pubDate>Fri, 26 Jun 2020 11:00:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Creating Your Own Embedded Dynamic Web Site. Linux, Busybox, Httpd and Sqlite]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650614">thread link</a>) | @vyuh
<br/>
June 26, 2020 | http://programming.key-spot.ru/article_02.html | <a href="https://web.archive.org/web/*/http://programming.key-spot.ru/article_02.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<td>

<p><b>Creating Your Own Embedded Dynamic Web Site. Linux, Busybox, Httpd and Sqlite</b></p><p><b>Introduction</b></p>
<p>Embedded Linux usually offers limited capabilities for web application programming. Disk space, available memory, processing speed put certain restrictions that may not allow installing and running de-facto standard LAMP bundle (Linux, Apache, MySQL, PHP/Perl).</p>
<p>At the same time by default any embedded Linux distribution contains software suitable for web programming. The first thing that comes to mind is Busybox.</p>
<p>Busybox is a single executable combining many standard Unix tools, much like the larger (but more capable) GNU Core Utilities. Busybox incorporates minimalist replacements of a variety of Unix utilities into a small single binary file, which makes it ideal for special purpose distributions and embedded devices. It is sometimes called "The Swiss Army Knife of Embedded Linux".</p>
<p>Although Busybox is highly customizable and may contain more than 200 common Unix utilities, the most important for embedded web development among them are:</p>
<p>
(a) ash&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;&nbsp;a Bourne compatible shell used in resource-constrained environments<br>
(b) httpd&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;&nbsp;a simple, lightweight http server<br>
(c) awk&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;&nbsp;an awk programming language interpreter<br>
(d) sed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;&nbsp;&nbsp;a standard Unix utility for text transformation<br>
</p>

<p>These four Busybox applets combined can provide enough flexibility for creation of dynamic web site powered with CGI ash scripts.</p>
<p><b>Starting and Configuring Httpd</b></p>
<p>The full syntax of httpd server commands is available at Busybox web site. Here we will show some of its options omitting others:</p>

<p>
[busybox] httpd [-c conffile] [-p [ip:]port] [-u user[:grp]] [-r realm] [-h home]<br>
[busybox] httpd [-m pass]<br>
[busybox] httpd [-d/-e string]<br>
</p>

<p>
-c conffile&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;configuration file to read. By default it is /etc/httpd.conf, although the server can start without any configuration file at all.<br>
-p [ip:]port&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;allows binding to another port. By default the port is 80.<br>
-u user[:grp]&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;sets server's UID[/GID].<br>
-r realm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;sets authentication realm (a string appearing at web browser login/password prompt).<br>
-h home&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;home directory.<br>
-m pass&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;encrypts the pass string with MD5 algorithm.<br>
-d/-e string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;:&nbsp;respectively decode URL string and encodes HTML string<br>
</p>


<p>For example the following command will start httpd server listening on 8080 port, with configured options and having nobody's privileges:</p>

<p>
busybox httpd -c /etc/httpd.conf -p 8080 -u nobody -r "Protected Area" -h /home/www
</p>

<p>A sample configuration file with detailed comments is available at Busybox website. It is relatively simple and easy to understand. To encrypt users' passwords one may use the following command that will append respective string to the configuration file:</p>

<p>
echo /directory/path:username:`Busybox httpd -m userpassword` &gt;&gt; /etc/httpd.conf
</p>

<p><b>Writing a Simple Calendar Script</b></p>
<p>Any URL starting by /cgi-bin/ is assumed to be a CGI script. Needless to say that in order to run properly scripts must have executable bit set. The server passes scripts to ash shell for execution after setting environment variables. All form's variables and their values are put into QUERY_STRING.</p>
<p>For demonstration purpose we will write a script that shows a month's calendar based on arguments submitted. A piece of html code for a form that posts the data to our script is shown below:</p>

<p>
&lt;form method="post" action="./cgi-bin/calendar.cgi"&gt;<br>
Enter MM/YYYY&lt;br&gt;<br>
&lt;input type="text" name="m" value="" style="width: 24px"&gt;<br>
&lt;input type="text" name="y" value="" style="width: 40px"&gt;&lt;br&gt;<br>
&lt;input type="submit" value="Submit"&gt;<br>&lt;/form&gt;<br>
</p>

<p>Our calendar script has four distinctive parts (see below): html header code; query string processing; printing of calendar information; and closing html tags. The html code is primarily generated by awk.</p>

<div><p>
#!/bin/ash</p><p>
echo -e "Content-type: text/html; charset=UTF-8\n"<br>
echo "&lt;html&gt;&lt;head&gt;&lt;title&gt;Calendar script&lt;/title&gt;&lt;/head&gt;&lt;body&gt;"</p><p>
read QUERY_STRING<br>
eval $(echo $QUERY_STRING|sed 's/&amp;/ /g')</p><p>
for i in $(echo $QUERY_STRING|awk -F'&amp;' '{for(;i++&lt;NF;) print $i}'|cut -d= -f1)<br>
do<br>
<span>eval $i='`busybox httpd -d $'$i'`' 2&gt;/dev/null<br></span>
done</p><p>
echo "&lt;table&gt;"<br>
busybox cal $m $y|<br>
awk&nbsp;&nbsp;&nbsp;&nbsp;'{<br>
<span>if(NR&gt;1)<br></span>
<span>{<br></span>
<span>print "&lt;tr align=right&gt;"<br></span>
<span>for(i=1; i &lt; 21; i+=3) print "&lt;td&gt;" substr($0, i, 2) "&lt;/td&gt;"<br></span>
<span>print "&lt;/tr&gt;"<br></span>
<span>}<br></span>
<span>else print "&lt;tr align=center&gt;&lt;td colspan=7&gt;" $0 "&lt;/td&gt;&lt;/tr&gt;"<br></span>
<span>}'<br></span>
echo "&lt;/table&gt;"</p><p>
echo "&lt;/body&gt;&lt;/html&gt;"</p><p>
exit 0</p></div>

<p>Versions of Unix calendar utility (cal, gcal or ncal) have slightly different output format and may contain or omit leading and/or trailing empty strings or spaces. As a result it is recommended to check the difference and amend the code accordingly.</p>
<p>Obviously we can make query string processing code reusable by putting it into a separate resource file loadable at every execution of a script. For this purpose we create the following .httpd.rc file and place it into our CGI directory. One can also put there functions printing opening and closing html tags.</p>

<div><p>
header ()<br>
{<br>
echo -e "Content-type: text/html; charset=$1\n"<br>
echo "&lt;html&gt;&lt;head&gt;&lt;title&gt;$2&lt;/title&gt;&lt;/head&gt;&lt;body&gt;"<br>
}</p><p>
cgi ()<br>
{<br>
read QUERY_STRING<br>
eval $(echo $QUERY_STRING|sed 's/&amp;/ /g')<br>
for i in $(echo $QUERY_STRING|awk -F'&amp;' '{for(;i++</p><nf;) print="" $i}'|cut="" -d="-f1)<br">
do<br>
<span>eval $i='`busybox httpd -d $'$i'`' 2&gt;/dev/null<br></span>
done<br>
}<p>
end () { echo "&lt;/body&gt;&lt;/html&gt;"; }</p></nf;)></div>

<p>As a result our calendar script looks much more concise now:</p>

<div><p>
#!/bin/ash</p><p>
. ./.httpd.rc 2&gt;/dev/null || exit 1</p><p>
header UTF-8 "Calendar script"<br>
cgi</p><p>
echo "&lt;table&gt;"<br>
busybox cal $m $y|<br>
awk&nbsp;&nbsp;&nbsp;&nbsp;'{<br>
<span>if(NR&gt;1)<br></span>
<span>{<br></span>
<span>print "&lt;tr align=right&gt;"<br></span>
<span>for(i=1; i &lt; 21; i+=3) print "&lt;td&gt;" substr($0, i, 2) "&lt;/td&gt;"<br></span>
<span>print "&lt;/tr&gt;"<br></span>
<span>}<br></span>
<span>else print "&lt;tr align=center&gt;&lt;td colspan=7&gt;" $0 "&lt;/td&gt;&lt;/tr&gt;"<br></span>
<span>}'<br></span>
echo "&lt;/table&gt;"</p><p>
end</p><p>
exit 0</p></div>

<p><b>SQLite Web Interface</b></p>

<p>Due to its small footprint, extensive SQL syntax support and high speed, SQLite is a good choice for an embedded web site database.</p>
<p>SQLite can be compiled as a command-line executable utility to access and modify its databases. This utility reads lines of input from Linux shell and passes them on to the SQLite library for execution. To demonstrate how to access the data, we create a sample SQLite database ./emp.db with a single table containing the list of a company's employees and their respective salaries:</p>

<p>
CREATE TABLE IF NOT EXISTS employees (name TEXT, salary INT);<br>
INSERT INTO employees VALUES('JANE DOE', 8500);<br>
INSERT INTO employees VALUES('JOHN DOE', 3500);<br>
INSERT INTO employees VALUES('RICHARD ROE', 2500);<br>
INSERT INTO employees VALUES('JOHN SMITH', 10500);<br>
INSERT INTO employees VALUES('WALTER JOHNSON', 10500);<br>
INSERT INTO employees VALUES('ANNE SMITH', 7500);<br>
</p>

<p>In our case we create a simple form containing two radio buttons allowing selection of (a) all employees or (b) just top 3 salaried ones (see below):</p>

<p>
&lt;form method="post" action="./cgi-bin/sqlite.cgi"&gt;<br>
&lt;input type="radio" name="limit" value="-1"&gt; All&lt;br&gt;<br>
&lt;input type="radio" name="limit" value="3"&gt; Top 3 only&lt;br&gt;&lt;br&gt;<br>
&lt;input type="submit" value="Submit"&gt;<br>&lt;/form&gt;<br>
</p>

<p>It is also possible to modify SQL query output format. A special dot-command .mode html passed to SQLite utility will make SQL query output html table coded data, a very useful feature especially for web applications.</p>
<p>The below script shows the table listing of employees (either all or top 3 salaried ones, depending on the form values submitted) and their average salary in the final row.</p>

<div><p>
#!/bin/ash</p><p>
. ./.httpd.rc 2&gt;/dev/null || exit 1</p><p>
header UTF-8 "Database script"<br>
cgi</p><p>
echo "&lt;table&gt;"<br>
echo "&lt;tr&gt;&lt;td&gt;Name&lt;/td&gt;&lt;td&gt;Salary&lt;/td&gt;&lt;/tr&gt;"<br>
echo&nbsp;&nbsp;&nbsp;".mode html<br>
<span>select * from employees order by salary desc limit $limit;<br></span>
<span>select \"Average salary:\", avg(salary) from employees;" | sqlite3 ./emp.db<br></span>
echo "&lt;/table&gt;"</p><p>
end</p><p>
exit 0</p></div>

<p><b>Conclusion</b></p>
<p>Despite the fact that Busybox applets do not provide functionality comparable to that of Perl or PHP scripting and Apache or MySQL engines, users may find them suitable for special purpose projects that do not require high level of sophistication or heavy workload. This article was an attempt to show how one can use capabilities provided by Busybox and SQLite to build a minimalist interactive web service equipped with a database engine.</p>
<p>January 20, 2010</p>
</td>
</div></div>]]>
            </description>
            <link>http://programming.key-spot.ru/article_02.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650614</guid>
            <pubDate>Fri, 26 Jun 2020 10:55:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Astronomers bolster case for potential of life on one of Jupiter's moons, Europa]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650607">thread link</a>) | @pseudolus
<br/>
June 26, 2020 | https://www.cbc.ca/news/technology/europa-habitability-jupiter-moon-life-ocean-1.5626940 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/europa-habitability-jupiter-moon-life-ocean-1.5626940">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>New research by NASA scientists lends further support to the theory that, beneath the thick, icy crust of Europa, the Jovian moon's interior ocean could be habitable.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.3779492.1593117803!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/science-jupiter-moon.jpg"></p></div><figcaption>Europa, above, is an icy moon where astronomers believe there could be an environment suitable for life in a subglacial ocean.<!-- --> <!-- -->(NASA/JPL-Caltech/SETI Institute/Reuters)</figcaption></figure><p><span><p>In the search for life in our solar system, the discussion typically revolves&nbsp;around Mars. But there are two moons many astronomers believe are even better&nbsp;bets: Saturn's moon Enceladus and Jupiter's moon Europa.</p>  <p>Now&nbsp;a new computer model by NASA scientists lends further support to the theory that, beneath the thick, icy crust of Europa, the Jovian moon's interior ocean could be habitable.</p>  <p>Europa is the sixth-largest moon in the solar system, smaller than the Earth's moon but larger than Pluto.</p>  <p>The scientists believe the moon's ocean may have formed after water-rich minerals released their water due to heating caused by the radioactive decay of&nbsp;the satellite's&nbsp;core. Due to its gravitational interactions with gas giant Jupiter&nbsp;and with other moons, the water is kept warm.&nbsp;</p>  <p>But not all water means life. Other important building blocks are needed, and&nbsp;researchers believe that was the case.</p>  <h2>'This ocean could be quite habitable'</h2>  <p>Billions of years ago, the ocean would have been mildly acidic, but with concentrations of carbon dioxide, calcium and sulfate too high for life as we know it.</p>  <p>"Our simulations, <a href="http://advances.sciencemag.org/content/5/6/eaaw7123" target="_blank">coupled with data from the Hubble Space Telescope</a>, showing chloride on Europa's surface, suggests that the water most likely became chloride-rich," said Mohit Melwani Daswani, a geochemist and planetary scientist at NASA's Jet Propulsion Laboratory, who presented the recent findings at the virtual Goldschmidt conference this week.</p>  <p>"In other words, its composition became more like oceans on Earth. We believe that this ocean [now] could be quite habitable for life."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5626966.1593104515!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/hubble-spots-possible-venting-activity-on-europa.jpg 300w,https://i.cbc.ca/1.5626966.1593104515!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/hubble-spots-possible-venting-activity-on-europa.jpg 460w,https://i.cbc.ca/1.5626966.1593104515!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/hubble-spots-possible-venting-activity-on-europa.jpg 620w,https://i.cbc.ca/1.5626966.1593104515!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/hubble-spots-possible-venting-activity-on-europa.jpg 780w,https://i.cbc.ca/1.5626966.1593104515!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/hubble-spots-possible-venting-activity-on-europa.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5626966.1593104515!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/hubble-spots-possible-venting-activity-on-europa.jpg"></p></div><figcaption>Observations of Europa by NASA's Hubble Space Telescope uncovered a probable plume of material erupting from the moon's surface at the same location where a similar plume was seen two years earlier by Hubble. Astronomers believe that this is more evidence of liquid water below its icy surface.<!-- --> <!-- -->(NASA/ESA)</figcaption></figure></span></p>  <p>Water and minerals aren't the only thing needed for life. Life needs energy.</p>  <p>"It's unlikely that any possible life forms in Europa's ocean would use sunlight as a source of energy, because Europa is really quite far from the sun, and the ocean would be under complete darkness beneath a really thick ice shell," Melwani Daswani said. "So we have to think about other sources of energy."</p>  <p>On Earth, life exists around hydrothermal vents, openings on the ocean floor that emit dissolved minerals, and there has been strong evidence that these may exist in Europa's subglacial ocean as well. That could be used as a source of energy for any potential life.</p>  <p>Melwani Daswani is cautious.</p>  <p>"We don't even know whether life as we know it would be happy over there or whether the energy available for that for life would be sufficient," he added.</p>  <h2>Mission to Europa</h2>  <p>Gordon Osinski, a professor in the department of Earth sciences at Western University in London, Ont., who was not involved in the study, said that this new research is another reason that missions to moons like Europa or Enceladus&nbsp;are&nbsp;so intriguing.</p>  <p>"I think the key take-home here is that these ocean worlds present the best likelihood for present-day habitable environments," he said. "So, life living on those planets at the present day. All the key ingredients are there."</p>    <p>NASA does have a mission in the works to visit the moon: the <a href="https://europa.nasa.gov/" target="_blank"><u>Europa Clipper</u></a>.</p>  <p>The mission — the first dedicated mission to a moon other than our own — won't be looking for signs of life, since it will only orbit, but it will look for increasing evidence of potential&nbsp;habitability by studying its geology, icy shell and composition.</p>  <p>Osinski said that it would be ideal for a future sample-return mission, where a spacecraft could even fly through and collect from plumes of water vapour that have&nbsp;been seen blown into space by both Europa and Enceladus through fissures in the ice.</p>  <p>"Because then we'll know," he said. "We'll have the unequivocal determination of whether there is life there or not."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/europa-habitability-jupiter-moon-life-ocean-1.5626940</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650607</guid>
            <pubDate>Fri, 26 Jun 2020 10:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying conversational design it to all types of interfaces]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23650440">thread link</a>) | @xTWOz
<br/>
June 26, 2020 | https://blog.prototypr.io/conversational-design-applying-it-to-all-types-of-interfaces-60b2b7beebd4 | <a href="https://web.archive.org/web/*/https://blog.prototypr.io/conversational-design-applying-it-to-all-types-of-interfaces-60b2b7beebd4">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://blog.prototypr.io/@danny_43726?source=post_page-----60b2b7beebd4----------------------" rel="noopener"><img alt="Danny McCabe" src="https://miro.medium.com/fit/c/96/96/2*8VpmtJ_6Tv5psuivUl5e8w.png" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*NJAE89ldM2UVR6fZQTcVRA.png?q=20" width="563" height="418" role="presentation"></p><p><img src="https://miro.medium.com/max/1126/1*NJAE89ldM2UVR6fZQTcVRA.png" width="563" height="418" srcset="https://miro.medium.com/max/552/1*NJAE89ldM2UVR6fZQTcVRA.png 276w, https://miro.medium.com/max/1104/1*NJAE89ldM2UVR6fZQTcVRA.png 552w, https://miro.medium.com/max/1126/1*NJAE89ldM2UVR6fZQTcVRA.png 563w" sizes="563px" role="presentation"></p></div></div></div></figure><p id="1e88">We live in an environment where interfaces are everywhere. For most of us, phones, watches, tablets, laptops, kiosks, payment systems, and televisions are all huge parts of our daily lives. And these are all predominantly visual interfaces only. Voice interfaces like Alexa, Siri and Cortana are also starting to be less of a novelty and more of a normal part of our lives. There are physical interfaces we interact with, and we are even starting to see sensory devices emerging. For instance, there already exist alarm clocks that allow you to wake up to the smell of fresh coffee, and haptic gloves that let you actually feel what you see in Virtual Reality.</p><figure><div></div></figure><p id="48f9">What all types of interfaces have in common, is that they are used, in part or entirely, by humans. That’s why we refer to them as <em>user interfaces</em>, and why the field of <em>User eXperience</em> (UX) exists; to give focus to human users and their experience when using and designing an interface.</p><p id="a2b1">Now, if interfaces are such an integral part of our everyday lives, it’s fair to say that these interfaces should, at the very least, be easy to use. Could you imagine a day where all you did was interact with interfaces that were difficult to use? Red wine sales would go through the roof on a day like this! It fascinates me though that there are still so many confusing and frustrating interfaces out there. And even the good ones still commonly contain the occasional confusing interaction here and there. So, why aren’t we designing more consistently easy to use interfaces? While there may be many contributing factors, it’s my belief that as UX designers, we are largely ignoring one of the most fundamental ways that humans are taught to interact with the world: via conversation.</p><p id="ee96">My aim here is to explore how conversation largely dictates how we think, how we communicate, and how we interact with everyone and everything, including interfaces. I’ll also explore some conversational design approaches I use as a UX designer that can provide more ‘natural’ experiences to users of any kinds of interfaces, not just voice and message-based applications.</p><p id="04fe">(<strong>Conversation Design</strong> exists currently as both a general approach to designing for voice UIs, and a Google-specific approach to designing for Google Assistant. I’d highly recommend taking a look over Google’s <a href="https://designguidelines.withgoogle.com/conversation/" target="_blank" rel="noopener nofollow">guidelines</a>, even if you are not designing for voice as they lay down an excellent foundation for considering any scope of conversational design.)</p><p id="fdc0">Most dictionaries define conversation as <em>an informal and verbal interchange of thoughts and ideas using language</em>. I’d like to be bold though and suggest that conversations occur in various ways besides verbally. They can also happen during thoughts and actions. A more general definition might be, <em>where language is used to facilitate back-and-forth communication between two or more parties</em>. With this more general definition we can now include non-verbal use of language, and parties other than humans, in a conversation. Have you ever had a conversation with yourself in your mind? “Don’t eat the pizza! Nah, just eat the pizza, it smells delicious! Yeah, but you’ll regret it. Pfft, I’m eating it!”. The old <em>angel on one shoulder and the devil on the other</em> idea. There is a back and forth of language-based thoughts happening in the mind between the angel and the devil!</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*C099tF_9vTcSsSRKF3GGiQ.jpeg?q=20" width="800" height="420" role="presentation"></p><p><img src="https://miro.medium.com/max/1600/1*C099tF_9vTcSsSRKF3GGiQ.jpeg" width="800" height="420" srcset="https://miro.medium.com/max/552/1*C099tF_9vTcSsSRKF3GGiQ.jpeg 276w, https://miro.medium.com/max/1104/1*C099tF_9vTcSsSRKF3GGiQ.jpeg 552w, https://miro.medium.com/max/1280/1*C099tF_9vTcSsSRKF3GGiQ.jpeg 640w, https://miro.medium.com/max/1400/1*C099tF_9vTcSsSRKF3GGiQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Image via Walt Disney Pictures</figcaption></figure><p id="574e">What about a back and forth communication between a person and a non-human party? For example, a user and a webpage. How does language play a role in this kind of interaction? First we need to look a little deeper into what language means to us.</p><p id="d61a">For many of us we not only use language to talk, we also think (and even dream) in the language we’re most fluent in. Language provides us with a means to define and comprehend what exists around us. It also helps us understand how we act, how we feel, and how we think. And of course, it provides us with a means for communicating with other people, pets, and computers (when they don’t do what you want them to). Language does a lot!</p><p id="8ea0">One of my favourite quotes is by the late philosopher Ludwig Wittgenstein, “the limits of my language mean the limits of my world”. It highlights how dependent we are on using language to understand and interact with our world. To me, it also suggests that language shapes many of our perceptions, thoughts and actions. When we are shopping and see a nice pair of shoes that we like it might be normal to think to ourselves, “How much do they cost?”. Or, in German, “How much costs they?”. Whether we give preference to the object or the verb by saying it first depends on the language. One could argue, given the word order, that in German the cost is more important than the shoes, and in English the shoes are more important than the cost. In either case you’d be considering the cost of the shoes by <em>thinking</em> in words and grammar that you’re familiar with.</p><p id="d304">Language is a construct that shapes many of our thoughts, and is more precious to us gold. And if Extreme’s hit song “More than words” is anything to go by, language seems to be rivalled only by love! Without language, all of our interactions, thoughts, even our sense of self, would be very different.</p><p id="6521">First and foremost, communication is the key reason for language existing in the first place. And generally, we are exposed to this practice of communicating our entire lives, starting the day we are born. It’s no wonder then why it can be difficult to engage with someone or something that doesn’t follow the kind of communication we are used to using. For example, if you wanted to frustrate or confuse someone during a conversation you might randomly scatter the word “Honda” throughout the conversation. I’ve been there, it’s annoying! And it’s annoying because it simply doesn’t make any grammatical sense.</p><p id="ad1d">When we are trying to process an interaction with a digital system, remembering that we tend to think using language, if that interaction doesn’t follow how we are used to thinking then the experience can be quite confusing. Have you ever thought to yourself “This interaction doesn’t make sense!”, and not been sure why it doesn’t? Let’s consider an example. Say you pick up your phone to check out some event photos your friends posted. You might start by thinking “Which social media app will I look at first?”. If your phone was good at having a conversation with you it might show apps under the title “Frequently used apps”. You might see this and think “Ok, I’ll look at this one first”. This seems like a simple but natural conversation. If the phone was a person the conversation might go like this:</p><ul><li id="0325"><strong>John Human: “Which social media app should I look at first?”</strong></li><li id="a10e"><strong>Phoney McPhone: “Well, this is the one you look at the most..”</strong></li><li id="b7ba"><strong>John Human: “Cool, I’ll look at that then.”</strong></li></ul><p id="04d7">It’s not a super friendly conversation, but it’s natural at least, and easy to follow. What if the conversation went like this though:</p><ul><li id="84d2"><strong>John Human: “Which social media app should I look at first?”</strong></li><li id="5843"><strong>Phoney McPhone: “Here are ten folders containing apps. Go look.”</strong></li><li id="960b"><strong>John Human: “Here we go again. Let’s play ‘<em>find the app</em>’ game.”</strong></li></ul><p id="23d1">It’s still an easy to follow conversation, but even less friendly than the previous example.</p><p id="100b">Consider another conversation:</p><ul><li id="a0f3"><strong>John Human: “Hey McPhone, open [favourite social media app]” <em>[tap app icon to open]</em></strong></li><li id="324b"><strong>Phoney McPhone: “…” [blank screen]</strong></li><li id="b5b4"><strong>John Human: “Hello? Are you there? Are you loading?”</strong></li><li id="2dce"><strong>Phoney McPhone: “…” [blank screen]</strong></li><li id="7e43"><strong>John Human: “Ahh, are you broken?”</strong></li><li id="5c9a"><strong>Phoney McPhone: “Here’s all your content!”</strong></li><li id="d18f"><strong>John Human: “Ok, not sure what all that silence was about. But whatevs, moving on.”</strong></li></ul><p id="366d">This example doesn’t follow a conversational flow that we are used to. Here, John is met with total silence and doesn’t know what is going on. This could be easily fixed by changing the conversation to this:</p><ul><li id="34a4"><strong>John Human: “Hey McPhone, open [favourite social media app]” <em>[tap app icon to open]</em></strong></li><li id="f9d3"><strong>Phoney McPhone: “Hang on, I’m just loading.”<em> [show loading gif]</em></strong></li><li id="7bfe"><strong>John Human: “No problem, I can wait.”</strong></li><li id="ce48"><strong>Phoney McPhone: “Here’s all your content!”</strong></li><li id="4621"><strong>John Human: “Nice, pizzas 25% off today!.”<em> [sees a tantalising advert]</em></strong></li></ul><p id="0c45">My main point here is that our brains respond best to interactions that flow like natural conversations. This is because interactions are led by thoughts, and thoughts are largely shaped using language. Language, also, is focussed primarily on communicating, most commonly in the form of conversations. Thus, conversations are our most common means of interacting. And this dependency implies that a good interaction is dependent on a good conversation.</p><p id="ce4c">When with friends, do you typically talk <strong><em>with</em></strong> them, or <strong><em>to</em></strong> them? The best conversations in my experience happen when people talk <em>with</em> each other, when both parties care about each other enough to listen at least as much as they talk. I’m of the opinion that conversations between a user and a system interface are no different in that both parties needs to engage well with the other.</p><p id="0449">I find it interesting that the field of UX is mainly concerned with empathising with, and catering for, the user but not the system. I mean, sure, we consider the needs and constraints of business, and observe technical limitations, but we don’t typically spend much, if any, time considering what kind of experience we want the system to have. This sounds a bit weird, I know, but consider that in a two-way conversation both the user and system are interacting <em>with</em> each other. And each have an experience that dictates their engagement. How does a system react to users? Is the system friendly? Is it witty? How well does the system know how to converse with humans, or more specifically, to you as an individual? Does the system react according to natural conversational flow when the user interacts with it? Does the system remember previous conversations with the user? I think that UX practice in general could do more to appreciate the system as a key participant in a conversation, and not just as a servant to the user’s wishes.</p><p id="201d">Google’s …</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.prototypr.io/conversational-design-applying-it-to-all-types-of-interfaces-60b2b7beebd4">https://blog.prototypr.io/conversational-design-applying-it-to-all-types-of-interfaces-60b2b7beebd4</a></em></p>]]>
            </description>
            <link>https://blog.prototypr.io/conversational-design-applying-it-to-all-types-of-interfaces-60b2b7beebd4</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650440</guid>
            <pubDate>Fri, 26 Jun 2020 10:21:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ISS HTV Docking Simulator]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23650408">thread link</a>) | @numpad0
<br/>
June 26, 2020 | https://ssl.tksc.jaxa.jp/htvgo/smartphone/ | <a href="https://web.archive.org/web/*/https://ssl.tksc.jaxa.jp/htvgo/smartphone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ssl.tksc.jaxa.jp/htvgo/smartphone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650408</guid>
            <pubDate>Fri, 26 Jun 2020 10:15:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Release Automation for Go Projects]]>
            </title>
            <description>
<![CDATA[
Score 5 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650402">thread link</a>) | @derberg
<br/>
June 26, 2020 | https://www.asyncapi.com/blog/automated-releases-part-two/ | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/automated-releases-part-two/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<blockquote>
<p>tl;dr
<a href="https://www.asyncapi.com/blog/automated-releases/">Here</a> you can find the first blog post about automated releasing. The purpose of this blog post is to show how you can do the same automation in non-JavaScript projects. Even if JavaScript community created tooling, you can still use it in other projects and don’t freak out.</p>
</blockquote>

<p>This post and the <a href="https://www.asyncapi.com/blog/automated-releases/">previous one</a> come from our experience we gained when working on full automation for all tools maintained by <a href="https://github.com/asyncapi/asyncapi/" target="_blank">AsyncaPI Initiative</a>.</p>

<blockquote>
<p><a href="https://github.com/asyncapi/asyncapi/" target="_blank">AsyncAPI</a> is a specification that you use to create machine-readable definitions of your event-driven APIs.</p>
</blockquote>

<p>The previous post focused on JavaScript as the first library that we automated was our <a href="https://github.com/asyncapi/generator/" target="_blank">generator</a>. It covered publishing to NPM and usage of the JavaScript community ecosystem. Now we have automation rolled out to all our libraries, Go-written too.</p>

<h2 id="what-i-need-to-automate-release">What I need to automate release?<a href="#what-i-need-to-automate-release" arialabel="Anchor"> #︎</a> </h2>

<p>To automate a release efficiently, you need two things:</p>

<ul>
<li>Machine-readable information that allows you to identify if a given commit should trigger a release or not.</li>
<li>Tooling that you can easily plug in and configure without the need to write everything from scratch.</li>
</ul>

<p>This automation is possible thanks to the following:</p>

<ul>
<li>The <a href="https://www.conventionalcommits.org/en/v1.0.0/" target="_blank">Conventional Commits</a> specification. The purpose of Conventional Commits is to make commits machine-readable but also human-readable. It defines a set of commit prefixes that can be easily parsed and analyzed by tooling and looks good to the human eye too.</li>
<li>The <a href="https://github.com/semantic-release/semantic-release" target="_blank">Semantic Release</a> package and related plugins that support Conventional Commits and publishing to different channels like GitHub, NPM, Slack, and others.</li>
</ul>

<h2 id="where-s-the-catch">Where’s the catch?<a href="#where-s-the-catch" arialabel="Anchor"> #︎</a> </h2>

<p>This blog post is about the automation of releases for non-JavaScript projects. Let me be honest though, solutions I mentioned in the previous chapter come from the JavaScript community.</p>

<p>The problem is, there are people who <a href="https://www.reddit.com/r/javascript/comments/9pwzpn/why_do_people_hate_javascript/" target="_blank">Hate JavaScript</a>, they truly <a href="https://www.quora.com/Why-is-JavaScript-so-hated" target="_blank">hate it</a> like it is a living thing. Although, I’m personally proud to be an idiot that has a programming language that I can use.</p>

<p>Conventional Commits specification is heavily inspired by <a href="https://github.com/angular/angular/blob/22b96b9/CONTRIBUTING.md#commit-message-format" target="_blank">Angular Commit Guidelines</a>. The Semantic Release package and its plugins ecosystem are all Node.js packages.</p>

<p><img src="https://media.giphy.com/media/10FHR5A4cXqVrO/giphy.gif" alt=""></p>

<p>If you have Java or Go project, you can still use these tools. You do not have to keep <code>package.json</code> in your repository, so don’t worry, you can keep your repository clean. The great folks from Semantic Release thought about you too.</p>

<p><img src="https://media.giphy.com/media/QynGWwS6GdOMj6cvmz/giphy-downsized.gif" alt=""></p>

<h2 id="using-semantic-release-with-github-action-in-go-project">Using Semantic Release with GitHub Action in Go project<a href="#using-semantic-release-with-github-action-in-go-project" arialabel="Anchor"> #︎</a> </h2>

<p>One of the projects where we use this JavaScript tools is our parser for AsyncAPI documents. It is a <a href="https://github.com/asyncapi/parser-go" target="_blank">Go parser</a>.</p>

<h3 id="semantic-release-configuration">Semantic Release configuration<a href="#semantic-release-configuration" arialabel="Anchor"> #︎</a> </h3>

<p>The Semantic Release package supports configuration files in different formats and file types. You are not bound to <code>package.json</code>. We chose to use <code>.releaserc</code> file in YAML format but there are <a href="https://github.com/semantic-release/semantic-release/blob/master/docs/usage/configuration.md#configuration-file" target="_blank">other options</a> too.</p>

<pre><code>---
branches:
- master
plugins:
- - "@semantic-release/commit-analyzer"
  - preset: conventionalcommits
- - "@semantic-release/release-notes-generator"
  - preset: conventionalcommits
- - "@semantic-release/github"
  - assets:
    - path: asyncapi-parser.darwin.amd64
      label: Binary - Darwin AMD64
    - path: asyncapi-parser.linux.amd64
      label: Binary - Linux AMD64
    - path: asyncapi-parser.windows.amd64.exe
      label: Binary - Windows AMD64
</code></pre>

<p>Our configuration uses plugins to:
- Analyze Git commits with Conventional Commits specification.
- Create a Git tag and generate changelog for release notes.
- Publish a release with additional assets. We compile our parser as binaries that are compatible with many platforms and we want to have them easily accessible with each release.</p>

<p>We place the configuration under <code>.github/workflows/</code>, next to our GitHub Action release workflow file: <code>release.yml</code>. It indicates that it is for release only, nothing else.</p>

<h3 id="release-workflow">Release workflow<a href="#release-workflow" arialabel="Anchor"> #︎</a> </h3>

<p>Let us have a look at the differences between this workflow and the workflow I described for a typical JavaScript project <a href="https://www.asyncapi.com/blog/automated-releases/">here</a>.</p>

<p>First, you define a <code>test</code> job with the Go environment to trigger tests with different versions of Go.</p>

<pre><code>test:
  name: 'Testing'
  runs-on: ubuntu-latest
  strategy:
    matrix:
      go: 
        - '1.14'
        - '1.13'
        - '1.12' 
  steps:
    - name: Checkout repo
      uses: actions/checkout@v2
    - name: Setup Go
      uses: actions/setup-go@v1.1.2
      with:
        go-version: '${{ matrix.go }}'
    - name: Invoking go test
      run: go test ./...
</code></pre>

<p>The next step is the <code>release</code> job, where you can differentiate two core steps. The first part is the generation of the binaries that you want to expose in the GitHub release.</p>

<pre><code>- name: Setup Go
  uses: actions/setup-go@v1.1.2
  with:
    go-version: '1.14'
- name: Invoking go vet and binaries generation
  run: |
    go vet ./...
    GOOS=darwin GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.darwin.amd64 ./cmd/api-parser/main.go
    GOOS=linux GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.linux.amd64 ./cmd/api-parser/main.go
    GOOS=windows GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.windows.amd64.exe ./cmd/api-parser/main.go
</code></pre>

<p>So far, it is all Go-related operations. How about the release? For the release, you need to set up a Node.js environment to run Semantic Release. Node.js community has this excellent package, <a href="https://www.npmjs.com/package/npx" target="_blank">npx</a>, that allows you to run a package without installing it, and this is what you can do here in the workflow.</p>

<pre><code>- name: Setup Node.js
  uses: actions/setup-node@v1
  with:
    node-version: 13
- name: Add plugin for conventional commits
  run: npm install conventional-changelog-conventionalcommits
  working-directory: ./.github/workflows
- name: Release to GitHub
  working-directory: ./.github/workflows
  env:
    GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
    GIT_AUTHOR_NAME: asyncapi-bot
    GIT_AUTHOR_EMAIL: info@asyncapi.io
    GIT_COMMITTER_NAME: asyncapi-bot
    GIT_COMMITTER_EMAIL: info@asyncapi.io
  run: npx semantic-release
</code></pre>

<p>You only have to install <code>conventional-changelog-conventionalcommits</code> explicitly if you want to use <code>conventionalcommits</code> preset when analyzing Git commits and generating the changelog:</p>

<pre><code>plugins:
- - "@semantic-release/commit-analyzer"
  - preset: conventionalcommits
- - "@semantic-release/release-notes-generator"
  - preset: conventionalcommits
</code></pre>

<p>Take a look at full release workflow for reference:</p>

<pre><code>name: Release

on:
  push:
    branches:
      - master

jobs:
  test:
    name: 'Testing'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        go: 
          - '1.14'
          - '1.13'
          - '1.12' 
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Setup Go
        uses: actions/setup-go@v1.1.2
        with:
          go-version: '${{ matrix.go }}'
      - name: Invoking go test
        run: go test ./...
  
  release:
    name: 'Release to GitHub'
    runs-on: ubuntu-latest
    needs: 
      - test
    steps:
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Setup Go
        uses: actions/setup-go@v1.1.2
        with:
          go-version: '1.14'
      - name: Invoking go vet and binaries generation
        run: |
          go vet ./...
          GOOS=darwin GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.darwin.amd64 ./cmd/api-parser/main.go
          GOOS=linux GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.linux.amd64 ./cmd/api-parser/main.go
          GOOS=windows GOARCH=amd64 go build -o=.github/workflows/asyncapi-parser.windows.amd64.exe ./cmd/api-parser/main.go
      - name: Setup Node.js
        uses: actions/setup-node@v1
        with:
          node-version: 13
      - name: Add plugin for conventional commits
        run: npm install conventional-changelog-conventionalcommits
        working-directory: ./.github/workflows
      - name: Release to GitHub
        working-directory: ./.github/workflows
        env:
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
          GIT_AUTHOR_NAME: asyncapi-bot
          GIT_AUTHOR_EMAIL: info@asyncapi.io
          GIT_COMMITTER_NAME: asyncapi-bot
          GIT_COMMITTER_EMAIL: info@asyncapi.io
        run: npx semantic-release
</code></pre>

<p>You see, you can still have your project “clean” from any JavaScript-specific files and references. Everything you need for running your release with the JavaScript community tooling is only in the release-related configuration.</p>

<h2 id="conclusion">Conclusion<a href="#conclusion" arialabel="Anchor"> #︎</a> </h2>

<p>I don’t think I can ever understand this “hate” towards JavaScript. I think, though, that you can “hate” the language, but if you see some amazing tooling built with it, that can increase your productivity, grit your teeth, put bias aside, and enjoy life. Especially, if in exchange you get this excellent feature, notification about release under the Issue and Pull Request:</p>

<p><img src="https://www.asyncapi.com/images/posts/pr-indicator.webp" alt="pr info about release"></p>

<p>In case you want to have more explanation on the release automation subject, I recommend reading <a href="https://www.asyncapi.com/blog/automated-releases/">the first part of the automation story</a>. You can also <a href="https://www.asyncapi.com/slack-invite/" target="_blank">join our Slack</a> for further discussion.</p>


</div></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/automated-releases-part-two/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650402</guid>
            <pubDate>Fri, 26 Jun 2020 10:13:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better git diff outputs with git submodules]]>
            </title>
            <description>
<![CDATA[
Score 3 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23650336">thread link</a>) | @NougatRillettes
<br/>
June 26, 2020 | https://www.jvt.me/posts/2018/05/04/git-submodule-diff-formats/ | <a href="https://web.archive.org/web/*/https://www.jvt.me/posts/2018/05/04/git-submodule-diff-formats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>Written by</span>
Jamie Tanna<br><span>on&nbsp;</span><time datetime="2018-05-04T11:59:42+0100">May 4, 2018</time><br><span><a href="http://creativecommons.org/licenses/by-nc-sa/4.0/legalcode"><i></i>CC-BY-NC-SA-4.0</a>
<a href="http://www.apache.org/licenses/LICENSE-2.0"><i></i>Apache-2.0</a></span><br><span>2 mins</span></p></div><div><p>I've recently been playing around with <a href="https://git-scm.com/book/en/v2/Git-Tools-Submodules">Git Submodules</a> a little bit more, and have been frustrated by the output of <code>git diff</code>s:</p><div><pre><code data-lang="diff"><span>diff --git a/vendor/git/startbootstrap-clean-blog b/vendor/git/startbootstrap-clean-blog
</span><span>index eda0a67..5daffc9 160000
</span><span></span><span>--- a/vendor/git/startbootstrap-clean-blog
</span><span></span><span>+++ b/vendor/git/startbootstrap-clean-blog
</span><span></span><span>@@ -1 +1 @@
</span><span></span><span>-Subproject commit eda0a676f655da9e909464eec6a028757b880bf0
</span><span></span><span>+Subproject commit 5daffc976c4a8769129f98733c961a0df90d0246
</span></code></pre></div><p>When trying to write commit messages, via <a href="https://www.jvt.me/posts/2017/06/01/git-commit-verbose/"><em>Viewing your diff while writing your commits with <code>git commit --verbose</code></em></a>, I've found that there's nothing really useful in the diff that I can describe as I'm writing the commit. To gain some understanding of what's happened in the submodule, I run:</p><pre><code>$ git log --oneline eda0a676f655da9e909464eec6a028757b880bf0...5daffc976c4a8769129f98733c961a0df90d0246
5daffc9 Centre-align site subtitle
e51780f Make site subtitle bold
</code></pre><p>This would then be added to a commit message such as:</p><pre><code>Theme: Subtitle changes

5daffc9 Centre-align site subtitle
e51780f Make site subtitle bold
</code></pre><p>However, after getting annoyed by this I've now discovered some other options, thanks to <a href="https://stackoverflow.com/questions/10757091/git-list-of-all-changed-files-including-those-in-submodules">Stack Overflow</a>, which can make it much easier to view changes with.</p><p>Perhaps the most useful of the options is an actual diff of changes within the submodule:</p><div><pre><code data-lang="diff">Submodule vendor/git/startbootstrap-clean-blog eda0a67..5daffc9:
<span>diff --git a/vendor/git/startbootstrap-clean-blog/assets/vendor/startbootstrap-clean-blog/scss/_masthead.scss b/vendor/git/startbootstrap-clean-blog/assets/vendor/startbootstrap-clean-blog/scss/_masthead.scss
</span><span>index f564652..fceee82 100644
</span><span></span><span>--- a/vendor/git/startbootstrap-clean-blog/assets/vendor/startbootstrap-clean-blog/scss/_masthead.scss
</span><span></span><span>+++ b/vendor/git/startbootstrap-clean-blog/assets/vendor/startbootstrap-clean-blog/scss/_masthead.scss
</span><span></span><span>@@ -37,8 +37,9 @@ header.masthead {
</span><span></span>       margin-top: 0;
     }
     .subheading {
<span>+      text-align: center;
</span><span></span>       font-size: 24px;
<span>-      font-weight: 300;
</span><span></span><span>+      font-weight: bold;
</span><span></span>       line-height: 1.1;
       display: block;
       margin: 10px 0 0;
</code></pre></div><p>You can set this as your default by running:</p><div><pre><code data-lang="bash"><span># either</span>
$ git config --global diff.submodule diff
<span># or</span>
$ git config --global -e
</code></pre></div><p>And adding:</p><p><code>short</code> simply shows the commit at the beginning and the end of a stage, such as:</p><div><pre><code data-lang="diff"><span>diff --git a/vendor/git/startbootstrap-clean-blog b/vendor/git/startbootstrap-clean-blog
</span><span>index eda0a67..5daffc9 160000
</span><span></span><span>--- a/vendor/git/startbootstrap-clean-blog
</span><span></span><span>+++ b/vendor/git/startbootstrap-clean-blog
</span><span></span><span>@@ -1 +1 @@
</span><span></span><span>-Subproject commit eda0a676f655da9e909464eec6a028757b880bf0
</span><span></span><span>+Subproject commit 5daffc976c4a8769129f98733c961a0df90d0246
</span></code></pre></div><p>This is Git's default, but to always have this setting, you can run:</p><div><pre><code data-lang="bash"><span># either</span>
$ git config --global diff.submodule short
<span># or</span>
$ git config --global -e
</code></pre></div><p>And adding:</p><p>Alternatively, you can get a log format, which is nice for putting in a CHANGELOG/commit message:</p><pre><code>Submodule vendor/git/startbootstrap-clean-blog eda0a67..5daffc9:
  &gt; Centre-align site subtitle
  &gt; Make site subtitle bold
</code></pre><p>You can set this as your default by running:</p><div><pre><code data-lang="bash"><span># either</span>
$ git config --global diff.submodule log
<span># or</span>
$ git config --global -e
</code></pre></div><p>And adding:</p></div></div>]]>
            </description>
            <link>https://www.jvt.me/posts/2018/05/04/git-submodule-diff-formats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650336</guid>
            <pubDate>Fri, 26 Jun 2020 09:58:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big Sur on Unsupported Macs]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 119 (<a href="https://news.ycombinator.com/item?id=23650031">thread link</a>) | @todsacerdoti
<br/>
June 26, 2020 | https://parrotgeek.com/bigsur/ | <a href="https://web.archive.org/web/*/https://parrotgeek.com/bigsur/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span face="Helvetica, Arial, sans-serif"><b><u>Compatibility
            status</u></b> <br>
        Note: this patcher <i>only</i> supports computers<b> </b>that
        are in the table below. <b>Do not ask me to add support for other models.</b><br>
      </span></p><div>
      <tbody>
        <tr>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Model Identifier</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Human-Readable Name</b><br>
            </span></td>
          <td><span face="Helvetica,
              Arial, sans-serif"><b>Status</b><br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Air (11-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookAir5,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Air (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro9,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (13-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (Retina, 15-inch, Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacBookPro10,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">MacBook









              Pro (Retina, 13-inch, Early 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              mini (Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything









              except Wi-Fi works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">Macmini6,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">Mac mini (Late
              2012) quad-core<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac13,2<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (27-inch, Late 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif"><span face="Helvetica, Arial, sans-serif">Everything except
                Wi-Fi works</span> </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2013) integrated GPU<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,2<br>
            </span></td>
          <td>
            <meta charset="utf-8">
            <span face="Helvetica, Arial, sans-serif">iMac (27-inch,
              Late 2013)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">iMac14,3<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">iMac









              (21.5-inch, Late 2013) discrete GPU</span><br>
          </td>
          <td><span face="Helvetica, Arial, sans-serif">Everything






              works<br>
            </span></td>
        </tr>
        <tr>
          <td><span face="Helvetica, Arial, sans-serif">MacPro5,1<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">Mac
              Pro (Mid 2010/Mid 2012)<br>
            </span></td>
          <td><span face="Helvetica, Arial, sans-serif">WiFi


              does not work; sleep issues<br>
            </span></td>
        </tr>
      </tbody>
    </div><p><span face="Helvetica, Arial, sans-serif">Special thanks to
        ASentientBot for the method of removing the installer
        compatibility check ("hax.dylib").</span><br>
    </p></div>]]>
            </description>
            <link>https://parrotgeek.com/bigsur/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23650031</guid>
            <pubDate>Fri, 26 Jun 2020 08:56:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Double Tap the Back of Your iPhone to Open Your Garage]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23649963">thread link</a>) | @eshtocof
<br/>
June 26, 2020 | https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075 | <a href="https://web.archive.org/web/*/https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="b613">WWDC20</h2><h2 id="299f">Learn how accessibility has changed for the better in iOS 14</h2><div><div><div><p><a href="https://heartbeat.fritz.ai/@vhanagwal?source=post_page-----33e0f144e075----------------------" rel="noopener"><img alt="Vardhan Agrawal" src="https://miro.medium.com/fit/c/96/96/1*ORFRUf6O2Tk4XbG3kElncQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><figure><div><div><div><p><img src="https://miro.medium.com/max/60/1*9wSXSk7Fua06okhjIeQbtw.jpeg?q=20" width="2500" height="1031" role="presentation"></p><p><img src="https://miro.medium.com/max/5000/1*9wSXSk7Fua06okhjIeQbtw.jpeg" width="2500" height="1031" srcset="https://miro.medium.com/max/552/1*9wSXSk7Fua06okhjIeQbtw.jpeg 276w, https://miro.medium.com/max/1104/1*9wSXSk7Fua06okhjIeQbtw.jpeg 552w, https://miro.medium.com/max/1280/1*9wSXSk7Fua06okhjIeQbtw.jpeg 640w, https://miro.medium.com/max/1456/1*9wSXSk7Fua06okhjIeQbtw.jpeg 728w, https://miro.medium.com/max/1632/1*9wSXSk7Fua06okhjIeQbtw.jpeg 816w, https://miro.medium.com/max/1808/1*9wSXSk7Fua06okhjIeQbtw.jpeg 904w, https://miro.medium.com/max/1984/1*9wSXSk7Fua06okhjIeQbtw.jpeg 992w, https://miro.medium.com/max/2160/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1080w, https://miro.medium.com/max/2700/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1350w, https://miro.medium.com/max/3240/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1620w, https://miro.medium.com/max/3780/1*9wSXSk7Fua06okhjIeQbtw.jpeg 1890w, https://miro.medium.com/max/4320/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2160w, https://miro.medium.com/max/4800/1*9wSXSk7Fua06okhjIeQbtw.jpeg 2400w" sizes="100vw" role="presentation"></p></div></div></div></figure></div><div><div><p id="90e1">Apple has long integrated accessibility features into their software — and for good reason. By using accessibility features in your app, you’re allowing your app to reach a wider audience.</p><p id="d948">Sticking with their commitment to accessibility, Apple has introduced several new features at WWDC20 which help developers make their apps easier and more entertaining for users with disabilities. By making apps more accessible, developers eliminate the need for users to purchase clunky, expensive devices in order to use their apps — everything they need to interact with the app is built right into the device.</p><p id="df0d">In this article, you’ll learn about some of the biggest and best upgrades to accessibility, announced at this year’s WWDC.</p></div></div></section><hr><section><div><div><p id="ecb9">The first on the list is an interesting feature — which didn’t get talked about on stage. As the name suggests, Back Tap allows users to set single, double, or triple taps on the back of their iPhones and link them to certain tasks. For example, you could double tap on the back of your iPhone to open the weather app.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*-mtu69eu445jv1BwH76CoQ.jpeg?q=20" width="1200" height="732" role="presentation"></p><p><img src="https://miro.medium.com/max/2400/1*-mtu69eu445jv1BwH76CoQ.jpeg" width="1200" height="732" srcset="https://miro.medium.com/max/552/1*-mtu69eu445jv1BwH76CoQ.jpeg 276w, https://miro.medium.com/max/1104/1*-mtu69eu445jv1BwH76CoQ.jpeg 552w, https://miro.medium.com/max/1280/1*-mtu69eu445jv1BwH76CoQ.jpeg 640w, https://miro.medium.com/max/1400/1*-mtu69eu445jv1BwH76CoQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Setting up Back Tap on iOS 14.</figcaption></figure><p id="91c1">And since the tapping feature can be linked to Shortcuts, it opens up a whole range of possibilities with home automation and more! As seen in the example above, you could triple tap the back of your phone to quickly take notes, or you could use it to unlock your door when you’re about to enter the house. Easy, right?</p><p id="563c">For users with hearing impairments, Apple has added the ability to adjust sound frequencies on supported headphones. By doing this, users can now set their own preferences on what they want to hear more of and what they want to hear less of.</p><p id="dc81">The new feature also comes with pre-set profiles for specific outdoor situations, in case the user doesn’t want to manually configure the sound frequencies.</p><blockquote><p id="dba7">This new accessibility feature is designed to amplify soft sounds and adjust certain frequencies for an individual’s hearing, to help music, movies, phone calls, and podcasts sound more crisp and clear. Headphone Accommodations also supports Transparency mode on AirPods Pro, making quiet voices more audible and tuning the sounds of your environment to your hearing needs.</p><p id="8aab">— Apple Documentation</p></blockquote><p id="6a9f">Further, the new feature also supports Transparency Mode on AirPods Pro, which allows users to adjust how much of the surroundings they want to hear. If they want to amplify soft voices or listen to the environment in more detail, they now have that autonomy.</p><p id="d5d2">In the same vein, a new feature called <strong>Sound Recognition</strong> can pick up important sounds in the environment, such as Sirens, Fire Alarms, or Car Horns and alert the user of them. Through machine learning models built into the operating system, these sounds can be picked up and transmitted to the user in any way that they wish.</p></div></div></section><hr><section></section><hr><section><div><div><figure><div><div><div><div><p><img src="https://miro.medium.com/max/38/1*3WhAhhK1A2LktugVV3KGHw.png?q=20" width="700" height="1110" role="presentation"></p><p><img src="https://miro.medium.com/max/1400/1*3WhAhhK1A2LktugVV3KGHw.png" width="700" height="1110" srcset="https://miro.medium.com/max/552/1*3WhAhhK1A2LktugVV3KGHw.png 276w, https://miro.medium.com/max/1000/1*3WhAhhK1A2LktugVV3KGHw.png 500w" sizes="500px" role="presentation"></p></div></div></div></div><figcaption>Real-Time Text on the iPhone.</figcaption></figure><p id="2bf5">Group FaceTime calls have become more important than ever during the global pandemic, and Apple has added a small but important accessibility feature to them. Now, if a member of a group FaceTime call is using sign language to communicate, their video will be automatically pinned.</p><p id="ab6c">Using computer vision to detect this can be a boon to those with hearing loss, since reading sign language while the screen is moving around can be frustrating.</p><p id="43b4">In addition to this, Apple has made further improvements to its Real-Time Text feature, which is used for text based communication during phone calls. Previously, it was difficult for RTT users to multitask during phone calls, but it no longer requires the full screen.</p><p id="0458">When we think of accessibility on iOS, VoiceOver is often the first to come to mind. This year, VoiceOver received several significant updates, making it even more useful than before. If you aren’t familiar with it, VoiceOver is Apple’s screen reader, available on all platforms, including iOS, macOS, tvOS, and watchOS.</p><h2 id="ae54">VoiceOver Recognition</h2><p id="aa80">In the past, VoiceOver would require developers to adopt it inside their apps to work well on third-party apps.</p><blockquote><p id="210b">On-device intelligence recognizes key elements displayed on your screen to add VoiceOver support for app and web experiences that don’t have accessibility support built in. — Apple</p></blockquote><p id="2717">This year, Apple is tapping into their machine learning technology to semantically detect where and how to use VoiceOver on unsupported apps. This makes virtually all apps natively supported by VoiceOver and increases their accessibility for those with visual impairments.</p><h2 id="6119">Image Descriptions</h2><p id="6f0d">To make VoiceOver even more useful, Apple has used its computer vision library with <em>even more</em> machine learning to detect the contents of an image.</p><blockquote><p id="2f5f">VoiceOver reads complete-sentence descriptions of images and photos within apps and on the web. VoiceOver speaks the text it identifies within images and photos. — Apple</p></blockquote><p id="f5ed">Instead of simply stating that an image is present, VoiceOver can now provide detailed descriptions of what’s pictured in an image for more useful information to VoiceOver users. It can also detect text in an image through optical character recognition — another great way that machine learning is being used in the iOS 14 update!</p></div></div></section><hr><section><div><div><p id="d6f7">Evidently, there have been plenty of great updates at WWDC20 in accessibility, with even more that weren’t listed here. By releasing a large number of small features, Apple has made their devices more accessible than ever. And, they’ve supercharged many of their flagship accessibility solutions by coupling machine learning technology with them.</p><p id="ab7f">Be sure to <strong>smash that “clap” button</strong> as many times as you can, <strong>share this tutorial</strong> on social media, and <strong>follow me on Twitter.</strong></p></div></div></section><hr><section><div><div><p id="08a6"><em>Editor’s Note:</em><a href="http://heartbeat.fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Heartbeat</em></strong></a><strong><em> </em></strong><em>is a contributor-driven online publication and community dedicated to exploring the emerging intersection of mobile app development and machine learning. We’re committed to supporting and inspiring developers and engineers from all walks of life.</em></p><p id="7676"><em>Editorially independent, Heartbeat is sponsored and published by</em><a href="http://fritz.ai/" target="_blank" rel="noopener"><em> </em><strong><em>Fritz AI</em></strong></a><em>, the machine learning platform that helps developers teach devices to see, hear, sense, and think. We pay our contributors, and we don’t sell ads.</em></p><p id="7977"><em>If you’d like to contribute, head on over to our</em><a target="_blank" rel="noopener" href="https://heartbeat.fritz.ai/call-for-contributors-october-2018-update-fee7f5b80f3e"><em> </em><strong><em>call for contributors</em></strong></a><em>. You can also sign up to receive our weekly newsletters (</em><a href="https://www.deeplearningweekly.com/" target="_blank" rel="noopener"><strong><em>Deep Learning Weekly</em></strong></a><em> and the </em><a href="https://www.fritz.ai/newsletter/?utm_campaign=fritzai-newsletter&amp;utm_source=heartbeat-statement" target="_blank" rel="noopener"><strong><em>Fritz AI Newsletter</em></strong></a><em>), join us on</em><a href="https://join.slack.com/t/fritz-ai-community/shared_invite/enQtNTY5NDM2MTQwMTgwLWU4ZDEwNTAxYWE2YjIxZDllMTcxMWE4MGFhNDk5Y2QwNTcxYzEyNWZmZWEwMzE4NTFkOWY2NTM0OGQwYjM5Y2U" target="_blank" rel="noopener"><em> </em></a><a href="http://fritz.ai/slack" target="_blank" rel="noopener"><strong><em>Slack</em></strong></a><em>, and follow Fritz AI on</em><a href="https://twitter.com/fritzlabs" target="_blank" rel="noopener"><em> </em><strong><em>Twitter</em></strong></a><em> for all the latest in mobile machine learning.</em></p></div></div></section></div></div>]]>
            </description>
            <link>https://heartbeat.fritz.ai/wwdc20-whats-changed-in-accessibility-on-ios-33e0f144e075</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649963</guid>
            <pubDate>Fri, 26 Jun 2020 08:42:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[3K, 60fps, 130ms: achieving it with Rust]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23649534">thread link</a>) | @lukastyrychtr
<br/>
June 26, 2020 | https://blog.tonari.no/why-we-love-rust?ref=twtr | <a href="https://web.archive.org/web/*/https://blog.tonari.no/why-we-love-rust?ref=twtr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How we chose the Rust programming language to advance the state-of-the-art in real-time communication</p><div><p><i>T</i><m><i>his post was written collectively with Ryo Kawaguchi, </i></m><m><m><i>Andrea Law, Brian Schwind</i></m></m><m><i>.</i></m></p><p><m>Our goal for tonari is to build a virtual doorway to another space that allows for truly natural human interactions. Nearly two years in development, tonari is, to the best of our knowledge, the lowest-latency high resolution production-ready "teleconferencing" (we are truly not fond of that word) product available. </m></p><ul><li><b>130ms</b> glass-to-glass latency (the time from light hitting the camera to when it appears on-screen on the other side)</li><li><b>3K, 60fps</b> video transmission</li><li>High-bitrate 48kHz stereo audio</li></ul><p>Compare this to the typical <b>315-500ms</b> latency for Zoom and <m>WebRTC</m>, as measured between two laptops (X1 Carbon and MacBook Pro) on the same network at our office. It's a huge difference. It's the difference between constantly interrupting each other versus having a natural flow of conversation. It's the difference between a blurry face from a camera seemingly pointed up someone's nose versus a wide-view high fidelity image that smoothly transfers all the subtle body language of an in-person conversation.</p><div><picture><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"><img src="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"></picture></div><p>Since launching <a href="https://blog.tonari.no/changing-communication-and-culture-in-an-organization" rel="noopener" target="_blank">our first pilot</a> in February, we've experienced no software-related downtime (tripping over ethernet cables is a different story). A<m>nd as much as we would love to think we're infallible engineers, we truly don't believe we could have achieved these numbers with this level of stability without Rust.</m></p><a href="#in-the-beginning-(or-why-we're-not-webrtc)" id="in-the-beginning-(or-why-we're-not-webrtc)"><h2>In the beginning (or: why we're not WebRTC)</h2></a><p>The <m>very</m> first tonari proof-of-concept used a basic projector, bluetooth speakers, and a website running on top of vanilla WebRTC (JavaScript). We've come a long way since those days.</p><p>While that prototype (and our opinionated vision of the future) got us grant funding, we knew that tonari would be dead on arrival unless we could<m> achieve </m><i>significantly</i> lower latency and higher fidelity than <m>WebRTC</m>—two things that aren't currently associated with video chat in 2020.</p><p>We figured, “Okay<i>, so we can just </i><m><i>modify</i></m><i> WebRTC directly and wrap it up with a slick UI in C++ and launch it in no time</i>.”</p><p>A week of struggling with WebRTC’s nearly 750,000 LoC <i>behemoth</i> of a codebase revealed just how painful a single small change could be — how hard it was to test, and feel truly <i>safe,</i> with the code you were dealing with.</p><a href="#let-there-be-light...weight-code" id="let-there-be-light...weight-code"><h3>Let there be light...weight code</h3></a><p>So in a furious (read: calm and thoroughly-discussed) rage quit we decided it was easier to re-implement the whole stack from scratch. We wanted to <i>know and understand every line of code</i> being run on our hardware, and it should be designed for the <i>exact</i> hardware we wanted.</p><p>Thus began our journey to the depths beyond high-level interfaces like a browser or existing RTC project, and into the world of low-level systems and hardware interaction from scratch.</p><p>We needed it to <m>be inherently </m><b><m><i>secure</i></m></b><m> to </m>protect the privacy of those who use tonari.  We needed it to be <b><i>performant</i></b> to make it feel as human and real-time as possible.  And we needed it to be <b><i>maintainable</i></b> as the code becomes more mature, as new brains show up and have to learn our work and expand on it.</p><p><m>We discussed and ruled out a handful of alternative approaches:</m></p><ul><li><b><i>Security: </i></b>C and C++ are memory- and concurrency-unsafe, and their disparate and seemingly infinite build systems make it hard to have a consistent and simple development experience.</li><li><i><b>Performance: </b></i>Java, <m>C#, and Go'</m>s memory management is opaque and can be difficult to work with in latency-sensitive applications where you want full control over your memory.</li><li><i><b>Maintainability: </b></i>Haskell, Nim, D, and a handful of other more bespoke languages tend to be more limited in tooling, community, and hire-ability.</li></ul><p>Rust is really the only production-ready language that we found confidently satisfies these needs.</p><a href="#finding-beauty-in-rust" id="finding-beauty-in-rust"><h2>Finding beauty in Rust</h2></a><p>Rust's beauty lies in the countless decisions made by the development community that constantly make you feel like you <m>can have</m> ten cakes and eat all of them too.</p><ul><li>Its build system is opinionated, and cleanly designed. It is itself a complete ecosystem that makes introducing new engineers to your project and setting up dev environments remarkably simple.</li><li>The memory and concurrency safety guarantees cannot be over-appreciated. We're confident that we wouldn't have done our first deployment yet if we had continued this in C++ - we'd still probably be stuck on subtle snags.</li><li>Our ability to interact at the lowest level with hardware via APIs like CUDA, oftentimes through existing <a href="https://crates.io/" rel="noopener" target="_blank"><m>crates</m></a> (Rust's term for a code library), has allowed us to have higher standards about the latency we want from our first production release.</li></ul><p>As tonari is getting more advanced, we're now choosing embedded microcontrollers whose firmware can be written in Rust so we don't have to leave our idyllic utopia into the old world of unsafe system programming.</p><a href="#crates-we-rely-on" id="crates-we-rely-on"><h2>Crates we rely on</h2></a><p>We're not going to <code>cat Cargo.toml</code> here, instead focusing on some select crates that have earned the prestigious award of a lifetime invitation to each of our birthday parties forever.</p><a href="#&quot;better-than-std&quot;-crates" id="&quot;better-than-std&quot;-crates"><h3>"Better-than-std" crates</h3></a><ul><li><a href="https://github.com/crossbeam-rs/crossbeam" rel="noopener" target="_blank"><code>crossbeam</code></a> is better for inter-thread communication than <code>std::sync::mpsc</code> in almost every way, and may be merged into <code>std</code> eventually.</li><li><a href="https://github.com/Amanieu/parking_lot" rel="noopener" target="_blank"><code>parking_lot</code></a> has a mutex implementation better than <code>std::sync::Mutex</code> in almost every way, and may be merged into the standard library (one day). It also provides many other useful synchronization primitives.</li><li><a href="https://github.com/tokio-rs/bytes" rel="noopener" target="_blank"><code>bytes</code></a> is a more robust, and often more performant, way to play with bytes compared to <code>Vec&lt;u8&gt;</code>.</li><li><a href="https://github.com/alexcrichton/socket2-rs" rel="noopener" target="_blank"><code>socket2</code></a> is what you will end up at if you are ever doing lower-level networking optimizations.</li></ul><a href="#beauty-supply" id="beauty-supply"><h3>Beauty supply</h3></a><ul><li><a href="https://github.com/daboross/fern" rel="noopener" target="_blank"><code>fern</code></a> is a dead-simple way to customize and prettify your logging output. We use it to keep our logs readable and internally standardized.</li><li><a href="https://github.com/TeXitoi/structopt" rel="noopener" target="_blank"><code>structopt</code></a> is how you always dreamed CLI arguments would be handled. There's no reason not to use it unless you're going for bare-minimum dependencies.</li></ul><a href="#cargo-cult-classics" id="cargo-cult-classics"><h3>Cargo cult classics</h3></a><ul><li><a href="https://github.com/sunng87/cargo-release" rel="noopener" target="_blank"><code>cargo-release</code></a> allows us to cut internal releases painlessly.</li><li><a href="https://github.com/est31/cargo-udeps" rel="noopener" target="_blank"><code>cargo-udeps</code></a> identifies unused dependencies and allows us to keep our build times minimal.</li><li><code>cargo tree</code> (recently integrated in cargo) shows a dependency tree that's useful in many ways, but <m>mainly</m> in identifying ways to minimize dependencies.</li><li><a href="https://github.com/rust-secure-code/cargo-geiger" rel="noopener" target="_blank"><code>cargo-geiger</code></a> helps us quickly evaluate external dependencies for possible security (or correctness) concerns.</li><li><a href="https://github.com/flamegraph-rs/flamegraph" rel="noopener" target="_blank"><code>cargo-flamegraph</code></a> helps us enormously when tracking down performance hot-spots in our code.</li></ul><a href="#project-structure" id="project-structure"><h2>Project structure</h2></a><p>The tonari codebase is a monorepo. At its root we have a Cargo workspace with a <code>binaries</code> crate, and a number of supporting library crates.</p><p>Having our crates in one repo makes them easy to reference in our <code>binaries</code> crate without needing to publish to <a href="https://crates.io/" rel="noopener" target="_blank">crates.io</a> or get too fancy with specifying git dependencies in our <code>Cargo.toml</code>. When the time comes to publish these libraries as open source, it's trivial to break it out into its own repo.</p><a href="#library,-binary,-why-not-both" id="library,-binary,-why-not-both"><h3>Library, binary, why not both?</h3></a><p>We have one main library crate that contains a unified API for talking to hardware, media codecs, network protocols, etc. Outside of that private API, we also have standalone crates in our workspace that we consider candidates for open-sourcing. For example, we’ve written our own actor framework fit for long-running high-throughput actors, as well as our own network protocol for reliable, high-bandwidth, low-latency media streaming.

We use separate binaries for different parts of the tonari system and each of these lives in <code>binaries</code>, a combination library/binary crate. Its library modules contains a set of reusable actors that combine our private API with our actor system, and then a collection of individual binaries that consume these actors and define the plumbing between them.</p><a href="#flags-as-far-as-the-eye-can-see" id="flags-as-far-as-the-eye-can-see"><h3>Flags as far as the eye can see</h3></a><p>We make extensive use of feature flags to allow development of our project on different OSes (like Brian's 1970s-era MacBook Pro) or different hardware configurations. This allows us to easily swap out camera hardware without extra runtime checks or using awful <code>sed</code> hacks.

For example, Linux uses <code>v4l2</code> (Video For Linux...2) to access most webcams, but other webcams might have their own SDK.  To compile for platforms that don't use <code>v4l2</code> or when an SDK isn't available for a particular OS, we can put those SDKs behind feature flags and export a common interface.

As a (simplified) concrete example, let's say we have a common camera interface defined as a trait:</p><pre><code><span>pub</span> <span>trait</span> Capture <span>{</span>
    
    <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span><span>;</span>
<span>}</span></code></pre><p>Let's also say we have three different camera interfaces - <code>v4l2</code>, <code>corevideo</code>, and <code>polaroid.</code> We can make our binaries work exclusively with this trait to be flexible, and we can swap in different implementations of <code>Capture</code> with feature flags.</p><pre><code><span>#[cfg(feature = "v4l2")]</span>
<span>mod</span> v4l2 <span>{</span>
    <span>pub</span> <span>struct</span> V4l2Capture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> V4l2Capture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>mod</span> corevideo <span>{</span>
    <span>pub</span> <span>struct</span> CoreVideoCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> CoreVideoCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>mod</span> polaroid <span>{</span>
    <span>pub</span> <span>struct</span> PolaroidCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> PolaroidCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "v4l2")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> v4l2<span>::</span>V4l2Capture<span>;</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> corevideo<span>::</span>CoreVideoCapture<span>;</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> polaroid<span>::</span>PolaroidCapture<span>;</span></code></pre><p>If we make our code work with things which implement the <code>Capture</code> trait instead of concrete types, we can now compile on and target various platforms by simply toggling feature flags. For example, we can have a struct which has a field - <code>video_capture: Box&lt;dyn Capture&gt;</code> which will let us store any type which can <code>Capture</code> from a camera.

An example <code>Cargo.toml</code> file to support the capture implementations we wrote above might look something like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tonari.no/why-we-love-rust?ref=twtr">https://blog.tonari.no/why-we-love-rust?ref=twtr</a></em></p>]]>
            </description>
            <link>https://blog.tonari.no/why-we-love-rust?ref=twtr</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649534</guid>
            <pubDate>Fri, 26 Jun 2020 07:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A multiplayer board game in Rust and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23649369">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | http://www.mattkeeter.com/projects/pont/ | <a href="https://web.archive.org/web/*/http://www.mattkeeter.com/projects/pont/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->


<h2>A multiplayer board game in Rust and WebAssembly</h2>
<p><a href="https://pont.mattkeeter.com/">
<img src="http://www.mattkeeter.com/projects/pont/screenshot.png">
</a></p><p>
<a href="https://pont.mattkeeter.com/">Click to play!</a>
</p>
<p><em>Pont</em> is an online implementation of
<a href="https://en.wikipedia.org/wiki/Qwirkle">Qwirkle, a board game by Mindware Games</a>.
It was written for my parents,
so they could play with friends and family during the COVID-19 stay-at-home era.</p>
<p>Play is split into <strong>rooms</strong>,
which are identified by a three-word code
(<code>size moody shape</code> in the image above).
Within each room,
the game distributes pieces,
enforces the game rules,
and provides a local chat window.</p>
<p>Unusually, it's a web-based multiplayer game <strong>without any Javascript</strong>:
both the client and server are written in <a href="https://www.rust-lang.org/">Rust</a>,
which is compiled into <a href="https://webassembly.org/">WebAssembly</a> to run on the browser.
(There's a Javascript shim to load the WebAssembly module, but I didn't have to write it myself)</p>
<h2>Architecture</h2>
<p>Keep in mind, I'm <em>not a web developer</em>,
so this is probably a weird <a href="https://en.wikipedia.org/wiki/Outsider_art">outsider architecture</a>
for web applications.
Here's what the system looks like:</p>
<p><img src="http://www.mattkeeter.com/projects/pont/diagram.svg" alt="Diagram"></p>
<p>The system uses <a href="https://letsencrypt.org/">Let's Encrypt</a> for certificates:
both static assets and WebSocket communication are encrypted
between the client and the server.
The game server does not communicate securely with the NGINX proxy,
but if anyone is on the server watching,
I've got bigger problems.</p>
<p>The <code>wasm</code> bundle and <code>pont-server</code> executable are both
written in Rust and managed in the <a href="https://github.com/mkeeter/pont"><code>pont</code> repository</a>.
They both depend on <a href="https://github.com/mkeeter/pont/blob/master/pont-common/src/lib.rs"><code>pont-common</code></a>,
which defines basic types and logic for gameplay
(e.g. so that both the client and server can check whether a move is legal).</p>
<p>The client and server communicate via <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API">WebSockets</a>.
Messages are strongly typed as an <a href="https://github.com/mkeeter/pont/blob/master/pont-common/src/lib.rs#L7-L48"><code>enum</code> in <code>pont-common</code></a>,
serialized using <a href="https://serde.rs/">Serde</a>,
and packed into <a href="https://github.com/servo/bincode">bincode</a>
to be sent as binary WebSocket messages.</p>
<h2>Server</h2>
<p>The game server using async Rust,
which was... exciting:</p>
<ul>
<li>There's a <a href="https://www.reddit.com/r/rust/comments/ej649l/a_summary_of_the_current_state_of_async_rust/fcw16a9/">"very polite cold war"</a>
going on between the two major (incompatible?) runtimes,
with packages that only work in one or the other</li>
<li>An <a href="https://docs.rs/futures/0.3.5/futures/channel/mpsc/index.html">infinite</a>
<a href="https://docs.rs/tokio/0.2.21/tokio/sync/mpsc/fn.channel.html">supply</a>
<a href="https://docs.rs/crossbeam-channel/0.4.2/crossbeam_channel/">of</a>
<a href="https://docs.rs/futures/0.3.5/futures/channel/oneshot/fn.channel.html">options</a>
<a href="https://docs.rs/futures-channel-preview/0.3.0-alpha.19/futures_channel/index.html">for</a>
<a href="https://doc.rust-lang.org/std/sync/mpsc/index.html">channels</a></li>
<li>General confusion between <a href="https://docs.rs/futures/0.3.5/futures/"><code>futures</code></a>,
<a href="https://doc.rust-lang.org/std/future/index.html"><code>std::Future</code></a>, and
<a href="https://docs.rs/futures-util/0.3.5/futures_util/"><code>futures_util</code></a>
(exacerbated by the fact that Googling for things will land you
into a random version of the docs)</li>
<li>Error messages that rival C++ in incomprehensibility</li>
</ul>
<p>To be fair, the Rust <code>async</code> ecosystem is relatively new,
so most of this can be ascribed to growing pains;
I'm sure that the ergonomics and library situation
will improve over time.</p>
<p>I ended up using the <a href="https://github.com/stjepang/smol"><code>smol</code> runtime</a>
because it's got relatively few dependencies,
and I appreciated that it wasn't trying to own the entire async universe
(unlike Tokio and <code>async-std</code>).</p>
<p>After getting over those hurdles,
the server architecture is relatively straightforward.
A bunch of independent tasks run asynchronously,
communicating to the outside world via WebSockets
and internally via <a href="https://docs.rs/futures/0.3.5/futures/channel/mpsc/fn.unbounded.html">unbounded MPSC queues</a>.</p>
<p>Here's an example of the server running one game (with two players),
plus one new client who has just connected.  Each rectangle
represents an async task:</p>
<p><img src="http://www.mattkeeter.com/projects/pont/server.svg" alt="Server"></p>
<p>The system has <code>2 + n_players + n_games</code> async tasks running at one time:</p>
<ul>
<li>A top-level task which accepts incoming connections.</li>
<li>A top-level task which logs the number of active rooms, once per minute</li>
<li>One async task per client connection, which passes messages between the WebSocket connection
and the application's internal queues.</li>
<li>One async task per room, which handles game state</li>
</ul>
<p>These tasks each map to a <a href="https://docs.rs/smol/0.1.10/smol/struct.Task.html"><code>smol::Task</code></a>.
(As a small optimization,
the first player's <code>Task</code> handles both the player communication
and running the room, which is why they're both blue in the diagram above)</p>
<p>The server compiles down to a 5 MB static binary.
The whole system is hosted on the smallest VM offered by
<a href="https://www.digitalocean.com/">Digital Ocean</a>,
which is a $5/month machine.
I'm looking forward to the inevitable <a href="https://news.ycombinator.com/">Hacker News</a>
<a href="https://en.wikipedia.org/wiki/Slashdot_effect">DDOS</a>,
where I can see how well it scales!</p>
<h2>Client</h2>
<p>The client is <a href="https://github.com/mkeeter/pont/blob/master/pont-client/src/lib.rs">2000 lines of framework-less excitement</a>.
It uses a
<a href="https://en.wikipedia.org/wiki/Finite-state_machine">state machine pattern</a>
to represent the flow of the game,
accepting messages from the server
and updating the state accordingly:
for example, top-level state flows from
<code>Connecting</code> to <code>CreateOrJoin</code> to <code>Playing</code>.</p>
<p>The game board is represented as an SVG;
everything else is standard HTML elements.
In fact, the whole UI is pre-constructed in
<a href="https://github.com/mkeeter/pont/blob/master/pont-client/deploy/index.html"><code>index.html</code></a>
and revealed on demand.</p>
<p>The client has a bit of polish:
Pieces are animated as they move around the board,
and there's an optional color-blind mode,
which adds corner markings to indicate color.</p>
<p><img src="http://www.mattkeeter.com/projects/pont/cb.png" alt="Color-blind mode"></p>
<p>I use direct DOM manipulation
(from the <a href="https://rustwasm.github.io/wasm-bindgen/api/web_sys/"><code>web-sys</code></a> crate)
to control the system.
This exercise has left me appreciating the usefulness of virtual DOMs,
but I didn't want to bring in the complexity of a framework.
(Is there a Rust + <code>wasm</code> version of <a href="https://svelte.dev/">Svelte</a> yet?)</p>
<p>For deployment,
I'm using <a href="https://rustwasm.github.io/wasm-pack/"><code>wasm-pack</code></a>
and serving the resulting <code>wasm</code> blob from the same server as the other static assets.</p>
<p>The main challenges on the client side were
(of course) dealing with cross-browser compatibility:
Safari, in particular, supports fewer features
and has funky handling of touch events.</p>
<h2>Conclusions</h2>
<p>After a bit of a learning curve,
this all worked surprisingly well!</p>
<p>The client side is still a bit messy,
with animations, UI inputs,
and server events all fighting to break the system's invariants.
For example,
there was a nasty bug where dragging the board while
an animation was running could drop the system into an invalid state.</p>
<p>This isn't surprising:
stateful UIs are hard,
which explains the popularity of declarative approaches.
At this point, the client is feature-complete
and hasn't quite collapsed under its own weight,
so I'm not inclined to do any dramatic refactorings.</p>
<p>Rust as a language continues to be great,
despite minor complaints.
I already discussed the async ecosystem above,
and won't dwell on that any further.
On the client side,
there are often impedance mismatches with WebAssembly:
for example, using Rust closures as callbacks
requires
<a href="https://github.com/mkeeter/pont/blob/master/pont-client/src/lib.rs#L1189-L1211">cryptic boilerplate</a>.</p>
<p>Still, with all of the pieces in place,
making changes is pleasantly fast,
and I trust the compiler to check that I haven't broken anything.</p>
<p>I'm particularly happy with the combination of WebSockets, Serde, and bincode:
having both the client and server process a strongly-typed stream of events
makes things easy to reason about.</p>
<h2>Links</h2>
<p><a href="https://pont.mattkeeter.com/">Play the game here</a>, or check out
<a href="https://github.com/mkeeter/pont">the source on Github</a></p>
<p><a href="https://news.ycombinator.com/item?id=23649369">Discussion on Hacker News</a></p>
<p>Questions?  Comments?  <a href="mailto:matt.j.keeter@gmail.com">Send me an email!</a></p>

<!-- Begin footer -->
</div></div>]]>
            </description>
            <link>http://www.mattkeeter.com/projects/pont/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649369</guid>
            <pubDate>Fri, 26 Jun 2020 06:44:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-Stacking the GUI Stack]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23649215">thread link</a>) | @todsacerdoti
<br/>
June 25, 2020 | https://genodians.org/nfeske/2020-06-23-gui-stack | <a href="https://web.archive.org/web/*/https://genodians.org/nfeske/2020-06-23-gui-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
        <div id="posting">
          <p><a href="https://genodians.org/nfeske/index">
            <img src="https://genodians.org/nfeske/author.png" alt="Norman Feske avatar">
           </a>
          </p>
          
          <p><span>June 23 2020 by
           <a href="https://genodians.org/nfeske/index">Norman Feske</a></span></p>
 <p>
  As I am currently right in the middle of a far-reaching rework of Genode's
  low-level GUI stack, I'd like to share a bit of background behind this work:
  the Why, the What, and the How.
 </p>
 <h4>
 <a name="Current_state"></a>
 Current state</h4>
  <p>
   The current incarnation of Genode's low-level GUI-related interfaces is almost
   identical to the very first version that we originally created in 2006.
   Genode has a very strong asymmetric notion of the
   <a href="https://genode.org/documentation/genode-foundations/20.05/architecture/Recursive_system_structure.html#Client-server_relationship">relationship</a>
   between client and server components. In this relationship, the client depends
   on the server but the server does not depend on the client.
  </p>
  <p>
   At the lowest level, the framebuffer driver and input driver(s) were
   envisioned as servers that provide the <i>Framebuffer</i> and <i>Input</i> session
   interfaces to higher-level GUI components. From our former academic view, this
   felt natural because those drivers <i>provide</i> <i>resources</i> to other components.
   Provide... serve... server! The nitpicker GUI server uses those low-level
   services to implement a higher level service that ultimately allows for the
   multiplexing of graphics and input.
   <a href="https://genode.org/documentation/genode-foundations/20.05/components/Common_session_interfaces.html#Nitpicker_GUI">Nitpicker</a>
   virtualizes the low-level framebuffer and input interfaces while supplementing
   the notions of visible views and input focus. Such a system looks as follows:
  </p>
  <p>
    <img src="https://genodians.org/nfeske/nitpicker_orig.png">
  </p>
  <p>
   The drivers and the nitpicker GUI server are displayed in red because they are
   servers. The GUI applications at the right are nitpicker clients. Nitpicker,
   in turn, is a client of the framebuffer and input drivers.
  </p>
  <p>
   The client interface of the nitpicker GUI server is success story. A few
   <a href="https://genode.org/documentation/release-notes/15.11#GUI_stack">evolutionary tweaks</a>
   notwithstanding, the original design scales up to the windowed working
   environment of Sculpt OS while retaining the tiny complexity of the nitpicker
   GUI server.
  </p>
  <p>
   However, the approach of modelling the framebuffer and input drivers as
   servers is a dead end, for the following reasons.
  </p>
  <ul>
   <li>
    <p>
     Drivers are sometimes extremely complex. When looking at the complexity of
     the Intel framebuffer driver (ported from the Linux kernel) for example, it
     feels foolish to trust that it won't fail. Because the nitpicker GUI server
     depends on the liveliness of the driver, however, the well-being of the
     driver is on the critical path for the entire GUI stack and all GUI
     applications.
    </p>
   </li>
   <li>
    <p>
     It is impossible to transparently restart or replace the driver at runtime
     without also restarting the GUI stack and - transitively - all GUI
     applications. This is because the nitpicker GUI server is connected as a
     client to the drivers. The connections are like a life supply for the GUI
     server. Cutting those would ultimately kill the GUI server.
    </p>
   </li>
   <li>
    <p>
     Adding secondary displays is rather difficult because this would require
     nitpicker to know what framebuffer servers are out there and to request
     multiple framebuffer connections. Adding such a protocol would inflate
     the complexity of nitpicker.
    </p>
   </li>
  </ul>
 <h4>
 <a name="Inverting_interfaces"></a>
 Inverting interfaces</h4>
  <p>
   To overcome these limitations, we must break the dependency of the GUI
   server from the drivers, like illustrated here:
  </p>
  <p>
    <img src="https://genodians.org/nfeske/nitpicker_next.png">
  </p>
  <p>
   In this scenario, the GUI server no longer <i>uses</i> the drivers, but the drivers
   use the GUI server. The relationship is reversed. Only the nitpicker GUI
   server remains red. Of course, the drivers cannot talk to nitpicker GUI
   server via nitpicker's regular client interface. Instead, two new interfaces
   enter the picture:
  </p>
  <div><dl>
   <dt>The <i>Capture</i> session interface</dt>
   <dd>
    <p>
     is like the inverse of the original
     <i>Framebuffer</i> session interface. It allows a client to obtain pixel data
     from the server. From the GUI server's perspective, a framebuffer driver
     is like a frame capturing device - which it is.
    </p>
   </dd>
   <dt>The <i>Event</i> session interface</dt>
   <dd>
    <p>
     is like the inverse of the original
     <i>Input</i> session interface. In contrast to a input session, which allows
     a client to obtain input events, an event session allows a client to
     induce input events. Nitpicker is an event server that consumes the input
     events from the driver(s).
    </p>
   </dd>
  </dl></div>
  <p>
   The benefits of this approach are manifold:
  </p>
  <ul>
   <li>
    <p>
     The low-complexity GUI server remains as the only component that must never
     fail, which makes the GUI stack much more resilient compared to today.
    </p>
   </li>
   <li>
    <p>
     Since the nitpicker GUI server no longer depends on the drivers, it can be
     started before the drivers are running, speeding up the boot time of
     graphical scenarios. In scenarios with rigid power management, we can remove
     the graphics driver - and switch off the graphics device - all while the GUI
     server and all GUI applications stay intact.
    </p>
   </li>
   <li>
    <p>
     Drivers can be restarted anytime. From the perspective of the nitpicker
     GUI server, this looks like a client disconnect and connect. Drivers
     can also be replaced at runtime, e.g., swapping out the VESA and Intel
     drivers.
    </p>
   </li>
   <li>
    <p>
     Connecting more than one driver to the nitpicker GUI server becomes
     conceptually simple. This clears the path towards multi-head support.
    </p>
   </li>
   <li>
    <p>
     The new capture session interface of the nitpicker GUI server would be
     the right hook for implementing screenshot/screencast applications, or a
     remote desktop server.
    </p>
   </li>
   <li>
    <p>
     Analogously to capture devices, input devices can enter and leave the
     system at any time without disruption, which will allow for the fine-grained
     management of USB HID devices. Think of plugging a new HID device to
     your Sculpt system. A new USB device would show up.
     The user can deploy the matching HID driver with the option of routing the
     event session of the driver to the system GUI server. Isn't that wonderful?
    </p>
   </li>
  </ul>
  <p>
   What is the downside? <i>It is a lot of work!</i> This leads us the following
   section.
  </p>
 <h4>
 <a name="The_plan"></a>
 The plan</h4>
  <p>
   Turning the low-level session interfaces upside down is an invasive operation
   that must be carried out in several steps, each yielding an intermediate
   consistent state.
  </p>
  <ol>
   <li>
    <p>
     We start off with some low-risk <b>cosmetic</b> changes, namely the renaming
     of the "Nitpicker" session interface to "Gui" session. The strange
     branding of the session interface after a particular implementation is a
     relic from the early days. This
     <a href="https://github.com/genodelabs/genode/issues/3778">change</a> has already
     entered Genode's master branch.
    </p>
   </li>
   <li>
    <p>
     Consistently use <b>32-bit RGB</b> as pixel format by all drivers and
     applications. This is a long-standing feature request that eliminates
     the need for color-space conversions and generally improves the output
     quality.
     It is quite labor-intensive because it requires me testing many
     different hardware platforms covering the drivers vesa_fb_drv, fb_sdl,
     intel_fb_drv, imx53_fb_drv, imx8_fb_drv, rpi_fb_drv, boot_fb_drv,
     omap4_fb_drv, exynos5_fb_drv.
     This <a href="https://github.com/genodelabs/genode/issues/3784">change</a> has already
     progressed well.
    </p>
   </li>
   <li>
    <p>
     Introducing the new <b>Capture</b> session <b>interface</b>.
    </p>
   </li>
   <li>
    <p>
     Implementing the <b>capture service</b> in the nitpicker GUI server.
    </p>
   </li>
   <li>
    <p>
     Introduce a <b>nitpicker</b> option to choose the framebuffer <b>back end</b> between
     the use of a requested framebuffer session (as done today), the use of a
     capture client for the pixel output, or the use of another GUI server
     (for stacking multiple instance of nitpicker).
    </p>
   </li>
   <li>
    <p>
     Turn "Framebuffer" <b>drivers</b> into "Capture" clients, covering all the
     drivers mentioned above. Shoveling code. Adjusting all existing
     scenarios to use nitpicker's capture service.
    </p>
   </li>
   <li>
    <p>
     <b>Pruning</b> the remaining use of the <b>framebuffer client</b> interface.
     In fact, when done, I want to remove the <tt>Framebuffer::Connection</tt>
     completely. This will require the reworking of the terminal, MESA back end,
     several tests, and the liquid_framebuffer. In the process, I hope to largely
     eliminate the use cases of the nit_fb (now called gui_fb) component so
     that this component can be removed in the end.
    </p>
   </li>
   <li>
    <p>
     <b>Turning</b> a few other <b>framebuffer clients</b> into "Capture" servers, in
     particular test-framebuffer, fb_bench, and test-driver_manager.
    </p>
   </li>
   <li>
    <p>
     <b>Removal</b> of the "Framebuffer" <b>session interface</b>, retaining the interface
     merely as a part of the GUI session.
    </p>
   </li>
   <li>
    <p>
     Introducing the new <b>Event</b> session <b>interface</b> and adding its implementation
     to the nitpicker GUI server.
    </p>
   </li>
   <li>
    <p>
     Adding a new <b>event_filter component</b> taking the place of the input_filter.
    </p>
   </li>
   <li>
    <p>
     With the structural changes done, it would be time for optimizations.
     As a prerequisite for tear-free animations, the <b>frame buffering</b> will be
     moved from the clients into the nitpicker GUI server. At first, this will be
     transparent to most clients. The subsequent removal of client-side buffering
     is second independent step. As another optimization, I plan to go though all
     places that employed the dithering of pixels.
    </p>
   </li>
  </ol>
  <p>
   Of those topics, the rework of the framebuffer drivers is certainly the most
   elaborate one. I'm considering to drop the Exynos5 and OMAP4 drivers.
   Even though I strive for replacing the input session interface by the new
   event session interface, the scope of the task of reworking the input drivers
   is not yet completely tangible to me.
  </p>
          
        </div> <!-- posting -->
      </div></div>]]>
            </description>
            <link>https://genodians.org/nfeske/2020-06-23-gui-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649215</guid>
            <pubDate>Fri, 26 Jun 2020 06:15:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Capturing 54M Passwords with a Docker SSH Honeypot]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23649079">thread link</a>) | @rbekker87
<br/>
June 25, 2020 | http://sysadmins.co.za/capturing-54-million-passwords-with-a-docker-ssh-honeypot/ | <a href="https://web.archive.org/web/*/http://sysadmins.co.za/capturing-54-million-passwords-with-a-docker-ssh-honeypot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

		<!-- .post-header -->


		<div>
			<p><img src="https://res.cloudinary.com/rbekker/image/upload/v1539291851/ssh-docker-honeypot_eyhzc7.png" alt=""></p>
<p>The last couple of days I picked up on my ELK Stack a couple thousands of SSH Brute Force Attacks, so I decided I will just revisit my SSH Server configuration, and change my SSH Port to something else for the interim. The dashboard that showed me the results at that point in time:</p>
<p><img src="https://res.cloudinary.com/rbekker/image/upload/v1539292443/kibana-failed-ssh-auth_udkxkl.png" alt=""></p>
<p>Then I decided I actually would like to setup a SSH Honeypot to listen on Port 22 and change my SSH Server to listen on 222 and capture their IP Addresses, Usernames and Passwords that they are trying to use and dump it all in a file so that I can build up my own password dictionary :D</p>
<h2 id="sshconfiguration">SSH Configuration:</h2>
<p>Changing the SSH Port:</p>
<pre><code>$ sudo vim /etc/ssh/sshd_config
</code></pre>
<p>Change the port to 222:</p>
<pre><code>Port 222
</code></pre>
<p>Restart the SSH Server:</p>
<pre><code>$ sudo /etc/init.d/ssh restart
</code></pre>
<p>Verify that the SSH Server is running on the new port:</p>
<pre><code>$ sudo netstat -tulpn | grep sshd
tcp        0      0 0.0.0.0:222            0.0.0.0:*               LISTEN      28838/sshd
</code></pre>

<p>Thanks to <a href="https://github.com/random-robbie/docker-ssh-honey">random-robbie</a>, as he had everything I was looking for on Github.</p>
<p>Setup the SSH Honeypot:</p>
<pre><code>$ git clone https://github.com/random-robbie/docker-ssh-honey
$ cd docker-ssh-honey/
$ docker build . -t local:ssh-honepot
$ docker run -itd --name ssh-honeypot -p 22:22 local:ssh-honepot
</code></pre>
<p>Once people attempt to ssh, you will get the output to stdout:</p>
<pre><code>$ docker logs -f $(docker ps -f name=ssh-honeypot -q) | grep -v 'Error exchanging' | head -10
[Tue Jul 31 01:13:41 2018] ssh-honeypot 0.0.8 by Daniel Roberson started on port 22. PID 5
[Tue Jul 31 01:19:49 2018] 1xx.1xx.1xx.1x gambaa gambaa
[Tue Jul 31 01:23:26 2018] 1xx.9x.1xx.1xx root toor
[Tue Jul 31 01:25:57 2018] 1xx.2xx.1xx.1xx root Passw0rd1234
[Tue Jul 31 01:26:00 2018] 1xx.2xx.1xx.1xx root Qwer1234
[Tue Jul 31 01:26:00 2018] 1xx.2xx.1xx.1xx root Abcd1234
[Tue Jul 31 01:26:08 2018] 1xx.2xx.1xx.1xx root ubuntu
[Tue Jul 31 01:26:09 2018] 1xx.2xx.1xx.1xx root PassWord
[Tue Jul 31 01:26:10 2018] 1xx.2xx.1xx.1xx root password321
[Tue Jul 31 01:26:15 2018] 1xx.2xx.1xx.1xx root zxcvbnm
</code></pre>
<h2 id="savingresultstodisk">Saving results to disk:</h2>
<p>Redirecting the output to a log file, running in the foreground as a screen session:</p>
<pre><code>$ screen -S honeypot
$ docker logs -f f6cb | grep -v 'Error exchanging' | awk '{print $6, $7, $8}' &gt;&gt; /var/log/ssh-honeypot.log
</code></pre>
<p>Detach from your screen session:</p>
<pre><code>Ctrl + a; d
</code></pre>
<p>Checking out the logs</p>
<pre><code>$ head -3 /var/log/ssh-honeypot.log
2.7.2x.1x root jiefan
4x.7.2x.1x root HowAreYou
4x.7.2x.1x root Sqladmin
</code></pre>
<p>Leaving this running for a couple of months, and I have a massive password database:</p>
<pre><code>$ wc -l /var/log/honeypot/ssh.log
54184260 /var/log/honeypot/ssh.log
</code></pre>
<p>That is correct, 54 million password attempts. 5372 Unique IPs, 4082 Unique Usernames, 88829 Unique Passwords.</p>

		</div><!-- .post-content -->

		<!-- .post-footer -->

		<!-- .comments-area -->



	</article></div>]]>
            </description>
            <link>http://sysadmins.co.za/capturing-54-million-passwords-with-a-docker-ssh-honeypot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649079</guid>
            <pubDate>Fri, 26 Jun 2020 05:47:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Hitchhiker’s Guide to PlantUML]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23648957">thread link</a>) | @bambambazooka
<br/>
June 25, 2020 | https://crashedmind.github.io/PlantUMLHitchhikersGuide/ | <a href="https://web.archive.org/web/*/https://crashedmind.github.io/PlantUMLHitchhikersGuide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Tip</p>
<p><a href="http://www.plantuml.com/plantuml/svg/SYWkIImgAStDKU3YAYueoYn9LL39JImgoynJY3OqCgWmD37HDpIBLQZc0j1YTykjipeOWCzxDPX_7Kh2tFybRIJILB7PAtJIxvrfkfonyo1vGKpxh-ByCeVhlytNv-oC--_Wm_iG_3_oty1UsAjxN8x-7XRMkeUDvTsVmavKunxthELFOUigkoz_0dlhtjaRVVmHBEp2TS_SwT_3swvxpLLs7yDhrztpAXyVms7XkcNUTHk0jc5nOrJuZIknSBZB0BWFnpttBeTmlSquODw6_HqMOK_k9eGmGhkm51ntNOc5mz6VONLXjzL1tNtOodfHdy798Y00xy0-MdYwUx3aUC049aWRi0lntkbzsHq-I9TVNDY1nRt0RXyUvqh9Q5rXtyD2_hBJaf-AHycTh-e6FBnmBtY_PFbrq6om1FicFBpu2Upb5wbPfxmDXyzWV_WGJSd0U_0mFuTzRxRPEx0RwaTmq9y-P0Ia_OgFz2aSv6Skc8W2zoquV0vBNDS08lKjsCM_WAF09XlmaVu6zh-5VHBPmf9VmYB_5WuAVx9awdLXmcThxVmjVE_r_gF04QAe3BLMPB4tuG--5eF2YNkZMhAaL1Hw2_xWGK3XWBt3P2VDMx3Alt_MqypBSZjF2yDx-4ZlUos8BkX9aaVIl4fV52OY9gWF5Xdv7UmCV9Mbh91ogIEbJ6tQ8iW8a12Wf52844aEQaLYJaT-1_UuA5d0c4jvW47VifsEHIv9fM5AfK85WL5iQWt2E3UzXRs5PsAgY5A85-sMG-GSOynCIKwF2NZ22DIzarXuezSnPKqfuT-RDXzJJDZoNBLYVS9u7a-Oa5ZXTTAth4sRFQpnxJOrPcYexWYiO6HY1eNT6jRaYiYiRYnnOsCUaT8tZEqEDsgCc0USIiaBEZxKcc8YAdBlalTJrjURAgp8qvNm0YPYoccqkbO4nBg4WOOh90uvvU0r8UNuZxyuXUbApZjy4X8aD-2CX8qXNs6PgSJC86rEG6LeafW14OhGQzV0_GRdauWXz06xMg4nbbktMTWcjCoHYb4VyJDYpN8BSdYXZVfqqnqkPsidrpcTKa6TdnVu59GLhqA760KiQIuIWux-Kcmg9QaxKtzWUi2rSpjF0eLx1a90IA_iT6Uevc41Gid2YfmhGWx-cH1pvTQmfFX8w1Rs4pu5RfmdJ4CX9i1IgwgMdI50mZhP7xegFOj5RX9-qix2BKruVBR820EkrAIjqdj0KfRlQOrgjh3GCEcOAxMVaFR5zmKC_MGSCW_O8GyAILwuDM5NcSMyojh-MWfmipbrZDt0Q60QtD2_UXMtiHoAsdYT-O5maOKcrIvqwqkuTc6amrzP6aqypFx_M2I5xHsqASWB-W9pL1W4qHP_LHHulEW4MgRcIjpQclQ7Nz5IY8N9Fs4ckSbVohTPy1eMwldHUcnf-Q8CgMBJCB6bJ_w6yGTM1xz86jxaKDjv8Ii-fd5-o2mX45hcxeYNX3nlDPM2bZwP7l3nXCKb-9h_fGKcbE5UQwqq_v619pm3kcw97UPUEEe9N5EoKqiKCh3EuqO0zOlc2KrWlD5KKaQQHLfPw1H4zlByhCju4fgnn8IFCucL9WG3o_t8yhM8pE9EM6WJ0NCgf5112oijhdn7XoYPj3IZe5wPiMdu2UUcVNO3xeM8snE-qrXI0KGiDxYXoBFSHrALEL9IgZNhCBxpW0FLKdBi0dUep1PMsW249UUIywNLZHkNQ51n2vmoAp77LD3CGIfkmZfMD-5UvmAXy9ec0AIcUR84E62RLEN20RV6HfLn16VWeqzOPI8MU4rFQkR9nYDREEMAZVBXMM0Jmkp5NC8m90ClwVQK6sCDtZa39vd7CXXtu0lCaEtpVw01knUO1BxBXZP53C1PE0FoMKLuXNbM-meVPYSH0AaPU4dFfQXXYMwcA9nIGOIYm2jCLGPuWREu4vRa6tpljxgTizDCEALSOR31kIjCDRbR8e5xWLqbQSoQ_eRFXZb7R-0w7_cbnnRMAHWEju3vl6pQCX0tfZNzA1hIuMno8sMTpO6jKT7XhU1ssoqMe7_IaAAx9F6YhWC6As-kuSKsjIAIj9NMSd2t724iXFkR9ca1vwh2MYQwD5JYTdECh2gsCe3Gx-3_qMftEwwhEXp0xy_J1FnXSmcawwtEkszCd9OqqpLhh-tvNumgMSgle8P1XZGRBF27RiQHl5dW1bksOhAMwlHdE1EFq9-v2Na4Zi_z1bkus91LVTJVmHW5kwmgOdGiZ7TuZKnPcEMwUBV-7s3w3hPiwZ9nMUYsts6AWosgfPXCH7FdvF0ZtPz5xs-r1KVWNq-r1KMBJXa7lK_w3ekgNc4WFaFf_Zgb6tmFYS5CY5XixtQ7VKsumhp2zzpXUpOMOJ9O-sxq7Ru72IqqWjjVmcQFpAzGsknB_89q1huECURixTQFSDxly3VfhRKY8zhwXpGLaL9_b_PtT_RsWVV7v_hiQFp0PS5EHDmVxx6zcAUhQ8-7SyweK-gz-TegR17HChVmJPX_0WRfVO1C2FdjJbU6sGyf8l7m1YJJpAlfiX-DY0g6mtwwaWrENy8v0pD4mpXS631yXc5Ke4J3CDpVm7wUQEjECAoOCpxd-jrrE9iS2biolE1qWyr5-14OSC9tsGTizMno_Ej4ov3JpJKOVW3EVbpfyiZroDXSmb69XiqbN6MFknCcoC7mtDkiyjFEYpk240fdG5vWo6jMbrMsIFXuhCjENraB0DVQLRSmk1Gbm-2PV0duNxA-LPSj1S69UYl-8dc-l7MBjLjmss9Ws9ATUtsu7_5oeSxUKB5o14nfIsLVv9LEgxjRMXx5505ZJa1roEBoUzmj-sEu5RQqfH2O411DRcpmJSxkFYmLRHPYO64okpvCFkcxkvlRS1i9Wdd8281sKkJoZ9CMmCKrE0V2cORS68o-hLlkKd8uHS9JxW8BxIoMntJPt60O3QFsSDbncF5vxfBT3O95sFVJcUoSIX7Mc3lFGoLjJpXc0H6VwvIIc5neeT7SaQxvvSQirHlvN0yvInz8PNn5ZsxsueR05kGvrq-vxrK9FToQmGLURavR1Em_hulSMsMQuL9DLXYWZzOEMe9WCldSO6Qnuw9Q79O1D_75RBA1y3PWborSUwsAI3DrtWcv96u7WcAoqMO3bG7JsGjKNlT2zkbN6BofdYqeiA0KWor-IGEMR46mPK0glisq49zD1zy1keqZeR2tE2VjGN_9UOHm2VmAX4lrTWlFY66p029i1vF7zo8BXiD7vfc_Y8fFXJABnHiao1GxrIe7mDxcBENSSVlFFH_tHJDnB2ppyTwgJA2rUA6ymIWK2Iixx8zdXqNr2YSG38JB0llZzLpKNfKqkp0CiIFc2vnzUM9lB99d_iBYO5JHKjGGNqPo9lz6efwZXaW0KV1sF7OL2B9NH0XXROyJXS66CLxk6US3hdCDVoiHXi5oWnFW9pX16CnyJ6vAwudg2GjVfpfb284jeiku7EOJzjAh5hW3EU4fhx2AFaifViG6d-DAorJx8kvoJXw8W-tnpmLa1XmkzPGXUm13OPFFnmCWbtgKUg_djx8W4XF6_RYg3uoUTzLwEqfrNkfHyMXhoXe6OxMBCUquojVQ1cRkJ5alSBMsTmtzVznwxVl3Z3O--7YFj94oP4khpIhVm___tpzjd45h8p4CXU_pAyImaDlCFOImi8HDe2cba5EQWp9MR7LiETXomz0_NwVJGW-zYCTxJtpw1Mhoo7B5X0467uk1z-QCmsXJB6B-HHyJt1mhrUgSVpqMmGpjQhZdIvjmMg_-pC5wrN-wwxPf92g1fuj2l7plBQ7TmOspWocMXO7NaXMKl8T0a50TfHS1TLX7cbWiQ0GIYvOWJ5MfAvanXzewqu0b4-p0uHl9Gi76oXBgsfcTsBeVy3jxKKdgM4Quonbl8noFJlMQbtq_9CoEJ60ndULAEtSS-oUFeeVzmvPrS8v7Ilb_OKFz8-ajfl6GgxF7mR5G_jNid0OFsytpvdG2bgo4fklgfT3y9J4b-0y0"><img alt="playbutton_index" src="https://crashedmind.github.io/PlantUMLHitchhikersGuide/_images/play6.png"></a> <strong>Press play</strong></p>
<blockquote>
<div><p>Imagine being able to</p>
<ol>
<li><p>share a model or diagram between all members of the team that they can all understand and contribute to and edit</p></li>
<li><p>draw diagrams like below automatically from a text description.</p></li>
<li><p>describe a system before you build it, when you’re building it, and as you maintain it into the future - keeping the description and the system current, and in sync.</p></li>
<li><p>maintain that text version in a source code repository beside the code for the system it is describing</p></li>
</ol>
<p>Imagine having a diagramming tool that</p>
<ol>
<li><p>fits with a developer workflow, and developers are comfortable using</p></li>
<li><p>enables <strong>lightweight just-enough</strong> <a href="http://agilemodeling.com/essays/barelyGoodEnough.html">AgileModeling</a> in a way that meets <a href="https://tdan.com/best-practices-for-agile-documentation/18936">AgileModelingBP</a></p></li>
<li><p>fits with modern practices of Continuous Integration Continuous Delivery - and “everything as code” including diagrams.</p></li>
</ol>
<p>Well that’s what PlantUML gives you, and more…</p>
</div></blockquote>
</div></div>]]>
            </description>
            <link>https://crashedmind.github.io/PlantUMLHitchhikersGuide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23648957</guid>
            <pubDate>Fri, 26 Jun 2020 05:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promote Imperfect People]]>
            </title>
            <description>
<![CDATA[
Score 4 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23647901">thread link</a>) | @svmanager
<br/>
June 25, 2020 | https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>You’ve likely experienced it: “You’re above and beyond everything we’re asking. There’s no promotion this round but all you need to do is <strong>__</strong>_”. Insert a semi-important but not absolutely necessary thing. Even worse if it’s something you’re really not good at.</p>

<p>One of the most demotivating things that an organization or manager can do is requiring “perfection” for a promotion. It’s a problem with two main dimensions:</p>
<ul>
  <li>It’s incommensurate with the value being added to the business.</li>
  <li>Perfection is subjective.</li>
</ul>

<h2 id="incommensurate-with-value-add">Incommensurate with Value-Add</h2>

<p>Ultimately all performance comes down to one thing: how much value are you adding to the business? Examples of where forcing perfection gets things out of whack:</p>
<ul>
  <li>I coded up a feature that brought in $10M to the business this year. I wasn’t promoted because they said I don’t speak enough in meetings.</li>
  <li>I saved the company from collapse because I was the only one who knew how to debug the system when it was melting. I wasn’t promoted because they said I show up too late every day.</li>
  <li>I identified a winning strategy for the entire business that drove us to another echelon of success. I wasn’t promoted because my design docs have typos.</li>
</ul>

<p>All that matters is the value being added to the business. There are nuances where behavior can set bad examples or cause issues for others, but that detracts from value added to the business and should be considered. The unfortunate and unbelievably common case is that some sort of benign missing strength is held against people.</p>

<h2 id="perfection-is-subjective">Perfection is Subjective</h2>

<p>When managers go down the rabbit whole of chasing perfect promotions they’re much more likely to be biased. In reality, most people’s internal picture of a perfect candidate for a promotion is something like “what did I look like when I got promoted?” That’s often the closest image a manager has of what a promotion at that level looks like.</p>

<p>In mild cases you get things like “when I got promoted I had to walk in the snow to work, uphill both ways.”</p>

<p>In more severe cases you get things like:</p>
<ul>
  <li>Men who don’t promote women because they’re not “aggressive enough” or they “don’t speak up enough”</li>
  <li>Extroverts who don’t promote introverts because they don’t like public speaking.</li>
  <li>Non-parents who don’t promote parents because they don’t work until midnight in the office.</li>
</ul>

<p>Promote people based on impact to the business, not their style of delivery.  Don’t hold people down because they deliver value in a way that isn’t comfortable, known, or practiced by you.</p>

<h2 id="conclusion">Conclusion</h2>

<p>In promotions and growth, focus more on amplifying strengths than fixing “weaknesses”.  You’ll find it’s much easier and much more fruitful to have people play to their strengths.</p>

<p>Promote imperfect people - that’s all you’ve got.</p>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/management/2020/06/23/Promote-Imperfect-People.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647901</guid>
            <pubDate>Fri, 26 Jun 2020 01:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The War on Upstart Fiber Internet Providers]]>
            </title>
            <description>
<![CDATA[
Score 533 | Comments 232 (<a href="https://news.ycombinator.com/item?id=23647609">thread link</a>) | @joecool1029
<br/>
June 25, 2020 | http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/ | <a href="https://web.archive.org/web/*/http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>                                
                                    <div> 
                                        <p>As someone who grew up throughout the 90's and 00's, some of my fondest memories stem from progressive advancements in internet and computing technologies.  Upgrading from Dial-Up internet to DSL was a grand event in our house.  I remember my brother and I fighting over the computer day in and day out to play games like Wolfenstein - Enemy Territory, which was released in 2003. (I'm convinced that this will be the all-time best FPS game ever created.)  At around the same time, we upgraded to one of the best Dell computer's available at the time. It had 512MB of RAM and a Pentium 4 processor.  This was a major upgrade from our Compaq Celeron, which had something like 64MB of RAM. <br>
<img src="http://chrishacken.com/content/images/2020/03/MV5BOGFmNjMzZTktNDg2ZS00ZjllLTlkMTAtZTAzMzBkN2UyMzk2XkEyXkFqcGdeQXVyMjU3MzI1NzI@._V1_.jpg" alt="Wolfenstein - Enemy Territory"></p>

<p>Eventually, the grandeur of DSL faded as the rest of the world began to adopt Cable and Fiber internet.  It wasn't until I briefly moved to Philadelphia that I was finally able to experienced what I had been missing out on.  In college I lived in a neighborhood that was one of Verizon's first Fios builds.  I was absolutely blown away by the 25 Mbps connection.  This was in 2009. I'm amazed that over a decade later, in 2020, some households still don't have access to cable or fiber internet yet.</p>

<p>Like many of our customers do now, I could never figure out why it was so difficult to get us fiber service.  The cable is cheap, just throw it up on a pole and give me internet! Right?  Well, not so fast... <br>
<img src="http://chrishacken.com/content/images/2020/03/1849761.jpg" alt="Fiber Spaghetti"></p>

<p>A quick overview of how utility services are run and the challenges involved...</p>

<p>As most people know, there are primarily two ways to deliver utility services to a home or business.  Aerial and underground.  Water, gas, and sewer are always serviced underground for obvious reasons.  Electric, telephone, cable, and fiber have the ability to either be above or below ground.</p>

<h3 id="aerial">Aerial.</h3>

<p>As with anything else, aerial has pro's and con's.</p>

<p>The pro's are primarily upfront costs (this is debatable) and speed of deployment (this is also debatable).</p>

<p>The con's are that contrary to it being cheaper to physically deploy, the pole owners generally charge up-front make ready fee's.  These fees can range from $0 to upwards of $50,000/mile.  It's essentially pay to play.  If we want to attach to 50 poles, the pole owner might determine that 10 of those poles are old and need to be replaced before we can attach to them.  Rather than fork up the cash themselves, they'll force us to pay to replace their poles in order to approve the attachment.</p>

<p>In addition to that, there are the annual pole fee's.  Depending on your agreement, we've seen pole fee's ranging anywhere from $7/pole per year all the way up to $43/pole per year with 10% annual increases (I'm looking at you PPL.  This ridiculous rate was purely intended to keep us from attaching to their poles, IMO.  It's impossible to make money with these rates). <br>
<img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-22.04.34.png" alt="Pole Rates"></p>

<p>Another con is that even though installing the cable on poles is faster, it usually takes the pole owner around 6 months just to review applications and to determine make ready requirements and costs.  As an example, if we have fiber on a pole that's 1 pole short from being able to service your house, it would take at least 6 months just to run fiber to that one additional pole. So close, yet so far.</p>

<h3 id="underground">Underground.</h3>

<p>Like aerial, underground has its own list of pro's and con's.</p>

<p>When you install a service underground, you own it for life.  There are no annual fee's.  You pay one time to install it and you're set for life.  This sounds like a pro, but it's also a con.  When we run metro conduit, it generally costs us between $15-25/ft (not including customer drops).  For the sake of argument, let's assume we're at the high-end of our costs.  If we install 1,000ft of conduit, that's $25,000 that we need to pay out of pocket upfront.  Some blocks have upwards of 30 customers, but others have as little as 5.  Let's average it out at 20 customers per block, that's $1,250 upfront per customer, assuming we get every single customer.  Conservatively, we're initially looking at a 50% take rate.  This could grow to 100% overtime, but we never make that assumption. So that's $2,500/customer.  Imagine spending $2,500 per house/building and then have them tell you that your $69/m service is too expensive.  Generally speaking, we won't do a street unless our numbers look better than this, but this is a realistic scenario as we scale and get access to cheaper capital, etc.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/enorthampton01.jpg" alt="Underground Construction">
<img src="http://chrishacken.com/content/images/2020/03/enorthampton02.jpg" alt="Underground Construction Restoration"></p>

<h3 id="politics">Politics</h3>

<p>Cost issues aside, there are a number of other hurdles one needs to get past just to begin the process of building out a network.  You'd think that risking everything you have in an effort to bring your local economy into the 21st Century would be a welcome sight.  That's what I thought too; was I wrong.  While there are plenty of supporters (I truly appreciate you all), there are just as many, if not more, critics.</p>

<p>We've been fortunate enough to have had a handful of people get behind us overtime and give us a shot.  I'm sure others haven't had it so easy.  I know this because even after we've become an established player in our city throughout the past 4 years, neighboring townships and municipalities haven't been as opened armed to welcome us into their communities as I had anticipated or would have liked.</p>

<p>I'll go into more detail on small government policies that really hamper our ability to deploy underground later below.</p>

<h3 id="toomanyopinions">Too Many Opinions</h3>

<p>I'm generally a big fan of individual citizens trying to make an impact in their communities.  However, in too many cases these contributions seem to be made in the form of unproductive complaints rather than productive feedback or action.  Far too many people have a say in things that they probably shouldn't.</p>

<p><strong><em>Case A.</em></strong></p>

<p>A new customer had recently signed an agreement with us to run fiber into their building.  This is a non-profit who's members are selflessly donating their time to restore a landmark in the community.  Upon receiving their signature, I notified the city that we would be pulling a permit to connect the building in question to our underground network.  They said okay; that was that.  Our nearest existing hand hole is approximately 90ft to the right of the new customer's property; in front of another property.  As a courtesy, I notified the manager of that establishment to let her know that we would be performing work over the weekend, from Friday into Saturday.  They're closed Saturday and Sunday so I had assumed they would appreciate the notice and possibly even sign up with us.  The project would involve removing 90ft of sidewalk, running conduit, and then restoring the sidewalk with brand spankin' new concrete.  The total timespan that this would occur, from when our shovel hit the ground to having new sidewalks in place, would be 48 hrs.  The response that I received from a member of their organization made me facepalm.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-18.53.55-copy.png" alt="Sidewalk Issues"></p>

<p>Not long after receiving this email, I became aware that they didn't even own the building in question, nevermind the sidewalk.  They lease it.  This was eventually "resolved" after a series of negotiations between the non-profit's president and the establishment in question.  Often times we aren't as lucky.</p>

<p>We initially planned to have this new customer installed within a week of them signing the contract.  Now it will end up being around 2 months from start to finish.  Long story short, I learned my lesson in trying to be courteous.</p>

<p><strong><em>Case B.</em></strong></p>

<p>Last year we were installing conduit for our fiber optic network.  There were countless instances where people would literally stop their cars, roll down their windows, and yell profanities at us.  In what world is that acceptable behavior for an adult? I can't imagine being so far off my rocker that I would feel the need to yell at a bunch of construction workers trying to build a fiber optic network (not that they had any idea what we were doing).  If these are the types of people influencing decisions, there's something wrong.</p>

<p>City workers have a tough job fielding complaints from people like this and I commend them for it.  It shouldn't affect policy though.</p>

<p><strong><em>Case C.</em></strong></p>

<p>In another incident that took place not long, maybe a day or two, after <em>Case B</em> above.  A local store owner came back to us as we're swinging pick axes in 95 degree heat telling us we need to hurry up and we should hire more workers.  "My customers keep calling saying there's no where to park."  Mind you, we're standing right next to a massive parking lot that is approximately 1/3rd full.  I made my best attempt to kindly explain that paying 3 guys to stand around a hole to watch one person hand-dig to expose a utility isn't going to make our work go any faster.  I don't think he liked my response.</p>

<h3 id="theconsequences">The Consequences</h3>

<p>In many cases, resident complaints are justified.  Utility providers need to be held accountable for shitty restoration work.  However, the way in which bad restoration work is being combated is counter productive.  There has been a huge increase in curb-to-curb restoration requirements by local governments.  Essentially what these rules state is that anytime a utility cuts asphalt beyond a predetermined length, say 100ft, they are then responsible for replacing the entire road surface from the curb on the left side of the street to the curb on the right side of the street.  I believe some municipalities are also trying to introduce these measures to offload the costs of repaving roads themselves, similar to how pole owners force you to replace their aging utility poles under their make-ready requirements.  (One municipality told me as much when I attended a local council meeting in an effort to get them to waive this ridiculous ordinance for us.)</p>

<p>These policies will ultimately do more harm than good.  For us, these are the one and only thing preventing us from providing superior fiber internet services in these areas.  Forcing curb-to-curb asphalt …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</a></em></p>]]>
            </description>
            <link>http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647609</guid>
            <pubDate>Fri, 26 Jun 2020 00:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Santa Cruz bans predictive policing]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23647504">thread link</a>) | @wturner
<br/>
June 25, 2020 | https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing | <a href="https://web.archive.org/web/*/https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-01f39fcbb7868f9a53a1"><div><div><p>As officials mull steps to tackle police brutality and racism, California’s Santa Cruz has become the first&nbsp;U.S. city to ban predictive policing, which digital rights experts said could spark similar moves across the&nbsp;country.&nbsp;</p><p>“Understanding how predictive policing and facial recognition can be disportionately biased against&nbsp;people of color, we officially banned the use of these technologies in the city of Santa Cruz,” Mayor&nbsp;Justin Cummings said on Wednesday.&nbsp;</p><p>His administration will work with the police to “help eliminate racism in policing”, the seaside city’s first&nbsp;male African-American mayor said on his Facebook page, following a vote on Tuesday evening.&nbsp;</p><p>Used by police across the United States for almost a decade, predictive policing relies on algorithms to&nbsp;interpret police records, analyzing arrest or parole data to send officers to target chronic offenders, or&nbsp;identifying places where crime may occur.&nbsp;</p><p>But critics says it reinforces racist patterns of policing - low-income, ethnic minority neighbourhoods&nbsp;have historically been overpoliced so the data shows them as crime hotspots, leading to the deployment&nbsp;of more police to those areas.&nbsp;</p><p>“As Santa Cruz rightly recognized, predictive policing and facial recognition are dangerous, racially&nbsp;biased technologies that should never be used by our government,” said Matt Cagle, a lawyer with the&nbsp;ACLU.</p></div><p>PredPol Inc, the Santa Cruz-headquartered firm that pioneered the technology, said that it supported the city resolution’s requirement that predictive policing “will not perpetuate bias”, among other criteria. </p><p>  “Given the institutionalized state of racial inequality in America, this is a legitimate filter to be applied to any new technology acquired by a public entity, whether used for public safety or not,” it said on Twitter on Tuesday.   </p><p>Boston’s city council on Wednesday voted to ban face surveillance technology, a move also welcomed by digital rights activists.</p><p>Continue reading <a href="https://www.reuters.com/article/us-usa-police-tech-trfn/california-city-bans-predictive-policing-in-u-s-first-idUSKBN23V2XC">here</a></p></div></div></div>]]>
            </description>
            <link>https://www.santacruzworks.org/news/santa-cruz-is-the-first-city-to-city-ban-predictive-policing</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647504</guid>
            <pubDate>Fri, 26 Jun 2020 00:39:54 GMT</pubDate>
        </item>
    </channel>
</rss>
